<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 20 Jun 2024 20:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Small claims court became Meta's customer service hotline (168 pts)]]></title>
            <link>https://www.engadget.com/how-small-claims-court-became-metas-customer-service-hotline-160224479.html</link>
            <guid>40741197</guid>
            <pubDate>Thu, 20 Jun 2024 17:37:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.engadget.com/how-small-claims-court-became-metas-customer-service-hotline-160224479.html">https://www.engadget.com/how-small-claims-court-became-metas-customer-service-hotline-160224479.html</a>, See on <a href="https://news.ycombinator.com/item?id=40741197">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Last month, Ray Palena boarded a plane from New Jersey to California to appear in court. He found himself engaged in a legal dispute against one of the largest corporations in the world, and improbably, the venue for their David-versus-Goliath showdown would be San Mateo's small claims court.</p><p>Over the course of eight months and an estimated $700 (mostly in travel expenses), he was able to claw back what all other methods had failed to render: his personal Facebook account.</p><p>Those may be extraordinary lengths to regain a digital profile with no relation to its owner's livelihood, Palena is one of a growing number of frustrated users of Meta's services who, unable to get help from an actual human through normal channels of recourse, are using the court system instead. And in many cases, it's working.</p><p>Engadget spoke with five individuals who have sued Meta in small claims court over the last two years in four different states. In three cases, the plaintiffs were able to restore access to at least one lost account. One person was also able to win financial damages and another reached a cash settlement. Two cases were dismissed. In every case, the plaintiffs were at least able to get the attention of Meta’s legal team, which appears to have something of a playbook for handling these claims.</p><h2 id="why-small-claims"><strong>Why small claims?</strong></h2><p>At the heart of these cases is the fact that Meta lacks the necessary volume of human customer service workers to assist those who lose their accounts. The company’s official help pages steer users who have been hacked toward confusing automated tools that often lead users to dead-end links or emails that don’t work if your account information has been changed. (The company recently launched a $14.99-per-month program, Meta Verified, which grants access to human customer support. Its track record as a means of recovering hacked accounts after the fact has been spotty at best, according to anecdotal descriptions.)</p><p>Hundreds of thousands of people also turn to their state Attorney General’s office as some state AGs have made requests on users’ behalf — on Reddit, this is known as the “AG method.” But attorneys general across the country have been so inundated with these requests they formally asked Meta to fix their customer service, too. “We refuse to operate as the customer service representatives of your company,” a coalition of 41 state AGs wrote in <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1" href="https://www.engadget.com/41-state-attorneys-general-tell-meta-to-fix-their-customer-support-for-hacking-victims-184709904.html" data-ylk="slk:a letter;elm:context_link;elmt:doNotAffiliate;cpos:1;pos:1;itc:0;sec:content-canvas">a letter</a> to the company earlier this year.</p><p>Facebook and Instagram users have long sought creative and sometimes extreme measures to get hacked accounts back due to Meta’s lack of customer support features. Some users have resorted to <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1" href="https://www.vice.com/en/article/59vnvk/hacked-instagram-influencers-get-accounts-back-white-hat-hackers" rel="nofollow noopener" target="_blank" data-ylk="slk:hiring;elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1;itc:0;sec:content-canvas">hiring</a> their own hackers or <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1" href="https://www.npr.org/2021/08/02/1023801277/your-facebook-account-was-hacked-getting-help-may-take-weeks-or-299" rel="nofollow noopener" target="_blank" data-ylk="slk:buying;elm:context_link;elmt:doNotAffiliate;cpos:3;pos:1;itc:0;sec:content-canvas">buying</a> an Oculus headset since Meta has dedicated support staff for the device (users on Reddit report this “method” no longer works). The small claims approach has become a popular topic on Reddit forums where frustrated Meta users trade advice on various “methods” for getting an account back. People Clerk, a site that helps people write demand letters and other paperwork required for small claims court, published a <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1" href="https://www.peopleclerk.com/post/how-to-sue-facebook" rel="nofollow noopener" target="_blank" data-ylk="slk:help article;elm:context_link;elmt:doNotAffiliate;cpos:4;pos:1;itc:0;sec:content-canvas">help article</a> called “How to Sue facebook,” in March.</p><p>It’s difficult to estimate just how many small claims cases are being brought by Facebook and Instagram users, but they may be on the rise. Patrick Forrest, the chief legal officer for Justice Direct, the legal services startup that owns People Clerk, says the company has seen a “significant increase” in cases against Meta over the last couple years.</p><p>One of the advantages of small claims court is that it’s much more accessible to people without deep pockets and legal training. Filing fees are typically under $100 and many courthouses have resources to help people complete the necessary paperwork for a case. “There's no discovery, there are no depositions, there's no pre-trial,” says Bruce Zucker, a law professor at California State University, Northridge. “You get a court date and it's going to be about a five or 10 minute hearing, and you have a judge who's probably also tried to call customer service and gotten nowhere.”</p><h2 id="the-stakes"><strong>The stakes</strong></h2><p>“Facebook and Instagram and WhatsApp [have] become crucial marketplaces where people conduct their business, where people are earning a living," Forrest said. “And if you are locked out of that account, business or personal, it can lead to severe financial damages, and it can disrupt your ability to sustain your livelihood.”</p><p>One such person whose finances were enmeshed with Meta's products is Valerie Garza, the owner of a massage business. She successfully sued the company in a San Diego small claims court in 2022 after a hack which cost her access to personal Facebook and Instagram accounts, as well as those associated with her business. She was able to document thousands of dollars in resulting losses.</p><p>A Meta legal representative contacted Garza a few weeks before her small claims court hearing, requesting she drop the case. She declined, and when Meta didn’t show up to her hearing, she won by default. "When we went through all of the loss of revenues," Garza told Engadget, "[the judge] kind of had to give it to me.”</p><p>But that wasn’t the end of Garza’s legal dispute with Meta. After the first hearing, the company filed a motion asking the judge to set aside the verdict, citing its own failure to appear at the hearing. Meta also tried to argue that its terms of service set a maximum of $100 liability. Another hearing was scheduled and a lawyer again contacted Garza offering to help get her account back.</p><p>“He seemed to actually kind of just want to get things turned back on, and that was still my goal, at this point,” Garza said. It was then she discovered that her business’ Instagram was being used to advertise sex work.</p><p>She began collecting screenshots of the activity on the account, which violated Instagram’s terms of service, as well as fraudulent charges for Facebook ads bought by whoever hacked her account. Once again, Meta didn’t show up to the hearing and a judge ordered the company to pay her the $7,268.65 in damages she had requested.</p><p>“I thought they were going to show up this time because they sent their exhibits, they didn't ask for a postponement or anything,” she says. “My guess is they didn't want to go on record and have a transcript showing how completely grossly negligent they are in their business and how very little they care about the safety or financial security of their paying advertisers.”</p><p>In July of 2023, Garza indicated in court documents that Meta had paid in full. In all, the process took more than a year, three court appearances and countless hours of work. But Garza says it was worth it. “I just can't stand letting somebody take advantage and walking away,” she says.</p><p>Even for individuals whose work doesn't depend on Meta's platforms, a hacked account can result in real harm.</p><p>Palena, who flew cross-country to challenge Meta in court, had no financial stake in his Facebook account, which he claimed nearly 20 years ago when the social network was still limited to college students. But whoever hacked him had changed the associated email address and phone number, and began using his page to run scam listings on Facebook Marketplace.</p><p>“I was more concerned about the damage it could do to me and my name if something did happen, if someone actually was scammed,” he tells Engadget. In his court filing, he asked for $10,000 in damages, the maximum allowed in California small claims court. He wrote that Meta had violated its own terms of service by allowing a hacked account to stay up, damaging his reputation. “I didn't really care that much about financial compensation,” Palena says “I really just wanted the account back because the person who hacked the account was still using it. They were using my profile with my name and my profile image."</p><p>A couple weeks later, a legal rep from Meta reached out to him and asked him for information about his account. They exchanged a few emails over several weeks, but his account was still inaccessible. The same day he boarded a plane to San Mateo, the Meta representative emailed him again and asked if he would be willing to drop the case since “the access team is close to getting your account secure and activated again.” He replied that he intended to be in court the next day as he was still unable to get into his account.</p><p>Less than half an hour before his hearing was scheduled to start, he received the email he had spent months waiting for: a password reset link to get back into his account. Palena still attended the hearing, though Meta did not. According to court records reviewed by Engadget, Palena told the judge the case had been “tentatively resolved,” though he hasn’t officially dropped the case yet.</p><h2 id="the-hurdles-of-small-claims"><strong>The hurdles of small claims</strong></h2><p>While filing a small claims court case is comparatively simple, it can still be a minefield, even to figure out something as seemingly straightforward as which court to file to. Forrest notes that Facebook’s <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:5;pos:1" href="https://web.archive.org/web/20240617191705/https://www.facebook.com/legal/terms?paipv=0&amp;eav=AfZS6qv1h_Yae53lI1YzSLPqunlR5E-qm81YGS-4ha4JAWI3_ZwvsJwVSr94z6FVhhI&amp;_rdr" rel="nofollow noopener" target="_blank" data-ylk="slk:terms of service;elm:context_link;elmt:doNotAffiliate;cpos:5;pos:1;itc:0;sec:content-canvas">terms of service</a> stipulates that legal cases must be brought in San Mateo County, home of Meta’s headquarters. But, confusingly, the terms of service for Meta accounts <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:6;pos:1" href="https://webcache.googleusercontent.com/search?q=cache%3Ahttps%3A%2F%2Fwww.meta.com%2Flegal%2Fsupplemental-terms-of-service%2F&amp;rlz=1C5GCEA_enUS1076US1076&amp;oq=cache%3Ahttps%3A%2F%2Fwww.meta.com%2Flegal%2Fsupplemental-terms-of-service%2F&amp;gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRg60gEIMjk2MGowajeoAgCwAgA&amp;sourceid=chrome&amp;ie=UTF-8" rel="nofollow noopener" target="_blank" data-ylk="slk:states;elm:context_link;elmt:doNotAffiliate;cpos:6;pos:1;itc:0;sec:content-canvas">states</a> that cases <em>other than small claims court</em> must be filed in San Mateo. In spite of the apparent contradiction, some people (like Garza) have had success suing Meta outside of San Mateo.</p><p>Each jurisdiction also has different rules for maximum allowable compensation in small claims, what sorts of relief those courts are able to grant and even whether or not parties are allowed to have a lawyer present. The low barrier to entry means many first-time plaintiffs are navigating the legal system for the first time without help, and making rookie mistakes along the way.</p><p>Shaun Freeman had spent years building up two Instagram accounts, which he describes as similar to TMZ but with “a little more character.” The pages, which had hundreds of thousands of followers, had also been a significant source of income to Freeman, who has also worked in the entertainment industry and uses the stage name Young Platinum.</p><p>He says his pages had been suspended or disabled in the past, but he was able to get them back through Meta’s appeals process, and once through a complaint to the California Attorney General’s office. But in 2023 he again lost access to both accounts. He says one was disabled and one is inaccessible due to what seems like a technical glitch.</p><p>He tried to file appeals and even asked a friend of a friend who worked at Meta to look into what had happened, but was unsuccessful. Apparently out of other options, he filed a small claims case in Nevada in February. A hearing was scheduled for May, but Freeman had trouble figuring out the legal mechanics. “It took me months and months to figure out how to get them served,” Freeman says. He was eventually able to hire a process server and got the necessary signature 10 days before his hearing. But it may have been too late. Court records show the case was dismissed for failure to serve.</p><p>Even without operator error, Meta seems content to create hardship for would-be litigants over matters much smaller than the company's more headline-grabbing antitrust and child safety disputes. Based on correspondence reviewed by Engadget, the company maintains a separate "small claims docket" email address to contact would-be litigants.</p><p>Ron Gaul, who lives in North Dakota, filed a small claims suit after Meta disabled his account following a wave of what he describes as targeted harassment. The case was eventually dismissed after Meta’s lawyers had the case moved to district court, which is permissible for a small claims case under North Dakota law.</p><p>Gaul says he couldn’t keep up with the motions filed by Meta’s lawyers, whom he had hoped to avoid by filing in small claims court. “I went to small claims because I couldn't have a lawyer,” he tells Engadget.</p><p>Ryan, an Arizona real estate agent who asked to be identified by his first name only, decided to sue Meta in small claims with his partner after their Facebook accounts were disabled in the fall of 2022. They were both admins of several large Facebook Groups and he says their accounts were disabled over a supposed copyright violation.</p><p>Before a scheduled hearing, the company reached out. “They started basically trying to bully us,” says Ryan, who asked to be identified by his first name only. “They started saying that they have a terms of service [and] they can do whatever they want, they could delete people for any reason.” Much like Gaul, Ryan expected small claims would level the playing field. But according to emails and court records reviewed by Engadget, Meta often deploys its own legal resources as well as outside law firms to respond to these sorts of claims and engage with small claims litigants outside of court. "They put people that still have legal training against these people that are, you know, representing themselves,” he said.</p><p>In the end, Meta’s legal team was able to help Ryan get his account back and he agreed to drop himself from the small claims case. But two months later his partner had still not gotten back into hers. Meta eventually told her that her account had been permanently deleted and was no longer able to be restored. Meta eventually offered $3,500 — the maximum amount for a small claims case in Arizona. He says they wanted more, but Meta refused, and they felt like they were out of options. Ryan claims they had already lost tens of thousands of dollars in potential sales that they normally sourced from Facebook. “We were prepared to go further, but no lawyer would really take it on without a $15,000 retainer and it wasn't worth it.”</p><p>While it may seem surprising that Meta would give these small claims cases so much attention, Zucker, the Cal State Northridge professor, says that big companies have their own reasons for wanting to avoid court. “I don’t think places like Google or Meta want to have a bunch of judgments against them … because then that becomes a public record and starts floating around,” he says. “So they do take these things seriously.”</p><p>Without responding to specific questions about the substance of this story, Meta instead sent Engadget the following statement:</p><div data-src=""><blockquote><p>"We know that losing and recovering access to your online accounts can be a frustrating experience. We invest heavily in designing account security systems to help prevent account compromise in the first place, and in educating our users, including by regularly sharing new security features and tips for how people can stay safe and vigilant against potential targeting by hackers. But we also know that bad actors, including scammers, target people across the internet and constantly adapt to evade detection by social media platforms like ours, email and telecom providers, banks and others. To detect malicious activity and help protect people who may have gotten compromised via email phishing, malware or other means, we also constantly improve our detection, enforcement and support systems, in addition to providing channels where people can report account access issues to us, working with law enforcement and taking legal action against malicious groups."</p></blockquote></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reining in America's $3.3T tax-exempt economy (126 pts)]]></title>
            <link>https://taxfoundation.org/research/all/federal/501c3-nonprofit-organization-tax-exempt/</link>
            <guid>40740237</guid>
            <pubDate>Thu, 20 Jun 2024 16:03:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://taxfoundation.org/research/all/federal/501c3-nonprofit-organization-tax-exempt/">https://taxfoundation.org/research/all/federal/501c3-nonprofit-organization-tax-exempt/</a>, See on <a href="https://news.ycombinator.com/item?id=40740237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<article id="post-173133">
  
  <div>
          
    
<h2>Key Findings</h2>
<ul>
<li>For over a century, lawmakers have exempted politically favored organizations and industries from the <span><a href="https://taxfoundation.org/taxedu/glossary/tax/">tax</a><cite>A tax is a mandatory payment or charge collected by local, state, and national governments from individuals or businesses to cover the costs of general government services, goods, and activities.
</cite></span> code. As a result, the tax-exempt nonprofit economy now comprises 15 percent of GDP, spans more than 1.8 million organizations, and manages over $8 trillion in assets. In 2019, it pocketed more than $238 billion in net income.</li>
<li>The tax-exempt sector is overdue for review and reform. The U.S. needs a principled, rules-based approach to 1) distinguish between benevolent organizations and tax-exempt businesses, and 2) level the playing field between the business activities of nonprofit and for-profit entities.</li>
<li>Many industries exempted from the income tax were designated as such in the Wilson-Gorman <span><a href="https://taxfoundation.org/taxedu/glossary/tariffs/">Tariff</a><cite>Tariffs are taxes imposed by one country on goods or services imported from another country. Tariffs are <a href="https://taxfoundation.org/topics/tariffs-and-trade/">trade barriers</a> that raise prices and reduce available quantities of goods and services for U.S. businesses and consumers.
</cite></span> Act of 1894 and the Tax Act of 1909, but they reflect the social norms of the 19<sup>th</sup> century, not our 21<sup>st</sup> century economy.</li>
<li>The majority of tax-exempt organizations today are business-like in form and function, including credit unions, hospitals, utilities, insurance companies, universities, professional athletic associations, golf clubs, and consulting firms, to name a few.</li>
<li>Business-like income has been the fastest growing source of income for 501(c)(3) tax-exempt organizations over the past 30 years, now accounting for 71 percent of their income. Charitable donations make up just 12 percent of nonprofit income.</li>
<li>More than half (55 percent) of all the income generated by 501(c)(3) organizations comes from tax-exempt hospitals and health-care plans. The largest nonprofit in America is Kaiser Permanente. Kaiser’s health plan, hospitals, and state health plans generated over $110 billion in revenues in 2019.</li>
<li>In 2019, there were 325 501(c)(3) nonprofits with more than $1 billion in revenues—nearly all of which are hospitals and universities.</li>
<li>The unrelated business income tax (UBIT) rules that were intended to rein in tax-exempt businesses have become toothless and have allowed the growth of large nonprofit businesses.</li>
<li>A reasonable rewriting of the tax-exempt rules should include narrowing the definition of “public charity” and subjecting all non-charitable income to the corporate tax rate of 21 percent. Doing so could raise nearly $40 billion annually in new tax revenues.</li>
</ul>
<h2>Introduction</h2>
<p>America has a $3.3 trillion <span><a href="https://taxfoundation.org/taxedu/glossary/tax-gap/">tax gap</a><cite>The tax gap is the difference between taxes legally owed and taxes collected. The gross tax gap in the U.S. accounts for at least 1 billion in lost revenue each year, according to the <a href="https://www.irs.gov/pub/irs-pdf/p5364.pdf">latest</a> estimate by the <a href="https://taxfoundation.org/taxedu/glossary/internal-revenue-service-irs/">IRS</a> (2011 to 2013), suggesting a voluntary taxpayer compliance rate of 83.6 percent. The net tax gap is calculated by subtracting late tax collections from the gross tax gap: from 2011 to 2013, the average net gap was around 1 billion.
</cite></span>. But it’s not the tax gap we hear most about: the revenues the IRS fails to collect because of underreporting, mistakes, or outright tax avoidance. This tax gap rests squarely with <a href="https://taxfoundation.org/location/washington/">Washington</a> lawmakers who, starting more than a century ago, began exempting politically favored institutions, organizations, and activities from the tax code.</p>
<p>The result today is a massive untaxed economy that comprises 15 percent of GDP<a href="#_ftn1" name="_ftnref1">[1]</a>, spans more than 1.8 million organizations<a href="#_ftn2" name="_ftnref2">[2]</a>, manages over $8 trillion in assets, and collectively pocketed more than $238 billion in net income in 2019<a href="#_ftn3" name="_ftnref3">[3]</a>.</p>
<p>After more than a century of unbridled expansion, the scope of this untaxed economy is overdue for review and reform. Many of the nearly 30 nonprofit designations under 501(c) of the Internal Revenue Code have their origins in the Wilson-Gorman Tariff Act of 1894 and are artifacts of a more communitarian 19<sup>th</sup> century American society, not a reflection of our modern 21<sup>st</sup> century economy.</p>
<p>Contrary to the common image of nonprofits as purely benevolent organizations surviving on charitable donations, such organizations are in the minority. The vast majority of tax-exempt organizations are business-like in form and function, such as credit unions, utilities, insurance companies, hospitals, universities, professional athletic associations, golf clubs, casinos, cemeteries, and consulting firms, to name a few. And many of these organizations use their tax-exempt status to compete with taxpaying for-profit firms.</p>
<p>Unfortunately, the guardrails lawmakers have created to prevent unfair competition from nonprofits have been either too weak or too flexible to draw firm lines between benevolent activities, such as a local women’s shelter, and large business enterprises, such as the $1.1 billion NCAA. Both are considered “charitable” nonprofit organizations.</p>
<p>Business-like income has been the fastest growing source of income for 501(c)(3) charitable organizations, entities that can accept tax-deductible donations. Indeed, of the nearly $2.5 trillion in revenues that charitable organizations received in 2019, just 12 percent came from donors’ tax-deductible contributions and gifts. The majority of their income came from business-like revenues such as insurance payments, ticket sales, TV broadcast rights, royalties, and federal programs such as Medicare and Medicaid.   </p>
<p>This raises the question: should an organization be considered a nonprofit, or even a charity, if only a fraction of its revenues come from charitable donations?</p>
<p>The <span><a href="https://taxfoundation.org/taxedu/glossary/tax-base/">tax base</a><cite>The tax base is the total amount of income, property, assets, consumption, transactions, or other economic activity subject to taxation by a tax authority. A narrow tax base is non-neutral and inefficient. A <a href="https://taxfoundation.org/taxedu/glossary/base-broadening/">broad</a> tax base reduces tax administration costs and allows more revenue to be raised at lower rates.
</cite></span> is narrower than it need be because of how much nonprofit income is fully exempt from taxation. Charitable donations are tax deductible for the donor and tax-exempt for the receiving organization, what economists call double-non-tax-income. Similarly, corporations may deduct payments to nonprofits for such things as memberships, broadcast rights, and licensing fees. Thus, all of this income is outside of the federal tax base.</p>
<p>As Congress’s Joint Committee on Taxation (JCT) has observed, “There is no unifying theme or singular principle that explains <span><a href="https://taxfoundation.org/taxedu/glossary/tax-exemption/">tax exemption</a><cite>A tax exemption excludes certain income, revenue, or even taxpayers from tax altogether. For example, nonprofits that fulfill certain requirements are granted tax-exempt status by the Internal Revenue Service (<a href="https://taxfoundation.org/taxedu/glossary/internal-revenue-service-irs/">IRS</a>), preventing them from having to pay income tax.
</cite></span> for the many diverse organizations in the exempt sector.”<a href="#_ftn4" name="_ftnref4">[4]</a> Nor, JCT says, is there an “agreed upon explanation of the rationale behind the charitable tax exemption and <span><a href="https://taxfoundation.org/taxedu/glossary/tax-deduction/">tax deduction</a><cite>A tax deduction is a provision that reduces <a href="https://taxfoundation.org/taxedu/glossary/taxable-income/">taxable income</a>. A <a href="https://taxfoundation.org/taxedu/glossary/standard-deduction/">standard deduction</a> is a single deduction at a fixed amount. <a href="https://taxfoundation.org/taxedu/glossary/itemized-deduction/">Itemized deductions</a> are popular among higher-income taxpayers who often have significant deductible expenses, such as <a href="https://taxfoundation.org/taxedu/glossary/salt-deduction/">state and local taxes</a> paid, <a href="https://taxfoundation.org/taxedu/glossary/mortgage-interest-deduction-mid/">mortgage interest</a>, and charitable contributions.
</cite></span>.”</p>
<p>A principled, rules-based approach to narrow the scope of qualified tax-exempt entities is needed. For example, taxing the income of nonprofits from sources other than charitable donations would broaden the tax base in a fair and economically efficient way. Such a rule would protect the charitable donations received by benevolent organizations while putting nonprofit businesses on the same level playing field as for-profit firms.</p>
<p>As we’ll see, based on 2019 data, taxing the business-like income of nonprofits could raise nearly $40 billion annually.</p>
<p>While there still may be a role in today’s economy for insurance-providing fraternal organizations, credit unions, and collegiate sports leagues, there is no longer a justification to exempt them from taxation.</p>
<h3>The Scope of This Study Is Limited to 501(c) Organizations</h3>
<p>It should be noted that the Tax Foundation is a 501(c)(3) tax-exempt organization whose mission is to advocate for economically principled tax policy, even if it means questioning our own industry.</p>
<p>The scope of this paper is limited to organizations that fall under 501(c) of the Internal Revenue Code, but the true scope of the tax-exempt economy is much larger. Churches, for example, are not required to file tax returns, so the government does not track how much income they collect annually, although Giving USA estimates that churches raised $143.6 billion in revenues in 2022.<a href="#_ftn5" name="_ftnref5">[5]</a> Churches are not included in the study, but some 501(c) religious organizations are included.</p>
<p>Another tax-exempt sector that is not included is quasi-government entities such as state public universities, the <a href="https://taxfoundation.org/location/tennessee/">Tennessee</a> Valley Authority, and Federal Home Loan Banks. These tax-exempt enterprises generate roughly $500 billion in untaxed annual income.</p>
<p>The paper also ignores the charitable deduction and other tax breaks that shield income from taxation. Tax expenditures in the code topped $1.7 trillion in 2023 and deserve their own separate analysis.</p>
<h2>The Nonprofit Tax Code Reflects America’s Pre-20<sup>th</sup> Century Self-Help Roots</h2>
<p>Volunteer and benevolent organizations existed in America long before our founding and even longer before the first federal income tax. Fraternal beneficiary societies provided insurance benefits for widows, aid for those too sick to work, and education for orphans.<a href="#_ftn6" name="_ftnref6">[6]</a> Farmers banded together into cooperatives to provide lending for crops and marketing assistance. Credit unions and building and loan associations were formed to provide banking and lending to their members who worked in specific trades or lived in local communities.<a href="#_ftn7" name="_ftnref7">[7]</a> Charity hospitals were common in most cities.</p>
<p>Such was the state of American society when lawmakers drafted a new income tax in the Wilson-Gorman Tariff Act of 1894 and decided to exempt certain organizations. But their decisions seemingly were based on social conventions rather than a coherent theory or principle.</p>
<p>The act specifically exempted “corporations, companies, or associations organized and conducted solely for charitable, religious, or educational purposes, including fraternal beneficiary societies, orders, or associations operating upon the lodge system and providing for the payment of life, sick, accident, and other benefits to the members of such societies, orders, or associations and dependents of such members.”<a href="#_ftn8" name="_ftnref8">[8]</a> It also exempted savings banks, institutions that lent only to members, mutual insurance companies, and the income generated by the stocks and securities owned by charitable organizations.</p>
<p>Although the Supreme Court struck down the 1894 income tax, the bill’s tax-exempt language became the foundation for all subsequent tax legislation addressing nonprofits, including the Revenue Act of 1909, which established an <span><a href="https://taxfoundation.org/taxedu/glossary/excise-tax/">excise tax</a><cite>An excise tax is a tax imposed on a specific good or activity. Excise taxes are commonly levied on cigarettes, alcoholic beverages, <a href="https://taxfoundation.org/taxedu/glossary/soda-tax/">soda</a>, <a href="https://taxfoundation.org/taxedu/glossary/gas-tax/">gasoline</a>, insurance premiums, amusement activities, and betting, and typically make up a relatively small and volatile portion of state and local and, to a lesser extent, federal tax collections.
</cite></span> on corporate profits.</p>
<h2>The 1909 Tax Bill Formalized Many of the Exempt Sectors We Know Today</h2>
<p>The Revenue Act of 1909 expanded the sectors first recommended for exemption in 1894 by adding labor, agricultural, and horticultural organizations. It further defined the nature of nonprofit organizations as those “operated exclusively for the mutual benefit of their members.” And “no part of the net income of which inures to the benefit of any private stockholder or individual.”<a href="#_ftn9" name="_ftnref9">[9]</a></p>
<p>The prohibition against private inurement became a key factor in defining a “nonprofit” organization. “Nonprofit” is a bit of a misnomer because charitable organizations do have net income after expenses, what would otherwise be called “profits.” But nonprofit tax rules prohibit such surpluses from being distributed to any individual or “shareholder” and must be reinvested in the mission of the organization.</p>
<p>Despite these provisions, lawmakers never really clarified a defining theory of why some organizations should be tax-exempt and not others. Indeed, the Senate debate over the 1909 tax bill illustrated the ad hoc nature of the decision-making, not to mention the propensity of senators to stretch the definitions to include their favored industries and organizations.</p>
<p>Sen. Augustus Bacon (D-GA) was the lead sponsor of an amendment to define which activities should be exempt from the new corporate tax. One senator asked Sen. Bacon if the for-profit Methodist Book Concern in Nashville, Tennessee, should be exempt because it devoted all of its profits to “religious, benevolent, charitable, and educational purposes.”<a href="#_ftn10" name="_ftnref10">[10]</a> Bacon argued that it should be tax-exempt because “It is organized for profit, but it is not organized for individual profit.”<a href="#_ftn11" name="_ftnref11">[11]</a></p>
<p>To address such questions, senators inserted the word “exclusively” into Bacon’s amendment to distinguish between the use of business profits worthy of tax exemption and profits that were not worthy.</p>
<p>An even more intense debate erupted over exempting building and loan associations from taxation. While some senators argued that the mission of helping the poor purchase homes was worthy of tax exemption, others argued that there were many large building and loan associations that were wholly commercial in nature and should not qualify for tax exemption. Senators ultimately agreed to add the words “mutual” and “domestic” to distinguish between small, local, and member-oriented building and loan associations and the large commercial firms.</p>
<h2>Lawmakers Worried That Too Much of the Economy Was Exempted from Tax</h2>
<p>Even with the adoption of qualifying language, some senators worried that too many sectors were being exempted, thus putting an unfair burden on the businesses still subject to the corporate tax.</p>
<p>Sen. Coe I. Crawford (R-SD) said, “The only question here is, Is it a corporation for profit and has it a net income to which this proposed [tax] law should apply? If so, why should it be exempted?”</p>
<p>Further, he predicted that groups would take advantage of the ambiguous language. “I think there is too much false sentiment about this matter,” he said. “Some one will come here and say ‘We are a lodge; we are an organization for the mutual help and benefit of our members, and therefore this law ought not to apply to us.’”<a href="#_ftn12" name="_ftnref12">[12]</a></p>
<p>Sen. Weldon B. Heyburn (R-ID) went a step further and asked, “Will some Senator tell me what remains and who there is remaining to pay this tax? I have just made a casual summary of the amount of capital exempted, and, according to the statistics, it is something over $1,800,000,000. There cannot be very much remaining.”<a href="#_ftn13" name="_ftnref13">[13]</a></p>
<p>Heyburn warned about the cumulative impact of the efforts by his fellow senators to exempt their special interests from the income tax. He said, “Having made a hasty mental summary as the various exemptions were proposed, and knowing as I do that you can call one of these concerns a ‘mutual benefit association,’ a ‘building association,’ or anything else, when it really may be a bank. I am merely calling attention to the fact that there will be very little left upon which to collect this revenue.”</p>
<p>Perhaps the most prophetic comment came from Sen. Joseph Bailey (D-TX), a strong proponent of the corporate tax, who said, “I would rather exempt some that ought to be taxed than to tax some that ought to be exempt.”</p>
<p>As we will see below, that philosophy likely explains the $3.3 trillion size of the untaxed economy today.</p>
<h2>Lawmakers Continued to Exempt More Sectors and Added the Charitable Deduction</h2>
<p>Sen. Crawford’s concern that lax definitions would lead to a proliferation of tax-exempt organizations proved to be far-sighted. The Revenue Act of 1913 expanded the list of exempt organizations even further, adding mutual savings banks, cemeteries, business leagues, chambers of commerce, civic leagues, and boards of trade. The Act also introduced the notion that civic leagues and similar organizations be “operated exclusively for the promotion of social welfare,” a term lawmakers did not define.<a href="#_ftn14" name="_ftnref14">[14]</a></p>
<p>The Revenue Act of 1916, which increased income tax rates and brackets, added to the list of tax-exempt organizations “clubs organized and operated exclusively for pleasure, recreation and other non-profitable purposes . . . cooperative banks, mutual hail, cyclone, or fire insurance companies, mutual ditch or irrigation companies, mutual telephone companies . . . farmers’ marketing associations . . . federal land banks and national farm loan associations,” to name just a few.<a href="#_ftn15" name="_ftnref15">[15]</a></p>
<p>The deduction for charitable gifts was established in the Revenue Act of 1917 out of concern that the high income tax rates levied during World War I would discourage charitable giving. Deductible contributions were limited to 15 percent of taxable net income.<a href="#_ftn16" name="_ftnref16">[16]</a> </p>
<h2>A “Nonprofit” Pasta Company Led to Stricter Limits on Business Activity</h2>
<p>Lawmakers’ failure to establish principled guardrails regarding how much business activity a nonprofit could engage in finally reached a head in the late 1940s when <a href="https://taxfoundation.org/location/new-york/">New York</a> University acquired C.F. Meuller pasta company with the intent of benefiting from the profits generated by selling macaroni.<a href="#_ftn17" name="_ftnref17">[17]</a> Such arrangements were not uncommon at the time because nonprofit law operated under a “destination of income” principle, which allowed income from any source to be tax-free as long as it was dedicated to a charitable purpose.<a href="#_ftn18" name="_ftnref18">[18]</a></p>
<p>In 1949, the Bureau of Internal Revenue, the precursor to the Internal Revenue Service, released the first-ever analysis of 990 tax returns, representing all tax-exempt organizations in 1946.<a href="#_ftn19" name="_ftnref19">[19]</a> The report separated the returns into two groups: business types, such as farm marketing cooperatives and mutual savings banks, and nonbusiness types such as civic clubs, charities, labor unions, and recreational groups that were not principally formed for business activities.</p>
<p>There were nearly 100,000 tax-exempt returns filed for 1946, and they reported total revenues of $9.8 billion. Of these, nearly 28,000 were business returns, accounting for $7.0 billion of the total revenues.</p>
<p>Interestingly, the report found that more than one-third of nonbusiness organizations reported business income totaling $1.1 billion. Business income accounted for 62 percent of the total revenues for “nonbusiness” organizations.</p>
<p>But even for organizations that did not report business-related income, charitable contributions and gifts were not a major share of their revenues. Indeed, charitable contributions and gifts composed 37.6 percent of their receipts. The majority of their income was generated by dues assessments from members as well as investment income.    </p>
<p>Cases such as the New York University pasta company renewed concern among lawmakers that nonprofits were unfairly competing against for-profit firms and potentially shrinking the corporate tax base.</p>
<p>Lawmakers’ solution was to establish the unrelated business income tax (UBIT) rules as part of the Revenue Act of 1950. UBIT requires that any business income be “substantially related” to the organization’s core mission. Business income that is not substantially related is taxed at the statutory corporate tax rate.</p>
<p>Shortly after the passage of UBIT, Congress voted in 1951 to remove the tax exemption for mutual savings banks and savings and loan associations “to establish parity between competing financial institutions.”<a href="#_ftn20" name="_ftnref20">[20]</a>   </p>
<p>However, as we’ll see later, UBIT has become so generous in defining what is allowable business income for nonprofits that it generates very little revenue each year.</p>
<h2>There Are Two Types of Nonprofits: Public-Serving and Member-Serving</h2>
<p>The Internal Revenue Code of 1954 was a watershed moment in tax policy.<a href="#_ftn21" name="_ftnref21">[21]</a> In addition to establishing the modern progressive income tax code that we recognize today, the Act formalized the designation of tax-exempt organizations under section 501(c) of the Internal Revenue Code.</p>
<p>The 1954 Act listed 16 types of tax-exempt organizations, but as Table 1 illustrates, the list has since grown to nearly 30 designations, although some are legacy designations and no longer in use.</p>
<p>The nonprofit world is generally split into two broad categories: public-serving and member-serving organizations.</p>
<ul>
<li><strong>Public-Serving</strong>: The most well-known nonprofits are 501(c)(3) public charity organizations intended to serve broad, public interests such as tending to the poor, education, public health, scientific research, and cultural interests. These organizations can accept tax-deductible contributions.</li>
<li><strong>Member-Serving</strong>: All other 501(c) designations are largely member-serving organizations, including credit unions, business leagues, professional associations, rural utilities, real estate holding companies, insurance companies, and cemeteries. These organizations cannot accept charitable donations.</li>
</ul>
<h2>The Tax-Exempt Sector Is Equal to the Fifth-Largest Economy in the World</h2>
<p>The senators who worried about the expanding list of tax-exempt entities in the Tax Act of 1909 would be shocked at the size of the tax-exempt economy today. Sen. Heyburn made a casual estimate of the amount of capital exempted at “something over $1,800,000,000,” or roughly 5 percent of U.S. GDP in 1909.<a href="#_ftn22" name="_ftnref22">[22]</a> Today, the tax-exempt economy commands 15 percent of GDP, roughly equal to the GDP of <a href="https://taxfoundation.org/location/california/">California</a>, which has the fifth-largest economy in the world.</p>
<p>Table 1 illustrates the breadth of the untaxed economy under 501(c) of the Internal Revenue Code. The data in this table is based on the most recent 2019 nonprofit datasets compiled and formatted by the Urban Institute’s National Center for Charitable Statistics. The Urban Institute datasets are drawn from various IRS data sources and include “financial information, governance details, and other organizational characteristics.”<a href="#_ftn23" name="_ftnref23">[23]</a></p>
<p>IRS data for tax-exempt organizations is available for COVID-19 years, 2020, 2021, and 2022. However, we chose not to use this data because it does not represent a typical year.</p>
<p>While the total number of nonprofits is over 1.8 million, the table represents organizations that file a full 990 federal income tax return providing complete financial information, which amounts to about 400,000 entities. The exception is 501(c)(1) federal credit unions that are not required to file a 990 tax return. Their financial information is sourced from the National Credit Union Administration. Many small nonprofits are allowed to file a postcard return and, thus, are generally not included in the data sets made available by the IRS.</p>
<!-- #tablepress-460 from cache -->
<p>In 2019, tax-exempt nonprofit organizations reported nearly $3.3 trillion in income and roughly $3.1 trillion in expenses, which resulted in $238 billion in net income. They commanded over $8 trillion in assets.</p>
<p>The largest category of nonprofit by far is the 501(c)(3) category of organizations. In 2019, these organizations booked nearly $2.5 trillion in revenues, equal to 75 percent of all nonprofit revenues. Their net income totaled nearly $152 billion, equal to 63 percent of all nonprofit net income. They also manage the majority of nonprofit assets.</p>
<p>The largest member-serving organizations by income include various insurance and retirement entities under sections 501(c)(4) Civic Leagues and Social Welfare Organizations (the largest of which are health insurers), 501(c)(9) Voluntary Employee’s Beneficiary Associations, and 501(c)(11) Teachers Retirement Fund Associations.</p>
<p>Federal and state credit unions, operating under sections 501(c)(1) and 501(c)(14), respectively, together generated $82.4 billion in revenues in 2019 and commanded over $1.5 trillion in assets in 2019, equal to 18 percent of all nonprofit assets.</p>
<p>Let’s first take a deeper look at public-serving nonprofits since they are by far the largest sector.</p>
<h2>The Majority of Public-Serving 501(c)(3) Nonprofits Are Business-Like Entities</h2>
<p>The universe of public-serving nonprofits is vast and diverse. Indeed, to manage this diversity, 501(c)(3) organizations have been further segmented into 28 codes under the National Taxonomy of Exempt Entities (NTEE), as illustrated in Table 2 below.</p>
<p>However, if we were to generalize the public-serving nonprofit industry by its dominant industries, it could be called the hospital, health insurance, university, and education sector. Of the $2.5 trillion in revenues collected by 501(c)(3) organizations in 2019, 55 percent was generated by nonprofit hospitals and health insurance firms, and another 12 percent was generated by higher education entities such as colleges and universities.</p>
<h2>There Are Many Very Rich Nonprofits</h2>
<p>In 2019, there were 325 501(c)(3) nonprofits with more than $1 billion in revenues—nearly all were either hospitals or universities. Among the $1 billion organizations that were not hospitals or universities:</p>
<ul>
<li>Just three are relief-oriented: World Vision, Feeding America, and the American Red Cross.</li>
<li>One is a museum: the Smithsonian Institution.</li>
<li>Four are essentially government contractors: the MITRE Corporation, Battelle Memorial Institute, Advanced Technology International, and Aerospace Corporation.</li>
<li>One is the largest collegiate athletic association: the NCAA.</li>
<li>Three are university-related organizations: the College Board, the Research Foundation for the State of New York, and the Educational Testing Service.</li>
<li>And the rest are donor-advised funds or public foundations: the Nemours Foundation, National Philanthropic, Goldman Sachs Philanthropy Fund, Schwab Charitable Fund, and Fidelity Investments Charitable Gift Fund.</li>
</ul>
<p>The largest nonprofit in America is Kaiser Permanente. In 2019, Kaiser’s health plan, hospitals, and state health plans generated more than $110 billion in combined tax-exempt revenues and over $5.6 billion in net income. No other nonprofit came close to Kaiser’s revenues. If Kaiser were for-profit, it would be among the Fortune 40 in revenues.</p>
<!-- #tablepress-461 from cache -->
<p>The other hospitals with more than $10 billion in revenues included the University of <a href="https://taxfoundation.org/location/pennsylvania/">Pennsylvania</a> Medical Center (UPMC) with $14.8 billion in revenues, Partners Health Care System with $13.6 billion, the Cleveland Clinic Foundation with $11.5 billion, and the Mayo Clinic Group with $10.4 billion. </p>
<p>Overall, nonprofit hospitals and health plans generated $1.4 trillion in revenues in 2019 and $61 billion in net income. They held assets of $1.9 trillion. Very little of this income comes from charitable contributions or grants. Urban Institute data shows that charitable contributions comprised 10 percent of hospital revenues and just 3 percent of health plan revenues.</p>
<p>Most hospital revenues are considered “program service income,” which includes insurance payments, patient reimbursements, and payments from Medicare and Medicaid. For health plans, most income is earned from insurance premiums.</p>
<p>Had these profitable health insurance and hospital firms been taxed at the standard corporate tax rate of 21 percent, they could have collectively been liable for nearly $13 billion in taxes in 2019.</p>
<h2>Private Universities and Their Endowments Dominate the Education Sector</h2>
<p>In 2019, there were 51 private universities with more than $1 billion in revenues. Ten universities reported more than $5 billion in income, including the University of Pennsylvania, Harvard, New York University, Johns Hopkins, Stanford, University of Southern California, Columbia, <a href="https://taxfoundation.org/location/massachusetts/">Massachusetts</a> Institute of Technology, Yale, and Cornell. As a group, they held $264 billion in assets.</p>
<p>Collectively, private colleges and universities enjoyed net income of $22.2 billion in 2019. Had they been taxed as for-profit businesses they could have been liable for $4.6 billion in taxes.</p>
<p>Despite their tax-exempt status, the majority of university income comes from sources other than charitable donations from alumni. Overall, nearly 70 percent of university income comes from “program service revenue,” which includes tuition, fees, ticket sales from sporting events, patent royalties, rents from dorms, and cafeteria sales—all considered substantively related to their mission and, thus, exempt from taxes.</p>
<p>By contrast, charitable contributions accounted for 19 percent of total revenues for private universities and colleges.</p>
<p>Many universities have separate investment arms categorized as general “education” organizations, putting them in the same category as private primary and secondary schools.</p>
<p>For example, the $2 billion Gothic Corporation invests on behalf of Duke University. It held $7.6 billion in assets in 2019. Similarly, the Harvard Management Private Equity Corporation managed $31 billion in assets, while the Harvard Private Capital Realty Inc. managed $3.5 billion in assets. The University of <a href="https://taxfoundation.org/location/virginia/">Virginia</a> Investment Management Corporation held $9.8 billion in assets, while the University of <a href="https://taxfoundation.org/location/wisconsin/">Wisconsin</a> Foundation reported $4.1 billion in assets.</p>
<p>The Urban Institute dataset contains more than 800 university-related endowments, foundations, and fund-raising entities in 2019. These entities raised a total of $26.8 billion that year and had more than $209 billion in assets. They ended the year with $7.5 billion in net income which, had it been taxed at 21 percent, could have generated more than $1.5 billion in tax revenues.</p>
<h2>Business-Like Organizations Abound in Unlikely 501(c)(3) Categories</h2>
<p>Many nonprofit categories contain an eclectic mix of large business-like organizations alongside small local organizations. For example, the Arts &amp; Culture sector contains hundreds of local arts projects, dance companies, theater groups, and orchestras. It also includes some very large institutions that could very well be considered for-profit organizations. The Harvard Business School Publishing Corporation is a good example.</p>
<p>In 2019, Harvard Business School Publishing (HBS) generated more than $265 million in revenues. According to its 990 tax return, it ended the year with net income of $3.9 million and paid about $1.1 million in taxes on $14 million in advertising income unrelated to its core mission.<a href="#_ftn24" name="_ftnref24">[24]</a> On paper, it would appear that HBS generated very little in the way of “profits” on its book publishing activities, but that is because it made a $52.9 million transfer to the “President and Fellows of Harvard College” that it booked as an expense, which reduced its true net income. However, if HBS were a for-profit firm, it would be able to deduct any gifts to Harvard or any other nonprofit.</p>
<p>In some respects, this is similar to NYU’s attempt to use the profits from pasta sales to fund university activities. The only difference in Harvard’s case is that both entities are 501(c)(3) organizations.</p>
<p>Other business-like entities under the Arts &amp; Culture umbrella include the Corporation for Public Broadcasting, the Public Broadcasting Service, National Public Radio, and the WGBH network, all nonprofit competitors of for-profit television and radio networks.</p>
<p>Another unique “cultural” entity is Creative Testing Solutions, which generated over $400 million in revenues in 2019, “Providing innovative, customized and exceptional laboratory testing services, in support of our healthcare partners and their life saving missions.”<a href="#_ftn25" name="_ftnref25">[25]</a> These services seem very commercial in nature.  </p>
<h2>Conducting “Science” Can Be Big Business</h2>
<p>Science research was one of the earliest activities to be made tax-exempt. But it is unlikely that those early lawmakers could have imagined how big of an industry “science research” and consulting services has become today and how much it lives off of government largess.</p>
<p>The biggest of these organizations is the Battelle Memorial Institute. By all appearances, Battelle is a government contractor. It manages nine national laboratories for the U.S. Department of Energy and Department of Homeland Security. Battelle bills itself as providing “comprehensive scientific solutions to companies and government agencies across multiple markets.” <a href="#_ftn26" name="_ftnref26">[26]</a> According to Battelle’s 2021 990 tax return, the organization generated $10 billion in revenues, 97 percent of which was from government grants and contracts.</p>
<p>Similar stories can be told about large tax-exempt science and engineering consulting organizations such as the MITRE Corporation, Aerospace Corporation, Fermi Research Alliance LLC, SRI International, Cold Spring Harbor Laboratory, Noblis Inc., SRC Inc., and In-Q-Tel Inc. Each of these organizations provides services for the government and corporations comparable to those provided by for-profit consulting and management firms. They just provide such services as a 501(c)(3) tax-exempt nonprofit.</p>
<p>Many universities have established affiliated research and consulting organizations to provide support and resources for the research activities of the university. The largest of these is the Research Triangle Institute (RTI), which was organized in 1958 by the state universities of <a href="https://taxfoundation.org/location/north-carolina/">North Carolina</a> along with Duke University, which is private. RTI generated more than $967 million in revenues in 2019.</p>
<p>RTI’s online promotional material reads like a commercial research and consulting firm.<a href="#_ftn27" name="_ftnref27">[27]</a> RTI bills itself as “a leading independent, nonprofit research institute, with the contractual, legal, and business structures to serve any client with projects of all sizes.” It combines “the scientific rigor of a university with the focus of a project management firm . . . to deliver what our clients need—on target and on time.”</p>
<p>RTI’s 990 tax return reports that the organization does have “several for-profit entities subject to corporate income taxation,” and its presence in “certain foreign countries results in income taxation in these countries.”<a href="#_ftn28" name="_ftnref28">[28]</a> Yet, RTI qualifies as a 501(c)(3) tax-exempt organization under the U.S. tax code.</p>
<h2>Business Income Is Now the Largest Share of Nonprofit Revenues</h2>
<p>Because of the growth of business-like income over the past three decades, it is hard to call the 501(c)(3) sector the “charitable” sector anymore. Figure 1 shows how the growth in program service revenues has driven the overall growth in nonprofit revenues over the past 30 years. Generally speaking, program service revenues can include Medicare and Medicaid payments, payments for medical services from insurers and patients, tuition, ticket sales, royalties, insurance premiums, conference registration fees, fees and contracts from government agencies, and unrelated business income.</p>
<p>Since 1988, program service revenues have risen from $548 billion, in today’s dollars, to more than $1.8 trillion in 2019—an increase of 310 percent.<a href="#_ftn29" name="_ftnref29">[29]</a></p>
<p>Program revenues comprised 71 percent of nonprofit revenues in 2019, up from 67 percent in 1988. By contrast, charitable contributions comprised just 12 percent of nonprofit revenues in 2019.</p>

<p>As surprising as this may seem, the real story is that charitable contributions have never been the dominant source of income for 501(c)(3) organizations or for tax-exempts generally. As we saw in the Treasury Department’s 1949 study, even for organizations without business-related income, charitable donations were exceeded by dues, membership fees, and other income sources.</p>
<p>IRS data shows that as a share of 501(c)(3) income, contributions fell from 27 percent in 1975 to 18 percent in 1982 and 12 percent in 2019.<a href="#_ftn30" name="_ftnref30">[30]</a></p>
<h2>Nonprofits Are Increasingly Dependent on Funds from Government</h2>
<p>While the 1949 Treasury study separated tax-exempt organizations into business and nonbusiness types, a third type of nonprofit has emerged since the Great Society of the 1960s—government-dependent organizations. Such organizations derive most of their income from government grants, contracts, or programs such as Medicaid, Medicare, public housing, and anti-poverty aid.</p>
<p>As we saw with the research and consulting organizations discussed above, many government agencies rely on nonprofit organizations as contractors or subcontractors, managing programs such as public housing, transit systems, social services, and job training.</p>
<p>Figure 1 shows that government grants alone nearly equal charitable contributions in most years, and government grants do not include revenues from government contracts or programs such as Medicare and Medicaid, which are considered program service income.</p>
<h2>Identifying Purely Benevolent 501(c)(3) Organizations Is Challenging</h2>
<p>Many of the organization types we have reviewed so far are business-like in form and function. But looking at the list of 501(c)(3) NTEE categories, a few stand out as containing more benevolent organizations than business-like organizations.</p>
<p>Employment and job-related organizations (category J) range from job training services to local trade unions. Perhaps the most prominent name in this category is Goodwill Industries, with some 180 local chapters. Dress for Success is another national organization with more than 50 chapters providing business attire and training to women seeking jobs.<a href="#_ftn31" name="_ftnref31">[31]</a></p>
<p>A sizeable number of organizations in this category are lesser-known community-based vocational training and apprenticeship organizations supported by government grants and private donations. Trade unions operate similar apprentice and training programs for carpenters, masons, electricians, and pipe fitters, for example.</p>
<p>Standing out from such training programs are numerous local union chapters, supported by member dues.  </p>
<p>The most benevolent-centered category is K, representing food, agriculture, and nutrition organizations. The Urban Institute dataset includes more than 5,700 food, agriculture, and nutrition organizations with total revenues of nearly $17.8 billion in 2019. Here we find that nearly every organization is a food bank, food pantry, child hunger-related organization, or adult nutrition service such as Meals on Wheels. The largest such organization is the $2.8 billion Feeding America, but most are local in nature such as the $10 million Food Bank of East <a href="https://taxfoundation.org/location/alabama/">Alabama</a> and the $30,000 Westlake Meals on Wheels. </p>
<p>Overall, contributions and grants comprised 90 percent of the revenues for food and nutrition organizations in 2019, which clearly sets these benevolent organizations apart from most other nonprofits.</p>
<p>The housing and shelter organizations comprising category L include a mix of benevolent organizations, government contractors, and business-like entities. Many of the larger organizations in this category are public housing providers or management contractors. The largest such organization is Navigate Affordable Housing Partners in Birmingham, Alabama, which received 99.7 percent of its $605 million in 2019 income from U.S. Department of Housing and Urban Development grants and contracts.<a href="#_ftn32" name="_ftnref32">[32]</a></p>
<p>Vetter Senior Living in Elkhorn, <a href="https://taxfoundation.org/location/nebraska/">Nebraska</a>, is also representative of the more business-like organizations in this category. Started in 1975 by Jack and Eldora Vetter, this chain of senior living facilities received more than half ($134 million) of its $222.5 million in revenues from Medicaid and Medicare in 2019.<a href="#_ftn33" name="_ftnref33">[33]</a> Most of the remaining income came from “patient service revenue” and “management revenues.”<a href="#_ftn34" name="_ftnref34">[34]</a> On the surface, it is difficult to distinguish between the services that Vetter provides as a “nonprofit” and those provided by for-profit senior living companies.</p>
<p>Habitat for Humanity is the largest of the more traditional volunteer-based service organizations found in this category. The vast majority of its $288 million in revenues in 2019 came from grants, contributions, and in-kind gifts.<a href="#_ftn35" name="_ftnref35">[35]</a></p>
<p>Multipurpose is the operative term for human service organizations in category P. The largest organization in this category is the American Red Cross with more than $2.8 billion in income in 2019. The AARP Foundation is also listed as a human service organization and illustrates how some large nonprofits use related tax-exempt entities to expand their operations. Its 990 for 2019 shows that it is affiliated with other AARP entities, including the main AARP entity, which is a 501(c)(4) nonprofit. <a href="#_ftn36" name="_ftnref36">[36]</a> The main AARP entity booked some $1.7 billion in revenues in 2019, including more than $977 million in tax-free royalty income.<a href="#_ftn37" name="_ftnref37">[37]</a></p>
<p>The Urban Institute datasets include more than 600 separate filings for local YMCA or WYCA chapters, which have combined income of $6.1 billion and assets of $12 billion. By contrast, the largest for-profit fitness company by income is LA Fitness, which also has 600 locations but only $2 billion in revenues.</p>
<p>But the category also includes an interesting variety of smaller organizations, such as dog rescues, adult day care centers, children’s day care centers, hospice care, community centers, thrift stores, pregnancy centers, diaper banks, and yoga studios.</p>
<h2>A Look into Member-Serving Tax-Exempt Organizations: 501(c)(1) – 501(c)(29)</h2>
<p>Almost by definition, organizations other than 501(c)(3) entities have a business orientation in some manner, even if they were intended to be member-serving. These include credit unions, rural utilities and coops, insurance companies, pension funds, business and sports leagues, cemeteries, real estate holding companies, farmer coops, fraternal organizations, social and recreation clubs, and veterans organizations.</p>
<p>Let’s explore a few of these categories.</p>
<p>501(c)(4) organizations are a good example of how tax-exempt definitions can be expanded to include big businesses. While tax laws require that such organizations be “operated exclusively to promote social welfare,” that concept seems to have been interpreted broadly.<a href="#_ftn38" name="_ftnref38">[38]</a></p>
<p>Washington insiders may associate 501(c)(4) organizations with activist and public policy organizations like the Sierra Club and the American Civil Liberties Union, but such organizations are in the minority. Social welfare organizations seem to be split between a few hundred large health-related firms and thousands of smaller 501(c)(4) organizations such as Rotary clubs, Kiwanis, Lions clubs, Optimist clubs, American Legion, Links chapters, homeowners associations, and volunteer fire departments. </p>
<p>The largest 501(c)(4) entities, those with more than $100 million in revenues, are predominantly health-related firms such as dental plans, HMOs, and health-care networks. Delta Dental Plans, with roughly 30 state entities, is the largest of these organizations. In 2019, it had combined revenues of more than $15 billion and net income of $339 million.  </p>
<p>Perhaps the most unusual of these large “social welfare” organizations is the Prairie Meadows Racetrack &amp; Casino Inc. in Altoona, <a href="https://taxfoundation.org/location/iowa/">Iowa</a>. Originally launched as a commercial venture, which went bankrupt, it was converted into a nonprofit in 1994 and is reportedly one of only two nonprofit casinos in the U.S. With more than $2.3 billion in 2019 revenues, Prairie Meadows says it is “dedicated to lessening the burden of government by raising funds for charitable organizations and community improvement projects.”<a href="#_ftn39" name="_ftnref39">[39]</a></p>
<p>Prairie Meadows’ mission statement is an interesting justification for the tax-exempt status of what was a failed commercial venture. It harkens back to the 1909 Senate quandary whether the for-profit Methodist Book Concern should pay the <span><a href="https://taxfoundation.org/taxedu/glossary/corporate-income-tax-cit/">corporate income tax</a><cite>A corporate income tax (CIT) is levied by federal and state governments on business profits. Many companies are not subject to the CIT because they are taxed as <a href="https://taxfoundation.org/taxedu/glossary/pass-through-business/">pass-through businesses</a>, with income reportable under the <a href="https://taxfoundation.org/taxedu/glossary/individual-income-tax/">individual income tax</a>.
</cite></span> because it gave away its profits to charitable causes. And tying a casino’s charitable status to “lessening the burden of government” is a questionable principle that could open the door to no end of dubious “commercial” but tax-exempt enterprises, such as a “nonprofit” marijuana dispensary.  </p>
<p>The 501(c)(6) “business league” category could be called the tax-exempt home of K Street lobbyists, golf and tennis companies, professional guilds, and tourism boards. The U.S. Chamber of Commerce is said to have led the effort in 1913 to exempt business membership organizations and civic leagues from tax during the debate over the Revenue Act of 1913. Indeed, some of the biggest business groups in Washington, D.C., are organized as 501(c)(6) entities, including the U.S. Chamber of Commerce, American Petroleum Institute, American Hospital Association, American Bureau of Shipping, American Chemistry Council, National Milk Producers Federation, and National Association of Broadcasters.</p>
<p>Many professional sports organizations are also organized as “business leagues.” While the NFL, MLB, and NBA renounced their tax-exempt status years ago, a number of prominent professional sports leagues still maintain their tax-exempt status. These include the PGA, <a href="https://taxfoundation.org/location/united-states/">United States</a> Tennis Association, ATP Tour, Ladies Professional Golf Association, WTA Tour Inc., United States Polo Association, the Breeders Cup Limited, National Hot Rod Association, and Professional Golfers Association of America.</p>
<p>This is also a common organizational form for professional organizations, such as the American Bar Association, American Medical Association, National Association of Realtors, Academy of Motion Picture Arts and Sciences, and Motion Picture Association.</p>
<p>Advertising and promotional organizations are frequently organized as 501(c)(6) organizations. Notable promotional organizations include the Houston Super Bowl Host Committee, Avocados from <a href="https://taxfoundation.org/location/mexico/">Mexico</a>, United States Meat Export Federation, Greater Miami Convention and Visitors Bureau, Atlanta Convention &amp; Visitors Bureau, and Dairy Promotion Inc.</p>
<p>The social and recreation clubs represented in the 501(c)(7) classification may consist of some of the most exclusive golf, athletic, and social clubs in the United States. Social and recreational clubs were exempted from tax in the 1916 Tax Act. Many of the largest cities have exclusive social and athletic clubs, including the New York Athletic Club, the Detroit Athletic Club, the Atlanta Athletic Club, the Yale Club of New York City, the Harvard Club of New York City, and the Bohemian Club near San Francisco. Indeed, the Tax Foundation was organized at a meeting of business leaders in 1937 at the University Club in New York City.</p>
<p>Golf courses dominate the 501(c)(7) category of nonprofit organizations, including some of the most iconic and exclusive golf clubs in America, such as the Congressional Country Club, Baltusrol Golf Club, Winged Foot Golf Club, Oakmont Country Club, and Sawgrass Country Club. By contrast, Augusta National Golf Club, which hosts the Masters tournament, is a for-profit corporate entity.</p>
<p>The richest of all the clubs in 2019 was the Desert Mountain Club in Scottsdale, <a href="https://taxfoundation.org/location/arizona/">Arizona</a>, which reported $68 million in revenues. Membership to this exclusive golf and lifestyle community is by “invitation only.”<a href="#_ftn40" name="_ftnref40">[40]</a> The Club’s real estate listings include homes ranging from $1.5 million to nearly $13 million.</p>
<p>There are certainly smaller, less famous clubs in this category, including a Giant Schnauzer club, local boating clubs, swim and tennis clubs, kennel clubs, singing clubs, model train clubs, a Slovak Citizens club, and various cotillion clubs.</p>
<p>Fraternal beneficiary societies organized under 501(c)(8) of the tax code are now largely insurance companies. Fraternal beneficiary societies were a prevalent part of America’s self-help culture when the first income taxes were being drafted, first in 1894 and then in 1909. Yet, as B.H. Meyer explained in an academic study in 1900, there was always a tension between their social function and their beneficiary function.</p>
<blockquote>
<p>Fraternal beneficiary societies, as the name suggests, are dual in their nature. Because they are both fraternal and beneficiary, these societies are really composed of two organizations each: a fraternity and an insurance company . . . In other words, a typical fraternal society rests upon three things: first, voluntary organization on a basis of equality; second, some ritualistic system; and third, a system of benefits. These three are united in different proportions in different societies, and in not a few of them a struggle for predominance is taking place between the first and third. This is the battle between “fraternalism and commercialism.”<a href="#_ftn41" name="_ftnref41">[41]</a></p>
</blockquote>
<p>More than 100 years later, the commercial side of these organizations has won out. For example, WoodmenLife—which was founded in 1890—offers various types of life insurance and retirement products.<a href="#_ftn42" name="_ftnref42">[42]</a> Modern Woodmen (unrelated to WoodmenLife) offers an even broader portfolio of products beyond life insurance, such as retirement planning, estate planning, and employee benefits.<a href="#_ftn43" name="_ftnref43">[43]</a> The Knights of Columbus does have a well-known service side, but also offers its members retirement annuities, mutual funds, donor advised funds, and various life insurance policies.<a href="#_ftn44" name="_ftnref44">[44]</a> </p>
<p>The products and services offered by these nonprofit organizations are in direct competition with similar products offered by for-profit financial service firms.</p>
<p>Tax-exempt public electric, water, and utility companies are a legacy of Depression-era efforts to promote rural self-help. Today’s 501(c)(12) tax-exempt utilities were formed as “cooperatives” during the early 1900s to bring electricity and water services to rural areas at a time when the larger urban utilities didn’t find it profitable to reach those markets. In 1934, Congress created the Rural Electrification Administration—now the Rural Utilities Service (RUS)—within the U.S. Department of Agriculture to promote the growth of rural coops and provide them low-cost financing.</p>
<p>Some 90 years later, rural coops are still dependent upon their tax-exempt status and subsidized loans. Notably, many of the “rural” communities these coops were created to serve are now prosperous suburbs of cities such as Washington, D.C., and Atlanta, <a href="https://taxfoundation.org/location/georgia/">Georgia</a>, not to mention tony resort communities such as Sanibel and Marco Island in <a href="https://taxfoundation.org/location/florida/">Florida</a>.</p>
<p>This ecosystem of tax-exempt utilities is supported by two larger tax-exempt organizations. The industry’s lobbying arm is the National Rural Electric Cooperative Association, a 501(c)(6) membership organization.<a href="#_ftn45" name="_ftnref45">[45]</a> The industry’s lending arm—independent of the federal RUS—is the $1.38 billion National Rural Utilities Cooperative Finance Corporation (CFC). CFC is a 501(c)(4) entity and bills itself as “Bridging the financial needs of the rural electric cooperative network with global capital markets.”<a href="#_ftn46" name="_ftnref46">[46]</a> It has more than $35 billion in assets.</p>
<h2>The Paper Tiger of Nonprofit Law: The Unrelated Business Income Tax</h2>
<p>Congress enacted UBIT in 1950 with the aim of leveling the playing field between tax-exempt organizations and for-profit firms. But as Jeffrey Scott Tenenbaum wrote in his primer on UBIT for the American Bar Association, “instead of prohibiting tax-exempt entities from engaging in any business activities at all . . . Congress chose to specifically permit a certain degree of business activity by tax-exempt organizations, but tax that activity like any other for-profit business.”<a href="#_ftn47" name="_ftnref47">[47]</a></p>
<p>Thus, writes Tenenbaum, “such business activities are permissible, so long as the activities are not a ‘substantial part of [the nonprofit’s] activities.’ The tax applies to virtually all tax-exempt entities.”</p>
<p>A frequent example of the difference between taxable and non-taxable sales activities is a museum gift shop that sells greeting cards bearing reproductions of paintings in the museum’s collection as well as local maps and souvenirs. UBIT rules would require the museum to pay tax on the income generated by the souvenirs because those items are not related to the museum’s mission. But it would not pay UBIT on income generated by the greeting cards with an image of a Monet because those sales are related to the museum’s mission of advancing art appreciation.<a href="#_ftn48" name="_ftnref48">[48]</a></p>
<p>The Harvard Business School magazine is another example. HBS does not pay tax on the income generated by its business publications or magazine subscriptions because they are determined to be a key element of the organization’s mission. However, HBS does pay tax on the income generated by the advertising in the magazine because those promote private and commercial interests separate from HBS’s mission.</p>
<p>There are, however, numerous exemptions to UBIT that give organizations wide latitude to earn business-like income. This includes income from corporate sponsorships, royalties, TV broadcast rights, certain rents, interest, dividends, and convention fees to name a few.</p>
<p>As a result of UBIT’s narrow scope and numerous exemptions, the tax raises very few revenue. IRS data on UBIT revenues from 1990 to 2017 shows that, on average, 17 percent of nonprofit charitable organizations reported unrelated business income and roughly half of those organizations were liable for UBIT. After adjusting for <span><a href="https://taxfoundation.org/taxedu/glossary/inflation/">inflation</a><cite><a href="https://taxfoundation.org/tags/inflation/">Inflation</a> is when the general price of goods and services increases across the economy, reducing the purchasing power of a currency and the value of certain assets. The same paycheck covers less goods, services, and bills. It is sometimes referred to as a “<a href="https://taxfoundation.org/blog/inflation-tax/">hidden tax</a>,” as it leaves taxpayers less well-off due to higher costs and “bracket creep,” while increasing the government’s spending power.
</cite></span>, UBIT raised an average of $586 million per year from 1990 to 2017, less than 0.5 percent of the billions in net income charitable nonprofits generated each year.<a href="#_ftn49" name="_ftnref49">[49]</a>      </p>
<p>So rather than level the playing field, UBIT has had little to no effect on preventing nonprofits from engaging in business-like activities nor competing directly with for-profit firms.</p>
<h2>Three Reforms Can Level the Playing Field and Broaden the Tax Base</h2>
<p>After more than 100 years of nonprofit expansion into the business economy, it is time that lawmakers developed some simple and uniform rules that accomplish two things: 1) distinguish between benevolent organizations and business-like entities, and 2) expressly level the playing field between the business activities of nonprofit and for-profit entities.</p>
<p>Three changes would remove the tax advantage that business-like nonprofits have over for-profit firms while protecting the charitable income of benevolent organizations.</p>
<p><strong>Step 1:</strong> The first step is to raise the threshold for the percentage of charitable contributions a 501(c)(3) organization must receive to be considered a “publicly supported” charity. Currently, an organization needs to show that it receives at least 30 percent of its revenues from “public” sources to be considered a public charity eligible to accept tax-deductible donations. Public sources is a broad concept that includes contributions from the public, government grants, grants from charitable foundations, net income from unrelated business activities, membership fees, and gross investment income.<a href="#_ftn50" name="_ftnref50">[50]</a></p>
<p>Since our goal is to narrow the definition of a “publicly supported” charity to focus on benevolent organizations, the income threshold should be increased to 80 percent and limited to donations from private individuals and grants from charitable foundations. Income from government contracts, government grants for services, membership fees, investment income, and business income should not be included as these sources are more business-like than charitable in nature.</p>
<p>Such a rule would protect the “public charity” status of a women’s shelter that hosts an annual charity ball but would likely deny that status for a nonprofit group such as the Battelle Memorial Institute that receives most of its income from contracts or grants for service from the departments of Energy or Defense, for example.  </p>
<p><strong>Step 2:</strong> The second step would be to eliminate UBIT and apply the 21 percent corporate income tax to the net program service income of all nonprofit organizations. The calculation of net program service income would differ between 501(c)(3) organizations and other nonprofits because of the need to separate charitable income from program service revenues.</p>
<p>As was discussed earlier, most 501(c)(3) organizations generate income from charitable donations and program service revenue. Program service revenues are the kind of income that a for-profit firm would normally pay tax on, including tuition, fees, Medicare and Medicaid payments, insurance reimbursements, rents, contract income, royalties, and broadcast rights. Under this proposed rule, nonprofits would subtract their program-related expenses from their program service revenues and pay income tax on the remainder.</p>
<p>In the table below, we estimate that 501(c)(3) organizations had $92 billion in net program service income in 2019. Had this net income, or profits, been taxed at the 21 percent corporate tax rate, it could have raised $19 billion in new tax revenues. This estimate does not account for any behavioral effects, nor have we accounted for an adjustment to corporate accounting standards such as bonus expensing.</p>
<p>Calculating <span><a href="https://taxfoundation.org/taxedu/glossary/taxable-income/">taxable income</a><cite>Taxable income is the amount of income subject to <a href="https://taxfoundation.org/taxedu/glossary/tax/">tax</a>, after <a href="https://taxfoundation.org/taxedu/glossary/tax-deduction/">deductions</a> and <a href="https://taxfoundation.org/taxedu/glossary/tax-exemption/">exemptions</a>. For both individuals and corporations, taxable income differs from—and is less than—gross income.
</cite></span> is much simpler for all other exempt organizations since they don’t have to account for charitable contributions. All of their income is assumed to be program service income. These organizations would simply pay the corporate income tax rate on their income net of expenses like any private business.</p>
<p>In 2019, these organizations had $87 billion in net income, or profits. Had these profits been taxed at the 21 percent corporate tax rate, it could have raised $18 billion in revenues.</p>
<p>Lastly, federal credit unions generated $7 billion in net income in 2019 and would have been liable for $2 billion in taxes had they been taxed at 21 percent.</p>
<p>Combined, taxing the net program income of all nonprofits could have raised $39 billion in new revenues in 2019.</p>
<!-- #tablepress-462 from cache -->
<p><strong>Step 3:</strong> The final step would be to decide how to tax the investment income—dividends, interest, and capital gains—of tax-exempt organizations. Table 3 includes investment income in the total net “profits” of tax-exempt organizations and, thus, assumes they are taxed at 21 percent. Currently, most nonprofits pay no tax on their investment income under the theory that such income supports the mission of the organization. However, private foundations are required to pay a 1.39 percent excise tax on their investment income. Large university endowments are also required to pay a 1.4 percent excise tax if the endowment assets exceed $500,000 per student.</p>
<p>The rate at which nonprofit investment income is taxed is not a trivial matter. In 2019, the Urban Institute dataset shows that 501(c)(3) organizations reported $51.8 billion in investment income. All other 501(c) organizations reported $19.4 billion in investment income, which brings the total of nonprofit investment income to $71.2 billion. Taxing this income at roughly 1.4 percent rather than 21 percent would yield much less revenue.</p>
<p>The tax exemption for investment income has allowed some large nonprofits to become tax-exempt hedge funds. Tax neutrality demands that all taxpayers pay the same rate on their investment income. Thus, it would make sense to tax the investment income of nonprofits at the 21 percent corporate rate and remove any incentive for arbitrage or income shifting.</p>
<h2>Conclusion</h2>
<p>Washington faces a brewing fiscal crisis that will force lawmakers to look for additional tax revenues, either to address mounting deficits or to offset the extension of key portions of the 2017 Tax Cuts and Jobs Act—perhaps even both. The fairest and least economically harmful way to raise new revenues is to expand the federal tax base to include business-like income earned by tax-exempt nonprofit organizations.</p>
<p>The rules governing the tax-exempt sector are long overdue for reform. The $3.3 trillion nonprofit economy is dominated by large, business-like organizations that overshadow the truly benevolent organizations the tax exemption should be reserved for.</p>
<p>A reasonable rewriting of the tax-exempt rules should include narrowing the definition of “public charity,” repealing the toothless UBIT, and subjecting all non-charitable income to taxation. Doing so would protect the charitable income of benevolent organizations while leveling the playing field between nonprofits and for-profit entities. Most importantly, tighter rules would also give a principled foundation to the nonprofit sector that has been missing for the past 120 years.</p>
<div data-id="1"><h2>Stay informed on the tax policies impacting you.</h2><p>Subscribe to get insights from our trusted experts delivered straight to your inbox.</p>
<p><a href="https://taxfoundation.org/tax-newsletter">Subscribe</a></p></div>
<hr>
<p><a href="#_ftnref1" name="_ftn1">[1]</a> Author calculations.</p>
<p><a href="#_ftnref2" name="_ftn2">[2]</a> Internal Revenue Service, “Exempt Organizations Business Master File Extract (EO BMF),” https://www.irs.gov/charities-non-profits/exempt-organizations-business-master-file-extract-eo-bmf</p>
<p><a href="#_ftnref3" name="_ftn3">[3]</a> Author calculations, See Table 1.</p>
<p><a href="#_ftnref4" name="_ftn4">[4]</a> Congress of the United States, Joint Committee on Taxation, <em>Historical Development and Present Law of the Federal Tax Exemption for Charities and Other Tax-Exempt Organizations</em>, Apr. 19, 2005, <a href="https://www.jct.gov/publications/2005/jcx-29-05/">https://www.jct.gov/publications/2005/jcx-29-05/</a>.</p>
<p><a href="#_ftnref5" name="_ftn5">[5]</a> Giving USA, “Giving USA Limited Data Tableau Visualization, 2022 Giving Overview,” <a href="https://givingusa.org/giving-usa-limited-data-tableau-visualization/">https://givingusa.org/giving-usa-limited-data-tableau-visualization/</a>.</p>
<p><a href="#_ftnref6" name="_ftn6">[6]</a> B.H. Meyer, “Fraternal Beneficiary Societies in the United States,” <em>American Journal of Sociology</em> 6:5 (March 1901): 647, <a href="https://www.jstor.org/stable/2762005" rel="nofollow">https://www.jstor.org/stable/2762005</a>.</p>
<p><a href="#_ftnref7" name="_ftn7">[7]</a> Scott Hodge, “After 90 Years, It Is Time to Wean Credit Unions off Taxpayer Subsidies,” Tax Foundation, Jan. 30, 2024, <a href="https://taxfoundation.org/research/all/federal/credit-union-tax-treatment/">https://taxfoundation.org/research/all/federal/credit-union-tax-treatment/</a></p>
<p><a href="#_ftnref8" name="_ftn8">[8]</a> Tariff of 1894 (Wilson-Gorman Tariff), Aug. 27, 1894, <a href="https://fraser.stlouisfed.org/title/5901">https://fraser.stlouisfed.org/title/5901</a>. (The income tax is defined on p. 553 and the tax-exempt language begins on p. 556.)</p>
<p><a href="#_ftnref9" name="_ftn9">[9]</a> American Association of Public Accountants, <em>The Corporation Tax Law of 1909,</em> <a href="https://egrove.olemiss.edu/cgi/viewcontent.cgi?article=1955&amp;context=aicpa_guides">https://egrove.olemiss.edu/cgi/viewcontent.cgi?article=1955&amp;context=aicpa_guides</a>.</p>
<p><a href="#_ftnref10" name="_ftn10">[10]</a> 44 Cong. Rec. 4151 (1909). </p>
<p><a href="#_ftnref11" name="_ftn11">[11]</a> Ibid.</p>
<p><a href="#_ftnref12" name="_ftn12">[12]</a> Ibid., p. 4155.</p>
<p><a href="#_ftnref13" name="_ftn13">[13]</a> Ibid., p. 4156.</p>
<p><a href="#_ftnref14" name="_ftn14">[14]</a> H.R. 3321, 63<sup>rd</sup> Cong. (1913), p. 172, <a href="https://fraser.stlouisfed.org/files/docs/historical/congressional/underwood-tariff-1913.pdf">https://fraser.stlouisfed.org/files/docs/historical/congressional/underwood-tariff-1913.pdf</a>.</p>
<p><a href="#_ftnref15" name="_ftn15">[15]</a> E. Gordon Keith, “New Data on Tax-Exempt Organizations,” <em>Proceedings of the Annual Conference on Taxation under the Auspices of the National Tax Association</em> 38 (1945): 257-269, <a href="http://www.jstor.org/stable/23404793" rel="nofollow">www.jstor.org/stable/23404793</a>.</p>
<p><a href="#_ftnref16" name="_ftn16">[16]</a> <span><a href="https://taxfoundation.org/taxedu/glossary/individual-income-tax/">Individual Income Tax</a><cite>An individual income tax (or personal income tax) is levied on the wages, salaries, investments, or other forms of income an individual or household earns. The U.S. imposes a <a href="https://taxfoundation.org/taxedu/glossary/progressive-tax/">progressive</a> income tax where rates <a href="https://taxfoundation.org/taxedu/glossary/graduated-rate-income-tax/">increase</a> with income. The Federal Income Tax was established in 1913 with the ratification of the <a href="https://taxfoundation.org/taxedu/educational-resources/primer-10-common-tax-myths-debunked/">16th Amendment</a>. Though barely 100 years old, individual income taxes are the <a href="https://taxfoundation.org/data/all/federal/us-tax-revenue-by-tax-type-2023/">largest</a> source of tax revenue in the U.S.
</cite></span> Return for Calendar Year 1917, Form 1040 Instructions, <a href="https://www.irs.gov/pub/irs-prior/f1040--1917.pdf">https://www.irs.gov/pub/irs-prior/f1040--1917.pdf</a>.</p>
<p><a href="#_ftnref17" name="_ftn17">[17]</a> Mark B. Edwards, “It All Started With Macaroni: A Trip Through the Shadowy World of UBIT,” prepared for the 2005 Legal Forum, September 2005, <a href="https://www.inumc.org/wp-content/uploads/2024/01/unrelatedbusinessincome-1.pdf">https://www.inumc.org/wp-content/uploads/2024/01/unrelatedbusinessincome-1.pdf</a>.</p>
<p><a href="#_ftnref18" name="_ftn18">[18]</a> Joint Committee on Taxation (2005), 100.</p>
<p><a href="#_ftnref19" name="_ftn19">[19]</a> United States Treasury Department, Bureau of Internal Revenue, “Supplement to Statistics of Income for 1946, Part 2,” October 1949, <a href="https://www.irs.gov/pub/irs-soi/46eosupsec2.pdf">https://www.irs.gov/pub/irs-soi/46eosupsec2.pdf</a>.</p>
<p><a href="#_ftnref20" name="_ftn20">[20]</a> Hodge, “After 90 Years, It Is Time to Wean Credit Unions off Taxpayer Subsidies.”</p>
<p><a href="#_ftnref21" name="_ftn21">[21]</a> Internal Revenue Code of 1954, <a href="https://www.govinfo.gov/content/pkg/STATUTE-68/pdf/STATUTE-68A-Pg1.pdf">https://www.govinfo.gov/content/pkg/STATUTE-68/pdf/STATUTE-68A-Pg1.pdf</a>.</p>
<p><a href="#_ftnref22" name="_ftn22">[22]</a> U.S. Department of Commerce Bureau of the Census, <em>Historical Statistics of the United States, Colonial Times to 1970, Part 1</em>, (Washington, DC, 1975), 224. Note: In 1909, U.S. GDP was $33.4 billion in current dollars.</p>
<p><a href="#_ftnref23" name="_ftn23">[23]</a> “NCCS Core Series Overview,” National Center for Charitable Statistics, <a href="https://nccs.urban.org/nccs/datasets/core/">https://nccs.urban.org/nccs/datasets/core/</a>.  </p>
<p><a href="#_ftnref24" name="_ftn24">[24]</a> IRS, <em>Form 990, Return of Organization Exempt from Income Tax, 2018</em>, Harvard Business School Publishing Corporation, <a href="https://apps.irs.gov/pub/epostcard/cor/043177990_201906_990_2021012817670018.pdf">https://apps.irs.gov/pub/epostcard/cor/043177990_201906_990_2021012817670018.pdf</a>.</p>
<p><a href="#_ftnref25" name="_ftn25">[25]</a> Creative Testing Solutions, <a href="https://www.mycts.org/">https://www.mycts.org/</a>.</p>
<p><a href="#_ftnref26" name="_ftn26">[26]</a> Battelle Memorial Institute, <a href="https://www.battelle.org/about-us">https://www.battelle.org/about-us</a>.</p>
<p><a href="#_ftnref27" name="_ftn27">[27]</a> RTI International, <a href="https://www.rti.org/about-us">https://www.rti.org/about-us</a>.</p>
<p><a href="#_ftnref28" name="_ftn28">[28]</a> IRS, <em>Form 990, Return of Organization Exempt from Income Tax, 2018</em>, Research Triangle Institute,  <a href="https://apps.irs.gov/pub/epostcard/cor/560686338_201909_990_2020101517377917.pdf">https://apps.irs.gov/pub/epostcard/cor/560686338_201909_990_2020101517377917.pdf</a>.</p>
<p><a href="#_ftnref29" name="_ftn29">[29]</a> Scott Hodge, “Nonprofits are Financially Healthy and Doing Big Business,” Tax Foundation, Oct. 6, 2023. <a href="https://taxfoundation.org/blog/501c3-nonprofit-revenue/">https://taxfoundation.org/blog/501c3-nonprofit-revenue/</a>.</p>
<p><a href="#_ftnref30" name="_ftn30">[30]</a> Ibid.</p>
<p><a href="#_ftnref31" name="_ftn31">[31]</a> Dress for Success, <a href="https://www.dressforsuccessqc.org/">https://www.dressforsuccessqc.org/</a>.</p>
<p><a href="#_ftnref32" name="_ftn32">[32]</a> IRS, <em>Form 990, Return of Organization Exempt from Income Tax, 2019,</em> Navigate Affordable Housing Partners Inc., <a href="https://apps.irs.gov/pub/epostcard/cor/630985617_201912_990_2020110517414338.pdf">https://apps.irs.gov/pub/epostcard/cor/630985617_201912_990_2020110517414338.pdf</a>.</p>
<p><a href="#_ftnref33" name="_ftn33">[33]</a> Vetter Senior Living, <a href="https://www.vetterseniorliving.com/we-believe/history/" rel="nofollow">https://www.vetterseniorliving.com/we-believe/history/</a>.  </p>
<p><a href="#_ftnref34" name="_ftn34">[34]</a> IRS, <em>Form 990, Return of Organization Exempt from Income Tax, 2018,</em> Vetter Senior Living, <a href="https://apps.irs.gov/pub/epostcard/cor/471108168_201906_990_2021012817669748.pdf">https://apps.irs.gov/pub/epostcard/cor/471108168_201906_990_2021012817669748.pdf</a>.</p>
<p><a href="#_ftnref35" name="_ftn35">[35]</a> IRS, <em>Form 990, Return of Organization Exempt from Income Tax, 2018</em>, Habitat for Humanity International Inc., <a href="https://apps.irs.gov/pub/epostcard/cor/911914868_201906_990_2020020617119545.pdf">https://apps.irs.gov/pub/epostcard/cor/911914868_201906_990_2020020617119545.pdf</a>.</p>
<p><a href="#_ftnref36" name="_ftn36">[36]</a> IRS, <em>Form 990, Return of Organization Exempt from Income Tax 2019,</em> AARP Foundation,<em> 2018</em><a href="https://apps.irs.gov/pub/epostcard/cor/520794300_201912_990_2021022617763807.pdf">https://apps.irs.gov/pub/epostcard/cor/520794300_201912_990_2021022617763807.pdf</a>.</p>
<p><a href="#_ftnref37" name="_ftn37">[37]</a> IRS, <em>Form 990, Return of Organization Exempt from Income Tax, 2019, </em>AARP, <a href="https://apps.irs.gov/pub/epostcard/cor/951985500_201912_990O_2022042920018144.pdf">https://apps.irs.gov/pub/epostcard/cor/951985500_201912_990O_2022042920018144.pdf</a>.</p>
<p><a href="#_ftnref38" name="_ftn38">[38]</a> Internal Revenue Service, “Social welfare organizations,” <a href="https://www.irs.gov/charities-non-profits/other-non-profits/social-welfare-organizations">https://www.irs.gov/charities-non-profits/other-non-profits/social-welfare-organizations</a>.</p>
<p><a href="#_ftnref39" name="_ftn39">[39]</a> Prairie Meadows, <a href="https://www.prairiemeadows.com/about-us/our-company">https://www.prairiemeadows.com/about-us/our-company</a>.</p>
<p><a href="#_ftnref40" name="_ftn40">[40]</a> Desert Mountain Club Inc., <a href="https://www.desertmountain.com/membership-information/">https://www.desertmountain.com/membership-information/</a>.</p>
<p><a href="#_ftnref41" name="_ftn41">[41]</a> B.H. Meyer, “Fraternal Beneficiary Societies in the United States,” <em>American Journal of Sociology</em> 6:5 (March 1901): 646-661, <a href="https://www.jstor.org/stable/2762005" rel="nofollow">https://www.jstor.org/stable/2762005</a>.</p>
<p><a href="#_ftnref42" name="_ftn42">[42]</a> Woodmen Life, <a href="https://www.woodmenlife.org/extras/">https://www.woodmenlife.org/extras/</a>.</p>
<p><a href="#_ftnref43" name="_ftn43">[43]</a> Modern Woodmen, <a href="https://www.modernwoodmen.org/financial-planning/protection/">https://www.modernwoodmen.org/financial-planning/protection/</a>.</p>
<p><a href="#_ftnref44" name="_ftn44">[44]</a> Knights of Columbus, <a href="https://www.kofc.org/en/what-we-do/insurance/index.html">https://www.kofc.org/en/what-we-do/insurance/index.html</a>.</p>
<p><a href="#_ftnref45" name="_ftn45">[45]</a> Cooperative Services Corporation, <a href="https://www.cooperative.com/cfc/pages/ncsc.aspx">https://www.cooperative.com/cfc/pages/ncsc.aspx</a>.</p>
<p><a href="#_ftnref46" name="_ftn46">[46]</a> National Rural Utilities Cooperative Finance Corporation, <a href="https://www.nrucfc.coop/content/nrucfc/en/about-cfc.html">https://www.nrucfc.coop/content/nrucfc/en/about-cfc.html</a>.</p>
<p><a href="#_ftnref47" name="_ftn47">[47]</a> Jeffrey Scott Tenenbaum, “Unrelated Business Income Tax (UBIT): A Comprehensive Overview for Nonprofits,” Business Law Today, November 2021, <a href="https://americanbar.org/groups/business_law/resources/business-law-today/2021-november/unrelated-business-income-tax/" rel="nofollow">https://americanbar.org/groups/business_law/resources/business-law-today/2021-november/unrelated-business-income-tax/</a>. </p>
<p><a href="#_ftnref48" name="_ftn48">[48]</a> Department of the Treasury, Internal Revenue Service, <em>Publication 598: Tax on Unrelated Business Income of Exempt Organizations</em>, Mar. 22, 2021, <a href="https://www.irs.gov/pub/irs-pdf/p598.pdf">https://www.irs.gov/pub/irs-pdf/p598.pdf</a>.</p>
<p><a href="#_ftnref49" name="_ftn49">[49]</a> Internal Revenue Service, Statistics of Income, <em>Table 16: Nonprofit Charitable Organization and Domestic Private Foundation Information Returns, and Exempt Organization Business Income Tax Returns: Selected Financial Data, Expanded</em>, <a href="https://www.irs.gov/statistics/soi-tax-stats-historical-table-16">https://www.irs.gov/statistics/soi-tax-stats-historical-table-16</a>.</p>
<p><a href="#_ftnref50" name="_ftn50">[50]</a> U.S. Department of Treasury, Internal Revenue Service, <em>Publication 557, Tax-Exempt Status for Your Organization</em>, revised January 2014, <a href="https://www.irs.gov/pub/irs-pdf/p557.pdf">https://www.irs.gov/pub/irs-pdf/p557.pdf</a>.</p>


  </div>

  

</article>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I made a puzzle game that gently introduces my favorite math mysteries (290 pts)]]></title>
            <link>https://www.rahulilango.com/coloring/</link>
            <guid>40740021</guid>
            <pubDate>Thu, 20 Jun 2024 15:45:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rahulilango.com/coloring/">https://www.rahulilango.com/coloring/</a>, See on <a href="https://news.ycombinator.com/item?id=40740021">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <p>
        Color the map of the British Isles so that no two physically bordering regions have the same color
        
    </p>
    

    <!-- sa uk pi af us wus nsa  -->
    <p>(Click to color)</p>
    <interactive-canvas mode="color" coloring-mode="four" preset-map="uk"></interactive-canvas>
    
    


    
    
    <!-- 100% privacy-first analytics -->
    
    


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Atkinson Dithering (143 pts)]]></title>
            <link>https://beyondloom.com/blog/dither.html</link>
            <guid>40739710</guid>
            <pubDate>Thu, 20 Jun 2024 15:18:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://beyondloom.com/blog/dither.html">https://beyondloom.com/blog/dither.html</a>, See on <a href="https://news.ycombinator.com/item?id=40739710">Hacker News</a></p>
<div id="readability-page-1" class="page"><h2 id="atkinsondithering">Atkinson Dithering</h2>

<p>When the <a href="https://beyondloom.com/blog/thinkc.html">Macintosh</a> was released in 1984, it featured a square-pixeled black-and-white display at a crisp 72 dots per inch. The 512x342 resolution might seem less than impressive today, but for the time it was a pleasantly high-resolution consumer-grade computer. Among other things, the monospaced <a href="https://en.wikipedia.org/wiki/Monaco_(typeface)">Monaco 9pt</a> bitmap font featured characters that were 6 pixels wide, allowing the Macintosh to render a standard 80-column terminal with ample room for a vertical scrollbar and other niceties.</p>

<p>Beyond <a href="https://en.wikipedia.org/wiki/Susan_Kare">Susan Kare’s</a> brilliant type design and pixel-art icons, a cornerstone of the visual vocabulary of the Macintosh is the use of dithered images. Dithering algorithms use a small palette (in our case, black and white) to represent a larger one (simulated grayscale). Here we will examine two popular techniques: Floyd-Steinberg dithering, and a variation common on the Macintosh, Atkinson dithering.</p>

<h2 id="floyd-steinberg">Floyd-Steinberg</h2>

<p>The central idea of Floyd-Steinberg dithering is <em>error diffusion</em>. When determining the 1-bit color to assign to a given pixel in a grayscale image, quantizing will result in some error- a pixel either <em>darker</em> or <em>lighter</em> than the true grayscale value. By “pushing” this rounding error to neighboring pixels, we can ensure that <em>on average</em> the distribution of black and white in the output image resembles the input. Your eye closes the gap, and reconstructs some of the lost information.</p>

<p>Floyd-Steinberg dithering scans input pixels in a single pass, top-to-bottom and left-to-right. Error left over from each pixel is distributed between neighboring pixels which have not been converted yet, in the following proportions:</p>

<figure>
	<img src="https://beyondloom.com/blog/dither-figures/floyd.png">
	<figcaption>Floyd-Steinberg error diffusion</figcaption>
</figure>

<p>Suppose we have the <em>[0.0,1.0]</em> grayscale values of an image in an array <code>pixels</code> and the width of the image <code>w</code>, and we wish to generate an array of <em>{0,1}</em> output pixels. If we are permitted to mutate <code>pixels</code> in-place, a JavaScript implementation of the algorithm might look something like the following:</p>

<pre><code>function floyd(pixels,w) {
	const m=[[1,7],[w-1,3],[w,5],[w+1,1]]
	for (let i=0; i&lt;pixels.length; i++) {
		const x=pixels[i], col=x&gt;.5, err=(x-col)/16
		m.forEach(([x,y]) =&gt; i+x&lt;pixels.length &amp;&amp; (pixels[i+x]+=err*y))
		pixels[i]=col
	}
	return pixels
}
</code></pre>

<p>Given a <em>mask</em> (<code>m</code>) of relative offsets to neighbor pixels and the proportion of error they should get, we map over our pixels in order. The <em>color</em> at each pixel (<code>col</code>) is a simple quantization of the grayscale value (<code>x&gt;.5</code>), the <em>error</em> (<code>err</code>) is the difference between this quantized value and the original, and we simply add a fraction of that error to neighbor pixels before returning <code>col</code>.</p>

<figure>
	<div>
		<div>
			<p><img src="https://beyondloom.com/blog/dither-figures/david.png"></p><figcaption>Original</figcaption>
		</div>
		<div>
			<p><img src="https://beyondloom.com/blog/dither-figures/david-floyd.png"></p><figcaption>Floyd-Steinberg dithering</figcaption>
		</div>
	</div>
</figure>

<p>Note that in this implementation error diffused from the right edge of the image will bleed into the left edge of the following row. The inherent noisyness of dithering makes this aesthetically irrelevant, and doing so simplifies the implementation. Everyone wins!</p>

<p>If we wanted to avoid modifying <code>pixels</code> in-place, we could observe that the accumulated error we care about would fit in a fixed-size circular buffer (<code>e</code>) proportional to the width of our image. The result is slightly more complex, but in some ways conceptually cleaner, since our main loop is now a <code>map()</code>:</p>

<pre><code>function floyd2(pixels,w) {
	const e=Array(w+1).fill(0), m=[[0,7],[w-2,3],[w-1,5],[w,1]]
	return pixels.map(x =&gt; {
		const pix=x+(e.push(0),e.shift()), col=pix&gt;.5, err=(pix-col)/16
		m.forEach(([x,y]) =&gt; e[x]+=err*y)
		return col
	})
}
</code></pre>

<p>(<code>Array.shift()</code> and <code>Array.push()</code> are used here for conciseness; use your imagination for a more efficient low-level implementation.)</p>

<h2 id="atkinsonsalgorithm">Atkinson’s Algorithm</h2>

<p>Apple’s <a href="https://en.wikipedia.org/wiki/Bill_Atkinson">Bill Atkinson</a> developed a variation of the above technique which produces results that are subjectively nicer-looking. The basics work the same, but error is spread in a broader pattern, and only 3/4ths of the error is preserved:</p>

<figure>
	<img src="https://beyondloom.com/blog/dither-figures/atkinson.png">
	<figcaption>Atkinson error diffusion</figcaption>
</figure>

<p>Modifying <code>floyd2()</code> above, we can simplify <code>m</code>, as all the error is propagated in an even proportion. The sliding error window <code>e</code> now needs to be roughly twice as large to account for the broader spread pattern:</p>

<pre><code>function atkinson(pixels,w) {
	const e=Array(2*w).fill(0), m=[0,1,w-2,w-1,w,2*w-1]
	return pixels.map(x =&gt; {
		const pix=x+(e.push(0),e.shift()), col=pix&gt;.5, err=(pix-col)/8
		m.forEach(x =&gt; e[x]+=err)
		return col
	})
}
</code></pre>

<figure>
	<div>
		<div>
			<p><img src="https://beyondloom.com/blog/dither-figures/mandrill.png"></p><figcaption>Original</figcaption>
		</div>
		<div>
			<p><img src="https://beyondloom.com/blog/dither-figures/mandrill-floyd.png"></p><figcaption>Floyd-Steinberg dithering</figcaption>
		</div>
		<div>
			<p><img src="https://beyondloom.com/blog/dither-figures/mandrill-atkinson.png"></p><figcaption>Atkinson dithering</figcaption>
		</div>
	</div>
</figure>

<p>Compared side-by-side with Floyd-Steinberg dithering, Atkinson’s algorithm seems to produce richer contrast, at the cost of some detail in very light or dark areas of the image.</p>

<h2 id="ditheringinike">Dithering in iKe</h2>

<p>Readers of this blog might be curious to know what Atkinson dithering would look like in <a href="https://github.com/JohnEarnest/ok/tree/gh-pages/ike">iKe</a>.</p>

<p>We can leverage iKe’s capabilities for loading remote images via the special <code>/i</code> operative. By specifying the built-in palette <code>gray</code>, the input image will be converted into a matrix of <em>[0,255]</em> grayscale values. To resize the iKe graphics window to match the image, we initialize the magic variables <code>w</code> and <code>h</code> based on the dimensions of this matrix. Our running error window is stored in a global (<code>e</code>) initialized with two rows worth of zeroes (<code>&amp;2*w</code>). The definition of our mask <code>m</code> is virtually identical to the JavaScript version above.</p>

<p>Most of the work happens in <code>d</code>, which is meant to dither one pixel. We find the value of the current pixel, incorporating accumulated error (<code>p:x+*e</code>), quantize the output color (<code>c:p&gt;.5</code>), shift out the consumed error value and shift in a zero (<code>e::1_e,0</code>), and then <em>amend</em> <code>e</code> by adding the error at the current pixel at every index in our mask <code>m</code> (<code>@[`e;m;+;(p-c)%8]</code>).</p>

<p>To dither the entire image, we explicitly apply <code>d</code> to each pixel of the matrix, remembering to first rescale the input <em>[0,255]</em> palette indices into floating point <em>[0.0,1.0]</em> values. For an animated application of this code, it would be necessary to reset <code>e</code> after each frame.</p>

<pre><code>/i pixels;gray;https://i.imgur.com/Lcq4Xi4.png
w: #*pixels
h: #pixels
e: &amp;2*w
m: (0;1;w-2;w-1;w;2*w-1)
d: {p:x+*e; c:p&gt;.5; e::1_e,0; @[`e;m;+;(p-c)%8]; c}
,(;;d''pixels%255)
</code></pre>

<figure>
<img src="https://beyondloom.com/blog/dither-figures/bill.png" alt="Thanks, Bill.">
<figcaption>Thanks, Bill.</figcaption>
</figure>

<p><a href="https://beyondloom.com/blog/index.html">back</a></p>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Could AI be a dot com sized bubble? (110 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40739431</link>
            <guid>40739431</guid>
            <pubDate>Thu, 20 Jun 2024 14:54:23 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40739431">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="40739431">
      <td><span></span></td>      <td><center><a id="up_40739431" href="https://news.ycombinator.com/vote?id=40739431&amp;how=up&amp;goto=item%3Fid%3D40739431"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=40739431">Ask HN: Could AI be a dot com sized bubble?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_40739431">103 points</span> by <a href="https://news.ycombinator.com/user?id=jameslk">jameslk</a> <span title="2024-06-20T14:54:23"><a href="https://news.ycombinator.com/item?id=40739431">4 hours ago</a></span> <span id="unv_40739431"></span> | <a href="https://news.ycombinator.com/hide?id=40739431&amp;goto=item%3Fid%3D40739431">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Could%20AI%20be%20a%20dot%20com%20sized%20bubble%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=40739431&amp;auth=11d20f8e338d8c8c26f2ae6471155cb537c45ff0">favorite</a> | <a href="https://news.ycombinator.com/item?id=40739431">91&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>AI hype has landed in the laps of retail investors and in general anyone passively investing as NVIDIA and Microsoft shares have risen and become part of major ETFs in the expectation that the AI-driven demand for their products will continue unabated. Other tech stocks seem to be seeing similar treatment around AI hype.</p><p>I do expect the current trajectory of generative models will eventually be incredibly important just like the internet was and is, but it seems there’s a lot of high expectations of how useful it can be in the near future with fuzzy ideas around business models like in the dot com era.</p><p>If these near future expectations don’t pan out, could companies slow down their R&amp;D expenditures which are floating NVIDIA, Microsoft, et al and lead to a sizable stock market correction?</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude 3.5 Sonnet (469 pts)]]></title>
            <link>https://www.anthropic.com/news/claude-3-5-sonnet</link>
            <guid>40738916</guid>
            <pubDate>Thu, 20 Jun 2024 14:03:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/claude-3-5-sonnet">https://www.anthropic.com/news/claude-3-5-sonnet</a>, See on <a href="https://news.ycombinator.com/item?id=40738916">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure><img alt="Claude head illustration" loading="eager" width="2880" height="1620" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F4e78f69ef8d4186fb5691714abe36224483d91b0-2880x1620.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F4e78f69ef8d4186fb5691714abe36224483d91b0-2880x1620.png&amp;w=3840&amp;q=75"></figure><p>Today, we’re launching Claude 3.5 Sonnet—our first release in the forthcoming Claude 3.5 model family. Claude 3.5 Sonnet raises the industry bar for intelligence, outperforming competitor models and Claude 3 Opus on a wide range of evaluations, with the speed and cost of our mid-tier model, Claude 3 Sonnet.</p><p>Claude 3.5 Sonnet is now available for free on Claude.ai and the Claude iOS app, while Claude Pro and Team plan subscribers can access it with significantly higher rate limits. It is also available via the Anthropic API, Amazon Bedrock, and Google Cloud’s Vertex AI. The model costs $3 per million input tokens and $15 per million output tokens, with a 200K token context window.</p><figure><img alt="Claude model family" loading="eager" width="2200" height="1174" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1f044104447e9db6b22db3a06e45d114f50f274e-2200x1174.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1f044104447e9db6b22db3a06e45d114f50f274e-2200x1174.png&amp;w=3840&amp;q=75"></figure><h3>Frontier intelligence at 2x the speed</h3><p>Claude 3.5 Sonnet sets new industry benchmarks for graduate-level reasoning (GPQA), undergraduate-level knowledge (MMLU), and coding proficiency (HumanEval). It shows marked improvement in grasping nuance, humor, and complex instructions, and is exceptional at writing high-quality content with a natural, relatable tone.</p><p>Claude 3.5 Sonnet operates at twice the speed of Claude 3 Opus. This performance boost, combined with cost-effective pricing, makes Claude 3.5 Sonnet ideal for complex tasks such as context-sensitive customer support and orchestrating multi-step workflows.</p><p>In an <a href="https://cdn.sanity.io/files/4zrzovbb/website/fed9cc193a14b84131812372d8d5857f8f304c52.pdf">internal agentic coding evaluation</a>, Claude 3.5 Sonnet solved 64% of problems, outperforming Claude 3 Opus which solved 38%. Our evaluation tests the model’s ability to fix a bug or add functionality to an open source codebase, given a natural language description of the desired improvement. When instructed and <a href="https://www.anthropic.com/news/tool-use-ga">provided with the relevant tools</a>, Claude 3.5 Sonnet can independently write, edit, and execute code with sophisticated reasoning and troubleshooting capabilities. It handles code translations with ease, making it particularly effective for updating legacy applications and migrating codebases.</p><figure><img alt="Claude 3.5 Sonnet benchmarks" loading="lazy" width="2200" height="1894" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fcf2c754458e9102b7334731fb18a965bfeb7ad08-2200x1894.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fcf2c754458e9102b7334731fb18a965bfeb7ad08-2200x1894.png&amp;w=3840&amp;q=75"></figure><h3>State-of-the-art vision</h3><p>Claude 3.5 Sonnet is our strongest vision model yet, surpassing Claude 3 Opus on standard vision benchmarks. These step-change improvements are most noticeable for tasks that require visual reasoning, like interpreting charts and graphs. Claude 3.5 Sonnet can also accurately transcribe text from imperfect images—a core capability for retail, logistics, and financial services, where AI may glean more insights from an image, graphic or illustration than from text alone.</p><!--$!--><template data-dgst="NEXT_DYNAMIC_NO_SSR_CODE"></template><!--/$--><figure><img alt="Claude 3.5 Sonnet vision evals" loading="lazy" width="2200" height="1110" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fcaff3d60763b27b59fe33e4ae984530f0dba4ddb-2200x1110.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fcaff3d60763b27b59fe33e4ae984530f0dba4ddb-2200x1110.png&amp;w=3840&amp;q=75"></figure><h3>Artifacts—a new way to use Claude</h3><p>Today, we’re also introducing Artifacts on Claude.ai, a new feature that expands how users can interact with Claude. When a user asks Claude to generate content like code snippets, text documents, or website designs, these Artifacts appear in a dedicated window alongside their conversation. This creates a dynamic workspace where they can see, edit, and build upon Claude’s creations in real-time, seamlessly integrating AI-generated content into their projects and workflows.</p><p>This preview feature marks Claude’s evolution from a conversational AI to a collaborative work environment. It’s just the beginning of a broader vision for Claude.ai, which will soon expand to support team collaboration. In the near future, teams—and eventually entire organizations—will be able to securely centralize their knowledge, documents, and ongoing work in one shared space, with Claude serving as an on-demand teammate.</p><!--$!--><template data-dgst="NEXT_DYNAMIC_NO_SSR_CODE"></template><!--/$--><h3>Commitment to safety and privacy</h3><p>Our models are subjected to rigorous testing and have been trained to reduce misuse. Despite Claude 3.5 Sonnet’s leap in intelligence, our red teaming assessments have concluded that Claude 3.5 Sonnet remains at <a href="https://www.anthropic.com/news/anthropics-responsible-scaling-policy">ASL-2</a>. More details can be found in the <a href="https://cdn.sanity.io/files/4zrzovbb/website/fed9cc193a14b84131812372d8d5857f8f304c52.pdf">model card addendum</a>.</p><p>As part of our commitment to safety and transparency, we’ve engaged with external experts to test and refine the safety mechanisms within this latest model. We recently provided Claude 3.5 Sonnet to the UK’s Artificial Intelligence Safety Institute (UK AISI) for pre-deployment safety evaluation. The UK AISI completed tests of 3.5 Sonnet and shared their results with the US AI Safety Institute (US AISI) as part of a Memorandum of Understanding, made possible by the partnership between the US and UK AISIs <a href="https://www.commerce.gov/news/press-releases/2024/04/us-and-uk-announce-partnership-science-ai-safety">announced earlier this year</a>.</p><p>We have integrated policy feedback from outside subject matter experts to ensure that our evaluations are robust and take into account new trends in abuse. This engagement has helped our teams scale up our ability to evaluate 3.5 Sonnet against various types of misuse. For example, we used feedback from child safety experts at <a href="https://www.thorn.org/">Thorn</a> to update our classifiers and fine-tune our models.</p><p>One of the core constitutional principles that guides our AI model development is privacy. We do not train our generative models on user-submitted data unless a user gives us explicit permission to do so. To date we have not used any customer or user-submitted data to train our generative models.</p><h3>Coming soon</h3><p>Our aim is to substantially improve the tradeoff curve between intelligence, speed, and cost every few months. To complete the Claude 3.5 model family, we’ll be releasing Claude 3.5 Haiku and Claude 3.5 Opus later this year.</p><p>In addition to working on our next-generation model family, we are developing new modalities and features to support more use cases for businesses, including integrations with enterprise applications. Our team is also exploring features like Memory, which will enable Claude to remember a user’s preferences and interaction history as specified, making their experience even more personalized and efficient.</p><p>We’re constantly working to improve Claude and love hearing from our users. You can submit feedback on Claude 3.5 Sonnet directly in-product to inform our development roadmap and help our teams to improve your experience. As always, we look forward to seeing what you build, create, and discover with Claude.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wc2: Investigates optimizing 'wc', the Unix word count program (125 pts)]]></title>
            <link>https://github.com/robertdavidgraham/wc2</link>
            <guid>40738833</guid>
            <pubDate>Thu, 20 Jun 2024 13:54:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/robertdavidgraham/wc2">https://github.com/robertdavidgraham/wc2</a>, See on <a href="https://news.ycombinator.com/item?id=40738833">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">wc2 - asynchronous state machine parsing</h2><a id="user-content-wc2---asynchronous-state-machine-parsing" aria-label="Permalink: wc2 - asynchronous state machine parsing" href="#wc2---asynchronous-state-machine-parsing"></a></p>
<p dir="auto">There have been multiple articles lately implementing the
classic <code>wc</code> program in various programming <em>languages</em>, to
"prove" their favorite language can be "just as fast" as C.</p>
<p dir="auto">This project does something different.
Instead of a different <em>language</em> it uses a different <em>algorithm</em>.
The new algorithm is significantly faster -- implementing in a
slow language like JavaScript is still faster than the original
<code>wc</code> program written in C.</p>
<p dir="auto">The algorithm is known as an "asynchronous state-machine parser".
It's a technique for <em>parsing</em> that you don't learn in college.
It's more <em>efficient</em>, but more importantly, it's more <em>scalable</em>.
That's why your browser uses a state-machine to parse GIFs,
and most web servers use state-machiens to parse incoming HTTP requests.</p>
<p dir="auto">This projects contains three versions:</p>
<ul dir="auto">
<li><code>wc2o.c</code> is a simplified 25 line version highlighting the idea</li>
<li><code>wc2.c</code> is the full version in C, supporting Unicode</li>
<li><code>wc2.js</code> is the version in JavaScript</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">The basic algorithm</h2><a id="user-content-the-basic-algorithm" aria-label="Permalink: The basic algorithm" href="#the-basic-algorithm"></a></p>
<p dir="auto">The algorithm reads input and passes each byte one at a time
to a state-machine. It looks something like:</p>
<div dir="auto" data-snippet-clipboard-copy-content="    length = fread(buf, 1, sizeof(buf), fp);
    for (i=0; i<length; i++) {
        c = buf[i];
        state = table[state][c];
        counts[state]++;
    }"><pre>    <span>length</span> <span>=</span> <span>fread</span>(<span>buf</span>, <span>1</span>, <span>sizeof</span>(<span>buf</span>), <span>fp</span>);
    <span>for</span> (<span>i</span><span>=</span><span>0</span>; <span>i</span><span>&lt;</span><span>length</span>; <span>i</span><span>++</span>) {
        <span>c</span> <span>=</span> <span>buf</span>[<span>i</span>];
        <span>state</span> <span>=</span> <span>table</span>[<span>state</span>][<span>c</span>];
        <span>counts</span>[<span>state</span>]<span>++</span>;
    }</pre></div>
<p dir="auto">No, you aren't suppose to be able to see how the word-count works
by looking at this code. The complexity happens elsewhere, setting
up the state-machine.</p>
<p dir="auto">The state-machine table is the difference between the simple version
(<code>wc2o.c</code>) and complex version (<code>wc2.c</code>) of the program. The algorithm
is the same, the one shown above, the difference is in how they setup
the table. The simple program creates a table for ASCII, the complex
program creates a much larger table supporting UTF-8.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How <code>wc</code> works</h2><a id="user-content-how-wc-works" aria-label="Permalink: How wc works" href="#how-wc-works"></a></p>
<p dir="auto">The <code>wc</code> word-count program counts the number of words in a file. A "word"
is some non-space characters separate by space.</p>
<p dir="auto">Those who re-implement <code>wc</code> simplify the problem by only doing ASCII instead
of the full UTF-8 Unicode. This is cheating, because much of the speed of
<code>wc</code> comes from its need to handle character-sets like UTF-8.
The real programs spend most of their time
in functions like <code>mbrtowc()</code> to parse multi-byte characters and
<code>iswspace()</code> to test if they are spaces -- which re-implementations
of <code>wc</code> skip.</p>
<p dir="auto">For this reason, we've implemented a full UTF-8 version in this project, to
prove that it works without cheating. Now the real <code>wc</code> works with a lot
more character-sets, and we don't do that. But by implementing UTF-8, we've
shown that it's possible, and that the speed for any character-set is the same.</p>
<p dir="auto">Another simplification is how invalid input is handled. The original <code>wc</code> program
largley ignores errors, but it's still an important factor in making sure you
are doing things correctly.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmark input files</h2><a id="user-content-benchmark-input-files" aria-label="Permalink: Benchmark input files" href="#benchmark-input-files"></a></p>
<p dir="auto">This project uses a number of large input files for benchmarking.
The traditional <code>wc</code> program has wildly different performance depending
upon input, such as whether the file is full of illegal characters, or
whether UTF-8 is being handled. The first test file is downloaded
from the Internet as "real-world data", while the others are generated
using a program built with this project (<code>wctool</code>).</p>
<ul dir="auto">
<li><code>pocorgtfo18.pdf</code> a large 92-million byte PDF file that contains binary/illegal characters</li>
<li><code>ascii.txt</code> a file the same size containing random words, ASCII-only</li>
<li><code>utf8.txt</code> a file containing random UTF-8 sequences of 1, 2, 3, and 4 bytes</li>
<li><code>word.txt</code> a file containing 92-million 'x' characters</li>
<li><code>space.txt</code> a file containing 92-million ' ' (space) characters</li>
</ul>
<p dir="auto">Before benchmarking the old <code>wc</code>, set the character-set to UTF-8. It's
probably already set to this on new systems, but do this to make sure:</p>
<div data-snippet-clipboard-copy-content="$ export LC_CTYPE=en_US.UTF-8"><pre><code>$ export LC_CTYPE=en_US.UTF-8
</code></pre></div>
<p dir="auto">When running <code>wc</code>, the <code>-lwc</code> is the default for counting words in ASCII text.
To convert it into UTF-8 "multi-byte" mode, change <code>c</code> o <code>m</code>, as in <code>-lwm</code>.</p>
<p dir="auto">The numbers are reported come from the Unix <code>time</code> command, the number of seconds for
<code>user</code> time. In other words, <code>elapsed</code> time or <code>system</code> time aren't reported.</p>
<p dir="auto">The following table shows benchmarking a 2019 x86 MacBook Air of the old
<code>wc</code> program. As you can see, it has a wide variety of speeds depending
on input.</p>
<p dir="auto">The <code>wc</code> program included with macOS and Linux are completely different.
Therefore, the following table shows them benchmarked against each other
on the same hardware.</p>
<table>
<thead>
<tr>
<th>Command</th>
<th>Input File</th>
<th>macOS</th>
<th>Linux</th>
</tr>
</thead>
<tbody>
<tr>
<td>wc -lwc</td>
<td>pocorgtfo18.pdf</td>
<td>0.709</td>
<td>5.591</td>
</tr>
<tr>
<td>wc -lwm</td>
<td>pocorgtfo18.pdf</td>
<td>0.693</td>
<td>5.419</td>
</tr>
<tr>
<td>wc -lwc</td>
<td>ascii.txt</td>
<td>0.296</td>
<td>2.509</td>
</tr>
<tr>
<td>wc -lwm</td>
<td>utf8.txt</td>
<td>0.532</td>
<td>1.840</td>
</tr>
<tr>
<td>wc -lwc</td>
<td>space.txt</td>
<td>0.296</td>
<td>0.284</td>
</tr>
<tr>
<td>wc -lwm</td>
<td>space.txt</td>
<td>0.295</td>
<td>0.298</td>
</tr>
<tr>
<td>wc -lwc</td>
<td>word.txt</td>
<td>0.302</td>
<td>1.268</td>
</tr>
<tr>
<td>wc -lwm</td>
<td>word.txt</td>
<td>0.294</td>
<td>1.337</td>
</tr>
</tbody>
</table>
<p dir="auto">These results tell us:</p>
<ul dir="auto">
<li>Illegal characters (in <code>pocorgtfo18.pdf</code>) slow things down a lot,
twice as slow on macOS, 10x slower on Linux.</li>
<li>Text that randomly switches between spaces and words is much slower
than text containing all the same character.</li>
<li>On Linux, the code path that reads all spaces is significantly faster.</li>
<li>The macOS program is in general much faster than the Linux version.</li>
<li>Processing Unicode (the file <code>utf8.txt</code> with the <code>-m</code> option) is slower
than processing ASCII (the file <code>ascii.txt</code> with the <code>-c</code> option).</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Our benchmarks</h2><a id="user-content-our-benchmarks" aria-label="Permalink: Our benchmarks" href="#our-benchmarks"></a></p>
<p dir="auto">The time for our algorithm, in C and JavaScript, are the following.
The state-machine parser is immune to input type, all the input files
show the same results.</p>
<table>
<thead>
<tr>
<th>Program</th>
<th>Input File</th>
<th>macOS</th>
<th>Linux</th>
</tr>
</thead>
<tbody>
<tr>
<td>wc2.c</td>
<td>(all)</td>
<td>0.206</td>
<td>0.278</td>
</tr>
<tr>
<td>wc2.js</td>
<td>(all)</td>
<td>0.281</td>
<td>0.488</td>
</tr>
</tbody>
</table>
<p dir="auto">These results tell us:</p>
<ul dir="auto">
<li>This state machine approach always results in the same speed, regardless
of input.</li>
<li>This state machine approach is faster than the built-in programs.</li>
<li>Even written in JavaScript, the state machine approach is competitive in speed.</li>
<li>The difference in macOS and Linux speed is actually the difference in <code>clang</code> and <code>gcc</code>
speed. The LLVM <code>clang</code> compiler is doing better optimizations for x86 processors here.</li>
<li>I don't know why Node.js behaves differently on macOS and Linux, it's probably just
due to different versions.</li>
<li>A JIT (like NodeJS) works well with simple compute algorithms. This tells
us little about it's relative performance in larger programs. All languages
that have a JIT should compile this sort of algorithm to roughly the same
speed.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Asynchronous scalability</h2><a id="user-content-asynchronous-scalability" aria-label="Permalink: Asynchronous scalability" href="#asynchronous-scalability"></a></p>
<p dir="auto">The algorithm is <em>faster</em>, but more importantly, it's more <em>scalable</em>.</p>
<p dir="auto">Such scalability isn't usefull for <code>wc</code>, but is incredibly important for network
programs. Consider an HTTP web-server. The traditional way that the Apache web-server
worked was by reading the entire header in and buffering it, before then parsing
the header. This need to buffer the entire header caused an enormous scalability
problem. In contrast, asynchronous web-servers like Nginx use a state-machine
parser. They parse the bytes as they arrive, and discard them.</p>
<p dir="auto">This is analogous to NFA and DFA regular-expressions. If you use the NFA
approach, you need to buffer the entire chunk of data, so that the regex
can backtrack. Using the DFA approach, input can be provided as a stream,
one byte at a time, without needing buffering. DFAs are more scalable than NFAs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">State machine parsers</h2><a id="user-content-state-machine-parsers" aria-label="Permalink: State machine parsers" href="#state-machine-parsers"></a></p>
<p dir="auto">This project contains a minimalistic <code>wc2o.c</code> program to highlight
the algorithm, without all the fuss of building UTF-8 tables, supporting
only ASCII.</p>
<div dir="auto" data-snippet-clipboard-copy-content="#include <stdio.h>
int main(void)
{
    static const unsigned char table[4][4] = {
        {2,0,1,0,}, {2,0,1,0,}, {3,0,1,0,},  {3,0,1,0,}
    };
    static const unsigned char column[256] = {
        0,0,0,0,0,0,0,0,0,1,2,1,1,1,0,0,0,
        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,
    };
    unsigned long counts[4] = {0,0,0,0};
    int state = 0;
    int c;

    while ((c = getchar()) != EOF) {
        state = table[state][column[c]];
        counts[state]++;
    }

    printf(&quot;%lu %lu %lu\n&quot;, counts[1], counts[2], 
                counts[0] + counts[1] + counts[2] + counts[3]);
    return 0;
}"><pre><span>#include</span> <span>&lt;stdio.h&gt;</span>
<span>int</span> <span>main</span>(<span>void</span>)
{
    <span>static</span> <span>const</span> <span>unsigned <span>char</span></span> <span>table</span>[<span>4</span>][<span>4</span>] <span>=</span> {
        {<span>2</span>,<span>0</span>,<span>1</span>,<span>0</span>,}, {<span>2</span>,<span>0</span>,<span>1</span>,<span>0</span>,}, {<span>3</span>,<span>0</span>,<span>1</span>,<span>0</span>,},  {<span>3</span>,<span>0</span>,<span>1</span>,<span>0</span>,}
    };
    <span>static</span> <span>const</span> <span>unsigned <span>char</span></span> <span>column</span>[<span>256</span>] <span>=</span> {
        <span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>1</span>,<span>2</span>,<span>1</span>,<span>1</span>,<span>1</span>,<span>0</span>,<span>0</span>,<span>0</span>,
        <span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>,<span>1</span>,<span>0</span>,
    };
    <span>unsigned long</span> <span>counts</span>[<span>4</span>] <span>=</span> {<span>0</span>,<span>0</span>,<span>0</span>,<span>0</span>};
    <span>int</span> <span>state</span> <span>=</span> <span>0</span>;
    <span>int</span> <span>c</span>;

    <span>while</span> ((<span>c</span> <span>=</span> <span>getchar</span>()) <span>!=</span> <span>EOF</span>) {
        <span>state</span> <span>=</span> <span>table</span>[<span>state</span>][<span>column</span>[<span>c</span>]];
        <span>counts</span>[<span>state</span>]<span>++</span>;
    }

    <span>printf</span>(<span>"%lu %lu %lu\n"</span>, <span>counts</span>[<span>1</span>], <span>counts</span>[<span>2</span>], 
                <span>counts</span>[<span>0</span>] <span>+</span> <span>counts</span>[<span>1</span>] <span>+</span> <span>counts</span>[<span>2</span>] <span>+</span> <span>counts</span>[<span>3</span>]);
    <span>return</span> <span>0</span>;
}</pre></div>
<p dir="auto">The key part that does all the word counting is in the two lines inside:</p>
<div dir="auto" data-snippet-clipboard-copy-content="    while ((c = getchar()) != EOF) {
        state = table[state][column[c]];
        counts[state]++;
    }"><pre>    <span>while</span> ((<span>c</span> <span>=</span> <span>getchar</span>()) <span>!=</span> <span>EOF</span>) {
        <span>state</span> <span>=</span> <span>table</span>[<span>state</span>][<span>column</span>[<span>c</span>]];
        <span>counts</span>[<span>state</span>]<span>++</span>;
    }</pre></div>
<p dir="auto">This is only defined for ASCII, so you can see the state-machine on a
single-line in the code (<code>table</code>).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Additional tools</h2><a id="user-content-additional-tools" aria-label="Permalink: Additional tools" href="#additional-tools"></a></p>
<p dir="auto">This project includes additional tools:</p>
<ul dir="auto">
<li><code>wctool</code> to generate large test files</li>
<li><code>wcdiff</code> to find difference between two implementatins of <code>wc</code></li>
<li><code>wcstream</code> to fragment input files (demonstrates a bug in macOS's <code>wc</code>)</li>
</ul>
<p dir="auto">The program <code>wc2.c</code> has the same logic, the difference being that it
generates a larger state-machine for parsing UTF-8.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Pointer arithmetic</h2><a id="user-content-pointer-arithmetic" aria-label="Permalink: Pointer arithmetic" href="#pointer-arithmetic"></a></p>
<p dir="auto">C has a peculiar idiom called "pointer arithmetic", where pointers can
be incremented. Looping through a buffer is done with an expression like
<code>*buf++</code> instead of <code>buf[i++]</code>. Many programmers think pointer-arithmetic
is faster.</p>
<p dir="auto">To test this, the <code>wc2.c</code> program has an option <code>-P</code> that makes this
small change, to test the difference in speed.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NPM and NodeJS should do more to make ES Modules easy to use (177 pts)]]></title>
            <link>https://borischerny.com/javascript,/typescript/2024/06/19/ES-Modules-Are-A-Mess.html</link>
            <guid>40737508</guid>
            <pubDate>Thu, 20 Jun 2024 11:40:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://borischerny.com/javascript,/typescript/2024/06/19/ES-Modules-Are-A-Mess.html">https://borischerny.com/javascript,/typescript/2024/06/19/ES-Modules-Are-A-Mess.html</a>, See on <a href="https://news.ycombinator.com/item?id=40737508">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <section role="heading">
      <header role="heading">
        <h2>
          <a href="https://borischerny.com/">Boris Cherny's Blog</a>
        </h2>
      </header>
      
    </section>
    <section role="article">
<h3>June 19, 2024</h3>

<p>Coming back to JavaScript and TypeScript after a few years neck deep in Python and Hack, I kept hitting a number of new, cryptic errors when running NodeJS code in my dev environment:</p>

<div><pre><code><span># when I ran ESM TypeScript code the wrong way:</span>
Error <span>[</span>ERR_REQUIRE_ESM]: Must use import to load ES Module

<span># when I imported an ESModule from a CommonJS .js file:</span>
Error <span>[</span>ERR_REQUIRE_ESM]: require<span>()</span> of ES Module .../lodash.js from .../index.cjs not supported

<span># when I imported an ESModule from a .ts file:</span>
error TS1479: The current file is a CommonJS module whose imports will produce <span>'require'</span> calls

<span># when I used ES6 import syntax in a .js file:</span>
SyntaxError: Cannot use import statement outside a module
</code></pre></div>

<p>These errors are all related to importing, typechecking, and loading modules. The JavaScript ecosystem moves fast, and things changing over the last few years was not a surprise. However, it was surprising to see so many errors related to such a core piece of the language!</p>

<h2 id="how-we-got-here">How we got here</h2>

<p>Modules in JavaScript and TypeScript have changed significantly over time:</p>

<ul>
  <li>Years ago, there was no module system for JavaScript and TypeScript. A number of solutions sprang up around ways to declare and load modules: IIFEs, <a href="https://github.com/getify/LABjs">LabJS</a>, <a href="https://github.com/amdjs/amdjs-api/blob/master/AMD.md">AMD</a>, <a href="https://requirejs.org/">require.js</a>, <a href="https://www.typescriptlang.org/docs/handbook/namespaces.html">TypeScript namespaces</a>, and more. Tooling support and interop were hit or miss.</li>
  <li>CommonJS emerged as a standard-by-convention for modules, across browser, server, JavaScript, and TypeScript.</li>
  <li>When ES6 came out, folks started switching over to <code>import</code> and <code>export</code> syntax (from CommonJS’s <code>require</code> and <code>module.exports</code>), using tools like Babel and TypeScript to compile code down to CommonJS.</li>
  <li>CommonJS can be challenging to statically analyze, and uses an <a href="https://www.youtube.com/watch?v=W5CXzo4TZVU">inefficient</a>, synchronous module loading algorithm at runtime. ES Modules were <a href="https://tc39.es/ecma262/#sec-modules">introduced</a> as the way to use <code>import</code> and <code>export</code>, while at the same time improving code load times at runtime.</li>
  <li>ES Modules introduced significant complexity for NodeJS in particular: instead of reusing the <em>.js</em> and <em>.ts</em> file extensions, ES Modules in NodeJS require either using <em>.mjs</em>, or setting <code>type=module</code> in your <em>package.json</em>. Interoperating these modules with an ecosystem-ful of CommonJS remains painful.</li>
</ul>

<h2 id="current-state-by-the-numbers">Current state, by the numbers</h2>

<p>I was curious – since ES Modules (<code>import</code>/<code>export</code>) were introduced in <a href="https://262.ecma-international.org/6.0/#sec-modules">2015</a>, and NodeJS has supported <code>type=module/commonjs</code>, <em>.mjs</em>, and <em>.cjs</em>, with the goal of replacing <em>.js</em>, since <a href="https://nodejs.org/api/packages.html#type">2019</a>, to what degree have these new conventions been adopted?</p>

<p>I answered this with data, using two approaches:</p>

<ol>
  <li>Looking at the most starred JavaScript and TypeScript repos on Github</li>
  <li>Looking at the most downloaded packages on NPM</li>
</ol>

<p>The <a href="https://github.com/bcherny/es-module-stats">results</a> are not rosy. After 5+ years, adoption of ES Modules remains weak:</p>

<ol>
  <li>Between 9-27% of JavaScript/TypeScript projects declare themselves to be ES Modules via the <code>type</code> (and lesser-used <code>exports</code>) fields in their <em>package.json</em>s.</li>
  <li>Less than 6% of JavaScript/TypeScript files declare that they are ES Modules via the <em>.mjs</em>, <em>.cjs</em>, <em>.mts</em>, etc. file extensions.</li>
</ol>

<p>Note that these ranges come from the two approaches I used to estimate the numbers. Head <a href="https://github.com/bcherny/es-module-stats">here</a> for more detailed data and code.</p>

<h2 id="how-do-we-fix-it">How do we fix it?</h2>

<p>This helps explain why it’s so painful to interoperate ES Modules and CommonJS across both NodeJS and TypeScript: enough libraries use ES Modules that for many projects you need to either use ES Modules, or figure out how to interoperate ES Modules with your CommonJS code. At the same time, enough code still uses CommonJS that you often need to figure out how to include that legacy code in your otherwise-ES Module project.</p>

<p>The benefits of ES Modules are significant. Rolling everything back to CommonJS is not the way forward. Is there more we can do to simplify the ecosystem, and push harder on adoption? Some ideas:</p>

<ol>
  <li>We should kill <em>.mjs</em>, <em>.cjs</em>, <em>.mts</em>, etc. The vast majority of projects use <code>type=module</code> in their <em>package.json</em>, rather than file extensions. It would simplify things considerably if we drop support for these new file extensions and stick to <em>.js</em>, <em>.jsx</em>, <em>.ts</em>, and <em>.tsx</em>.</li>
  <li>We should make <code>type=module</code> the <a href="https://github.com/npm/cli/issues/7594">default</a> for new <em>package.json</em> files for the <code>npm init</code>, <code>yarn init</code>, and <code>pnpm init</code> commands. Package managers’ <code>publish</code> commands should warn when <code>type</code> is not set to <code>module</code>.</li>
  <li>We should upgrade the most common libraries used by the community to ES Modules, either manually or through automated pull requests (this feels like something that can be semi-automated).</li>
  <li>The NPM registry can require an explicit <code>module</code> field on new packages, making it clear when a package intentionally uses CommonJS (eg. because it targets legacy NodeJS versions).</li>
  <li>NodeJS can officially drop support for <code>require</code> and <code>module.exports</code> in a future version, creating a bit more pressure to migrate.</li>
</ol>

<p>I’d love to hear others’ thoughts. Have you also felt the pain of interoperating ES Modules and CommonJS?</p>

<hr>

<p>Discuss this post on <a href="https://news.ycombinator.com/item?id=40737508">HackerNews</a> or on <a href="https://www.threads.net/@boris_cherny/post/C8aDJuGI5HM">Threads</a>.</p>

</section>
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Curl is inside 22,734 Steam games (134 pts)]]></title>
            <link>https://daniel.haxx.se/blog/2024/06/20/inside-22734-steam-games/</link>
            <guid>40737349</guid>
            <pubDate>Thu, 20 Jun 2024 11:18:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daniel.haxx.se/blog/2024/06/20/inside-22734-steam-games/">https://daniel.haxx.se/blog/2024/06/20/inside-22734-steam-games/</a>, See on <a href="https://news.ycombinator.com/item?id=40737349">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">

	<div id="primary" role="main">
			
<article id="post-25020">
	
		<p><img width="672" height="372" src="https://daniel.haxx.se/blog/wp-content/uploads/2016/09/GTA-end-credits-libcurl-672x372.jpg" alt="" decoding="async" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2016/09/GTA-end-credits-libcurl-672x372.jpg 672w, https://daniel.haxx.se/blog/wp-content/uploads/2016/09/GTA-end-credits-libcurl-200x110.jpg 200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/09/GTA-end-credits-libcurl-1038x576.jpg 1038w" sizes="(max-width: 672px) 100vw, 672px">		</p>

		
	<!-- .entry-header -->

		<div>
		
<p>About a year ago I blogged about <a href="https://daniel.haxx.se/blog/2023/06/09/games-curl-too/" data-type="post" data-id="22459">games that use curl</a>. In that post I listed a bunch of well-known titles I knew use curl and there was a list of 136 additional games giving credit to curl.</p>



<p>Kind of amazing that over <em>one hundred games</em> decided to use curl!</p>



<p>At the time, lots of people told me that number was probably way low and while I kind of had that feeling as well it was just a feeling and nothing else. We cannot be <em>absolutely certain</em> unless there is data or evidence to actually back it up.</p>



<p>The speculation could stop this week when someone provided me with a link to a database of Steam titles (<a href="https://en.wikipedia.org/wiki/Steam_(service)">Steam</a>, as in the video game service). <a href="https://steamdb.info/">SteamDB</a> is a third-party site that among other things extracts data and figures out which “SDKs” are used by Steam games: <a href="https://steamdb.info/tech/SDK/cURL/">Their list of game titles on Steam using curl</a>.</p>



<p>Since that list is capped at 10,000 titles, I had to filter it and add up the number of titles based on release year. Out of the 91,559 titles they currently list in their database, <strong>22,734</strong> are identified to be using curl: <strong>24.8%</strong>.</p>



<p>Not too shabby for a hobby.</p>


<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/daniel.haxx.se\/blog\/wp-content\/uploads\/2024\/04\/curl-is-just-2000.jpg&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-24622&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:2000,&quot;targetHeight&quot;:1500,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img decoding="async" width="2000" height="1500" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://daniel.haxx.se/blog/wp-content/uploads/2024/04/curl-is-just-2000.jpg" alt=""></figure></div>	</div><!-- .entry-content -->
	
	</article><!-- #post-25020 -->
		<nav>
		<h2>
			Post navigation		</h2>
		<!-- .nav-links -->
		</nav><!-- .navigation -->
		
<!-- #comments -->
		</div><!-- #primary -->

<!-- #content-sidebar -->
<div id="secondary">
		<h2>tech, open source and networking</h2>
	
	
		<!-- #primary-sidebar -->
	</div><!-- #secondary -->

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Delusion of Advanced Plastic Recycling (173 pts)]]></title>
            <link>https://www.propublica.org/article/delusion-advanced-chemical-plastic-recycling-pyrolysis</link>
            <guid>40737308</guid>
            <pubDate>Thu, 20 Jun 2024 11:12:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.propublica.org/article/delusion-advanced-chemical-plastic-recycling-pyrolysis">https://www.propublica.org/article/delusion-advanced-chemical-plastic-recycling-pyrolysis</a>, See on <a href="https://news.ycombinator.com/item?id=40737308">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pp-location="article body">

        
        
        




                    
<p data-pp-blocktype="copy" data-pp-id="2.0"><span>Last year,</span> I became obsessed with a plastic cup. </p>

<p data-pp-blocktype="copy" data-pp-id="2.1">It was a small container that held diced fruit, the type thrown into lunch boxes. And it was the first product I’d seen born of what’s being touted as a cure for a crisis.</p>
        
    
                        


   
            
            
            
            

   
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="4.0">Plastic doesn’t break down in nature. If you turned all of what’s been made into cling wrap, it would <a href="https://www.sciencedaily.com/releases/2016/01/160127083854.htm">cover every inch of the globe</a>. It’s piling up, <a href="https://www.epa.gov/plastics/impacts-plastic-pollution">leaching into our water</a> and <a href="https://www.sciencenews.org/article/microplastics-nanoplastics-heart-attacks-strokes-health">poisoning our bodies</a>.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="5.0">Scientists say the key to fixing this is to make less of it; the world churns out 430 million metric tons each year.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="6.0">But businesses that rely on plastic production, like fossil fuel and chemical companies, have worked since the <a href="https://grist.org/accountability/petrochemical-companies-have-known-for-40-years-that-plastics-recycling-wouldnt-work/">1980s to spin the pollution as a failure of waste management</a> — one that can be solved with recycling.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="7.0"><a href="https://www.npr.org/2020/03/31/822597631/plastic-wars-three-takeaways-from-the-fight-over-the-future-of-plastics">Industry leaders knew then</a> what we know now: Traditional recycling <a href="https://theintercept.com/2019/07/20/plastics-industry-plastic-recycling/">would </a><a href="https://theintercept.com/2019/07/20/plastics-industry-plastic-recycling/">barely put a dent in the trash heap</a>. It’s hard to transform flimsy candy wrappers into sandwich bags, or to make containers that once held motor oil clean enough for milk.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="8.0">Now, the industry is heralding nothing short of a miracle: an “advanced”type of recycling known as pyrolysis — “pyro” means fire and “lysis” means separation. It uses heat to break plastic all the way down to its molecular building blocks.</p>
        
    
                    
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="10.0">While old-school, “mechanical” recycling yields plastic that’s degraded or contaminated, this type of “chemical” recycling promises plastic that behaves like it’s new, and could usher in what the industry casts as a green revolution: Not only would it save hard-to-recycle plastics like frozen food wrappers from the dumpster, but it would turn them into new products that can replace the old ones and be chemically recycled again and again.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="11.0">So when three companies used ExxonMobil’s pyrolysis-based technology to successfully conjure up that fruit cup, <a href="https://www.packworld.com/supplier-news/news/22871469/printpack-printpack-exxonmobil-pacific-coast-producers-bring-circularity-to-fruit-cups">they announced it to the world</a>.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="12.0">“This is a significant milestone,” said Printpack, which turned the plastic into cups. The fruit supplier Pacific Coast Producers called it “the most important initiative a consumer-packaged goods company can pursue.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="13.0">“ExxonMobil is supporting the circularity of plastics,” the August 2023 news release said, citing <a href="https://grist.org/accountability/circular-economy-plastics-recycling-reuse-waste-conference-seattle/">a </a><a href="https://grist.org/accountability/circular-economy-plastics-recycling-reuse-waste-conference-seattle/">buzzword</a> that implies an infinite loop of using, recycling and reusing.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="14.0">They were so proud, I hoped they would tell me all about how they made the cup, how many of them existed and where I could buy one.</p>

<p data-pp-blocktype="copy" data-pp-id="14.1">So began my long — and, well, circular — pursuit of the truth at a time when it really matters.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="15.0">This year, nearly all of the world’s countries are hammering out a <a href="https://www.propublica.org/article/plastics-waste-united-nations-international-conference-treaty-ottawa">United Nations treaty to deal with the plastic crisis</a>. As they consider limiting production, <a href="https://www.ehn.org/chemical-recycling-of-plastics-2667297273.html">the industry is making a hard push to shift the conversation</a> to the wonders of chemical recycling. It’s also buying ads during cable news shows as U.S. states consider laws to limit plastic packaging and lobbying federal agencies to loosen the very definition of what it means to recycle.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="16.0">It’s been selling governments on chemical recycling, with quite a bit of success. American and <a href="https://www.euwid-recycling.com/news/business/lyondellbasell-to-receive-eur40m-in-eu-funding-for-chemical-recycling-plant-080124/">European regulators</a> <a href="https://theintercept.com/2023/10/31/plastics-pollution-advanced-recycling/">have spent tens of </a><a href="https://theintercept.com/2023/10/31/plastics-pollution-advanced-recycling/">millions</a><a href="https://theintercept.com/2023/10/31/plastics-pollution-advanced-recycling/"> subsidizing pyrolysis facilities</a>. <a href="https://www.americanchemistry.com/chemistry-in-america/news-trends/press-release/2024/with-wyoming-half-the-country-open-to-advanced-recycling">Half of all U.S. states</a> have <a href="https://e360.yale.edu/features/advanced-plastics-recycling-pyrolysis">eased air pollution rules</a> for the process, which has been found to <a href="https://www.nrdc.org/sites/default/files/chemical-recycling-greenwashing-incineration-ib.pdf">release carcinogens like benzene and dioxins</a> and <a href="https://pubs.acs.org/doi/10.1021/acssuschemeng.2c05497#">give off more greenhouse gases than making plastic from crude oil</a>.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="17.0">Given the high stakes of this moment, I set out to understand exactly what the world is getting out of this recycling technology. For months, I tracked press releases, interviewed experts, tried to buy plastic made via pyrolysis and learned more than I ever wanted to know about the science of recycled molecules.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="18.0">Under all the math and engineering, I found an inconvenient truth: Not much is being recycled at all, nor is pyrolysis capable of curbing the plastic crisis.  </p>

<p data-pp-blocktype="copy" data-pp-id="18.1">Not now. Maybe not ever.</p>
        
    
                    

<figure data-pp-id="20" data-pp-blocktype="image">

    


                    
    


    <img alt="" width="300" height="200" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/item-10.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=533&amp;q=80&amp;w=800&amp;s=7c0cf6520a1b45b5c6b466ab9f20c825" srcset="https://img.assets-d.propublica.org/v5/images/item-10.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=267&amp;q=80&amp;w=400&amp;s=c2a95b75734aaec3d82ebab09ca6e07a 400w, https://img.assets-d.propublica.org/v5/images/item-10.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=533&amp;q=80&amp;w=800&amp;s=7c0cf6520a1b45b5c6b466ab9f20c825 800w, https://img.assets-d.propublica.org/v5/images/item-10.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=80&amp;w=1200&amp;s=35a4dfd7efe9417e228127c272472461 1200w, https://img.assets-d.propublica.org/v5/images/item-10.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=867&amp;q=80&amp;w=1300&amp;s=292b2d8c2964a3aea440141efbaf99da 1300w, https://img.assets-d.propublica.org/v5/images/item-10.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=967&amp;q=80&amp;w=1450&amp;s=fbb209578b9489431171ea59aa2b5947 1450w, https://img.assets-d.propublica.org/v5/images/item-10.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1067&amp;q=80&amp;w=1600&amp;s=0651de84e0db97e13899d7e6ac61577d 1600w, https://img.assets-d.propublica.org/v5/images/item-10.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1333&amp;q=80&amp;w=2000&amp;s=4d3b38b00a27b9a622eeebf3dd17ed4e 2000w">

            
    
<figcaption>
    
    
    
    </figcaption>

</figure>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="21.0"><span>Let’s take</span> a closer look at that Printpack press release, which uses convoluted terms to describe the recycled plastic in that fruit cup: </p>

<p data-pp-blocktype="copy" data-pp-id="21.1">“30% ISCC PLUS certified-circular”</p>

<p data-pp-blocktype="copy" data-pp-id="21.2">“mass balance free attribution”</p>

<p data-pp-blocktype="copy" data-pp-id="21.3">It’s easy to conclude the cup was made with 30% recycled plastic — until you break down the numerical sleight of hand that props up that number. </p>

<p data-pp-blocktype="copy" data-pp-id="21.4">It took interviews with a dozen academics, consultants, environmentalists and engineers to help me do just that. </p>

<p data-pp-blocktype="copy" data-pp-id="21.5">Stick with me as I unravel it all.</p>
        
            
    
    
    
                            

<figure data-pp-id="1" data-pp-blocktype="embed">

    


                        <div id="lesson-one">
    <div>
         <p>
         <h3><span>Lesson 1</span></h3>
         </p>
          <h2>Most of the old plastic that goes <span>into</span> pyrolysis doesn’t actually become new&nbsp;plastic.
</h2>
      </div>
         <p><img src="https://static.propublica.org/projects/graphics/2024-plastics/images/item-1.png">
       <img src="https://static.propublica.org/projects/graphics/2024-plastics/images/item-2.png">
        <img src="https://static.propublica.org/projects/graphics/2024-plastics/images/item-3.png">
         <img src="https://static.propublica.org/projects/graphics/2024-plastics/images/item-5.png">
     
      
    </p>
</div>
            
    
<figcaption>
    
    
    
    </figcaption>


</figure>

            
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="24.0"><span>In traditional recycling,</span> plastic is turned into tiny pellets or flakes,  which you can melt again and mold back into recycled plastic products.</p>

<p data-pp-blocktype="copy" data-pp-id="24.1">Even in a real-life scenario, where bottles have labels and a little bit of juice left in them, most of the plastic products that go into the process find new life.</p>
        
            
    
    
    
                            

<figure data-pp-id="1" data-pp-blocktype="embed">

    


                        <!-- Generated by ai2html v0.115.1 - 2024-06-13 12:31 -->
<!-- ai file: plastic-recyclingrate-mechanical-ai2html.ai -->




<!-- End ai2html - 2024-06-13 12:31 -->
            
    
<figcaption>
    
    
    
    </figcaption>


</figure>

            
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="26.0">The numbers are much lower for pyrolysis.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="27.0">It’s “very, very, very, very difficult” to break down plastic that way, said Steve Jenkins, vice president of chemicals consulting at Wood Mackenzie, an energy and resources analytics firm. “The laws of nature and the laws of physics are trying to stop you.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="28.0">Waste is heated until it turns into oil. Part of that oil is composed of a liquid called naphtha, which is essential for making plastic. </p>

<p data-pp-blocktype="copy" data-pp-id="28.1">There are two ingredients in the naphtha that recyclers want to isolate: propylene and ethylene — gases that can be turned into solid plastics.</p>

<p data-pp-blocktype="copy" data-pp-id="28.2">To split the naphtha into different chemicals, it’s fed into a machine called a steam cracker. Less than half of what it spits out becomes propylene and ethylene.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="29.0">This means that if a pyrolysis operator started with 100 pounds of plastic waste, it can expect to end up with 15-20 pounds of reusable plastic. Experts told me the process can yield less if the plastic used is dirty or more if the technology is particularly advanced.</p>
        
            
    
    
    
                            

<figure data-pp-id="1" data-pp-blocktype="embed">

    


                        <!-- Generated by ai2html v0.115.1 - 2024-06-13 12:31 -->
<!-- ai file: plastic-recyclingrate-chemical-ai2html.ai -->




<!-- End ai2html - 2024-06-13 12:31 -->
            
    
<figcaption>
    
    
    
    </figcaption>


</figure>

            
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="31.0">I reached out to several companies to ask how much new plastic their processes actually yield, and none provided numbers. The American Chemistry Council, the nation’s largest plastic lobby, told me that because so many factors impact a company’s yield, it’s impossible to estimate that number for the entire industry.</p>
        
            
    
    
    
                            

<figure data-pp-id="1" data-pp-blocktype="embed">

    


                        <div id="lesson-two">

    <div>
         <p>
         <h3><span>Lesson 2</span></h3>
         </p>
          <h2> The plastic that comes <span>out of</span> pyrolysis contains very little recycled material. 

</h2>
      </div>
       <p><img src="https://static.propublica.org/projects/graphics/2024-plastics/images/item-7.png">

         <img src="https://static.propublica.org/projects/graphics/2024-plastics/images/item-5.png">
         <img src="https://static.propublica.org/projects/graphics/2024-plastics/images/item-2.png">
         <img src="https://static.propublica.org/projects/graphics/2024-plastics/images/item-6.png">




   </p>


</div>


            
    
<figcaption>
    
    
    
    </figcaption>


</figure>

            
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="34.0"><span>With mechanical recycling,</span> it’s hard to make plastic that’s 100% recycled; it’s expensive to do, and the process degrades plastic. Recycled pellets are often combined with new pellets to make stuff that’s 25% or 50% recycled, for example.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="35.0">But far less recycled plastic winds up in products made through pyrolysis. </p>

<p data-pp-blocktype="copy" data-pp-id="35.1">That’s because the naphtha created using recycled plastic is contaminated. Manufacturers add all kinds of chemicals to make products bend or keep them from degrading in the sun.</p>
        
            
    
    
    
                            

<figure data-pp-id="1" data-pp-blocktype="embed">

    


                        

    <img alt="" width="1460" height="2285" loading="lazy" js-autosizes="" src="https://static.propublica.org/projects/graphics/2024-plastics/graphics/plastic-steamcracker-mobile-FINAL.png">
            
    
<figcaption>
    
    
    
    </figcaption>


</figure>

            
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="37.0">Recyclers can overpower them by heavily diluting the recycled naphtha. With what, you ask? Nonrecycled naphtha made from ordinary crude oil!</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="38.0">This is the quiet — and convenient — part of the industry’s revolutionary pyrolysis method: It relies heavily on extracting fossil fuels. At least 90% of the naphtha used in pyrolysis is fossil fuel naphtha. Only then can it be poured into the steam cracker to separate the chemicals that make plastic.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="39.0">So at the end of the day, nothing that comes out of pyrolysis physically contains more than 10% recycled material (though experts and studies have shown that, in practice, it’s more like 5% or 2%).</p>
        
            
    
    
    
                            

<figure data-pp-id="1" data-pp-blocktype="embed">

    


                        

    <img alt="" width="1460" height="2285" loading="lazy" js-autosizes="" src="https://static.propublica.org/projects/graphics/2024-plastics/graphics/plastic-steamcracker-mobile-FINAL.png">
            
    
<figcaption>
    
    
    
    </figcaption>


</figure>

            
        
            
    
    
    
                            

<figure data-pp-id="1" data-pp-blocktype="embed">

    


                        <div id="lesson-three">

    <div>
         <p>
         <h3><span>Lesson 3</span></h3>
         </p>
          <h2>The industry uses mathematical acrobatics to make pyrolysis look like a&nbsp;success. 
</h2>
      </div>

        <p><img src="https://static.propublica.org/projects/graphics/2024-plastics/images/item-3.png">


              <img src="https://static.propublica.org/projects/graphics/2024-plastics/images/item-7.png">

     </p>


</div>


            
    
<figcaption>
    
    
    
    </figcaption>


</figure>

            
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="43.0"><span>Ten percent</span> doesn’t look very impressive. Some consumers are willing to pay <a href="https://theconversation.com/climate-explained-are-consumers-willing-to-pay-more-for-climate-friendly-products-146757">a premium for sustainability</a>, so companies use a form of accounting called mass balance to inflate the recycled-ness of their products. It’s not unlike offset schemes I’ve uncovered that <a href="https://features.propublica.org/brazil-carbon-offsets/inconvenient-truth-carbon-credits-dont-work-deforestation-redd-acre-cambodia/">absolve refineries of their carbon emissions</a> and <a href="https://www.propublica.org/article/biodiversity-offsets-guinea-world-bank-group-chimpanzees-outbreak">enable mining companies to kill chimpanzees</a>. Industry-affiliated groups like the International Sustainability and Carbon Certification write the rules. (ISCC didn’t respond to requests for comment.)</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="44.0">To see how this works, let’s take a look at what might happen to a batch of recycled naphtha. Let’s say the steam cracker splits the batch into 100 pounds of assorted ingredients.</p>
        
            
    
    
    
                            

<figure data-pp-id="1" data-pp-blocktype="embed">

    


                        

  

      <section id="scrolly-1">
        <div>

                <!-- persistent labels -->
                  <p>
                    = 1 pound
                  </p>
                  <p id="recycled-dot-label">
                    = 1 "recycled" pound
                  </p>
                  <p>
                    Propylene
                  </p>
                  <p>
                    Ethylene
                  </p>
                  <p>
                    Other chemicals, including fuel
                  </p>


                  
                  
                <!-- close all-content below -->
                </div>
          

        <div>
          <p>You'll get some colorless gasses that are used to make plastic: 13 pounds of propylene and 30 pounds of ethylene. You'll also wind up with 57 pounds of other chemicals.</p>
          <p>Propylene makes sturdy material such as butter tubs <img src="https://static.propublica.org/projects/graphics/2024-plastics/explainer/inline-butter.png">; ethylene makes flexible plastics like yogurt pouches <span><img src="https://static.propublica.org/projects/graphics/2024-plastics/explainer/inline-yogurt.png">.</span> Many of the other chemicals <img src="https://static.propublica.org/projects/graphics/2024-plastics/explainer/inline-chemicals.png"> aren't used to make plastic — some get used to make rubber and paint or are used as fuel. </p>
          <p>All of these outputs are technically 10% recycled, since they were made from 10% recycled naphtha. (I’m using this optimistic hypothetical to make the math easy.) </p>
          <p>But companies can do a number shuffle to assign all of the recycled value from the butter tubs <img src="https://static.propublica.org/projects/graphics/2024-plastics/explainer/inline-butter.png"> to the yogurt pouches <span><img src="https://static.propublica.org/projects/graphics/2024-plastics/explainer/inline-yogurt.png">.</span>  </p>
          <p>That way they can market the yogurt pouches <img src="https://static.propublica.org/projects/graphics/2024-plastics/explainer/inline-yogurt.png"> as 14% recycled (or “circular”), even though nothing has physically changed about the makeup of the pouches.  </p>
          <p>What's more, through a method called free attribution, companies can assign the recycled value from other chemicals <img src="https://static.propublica.org/projects/graphics/2024-plastics/explainer/inline-chemicals.png"> (even if they would never be turned into plastic) to the yogurt pouches <span><img src="https://static.propublica.org/projects/graphics/2024-plastics/explainer/inline-yogurt.png">.</span></p>
          <p>Now, the yogurt pouches <img src="https://static.propublica.org/projects/graphics/2024-plastics/explainer/inline-yogurt.png"> can be sold as 33% recycled. </p>
 
        </div>
      </section>

  
    
            
    
<figcaption>
    
    
    
    </figcaption>


</figure>

            
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="46.0">There are many flavors of this kind of accounting. Another version of free attribution would allow the company to take that entire 30-pound batch of “33% recycled” pouches and split them even further:</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="47.0">A third of them, 10 pounds, could be labeled 100% recycled — shifting the value of the full batch onto them — so long as the remaining 20 pounds aren’t labeled as recycled at all.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="48.0">As long as you avoid double counting, Jenkins told me, you can attribute the full value of recycled naphtha to the products that will make the most money. Companies need that financial incentive to recoup the costs of pyrolysis, he said.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="49.0">But it’s hard to argue that this type of marketing is transparent. Consumers aren’t going to parse through the caveats of a 33% recycled claim or understand how the green technology they’re being sold perpetuates the fossil fuel industry. I posed the critiques to the industry, including environmentalists’ accusations that mass balance is just a fancy way of greenwashing.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="50.0">The American Chemistry Council told me it’s impossible to know whether a particular ethylene molecule comes from pyrolysis naphtha or fossil fuel naphtha; the compounds produced are “fungible” and can be used for multiple products, like making rubber, solvents and paints that would reduce the amount of new fossil fuels needed. Its statement called mass balance a “well-known methodology” that’s been used by other industries including fair trade coffee, chocolate and renewable energy.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="51.0">Legislation in the European Union already forbids free attribution, and leaders are debating whether to allow other forms of mass balance. U.S. regulation is far behind that, but as the Federal Trade Commission revises its general guidelines for green marketing, the industry is arguing that mass balance is crucial to the future of advanced recycling. “The science of advanced recycling simply does not support any other approach because the ability to track individual molecules does not readily exist,” said a <a href="https://www.documentcloud.org/documents/24688789-2023-04-24-exxonmobil-ftc-comments#document/p5/a2562175">comment from ExxonMobil</a>.</p>
        
    
                    

<figure data-pp-id="53" data-pp-blocktype="image">

    


                    
    


    <img alt="" width="300" height="200" loading="lazy" js-autosizes="" src="https://img.assets-d.propublica.org/v5/images/item-4.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=533&amp;q=80&amp;w=800&amp;s=4295b6950dd8b4d6cbca0138e6620862" srcset="https://img.assets-d.propublica.org/v5/images/item-4.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=267&amp;q=80&amp;w=400&amp;s=0967e518b1a2cf3cc2f1ad07c56bf7ff 400w, https://img.assets-d.propublica.org/v5/images/item-4.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=533&amp;q=80&amp;w=800&amp;s=4295b6950dd8b4d6cbca0138e6620862 800w, https://img.assets-d.propublica.org/v5/images/item-4.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=800&amp;q=80&amp;w=1200&amp;s=d06685d5ac9a42c7b8f8e122aaf2dc61 1200w, https://img.assets-d.propublica.org/v5/images/item-4.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=867&amp;q=80&amp;w=1300&amp;s=d6a7708b4b0eabe988f74f0041f3f0f2 1300w, https://img.assets-d.propublica.org/v5/images/item-4.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=967&amp;q=80&amp;w=1450&amp;s=40944522eff6cdd5c523b4d3ccb5d794 1450w, https://img.assets-d.propublica.org/v5/images/item-4.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1067&amp;q=80&amp;w=1600&amp;s=ca693587302aff1f58ee145d106798c1 1600w, https://img.assets-d.propublica.org/v5/images/item-4.png?crop=focalpoint&amp;fit=crop&amp;fm=webp&amp;fp-x=0.5&amp;fp-y=0.5&amp;h=1333&amp;q=80&amp;w=2000&amp;s=f381d567cd668920d90865bf81773611 2000w">

            
    
<figcaption>
    
    
    
    </figcaption>

</figure>

        
    
                    
<p data-pp-blocktype="copy" data-pp-id="54.0"><span>If you think</span> navigating the ins and outs of pyrolysis is hard, try getting your hands on actual plastic made through it.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="55.0">It’s not as easy as going to the grocery store. Those water bottles you might see with 100% recycled claims are almost certainly made through traditional recycling. The biggest giveaway is that the labels don’t contain the asterisks or fine print typical of products made through pyrolysis, like “mass balance,” “circular” or “certified.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="56.0">When I asked about the fruit cup, ExxonMobil directed me to its partners. Printpack didn’t respond to my inquiries. Pacific Coast Producers told me it was “engaged in a small pilot pack of plastic bowls that contain post-consumer content with materials certified” by third parties, and that it “has made no label claims regarding these cups and is evaluating their use.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="57.0">I pressed the American Chemistry Council for other examples.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="58.0">“Chemical recycling is a proven technology that is already manufacturing products, conserving natural resources, and offering the potential to dramatically improve recycling rates,” said Matthew Kastner, a media relations director. His colleague added that much of the plastic made via pyrolysis is “being used for food- and medical-grade packaging, oftentimes not branded.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="59.0">They provided links to products including a Chevron Phillips Chemical announcement about bringing recycled plastic food wrapping <a href="https://www.waste360.com/waste-producers/chevron-phillips-chemical-and-charter-next-generation-to-bring-circular-polyethylene-to-retail-stores">to retail stores</a>.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="60.0">“For competitive reasons,” a Chevron spokesperson declined to discuss brand names, the product’s availability or the amount produced.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="61.0">In another case, a grocery store chain sold <a href="https://www.exxonmobilchemical.com/en/resources/library/library-detail/107131/circularity_demo_press_release_en">chicken wrapped in plastic</a> made by ExxonMobil’s pyrolysis process. The producers told me they were part of a small project that’s now discontinued.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="62.0">In the end, I ran down half a dozen claims about products that came out of pyrolysis; each either existed in limited quantities or had its recycled-ness obscured with mass balance caveats. </p>

<p data-pp-blocktype="copy" data-pp-id="62.1">Then this April, nearly eight months after I’d begun my pursuit, I could barely contain myself when I got my hands on an actual product.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="63.0">I was at a United Nations treaty negotiation in Ottawa, Ontario, and an industry group had set up a nearby showcase. On display was a case of Heinz baked beans, packaged in “39% recycled plastic*.” (The asterisk took me down an online rabbit hole about certification and circularity. Heinz didn’t respond to my questions.)</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="64.0">This, too, was part of an old trial. The beans were expired.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="65.0">Pyrolysis is a “fairy tale,” I heard from Neil Tangri, the science and policy director at the environmental justice network Global Alliance for Incinerator Alternatives. He said he’s been hearing pyrolysis claims since the ’90s but has yet to see proof it works as promised.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="66.0">“If anyone has cracked the code for a large-scale, efficient and profitable way to turn plastic into plastic,” he said, “every reporter in the world” would get a tour.</p>

<p data-pp-blocktype="copy" data-pp-id="66.1">If I did get a tour, I wondered, would I even see all of that stubborn, dirty plastic they were supposedly recycling?</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="67.0">The industry’s marketing implied we could soon toss sandwich bags and string cheese wrappers into curbside recycling bins, where they would be diverted to pyrolysis plants. But I grew skeptical as I watched a webinar for ExxonMobil’s pyrolysis-based technology, the kind used to make the fruit cup. The company showed photos of plastic packaging and oil field equipment as examples of its starting material but then mentioned something that made me sit up straight: It was using pre-consumer plastic to “give consistency” to the waste stream.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="68.0">Chemical plants need consistency, so it’s easier to use plastic that hasn’t been gunked up by consumer use, Jenkins explained.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="69.0">But plastic waste that had never been touched by consumers, such as industrial scrap found at the edges of factory molds, could easily be recycled the old-fashioned way. Didn’t that negate the need for this more polluting, less efficient process?</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="70.0">I asked ExxonMobil how much post-consumer plastic it was actually using. Catie Tuley, a media relations adviser, said it depends on what’s available. “At the end of the day, advanced recycling allows us to divert plastic waste from landfills and give new life to plastic waste.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="71.0">I posed the same question to several other operators. A company in Europe told me it uses “mixed post-consumer, flexible plastic waste” and does not recycle pre-consumer waste.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="72.0">But this spring at an environmental journalism conference, an American Chemistry Council executive confirmed the industry’s preference for clean plastic as he talked about an Atlanta-based company and its pyrolysis process. My colleague Sharon Lerner asked whether it was sourcing curbside-recycled plastic for pyrolysis.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="73.0">If Nexus Circular had a “magic wand,” it would, he acknowledged, but right now that kind of waste “isn’t good enough.” He added, “It’s got tomatoes in it.”</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="74.0">(Nexus later confirmed that most of the plastic it used was pre-consumer and about a third was post-consumer, including motor oil containers sourced from car repair shops and bags dropped off at special recycling centers.)</p>
        
    
                                  
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="76.0">Clean, well-sorted plastic is a valuable commodity. If the chemical recycling industry grows, experts told me, those companies could end up competing with the far more efficient traditional recycling.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="77.0">To spur that growth, the American Chemistry Council is lobbying for mandates that would require more recycled plastic in packaging; it wants to make sure that chemically recycled plastic counts. “This would create market-driven demand signals,” Kastner told me, and ease the way for large-scale investment in new chemical recycling plants.</p>
        
    
                    
<p data-pp-blocktype="copy" data-pp-id="78.0">I asked Jenkins, the energy industry analyst, to play out this scenario on a larger scale. </p>

<p data-pp-blocktype="copy" data-pp-id="78.1">Were all of these projects adding up? Could the industry conceivably make enough propylene and ethylene through pyrolysis to replace much of our demand for new plastic? </p>

<p data-pp-blocktype="copy" data-pp-id="78.2">He looked three years into the future, using his company’s latest figures on global pyrolysis investment, and gave an optimistic assessment. </p>

<p data-pp-blocktype="copy" data-pp-id="78.3">At best, the world could replace 0.2% of new plastic churned out in a year with products made through pyrolysis.</p>
        
    
                    <div data-pp-location="bottom-note">
                                    

                                    
        <div data-pp-location="bottom-note">
                        <h2><strong>About the Math</strong></h2>
<p>Our article is focused on pyrolysis because it’s the most popular form of chemical recycling. Other types of chemical recycling technologies have their own strengths and weaknesses.</p>
<p>There are different variations of pyrolysis, and steam crackers produce a range of ethylene and propylene yields. Companies are secretive about their operations. To estimate the efficiencies of pyrolysis and mass balance, I read dozens of peer-reviewed studies, reports, industry presentations, advertisements and news stories. I also fact checked with a dozen experts who have different opinions on pyrolysis, mass balance and recycling. Some of them, including Jenkins and Anthony Schiavo, senior director at Lux Research, provided estimates of overall yields for companies trying to make plastic. All of that information coalesced around a 15% to 20% yield for conventional pyrolysis processes and 25% to 30% for more advanced technologies. We are showcasing the conventional process because it’s the most common scenario.</p>
<p>We took steps to simplify the math and jargon. For instance, we skipped over the fact that a small amount of the naphtha fed into the steam cracker is consumed as fuel. And we called the fraction of pyrolysis oil that’s suitable for a steam cracker “pyrolysis naphtha”; it is technically a naphtha-like product.</p>
<p>These processes may improve over time as new technologies are developed. But there are hard limits and tradeoffs associated with the nature of steam cracking, the contamination in the feedstock, the type of feedstock used and financial and energy costs.</p>

        </div>

    


                                    
        <div data-pp-location="bottom-note">
                        <p>Graphics and development by <a href="https://www.propublica.org/people/lucas-waldron">Lucas Waldron</a>. Design and development by <a href="https://www.propublica.org/people/Anna-Donlan">Anna Donlan</a>. <a href="https://www.propublica.org/people/Mollie-Simon">Mollie Simon</a> and <a href="https://www.propublica.org/people/Gabriel-Sandoval">Gabriel Sandoval</a> contributed research.</p>

        </div>

    
            </div><!-- end .article-body__bottom-notes -->
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tetris as Font (470 pts)]]></title>
            <link>https://erikdemaine.org/fonts/tetris/</link>
            <guid>40737294</guid>
            <pubDate>Thu, 20 Jun 2024 11:11:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://erikdemaine.org/fonts/tetris/">https://erikdemaine.org/fonts/tetris/</a>, See on <a href="https://news.ycombinator.com/item?id=40737294">Hacker News</a></p>
<div id="readability-page-1" class="page"><table id="data"><tbody><tr><td><label for="text">Enter text to render: &nbsp;</label><p><label for="rot">Obscure in URL</label></p></td><td><label for="anim">Animate</label><p><label for="rotate">Include rotations</label><br><label for="speed">Speed:</label>&nbsp;</p><label for="puzzle">Puzzle font</label><br><label for="black">Black pieces (dissection puzzle)</label></td><td><label for="grid">Grid</label><br><label for="center">Rotation center</label><br><label for="floor">Bottom floor</label><br></td></tr></tbody></table><p>GIF width:<a id="download"></a></p><hr><p><b><a href="https://en.wikipedia.org/wiki/Tetris">Tetris</a></b> is
<a href="https://en.wikipedia.org/wiki/List_of_best-selling_video_games">among the best-selling</a> (and perhaps best-known) video games ever.
We grew up playing the
<a href="https://en.wikipedia.org/wiki/Game_Boy">Game Boy</a> and
<a href="https://en.wikipedia.org/wiki/Spectrum_HoloByte">Spectrum HoloByte</a> PC editions.
Erik is even a <a href="http://erikdemaine.org/images/tetris_award_large.jpg">Tetris Master</a>.
Nowadays you can play
<a href="https://tetris.com/play-tetris/">in your browser</a>
or <a href="https://en.wikipedia.org/wiki/Tetris_99">on a Switch</a>
or <a href="https://en.wikipedia.org/wiki/Tetris_Effect">on PS4/PC/VR</a>.
</p><p><b>Font design.</b>  Each letter and digit in this typeface is made up of
exactly one of each of the Tetris pieces:
<span id="pieceI"></span> (I),
<span id="pieceJ"></span> (J),
<span id="pieceL"></span> (L),
<span id="pieceO"></span> (O),
<span id="pieceS"></span> (S),
<span id="pieceT"></span> (T), and
<span id="pieceZ"></span> (Z).
Furthermore, the letter is designed so that it can actually be constructed
by stacking these pieces one at a time and be supported by previous pieces,
as in Tetris.
These designs were found by hand, aided by the
<a href="http://burrtools.sourceforge.net/">BurrTools</a> software
which enabled searching for whether the Tetris pieces could fit inside
a candidate outline for a letter.
The piece colors roughly follow
<a href="https://en.wikipedia.org/wiki/Tetris#Game_pieces">The Tetris Company's standard colors</a>,
or you can switch to black pieces.
The initial rotations follow the standard
<a href="https://tetris.fandom.com/wiki/SRS">Super Rotation System</a>.
</p><p><b>Puzzles.</b>
In the <b>puzzle font</b>, the letters are at the correct rotations and
horizontal positions, and their vertical position represents their drop
sequence.  Drop the pieces in your head (or via <b>animate</b>) to figure
out what letter is encoded.
•
Even without puzzle font turned on, in the <b>animated</b> font, you can
try to guess what the letter is before all the pieces have arrived.
•
One final set of puzzles: In the unanimated unpuzzle <b>black-pieces</b> font,
try to figure out how one of each Tetris piece perfectly packs that shape.
(This is the task that BurrTools is very good at.)
</p><p><b>Related mathematics.</b>
(Perfect-information)
<a href="http://erikdemaine.org/papers/Tetris_IJCGA/">Tetris is NP-complete</a>,
meaning that it's computationally intractable to figure out whether you can
survive, or clear the board, given an initial board configuration and a
sequence of <i>n</i> pieces to come.
<a href="http://erikdemaine.org/papers/TotalTetris_JIP/">Similar results
hold</a> for <i>k</i>-tris played with
<a href="https://en.wikipedia.org/wiki/Polyomino"><i>k</i>-ominoes</a>
instead of tetrominoes.  Most recently, we
<a href="http://erikdemaine.org/papers/ThinTetris_JIP/">analyzed the
complexity of Tetris with few rows or columns</a>; this font appears
in that paper.
</p><p><b>Acknowledgments.</b>  This font was inspired by a collaboration with
Alex Streif and Kate Jones of
<a href="http://www.gamepuzzles.com/">Kadon Enterprises</a>
during <a href="https://bridgesmathart.org/bridges-2017/">BRIDGES 2017</a>,
where we started designing a font using just 5 pieces:
the “<a href="https://en.wikipedia.org/wiki/Tetromino">free
tetrominoes</a>” where S is the same piece as Z and J is the same
piece as L.
Relatedly, Kate Jones designed <a href="https://erikdemaine.org/fonts/tetris/kadon_fonts.jpg">other polyomino
fonts included in some Kadon manuals</a>.
By contrast, this typeface aims closer to the rules of Tetris,
where reflection matters and the pieces must stack and be supported.
</p><p>Check out <a href="http://erikdemaine.org/fonts/">other mathematical and
puzzle fonts</a>. • Feedback or not working?
<a href="mailto:edemaine+fonts@mit.edu">Email Erik</a>. •
<a href="https://github.com/edemaine/font-tetris">Source code on GitHub</a>.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU Council has withdrawn the vote on Chat Control (822 pts)]]></title>
            <link>https://stackdiary.com/eu-council-has-withdrawn-the-vote-on-chat-control/</link>
            <guid>40736771</guid>
            <pubDate>Thu, 20 Jun 2024 09:45:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stackdiary.com/eu-council-has-withdrawn-the-vote-on-chat-control/">https://stackdiary.com/eu-council-has-withdrawn-the-vote-on-chat-control/</a>, See on <a href="https://news.ycombinator.com/item?id=40736771">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
<p>The EU Council and its participants have decided to withdraw the vote on the contentious Chat Control plan proposed by Belgium, the current EU President.</p>



<p>According to <a href="https://netzpolitik.org/2024/etappensieg-belgien-scheitert-mit-abstimmung-zur-chatkontrolle/" target="_blank" rel="noreferrer noopener">Netzpolitik</a> (<em>German</em>), “The EU Council did not make a decision on chat control today, as the agenda item was removed due to the lack of a majority, confirmed by Council and member state spokespersons”.</p>



<p>Belgium’s draft law, which was supposed to be adopted as the Council’s negotiating position, was instead postponed indefinitely. Although the Committee of Permanent Representatives meets weekly, Belgium cannot currently present a proposal that would gain a majority. In July, the Council Presidency will transfer from Belgium to Hungary, which has stated its intention to advance negotiations on chat control as part of its work program.</p>



<p>At the start of 2022, the European Commission proposed <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=COM%3A2022%3A209%3AFIN&amp;qid=1652451192472" target="_blank" rel="noreferrer noopener">monitoring all chat messages</a> and other forms of digital communication among citizens. This initiative includes client-side scanning for end-to-end encrypted services, meaning all messages would be checked irrespective of suspicion.</p>



<p>The plan targets the detection of both known and unknown abusive material and grooming activities. Experts have cautioned that such measures are prone to generating numerous false positives, particularly when identifying unknown content, leading to innocent citizens being misidentified as senders of abusive material.</p>



<p>European legislation is formed through a trialogue process involving negotiations between the European Commission, the European Parliament, and the Council of Ministers. Initially, the European Parliament rejected the European Commission’s proposal and <a href="https://oeil.secure.europarl.europa.eu/oeil/popups/ficheprocedure.do?reference=2022/0155(COD)&amp;l=en" target="_blank" rel="noreferrer noopener">introduced its own</a>, which, while still critical, excluded end-to-end encrypted services. However, Belgium’s new proposal <a href="https://www.euronews.com/next/2024/05/21/diplomats-mull-online-child-abuse-with-no-deal-in-sight" target="_blank" rel="noreferrer noopener">reintroduced client-side scanning</a> for these services, stipulating that users must consent to chat controls; otherwise, they would lose the ability to send photos, videos, and URLs. </p>



<p>This method, termed “upload moderation” by Belgium, has been criticized by opponents as merely a rebranding of the original concept.</p>



<h2>Signal and other apps threaten to leave the EU if the proposal is enacted as law</h2>



<p>Meredith Whittaker, president of the chat app Signal, <a href="https://x.com/mer__edith/status/1796508893822238881" target="_blank" rel="noreferrer noopener">has been vocal</a> against these plans. She argues that implementing such measures within end-to-end encrypted communications fundamentally undermines encryption and introduces significant vulnerabilities in the digital infrastructure. </p>



<p>Whittaker emphasizes that these vulnerabilities have far-reaching global implications, not just within Europe. She has repeatedly highlighted the issue, stating, “There is no way to implement such proposals without fundamentally undermining encryption and introducing dangerous vulnerabilities.”</p>



<p>On June 17, Whittaker published <a href="https://signal.org/blog/pdfs/upload-moderation.pdf" target="_blank" rel="noreferrer noopener">an official position</a> condemning the EU’s proposed “upload moderation” as a rebranding of client-side scanning that fundamentally undermines end-to-end encryption. </p>



<p>She emphasized that despite attempts to mask the dangers through marketing, these measures expose encrypted communications to mass surveillance, creating vulnerabilities exploitable by hackers and hostile nations. Whittaker urged a cessation of such rhetorical games, reiterating that any form of mandated mass scanning compromises encryption, thereby threatening global security and privacy at a critically unstable geopolitical moment.</p>



<p>The privacy messenger Threema published <a href="https://threema.ch/en/blog/posts/stop-chat-control" target="_blank" rel="noreferrer noopener">a blog post</a> saying the EU’s proposed Chat Control bill represents a dangerous mass surveillance initiative that would undermine data security, violate privacy rights, and negatively impact professionals and minors.</p>



<p>Patrick Breyer, <a href="https://stackdiary.com/patrick-breyer-and-pirate-party-lose-eu-parliament-seats/">the outgoing MEP</a> from the Pirate Party, raised concerns, noting that proponents of chat control have leveraged the period following the European elections, when attention is lower and the European Parliament is in transition, to advance their agenda. Breyer has called on European citizens <a href="https://www.patrick-breyer.de/en/council-to-greenlight-chat-control-take-action-now/" target="_blank" rel="noreferrer noopener">to take action</a> and urge their politicians to oppose the measures.</p>



<p>Edward Snowden, the NSA whistleblower, <a href="https://x.com/Snowden/status/1803127597158760735" target="_blank" rel="noreferrer noopener">criticized the proposal</a>, stating, “EU apparatchiks are trying to legislate a terrible mass surveillance measure, despite universal public opposition (no sane person wants this), by inventing a new word for it – upload moderation – and hoping no one finds out what it is until it’s too late.”</p>



<h2>What happens next?</h2>



<p>With the EU Council withdrawing the vote on the Chat Control proposal today, the legislative process faces new uncertainty. The proposal will return to the drawing board, as the European Commission[<a href="#footnote">1</a>] and the European Parliament continue to deliberate on the best way forward.</p>



<p>The discussions will resume after the summer, once the new Parliament is seated and Hungary assumes the Council presidency from Belgium in July. Hungary has already committed to developing a comprehensive legislative framework to prevent and combat online child sexual abuse and revising the directive against the sexual exploitation of children.</p>



<p>The forthcoming negotiations are anticipated to be highly contentious, especially since the European Parliament has firmly opposed any measures that would circumvent end-to-end encryption. The Member States and the Parliament have until April 2026 to agree. This deadline is crucial, as <a href="https://www.europarl.europa.eu/news/en/press-room/20240408IPR20311/child-sexual-abuse-online-current-rules-extended-until-april-2026" target="_blank" rel="noreferrer noopener">an existing exemption</a> allowing social networks to self-moderate content will expire, potentially eliminating current safeguards against sharing sensitive images.</p>



<p>In the meantime, privacy advocates and digital rights organizations will likely continue to voice their concerns, urging EU citizens to remain vigilant and engaged in the debate over digital privacy and surveillance. The next steps will involve intense negotiations and potential revisions to address the complex issues at stake.</p>



<p id="footnote"><em>[footnote #1]: On June 20, at the European Data Protection Supervisor (EDPS) 20th anniversary summit, EU Commissioner for Justice Vera Jourová&nbsp;<a href="https://x.com/ellajakubowska1/status/1803709746429538685" target="_blank" rel="noreferrer noopener">stated</a>&nbsp;that the European Commission’s proposal for the Child Sexual Abuse Regulation (CSAR) would break encryption. This marks the first time the European Commission has publicly acknowledged that the CSAR proposal would compromise encryption, a significant departure from the stance maintained over the past three years by Home Affairs Commissioner Ylva Johansson, who consistently claimed that the proposal would not affect encryption.</em></p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bun is much faster than Node.js 22 at decoding Base64 but both rely on same lib (111 pts)]]></title>
            <link>https://twitter.com/lemire/status/1803598132334436415</link>
            <guid>40736685</guid>
            <pubDate>Thu, 20 Jun 2024 09:31:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/lemire/status/1803598132334436415">https://twitter.com/lemire/status/1803598132334436415</a>, See on <a href="https://news.ycombinator.com/item?id=40736685">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Free software hijacked Philip Hazel's life (237 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/978463/608c876c1153fd31/</link>
            <guid>40736577</guid>
            <pubDate>Thu, 20 Jun 2024 09:14:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/978463/608c876c1153fd31/">https://lwn.net/SubscriberLink/978463/608c876c1153fd31/</a>, See on <a href="https://news.ycombinator.com/item?id=40736577">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>Philip Hazel was 51 when he began the <a href="https://www.exim.org/">Exim</a> message transfer agent (MTA)
project in 1995, which
led to the <a href="https://github.com/PCRE2Project/pcre2">Perl-Compatible Regular
Expressions</a> (PCRE) project in 1998. At 80,
he's maintained PCRE, and its successor PCRE2, for more than 27
years. For those doing the math, that's a year longer than LWN has
been in publication. Exim maintenance was handed off around the time
of his retirement in 2007. Now, he is ready to hand off PCRE2 as well,
if a successor can be found.</p>

<h4>Punch cards to flat screens</h4>

<p>Hazel's tenure as a free-software developer is exceptional, if not
record-breaking in its length. Linus Torvalds began
working on Linux in 1991 as a college student and is still leading its development 33 years
later with no signs of slowing. However, as Hazel <a href="https://drive.google.com/file/d/10TAOEgIL--CmzqOl0fkdP-cagjSLBM4J/view?usp=sharing">wrote</a>
in his technical memoir <em>From Punched Cards To Flat Screens</em>,
he began contributing to free software "<q>nearer the end than the
start</q>" of his career.</p>

<blockquote>
	<b>Like what you are reading?</b>
    		<a href="https://lwn.net/Promo/slink-trial-terse/claim">Try LWN for free</a> for 1 month,
    		no credit card required.
</blockquote>


<p>At the start of his career, Hazel was introduced to computers as an
undergraduate when the University of Cape Town (UCT) received its
first computer: an <a href="https://en.wikipedia.org/wiki/ICT_1301">International Computers
and Tabulators (ICT) 1301</a>, with a dazzling capacity to read as
many as 600 punched cards per minute. He attended introductory
programming lectures, read the Manchester <a href="https://en.wikipedia.org/wiki/Autocode">Autocode</a> programming
manual from cover to cover, and began writing test programs encoded onto paper punch cards:</p>

<blockquote>
If you were lucky and your program worked, the output appeared on the
printer; more often that not (at least at the start) all you got was
an error message, which meant that you had to fix your program, return
to the back of the queue, and hope to get another run before the end
of the session. The more attempts it took to get a program to work,
the more useful scrap paper one accumulated.
</blockquote>

<p>He later moved on to the University of Cambridge as a PhD
student. Cambridge was blessed with four computers when Hazel arrived
in 1967: a <a href="https://en.wikipedia.org/wiki/Titan_(1963_computer)">Titan</a>,
<a href="https://en.wikipedia.org/wiki/IBM_1130">IBM 1130</a>, <a href="https://en.wikipedia.org/wiki/IBM_System/360">IBM 360</a>, and
<a href="https://en.wikipedia.org/wiki/PDP-7">PDP-7</a>. Because Hazel
knew the Manchester Autocode language, which is similar to Titan Autocode, he
was given an account on the Titan "<q>and that was the start of the
slippery slope down which I have been sliding ever since</q>".</p>

<p>That slope, as well-detailed in Hazel's memoir (and mercilessly
abbreviated here), ultimately led to his joining the Cambridge
Computing Service as a software developer in 1971. During his tenure
at Cambridge, and at home, Hazel had the opportunity to work with a
number of interesting systems including the PDP-11, Ultrix,
Sinclair&nbsp;ZX-81, and BBC&nbsp;Micro. In 1990 the Computing Service
decided to set up a cluster of Unix systems for the use of staff and
graduate students, and he began working with Sun boxes
running SunOS. This coincided with the transition from the <a href="https://en.wikipedia.org/wiki/X.25">X.25</a> wide-area network
standard to the Internet Protocol (IP).</p>

<p>Hazel was responsible for the email service, and found it difficult
to configure <a href="https://www.proofpoint.com/us/products/email-protection/open-source-email-solution">Sendmail</a>
to choose between IP and X.25 to
deliver email. A colleague suggested that he try the free-software <a href="https://en.wikipedia.org/wiki/Smail">Smail</a> MTA instead. Hazel
took him up on the suggestion and added two features to Smail to
manage the DNS lookups and decide whether to send mail via SMTP or
X.25. While managing Smail for Cambridge, he submitted additional
features to cope with messages that had bad senders:</p>

<blockquote>
If such a message could not be delivered, the bad sender meant that an error report could
also not be delivered, and the postmaster (me) had to intervene to sort things
out. By rejecting messages whose sender address could not be verified, I pushed
the onus of dealing with this problem out to the sending MTA. This kind of
checking is now standard MTA practice (along with many other checks for
spam and viruses).
</blockquote>

<p>This was a small start that led Hazel to thinking about more
checking and verification that would be needed for MTAs. He
considered, but decided against, trying to modify Smail. It was
written in pre-standard C and carried "<q>a lot of <a href="https://en.wikipedia.org/wiki/UUCP">UUCP</a> baggage</q>". Hazel
wanted to write an MTA for modern (at the time) operating systems with
standard C compilers and runtimes, and permanent connections to a
TCP/IP network. He began working on the Experimental Internet Mailer
(Exim) in March 1995. By November it was "<q>just about able to send
and receive emails</q>".</p>

<h4>Exim</h4>

<p>Hazel had informed a colleague, Piete Brooks, that he was working
on Exim. Brooks wanted to try it out, but Hazel demurred because he
had not written any documentation. (This may be the first known case
of a programmer refusing to distribute undocumented code...) Brooks
response was "<q>I don't want the documentation, I want the
code.</q>" Even so, Hazel insisted on writing a first cut of the Exim
manual before packaging up the code and sending it off to meet its fate.</p>

<p>Brooks put the code into service right away, and started
telling others about it. Hazel put Exim releases on a public FTP site,
and gave a talk on Exim at a "Campus Mail Day" in Aberdeen, which led
to more usage. A request from Richard Stallman persuaded him to switch
from a homegrown license for Exim to the GPL. It began being ported to
other operating systems, and eventually found its way to Linux in 1997
or 1998, "<q>which by then had become an operating system that could be
used in production environments</q>". Over time, Exim would become
(and still is) a popular MTA used all over the planet. Its adoption
far exceeded Hazel's expectations:</p>

<blockquote>
<p>I never expected commercial sites to get involved, nor for it to
become the default MTA in any operating systems. In short, I did not
foresee that it would grow into the fully-fledged open source
development project that it has.</p>
</blockquote>

<h4>PCRE</h4>

<p>Regular expressions play a rather large part in managing mail, and
Hazel wanted to have more flexible regular expressions for Exim than were
present in Smail. He chose a regular-expression library
written by Henry Spencer for early versions of Exim, but found it
limiting compared to Perl's extended pattern-matching features. He
thought about lifting Perl's implementation, but it was too integrated
to be easily adapted to Exim. "<q>In the end, I solved the problem the
way programmers generally solve their problems: by writing something
myself.</q>" That, of course, became PCRE.</p>

<p>Hazel bundled PCRE with Exim and also released it as a standalone
library. Like Exim, it filled a need that he did not even realize
existed. PCRE was adopted by Apache HTTPD, and Hazel was
"<q>particularly gratified</q>" to find that it had been included with
the <a href="https://www.postfix.org/">Postfix</a> MTA. After a while, PCRE looked beyond Perl
to include features such as recursion inside a regular expression, and
named subpatterns (borrowed from Python), as well as other ideas taken
from other regular-expression implementations.</p>

<p>In 2014, Hazel decided that PCRE's API was "<q>not capable of much
further extension</q>" and began working on a new, incompatible,
version of the code. The first PCRE2 release (starting at version
10.00 to avoid confusion with then-current PCRE 8.x releases) was <a href="https://lists.exim.org/lurker/message/20150105.162835.0666407a.en.html">announced</a>
in January 2015. Hazel continued supporting PCRE until its <a href="https://lists.exim.org/lurker/message/20210615.162400.c16ff8a3.en.html">final release</a> in 2021. PCRE2 <a href="https://groups.google.com/g/pcre2-dev/c/OUI1FYTcm_E">moved to GitHub</a> in 2022. The most recent release of PCRE2, <a href="https://github.com/PCRE2Project/pcre2/releases/tag/pcre2-10.44">10.44</a>,
came out on June 7, 2024.</p>

<p>Hazel wrote that PCRE may now be even
more important than Exim was "<q>because of its widespread use in many
different applications and operating systems</q>". Indeed, just
looking to see the installed software that depends on the PCRE2
library on Fedora&nbsp;40 turns up use by Git, Grep, MariaDB, nmap,
SELinux's command-line tools, Sway, Wget&nbsp;2, and quite a few others.</p>

<p>In his memoir, Hazel had written that it felt right to pass
maintenance of Exim on to others after so long. "<q>More than a decade on one
project is long enough.</q>" In his 2017 update to the memoir, he
noted that the sentence had come back to bite him: He was still
working on PCRE 19 years after he started to write it. Little did he
suspect he would still be maintaining it in 2024. He would like to <a href="https://github.com/PCRE2Project/pcre2/issues/426">hand it
off</a> while he can help with the transition.</p>

<h4>Passing the torch</h4>

<p>I emailed Hazel with a few questions about his thoughts on
long-term free-software maintenance, changes to the industry, and what
he might do once PCRE was handed off. Hazel wrote that he does not
have any post-PCRE plans. All of <a href="http://quercite.dx.am/">his projects</a>, with the exception of the <a href="https://github.com/PhilipHazel/b2pf">base to presentation
form</a> (B2PF) library for converting Unicode characters for
printing, were started while he was still working. "Since I retired I
haven't felt a lack of anything enough to spur me into writing something
new". He added that he would continue to maintain his non-PCRE2
projects "if necessary" and would help with PCRE2 if needed.</p>

<p>When asked how new generations of tools, and developers, had
changed his work habits, Hazel replied that he has changed
little. "I am sufficiently old that I am well stuck in my ways, and
haven't changed how I do things since the 90s" with the exception
of moving development to GitHub. He admitted that he was not good at
anticipating or keeping up with trends in development. For example, he
said he was not aware of Unicode when he began PCRE development, so it
was written to support ASCII and with a limit of 64K for compiled
patterns. Others had to persuade him to extend PCRE with Unicode
support, and the option for larger patterns. Contributors,
he said, have not changed. The world has, though:</p>

<blockquote>
When I was born, there were no digital computers, though their
predecessors, for example the Colossus at Bletchley Park, were around. The
world has gone from nothing to where we are now in just one lifetime.
Incredible! What particularly amazes me more than the CPU power is the
amount of storage that I carry in my pocket.
</blockquote>

<p>Hazel did offer some advice for those starting new software
projects, though he noted he was not the first to make this point:</p>

<blockquote>
It's worth remembering that the effort needed to maintain a piece of
successful software over its lifetime far outweighs the effort of
writing it in the first place. In the case of PCRE there have been
several major re-designs and re-writes of the internals as
well as continual extensions to the user-visible features.
</blockquote>

<p>He also suggested that developers think about how software would be
tested as it is designed: "Effort put into building test harnesses is
never wasted."</p>

<p>I asked Hazel, given the recent <a href="https://lwn.net/Articles/967866/">XZ backdoor</a> attempt, how
he intended to vet any prospective PCRE2 maintainers. He replied that it
was a good question "to which I have no answer. I will have to see
who (if anyone) makes an offer". To date, he said he had received
"no communications whatsoever" about taking over the
project. Perhaps, once the word gets out more widely, a qualified
maintainer will step forward to take PCRE2 into the future.</p><br clear="all">
               <br clear="all">
               <hr><p>
           (<a href="https://lwn.net/Login/?target=/Articles/978463/">Log in</a> to post comments)
           </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Is Google deliberately breaking Firefox? (101 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40736397</link>
            <guid>40736397</guid>
            <pubDate>Thu, 20 Jun 2024 08:40:35 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40736397">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="40736601"><td></td></tr>
                <tr id="40736880"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40736880" href="https://news.ycombinator.com/vote?id=40736880&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>On Linux (Kubuntu with KDE and Wayland), I cannot use Youtube at all as it freezes for a long time when I start playing a video. It plays the sound but the browser stays frozen for around half a minute or so. It does eventually start showing the video as well... Do you know if there's any known issue for this?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40736929"><td></td></tr>
                <tr id="40736973"><td></td></tr>
                        <tr id="40741309"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40741309" href="https://news.ycombinator.com/vote?id=40741309&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>Not sure if it's related, but I have been having multiple issues on multiple sites related to Firefox, and where the issues go away when using Chrome.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736891"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40736891" href="https://news.ycombinator.com/vote?id=40736891&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>Doesn't that confirm that google is breaking firefox? We can't prove deliberately without evidence, but it seems to fit</p><p>Firefox is fixing youtube's bug because google won't fix a bug</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40736896"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40736896" href="https://news.ycombinator.com/vote?id=40736896&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>Google pays money to Mozilla for being a default search engine. I think "Google breaking firefox" is kind of conspiracy.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40737034"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40737034" href="https://news.ycombinator.com/vote?id=40737034&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>Google only pays because Firefox has enough users to justify it. If enough users switch to Chrome because of broken Google-owned websites, why would they keep paying?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40737072"><td></td></tr>
                  <tr id="40737085"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40737085" href="https://news.ycombinator.com/vote?id=40737085&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>From the zdnet interview with Johnathan Nightingale someone else linked:</p><p>"All of this is stuff you're allowed to do to compete, of course. But we were still a search partner, so we'd say 'hey what gives?' And every time, they'd say, 'oops. That was accidental. We'll fix it in the next push in 2 weeks."</p><p>"Over and over. Oops. Another accident. We'll fix it soon. We want the same things. We're on the same team. There were dozens of oopses. Hundreds maybe?"</p><p>"I'm all for 'don't attribute to malice what can be explained by incompetence' but I don't believe Google is that incompetent. I think they were running out the clock. We lost users during every oops. And we spent effort and frustration every clock tick on that instead of improving our product. We got outfoxed for a while and by the time we started calling it what it was, a lot of damage had been done,"</p><p>When exactly should we shift our framing of an issue from "conspiracy theory" to "actual concern"?</p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="40736702"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736702" href="https://news.ycombinator.com/vote?id=40736702&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>I don't have much problems (Firefox on Mac) but seeing how many others complain I guess it is just a matter of time before I get moved to another A/B testing "experiment" testing how much I can endure before I give up and switch to Chrome (it won't happen).</p><p>Seeing how many of the users report the problem goes away if they let Firefox report as Chrome I personally am rather sure this is intentionally from Googles side:</p><p>Yes, I believe there are some real bugs, but I also think Google do take advantage of "useful" bugs to force us over to Chrome.</p><p>So I have decided to put my money where my mouth is and since last month I am a nebula subscriber. I am also considering Patreon.</p><p>Please consider doing the same, and please do write competition authorities in your country and do ask about when they will look into Googles rampant abuse of market position.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40736786"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40736786" href="https://news.ycombinator.com/vote?id=40736786&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>Hanlon's Razor: <i>Never attribute to malice that which can adequately be explained by stupidity.</i></p><p>I feel its far more likely Google devs are just lazy and don't bother to test in Firefox, much like devs at pretty much every company these days. Unfortunate, but (probably) not part of some deliberate evil plan.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40736837"><td></td></tr>
            <tr id="40736919"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40736919" href="https://news.ycombinator.com/vote?id=40736919&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>Devs are lazy, but management systematically underfunds the web test team to keep it difficult to test on other browsers.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736960"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40736960" href="https://news.ycombinator.com/vote?id=40736960&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>Never apply Hanlon's razor to that which can be adequately be explained by disregard for the consequences.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40739207"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40739207" href="https://news.ycombinator.com/vote?id=40739207&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>At a certain size, making sure ones company doesn't destroy whole ecosystems should be a management responsibility.</p><p>Also, as pointed out by others, when again and again these stupidities benefits the bottom line there is good reason to ask if someone somewhere doesn't have a bonus that goes up with every mistake.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40737030"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40737030" href="https://news.ycombinator.com/vote?id=40737030&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>No I think the lack of testing is due to laziness but a concerted effort to minimally test FF. Which comes down to malice.</p><p>Now, if YT and Chrome were distaste companies, then we might not have this problem...</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736886"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40736886" href="https://news.ycombinator.com/vote?id=40736886&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>this is right for individuals, not corporations like those where every single decision is reviewed in meetings. you should actually apply the opposite for them : guilty unless proven innocent</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40737012"><td></td></tr>
            <tr id="40738421"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40738421" href="https://news.ycombinator.com/vote?id=40738421&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>Hanlon's Razor is for applying to single instances.</p><p>When you have a long-standing pattern of behavior, you need to start using critical thinking, instead.</p><p>Is there a benefit to Google from breaking Firefox?</p><p>Yes, clearly.</p><p>Does Google have the technical competency to avoid breaking Firefox if they want to?</p><p>I would say this is very likely.</p><p>If you misapply Hanlon's Razor where it's no longer appropriate, you're liable to cut yourself off from the truth.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40736939"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736939" href="https://news.ycombinator.com/vote?id=40736939&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>Let's face it. Chrome is the new Internet Explorer. Especially when it comes to google and microsoft websites 'extending' the standard.</p><p>They may not be using explicit "Works best with Internet Explorer" stickers, but I come across a "requires edge or chrome to work properly" or "for best results"-style popup at least twice a week. Or sometimes things just straight-up don't work until you switch to chrome.</p><p>Don't get me started on text-fragments.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736803"><td></td></tr>
            <tr id="40736542"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736542" href="https://news.ycombinator.com/vote?id=40736542&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>I use Firefox for most things at home, including a lot of browsing YouTube. I don't have the issues you're describing. Though I am on YT Premium and use uBlock.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40736916"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40736916" href="https://news.ycombinator.com/vote?id=40736916&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>&gt; Though I am on YT Premium and use uBlock.</p><p>YT Premium is supposed to be ad-less? What the advantages of uBlock here?</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40736947"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40736947" href="https://news.ycombinator.com/vote?id=40736947&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>They might not show you the ads but I guarantee the code is still in the background keeping track of your habits so they can show you more targeted ads elsewhere.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40737090"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40737090" href="https://news.ycombinator.com/vote?id=40737090&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>uBlock, not much but SponsorBlock is very useful.
I am using all of those with YT Premium and I do have issues. I was recently offered their redesign and it made it a lot worse. It's hard to watch a video uninterrupted now.
Note that I also chose not to allow DRM videos, so no Netflix on Firefox for me. This might actually influence the codecs used by Youtube and these issues might only appear on "fallback" codecs when you refuse DRM ones.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40736522"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736522" href="https://news.ycombinator.com/vote?id=40736522&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>I have found, rather amusingly, that Firefox for Android runs YouTube <i>better than the official Android app</i>. The official app randomly closes itself for no reason during long videos, while the web version in Firefox stays up forever (even in the background!)</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40736869"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40736869" href="https://news.ycombinator.com/vote?id=40736869&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>Usually when you have a choice of using a web site or using an app you are better off using the web site.  There is the problem of React pages showing you stale or invalid content in the process of re-re-re-rendering but on iOS I find some apps basically render right, others (like Skype these days) are like a bad React app squared.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40736489"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736489" href="https://news.ycombinator.com/vote?id=40736489&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>The Google Cloud web interface is horribly slow for me in Firefox. For instance, while filtering logs, it can take a few seconds for my keystrokes to show up. This is the only website I've noticed performing poorly like this.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40736935"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40736935" href="https://news.ycombinator.com/vote?id=40736935&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>that issue is visible in any browser, the GCP console is really  bad in some places. for example checking metrics can freeze chrome on a desktop with 7800x3d+64gb ram</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736943"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40736943" href="https://news.ycombinator.com/vote?id=40736943&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>If you want to make a case against SPA/Angular just show someone the monstrosity GCP dashboard is.</p><p>Visually ugly, poor performance, functionally buggy with no sign of support for an independent developer.</p><p>I know all of that is not Angular's fault but some of it sure is.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736574"><td></td></tr>
            <tr id="40736642"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40736642" href="https://news.ycombinator.com/vote?id=40736642&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>Same. Disabling DarkReader extension made it a bit more tolerable.</p><p>For anything other than logs, I just use the Lens desktop app.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40736585"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736585" href="https://news.ycombinator.com/vote?id=40736585&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>I have not noticed issues with YouTube, but it's been clear to me how gimped Firefox is compared with Chrome on Google Meet. Some missing minor features, sluggish performance and lower streaming quality to name a few.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40736623"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40736623" href="https://news.ycombinator.com/vote?id=40736623&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>They did recently (last 6-12 months) add virtual backgrounds to Meet in FF, and it feels fine now. That said I only use Meet on FF and Safari so maybe I don't know what I'm missing out on.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736844"><td></td></tr>
                  <tr id="40736770"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736770" href="https://news.ycombinator.com/vote?id=40736770&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>Photo edits sometimes won't respond on Google Photos in Firefox. It is not just Google. Microsoft Teams, Excel online etc don't work very well in Firefox and it is deliberate.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40740191"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40740191" href="https://news.ycombinator.com/vote?id=40740191&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>There is a simple solution: do not use youtube. After I stopped watching youtube my side projects finally started moving forward, and I get quite a few extra hours in a day, especially on weekends. Although I still watch a video or two on archive.org or one of Peertube instances: tilvids, makertube, to name a few. But no more algorithm induced binge watching of random videos till late in the night.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736428"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736428" href="https://news.ycombinator.com/vote?id=40736428&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>I exclusively use Firefox and I don't have major issues with YouTube. I don't know about the other stuff. However, from what I gather, Google often does A/B testing, so different sessions may get served different versions of the same website, and I do see this often. Because of that, sometimes it's hard to pin down where it's breaking.</p><p>Edit to add: To clarify and be more specific, I watched a live stream on YouTube recently and it seemed to work fine.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40737166"><td></td></tr>
            <tr id="40736903"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736903" href="https://news.ycombinator.com/vote?id=40736903&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>&gt; Is Google deliberately breaking Firefox?</p><p>Yes, and they have been doing so for years.</p><p>&gt; a former Mozilla exec who bemoaned intentional sabotage from the Google camp over several years. Johnathan Nightingale, who worked as a GM &amp; VP on Firefox, saw relations between Google and Firefox sour as the former grew more ambitious for browser market share. Not only did YouTube suffer, he saw "oopses" hitting functionality and performance in other popular Google properties like Gmail and Google Docs.</p><p><a href="https://www.tomshardware.com/news/youtube-responds-to-delayed-loading-in-rival-browser-complaints" rel="nofollow">https://www.tomshardware.com/news/youtube-responds-to-delaye...</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736694"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736694" href="https://news.ycombinator.com/vote?id=40736694&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>I only use Firefox, I haven't open Chrome in months... But I try to stay away from Google most of the time, so probably not the best.</p><p>And as some other people it's better Firefox on Android than the app. I don't have to deal with adds on Firefox, the official app always have 2 or 4 adds waiting for the next video</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736533"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736533" href="https://news.ycombinator.com/vote?id=40736533&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>I use all the time with Fedora Linux. No such problems, including a new experimental ui available for premium users.</p><p>Now the experience with other Google services, plus Firefox mobile is terrible. I log into Gmail from time to time, it's awful. No, I don't want to use the app, I have other reasons and procedures.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736521"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736521" href="https://news.ycombinator.com/vote?id=40736521&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>I've had similar experiences. Switching to Safari seems to help when this happen. I don't expect they'll be doing this on purpose.</p><p>It could be that the encoded video block required by Firefox and not used that much, as such the cache hit rates are bad requiring trips back to an overloaded origin server.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40738560"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40738560" href="https://news.ycombinator.com/vote?id=40738560&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>I faced this too but I attributed it to some obscure bug or setup issue. Seems like I am not alone.</p><p>Google sheets takes forever to load (Just 150 records on the biggest sheet. 9 other sheets with paltry records). Any keypress or scroll takes 10 seconds or more to take effect. I am torn between getting work done and being annoyed by how I am forced to use Chrome. Didn't yield, yet.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40739377"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40739377" href="https://news.ycombinator.com/vote?id=40739377&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>Does no one use Brave?  I like how there's a Scripts on/off toggle, and various shields</p><p>Lots of stuff breaks, but I blame stuff, not the browser</p><p>Turning off my ability to turn off autoplay videos is what made me flee, angrily, Chrome.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40739244"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40739244" href="https://news.ycombinator.com/vote?id=40739244&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>I always use YouTube in Firefox because it allows one to disable autoplay. For the past week I've had frequent issues with buffering/stuttering, but reloading the page tends to fix it.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40737255"><td></td></tr>
            <tr id="40736890"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736890" href="https://news.ycombinator.com/vote?id=40736890&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>I am a fanatic Firefox user who develops in it most of the time so in the last few places I’ve worked (except for one) I was keeping our products compatible with it.</p><p>We have one screen in our admin Ui which loads way too much data and it is notably slow on FF,  but otherwise it is great.</p><p>I have definitely noted sites hat are incompatible with Firefox are turning up but YouTube is by far the worst and most common.  So I browse YouTube with Edge.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736519"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736519" href="https://news.ycombinator.com/vote?id=40736519&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>I haven't noticed any problems with Youtube on Firefox, but I also have some privacy toggles enabled that lie about my user agent.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40737116"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40737116" href="https://news.ycombinator.com/vote?id=40737116&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>I don't think Google cares at this point to break Firefox on purpose vs simply not testing changes on it at all.</p><p>Whenever I need to use Chrome for whatever reason, I simply open Microsoft Edge - not that Microsoft is any better than Google in general, but at least it doesn't own the Internet.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40737183"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40737183" href="https://news.ycombinator.com/vote?id=40737183&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>Edge is Chrome-based these days unfortunately.
And they first leveraged their ad platform to feed people Chrome, then they broke the internet where they could for competitors to gain a greater marketshare to ship this spyware in browserdisguise and now they wanna eat the whole cake.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40737565"><td></td></tr>
                <tr id="40737681"><td></td></tr>
                  <tr id="40736523"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736523" href="https://news.ycombinator.com/vote?id=40736523&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>Malice, incompetence...</p><p>Every team has a mountain of bugs screaming for their attention and a director losing their mind over AI.</p><p>And no one gets promoted for fixing bugs anymore.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40736543"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40736543" href="https://news.ycombinator.com/vote?id=40736543&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>&gt; Every team has a mountain of bugs screaming for their attention and a director losing their mind over AI.</p><p>I don't know whether to laugh or cry.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40736718"><td></td></tr>
                        <tr id="40737466"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40737466" href="https://news.ycombinator.com/vote?id=40737466&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>Main thing I've noticed is missing/fewer features, rather than outright breakage. Particularly Google meet on Firefox missing the fancy background effects and things like that.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736650"><td></td></tr>
            <tr id="40736581"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736581" href="https://news.ycombinator.com/vote?id=40736581&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>Something to note is there is a thousand of experiments running on YouTube at the same time. They test a lot of stuff directly on users. Try VPN, change user agent and/or open in private browsing mode to get a different set of feature flags.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40737710"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40737710" href="https://news.ycombinator.com/vote?id=40737710&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>I think the youtube streaming issue can be fixed with the h264ify extension. I've had it installed for years and I think that was why I did so.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736608"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736608" href="https://news.ycombinator.com/vote?id=40736608&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>Usually I have zero issues with Google Docs (which I only use because of my company) or Youtube (which is use quite rarely). I'm using uBlock though, not sure if it makes any difference. Never used Google Photos.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736647"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736647" href="https://news.ycombinator.com/vote?id=40736647&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>I switched to Firefox, start of this year, I have some issues with YouTube, but I think it must be related to Ad blocker I use.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40736518"><td></td></tr>
                <tr id="40736534"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40736534" href="https://news.ycombinator.com/vote?id=40736534&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>"Never attribute to malice that which is adequately explained by stupidity."
(stupidity is the wrong term here, lazyness is more apt).</p><p>Firefox is a the one different browser with an entirely different pedigree. Assumptions made about _all– other browser will not necessarily hold true for Firefox.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40737043"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40737043" href="https://news.ycombinator.com/vote?id=40737043&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>&gt;"Never attribute to malice that which is adequately explained by stupidity." (stupidity is the wrong term here, lazyness is more apt).</p><p>Ah, but sufficiently advanced stupidity is indistinguishable from malice</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40737707"><td></td></tr>
                        <tr id="40736758"><td></td></tr>
                  <tr id="40736539"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40736539" href="https://news.ycombinator.com/vote?id=40736539&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div>
                  <p>I’ve definitely noticed issues with YouTube on Firefox where a video will start buffering for ages, but I’ve chalked that up to YouTube and uBlock Origin breaking each other. Quite often it’s been a better experience to just use mpv (yt-dlp) instead of the website. Haven’t tried it on Chrome though.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40737003"><td></td></tr>
            <tr id="40736801"><td></td></tr>
            <tr id="40737970"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40737970" href="https://news.ycombinator.com/vote?id=40737970&amp;how=up&amp;goto=item%3Fid%3D40736397"></a></center>    </td><td><br><div><p>Are there people who still watch videos from that cesspit domain called youtube.com?</p><p>Do yourself a favour and use Libretube/NewPipe/Tartube/mpv, or any other youtube-dl/yt-dlp based wrapper.</p><p>No trackers, no ads whose aggregate duration is longer than the video itself, no idiotic Google employees who regularly break the UI, no aggressive policies against adblockers or any other extensions that you want to use.</p><p>Avoiding youtube.com and making sure that not a single dime goes in Google's pockets for providing such a shitty service is a moral duty. Directly fund video creators through Patreon/PayPal if you want to feel less guilty.</p></div></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lessons Learned from Scaling to Multi-Terabyte Datasets (116 pts)]]></title>
            <link>https://v2thegreat.com/2024/06/19/lessons-learned-from-scaling-to-multi-terabyte-datasets/</link>
            <guid>40735859</guid>
            <pubDate>Thu, 20 Jun 2024 07:20:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://v2thegreat.com/2024/06/19/lessons-learned-from-scaling-to-multi-terabyte-datasets/">https://v2thegreat.com/2024/06/19/lessons-learned-from-scaling-to-multi-terabyte-datasets/</a>, See on <a href="https://news.ycombinator.com/item?id=40735859">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
<p>This post is meant to guide you through some of the lessons I’ve learned while working with multi-terabyte datasets. The lessons shared are focused on what someone may face as the size of their dataset scales up and some of the things I’ve done to overcome them. I hope you’re waiting for something to finish running while reading this!</p>



<p>Remember, this is not a rigid guide. It’s about introducing concepts and explaining why you should start applying them. Numerous other tools can surpass the ones I’ve used, and I strongly encourage you to take the initiative and explore them independently. Your active exploration is key to your professional growth.</p>



<p>I’ve divided this post into two sections: scaling on single machines and multi-machine scaling. The goal is to maximize your available resources and reach your goals as quickly as possible.</p>



<p>Lastly, I want to emphasize that no optimization or scaling can compensate for a flawed algorithm. Before scaling up, it’s crucial to evaluate your algorithm. This should always be your first step, providing a confident guide for your work.</p>



<h2>Scaling on a Single Machine</h2>



<h3>Joblib</h3>



<p>Compute is the first bottleneck that comes to mind when scaling. Scaling up computations can be done in several different practical ways. If you’re a data scientist or a machine learning engineer, you might already be familiar with Joblib, a library used to run code in parallel (among other things). It is often used in other libraries, such as scikit-learn or XGBoost.</p>



<p>The process of parallelizing something using Joblib is simple, as follows (modified for clarity from the Joblib docs):</p>


<div><pre title="">&gt;&gt;&gt; from joblib import Parallel, delayed
&gt;&gt;&gt; from math import sqrt

&gt;&gt;&gt; parallel_mapper = Parallel(n_jobs=-1)
&gt;&gt;&gt; delayed_func = delayed(sqrt)
&gt;&gt;&gt; jobs = [
    delayed_func(x**2)
    for x in range(10)
]
&gt;&gt;&gt; parallel_mapper(jobs)
[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]
</pre></div>


<p>Joblib is a great way to scale up your parallel workloads. It’s used in scikit-learn and other tools, proving reliable for many workloads. This isn’t even considering its other excellent features regarding memoization or Fast Compressed Persistence. Joblib is helpful for just making a function parallelizable across all your CPU cores.</p>



<h3>GNU Parallel</h3>



<p>GNU Parallel is a powerful tool for preprocessing or extracting data in the CLI. It differs from Joblib as it can be used outside a script and is versatile. You can even run other Python scripts in parallel. One of the most common use cases is decompressing many files simultaneously. Here’s how I would do it:</p>


<div><pre title="">&gt; ls
random_0.zip&amp;nbsp; random_2.zip&amp;nbsp; random_4.zip&amp;nbsp; random_6.zip&amp;nbsp; random_8.zip
random_1.zip&amp;nbsp; random_3.zip&amp;nbsp; random_5.zip&amp;nbsp; random_7.zip&amp;nbsp; random_9.zip
...

&gt; mkdir output
&gt; ls | parallel --eta --bar "unzip -q {} -d output/"
100% 10:0=0s random_9.zip

&gt; ls output/
random_0.txt&amp;nbsp; random_2.txt&amp;nbsp; random_4.txt&amp;nbsp; random_6.txt&amp;nbsp; random_8.txt
random_1.txt&amp;nbsp; random_3.txt&amp;nbsp; random_5.txt&amp;nbsp; random_7.txt&amp;nbsp; random_9.txt
...
</pre></div>


<p>These commands are pretty straightforward if you have used a Linux terminal before. The main part to focus on is piping the file names to <code>parallel</code> so that <code>unzip</code> can decompress them.</p>



<p>For any task, once you have a bash command set to run on a single file, you can parallelize it by modifying your command slightly. By default, parallel uses all available CPU cores and can execute commands on multiple machines using ssh, meaning that it could be used as an ad-hock computing cluster.</p>



<p>Another use case is downloading a large number of files. With <code>wget</code> and <code>parallel</code> and a list of files to download, writing a quick one-liner to download all the files in parallel is easy. Other tools, such as <code>axel</code> and <code>aria2c</code>, can do this just as well, but I’ve found this to work better when I need to download many smaller files.</p>



<p><strong>A quick note:</strong> While you can use this to download many files, be aware that this can cause strain on servers by creating multiple connections, leading to network congestion and reduced performance for other users or even being seen as a DOS attack. This increased server load can be particularly problematic for smaller websites or servers with limited bandwidth. Famously, aria2c <a href="https://github.com/aria2/aria2/issues/1039">has rejected proposals</a> to increase the maximum number of connections from 16, even though computers have gotten faster, and network bandwidth has increased dramatically. Given their position, I agree with their decisions and ask you to act responsibly when downloading.</p>



<p>Another point I’d like to mention is that while you can get things working quicker with Parallel, it may be challenging to manage <code>bash</code> commands, especially for a beginner where the rest of the team might be more Python/traditional programming language focused. Due to this, I generally recommend keeping Parallel for one-off tasks rather than writing complex ETL pipelines in <code>bash</code>. Maintainable code is second to only no code at all.</p>



<h2>Scaling to Multiple Machines</h2>



<h3>When to Start Using Multiple Machines</h3>



<p>One key identifier for when it makes sense to switch to using multiple machines (think Spark or, my favourite, Dask) is when computing is taking too long for your use cases. This could be experiments, data processing, or whatever. The worst timeframe I’ve estimated is some jobs taking months or a year to finish computing if I were to stick to a single instance, even on AWS’s <a href="https://instances.vantage.sh/aws/ec2/u-24tb1.112xlarge">u-24tb1.112xlarge</a> (a beast of a machine). I’m against the waste of any kind, and the better you can utilize the resources available, the better, in my opinion.</p>



<p>By switching to multiple smaller machines, you leverage several performance benefits over a more prominent instance. Depending on your scaling solution, horizontal scaling allows for almost linear scaling across your CPU, memory, and networking with the number of instances you use.</p>



<p>Most reasonably large EC2 instances offer up to 10 GBit internet speeds, which can help alleviate IO bottlenecks, especially if you’re rapidly streaming data to or from S3. If your workload requires data coming in at 50 Gbit/s, you’ve got the option to either use a m7i.48xlarge instance, which costs <code><em>$9.6768</em></code> hourly and runs at 50 GBit, or four m7i.8xlarge instances, which costs <code>$1.6128</code> hourly per instance or <code>$6.4512 hourly</code> for the same network bandwidth.</p>



<p>I selected networking speeds and cost as the two metrics to focus on here, but if you’re looking to maximize your memory and CPU usage, we can compare the previously mentioned u-24tb1.112xlarge. For the exact cost, you can rent out 135 m7i.8xlarge instances. That gives you 4320 CPUs (10x the instance), 17.28TB of RAM, and 1687.5 Gigabit internet speed (~17x the instance)! While RAM is less, I’ve used a general-purpose instance here to scale, not a memory-optimized one. Using the memory-optimized equivalent, we can get 34.56 TB of RAM, with all the other benefits of using multiple machines (redundancy, finer control for the instance size, etc).</p>



<p>Moreover, with the correct backend, I can scale to as many instances as my use case, orchestration tool, or accounting department will allow. This level of scalability is a crucial advantage, enabling you to meet the demands of your workload without being limited by the capabilities of a single instance.</p>



<p>As with everything, there are benefits to your different approaches. It’s your job to evaluate the pros and cons of each solution and determine what works best for your use case. Minimizing cost while maximizing performance is a good exercise in building intuition for these tasks.</p>



<p>However, given these incredible benefits, I only recommend using multiple instances once you’ve understood the bottlenecks you face. I have seen teams start to scale and over-engineer their approach to computing before understanding their use case. I may have even been a part of those teams before learning my lesson. In some instances, <a href="https://adamdrake.com/command-line-tools-can-be-235x-faster-than-your-hadoop-cluster.html">well-written cli tools could process data faster than an entire spark cluster</a>.</p>



<h2>Different Computing Models</h2>



<h3>For Embarrassingly Parallel Workloads</h3>



<p>Embarrassingly Parallel Workloads are generally the easiest to scale compared to other types of workloads. We’ve already touched on how to scale up computing using Joblib or Parallel, but what about scaling to multiple machines? There are quite a few tools to scale up computation. I would recommend using AWS Batch or AWS Lambda for embarrassingly parallel workloads that are one-off. Batch is scalable, and with spot pricing, you can get most of your tasks done at a fraction of the cost of using on-demand instances in a fraction of the time it would take to run them in parallel on a single machine. There are other tools you can use (GCP’s Cloud Run, for example), but I can only recommend AWS Batch for longer-running tasks since that’s what I’ve used in the past.</p>



<p>Since setting up the cluster can be time-consuming and is out of the scope of this post, I’ve included a link <a href="https://medium.com/@jackthecloudguy/scale-out-your-genomics-analysis-with-aws-batch-923c41a3c99">here</a> incase you’re interested in exploring this yourself.</p>



<p>One caveat worth mentioning is that the general throughput of your job will be limited by your read and write speeds more so than the compute speed. If you’re reading from/writing to a database, then the database is likely to be a bottleneck (or even crash). S3 is a viable option for reading and writing, given it’s designed to scale better, but it still has its limits. 3,500 writes and 5,500 reads per second per partitioned prefix. S3 is designed to be invisible when scaling to the user, so you may have little control over how it adapts to the increased throughput.</p>



<p>Once the data is in S3 (or whatever service you use), you can transfer it wherever needed.</p>



<p>This setup is quite tedious but scales well for one-off tasks. With a few iterations, you can reduce the setup time to a few minutes, depending on how well you’ve automated the process and your team’s needs. Generally, I’ve found that the setup time is worth it for the computing and engineering time saved, but you can understand my hesitation in using this for every task.</p>



<h3>Analytical Workloads</h3>



<p>Analytical workloads are a bit more challenging to scale. This is because you’re generally working with a single dataset and trying to do a lot of operations on that dataset. You may also have an element of interactivity, such as things running in a Jupyter Notebook. My go-to tool for scaling up analytical workloads is Dask, with an alternative being Spark. Dask and Spark are open-source tools that allow you to scale up your workloads to multiple machines, with their pros and cons. Both these tools can also be used locally, and their implementations of DataFrames (Dask DataFrame and Spark Dataframe) can be used to scale up existing workloads.</p>



<p>Dask is much easier to set up and install. I can get Dask running locally in a few minutes with a single command (<code>pip install "dask[complete]"</code> by the way). On the other hand, Spark requires a bit more setup, and I’ve found that running on my local machine is a bit more challenging. Dask also comes with the benefit that any data scientist using Pandas or Numpy can get used to it quickly while knowing Spark is an entirely different skill set. Dask is also better integrated with several PyData tools, meaning you can take advantage of them immediately. However, given all this, Spark and the Spark ecosystem are much more mature by comparison, and it’s likely that your team already has invested time into getting a Spark cluster up and running. I run into the occasional bug or performance issue with Dask, while Spark is known to be much more stable due to its maturity. Dask is also not suited for longer-running computations.</p>



<p>Given this, my general recommendation is:</p>



<ul>
<li>If you’re a small team or startup with no infrastructure for big data or distributed computing. In that case, I recommend at least experimenting with Dask, regardless of the team’s experience with Spark. In the time you take to get Spark running locally, you could’ve validated your use case with Dask, and your team will be able to leverage other tools in the PyData space.</li>



<li>If you’re already part of a larger organization that uses Spark or some other significant data infrastructure. In that case, it makes sense to stick with it unless you have a compelling reason not to. I recommend watching <a href="https://www.youtube.com/watch?v=obKZzFRNTxo">Eric Dill’s talk on Is Spark Still Relevant?</a> for why larger organizations prefer to use Spark over more modern tools. It is five years old, so some talking points may be outdated. That said, you should still try Dask since <a href="https://docs.dask.org/en/latest/spark.html#reasons-to-choose-both">you can use both</a>.</li>
</ul>



<h2>Conclusion</h2>



<p>In conclusion, managing and scaling multi-terabyte datasets requires a deep understanding of both your data and the tools at your disposal. By leveraging Joblib and GNU Parallel for single-machine scaling, you can maximize the efficiency of your computational resources. When scaling beyond a single machine is necessary, AWS Batch, Dask, and Spark provide robust solutions for various workloads, from embarrassingly parallel tasks to complex analytical operations.</p>



<p>The key takeaway is to start by optimizing your algorithms before scaling, ensuring you’re not merely amplifying inefficiencies. Actively exploring and adapting new tools can significantly enhance your performance and cost-effectiveness. Successful scaling is as much about strategic planning and resource management as raw computational power. Embrace the learning curve; you’ll be well-equipped to handle even the largest datasets confidently and skillfully.</p>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oldest white wine in the world found in a first-century tomb in Spain (189 pts)]]></title>
            <link>https://doi.org/10.1016/j.jasrep.2024.104636</link>
            <guid>40735743</guid>
            <pubDate>Thu, 20 Jun 2024 06:58:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://doi.org/10.1016/j.jasrep.2024.104636">https://doi.org/10.1016/j.jasrep.2024.104636</a>, See on <a href="https://news.ycombinator.com/item?id=40735743">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Protecting Children's Safety Requires End-to-End Encryption (110 pts)]]></title>
            <link>https://simplex.chat/blog/20240601-protecting-children-safety-requires-e2e-encryption.html</link>
            <guid>40735627</guid>
            <pubDate>Thu, 20 Jun 2024 06:37:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simplex.chat/blog/20240601-protecting-children-safety-requires-e2e-encryption.html">https://simplex.chat/blog/20240601-protecting-children-safety-requires-e2e-encryption.html</a>, See on <a href="https://news.ycombinator.com/item?id=40735627">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article">
<p>As lawmakers grapple with the serious issue of child exploitation online, some proposed solutions would fuel the very problem they aim to solve. Despite expert warnings, the Belgian Presidency persists in pushing for the implementation of client-side scanning on encrypted messaging services, rebranding the effort as "upload moderation". Their <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=COM%3A2022%3A209%3AFIN&amp;qid=1652451192472">latest proposal</a> mandates that providers of private communication services obtain user consent for AI-based scanning of their private chats. If users do not consent, they will be prohibited from sharing images, videos, and URLs.</p>
<p>Privacy critics have long pushed for measures like centralized scanning of private photos and messaging data, arguing it could detect illicit content. However, invasive monitoring of private communications would create detrimental risks that far outweigh any perceived benefits.</p>
<h2 id="why-were-taking-action" tabindex="-1">Why we’re taking action</h2>
<p>SimpleX Chat signed a <a href="https://www.globalencryption.org/2024/05/joint-statement-on-the-dangers-of-the-may-2024-council-of-the-eu-compromise-proposal-on-eu-csam/">joint statement</a> about the dangers of the EU compromise proposal on EU CSAM because maintaining end-to-end encryption is crucial for protecting privacy and security for everyone, including and especially children.</p>
<p>We urge the Ministers in the Council of the EU to stand firm against any scanning proposals that undermine end-to-end encryption, which would enable mass surveillance and misuse by bad actors, whether framed as client-side scanning, upload moderation, or any other terminology. Compromising this basic principle opens the door to devastating privacy violations. We also urge any organizations or individuals reading this to write to their representatives and voice their concerns. European Digital Rights has <a href="https://edri.org/our-work/be-scanned-or-get-banned/">outlined these issues</a> in greater detail for anyone seeking more information.</p>
<h2 id="why-compromising-privacy-endangers-children" tabindex="-1">Why compromising privacy endangers children</h2>
<p>The core issue is that compromising encryption and privacy makes innocent people vulnerable to malicious hackers and criminals seeking to exploit users data. Centralized scanning systems become a tempting target, potentially exposing millions of private family photos when breached. This would easily open up avenues for blackmail, abuse, and victimization of children. A case in point is the recent <a href="https://techcrunch.com/2024/01/17/unredacted-meta-documents-reveal-historical-reluctance-to-protect-children-new-mexico-lawsuit/">criminal charges</a> against Meta in New Mexico, which highlights how the tech giant's algorithms enabled child exploitation by encouraging connections between minors and sexual predators. Privacy-eroding initiatives like client-side scanning would play into the hands of malicious actors by making more sensitive information accessible and weaponized in the same way that it has been on Meta platforms.</p>
<h2 id="what-should-be-done" tabindex="-1">What should be done</h2>
<p>Rather than undermining privacy, to achieve child safety online users should be empowered with high standards for encryption and data control. For example, adopting a model where children (and users in general) cannot be discovered or approached on networks unless they or their parents permit it, similar to the SimpleX network privacy model. Intelligent multi-device synchronization could enable this oversight without compromising end-to-end encryption overall. It’s always possible to protect children without opening everyone, especially children themselves, to greater vulnerabilities due to such proposals.</p>
<p>However, some recent legislative efforts have bizarrely moved in the opposite direction by seeking to limit parental access. The chilling truth is that the least private platforms have been major enablers of child exploitation. Eroding privacy protections on other services will only aid criminals further, not protect children. Preserving strong encryption and user privacy must be the foundation for any credible effort to combat online child exploitation. Initiatives trading privacy for supposed safety are not just technically flawed, but would achieve the exact opposite of their stated intent. We must avoid being gaslighted by narratives that defy logic, and instead provide users with the highest possible standards for privacy protections as a core principle.</p>
<p>Protecting end-to-end encryption without carving out backdoors or vulnerabilities should be non-negotiable for children's and everyone’s safety. It is critical to redirect the discourse to focus on taking genuine privacy further by protecting against <a href="https://simplex.chat/blog/20240416-dangers-of-metadata-in-messengers.html">metadata hoarding</a> and other means by which people’s data can be abused or subjected to surveillance.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OSRD: Open-Source Railway Designer (177 pts)]]></title>
            <link>https://osrd.fr/en/</link>
            <guid>40733705</guid>
            <pubDate>Thu, 20 Jun 2024 00:21:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://osrd.fr/en/">https://osrd.fr/en/</a>, See on <a href="https://news.ycombinator.com/item?id=40733705">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main role="main"><div id="td-cover-block-0"><p><img src="https://osrd.fr/logos/logo_white.svg"></p><h2>Open Source Railway Designer</h2></div><div><p>An open source web application for railway infrastructure design, capacity analysis, timetabling and more!</p></div><div><div><h4>Railway design</h4><p>Design railway infrastructure and timetables</p></div><div><h4>Capacity Analysis</h4><p>Detect conflicts and visualize capacity</p></div><div><h4>Short-term planning</h4><p>Automatically add new trains to an existing timetable</p></div></div><div><div><h4>Open source development</h4><p>Anyone can use, develop and distribute OSRD</p><p><a href="https://osrd.fr/en/about/opensource/">Read more …</a></p></div><div><h4>Open governance</h4><p>OSRD is publicly designed, decisions are taken collectively</p><p><a href="https://osrd.fr/en/about/governance/">Read more …</a></p></div><div><h4>Designed for interoperability</h4><p>Make custom infrastructure formats and signaling systems work together</p></div></div><section><video controls="">
<source src="https://osrd.fr/en/video.en.webm" type="video/webm"></video></section><section><h2>Sponsors</h2><p><img src="https://osrd.fr/sponsors/france-dot.svg" width="180px" height="180px" alt="Ministère chargé des Transports">
<img src="https://osrd.fr/sponsors/european-union.svg" width="180px" height="180px" alt="European Union">
<img src="https://osrd.fr/sponsors/sncf-reseau.svg" width="180px" height="180px" alt="SNCF Réseau"></p></section></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nobody knows what's going on (208 pts)]]></title>
            <link>https://www.raptitude.com/2024/06/nobody-knows-whats-going-on/</link>
            <guid>40733615</guid>
            <pubDate>Thu, 20 Jun 2024 00:06:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.raptitude.com/2024/06/nobody-knows-whats-going-on/">https://www.raptitude.com/2024/06/nobody-knows-whats-going-on/</a>, See on <a href="https://news.ycombinator.com/item?id=40733615">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img src="https://www.raptitude.com/wp-content/uploads/2024/06/artem-beliaikin-v6kii3H5CcU-unsplash.jpg" width="600" height="400" alt="Post image for Nobody Knows What’s Going On"></p><p>A major online publication once reported in a profile on me that I had retired at 33. A few old friends and acquaintances reached out to congratulate me on my financial independence.</p>



<p>I think it was an honest mistake on the part of the reporter. I told her I had quit my job to write full time, and I guess she thought that meant I must have millions of dollars.</p>



<p>To be clear, I was not then, and am not now financially independent. The 100 or so people that actually know me could discern that just by seeing my kitchen. Yet perhaps 20,000 people read somewhere that I am. That means potentially 200 times more people are wrong than right on this question, because of an inference made by a reporter.</p>



<p>This scenario, in which there’s much more wrongness going around than rightness, is probably the norm. People make bad inferences like that all day long. These wrong ideas replicate themselves whenever the person tells someone else what they know, which the internet makes easier than ever.</p>



<p>Consider the possibility that <em>most</em> of the information being passed around, on whatever topic, is bad information, even where there’s no intentional deception. As George Orwell said, “The most fundamental mistake of man is that he thinks he knows what’s going on. Nobody knows what’s going on.”</p>



<p>Technology may have made this state of affairs inevitable. Today, the vast majority of a person’s worldview is assembled from second-hand sources, not from their own experience. Second-hand knowledge, from “reliable” sources or not, usually functions as hearsay – if it <em>seems</em> true, it is immediately incorporated into one’s worldview, usually without any attempt to substantiate it. Most of what you “know” is just something you heard somewhere.</p>


<div>
<figure><a href="https://www.raptitude.com/wp-content/uploads/2024/06/titanic-onion.jpg"><img fetchpriority="high" decoding="async" width="300" height="297" src="https://www.raptitude.com/wp-content/uploads/2024/06/titanic-onion-300x297.jpg" alt="" srcset="https://www.raptitude.com/wp-content/uploads/2024/06/titanic-onion-300x297.jpg 300w, https://www.raptitude.com/wp-content/uploads/2024/06/titanic-onion-150x150.jpg 150w, https://www.raptitude.com/wp-content/uploads/2024/06/titanic-onion-194x192.jpg 194w, https://www.raptitude.com/wp-content/uploads/2024/06/titanic-onion.jpg 400w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption><em>Standard editorial approach</em></figcaption></figure></div>


<p>When people go on to share what they “know”, there’s usually no penalty for being wrong, but there are rewards for convincing people you’re right: attention, money, adoration, public rhetorical victories over others, and many other things humans enjoy.</p>



<h3>The Two Kinds of Knowing</h3>



<p>First-hand knowledge is a whole different thing from the second-hand kind. When you experience an event with your senses, you’re not just accepting a verbal claim, such as “There’s fighting in the streets of Kabul” — the truth is actually happening to you. The experienced sailor <em>knows</em> that looming cloud formation means trouble. The soldier knows the attack on his unit’s position was repelled. The dog owner knows exactly how long she can leave Rocco alone at home before he relieves himself on the floor. The friend sitting on my fifteen-year-old couch knows I’m not independently wealthy. Experience imprints reality right into your neurons; it doesn’t just add another thought to the abstract space in your brain where you keep your axioms and factoids.</p>


<div>
<figure><a href="https://www.raptitude.com/wp-content/uploads/2024/06/jamie-street-s9Tf1eBDFqw-unsplash600.jpg"><img decoding="async" width="300" height="225" src="https://www.raptitude.com/wp-content/uploads/2024/06/jamie-street-s9Tf1eBDFqw-unsplash600-300x225.jpg" alt="" srcset="https://www.raptitude.com/wp-content/uploads/2024/06/jamie-street-s9Tf1eBDFqw-unsplash600-300x225.jpg 300w, https://www.raptitude.com/wp-content/uploads/2024/06/jamie-street-s9Tf1eBDFqw-unsplash600-256x192.jpg 256w, https://www.raptitude.com/wp-content/uploads/2024/06/jamie-street-s9Tf1eBDFqw-unsplash600.jpg 600w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption><em>Good for about six hours</em></figcaption></figure></div>


<p>Only a tiny percentage of what a given person “knows” is in this first-hand, embodied form. The rest is made of impressions gathered from anecdotes, newspapers, books, schoolteachers, blogs, and things our older siblings told us when we were little.</p>



<p>If you ever read an article on a subject with which you have a lot of first-hand experience, you’ll notice that they <em>always</em> get major things wrong – basic facts, dates, names of people and organizations, the stated intentions of involved parties, the reasons a thing is happening – things even a novice in the space would know better about.</p>



<p>It makes perfect sense, if you think about it, that reporting is so reliably unreliable. Why do we expect reporters to learn about a suddenly newsworthy situation, gather information about it under deadline, then confidently explain the subject to the rest of the nation after having known about it for all of a week? People form their entire worldviews out of this stuff.</p>


<div>
<figure><a href="https://www.raptitude.com/wp-content/uploads/2024/06/owlsnot-as-they-seem500.jpg"><img decoding="async" width="300" height="278" src="https://www.raptitude.com/wp-content/uploads/2024/06/owlsnot-as-they-seem500-300x278.jpg" alt="" srcset="https://www.raptitude.com/wp-content/uploads/2024/06/owlsnot-as-they-seem500-300x278.jpg 300w, https://www.raptitude.com/wp-content/uploads/2024/06/owlsnot-as-they-seem500-207x192.jpg 207w, https://www.raptitude.com/wp-content/uploads/2024/06/owlsnot-as-they-seem500.jpg 500w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption><em>Me forming my worldview</em></figcaption></figure></div>


<p>What doesn’t make sense is that we immediately become credulous again as soon as the subject matter changes back to a topic on which we <em>don’t </em>have first-hand experience. You know they don’t know what they hell they’re talking about on Subject A, but hey what’s this about Subject B? In 2002, author Michael Crichton named this the “Gell-Mann Amnesia effect”:</p>



<blockquote>
<p>Briefly stated, the Gell-Mann Amnesia effect is as follows. You open the newspaper to an article on some subject you know well. In [Murray Gell-Mann’s] case, physics. In mine, show business. You read the article and see the journalist has absolutely no understanding of either the facts or the issues. Often, the article is so wrong it actually presents the story backward—reversing cause and effect. I call these the “wet streets cause rain” stories. Paper’s full of them.</p>



<p>In any case, you read with exasperation or amusement the multiple errors in a story, and then turn the page to national or international affairs, and read as if the rest of the newspaper was somehow more accurate about Palestine than the baloney you just read. You turn the page, and forget what you know.</p>
</blockquote>



<p>Crichton clarifies in the <a href="https://www.docdroid.net/4wgVecr/why-speculate-michael-crichton-pdf#page=2">full speech</a> that by “media” he’s not only talking about newspapers, but books, television, and internet too, and of course anybody’s recounting of what these sources say. Well, that accounts for just about 100% of our second-hand knowledge.</p>


<div>
<figure><a href="https://www.raptitude.com/wp-content/uploads/2024/06/gaurav-bagdi-K-fbBy5HNSg-unsplash600cropped.jpg"><img loading="lazy" decoding="async" width="282" height="300" src="https://www.raptitude.com/wp-content/uploads/2024/06/gaurav-bagdi-K-fbBy5HNSg-unsplash600cropped-282x300.jpg" alt="" srcset="https://www.raptitude.com/wp-content/uploads/2024/06/gaurav-bagdi-K-fbBy5HNSg-unsplash600cropped-282x300.jpg 282w, https://www.raptitude.com/wp-content/uploads/2024/06/gaurav-bagdi-K-fbBy5HNSg-unsplash600cropped-181x192.jpg 181w, https://www.raptitude.com/wp-content/uploads/2024/06/gaurav-bagdi-K-fbBy5HNSg-unsplash600cropped.jpg 600w" sizes="(max-width: 282px) 100vw, 282px"></a><figcaption>“<em>The situation is developing”</em></figcaption></figure></div>


<p>People do know things though. We have airplanes and phones and spaceships. Clearly somebody knows something. Human beings <em>can</em> be reliable sources of knowledge, but only about small slivers of the whole of what’s going on. They know things because they deal with their sliver every day, and they’re personally invested in how well they know their sliver, which gives them constant feedback on the quality of their beliefs.</p>



<p>Plumbing knowledge, for example, is constantly tested by whether the place floods after you’ve advanced your theory about what pipe connects to what. You need to get it right because it costs you something when you get it wrong.</p>



<p>The mechanic has seen a thousand check-engine lights and knows how each of them was resolved. The English professor has seen a thousand essays and can tell you what’s wrong with yours. The night club bouncer has dealt with a thousand drunk patrons and knows which guests will be trouble even before they do.</p>


<div>
<figure><a href="https://www.raptitude.com/wp-content/uploads/2024/06/rivage-4CNNH2KEjhc-unsplash600.jpg"><img loading="lazy" decoding="async" width="300" height="225" src="https://www.raptitude.com/wp-content/uploads/2024/06/rivage-4CNNH2KEjhc-unsplash600-300x225.jpg" alt="" srcset="https://www.raptitude.com/wp-content/uploads/2024/06/rivage-4CNNH2KEjhc-unsplash600-300x225.jpg 300w, https://www.raptitude.com/wp-content/uploads/2024/06/rivage-4CNNH2KEjhc-unsplash600-256x192.jpg 256w, https://www.raptitude.com/wp-content/uploads/2024/06/rivage-4CNNH2KEjhc-unsplash600.jpg 600w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption><em>Somebody’s sliver, thankfully</em></figcaption></figure></div>


<p>There are ways to carefully gather, scrutinize, and compare high-quality second-hand sources, and maybe learn something reliable, but this is extremely difficult for the groupish, emotional creature we are. It is <a href="https://www.raptitude.com/2023/05/how-to-think-about-politics-without-going-insane/">viscerally unpleasant</a> (not to mention time-consuming) to honestly question beliefs you feel positively towards, or honestly entertain ones you don’t, and ultimately you’re just determining what “feels right” anyway.</p>



<p>Aside from our own respective slivers of reliable knowledge, we mostly carry a lot of untested beliefs — teetering piles of them, accumulated over years, from random people assuring us “this is how it is.” Most of these beliefs are bunk, but we don’t know which ones. &nbsp;&nbsp;</p>



<h3>Beliefs are Mostly Mind-Candy</h3>



<p>Humans love beliefs, not because they’re reliable pointers to what’s true, but because they often feel good in some way, or have social rewards. Expressing and sharing beliefs can get us attention and social status, make us feel competent, sell our goods and services, and motivate people to do things for us, and they can just feel satisfying to say aloud. A convincing belief is simply one that feels good to the ears, or the mind.</p>


<div>
<figure><a href="https://www.raptitude.com/wp-content/uploads/2024/06/ryan-brooklyn-e5Ja8Z_WEvA-unsplash600.jpg"><img loading="lazy" decoding="async" width="300" height="200" src="https://www.raptitude.com/wp-content/uploads/2024/06/ryan-brooklyn-e5Ja8Z_WEvA-unsplash600-300x200.jpg" alt="" srcset="https://www.raptitude.com/wp-content/uploads/2024/06/ryan-brooklyn-e5Ja8Z_WEvA-unsplash600-300x200.jpg 300w, https://www.raptitude.com/wp-content/uploads/2024/06/ryan-brooklyn-e5Ja8Z_WEvA-unsplash600-288x192.jpg 288w, https://www.raptitude.com/wp-content/uploads/2024/06/ryan-brooklyn-e5Ja8Z_WEvA-unsplash600.jpg 600w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption><em>Beliefs of mine, awaiting testing</em></figcaption></figure></div>


<p>Theory feels good. Pithiness and analogy feel good. A tight sentence feels good. Neat and snappy stories about what’s “true” are like candy to the sense-craving part of the human brain.</p>



<p>Notice how many smart people believe things like, “You can’t reason yourself out of a belief you didn’t reason yourself into.” This is a belief nobody would arrive at through reason. It doesn’t stand up to even a minute’s logical scrutiny. You certainly didn’t reason yourself into a belief that North-Pole-dwelling elves made your childhood toys, but you probably reasoned yourself out of it. Both beliefs are just mind-candy, only for different audiences.</p>



<p>In short, human beings are bad at gathering information, inferring the right things from it, and responsibly passing it on to others. It is incredible what we’ve achieved in spite of this — almost entirely by carefully combining and testing our respective reliable slivers — but as a species we remain supremely untalented at knowing what’s true outside the range of our senses.</p>


<div>
<figure><a href="https://www.raptitude.com/wp-content/uploads/2024/06/Kids_in_the_Hall_Brain_Candy_poster.jpg"><img loading="lazy" decoding="async" width="257" height="388" src="https://www.raptitude.com/wp-content/uploads/2024/06/Kids_in_the_Hall_Brain_Candy_poster.jpg" alt="" srcset="https://www.raptitude.com/wp-content/uploads/2024/06/Kids_in_the_Hall_Brain_Candy_poster.jpg 257w, https://www.raptitude.com/wp-content/uploads/2024/06/Kids_in_the_Hall_Brain_Candy_poster-199x300.jpg 199w, https://www.raptitude.com/wp-content/uploads/2024/06/Kids_in_the_Hall_Brain_Candy_poster-127x192.jpg 127w" sizes="(max-width: 257px) 100vw, 257px"></a><figcaption><em>A relevant documentary (1996)</em></figcaption></figure></div>


<p>Much of the problem is that we want so badly to be believed, to be seen as someone who knows stuff. In the rest of Crichton’s speech, he explains why he named the Gell-Mann Amnesia effect after Murray Gell-Mann: because he’s famous, and he’s a physicist. People believe things named after physicists because we know they’re smart. And Crichton is a medical doctor, so you should listen to the guy.</p>



<p>Also, none of you will be able to confirm this, but George Orwell did not say the line in the intro of this article. I just said that he did so you would take my own assertions more seriously. And it’s too late — you’ve already tasted the candy. I mean, Orwell could have said something like that. He might as well have said it. He probably did, basically! I will sleep soundly anyway. There are few penalties for bullshit, and many rewards. Because nobody knows what’s going on.</p>



<p>***</p>



<p><em>Images by <a href="https://unsplash.com/@belart84">Artem Beliaikin</a>, <a href="https://www.theonion.com/">The Onion</a>, <a href="https://unsplash.com/@jamie452">Jamie Street</a>, <a href="https://unsplash.com/@sigmund">Rivage</a>, <a href="https://unsplash.com/@rbrooklyn">Ryan Brooklyn</a>, <a href="https://unsplash.com/@dfyngrvty">Gaurav Bagdi</a></em></p>

            

        				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hypermedia Systems (230 pts)]]></title>
            <link>https://hypermedia.systems/</link>
            <guid>40733160</guid>
            <pubDate>Wed, 19 Jun 2024 22:39:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hypermedia.systems/">https://hypermedia.systems/</a>, See on <a href="https://news.ycombinator.com/item?id=40733160">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <ul id="blurb" role="list" data-cols="1 3" data-cols@s="1" data-rows="1 3">
        <li>The revolutionary ideas that empowered the Web</li>
        <li>A simpler approach to building applications on the Web and beyond with <a href="https://htmx.org/">htmx</a> and <a href="https://hyperview.org/">Hyperview</a></li>
        <li>Enhancing web applications without using SPA frameworks</li>
        <li></li>
        </ul>

        <ul data-cols="4 5" data-cols@s="1" role="list">
        <li><strong><a href="https://hypermedia.systems/book/contents">
            <span>
                Read online
                <small>(Free, forever)</small>
            </span>
        </a></strong>
        </li>
        <li><strong><a href="https://www.amazon.com/dp/B0C9S88QV6/ref=sr_1_1">
            <span>
                Hard copy
                <small>(Buy on Amazon)</small>
            </span>
        </a></strong>
        </li>
        <li><strong><a href="https://www.amazon.com/Hypermedia-Systems-Carson-Gross-ebook/dp/B0CC315VJK/ref=tmm_kin_swatch_0">
            <span>
                Ebook
                <small>(Buy on Amazon)</small>
            </span>
        </a></strong>
        </li>
        </ul>

        <p data-cols="4 5" data-cols@s="1">
            For web developers frustrated with the complexity of modern practice,<span></span>
            those looking to brush up on web fundamentals,<span></span>
            web development shops looking to bring their apps to mobile,<span></span>
            and any workaday programmer looking for an introduction to hypermedia and REST.
        </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unique3D: Image-to-3D Generation from a Single Image (128 pts)]]></title>
            <link>https://github.com/AiuniAI/Unique3D</link>
            <guid>40732490</guid>
            <pubDate>Wed, 19 Jun 2024 21:20:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/AiuniAI/Unique3D">https://github.com/AiuniAI/Unique3D</a>, See on <a href="https://news.ycombinator.com/item?id=40732490">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><strong><a href="https://github.com/AiuniAI/Unique3D/blob/main/README_zh.md">中文版本</a></strong></p>
<p dir="auto"><strong><a href="https://github.com/AiuniAI/Unique3D/blob/main/README_jp.md">日本語版</a></strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Unique3D</h2><a id="user-content-unique3d" aria-label="Permalink: Unique3D" href="#unique3d"></a></p>
<p dir="auto">Official implementation of Unique3D: High-Quality and Efficient 3D Mesh Generation from a Single Image.</p>
<p dir="auto"><a href="https://scholar.google.com/citations?user=VTU0gysAAAAJ&amp;hl=zh-CN&amp;oi=ao" rel="nofollow">Kailu Wu</a>, <a href="https://liuff19.github.io/" rel="nofollow">Fangfu Liu</a>, Zhihan Cai, Runjie Yan, Hanyang Wang, Yating Hu, <a href="https://duanyueqi.github.io/" rel="nofollow">Yueqi Duan</a>, <a href="https://group.iiis.tsinghua.edu.cn/~maks/" rel="nofollow">Kaisheng Ma</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><a href="https://arxiv.org/abs/2405.20343" rel="nofollow">Paper</a> | <a href="https://wukailu.github.io/Unique3D/" rel="nofollow">Project page</a> | <a href="https://huggingface.co/spaces/Wuvin/Unique3D" rel="nofollow">Huggingface Demo</a> | <a href="https://u45213-bcf9-ef67553e.westx.seetacloud.com:8443/" rel="nofollow">Gradio Demo</a> | <a href="https://www.aiuni.ai/" rel="nofollow">Online Demo</a></h2><a id="user-content-paper--project-page--huggingface-demo--gradio-demo--online-demo" aria-label="Permalink: Paper | Project page | Huggingface Demo | Gradio Demo | Online Demo" href="#paper--project-page--huggingface-demo--gradio-demo--online-demo"></a></p>
<ul dir="auto">
<li>Demo inference speed: Gradio Demo &gt; Huggingface Demo &gt; Huggingface Demo2 &gt; Online Demo</li>
</ul>
<p dir="auto"><strong>If the Gradio Demo unfortunately hangs or is very crowded, you can use the Online Demo <a href="https://www.aiuni.ai/" rel="nofollow">aiuni.ai</a>, which is free to try (get the registration invitation code Join Discord: <a href="https://discord.gg/aiuni" rel="nofollow">https://discord.gg/aiuni</a>). However, the Online Demo is slightly different from the Gradio Demo, in that the inference speed is slower, and the generation results is less stable, but the quality of the material is better.</strong></p>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/AiuniAI/Unique3D/blob/main/assets/teaser_safe.jpg"><img src="https://github.com/AiuniAI/Unique3D/raw/main/assets/teaser_safe.jpg"></a>
</p>
<p dir="auto">High-fidelity and diverse textured meshes generated by Unique3D from single-view wild images in 30 seconds.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">More features</h2><a id="user-content-more-features" aria-label="Permalink: More features" href="#more-features"></a></p>
<p dir="auto">The repo is still being under construction, thanks for your patience.</p>
<ul>
<li> Upload weights.</li>
<li> Local gradio demo.</li>
<li> Detailed tutorial.</li>
<li> Huggingface demo.</li>
<li> Detailed local demo.</li>
<li> Comfyui support.</li>
<li> Windows support.</li>
<li> Docker support.</li>
<li> More stable reconstruction with normal.</li>
<li> Training code release.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Preparation for inference</h2><a id="user-content-preparation-for-inference" aria-label="Permalink: Preparation for inference" href="#preparation-for-inference"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Linux System Setup.</h3><a id="user-content-linux-system-setup" aria-label="Permalink: Linux System Setup." href="#linux-system-setup"></a></p>
<p dir="auto">Adapted for Ubuntu 22.04.4 LTS and CUDA 12.1.</p>
<div data-snippet-clipboard-copy-content="conda create -n unique3d python=3.11
conda activate unique3d

pip install ninja
pip install diffusers==0.27.2

pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu121/torch2.3.1/index.html

pip install -r requirements.txt"><pre lang="angular2html"><code>conda create -n unique3d python=3.11
conda activate unique3d

pip install ninja
pip install diffusers==0.27.2

pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu121/torch2.3.1/index.html

pip install -r requirements.txt
</code></pre></div>
<p dir="auto"><a href="https://github.com/oak-barry">oak-barry</a> provide another setup script for torch210+cu121 at <a href="https://github.com/oak-barry/Unique3D">here</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Windows Setup.</h3><a id="user-content-windows-setup" aria-label="Permalink: Windows Setup." href="#windows-setup"></a></p>
<ul dir="auto">
<li>Thank you very much <code>jtydhr88</code> for the windows installation method! See <a href="https://github.com/AiuniAI/Unique3D/issues/15" data-hovercard-type="issue" data-hovercard-url="/AiuniAI/Unique3D/issues/15/hovercard">issues/15</a>.</li>
</ul>
<p dir="auto">According to <a href="https://github.com/AiuniAI/Unique3D/issues/15" data-hovercard-type="issue" data-hovercard-url="/AiuniAI/Unique3D/issues/15/hovercard">issues/15</a>, implemented a bat script to run the commands, so you can:</p>
<ol dir="auto">
<li>Might still require Visual Studio Build Tools, you can find it from <a href="https://visualstudio.microsoft.com/downloads/?q=build+tools" rel="nofollow">Visual Studio Build Tools</a>.</li>
<li>Create conda env and activate it
<ol dir="auto">
<li><code>conda create -n unique3d-py311 python=3.11</code></li>
<li><code>conda activate unique3d-py311</code></li>
</ol>
</li>
<li>download <a href="https://huggingface.co/madbuda/triton-windows-builds/resolve/main/triton-2.1.0-cp311-cp311-win_amd64.whl" rel="nofollow">triton whl</a> for py311, and put it into this project.</li>
<li>run <strong>install_windows_win_py311_cu121.bat</strong></li>
<li>answer y while asking you uninstall onnxruntime and onnxruntime-gpu</li>
<li>create the output folder <strong>tmp\gradio</strong> under the driver root, such as F:\tmp\gradio for me.</li>
<li>python app/gradio_local.py --port 7860</li>
</ol>
<p dir="auto">More details prefer to <a href="https://github.com/AiuniAI/Unique3D/issues/15" data-hovercard-type="issue" data-hovercard-url="/AiuniAI/Unique3D/issues/15/hovercard">issues/15</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Interactive inference: run your local gradio demo.</h3><a id="user-content-interactive-inference-run-your-local-gradio-demo" aria-label="Permalink: Interactive inference: run your local gradio demo." href="#interactive-inference-run-your-local-gradio-demo"></a></p>
<ol dir="auto">
<li>Download the weights from <a href="https://huggingface.co/spaces/Wuvin/Unique3D/tree/main/ckpt" rel="nofollow">huggingface spaces</a> or <a href="https://cloud.tsinghua.edu.cn/d/319762ec478d46c8bdf7/" rel="nofollow">Tsinghua Cloud Drive</a>, and extract it to <code>ckpt/*</code>.</li>
</ol>
<div data-snippet-clipboard-copy-content="Unique3D
    ├──ckpt
        ├── controlnet-tile/
        ├── image2normal/
        ├── img2mvimg/
        ├── realesrgan-x4.onnx
        └── v1-inference.yaml"><pre><code>Unique3D
    ├──ckpt
        ├── controlnet-tile/
        ├── image2normal/
        ├── img2mvimg/
        ├── realesrgan-x4.onnx
        └── v1-inference.yaml
</code></pre></div>
<ol start="2" dir="auto">
<li>Run the interactive inference locally.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python app/gradio_local.py --port 7860"><pre>python app/gradio_local.py --port 7860</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">ComfyUI Support</h2><a id="user-content-comfyui-support" aria-label="Permalink: ComfyUI Support" href="#comfyui-support"></a></p>
<p dir="auto">Thanks for the <a href="https://github.com/jtydhr88/ComfyUI-Unique3D">ComfyUI-Unique3D</a> implementation from <a href="https://github.com/jtydhr88">jtydhr88</a>!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tips to get better results</h2><a id="user-content-tips-to-get-better-results" aria-label="Permalink: Tips to get better results" href="#tips-to-get-better-results"></a></p>
<ol dir="auto">
<li>Unique3D is sensitive to the facing direction of input images. Due to the distribution of the training data, orthographic front-facing images with a rest pose always lead to good reconstructions.</li>
<li>Images with occlusions will cause worse reconstructions, since four views cannot cover the complete object. Images with fewer occlusions lead to better results.</li>
<li>Pass an image with as high a resolution as possible to the input when resolution is a factor.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgement</h2><a id="user-content-acknowledgement" aria-label="Permalink: Acknowledgement" href="#acknowledgement"></a></p>
<p dir="auto">We have intensively borrowed code from the following repositories. Many thanks to the authors for sharing their code.</p>
<ul dir="auto">
<li><a href="https://github.com/CompVis/stable-diffusion">Stable Diffusion</a></li>
<li><a href="https://github.com/xxlong0/Wonder3D">Wonder3d</a></li>
<li><a href="https://github.com/SUDO-AI-3D/zero123plus">Zero123Plus</a></li>
<li><a href="https://github.com/Profactor/continuous-remeshing">Continues Remeshing</a></li>
<li><a href="https://github.com/YertleTurtleGit/depth-from-normals">Depth from Normals</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Collaborations</h2><a id="user-content-collaborations" aria-label="Permalink: Collaborations" href="#collaborations"></a></p>
<p dir="auto">Our mission is to create a 4D generative model with 3D concepts. This is just our first step, and the road ahead is still long, but we are confident. We warmly invite you to join the discussion and explore potential collaborations in any capacity. <span><strong>If you're interested in connecting or partnering with us, please don't hesitate to reach out via email (<a href="mailto:wkl22@mails.tsinghua.edu.cn">wkl22@mails.tsinghua.edu.cn</a>)</strong></span>.</p>
<ul dir="auto">
<li>Follow us on twitter for the latest updates: <a href="https://x.com/aiuni_ai" rel="nofollow">https://x.com/aiuni_ai</a></li>
<li>Join AIGC 3D/4D generation community on discord: <a href="https://discord.gg/aiuni" rel="nofollow">https://discord.gg/aiuni</a></li>
<li>Research collaboration, please contact: <a href="mailto:ai@aiuni.ai">ai@aiuni.ai</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<p dir="auto">If you found Unique3D helpful, please cite our report:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@misc{wu2024unique3d,
      title={Unique3D: High-Quality and Efficient 3D Mesh Generation from a Single Image}, 
      author={Kailu Wu and Fangfu Liu and Zhihan Cai and Runjie Yan and Hanyang Wang and Yating Hu and Yueqi Duan and Kaisheng Ma},
      year={2024},
      eprint={2405.20343},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}"><pre><span>@misc</span>{<span>wu2024unique3d</span>,
      <span>title</span>=<span><span>{</span>Unique3D: High-Quality and Efficient 3D Mesh Generation from a Single Image<span>}</span></span>, 
      <span>author</span>=<span><span>{</span>Kailu Wu and Fangfu Liu and Zhihan Cai and Runjie Yan and Hanyang Wang and Yating Hu and Yueqi Duan and Kaisheng Ma<span>}</span></span>,
      <span>year</span>=<span><span>{</span>2024<span>}</span></span>,
      <span>eprint</span>=<span><span>{</span>2405.20343<span>}</span></span>,
      <span>archivePrefix</span>=<span><span>{</span>arXiv<span>}</span></span>,
      <span>primaryClass</span>=<span><span>{</span>cs.CV<span>}</span></span>
}</pre></div>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>