(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 28 Sep 2025 13:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Why I gave the world wide web away for free (118 pts)]]></title>
            <link>https://www.theguardian.com/technology/2025/sep/28/why-i-gave-the-world-wide-web-away-for-free</link>
            <guid>45403501</guid>
            <pubDate>Sun, 28 Sep 2025 11:17:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2025/sep/28/why-i-gave-the-world-wide-web-away-for-free">https://www.theguardian.com/technology/2025/sep/28/why-i-gave-the-world-wide-web-away-for-free</a>, See on <a href="https://news.ycombinator.com/item?id=45403501">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><span>I</span> was 34 years old when I first had the idea for the world wide web. I took every opportunity to talk about it: pitching it in meetings, sketching it out on a whiteboard for anyone who was interested, even drawing the web in the snow with a ski pole for my friend on what was meant to be a peaceful day out.</p><p>I relentlessly petitioned bosses at the European Organization for Nuclear Research (Cern), where I worked at the time, who initially found the idea <em>“</em>a little eccentric<em>” </em>but eventually gave in and let me work on it.<em> </em>I was seized by the idea of combining two pre-existing computer technologies: the internet and hypertext, which takes an ordinary document and brings it to life by adding “links”.</p><p>I believed that giving users such a simple way to navigate the internet would unlock creativity and collaboration on a global scale. If you could put anything on it, then after a while, it would have everything on it.</p><p>But for the web to have everything on it, everyone had to be able to use it, and want to do so. This was already asking a lot. I couldn’t also ask that they pay for each search or upload they made. In order to succeed, therefore, it would have to be free. That’s why, in 1993, I convinced my Cern managers to donate the intellectual property of the world wide web, putting it into the public domain. We gave the web away to everyone.</p><p>Today, I look at my invention and I am forced to ask: is the web still free today? No, not all of it. We see a handful of large platforms harvesting users’ private data to share with commercial brokers or even repressive&nbsp;governments. We see ubiquitous algorithms that are addictive by design and damaging to our teenagers’ mental health. Trading personal data for use certainly&nbsp;does not fit with my vision for a free web.</p><p>On many platforms, we are no longer the customers, but instead have become the product. Our data, even if anonymised, is sold on to actors we never intended it to reach, who can then target us with content and&nbsp;advertising. This includes deliberately harmful content that leads to real-world violence, spreads misinformation, wreaks havoc on our psychological wellbeing and seeks to undermine social cohesion.</p><p>We have the technical capability to give that power back to the individual. <a href="https://solidproject.org/" data-link-name="in body link">Solid</a> is an open-source interoperable standard that I and my team developed at MIT more than a decade ago. Apps running on Solid don’t implicitly own your data – they have to request it from you and you choose whether to agree, or not. Rather than being in countless separate places on the internet in the hands of whomever it had been resold to, your data is in one place, controlled by you.</p><p>Sharing your information in a smart way can also liberate it. Why is your smartwatch writing your biological data to one silo in one format? Why is your credit card writing your financial data to a second silo in a different format? Why are your YouTube comments, Reddit posts, Facebook updates and tweets all stored in different places? Why is the default expectation that you aren’t supposed to be able to look at any of this stuff? You generate all this data – your actions, your choices, your body, your preferences, your decisions. You should own it. You should be empowered&nbsp;by it.</p><p>Somewhere between my original vision for web 1.0 and the rise of social media as part of web 2.0, we took the wrong path. We’re now at a new crossroads, one where we must decide if AI will be used for the betterment or to the detriment of society. How can we learn from the mistakes of the past? First of all, we must ensure policymakers do not end up playing the same decade-long game of catchup they have done over social media. The time to decide the governance model for AI was yesterday, so we must act with urgency.</p><p>In 2017, I wrote a thought experiment about an AI that works for <em>you</em>. I called it <a href="https://www.w3.org/DesignIssues/Works.html" data-link-name="in body link">Charlie</a>. Charlie works for you like your doctor or your lawyer, bound by law, regulation and codes of conduct. Why can’t the same frameworks be adopted for AI? We have learned from social media that power rests with the monopolies who control and harvest personal data. We can’t let the same thing happen with AI.</p><p>So how do we move forward? Part of the frustration with democracy in the 21st century is that governments have been too slow to meet the demands of digital citizens. The AI industry landscape is fiercely competitive, and development and governance are dictated by companies. The lesson from social media is that this will not create value for the individual.</p><p>I coded the world wide web on a single computer in a small room. But that small room didn’t belong to me, it was at Cern. Cern was created in the aftermath of the second world war by the UN and European governments who identified a historic, scientific turning point that required international collaboration. It is hard to imagine a big tech company agreeing to share the world wide web for no commercial reward like Cern allowed me to. That’s why we need a Cern-like not-for-profit body driving forward international AI research.</p><p>I gave the world wide web away for free because I thought that it would only work if it worked for everyone. Today, I believe that to be truer than ever. Regulation and global governance are technically feasible, but reliant on political willpower. If we are able to muster it, we have the chance to restore the web as a tool for collaboration, creativity and compassion across cultural borders. We can re-empower individuals, and take the web back. It’s not too late.</p><p><span data-dcr-style="bullet"></span> Tim Berners-Lee is the author of <a href="https://thisisforeveryone.timbl.com/" data-link-name="in body link">This Is for Everyone</a> <em>(Macmillan</em><em>).</em></p><h2 id="further-reading"><strong>Further reading</strong></h2><p><a href="https://guardianbookshop.com/innovators-9781471138805/?utm_source=editoriallink&amp;amp;utm_medium=merch&amp;amp;utm_campaign=article" data-link-name="in body link">The Innovators</a> by Walter Isaacson (Simon &amp; Schuster, £10.99)</p><p><a href="https://guardianbookshop.com/the-web-we-weave-9781541604124/?utm_source=editoriallink&amp;amp;utm_medium=merch&amp;amp;utm_campaign=article" data-link-name="in body link">The Web We Weave</a> by Jeff Jarvis (Basic, £25)</p><p><a href="https://guardianbookshop.com/the-history-of-the-internet-in-byte-sized-chunks-9781789295597/?utm_source=editoriallink&amp;amp;utm_medium=merch&amp;amp;utm_campaign=article" data-link-name="in body link">The History of the Internet in Byte-Sized Chunks</a> by Chris Stokel-Walker (Michael O’Mara, £12.99)</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Solar panels + cold = A potential problem (113 pts)]]></title>
            <link>https://www.linspyre.com/ecoholics/temps.html</link>
            <guid>45401051</guid>
            <pubDate>Sun, 28 Sep 2025 01:48:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.linspyre.com/ecoholics/temps.html">https://www.linspyre.com/ecoholics/temps.html</a>, See on <a href="https://news.ycombinator.com/item?id=45401051">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <figcaption>Photo Credit: Kevin L @ EcoFlow DELTA Facebook Group</figcaption>
    <h2>Do Not Do This...Unless You Want Magic Black Smoke</h2>
    <p>You purchased a new Delta Pro and looked up the
    <a href="https://www.linspyre.com/ecoholics/specs.html" target="_blank">specifications</a> - Delta Pro can take up to 1600w/150v/15a of solar input. Then you buy four EcoFlow 400w Rigid solar panels
    to plug them in series.</p>
    <p>You check the math</p>
    <p>37.1v VoC × 4 panels = 148.4v</p>
    <p>... just under the 150v Delta Pro solar input limit. The new solar array is right at the watt limit, just under the volt limit, and a little under the amp limit.
    You think you are good to go, right?</p><p><span>Wrong!!!</span></p>
    <p>This will likely create black magic smoke from your solar generator on the first cold and sunny day.
    This is because solar panel voltages increase as temperatures drop. We see many complaints from newbee EcoFlow customers
    who are all excited with their new toy, they proceed destroy their MPPT controller, then complain bitterly on social media about
    EcoFlow's customer support and voided warranty policy. Plugging in four 400w solar panels in series is similar to filling your gasoline powered
    car with diesel and wondering why the car manufacturer isn't replacing your new car.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bonding twelve 56K modems together to set dial-up broadband records (102 pts)]]></title>
            <link>https://www.tomshardware.com/networking/enthusiasts-bond-twelve-56k-dial-up-modems-together-to-set-dial-up-broadband-records-a-dozen-screeching-boxes-achieve-record-668-kbps-download-speeds</link>
            <guid>45400828</guid>
            <pubDate>Sun, 28 Sep 2025 00:59:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/networking/enthusiasts-bond-twelve-56k-dial-up-modems-together-to-set-dial-up-broadband-records-a-dozen-screeching-boxes-achieve-record-668-kbps-download-speeds">https://www.tomshardware.com/networking/enthusiasts-bond-twelve-56k-dial-up-modems-together-to-set-dial-up-broadband-records-a-dozen-screeching-boxes-achieve-record-668-kbps-download-speeds</a>, See on <a href="https://news.ycombinator.com/item?id=45400828">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>


<div id="article-body">
<p id="ad8b068f-18a1-4e4c-9734-78dd200b7943">The latest episode published by tech channel <a data-analytics-id="inline-link" href="https://www.youtube.com/watch?v=LZ259Jx8MQY" data-url="https://www.youtube.com/watch?v=LZ259Jx8MQY" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">The Serial Port</a> began with an interesting question: Is it possible to stream YouTube via dial-up internet? As the headline suggests, the answer is a resounding yes, with our intrepid heroes managing to establish a connection offering download speeds of 668.8 kbps. The feat was eventually achieved using an era-appropriate Windows XP PC, a Cisco VoIP unit, a couple of serial port packing PCI cards, and a dozen 56K modems bonded using Multilink PPP (MPPP) technology. This is probably a world record.</p><figure data-bordeaux-image-check="" id="8633c508-a059-4e2a-aa3c-b9a06a82b171"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge.jpg" alt="Broadband using 56K dial-up modems" srcset="https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/tbBDF6FdgrsgxL44yJh4Ge.jpg">
</picture></p></div><figcaption itemprop="caption description"><span>success! </span><span itemprop="copyrightHolder">(Image credit: &nbsp;<a href="https://www.youtube.com/watch?v=LZ259Jx8MQY" data-url="https://www.youtube.com/watch?v=LZ259Jx8MQY" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">The Serial Port</a>)</span></figcaption></figure><h2 id="when-broadband-wasn-t-so-broad-3">When broadband wasn’t so broad</h2><p id="ce08e175-c9a0-4bf7-8793-4bf7cbc2a9fb">The latest regulations from the FCC define <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/broadband-internet-prices-speed-us-comparison" data-before-rewrite-localise="https://www.tomshardware.com/news/broadband-internet-prices-speed-us-comparison">broadband </a>as 100 Mbps or higher, but in 2000, a far slower connection of 200 Kbps or higher was considered adequate to earn the designation. Back then, connectivity was slow, but by the turn of the millennium, websites and communications were simpler and had lower bandwidth. For example, downloading multimedia files like MP3s back then could tie up your phone line for 10 to 20 minutes. Thus, applications like the infamous Napster and emerging streaming video and online multimedia experiences begged for broadband.</p><p id="ce08e175-c9a0-4bf7-8793-4bf7cbc2a9fb-1">Multilink PPP technology was one possible solution to faster internet connectivity before ISDN and ADSL connectivity became widespread. As the name suggests, MPPP tech combines the bandwidth of multiple <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/apples-modems-are-three-years-behind-qualcomm-report" data-before-rewrite-localise="https://www.tomshardware.com/news/apples-modems-are-three-years-behind-qualcomm-report">modems </a>to create a single logical data pipe.</p><p>Commercial solutions like “the Diamond Multimedia Shotgun, a PCI card with two onboard modems that could be bonded together using multilink PPP,” leveraged this tech, point out the YouTubers. However, it didn’t gain traction due to the multiple lines and ISP shenanigans required.</p><p>Now, with an ISP that supports digital modems and the equipment (including a Cisco VoIP gateway) to make it happen, The Serial Port had an opportunity to see how far Multilink PPP can go. Encouragingly, the official MPPP standard doesn’t highlight any practical limits…</p><h2 id="cover-your-ears-preparing-for-screeching-modem-broadband-3">Cover your ears - Preparing for screeching modem broadband</h2><p id="ea6e6f0b-2ed5-436d-8d2b-0a80a6d4164b">Refocusing on the overarching YouTube streaming goal, our intrepid TechTubers calculated how much bandwidth would need to be squeezed out of their bonded modem array to make streaming tolerable. In brief, ~four 56K modems should be sufficient for minimum-quality desktop streaming (240p, ~200 kbps) in 2025.</p><p>The first client PC chosen was a 2001-vintage <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/ibm" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/ibm">IBM</a> desktop with Windows ME, released just ahead of the widespread availability of broadband. This setup worked with two 56K modems bonded together—a promising start.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-A78rnrL7MDW7YovDDCio4S"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div><p>With the proof that MPPP worked on this contemporaneous PC system, the TechTubers sought to pack more serial ports into the IBM. A card featuring an extra eight serial ports was found. However, driver clashes prevented further scaling…</p><p>Still optimistic about their project, the team moved up to “slightly newer hardware.” Specifically, an IBM Think Center from 2004 was chosen as a compromise, as we did not want to go too modern. <a data-analytics-id="inline-link" href="https://www.tomshardware.com/software/windows/40-years-of-windows-how-windows-xp-changed-everything" data-before-rewrite-localise="https://www.tomshardware.com/software/windows/40-years-of-windows-how-windows-xp-changed-everything">Windows XP</a> was pre-installed on this system, and it was hoped that it could do better with MPPP.</p><p>Using the newer XP PC, two identical serial expansion cards were installed. However, they didn’t work together, as they overlapped COM port addresses in the Device Manager. So the TechTubers switched to a different brand of serial expansion card for the second card. They ended up with 13 ports in total (including the one on the motherboard).</p><figure data-bordeaux-image-check="" id="939a627f-4eed-4420-ad22-7897c56e7624"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe.jpg" alt="Broadband using 56K dial-up modems" srcset="https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe.jpg">
</picture><a href="https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe.jpg" target="_blank" data-url="https://cdn.mos.cms.futurecdn.net/5QyoWmdTNq6ojA22QLyQGe.jpg" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"></a></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: &nbsp;<a href="https://www.youtube.com/watch?v=LZ259Jx8MQY" data-url="https://www.youtube.com/watch?v=LZ259Jx8MQY" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">The Serial Port</a>)</span></figcaption></figure><h2 id="the-dusty-dozen-3">The dusty dozen</h2><p id="9ff16b99-222f-4eb5-af05-efb0eae1cf4c">Unlike with Windows ME, where each modem was dialed in turn, it was observed that XP dialed them all simultaneously! Moreover, the team successfully scaled up from two modems to 12 after several rounds of fiddling with modem DIP switches, phone line connectors, and XP’s serial port controls. As more modems were added to the system, the TechTubers laughed joyously at the sound of multiple modems dialing and negotiating.</p><p>The dozen modems connected to the Windows XP machine achieved a combined connection speed of 668.8 kbps, offering blistering download speeds. Testing confirmed that this system was able to load and stream <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/youtube-responds-to-delayed-loading-in-rival-browser-complaints" data-before-rewrite-localise="https://www.tomshardware.com/news/youtube-responds-to-delayed-loading-in-rival-browser-complaints">YouTube</a> videos, and no buffering was observed after a slight delay (likely due to the old PC's processing power).</p><p>Did The Serial Port achieve a world record? The TechTubers couldn’t find any accounts of people using more than four modems in MPPP at the same time. The video ends with a tease that they haven’t yet found a limit to MPPP…</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank" data-url="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank" data-url="https://google.com/preferences/source?q=" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p>
</div>



<!-- Drop in a standard article here maybe? -->



<div id="slice-container-authorBio-A78rnrL7MDW7YovDDCio4S"><p>Mark Tyson is a news editor at Tom's Hardware. He enjoys covering the full breadth of PC tech; from business and semiconductor design to products approaching the edge of reason.</p></div>
</section>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Learn to play Go (229 pts)]]></title>
            <link>https://online-go.com/learn-to-play-go</link>
            <guid>45400376</guid>
            <pubDate>Sat, 27 Sep 2025 23:50:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://online-go.com/learn-to-play-go">https://online-go.com/learn-to-play-go</a>, See on <a href="https://news.ycombinator.com/item?id=45400376">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="loading-svg-container" role="status" aria-live="polite"><p><span>Loading...</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The (economic) AI apocalypse is nigh (114 pts)]]></title>
            <link>https://pluralistic.net/2025/09/27/econopocalypse/</link>
            <guid>45399893</guid>
            <pubDate>Sat, 27 Sep 2025 22:30:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pluralistic.net/2025/09/27/econopocalypse/">https://pluralistic.net/2025/09/27/econopocalypse/</a>, See on <a href="https://news.ycombinator.com/item?id=45399893">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-11677">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
ai, business models, economics, bubbles, ai apocalypse, ai econopocalypse, econopocalypse

Summary:
The real (economic) AI apocalypse is nigh; Hey look at this; Upcoming appearances; Recent appearances; Latest books; Upcoming books

URL:
https://pluralistic.net/2025/09/27/econopocalypse/

Title:
Pluralistic: The real (economic) AI apocalypse is nigh (27 Sep 2025) econopocalypse

Bullet:
🔋

Separator:
⠂⠄⠄⠂⠁⠁⠂⠄⠄⠂⠁⠁⠂⠄⠄⠂ ⠂⠄⠄⠂⠂⠄⠄⠂⠁⠁⠂⠄⠄⠂⠁⠁⠂⠄⠄⠂ ⠂⠄⠄⠂⠂⠄⠄⠂⠁⠁⠂⠄

Top Sources:
Today's top sources: James Boyle (https://www.thepublicdomain.org/).

--><br>
<a href="https://pluralistic.net/2025/09/27/econopocalypse/"><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/27Sep2025.jpg?w=840&amp;ssl=1"></a></p>
<h2>Today's links</h2>
<ul>
<li><a href="https://pluralistic.net/2025/09/27/econopocalypse/#subprime-intelligence">The real (economic) AI apocalypse is nigh</a>: Sweating (the assets) to the oldies.
</li>
<li><a href="https://pluralistic.net/2025/09/27/econopocalypse/#linkdump">Hey look at this</a>: Delights to delectate.
</li>
<li><a href="https://pluralistic.net/2025/09/27/econopocalypse/#retro">Object permanence</a>: Dying on the job; Google audiocomplete blacklist; Lockheed Martin v. 'gathering information.'
</li>
<li><a href="https://pluralistic.net/2025/09/27/econopocalypse/#upcoming">Upcoming appearances</a>: Where to find me.
</li>
<li><a href="https://pluralistic.net/2025/09/27/econopocalypse/#recent">Recent appearances</a>: Where I've been.
</li>
<li><a href="https://pluralistic.net/2025/09/27/econopocalypse/#latest">Latest books</a>: You keep readin' em, I'll keep writin' 'em.
</li>
<li><a href="https://pluralistic.net/2025/09/27/econopocalypse/#upcoming-books">Upcoming books</a>: Like I said, I'll keep writin' 'em.
</li>
<li><a href="https://pluralistic.net/2025/09/27/econopocalypse/#bragsheet">Colophon</a>: All the rest.
</li>
</ul>

<hr>
<p><a name="subprime-intelligence"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A Zimbabwean one hundred trillion dollar bill; the bill's iconography have been replaced with the glaring red eye of HAL 9000 from Stanley Kubrick's '2001: A Space Odyssey' and a stylized, engraving-style portrait of Sam Altman." src="https://i0.wp.com/craphound.com/images/ai-costs.jpg?w=840&amp;ssl=1"></p>
<h2>The real (economic) AI apocalypse is nigh (<a href="https://pluralistic.net/2025/09/27/econopocalypse/#subprime-intelligence">permalink</a>)</h2>
<p>Like you, I'm sick to the back teeth of talking about AI. Like you, I keep getting dragged into discussions of AI. Unlike you‡, I spent the summer writing a book about why I'm sick of writing about AI⹋, which Farrar, Straus and Giroux will publish in 2026.</p>
<p>‡probably</p>
<p>⹋"The Reverse Centaur's Guide to AI"</p>
<p>A week ago, I turned that book into a speech, which I delivered as the annual Nordlander Memorial Lecture at Cornell, where I'm an AD White Professor-at-Large. This was my first-ever speech about AI and I wasn't sure how it would go over, but thankfully, it went great and sparked a lively Q&amp;A. One of those questions came from a young man who said something like "So, you're saying a third of the stock market is tied up in seven AI companies that have no way to become profitable and that this is a bubble that's going to burst and take the whole economy with it?"</p>
<p>I said, "Yes, that's right."</p>
<p>He said, "OK, but what can we do about that?"</p>
<p>So I re-iterated the book's thesis: that the AI bubble is driven by monopolists who've conquered their markets and have no more growth potential, who are desperate to convince investors that they can continue to grow by moving into some other sector, e.g. "pivot to video," crypto, blockchain, NFTs, AI, and now "super-intelligence." Further: the topline growth that AI companies are selling comes from replacing most workers with AI, and re-tasking the surviving workers as AI babysitters ("humans in the loop"), which won't work. Finally: AI <em>cannot</em> do your job, but an AI salesman can <em>100%</em> convince your boss to fire you and replace you with an AI that <em>can't</em> do your job, and when the bubble bursts, the money-hemorrhaging "foundation models" will be shut off and we'll lose the AI that can't do your job, <em>and</em> you will be long gone, retrained or retired or "discouraged" and out of the labor market, and <em>no one</em> will do your job. AI is the asbestos we are shoveling into the walls of our society and our descendants will be digging it out for generations:</p>
<p><a href="https://pluralistic.net/2025/05/27/rancid-vibe-coding/#class-war">https://pluralistic.net/2025/05/27/rancid-vibe-coding/#class-war</a></p>
<p>The only thing (I said) that we can do about this is to puncture the AI bubble <em>as soon as possible</em>, to halt this before it progresses any further and to head off the accumulation of social and economic debt. To do that, we have to take aim at the <em>material basis</em> for the AI bubble (creating a growth story by claiming that defective AI can do your job).</p>
<p>"OK," the young man said, "but what can we <em>do</em> about the crash?" He was clearly very worried.</p>
<p>"I don't think there's anything we can do about that. I think it's already locked in. I mean, maybe if we had a different government, they'd fund a jobs guarantee to pull us out of it, but I don't think Trump'll do that, so –"</p>
<p>"But what can we <em>do?</em>"</p>
<p>We went through a few rounds of this, with this poor kid just repeating the same question in different tones of voice, like an acting coach demonstrating the five stages of grieving using nothing but inflection. It was an uncomfortable moment, and there was some decidedly nervous chuckling around the room as we pondered the coming AI (economic) apocalypse, and the fate of this kid graduating with mid-six-figure debts into an economy of ashes and rubble.</p>
<p>I firmly believe the (economic) AI apocalypse is coming. These companies are not profitable. They can't be profitable. They keep the lights on by soaking up hundreds of billions of dollars in other people's money and then lighting it on fire. Eventually those other people are going to want to see a return on their investment, and when they don't get it, they will halt the flow of billions of dollars. Anything that can't go on forever eventually stops.</p>
<p>This isn't like the early days of the web, or Amazon, or any of those other big winners that lost money before becoming profitable. Those were all propositions with excellent "unit economics" – they got cheaper with every successive technological generation, and the more customers they added, the more profitable they became. AI companies have – in the memorable phraseology of Ed Zitron – "dogshit unit-economics." Each generation of AI has been vastly more expensive than the previous one, and each new AI customer makes the AI companies lose <em>more</em> money:</p>
<p><a href="https://pluralistic.net/2025/06/30/accounting-gaffs/#artificial-income">https://pluralistic.net/2025/06/30/accounting-gaffs/#artificial-income</a></p>
<p>This week, no less than the <em>Wall Street Journal</em> published a lengthy, well-reported story (by Eliot Brown and Robbie Whelan) on the catastrophic finances of AI companies:</p>
<p><a href="https://www.wsj.com/tech/ai/ai-bubble-building-spree-55ee6128?st=efV1EF&amp;amp;reflink=article_email_share">https://www.wsj.com/tech/ai/ai-bubble-building-spree-55ee6128?st=efV1EF&amp;amp;reflink=article_email_share</a></p>
<p>The <em>WSJ</em> writers compare the AI bubble to other bubbles, like Worldcom's fraud-soaked fiber optic bonanza (which saw the company's CEO sent to prison, where he eventually died), and conclude that the AI bubble is <em>vastly</em> larger than any other bubble in recent history.</p>
<p>The data-center buildout has genuinely absurd finances – there are data-center companies that are collateralizing their loans by staking their giant Nvidia GPUs as collateral. This is wild: there's pretty much nothing (apart from fresh-caught fish) that loses its value faster than silicon chips. That goes <em>triple</em> for GPUs used in AI data-centers, where it's normal for tens of thousands of chips to burn out over a single, 54-day training run:</p>
<p><a href="https://techblog.comsoc.org/2024/11/25/superclusters-of-nvidia-gpu-ai-chips-combined-with-end-to-end-network-platforms-to-create-next-generation-data-centers/">https://techblog.comsoc.org/2024/11/25/superclusters-of-nvidia-gpu-ai-chips-combined-with-end-to-end-network-platforms-to-create-next-generation-data-centers/</a></p>
<p>Talk about sweating your assets!</p>
<p>That barely scratches the surface of the funny accounting in the AI bubble. Microsoft "invests" in Openai by giving the company free access to its servers. Openai reports this as a ten billion dollar investment, then redeems these "tokens" at Microsoft's data-centers. Microsoft then books this as ten billion in revenue.</p>
<p>That's par for the course in AI, where it's normal for Nvidia to "invest" tens of billions in a data-center company, which then spends that investment buying Nvidia chips. The the same chunk of money being energetically passed back and forth between these closely related companies, all of which claim it as investment, as an asset, or as revenue (or all three).</p>
<p>The <em>Journal</em> quotes David Cahn, a VC from Sequoia, who says that for AI companies to become profitable, they would have to sell us <em>$800 billion</em> worth of services <em>over the life of today's data centers and GPUs</em>. Not only is that a very large number – it's also a very short time. AI bosses themselves will tell you that these data centers and GPUs will be obsolete practically from the moment they start operating. Mark Zuckerberg says he's prepared to waste "a couple hundred billion dollars" on misspent AI investments:</p>
<p><a href="https://www.businessinsider.com/mark-zuckerberg-meta-risk-billions-miss-superintelligence-ai-bubble-2025-9">https://www.businessinsider.com/mark-zuckerberg-meta-risk-billions-miss-superintelligence-ai-bubble-2025-9</a></p>
<p>Bain &amp; Co says that the only way to make today's AI investments profitable is for the sector to bring in <em>$2 trillion</em> by 2030 (the <em>Journal</em> notes that this is more than the combined revenue of Amazon, Google, Microsoft, Apple Nvidia and Meta):</p>
<p><a href="https://www.bain.com/about/media-center/press-releases/20252/$2-trillion-in-new-revenue-needed-to-fund-ais-scaling-trend---bain--companys-6th-annual-global-technology-report/">https://www.bain.com/about/media-center/press-releases/20252/$2-trillion-in-new-revenue-needed-to-fund-ais-scaling-trend—bain–companys-6th-annual-global-technology-report/</a></p>
<p>How much money is the AI industry making? Morgan Stanley says it's $45b/year. But that $45b is based on the AI industry's own exceedingly cooked books, where <em>annual</em> revenue is actually <em>annualized</em> revenue, an accounting scam whereby a company chooses its best single revenue month and multiplies it by 12, even if that month is a wild outlier:</p>
<p><a href="https://www.wheresyoured.at/the-haters-gui/">https://www.wheresyoured.at/the-haters-gui/</a></p>
<p>Industry darlings like Coreweave (a middleman that rents out data-centers) are sitting on <em>massive</em> piles of debt, secured by short-term deals with tech companies that run out <em>long</em> before the debts can be repaid. If they can't find a bunch of new clients in a couple short years, they will default and collapse.</p>
<p>Today's AI bubble has absorbed more of the country's wealth and represents more of its economic activity than historic nation-shattering bubbles, like the 19th century UK rail bubble. A much-discussed MIT paper found that 95% of companies that had tried AI had either nothing to show for it, or experienced a loss:</p>
<p><a href="https://www.technologyreview.com/2019/01/25/1436/we-analyzed-16625-papers-to-figure-out-where-ai-is-headed-next/">https://www.technologyreview.com/2019/01/25/1436/we-analyzed-16625-papers-to-figure-out-where-ai-is-headed-next/</a></p>
<p>A less well-known U Chicago paper finds that AI has "no significant impact on workers’ earnings, recorded hours, or wages":</p>
<p><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5219933">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5219933</a></p>
<p>Anything that can't go on forever eventually stops. Trump might bail out the AI companies, but for how long? They are incinerating money faster than practically any other human endeavor in history, with precious little to show for it.</p>
<p>During my stay at Cornell, one of the people responsible for the university's AI strategy asked me what I thought the university should be doing about AI. I told them that they should be planning to absorb the productive residue that will be left behind after the bubble bursts:</p>
<p><a href="https://locusmag.com/feature/commentary-cory-doctorow-what-kind-of-bubble-is-ai/">https://locusmag.com/feature/commentary-cory-doctorow-what-kind-of-bubble-is-ai/</a></p>
<p>Plan for a future where you can buy GPUs for ten cents on the dollar, where there's a buyer's market for hiring skilled applied statisticians, and where there's a ton of extremely promising open source models that have barely been optimized and have <em>vast</em> potential for improvement.</p>
<p>There's plenty of useful things you can do with AI. But AI is (as Princeton's Arvind Narayanan and Sayash Kapoor, authors of <em>AI Snake Oil</em> put it), a <em>normal</em> technology:</p>
<p><a href="https://knightcolumbia.org/content/ai-as-normal-technology">https://knightcolumbia.org/content/ai-as-normal-technology</a></p>
<p>That doesn't mean "nothing to see here, move on." It means that AI isn't the bow-wave of "impending superintelligence." Nor is it going to deliver "humanlike intelligence."</p>
<p>It's a grab-bag of useful (sometimes very useful) tools that can sometimes make workers' lives better, when workers get to decide how and when they're used.</p>
<p>The most important thing about AI isn't its technical capabilities or limitations. The most important thing is the investor story and the ensuing mania that has teed up an economical catastrophe that will harm hundreds of millions or even billions of people. AI isn't going to wake up, become superintelligent and turn you into paperclips – but rich people with AI investor psychosis are almost certainly going to make you much, much poorer.</p>
<p>(<i>Image: <a href="https://commons.wikimedia.org/wiki/File:Sam_Altman_-_TechCrunch_Disrupt_SF_2017_(36522988343).jpg">TechCrunch</a>, <a href="https://creativecommons.org/licenses/by/2.0/deed.en">CC BY 2.0</a>; <a href="https://commons.wikimedia.org/wiki/File:HAL9000.svg">Cryteria</a>, <a href="https://creativecommons.org/licenses/by/3.0/deed.en">CC BY 3.0</a>; modified</i>)</p>
<hr>

<h2 heds="0">Hey look at this (<a href="https://pluralistic.net/2025/09/27/econopocalypse/#linkdump">permalink</a>)</h2>
<p><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/heylookatthis2.jpg?w=840&amp;ssl=1"></p>
<ul>
<li>EU ministers reach 'compromise' on digital euro roadmap <a href="https://www.reuters.com/business/finance/eu-ministers-seek-agreement-digital-euro-be-independent-visa-mastercard-2025-09-19/">https://www.reuters.com/business/finance/eu-ministers-seek-agreement-digital-euro-be-independent-visa-mastercard-2025-09-19/</a>
</li>
<li>
<p>Amazon will pay $2.5 billion to settle the FTC’s Prime lawsuit <a href="https://www.theverge.com/news/785744/amazon-ftc-prime-subscription-settlment">https://www.theverge.com/news/785744/amazon-ftc-prime-subscription-settlment</a></p>
</li>
<li>
<p>Conservative Dem Compares Ad About Her Corporate Donations to ‘Political Violence’ <a href="https://prospect.org/politics/2025-09-25-conservative-dem-ad-corporate-donations-violence-bains-california/">https://prospect.org/politics/2025-09-25-conservative-dem-ad-corporate-donations-violence-bains-california/</a></p>
</li>
<li>
<p>Monopoly Utilities Ousted America's Best Regulator <a href="https://economicpopulist.substack.com/p/monopoly-utilities-ousted-americas">https://economicpopulist.substack.com/p/monopoly-utilities-ousted-americas</a></p>
</li>
<li>
<p>WNYC offers free programs to stations affected by funding cuts <a href="https://current.org/2025/09/wnyc-offers-free-programs-to-stations-affected-by-funding-cuts/">https://current.org/2025/09/wnyc-offers-free-programs-to-stations-affected-by-funding-cuts/</a></p>
</li>
</ul>
<hr>
<p><a name="retro"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A shelf of leatherbound history books with a gilt-stamped series title, 'The World's Famous Events.'" src="https://i0.wp.com/craphound.com/images/worlds-famous-events.png?w=840&amp;ssl=1"></p>
<h2 heds="0">Object permanence (<a href="https://pluralistic.net/2025/09/27/econopocalypse/#retro">permalink</a>)</h2>
<p>#20yrsago Financial Times: WIPO’s webcaster treaty is a disaster <a href="https://www.ft.com/content/441306be-2eb6-11da-9aed-00000e2511c8">https://www.ft.com/content/441306be-2eb6-11da-9aed-00000e2511c8</a></p>
<p>#15yrsago Google’s autocomplete blacklist <a href="https://www.2600.com/googleblacklist/">https://www.2600.com/googleblacklist/</a></p>
<p>#15yrsago FBI ignores DoJ report, raids activists, arrests Time Person of the Year <a href="https://www.democracynow.org/2010/9/27/fbi_raids_homes_of_anti_war">https://www.democracynow.org/2010/9/27/fbi_raids_homes_of_anti_war</a></p>
<p>#15yrsago Meta-textual analysis of mainstream science reporting <a href="https://www.theguardian.com/science/the-lay-scientist/2010/sep/24/1">https://www.theguardian.com/science/the-lay-scientist/2010/sep/24/1</a></p>
<p>#15yrsago Lockheed Martin sign prohibits sketching and “gathering information” <a href="https://www.flickr.com/photos/jef/5028187145/">https://www.flickr.com/photos/jef/5028187145/</a></p>
<p>#5yrsago Ransomware for coffee makers <a href="https://pluralistic.net/2020/09/27/junky-styling/#java-script">https://pluralistic.net/2020/09/27/junky-styling/#java-script</a></p>
<p>#5yrsago The joys of tailoring <a href="https://pluralistic.net/2020/09/27/junky-styling/#inseams">https://pluralistic.net/2020/09/27/junky-styling/#inseams</a></p>
<p>#1yrago Return to office and dying on the job <a href="https://pluralistic.net/2024/09/27/sharpen-your-blades-boys/#disciplinary-technology">https://pluralistic.net/2024/09/27/sharpen-your-blades-boys/#disciplinary-technology</a></p>
<hr>

<h2 heds="0">Upcoming appearances (<a href="https://pluralistic.net/2025/09/27/econopocalypse/#upcoming">permalink</a>)</h2>
<p><img data-recalc-dims="1" decoding="async" alt="A photo of me onstage, giving a speech, pounding the podium." src="https://i0.wp.com/craphound.com/images/appearances2.jpg?w=840&amp;ssl=1"></p>
<ul>
<li>Boston: Enshittification with Randall Munroe (Brattle Theater), Oct 7<br>
<a href="https://www.eventbrite.com/e/cory-doctorow-at-the-brattle-theatre-tickets-1591235180259?aff=oddtdtcreator">https://www.eventbrite.com/e/cory-doctorow-at-the-brattle-theatre-tickets-1591235180259?aff=oddtdtcreator</a>
</li>
<li>
<p>DC: Enshittification with Rohit Chopra (Politics and Prose), Oct 8<br>
<a href="https://politics-prose.com/cory-doctorow-10825">https://politics-prose.com/cory-doctorow-10825</a></p>
</li>
<li>
<p>NYC: Enshittification with Lina Khan (Brooklyn Public Library), Oct 9<br>
<a href="https://www.bklynlibrary.org/calendar/cory-doctorow-discusses-central-library-dweck-20251009-0700pm">https://www.bklynlibrary.org/calendar/cory-doctorow-discusses-central-library-dweck-20251009-0700pm</a></p>
</li>
<li>
<p>New Orleans: DeepSouthCon63, Oct 10-12<br>
<a href="http://www.contraflowscifi.org/">http://www.contraflowscifi.org/</a></p>
</li>
<li>
<p>New Orleans: Enshittification at Octavia Books, Oct 12<br>
<a href="https://www.octaviabooks.com/event/enshittification-cory-doctorow">https://www.octaviabooks.com/event/enshittification-cory-doctorow</a></p>
</li>
<li>
<p>Chicago: Enshittification with Anand Giridharadas (Chicago Humanities), Oct 15<br>
<a href="https://www.oldtownschool.org/concerts/2025/10-15-2025-kara-swisher-and-cory-doctorow-on-enshittification/">https://www.oldtownschool.org/concerts/2025/10-15-2025-kara-swisher-and-cory-doctorow-on-enshittification/</a></p>
</li>
<li>
<p>Los Angeles: Enshittification with David Dayen (Diesel), Oct 16<br>
<a href="https://dieselbookstore.com/event/2025-10-16/cory-doctorow-enshittification">https://dieselbookstore.com/event/2025-10-16/cory-doctorow-enshittification</a></p>
</li>
<li>
<p>San Francisco: Enshittification at Public Works with Jenny Odell (The Booksmith), Oct 20<br>
<a href="https://app.gopassage.com/events/doctorow25">https://app.gopassage.com/events/doctorow25</a></p>
</li>
<li>
<p>PDX: Enshittification at Powell's, Oct 21<br>
<a href="https://www.powells.com/events/cory-doctorow-10-21-25">https://www.powells.com/events/cory-doctorow-10-21-25</a></p>
</li>
<li>
<p>Seattle: Enshittification and the Rot Economy, with Ed Zitron (Clarion West), Oct 22<br>
<a href="https://www.clarionwest.org/event/2025-deep-dives-cory-doctorow/">https://www.clarionwest.org/event/2025-deep-dives-cory-doctorow/</a></p>
</li>
<li>
<p>Madrid: Conferencia EUROPEA 4D (Virtual), Oct 28<br>
<a href="https://4d.cat/es/conferencia/">https://4d.cat/es/conferencia/</a></p>
</li>
<li>
<p>Miami: Enshittification at Books &amp; Books, Nov 5<br>
<a href="https://www.eventbrite.com/e/an-evening-with-cory-doctorow-tickets-1504647263469">https://www.eventbrite.com/e/an-evening-with-cory-doctorow-tickets-1504647263469</a></p>
</li>
<li>
<p>Miami: Cloudfest, Nov 6<br>
<a href="https://www.cloudfest.com/usa/">https://www.cloudfest.com/usa/</a></p>
</li>
<li>
<p>Burbank: Burbank Book Festival, Nov 8<br>
<a href="https://www.burbankbookfestival.com/">https://www.burbankbookfestival.com/</a></p>
</li>
</ul>
<hr>
<p><a name="recent"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A screenshot of me at my desk, doing a livecast." src="https://i0.wp.com/craphound.com/images/recentappearances2.jpg?w=840&amp;ssl=1"></p>
<h2 heds="0">Recent appearances (<a href="https://pluralistic.net/2025/09/27/econopocalypse/#recent">permalink</a>)</h2>
<ul>
<li>Enshittification (Cornell)<br>
<a href="https://ecornell.cornell.edu/keynotes/view/K091225/">https://ecornell.cornell.edu/keynotes/view/K091225/</a>
</li>
<li>
<p>Escaping Big Tech, Privacy Battles &amp; “Enshittification” (Revolution.social)<br>
<a href="https://www.youtube.com/watch?v=exvpetQRSVo">https://www.youtube.com/watch?v=exvpetQRSVo</a></p>
</li>
<li>
<p>Nerd Harder! (This Week in Tech)<br>
<a href="https://twit.tv/shows/this-week-in-tech/episodes/1047">https://twit.tv/shows/this-week-in-tech/episodes/1047</a></p>
</li>
</ul>
<hr>
<p><a name="latest"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A grid of my books with Will Stahle covers.." src="https://i0.wp.com/craphound.com/images/recent.jpg?w=840&amp;ssl=1"></p>
<h2 heds="0">Latest books (<a href="https://pluralistic.net/2025/09/27/econopocalypse/#latest">permalink</a>)</h2>
<ul>
<li>"Picks and Shovels": a sequel to "Red Team Blues," about the heroic era of the PC, Tor Books (US), Head of Zeus (UK), February 2025 (<a href="https://us.macmillan.com/books/9781250865908/picksandshovels">https://us.macmillan.com/books/9781250865908/picksandshovels</a>).
</li>
<li>
<p>"The Bezzle": a sequel to "Red Team Blues," about prison-tech and other grifts, Tor Books (US), Head of Zeus (UK), February 2024 (<a href="http://the-bezzle.org/">the-bezzle.org</a>).</p>
</li>
<li>
<p>"The Lost Cause:" a solarpunk novel of hope in the climate emergency, Tor Books (US), Head of Zeus (UK), November 2023 (<a href="http://lost-cause.org/">http://lost-cause.org</a>).</p>
</li>
<li>
<p>"The Internet Con": A nonfiction book about interoperability and Big Tech (Verso) September 2023 (<a href="http://seizethemeansofcomputation.org/">http://seizethemeansofcomputation.org</a>). Signed copies at Book Soup (<a href="https://www.booksoup.com/book/9781804291245">https://www.booksoup.com/book/9781804291245</a>).</p>
</li>
<li>
<p>"Red Team Blues": "A grabby, compulsive thriller that will leave you knowing more about how the world works than you did before." Tor Books <a href="http://redteamblues.com/">http://redteamblues.com</a>.</p>
</li>
<li>
<p>"Chokepoint Capitalism: How to Beat Big Tech, Tame Big Content, and Get Artists Paid, with Rebecca Giblin", on how to unrig the markets for creative labor, Beacon Press/Scribe 2022 <a href="https://chokepointcapitalism.com/">https://chokepointcapitalism.com</a></p>
</li>
</ul>
<hr>
<p><a name="upcoming-books"></a><br>
<img data-recalc-dims="1" decoding="async" alt="A cardboard book box with the Macmillan logo." src="https://i0.wp.com/craphound.com/images/upcoming-books.jpg?w=840&amp;ssl=1"></p>
<h2 heds="0">Upcoming books (<a href="https://pluralistic.net/2025/09/27/econopocalypse/#upcoming-books">permalink</a>)</h2>
<ul>
<li>"Canny Valley": A limited edition collection of the collages I create for Pluralistic, self-published, September 2025
</li>
<li>
<p>"Enshittification: Why Everything Suddenly Got Worse and What to Do About It," Farrar, Straus, Giroux, October 7 2025<br>
<a href="https://us.macmillan.com/books/9780374619329/enshittification/">https://us.macmillan.com/books/9780374619329/enshittification/</a></p>
</li>
<li>
<p>"Unauthorized Bread": a middle-grades graphic novel adapted from my novella about refugees, toasters and DRM, FirstSecond, 2026</p>
</li>
<li>
<p>"Enshittification, Why Everything Suddenly Got Worse and What to Do About It" (the graphic novel), Firstsecond, 2026</p>
</li>
<li>
<p>"The Memex Method," Farrar, Straus, Giroux, 2026</p>
</li>
<li>
<p>"The Reverse-Centaur's Guide to AI," a short book about being a better AI critic, Farrar, Straus and Giroux, 2026</p>
</li>
</ul>
<hr>
<p><a name="bragsheet"></a><br>
<img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/colophon2.jpg?w=840&amp;ssl=1"></p>
<h2 heds="0">Colophon (<a href="https://pluralistic.net/2025/09/27/econopocalypse/#bragsheet">permalink</a>)</h2>
<p>Today's top sources: James Boyle (<a href="https://www.thepublicdomain.org/">https://www.thepublicdomain.org/</a>).</p>
<p><b>Currently writing: </b></p>
<ul>
<li>"The Reverse Centaur's Guide to AI," a short book for Farrar, Straus and Giroux about being an effective AI critic. FIRST DRAFT COMPLETE AND SUBMITTED.
</li>
<li>
<p>A Little Brother short story about DIY insulin PLANNING</p>
</li>
</ul>
<hr>
<p><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/craphound.com/images/by.svg.png?w=840&amp;ssl=1"></p>
<p>This work – excluding any serialized fiction – is licensed under a Creative Commons Attribution 4.0 license. That means you can use it any way you like, including commercially, provided that you attribute it to me, Cory Doctorow, and include a link to pluralistic.net.</p>
<p><a href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></p>
<p>Quotations and images are not included in this license; they are included either under a limitation or exception to copyright, or on the basis of a separate license. Please exercise caution.</p>
<hr>
<h2>How to get Pluralistic:</h2>
<p>Blog (no ads, tracking, or data-collection):</p>
<p><a href="http://pluralistic.net/">Pluralistic.net</a></p>
<p>Newsletter (no ads, tracking, or data-collection):</p>
<p><a href="https://pluralistic.net/plura-list">https://pluralistic.net/plura-list</a></p>
<p>Mastodon (no ads, tracking, or data-collection):</p>
<p><a href="https://mamot.fr/@pluralistic">https://mamot.fr/@pluralistic</a></p>
<p>Medium (no ads, paywalled):</p>
<p><a href="https://doctorow.medium.com/">https://doctorow.medium.com/</a></p>
<p>Twitter (mass-scale, unrestricted, third-party surveillance and advertising):</p>
<p><a href="https://twitter.com/doctorow">https://twitter.com/doctorow</a></p>
<p>Tumblr (mass-scale, unrestricted, third-party surveillance and advertising):</p>
<p><a href="https://mostlysignssomeportents.tumblr.com/tagged/pluralistic">https://mostlysignssomeportents.tumblr.com/tagged/pluralistic</a></p>
<p>"<em>When life gives you SARS, you make sarsaparilla</em>" -Joey "Accordion Guy" DeVilla</p>
<p>READ CAREFULLY: By reading this, you agree, on behalf of your employer, to release me from all obligations and waivers arising from any and all NON-NEGOTIATED agreements, licenses, terms-of-service, shrinkwrap, clickwrap, browsewrap, confidentiality, non-disclosure, non-compete and acceptable use policies ("BOGUS AGREEMENTS") that I have entered into with your employer, its partners, licensors, agents and assigns, in perpetuity, without prejudice to my ongoing rights and privileges. You further represent that you have the authority to release me from any BOGUS AGREEMENTS on behalf of your employer.</p>
<p>ISSN: 3066-764X</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microwave weapon downs 49 drones with a single blast (184 pts)]]></title>
            <link>https://newatlas.com/military/microwave-beam-anti-drone-weapon/</link>
            <guid>45399863</guid>
            <pubDate>Sat, 27 Sep 2025 22:25:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newatlas.com/military/microwave-beam-anti-drone-weapon/">https://newatlas.com/military/microwave-beam-anti-drone-weapon/</a>, See on <a href="https://news.ycombinator.com/item?id=45399863">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In a demonstration not so much of marksmanship but more of the advantages of microwaves, an Epirus Leonidas directed energy, high-power microwave (HPM) anti-drone weapon has knocked 49 Uncrewed Aerial Vehicles (UAV) out of the air with one shot.</p><p>Two things that make drones particularly concerning is that they're small enough to appear from unexpected corners of the sky and they're cheap enough that they can be <a href="https://newatlas.com/ufo-drones-graffiti-painting/60423/" data-cms-ai="0">deployed in huge numbers</a>. In fact, they are so cheap that they pose not only a military threat, but a serious hazard to civilian aviation from individuals who are irresponsible, mischievous, or just oblivious.</p><p>This is the reason there are so many different types of <a href="https://newatlas.com/military/thor-microwave-weapon-drone-swarms/" data-cms-ai="0">anti-drone weapons</a>. Each has their advantages and disadvantages, with none providing a one-size-fits-all panacea. Instead, each needs to be fitted to a particular scenario or deployed as part of a layered defense strategy.</p><p>One countermeasure is the use of microwave weapons like Leonidas. Named after the Spartan king who held off a Persian invasion with a vastly inferior force at the Battle of Thermopylae, Leonidas is one of a family of weapons based on using long-pulse microwave beams to burn out the electronics of small drones.</p><p>The idea isn't new, but Epirus has improved on previous iterations by using Gallium Nitride (GaN) semiconductors to generate microwaves instead of fragile, power-hungry magnetron vacuum tubes. This allows for smaller, more durable, and more mobile systems that use less power. In addition, Leonidas is software driven and can tailor its waveform for optimum effect, it is safe to use around humans who may be in the field of fire, and the present system has twice the range of the 2022 version.</p><p>But the core feature is its "one-to-many" capability that gives it operational flexibility to handle a variety of scenarios. For example, it can strike against targets with precision to take out <a href="https://newatlas.com/military/valkyrie-combat-drone-launch-smaller-drone-test-flight/" data-cms-ai="0">hostile drones</a> while avoiding collateral damage, be programmed to set up no-fly zones with safety corridors to take out hostiles while allowing friendlies to pass, sustain continuous fire without overheating, and take down swarms in one go.</p><div data-align-center="">
                
                    <figure>
    
    
    
    


<p><img alt="The Leonidas microwave weapon on an armored vehicle" width="754" height="462" data-image-size="articleImage" loading="lazy" srcset="https://assets.newatlas.com/dims4/default/d6c72a3/2147483647/strip/true/crop/754x462+0+0/resize/440x270!/format/webp/quality/90/?url=https%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F0d%2F38%2F86e911324e6883ff677ccf3ab8ce%2Fscreenshot-2025-09-21-150303.jpg 440w,https://assets.newatlas.com/dims4/default/ccb09f5/2147483647/strip/true/crop/754x462+0+0/resize/725x444!/format/webp/quality/90/?url=https%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F0d%2F38%2F86e911324e6883ff677ccf3ab8ce%2Fscreenshot-2025-09-21-150303.jpg 725w,https://assets.newatlas.com/dims4/default/cb4580d/2147483647/strip/true/crop/754x462+0+0/resize/800x490!/format/webp/quality/90/?url=https%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F0d%2F38%2F86e911324e6883ff677ccf3ab8ce%2Fscreenshot-2025-09-21-150303.jpg 800w,https://assets.newatlas.com/dims4/default/0392e8b/2147483647/strip/true/crop/754x462+0+0/resize/1200x735!/format/webp/quality/90/?url=https%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F0d%2F38%2F86e911324e6883ff677ccf3ab8ce%2Fscreenshot-2025-09-21-150303.jpg 1200w,https://assets.newatlas.com/dims4/default/c31a3b3/2147483647/strip/true/crop/754x462+0+0/resize/1920x1176!/format/webp/quality/90/?url=https%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F0d%2F38%2F86e911324e6883ff677ccf3ab8ce%2Fscreenshot-2025-09-21-150303.jpg 1920w" src="https://assets.newatlas.com/dims4/default/d09a9cf/2147483647/strip/true/crop/754x462+0+0/resize/754x462!/format/webp/quality/90/?url=https%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F0d%2F38%2F86e911324e6883ff677ccf3ab8ce%2Fscreenshot-2025-09-21-150303.jpg" sizes="(min-width: 768px) 800px, 100vw">
</p>



    
    

    
        <div><figcaption itemprop="caption">The Leonidas microwave weapon on an armored vehicle</figcaption><p>Epirus</p></div>
    
</figure>

                
            </div><p>On August 26, 2025, in front of an invitation-only audience at Camp Atterbury, Indiana, Leonidas took part in a live fire exercise in which it disabled 61 drones with 100% success. This included knocking out two groups of three drones approaching <a href="https://newatlas.com/military/roadrunner-m-anti-aircraft-drone-reusable/" data-cms-ai="0">without warning</a> from opposite directions, targeting one of two drones selected by an audience member before disabling the second one, and intercepting and dropping a single drone into a predetermined safe zone.</p><p>Then came the party piece, it took on over four dozen drones at once, dropping them out of the sky simultaneously with a single pulse. That may not seem like much in words, but a video provided by the company had the lot suddenly crashing like someone had cut their strings.</p><div data-video-disable-history="" data-align-center="">
    
        <p><ps-youtubeplayer data-video-player="" data-player-id="f66f7afb1ce0d4212adc356019d091a96" data-video-id="ZrkopSw5uas" data-video-title="Epirus’ Leonidas High-Power Microwave Defeats 49-Drone Swarm">

    <iframe id="YouTubeVideoPlayer-f66f7afb1ce0d4212adc356019d091a96" role="application" title="YouTube embedded video player" allowfullscreen="" loading="lazy" src="https://www.youtube.com/embed/ZrkopSw5uas?enablejsapi=1"></iframe>
</ps-youtubeplayer>
</p>
    
    
        <p>Epirus’ Leonidas High-Power Microwave Defeats 49-Drone Swarm</p>
    
</div><p>"This is a watershed moment for Epirus," said Andy Lowery, Epirus CEO. "We believe showcasing our weaponized electromagnetic interference is the most effective way to communicate that Leonidas is the only mission-capable, counter-swarm solution for the one-to-many fight.Those who joined us witnessed this first-hand as 61 drones went up – and 61 went down."</p><p>Source: <a href="https://www.epirusinc.com/press-releases/epirus-leonidas-high-power-microwave-defeats-49-drone-swarm-100-of-drones-flown-at-live-fire-demonstration" target="_blank" data-cms-ai="0">Epirus</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We reverse-engineered Flash Attention 4 (108 pts)]]></title>
            <link>https://modal.com/blog/reverse-engineer-flash-attention-4</link>
            <guid>45399637</guid>
            <pubDate>Sat, 27 Sep 2025 21:50:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://modal.com/blog/reverse-engineer-flash-attention-4">https://modal.com/blog/reverse-engineer-flash-attention-4</a>, See on <a href="https://news.ycombinator.com/item?id=45399637">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!----><article><!----><p>One month ago at <a rel="nofollow" href="https://hotchips.org/"><!----><!---->Hot Chips<!----></a><!---->, Tri Dao presented preliminary results on Flash Attention 4, the latest addition to the <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention"><!----><!---->Flash Attention series of CUDA kernels<!----></a><!---->. These kernels are used in the attention layers of Transformer neural networks. Along with more standard matrix multiplications, these calculations are the primary bottlenecks in contemporary generative AI workloads. Billions of dollars and gigawatts of power are being expended on GPUs to run more of these calculations faster. And Flash Attention 4 is the way to run lots of them as fast as possible. This blog post explains how it works.</p> <p>The new FA4 kernel is optimized for Nvidia’s new <a rel="nofollow" href="https://modal.com/blog/introducing-b200-h200"><!----><!---->Blackwell Streaming Multiprocessor architecture<!----></a><!----> and achieves a reported ~20% speedup over the previous state-of-the-art, the attention kernels in Nvidia’s <a rel="nofollow" href="https://modal.com/gpu-glossary/host-software/cudnn"><!----><code>cudnn</code><!----></a><!----> library.</p> <p><img src="https://modal-cdn.com/blog/images/fa4-vs-cudnn-results-slide.jpg" alt="A chart depicting the ~20% performance improvement of Flash Attention 4 over cudnn attention kernels."> <!--[!--><!--]--><!----></p> <p><code>cudnn</code> kernels are closed source, so Jensen only knows what’s going on in there.</p> <p>There’s also no official technical report on how FA4 works yet. But the source code for Flash Attention 4 was already released online <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py"><!----><!---->here<!----></a><!---->. We’ve <a rel="nofollow" href="https://github.com/sgl-project/sglang/pull/9588"><!----><!---->recently<!----></a><!----> been contributing to open source LLM inference engines, so we read the code and reverse-engineered how the kernel works, including two math tricks (faster approximate exponentials and a more efficient online softmax) that are classic Dao. This write-up contains our findings.</p> <p>Perhaps surprisingly, the architecture of FA4 is readily understandable by a general software engineering audience.</p> <p>That’s because the biggest change in FA4 isn’t the (very cool) math — it’s a massive increase in the complexity of its asynchronous “pipeline” of operations. This kind of asynchronous programming is fairly new in the world of CUDA, but <a rel="nofollow" href="https://assets.bitbashing.io/images/cubedrone-103.png"><!----><!---->pipes have been in Unix for like 40 goddamn years<!----></a><!---->. A programmer who has experience with parallel and concurrent programs, like high performance databases and web servers, will feel right at home (absent some novel <a rel="nofollow" href="https://modal.com/gpu-glossary/readme"><!----><!---->GPU technical vocabulary<!----></a><!---->).</p> <p>So we organize our write-up into two parts.</p> <p>The first section, a “quick tour”, covers the architecture of FA4 by tracing what happens as a block of inputs is turned into a block of outputs. It is written to be understandable by a practicing software engineer without any CUDA programming experience. We give brief explanations of CUDA concepts and hardware, like <a rel="nofollow" href="https://modal.com/gpu-glossary/device-software/warp"><!----><!---->warps<!----></a><!----> and <a rel="nofollow" href="https://modal.com/gpu-glossary/device-hardware/warp-scheduler"><!----><!---->warp schedulers<!----></a><!---->, but defer detailed explanation to our <a rel="nofollow" href="https://modal.com/gpu-glossary/readme"><!----><!---->GPU Glossary<!----></a><!----> (linked throughout).</p> <p>The second section, a “deep dive”, walks through each of the subcomponents in turn, explaining what each does, supported by links to the source code for particularly intrepid spelunkers.</p> <h2 id="a-quick-tour-of-flash-attention-4-the-life-of-a-tile">A quick tour of Flash Attention 4: The “Life of a Tile”</h2> <p>We start with <a rel="nofollow" href="https://float.exposed/b0x3a0a"><!----><!---->bf16<!----></a><!----> tensors of queries, keys, and values in <a rel="nofollow" href="https://modal.com/gpu-glossary/device-software/global-memory"><!----><!---->global memory<!----></a><!----> (aka <a rel="nofollow" href="https://modal.com/gpu-glossary/device-hardware/gpu-ram"><!----><!---->GPU RAM<!----></a><!---->). We’re aiming to produce a tensor of bf16 outputs, also in global memory. Outputs are values weighted by the similarity of queries to keys. Computing this weighting requires matrix multiplication, exponentiation, and normalization.</p> <p>Like the good engineers we are, we tackle this very big problem by breaking it down into smaller pieces. That’s fairly literal in this case: we take our very large input tensor and split it up into “tiles” of adjacent rows and columns, each of which contribute to the calculation of one tile of outputs.</p> <p>Specifically, one running instance of our kernel program (namely, one <a rel="nofollow" href="https://modal.com/gpu-glossary/device-software/cooperative-thread-array"><!----><!---->“cooperative thread array”<!----></a><!----> of threads) produces two tiles of the outputs tensor by reading two tiles of the queries tensor. In between, it streams all of the keys &amp; values for each query tile. Keys and values are also read in tiles. If you’re a database ‘head, you might think of it as a vectorized sequential scan for a batch of aggregation queries against a key-value store.</p> <p><img src="https://modal-cdn.com/blog/images/fa4-streaming-tiles.jpg" alt="A diagram showing a tile of queries combining with a stream of key and value tiles to produce an output tile."> <!--[!--><!--]--><!----></p> <p>By running this tile-level program many times concurrently (typically, massively in parallel), we produce the entire outputs tensor. This is a <a rel="nofollow" href="https://modal.com/gpu-glossary/device-software/kernel"><!----><!---->“single program, multiple data” execution model<!----></a><!---->, where each datum is a pair of tiles. This kind of concurrency <em>across</em> program instances is the bread-and-butter of the <a rel="nofollow" href="https://modal.com/gpu-glossary/device-software/cuda-programming-model"><!----><!---->CUDA programming model<!----></a><!----> and is transparently handled for the programmer by the <a rel="nofollow" href="https://modal.com/gpu-glossary/host-software/cuda-software-platform"><!----><!---->CUDA runtime<!----></a><!---->.</p> <p>But with the fastest contemporary kernels, like Flash Attention 3 &amp; 4 and all state-of-the-art matrix multiplications, there is also concurrency <em>within</em> our program. Each program instance sets up an asynchronous pipeline of operations that together effect the tile-level computation depicted above. We write our kernel such that all of our pipeline steps can run as concurrently as possible as we process a tile. In Flash Attention 4, we achieve this by mapping chunks of our pipeline onto 32-thread groups called <a rel="nofollow" href="https://modal.com/gpu-glossary/device-software/warp"><!----><em>warps</em><!----></a><!----> (a technique called <em>warp specialization</em>).</p> <p>We then rely on the <a rel="nofollow" href="https://modal.com/gpu-glossary/device-hardware/warp-scheduler"><!----><!---->warp schedulers<!----></a><!----> to switch between pipeline steps within program instances on each clock, swapping out when a step stalls and swapping back in when a step’s next input is ready. Think <a rel="nofollow" href="https://blog.codingconfessions.com/p/simultaneous-multithreading"><!----><!---->simultaneous multithreading<!----></a><!---->/“hyperthreading” from CPUs, but on steroids. The diagram below, from our <a rel="nofollow" href="https://modal.com/gpu-glossary/perf"><!----><!---->GPU Performance Glossary<!----></a><!---->, depicts four cycles across four parallel slots, for a total of sixteen <a rel="nofollow" href="https://modal.com/gpu-glossary/perf/issue-efficiency"><!----><!---->execution slots<!----></a><!---->, fifteen of which are filled with warps actively executing instructions thanks to this rapid warp switching. See the <a rel="nofollow" href="https://modal.com/gpu-glossary/perf/warp-execution-state"><!----><!---->associated article<!----></a><!----> for details.</p> <p><img src="https://modal-cdn.com/gpu-glossary/terminal-cycles.svg" alt="A diagram depicting sixteen execution slots. Fifteen of them are colored in, indicating that they are filled with an active warp."> <!--[!--><!--]--><!----></p> <p>This execution model is “dual” to <a rel="nofollow" href="https://ibraheem.ca/posts/too-many-web-servers/"><!----><!---->the way that an asynchronous program for CPUs works<!----></a><!----> in the following sense. In an async CPU program, a single thread implements the entire journey of a single datum (e.g. request) through a state machine (e.g. Reading, Parsing, Writing), switching between transitions as data become ready. In an async GPU program like FA4, a single warp implements a single <em>transition</em> (e.g. from queries and values to attention scores) in a similar state machine.</p> <p><img src="https://modal-cdn.com/blog/images/fa4-cpu-async-vs-gpu-async.jpg" alt="cpu-async-vs-gpu-async.drawio.png"> <!--[!--><!--]--><!----></p> <p>The pipeline is organized with a producer/consumer model and uses barriers for synchronization.</p> <p>Unlike the concurrency across program instances, the internal pipeline concurrency is all implemented manually. This leads to quite gnar code — though the control flow will look familiar to anyone who has <a rel="nofollow" href="https://os.phil-opp.com/async-await/"><!----><!---->written their own event loop<!----></a><!---->.</p> <p>So like most async code, the FA4 kernel is best understood by tracing the path of a single tile: the “life of a tile”, akin to <a rel="nofollow" href="https://groups.google.com/a/chromium.org/g/blink-dev/c/AK_rwEp61ME"><!----><!---->the “life of a pixel” in a browser’s rendering pipeline<!----></a><!---->. In particular, let’s follow the tile’s path through the <a rel="nofollow" href="https://modal.com/gpu-glossary/device-software/memory-hierarchy"><!----><!---->memory hierarchy of the GPU<!----></a><!----> as it is transformed from initial query tile to final output tile.</p> <p>At a high level, and eliding a few details about multiple buffering that increase concurrency and parallelism, that looks something like this:</p> <p><img src="https://modal-cdn.com/blog/images/fa4-life-of-a-tile.jpg" alt="fa4-life-of-tile.drawio.png"> <!--[!--><!--]--><!----></p> <p>Which vaguely resembles a <a rel="nofollow" href="https://microservices.io/patterns/microservices.html"><!----><!---->microservices diagram<!----></a><!---->. As above, so below!</p> <p>Spelled out, that’s:</p> <ul><li>A tile of queries is loaded from global memory (<code>mQ</code>) into shared memory (<code>sQ</code>) by the Load warp. <a rel="nofollow" href="https://modal.com/gpu-glossary/device-software/shared-memory"><!----><!---->Shared memory<!----></a><!----> is a “scratchpad” L1 cache managed by the programmer.</li> <li>Tiles of keys (<code>mK</code>) and values (<code>mV</code>) are streamed into shared memory (<code>sK</code>, <code>sV</code>), also by the Load warp. Note that if the working set size permits, future loads of these tiles for other query tiles will be serviced from the hardware-managed L2 cache (not pictured).</li> <li>When each tile of keys is ready, the MMA warp multiplies it with our tile of queries using a Tensor Core, producing a tile of unnormalized attention scores in Tensor Memory (<code>tS</code>). <a rel="nofollow" href="https://modal.com/gpu-glossary/device-hardware/tensor-core"><!----><!---->Tensor Cores<!----></a><!----> are single-purpose hardware for running matmuls. <a rel="nofollow" href="https://modal.com/gpu-glossary/device-hardware/tensor-memory"><!----><!---->Tensor Memory<!----></a><!----> is another programmer-managed L1 cache designed to hold and accumulate intermediates during sequences of Tensor Core operations.</li> <li>When each tile of unnormalized attention scores is ready, a Softmax warp produces normalized attention scores for that tile in Tensor Memory (<code>tP</code>) without using the Tensor Core and updates a scaling factor used for numerical stability (in shared memory, not pictured). <ul><li>⚡️ New in Flash Attention 4: this step can use CUDA Cores instead of <a rel="nofollow" href="https://modal.com/gpu-glossary/device-hardware/special-function-unit"><!----><!---->Special Function Units (SFUs)<!----></a><!----> to perform the exponential step of the normalization. SFUs are intended to provide hardware acceleration for transcendental operations like exponentials. But there are <a rel="nofollow" href="https://modal.com/gpu-glossary/device-hardware/streaming-multiprocessor"><!----><!---->far fewer SFUs than CUDA Cores<!----></a><!---->, which can lead to queueing. The basic idea, fast approximate exponentiation in software for neural networks that can tolerate a bit of accuracy loss, was proposed in <a rel="nofollow" href="https://nic.schraudolph.org/pubs/Schraudolph99.pdf"><!----><!---->a 1999 <em>Neural Computation</em> paper by Schraudolph<!----></a><!---->, but the implementation here is quite different, involving a cubic polynomial approximation (as described in detail below).</li></ul></li> <li>When each tile of normalized attention scores is ready, a Correction warp checks if the normalization scaling factor has changed and, if necessary, rescales the final output tile in Tensor Memory (<code>tO</code>). <ul><li>⚡️ New in Flash Attention 4: the choice of when to rescale became much smarter, reportedly cutting down on output rescaling operations by a factor of 10. Roughly: the scaling factor used to be a simple running maximum. Now updates are applied only when the maximum has changed enough to impact numerical stability. This seems like a good, and very portable, idea.</li></ul></li> <li>When each rescaling update finishes, the MMA warp updates the output tile in Tensor Memory (<code>tO</code>) by accumulating it with the value tile (<code>sV</code>) scaled by the attention score tile (<code>tP</code>).</li> <li>When each tile of final output values is ready, the Correction warp stores it in shared memory (<code>sO</code>), then the Epilogue warp stores it in global memory (<code>mO</code>), and we’re done with that tile.</li></ul> <p>Our high-level, tile-centric view elides a number of details, like the number of warps assigned to each pipeline step and the use of buffers to store different tiles. It also leaves out all of the details of the barrier synchronization, which is required on both sides of every producer/consumer relationship (aka where an arrow tip meets an arrow tail in the diagram). These are critical for performance.</p> <p>We go through these details in a “warp-centric” view of the kernel below, which focuses on the operations in each warp, rather than the movement of tiles, and includes links to the source code. This is necessarily more technical and goes through some GPU-specific features at higher speed, so it’s less suitable for a general software engineering audience.</p> <p>But before that, one last takeaway for those only interested in the high level.</p> <h2 id="where-does-gpu-programming-go-from-here">Where does GPU programming go from here?</h2> <p>When <a rel="nofollow" href="https://graphics.stanford.edu/papers/brookgpu/brookgpu.pdf"><!----><!---->Ian Buck<!----></a><!----> and others designed <a rel="nofollow" href="https://modal.com/gpu-glossary/host-software/cuda-c"><!----><!---->CUDA C<!----></a><!---->, they were driven by a north star: can it be used to write a single precision vector addition (<code>saxpy</code>) with respectable performance as a clean one-liner that’s easily understood by a C programmer? The core of the <a rel="nofollow" href="https://modal.com/gpu-glossary/device-software/cuda-programming-model"><!----><!---->CUDA programming model<!----></a><!----> laid down then and described in the <a rel="nofollow" href="https://www.cs.cmu.edu/afs/cs/academic/class/15869-f11/www/readings/lindholm08_tesla.pdf"><!----><!---->2008 Lindholm et al. paper<!----></a><!----> still persists today.</p> <p>What’s new in the last few years (in the Hopper and Blackwell architectures) is an increasing reliance on programmer-managed asynchrony, like FA4’s multi-stage, multi-buffered pipeline. This represents a major jump in complexity from FA3’s simpler “ping-pong” pipeline (<a rel="nofollow" href="https://www.together.ai/blog/flashattention-3"><!----><!---->added to take advantage of Hopper GPUs’ async capabilities<!----></a><!---->).</p> <p>And <a rel="nofollow" href="https://bitbashing.io/async-rust.html"><!----><!---->just as in other well-designed languages<!----></a><!---->, CUDA C/C++ has struggled to accommodate the introduction of asynchrony. It is a <a rel="nofollow" href="https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/"><!----><!---->truth universally acknowledged<!----></a><!----> that <a rel="nofollow" href="https://fasterthanli.me/articles/pin-and-suffering"><!----><!---->async programming sucks absolute ass<!----></a><!---->. That’s especially true when you need to manage your own event loop, as we’re effectively doing here. And it’s made harder, not easier, by the thread-centricity and warp uniformity of the CUDA programming model and <a rel="nofollow" href="https://modal.com/gpu-glossary/device-software/parallel-thread-execution"><!----><!---->PTX machine model<!----></a><!---->.</p> <p>No wonder <a rel="nofollow" href="https://www.youtube.com/watch?v=5e1YKqsP8i8&amp;t=1059s"><!----><!---->the Triton team gave up on writing Blackwell attention<!----></a><!----> and added the new Gluon frontend at a lower level!</p> <p>Triton’s troubles notwithstanding, this kernel is a clear instance of the swing towards tile-based, warp-specialized programming. And Nvidia is betting big on a number of new languages and libraries to try to make this easier, from the <a rel="nofollow" href="https://docs.nvidia.com/cutlass/media/docs/pythonDSL/cute_dsl_general/dsl_introduction.html"><!----><!---->CuTe DSL<!----></a><!----> and <a rel="nofollow" href="https://docs.nvidia.com/cutlass/index.html"><!----><!---->CUTLASS<!----></a><!----> C++ used in this kernel to the forthcoming <a rel="nofollow" href="https://www.youtube.com/watch?v=uZTtViomW6w"><!----><!---->CuTile<!----></a><!---->. Say what you will about the chatbot hype wave, these are exciting times for high performance numerical computing!</p> <h2 id="deep-dive-for-the-gpu-enjoyers-what-does-each-warp-do-in-flash-attention-4">Deep dive for the GPU enjoyers: What does each warp do in Flash Attention 4?</h2> <p>There are five different specializations for warps in the Flash Attention 4 kernel. They are listed below, along with links to their source code.</p> <ol><li>A <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L837"><!----><!---->Load warp<!----></a><!----> to load query, key, and value tiles from global memory into shared memory</li> <li>An <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L953"><!----><!---->MMA warp<!----></a><!----> to compute unnormalized attention scores from query and key tiles and accumulate score-weighted value tiles into the output tiles</li> <li>Eight <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1143-L1145"><!----><!---->Softmax warps<!----></a><!----> to compute normalized attention scores and track running stats (max, sum)</li> <li>Four <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1413"><!----><!---->Correction warps<!----></a><!----> to watch for updates to the normalization scale and re-normalize the output tiles</li> <li>One or two <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1737"><!----><!---->Epilogue warps<!----></a><!----> to store completed output tiles from shared memory into global memory</li></ol> <p>In the above discussion, we implied that each CTA works on just two query tiles and produces just two output tiles. That’s true in some settings, but the mapping between tiles and CTAs is technically abstracted by a <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L398-L404"><!----><code>TileScheduler</code><!----></a><!---->. For the best performance, you need to use the <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/1ceaa984b2f348caea18b39a98458d33b4ea7a09/flash_attn/cute/tile_scheduler.py#L122"><!----><code>StaticPersistentTileScheduler</code><!----></a><!---->, which launches <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/1ceaa984b2f348caea18b39a98458d33b4ea7a09/flash_attn/cute/tile_scheduler.py#L162-L163"><!----><!---->at most one CTA per Streaming Multiprocessor<!----></a><!----> and then schedules tiles onto those SMs. This reduces CTA launch overhead and allows for more fine-grained concurrency (e.g. overlapping Epilogue warps for one tile with the Load and MMA warps for the next tile).</p> <p>The core work of the kernel is the same — there’s just not a clean mapping of work onto thread constructs, which makes explaining the work harder. From here, we’ll go back to speaking about the code as though each CTA handles only two tiles (which is literally true if you use the <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/1ceaa984b2f348caea18b39a98458d33b4ea7a09/flash_attn/cute/tile_scheduler.py#L56"><!----><code>SingleTileScheduler</code><!----></a><!---->).</p> <p>Also, from here we will start using some shorthand, matching the code and convention: Q for queries, K for keys, V for values, O for outputs, S for unnormalized attention scores, and P for normalized attention scores/“probabilities”.</p> <h3 id="the-load-warp-loads-two-q-tiles-and-streams-all-k-and-v-tiles">The Load warp loads two Q tiles and streams all K and V tiles.</h3> <p>The <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L837"><!----><!---->Load warp<!----></a><!----> operates on <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L841-L843"><!----><!---->pointers to Q, K, and V tensors in global memory<!----></a><!----> and writes to <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L844-L846"><!----><!---->Q, K, and V tensors in shared memory<!----></a><!---->. It supports paged keys and values (as in <a rel="nofollow" href="https://arxiv.org/abs/2309.06180"><!----><!---->Paged Attention<!----></a><!---->, not as in operating system pages) via an <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L847"><!----><!---->optional “page table” tensor<!----></a><!----> (again, <em>not</em> the page tables co-managed by the OS, the CPU, and the MMU).</p> <p>It uses the <a rel="nofollow" href="https://modal.com/gpu-glossary/device-hardware/tensor-memory-accelerator"><!----><!---->Tensor Memory Accelerator (TMA)<!----></a><!----> to reduce register pressure from multidimensional array access and <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L889-L909"><!----><!---->fire off copies asynchronously<!----></a><!---->. This also avoids very long <a rel="nofollow" href="https://modal.com/gpu-glossary/perf/warp-execution-state"><!----><!---->warp stalls<!----></a><!----> on loads that would require even more warp specialization to <a rel="nofollow" href="https://modal.com/gpu-glossary/perf/latency-hiding"><!----><!---->hide latency<!----></a><!---->.</p> <p>The Load warp <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L934-L935"><!----><!---->loads two Q tiles<!----></a><!---->. It loads all K and V blocks <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L939-L946"><!----><!---->in a loop<!----></a><!---->. It is the ”<a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L859"><!----><!---->producer<!----></a><!---->” of these tiles (in a producer/consumer setup). It can <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L170"><!----><!---->concurrently load up to three blocks each of K and V<!----></a><!---->.</p> <p>As it completes these loads, the Load warp signals their completion to the MMA warp through <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L852"><!----><!---->an array of barriers in shared memory<!----></a><!---->. All barriers (not just for Load/MMA synchronization) are <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L913"><!----><!---->referenced via their offset in this array<!----></a><!----> to support variable barrier counts with different configuration settings.</p> <h3 id="the-mma-warp-computes-unnormalized-attention-scores-and-output-values">The MMA warp computes unnormalized attention scores and output values.</h3> <p>The <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L953"><!----><!---->MMA warp<!----></a><!----> operates on pointers to Q, K, and V tensors in <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L957-L959"><!----><!---->shared memory<!----></a><!---->. For every K/V tile, it runs <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L990"><!----><!---->two matmuls to create S tiles<!----></a><!----> and <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L998"><!----><!---->two matmuls for O<!----></a><!----> (Q/K for the S tiles, P/V for the O tiles). The matmuls are <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/1ceaa984b2f348caea18b39a98458d33b4ea7a09/flash_attn/cute/blackwell_helpers.py#L327-L369"><!----><!---->emitted as inline PTX assembly<!----></a><!---->, as is necessary for CUDA C/C++ programs to use the Tensor Cores in Hopper and Blackwell. The vast majority of the FLOPS in this kernel are driven by these lines; most everything else is memory management.</p> <p>The specific PTX instruction used is <code>tcgen05.mma.cta_group::1</code>. <code>mma</code> is matrix-multiply-accumulate. <code>tcgen05</code> means <code>5</code>th generation <code>t</code>ensor <code>c</code>ore, aka Blackwell, as in <code>sm100</code>/<a rel="nofollow" href="https://modal.com/gpu-glossary/device-software/compute-capability"><!----><!---->Compute Capability 10.0<!----></a><!---->. <code>cta_group::1</code> means we run our matmul using only a single CTA, avoiding the nastiness of <a rel="nofollow" href="https://modal.com/gpu-glossary/device-hardware/texture-processing-cluster"><!----><!---->TPC<!----></a><!---->-based 2SM/2CTA matmuls <a rel="nofollow" href="https://docs.nvidia.com/cutlass/media/docs/cpp/blackwell_functionality.html"><!----><!---->available in Blackwell<!----></a><!---->. This likely introduces a small memory throughput penalty but simplifies CTA/tile scheduling. Interestingly, the <a rel="nofollow" href="https://github.com/HazyResearch/ThunderKittens/blob/2ba96ceedfb1b5c5d6e1eb4a1241a24d16049be4/kernels/attn/b200/b200.cu"><!----><!---->ThunderKittens Blackwell attention kernel<!----></a><!----> makes a different choice.</p> <p>Also on the front of scheduling/simplification: only a single <code>leader_thread</code> issues the instruction. And we’re only working from a single warp. This is an important difference from performant Hopper MMAs, which were coordinated across an entire warpgroup.</p> <p>After <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1017"><!----><!---->getting hold of a Q tile<!----></a><!----> and our first K tile, we <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1031"><!----><!---->run our first matmul<!----></a><!----> to produce our first result for S. Then we <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1045"><!----><!---->loop over the remaining K and V tiles<!----></a><!----> and update S and O. These <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L963-L964"><!----><!---->S and O tensors<!----></a><!----> live in Tensor Memory. This is <a rel="nofollow" href="https://modal.com/gpu-glossary/device-hardware/tensor-memory"><!----><!---->the “intended” use of Tensor Memory<!----></a><!---->, as a store for accumulators read from and written to by the Tensor Cores.</p> <p>Since the K and V tiles are buffered, we need to signal the Load warp every time we finish using them (eg <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1073-L1075"><!----><!---->here<!----></a><!---->, signaling that the memory containing V can be reused once it has been used to construct the second O tile). There’s some additional coordination here (around S, P, and O), which we’ll discuss as it comes in up in the other warps.</p> <h3 id="eight-softmax-warps-produce-normalized-attention-scores">Eight Softmax warps produce normalized attention scores.</h3> <p>The Softmax warps <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1401"><!----><!---->produce normalized attention scores<!----></a><!----> (P, as in “probabilities”) consumed by the MMA warps. Ignore the name and don’t try to come up with an interpretation of the attention scores as the probability distribution for a random variable; it’ll make your head hurt and give you bad intuition about Transformers. They’re <a rel="nofollow" href="https://transformer-circuits.pub/"><!----><!---->better thought of<!----></a><!----> as weights for a linear combination of vectors from V.</p> <p>The core <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1143-L1145"><!----><!---->softmax operation is implemented by two warpgroups<!----></a><!---->, aka eight warps. The two warpgroups are mapped onto the two query/output tile workstreams. Warpgroups are made up of four adjacent warps with a warp index alignment of four. Using them was critical for the fast warpgroup MMAs in Hopper GPUs, <a rel="nofollow" href="https://www.together.ai/blog/flashattention-3"><!----><!---->as in Flash Attention 3<!----></a><!---->, but we didn’t see anything in this kernel that made explicit use of them. Warpgroup alignment may lead to more even distribution of work across warp schedulers/subunits of the SM, as it did in Hopper, which had <a rel="nofollow" href="https://modal.com/gpu-glossary/device-hardware/streaming-multiprocessor-architecture"><!----><!---->four warp schedulers per SM<!----></a><!---->. To our <a rel="nofollow" href="https://en.wikipedia.org/wiki/Blackwell_(microarchitecture)#Blackwell_dies"><!----><!---->and Wikipedia’s<!----></a><!----> knowledge, this level of detail on SM100 Blackwell GPUs like B200s is not published anywhere (but it <a rel="nofollow" href="https://images.nvidia.com/aem-dam/Solutions/geforce/blackwell/nvidia-rtx-blackwell-gpu-architecture.pdf"><!----><!---->is true of SM120 RTX Blackwell GPUs<!----></a><!---->).</p> <p>We’re also not certain of the reason why some pipeline stages are assigned more warps than others and in this particular ratio. Presumably, it helps ensure balanced throughput across the different stages, but our napkin math on relative operational load, bandwidth, and latency between the matmuls and the attention operations didn’t produce a smoking gun. We speculate that it was determined by benchmarking.</p> <p>Each warp runs <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1315"><!----><!---->a single step<!----></a><!----> of the online softmax calculation at a time while <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1267-L1269"><!----><!---->looping over<!----></a><!----> the <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1384"><!----><!---->S tiles produced by the MMA warp<!----></a><!---->.</p> <p>Looking within the individual <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1315"><!----><!---->softmax step<!----></a><!---->: the unnormalized attention scores are stored in Tensor Memory, which can only be <em>directly</em> operated on by the Tensor Cores. But the Tensor Cores can only do matrix multiplication. So the Softmax warps have to <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1363"><!----><!---->copy the scores<!----></a><!----> into the registers to apply the exponentiation and then <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1398"><!----><!---->copy the result back<!----></a><!---->.</p> <p>The exponentiation is done differently than in previous versions of Flash Attention. FA3 and earlier used the GPU’s Special Function Units to perform a hardware-accelerated exponentiation. Specifically, they use the <code>exp2</code> CUDA PTX intrinsic, which is typically <a rel="nofollow" href="https://godbolt.org/z/7e5jx9qcr"><!----><!---->mapped by the (closed-source) <code>ptxas</code> compiler to the <code>MUFU.EX2</code> SASS instruction<!----></a><!---->.</p> <p>The FA4 kernel does that too, but for <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/add175637c5d54b74bc25372e49ce282d6f236fc/flash_attn/cute/flash_fwd_sm100.py#L1390-L1391"><!----><!---->smaller attention head sizes<!----></a><!----> it <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/0165c96fff7a7cd2e152aa9659f75c972a702f5d/flash_attn/cute/softmax.py#L234-L238"><!----><!---->additionally mixes in a different exponentiation algorithm on some iterations with a tunable frequency<!----></a><!---->. That implementation uses <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/add175637c5d54b74bc25372e49ce282d6f236fc/flash_attn/cute/utils.py#L501-L541"><!----><!---->this block of inline PTX<!----></a><!----> to compute <code>2 ** x</code>. The algorithm splits the exponentiation into two parts: the easy integer part (<code>2 ** floor(x)</code>) and the hard rational part (<code>2 ** (x - floor(x))</code>). It uses a cubic polynomial to approximate <code>2 ** x</code> on the unit interval (check out the approximation on Wolfram Alpha <a rel="nofollow" href="https://www.wolframalpha.com/input?i=0.07711909*r%5E3%2B0.22756439*r%5E2%2B0.69514614*r%2B1.0+compared+to+2%5Er"><!----><!---->here<!----></a><!---->).</p> <p>The cubic polynomial calculation is done, following Horner’s method for linear time polynomial evaluation, with three fused multiply-adds (<code>fma</code>):</p> <!----> <p>Note that <code>f32x2</code> means that we operate on a vector (as in <a rel="nofollow" href="https://people.eecs.berkeley.edu/~pattrsn/252S98/Lec06-vector.pdf"><!----><!---->vector lanes<!----></a><!---->) of two 32 bit values. You can read about a similar implementation for CPU vector instructions on Stack Overflow <a rel="nofollow" href="https://stackoverflow.com/questions/47025373/fastest-implementation-of-the-natural-exponential-function-using-sse"><!----><!---->here<!----></a><!---->.</p> <p>In addition to only applying this method on some iterations, it <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/0165c96fff7a7cd2e152aa9659f75c972a702f5d/flash_attn/cute/softmax.py#L234-L238"><!----><!---->stops applying it on a configurable number of the last S tiles<!----></a><!---->. Together, these suggest that the reason for applying it is to avoid a bottleneck on the SFUs (which, due to <a rel="nofollow" href="https://www.thonking.ai/p/what-shapes-do-matrix-multiplications"><!----><!---->wave quantization effects<!----></a><!---->, is less relevant for the final tiles).</p> <p>The Softmax warps also <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1282"><!----><!---->track the running statistics for rescaling and normalizing attention scores<!----></a><!----> used by the Correction warps, as discussed below.</p> <p>There’s another important change here. All softmax algorithms need to handle <a rel="nofollow" href="https://en.wikipedia.org/wiki/Softmax_function#Numerical_algorithms"><!----><!---->numerical instability caused by exponentiation of large values<!----></a><!---->. Before Flash Attention, this was usually done by finding the largest value in each row and subtracting it from the value before exponentiating. All Flash Attention kernels use a streaming or online softmax algorithm, and the largest value is not known in advance — searching through the scores to find it would defeat the purpose of using a streaming algorithm! Instead, they use a running maximum for numerical stability and update the scaling factor whenever a new maximum is encountered. This ensures continued numerical stability and avoids an extra scan, but requires a costly correction of previous values (handled by the Correction warps) every time a new maximum is observed.</p> <p>This is inefficient. We only need to update the scaling factor <em>when the new maximum changes enough to threaten numerical stability</em>, not every time a new maximum appears. That logic is implemented <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/0165c96fff7a7cd2e152aa9659f75c972a702f5d/flash_attn/cute/softmax.py#L176-L179"><!----><!---->here<!----></a><!---->. In the Hot Chips talk, Dao indicated that this reduced the number of corrections by a factor of 10.</p> <p>There is additional support for <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1153"><!----><!---->attention sinks<!----></a><!----> and storing <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1152"><!----><!---->the log-sum-exp tensor<!----></a><!----> used in the backwards pass. At time of writing in late September 2025, a backwards version of this kernel is not available, but is expected imminently.</p> <h3 id="four-correction-warps-rescale-previous-outputs-as-the-normalization-changes">Four Correction warps rescale previous outputs as the normalization changes.</h3> <p>The <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1413"><!----><!---->Correction warps<!----></a><!----> update <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1418"><!----><!---->past output results<!----></a><!----> from the MMA warps <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1476-L1477"><!----><!---->as the numerical stability scaling factor changes<!----></a><!---->. The Correction warps need to coordinate their access to the O values in Tensor Memory with the MMA warps (eg <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1533"><!----><!---->here<!----></a><!---->, indicating that those values are consumed and the memory can be reclaimed).</p> <p>Like the Softmax warps, the four Correction warps form a warpgroup. Also like the Softmax warps, they need to load from Tensor Memory to registers to apply their <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1588"><!----><!---->non-matmul rescaling operation<!----></a><!---->.</p> <p>The Correction warps are also responsible for writing the output from Tensor Memory to shared memory and applying the final scaling by the row sum. This is <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1527-L1529"><!----><!---->called the <code>correction_epilogue</code><!----></a><!---->. “Epilogue” here means the same thing as in the name of the “Epilogue” warps — an operation that occurs at the end of a sequence of operations on values stored in one memory and before the results are written to another memory. But in this case, it refers to operations on data in Tensor Memory before they are stored to shared memory, whereas the Epilogue warps take data from shared memory and store it in global memory.</p> <p>This is especially confusing because the completion of this epilogue is the signal for the Epilogue warps to start their work.</p> <p>The Correction warps have the <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1420"><!----><!---->global memory output tensor among their arguments<!----></a><!---->, but only use it in commented-out code.</p> <h3 id="the-epilogue-warps-store-complete-output-tiles-back-into-global-memory">The Epilogue Warp(s) store complete output tiles back into global memory.</h3> <p>There are either one or two <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1737"><!----><!---->Epilogue warps<!----></a><!----> depending on <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L367"><!----><!---->whether the TMA is enabled<!----></a><!---->.</p> <p>In <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1759"><!----><!---->the case that the Epilogue warps can use the TMA<!----></a><!---->, there’s only one and its work is simple. It <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1770"><!----><!---->waits on the correction loop to finish for an output tile<!----></a><!---->, then <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1772-L1773"><!----><!---->runs a TMA copy<!----></a><!---->, then <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1777"><!----><!---->signals that it has finished reading the O tensor in shared memory<!----></a><!----> and the buffer can be reused.</p> <p>If <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1778"><!----><!---->they can’t use the TMA<!----></a><!---->, their work is more complicated — they need to handle <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1780"><!----><!---->slicing<!----></a><!----> and <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1789"><!----><!---->packing<!----></a><!---->, which is <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1787"><!----><!---->pretty hard<!----></a><!---->. It also consumes <a rel="nofollow" href="https://github.com/Dao-AILab/flash-attention/blob/5c1627a7a1cda9c32cb9b937a053564e663f81bc/flash_attn/cute/flash_fwd_sm100.py#L1795"><!----><!---->quite a few more registers<!----></a><!---->.</p> <h2 id="if-you-made-it-this-far-you-might-enjoy-working-at-modal">If you made it this far, you might enjoy working at Modal.</h2> <p>At Modal, we’re building the cloud infrastructure that compute-intensive workloads like giant Transformers need. Our platform is used by companies like <a href="https://modal.com/blog/suno-case-study"><!----><!---->Suno<!----></a><!---->, <a href="https://modal.com/blog/lovable-case-study"><!----><!---->Lovable<!----></a><!---->, <a href="https://modal.com/blog/ramp-case-study"><!----><!---->Ramp<!----></a><!---->, and <a href="https://modal.com/blog/substack-case-study"><!----><!---->Substack<!----></a><!---->. We’re <a href="https://modal.com/careers"><!----><!---->hiring<!----></a><!---->.</p> <p><em>The authors would like to thank Simon Mo of vLLM, Michael Goin of RedHat AI, and Kimbo Chen of SemiAnalysis for their comments on drafts of this article. We’d also like to thank Tri Dao for writing another banger of a kernel.</em></p><!----></article><!----></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Handy – Free open-source speech-to-text app written in Rust (182 pts)]]></title>
            <link>https://handy.computer/</link>
            <guid>45399106</guid>
            <pubDate>Sat, 27 Sep 2025 20:33:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://handy.computer/">https://handy.computer/</a>, See on <a href="https://news.ycombinator.com/item?id=45399106">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-j7pv25f6="" id="main-content" role="main"><div data-astro-cid-j7pv25f6=""><video width="640" height="360" controls="" playsinline="" aria-label="Handy speech-to-text demonstration video" aria-describedby="video-transcript" data-astro-cid-j7pv25f6=""><source src="https://handy.computer/handy-video.mp4" type="video/mp4" data-astro-cid-j7pv25f6=""><source src="https://handy.computer/handy-video.webm" type="video/webm" data-astro-cid-j7pv25f6=""><track kind="captions" src="/handy-video.vtt" srclang="en" label="English captions" default="" data-astro-cid-j7pv25f6=""><p data-astro-cid-j7pv25f6="">
Your browser doesn't support HTML video. <a href="https://handy.computer/handy-video.webm" data-astro-cid-j7pv25f6="">Download the video</a> instead.
</p></video><div id="video-transcript" data-astro-cid-j7pv25f6=""><h3 data-astro-cid-j7pv25f6="">Video Transcript</h3><p data-astro-cid-j7pv25f6="">
CJ: Hello, I'm CJ and I want to show you Handy. Handy is an
                    open source speech-to-text application that you can run on
                    your own computer. Simply press a keyboard shortcut, speak,
                    and release, and Handy will paste whatever you said into the
                    text field you're typing into.
</p><p data-astro-cid-j7pv25f6="">
Let's take a look at the settings menu for Handy, and it's
                    really simple. You have a push-to-talk mode that you can
                    enable, this is enabled by default so you press and hold the
                    keys or alternatively you can turn it off so the
                    transcription starts when you press the key combination and
                    it stops when you press it again. And you can also change
                    what key binding you would like to use for the
                    transcription.
</p><p data-astro-cid-j7pv25f6="">
So now it's mapped to Ctrl-Z and if I turn this off, when I
                    hit control Z, when you look up in the top corner of my Mac
                    here, this little transcription icon lights up. And when I
                    click it again, it turns off and transcribes the audio.
                    There's nothing to paste into. So it just does nothing here.
</p><p data-astro-cid-j7pv25f6="">So sit back, relax, and let Handy give you a hand.</p></div></div><div data-astro-cid-j7pv25f6=""><div data-astro-cid-j7pv25f6=""><h2 data-astro-cid-j7pv25f6="">Free</h2><p data-astro-cid-j7pv25f6="">
Accessibility tooling belongs in everyone's hands, not
                    behind a paywall.
</p></div><div data-astro-cid-j7pv25f6=""><h2 data-astro-cid-j7pv25f6="">Open Source</h2><p data-astro-cid-j7pv25f6="">
Together we can build further. Extend Handy for yourself and
                    contribute to something bigger.
</p></div><div data-astro-cid-j7pv25f6=""><h2 data-astro-cid-j7pv25f6="">Private</h2><p data-astro-cid-j7pv25f6="">
Your voice stays on your computer. Get transcriptions
                    without sending audio to the cloud.
</p></div><div data-astro-cid-j7pv25f6=""><h2 data-astro-cid-j7pv25f6="">Simple</h2><p data-astro-cid-j7pv25f6="">
One tool, one job. Transcribe what you say and put it into a
                    text box.
</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iPhone 17 chip becomes the fastest single-core CPU in the world on PassMark (122 pts)]]></title>
            <link>https://www.tomshardware.com/pc-components/cpus/apples-a19-becomes-the-fastest-single-core-cpu-in-the-world-on-passmark-beating-pc-chips-and-apples-own-m3-ultra-passively-cooled-iphone-17-chip-catapults-past-power-hungry-competitors</link>
            <guid>45398802</guid>
            <pubDate>Sat, 27 Sep 2025 19:48:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/pc-components/cpus/apples-a19-becomes-the-fastest-single-core-cpu-in-the-world-on-passmark-beating-pc-chips-and-apples-own-m3-ultra-passively-cooled-iphone-17-chip-catapults-past-power-hungry-competitors">https://www.tomshardware.com/pc-components/cpus/apples-a19-becomes-the-fastest-single-core-cpu-in-the-world-on-passmark-beating-pc-chips-and-apples-own-m3-ultra-passively-cooled-iphone-17-chip-catapults-past-power-hungry-competitors</a>, See on <a href="https://news.ycombinator.com/item?id=45398802">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH-1451-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH.jpg" alt="Apple A19" srcset="https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH-1451-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/ycugCVL9Mycynwx4LPGKeH.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>(Image credit: Apple)</span>
</figcaption>
</div>

<div id="article-body">
<p id="9598606f-6e07-4467-9c5e-8574022330ed">Apple's latest generation of iPhones is equipped with its A19 chips — the standard A19 on iPhone 17 and the A19 Pro on iPhone 17 Air and Pros — which represent the best the company has to offer, <em>literally</em>. In PassMark's single-threaded benchmark, the A19 produced <a data-analytics-id="inline-link" href="https://x.com/PassMarkInc/status/1971365505710817321" data-url="https://x.com/PassMarkInc/status/1971365505710817321" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">the best numbers of any chip</a> available, including fully-fledged desktop SKUs. It did that while consuming significantly less power and being passively cooled. At least in this hyper-specific case, Apple's A19 has become the fastest CPU available.</p><p>Both the A19 and A19 Pro benchmarked within the margin of error of each other; however, officially, it was the regular A19 that posted 5,149 points to claim the single-thread performance crown. The A19 Pro scored 5,088 points, which makes sense considering both chips share the same cores, just differing amounts of them. The A19 beats heavy hitters like Apple's own desktop-class <a data-analytics-id="inline-link" href="https://www.tomshardware.com/desktops/apple-debuts-m3-ultra-in-refreshed-mac-studio-with-up-to-512gb-memory" data-before-rewrite-localise="https://www.tomshardware.com/desktops/apple-debuts-m3-ultra-in-refreshed-mac-studio-with-up-to-512gb-memory">M3 Ultra</a> (both 28- and 32-core variants), <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/amd-ryzen-9-9950x-vs-intel-core-ultra-9-285k-faceoff-it-isnt-even-close" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/amd-ryzen-9-9950x-vs-intel-core-ultra-9-285k-faceoff-it-isnt-even-close">Intel's Core Ultra 9 285K</a>, and even the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/cpus/new-zen-5-128-core-epyc-cpu-weilds-512mb-of-l3-cache" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/cpus/new-zen-5-128-core-epyc-cpu-weilds-512mb-of-l3-cache">EPYC 4585PX</a> from AMD — all of which would be actively cooled.</p><div id="1971365505710817321"><blockquote data-lang="en"><p lang="en" dir="ltr">This is a pretty incredible single threaded benchmark result from Apple with the A19. Plus it is claimed to use only 12watts. For comparison the Ultra 9 is 125W+ and EPYC 4585PX is 170W+https://t.co/ysO73jpaVv pic.twitter.com/e9niPV5I3y<a href="https://twitter.com/cantworkitout/status/1971365505710817321" data-url="https://twitter.com/cantworkitout/status/1971365505710817321" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">September 26, 2025</a></p></blockquote></div><p id="727fbaf0-c5aa-42b1-b355-91c2dc1f4bca-0">The tweet caption lists nominal TDPs of these chips for comparison, but that's not what a single-core load would actually use. Since it's incredibly difficult to pinpoint that, PassMark itself estimated the single-threaded power consumption <a data-analytics-id="inline-link" href="https://x.com/PassMarkInc/status/1971730057862566329" data-url="https://x.com/PassMarkInc/status/1971730057862566329" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">in a reply</a>, saying the A19 is likely using 4W, the 285K is using 44W, and the EPYC is using 56W. Even if those 1/3 assumptions are wrong, the delta is so high between the three that it doesn't really matter. The A19 is miles ahead in terms of efficiency.</p><p>Where it falters, of course, is multi-threaded performance. It doesn't scale upward when you take more/all cores into account, but that's to be expected with a mobile-only chip, given that it simply has fewer cores than every other CPU on the list. Moreover, keep in mind that the A19 is inside the iPhone 17, which doesn't have a vapor chamber, so it's even more impressive for it to pull these kinds of numbers. Then again, this isn't precisely an uber-scientific test, so don't take these results at face value.</p><p><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank" data-url="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><em>Tom's Hardware on Google News</em></a><em>, or </em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank" data-url="https://google.com/preferences/source?q=" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><em>add us as a preferred source</em></a><em>, to get our up-to-date news, analysis, and reviews in your feeds. Make sure to click the Follow button!</em></p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-oES5rGgX64e8ph3uKSdwEg"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div>
</div>



<!-- Drop in a standard article here maybe? -->




<div id="slice-container-authorBio-oES5rGgX64e8ph3uKSdwEg"><p>Hassam Nasir is a die-hard hardware enthusiast with years of experience as a tech editor and writer, focusing on detailed CPU comparisons and general hardware news. When he’s not working, you’ll find him bending tubes for his ever-evolving custom water-loop gaming rig or benchmarking the latest CPUs and GPUs just for fun.  </p></div>
</section>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[2025 Nikon Small World in Motion Competition Winners (119 pts)]]></title>
            <link>https://www.nikonsmallworld.com/galleries/2025-small-world-in-motion-competition</link>
            <guid>45398731</guid>
            <pubDate>Sat, 27 Sep 2025 19:38:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nikonsmallworld.com/galleries/2025-small-world-in-motion-competition">https://www.nikonsmallworld.com/galleries/2025-small-world-in-motion-competition</a>, See on <a href="https://news.ycombinator.com/item?id=45398731">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <section id="galleryapp" v-touch:swipe.left="pageNext" v-touch:swipe.right="pagePrev">

            <section id="swim-winner_gallery">
    <h2>Winning Videos</h2>
        
        <hr>
    
        
              </section>
              <section id="swim-honorable-mention_gallery">
    <h2>Honorable Mentions</h2>
        
        <hr>
        
    
            
          </section>
      <section id="judges">
    <h2>Judges</h2>
  <div>
                      <div>
          <h3>Dr. Deboki Chakravarti</h3>
          <p><em>Science Communicator</em><br></p>
                    <p><img src="https://www.nikonsmallworld.com/images/bio-photos/_squareThumb2x/Deboki-Chakravarti.jpg" width="120"></p><p>Deboki Chakravarti, PhD is a science writer based out of western Massachusetts who focuses on creating educational science videos and podcasts, including <em>Journey to the Microcosmos</em>, <em>Tiny Matters</em>, <em>Scishow Tangents</em>, and <em>Crash Course Organic Chemistry</em>. From designing better bike seats to existential crises inspired by amoebas, Chakravarti’s work covers a wide range of subjects, all of which are tied together by her fascination with how science interacts with the culture around it. Chakravarti received her PhD in biomedical engineering from Boston University, where she worked on engineering T cells for cancer immunotherapy. Prior to that, she earned her bachelor’s degree in bioengineering and English from The California Institute of Technology.</p>
        </div>
                      <div>
          <h3>Jeff DelViscio</h3>
          <p><em>Chief Multimedia Editor and Executive Producer at Scientific American</em><br></p>
                    <p><img src="https://www.nikonsmallworld.com/images/bio-photos/_squareThumb2x/Jeff-DelViscio.jpg" width="120"></p><p>Jeff DelViscio is the chief multimedia editor/executive producer at <em>Scientific American</em>. He is the former director of multimedia at STAT, where he oversaw all visual, audio, and interactive journalism. Before that, he spent more than eight years at <em>The New York Time</em><em>s</em>, where he worked on five different desks across the paper. DelViscio holds dual master’s degrees from Columbia University in journalism and in earth and environmental sciences. He has worked aboard oceanographic research vessels and tracked money and politics in science from Washington, D.C. He was a Knight Science Journalism Fellow at MIT in 2018–19. DelViscio’s work has won numerous awards, including two News and Documentary Emmys.</p>
        </div>
                      <div>
          <h3><a href="https://www.nikonsmallworld.com/people/andrew-moore">Dr. Andrew Moore</a></h3>
          <p><em>Postdoctoral Scientist in the Lippincott-Schwartz Lab at the Howard Hughes Medical Institute's Janelia Research Campus</em><br><a href="https://www.nikonsmallworld.com/organizations/howard-hughes-medical-institute-hhmi"></a></p>
                    <p><img src="https://www.nikonsmallworld.com/images/bio-photos/_squareThumb2x/andrew-moore.jpg" width="120"></p><p>Andrew Moore, PhD is a postdoctoral scientist in the Lippincott-Schwartz Lab at the Howard Hughes Medical Institute’s Janelia Research Campus who specializes in cell biology with a focus on organelle-cytoskeleton interactions. He completed his graduate training in the Holzbaur Lab at the<a href="https://www.nikonsmallworld.com/organizations/university-of-pennsylvania"> University of Pennsylvania</a>, where he researched mitochondria quality control and dynamics. Currently, Moore’s work centers on understanding how cells organize and position their organelles, particularly exploring the interactions between vimentin intermediate filaments and the endoplasmic reticulum. His research combines advanced light and volume electron microscopy techniques to delve into the complexities of cell structure and function. Moore is no stranger to Nikon Small World; he has <a href="https://www.nikonsmallworld.com/people/andrew-moore">placed six photos and six videos in the competitions</a> since 2018 and he is grateful for the opportunity to experience this year’s competition from the other side of the judges’ table.</p>
        </div>
                      <div>
          <h3>Dr. Liz Roth-Johnson</h3>
          <p><em>Curator of Life Sciences at the California Science Center</em><br></p>
                    <p><img src="https://www.nikonsmallworld.com/images/bio-photos/_squareThumb2x/liz-johnson.jpg" width="120"></p><p>Liz Roth-Johnson, PhD is a scientist turned science communicator with more than a decade of experience making complex scientific ideas accessible and compelling to broad audiences. At the California Science Center, Roth-Johnson oversees the development of fun, memorable exhibit experiences that spark curiosity and inspire science learning in all ages and backgrounds. Recent projects include a Nikon Small World exhibit that explores some of the light microscopy tools and techniques scientists use to study life. Prior to her tenure at the California Science Center, Roth-Johnson created popular online food science content, reported science stories for <em>KQED Science</em>, consulted for the Autry Museum of the American West, and designed introductory biology courses for undergraduate students at UCLA. Roth-Johnson earned her PhD in molecular biology from <a href="https://www.nikonsmallworld.com/organizations/university-of-california-los-angeles">UCLA</a> and received her BA degree from <a href="https://www.nikonsmallworld.com/organizations/university-of-california-berkeley">UC Berkeley</a>, where she majored in molecular &amp; cell biology and music. She completed postdoctoral work as a Discipline-Based Education Research Fellow in the UCLA Department of Life Science Core Education.</p>
        </div>
                      <div>
          <h3>Dr. W. Gregory Sawyer</h3>
          <p><em>Chief BioEngineering Officer and Chair of the Department of BioEngineering at the Moffitt Cancer Center</em><br><a href="https://www.nikonsmallworld.com/organizations/h.-lee-moffitt-cancer-center"></a></p>
                    <p><img src="https://www.nikonsmallworld.com/images/bio-photos/_squareThumb2x/greg-sawyer.jpg" width="120"></p><p>W. Gregory Sawyer, PhD is chief bioengineering officer and chair of the Department of BioEngineering at the Moffitt Cancer Center in Tampa, Florida. Professor Sawyer has published over 200 journal papers, has over 16,000 citations, holds over 40 patents, and is most proud of his numerous PhD students who are now faculty members and scientists across the globe. He was a member of the original Mars Rover Program (NASA-JPL), a speaker at TED 8, led the first remotely space-tribology experiments on the International Space Station (ISS), developed novel biomaterials for the ocular surface, and is currently leading efforts in Cancer Engineering.</p>
        </div>
          </div>
    
      </section>
  </section>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NSPM-7 labels common beliefs as terrorism 'indicators' (112 pts)]]></title>
            <link>https://www.kenklippenstein.com/p/trumps-nspm-7-labels-common-beliefs</link>
            <guid>45398719</guid>
            <pubDate>Sat, 27 Sep 2025 19:35:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kenklippenstein.com/p/trumps-nspm-7-labels-common-beliefs">https://www.kenklippenstein.com/p/trumps-nspm-7-labels-common-beliefs</a>, See on <a href="https://news.ycombinator.com/item?id=45398719">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!fMp7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91129dba-8e6b-4ca7-a4ac-83d34e6abfee_1200x800.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!fMp7!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91129dba-8e6b-4ca7-a4ac-83d34e6abfee_1200x800.webp 424w, https://substackcdn.com/image/fetch/$s_!fMp7!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91129dba-8e6b-4ca7-a4ac-83d34e6abfee_1200x800.webp 848w, https://substackcdn.com/image/fetch/$s_!fMp7!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91129dba-8e6b-4ca7-a4ac-83d34e6abfee_1200x800.webp 1272w, https://substackcdn.com/image/fetch/$s_!fMp7!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91129dba-8e6b-4ca7-a4ac-83d34e6abfee_1200x800.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!fMp7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91129dba-8e6b-4ca7-a4ac-83d34e6abfee_1200x800.webp" width="1200" height="800" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/91129dba-8e6b-4ca7-a4ac-83d34e6abfee_1200x800.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:67314,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.kenklippenstein.com/i/174704382?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91129dba-8e6b-4ca7-a4ac-83d34e6abfee_1200x800.webp&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!fMp7!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91129dba-8e6b-4ca7-a4ac-83d34e6abfee_1200x800.webp 424w, https://substackcdn.com/image/fetch/$s_!fMp7!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91129dba-8e6b-4ca7-a4ac-83d34e6abfee_1200x800.webp 848w, https://substackcdn.com/image/fetch/$s_!fMp7!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91129dba-8e6b-4ca7-a4ac-83d34e6abfee_1200x800.webp 1272w, https://substackcdn.com/image/fetch/$s_!fMp7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F91129dba-8e6b-4ca7-a4ac-83d34e6abfee_1200x800.webp 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Trump displays NSPM-7 at the Oval Office on Thursday</figcaption></figure></div><p><span>With the mainstream media distracted by the made-for-TV drama of James Comey’s indictment, Trump has signed a little-noticed </span><a href="https://www.whitehouse.gov/presidential-actions/2025/09/countering-domestic-terrorism-and-organized-political-violence/" rel="">national security directive</a><span> identifying “anti-Christian” and “anti-American” views as indicators of radical left violence. Called National Security Presidential Memorandum 7, it’s being referred to as “NSPM-7” by administration insiders.</span></p><p>“This is the first time in American history that there is an all-of-government effort to dismantle left wing terrorism,” Trump’s homeland security advisor Stephen Miller said, referring to the issuance.</p><p><span>To the extent that the major media noticed the directive at all, they (even C-SPAN!) incorrectly labeled it an “executive order,” like this week’s </span><a href="https://www.kenklippenstein.com/p/breaking-trump-declares-war-on-left" rel="">designation</a><span> of “Antifa” as a domestic terrorist organization.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!mkJ5!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3af4d84-03ee-40bb-a36f-62363ef39cd4_1220x988.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!mkJ5!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3af4d84-03ee-40bb-a36f-62363ef39cd4_1220x988.png 424w, https://substackcdn.com/image/fetch/$s_!mkJ5!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3af4d84-03ee-40bb-a36f-62363ef39cd4_1220x988.png 848w, https://substackcdn.com/image/fetch/$s_!mkJ5!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3af4d84-03ee-40bb-a36f-62363ef39cd4_1220x988.png 1272w, https://substackcdn.com/image/fetch/$s_!mkJ5!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3af4d84-03ee-40bb-a36f-62363ef39cd4_1220x988.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!mkJ5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3af4d84-03ee-40bb-a36f-62363ef39cd4_1220x988.png" width="1220" height="988" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f3af4d84-03ee-40bb-a36f-62363ef39cd4_1220x988.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:988,&quot;width&quot;:1220,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1379540,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.kenklippenstein.com/i/174704382?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3af4d84-03ee-40bb-a36f-62363ef39cd4_1220x988.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!mkJ5!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3af4d84-03ee-40bb-a36f-62363ef39cd4_1220x988.png 424w, https://substackcdn.com/image/fetch/$s_!mkJ5!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3af4d84-03ee-40bb-a36f-62363ef39cd4_1220x988.png 848w, https://substackcdn.com/image/fetch/$s_!mkJ5!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3af4d84-03ee-40bb-a36f-62363ef39cd4_1220x988.png 1272w, https://substackcdn.com/image/fetch/$s_!mkJ5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3af4d84-03ee-40bb-a36f-62363ef39cd4_1220x988.png 1456w" sizes="100vw"></picture></div></a><figcaption>Come on, C-SPAN</figcaption></figure></div><p>It’s hard to overstate how much different NSPM-7 is from the over 200 executive orders Trump has frantically signed since coming back into office.</p><p>An executive order publicly lays out the course of day-to-day federal government operations; whereas a national security directive is a sweeping policy decree for the defense, foreign policy, intelligence, and law enforcement apparatus. National security directives are often secret, but in this case the Trump administration chose to publish NSPM-7 — only the seventh since he’s come into office.)</p><p><span>Previous national security directives have been controversial, even politically earthshaking. In 1980, for example, President Jimmy Carter signed the Top Secret </span><a href="https://nsarchive2.gwu.edu/nukevault/ebb390/docs/7-25-80%20PD%2059.pdf?utm_source=chatgpt.com" rel="">Presidential Directive 59</a><span> (“PD-59”) directing new nuclear warfighting policies that persisted until the end of the Cold War. When revealed, PD-59 caused a public furor.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!THR3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239e355c-5037-47ed-bfcb-31c582f4e1f0_1872x1304.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!THR3!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239e355c-5037-47ed-bfcb-31c582f4e1f0_1872x1304.png 424w, https://substackcdn.com/image/fetch/$s_!THR3!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239e355c-5037-47ed-bfcb-31c582f4e1f0_1872x1304.png 848w, https://substackcdn.com/image/fetch/$s_!THR3!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239e355c-5037-47ed-bfcb-31c582f4e1f0_1872x1304.png 1272w, https://substackcdn.com/image/fetch/$s_!THR3!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239e355c-5037-47ed-bfcb-31c582f4e1f0_1872x1304.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!THR3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239e355c-5037-47ed-bfcb-31c582f4e1f0_1872x1304.png" width="1456" height="1014" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/239e355c-5037-47ed-bfcb-31c582f4e1f0_1872x1304.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1014,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:442736,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.kenklippenstein.com/i/174704382?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239e355c-5037-47ed-bfcb-31c582f4e1f0_1872x1304.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!THR3!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239e355c-5037-47ed-bfcb-31c582f4e1f0_1872x1304.png 424w, https://substackcdn.com/image/fetch/$s_!THR3!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239e355c-5037-47ed-bfcb-31c582f4e1f0_1872x1304.png 848w, https://substackcdn.com/image/fetch/$s_!THR3!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239e355c-5037-47ed-bfcb-31c582f4e1f0_1872x1304.png 1272w, https://substackcdn.com/image/fetch/$s_!THR3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F239e355c-5037-47ed-bfcb-31c582f4e1f0_1872x1304.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Declassified copy of PD-59 | Carter Library</figcaption></figure></div><p>Similarly, President George W. Bush signed a series of classified national security directives after 9/11, the most famous of which authorized NSA’s unlawful domestic intercepts, a directive that wasn’t publicly revealed until four years later.</p><p><span>In NSPM-7, “Countering Domestic Terrorism and Organized Political Violence,” President Trump </span><em>directs</em><span> the Justice Department, the FBI, and other national security agencies and departments to fight his version of political violence in America, retooling a network of Joint Terrorism Task Forces to focus on “leftist” political violence in America. This vast counterterrorism army, made up of federal, state, and local agents would, as Trump aide Stephen Miller said, form “the central hub of that effort.”</span></p><p>NSPM-7 directs a new national strategy to “disrupt” any individual or groups “that foment political violence,” including “before they result in violent political acts.” </p><p><span>In other words, they’re targeting pre-crime, to reference </span><em>Minority Report</em><span>.</span></p><p>The Trump administration isn’t only targeting organizations or groups but even  individuals and “entities” whom NSPM-7 says can be identified by any of the following “indica” (indicators) of violence:</p><ul><li><p>anti-Americanism,</p></li><li><p>anti-capitalism,</p></li><li><p>anti-Christianity,</p></li><li><p>support for the overthrow of the United States Government,</p></li><li><p>extremism on migration,</p></li><li><p>extremism on race,</p></li><li><p>extremism on gender</p></li><li><p>hostility towards those who hold traditional American views on family,</p></li><li><p>hostility towards those who hold traditional American views on religion, and</p></li><li><p>hostility towards those who hold traditional American views on morality.</p></li></ul><p><span>“The United States requires a national strategy to investigate and disrupt networks, entities, and organizations that foment political violence so that law enforcement can intervene in criminal conspiracies </span><em>before they result in violent political acts</em><span>,” the directive states (emphasis mine).</span></p><p>A “pre-crime” endeavor, preventing attacks before they happen, is core to the post-9/11 concept of counterterrorism itself. No longer satisfied to investigate acts of terrorism after the fact to bring terrorists to justice, the Bush administration adopted preemption. Overseas, that led to aerial assassination by drones and “special operations” kill missions. Domestically, it led to a counter-terrorism campaign whose hallmark was excessive and illegal government surveillance and the use of undercover agents and “confidential human sources” to trap (and entrap) would-be terrorists.</p><p>Now, with Donald Trump’s directive retooling the counter-terror apparatus to go after Americans at home, this means monitoring political activity, or speech, as an investigative method to discover “radicalism.” (Contrary to other national security documents all during the post-Watergate era, NSPM-7 doesn’t even mention the First Amendment or the fundamental right of Americans to organize and protest.)</p><p>The focus on speech is evident throughout NSPM-7. The directive says that political violence is the result of “organized campaigns” that often begin (with the left) dehumanizing targets in “anonymous chat foras, in-person meetings, social media, and even educational institutions.”</p><p><span>To give a sense of how broad this formulation is, Trump’s earlier designation of Antifa as a domestic terrorist group was accompanied by a White House fact sheet singling out people who “celebrated” Luigi Mangione, the alleged killer of UnitedHealthcare CEO Brian Thompson last December. As </span><a href="https://www.kenklippenstein.com/p/breaking-trump-declares-war-on-left" rel="">I wrote at the time</a><span>, this describes a lot of Americans!</span></p><p>Trump’s new national security memorandum also alludes to Mangione but adds to it even larger categories of potential targets.</p><p><span>NSPM-7 is fundamentally a law enforcement directive, and it dispenses with the complications of using the active duty military or the National Guard in pursuit of political violence. It directs the Department of Justice to focus the FBI’s </span><a href="https://www.fbi.gov/investigate/terrorism/joint-terrorism-task-forces" rel="">approximately 200</a><span> Joint Terrorism Task Forces (JTTFs) to the new mission. The FBI network of task forces comprises over 4,000 members—including FBI personnel and task force officers (or TFOs) from more than 500 state and local agencies and 50 federal agencies, including special agents, police officers, intelligence analysts and surveillance technicians. First established in New York City in 1980 to systematize FBI and NYPD cooperation, today there are task forces around the country, including at least one in each of the FBI’s 55 field offices.</span></p><p>For the Trump White House, the beauty of using an already existing network is that it bypasses Congressional oversight and scrutiny and even obscures federal activity to governors and legislatures at the state level. States, cities, and local police have already signed Memoranda of Agreements with the feds to fight terrorism and officers are already assigned as task force officers.</p><p>NSPM-7 says the JTTFs “shall investigate” potential federal crimes relating to “acts of recruiting or radicalizing persons” for the purpose of “political violence, terrorism, or conspiracy against rights; and the violent deprivation of any citizen’s rights.” It authorizes the JTTFs to investigate individuals, organizations, and funders “responsible for, sponsor, or otherwise aid and abet the principal actors engaging in the criminal conduct.”</p><p>“The Attorney General shall issue specific guidance that ensures domestic terrorism priorities include politically motivated terrorist acts such as organized doxing campaigns, swatting, rioting, looting, trespass, assault, destruction of property, threats of violence, and civil disorder,” NSPM-7 says. Civil disorder?</p><p><span>I don’t want to sound hyperbolic but the plain truth is that NSPM-7 is a declaration of war on anyone who does not support the Trump administration and its agenda. Yes, it repeats the word “violent” over and over to purport only to go after citizens who are moved to take up arms, but it also directs monitoring and intelligence collection to map and target the new “evildoers,” to borrow a Bush label </span><a href="https://georgewbush-whitehouse.archives.gov/news/releases/2001/09/20010916-2.html" rel="">he took</a><span> from the Bible just days after 9/11. </span></p><p>The partisan focus couldn’t be more obvious.</p><p>“The real problem is this: since Charlie [Kirk] was murdered — a friend of mine, assassinated — nothing’s changed on their side,” White House counter-terrorism czar Sebastian Gorka told Newsmax after NSPM-7 was signed. “Not one leader —not one left wing thought leader, member of Congress, Senator — nobody has said we distance ourselves from the violent rhetoric.” </p><p>“The left refuses to rid themselves of the justification for violence,” Gorka continued, “and as such, President Trump is taking measures to protect us from the violent rhetoric that becomes snipers and bullets.”</p><p data-attrs="{&quot;url&quot;:&quot;https://www.kenklippenstein.com/p/trumps-nspm-7-labels-common-beliefs/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.kenklippenstein.com/p/trumps-nspm-7-labels-common-beliefs/comments" rel=""><span>Leave a comment</span></a></p><p data-attrs="{&quot;url&quot;:&quot;https://www.kenklippenstein.com/p/trumps-nspm-7-labels-common-beliefs?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.kenklippenstein.com/p/trumps-nspm-7-labels-common-beliefs?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><span>— </span><em>Edited by William M. Arkin</em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Docker Was Too Slow, So We Replaced It: Nix in Production [video] (105 pts)]]></title>
            <link>https://www.youtube.com/watch?v=iPoL03tFBtU</link>
            <guid>45398468</guid>
            <pubDate>Sat, 27 Sep 2025 18:56:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=iPoL03tFBtU">https://www.youtube.com/watch?v=iPoL03tFBtU</a>, See on <a href="https://news.ycombinator.com/item?id=45398468">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[LLM Observability in the Wild – Why OpenTelemetry Should Be the Standard (121 pts)]]></title>
            <link>https://signoz.io/blog/llm-observability-opentelemetry/</link>
            <guid>45398467</guid>
            <pubDate>Sat, 27 Sep 2025 18:56:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://signoz.io/blog/llm-observability-opentelemetry/">https://signoz.io/blog/llm-observability-opentelemetry/</a>, See on <a href="https://news.ycombinator.com/item?id=45398467">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>A few days ago I hosted a live conversation with Pranav, co-founder of Chatwoot, about issues his team was running into with LLM observability.</p><p>The short version: building, debugging, and improving AI agents in production gets messy fast. There's multiple competing standards for default libraries for LLM observability. And many such libraries like OpenInference which claim to be based on OpenTelemetry don't strictly adhere to it's conventions. This introduces problems for users who are trying to get better observability across their stack.</p><p>Here’s a write-up of what we covered and what I think it means for anyone shipping LLM features into real products. Feel free to watch the complete video</p><p><iframe src="https://www.youtube.com/embed/DPL35sYPGPU" title="YouTube Video Player" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe></p><h2 id="the-problem-emerges-in-prod">The Problem Emerges in Prod</h2><p>Pranav and I go way back to our YC days in 2021, and it's always interesting to see how our paths have evolved. Chatwoot has built something really compelling - an open-source customer support platform that unifies conversations across every channel you can imagine: live chat, email, WhatsApp, social media, you name it. All in a single dashboard.</p><p>But here's where it gets interesting. They've built an AI agent called "Captain" that can work across all these channels. You build the logic once, and it can handle support queries whether they come through email, live chat, or WhatsApp. Pretty neat, right?</p><p>The problem started showing up in production in the most unexpected ways. Sometimes their AI would randomly respond in Spanish when it absolutely shouldn't. Other times, responses just weren't quite right, and they had no visibility into <em>why</em>.</p><h2 id="the-quest-for-llm-observability">The Quest for LLM Observability</h2><p>This is where Pranav's journey into LLM observability began, it mirrors what I've been seeing across many companies building LLM applications. You need to understand:</p><ul><li>What documents were retrieved for a RAG query?</li><li>Which tool calls were made?</li><li>What was the exact input and output at each step?</li><li>Why did the AI make certain decisions?</li></ul><p>Without this visibility, you're essentially flying blind in production.</p><h2 id="the-standards-problem">The Standards Problem</h2><p>Here's where things get really interesting, and frankly, frustrating. Pranav explored several solutions:</p><p><strong>OpenAI's native tracing</strong> looked promising with rich, detailed traces showing guardrails, agent flows, and tool calls. But it's tightly coupled to OpenAI's agent framework. Also, it only provides traces as an atomic unit. If you want to filter spans based on attributes or just examine specific spans directly, you can't do that.</p><div data-rmiz-content="not-found" aria-owns="rmiz-modal-" data-rmiz=""><figure><img src="https://signoz.io/img/blog/2025/09/openAI-agent-traces.webp" alt="OpenAI agent workflow traces"><figcaption><i>OpenAI agent workflow traces<!-- --> </i></figcaption></figure></div><p><strong>New Relic</strong> was easy to integrate since they already use it, and it supports OpenTelemetry. But the UI required clicking through 5-6 layers just to see relevant information. Not ideal when you're trying to debug production issues.</p><p><strong>Phoenix</strong> caught their attention because it follows the OpenInference standard, which provides much richer, AI-specific span types. You can easily filter for just LLM calls, tool calls, or agent spans. The traces are beautiful and informative.</p><div data-rmiz-content="not-found" aria-owns="rmiz-modal-" data-rmiz=""><figure><img src="https://signoz.io/img/blog/2025/09/phoenix-unknown.webp" alt="Phoenix doesn't recognize OpenTelemetry span kinds"><figcaption><i>Phoenix doesn't recognize OpenTelemetry span kinds<!-- --> </i></figcaption></figure></div><p>But here's the kicker: Chatwoot is primarily a Ruby on Rails shop, and guess what? No Ruby SDK for OpenInference. Moreover, Phoenix doesn't completely adhere to OTel semantic conventions, so if you send it telemetry data directly via OpenTelemetry, it doesn't recognize the type of spans, etc.</p><p>As shown in the example above, Phoenix doesn't shows data sent with OpenTelemetry span kinds as <code>unknown</code>.</p><h2 id="the-opentelemetry-vs-openinference-divide">The OpenTelemetry vs OpenInference Divide</h2><p>This is where the conversation got really technical and revealed a fundamental industry problem. There are essentially two standards emerging:</p><p><strong>OpenTelemetry</strong> is the industry standard. It has libraries for every language, it's production-ready, and it's widely adopted. But it was built for traditional applications, not AI workflows. It only supports basic span types: internal, server, client, producer, consumer. That's it.</p><p><strong>OpenInference</strong> was created specifically for AI applications. It has rich span types like LLM, tool, chain, embedding, agent, etc. You can easily query for "show me all the LLM calls" or "what were all the tool executions." But it's newer, has limited language support, and isn't as widely adopted.</p><p>The tragic part? OpenInference claims to be "OpenTelemetry compatible," but as Pranav discovered, that compatibility is shallow. You can send OpenTelemetry format data to Phoenix, but it doesn't recognize the AI-specific semantics and just shows everything as "unknown" spans.</p><h2 id="the-ruby-problem-makes-it-worse">The Ruby Problem Makes It Worse</h2><p>For teams using languages like Ruby that don't have direct OpenInference SDK support, this becomes even more challenging. Pranav had to choose between:</p><ol><li>Building an SDK from scratch for Ruby</li><li>Using OpenTelemetry and losing AI-specific insights</li><li>Switching to a different language stack just for AI observability (way tougher)</li></ol><p>None of these are great options.</p><h2 id="why-we-still-bias-to-opentelemetry">Why we (still) bias to OpenTelemetry</h2><p>At SigNoz we’re all-in on OpenTelemetry. One reason: OTel’s consistency enables out-of-the-box experiences across your <em>whole</em> stack. Example: we can auto-surface <a target="_blank" rel="noopener noreferrer" href="https://signoz.io/docs/external-api-monitoring/overview/">external API</a> usage and performance based on span kinds and attributes. When parts of the app send telemetry via non-OTel conventions, those views degrade.</p><p>Chatwoot lands similarly: their entire product already emits OTel. Pulling in a second telemetry standard just for LLMs fragments the picture and complicates how they go about observability. This also silos their observability into different products which makes it difficult to solves issues when they occur.</p><h2 id="takeaways-for-builders">Takeaways for builders</h2><ul><li><strong>Pick one telemetry backbone</strong> - If most of your app is OTel, prefer staying OTel-native for LLMs too, even if it means adding richer attributes until GenAI conventions catch up.</li><li><strong>LLM specific libraries</strong> - Even if you have to use LLM specific libraries like OpenInference, try to keep your usage as close to OpenTelemetry as possible so that you are aware what non-OTel attributes you are using which may break things.</li><li><strong>Follow OTel GenAI working group</strong> - There is active work happening in OTel <a target="_blank" rel="noopener noreferrer" href="https://opentelemetry.io/blog/2024/otel-generative-ai/">Gen AI working group</a>. Follow the work happening there and do share your use cases so that the standards which OpenTelemetry builds are able to cater to most common use cases.</li></ul><p>As the LLM space is still evolving rapidly, we as a community need to share our voices so that the standards are robust.</p><hr><h2 id="what-were-doing-at-signoz">What we’re doing at SigNoz</h2><p>We’re continuing to invest in OpenTelemetry-native LLM observability so teams don’t have to choose between stability and clarity. Concretely, that means:</p><ul><li><p>Clear dashboards and traces when LLM calls are modeled using OTel spans/attributes. You can find examples and dashboards in our <a target="_blank" rel="noopener noreferrer" href="https://signoz.io/docs/llm-observability/">LLM observability</a> docs. Though we have also use LLM specific libraries like OpenInference in our docs (as they are still the easiest way for ppl to get started), we have kept the dashboards as close to OTel standards as possible. We also plan to actively update this as OTel GenAI semantic conventions become more mature.</p></li><li><p>Guidance and examples for popular frameworks (LangChain, LlamaIndex, etc.) on emitting OTel-friendly telemetry.</p></li><li><p>Build features leveraging OpenTelemetry semantic conventions so that you get great out-of-box experience in SigNoz and adhere to thoughtful defaults that keep your services, DBs, queues, and LLM agents—in one coherent picture.</p></li></ul><p>If you’re wrestling with these trade-offs, we’d love to hear what’s breaking for you and what “rich semantics” you actually use day-to-day.</p><hr><h2 id="what-next">What next?</h2><p>Huge thanks to Pranav for going deep, especially from the Ruby perspective. If you’re shipping AI features and care about operability, add your voice: push for richer GenAI semantics in OpenTelemetry, and share real traces (sanitized) that show what you need to see.</p><p>If you want to compare notes or need help getting your LLM telemetry into an OTel-native view, ping me.</p><div><h3>Was this page helpful?</h3></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The death of east London's most radical bookshop (187 pts)]]></title>
            <link>https://www.the-londoner.co.uk/scarlett-letters-closure-left-wing-bookshop/</link>
            <guid>45398153</guid>
            <pubDate>Sat, 27 Sep 2025 18:15:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.the-londoner.co.uk/scarlett-letters-closure-left-wing-bookshop/">https://www.the-londoner.co.uk/scarlett-letters-closure-left-wing-bookshop/</a>, See on <a href="https://news.ycombinator.com/item?id=45398153">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
<div data-layout="minimal">
                
                    <p><a href="#/portal/signup/free"><img src="https://www.the-londoner.co.uk/content/images/2025/07/The-Londoner-icons-3.png" alt="CTA Image" data-image-dimensions="170x170"></a>
                    </p>
                
                
                    <div>
                    
                        <p><span>This article was published by </span><b><strong>The Londoner</strong></b><span>: a new newsletter covering the capital. Join our free mailing list below to get great writing and big scoops in your inbox.</span></p>
                    
                    
                        <p><a href="#/portal/signup/free">
                            Join The Londoner for free
                        </a>
                        
                    </p></div>
                
            </div>
<p>It was 4am on the 1st of July as Jack Parker bolted upright in the basement below the Scarlett Letters bookshop. From above, Parker could hear drilling. Then a “thunderstorm” of footsteps. Startled and bleary-eyed, they hurriedly dressed, then crept up the stairs into the main bookshop. What they saw “horrified” them.</p><p>Dozens of people hurriedly packing books into boxes and unscrewing bookshelves. Amongst the torrent of people, maybe the strangest thing they noticed was the face of Blaise Agüera y Arcas: author, AI researcher and the vice president of Google’s research arm. Peculiar though it was to see one of the most senior staff at one of the world’s biggest tech giants busting into a bookshop occupation in Bethnal Green, maybe what was more peculiar was how it all came about in the first place. The setting for this bizarre scene was the Scarlett Letters, named for its owner Marin Scarlett, a radical east London bookshop that was greeted with widespread fanfare by many of the capital's left-wing activists.</p><p>And here Scarlett was, with a team of people, bursting into the bookshop in the middle of the night in an attempt to disrupt an occupation by a radical cohort of the shop’s staff. To Parker's mind, for a project started with the aim of platforming sex workers and being a “hub for resistance, community, stories and imagination” to have reached such a point was mortifying. How had things gotten so bad? Well, at least in Parker's telling, it started with a clogged toilet.</p><p>Sporting a black T-shirt, cropped hair and anticapitalist and LGBT-rights tattoos on each arm, the former bookseller meets me in the bare, debris-littered unit that used to house the bookshop. We’re here to talk about the whole sorry saga of Scarlett Letters — the rise, the fall, the union disputes, the rows, the occupations and the drilled locks under nightfall. But first, we need to talk toilets.</p><figure><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcdHMQ65c8ly6f0-tKauKHUlkYWoNO1vN9oHlxsjcsdddccqY3Q0aRCaf48hPa9EbBd9sEcNZ8XIOsvqbobkEj9zY-K983KkJoGpD4HFHO_11kUDBnjV8dGsGU8u455bj9XdtGj?key=kMtj8Yn4kpj1VvRQ2cmVqw" alt="" loading="lazy" width="602" height="339"><figcaption><span>The leftover debris in the bookshop now. Image by Andrew Kersley&nbsp;</span></figcaption></figure><p>On a fateful day in early April, less than six months after the shop opened, a plumber had to be called in to fix the disabled toilet, which was inexplicably installed in the non-wheelchair-accessible basement of the bookshop. After the plumber was done, staff opened the work WhatsApp chat to see a message from Marin Scarlett updating the shop’s toilet policy: “We have had an issue over the last few weeks of people just letting themselves downstairs to use the toilet. Our toilet is there for people to use on request, but it is a problem if someone feels they can just let themselves down there without asking.”</p><p>Keen to thwart any further opportunistic toilet-users, Scarlett had a new policy. Staff were to personally escort anyone who asked to use the toilet to ensure they didn’t steal any stock or snoop around the staff area. She then told her staff she wanted to “role play” some scenarios in which they could practice saying “no”. Seemingly, the crux of the toilet problem was that they were simply too kind, too feminine, too British: “You are all extremely nice, assigned female at birth, in customer service, mostly British etc., and all of this sometimes doesn't lend itself to ‘no,’” the WhatsApp message explained. She suggested staff had been failing to tell customers “no” when they asked to borrow scissors or mugs from the shop, to come behind the counter or when they wanted to serenade them without prompting.</p><p>Like a toilet with a burst pipe, “toilet-gate” then erupted. Almost immediately, a dispute broke out in the work WhatsApp over the message; there was anger not just about that final message, which Parker saw as “bizarre and sexist”, but over the political ramifications of making members of the community ask to use the toilet in the bookshop.</p><p>While there had been rumblings of unease from staff for months at the store over the lack of shifts, sick pay and secure contracts, something changed in that moment. “We hadn't broadly discussed unionising with everyone,” explains Parker. “But I saw this, it was like we were in complete solidarity. We needed to unionise immediately.”</p><div data-lexical-signup-form="">
                    <h2><span>Join for free </span></h2>
                    <p><span>This article was published by </span><b><strong>The Londoner</strong></b><span>, a new quality newspaper delivered via email. Four days a week, we send you a carefully chosen story, plus our best recommendations. We prioritise </span><b><strong>quality over quantity</strong></b><span> and everything we send is in your inbox - you don't need to click on any links. To give us a try, join our </span><b><strong>free mailing list </strong></b><span>below. </span></p>
                    
        
        
                    <p><span>Click subscribe and then check your email now to complete your signup.</span></p>
                </div><p>Unionisation at a place like Scarlett Letters might sound a bit strange. It was, after all, billed as a radical left-wing bookshop, not generally the sort of place that should need unions. Even the union was a bit confused. “I was a bit surprised when they contacted us,” explains Matt Collins, an organiser for the United Voices of the World trade union.</p><p>But within a week of “toilet-gate”, every single member of staff at the shop had joined the UVW. They drafted a list of demands, which included being granted sick pay, an end to the use of zero hours contracts<strong><em> </em></strong>and running the shop on co-operative principles (in other words, allowing staff to have a say in management). It was sent to Scarlett at the end of April. An initial meeting between Scarlett and the UVW yielded some agreements, though Scarlett told the meeting she was working six or seven days most weeks, and was earning less per hour than the booksellers, so needed to hire a manager, a move that would mean several of the booksellers would need to be let go.</p><figure><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXe4qzupbRocoxtysLm4mwLcA-k65W2VRjrrykHl5L7A76ILaC0x3ZhvwO1LBY0UpXq4jF1JV-vJIxLa0Z51CgFkXfz-ShSwCrlsDRW18VDwPjq4vehbC0NlrpDqWYkhlX0DfvR-?key=kMtj8Yn4kpj1VvRQ2cmVqw" alt="" loading="lazy" width="602" height="339"><figcaption><span>The now abandoned front of the bookshop. Image by Andrew Kersley</span></figcaption></figure><p>Then there was the tricky business of the bookseller’s call for a co-operative management model. Since opening, the Scarlett Letters hadn’t made a month-by-month profit, but had been kept afloat by savings and a monthly donation of £10,000 from an anonymous “angel investor”. Only Scarlett knew the identity of the investor and she shared a response from the investor that they were considering cutting or even pulling their donation if the shop became a co-operative.</p><p>With the dispute at something of a stalemate, the booksellers reached for the most obvious lever available to them, unleashing a broadside of Instagram posts in Scarlett’s direction. A newly launched account said they were in “open dispute” with their employer over the threats to fire staff and the failure to meet all its demands. “The workers are queer, trans, racialised, disabled, sex workers and students,” it argued. “Their identities have been used to advertise and fundraise for the bookshop as a radical space whilst their voices are not listened to.” As might be expected, there was an outraged response online. Responses on Instagram accused the bookshop of being a “marketing campaign” as well as “colonial”.</p><p>Eight days later, Scarlett fired back on the shop’s Instagram, claiming they had attempted to, or were in the process of meeting, almost all the union’s demands. “Trying to create a space like this in advanced capitalism is extremely difficult,” it read. “The management targeted by this dispute is not a faceless collective of executives in boardrooms. It is one person, who is multiply marginalised, a known member of the community and for the past year has been working for six or seven days a week for the fraction of the salary offered to the booksellers.” It ended with a shocking revelation: the bookshop would now be closing. A meeting with an external HR firm was scheduled for the end of June to discuss the closure and the staff’s redundancies. Scarlett herself said she was surprised at how things escalated and insists she “sent requests to meet again four separate times,” but that “these were ignored or refused”.</p><figure><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcQaeJGZxNUAHmRaV3XG9UANYazwR3_aRFAF2nCWe7LfGGcPhZ9WdMddWiz2tvi-UCzUNiZMFzcQbg9_vDSmu1g9efuZU3CA7saZ61zjXZ1KL_5Lrvhocq3Mrp4vjOg5AfI1ngirA?key=kMtj8Yn4kpj1VvRQ2cmVqw" alt="" loading="lazy" width="602" height="401"><figcaption><span>The bookstore back when it was still open. Image courtesy of Marin Scarlett</span></figcaption></figure><p>And that might have been that. A sad, if fairly run-of-the-mill tale of how an unfortunate toilet clogging thwarted Bethnal Green’s heady dream of a radical bookshop. But that’s not how our story ends, because the soon-to-be jobless booksellers weren’t giving up that easily. In response to Scarlett’s decision, they hatched a plan: they were going to occupy the bookshop.</p><p>Parker is keen to state that they weren’t aiming to make Scarlett hand over the directorship of the shop, rather they wanted her to donate them the stock. Estimating it to be worth £70,000 (Scarlett puts this figure at closer to £10,000) they felt they could use it to start a new bookshop more closely aligned with their political values.&nbsp;</p><p>On the Sunday ahead of the meeting, the staff moved themselves into the crammed two floor bookshop. Parker came with a suitcase, planning to spend four days there. “I didn't have enough money to keep getting the train back and forth from Wimbledon,” they explain. “So I figured that I'll just put myself on the rota for four nights. I was getting a small payment from a porn site that wasn’t a significant amount of money, but enough for the train home.”</p><p>On Monday, they joined the video call on one computer, sitting as a group with the shelves of the store as their backdrop. The meeting would last just a few minutes. They made their demand for the stock to be transferred to them. The official from the HR firm explained, on behalf of Scarlett, that the<strong><em> </em></strong>bookshop’s legal obligations meant the books were “asset-locked” and that there was no legal mechanism to transfer stock to employees for free. As the shop’s director, Scarlett could even be liable and struck off starting a company if she did so. </p><p>But the booksellers didn’t waver. They announced they would be occupying the shop until their demands were met, and abruptly left the call. Next, they hurriedly unfurled a banner announcing the occupation across the storefront. They had the only set of keys, Parker told me, so thought that as long as no-one allowed management to access the building they could stay indefinitely, protected by squatter’s rights.</p><p>By 10pm that night, the three occupiers who volunteered to stay overnight went down to the basement and bedded down, steeling themselves for the weeks of resistance to come. In the end, it would be much shorter than expected.&nbsp;</p><div data-lexical-signup-form="">
                    <h2><span>Join for free </span></h2>
                    <p><span>This article was published by </span><b><strong>The Londoner</strong></b><span>, a new quality newspaper delivered via email. Four days a week, we send you a carefully chosen story, plus our best recommendations. We prioritise </span><b><strong>quality over quantity</strong></b><span> and everything we send is in your inbox - you don't need to click on any links. To give us a try, join our </span><b><strong>free mailing list </strong></b><span>below. </span></p>
                    
        
        
                    <p><span>Click subscribe and then check your email now to complete your signup.</span></p>
                </div><p>What the group hadn’t accounted for, was the foresight of Marin Scarlett. As it happened, on the first day of the occupation she had arranged a locksmith, as well as a team to help her recover the stock. She’d covered every base: even hiring carpenters to remove the bookshelves and bringing along three legal observers to impartially oversee things. At around 4am, they arrived at Scarlett Letters and started drilling.&nbsp;</p><p>Over the next three hours, books were slid into boxes and shelves were unscrewed from walls. At some point in the night, Parker emerged up the stairwell and saw the whole sorry scene play out. “There were people I knew personally, and that just horrified me,” Parker says. </p><figure><img src="https://www.the-londoner.co.uk/content/images/2025/07/AD_4nXfEOTKGm3VN166-4MxvS1ujhRKvzYwdygLYyc1V-dMIRP5192r-NFS1QKTq82oM6DK-OrMqPo_A4BEo9Vwqb7GPdLOWyE9PoLJ_pbUFLNyWIvRhpoVM_yrneF3syb9inxMuJaQY.jpeg" alt="" loading="lazy" width="900" height="982" srcset="https://www.the-londoner.co.uk/content/images/size/w600/2025/07/AD_4nXfEOTKGm3VN166-4MxvS1ujhRKvzYwdygLYyc1V-dMIRP5192r-NFS1QKTq82oM6DK-OrMqPo_A4BEo9Vwqb7GPdLOWyE9PoLJ_pbUFLNyWIvRhpoVM_yrneF3syb9inxMuJaQY.jpeg 600w, https://www.the-londoner.co.uk/content/images/2025/07/AD_4nXfEOTKGm3VN166-4MxvS1ujhRKvzYwdygLYyc1V-dMIRP5192r-NFS1QKTq82oM6DK-OrMqPo_A4BEo9Vwqb7GPdLOWyE9PoLJ_pbUFLNyWIvRhpoVM_yrneF3syb9inxMuJaQY.jpeg 900w" sizes="(min-width: 720px) 720px"><figcaption><span>A sign on the wall of the now empty bookstore announcing its planned reopening. Image by Andrew Kersley</span></figcaption></figure><p>Now, the bookshop is a husk, almost entirely empty apart from the posters announcing future plans to reopen as “The People’s Letters” — a co-operative run by the booksellers that they believe will adhere to more leftist principles than its predecessor. </p><p>Unsurprisingly, Scarlett sees the whole debacle quite differently to the booksellers. She says she “had hoped to work with the union” and that “an improved sick pay was immediately implemented after our first meeting with UVW”. When the talks with the union broke down and things were taken to social media, sales tanked and it became clear that the store couldn’t stay open. The “shop would have stayed open until late July had the booksellers not tried to steal the stock, but their actions forced us to close several weeks early”. When she and a group of friends entered the shop to reclaim the books, they “did not know that anyone was in the property when we entered”.</p><p>Collins has spent 14 years in the trade union movement, but is equally baffled by how things managed to end where they did. “I've never experienced a dispute like it before,” he tells me. “I imagine I never will again.” Here ends the tale of Scarlett Letters, the radical bookshop the capital could have had, only for those dreams to be flushed away.</p>
<div data-layout="immersive">
                    
                        <div>
                            <p><span>Welcome to The Londoner. We’re the capital’s new magazine, delivered entirely by email. Sign up to our </span><a href="https://www.the-londoner.co.uk/young-successful-and-far-right/#/portal/signup/free" rel="noreferrer"><span>mailing list</span></a><span> and get two </span><b><strong>totally free</strong></b><span> editions of The Londoner every week: a Monday briefing, full of everything you need to know about that’s going on in the city; and an in-depth weekend piece like the one you're currently reading.</span></p><p><span>No ads, no gimmicks: just click the button below and get our unique brand of local journalism straight to your inbox. </span></p>
                        </div>
                    
                    
                        <p><a href="#/portal/signup/free">
                            Sign up for free
                        </a>
                        
                    </p></div>



    </div><p>
  <strong>How to comment:</strong><br>
  If you are <i>already a member, </i>
  <a href="#/portal/signin" onmouseover="this.style.textDecoration='underline'" onmouseout="this.style.textDecoration='none'">
     click here to sign in 
  </a> and leave a comment. <br>
  If you aren't a member, 
  <a href="#/portal/signup" onmouseover="this.style.textDecoration='underline'" onmouseout="this.style.textDecoration='none'">
    sign up here 
  </a> to be able to leave a comment. <br>

To add your photo, <a href="https://gravatar.com/" target="_blank" onmouseover="this.style.textDecoration='underline'" onmouseout="this.style.textDecoration='none'">click here to create a profile on Gravatar.</a><br>



  </p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I made a public living room and the internet keeps putting weirder stuff in it (240 pts)]]></title>
            <link>https://www.theroom.lol</link>
            <guid>45398005</guid>
            <pubDate>Sat, 27 Sep 2025 17:59:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theroom.lol">https://www.theroom.lol</a>, See on <a href="https://news.ycombinator.com/item?id=45398005">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="app">
    
    <p>0</p>
    <p>IMAGE RESET ON NEXT PROMPT</p>
    <div id="overlay">
        
        <div id="uploadPane">
          <div id="uploadSection">
            <p id="uploadMessage">Upload a base image to start editing this room.</p>
            
            
          </div>
          <div id="intervalGroup">
            <p><label for="resetInterval">Reset after this many prompts:</label></p>
            
          </div>
        </div>
        <form id="form">
          
          
          
        </form>
        
        <div id="indicatorRow">
          <p>0 here</p>
          <div id="indicatorRight">
            <div id="roomSwitch" aria-label="Room selector"><p><a href="https://www.theroom.lol/">Room 1</a><span>/</span><a href="https://www.theroom.lol/overflow">Room 2</a></p></div>
            <p>--</p>
          </div>
        </div>
      </div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Greenland Is a Beautiful Nightmare (553 pts)]]></title>
            <link>https://matduggan.com/greenland-is-a-beautiful-nightmare/</link>
            <guid>45396754</guid>
            <pubDate>Sat, 27 Sep 2025 15:46:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matduggan.com/greenland-is-a-beautiful-nightmare/">https://matduggan.com/greenland-is-a-beautiful-nightmare/</a>, See on <a href="https://news.ycombinator.com/item?id=45396754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <main id="main-content" role="main">
            
<article>
    

    <figure>
        <img srcset="https://images.unsplash.com/photo-1573995975633-faee0123f31f?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGdyZWVubGFuZHxlbnwwfHx8fDE3NTg5NjI3MzN8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=2000 300w,
                    https://images.unsplash.com/photo-1573995975633-faee0123f31f?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGdyZWVubGFuZHxlbnwwfHx8fDE3NTg5NjI3MzN8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=2000 600w,
                    https://images.unsplash.com/photo-1573995975633-faee0123f31f?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGdyZWVubGFuZHxlbnwwfHx8fDE3NTg5NjI3MzN8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=2000 1000w,
                    https://images.unsplash.com/photo-1573995975633-faee0123f31f?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGdyZWVubGFuZHxlbnwwfHx8fDE3NTg5NjI3MzN8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=2000 2000w" sizes="(max-width: 1000px) 400px, 700px" src="https://images.unsplash.com/photo-1573995975633-faee0123f31f?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGdyZWVubGFuZHxlbnwwfHx8fDE3NTg5NjI3MzN8MA&amp;ixlib=rb-4.1.0&amp;q=80&amp;w=2000" alt="Greenland is a beautiful nightmare" loading="lazy" decoding="async">
            <figcaption><span>Photo by </span><a href="https://unsplash.com/@visitgreenland?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span>Visit Greenland</span></a><span> / </span><a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span>Unsplash</span></a></figcaption>
    </figure>
    
    <div>
            <p>Greenland is a complicated topic here in Denmark. The former colony that is still treated a bit like a colony is something that inspires a lot of emotions. Greenland has been subjected to a lot of unethical experiments by Denmark, from taking their kids to wild experiments in criminal justice. But there is also a genuine pride a lot of people have here for the place and you run into Danes who grew up there more often than I would have guessed. </p><p>When the idea of going to Greenland was introduced to me, I was curious. Having lived in Denmark for awhile, you hear a lot about the former colony and its 55,000 residents. We were invited by a family that my wife was close with growing up and is Danish. They wanted to take their father back to see the place he had spend some time in during his 20s and had left quite an impression. A few drinks in, I said "absolutely let's do it", not realizing we had already committed to going and I had missed the text message chain. </p><p>A few weeks before I went, I realized "I don't know anything about Greenland" and started to watch some YouTube videos. It was about this time when I started to get a pit in my stomach, the "oh god I think I've made a huge mistake" feeling I'm painfully familiar with after a career in tech.  Greenland appeared to have roughly 9 people living there and maybe 5 things to look at. Even professional travel personalities seemed to be scraping the bottom of the barrel. "There's the grocery store again!" they would point out as they slipped down the snowy roads. I couldn't  tell any difference between different towns in the country.</p><p>It reminded me a lot of driving through Indiana. For those not in the US, Indiana is a state in the US famous for being a state one must drive through in order to get somewhere better. If you live in Michigan, a good state and want to go to Illinois, another good state, one must pass through Indiana, a blank state. Because of this little strip here, you often found yourself passing through this place. </p><figure><img src="https://matduggan.com/content/images/2025/09/image-1.png" alt="" loading="lazy" width="470" height="299"></figure><p>Driving through Indiana isn't bad, it's just an empty void. It's like a time machine back to the 90s when people still smoke in restaurants but also there's nothing that sticks out about it. There is nothing distinct about Indiana, it's just a place full of people who got too tired on their way to somewhere better and decided "this is good enough". The difference is that Greenland is very hard to get to, as I was about to learn. </p><p>Finally the day arrived. Me, my wife, daughter, 4 other children and 6 other adults all came to the Copenhagen Airport and held up a gate agent for what felt like an hour to slowly process all of our documents. Meanwhile, I nursed a creeping paranoia that I'd be treated as some sort of American spy, given my government's recent hobby of threatening to purchase entire countries like they're vintage motorcycles on Craigslist.</p><p>The 5 hour flight is uneventful, the children are beautifully behaved and I begin to think "well this seems ok!" like the idiot I am. As I can look down and see the airport, the pilot comes on and informs us that there is too much fog to land safely. <em>Surely fog cannot stop a modern aircraft full of all these dials and screens</em> I think, foolishly. We are informed there is enough fuel to circle the airport for 5 hours to wait for the fog to lift. </p><p>What followed was three hours of flying in lazy circles, like a very expensive, very slow merry-go-round. After the allotted time, we are informed that we must fly to Iceland to refuel and then <em>we will be returning to Denmark</em>. After a total of 15 hours in the air we will be going back to exactly where we started, to do the entire thing again. We were obviously upset at this turn of events, but I noticed the native Greenlandic folks seemed not surprised at this turn of events. As I later learned, this happens <em>all the time</em>. </p><p>The native Greenlanders on board seemed utterly unsurprised by this development, displaying the kind of resigned familiarity that suggested this was Tuesday for them. I began wondering if I could just pretend Iceland was Greenland—surely my family wouldn't notice the difference? But the pilot, apparently reading my mind, announced that no one would be disembarking in Iceland. It felt oddly authoritarian, like being grounded by an airline, as if they knew we'd all just wander off into Reykjavik and call it close enough.</p><p>We crash out in a airport hotel 20 minutes from our apartment after 15 hours in the air and tons of CO2 emissions only to wake up the next day to start again. This time, I notice that all of the people are asking for (and receiving) free beer from the crew that they are stashing in their bags. It turns out soda and beer, really anything that needs to be imported, is pretty expensive in Greenland. The complimentary drinks are there to be kept for later. </p><p>Finally we land. The first thing you notice when you land in Greenland is there are no trees or grass. There is snow and then there is exposed rock. The exterior of the airport is metal but the inside is wood, which is strange because again there are no trees. This would end up being a theme, where buildings representing Denmark were made out of lots of wood, almost to ensure that you understood they weren't from here. We ended up piling all of our stuff into a bus and heading for the hotel in Nuuk. </p><h3 id="nuuk">Nuuk</h3><p>Nuuk is the capital of Greenland and your introduction to the incredible calm of the Greenlandic people. I have never met a less stressed out group of humans in my life. Nobody is really rushing anywhere, it's all pretty quiet and calm. The air is cold and crisp with lots of kids playing outside and just generally enjoying life. </p><figure><img src="https://matduggan.com/content/images/2025/09/image-2.png" alt="" loading="lazy" width="1280" height="840" srcset="https://matduggan.com/content/images/size/w600/2025/09/image-2.png 600w, https://matduggan.com/content/images/size/w1000/2025/09/image-2.png 1000w, https://matduggan.com/content/images/2025/09/image-2.png 1280w" sizes="(min-width: 720px) 720px"></figure><p>The city itself sits in a landscape so dramatically inhospitable it makes the surface of Mars look cozy. Walking through the local mall, half the shops sell gear designed to help you survive what appears to be the apocalypse. Yet somehow, there's traffic. Actual traffic jams in a place where you can walk from one end to the other in twenty minutes. It's like being stuck behind a school bus in your own driveway.</p><figure><img src="https://matduggan.com/content/images/2025/09/image-3.png" alt="" loading="lazy" width="1302" height="1208" srcset="https://matduggan.com/content/images/size/w600/2025/09/image-3.png 600w, https://matduggan.com/content/images/size/w1000/2025/09/image-3.png 1000w, https://matduggan.com/content/images/2025/09/image-3.png 1302w" sizes="(min-width: 720px) 720px"></figure><p>To put this map into some perspective, it is only six kilometers from the sorta furthest tip to the airport. </p><figure><img src="https://matduggan.com/content/images/2025/09/image-4.png" alt="" loading="lazy" width="1368" height="1114" srcset="https://matduggan.com/content/images/size/w600/2025/09/image-4.png 600w, https://matduggan.com/content/images/size/w1000/2025/09/image-4.png 1000w, https://matduggan.com/content/images/2025/09/image-4.png 1368w" sizes="(min-width: 720px) 720px"></figure><p>But riding the bus around Nuuk was a peaceful experience that lets you see pretty much the entire city without needing to book a tour or spend a lot of money. We went to Katuaq, a cultural center with a cafe and a movie theater that was absolutely delicious food. </p><p>But again even riding the bus around it is impossible to escape the feeling that this is a fundamentally hostile to human life place. The sun is bright and during the summer its pretty hot, with my skin feeling like it was starting the burn pretty much the second it was exposed to the light. It's hard to even dress for, with layers of sunscreen, bug spray and then something warm on top if you suddenly got cold. </p><p>The sun, meanwhile, has apparently forgotten how to set, turning our hotel rooms into solar ovens. You wake up in a pool of your own sweat, crack a window for relief, and immediately get hit with air so cold it feels personal. It's like being trapped in a meteorological mood swing.</p><p>So after a night here, we went back to the airport again and flew to our final destination, Ilulissat.</p><h3 id="ilulissat">Ilulissat </h3><figure><img src="https://matduggan.com/content/images/2025/09/FE5AF77D-8082-4A05-B6F4-03B54D9008DE_1_105_c.jpeg" alt="" loading="lazy" width="1024" height="768" srcset="https://matduggan.com/content/images/size/w600/2025/09/FE5AF77D-8082-4A05-B6F4-03B54D9008DE_1_105_c.jpeg 600w, https://matduggan.com/content/images/size/w1000/2025/09/FE5AF77D-8082-4A05-B6F4-03B54D9008DE_1_105_c.jpeg 1000w, https://matduggan.com/content/images/2025/09/FE5AF77D-8082-4A05-B6F4-03B54D9008DE_1_105_c.jpeg 1024w" sizes="(min-width: 720px) 720px"><figcaption><span>My new favorite airport</span></figcaption></figure><p>The flight to our final destination revealed Greenland's true nature: endless, empty hills stretching toward infinity, punctuated by ice formations that look like nature's sculpture garden.</p><figure><img src="https://matduggan.com/content/images/2025/09/F321BAFB-F30A-4D36-A2C6-E85FB3CA3BEB_1_105_c.jpeg" alt="" loading="lazy" width="1024" height="768" srcset="https://matduggan.com/content/images/size/w600/2025/09/F321BAFB-F30A-4D36-A2C6-E85FB3CA3BEB_1_105_c.jpeg 600w, https://matduggan.com/content/images/size/w1000/2025/09/F321BAFB-F30A-4D36-A2C6-E85FB3CA3BEB_1_105_c.jpeg 1000w, https://matduggan.com/content/images/2025/09/F321BAFB-F30A-4D36-A2C6-E85FB3CA3BEB_1_105_c.jpeg 1024w" sizes="(min-width: 720px) 720px"></figure><p>Landing in Ilulissat felt like victory—we'd made it to the actual destination, not just another waypoint in our Arctic odyssey. Walking through the tiny airport, past Danish military recruitment posters (apparently someone, somewhere, thought this place needed defending), I felt genuinely optimistic for the first time in days.</p><p>Well you can sleep easy Danish military, because Ilulissat is completely protected from invasion. The second I stepped outside I was set upon by a flood of mosquitos like I have never experienced before. I have been to the jungles of Vietnam, the swamps of Florida and the Canadian countryside. This was beyond anything I've ever experienced. </p><p>There are bugs in my mouth, ears, eyes and nose almost immediately. The photo below is not me being dramatic, it is actually what is required to keep them off of me. </p><figure><img src="https://matduggan.com/content/images/2025/09/46C37475-5A8C-4702-BC2E-B6B89A12F9D7_4_5005_c.jpeg" alt="" loading="lazy" width="360" height="480"></figure><p>In fact what you need to purchase in order to walk around this area at all are basically bug nets for your face. They're effectively plastic mesh bags that you put on. </p><figure><img src="https://matduggan.com/content/images/2025/09/F3FD1061-F86E-4545-937B-87F8B7FA85E3_1_105_c.jpeg" alt="" loading="lazy" width="768" height="1024" srcset="https://matduggan.com/content/images/size/w600/2025/09/F3FD1061-F86E-4545-937B-87F8B7FA85E3_1_105_c.jpeg 600w, https://matduggan.com/content/images/2025/09/F3FD1061-F86E-4545-937B-87F8B7FA85E3_1_105_c.jpeg 768w" sizes="(min-width: 720px) 720px"></figure><h3 id="the-dogs">The Dogs</h3><p>Our hotel, charming in that "remote Arctic outpost" way, sat adjacent to what I can only describe as a canine correctional facility. Dozens of sled dogs were chained to rocks like some sort of prehistoric parking lot, each with a tiny house they could retreat to when the existential weight of their circumstances became too much.</p><p>Now, I'd always imagined sled dogs living their best life—running through snow, tongues lolling, living the Disney version of Arctic life. I'd never really considered their downtime, assuming they frolicked in meadows or something equally wholesome. The reality was more "minimum security prison with a view."</p><p>The dogs are visited roughly twice a day by the person who owns and feeds them, which was quite the party for the dogs that lost their minds whenever the car pulled up. Soon the kids really looked forward to dog feeding time. The fish scrapes the dogs lived on came out of a chest freezer that was left exposed up on the rock face without electricity and you could smell it from 50 yards away when it opened. </p><p>During one such performance, a fellow parent leaned over and whispered with the casual tone of someone commenting on the weather, "I think that one is dead." Before I could process this information, the frozen canine was unceremoniously launched over a small cliff like a furry discus. A second doggy popsicle followed shortly after, right in front of our assembled children, who watched with the kind of wide-eyed fascination usually reserved for magic shows.</p><figure><img src="https://matduggan.com/content/images/2025/09/IMG_0069-2.jpeg" alt="" loading="lazy" width="2000" height="2667" srcset="https://matduggan.com/content/images/size/w600/2025/09/IMG_0069-2.jpeg 600w, https://matduggan.com/content/images/size/w1000/2025/09/IMG_0069-2.jpeg 1000w, https://matduggan.com/content/images/size/w1600/2025/09/IMG_0069-2.jpeg 1600w, https://matduggan.com/content/images/size/w2400/2025/09/IMG_0069-2.jpeg 2400w" sizes="(min-width: 720px) 720px"></figure><p>We stopped making dog feeding time a group activity after that and had to distract the kids from ravens flying away with tufts of dog fur. </p><h3 id="whales-taste-like-seaweed">Whales taste like seaweed </h3><p>Obviously a big part of Greenland is the nature, specifically the icebergs. Icebergs are incredible and during the week we spend up there, I enjoyed watching them every morning. It's like watching a mountain slowly moving while you sit still. The visual contrast of the ice and the exposed stone is beautiful and peaceful. </p><figure><img src="https://matduggan.com/content/images/2025/09/IMG_1096-copy.jpg" alt="" loading="lazy" width="2000" height="1500" srcset="https://matduggan.com/content/images/size/w600/2025/09/IMG_1096-copy.jpg 600w, https://matduggan.com/content/images/size/w1000/2025/09/IMG_1096-copy.jpg 1000w, https://matduggan.com/content/images/size/w1600/2025/09/IMG_1096-copy.jpg 1600w, https://matduggan.com/content/images/size/w2400/2025/09/IMG_1096-copy.jpg 2400w" sizes="(min-width: 720px) 720px"></figure><p>Finding our tour operator proved to be an exercise in small-town efficiency. The man who gave me directions was the same person who picked us up from the airport, who was also our tour guide, who probably doubled as the mayor and local meteorologist. It was like a one-man civic operation disguised as multiple businesses—the ultimate small-town gig economy.</p><p>The sea around Greenland is calmer than anything I've ever been on before, perfectly calm and serene. All around us whales emerged, thrilling my daughter. However the biggest hit of the entire tour, maybe the entire trip, was a member of the crew who handed each of the kids a giant rock of glacier ice to eat. I had to pull my daughter away to observe the natural beauty as she ate glacier ice like it was ice cream. "LOOK AT MY ICE" she was yelling as they slipped and slid around the deck of this boat. </p><p>So if you've ever wonder "what is a glacier", let me tell you. Greenland has a lot of ice and it pushes out from the land that is covers into the sea. When that happens, a lot of it breaks off. This sounds more exciting than it is. On TV in 4K it looks incredible, giant mountains of ice falling into the ocean. Honestly you can go read the same thing I did <a href="https://science.howstuffworks.com/environmental/earth/geophysics/glacier.htm" rel="noreferrer">here</a>.</p><p>However that doesn't happen very often. So in order for us tourists to be able to see anything, we had to go to a very productive glacier. This means there are constantly small chunks breaking off and falling into the sea. Practically though, it kinda looks like you are a boat in a slushee. It's beautiful and something to see, but also depressing to see along the rock face how much more ice there used to be. </p><p>Back in town, we hopped on the "bus". Now the bus here is clearly a retrofitted party van, complete with blue LED lights. The payment system is zip tied to a desk chair that is, itself, wedged in the front. However the bus works well and does get you around. The confusing part is that you will, once again, sometimes encounter a lot of traffic. People are driving pretty quickly and really seem to have somewhere to go. You also see a lot of fancy cars parked outside of houses here. </p><p>Which begs a pretty basic question. If there was almost nowhere to drive to in Nuuk, where in the <em>hell are these people driving</em>. The distance between the end of the road and the beginning of the road is less than 6 km. Also the process to make a road here is beyond anything you've ever seen. Everything requires a giant pile of explosives. </p><figure><img src="https://matduggan.com/content/images/2025/09/image-5.png" alt="" loading="lazy" width="575" height="561"></figure><p>Where did these vehicles even come from? Why does one ship a BMW to a place accessible only by plane and boat? More importantly, where was everyone going with such determination? It was like watching a very expensive version of bumper cars, except everyone was committed to the illusion that they had somewhere important to be. Everyone had dings and scrapes like crashes were common. </p><h3 id="grocery-store-from-the-sea">Grocery Store from the Sea</h3><p>Anyway, as I dodged speeding cars filled with people heading nowhere, I decided to hop off the bus and head to the grocery store. Inside was less a store and more the idea of a store. There was a lot of alcohol, chips, candy and shelf-stable foods, which all makes sense to me. What was strange was there wasn't a lot else, including meat. Locals couldn't be eating at the local restaurants, where the prices were as high as Berlin or Copenhagen for food. So what were they eating?</p><p>When I asked one of my bus drivers, he told me that it was pretty unusual to buy meat. They purchased a lot of whale and seal meat. I had sorta heard this before, but when we stopped the bus he pointed out a group of men hauling guns out into a small boat to go shoot seals. The guns were held together with a surprising amount of duct tape, which is not something I associate with the wild. </p><p>I had assumed, based on my casual reading of the news, that we were <em>mostly</em> done killing whales. As it turns out, I was wrong. They eat a lot of whale and it is, in fact, not hard to find. If you are curious, whale does not taste fishy. It tastes a little bit like if you cooked reindeer in a pot of seaweed. I wouldn't go out of your way for it, but it's not terrible. </p><p>The argument I've always heard for why people still kill whales is because it's part of their culture and also because it's an important source of protein. When you hear the phrase "part of their culture" I always imagined like traditional boats going out with spears. What I didn't imagine was industrial fishing boats and an industrial crane that lifts the dead whale out of the water for "processing". Some of the illusion is broken when your boat tour guide points out the metal warehouse with the word "whale" on the side. "Yeah the water here was red with blood for a week" the guide said, counting the cigarettes left in a pack he had. </p><h3 id="should-you-go-to-greenland">Should you go to Greenland?</h3><p>It's a wild place unlike anywhere I've ever been. It is the closest I have ever felt to living a sci-fi type experience. The people of Greenland are amazing, tough, calm and kind. I have nothing but positive experiences to recount from the many people I met there, Danish and Greenlandic, who patiently sat through my millions of questions. </p><p>However it is, by far, the least hospitable to human life place I've ever been to. The folks who live there have adapted to the situation in, frankly, genius ways. If that's your idea of a good time, Greenland is perfect for you. Maybe don't get emotionally attached to the sled dogs though. Or the whales. </p>
        </div>



</article>

        </main>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Norway to monitor airborne radioactivity in Svalbard (104 pts)]]></title>
            <link>https://www.highnorthnews.com/en/norway-monitor-airborne-radioactivity-svalbard</link>
            <guid>45396641</guid>
            <pubDate>Sat, 27 Sep 2025 15:35:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.highnorthnews.com/en/norway-monitor-airborne-radioactivity-svalbard">https://www.highnorthnews.com/en/norway-monitor-airborne-radioactivity-svalbard</a>, See on <a href="https://news.ycombinator.com/item?id=45396641">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://www.highnorthnews.com/nb/starter-overvakning-av-radioaktivitet-i-luft-pa-svalbard"><em>Les på norsk.</em></a></p><p>The Finnish Meteorological Institute is to discontinue its air monitoring in Svalbard, and on October 1st, the Norwegian Radiation and Nuclear Safety Authority (DSA) will take over ownership of its air sampling equipment.</p><p>The purpose is to strengthen Norway's ability to monitor airborne radioactivity and increase vigilance in the High North.</p>    <figure>
      
            
  </figure>
<p>"This will be an important supplement to our already existing network of air filter stations in Norway, and particularly important for nuclear preparedness in the North," says Markus Ottosen, section leader for the High North at the DSA.</p><p>"The stations are used to monitor radioactivity in the air, and to assess the size and composition in the event of possible accidents and incidents," Ottosen continues.</p><p>The relevant station near Ny-Ålesund has been in operation since 2000.</p><p>The DSA also has access to data from a similar station on Platåfjellet outside Longyearbyen. This is operated by the research institute NORSAR on behalf of the Comprehensive Nuclear-Test-Ban Treaty Organization.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI model trapped in a Raspberry Pi (123 pts)]]></title>
            <link>https://blog.adafruit.com/2025/09/26/ai-model-trapped-in-raspberry-pi-piday-raspberrypi/</link>
            <guid>45396624</guid>
            <pubDate>Sat, 27 Sep 2025 15:34:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.adafruit.com/2025/09/26/ai-model-trapped-in-raspberry-pi-piday-raspberrypi/">https://blog.adafruit.com/2025/09/26/ai-model-trapped-in-raspberry-pi-piday-raspberrypi/</a>, See on <a href="https://news.ycombinator.com/item?id=45396624">Hacker News</a></p>
Couldn't get https://blog.adafruit.com/2025/09/26/ai-model-trapped-in-raspberry-pi-piday-raspberrypi/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[A WebGL game where you deliver messages on a tiny planet (1691 pts)]]></title>
            <link>https://messenger.abeto.co/</link>
            <guid>45396441</guid>
            <pubDate>Sat, 27 Sep 2025 15:17:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://messenger.abeto.co/">https://messenger.abeto.co/</a>, See on <a href="https://news.ycombinator.com/item?id=45396441">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Scientists say X has lost its professional edge and Bluesky is taking its place (236 pts)]]></title>
            <link>https://www.psypost.org/scientists-say-x-formerly-twitter-has-lost-its-professional-edge-and-bluesky-is-taking-its-place/</link>
            <guid>45396377</guid>
            <pubDate>Sat, 27 Sep 2025 15:10:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.psypost.org/scientists-say-x-formerly-twitter-has-lost-its-professional-edge-and-bluesky-is-taking-its-place/">https://www.psypost.org/scientists-say-x-formerly-twitter-has-lost-its-professional-edge-and-bluesky-is-taking-its-place/</a>, See on <a href="https://news.ycombinator.com/item?id=45396377">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A new study published in <em><a href="https://doi.org/10.1093/icb/icaf127" target="_blank" rel="noopener">Integrative and Comparative Biology</a></em> suggests that scientists are leaving X (formerly known as Twitter) in significant numbers due to its declining professional value. The survey of over 800 researchers and science communicators indicates that many now find Bluesky to be a more effective platform for networking, outreach, and staying updated on research. The findings suggest a significant shift in how scientists interact online, with Bluesky emerging as a preferred space for professional engagement.</p><p>Twitter, once considered the central gathering place for scientists on social media, has changed dramatically in recent years. The platform, now officially called “X,” was purchased by Elon Musk in late 2022. Since then, changes to how the platform is moderated and how content appears in users’ feeds have raised concerns among many users, especially academics.</p><p>Reports have pointed to a rise in misinformation, conspiracy theories, and harassment, particularly directed at minority groups. These shifts appear to have made the platform less welcoming and less useful for professional tasks. As Twitter’s character evolved, so too did the willingness of researchers to remain active on the platform.</p><p>In its place, Bluesky has gained attention as a new space for academic interaction. Although other platforms like Threads and Mastodon have also positioned themselves as alternatives, Bluesky appears to be the primary destination for scientists migrating from X. Against this backdrop, researchers set out to document whether scientists were truly abandoning X and whether Bluesky was filling the gap.</p><p>“I am a scholar of public understanding (and misunderstanding) of science and the environment, and have long been fascinated by where people learn things about nature. Social media has become one of the leading sources of information about the world, but the social media landscape is changing, and I wanted to see how my professional colleagues were adapting,” said study author David Shiffman, a marine biologist and public science engagement specialist based in Washington, D.C, and author of <em><a href="https://www.press.jhu.edu/books/title/12267/why-sharks-matter" target="_blank" rel="noopener">Why Sharks Matter</a></em>.</p><p>To investigate these questions, researchers distributed a survey to professional scientists, science communicators, and educators who had used both X and Bluesky for work-related purposes. In total, 813 individuals participated. The survey asked when participants joined each platform, how they used them, and how their experiences had changed over time.</p><p>The responses showed that X had once served a wide range of professional purposes. Nearly all respondents had used it to learn about developments in their fields, and most had relied on it for networking and public outreach. Many also used it for job postings, research promotion, and casual professional conversation.</p><p>However, those same users reported a sharp decline in the usefulness of X. Roughly three-quarters said the platform was now “much less useful” for networking and science communication. Two-thirds said it was less helpful for keeping up with developments in their field.</p><p>The vast majority described their experience on Twitter as increasingly unpleasant, citing irrelevant content, ads, spam, extremist posts, and a loss of meaningful engagement. Some described ethical discomfort with continuing to use a platform that appeared to tolerate, or even amplify, harassment and misinformation.</p><p>In terms of actual usage patterns, only 11 percent of respondents said they still actively use X. Nearly 40 percent had deleted their accounts entirely. Almost half said they still had accounts but rarely used them.</p><p>In contrast, users reported that Bluesky was meeting many of their professional needs. Like Twitter in its earlier days, Bluesky offered a space for learning, networking, and public engagement. Over 94 percent said they used Bluesky to stay informed about research in their field, and nearly 88 percent used it for professional networking. A majority said the new platform was more useful than X for these purposes.</p><p>The researchers also explored why people chose to try Bluesky. Nearly half said they were invited by a colleague or saw others in the science community making the shift. Many viewed Bluesky’s features — such as stronger moderation tools, less algorithmic interference, and more control over what appears in their feed — as more aligned with their professional goals.</p><p>Others said they were simply trying to avoid X’s drawbacks. More than a quarter said they moved to Bluesky because of what they perceived as a rise in extremism on X, and many explicitly named Elon Musk as a reason for their departure.</p><p>“The degree to which the scientific community’s experiences mirrored my own was surprising,” Shiffman told PsyPost. “I knew that for me, Twitter had become unusable, but the extent to which hundreds of surveyed experts strongly agreed with me on almost every point was surprising. You rarely see that kind of strong agreement in surveys.”</p><p>These results provide new evidence to support what other studies and media reports have been suggesting for some time: that X’s role as a hub for academic communication is fading. A previous study <a href="https://www.psypost.org/elon-musks-twitter-takeover-triggered-academic-exodus-study-suggests/" target="_blank" rel="noopener">documented a noticeable drop in academic activity on X</a> after Musk’s acquisition. That research tracked over 15,000 academic accounts and found a significant reduction in tweets, especially original posts and quote tweets, starting in November 2022. Verified users — typically more established academics — were especially likely to reduce their engagement.</p><p>Both studies indicate that changes to how X is managed and moderated have had measurable effects on academic use of the platform. The new survey adds further weight to this idea by showing that scientists are not just using X less — they are actively replacing it with another platform.</p><p>What makes the current study distinctive is its focus on Bluesky as the replacement. While earlier data showed general declines in X use, this survey points to a specific alternative that scientists are embracing. And unlike the earlier study, which focused on activity levels, the new survey captures users’ motivations and perceptions, offering a more detailed view of what is driving this migration.</p><p>“For many years, Twitter was the leading platform used by academics for a wide variety of purposes, including public education about science,” Shiffman explained. “I was a Twitter power-user and evangelist for a decade, and I trained thousands of scientists how to use the platform. Changes to the platform made by Elon Musk, including changing the algorithm to promote extremist views and changes to harassment policy, have made Twitter almost unusable for professional purposes, and academics are abandoning Twitter in droves. Fortunately, alternatives exist, and I, along with many other academics, prefer Bluesky of the available alternatives.”</p><p>The authors note that the survey was limited to users who had already made the switch from X to Bluesky, or were using both platforms. This means it does not account for those who may have stopped using social media altogether or migrated to other platforms. Because the survey was shared primarily through one author’s network, it may reflect the perspectives of those within particular academic communities more than others.</p><p>Another open question concerns whether Bluesky can support the same level of diversity that once defined the science community on X. Movements like Black Birders Week and Queer in STEM gained traction through Twitter’s large, visible networks. It remains unclear whether Bluesky can foster similar grassroots engagement. The authors suggest this should be the focus of future research, particularly if scientists want to ensure that new digital spaces remain inclusive.</p><p>There is also the issue of platform longevity. Whether Bluesky can maintain momentum over time — or whether users will need to shift again — is uncertain. But for now, it appears to offer what many researchers were missing from X: a sense of community, professional utility, and control over their online interactions.</p><p>The study, “<a href="https://doi.org/10.1093/icb/icaf127" target="_blank" rel="noopener">Scientists no Longer Find Twitter Professionally Useful, and have Switched to Bluesky</a>,” was authored by David S. Shiffman and Julia Wester.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Role of Amazon fires in the record atmospheric CO₂ growth in 2024 (156 pts)]]></title>
            <link>https://essopenarchive.org/doi/full/10.22541/essoar.175874118.83695562/v1</link>
            <guid>45396284</guid>
            <pubDate>Sat, 27 Sep 2025 15:02:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://essopenarchive.org/doi/full/10.22541/essoar.175874118.83695562/v1">https://essopenarchive.org/doi/full/10.22541/essoar.175874118.83695562/v1</a>, See on <a href="https://news.ycombinator.com/item?id=45396284">Hacker News</a></p>
Couldn't get https://essopenarchive.org/doi/full/10.22541/essoar.175874118.83695562/v1: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Thoughts on Cloudflare (148 pts)]]></title>
            <link>https://xn--gckvb8fzb.com/thoughts-on-cloudflare/</link>
            <guid>45396234</guid>
            <pubDate>Sat, 27 Sep 2025 14:55:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xn--gckvb8fzb.com/thoughts-on-cloudflare/">https://xn--gckvb8fzb.com/thoughts-on-cloudflare/</a>, See on <a href="https://news.ycombinator.com/item?id=45396234">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Thoughts on its role and impact on the web’s landscape.</p><div><p>As many of you know, I am skeptical of the concept of relying on <em>someone else’s
computer</em>, especially when a service grows to the point where it becomes an
oligopoly, or worse, a monopoly. Cloudflare is, in my view, on track to becoming
precisely that. As a result, I would argue they are a net negative for the
internet and society at large.</p><p>Besides the frustration they cause to VPN and Tor users through incessant
captchas, Cloudflare’s infamous <em>one more step</em> pages have dulled users'
vigilance, making them more vulnerable to
<a href="https://www.bleepingcomputer.com/news/security/new-latrodectus-malware-attacks-use-microsoft-cloudflare-themes/#google_vignette">even the most blatant malware attacks</a>.</p><p>Moreover, under the guise of <em>iNnOvAtIvE cLoUd InFrAsTrUcTuRe</em>, Cloudflare not
only enable <a href="https://thehackernews.com/2024/05/new-tricks-in-phishing-playbook.html">phishermen to phish</a> and
<a href="https://www.csoonline.com/article/649000/attackers-use-cloudflare-tunnel-to-proxy-into-victim-networks.html">tunnelers to tunnel</a>:</p><p>Ironically, the very security measures they sell can be
<a href="https://www.bleepingcomputer.com/news/security/cloudflare-ddos-protections-ironically-bypassed-using-cloudflare/">bypassed by bad actors using Cloudflare itself</a>. It’s a similar
irony that their systems, designed to shield clients from threats, sometimes
struggle to <a href="https://www.bleepingcomputer.com/news/technology/cloudflare-website-downed-by-ddos-attack-claimed-by-anonymous-sudan/">defend their own infrastructure</a>.</p><p>Incidents like these highlight not only weaknesses in Cloudflare’s offerings but
a broader issue: Cloudflare has become
<a href="https://www.securityweek.com/cloudflare-hacked-by-suspected-state-sponsored-attacker/">a highly attractive target for state-sponsored attacks</a>,
suffering from <a href="https://www.msspalert.com/news/cloudflare-hit-again-by-okta-breach-atlassian-server-compromised">recurring breaches</a>. Their sheer scale, considering
that they are serving a substantial portion of the internet, means that an
outage or compromise could have widespread, costly consequences.</p><p>Another major concern is, that in many cases, Cloudflare acts as a
man-in-the-middle SSL-terminating proxy between users and websites. They have
visibility into everything users do on these sites, from browsing habits to
submitting sensitive personal information. This makes Cloudflare a prime target
for any actor seeking to harvest massive amounts of data. The
<a href="https://en.wikipedia.org/wiki/Cloudbleed">Cloudbleed incident</a> clearly demonstrated the risks:</p><blockquote><p>Tavis Ormandy posted the issue on his team’s issue tracker and said that he
informed Cloudflare of the problem on February 17. In his own proof-of-concept
attack he got a Cloudflare server to return “private messages from major
dating sites, full messages from a well-known chat service, online password
manager data, frames from adult video sites, hotel bookings. We’re talking
full https requests, client IP addresses, full responses, cookies, passwords,
keys, data, everything.”</p></blockquote><p>I stand with <a href="https://www.devever.net/~hl/cloudflare">Hugo</a> in considering Cloudflare harmful and recommend
that websites avoid relying on it whenever possible. Cloudflare’s origins in
<a href="https://web.archive.org/web/20100517055332if_/http://www.projecthoneypot.org:80/cloudflare_beta.html"><em>Project Honeypot</em></a>, and its early ties to the US Department
of Homeland Security, are troubling to say the least:</p><blockquote><p>Five years later Mr Prince was doing a Master of Business Administration (MBA)
at Harvard Business School, and the project was far from his mind, when he got
an unexpected phone call from the US Department of Homeland Security asking
him about the information he had gathered on attacks.</p><p>Mr Prince recalls: “They said ‘do you have any idea how valuable the data you
have is? Is there any way you would sell us that data?’. “I added up the cost
of running it, multiplied it by ten, and said ‘how about $20,000 (£15,000)?’.</p><p>“It felt like a lot of money. That cheque showed up so fast.”</p><p>Mr Prince, who has a degree in computer science, adds: “I was telling the
story to Michelle Zatlyn, one of my classmates, and she said, ‘if they’ll pay
for it, other people will pay for it’.”</p></blockquote><p><a href="https://www.bbc.com/news/business-37348016#:~:text=got%20an%20unexpected%20phone%20call%20from%20the%20US%20Department%20of%20Homeland%20Security">Source: BBC</a></p><p>Furthermore, Cloudflare has been <a href="https://www.glassdoor.com/Overview/Working-at-Cloudflare-EI_IE430862.11,21.htm">criticized as an employer</a>, reportedly
fostering a <a href="https://www.benzinga.com/markets/equities/24/01/36621316/cloudflare-ceo-says-viral-firing-video-is-painful-we-were-far-from-perfect-we-dont-always-get-it">hire-and-fire culture</a> among its
<a href="https://fortune.com/2023/07/10/cloudflare-ceo-says-exclusionary-culture-hurts-utahs-tech-status-but-admits-mormon-missionaries-grow-up-to-be-great-salespeople-youre-selling-the-toughest-thing-in-the-world/">sales staff</a>. Even its CEO has attracted controversy, such as
<a href="https://www.theregister.com/2024/04/29/cloudflare_ceo_dog_lawsuit/">suing neighbors over their dogs</a> following objections to
<a href="https://parkcityut.portal.civicclerk.com/event/342/files/attachment/2421">his plans</a> to build an 11,300-square-foot estate. Plans that required
lobbying to <a href="https://archive.ph/tGptp">overcome local zoning laws</a>.</p><p>Given all this, it is time to reconsider Cloudflare’s
<a href="https://6sense.com/tech/content-delivery-network-cdn">dominant market position</a>, controlling
<a href="https://blog.cloudflare.com/cloudflares-annual-founders-letter-2022/">over 20% of the internet</a>. Cloudflare has shown a pattern of
<a href="https://arstechnica.com/tech-policy/2022/03/cloudflare-wont-cut-off-russia-says-it-needs-more-internet-access-not-less/">equivocating on politically sensitive issues</a>, perhaps to maintain
its status as <a href="https://www.spamhaus.org/resource-hub/botnet-c-c/botnet-threat-update-q1-2020/">the world’s largest botnet operator</a>, and they appear
to defend “free speech” <a href="https://www.jwz.org/blog/2017/12/cloudflare-really-wants-that-sweet-sweet-nazi-cash-to-return/">when it is profitable</a>, but not
<a href="https://www.vice.com/en/article/8xk78x/switter-down-cloudflare-banned-sex-workers-sesta-fosta">when it isn’t</a>. Cloudflare has also been accused of
<a href="https://cyberscoop.com/cloudflare-ipo-terrorism-narcotics/">providing services to terrorists and drug traffickers</a> while
<a href="https://www.wsj.com/articles/cloud-services-company-cloudflare-discloses-potential-sanctions-violations-11568152033">skirting international sanctions</a>. Meanwhile,
<a href="https://www.coindesk.com/policy/2024/05/14/tornado-cash-developer-alexey-pertsev-found-guilty-of-money-laundering/">open-source developers</a> have been harshly punished for less.</p><p>Despite the brilliance of many engineers at Cloudflare, they are not infallible.
They, too, experience <a href="https://www.datacenterdynamics.com/en/news/cloudflare-suffers-second-power-outage-at-flexential-data-center-in-oregon-in-six-months/">recurring downtime</a> and
<a href="https://www.theverge.com/2022/6/21/23176519/cloudflare-outage-june-2022-discord-shopify-fitbit-peleton">preventable mistakes</a>. Cloudflare, like any other company,
<a href="https://blog.cloudflare.com/deep-dive-into-cloudflares-sept-12-dashboard-and-api-outage/">puts its pants on</a> <a href="https://www.fastly.com/blog/debunking-cloudflares-recent-performance-tests/">one leg at a time</a>. There is no reason it
should be treated as the default, or sole, solution for content delivery.</p><h2 id="so-what-can-i-do"><em>So what can I do?</em></h2><p>If running your own <a href="https://varnish-cache.org/">Varnish</a> instances isn’t feasible, and you need a global
CDN, consider these alternatives to support competition and balance the scales:</p><ul><li>BlazingCDN</li><li>BunnyCDN</li><li>CDN77</li><li>CDNetworks</li><li>CacheFly</li><li>DigitalOcean Spaces</li><li>Fastly CDN</li><li>KeyCDN</li><li>Netlify Edge</li><li>Vultr CDN</li><li>… or just any other cloud provider’s CDN</li></ul><p><strong>Info:</strong> Some hosting services might use Cloudflare without disclosing it
openly/obviously, e.g. <em>Render</em>. Make sure to check whatever hosting service
that you’re using whether it employs Cloudflare’s infrastructure in the
background.</p><p>If you currently have domains registered with Cloudflare, move them elsewhere
immediately. As a general rule, never allow your CDN or hosting provider to also
hold your domain registrations. Should the hosting provider cut you off, you’ll
want the freedom to quickly redirect your domains to another provider without
disruption.</p><p>For more info, visit the <a href="https://xn--gckvb8fzb.com/infrastructure/#cloud">cloud</a> and <a href="https://xn--gckvb8fzb.com/infrastructure/#domains">domains</a> sections of the <a href="https://xn--gckvb8fzb.com/infrastructure/">infrastructure</a>
page.</p><p>If, however, you’re running Cloudflare’s more advanced service offers, like
Cloudflare Workers, you will likely have a harder time moving away. While some
frameworks support different providers, like Vercel, Fastly, AWS, Azure, or
Akamai, it is likely that most <em>simple</em> implementations will be heavily reliant
on Cloudflare’s architecture. There’s unfortunately no easy path out of this,
other than rewriting the specific components and infrastructure deployment
configuration to support a different provider.</p><p>If you wish to identify or avoid websites that make use of Cloudflare, you can
use this browser extension for <a href="https://addons.mozilla.org/en-US/firefox/addon/cloudflare-optics/">Firefox</a> and <a href="https://chromewebstore.google.com/detail/cloudflare-optics/mdjgbjnbdnhneejmmaabmccfehigbjbe">Chrome</a>
(ironically created by Cloudflare). Beware that these extensions <em>might</em>
transfer information about your browsing behavior to Cloudflare. Configure them
to be active only when manually clicked on specific websites that you want
investigate. There are third-party alternatives like <a href="https://chromewebstore.google.com/detail/cloudbleed-indicator/kpemamadacmlpafjkboflojhlhcjekli">this</a> and
<a href="https://chromewebstore.google.com/detail/claire/fgbpcgddpmjmamlibbaobboigaijnmkl">this</a>, as well as older/unmaintained extensions like <a href="https://github.com/traktofon/cf-detect">this</a>
and <a href="https://github.com/lilydjwg/cf-pop">this</a>.</p><p>PS: <a href="https://decentraleyes.org/">Decentraleyes</a> is a solid option to enhance browsing privacy; check the
<a href="https://xn--gckvb8fzb.com/infrastructure/#browsing">browser</a> section for other helpful extensions.</p><p>All that said, you might think <em>“Come on, Cloudflare isn’t that bad!”</em>, and
you’d be right: Every now and then, they <a href="https://torrentfreak.com/serie-a-legal-action-claims-cloudflare-helps-pirates-evade-piracy-shield-240528/">do <em>some</em> good</a>.
<em>*smirk*</em> Still, we have to recognize that Cloudflare has grown into a
cornerstone of modern digital infrastructure, which is a role that could
eventually render it <a href="https://en.wikipedia.org/wiki/Too_big_to_fail"><em>too big too fail</em></a>, to borrow a term from the
financial world.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SSH3: Faster and rich secure shell using HTTP/3 (455 pts)]]></title>
            <link>https://github.com/francoismichel/ssh3</link>
            <guid>45395991</guid>
            <pubDate>Sat, 27 Sep 2025 14:27:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/francoismichel/ssh3">https://github.com/francoismichel/ssh3</a>, See on <a href="https://news.ycombinator.com/item?id=45395991">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p><a target="_blank" rel="noopener noreferrer" href="https://github.com/francoismichel/ssh3/blob/main/resources/figures/ssh3.png"><img src="https://github.com/francoismichel/ssh3/raw/main/resources/figures/ssh3.png"></a>
</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">SSH3 is probably going to change its name. It is still the SSH Connection Protocol (RFC4254) running on top of HTTP/3 Extended connect, but the required changes are heavy and
too distant from the philosophy of popular SSH implementations to be considered for integration. The <a href="https://datatracker.ietf.org/doc/draft-michel-remote-terminal-http3/" rel="nofollow">specification draft</a> has already been renamed ("Remote Terminals over HTTP/3"),
but we need some time to come up with a nice permanent name.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">SSH3: faster and rich secure shell using HTTP/3</h2><a id="user-content-ssh3-faster-and-rich-secure-shell-using-http3" aria-label="Permalink: SSH3: faster and rich secure shell using HTTP/3" href="#ssh3-faster-and-rich-secure-shell-using-http3"></a></p>
<p dir="auto">SSH3 is a complete revisit of the SSH
protocol, mapping its semantics on top of the HTTP mechanisms. It comes from our research work and we (researchers) recently proposed it as an <a href="https://www.ietf.org/how/ids/" rel="nofollow">Internet-Draft</a> (<a href="https://datatracker.ietf.org/doc/draft-michel-remote-terminal-http3/" rel="nofollow">draft-michel-remote-terminal-http3-00</a>).</p>
<p dir="auto">In a nutshell, SSH3 uses <a href="https://datatracker.ietf.org/doc/html/rfc9000" rel="nofollow">QUIC</a>+<a href="https://datatracker.ietf.org/doc/html/rfc8446" rel="nofollow">TLS1.3</a> for
secure channel establishment and the <a href="https://www.rfc-editor.org/rfc/rfc9110.html#name-authorization" rel="nofollow">HTTP Authorization</a> mechanisms for user authentication.
Among others, SSH3 allows the following improvements:</p>
<ul dir="auto">
<li>Significantly faster session establishment</li>
<li>New HTTP authentication methods such as <a href="https://datatracker.ietf.org/doc/html/rfc6749" rel="nofollow">OAuth 2.0</a> and <a href="https://openid.net/specs/openid-connect-core-1_0.html" rel="nofollow">OpenID Connect</a> in addition to classical SSH authentication</li>
<li>Robustness to port scanning attacks: your SSH3 server can be made <strong>invisible</strong> to other Internet users</li>
<li>UDP port forwarding in addition to classical TCP port forwarding</li>
<li>All the features allowed by the modern QUIC protocol: including connection migration (soon) and multipath connections</li>
</ul>
<div dir="auto"><p dir="auto">Tip</p><p dir="auto">Quickly want to get started ? Checkout how to <a href="#installing-ssh3">install SSH3</a>. You will learn to <a href="#deploying-an-ssh3-server">setup an SSH3 server</a> and <a href="#using-the-ssh3-client">use the SSH3 client</a>.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">⚡ SSH3 is faster</h2><a id="user-content--ssh3-is-faster" aria-label="Permalink: ⚡ SSH3 is faster" href="#-ssh3-is-faster"></a></p>
<p dir="auto">Faster for session establishment, not throughput ! SSH3 offers a significantly faster session establishment than SSHv2. Establishing a new session with SSHv2 can take 5 to 7 network round-trip times, which can easily be noticed by the user. SSH3 only needs 3 round-trip times. The keystroke latency in a running session is unchanged.</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/francoismichel/ssh3/blob/main/resources/figures/ssh3_100ms_rtt.gif"><img src="https://github.com/francoismichel/ssh3/raw/main/resources/figures/ssh3_100ms_rtt.gif" data-animated-image=""></a>
<i>SSH3 (top) VS SSHv2 (bottom) session establishement with a 100ms ping towards the server.</i>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔒 SSH3 security</h2><a id="user-content--ssh3-security" aria-label="Permalink: 🔒 SSH3 security" href="#-ssh3-security"></a></p>
<p dir="auto">While SSHv2 defines its own protocols for user authentication and secure channel establishment, SSH3 relies on the robust and time-tested mechanisms of TLS 1.3, QUIC and HTTP. These protocols are already extensively used to secure security-critical applications on the Internet such as e-commerce and Internet banking.</p>
<p dir="auto">SSH3 already implements the common password-based and public-key (RSA and EdDSA/ed25519) authentication methods. It also supports new authentication methods such as OAuth 2.0 and allows logging in to your servers using your Google/Microsoft/Github accounts.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🧪 SSH3 is still experimental</h3><a id="user-content--ssh3-is-still-experimental" aria-label="Permalink: 🧪 SSH3 is still experimental" href="#-ssh3-is-still-experimental"></a></p>
<p dir="auto">While SSH3 shows promise for faster session establishment, it is still at an early proof-of-concept stage. As with any new complex protocol, <strong>expert cryptographic review over an extended timeframe is required before reasonable security conclusions can be made</strong>.</p>
<p dir="auto">We are developing SSH3 as an open source project to facilitate community feedback and analysis. However, we <strong>cannot yet endorse its appropriateness for production systems</strong> without further peer review. Please collaborate with us if you have relevant expertise!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🥷 Do not deploy the SSH3 server on your production servers for now</h3><a id="user-content--do-not-deploy-the-ssh3-server-on-your-production-servers-for-now" aria-label="Permalink: 🥷 Do not deploy the SSH3 server on your production servers for now" href="#-do-not-deploy-the-ssh3-server-on-your-production-servers-for-now"></a></p>
<p dir="auto">Given the current prototype state, we advise <em>testing SSH3 in sandboxed environments or private networks</em>. Be aware that making experimental servers directly Internet-accessible could introduce risk before thorough security vetting.</p>
<p dir="auto">While <a href="#-your-ssh3-public-server-can-be-hidden">hiding</a> servers behind secret paths has potential benefits, it does not negate the need for rigorous vulnerability analysis before entering production. We are excited by SSH3's future possibilities but encourage additional scrutiny first.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🥷 Your SSH3 public server can be hidden</h2><a id="user-content--your-ssh3-public-server-can-be-hidden" aria-label="Permalink: 🥷 Your SSH3 public server can be hidden" href="#-your-ssh3-public-server-can-be-hidden"></a></p>
<p dir="auto">Using SSH3, you can avoid the usual stress of scanning and dictionary attacks against your SSH server. Similarly to your secret Google Drive documents, your SSH3 server can be hidden behind a secret link and only answer to authentication attempts that made an HTTP request to this specific link, like the following:</p>
<div data-snippet-clipboard-copy-content="ssh3-server -bind 192.0.2.0:443 -url-path <my-long-secret>"><pre><code>ssh3-server -bind 192.0.2.0:443 -url-path &lt;my-long-secret&gt;
</code></pre></div>
<p dir="auto">By replacing <code>&lt;my-long-secret&gt;</code> by, let's say, the random value <code>M3MzkxYWMxMjYxMjc5YzJkODZiMTAyMjU</code>, your SSH3 server will only answer to SSH3 connection attempts made to the URL <code>https://192.0.2.0:443/M3MzkxYWMxMjYxMjc5YzJkODZiMTAyMjU</code> and it will respond a <code>404 Not Found</code> to other requests. Attackers and crawlers on the Internet can therefore not detect the presence of your SSH3 server. They will only see a simple web server answering 404 status codes to every request.</p>
<p dir="auto"><strong>NOTE WELL</strong>: placing your SSH3 server behind a secret URL may reduce the impact of scanning attacks but will and must <em>never</em> replace classical authentication mechanisms. The secret link should only be used to avoid your host to be discovered. Knowing the secret URL should not grant someone access to your server. Use the classical authentication mechanisms described above to protect your server.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">💐 SSH3 is already feature-rich</h2><a id="user-content--ssh3-is-already-feature-rich" aria-label="Permalink: 💐 SSH3 is already feature-rich" href="#-ssh3-is-already-feature-rich"></a></p>
<p dir="auto">SSH3 provides new feature that could not be provided by the SSHv2 protocol.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Brand new features</h3><a id="user-content-brand-new-features" aria-label="Permalink: Brand new features" href="#brand-new-features"></a></p>
<ul dir="auto">
<li><strong>UDP port forwarding</strong>: you can now access your QUIC, DNS, RTP or any UDP-based server that are only reachable from your SSH3 host.
UDP packets are forwarded using QUIC datagrams.</li>
<li><strong>X.509 certificates</strong>: you can now use your classical HTTPS certificates to authenticate your SSH3 server. This mechanism is more secure than the classical SSHv2 host key mechanism. Certificates can be obtained easily using LetsEncrypt for instance.</li>
<li><strong>Hiding</strong> your server behind a secret link.</li>
<li><strong>Keyless</strong> secure user authentication using <strong>OpenID Connect</strong>. You can connect to your SSH3 server using the SSO of your company or your Google/Github account, and you don't need to copy the public keys of your users anymore.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Famous OpenSSH features implemented</h3><a id="user-content-famous-openssh-features-implemented" aria-label="Permalink: Famous OpenSSH features implemented" href="#famous-openssh-features-implemented"></a></p>
<p dir="auto">This SSH3 implementation already provides many of the popular features of OpenSSH, so if you are used to OpenSSH, the process of adopting SSH3 will be smooth. Here is a list of some OpenSSH features that SSH3 also implements:</p>
<ul dir="auto">
<li>Parses <code>~/.ssh/authorized_keys</code> on the server</li>
<li>Certificate-based server authentication</li>
<li><code>known_hosts</code> mechanism when X.509 certificates are not used.</li>
<li>Automatically using the <code>ssh-agent</code> for public key authentication</li>
<li>SSH agent forwarding to use your local keys on your remote server</li>
<li>Direct TCP port forwarding (reverse port forwarding will be implemented in the future)</li>
<li>Proxy jump (see the <code>-proxy-jump</code> parameter). If A is an SSH3 client and B and C are both SSH3 servers, you can connect from A to C using B as a gateway/proxy. The proxy uses UDP forwarding to forward the QUIC packets from A to C, so B cannot decrypt the traffic A&lt;-&gt;C SSH3 traffic.</li>
<li>Parses <code>~/.ssh/config</code> on the client and handles the <code>Hostname</code>, <code>User</code>, <code>Port</code> and <code>IdentityFile</code> config options (the other options are currently ignored). Also parses a new <code>UDPProxyJump</code> that behaves similarly to OpenSSH's <code>ProxyJump</code>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🙏 Community support</h2><a id="user-content--community-support" aria-label="Permalink: 🙏 Community support" href="#-community-support"></a></p>
<p dir="auto">Help us progress SSH3 responsibly! We welcome capable security researchers to review our codebase and provide feedback. Please also connect us with relevant standards bodies to potentially advance SSH3 through the formal IETF/IRTF processes over time.</p>
<p dir="auto">With collaborative assistance, we hope to iteratively improve SSH3 towards safe production readiness. But we cannot credibly make definitive security claims without evidence of extensive expert cryptographic review and adoption by respected security authorities. Let's work together to realize SSH3's possibilities!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installing SSH3</h2><a id="user-content-installing-ssh3" aria-label="Permalink: Installing SSH3" href="#installing-ssh3"></a></p>
<p dir="auto">You can either download the last <a href="https://github.com/francoismichel/ssh3/releases">release binaries</a>,
<a href="#installing-ssh3-and-ssh3-server-using-go-install">install it using <code>go install</code></a> or generate these binaries yourself by compiling the code from source.</p>
<div dir="auto"><p dir="auto">Tip</p><p dir="auto">SSH3 is still experimental and is the fruit of a research work. If you are afraid of deploying publicly a new SSH3 server, you can use the
<a href="#-your-ssh3-public-server-can-be-hidden">secret path</a> feature of SSH3 to hide it behing a secret URL.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installing ssh3 and ssh3-server using Go install</h3><a id="user-content-installing-ssh3-and-ssh3-server-using-go-install" aria-label="Permalink: Installing ssh3 and ssh3-server using Go install" href="#installing-ssh3-and-ssh3-server-using-go-install"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="go install github.com/francoismichel/ssh3/cmd/...@latest"><pre>go install github.com/francoismichel/ssh3/cmd/...@latest</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Compiling SSH3 from source</h3><a id="user-content-compiling-ssh3-from-source" aria-label="Permalink: Compiling SSH3 from source" href="#compiling-ssh3-from-source"></a></p>
<p dir="auto">You need a recent <a href="https://go.dev/dl/" rel="nofollow">Golang</a> version to do this.
Downloading the source code and compiling the binaries can be done with the following steps:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/francoismichel/ssh3    # clone the repo
cd ssh3
go build -o ssh3 cmd/ssh3/main.go                        # build the client
CGO_ENABLED=1 go build -o ssh3-server cmd/ssh3-server/main.go   # build the server, requires having gcc installed"><pre>git clone https://github.com/francoismichel/ssh3    <span><span>#</span> clone the repo</span>
<span>cd</span> ssh3
go build -o ssh3 cmd/ssh3/main.go                        <span><span>#</span> build the client</span>
CGO_ENABLED=1 go build -o ssh3-server cmd/ssh3-server/main.go   <span><span>#</span> build the server, requires having gcc installed</span></pre></div>
<p dir="auto">If you have root/sudo privileges and you want to make ssh3 accessible to all you users,
you can then directly copy the binaries to <code>/usr/bin</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cp ssh3 /usr/bin/ &amp;&amp; cp ssh3-server /usr/bin"><pre>cp ssh3 /usr/bin/ <span>&amp;&amp;</span> cp ssh3-server /usr/bin</pre></div>
<p dir="auto">Otherwise, you can simply add the executables to your <code>PATH</code> environment variable by adding
the following line at the end of your <code>.bashrc</code> or equivalent:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export PATH=$PATH:/path/to/the/ssh3/directory"><pre><span>export</span> PATH=<span>$PATH</span>:/path/to/the/ssh3/directory</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Deploying an SSH3 server</h3><a id="user-content-deploying-an-ssh3-server" aria-label="Permalink: Deploying an SSH3 server" href="#deploying-an-ssh3-server"></a></p>
<p dir="auto">Before connecting to your host, you need to deploy an SSH3 server on it. There is currently
no SSH3 daemon, so right now, you will have to run the <code>ssh3-server</code> executable in background
using <code>screen</code> or a similar utility.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">As SSH3 runs on top of HTTP/3, a server needs an X.509 certificate and its corresponding private key. Public certificates can be generated automatically for your public domain name through Let's Encrypt using the <code>-generate-public-cert</code> command-line argument on the server. If you do not want to generate a certificate signed by a real certificate authority or if you don't have any public domain name, you can generate a self-signed one using the <code>-generate-selfsigned-cert</code> command-line argument. Self-signed certificates provide you with similar security guarantees to SSHv2's host keys mechanism, with the same security issue: you may be vulnerable to machine-in-the-middle attacks during your first connection to your server. Using real certificates signed by public certificate authorities such as Let's Encrypt avoids this issue.</p>
</div>
<p dir="auto">Here is the usage of the <code>ssh3-server</code> executable:</p>
<div data-snippet-clipboard-copy-content="Usage of ./ssh3-server:
  -bind string
        the address:port pair to listen to, e.g. 0.0.0.0:443 (default &quot;[::]:443&quot;)
  -cert string
        the filename of the server certificate (or fullchain) (default &quot;./cert.pem&quot;)
  -key string
        the filename of the certificate private key (default &quot;./priv.key&quot;)
  -enable-password-login
        if set, enable password authentication (disabled by default)
  -generate-public-cert value
        Automatically produce and use a valid public certificate usingLet's Encrypt for the provided domain name. The flag can be used several times to generate several certificates.If certificates have already been generated previously using this flag, they will simply be reused without being regenerated. The public certificates are automatically renewed as long as the server is running. Automatically-generated IP public certificates are not available yet.
  -generate-selfsigned-cert
        if set, generates a self-self-signed cerificate and key that will be stored at the paths indicated by the -cert and -key args (they must not already exist)
  -url-path string
        the secret URL path on which the ssh3 server listens (default &quot;/ssh3-term&quot;)
  -v    verbose mode, if set
  -version
        if set, displays the software version on standard output and exit"><pre><code>Usage of ./ssh3-server:
  -bind string
        the address:port pair to listen to, e.g. 0.0.0.0:443 (default "[::]:443")
  -cert string
        the filename of the server certificate (or fullchain) (default "./cert.pem")
  -key string
        the filename of the certificate private key (default "./priv.key")
  -enable-password-login
        if set, enable password authentication (disabled by default)
  -generate-public-cert value
        Automatically produce and use a valid public certificate usingLet's Encrypt for the provided domain name. The flag can be used several times to generate several certificates.If certificates have already been generated previously using this flag, they will simply be reused without being regenerated. The public certificates are automatically renewed as long as the server is running. Automatically-generated IP public certificates are not available yet.
  -generate-selfsigned-cert
        if set, generates a self-self-signed cerificate and key that will be stored at the paths indicated by the -cert and -key args (they must not already exist)
  -url-path string
        the secret URL path on which the ssh3 server listens (default "/ssh3-term")
  -v    verbose mode, if set
  -version
        if set, displays the software version on standard output and exit
</code></pre></div>
<p dir="auto">The following command starts a public SSH3 server on port 443 with a valid Let's Encrypt public certificate
for domain <code>my-domain.example.org</code> and answers to new sessions requests querying the <code>/ssh3</code> URL path:</p>
<div data-snippet-clipboard-copy-content="ssh3-server -generate-public-cert my-domain.example.org -url-path /ssh3"><pre><code>ssh3-server -generate-public-cert my-domain.example.org -url-path /ssh3
</code></pre></div>
<p dir="auto">If you don't have a public domain name (i.e. only an IP address), you can either use an existing certificate
for your IP address using the <code>-cert</code> and <code>-key</code> arguments or generate a self-signed certificate using the
<code>-generate-selfsigned-cert</code> argument.</p>
<p dir="auto">If you have existing certificates and keys, you can run the server as follows to use them=</p>
<div data-snippet-clipboard-copy-content="ssh3-server -cert /path/to/cert/or/fullchain -key /path/to/cert/private/key -url-path /ssh3"><pre><code>ssh3-server -cert /path/to/cert/or/fullchain -key /path/to/cert/private/key -url-path /ssh3
</code></pre></div>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Similarly to OpenSSH, the server must be run with root priviledges to log in as other users.</p>
</div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Authorized keys and authorized identities</h4><a id="user-content-authorized-keys-and-authorized-identities" aria-label="Permalink: Authorized keys and authorized identities" href="#authorized-keys-and-authorized-identities"></a></p>
<p dir="auto">By default, the SSH3 server will look for identities in the <code>~/.ssh/authorized_keys</code> and <code>~/.ssh3/authorized_identities</code> files for each user.
<code>~/.ssh3/authorized_identities</code> allows new identities such as OpenID Connect (<code>oidc</code>) discussed <a href="#openid-connect-authentication-still-experimental">below</a>.
Popular key types such as <code>rsa</code>, <code>ed25519</code> and keys in the OpenSSH format can be used.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using the SSH3 client</h3><a id="user-content-using-the-ssh3-client" aria-label="Permalink: Using the SSH3 client" href="#using-the-ssh3-client"></a></p>
<p dir="auto">Once you have an SSH3 server running, you can connect to it using the SSH3 client similarly to what
you did with your classical SSHv2 tool.</p>
<p dir="auto">Here is the usage of the <code>ssh3</code> executable:</p>
<div data-snippet-clipboard-copy-content="Usage of ssh3:
  -pubkey-for-agent string
        if set, use an agent key whose public key matches the one in the specified path
  -privkey string
        private key file
  -use-password
        if set, do classical password authentication
  -forward-agent
        if set, forwards ssh agent to be used with sshv2 connections on the remote host
  -forward-tcp string
        if set, take a localport/remoteip@remoteport forwarding localhost@localport towards remoteip@remoteport
  -forward-udp string
        if set, take a localport/remoteip@remoteport forwarding localhost@localport towards remoteip@remoteport
  -proxy-jump string
    	if set, performs a proxy jump using the specified remote host as proxy
  -insecure
        if set, skip server certificate verification
  -keylog string
        Write QUIC TLS keys and master secret in the specified keylog file: only for debugging purpose
  -use-oidc string
        if set, force the use of OpenID Connect with the specified issuer url as parameter
  -oidc-config string
        OpenID Connect json config file containing the &quot;client_id&quot; and &quot;client_secret&quot; fields needed for most identity providers
  -do-pkce
        if set, perform PKCE challenge-response with oidc
  -v    if set, enable verbose mode"><pre><code>Usage of ssh3:
  -pubkey-for-agent string
        if set, use an agent key whose public key matches the one in the specified path
  -privkey string
        private key file
  -use-password
        if set, do classical password authentication
  -forward-agent
        if set, forwards ssh agent to be used with sshv2 connections on the remote host
  -forward-tcp string
        if set, take a localport/remoteip@remoteport forwarding localhost@localport towards remoteip@remoteport
  -forward-udp string
        if set, take a localport/remoteip@remoteport forwarding localhost@localport towards remoteip@remoteport
  -proxy-jump string
    	if set, performs a proxy jump using the specified remote host as proxy
  -insecure
        if set, skip server certificate verification
  -keylog string
        Write QUIC TLS keys and master secret in the specified keylog file: only for debugging purpose
  -use-oidc string
        if set, force the use of OpenID Connect with the specified issuer url as parameter
  -oidc-config string
        OpenID Connect json config file containing the "client_id" and "client_secret" fields needed for most identity providers
  -do-pkce
        if set, perform PKCE challenge-response with oidc
  -v    if set, enable verbose mode
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Private-key authentication</h4><a id="user-content-private-key-authentication" aria-label="Permalink: Private-key authentication" href="#private-key-authentication"></a></p>
<p dir="auto">You can connect to your SSH3 server at my-server.example.org listening on <code>/my-secret-path</code> using the private key located in <code>~/.ssh/id_rsa</code> with the following command:</p>
<div data-snippet-clipboard-copy-content="  ssh3 -privkey ~/.ssh/id_rsa username@my-server.example.org/my-secret-path"><pre><code>  ssh3 -privkey ~/.ssh/id_rsa username@my-server.example.org/my-secret-path
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Agent-based private key authentication</h4><a id="user-content-agent-based-private-key-authentication" aria-label="Permalink: Agent-based private key authentication" href="#agent-based-private-key-authentication"></a></p>
<p dir="auto">The SSH3 client works with the OpenSSH agent and uses the classical <code>SSH_AUTH_SOCK</code> environment variable to
communicate with this agent. Similarly to OpenSSH, SSH3 will list the keys provided by the SSH agent
and connect using the first key listen by the agent by default.
If you want to specify a specific key to use with the agent, you can either specify the private key
directly with the <code>-privkey</code> argument like above, or specify the corresponding public key using the
<code>-pubkey-for-agent</code> argument. This allows you to authenticate in situations where only the agent has
a direct access to the private key but you only have access to the public key.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Password-based authentication</h4><a id="user-content-password-based-authentication" aria-label="Permalink: Password-based authentication" href="#password-based-authentication"></a></p>
<p dir="auto">While discouraged, you can connect to your server using passwords (if explicitly enabled on the <code>ssh3-server</code>)
with the following command:</p>
<div data-snippet-clipboard-copy-content="  ssh3 -use-password username@my-server.example.org/my-secret-path"><pre><code>  ssh3 -use-password username@my-server.example.org/my-secret-path
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Config-based session establishment</h4><a id="user-content-config-based-session-establishment" aria-label="Permalink: Config-based session establishment" href="#config-based-session-establishment"></a></p>
<p dir="auto"><code>ssh3</code> parses your OpenSSH config. Currently, it only handles the <code>Hostname</code>; <code>User</code>, <code>Port</code> and <code>IdentityFile</code> OpenSSH options.
It also adds new option only used by SSH3, such as <code>URLPath</code> or <code>UDPProxyJump</code>. <code>URLPath</code> allows you to omit the secret URL path in your
SSH3 command. <code>UDPProxyJump</code> allows you to perform SSH3 (#proxy-jump)[Proxy Jump] and has the same meaning as the <code>-proxy-jump</code> command-line argument.
Let's say you have the following lines in your OpenSSH config located in <code>~/.ssh/config</code> :</p>
<div data-snippet-clipboard-copy-content="IgnoreUnknown URLPath
Host my-server
  HostName 192.0.2.0
  User username
  IdentityFile ~/.ssh/id_rsa
  URLPath /my-secret-path"><pre><code>IgnoreUnknown URLPath
Host my-server
  HostName 192.0.2.0
  User username
  IdentityFile ~/.ssh/id_rsa
  URLPath /my-secret-path
</code></pre></div>
<p dir="auto">Similarly to what OpenSSH does, the following <code>ssh3</code> command will connect you to the SSH3 server running on 192.0.2.0 on UDP port 443 using public key authentication with the private key located in <code>.ssh/id_rsa</code> :</p>
<div data-snippet-clipboard-copy-content="  ssh3 my-server/my-secret-path"><pre><code>  ssh3 my-server/my-secret-path
</code></pre></div>
<p dir="auto">If you do not want a config-based utilization of SSH3, you can read the sections below to see how to use the CLI parameters of <code>ssh3</code>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">OpenID Connect authentication (still experimental)</h4><a id="user-content-openid-connect-authentication-still-experimental" aria-label="Permalink: OpenID Connect authentication (still experimental)" href="#openid-connect-authentication-still-experimental"></a></p>
<p dir="auto">This feature allows you to connect using an external identity provider such as the one
of your company or any other provider that implements the OpenID Connect standard, such as Google Identity,
Github or Microsoft Entra. The authentication flow is illustrated in the GIF below.</p>
<div dir="auto">
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/francoismichel/ssh3/blob/main/resources/figures/ssh3_oidc.gif"><img src="https://github.com/francoismichel/ssh3/raw/main/resources/figures/ssh3_oidc.gif" width="75%" data-animated-image=""></a></p><p dir="auto"><em>Secure connection without private key using a Google account.</em></p>
</div>
<p dir="auto">The way it connects to your identity provider is configured in a file named <code>~/.ssh3/oidc_config.json</code>.
Below is an example <code>config.json</code> file for use with a Google account. This configuration file is an array
and can contain several identity providers configurations.</p>
<div dir="auto" data-snippet-clipboard-copy-content="[
    {
        &quot;issuer_url&quot;: &quot;https://accounts.google.com&quot;,
        &quot;client_id&quot;: &quot;<your_client_id>&quot;,
        &quot;client_secret&quot;: &quot;<your_client_secret>&quot;
    }
]"><pre>[
    {
        <span>"issuer_url"</span>: <span><span>"</span>https://accounts.google.com<span>"</span></span>,
        <span>"client_id"</span>: <span><span>"</span>&lt;your_client_id&gt;<span>"</span></span>,
        <span>"client_secret"</span>: <span><span>"</span>&lt;your_client_secret&gt;<span>"</span></span>
    }
]</pre></div>
<p dir="auto">This might change in the future, but currently, to make this feature work with your Google account, you will need to setup a new experimental application in your Google Cloud console and add your email as authorized users.
This will provide you with a <code>client_id</code> and a <code>client_secret</code> that you can then set in your <code>~/.ssh3/oidc_config.json</code>. On the server side, you just have to add the following line in your <code>~/.ssh3/authorized_identities</code>:</p>
<div data-snippet-clipboard-copy-content="oidc <client_id> https://accounts.google.com <email>"><pre><code>oidc &lt;client_id&gt; https://accounts.google.com &lt;email&gt;
</code></pre></div>
<p dir="auto">We currently consider removing the need of setting the client_id in the <code>authorized_identities</code> file in the future.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Proxy jump</h4><a id="user-content-proxy-jump" aria-label="Permalink: Proxy jump" href="#proxy-jump"></a></p>
<p dir="auto">It is often the case that some SSH hosts can only be accessed through a gateway. SSH3 allows you to perform a Proxy Jump similarly to what is proposed by OpenSSH.
You can connect from A to C using B as a gateway/proxy. B and C must both be running a valid SSH3 server. This works by establishing UDP port forwarding on B to forward QUIC packets from A to C.
The connection from A to C is therefore fully end-to-end and B cannot decrypt or alter the SSH3 traffic between A and C.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First Malicious MCP in the Wild: The Postmark Backdoor Stealing Your Emails (278 pts)]]></title>
            <link>https://www.koi.security/blog/postmark-mcp-npm-malicious-backdoor-email-theft</link>
            <guid>45395957</guid>
            <pubDate>Sat, 27 Sep 2025 14:23:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.koi.security/blog/postmark-mcp-npm-malicious-backdoor-email-theft">https://www.koi.security/blog/postmark-mcp-npm-malicious-backdoor-email-theft</a>, See on <a href="https://news.ycombinator.com/item?id=45395957">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="blog-rich-text"><p>You know MCP servers, right? Those handy tools that let your AI assistant send emails, run database queries, basically handle all the tedious stuff we don't want to do manually anymore. Well, here's the thing not enough people talk about: we're giving these tools god-mode permissions. Tools built by people we've never met. People we have zero way to vet. And our AI assistants? We just... trust them. Completely.</p><p>Which brings me to why I'm writing this. <code>postmark-mcp</code> - downloaded <strong>1,500 times every single week</strong>, integrated into hundreds of developer workflows. Since version <code>1.0.16</code>, it's been quietly copying every email to the developer's personal server. I'm talking password resets, invoices, internal memos, confidential documents - everything.</p><p>This is the<strong> world’s first sighting of a real world malicious MCP server</strong>. The attack surface for endpoint supply chain attacks is slowly becoming the enterprise’s biggest attack surface.</p><h2>So… What Did Our Risk Engine Detect?</h2><p>Here's how this whole thing started. Our risk engine at Koi flagged <code>postmark-mcp</code> when version <code>1.0.16</code> introduced some suspicious behavior changes. When our researchers dug into it, like we do to any malware our risk engine flags, what we found was very disturbing.</p><p>On paper, this package looked perfect. The developer? Software engineer from Paris, using his real name, GitHub profile packed with legitimate projects. This wasn't some shady anonymous account with an anime avatar. This was a real person with a real reputation, someone you'd probably grab coffee with at a conference.</p><p>For 15 versions - FIFTEEN - the tool worked flawlessly. Developers were recommending it to their teams. "Hey, check out this great MCP server for Postmark integration." It became part of developer’s daily workflows, as trusted as their morning coffee.</p><p>Then version 1.0.16 dropped. Buried on line 231, our risk engine found this gem:</p><figure><p><img src="https://cdn.prod.website-files.com/689ad8c5d13f40cf59df0e0c/68d2dbea5498f5d66a60eaea_carbon%20(11)%20(1).png" loading="lazy" alt=""></p><figcaption>A simple line that steals thousands of emails</figcaption></figure><p>One single line. And boom - every email now has an unwanted passenger.</p><p>Here's the thing - there's a completely legitimate GitHub repo with the same name, officially maintained by Postmark (ActiveCampaign). The attacker took the legitimate code from their repo, added his malicious BCC line, and published it to npm under the same name. Classic impersonation.</p><p>Look, I get it. Life happens. Maybe the developer hit financial troubles. Maybe someone slid into his DMs with an offer he couldn't refuse. Hell, maybe he just woke up one day and thought "I wonder if I could get away with this." We'll never really know what flips that switch in someone's head - what makes a legitimate developer suddenly decide to backstab 1,500 users who trusted them.</p><p>But that's exactly the point. We CAN'T know. We can't predict it. And when it happens? Most of us won't even notice until it's way too late. For modern enterprises the problem is even more severe. As security teams focus on traditional threats and compliance frameworks, developers are independently adopting AI tools that operate completely outside established security perimeters. These MCP servers run with the same privileges as the AI assistants themselves - full email access, database connections, API permissions - yet they don't appear in any asset inventory, skip vendor risk assessments, and bypass every security control from DLP to email gateways. By the time someone realizes their AI assistant has been quietly BCCing emails to an external server for months, the damage is already catastrophic.</p><h2>Lets Talk About the Impact</h2><p>Okay, bear with me while I break down what we're actually looking at here.</p><p>You install an MCP server because you want your AI to handle emails, right? Seems reasonable. Saves time. Increases productivity. All that good stuff. But what you're actually doing is handing complete control of your entire email flow to someone you've never met.&nbsp;</p><p>We can only guestimate the impact:</p><ul role="list"><li>1,500 downloads every single week</li><li>Being conservative, maybe 20% are actively in use</li><li>That's about 300 organizations</li><li>Each one probably sending what, 10-50 emails daily?</li><li>We're talking about 3,000 to 15,000 emails EVERY DAY flowing straight to giftshop.club</li></ul><p>And the truly messed up part? The developer didn't hack anything. Didn't exploit a zero-day. Didn't use some sophisticated attack vector. We literally handed him the keys, said "here, run this code with full permissions," and let our AI assistants use it hundreds of times a day. We did this to ourselves.</p><figure><p><img src="https://cdn.prod.website-files.com/689ad8c5d13f40cf59df0e0c/68d2e7796d400a7fb93e983c_Screenshot%202025-09-23%20at%2021.29.33%20(1).png" loading="lazy" alt=""></p><figcaption>Koidex report for postmark-mcp</figcaption></figure><p>I've been doing security for years now, and this particular issue keeps me up at night. Somehow, we've all just accepted that it's totally normal to install tools from random strangers that can:</p><ul role="list"><li>Send emails as us (with our full authority)</li><li>Access our databases (yeah, all of them)</li><li>Execute commands on our systems</li><li>Make API calls with our credentials</li></ul><p>And once you install them? Your AI assistant just goes to town. No review process. No "hey, should I really send this email with a BCC to giftshop.club?" Just blind, automated execution. Over and over. Hundreds of times a day.</p><p>There's literally no security model here. No sandbox. No containment. Nothing. If the tool says "send this email," your AI sends it. If it says "oh, also copy everything to this random address," your AI does that too. No questions asked.</p><p>The postmark-mcp backdoor isn't sophisticated - it's embarrassingly simple. But it perfectly demonstrates how completely broken this whole setup is. One developer. One line of code. Thousands upon thousands of stolen emails.</p><figure><p><img src="https://cdn.prod.website-files.com/689ad8c5d13f40cf59df0e0c/68d2e67416d1614856d43205_Screenshot%202025-09-23%20at%2021.26.25.png" loading="lazy" alt=""></p><figcaption>postmark-mcp NPM page</figcaption></figure><h2>The Attack Timeline</h2><p><strong>Phase 1: Build a Legitimate Tool</strong><br>Versions 1.0.0 through 1.0.15 work perfectly. Users trust the package.</p><p><strong>Phase 2: Add One Line</strong><br>Version 1.0.16 adds the BCC. Nothing else changes.</p><p><strong>Phase 3: Profit</strong><br>Sit back and watch emails containing passwords, API keys, financial data, and customer information flow into giftshop.club.</p><p>This pattern absolutely terrifies me. A tool can be completely legitimate for months. It gets battle-tested in production. It becomes essential to your workflow. Your team depends on it. And then one day - BAM - it's malware. By the time the backdoor activates, it's not some random package anymore. It's trusted infrastructure.</p><p>Oh, and <code>giftshop.club</code>? Looks like it might be another one of the developer's side projects. But now it's collecting a very different kind of gift. Your emails are the gifts.</p><figure><p><img src="https://cdn.prod.website-files.com/689ad8c5d13f40cf59df0e0c/68d2dfc7f12afe4d7c64ce5e_Screenshot%202025-09-23%20at%2020.57.31.jpg" loading="lazy" alt=""></p><figcaption>Another side-project by the same developer was used as the C2 server</figcaption></figure><p>When we reached out to the developer for clarification, we got silence. No explanation. No denial. Nothing. But he did take action - just not the kind we hoped for. He promptly deleted the package from npm, trying to erase the evidence.</p><p>Here's the thing though: deleting a package from npm doesn't remove it from the machines where it's already installed. Every single one of those 1,500 weekly downloads? They're still compromised. Still sending BCCs to <code>giftshop.club</code>. The developer knows this. He's banking on victims not realizing they're still infected even though the package has vanished from npm.</p><h2>Why MCP's Entire Model Is Fundamentally Broken</h2><p>Let me be really clear about something: MCP servers aren't like regular npm packages. These are tools specifically designed for AI assistants to use autonomously. That's the whole point.</p><p>When you install postmark-mcp, you're not just adding some dependency to your package.json. You're giving your AI assistant a tool it will use hundreds of times, automatically, without ever stopping to think "hmm, is something wrong here?"</p><p>Your AI can't detect that BCC field. It has no idea emails are being stolen. All it sees is a functioning email tool. Send email. Success. Send another email. Success. Meanwhile, every single message is being silently exfiltrated. Day after day. Week after week.</p><p>The postmark-mcp backdoor isn't just about one malicious developer or 1,500 weekly compromised installations. It's a warning shot about the MCP ecosystem itself.</p><p>We're handing god-mode permissions to tools built by people we don't know, can't verify, and have no reason to trust. These aren't just npm packages - they're direct pipelines into our most sensitive operations, automated by AI assistants that will use them thousands of times without question.</p><p>The backdoor is actively harvesting emails as you read this. We've reported it to npm, but here's the terrifying question: how many other MCP servers are already compromised? How would you even know?</p><p>At Koi, we detect these behavioral changes in packages because the MCP ecosystem has no built-in security model. When you're trusting anonymous developers with your AI's capabilities, you need verification, not faith. Our risk engine automatically caught this backdoor the moment version 1.0.16 introduced the BCC behavior - something no traditional security tool would flag. But detection is just the first step. Our supply chain gateway ensures that malicious packages like this never make it into your environment in the first place. It acts as a checkpoint between your developers and the wild west of npm, MCP servers, and browser extensions - blocking known threats, flagging suspicious updates, and requiring approval for packages that touch sensitive operations like email or database access. While everyone else is hoping their developers make good choices, we're making sure they can only choose from verified, continuously monitored options.</p><p>If you're using <code>postmark-mcp</code> version <code>1.0.16</code> or later, you're compromised. Remove it immediately and rotate any credentials that may have been exposed through email. But more importantly, audit every MCP server you're using. Ask yourself: do you actually know who built these tools you're trusting with everything?</p><p>Stay paranoid. With MCPs, paranoia is just good sense.</p><h2>IOCs</h2><p><strong>Package:</strong> postmark-mcp (npm)<br><strong>Malicious Version:</strong> 1.0.16 and later<br><strong>Backdoor Email:</strong> phan@giftshop[.]club<br><strong>Domain:</strong> giftshop[.]club</p><p><strong>Detection:</strong></p><ul role="list"><li>Check for BCC headers to giftshop.club in email logs</li><li>Audit MCP server configurations for unexpected email parameters</li><li>Review npm packages for version 1.0.16+ of postmark-mcp</li></ul><p><strong>Mitigation:</strong></p><ul role="list"><li>Immediately uninstall postmark-mcp</li><li>Rotate any credentials sent via email during the compromise period</li><li>Audit email logs for sensitive data that may have been exfiltrated</li><li>Report any confirmed breaches to appropriate authorities</li></ul><p>‍</p></div></div>]]></description>
        </item>
    </channel>
</rss>