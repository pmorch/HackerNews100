<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 19 Nov 2025 16:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Your Smartphone, Their Rules: App Stores Enable Corporate-Government Censorship (238 pts)]]></title>
            <link>https://www.aclu.org/news/free-speech/app-store-oligopoly</link>
            <guid>45979297</guid>
            <pubDate>Wed, 19 Nov 2025 13:28:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aclu.org/news/free-speech/app-store-oligopoly">https://www.aclu.org/news/free-speech/app-store-oligopoly</a>, See on <a href="https://news.ycombinator.com/item?id=45979297">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							<!-- Author Info -->

<p>,<br>
        <span>Senior Staff Technologist</span>,<br>
        <span>ACLU Speech, Privacy, and Technology Project</span></p>
<!-- social share component -->


<p><span>November 18, 2025</span>
						</p></div><div>
	  <p><a href="https://action.aclu.org/signup/free-future-newsletter"><strong><em>Subscribe to the Free Future Newsletter</em></strong></a><br>
<em><a href="http://www.aclu.org/freefuture">Free Future home</a></em></p>
<p>Who controls what you can do on your mobile phone? What happens when your device can only run what the government decides is OK? We are dangerously close to this kind of totalitarian control, thanks to a combination of government overreach and technocratic infrastructure choices.</p>
<p>Most Americans have a smartphone, and the average American spends <a href="https://www.harmonyhit.com/phone-screen-time-statistics/">over 5 hours a day on their phone</a>. While these devices are critical to most people’s daily lives, what they can actually do is shaped by what apps are readily available. A slim majority of American smartphone users use an iPhone, which means they can only install apps available from Apple’s AppStore. Nearly all the rest of US smartphone users use some variant of Android, and by default they get their apps from Google’s Play Store.</p>
<p>Collectively, these two app stores shape the universe of what is available to most people as they use the Internet and make their way through their daily lives. When those app stores block or limit apps based on government requests, they are shaping what people can do, say, communicate, and experience.</p>
<p>Recently, Apple <a href="https://www.404media.co/iceblock-owner-after-apple-removes-app-we-are-determined-to-fight-this/">pulled </a><a href="https://www.404media.co/iceblock-owner-after-apple-removes-app-we-are-determined-to-fight-this/">an app called </a>ICEBlock from the AppStore, making it unavailable in one fell swoop. This app was designed to let people anonymously report public sightings of ICE agents. In the United States people absolutely have a First Amendment right to inform others about what they have seen government officials doing and where — very much including immigration agents whose tactics have been <a href="https://www.bbc.com/news/articles/cvg430dx702o">controversial</a> and <a href="https://projects.propublica.org/trump-ice-smashed-windows-deportation-arrests/">violent</a>. Apple pulled the ICEBlock app at <a href="https://www.foxbusiness.com/politics/apple-takes-down-ice-tracking-app-after-pressure-from-ag-bondi">the demand of the US Department of Justice</a>. The following day, Google <a href="https://www.404media.co/google-calls-ice-agents-a-vulnerable-group-removes-ice-spotting-app-red-dot/">pulled a similar app called Red Dot</a> from the Google Play Store.</p>
<p>The DOJ’s pressuring of Apple is an unacceptable, censorious overreach. And Google’s subsequent removal of Red Dot looks like troubling premature capitulation. While some experts and activists have expressed <a href="https://micahflee.com/unfortunately-the-iceblock-app-is-activism-theater/">concerns over ICEBlock’s design and development practices</a>, those concerns are no reason for the government to meddle in software distribution. The administration’s ostensible <a href="https://www.whitehouse.gov/presidential-actions/2025/01/restoring-freedom-of-speech-and-ending-federal-censorship/">free speech warriors</a> are trying to shape how Americans can communicate with each other about matters of pressing political concern.</p>
<p><strong>Infrastructure choices</strong><br>
But the government’s overreach isn’t the whole story here. The current structure of the mobile phone ecosystem enables this kind of abuse and control.</p>
<p>Apple’s iOS (the operating system for any iPhone) is designed to only be able to run apps from the AppStore. If Apple hasn’t signed off on it, the app won’t run. This centralized control is ripe for abuse:</p>
<ul>
<li>Apple has <a href="https://www.reuters.com/technology/apple-enforces-new-check-apps-china-beijing-tightens-oversight-2023-10-03/">handed the Chinese government</a> control over what apps are available to iPhone users in China, including <a href="https://www.wired.com/story/apple-removes-gay-dating-apps-china-app-store/">banning gay dating apps</a>.</li>
<li>The corporation has used its authority over the AppStore <a href="https://www.theverge.com/2012/10/12/3495466/apple-bans-another-objectionable-iphone-game-about-foxconn-workers">to block a</a> <a href="https://www.theverge.com/2012/10/12/3495466/apple-bans-another-objectionable-iphone-game-about-foxconn-workers">game that</a> critiqued its<a href="https://www.theverge.com/2012/10/12/3495466/apple-bans-another-objectionable-iphone-game-about-foxconn-workers"> labor practices</a>.</li>
<li>Apple’s <a href="https://developer.apple.com/app-store/review/guidelines/">guidelines </a>say that “‘Enemies’ within the context of a game cannot solely target a specific … government, corporation, or any other real entity.” That represents a potential for sweeping censorship of anyone who wants to use the art of games to criticize companies or otherwise advance political messages.</li>
<li>It <a href="https://fortune.com/2025/05/17/apple-blocks-fortnite-on-ios-app-store/">banned </a>the popular game Fortnite from the App Store as it was battling the gamemaker to get a bigger cut of money from user transactions.</li>
<li>In 2012 Apple <a href="https://www.aclu.org/news/civil-liberties/apple-drone-strikes-and-limits-censorship">rejected</a> an app that compiled reports of highly controversial overseas drone strikes by the U.S. government during the “War on Terror.”</li>
</ul>
<p>Unlike Apple, Google’s Android operating system has traditionally allowed relatively easy access to “sideloading”, which just means installing apps through means other than Google’s Play Store. Although most installations default to getting apps from the Play Store, the availability of sideloading means that even if Google censors apps in the Play Store, people can still install them. Even apps critical of Google can make it onto an Android device. It’s also possible to run a variant of Android without the Play Store at all, such as <a href="https://grapheneos.org/">GrapheneOS</a>.</p>
<p>Unfortunately that is all set to change with a <a href="https://arstechnica.com/gadgets/2025/08/google-will-block-sideloading-of-unverified-android-apps-starting-next-year/">recent Google announcement</a> that it will block apps from “certified Android” devices (which is nearly all Android phones) unless they come from what Google calls a “verified developer.” This means that the common Android user trying to install an app will have to get Google’s blessing: does this app come from someone that Google has “verified”? How Google will decide who is allowed to be verified and who is not is still unclear. Can a developer become “unverified”?</p>
<p>This upcoming change is framed by Google as <a href="https://developer.android.com/developer-verification">a security measure</a>, but merely knowing the identity of the developer of an app doesn’t provide any security. So the only way that the “verified developer” requirement can offer security is if Google withholds “verified developer” status from people it deems bad actors. But Google’s ability to withhold that status can be abused in the same way that Apple’s AppStore lock-in is being abused. A government will simply make a demand: “treat this developer as a bad actor” and effectively cut off any app by targeting its developer.</p>
<p>When a lever of control is available, the would-be censors will try to use it. It has never been true that someone who buys a Lenovo or Dell laptop, for example, has to let Lenovo or Dell tell them what programs they can and cannot install on their computer. Yet that will soon be the situation with regards to nearly all cell phones used in the United States.</p>
<p>Note that American iPhones are limited to only apps from the AppStore, but European Union (EU) iPhones don’t have that restriction. The EU’s Digital Markets Act (DMA) required Apple to permit <a href="https://developer.apple.com/support/dma-and-apps-in-the-eu/">alternate app stores and sideloading</a> (which Apple calls “web distribution”). As a result, marketplaces like <a href="https://altstore.io/">AltStore</a> are starting to become available — but Apple only lets EU customers use them. The European regime is not perfect, however; while sideloaded apps and alternative app stores aren’t subject to the app store’s constraints, they are still obliged to follow Apple’s <a href="https://developer.apple.com/support/dma-and-apps-in-the-eu/#notarization-for-ios-apps">“Notarization” requirements</a>, which requires Apple to review all iOS apps – even from these alternate sources – on the basis of several vaguely worded rationales. For example, if the DoJ were to claim that ICEBlock “promoted physical harm” (even though it clearly does not), Apple could use this as an excuse to justify revoking their notarization of the app, which would prevent it from being installed even from these alternate channels.</p>
<p><strong>App store security and surveillance</strong><br>
Both Apple and Google make claims that their app distribution mechanisms improve security for their users. And clearly, these tech giants do block some abusive apps by exercising the control they have.</p>
<p>But both of them also regularly allow apps that contain common malicious patterns, including many apps built with <a href="https://appfigures.com/top-sdks/ads/all">surveillance tooling</a> that <a href="https://www.iccl.ie/wp-content/uploads/2025/01/EPIC-ICCL-Enforce-In-re-Googles-RTB-Complaint.pdf">sell their users’ data to </a><a href="https://www.iccl.ie/wp-content/uploads/2025/01/EPIC-ICCL-Enforce-In-re-Googles-RTB-Complaint.pdf">data brokers</a>. If either tech giant were serious about user security, they could ban these practices, but they do not. Google’s security claims are also undermined by the fact that the cellphone hacking company Cellebrite <a href="https://arstechnica.com/gadgets/2025/10/leaker-reveals-which-pixels-are-vulnerable-to-cellebrite-phone-hacking/">tells law enforcement</a> that Google’s Pixel phones can be hacked, while those running GrapheneOS, created by a small non-profit, cannot. (Asked by a reporter why that was so, Google <a href="https://arstechnica.com/gadgets/2025/10/leaker-reveals-which-pixels-are-vulnerable-to-cellebrite-phone-hacking/">did not respond</a>.)</p>
<p>Making matters worse, organizations like Google are unclear about their policies, and some of their policy statements can put developers and users at risk. Discussing blocking Red Dot, for example, <a href="https://www.404media.co/google-calls-ice-agents-a-vulnerable-group-removes-ice-spotting-app-red-dot/">Google told 404Media</a> that “apps that have user generated content must also conduct content moderation.” This implies that Google could become unwilling to distribute fully end-to-end encrypted apps, like <a href="https://signal.org/">Signal Private Messenger</a> or <a href="https://delta.chat/">Delta Chat</a>, since those app vendors by design are incapable of reviewing user-generated content. End-to-end encrypted apps are <a href="https://www.globalencryption.org/">the gold standard</a> for secure communications, and no app store that signals a willingness to remove them can claim to put security first.</p>
<p>In addition, even if you’ve carefully curated the apps you have installed from these dominant app stores to avoid spyware and use strongly secure apps, the stores themselves monitor the devices, keeping dossiers of what apps are installed on each device, and <a href="https://www.scss.tcd.ie/doug.leith/Android_privacy_report.pdf">maybe more</a>. Being a user of these app stores means being under heavy, regular surveillance.</p>
<p><strong>Other options exist<br>
</strong>These centralized, surveilled, censorship-enabling app stores are not the only way to distribute software. Consider alternative app stores for Android, like <a href="https://accrescent.app/">Accrescent</a>, which prioritizes <a href="https://accrescent.app/docs/guide/appendix/requirements.html">privacy and security requirements</a> in its apps, and <a href="https://f-droid.org/">F-Droid</a>, which enables installation of free and open source apps. In addition to offering quality tools and auditing, F-Droid’s policies <a href="https://f-droid.org/docs/Anti-Features/">incentivize</a> the apps distributed on the platform to trim out overwhelming amounts of corporate spyware that infest both Google and Apple’s app stores. Neither F-Droid nor Accrescent do any surveillance of their users at all.</p>
<p>The F-Droid developers <a href="https://f-droid.org/en/2025/09/29/google-developer-registration-decree.html">recently </a><a href="https://f-droid.org/en/2025/09/29/google-developer-registration-decree.html">wrote about </a>the impact that Google’s upcoming developer registration requirements are likely to have on the broader ecosystem of privacy-preserving Android apps. The outcome doesn’t look good: the ability to install free and open source software on a common device might be going away. Those few people left using unusual devices (“uncertified” Android deployments like <a href="https://grapheneos.org/">GrapheneOS</a>, or even more obscure non-Android operating systems like <a href="https://phosh.mobi/">phosh</a>) will still have the freedom to install tools that they want, but the overwhelming majority of people will be stuck with what can quickly devolve into a government-controlled cop-in-your-pocket.</p>
<p><strong>How we can push back<br>
</strong>In an increasingly centralized world, it will take very little for an abusive government to cause an effective organizing tool to disappear, to block an app that belongs to a critical dissenting media outlet, or to force invasive malware <a href="https://www.aclu.org/issues/privacy-technology/consumer-privacy/how-malicious-software-updates-endanger-everyone">into a software update</a> used by everyone. We need a shared infrastructure that doesn’t permit this kind of centralized control. We can disrupt oligopolistic control over software through user choice (e.g., preferring and installing free software), building good protocol frameworks (e.g., demanding tools that use open standards for interoperability), and through regulatory intervention (e.g., breaking up monopolistic actors, or mandating that an OS must allow sideloading, as the EU did with the DMA).</p>
<p>The device you carry with you that is privy to much of your life should be under your control, not under the control of an abusive government or corporations that do its bidding.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Peaceful Transfer of Power in Open Source Projects (113 pts)]]></title>
            <link>https://shkspr.mobi/blog/2025/11/the-peaceful-transfer-of-power-in-open-source-projects/</link>
            <guid>45979232</guid>
            <pubDate>Wed, 19 Nov 2025 13:20:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shkspr.mobi/blog/2025/11/the-peaceful-transfer-of-power-in-open-source-projects/">https://shkspr.mobi/blog/2025/11/the-peaceful-transfer-of-power-in-open-source-projects/</a>, See on <a href="https://news.ycombinator.com/item?id=45979232">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The $1k AWS Mistake (150 pts)]]></title>
            <link>https://www.geocod.io/code-and-coordinates/2025-11-18-the-1000-aws-mistake/</link>
            <guid>45977744</guid>
            <pubDate>Wed, 19 Nov 2025 10:00:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.geocod.io/code-and-coordinates/2025-11-18-the-1000-aws-mistake/">https://www.geocod.io/code-and-coordinates/2025-11-18-the-1000-aws-mistake/</a>, See on <a href="https://news.ycombinator.com/item?id=45977744">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>A cautionary tale about AWS VPC networking, NAT Gateways, and how a missing VPC Endpoint turned our S3 data transfers into an expensive lesson.</p><div><p>I've been using AWS since around 2007. Back then, EC2 storage was entirely ephemeral and stopping an instance meant losing all your data. The platform has come a long way since then.</p>
<p>Even after nearly two decades with the platform, there's always something new to learn. And sometimes those lessons come with a $1,000 price tag.</p>
<h2 id="the-setup"><a href="#the-setup" aria-label="the setup permalink"></a>The setup</h2>
<p>We recently moved over to using S3 for mirroring some large internal data files for Geocodio. We're talking about geographic datasets (things like address points, boundary data, and census information) that range from a few gigabytes to hundreds of gigabytes each. Some of these files are updated almost daily with fresh data, while others are refreshed less frequently. They need to be synced regularly from our ETL platform (which is hosted with Hetzner) to our processing infrastructure on AWS.</p>
<p>AWS has notoriously high data transfer costs. <a href="https://blog.cloudflare.com/aws-egregious-egress/">Cloudflare has written extensively about this</a>, and it's a common complaint across the industry. Corey Quinn from Last Week in AWS has also <a href="https://www.lastweekinaws.com/blog/the-aws-managed-nat-gateway-is-unpleasant-and-not-recommended/">called out the AWS Managed NAT Gateway</a> for being particularly expensive. AWS charges $0.09 per GB for data transfer out to the internet from most regions, which adds up fast when you're moving terabytes of data.</p>
<p>So before starting this project, I did my homework. I carefully researched the costs involved and confirmed two critical things:</p>
<ol>
<li><strong>AWS still allows free transfer between EC2 instances and S3</strong> (as long as they're in the same region)</li>
<li><strong>Transfers <em>into</em> S3 are free</strong> (this was important since the data comes from our ETL platform hosted with Hetzner)</li>
</ol>
<p>Great! I had a clear picture of the costs.</p>
<p>...Or so I thought.</p>
<h2 id="the-surprise"><a href="#the-surprise" aria-label="the surprise permalink"></a>The surprise</h2>
<p>A few days after deploying the new S3 sync process, I got a notification from AWS Cost Anomaly Detection. (Boy, was I happy that I had that enabled!)</p>
<p>The alert showed something alarming: <strong>20,167.32 GB</strong> of "NAT Gateway" data transfers in a single day, which amounted to <strong>$907.53</strong>.</p>
<p>Month to date, this had already surpassed $1,000.</p>
<p><img src="https://www.geocod.io/img/blog/aws-traffic-cost.png" alt="AWS Cost Anomaly Detection showing unexpected NAT Gateway charges"></p>
<p>I stared at the dashboard in disbelief. How could this be happening? I had specifically confirmed that EC2-to-S3 transfers were free!</p>
<h2 id="but-why-oh-why"><a href="#but-why-oh-why" aria-label="but why oh why permalink"></a>But why oh why?</h2>
<p>After some frantic investigating (and a bit of panic), I discovered the culprit.</p>
<p>When you're using VPCs with a NAT Gateway (which most production AWS setups do), S3 transfers <strong>still go through the NAT Gateway</strong> by default. Even though you're making requests to an AWS service that's in the same region, the traffic is routed out through your NAT Gateway and back in, incurring data transfer charges at $0.045 per GB.</p>
<p><img src="https://www.geocod.io/img/blog/aws-nat-gateway-problem.png" alt="Architecture diagram showing traffic flowing from EC2 through NAT Gateway to S3"></p>
<p>The solution? <strong>VPC Endpoints for S3</strong>, specifically what AWS calls a "Gateway Endpoint."</p>
<p>A Gateway Endpoint is a special type of VPC endpoint that allows you to privately route traffic to S3 without going through your NAT Gateway or Internet Gateway. It's essentially a direct pipe from your VPC to S3.</p>
<p>Even better, Gateway Endpoints for S3 are <strong>completely free</strong>. No hourly charges, no data transfer charges. Nothing.</p>
<h2 id="the-fix"><a href="#the-fix" aria-label="the fix permalink"></a>The fix</h2>
<p>The solution is to create a VPC Gateway Endpoint for S3. This is a special type of VPC endpoint that creates a direct route from your VPC to S3, bypassing the NAT Gateway entirely.</p>
<p><img src="https://www.geocod.io/img/blog/aws-vpc-endpoint-solution.png" alt="Architecture diagram showing direct traffic flow from EC2 through VPC Gateway Endpoint to S3"></p>
<p>In our case, we manage infrastructure with Terraform, so it was just a matter of adding the Gateway Endpoint resource and associating it with our route tables. AWS automatically handles the routing updates to direct S3 traffic through the endpoint instead of the NAT Gateway.</p>
<h2 id="the-lesson"><a href="#the-lesson" aria-label="the lesson permalink"></a>The lesson</h2>
<p>I've built countless VPCs, configured security groups, set up load balancers, and optimized costs in dozens of ways over the years. But somehow, VPC Endpoints for S3 had slipped through the cracks of my knowledge.</p>
<p>AWS's networking can be deceptively complex. Even when you think you've done your research and confirmed the costs, there are layers of configuration that can dramatically change your bill.</p>
<p>Don't make my mistake. Here are a few things I'd suggest checking to help you avoid <em>your own</em> surprise $1,000 bill:</p>
<p><strong>AWS Cost Anomaly Detection is worth setting up.</strong> It caught this issue within days, saving us from an even larger surprise at the end of the month. If you haven't enabled it yet, <a href="https://console.aws.amazon.com/costmanagement/">do it <em>now</em></a>.</p>
<p><strong><a href="https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html">VPC Endpoints</a> are your friend.</strong> If you're using S3 or DynamoDB from EC2 instances in a VPC with a NAT Gateway, you absolutely need Gateway Endpoints. There's literally no reason not to use them. They're free and improve performance.</p>
<p><strong>Always validate your assumptions.</strong> I thought "EC2 to S3 is free" was enough. I should have tested with a small amount of data and monitored the costs before scaling up to terabytes.</p>
<p><strong>The cloud is complicated.</strong> There's always more to learn, even after nearly two decades. And that's okay. It just means we need to be careful and vigilant.</p>
<p>And we're not alone in this. Just last year, <a href="https://www.infoq.com/news/2024/11/aws-websockets-costs/">Recall.ai discovered they were paying $1M annually in unexpected AWS WebSocket data processing fees</a>. Even experienced teams hit these surprises.</p>
<h2 id="whats-next"><a href="#whats-next" aria-label="whats next permalink"></a>What's next</h2>
<p>We've since audited our entire AWS infrastructure to make sure we have Gateway Endpoints configured for all VPCs that communicate with S3.</p>
<p>If you're using AWS and you haven't checked your VPC Endpoint configuration lately, I'd recommend taking a look. That $1,000 lesson doesn't need to be repeated.</p>
<p><em>TL;DR: NAT Gateways charge for ALL data processing, even for traffic to AWS services like S3 that have no data transfer fees. Use VPC Endpoints to bypass this.</em></p>
<h2 id="additional-resources"><a href="#additional-resources" aria-label="additional resources permalink"></a>Additional Resources</h2>
<ul>
<li><a href="https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html">AWS VPC Endpoints for S3</a></li>
<li><a href="https://aws.amazon.com/aws-cost-management/aws-cost-anomaly-detection/">AWS Cost Anomaly Detection</a></li>
<li><a href="https://carmencincotti.com/2023-03-27/the-five-minute-hack-to-saving-money-with-gateway%20endpoints/">Save Cash by Avoiding The AWS NAT Gateway with Gateway Endpoints</a> by Carmen Cincotti</li>
<li><a href="https://www.lastweekinaws.com/blog/the-aws-managed-nat-gateway-is-unpleasant-and-not-recommended/">The AWS Managed NAT Gateway is Unpleasant and Not Recommended</a> by Corey Quinn</li>
<li><a href="https://blog.cloudflare.com/aws-egregious-egress/">Cloudflare's take on AWS egress costs</a></li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A down detector for down detector's down detector (181 pts)]]></title>
            <link>https://downdetectorsdowndetectorsdowndetector.com/</link>
            <guid>45976670</guid>
            <pubDate>Wed, 19 Nov 2025 07:09:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://downdetectorsdowndetectorsdowndetector.com/">https://downdetectorsdowndetectorsdowndetector.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45976670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		

		<p>
			A tiny independent status checker.
		</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I just want working RCS messaging (204 pts)]]></title>
            <link>https://wt.gd/i-just-want-my-rcs-messaging-to-work</link>
            <guid>45974869</guid>
            <pubDate>Wed, 19 Nov 2025 01:41:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wt.gd/i-just-want-my-rcs-messaging-to-work">https://wt.gd/i-just-want-my-rcs-messaging-to-work</a>, See on <a href="https://news.ycombinator.com/item?id=45974869">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="container">
  <article id="56Vq422Qs4qiZnGDAb7eju">
	<time datetime="2025-11-18">November 18, 2025</time>
  <h2>
    <a href="https://wt.gd/i-just-want-my-rcs-messaging-to-work">I just want working RCS messaging</a>
  </h2>
	<p><strong>I’m in over a month now with non-working RCS on my iPhone 15 Pro.</strong> Apple blames the carriers, the carriers tell me it’s not them (mostly T-Mobile since I have good contacts there). They tell me they can’t really do anything about iPhones not working on RCS, go back to Apple. This is what it looks like: </p>

<p><a href="https://svbtleusercontent.com/e3D6xwwmfoFozgTp5RMytW0xspap.png"><img src="https://svbtleusercontent.com/e3D6xwwmfoFozgTp5RMytW0xspap_small.png" alt="Waiting for Activation"></a></p>

<p>In short, it’s probably Apple or Google and there’s zero accountability from Apple. I have AppleCare+ and really hoped they’d actually try to troubleshoot and fix this rather than waste my time working around it (in a stupidly expensive way for me and Apple).</p>
<h2 id="my-background_1">My background <a href="#my-background_1">#</a></h2>
<p>I’m OS agnostic as much as possible, I daily both Android and iOS devices and previously used BlackBerry 10 and Harmattan (Nokia N9’s OS). If Windows Phone was still around I’d probably still be running that as well. If it’s possible to gather information on how all this works under the hood, I can and do. The OnePlus Android devices I’m running are my own LineageOS builds. </p>
<h2 id="previous-history-fixing-mms-failures-for-carr_2">Previous history fixing MMS failures for Carriers/Vendors <a href="#previous-history-fixing-mms-failures-for-carr_2">#</a></h2>
<p>I’m also happy to blame carriers and vendors: I previously brought and helped resolve an issue with Verizon Wireless on LineageOS phones due to how MMS messaging works. Here’s my initial submission, their developer LuK found a better way to go about it, but it at least started the ball rolling: <a href="https://review.lineageos.org/c/LineageOS/android_device_oneplus_sm8250-common/+/333379">https://review.lineageos.org/c/LineageOS/android_device_oneplus_sm8250-common/+/333379</a></p>

<p>In short: When you received a picture message on Verizon in the past their network would notify your device that a new message arrived. When the device went to grab and download the image, it sends something similar to browser User Agent, called a UAProf. This is a link to a file that describes what the phone can handle, so a smartphone gets a high resolution image and a featurephone gets a lower resolution one. Verizon’s management sucks and decommissioned the domain that hosts all the UAProfs for their devices. Of note, Verizon is uniquely affected by this issue, T-Mobile doesn’t care what UAProf a device advertises, it’s not required on their network. I haven’t done enough testing with AT&amp;T to answer whether it’s an issue for them.</p>
<h2 id="mms-failure-demonstrations_2">MMS Failure Demonstrations <a href="#mms-failure-demonstrations_2">#</a></h2>
<p>This is a former link to a Verizon UAProf for a Samsung device: <a href="http://uaprof.vtext.com/sam/i515/i515.xml">http://uaprof.vtext.com/sam/i515/i515.xml</a></p>

<p>Notice it doesn’t load? Apple/Blackberry and basically any non-Android manufacturers didn’t trust carriers to host these files. Some manager at Verizon decided to kill the vtext service and also fucked over any MMS users on their network not using an iPhone.</p>

<p>Here’s Apple’s: <a href="https://www.apple.com/mms/uaprof.rdf">https://www.apple.com/mms/uaprof.rdf</a>. <br>
And here’s Blackberry’s: <a href="https://www.blackberry.com/go/mobile/profiles/uaprof/9700/5.0.0.rdf">https://www.blackberry.com/go/mobile/profiles/uaprof/9700/5.0.0.rdf</a></p>

<p><strong>I’m getting off-topic though, I just wanted to post some context that this is not my first rodeo with fixing these kinds of issues. Carriers are incompetent with this sort of interoperability and they gave up on running their own RCS servers to let Google do it through something called Google Jibe, I’ll talk about that soon.</strong> </p>
<h2 id="google-breaking-rcs-on-lineageos_1">Google breaking RCS on LineageOS <a href="#google-breaking-rcs-on-lineageos_1">#</a></h2>
<p>Starting around the end of 2023, Google started to maliciously break RCS for custom Android OS’s. I say maliciously because it was a silent failure, RCS reported as working, but messages wouldn’t go through, and incoming messages would fail to receive. Google could have remained silent about it and rumors probably would have swirled: Perhaps it was a technical issue or the custom ROM developers’ faults? </p>

<p>No, Google <strong>intentionally</strong> broke it.</p>

<p>They straight up admitted to blocking it: <a href="https://www.androidauthority.com/google-silently-blocking-rcs-rooted-android-phones-custom-roms-3421652/">https://www.androidauthority.com/google-silently-blocking-rcs-rooted-android-phones-custom-roms-3421652/</a> and it wasn’t until months later that they even showed a notification that it was disabled on affected devices. I really hope some lawyer or regulator reading this will get to extract their pound of blood because Google loves to boast about doing 911 over RCS: <a href="https://blog.google/products/messages/google-messages-rcs-911-emergency/">https://blog.google/products/messages/google-messages-rcs-911-emergency/</a></p>

<p>Eventually for my own devices I would spoof to the fingerprint of Google PIxel devices to be able to use RCS. It has mostly continued to work since then, but it begs the question: <strong>If I could reliably work around the blocking, then what excuse do you have about it being to prevent spam?</strong> Since those spammers will just use the same methods I’ve used, which are hardly secret. It just aims to hurt users that want some control of their device.</p>
<h2 id="apple-launches-rcs_1">Apple launches RCS <a href="#apple-launches-rcs_1">#</a></h2>
<p>At some point Apple was dragged kicking and screaming into RCS interoperability. I actually have some sympathy here because MMS was really a terrible protocol that nobody should have adopted and Apple was dragged into supporting that years after the original iPhone launch in iOS 3. Regardless, with iOS 18, Apple brought in baseline RCS (version 2.4) support. It is hoped that they will update it sometime in the iOS 26 series to include E2E encryption.</p>
<h2 id="my-iphone-background-start-of-rcs-issues_1">My iPhone Background, Start of RCS Issues <a href="#my-iphone-background-start-of-rcs-issues_1">#</a></h2>
<p>RCS always worked on my phone in iOS 18 until the past month when I upgraded to iOS 26. I should note that unlike Android, I do not modify iOS device in any way, basically I expect it should ‘just work’. The only unusual thing I run is Mullvad’s DNS to act as an adblocker, but so does my family and their iDevices don’t have RCS issues. </p>

<p>I am a dual-sim user on T-Mobile and US Mobile (usually on the AT&amp;T network). With iOS 26 both lines have been stuck on “Waiting for activation…”. If I transfer the lines off to any other iPhone, the lines activate in seconds. I additionally took a Verizon Wireless line from my Mom’s 14 Pro Max and it also displayed the same issue. My girlfriend has a 14 Pro Max and a SE3, both can activate my RCS lines when I transfer them over.</p>
<h2 id="troubleshooting-steps-i-did_1">Troubleshooting Steps I Did <a href="#troubleshooting-steps-i-did_1">#</a></h2>
<p>I’ve done an absolutely exhaustive level of testing to see if these lines would activate on my phone, there’s probably more than this but this is what I could think of:</p>

<ol>
<li>Rebooted/Toggled Airplane Mode/Toggled RCS</li>
<li>Resetting Network Settings</li>
<li>Removed all my VPN profiles and apps. (Mullvad/Orbot/Mullvad’s DNS profile/my server’s wireguard profile)</li>
<li>Deactivated one of my lines and tried reactivating RCS.</li>
<li>Disabling 5G and trying to activate RCS. </li>
<li>Reissuing both eSIM’s from the carriers.</li>
<li>Toggling iMessage.</li>
<li>Resetting All settings
9 Resetting everything on device.

<ul>
<li>Restoring from iTunes backup</li>
<li>Restoring from iCloud backup (literally activated a trial to be able to do this)</li>
<li>Tested resetting with and without eSIM.</li>
</ul></li>
<li>Recovering device (recovery mode, setting up as new device) 

<ul>
<li>Both with and without eSIM’s on device.</li>
</ul></li>
<li>Disabling RCS and waiting <strong>days</strong> before attempting to reactivate.</li>
<li>Updating my e911 addresses, disabling/renabling wifi calling. Testing on Wifi.</li>
<li>Reissuing just T-Mobile eSIM but to the other IMEI on the phone that it’s normally not on. </li>
<li>Deleting the numbers out numerous times in Carrier settings (I have no idea what this does but it does make the signal reconnect). </li>
<li>Testing sending messages from devices that work with RCS to this device in hopes it upgrades.</li>
<li>Testing the iOS beta releases. </li>
<li>I brought up the Gentoo Linux packages for libimobiledevice so I could run idevicesyslog and dump hundreds of megabytes of live logs in hopes of being able to see what the phone is failing on: (the packages) <a href="https://github.com/joecool1029/joecool-overlay/tree/master/app-pda">https://github.com/joecool1029/joecool-overlay/tree/master/app-pda</a>

<ul>
<li>This is a small T-Mobile related excerpt of what looks like the problem could be. Specifically, UserInteractionRequired.xml. I don’t know what interaction is needed and why Apple’s software isn’t presenting more information, but this is the best I could do from digging through a ton of redacted logs:
<code>
Nov  9 15:54:14.294398 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294406 CommCenter[101] &lt;Notice&gt;: #I --&gt; switch: true, bundle_support: false, entitlement_support: true, enabled_by_default: true, disabled_by_profile: false, is_store_demo_device: false
Nov  9 15:54:14.294415 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294424 CommCenter[101] &lt;Notice&gt;: #I --&gt; encryption_supported: false, push_supported: false, push_enabled: false, private_relay_supported: false, msisdn_source: (empty)
Nov  9 15:54:14.294432 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294440 CommCenter[101] &lt;Notice&gt;: #I --&gt; Changed: (nothing)
Nov  9 15:54:14.294448 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294455 CommCenter[101] &lt;Notice&gt;: #I Ims registration interface: kUnknown --&gt; kCellular
Nov  9 15:54:14.294463 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294471 CommCenter[101] &lt;Notice&gt;: #I Lazuli model not allowed: [provisioning style: kUsingToken, sms online: false, msisdn OK: true]
Nov  9 15:54:14.294479 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294487 CommCenter[101] &lt;Notice&gt;: #I Provisioning not possible
Nov  9 15:54:14.294494 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294505 CommCenter[101] &lt;Notice&gt;: #I Infinite validity of UserInteractionRequired.xml xml
Nov  9 15:54:14.294514 CommCenter[101] &lt;Notice&gt;: #I [config.rcs.mnc260.mcc310.jibecloud.net] Declaring IMS not ready. Unexpired : UserInteractionRequired.xml
Nov  9 15:54:14.294522 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294529 CommCenter[101] &lt;Notice&gt;: #I Nudge not required: Allowed
Nov  9 15:54:14.294537 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294546 CommCenter[101] &lt;Notice&gt;: #I Evaluate recheckEntitlementForRCS. Ent:Allowed, Switch toggled:false, CB recheck:false
Nov  9 15:54:14.294554 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294561 CommCenter[101] &lt;Notice&gt;: #I Entitlement result: [RCS support: kSupported, user eligibile: kEligible, token-support: true]
Nov  9 15:54:14.294569 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294577 CommCenter[101] &lt;Notice&gt;: #I Evaluated provisioning style: kUsingToken
Nov  9 15:54:14.294584 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294592 CommCenter[101] &lt;Notice&gt;: #I Retrieving feature switch state
Nov  9 15:54:14.294600 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294608 CommCenter(CoreServices)[101] &lt;Debug&gt;: Starting database access (depth 0, options: 1)   
Nov  9 15:54:14.294616 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294624 CommCenter(CoreServices)[101] &lt;Debug&gt;: BindingEvaluator::CreateWithBundleInfo(ID=&lt;private&gt;, name=&lt;private&gt;, CC=????, vers=(null))
Nov  9 15:54:14.294633 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294641 CommCenter(CoreServices)[101] &lt;Debug&gt;: Truncating a list of bindings to max 1 known-good ones.
Nov  9 15:54:14.294648 CommCenter[101] &lt;Debug&gt;: #D supportsHOVirtualInterfaces: ret = false
Nov  9 15:54:14.294656 CommCenter(CoreServices)[101] &lt;Debug&gt;: Truncating a list of bindings to max 1 known-good ones.
</code></li>
</ul></li>
</ol>

<p>So this last entry probably tells us where to look. The carrier (T-Mobile here) is provisioned for RCS, it’s receiving this interaction required file with infinite validity. So long as that’s in place, it fails to activate. (This is a guess, but it’s certainly more information than the KB articles give on Apple’s sites).</p>
<h2 id="apple-does-not-provide-their-employees-with-c_2">Apple does not provide their employees with correct information on troubleshooting this issue. They do not empower them to properly troubleshoot the issue. <a href="#apple-does-not-provide-their-employees-with-c_2">#</a></h2>
<p><strong>The standard instruction given to them is: “Do not take accountability, blame the carrier.”</strong> </p>

<p>So then I come in and say I have failures with all 3 major carriers and categorically refuse to accept that explanation, when I know my lines work just fine on other iDevices.</p>

<p>The Apple Store initially blamed software, this would be reasonable except we’ve reloaded the state of my phone 3 times now (once from iTunes, and twice now from iCloud, tomorrow will be the 4th time). I gave them permission to wipe any setting and recover the phone, but I go a step further <strong>and request they transfer my T-Mobile eSIM to another store device preferably in the 15 Pro line. They cannot do this because of user privacy reasons</strong>. This is a dealbreaker from troubleshooting, I am not made of money and I do not have any additional 15 pro devices to test with, it’s already crazy enough I have multiple carriers at the ready to test, 2 14 Pro Max’s and a SE3. </p>
<h2 id="google-jibe_1">Google Jibe <a href="#google-jibe_1">#</a></h2>
<p>I think this is where we need information. As I said before, the carriers in the US gave up running their own RCS infrastructure and Apple’s employees aren’t really trained about this situation. With the exception of my own knowledge and the logs I pulled from the phone, Jibe was not mentioned once in the 3 phone calls and the multiple hours onsite in Apple Store today.</p>

<p>I have no business relationship with Google Jibe, and there’s no way for me to interact with or contact them. Their documentation is probably here but I can’t read it, since I’m not a carrier partner: <a href="https://docs.jibemobile.com/">https://docs.jibemobile.com/</a> Apple knows there’s a ‘carrier’ issue, but in reality, RCS is run through Google Jibe in the US and this was never once disclosed to me. I never brought it up until this blog post, I cannot go into a store and say <strong>“I have been using opensource tools to analyze the logs from this phone and think it’s a failure with Jibe”</strong>. Do you get how crazy this sounds? </p>
<h2 id="what-apple39s-going-to-do-tomorrow_1">What Apple’s Going To Do Tomorrow <a href="#what-apple39s-going-to-do-tomorrow_1">#</a></h2>
<p>Since they hit a wall and I refuse to continue to entertain the “go bug T-Mobile/US Mobile” direction, Apple is swapping the board in my phone. Of course they didn’t have the parts in the store to do it, so I have to wait to drive back tomorrow for them to do it. This will have new IMEI numbers and given the experience I’ve had with these lines activating on 3 other iDevices, it should probably work. The only way it wouldn’t is if this was a generational issue, but they have not given me a way to test this. They adamantly tell me: “We are doing you the favor as a courtesy, we don’t believe this is our problem.” I know they are trained to say this but it’s terrible customer service. I shelled out for Applecare+, if it might be the phone just swap it and analyze it back at Apple HQ, I’ve done enough testing now to know it’s something with just this specific device. I referred people to use iPhones because in general they do not often have these issues and the customer support was good. The board swap solution they are offering only wastes my time/fuel and punts the problem down the road. Since we never actually looked at the logs I might hit it again, other users might be affected.</p>
<h2 id="i39d-rather-apple-actually-fix-the-problem_1">I’d rather Apple actually fix the problem <a href="#i39d-rather-apple-actually-fix-the-problem_1">#</a></h2>
<p>I use opensource software not because it’s inherently better, but rather because I can at least triage, understand, and fix problems. <strong>Give me a radar Apple.</strong> I’m a rare dual-SIM user in the US with a Google Jibe RCS failure. Where did it fail? Dig into my logs and tell me: Is it because I hop between primary data carriers (because the whole reason I have dual-carrier is better service coverage). I don’t spend a lot of time on WiFI, I run my house on mobile carriers. The only thing I know is I didn’t change my configuration from iOS 18 to iOS 26, but things stopped working and there’s no way for me to downgrade to 18 because you stopped signing it!</p>

  <figure id="kudo_56Vq422Qs4qiZnGDAb7eju">
    <a href="#kudo">
      
    </a>
    <p>82</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_56Vq422Qs4qiZnGDAb7eju">
    <a href="#kudo">
      
    </a>
    <p>82</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I made a down detector for down detector (394 pts)]]></title>
            <link>https://downdetectorsdowndetector.com</link>
            <guid>45974012</guid>
            <pubDate>Wed, 19 Nov 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://downdetectorsdowndetector.com">https://downdetectorsdowndetector.com</a>, See on <a href="https://news.ycombinator.com/item?id=45974012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">
      
      <header>
        
        <p>A tiny independent status checker.</p>
      </header>

      <div id="status-card">
            <p>Checks by region</p>
            <div>
              <table>
                <thead>
                  <tr>
                    <th>Region</th>
                    <th>Status</th>
                    <th>HTTP</th>
                    <th>Latency</th>
                  </tr>
                </thead>
                <tbody id="regions-body">
                  <tr>
                    <td colspan="4">
                      Loading region checks…
                    </td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>

      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cloudflare outage on November 18, 2025 post mortem (1335 pts)]]></title>
            <link>https://blog.cloudflare.com/18-november-2025-outage/</link>
            <guid>45973709</guid>
            <pubDate>Tue, 18 Nov 2025 23:31:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cloudflare.com/18-november-2025-outage/">https://blog.cloudflare.com/18-november-2025-outage/</a>, See on <a href="https://news.ycombinator.com/item?id=45973709">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post"><article><p>2025-11-18</p><section><p>12 min read</p><img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/9f2k63fiixI2YXDgsnbGq/3c377a6fbd84b5347f814deb6435c476/Cloudflare-Outage-hero-18-nov-2025.png" alt=""><div><p>On 18 November 2025 at 11:20 UTC (all times in this blog are UTC), Cloudflare's network began experiencing significant failures to deliver core network traffic. This showed up to Internet users trying to access our customers' sites as an error page indicating a failure within Cloudflare's network.  </p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3ony9XsTIteX8DNEFJDddJ/7da2edd5abca755e9088002a0f5d1758/BLOG-3079_2.png" alt="HTTP error page displayed during the incident" width="1258" height="854" loading="lazy">
          </figure><p><b>The issue was not caused, directly or indirectly, by a cyber attack or malicious activity of any kind.</b> Instead, it was triggered by a change to one of our database systems' permissions which caused the database to output multiple entries into a “feature file” used by our Bot Management system. That feature file, in turn, doubled in size. The larger-than-expected feature file was then propagated to all the machines that make up our network.</p><p>The software running on these machines to route traffic across our network reads this feature file to keep our Bot Management system up to date with ever changing threats. The software had a limit on the size of the feature file that was below its doubled size. That caused the software to fail.</p><p>After we initially wrongly suspected the symptoms we were seeing were caused by a hyper-scale DDoS attack, we correctly identified the core issue and were able to stop the propagation of the larger-than-expected feature file and replace it with an earlier version of the file. Core traffic was largely flowing as normal by 14:30. We worked over the next few hours to mitigate increased load on various parts of our network as traffic rushed back online. As of 17:06 all systems at Cloudflare were functioning as normal.</p><p>We are sorry for the impact to our customers and to the Internet in general. Given Cloudflare's importance in the Internet ecosystem any outage of any of our systems is unacceptable. That there was a period of time where our network was not able to route traffic is deeply painful to every member of our team. We know we let you down today.</p><p>This post is an in-depth recount of exactly what happened and what systems and processes failed. It is also the beginning, though not the end, of what we plan to do in order to make sure an outage like this will not happen again.</p>
    <p>
      <h2 id="the-outage">The outage</h2>
      
    </p>
    <p>The chart below shows the volume of 5xx error HTTP status codes served by the Cloudflare network. Normally this should be very low, and it was right up until the start of the outage. </p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7GdZcWhEqNjwOmLcsKOXT0/fca7e6970d422d04c81b2baafb988cbe/BLOG-3079_3.png" alt="Volume of HTTP 5xx requests served by the Cloudflare network" width="1507" height="733" loading="lazy">
          </figure><p>The volume prior to 11:20 is the expected baseline of 5xx errors observed across our network. The spike, and subsequent fluctuations, show our system failing due to loading the incorrect feature file. What’s notable is that our system would then recover for a period. This was very unusual behavior for an internal error.</p><p>The explanation was that the file was being generated every five minutes by a query running on a ClickHouse database cluster, which was being gradually updated to improve permissions management. Bad data was only generated if the query ran on a part of the cluster which had been updated. As a result, every five minutes there was a chance of either a good or a bad set of configuration files being generated and rapidly propagated across the network.</p><p>This fluctuation made it unclear what was happening as the entire system would recover and then fail again as sometimes good, sometimes bad configuration files were distributed to our network. Initially, this led us to believe this might be caused by an attack. Eventually, every ClickHouse node was generating the bad configuration file and the fluctuation stabilized in the failing state.</p><p>Errors continued until the underlying issue was identified and resolved starting at 14:30. We solved the problem by stopping the generation and propagation of the bad feature file and manually inserting a known good file into the feature file distribution queue. And then forcing a restart of our core proxy.</p><p>The remaining long tail in the chart above is our team restarting remaining services that had entered a bad state, with 5xx error code volume returning to normal at 17:06.</p><p>The following services were impacted:</p><table><tbody><tr><th><p><b>Service / Product</b></p></th><th><p><b>Impact description</b></p></th></tr><tr><td><p>Core CDN and security services</p></td><td><p>HTTP 5xx status codes. The screenshot at the top of this post shows a typical error page delivered to end users.</p></td></tr><tr><td><p>Turnstile</p></td><td><p>Turnstile failed to load.</p></td></tr><tr><td><p>Workers KV</p></td><td><p>Workers KV returned a significantly elevated level of HTTP 5xx errors as requests to KV’s “front end” gateway failed due to the core proxy failing.</p></td></tr><tr><td><p>Dashboard</p></td><td><p>While the dashboard was mostly operational, most users were unable to log in due to Turnstile being unavailable on the login page.</p></td></tr><tr><td><p>Email Security</p></td><td><p>While email processing and delivery were unaffected, we observed a temporary loss of access to an IP reputation source which reduced spam-detection accuracy and prevented some new-domain-age detections from triggering, with no critical customer impact observed. We also saw failures in some Auto Move actions; all affected messages have been reviewed and remediated.</p></td></tr><tr><td><p>Access</p></td><td><p>Authentication failures were widespread for most users, beginning at the start of the incident and continuing until the rollback was initiated at 13:05. Any existing Access sessions were unaffected.</p><p>All failed authentication attempts resulted in an error page, meaning none of these users ever reached the target application while authentication was failing. Successful logins during this period were correctly logged during this incident.&nbsp;</p><p>Any Access configuration updates attempted at that time would have either failed outright or propagated very slowly. All configuration updates are now recovered.</p></td></tr></tbody></table><p>As well as returning HTTP 5xx errors, we observed significant increases in latency of responses from our CDN during the impact period. This was due to large amounts of CPU being consumed by our debugging and observability systems, which automatically enhance uncaught errors with additional debugging information.</p>
    <p>
      <h2 id="how-cloudflare-processes-requests-and-how-this-went-wrong-today">How Cloudflare processes requests, and how this went wrong today</h2>
      
    </p>
    <p>Every request to Cloudflare takes a well-defined path through our network. It could be from a browser loading a webpage, a mobile app calling an API, or automated traffic from another service. These requests first terminate at our HTTP and TLS layer, then flow into our core proxy system (which we call FL for “Frontline”), and finally through Pingora, which performs cache lookups or fetches data from the origin if needed.</p><p>We previously shared more detail about how the core proxy works <a href="https://blog.cloudflare.com/20-percent-internet-upgrade/"><u>here</u></a>.&nbsp;</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/6qlWXM3gh4SaYYvsGc7mFV/99294b22963bb414435044323aed7706/BLOG-3079_4.png" alt="Diagram of our reverse proxy architecture" width="1999" height="846" loading="lazy">
          </figure><p>As a request transits the core proxy, we run the various security and performance products available in our network. The proxy applies each customer’s unique configuration and settings, from enforcing WAF rules and DDoS protection to routing traffic to the Developer Platform and R2. It accomplishes this through a set of domain-specific modules that apply the configuration and policy rules to traffic transiting our proxy.</p><p>One of those modules, Bot Management, was the source of today’s outage.&nbsp;</p><p>Cloudflare’s <a href="https://www.cloudflare.com/application-services/products/bot-management/"><u>Bot Management</u></a> includes, among other systems, a machine learning model that we use to generate bot scores for every request traversing our network. Our customers use bot scores to control which bots are allowed to access their sites — or not.</p><p>The model takes as input a “feature” configuration file. A feature, in this context, is an individual trait used by the machine learning model to make a prediction about whether the request was automated or not. The feature configuration file is a collection of individual features.</p><p>This feature file is refreshed every few minutes and published to our entire network and allows us to react to variations in traffic flows across the Internet. It allows us to react to new types of bots and new bot attacks. So it’s critical that it is rolled out frequently and rapidly as bad actors change their tactics quickly.</p><p>A change in our underlying ClickHouse query behaviour (explained below) that generates this file caused it to have a large number of duplicate “feature” rows. This changed the size of the previously fixed-size feature configuration file, causing the bots module to trigger an error.</p><p>As a result, HTTP 5xx error codes were returned by the core proxy system that handles traffic processing for our customers, for any traffic that depended on the bots module. This also affected Workers KV and Access, which rely on the core proxy.</p><p>Unrelated to this incident, we were and are currently migrating our customer traffic to a new version of our proxy service, internally known as <a href="https://blog.cloudflare.com/20-percent-internet-upgrade/"><u>FL2</u></a>. Both versions were affected by the issue, although the impact observed was different.</p><p>Customers deployed on the new FL2 proxy engine, observed HTTP 5xx errors. Customers on our old proxy engine, known as FL, did not see errors, but bot scores were not generated correctly, resulting in all traffic receiving a bot score of zero. Customers that had rules deployed to block bots would have seen large numbers of false positives. Customers who were not using our bot score in their rules did not see any impact.</p><p>Throwing us off and making us believe this might have been an attack was another apparent symptom we observed: Cloudflare’s status page went down. The status page is hosted completely off Cloudflare’s infrastructure with no dependencies on Cloudflare. While it turned out to be a coincidence, it led some of the team diagnosing the issue to believe that an attacker may be targeting both our systems as well as our status page. Visitors to the status page at that time were greeted by an error message:</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/7LwbB5fv7vdoNRWWDGN7ia/dad8cef76eee1305e0216d74a813612b/BLOG-3079_5.png" alt="Error on the Cloudflare status page" width="1999" height="478" loading="lazy">
          </figure><p>In the internal incident chat room, we were concerned that this might be the continuation of the recent spate of high volume <a href="https://techcommunity.microsoft.com/blog/azureinfrastructureblog/defending-the-cloud-azure-neutralized-a-record-breaking-15-tbps-ddos-attack/4470422"><u>Aisuru</u></a> <a href="https://blog.cloudflare.com/defending-the-internet-how-cloudflare-blocked-a-monumental-7-3-tbps-ddos/"><u>DDoS attacks</u></a>:</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/3Ph13HSsOGC0KYRfoeZmSy/46522e46ed0132d2ea551aef4c71a5d6/BLOG-3079_6.png" alt="Internal chat screenshot" width="1188" height="278" loading="lazy">
          </figure>
    <p>
      <h3 id="the-query-behaviour-change">The query behaviour change</h3>
      
    </p>
    <p>I mentioned above that a change in the underlying query behaviour resulted in the feature file containing a large number of duplicate rows. The database system in question uses ClickHouse’s software.</p><p>For context, it’s helpful to know how ClickHouse distributed queries work. A ClickHouse cluster consists of many shards. To query data from all shards, we have so-called distributed tables (powered by the table engine <code>Distributed</code>) in a database called <code>default</code>. The Distributed engine queries underlying tables in a database <code>r0</code>. The underlying tables are where data is stored on each shard of a ClickHouse cluster.</p><p>Queries to the distributed tables run through a shared system account. As part of efforts to improve our distributed queries security and reliability, there’s work being done to make them run under the initial user accounts instead.</p><p>Before today, ClickHouse users would only see the tables in the <code>default</code> database when querying table metadata from ClickHouse system tables such as <code>system.tables</code> or <code>system.columns</code>.</p><p>Since users already have implicit access to underlying tables in <code>r0</code>, we made a change at 11:05 to make this access explicit, so that users can see the metadata of these tables as well. By making sure that all distributed subqueries can run under the initial user, query limits and access grants can be evaluated in a more fine-grained manner, avoiding one bad subquery from a user affecting others.</p><p>The change explained above resulted in all users accessing accurate metadata about tables they have access to. Unfortunately, there were assumptions made in the past, that the list of columns returned by a query like this would only include the “<code>default</code>” database:</p><p><code>SELECT
  name,
  type
FROM system.columns
WHERE
  table = 'http_requests_features'
order by name;</code></p><p>Note how the query does not filter for the database name. With us gradually rolling out the explicit grants to users of a given ClickHouse cluster, after the change at 11:05 the query above started returning “duplicates” of columns because those were for underlying tables stored in the r0 database.</p><p>This, unfortunately, was the type of query that was performed by the Bot Management feature file generation logic to construct each input “feature” for the file mentioned at the beginning of this section.&nbsp;</p><p>The query above would return a table of columns like the one displayed (simplified example):</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/ZIC5X8vMM7ifbJc0vxgLD/49dd33e7267bdb03b265ee0acccf381d/Screenshot_2025-11-18_at_2.51.24%C3%A2__PM.png" alt="Example of code block" width="548" height="121" loading="lazy">
          </figure><p>However, as part of the additional permissions that were granted to the user, the response now contained all the metadata of the <code>r0</code> schema effectively more than doubling the rows in the response ultimately affecting the number of rows (i.e. features) in the final file output.&nbsp;</p>
    <p>
      <h3 id="memory-preallocation">Memory preallocation</h3>
      
    </p>
    <p>Each module running on our proxy service has a number of limits in place to avoid unbounded memory consumption and to preallocate memory as a performance optimization. In this specific instance, the Bot Management system has a limit on the number of machine learning features that can be used at runtime. Currently that limit is set to 200, well above our current use of ~60 features. Again, the limit exists because for performance reasons we preallocate memory for the features.</p><p>When the bad file with more than 200 features was propagated to our servers, this limit was hit — resulting in the system panicking. The FL2 Rust code that makes the check and was the source of the unhandled error is shown below:</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/640fjk9dawDk7f0wJ8Jm5S/668bcf1f574ae9e896671d9eee50da1b/BLOG-3079_7.png" alt="code that generated the error" width="1472" height="456" loading="lazy">
          </figure><p>This resulted in the following panic which in turn resulted in a 5xx error:</p><p><code>thread fl2_worker_thread panicked: called Result::unwrap() on an Err value</code></p>
    <p>
      <h3 id="other-impact-during-the-incident">Other impact during the incident</h3>
      
    </p>
    <p>Other systems that rely on our core proxy were impacted during the incident. This included Workers KV and Cloudflare Access. The team was able to reduce the impact to these systems at 13:04, when a patch was made to Workers KV to bypass the core proxy. Subsequently, all downstream systems that rely on Workers KV (such as Access itself) observed a reduced error rate.&nbsp;</p><p>The Cloudflare Dashboard was also impacted due to both Workers KV being used internally and Cloudflare Turnstile being deployed as part of our login flow.</p><p>Turnstile was impacted by this outage, resulting in customers who did not have an active dashboard session being unable to log in. This showed up as reduced availability during two time periods: from 11:30 to 13:10, and between 14:40 and 15:30, as seen in the graph below.</p>
          <figure>
          <img src="https://cf-assets.www.cloudflare.com/zkvhlag99gkb/nB2ZlYyXiGTNngsVotyjN/479a0f9273c160c63925be87592be023/BLOG-3079_8.png" alt="availability of Cloudflare internal APIs during the incident" width="1999" height="674" loading="lazy">
          </figure><p>The first period, from 11:30 to 13:10, was due to the impact to Workers KV, which some control plane and dashboard functions rely upon. This was restored at 13:10, when Workers KV bypassed the core proxy system.

The second period of impact to the dashboard occurred after restoring the feature configuration data. A backlog of login attempts began to overwhelm the dashboard. This backlog, in combination with retry attempts, resulted in elevated latency, reducing dashboard availability. Scaling control plane concurrency restored availability at approximately 15:30.</p>
    
    <p>Now that our systems are back online and functioning normally, work has already begun on how we will harden them against failures like this in the future. In particular we are:</p><ul><li><p>Hardening ingestion of Cloudflare-generated configuration files in the same way we would for user-generated input</p></li><li><p>Enabling more global kill switches for features</p></li><li><p>Eliminating the ability for core dumps or other error reports to overwhelm system resources</p></li><li><p>Reviewing failure modes for error conditions across all core proxy modules</p></li></ul><p>Today was Cloudflare's worst outage <a href="https://blog.cloudflare.com/details-of-the-cloudflare-outage-on-july-2-2019/"><u>since 2019</u></a>. We've had outages that have made our <a href="https://blog.cloudflare.com/post-mortem-on-cloudflare-control-plane-and-analytics-outage/"><u>dashboard unavailable</u></a>. Some that have caused <a href="https://blog.cloudflare.com/cloudflare-service-outage-june-12-2025/"><u>newer features</u></a> to not be available for a period of time. But in the last 6+ years we've not had another outage that has caused the majority of core traffic to stop flowing through our network.</p><p>An outage like today is unacceptable. We've architected our systems to be highly resilient to failure to ensure traffic will always continue to flow. When we've had outages in the past it's always led to us building new, more resilient systems.</p><p>On behalf of the entire team at Cloudflare, I would like to apologize for the pain we caused the Internet today. </p><table><tbody><tr><th><p>Time (UTC)</p></th><th><p>Status</p></th><th><p>Description</p></th></tr><tr><td><p>11:05</p></td><td><p>Normal.</p></td><td><p>Database access control change deployed.</p></td></tr><tr><td><p>11:28</p></td><td><p>Impact starts.</p></td><td><p>Deployment reaches customer environments, first errors observed on customer HTTP traffic.</p></td></tr><tr><td><p>11:32-13:05</p></td><td><p>The team investigated elevated traffic levels and errors to Workers KV service.</p></td><td><p>The initial symptom appeared to be degraded Workers KV response rate causing downstream impact on other Cloudflare services.</p><p>Mitigations such as traffic manipulation and account limiting were attempted to bring the Workers KV service back to normal operating levels.</p><p>The first automated test detected the issue at 11:31 and manual investigation started at 11:32. The incident call was created at 11:35.</p></td></tr><tr><td><p>13:05</p></td><td><p>Workers KV and Cloudflare Access bypass implemented — impact reduced.</p></td><td><p>During investigation, we used internal system bypasses for Workers KV and Cloudflare Access so they fell back to a prior version of our core proxy. Although the issue was also present in prior versions of our proxy, the impact was smaller as described below.</p></td></tr><tr><td><p>13:37</p></td><td><p>Work focused on rollback of the Bot Management configuration file to a last-known-good version.</p></td><td><p>We were confident that the Bot Management configuration file was the trigger for the incident. Teams worked on ways to repair the service in multiple workstreams, with the fastest workstream a restore of a previous version of the file.</p></td></tr><tr><td><p>14:24</p></td><td><p>Stopped creation and propagation of new Bot Management configuration files.</p></td><td><p>We identified that the Bot Management module was the source of the 500 errors and that this was caused by a bad configuration file. We stopped automatic deployment of new Bot Management configuration files.</p></td></tr><tr><td><p>14:24</p></td><td><p>Test of new file complete.</p></td><td><p>We observed successful recovery using the old version of the configuration file and then focused on accelerating the fix globally.</p></td></tr><tr><td><p>14:30</p></td><td><p>Main impact resolved. Downstream impacted services started observing reduced errors.</p></td><td><p>A correct Bot Management configuration file was deployed globally and most services started operating correctly.</p></td></tr><tr><td><p>17:06</p></td><td><p>All services resolved. Impact ends.</p></td><td><p>All downstream services restarted and all operations fully restored.</p></td></tr></tbody></table></div></section><div><p>Cloudflare's connectivity cloud protects <a target="_blank" href="https://www.cloudflare.com/network-services/" rel="noreferrer">entire corporate networks</a>, helps customers build <a target="_blank" href="https://workers.cloudflare.com/" rel="noreferrer">Internet-scale applications efficiently</a>, accelerates any <a target="_blank" href="https://www.cloudflare.com/performance/accelerate-internet-applications/" rel="noreferrer">website or Internet application</a>, <a target="_blank" href="https://www.cloudflare.com/ddos/" rel="noreferrer">wards off DDoS attacks</a>, keeps <a target="_blank" href="https://www.cloudflare.com/application-security/" rel="noreferrer">hackers at bay</a>, and can help you on <a target="_blank" href="https://www.cloudflare.com/products/zero-trust/" rel="noreferrer">your journey to Zero Trust</a>.</p><p>Visit <a target="_blank" href="https://one.one.one.one/" rel="noreferrer">1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.</p><p>To learn more about our mission to help build a better Internet, <a target="_blank" href="https://www.cloudflare.com/learning/what-is-cloudflare/" rel="noreferrer">start here</a>. If you're looking for a new career direction, check out <a target="_blank" href="https://www.cloudflare.com/careers" rel="noreferrer">our open positions</a>.</p></div><astro-slot> <!--[if astro]>server-island-start<![endif]--> </astro-slot><a href="https://blog.cloudflare.com/tag/outage/">Outage</a><a href="https://blog.cloudflare.com/tag/post-mortem/">Post Mortem</a><a href="https://blog.cloudflare.com/tag/bot-management/">Bot Management</a></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rebecca Heineman – from homelessness to porting Doom (2022) (232 pts)]]></title>
            <link>https://corecursive.com/doomed-to-fail-with-burger-becky/</link>
            <guid>45973573</guid>
            <pubDate>Tue, 18 Nov 2025 23:13:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://corecursive.com/doomed-to-fail-with-burger-becky/">https://corecursive.com/doomed-to-fail-with-burger-becky/</a>, See on <a href="https://news.ycombinator.com/item?id=45973573">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><i>Note: This podcast is designed to be heard. If you are able, we strongly encourage you to listen to the
          audio, which includes emphasis that’s not on the page</i></p><div>
          <h2 id="introduction"><strong>Introduction</strong><!-- 00:00 --></h2>

<p><strong>Adam:</strong><!--(00:00)-->
Hi. This is CoRecursive, and I’m Adam Gordon Bell. Each episode is the story of a piece of software being built. Why don’t you tell me what you do and who you are?</p>

<p><strong>Becky:</strong><!--(00:12)-->
Okay. Yeah. I’m Rebecca Ann Heineman. I’ve been in the video game industry since the beginning of time. I started by winning the Atari 2600 Space Invaders tournament in November of 1980. Since then, went to work at companies like Avalon Hill, and then Boone Corporation until Boone imploded, and then we formed Interplay out of the ashes of Boone.</p>

<p><strong>Adam:</strong><!--(00:36)-->
Becky’s a bit famous, she’s worked on hundreds of games. And her specialty was porting games from one platform to another. Today is about a game port that went sideways, porting a little game called Doom, and the struggles involved.</p>

<p><strong>Becky:</strong><!--(00:50)-->
And I said, “Okay, see this golden master I’ve got right here? I just encrypted, ready to go for duplication. Where’s my other $20,000?” “Where’s the new weapons?” It’s like, “Didn’t have enough space, didn’t have enough time.” And he’s like, “Oh, but I promised people knew weapons.” Like, “Can’t do it. Don’t have time.” “But I gave you JPEGs.” “I put them in the trash. Sorry.” He was mad. Oh gosh, he was mad.</p>

<h2 id="childhood"><strong>Childhood</strong><!-- 01:14 --></h2>

<p><strong>Adam:</strong><!--(01:14)-->
So that’s today’s story. The story of Burger Becky porting Doom to the 3DO. It’s kind of a retro software story, but it’s also a story about project management and software development going a little bit sideways. There’s engines to tweak, there’s deadlines to hit, hardware acceleration to get working. And dramatic rock anthems to record.</p>

<!--(01:38)-->
<p>The path that led Burger Becky into video game development, which he’s still doing today, it started back when she was a young teen. This was the late 70s, the Atari 2600 had recently come out, and so had the Apple II. And Becky’s childhood set her on a path that eventually led her right towards that port. But even so, she wouldn’t wish her early years on anyone.</p>

<p><strong>Becky:</strong><!--(02:03)-->
If I was in my 20s, I would basically not even bring it up. In my 30s, I would probably burst into tears halfway through any of this. By the time I was in my 40s, my parents have already passed away. I’m like, okay, the people who caused this are gone. And now I could finally set myself free and no longer have to have nightmares of my dad bursting in the door to beat the crap out of me because he was drunk again. Which is one of the reasons why I don’t smoke or drink, because it reminds me of my shitty parents.</p>

<p><strong>Adam:</strong><!--(02:34)-->
Becky normally doesn’t talk about this stuff because, well, the specifics are hard to hear.</p>

<p><strong>Becky:</strong><!--(02:40)-->
My mom and dad married because my mom was already pregnant, and they couldn’t have a child out of wedlock. And my dad was not my dad, it was someone else. Then in time, they had two more children, two sons. I was the eldest. My dad would favor my two brothers, and he would treat them like princes. Whereas, I was being treated as the help. And so I was always having to clean the dishes, do this. And every time my dad got mad, which every other day, I would be the one he would beat the crap out of. And then when we had dinner with the family, I was the one serving the meals while everybody else was eating around there. And of course I didn’t get a plate. And then by the time it was all done, I would eat the leftovers. And of course if they saw me eating the leftovers, I would get punished.</p>

<p><strong>Adam:</strong><!--(03:24)-->
As an adult, she’s never totally gotten past this food insecurity. Coworkers would spread rumors about her hiding burgers in her desks to nibble on when no one was looking.</p>

<p><strong>Becky:</strong><!--(03:34)-->
Honestly, there’s truth to that. I was not picky about the condition of the food I was eating because I was conditioned from my earliest memory to the time I got out of that hell hole that food is life. Don’t be picky about it, because otherwise starving is your only other option.</p>

<p><strong>Adam:</strong><!--(03:54)-->
Her nickname came from her food insecurities and from a rough childhood. And eventually it was all too much for her.</p>

<h2 id="homeless"><strong>Homeless</strong><!-- 04:00 --></h2>

<p><strong>Becky:</strong><!--(04:00)-->
Somewhere when I was 15-ish I just had it. And I went to school and I just didn’t go home. And to put it in perspective, my family never sent out a missing persons report, or anything like that. That’s how much they cared. I then lived behind a dumpster of a store, I think was called Market Basket at the time. But I just lived either in the dumpster when it was raining or behind it, because they had blankets and stuff like that.</p>

<p><strong>Adam:</strong><!--(04:26)-->
Becky got a job at JC Penny.</p>

<p><strong>Becky:</strong><!--(04:28)-->
I just went in there and just said, “Hey, I’m 18.” And they didn’t bother checking anything, because back then we weren’t so anal about immigration status and shit like that. Then Christmas was done, then they had me transfer to their warehouse, but I was just in there moving boxes around, moving shit around. And that was it until finally I ended up at a video game contest.</p>

<h2 id="atari-space-invaders"><strong>Atari Space Invaders</strong><!-- 04:51 --></h2>

<p><strong>Adam:</strong><!--(04:51)-->
The video game contest ends up being her entry into the industry, and it went like this. Space Invaders was pretty big at the time, and Atari decided as a publicity stunt to have a national tournament. It was the first eSport tournament in North America.</p>

<p><strong>Becky:</strong><!--(05:06)-->
They had people come into five different cities. It was San Jose, Los Angeles, Dallas, Chicago, and New York. And then each of the winners were then flown to New York City, and then that contest was televised.</p>

<p><strong>Adam:</strong><!--(05:21)-->
Becky’s friend convinced her to compete in the LA contest, and she won, and was flown off to New York for the championship.</p>

<p><strong>Becky:</strong><!--(05:29)-->
It was more terrifying than exciting because I didn’t really understand what the heck was going on, I was just a kid. And I was there without my parents. They didn’t factor in that kids would be winning these contests, so they lucked out in which the parents of the other four contestants actually paid their own way and came to the nationals. I went by myself to which Atari, to their horror was like, “Where’s your parents?” “You only gave me one ticket.” There was a comedy of errors, but it was back to the fact that it was never been done before. And hence, when it was the first contest, yeah, you can imagine some growing pains.</p>

<p><strong>Adam:</strong><!--(06:10)-->
All of a sudden they have a moment where they’re like, wait, are we just paying to fly minors across state lines without…</p>

<p><strong>Becky:</strong><!--(06:17)-->
Oh, I’m certain their liability attorneys were just crapping their pants in the other room going like, oh, please don’t fall down the stairs. Please don’t stub her toe. Please don’t get food poisoning. Please don’t get in an accident, the liability, because we are taking care of a minor.</p>

<p><strong>Adam:</strong><!--(06:38)-->
Becky won, and she became the first championship competitive gamer in the US.</p>

<p><strong>Becky:</strong><!--(06:45)-->
They had people from the news all behind us, like 200 people from different newspapers. And CNN, which was just brand new. I think CNN was only three months old at the time. And then ABC, NBC, CBS, et cetera. And of course they recorded it. And then once the contest was over, then I had microphones shoved in my face and they interviewed me, and then sent it off.</p>

<h2 id="arcade-repair"><strong>Arcade Repair</strong><!-- 07:08 --></h2>

<p><strong>Adam:</strong><!--(07:08)-->
Back at home, after the tournament, Becky’s a bit famous and she gets some opportunities thrown in her lap. She gets a job at an arcade where she’s making change and repairing machines because they thought it would be pretty cool to be able to say they had the national champ there.</p>

<p><strong>Becky:</strong><!--(07:23)-->
But then I found I had a talent for fixing video games, and I met a friend there who taught me the fine art of video game logic board repair. Which then, now that’s why I learned all my TTL logic and stuff like that, which helped me design boards that would allow me to copy Atari 2600 cartridges. But yeah, I was homeless not that long. It was maybe three or four months, because every now and then I would go back to my old house. But then one day I went there and I saw a moving van. And, that’s weird. And then I saw my mom and she was like, “Oh, where have you been?” It’s like, “Been away.” And she’s like, “Well, we’re getting a divorce. I’m moving to this place.” And says, “Oh, so dad’s not going to be with you.” It’s like, “No, he’s staying here.” “Okay. Then, can I move in with you?” And at that point, moved back in. And that was my home base until I moved to Towson, Maryland.</p>

<h2 id="the-apple-ii-and-the-2600"><strong>The Apple II and The 2600</strong><!-- 08:15 --></h2>

<p><strong>Adam:</strong><!--(08:15)-->
At home with her mom, Becky had an Apple II she was tinkering around with, and she kept working at the arcade repairing video game boards. And this gave her some familiarity with game hardware. And meanwhile, the video game industry is exploding.</p>

<p><strong>Becky:</strong><!--(08:31)-->
The Quaker Oats company formed a video game company. Milton Bradley had game company. 20th Century Fox made a game company. Of course, you know the big players, Imagic and Activision. And even Mattel making Atari cartridges. It’s like, this is also at a time when every video game console, the Atari, the Intellivision, and the Coleco, they were closely guarding how their machines worked because they did not license their technology to anyone because it had not been heard of. And you may remember when a bunch of Atari employees left to form Activision, Atari immediately sued them. And the grounds was, you can’t make cartridges for our player, the Atari 2600, because it’s covered under patent, covered under all this other copyright and other gobbledygook.</p>

<p><strong>Adam:</strong><!--(09:22)-->
But the lawsuit failed, and the market for third party games opened up on the 2600. If you could hire an Atari game maker, you could boot up a game company and make a bunch of money. It was a bubble. And while all this was happening, Becky was using her arcade repair knowledge to pirate Atari cartridges. And then she starts figuring out how video game software works through an odd coincidence.</p>

<h2 id="the-6502"><strong>The 6502</strong><!-- 09:45 --></h2>

<p><strong>Becky:</strong><!--(09:45)-->
The Apple II uses a 6502 processor. The Atari 2600 uses a 6502 processor. Now, in the Apple II, if you put data in your memory, go into what’s called the monitor, which allows you to disassemble 6502 code. I was constantly looking at the ROMs of the Apple II, and disassemble it and saw all this instructions, and figured out how the instructions worked. And so I can write my own little Apple II programs. Well, when I was piloting Atari 2600 cartridges, I put them in memory. I said, let’s take a look what’s in there. And I saw code, and it all made sense. It was 6502.</p>

<!--(10:19)-->
<p>So I was disassembling I was like, what does this code do? What does this do? Then I would, let’s say, okay, it loaded value in this register. Let’s change that value, upload the game into an Atari 2600, see what happens. And eventually I found, oh, this register changes the background color. This changes the left Sprite, this changes the right Sprite. And then just through iteration, iteration, iteration, trial and error, I was able to figure out how to generate an Atari 2600 screen. And of course, yeah, there was a couple of registers I didn’t know what they did, but over time I figured them all out.</p>

<h2 id="avalon-games"><strong>Avalon Games</strong><!-- 10:55 --></h2>

<p><strong>Adam:</strong><!--(10:55)-->
She mentions this, that she’s creating her own cartridges to someone who works in the industry.</p>

<p><strong>Becky:</strong><!--(11:00)-->
And he’s like, “You reversed the Atari 2600?” Says, “Yeah, I did.” And he goes, “I’ve got a company to talk to.” And he introduced me to the owners of a company called the Avalon Hill Game Company, who called me up. And I told him, “Yeah, I know how to program the 2600. I got demo carts and everything.”</p>

<p><strong>Adam:</strong><!--(11:19)-->
Avalon Games was a maker of board games, and they had produced some computer games as well. But they were small players, they couldn’t afford to get some Atari employee to work there and port their games to cartridges. But now they didn’t have to, they had their own cartridge expert in teenage Becky.</p>

<p><strong>Becky:</strong><!--(11:35)-->
They hired me right there on the phone. And then a couple of days later I had a plane ticket and everything, and I relocated to Towson, Maryland from Whittier, California. And that was my first paid programming job. And I had never had any training whatsoever, it was just me learning on my own.</p>

<h2 id="the-port-master"><strong>The Port Master</strong><!-- 11:53 --></h2>

<p><strong>Adam:</strong><!--(11:53)-->
And so Becky’s career took off from there, she became the go-to person for porting games. And eventually masters not just the Apple II, but the 2600 and the Commodore, and PCs, and much more. She was on the founding team of the company Interplay, and was their go-to person for ports and everything Apple. And then a new console came out.</p>

<p><strong>Becky:</strong><!--(12:13)-->
This was around 1994, and I’d already gotten a reputation at Interplay that I can assimilate a new console or a new platform within weeks, and already start generating code on it. Everything from the Super Nintendo, the 8 bit Nintendo, the Game Boy. And of course, I already had an affection for Macintosh’s, because I had written so many games for Mac Play. But that aside, what happened was that a new console was coming out called the 3DO.</p>

<p><strong>Adam:</strong><!--(12:41)-->
The 3DO was a gaming console proposed by EA founder Trip Hawkins, and produced by Panasonic among others. It was competing with the Atari Jaguar and the Sega Saturn. But it was the one with all the buzz. It had such a huge buzz that Time Magazine called it 1993’s Product of the Year.</p>

<p><strong>Becky:</strong><!--(12:59)-->
Since it acquired a Mac for development, I was of course the logical choice. So I got a 3DO dev kit, got the software, and started just testing stuff to see what in the world I could do on this new console.</p>

<p><strong>Adam:</strong><!--(13:13)-->
What does the dev kit look like? How does it work? What am I seeing?</p>

<h2 id="3do-dev-kit"><strong>3DO Dev Kit</strong><!-- 13:16 --></h2>

<p><strong>Becky:</strong><!--(13:16)-->
The dev kit looks like a big PC. It literally is in a PC case, vertical orientation, popular among the 90s PCs. The only thing that you’ll notice is different is that in the front just below where the CD is, is a little panel which just says Reset, Debug, and has a 3DO logo on it, and a little switch that says Encrypted and Not. And the whole idea behind that is if you turn on encrypted, then you could put encrypted retail discs inside of it and run the game. But if you turn non-encrypted, then you don’t need to be encrypted. And then you could also use the debugging feature. There was a NuBus card made by 3DO that plugs into your 68K Mac on a NuBus card. And then you had a fiber optic cable, which goes from the 3DO into the Macintosh.</p>

<p><strong>Adam:</strong><!--(14:05)-->
You did the development for the 3DO using your Mac over that cable using MPW, the Macintosh programmer’s workshop.</p>

<p><strong>Becky:</strong><!--(14:12)-->
It essentially is their idea of an IDE/command line. In which you have text editors, you have a command line, and you could go ahead and issue commands and so forth, but it’s all hybrided. You could be in the middle of editing text, but if you hit command return or something like that, that line would execute it as a command line. It’s kind of weird. But I think VS code is now doing something like this these days. But what goes on is that you have a bunch of command lines, much like you do with a modern operating system, where you have a shell and a bunch of tools and so forth. Except of course the tools here you have is the Norcroft C compiler, which just compiles into ARM. Because it was like, as far as I know, the 3DO was the first console that used an ARM CPU.</p>

<p><strong>Adam:</strong><!--(14:58)-->
So you wrote C code, compiled it on the 3DO operating system, and then you generate art using Electronic Arts 3D Studio.</p>

<p><strong>Becky:</strong><!--(15:06)-->
And they had plugins specifically for 3DO. So you draw some art, when it’s all done, the plugin would convert it to 3DO cell format, which is the hardware blitters format.</p>

<p><strong>Adam:</strong><!--(15:17)-->
A blitter is a graphics co-processor. It’s sort of an early version of a GPU.</p>

<p><strong>Becky:</strong><!--(15:23)-->
And then you just take these files and put them in your game, and you’d run your game.</p>

<h2 id="wolfenstien-for-the-3do"><strong>Wolfenstien for the 3DO</strong><!-- 15:27 --></h2>

<p><strong>Adam:</strong><!--(15:27)-->
The first game Becky ported to the 3DO was a personal favorite of mine, it was Wolfenstein.</p>

<p><strong>Becky:</strong><!--(15:32)-->
And I just simply took the source code I had for Wolfenstein. At the time, it was the Mac. Put that here, built it for 3DO. Made a 3DO shell, added a console-like control panel. Because the Macintosh used a mouse and keyboard. The 3DO uses exclusively the console controller. Wrote that all together, put it out there, and the game shift. And then, yeah, it was very easy. And the 3DO really worked well with what Wolfenstein 3D wanted. The game ran at 30 frames per second, and it was perfect for the platform. And then I did games like Battle Chess, Siberia, Casper, Shadowland, Kingdom of Far Reaches. There’s games I’m even forgetting that I did on the 3DO. Out of This World, that’s another one. The 3DO version of Out of This World, we took all the backgrounds, sent them to an animation studio who does backgrounds for cartoons. And then they drew paintings of each background. We then scanned them, and then that is what was used in the video game.</p>

<p><strong>Adam:</strong><!--(16:39)-->
In an upcoming Supporters episode, Becky’s going to go deep on this Out of the World port. It’s a wild story. But yeah, Becky becomes the 3DO expert, and so more of this work keeps coming her way.</p>

<h2 id="the-doom-project"><strong>The DOOM Project</strong><!-- 16:51 --></h2>

<p><strong>Becky:</strong><!--(16:51)-->
The guys at 3DO were very impressed with the port, because it was something that was really showcasing the 3DO. We sold a lot of copies on that platform. Well, then they told me that, “Hey, you’re still doing in software conversions?” “Yeah, I still do that.” They said they had a company that has the rights to Doom for the 3DO. The problem was that they were having a hard time getting a copy of this game from 3DO, despite the fact that they’ve been telling people that it’s 90% complete. And that it’s going to have new weapons, new stuff, whatever. And the latest excuse they’re getting from them is that the game is 90% complete, but their developer flaked on them. So now they need someone to help them finish the game. They said, “Can you handle this?” And I go, “Yeah, if the game’s 90% complete, no problem.”</p>

<p><strong>Adam:</strong><!--(17:37)-->
This seems like it would be a pretty sweet gig. The game had to be ready for Christmas, but it’s August and there’s only 10% left. Plus then Becky would be able to say she worked on the Doom port. It seems like a great deal. The thing was, Becky had been around in the industry and she knew a lot of the players, but she had never heard of Art Data. That actually wasn’t that surprising, considering what was going on in the industry at that time. The thing was, Becky knew a lot of the players in the industry, and she had never heard of Art Data. But that actually wasn’t that surprising considering what was going on at the industry at that time.</p>



<p><strong>Becky:</strong><!--(18:12)-->
3DO was so hyped as they’re becoming the next wave of multimedia. Because in addition to being a new video game console, they were bragging about how the 3DO could play movie DVDs. It was actually not a DVD, it was a CD format, but it was called a CDV or something like that. So you could buy movies, put them on the 3DO and watch a movie on it. They had the idea that was going to be streaming, they were going to have some sort of add-on that allows you to connect to your cable TV box. There was going to be an add-on lets you have ethernet so you can go ahead and get on the web. So it was going to be like this all-in-one set-top box. That in addition to playing games, it was supposed to be the center of your entertainment center. And that the Trip Hawkins behind it, they were already putting in millions of dollars and Electronic Arts was devoting a large percentage of their game development into 3DO titles.</p>

<!--(19:07)-->
<p>That’s why 3DO titles, there’s so many EA games. And then of course you had Samsung, Panasonic, et cetera, all making 3DO consoles. And there was plans that you’re going to buy a TV that had a 3DO built-in. And then eventually everything was going to have 3DO in it. So with that kind of hype, a lot of companies started coming out of the woodwork and say, “We got to get into CD multimedia.” And much like today where you say, “We’re based on the blockchain,” that’s all an investor has to know in order to start dumping money in your company. Despite the fact that you’re going to say, “Well, what we really do is we milk cows, but we’re based on the blockchain.” But it shows you exactly how people who just love buzzwords jump into the market. Well, that’s what happened with the CEO of Art Data.</p>

<h2 id="art-data"><strong>Art Data</strong><!-- 20:00 --></h2>

<p><strong>Becky:</strong><!--(20:00)-->
He was a guy who lived up in Simi Valley, or something like that. He somehow convinced his friends and congregants at a church, and they gave him something like $250,000 or some God awful lot of money to form Art Data. And the first game they did was called Chess Wars, a Medieval fantasy which is essentially a ripoff of Battle Chess, but done very poorly. And then they licensed the game, which became Rise of the Robots, I believe. But then later on, the word got out that the rights to Doom for 3DO were up for grabs. But since ID Software wasn’t really that enthused about the 3DO platform, they just put an insane price. It was like $250,000.</p>

<!--(20:44)-->
<p>Which in that year, $250,000 for the rights to Doom was a lot of money. And the 3DO wasn’t really selling that well. So to sell enough copies to recoup that amount of money, you’d have to either have the best version of Doom ever, or you just simply want Doom in your catalog as a loss leader and are trying to push for other titles. But Randy believed that if he got Doom, he would put his company on the map, and then he was going to have this game with new levels, new maps, new stuff like that.</p>

<p><strong>Adam:</strong><!--(21:19)-->
So Randy raised the money, and Art Data bought the rights to Doom on the 3DO. And Doom at this time was huge. People were dragging their computers to each other’s houses to play Doom multiplayer. It was the birth of LAN parties. And Randy knew a good press opportunity when he saw one, so he started doing interviews.</p>

<p><strong>Becky:</strong><!--(21:37)-->
There are videos and magazine articles of him, mostly in Japanese magazines, of him showing off mock-up screens with new weapons and new monsters and things like that. And then somewhere around April, there’s this video I saw him in April of ‘95 of him holding a CD that says Doom 3DO on it.</p>

<h2 id="the-development-plan"><strong>The Development Plan</strong><!-- 21:56 --></h2>

<p><strong>Adam:</strong><!--(21:56)-->
That Doom that’s on that CD in the photo shoot is what Becky’s going to polish up for release. And she’s been doing this for a while. She’s worked with the Doom code base before, so she immediately knows how she would tackle a port. The trick is to get the game engine simplified so it can run on the lower memory constraints of a console, and then optimizing it to get a good frame rate because resources are more constrained.</p>

<p><strong>Becky:</strong><!--(22:18)-->
I would’ve allocated at least three people and at least six months to maybe nine months to do the actual port. One person writing, there’s nothing but a brand new game engine designed to run a Doom-like game on the 3DO. And the walls would be the perfect 3D walls, because that’s what I did with Wolfenstein. It was perfect 3D. But the floor and ceilings would be sliding textures and stuff like that with some error correction to get it to work somewhat nicely on the 3DO. But then we would actually do some new weapons, new players. We would plan them out because we’d actually have to make an editor, taking the Jaguar levels, planting new objects in them, and probably even making a few more new levels specifically to highlight the new weapons and add some more storyline or something like that.</p>

<!--(23:03)-->
<p>And lastly, I would’ve had to hire a musician to do a kicking soundtrack, because that was something that I really would’ve wanted to do on the 3DO no matter what happened. But it would’ve come out in which the game would’ve been running at 30 frames per second. And with that, we would’ve shipped a pretty decent game, and it probably would’ve sold 20,000 units.</p>

<h2 id="90-complete"><strong>90% Complete</strong><!-- 23:23 --></h2>

<p><strong>Adam:</strong><!--(23:23)-->
Becky assumes the Art Data people are doing something similar to her plan, and she’s pretty excited to help them finish. And also help the 3DO people, because they’ve been pumping up this game as well. So she reaches out to Art Data.</p>

<p><strong>Becky:</strong><!--(23:36)-->
They kept with the story. They said the game was 90% done. They needed me to add in a couple of new weapons and a couple of new maps. So I asked him, “Great, do you have the maps?” He says, “Yes, we do.” “Do you have the new weapons?” “Yes we do.” “Can I have the source code?” “Eventually. Once you sign.” I was like, “But I need to do a code review before I sign.” And they’re like, “Well, it’s 90% done. You don’t need to really do that.” I should have taken that red flag, but I didn’t, because I was excited to bring Doom to the 3DO. And if the game was already 90% complete, then yeah, I could put my credit on there even though I only worked on 10% of it. We negotiated a price for doing the project and then I said, “Okay, let’s get going.”</p>

<p><strong>Adam:</strong><!--(24:23)-->
How much were they going to pay you?</p>

<p><strong>Becky:</strong><!--(24:26)-->
They were going to pay me $10,000 to do the conversion at 90%, just to finish the game. Which is fine, $10,000 to finish a game, that’s reasonable. Well then I then waited, and waited, and waited. And said, “Where is the source code?” So I said, “Oh, okay, I thought you already had it.” It’s like, “No, you’re supposed to give me the game. You say it’s 90% complete.” So they gave me a copy of Doom two on a CD. It was a copy of the game for the PC.</p>

<p><strong>Adam:</strong><!--(24:59)-->
They gave her a retail version of the game for the PC, a CD-ROM. The compiled final version of the game, compiled for a completely different platform with a different architecture, but it’s on a CD and the 3DO has a CD drive.</p>

<p><strong>Becky:</strong><!--(25:14)-->
Said it runs on the PC, so we just say that’s 90% complete. And I’m like, “That’s not how this works.” So I then ask, “Who is the developer that you said flaked on you?” And they gave me radio silence. “Oh, the developer doesn’t want to talk to us. The developer can’t be reached because we owe them money.” “You owe them money? Okay. At least give me the name of the developer so I will speak to them directly.” Chirp, chirp, chirp.</p>

<h2 id="payment-issue"><strong>Payment Issue</strong><!-- 25:43 --></h2>

<p><strong>Adam:</strong><!--(25:43)-->
Okay, so maybe it’s just a payment issue. Not great, but maybe they didn’t pay the developer and so he didn’t hand over the new version of the game that has the new engine that works on the 3DO and the new levels and the new maps and all that. Maybe Becky can talk to them, get them paid, get the game, and start working on that final 10% of optimization and polish. Get the frame rate up and so on. But nope, that wasn’t the case.</p>

<p><strong>Becky:</strong><!--(26:09)-->
An employee at Art Data came to me privately and said, “We don’t have anything. There is no developer, there’s nothing.” At this point I’m in a panic and I then call 3DO. It’s like, “Project canceled. We’re done. We’re not doing this because the tenants of the contract is that 90% complete. Get the source code, finish it. If you want me to do a full port, we’re going to talk something different.”</p>

<p><strong>Adam:</strong><!--(26:32)-->
That doesn’t sound good to 3DO though. They want to pump up this release. They thought Doom could sell some consoles. And now the deadline to get something in stores for Christmas is getting closer. There’s only 10 weeks of development left if the game needs to be handed off to 3DO in time to get in shelves for Christmas. But 3DO and Art Data aren’t the only parties here. Remember, ID Software had licensed the game to Art Data for the 3DO, and they were probably pretty motivated to keep their big check.</p>

<p><strong>Becky:</strong><!--(27:00)-->
So then I contacted ID Software, and after a small discussion with John, he then suggested, “Why don’t we just use the Jaguar version and base it off that?” Says, “Okay.” So he send me a CD with the complete assets of everything for the Jaguar version of Doom, which was perfect. The levels are already made for low memory, the code’s been simplified, networking’s been taken out, all this stuff going on. A lot of the work that I would’ve need to have done has already been done in the Jaguar version. So I then told 3DO, “Okay, let’s go get with Art Data and I’m just going to do a port, and it’s going to cost you $40,000 now.” So at that point, Art Data reluctantly said yes and says, “Great.” “I need to check for 20,000 right now. I’m not starting until I see $20,000.” So I got a check.</p>

<!--(27:47)-->
<p>So okay, let’s go. Started the work. Unfortunately, the CEO of Art Data, who honestly believed that because the game was on a CD and the 3DO has a CD player, that the game will run on the 3DO because it’s a CD. That was his interpretation of 90% complete, because the game already runs. So when I realized that I was working with Einstein here, I decided, okay, just ignore him. I’m going to focus it. Because after working on this for a little bit and having him incessantly ask me for progress on stuff because he wanted to do demos and press tours, and I’m like, “I haven’t even gotten the graphics up for this game on the 3DO yet, and you’re asking me for this crap?”</p>

<h2 id="the-band"><strong>The Band</strong><!-- 28:21 --></h2>

<p><strong>Becky:</strong><!--(28:21)-->
Well, the CEO guy at Art Data was bragging about all those things that he did, and he also bragged he had a band. Oh really? I had a cassette made of all the PC music, just had the PC music, started the game, let the music play into a cassette. Went to another level, did it again, did another level, did it again. I think it was, we gave him six or seven cassettes. Each one had three songs on it or something like that. Because after we record three songs, we give them the tape, another three songs, give them the tape, and so forth. I said, “Okay, take this cassette. It’s got an hour’s worth of music on it. Do covers.” Because once you gave him a tape he was off to the races. And then he went ahead and made these really kicking music tracks, which I then converted to 3DO format and put them in the game. And it gave him a feeling of he’s contributing to Doom, which technically he was, but it got him off my back.</p>

<p><strong>Adam:</strong><!--(29:30)-->
What I picture is that Randy was in a church band at the same church he raised his money at, or maybe he had a old high school band. And he called them up and he put the band to work doing covers of these Doom midi tracks.</p>

<!--(29:55)-->
<p>I’m not sure what actually happened, but one thing’s for sure, the music rocks. It’s probably going to be the best thing about this game. That music, it could be played because the 3DO with its CD format had more space for rich assets. It was easy to include and play high quality music and even videos, which means that if you wanted to make Doom the definitive game for the 3DO, you needed not just rocking music, but you needed live action.</p>

<p><strong>Becky:</strong><!--(30:22)-->
He didn’t even notify me of it, he just did it. What had happened was that I told you about the chess game called Chess Wars. He hired an actual film crew with stunts, everything. So it was expensive. And they filmed all these scenes. Well, he then asked some of the people, says, “Hey, could you also do some scenes for a game based on Doom?” And they’re like, “Cool. Doom. We like Doom.” I understand that the director had an idea for a film in which the scenes would be shot in a way that it would actually tell a cohesive story.</p>

<p><strong>Adam:</strong><!--(31:02)-->
But that didn’t happen, it was all a last minute scramble. But depending on how you feel about full motion video inside of video games, what they ended up with was pretty cool looking.</p>

<h2 id="live-action-doom"><strong>Live Action Doom</strong><!-- 31:13 --></h2>

<p><strong>Becky:</strong><!--(31:13)-->
So a Hollywood costume designer had an ogre outfit for some other event, some other film shoot or whatever it was. So from the neck down it was just literally an ogre, but from the head up, it’s more like an orc from Lord of the Rings. That wasn’t going to do, so they custom made this demon bull head, which is modeled after the Baron of Hell. And the guy says, “Yeah, it would’ve been a $10,000 job had I actually charged him for it.” Now of course this is 1994 dollars. But it was awesome. The head looked great.</p>

<!--(31:51)-->
<p>And then they put that on. The guy who actually designed the costume actually put on the suit and everything. And then they had a couple of people dress up in Marine uniforms. They have a man and a woman dress up as Marines, they have prop guns, and they just did a bunch of poses. And then they took an ice cooler and put a red cross on it to mimic the health pack. They put it there and they just did a bunch of poses in front of her pictures. But then they did a bunch of scenes in which the woman and the guy would say some lines and then the monster would roar in. The monster would hold this guy… Like that.</p>

<p><strong>Adam:</strong><!--(32:28)-->
There was originally a plan for how the scenes would fit together with the game.</p>

<p><strong>Becky:</strong><!--(32:31)-->
The soldier’s going to run off away from his people and then he is going to open a door and then it’s going to be E1M1. And you start the game. And then after you get to the end of the level and you pull the switch, there’s going to be a cut scene of the soldier pulling the switch and then movie, movie, movie. Then it’ll introduce him going to the next level, which of course is reasonable. That’s actually thought out. But to do that you would have to first go through all the levels we had, which he had no knowledge because he didn’t know we switched from the PC levels to the Jaguar levels, which are different levels.</p>

<!--(33:05)-->
<p>And secondly, is that’s a lot of footage. We’re talking about at least maybe 45 minutes to a full hour worth of footage. And on a CD, that’s pushing it on what we can fit with all the music and all the other stuff in there too. Because you got to put the game in there too. It’s doable. It is doable. But the amount of time to actually script, build sets, film, add visual effects, you’re talking at least for about an hour of footage of that type, it’d be about a million dollars. And our data was squawking about 20K.</p>

<p><strong>Adam:</strong><!--(33:44)-->
Of course, Becky was oblivious to all this at the time because she was just heads down trying to get the game port working.</p>

<p><strong>Becky:</strong><!--(33:51)-->
And of course there was a day, I do remember that Randy came by with me with a disc saying, “Here are all the cut scenes.” I’m like, “I can’t use any cut scene.” So I didn’t even take the disc from him. Now I look back and I regret it because those would’ve been great on YouTube right now. I have no idea where that disc is. And I’ve been asking around, it’s been almost 25 years since that. And to this date, I haven’t found anybody who would fess up to having the actual raw footage.</p>

<h2 id="christmas-deadline"><strong>Christmas Deadline</strong><!-- 34:19 --></h2>

<p><strong>Adam:</strong><!--(34:19)-->
Also, there was a deadline, right? Remember this game was supposed to be ready for Christmas. There was PR events and interviews where the game was being shown on a CD. Expectations were high.</p>

<p><strong>Becky:</strong><!--(34:31)-->
But there was only so much I could do without actually rewriting extensive parts of the Doom engine, which was beyond the amount of time. Because 3DO made it very, very clear they needed this game in the stores by Christmas because they wanted to do an ad campaign saying that Doom was on the 3DO. Saying the 3DO is so powerful, it runs Doom.</p>

<p><strong>Adam:</strong><!--(34:52)-->
But here’s the thing, the 3DO has a 12 megahertz processor. It really can’t run the Jaguar version of Doom without extensive work. The Jaguar had three CPUs, two of which ran at 25 megahertz, twice the speed.</p>

<p><strong>Becky:</strong><!--(35:05)-->
So after all this stuff, it turned out I just lived at the office, worked like a dog. Because halfway through the development process I’m like, how in the hell am I going to finish this? Because the game’s going to be buggy, the game’s going to have issues. I already knew the framer, it’s going to be probably laggy. And John’s going to hate my guts over at ID. Because he was still very touchy about the quality of Doom.</p>

<p><strong>Adam:</strong><!--(35:31)-->
But Becky gets Doom up and actually running on the 3DO, and it’s a small miracle, but it only runs at three frames per second. For comparison, the Wolfenstein port she did earlier was running on the same 3DO software at 30 frames per second, 10 times as fast. Three frames per second is totally unplayable. So Becky phones John Carmack, and instead of being unhappy with her, he suggests just making the screen smaller. So now there’s less to draw. That helps. And then with some more optimizing, she gets the frame rate up to 10 frames per second, which is a bit choppy, but playable.</p>

<p><strong>Becky:</strong><!--(36:09)-->
It shows that it was a 10 week port under extreme circumstances. Because while the game plays from beginning to end bug free, which is a miracle in itself, it only runs in a small window because I still had to render some of the walls, like the floor and ceiling still had to render in software. I couldn’t use the hardware blitter because I didn’t have time to make the code changes for that. But it ran, it was Doom. Doom on 3DO. But it had a kicking soundtrack.</p>

<h2 id="the-confrontation"><strong>The Confrontation</strong><!-- 36:39 --></h2>

<p><strong>Adam:</strong><!--(36:39)-->
The problem with working with someone who doesn’t understand the industry is that they don’t understand when you’ve pulled off a miracle. Without the Jaguar version, without Becky working day and night, they wouldn’t have had anything. But Randy didn’t see it that way. He thought building games was a simpler proposition.</p>

<p><strong>Becky:</strong><!--(36:56)-->
“Well, where’s all the new weapons, and where’s the new maps as well? Look at the maps, they’re different.” It’s true, because the maps that were used in the Jaguar version are different from the PC version. “Where’s the new weapons?” Nevermind you have to place the new weapon in spawn points around the map and then also code in the weapon’s usage, what’s firing, and it’s effects. No, no, no, let’s not factor any of that in. All you had to do is draw a JPEG of a new weapon at the bottom of the screen and just put it into the directory of Doom and it automatically gives you the new weapon. Just put the JPEG in, it’s magic. It’s like, didn’t have enough space, didn’t have enough time.</p>

<p><strong>Adam:</strong><!--(37:42)-->
By this point, Becky had enough. She hadn’t handed over the completed game, and so she had him at her mercy. She demanded the rest of the money.</p>

<p><strong>Becky:</strong><!--(37:50)-->
He was mad. Oh gosh, he was mad. But I got the check. And after that gave the disc. And I think we did one revision after that. But then that was the revision that actually went out to the stores and was sold.</p>

<p><strong>Adam:</strong><!--(38:05)-->
Now Becky wasn’t exactly happy with the end result of the game, but the game was bug free and could be played, which left her with one thought.</p>

<p><strong>Becky:</strong><!--(38:14)-->
Mission accomplished. Not necessarily a game I’m going to be proud of as a game, but the very fact that I was able to deliver a title at that kind of insane deadline said I did it. I still got it.</p>

<h2 id="the-business-of-gaming"><strong>The Business of Gaming</strong><!-- 38:28 --></h2>

<p><strong>Adam:</strong><!--(38:28)-->
That’s awesome. You got it out. Did Art Data make their money back do you think?</p>

<p><strong>Becky:</strong><!--(38:32)-->
Oh, hell no. He made the next mistake. After the game was golden mastered, he then went and had 50,000 copies pressed because he thought the game was going to just sell because it’s Doom. It’s the adage of, hey, if you put Harry Potter on a box and put cow poop in it, it’s going to sell. So he thought that. In which, hey, the game is Doom. It plays from start to finish. It is actually a decent version of the game for the 3DO, and it’s got a kicking soundtrack. But Doom was not a game that everybody was going to buy. So he had 50,000 units pressed, which meant that he had to give a check for about $300,000 to 3DO. So he was owing that much money. And then he sold maybe about, I don’t know, 3,000, 4,000 copies.</p>

<p><strong>Adam:</strong><!--(39:23)-->
Oh, wow.</p>

<p><strong>Becky:</strong><!--(39:24)-->
Yeah.</p>

<p><strong>Adam:</strong><!--(39:25)-->
So there’s a warehouse somewhere Indiana Jones style?</p>

<p><strong>Becky:</strong><!--(39:27)-->
Oh, I’m certain there’s a landfill somewhere. But let’s just say that he didn’t do any more 3DO games after that. Art Data folded not that much longer.</p>

<p><strong>Adam:</strong><!--(39:35)-->
Maybe him and his band, they have a practice space, and the walls are just stacked up with all these boxes of the-</p>

<p><strong>Becky:</strong><!--(39:42)-->
Yeah, he could use it to layer a wall with it and use that for the soundproof acoustics.</p>

<h2 id="how-to-learn-low-level-programming"><strong>How to Learn Low Level Programming</strong><!-- 39:54 --></h2>

<p><strong>Adam:</strong><!--(39:54)-->
That’s the story of porting Doom. Doom fans know it as one of the lowest frame rate ports, but it’s playable, and it has a rocking soundtrack. Not bad for a 10 week port. The thing Becky’s story brings to mind for me is that I could never do this. You couldn’t throw me at some new hardware and get me to port a game or anything to run on it. I feel like my development skills just don’t go down that close to the metal. But Becky says it’s a trainable skill.</p>

<p><strong>Becky:</strong><!--(40:24)-->
Yeah. What I would advise a lot of people these days, if you really want to understand computers, first start off with one of the old classic machines. And you could do it with an emulator, but of course you could buy the real thing. Learn how to program an Apple II. Learn how to program an Atari 100 or a Commodore 64, because you have to learn a similar language. You learn the hardware, you learn how it all interacts. It takes away a lot of the magic that’s been given to modern computers. Because modern computers, they think that programming a webpage in JavaScript is programming a computer, that’s the furthest from the truth. Or writing code in Python is writing code directly to the metal. No, it’s an interpreted language. And even when you’re writing code in C++ and so forth, especially the most modern ones with their template bonanzas. When you look at the actual assembly code it generates, you see all the stuff it’s doing for the overhead and go, what the hell?</p>

<!--(41:22)-->
<p>I miss the elegance and simplicity of writing 6502 code. The code, you enter it, it just does one task, leaves. Next function does the same thing. Whereas in C++, you can write code that actually still maintains that paradigm and it works just fine. But it’s so easy if you don’t really know what’s going on to write what you think is three lines of code, this’ll do everything. But when you look at the output of the compiler, it’s a novel. That’s my main takeaway. Is that when you truly understand the instruction sets, how the stack works, how memory management works, how the hardware works, how it all interacts, then you have a true understanding of the limitations of computers.</p>

<p><strong>Adam:</strong><!--(42:08)-->
I think there’s a big divide between the programming that you have done and the people who never leave Java, JVM, or Python, or whatever. I wouldn’t know where to start exactly.</p>

<p><strong>Becky:</strong><!--(42:21)-->
Oh, there are plenty of books out there. One I would recommend highly is a book called Assembly Lines, by Roger Wagner. It’s a great investment. Just look up Roger Wagner, Assembly Lines. It’s a book about maybe 200 pages long, and it is a beginner’s guide to assembly language, programming the Apple II, and all the fundamentals. In fact, in most cases, if you read the book cover to cover, you may not even have to start up an Apple II, you will get a very good fundamental grasp of how a computer operates. And then if what you’ve read intrigues you, then pull up an Apple II emulator or the real thing. You can buy one on eBay, it’s not that expensive, and go to town and see what’s going on.</p>

<!--(43:05)-->
<p>But the end result is not for you to make a brand new Apple II video game. You could if you want, there’s still a market for them. Granted, you’ll sell a couple hundred copies instead of thousands. But what goes on is that you will truly understand how a computer works because there’s very little difference fundamentally from how an Apple II, a 1977 computer versus a modern computer. Yeah, there’s more stuff on it like memory protection, multi CPUs, and protected IO ports. But still fundamentally the same thing. A processor registers a stack, memory IO registers, and a memory map and firmware. Those exist in modern computers. They haven’t changed. So there you go.</p>

<h2 id="outro"><strong>Outro</strong><!-- 44:04 --></h2>

<p><strong>Adam:</strong><!--(44:04)-->
So there you go, that was the show. Learning the Apple II as a path towards bare metal programming sounds fun. If you attempt it, let me know on Twitter or on our Slack channel.</p>

<p>And thank you so much to Becky. You could find her on Twitter @BurgerBecky, and on Twitch as Burger Becky as well.</p>

<p>In an upcoming bonus episode for supporters, she’ll be sharing the porting of another game that I mentioned earlier, Out of this World for the Super Nintendo. And in this case, it’s a totally different story. It’s about a porting going very well under a different type of stress.</p>

<p>And you’ll get to hear some of the background behind this interview, and me chatting with Becky. I’m up to 13 bonus episodes now for supporters, 14 once that one’s out. So I recommend that you check it out. That’s at <a href="https://corecursive.com/supporters">corecursive.com/supporters</a>.</p>

<p>And until next time, enjoy this rocking Doom inspired rock anthems. I couldn’t actually include the real Doom music, because I don’t really know who owns them. But yeah, until next time, thank you so much for listening.</p>

          <form action="https://app.convertkit.com/forms/2082075/subscriptions" method="post" data-sv-form="2082075" data-uid="99a50e1950" data-format="inline" data-version="5" data-options="{&quot;settings&quot;:{&quot;after_subscribe&quot;:{&quot;action&quot;:&quot;message&quot;,&quot;success_message&quot;:&quot;Success! Now check your email to confirm your subscription.&quot;,&quot;redirect_url&quot;:&quot;&quot;},&quot;analytics&quot;:{&quot;google&quot;:null,&quot;facebook&quot;:null,&quot;segment&quot;:null,&quot;pinterest&quot;:null,&quot;sparkloop&quot;:null,&quot;googletagmanager&quot;:null},&quot;modal&quot;:{&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;powered_by&quot;:{&quot;show&quot;:true,&quot;url&quot;:&quot;https://convertkit.com?utm_source=dynamic&amp;utm_medium=referral&amp;utm_campaign=poweredby&amp;utm_content=form&quot;},&quot;recaptcha&quot;:{&quot;enabled&quot;:false},&quot;return_visitor&quot;:{&quot;action&quot;:&quot;show&quot;,&quot;custom_content&quot;:&quot;&quot;},&quot;slide_in&quot;:{&quot;display_in&quot;:&quot;bottom_right&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15},&quot;sticky_bar&quot;:{&quot;display_in&quot;:&quot;top&quot;,&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:5,&quot;devices&quot;:&quot;all&quot;,&quot;show_once_every&quot;:15}},&quot;version&quot;:&quot;5&quot;}" min-width="400 500 600 700 800">
  
  <div data-style="minimal">
    
    <p>
      Hello, <br>I make CoRecursive because I love it when someone shares the details behind some project, some bug, or some incident with me. 
    </p><p>  
      No other podcast was telling stories quite like I wanted to hear.
    </p><p> 
      Right now this is all done by just me and I love doing it, but it's also exhausting. 
    </p><p> 
      Recommending the show to others and contributing to this patreon are the biggest things you can do to help out.
    </p><div><p> 
      Whatever you can do to help, I truly appreciate it!</p><p>
      Thanks! Adam Gordon Bell
    </p></div>
      <p><a href="https://www.patreon.com/adamgordonbell">Support The Podcast</a>
  </p></div>
</form>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Monotype font licencing shake-down (183 pts)]]></title>
            <link>https://www.insanityworks.org/randomtangent/2025/11/14/monotype-font-licencing-shake-down</link>
            <guid>45973261</guid>
            <pubDate>Tue, 18 Nov 2025 22:42:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.insanityworks.org/randomtangent/2025/11/14/monotype-font-licencing-shake-down">https://www.insanityworks.org/randomtangent/2025/11/14/monotype-font-licencing-shake-down</a>, See on <a href="https://news.ycombinator.com/item?id=45973261">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="canvasWrapper">

    		
        

        

          
          
          <div id="top" data-collection-id="519f8468e4b0cab750b86f4c">
            <p>Random tangent (blog)</p>
            <div><p data-rte-preserve-empty="true">​Ameel Khan's personal blog. This is a blog about life, technology, photography, typography, the internet, science, feminism, books, film, music, and whatever other random stuff I come across or happen to be interested in today.</p></div>
          </div>
          

          <div id="folderNav" data-content-field="navigation-foldernav">
  <nav>
    <ul>
    
      
      <li><a href="https://www.insanityworks.org/about-ameel">About Ameel</a></li>
      
  
      
  
    
      
      <li><a href="https://www.insanityworks.org/speaker-bio">Speaker bio</a></li>
      
  
      
  
    
      
      <li><a href="https://www.insanityworks.org/acme">ACME</a></li>
      
  
      
  
    
      
      <li><a href="https://www.insanityworks.org/randomtangent">Random tangent</a></li>
      
  
      
  
    
      
      <li><a href="https://www.insanityworks.org/music">Music</a></li>
      
  
      
  
    
      
      <li><a href="https://www.insanityworks.org/typography">Typography</a></li>
      
  
      
  
    
      
      <li><a href="https://www.insanityworks.org/shahla-zia">Shahla Zia</a></li>
      
  
      
  
    
      
      <li><a href="https://www.insanityworks.org/wedding-song-lyrics">Wedding song lyrics</a></li>
      
  
      
  
    
    </ul>
  </nav>
</div>

          
          <div id="categoryNav">
            <nav>
              <ul>
                <li><a href="https://www.insanityworks.org/randomtangent">All</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Australia">Australia</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Blogging">Blogging</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Books">Books</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Design">Design</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Family">Family</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Feminism">Feminism</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Film">Film</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Internet">Internet</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Life">Life</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=LUMS">LUMS</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Maggie">Maggie</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=MBA">MBA</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Melbourne">Melbourne</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Music">Music</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Nadia">Nadia</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Pakistan">Pakistan</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Photography">Photography</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Science">Science</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Science+Fiction">Science Fiction</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Skepticism">Skepticism</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Society">Society</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Tablet+PC">Tablet PC</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Technology">Technology</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Television">Television</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Typography">Typography</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Watches">Watches</a></li>
              
                <li><a href="https://www.insanityworks.org/randomtangent?category=Writing">Writing</a></li>
              
              </ul>
            </nav>
          </div>
          

        

    		<div id="page" role="main" data-content-field="main-content" data-collection-id="519f8468e4b0cab750b86f4c" data-edit-main-image="Banner">



<article id="article-6916fdb5c7c0f5199592dbaa" data-item-id="6916fdb5c7c0f5199592dbaa">

  <!--SPECIAL CONTENT-->

  


  <!--POST HEADER-->
    
  <header>
    
    
  </header>
    
  <!--POST BODY-->
  

  <div data-layout-label="Post Body" data-type="item" data-updated-on="1763114525040" id="item-6916fdb5c7c0f5199592dbaa"><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-b323b5427732ccabe27a">
  <p>tl;dr Don’t try to shake-down a typography nerd with your dubious, automated claims about his employer using unlicensed fonts.  </p><h2>How it started</h2><p>It started with a LinkedIn <a href="https://www.linkedin.com/help/linkedin/answer/a543895/inmail-overview?lang=en">InMail</a> message (sanitised to protect privacy):  </p><blockquote><p><strong>Subject: [Urgent] Font Software Licensing Review</strong>  </p><p>Hi Ameel</p><p>I hope you’re doing well.</p><p>I’m [NAME] from Monotype and have been trying to reach you at [WORK EMAIL ADDRESS], but I’m unsure if my emails have been received.</p><p>Our team has identified Monotype font software embedded in the websites/apps of [YOUR COMPANY], but we couldn’t locate the corresponding licenses in our database.</p><p>Would you be able to share the correct email address so I can provide more details and documentation? Alternatively, you’re welcome to reach out to me directly at [SENDER’S EMAIL ADDRESS]</p><p>I appreciate your time and look forward to resolving this with you at your earliest convenience.</p><p>Best regards,</p><p>[NAME]</p><p>Business Development Representative | Monotype, Australia</p></blockquote><p>I was puzzled by this for two reasons:  </p><ol data-rte-list="default"><li><p>This person had my correct work email address, but at no point had they sent me an email about this issue or about anything else. I checked. (Starting with a lie? Not a good look.)</p></li><li><p>As far as I knew, my employer didn’t use <em>any</em> Monotype fonts on its websites and apps.  </p></li></ol><h2>Always good to check</h2><p>Just in case there was any merit to this claim, I did a quick review and found that I was right. In Australia we have one corporate website, one retail website, and one retail app (with iOS and Android versions) and all of those use our official font which, for better or for worse, is <a href="https://fonts.google.com/specimen/Open+Sans">Open Sans</a>.</p><p>Now, not only is Open Sans <em>not</em> a Monotype typeface, it is available under the <a href="https://openfontlicense.org/">SIL Open Font License</a> (OFL) meaning we can <a href="https://openfontlicense.org/how-to-use-ofl-fonts/">use this typeface</a> for literally anything except selling the font itself. So that couldn’t be what this person was talking about.  </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1763114406260_127460">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="true" data-src="https://images.squarespace-cdn.com/content/v1/5194d3ffe4b05e9de60d63d8/ecc8a81b-b1f2-4ff9-b84d-29af7bc7e817/OFL+SIL+website.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5194d3ffe4b05e9de60d63d8/ecc8a81b-b1f2-4ff9-b84d-29af7bc7e817/OFL+SIL+website.jpg" data-image-dimensions="1041x860" data-image-focal-point="0.5,0.5" alt="" data-load="false" elementtiming="system-image-block" src="https://images.squarespace-cdn.com/content/v1/5194d3ffe4b05e9de60d63d8/ecc8a81b-b1f2-4ff9-b84d-29af7bc7e817/OFL+SIL+website.jpg" width="1041" height="860" sizes="(max-width: 640px) 100vw, (max-width: 767px) 100vw, 100vw" onload="this.classList.add(&quot;loaded&quot;)" srcset="https://images.squarespace-cdn.com/content/v1/5194d3ffe4b05e9de60d63d8/ecc8a81b-b1f2-4ff9-b84d-29af7bc7e817/OFL+SIL+website.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/5194d3ffe4b05e9de60d63d8/ecc8a81b-b1f2-4ff9-b84d-29af7bc7e817/OFL+SIL+website.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/5194d3ffe4b05e9de60d63d8/ecc8a81b-b1f2-4ff9-b84d-29af7bc7e817/OFL+SIL+website.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/5194d3ffe4b05e9de60d63d8/ecc8a81b-b1f2-4ff9-b84d-29af7bc7e817/OFL+SIL+website.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/5194d3ffe4b05e9de60d63d8/ecc8a81b-b1f2-4ff9-b84d-29af7bc7e817/OFL+SIL+website.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/5194d3ffe4b05e9de60d63d8/ecc8a81b-b1f2-4ff9-b84d-29af7bc7e817/OFL+SIL+website.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/5194d3ffe4b05e9de60d63d8/ecc8a81b-b1f2-4ff9-b84d-29af7bc7e817/OFL+SIL+website.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">

            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p>Screenshot of the SIL Open Font Licence home page. Text below the heading reads, “The widely used, community-approved, free, libre, and open source license specifically designed for fonts and related software: a solid legal framework for worldwide development, sharing, and improvement of fonts and related software in a collaborative manner.”</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1763114406260_128114">
  <p>Next I checked our international retail websites and our project and partnership websites, since all of those have their own branding.   </p><p>I found that on the websites we directly manage, we use these typefaces:</p><ul data-rte-list="default"><li><p><a href="https://fonts.google.com/specimen/Roboto">Roboto</a>, available under the SIL OFL  </p></li><li><p><a href="https://fonts.google.com/specimen/Asap">Asap</a>, available under the SIL OFL</p></li></ul><p>So no issue there.  </p><p>And on the websites our partners manage, we use these typefaces:  </p><ul data-rte-list="default"><li><p><a href="https://fonts.google.com/specimen/Public+Sans">Public Sans</a>, available under the SIL OFL,  </p></li><li><p><a href="https://okinterrupt.website/Network-Sans">Network Sans</a>, a custom font created for the government agency that built the website this is used on so they wouldn’t need a licence, and</p></li><li><p><a href="https://www.marksimonson.com/fonts/view/proxima-nova/">Proxima Nova</a>, the only font that <em>does</em> require a licence, except that Monotype doesn’t sell a licence to it.</p></li></ul><p>So no issue there either.  </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1763114406260_134581">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Promotional graphics displaying the Roboto, Asap, Public Sans, Network Sans, and Proxima Nova typefaces.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1763114406260_134957">
  <p>With those initial checks done, I reached out to our digital team (who build and manage our websites and apps) with a screenshot of the LinkedIn message I’d received and a summary of my investigation. I asked them how they wanted me to reply.  </p><p>I needed to check with these folks first because my team and I only look after the corporate website. My employer’s overall digital presence – including the back-end of the corporate website – is managed by the digital team.  </p><p>Turns out a couple of people from the digital and design teams had received identical messages from this Monotype “Business Development Representative”.  </p><p>A few internal back-and-forth emails later we decided that:  </p><ul data-rte-list="default"><li><p>Instead of all of us responding, only one nominated person from the digital team would respond.  </p></li><li><p>But before responding, the digital team would do their own investigation into the fonts we use and the licences we own so we could verify everything was in compliance.  </p></li></ul><p>Of course that’s not how things actually went down.  </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1763114406260_140635">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Three-panel meme showing Oprah Winfrey pointing at members of her TV talk show audience apparently shouting, at least according to the text captions at the bottom of each panel, “You get a LinkedIn message!”</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1763114406260_141233">
  <h2>Fishing (phishing?) around</h2><p>What the Monotype rep did next is kind of what a malicious hacker does when they’re trying to get someone from your company to click on a link that’ll install malware on your computer. Over the next couple of weeks, the rep messaged a dozen or so more people from different parts of the business, hoping to hook just one person who would reply to the scary message they were sending.</p><p>Now I’d already emailed my design, brand, and digital team colleagues to tell them about this mass-messaging campaign and our plan of action for it, but the Monotype rep expanded their campaign to include people from our procurement team, who I hadn’t thought to forewarn.  </p><p>So not long after, I received a message from one of my procurement team colleagues who’d been forwarded that LinkedIn message from their senior manager with an instruction to deal with this. I explained to my colleague that, as far as I could tell, this Monotype campaign was similar to the <a href="https://www.consumer.vic.gov.au/consumers-and-businesses/scams/small-business-scams/domain-name-scam">domain name scams</a> the procurement team is already familiar with. So please sit tight till our digital team colleagues have completed their audit and then we’ll figure out which one person should start the conversation with Monotype.</p><p>But, like any successful phishing campaign, the Monotype rep’s LinkedIn messages eventually reached someone who did respond. This was another person in the procurement team and, just to be completely clear, I don’t blame them for responding. They were just doing their job of protecting our business from potential copyright liability.  </p><h2>Being forced to deal with the issue  </h2><p>Since I’d handed this over to the digital team, I hadn’t kept track of how things were progressing. I was brought back into the discussion when our brand manager included me in an email thread between her and the procurement person who’d responded to Monotype.  </p><p>I quickly brought this second procurement person up to speed with our earlier plan of action and then I looped in the digital team again. Turns out the digital team had completed their audit, found that we were in compliance, but had gotten busy with other work so no one had responded to Monotype. *sigh*</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1763114406260_163962">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Screenshot from the TV series ‘Star Trek: The Next Generation’ showing the character of Captain Jean-Luc Picard sitting in the captain’s chair with his hand covering his face, typically referred to as a “face palm” gesture.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1763114406260_164539">
  <p>Now, of course, everyone was on the back foot because our new procurement rep had shared the PDF that Monotype had sent, listing all the places where we <em>were </em>using Monotype fonts without a proper licence.  </p><p>And, to quote from the procurement rep’s email:  </p><blockquote><p>Supplier has confirmed two options:</p><p>Past Use License Agreement is used (PULA) to cover the usage for the period without a license if the software is to be removed.</p><p>Process the PULA with a Go Forward license agreement to allow compliant continued use of the fonts in use.</p></blockquote><p>Reading that, I got this procurement rep to quickly convene a meeting with everyone involved, though it turned out the person from the digital team who’d done the font audit had gone on annual leave.</p><p>The rest of the digital team didn’t know anything about font licencing and this was the first time this procurement rep was dealing with font licencing as well. So, partly spurred on by their senior manager’s instruction to deal with this, the procurement rep was seriously considering paying the licencing fee that Monotype had asked for, just to make this whole headache go away.  </p><p>This is where I jumped in and told everyone to hold up. I said I would take the lead on this internally and I would take over the discussion we were having with Monotype as well. The procurement rep, I think somewhat relieved to have this taken out of their hands, agreed.  </p><p>Why did I insist on taking this over? Two reasons: </p><ul data-rte-list="default"><li><p><a href="https://www.insanityworks.org/typography">I’m a bit of a typography nerd</a> so I know what I’m talking about and</p></li><li><p>a quick look at the document Monotype had sent over with the list our alleged copyright infringements had told me that <em>everything</em> the Monotype rep was alleging was wrong.  </p></li></ul>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1763114406260_170534">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Screenshot from the film ‘Star Wars: The Rise of Skywalker’ in which the character Luke Skywalker is saying, “Amazing. Every word of what you just said was wrong.”</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1763114406260_170909">
  <h2>Never send an AI to do a human’s job</h2><p>An April 2025 blog post from Studio Twofold’s Jamie Walker titled ‘<a href="https://studiotwofold.com.au/unlicensed-fonts-hidden-risk-in-branding/">Unlicensed Fonts: The Hidden Risk in your Branding</a>’ opens with:  </p><blockquote><p>Lately, we’ve seen a noticeable uptick in copyright issues related to both images and fonts. Several clients have reached out after receiving emails about fonts [an] agency used on their site years ago.</p><p>Naturally, they’re a bit rattled — and with good reason. These kinds of copyright claims can come with hefty fees if you’re found to be in breach.</p></blockquote><p>Further down Jamie writes:  </p><blockquote><p>Smaller businesses can get caught off guard — and with <a href="https://www.redpoints.com/usecase/copyright-infringement-protection/">AI now scanning the web for even the tiniest copyright infringements</a>, it’s more important than ever to stay protected.</p><p>Think they’re only picking on the small guys? Think again. Even giants have been caught out – proving no one is too big to face the music (or in this case, the typography).</p></blockquote><p>Basically, the reason so many organisations are getting out-of-the-blue copyright claims these days is because major copyright holders have started using automated, AI-powered copyright infringement detection software, of which there is a lot out there. *sigh*</p><p>Monotype seems to have used one of these products too, because the two fonts its report claimed we were using without a valid licence are:  </p><ul data-rte-list="default"><li><p><a href="https://www.myfonts.com/collections/credit-cards-p01-font-monotype-imaging">Credit Cards</a> in our iOS and Android apps and</p></li><li><p><a href="https://www.marksimonson.com/fonts/view/proxima-nova/">Proxima Nova</a> in one of our project websites.  </p></li></ul><p>Let’s take those one at a time, shall we?</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1763114406260_176339">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Screenshot from the film ‘The Princess Bride’ in which the character Inigo Montoya is saying, “Let me explain. No, there is too much. Let me sum up.” </p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1763114406260_176715">
  <h3>What’s in a name?</h3><p>The first thing I did as I read the report was look up the <a href="https://www.myfonts.com/collections/credit-cards-p01-font-monotype-imaging">Credit Cards</a> font on MyFonts.com, Monotype’s online store front.  </p><p>Credit Cards is a pictogram font that contains these icons:  </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1763114406260_181422">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Screenshot from the MyFonts.com website showing the glyphs contained within the Credit Cards font.  </p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1763114406260_181798">
  <p>When I saw that I thought to myself, “Why would we want to use <em>those</em> icons in our apps?”</p><p>Next I read Monotype’s report in detail and saw this screenshot. This is from an analysis of our app’s payload and is the apparent proof that Credit Cards is being used in our smartphone apps:  </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1763114406260_186117">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Screenshot of a table in a PDF file showing a 70 kilobyte size font file with the extension TTF and the filename, “CREDC” followed by three underscore characters.  </p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1763114406260_186606">
  <p>Having worked with a great many font files over the years, when I saw that filename I thought to myself, “Are we sure that’s <em>actually</em> the Credit Cards font that Monotype claims it is?”  </p><p>So I checked. I did a web search for fonts with “credit card” in their name and very quickly found one called ‘<a href="https://www.k-type.com/fonts/credit-card/">Credit Card</a>’ – singular – from K-Type. This is a regular text font (as opposed to an icon font) that looks like the raised text that’s printed on credit cards.  </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1763114406260_189142">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Screenshot from the K-Type website showing the description and sales page of a font named Credit Card. The description starts with, “Credit Card is an all capitals font for simulating bank cards.”</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1763114406260_189619">
  <p>Now <em>that</em> I was something I could see us using in our apps.  </p><p>Happily, Credit Card is free for personal use so I downloaded it and looked at the zip file. And guess what the filename of the font is?  </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1763114406260_192592">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Screenshot of software showing the contents of a zip file. A file among this list is highlighted. Its name is “CREDC” followed by three underscore characters. It has the extension TTF and is approximately 70 kilobytes in size.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1763114406260_192967">
  <p>Yup, the filename is <strong>CREDC___.ttf</strong> – which is <em>exactly</em> the filename that was in the app payload analysis from Monotype.  </p><p>Seeing this, I reached out to my design team contact who then got me in touch with the person who manages our smartphone apps. From them I found out that, sure enough, the only font over and above Open Sans that we use in our smartphone apps is Credit Card by K-Type.  </p><p><strong>SCORE: Ameel 1, Monotype 0</strong></p><h3>Proxima Nova, really?</h3><p>Unlike the Credit Cards font, our use of Mark Simonson’s <a href="https://www.marksimonson.com/fonts/view/proxima-nova/">Proxima Nova</a> was never in contention. We clearly use it in one of our project websites. My employer didn’t actually build that website – we bought this under-construction project from another entity – but this website is very much our responsibility now.  </p><p>The problem for Monotype here was that it no longer sells licences to Proxima Nova. There was a time you could buy a licence to Proxima Nova from Fonts.com, which was Linotype’s online marketplace. But <a href="https://en.wikipedia.org/wiki/Monotype_Imaging">Monotype</a> bought <a href="https://en.wikipedia.org/wiki/Mergenthaler_Linotype_Company">Linotype</a> and eventually killed off Fonts.com and, some time after that (I don’t know when or why), the font’s designer stopped selling licences to Proxima Nova through MyFonts.com.  </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1763114406260_196409">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Screenshot from the MyFonts website showing a page with an error message that reads, “The font is no longer available for purchase”.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1763114406260_196784">
  <p>Of course learning this fact didn’t mean that I was just going to stop my investigation. I reached out to a person, who reached out to a person, who reached out to the design agency that designed (and still maintains) our project website. The design agency contact did their own investigation and quickly confirmed that, yes, they do indeed have a licence to use Proxima Nova on this site – one that they had <a href="https://fonts.adobe.com/fonts/proxima-nova">purchased from Adobe</a> several years ago.  </p><p><strong>SCORE: Ameel 2, Monotype 0</strong></p><h2>Closing the book on this whole affair</h2><p>Armed with this knowledge, I got the procurement person to introduce me to the Monotype rep. The rep and one of their colleagues were very eager to talk, replying to this introductory email within fifteen minutes. They wanted to organise a meeting so they could finally get the font licencing agreement signed. Instead what they got was a long email from me in which I explained the situation in detail, complete with annotated screenshots like the one above :)</p><p>The Monotype rep chewed on this for a few days and then made one final attempt at getting money out of us. They agreed that they were currently unable to sell a licence to Proxima Nova, but it turns out Monotype is one of K-Type’s authorised resellers and [they] “currently cannot see the license on our files for this use” – meaning there wasn’t a record of us purchasing a licence to Credit Card from Monotype. So could we please “confirm if there is one that we for some reason are unable to see in our systems?”.  </p><p>*sigh*</p><p>I wrote back and told them the reason Monotype doesn’t have a record of this licence is because we purchased a one-off Enterprise Licence directly from K-Type several years ago.</p><p>This was several weeks ago and I haven’t heard a peep from them since.  </p><p>¯\_(ツ)_/¯</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1763114406260_199819">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Graphic showing cracked green paint on pavement on top of which white coloured text has been overlaid. The text is a quote from Ben Goldacre that reads, “I think you’ll find it’s a bit more complicated than that”.  </p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1763114406260_200194">
  <h2>Two sides to the story</h2><p>Despite my making light of the situation, I don’t actually hate Monotype for doing this. Using fonts without purchasing a proper license (or purchasing the fonts outright) is stealing and you absolutely should not do it.  </p><p>The fact that font licensing can be a complicated issue is not an excuse; lots of things are complicated and we figure them out.  </p><p>More importantly, I think the type designers and type foundries that create fonts should be fairly compensated for their work. Paying for fonts, or an ongoing licence to those fonts, is how you do that.  </p><p>In short, you should pay for fonts and you should call out people and organisations when they use fonts without a proper licence.</p><p>(For completeness’ sake, I should say that I also don’t mind that Monotype used automated systems to find copyright violations. The internet is so large that it’s impossible to manually find all the people who have stolen your stuff!)   </p><h3>It’s not what you do, it’s how you do it</h3><p>That said, I hate how Monotype’s business development people went about doing this. Much like the blatantly overzealous content blockers on YouTube, the Monotype reps who reached out to us didn’t even bother to verify whether the report their AI spat out at them showed an actual copyright violation or not.  </p><p>I mean, I know why they didn’t double-check. Just like with scammers and <a href="https://en.wikipedia.org/wiki/Phishing">phishers</a>, this is a volume game, not an accuracy or fairness game. You bombard people with messages, scaring them with your (potentially unverified) claims, and eventually some of the thousands of people you’ve messaged will reply. You then rush these folks into paying a licence fee because your targets don’t have enough information about font licencing and, frankly, they just want the problem to go away. This is a shitty way to do business and it reflects poorly on your organisation.  </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1763114406260_201940">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Screenshot from the Nebula.tv website showing a documentary with the title ‘Nebula Sans’. The short description of this documentary reads, “The story of a font built on principle, free to use for anyone who needs it.”</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1763114406260_202315">
  <h3>You’re not making any friends</h3><p>Not that reputation seems to matter too much to popular digital marketplaces – Amazon being the poster child for this. They’re big, they’re arguably <a href="https://en.wikipedia.org/wiki/Enshittification">enshittified</a>, and all they appear to care about is making as much money as possible.  </p><p>I mean there’s a reason why so many type designers urge people not to licence fonts – even their own fonts – from MyFonts and instead buy or licence fonts directly from designer and type foundry websites. And, barring that, buying or licencing fonts from smaller, independent stores like <a href="https://www.fontspring.com/">Fontspring</a> instead.</p><p>This is also why <a href="https://typetype.org/font-subscription/">TypeType</a> and <a href="https://fontstand.com/apps/">Fontstand</a> offer font subscriptions that are alternatives to those from <a href="https://fonts.adobe.com/">Adobe Fonts</a> and Monotype.  </p><p>And this is why, for example, the independent video streaming site <a href="https://nebula.tv/">Nebula</a> was forced to design their custom <a href="https://www.nebulasans.com/">Nebula Sans</a> font. Nebula’s website and streaming apps used to use the Screen Smart version of the <a href="https://www.typography.com/fonts/whitney/styles/screensmart">Whitney</a> font from <a href="https://www.typography.com/">Hoefler&amp;Co</a>. But when Monotype purchased Hoefler&amp;Co, the <a href="https://foundrysupport.monotype.com/hc/en-us/articles/15723177145236-Monotype-Fonts-Royalty-Model">new Monotype licencing/royalty structure</a> meant that a licence to Whitney was suddenly unaffordable to Nebula. Since paying that (apparently much) higher amount to Monotype wasn’t going to be financially sustainable, Nebula instead paid Paul D. Hunt, the original designer of the excellent <a href="https://en.wikipedia.org/wiki/Source_Sans_3">Source Sans</a> font, to modify his font so it would be a drop-in replacement for Whitney in all of Nebula’s digital products. And because Source Sans was released under the SIL Open Font License, Nebula also released Nebula Sans under this OFL.  </p><p>If that’s how much effort folks are willing to make to to avoid using your company, you probably already know that you’re not very well loved.  </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1763114406260_203801">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>Screenshot of a website banner that shows the date range, “November 6 – December 4” and reads, in fancy, bright-pink, all capital letters, “cyber sale” and, “shop now”.</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1763114406260_204191">
  <h2>What do do?</h2><p>So what’s my take-away from all this?  </p><ul data-rte-list="default"><li><p>Don’t use scammy tactics to scare people into purchasing your shit. And if you are going to use those tactics, at least don’t be wrong about it!  </p></li><li><p>If anything like this happens to you or your employer, find the relevant nerd in your friend group or organisation and ask for their help.  </p></li><li><p>If you can, avoid licencing fonts from Monotype. Get your fonts directly from the original designers and type foundries, or maybe from smaller, independent marketplaces like <a href="https://www.fontspring.com/">Fontspring</a> (which has its big annual “cyber sale” on till 4 December, by the way).  </p></li><li><p>If you’d rather avoid the hassle of font licencing altogether, then do what my employer did and pick an excellent, versatile OFL font and use that instead. Though, if you want to stand out from the crowd, please consider avoiding <a href="https://fonts.google.com/?sort=popularity">the most popular fonts on Google Fonts</a>.  </p></li></ul><p>Oh, and while I’m far from an expert on typography, if you need a hand with anything font-related, please reach out. I’d be happy to help in any way that I can :)  </p>
</div></div>

              
  <!--POST FOOTER-->
    
  
    
  
  </article>



<!--PAGINATION-->
  







  
  




</div>

        

        

        
        <div id="details" data-content-field="page-settings">
              <h2>Insanity Works</h2>
              <h3>Nadia &amp; Ameel's online home</h3>
	      <p>This is personal website of <a href="https://www.insanityworks.org/nadia">Nadia Niaz</a> and <a href="https://www.insanityworks.org/ameel">Ameel Zia Khan</a>. Here we document our lives in Melbourne, Australia.&nbsp;</p>
              
              
              <p>Melbourne, Victoria, Australia</p>
          		<figure><a href="https://maps.google.com/maps?q=-37.814107,144.96327999999994" target="_blank" title="View map in new window" data-latitude="-37.814107" data-longitude="144.96327999999994" data-zoom="12"></a></figure>
              
              
              
                


              
            </div>
        

    	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Blender 5.0 (920 pts)]]></title>
            <link>https://www.blender.org/download/releases/5-0/</link>
            <guid>45972519</guid>
            <pubDate>Tue, 18 Nov 2025 21:39:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.blender.org/download/releases/5-0/">https://www.blender.org/download/releases/5-0/</a>, See on <a href="https://news.ycombinator.com/item?id=45972519">Hacker News</a></p>
Couldn't get https://www.blender.org/download/releases/5-0/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub: Git operation failures (375 pts)]]></title>
            <link>https://www.githubstatus.com/incidents/5q7nmlxz30sk</link>
            <guid>45971726</guid>
            <pubDate>Tue, 18 Nov 2025 20:40:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.githubstatus.com/incidents/5q7nmlxz30sk">https://www.githubstatus.com/incidents/5q7nmlxz30sk</a>, See on <a href="https://news.ycombinator.com/item?id=45971726">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <!-- postmortem if it's published -->

      <!-- incident updates in reverse order -->
        <div>
          <h2>
            Resolved
          </h2>
          <div>
            <p><span>This incident has been resolved. Thank you for your patience and understanding as we addressed this issue. A detailed root cause analysis will be shared as soon as it is available.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1763503161000"></span>Nov <var data-var="date">18</var>, <var data-var="year">2025</var> - <var data-var="time">21:59</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Git Operations is operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1763502975000"></span>Nov <var data-var="date">18</var>, <var data-var="year">2025</var> - <var data-var="time">21:56</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We are seeing full recovery after rolling out the fix and all services are operational.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1763502956000"></span>Nov <var data-var="date">18</var>, <var data-var="year">2025</var> - <var data-var="time">21:55</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Codespaces is operating normally.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1763502917000"></span>Nov <var data-var="date">18</var>, <var data-var="year">2025</var> - <var data-var="time">21:55</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We have shipped a fix and are seeing recovery in some areas and will continue to provide updates.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1763501814000"></span>Nov <var data-var="date">18</var>, <var data-var="year">2025</var> - <var data-var="time">21:36</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We have identified the likely cause of the incident and are working on a fix. We will provide another update as we get closer to deploying the fix.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1763501261000"></span>Nov <var data-var="date">18</var>, <var data-var="year">2025</var> - <var data-var="time">21:27</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Codespaces is experiencing degraded availability. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1763501135000"></span>Nov <var data-var="date">18</var>, <var data-var="year">2025</var> - <var data-var="time">21:25</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We are currently investigating failures on all Git operations, including both SSH and HTTP.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1763500295000"></span>Nov <var data-var="date">18</var>, <var data-var="year">2025</var> - <var data-var="time">21:11</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We are seeing failures for some git http operations and are investigating</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1763499157000"></span>Nov <var data-var="date">18</var>, <var data-var="year">2025</var> - <var data-var="time">20:52</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>Git Operations is experiencing degraded availability. We are continuing to investigate.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1763498397000"></span>Nov <var data-var="date">18</var>, <var data-var="year">2025</var> - <var data-var="time">20:39</var> UTC
            </p>
          </div>
        </div>
        <div>
          <h2>
            Investigating
          </h2>
          <div>
            <p><span>We are currently investigating this issue.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1763498386000"></span>Nov <var data-var="date">18</var>, <var data-var="year">2025</var> - <var data-var="time">20:39</var> UTC
            </p>
          </div>
        </div>

      <!-- affected components -->
        <p>
          This incident affected: Git Operations and Codespaces.
        </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oracle is underwater on its $300B OpenAI deal (238 pts)]]></title>
            <link>https://www.ft.com/content/064bbca0-1cb2-45ab-85f4-25fdfc318d89</link>
            <guid>45971601</guid>
            <pubDate>Tue, 18 Nov 2025 20:29:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/064bbca0-1cb2-45ab-85f4-25fdfc318d89">https://www.ft.com/content/064bbca0-1cb2-45ab-85f4-25fdfc318d89</a>, See on <a href="https://news.ycombinator.com/item?id=45971601">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Stay informed with free updates</p><p><span>Simply sign up to the <!-- -->Technology sector<!-- --> myFT Digest -- delivered directly to your inbox.</span></p></div><article id="article-body" data-attribute="article-content-body" data-component="article-content-body"><p>It’s too soon to be talking about the Curse of OpenAI, but we’re going to anyway. </p><p>Since September 10, when Oracle announced a $300bn deal with the chatbot maker, its stock has shed $315bn* in market value:</p><div id="vdhpuacg" data-component="flourish" data-component-id="3451968" data-component-type="flourish-in-article"><figure><a href="#3451968"><picture data-asset-type="flourish" data-flourish-id="3451968" data-flourish-type="story"><div id="3451968" data-o-component="o-message"><p>Some content could not load. Check your internet connection or browser settings.</p></div><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fpublic.flourish.studio%2Fstory%2F3451968%2Fthumbnail%3FcacheBuster%3D979709?source=next-article&amp;fit=scale-down&amp;quality=highest&amp;width=1020&amp;dpr=1" alt=""></picture></a></figure></div><p>OK, yes, it’s a gross simplification to just look at market cap. But equivalents to Oracle shares are little changed over the same period (Nasdaq Composite, Microsoft, Dow Jones US Software Index), so the $60bn loss figure is not entirely wrong. Oracle’s “<a href="https://www.ft.com/content/86895a63-2c5b-4aea-b385-418130b64996" title="" data-trackable="link">astonishing quarter</a>” really has cost it nearly as much as one <a href="https://markets.ft.com/data/equities/tearsheet/summary?s=GM:NYQ" title="" data-trackable="link">General Motors</a>, or two <a href="https://markets.ft.com/data/equities/tearsheet/summary?s=KHC:NSQ" title="" data-trackable="link">Kraft Heinz</a>.</p><p>Investor unease stems from Big Red betting a debt-financed data farm on OpenAI, as <a href="https://www.ft.com/content/583e9391-bdd0-433e-91e0-b1b93038d51e" title="" data-trackable="link">MainFT reported</a> last week. We’ve nothing much to add to that report other than the below charts showing how much Oracle has, in effect, become OpenAI’s US public market proxy: </p><div id="gflyurgq" data-component="flourish" data-component-id="26278964" data-component-type="flourish-in-article"><figure><a href="#26278964"><picture data-asset-type="flourish" data-flourish-id="26278964" data-flourish-type="visualisation"><div id="26278964" data-o-component="o-message"><p>Some content could not load. Check your internet connection or browser settings.</p></div><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fpublic.flourish.studio%2Fvisualisation%2F26278964%2Fthumbnail%3FcacheBuster%3D979709?source=next-article&amp;fit=scale-down&amp;quality=highest&amp;width=1020&amp;dpr=1" alt=""></picture></a></figure></div><p>The theory goes that OpenAI is in a rush to <s>define</s> discover AGI, and Oracle is uniquely able to scale the compute capacity it needs. Oracle promises the lowest upfront costs and fastest path to income generation among the hyperscalers because it’s a data centre tenant rather than the landlord. </p><p>Alternatively, Oracle doesn’t have as much operating profit to burn as its competitors, so is throwing everything it can at supporting its one big customer in exchange for an IOU:</p><div id="eqcyswim" data-component="flourish" data-component-id="26279965" data-component-type="flourish-in-article"><figure><a href="#26279965"><picture data-asset-type="flourish" data-flourish-id="26279965" data-flourish-type="visualisation"><div id="26279965" data-o-component="o-message"><p>Some content could not load. Check your internet connection or browser settings.</p></div><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fpublic.flourish.studio%2Fvisualisation%2F26279965%2Fthumbnail%3FcacheBuster%3D979709?source=next-article&amp;fit=scale-down&amp;quality=highest&amp;width=1020&amp;dpr=1" alt=""></picture></a></figure></div><p>At an analyst day last month in Las Vegas, Oracle said it was aiming for cloud computing revenue of $166bn by 2030:</p><figure id="jajuiqkc" data-component="image-set"><picture><source media="(min-width: 700px)" srcset="https://images.ft.com/v3/image/raw/ftcms%3A73cc4098-a2ec-4934-becb-f20505362b21?source=next-article&amp;fit=scale-down&amp;quality=highest&amp;width=700&amp;dpr=1 1x" width="1156" height="627"><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fd1e00ek4ebabms.cloudfront.net%2Fproduction%2F73cc4098-a2ec-4934-becb-f20505362b21.png?source=next-article&amp;fit=scale-down&amp;quality=highest&amp;width=700&amp;dpr=1" alt="" data-image-type="image" width="1156" height="627" loading="lazy"></picture><figcaption><span></span><span>© Oracle company presentation</span></figcaption></figure><p>To get there, Oracle’s capex budget for the current financial year ending May is $35bn. The consensus has annual capex levelling out at around $80bn a year in 2029, after which revenues continue to ramp:</p><div id="kgdqugeg" data-component="flourish" data-component-id="26283610" data-component-type="flourish-in-article"><figure><a href="#26283610"><picture data-asset-type="flourish" data-flourish-id="26283610" data-flourish-type="visualisation"><div id="26283610" data-o-component="o-message"><p>Some content could not load. Check your internet connection or browser settings.</p></div><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fpublic.flourish.studio%2Fvisualisation%2F26283610%2Fthumbnail%3FcacheBuster%3D979709?source=next-article&amp;fit=scale-down&amp;quality=highest&amp;width=1020&amp;dpr=1" alt=""></picture></a></figure></div><p>And from 2027, the majority of revenue would be coming from OpenAI:</p><div id="xlfqwblu" data-component="flourish" data-component-id="26284410" data-component-type="flourish-in-article"><figure><a href="#26284410"><picture data-asset-type="flourish" data-flourish-id="26284410" data-flourish-type="visualisation"><div id="26284410" data-o-component="o-message"><p>Some content could not load. Check your internet connection or browser settings.</p></div><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fpublic.flourish.studio%2Fvisualisation%2F26284410%2Fthumbnail%3FcacheBuster%3D979709?source=next-article&amp;fit=scale-down&amp;quality=highest&amp;width=1020&amp;dpr=1" alt=""></picture></a></figure></div><p>But Oracle’s net debt is already at 2.5 times ebitda, having more than doubled since 2021, and it’s expected to nearly double again by 2030. Cash flow is forecast to remain negative for five straight years:</p><div id="jzpzfjqz" data-component="flourish" data-component-id="26280511" data-component-type="flourish-in-article"><figure><a href="#26280511"><picture data-asset-type="flourish" data-flourish-id="26280511" data-flourish-type="visualisation"><div id="26280511" data-o-component="o-message"><p>Some content could not load. Check your internet connection or browser settings.</p></div><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fpublic.flourish.studio%2Fvisualisation%2F26280511%2Fthumbnail%3FcacheBuster%3D979709?source=next-article&amp;fit=scale-down&amp;quality=highest&amp;width=1020&amp;dpr=1" alt=""></picture></a></figure></div><p>So while the OpenAI agreement has been more than written off the equity, the risk of unfunded expansion remains and the cost of hedging Oracle debt is at a three-year high. </p><div id="vyysibme" data-component="flourish" data-component-id="26292276" data-component-type="flourish-in-article"><figure><a href="#26292276"><picture data-asset-type="flourish" data-flourish-id="26292276" data-flourish-type="visualisation"><div id="26292276" data-o-component="o-message"><p>Some content could not load. Check your internet connection or browser settings.</p></div><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fpublic.flourish.studio%2Fvisualisation%2F26292276%2Fthumbnail%3FcacheBuster%3D979709?source=next-article&amp;fit=scale-down&amp;quality=highest&amp;width=1020&amp;dpr=1" alt=""></picture></a></figure></div><p>We need to add the usual warnings: Credit-default-swap <a href="https://www.ft.com/content/e5f64cf4-7f63-4455-96bb-e7132e0e8a32" title="" data-trackable="link">liquidity isn’t great</a>; the increased demand for Oracle CDS comes after <a href="https://www.datacenterdynamics.com/en/news/oracle-takes-on-18bn-in-debt-ahead-of-ai-data-center-build-out/" title="" data-trackable="link">$18bn of bond sales in September</a>; a CDS premium in the low 100 basis points isn’t <em>that</em> exciting; and some firms <a href="https://www.reuters.com/business/finance/weinsteins-saba-sells-credit-derivatives-big-tech-as-ai-risks-grow-source-says-2025-11-17/" title="" data-trackable="link">taking the other side of the trade</a> are no mugs. Still, pointy.</p><p>Beyond the charts, a broader question relates to whether an OpenAI deal is still worth announcing. </p><p>A few months ago, any kind of agreement with OpenAI could make a share price go up. OpenAI did very nicely out of its power to reflect glory, most notably in October when it <a href="https://www.ft.com/content/bfafd06e-0a92-4add-9ae5-622e3c2c8f29" title="" data-trackable="link">took AMD warrants</a> as part of a chip deal that bumped share price by 24 per cent.</p><p>But Oracle is not the only laggard. <a href="https://openai.com/index/openai-and-broadcom-announce-strategic-collaboration/" title="" data-trackable="link">Broadcom</a> and <a href="https://www.ft.com/content/74d79365-efdc-4446-b0ed-d53ad4b55f59" title="" data-trackable="link">Amazon</a> are both down following OpenAI deal news, while Nvidia’s barely changed since its <a href="https://www.ft.com/content/d3caeac1-def8-45ae-b56b-e34c7c435ccc" title="" data-trackable="link">investment agreement</a> in September. Without a share price lift, what’s the point? A combined trillion dollars of AI capex might look like commitment, but investment fashions are fickle.</p><p><em>* Calculation and graph updated at 11am GMT for shares outstanding, and text tweaked at 2pm GMT to reflect a less clickbait headline</em></p><p><strong>Further reading:<br></strong>— <a href="https://www.ft.com/content/86895a63-2c5b-4aea-b385-418130b64996" title="" data-trackable="link">Oracle’s astonishing jam-tomorrow OpenAI trade</a> (FTAV)</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New EU Chat Control proposal moves forward (134 pts)]]></title>
            <link>https://techreport.com/news/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor/</link>
            <guid>45970663</guid>
            <pubDate>Tue, 18 Nov 2025 19:16:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techreport.com/news/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor/">https://techreport.com/news/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor/</a>, See on <a href="https://news.ycombinator.com/item?id=45970663">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
<div>
<p><strong>Key Takeaways: </strong></p>







<ul>
<li><strong>The EU has introduced a new Chat Control proposal: </strong>Mandatory scanning is gone, but Article 4’s ‘risk mitigation’ clause could still push services toward scanning private and encrypted messages.</li>



<li><strong>Anonymity could be severely limited: </strong>Age-verification rules would make anonymous accounts difficult, affecting journalists, whistleblowers, and users who rely on privacy for safety. </li>



<li><strong>The scope of scanning is expanding: </strong>The proposal allows detection of chat text and metadata, raising concerns about large-scale monitoring across the EU’s 450M citizens.</li>



<li><strong>The technology behind it still isn’t viable: </strong>Experts say safe CSAM detection in encrypted apps doesn’t exist yet, even Apple abandoned its own client-side scanning system after backlash.</li>
</ul>
</div>



<figure><picture fetchpriority="high" decoding="async">
<source type="image/webp" data-lazy-srcset="https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor-1200x675.jpg.webp 1200w, https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor-300x169.jpg.webp 300w, https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor-150x84.jpg.webp 150w, https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor-768x432.jpg.webp 768w, https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor-1536x864.jpg.webp 1536w, https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor-777x437.jpg.webp 777w, https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor.jpg.webp 1920w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%20675'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1200px) 100vw, 1200px">
<img fetchpriority="high" decoding="async" width="1200" height="675" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%20675'%3E%3C/svg%3E" alt="New EU Chat Control Proposal Moves Forward – Privacy Experts See a Dangerous Backdoor." data-lazy-srcset="https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor-1200x675.jpg 1200w, https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor-300x169.jpg 300w, https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor-150x84.jpg 150w, https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor-768x432.jpg 768w, https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor-1536x864.jpg 1536w, https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor-777x437.jpg 777w, https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor.jpg 1920w" data-lazy-sizes="(max-width: 1200px) 100vw, 1200px" data-lazy-src="https://techreport.com/wp-content/uploads/2025/11/new-eu-chat-control-proposal-privacy-experts-see-dangerous-backdoor-1200x675.jpg?_t=1763287191">
</picture>
</figure>



<p>The Chat Control proposal is back in Brussels. Again.&nbsp;</p>



<p>Lawmakers are treating it like a familiar guest who keeps showing up at the door wearing a slightly different jacket. Privacy experts say the jacket is hiding something sharp.&nbsp;</p>



<p>A revised version of the <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=COM%3A2022%3A209%3AFIN" target="_blank" rel="noreferrer noopener dofollow">EU’s Child Sexual Abuse Regulation (CSAR)</a> has now moved from the Law Enforcement Working Party to the Coreper (Committee of Permanent Representatives). </p>



<p>Coreper is the group of permanent representatives from all EU member states, if Coreper likes the text, the Council will adopt its position. After that, the proposal jumps straight into a fast trilogue.</p>



<p>On paper, the new version looks softer.&nbsp;Mandatory scanning of private chats, photos, and URLs was removed. Scanning is now voluntary. Lawmakers seem happy. They might even feel relieved.&nbsp;</p>



<p>Privacy experts, however, are staring at one line in Article 4 like it’s a hidden knife taped under the table. </p>



<p>Let’s break down what actually changed, what didn’t, and why critics say this version may be even worse than the old one.&nbsp;</p>



<h2>The ‘Voluntary’ Scanning That Doesn’t Feel Very Voluntary</h2>



<p>The <a href="https://cdn.netzpolitik.org/wp-upload/2025/11/2025-10-30_Council_Presidency_CSAR_Policy-debate_14032.pdf" target="_blank" rel="noreferrer noopener dofollow">Denmark Presidency produced the new compromise</a> after negotiations stalled for over three years.&nbsp;</p>



<p>When the Law Enforcement Working Party <a href="https://www.consilium.europa.eu/de/meetings/mpo/2025/11/law-enforcement-wp-lewp-police-%28361206%29/" target="_blank" rel="noreferrer noopener dofollow">met on November 12</a>, the group accepted it with broad support.&nbsp;</p>



<p>No dissenting votes. No further changes needed. A rare moment of harmony inside the EU Council meeting room. </p>



<p><strong><em>The key change is the removal of mandatory scanning. Messaging apps will not be forced to scan shared pictures, videos, or URLs. Providers like WhatsApp, Signal, Telegram, and email services can choose to scan for CSAM material.&nbsp;</em></strong></p>



<p>It sounds like the pressure is gone. </p>



<p>But then Article 4 happens. It includes something vague, flexible, and extremely powerful. It’s called a ‘risk mitigation measure.’&nbsp;High-risk services may need to apply ‘all appropriate risk mitigation measures.’ The phrase feels harmless until you imagine how governments could interpret it. </p>



<figure><picture decoding="async">
<source type="image/webp" data-lazy-srcset="https://techreport.com/wp-content/uploads/2025/11/article-4-extract-from-the-new-chat-control-proposal.png.webp 1184w, https://techreport.com/wp-content/uploads/2025/11/article-4-extract-from-the-new-chat-control-proposal-300x74.png.webp 300w, https://techreport.com/wp-content/uploads/2025/11/article-4-extract-from-the-new-chat-control-proposal-150x37.png.webp 150w, https://techreport.com/wp-content/uploads/2025/11/article-4-extract-from-the-new-chat-control-proposal-768x191.png.webp 768w, https://techreport.com/wp-content/uploads/2025/11/article-4-extract-from-the-new-chat-control-proposal-777x193.png.webp 777w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201184%20294'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1184px) 100vw, 1184px">
<img decoding="async" width="1184" height="294" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201184%20294'%3E%3C/svg%3E" alt="article 4 extract from the new chat control proposal." data-lazy-srcset="https://techreport.com/wp-content/uploads/2025/11/article-4-extract-from-the-new-chat-control-proposal.png 1184w, https://techreport.com/wp-content/uploads/2025/11/article-4-extract-from-the-new-chat-control-proposal-300x74.png 300w, https://techreport.com/wp-content/uploads/2025/11/article-4-extract-from-the-new-chat-control-proposal-150x37.png 150w, https://techreport.com/wp-content/uploads/2025/11/article-4-extract-from-the-new-chat-control-proposal-768x191.png 768w, https://techreport.com/wp-content/uploads/2025/11/article-4-extract-from-the-new-chat-control-proposal-777x193.png 777w" data-lazy-sizes="(max-width: 1184px) 100vw, 1184px" data-lazy-src="https://techreport.com/wp-content/uploads/2025/11/article-4-extract-from-the-new-chat-control-proposal.png?_t=1763291102">
</picture>
<figcaption>Source: <a href="https://cdn.netzpolitik.org/wp-upload/2025/11/2025-11-06_Council_Presidency_LEWP_CSA-R_Presidency-compromise-texts_14092.pdf" target="_blank" rel="noreferrer noopener dofollow">Proposal for a Regulation of the European Parliament and of the Council</a> </figcaption></figure>



<p><a href="https://techreport.com/news/business/germany-reaffirms-opposition-to-eu-chat-control-privacy-debate/" target="_blank" rel="noreferrer noopener dofollow">Germany has publicly reaffirmed opposition</a> to a version of the proposal that mandates scanning of encrypted chats. Whether it will maintain that firm stance throughout the negotiations remains uncertain. </p>



<p>Patrick Breyer, digital rights jurist and longtime critic of Chat Control, says this line reintroduces mandatory scanning through the back door. His argument is simple.&nbsp;</p>



<p>If a service is labeled ‘high-risk,’ it might be obliged to scan everything anyway. Even private, end-to-end encrypted content. </p>



<figure><picture decoding="async">
<source type="image/webp" data-lazy-srcset="https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X-1058x1024.png.webp 1058w, https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X-300x290.png.webp 300w, https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X-150x145.png.webp 150w, https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X-768x743.png.webp 768w, https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X-20x20.png.webp 20w, https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X-777x752.png.webp 777w, https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X.png.webp 1184w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201058%201024'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1058px) 100vw, 1058px">
<img decoding="async" width="1058" height="1024" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201058%201024'%3E%3C/svg%3E" alt="Patrick Breyer post on X." data-lazy-srcset="https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X-1058x1024.png 1058w, https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X-300x290.png 300w, https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X-150x145.png 150w, https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X-768x743.png 768w, https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X-20x20.png 20w, https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X-777x752.png 777w, https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X.png 1184w" data-lazy-sizes="(max-width: 1058px) 100vw, 1058px" data-lazy-src="https://techreport.com/wp-content/uploads/2025/11/Patrick-Breyer-post-on-X-1058x1024.png?_t=1763290432">
</picture>
</figure>



<p>Breyer says this could make client-side scanning mandatory. That is when your phone or laptop scans your messages before encryption kicks in. It essentially turns your device into a small police assistant.&nbsp;</p>



<p>You never asked for that. It’s like buying headphones and discovering they also whisper everything you say back to a security office.&nbsp;</p>



<h2>Encryption Isn’t Just a Tech Feature – It’s How Modern Life Works</h2>



<p>The biggest concern is the effect on end-to-end encryption. This is the shield that protects private communication on WhatsApp, Signal, and other messengers. </p>



<p>It’s the same shield used by journalists, doctors, activists, lawyers, and everyone who occasionally sends a photo of their passport to a friend for a hotel booking.</p>



<figure><picture decoding="async">
<source type="image/webp" data-lazy-srcset="https://techreport.com/wp-content/uploads/2025/11/How-does-end-to-end-encryption-work.png.webp 1024w, https://techreport.com/wp-content/uploads/2025/11/How-does-end-to-end-encryption-work-300x157.png.webp 300w, https://techreport.com/wp-content/uploads/2025/11/How-does-end-to-end-encryption-work-150x79.png.webp 150w, https://techreport.com/wp-content/uploads/2025/11/How-does-end-to-end-encryption-work-768x402.png.webp 768w, https://techreport.com/wp-content/uploads/2025/11/How-does-end-to-end-encryption-work-777x407.png.webp 777w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20536'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px">
<img decoding="async" width="1024" height="536" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20536'%3E%3C/svg%3E" alt="How does end-to-end encryption work" data-lazy-srcset="https://techreport.com/wp-content/uploads/2025/11/How-does-end-to-end-encryption-work.png 1024w, https://techreport.com/wp-content/uploads/2025/11/How-does-end-to-end-encryption-work-300x157.png 300w, https://techreport.com/wp-content/uploads/2025/11/How-does-end-to-end-encryption-work-150x79.png 150w, https://techreport.com/wp-content/uploads/2025/11/How-does-end-to-end-encryption-work-768x402.png 768w, https://techreport.com/wp-content/uploads/2025/11/How-does-end-to-end-encryption-work-777x407.png 777w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://techreport.com/wp-content/uploads/2025/11/How-does-end-to-end-encryption-work.png">
</picture>
</figure>



<p>Breaking encryption has always been the red line. No government has found a safe way to weaken encryption for criminals without also weakening it for everyone else.&nbsp;</p>



<p>It’s like removing the doors from all apartments in a building because one person is suspected of wrongdoing.&nbsp;</p>



<p>Everyone becomes vulnerable, and burglars get a Black Friday sale they didn’t expect.</p>



<p>The new compromise avoids saying ‘break encryption.’ It uses vague language. However, privacy specialists argue that the outcome remains the same.&nbsp;</p>



<p>If scanning becomes a mandatory risk mitigation measure, encrypted platforms will need to scan content before encryption is applied. That collapses the entire security model.&nbsp;</p>



<h2>Anonymous Communication May Also Be on the Line </h2>



<p>The <a href="https://fightchatcontrol.eu/" target="_blank" rel="noreferrer noopener dofollow">Fight Chat Control group</a> published a summary of the new text. They highlight another major change. Anonymous communication becomes nearly impossible. </p>



<figure><picture decoding="async">
<source type="image/webp" data-lazy-srcset="https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-initiative-extract.png.webp 992w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-initiative-extract-300x226.png.webp 300w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-initiative-extract-150x113.png.webp 150w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-initiative-extract-768x579.png.webp 768w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-initiative-extract-777x586.png.webp 777w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20992%20748'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 992px) 100vw, 992px">
<img decoding="async" width="992" height="748" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20992%20748'%3E%3C/svg%3E" alt="fight chat control initiative extract." data-lazy-srcset="https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-initiative-extract.png 992w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-initiative-extract-300x226.png 300w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-initiative-extract-150x113.png 150w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-initiative-extract-768x579.png 768w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-initiative-extract-777x586.png 777w" data-lazy-sizes="(max-width: 992px) 100vw, 992px" data-lazy-src="https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-initiative-extract.png?_t=1763290134">
</picture>
<figcaption>Source: <a href="https://fightchatcontrol.eu/" target="_blank" rel="noreferrer noopener dofollow">fightchatcontrol.eu</a></figcaption></figure>



<p>The proposal requires every user to verify their age before accessing communication services. This eliminates the option to create anonymous accounts.&nbsp;</p>



<p>That affects whistleblowers and journalists. It affects people escaping abusive households. It affects people living under repressive governments who rely on anonymity for safety. </p>



<p><strong><em>Requiring age verification for every single user is like asking everyone to show their passport before entering a grocery store. It may solve one problem. It creates many more.</em></strong></p>



<p>Article 6 also includes restrictions that critics call a ‘digital house arrest’ for minors. It bans children from installing many apps associated with grooming risk. The list includes WhatsApp, Instagram, and even online games like Roblox.&nbsp;</p>



<p>Imagine a 15-year-old today without messaging apps or online games. They would end up communicating solely through school assignments and fridge magnets.&nbsp;</p>



<h2>Why This Version Worries Experts Even More</h2>



<p>The original proposal already concerned privacy advocates. It focused on scanning photos, videos, and URLs for CSAM content.</p>



<p>The new version goes further. Breyer notes it includes scanning of private chat text and metadata. Metadata can reveal who you talk to, how often, and from where you talk to them.&nbsp;</p>



<p>It turns the communication graph of the entire EU population into a map available for inspection.</p>



<p>This shift from media scanning to text scanning is a significant development. It expands what authorities can request. It expands the scope of what companies must monitor to avoid being labeled ‘high-risk.’ And it expands the potential for abuse.</p>



<p>Critics also point out that voluntary scanning does not guarantee privacy.&nbsp;</p>



<p>If one major app decides to comply, others may feel pressure to follow. Competition might turn into a race where the winner is the one who scans the most.&nbsp;</p>



<h2>A Political Win, A Technical Minefield</h2>



<p>Politically, lawmakers are celebrating. After years of deadlock, they finally have a text that appears less aggressive. Removing mandatory scanning looks like a concession.&nbsp;</p>



<p>It’s easy to present this as a victory for privacy.&nbsp;&nbsp;</p>



<p><strong><em>Technically, the situation is far from reassuring. The proposal now relies heavily on interpretation. The phrase ‘all appropriate risk mitigation measures’ could mean anything.&nbsp;</em></strong></p>



<p>It gives enormous discretion to authorities. It lets governments later argue that scanning is essential for safety.&nbsp;</p>



<p>That is why privacy groups call this version a political trick. It removes the scary parts from the front of the bill. Then it grows them back under a different name.&nbsp;</p>



<h2>The EU Parliament Will Have Its Say – But History Is Complicated&nbsp;</h2>



<p>The next step is Coreper. If they approve the text on November 19 or soon after, the Council will adopt its official position.&nbsp;</p>



<p>Then a trilogue begins between the Council, the Commission, and the European Parliament.&nbsp;</p>



<figure><picture decoding="async">
<source type="image/webp" data-lazy-srcset="https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-extract-whats-next.png.webp 958w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-extract-whats-next-300x119.png.webp 300w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-extract-whats-next-150x59.png.webp 150w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-extract-whats-next-768x305.png.webp 768w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-extract-whats-next-777x308.png.webp 777w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20958%20380'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 958px) 100vw, 958px">
<img decoding="async" width="958" height="380" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20958%20380'%3E%3C/svg%3E" alt="fight chat control extract what's next." data-lazy-srcset="https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-extract-whats-next.png 958w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-extract-whats-next-300x119.png 300w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-extract-whats-next-150x59.png 150w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-extract-whats-next-768x305.png 768w, https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-extract-whats-next-777x308.png 777w" data-lazy-sizes="(max-width: 958px) 100vw, 958px" data-lazy-src="https://techreport.com/wp-content/uploads/2025/11/fight-chat-control-extract-whats-next.png?_t=1763290638">
</picture>
<figcaption>Source: <a href="https://fightchatcontrol.eu/" target="_blank" rel="dofollow">fightchatcontrol.eu</a></figcaption></figure>



<p>In theory, Parliament could oppose it.&nbsp;</p>



<p>In practice, Parliament has often compromised on surveillance laws after political pressure. Privacy groups fear a rushed trilogue where Parliament gives in to urgency.</p>



<p>The Council and the Commission are now aligned. Both want stronger online monitoring. This alignment alone makes many observers nervous.&nbsp;</p>



<h2>The Bigger Story: Europe Keeps Trying to Build Scanning Systems That Don’t Exist&nbsp;</h2>



<p>There is a broader theme here. The EU continues to propose scanning systems that experts say cannot operate safely.&nbsp;</p>



<p>The automatic detection of CSAM in encrypted environments remains technically unsolved. Client-side scanning has accuracy issues, privacy concerns, and a potential for misuse.&nbsp;</p>



<p>Even <a href="https://edition.cnn.com/2022/12/08/tech/apple-csam-tool" target="_blank" rel="noreferrer noopener dofollow">Apple backed away</a> from its own client-side scanning feature after heavy criticism from researchers.&nbsp;</p>



<p>The EU is once again attempting to regulate technology that does not yet exist in a safe form. It is similar to writing a law that requires cars to fly by next summer.&nbsp;</p>



<p>The idea might be noble. The engineering reality is not ready.&nbsp;</p>



<p>Governments want a system that detects serious crimes. Researchers seek a system that malicious actors cannot exploit. Companies want a system that doesn’t destroy trust.&nbsp;</p>



<p>So far, no system satisfies all three.&nbsp;</p>



<h2>The Real Test Is About to Begin</h2>



<p>The next few days will decide how far the EU is willing to push this plan.&nbsp;</p>



<p>Coreper will review the text, and if nobody objects, the Council will lock in its position fast. Privacy groups and security experts are raising alarms again because the new compromise still creates a path to mass scanning, even if the language looks softer.&nbsp;</p>



<p>The proposal also threatens anonymity and introduces new monitoring routes that could reshape private communication for 450M people in the EU.&nbsp;</p>



<p>Lawmakers call it progress. Experts call it a warning sign.&nbsp;</p>



<p>Everything now depends on how Article 4 is interpreted and how much power it quietly hands over. The final battle will happen in trilogue, and the tech community is already bracing for impact.&nbsp;</p>

                        <div>
    <div>
            <picture>
<source type="image/webp" srcset="https://techreport.com/wp-content/uploads/2024/11/anya-zhukova-techreport-journalist-1-286x300.jpeg.webp?_t=1730785811">
<img src="https://techreport.com/wp-content/uploads/2024/11/anya-zhukova-techreport-journalist-1-286x300.jpeg?_t=1730785811" alt="Anya Zhukova">
</picture>

        </div>

    <p>
        Anya Zhukova is an in-house tech and crypto writer at Techreport with 10 years of hands-on experience covering cybersecurity, consumer tech, digital privacy, and blockchain. She’s known for turning complex topics into clear, useful advice that regular people can actually understand and use.&nbsp; Her work has been featured in top-tier digital publications including <a href="https://www.makeuseof.com/author/anyazhukova/" rel="noopener"><i>MakeUseOf</i></a>, <a href="https://www.online-tech-tips.com/author/azhukova/" rel="noopener"><i>Online Tech Tips</i></a>, <a href="https://helpdeskgeek.com/author/azhukova/" rel="noopener"><i>Help Desk Geek</i></a>, <a href="https://www.switchingtomac.com/author/azhukova/" rel="noopener"><i>Switching to Mac</i></a>, and <a href="https://www.maketecheasier.com/author/anyazhukova/" rel="noopener"><i>Make Tech Easier</i></a>.
Whether she’s writing about the latest privacy tools or reviewing a new laptop, her goal is always the same: help readers feel confident and in control of the tech they use every day.&nbsp; Anya holds a BA in English Philology and Translation from Tula State Pedagogical University and also studied Mass Media and Journalism at Minnesota State University, Mankato. That mix of language, media, and tech has given her a unique lens to look at how technology shapes our daily lives.&nbsp; Over the years, she’s also taken courses and done research in data privacy, digital security, and ethical writing – skills she uses when tackling sensitive topics like PC hardware, system vulnerabilities, and crypto security.&nbsp; Anya worked directly with brands like <i>Framework</i>, <i>Insta360</i>, <i>Redmagic</i>, <i>Inmotion</i>, <i>Secretlab</i>, <i>Kodak</i>, and <i>Anker</i>, reviewing their products in real-life scenarios.
Her testing process involves real-world use cases – whether it's stress-testing laptops for creative workloads, reviewing the battery performance of mobile gaming phones, or evaluating the long-term ergonomics of furniture designed for hybrid workspaces.&nbsp; In the world of crypto, Anya covers everything from beginner guides to deep dives into hardware wallets, DeFi protocols, and Web3 tools. She helps readers understand how to use multisig wallets, keep their assets safe, and choose the right platforms for their needs.&nbsp; Her writing often touches on financial freedom and privacy – two things she strongly believes should be in everyone’s hands.
Outside of writing, Anya contributes to editorial style guides focused on privacy and inclusivity, and she mentors newer tech writers on how to build subject matter expertise and write responsibly.&nbsp;
She sticks to high editorial standards, only recommends products she’s personally tested, and always aims to give readers the full picture.&nbsp; You can find her on <a href="https://www.linkedin.com/in/anyazhukova/" rel="noopener">LinkedIn</a>, where she shares more about her work and projects.&nbsp;
<b>Key Areas of Expertise:</b> Consumer Tech (laptops, phones, wearables, etc.) Cybersecurity and Digital Privacy PC/PC Hardware Blockchain, Crypto Wallets, and DeFi In-Depth Product Reviews and Buying Guides Whether she’s reviewing a new wallet or benchmarking a PC build, Anya brings curiosity, care, and a strong sense of responsibility to everything she writes. Her mission? To make the digital world a little easier – and safer – for everyone.&nbsp;
    </p>
    <a href="https://techreport.com/author/anyaz/">
        View all articles by Anya Zhukova
        <svg width="8" height="13" viewBox="0 0 8 13" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M1.5 11.9297L6.5 6.92969L1.5 1.92969" stroke="#080C2D" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path>
        </svg>
    </a>
</div>
                
        <div>
      
      <p>The Tech Report&nbsp;editorial policy&nbsp;is centered on providing helpful, accurate content that offers real value to our readers. We only work with experienced writers who have specific knowledge in the topics they cover, including latest developments in technology, software, hardware, and more. Our editorial policy ensures that each topic is researched and curated by our in-house editors. We maintain rigorous journalistic standards, and every article is 100% written by&nbsp;real authors.</p>
  </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trying out Gemini 3 Pro with audio transcription and a new pelican benchmark (169 pts)]]></title>
            <link>https://simonwillison.net/2025/Nov/18/gemini-3/</link>
            <guid>45970519</guid>
            <pubDate>Tue, 18 Nov 2025 19:05:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2025/Nov/18/gemini-3/">https://simonwillison.net/2025/Nov/18/gemini-3/</a>, See on <a href="https://news.ycombinator.com/item?id=45970519">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-permalink-context="/2025/Nov/18/gemini-3/">

<p>18th November 2025</p>



<p>Google released Gemini 3 Pro today. Here’s <a href="https://blog.google/products/gemini/gemini-3/">the announcement from Sundar Pichai, Demis Hassabis, and Koray Kavukcuoglu</a>, their <a href="https://blog.google/technology/developers/gemini-3-developers/">developer blog announcement from Logan Kilpatrick</a>, the <a href="https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf">Gemini 3 Pro Model Card</a>, and their <a href="https://blog.google/products/gemini/gemini-3-collection/">collection of 11 more articles</a>. It’s a big release!</p>
<p>I had a few days of preview access to this model via <a href="https://aistudio.google.com/">AI Studio</a>. The best way to describe it is that it’s <strong>Gemini 2.5 upgraded to match the leading rival models</strong>.</p>
<p>Gemini 3 has the same underlying characteristics as Gemini 2.5. The knowledge cutoff is the same (January 2025). It accepts 1 million input tokens, can output up to 64,000 tokens, and has multimodal inputs across text, images, audio, and video.</p>
<h4 id="benchmarks">Benchmarks</h4>
<p>Google’s own reported numbers (in <a href="https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf">the model card</a>) show it scoring slightly higher against Claude 4.5 Sonnet and GPT-5.1 against most of the standard benchmarks. As always I’m waiting for independent confirmation, but I have no reason to believe those numbers are inaccurate.</p>
<p><img src="https://static.simonwillison.net/static/2025/gemini-3-benchmarks.jpg" alt="Table of benchmark numbers, described in full below"></p>
<h4 id="pricing">Pricing</h4>
<p>It terms of pricing it’s a little more expensive than Gemini 2.5 but still cheaper than Claude Sonnet 4.5. Here’s how it fits in with those other leading models:</p>
<center><table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Input (per 1M tokens)</th>
      <th>Output (per 1M tokens)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>GPT-5.1</td>
      <td>$1.25</td>
      <td>$10.00</td>
    </tr>
    <tr>
      <td>Gemini 2.5 Pro</td>
      <td>
        ≤ 200k tokens: $1.25<br>
        &gt; 200k tokens: $2.50
      </td>
      <td>
        ≤ 200k tokens: $10.00<br>
        &gt; 200k tokens: $15.00
      </td>
    </tr>
    <tr>
      <td><strong>Gemini 3 Pro</strong></td>
      <td>
        ≤ 200k tokens: $2.00<br>
        &gt; 200k tokens: $4.00
      </td>
      <td>
        ≤ 200k tokens: $12.00<br>
        &gt; 200k tokens: $18.00
      </td>
    </tr>
    <tr>
      <td>Claude Sonnet 4.5</td>
      <td>
        ≤ 200k tokens: $3.00<br>
        &gt; 200k tokens: $6.00
      </td>
      <td>
        ≤ 200k tokens: $15.00<br>
        &gt; 200k tokens: $22.50
      </td>
    </tr>
    <tr>
      <td>Claude Opus 4.1</td>
      <td>$15.00</td>
      <td>$75.00</td>
    </tr>
  </tbody>
</table></center>
<h4 id="trying-it-out-against-a-complex-image">Trying it out against a complex image</h4>
<p>That screenshot of the benchmarks from above looked like a good test for Gemini 3’s multimodal support. I fed it that image URL and asked it to generate alt text for the image:</p>
<blockquote>
<p><code>llm -m gemini-3-pro-preview -a https://static.simonwillison.net/static/2025/gemini-3-benchmarks.jpg 'Alt text for this image, include all figures and make them comprehensible to a screen reader user'</code></p>
</blockquote>
<p>Here’s what I got back:</p>
<blockquote>
<p>A comprehensive table comparing four AI models across various performance benchmarks. The columns listed are: Benchmark Name, Description, Gemini 3 Pro (highlighted in blue), Gemini 2.5 Pro, Claude Sonnet 4.5, and GPT-5.1.</p>
<p><strong>Humanity’s Last Exam (Academic reasoning)</strong></p>
<ul>
<li>No tools: Gemini 3 Pro 37.5%, Gemini 2.5 Pro 21.6%, Claude Sonnet 4.5 13.7%, GPT-5.1 26.5%.</li>
<li>With search and code execution: Gemini 3 Pro 45.8% (others have no data).</li>
</ul>
<p><strong>ARC-AGI-2 (Visual reasoning puzzles; ARC Prize Verified)</strong></p>
<ul>
<li>Gemini 3 Pro 31.1%, Gemini 2.5 Pro 4.9%, Claude Sonnet 4.5 13.6%, GPT-5.1 17.6%.</li>
</ul>
<p><strong>GPQA Diamond (Scientific knowledge; No tools)</strong></p>
<ul>
<li>Gemini 3 Pro 91.9%, Gemini 2.5 Pro 86.4%, Claude Sonnet 4.5 83.4%, GPT-5.1 88.1%.</li>
</ul>
<p><strong>AIME 2025 (Mathematics)</strong></p>
<ul>
<li>No tools: Gemini 3 Pro 95.0%, Gemini 2.5 Pro 88.0%, Claude Sonnet 4.5 87.0%, GPT-5.1 94.0%.</li>
<li>With code execution: Gemini 3 Pro 100%, Claude Sonnet 4.5 100%.</li>
</ul>
<p><strong>MathArena Apex (Challenging Math Contest problems)</strong></p>
<ul>
<li>Gemini 3 Pro 23.4%, Gemini 2.5 Pro 0.5%, Claude Sonnet 4.5 1.6%, GPT-5.1 1.0%.</li>
</ul>
<p><strong>MMMU-Pro (Multimodal understanding and reasoning)</strong></p>
<ul>
<li>Gemini 3 Pro 81.0%, Gemini 2.5 Pro 68.0%, Claude Sonnet 4.5 68.0%, GPT-5.1 76.0%.</li>
</ul>
<p><strong>ScreenSpot-Pro (Screen understanding)</strong></p>
<ul>
<li>Gemini 3 Pro 72.7%, Gemini 2.5 Pro 11.4%, Claude Sonnet 4.5 36.2%, GPT-5.1 3.5%.</li>
</ul>
<p><strong>CharXiv Reasoning (Information synthesis from complex charts)</strong></p>
<ul>
<li>Gemini 3 Pro 81.4%, Gemini 2.5 Pro 69.6%, Claude Sonnet 4.5 68.5%, GPT-5.1 69.5%.</li>
</ul>
<p><strong>OmniDocBench 1.5 (OCR; Overall Edit Distance, lower is better)</strong></p>
<ul>
<li>Gemini 3 Pro 0.115, Gemini 2.5 Pro 0.145, Claude Sonnet 4.5 0.145, GPT-5.1 0.147.</li>
</ul>
<p><strong>Video-MMMU (Knowledge acquisition from videos)</strong></p>
<ul>
<li>Gemini 3 Pro 87.6%, Gemini 2.5 Pro 83.6%, Claude Sonnet 4.5 77.8%, GPT-5.1 80.4%.</li>
</ul>
<p><strong>LiveCodeBench Pro (Competitive coding problems; Elo Rating, higher is better)</strong></p>
<ul>
<li>Gemini 3 Pro 2,439; Gemini 2.5 Pro 1,775; Claude Sonnet 4.5 1,418; GPT-5.1 2,243.</li>
</ul>
<p><strong>Terminal-Bench 2.0 (Agentic terminal coding; Terminus-2 agent)</strong></p>
<ul>
<li>Gemini 3 Pro 54.2%, Gemini 2.5 Pro 32.6%, Claude Sonnet 4.5 42.8%, GPT-5.1 47.6%.</li>
</ul>
<p><strong>SWE-Bench Verified (Agentic coding; Single attempt)</strong></p>
<ul>
<li>Gemini 3 Pro 76.2%, Gemini 2.5 Pro 59.6%, Claude Sonnet 4.5 77.2%, GPT-5.1 76.3%.</li>
</ul>
<p><strong>t2-bench (Agentic tool use)</strong></p>
<ul>
<li>Gemini 3 Pro 85.4%, Gemini 2.5 Pro 54.9%, Claude Sonnet 4.5 84.7%, GPT-5.1 80.2%.</li>
</ul>
<p><strong>Vending-Bench 2 (Long-horizon agentic tasks; Net worth (mean), higher is better)</strong></p>
<ul>
<li>Gemini 3 Pro $5,478.16; Gemini 2.5 Pro $573.64; Claude Sonnet 4.5 $3,838.74; GPT-5.1 $1,473.43.</li>
</ul>
<p><strong>FACTS Benchmark Suite (Held out internal grounding, parametric, MM, and search retrieval benchmarks)</strong></p>
<ul>
<li>Gemini 3 Pro 70.5%, Gemini 2.5 Pro 63.4%, Claude Sonnet 4.5 50.4%, GPT-5.1 50.8%.</li>
</ul>
<p><strong>SimpleQA Verified (Parametric knowledge)</strong></p>
<ul>
<li>Gemini 3 Pro 72.1%, Gemini 2.5 Pro 54.5%, Claude Sonnet 4.5 29.3%, GPT-5.1 34.9%.</li>
</ul>
<p><strong>MMMLU (Multilingual Q&amp;A)</strong></p>
<ul>
<li>Gemini 3 Pro 91.8%, Gemini 2.5 Pro 89.5%, Claude Sonnet 4.5 89.1%, GPT-5.1 91.0%.</li>
</ul>
<p><strong>Global PIQA (Commonsense reasoning across 100 Languages and Cultures)</strong></p>
<ul>
<li>Gemini 3 Pro 93.4%, Gemini 2.5 Pro 91.5%, Claude Sonnet 4.5 90.1%, GPT-5.1 90.9%.</li>
</ul>
<p><strong>MRCR v2 (8-needle) (Long context performance)</strong></p>
<ul>
<li>128k (average): Gemini 3 Pro 77.0%, Gemini 2.5 Pro 58.0%, Claude Sonnet 4.5 47.1%, GPT-5.1 61.6%.</li>
<li>1M (pointwise): Gemini 3 Pro 26.3%, Gemini 2.5 Pro 16.4%, Claude Sonnet 4.5 (not supported), GPT-5.1 (not supported).</li>
</ul>
</blockquote>
<p>I have not checked every line of this but a loose spot-check looks accurate to me.</p>
<p>That prompt took 1,105 input and 3,901 output tokens, at a cost of <a href="https://www.llm-prices.com/#it=1105&amp;cit=3901&amp;ot=3901&amp;ic=2&amp;oc=12&amp;sel=gemini-3-pro-preview">5.6824 cents</a>.</p>
<p>I ran this follow-up prompt:</p>
<blockquote>
<p><code>llm -c 'Convert to JSON'</code></p>
</blockquote>
<p>You can see <a href="https://gist.github.com/simonw/ea7d52706557528e7eb3912cdf9250b0#response-1">the full output here</a>, which starts like this:</p>
<div><pre>{
  <span>"metadata"</span>: {
    <span>"columns"</span>: [
      <span><span>"</span>Benchmark<span>"</span></span>,
      <span><span>"</span>Description<span>"</span></span>,
      <span><span>"</span>Gemini 3 Pro<span>"</span></span>,
      <span><span>"</span>Gemini 2.5 Pro<span>"</span></span>,
      <span><span>"</span>Claude Sonnet 4.5<span>"</span></span>,
      <span><span>"</span>GPT-5.1<span>"</span></span>
    ]
  },
  <span>"benchmarks"</span>: [
    {
      <span>"name"</span>: <span><span>"</span>Humanity's Last Exam<span>"</span></span>,
      <span>"description"</span>: <span><span>"</span>Academic reasoning<span>"</span></span>,
      <span>"sub_results"</span>: [
        {
          <span>"condition"</span>: <span><span>"</span>No tools<span>"</span></span>,
          <span>"gemini_3_pro"</span>: <span><span>"</span>37.5%<span>"</span></span>,
          <span>"gemini_2_5_pro"</span>: <span><span>"</span>21.6%<span>"</span></span>,
          <span>"claude_sonnet_4_5"</span>: <span><span>"</span>13.7%<span>"</span></span>,
          <span>"gpt_5_1"</span>: <span><span>"</span>26.5%<span>"</span></span>
        },
        {
          <span>"condition"</span>: <span><span>"</span>With search and code execution<span>"</span></span>,
          <span>"gemini_3_pro"</span>: <span><span>"</span>45.8%<span>"</span></span>,
          <span>"gemini_2_5_pro"</span>: <span>null</span>,
          <span>"claude_sonnet_4_5"</span>: <span>null</span>,
          <span>"gpt_5_1"</span>: <span>null</span>
        }
      ]
    },</pre></div>
<h4 id="analyzing-a-city-council-meeting">Analyzing a city council meeting</h4>
<p>To try it out against an audio file I extracted the 3h33m of audio from the video <a href="https://www.youtube.com/watch?v=qgJ7x7R6gy0">Half Moon Bay City Council Meeting—November 4, 2025</a>. I used <code>yt-dlp</code> to get that audio:</p>
<div><pre>yt-dlp -x --audio-format m4a <span><span>'</span>https://www.youtube.com/watch?v=qgJ7x7R6gy0<span>'</span></span></pre></div>
<p>That gave me a 74M m4a file, which I ran through Gemini 3 Pro like this:</p>
<blockquote>
<p><code>llm -m gemini-3-pro-preview -a /tmp/HMBCC\ 11⧸4⧸25\ -\ Half\ Moon\ Bay\ City\ Council\ Meeting\ -\ November\ 4,\ 2025\ \[qgJ7x7R6gy0\].m4a 'Output a Markdown transcript of this meeting. Include speaker names and timestamps. Start with an outline of the key meeting sections, each with a title and summary and timestamp and list of participating names. Note in bold if anyone raised their voices, interrupted each other or had disagreements. Then follow with the full transcript.'</code></p>
</blockquote>
<p>That failed with an “Internal error encountered” message, so I shrunk the file down to a more manageable 38MB using <code>ffmpeg</code>:</p>
<div><pre>ffmpeg -i <span><span>"</span>/private/tmp/HMB.m4a<span>"</span></span> -ac 1 -ar 22050 -c:a aac -b:a 24k <span><span>"</span>/private/tmp/HMB_compressed.m4a<span>"</span></span></pre></div>
<p>Then ran it again like this (for some reason I had to use <code>--attachment-type</code> this time):</p>
<blockquote>
<p><code>llm -m gemini-3-pro-preview --attachment-type /tmp/HMB_compressed.m4a 'audio/aac' 'Output a Markdown transcript of this meeting. Include speaker names and timestamps. Start with an outline of the key meeting sections, each with a title and summary and timestamp and list of participating names. Note in bold if anyone raised their voices, interrupted each other or had disagreements. Then follow with the full transcript.'</code></p>
</blockquote>
<p>This time it worked! The <a href="https://gist.github.com/simonw/0b7bc23adb6698f376aebfd700943314">full output is here</a>, but it starts like this:</p>
<blockquote>
<p>Here is the transcript of the Half Moon Bay City Council meeting.</p>
<h4>Meeting Outline</h4>
<p><strong>1. Call to Order, Updates, and Public Forum</strong></p>
<ul>
<li>
<strong>Summary:</strong> Mayor Brownstone calls the meeting to order. City Manager Chidester reports no reportable actions from the closed session. Announcements are made regarding food insecurity volunteers and the Diwali celebration. During the public forum, Councilmember Penrose (speaking as a citizen) warns against autocracy. Citizens speak regarding lease agreements, downtown maintenance, local music events, and homelessness outreach statistics.</li>
<li>
<strong>Timestamp:</strong> 00:00:00—00:13:25</li>
<li>
<strong>Participants:</strong> Mayor Brownstone, Matthew Chidester, Irma Acosta, Deborah Penrose, Jennifer Moore, Sandy Vella, Joaquin Jimenez, Anita Rees.</li>
</ul>
<p><strong>2. Consent Calendar</strong></p>
<ul>
<li>
<strong>Summary:</strong> The Council approves minutes from previous meetings and a resolution authorizing a licensing agreement for Seahorse Ranch. Councilmember Johnson corrects a pull request regarding abstentions on minutes.</li>
<li>
<strong>Timestamp:</strong> 00:13:25—00:15:15</li>
<li>
<strong>Participants:</strong> Mayor Brownstone, Councilmember Johnson, Councilmember Penrose, Vice Mayor Ruddick, Councilmember Nagengast.</li>
</ul>
<p><strong>3. Ordinance Introduction: Commercial Vitality (Item 9A)</strong></p>
<ul>
<li>
<strong>Summary:</strong> Staff presents a new ordinance to address neglected and empty commercial storefronts, establishing maintenance and display standards. Councilmembers discuss enforcement mechanisms, window cleanliness standards, and the need for objective guidance documents to avoid subjective enforcement.</li>
<li>
<strong>Timestamp:</strong> 00:15:15—00:30:45</li>
<li>
<strong>Participants:</strong> Karen Decker, Councilmember Johnson, Councilmember Nagengast, Vice Mayor Ruddick, Councilmember Penrose.</li>
</ul>
<p><strong>4. Ordinance Introduction: Building Standards &amp; Electrification (Item 9B)</strong></p>
<ul>
<li>
<strong>Summary:</strong> Staff introduces updates to the 2025 Building Code. A major change involves repealing the city’s all-electric building requirement due to the 9th Circuit Court ruling (<em>California Restaurant Association v. City of Berkeley</em>). <strong>Public speaker Mike Ferreira expresses strong frustration and disagreement with “unelected state agencies” forcing the City to change its ordinances.</strong>
</li>
<li>
<strong>Timestamp:</strong> 00:30:45—00:45:00</li>
<li>
<strong>Participants:</strong> Ben Corrales, Keith Weiner, Joaquin Jimenez, Jeremy Levine, Mike Ferreira, Councilmember Penrose, Vice Mayor Ruddick.</li>
</ul>
<p><strong>5. Housing Element Update &amp; Adoption (Item 9C)</strong></p>
<ul>
<li>
<strong>Summary:</strong> Staff presents the 5th draft of the Housing Element, noting State HCD requirements to modify ADU allocations and place a measure on the ballot regarding the “Measure D” growth cap. <strong>There is significant disagreement from Councilmembers Ruddick and Penrose regarding the State’s requirement to hold a ballot measure.</strong> Public speakers debate the enforceability of Measure D. <strong>Mike Ferreira interrupts the vibe to voice strong distaste for HCD’s interference in local law.</strong> The Council votes to adopt the element but strikes the language committing to a ballot measure.</li>
<li>
<strong>Timestamp:</strong> 00:45:00—01:05:00</li>
<li>
<strong>Participants:</strong> Leslie (Staff), Joaquin Jimenez, Jeremy Levine, Mike Ferreira, Councilmember Penrose, Vice Mayor Ruddick, Councilmember Johnson.</li>
</ul>
<hr>
<h4>Transcript</h4>
<p><strong>Mayor Brownstone</strong> [00:00:00]
Good evening everybody and welcome to the November 4th Half Moon Bay City Council meeting. As a reminder, we have Spanish interpretation services available in person and on Zoom.</p>
<p><strong>Victor Hernandez (Interpreter)</strong> [00:00:35]
Thank you, Mr. Mayor, City Council, all city staff, members of the public. <em>[Spanish instructions provided regarding accessing the interpretation channel on Zoom and in the room.]</em> Thank you very much.</p>
</blockquote>
<p>Those first two lines of the transcript already illustrate something interesting here: Gemini 3 Pro chose NOT to include the exact text of the Spanish instructions, instead summarizing them as “[Spanish instructions provided regarding accessing the interpretation channel on Zoom and in the room.]”.</p>
<p>I haven’t spot-checked the entire 3hr33m meeting, but I’ve confirmed that the timestamps do not line up. The transcript closes like this:</p>
<blockquote>
<p><strong>Mayor Brownstone</strong> [01:04:00]
Meeting adjourned. Have a good evening.</p>
</blockquote>
<p>That actually happens <a href="https://www.youtube.com/watch?v=qgJ7x7R6gy0&amp;t=3h31m5s">at 3h31m5s</a> and the mayor says:</p>
<blockquote>
<p>Okay. Well, thanks everybody, members of the public for participating. Thank you for staff. Thank you to fellow council members. This meeting is now adjourned. Have a good evening.</p>
</blockquote>
<p>I’m disappointed about the timestamps, since mismatches there make it much harder to jump to the right point and confirm that the summarized transcript is an accurate representation of what was said.</p>
<p>This took 320,087 input tokens and 7,870 output tokens, for a total cost of <a href="https://www.llm-prices.com/#it=320087&amp;ot=7870&amp;ic=4&amp;oc=18">$1.42</a>.</p>
<h4 id="and-a-new-pelican-benchmark">And a new pelican benchmark</h4>
<p>Gemini 3 Pro has a new concept of a “thinking level” which can be set to low or high (and defaults to high). I tried my classic <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">Generate an SVG of a pelican riding a bicycle</a> prompt at both levels.</p>
<p>Here’s low—Gemini decided to add a jaunty little hat (with a comment <a href="https://gist.github.com/simonw/70d56ba39b7cbb44985d2384004fc4a0#response">in the SVG</a> that says <code>&lt;!-- Hat (Optional Fun Detail) --&gt;</code>):</p>
<p><img src="https://static.simonwillison.net/static/2025/gemini-3-pelican-low.png" alt="The pelican is wearing a blue hat. It has a good beak. The bicycle is a little bit incorrect but generally a good effort."></p>
<p>And here’s high. This is genuinely an excellent pelican, and the bicycle frame is at least the correct shape:</p>
<p><img src="https://static.simonwillison.net/static/2025/gemini-3-pelican-high.png" alt="The pelican is not wearing a hat. It has a good beak. The bicycle is accurate and well-drawn."></p>
<p>Honestly though, my pelican benchmark is beginning to feel a little bit too basic. I decided to upgrade it. Here’s v2 of the benchmark, which I plan to use going forward:</p>
<blockquote>
<p><code>Generate an SVG of a California brown pelican riding a bicycle. The bicycle must have spokes and a correctly shaped bicycle frame. The pelican must have its characteristic large pouch, and there should be a clear indication of feathers. The pelican must be clearly pedaling the bicycle. The image should show the full breeding plumage of the California brown pelican.</code></p>
</blockquote>
<p>For reference, here’s a photo I took of a California brown pelican recently (sadly without a bicycle):</p>
<p><img src="https://static.simonwillison.net/static/2025/breeding-plumage.jpg" alt="A glorious California brown pelican perched on a rock by the water. It has a yellow tint to its head and a red spot near its throat."></p>
<p>Here’s Gemini 3 Pro’s <a href="https://gist.github.com/simonw/2b9930ae1ce6f3f5e9cfe3cb31ec0c0a">attempt</a> at high thinking level for that new prompt:</p>
<p><img src="https://static.simonwillison.net/static/2025/gemini-3-breeding-pelican-high.png" alt="It's clearly a pelican. It has all of the requested features. It looks a bit abstract though."></p>
<p>And for good measure, here’s that same prompt <a href="https://gist.github.com/simonw/7a655ebe42f3d428d2ea5363dad8067c">against GPT-5.1</a>—which produced this dumpy little fellow:</p>
<p><img src="https://static.simonwillison.net/static/2025/gpt-5-1-breeding-pelican.png" alt="The pelican is very round. Its body overlaps much of the bicycle. It has a lot of dorky charisma."></p>
<p>And Claude Sonnet 4.5, which <a href="https://gist.github.com/simonw/3296af92e4328dd4740385e6a4a2ac35">didn’t do quite as well</a>:</p>
<p><img src="https://static.simonwillison.net/static/2025/claude-sonnet-4-5-breeding-pelican.png" alt="Oh dear. It has all of the requested components, but the bicycle is a bit wrong and the pelican is arranged in a very awkward shape."></p>
<p>None of the models seem to have caught on to the crucial detail that the California brown pelican is not, in fact, brown.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OrthoRoute – GPU-accelerated autorouting for KiCad (197 pts)]]></title>
            <link>https://bbenchoff.github.io/pages/OrthoRoute.html</link>
            <guid>45970391</guid>
            <pubDate>Tue, 18 Nov 2025 18:54:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bbenchoff.github.io/pages/OrthoRoute.html">https://bbenchoff.github.io/pages/OrthoRoute.html</a>, See on <a href="https://news.ycombinator.com/item?id=45970391">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        



<h4 id="this-document-is-a-complement-to-the-readme-in-the-github-repository-the-readme-provides-information-about-performance-capabilities-and-tests-this-document-reflects-more-on-the-why-and-how-orthoroute-was-developed">This document is a complement to the README in <a href="https://github.com/bbenchoff/OrthoRoute">the Github repository</a>. The README provides information about performance, capabilities, and tests. This document reflects more on the why and how OrthoRoute was developed.</h4>



<h2 id="why-i-built-this">Why I Built This</h2>

<p>This is a project born out of necessity. Another thing I was working on needed an <em>enormous</em> backplane. A PCB with sixteen connectors, with 1,100 pins on each connector. That’s 17,600 individual pads, and 8,192 airwires that need to be routed. Here, just take a look:</p>

<p><img src="https://bbenchoff.github.io/images/ConnM/unroutedbackplane.png" alt="a view of the backplane, before routing the PCB"></p>

<p>Look at that shit. Hand routing this would take months. For a laugh, I tried <a href="https://freerouting.org/">FreeRouting</a>, the KiCad autorouter plugin, and it routed 4% of the traces in seven hours. If that trend held, which it wouldn’t, that would be a month of autorouting. And it probably wouldn’t work in the end. I had a few options, all of which would take far too long</p>

<ul>
  <li>I could route the board by hand. This would be painful and take months, but I would get a good-looking board at the end.</li>
  <li>I could YOLO everything and just let the FreeRouting autorouter handle it. It would take weeks, because the first traces are easy, the last traces take the longest. This would result in an ugly board.</li>
  <li>I could spend a month or two building my own autorouter plugin for KiCad. I have a fairly powerful GPU and <em>I thought</em> routing a PCB is a very parallel problem. I could also implement my own routing algorithms to make the finished product look good.</li>
</ul>

<p>When confronted with a task that will take months, always choose the more interesting path.</p>

<h2 id="a-new-kicad-api-and-a-traditional-autorouter">A New KiCad API, and a ‘Traditional’ Autorouter</h2>

<p>KiCad, Pre-version 9.0, had a SWIG-based plugin system. There are serious deficits with this system compared to the new IPC plugin system released with KiCad 9. The SWIG-based system was locked to the Python environment bundled with KiCad. Process isolation, threading, and performance constraints were a problem. Doing GPU programming with CuPy or PyTorch, while not impossible, is difficult.</p>

<p>The new IPC plugin system for KiCad is a godsend. The basic structure of the OrthoRoute plugin looks something like this:</p>

<p><img src="https://bbenchoff.github.io/images/ConnM/OrthorouteArch.png" alt="Orthoroute architecture"></p>

<p>The OrthoRoute plugin communicates with KiCad via the IPC API over a UNIX-ey socket. This API is basically a bunch of C++ classes that gives me access to board data – nets, pads, copper pour geometry, airwires, and everything else. This allows me to build a second model of a PCB inside a Python script and model it however I want. With a second model of a board inside <em>my</em> plugin, all I have to do is draw the rest of the owl.</p>

<h2 id="development-of-the-manhattan-routing-engine">Development of the Manhattan Routing Engine</h2>

<p>After wrapping my head around the the ability to <em>read</em> and <em>write</em> board information to and from KiCad, I had to figure out a way to route this stupidly complex backplane. A non-orthogonal autorouter is a good starting point, but I simply used that as an exercise to wrap my head around the KiCad IPC API. The real build is a ‘Manhattan Orthogonal Routing Engine’, the tool needed to route my mess of a backplane.</p>

<h3 id="project-pathfinder">Project PathFinder</h3>

<p>The algorithm used for this autorouter is <a href="https://dl.acm.org/doi/10.1145/201310.201328">PathFinder: a negotiation-based performance-driven router for FPGAs</a>. My implementation of PathFinder treats the PCB as a graph: nodes are intersections on an x–y grid where vias can go, and edges are the segments between intersections where copper traces can run. Each edge and node is treated as a shared resource.</p>

<p>PathFinder is iterative. In the first iteration, all nets (airwires) are routed <em>greedily</em>, without accounting for overuse of nodes or edges. Subsequent iterations account for congestion, increasing the “cost” of overused edges and ripping up the worst offenders to re-route them. Over time, the algorithm <em>converges</em> to a PCB layout where no edge or node is over-subscribed by multiple nets.</p>

<p>With this architecture – the PathFinder algorithm on a very large graph, within the same order of magnitude of the largest FPGAs – it makes sense to run the algorithm with GPU acceleration. There are a few factors that went into this decision:</p>

<ol>
  <li>Everyone who’s routing giant backplanes probably has a gaming PC. Or you can rent a GPU from whatever company is advertising on MUNI bus stops this month.</li>
  <li>The PathFinder algorithm requires hundreds of billions of calculations for every iteration, making single-core CPU computation glacially slow.</li>
  <li>With CUDA, I can implement a SSSP (parallel Dijkstra) to find a path through a weighted graph very fast.</li>
</ol>

<h3 id="adapting-fpga-algorithms-to-pcbs">Adapting FPGA Algorithms to PCBs</h3>

<p>The original PathFinder paper was, <em>“A Negotiation-Based Performance-Driven Router for FPGAs”</em> and from 1995, this meant early FPGAs like the Xilinx 3000 series and others manufactured by Tryptych. These devices were simple, and to get a good idea of how they worked, <a href="https://www.righto.com/2020/09/reverse-engineering-first-fpga-chip.html">check out Ken Shirriff’s blog</a>. Here’s what the inside of a Xilinx XC2064 looks like:</p>

<p><img src="https://bbenchoff.github.io/images/ConnM/FPGALayout.png" alt="How FPGAs are laid out"></p>

<p>That looks complicated, but it’s really exceptionally simple. All the LUTs, or logic elements, are connected to each other with wires. Where the wires cross over, there are fuzes. Burn the fuzes and you’ve connected the wires together. It’s a <em>simple</em> graph and all the complexity of the actual paths inside the chip are abstracted away. For a circuit board, I don’t have this luxury. I have to figure out how to get the signal from the pads on the top layer of the PCB and ‘drill down’ with vias into the grid. I need to come up with some way to account for both the edges of the graph and nodes of the graph, something that’s untread territory with the PathFinder algorithm.</p>

<p>The first step of that is the <a href="https://github.com/bbenchoff/OrthoRoute/blob/main/orthoroute/algorithms/manhattan/pad_escape_planner.py">pad escape planner</a> that pre-computes the escape routing of all the pads. Because the entire Manhattan Routing Engine is designed for a backplane, we can make some assumptions: All of the components are going to be SMD, because THT parts would kill the efficiency of a routing lattice. The components are going to be arranged on a grid, and just to be nice I’d like some ‘randomization’ in where it puts the vias punching down into the grid. Here’s what the escape planning looks like:</p>

<p><img src="https://bbenchoff.github.io/images/ConnM/EscapePlanning.png" alt="The escape path planning for individual pads"></p>

<h3 id="how-pathfinder-almost-killed-me-and-how-i-made-pathfinder-not-suck">How PathFinder Almost Killed Me, and How I made PathFinder not suck</h3>

<p>I found every bug imaginable while developing OrthoRoute. For one, congestion of nets would grow each iterations. The router would start fine with 9,495 edges with congestion in iteration 1. Then iteration 2: 18,636 edges. Iteration 3: 36,998 edges. The overuse was <em>growing</em> by 3× per iteration instead of converging. Something was fundamentally broken. The culprit? History costs were <em>decaying</em> instead of accumulating. The algorithm needs to remember which edges were problematic in past iterations, but my implementation had <code>history_decay=0.995</code>, so it was forgetting 0.5% of the problem every iteration. By iteration 10, it had forgotten everything. No memory = no learning = explosion.</p>

<p>With the history fixed, I ran another test. I got <em>oscillation</em>. The algorithm would improve for 12 iterations (9,495 → 5,527, a 42% improvement!), then spike back to 11,817, then drop to 7,252, then spike to 14,000. The pattern repeated forever. The problem was “adaptive hotset sizing”—when progress slowed, the algorithm would enlarge the set of nets being rerouted from 150 to 225, causing massive disruption. Fixing the hotset at 100 nets eliminated the oscillation.</p>

<p>Even with fixed hotsets, late-stage oscillation returned after iteration 15. Why? The present cost factor escalates exponentially: <code>pres_fac = 1.15^iteration</code>. By iteration 19, present cost was 12.4× stronger than iteration 1, completely overwhelming history (which grows linearly). The solution: cap <code>pres_fac_max=8.0</code> to keep history competitive throughout convergence.</p>

<p>PathFinder is designed for FPGAs, and each and every Xilinx XC3000 chip is the same as every other XC3000 chip. Configuring the parameters for an old Xilinx chip means every routing problem will <em>probably</em> converge on that particular chip. PCBs are different; every single PCB is different from every other PCB. There is no single set of history, pressure, and decay parameters that will work on every single PCB.</p>

<p>What I had to do was figure out these paramaters on the fly. So that’s what I did. Right now I’m using Board-adaptive parameters for the Manhattan router. Before beginning the PathFinder algorithm it analyzes the board in KiCad for the number of signal layers, how many nets will be routed, and how dense the set of nets are. It’s clunky, but it kinda works.</p>

<p>Where PathFinder was tuned once for each family of FPGAs, I’m auto-tuning it for the entire class of circuit boards. A huge backplane gets careful routing and an Arduino clone gets fast, aggressive routing. The hope is that both will converge – produce a valid routing solution – and maybe that works. Maybe it doesn’t. There’s still more work to do.</p>

<h2 id="routing-the-monster-board">Routing The Monster Board</h2>

<p>After significant testing with “small” boards (actually 500+ net subsets of my large backplane, with 18 layers), I started work on the entire purpose of this project, the 8000+ net, 17000 pad monster board. There was one significant problem: it wouldn’t fit on my GPU. Admittedly, I only have a 16GB Nvidia 5080, but even this was far too small for the big backplane.</p>

<p>This led me to develop a ‘cloud routing solution’. It boils down to extracting a “OrthoRoute PCB file” from the OrthoRoute plugin. From there, I rent a Linux box with a GPU and run the autorouting algorithm with a headless mode. This produces an “OrthoRoute Solution file”. I import this back into KiCad by running the OrthoRoute plugin on my local machine, and importing the solution file, then pushing <em>that</em> to KiCad.</p>

<p>Here’s the result:</p>

<figure>
  <img src="https://bbenchoff.github.io/images/ConnM/OrthoRouteLarge.png" alt="Full backplane view showing completed routing">
  <figcaption>
    The full backplane view: 8,192 nets routed through 32 layers, in OrthoRoute
  </figcaption>
</figure>

<figure>
  <img src="https://bbenchoff.github.io/images/ConnM/OrthorouteRouted.png" alt="Zoomed detail of Manhattan lattice routing">
  <figcaption>
    Zoomed detail showing Manhattan lattice routing density
  </figcaption>
</figure>

<figure>
  <img src="https://bbenchoff.github.io/images/ConnM/OrthoRouteKiCad.png" alt="Routed board imported into KiCad">
  <figcaption>
    The routed board imported back into KiCad for final cleanup
  </figcaption>
</figure>

<p>That’s it, that’s the finished board. A few specs:</p>

<ul>
  <li>44,233 blind and buried vias. 68,975 track segments.</li>
  <li>Routed on an 80GB A100 GPU, rented on vast.io. The total VRAM required to route this board was 33.5 GB, so close to being under 32GB and allowing me to rent a cheaper GPU</li>
  <li>Total time to route this board to completion was 41 hours. This is far better than the months it would have taken FreeRouting to route this board, but it’s still not fast.</li>
  <li>The routing result is <em>good</em> but not <em>great</em>. A big problem is the DRC-awareness of the escape pad planning. There are traces that don’t quite overlap, but because of the geometry generated by the escape route planner they don’t pass a strict DRC. This could be fixed in future versions. There are also some overlapping traces in what PathFinder generated. Not many, but a few.</li>
</ul>

<p>While the output from my autorouter isn’t perfect, no one would expect an autorouter to produce a <em>perfect</em> result, ready for production. It’s an autorouter, something you shouldn’t trust. Turning the result for OrthoRoute into a DRC-compliant board took a few days, but it was far easier than the intractable problem of eight thousand airwires I had at the beginning.</p>

<h2 id="the-future-of-orthoroute">The Future of OrthoRoute</h2>

<p>I built this for one reason: to route my pathologically large backplane. Mission accomplished. And along the way, I accidentally built something more useful than I expected.</p>

<p>OrthoRoute proves that GPU-accelerated routing isn’t just theoretical, and that algorithms designed for routing FPGAs can be adapted to the more general class of circuit boards. It’s fast, too. The Manhattan lattice approach handles high-density designs that make traditional autorouters choke. And the PathFinder implementation converges in minutes on boards that would take hours or days with CPU-based approaches.</p>

<p>More importantly, the architecture is modular. The hard parts—KiCad IPC integration, GPU acceleration framework, DRC-aware routing space generation are done. Adding new routing strategies on top of this foundation is straightforward. Someone could implement different algorithms, optimize for specific board types, or extend it to handle flex PCBs.</p>

<p>The code is <a href="https://github.com/bbenchoff/OrthoRoute">up on GitHub</a>. I’m genuinely curious what other people will do with it. Want to add different routing strategies? Optimize for RF boards? Extend it to flex PCBs? PRs welcome, contributors welcome.</p>

<p>And yes, you should still manually route critical signals. But for dense digital boards with hundreds of mundane power and data nets? Let the GPU handle it while you grab coffee. That’s what autorouters are for.</p>

<p><strong>Never trust the autorouter. But at least this one is fast.</strong></p>



<p><a href="https://bbenchoff.github.io/">back</a></p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: RowboatX – open-source Claude Code for everyday automations (104 pts)]]></title>
            <link>https://github.com/rowboatlabs/rowboat</link>
            <guid>45970338</guid>
            <pubDate>Tue, 18 Nov 2025 18:50:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rowboatlabs/rowboat">https://github.com/rowboatlabs/rowboat</a>, See on <a href="https://news.ycombinator.com/item?id=45970338">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/rowboatlabs/rowboat/blob/main/assets/banner.png"><img src="https://github.com/rowboatlabs/rowboat/raw/main/assets/banner.png" alt="ui"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">RowboatX - CLI Tool for Background Agents</h2><a id="user-content-rowboatx---cli-tool-for-background-agents" aria-label="Permalink: RowboatX - CLI Tool for Background Agents" href="#rowboatx---cli-tool-for-background-agents"></a></p>

<ul dir="auto">
<li>✨ <strong>Create background agents with full shell access</strong>
<ul dir="auto">
<li>E.g. "Generate a NotebookLM-style podcast from my saved articles every morning"</li>
</ul>
</li>
<li>🔧 <strong>Connect any MCP server to add capabilities</strong>
<ul dir="auto">
<li>Add MCP servers and RowboatX handles the integration</li>
</ul>
</li>
<li>🎯 <strong>Let RowboatX control and monitor your background agents</strong>
<ul dir="auto">
<li>Easily inspect state on the filesystem</li>
</ul>
</li>
</ul>
<p dir="auto">Inspired by Claude Code, RowboatX brings the same shell-native power to background automations.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick start" href="#quick-start"></a></p>
<ol dir="auto">
<li>Install RowboatX
<div dir="auto" data-snippet-clipboard-copy-content="npx @rowboatlabs/rowboatx"><pre>npx @rowboatlabs/rowboatx</pre></div>
</li>
<li>Configure LLM (defaults to OpenAI)
<div data-snippet-clipboard-copy-content="edit ~/.rowboat/config/models.json "><pre><code>edit ~/.rowboat/config/models.json 
</code></pre></div>
</li>
</ol>
<p dir="auto">Then set your API key in your environment. Supports OpenAI, Ollama, Anthropic, Gemini, LMStudio, OpenRouter, LiteLLM</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=cyPBinQzicY&amp;t" rel="nofollow"><img src="https://private-user-images.githubusercontent.com/30795890/515897913-ab46ff8b-44bd-400e-beb0-801c6431033f.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjM1NjY1MDIsIm5iZiI6MTc2MzU2NjIwMiwicGF0aCI6Ii8zMDc5NTg5MC81MTU4OTc5MTMtYWI0NmZmOGItNDRiZC00MDBlLWJlYjAtODAxYzY0MzEwMzNmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTExMTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMTE5VDE1MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTI1N2M0Yzk3ZWFiNGNlNmRiNzdkOTg0MTExYmY4YTIwMjEyNWFhY2RiZTlhOWYyNDhmMjAwZjJiMzc0NWZkMDYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.PDPTwQkUzTot7Slf1zZGoiFUyWY2vnGWWWr0jEh89iI" alt="Screenshot" secured-asset-link=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Add and Manage MCP servers</h3><a id="user-content-add-and-manage-mcp-servers" aria-label="Permalink: Add and Manage MCP servers" href="#add-and-manage-mcp-servers"></a></p>
<p dir="auto"><code>$ rowboatx</code></p>
<ul dir="auto">
<li>Add MCP: 'Add this MCP server config: &lt;config&gt; '</li>
<li>Explore tools: 'What tools are there in &lt;server-name&gt; '</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Create background agents</h3><a id="user-content-create-background-agents" aria-label="Permalink: Create background agents" href="#create-background-agents"></a></p>
<p dir="auto"><code>$ rowboatx</code></p>
<ul dir="auto">
<li>'Create agent to do X.'</li>
<li>'... Attach the correct tools from &lt;mcp-server-name&gt; to the agent'</li>
<li>'... Allow the agent to run shell commands including ffmpeg'</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Schedule and monitor agents</h3><a id="user-content-schedule-and-monitor-agents" aria-label="Permalink: Schedule and monitor agents" href="#schedule-and-monitor-agents"></a></p>
<p dir="auto"><code>$ rowboatx</code></p>
<ul dir="auto">
<li>'Make agent &lt;background-agent-name&gt; run every day at 10 AM'</li>
<li>'What agents do I have scheduled to run and at what times'</li>
<li>'When was &lt;background-agent-name&gt; last run'</li>
<li>'Are any agents waiting for my input or confirmation'</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Run background agents manually</h3><a id="user-content-run-background-agents-manually" aria-label="Permalink: Run background agents manually" href="#run-background-agents-manually"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="rowboatx --agent=<agent-name> --input=&quot;xyz&quot; --no-interactive=true"><pre>rowboatx --agent=<span>&lt;</span>agent-name<span>&gt;</span> --input=<span><span>"</span>xyz<span>"</span></span> --no-interactive=true</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="rowboatx --agent=<agent-name> --run_id=<run_id> # resume from a previous run"><pre>rowboatx --agent=<span>&lt;</span>agent-name<span>&gt;</span> --run_id=<span>&lt;</span>run_id<span>&gt;</span> <span><span>#</span> resume from a previous run</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Models support</h2><a id="user-content-models-support" aria-label="Permalink: Models support" href="#models-support"></a></p>
<p dir="auto">You can configure your models in <code>~/.rowboat/config/models.json</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;providers&quot;: {
    &quot;openai&quot;: {
      &quot;flavor&quot;: &quot;openai&quot;
    },
    &quot;openai-compatible-host&quot;: {
      &quot;flavor&quot;: &quot;openai&quot;,
      &quot;baseURL&quot;: &quot;http://localhost:2000/...&quot;,
      &quot;apiKey&quot;: &quot;...&quot;,
      &quot;headers&quot;: {
        &quot;foo&quot;: &quot;bar&quot;
      }
    },
    &quot;anthropic&quot;: {
      &quot;flavor&quot;: &quot;anthropic&quot;
    },
    &quot;google&quot;: {
      &quot;flavor&quot;: &quot;google&quot;
    },
    &quot;ollama&quot;: {
      &quot;flavor&quot;: &quot;ollama&quot;
    }
  },
  &quot;defaults&quot;: {
    &quot;provider&quot;: &quot;openai&quot;,
    &quot;model&quot;: &quot;gpt-5&quot;
  }
}"><pre>{
  <span>"providers"</span>: {
    <span>"openai"</span>: {
      <span>"flavor"</span>: <span><span>"</span>openai<span>"</span></span>
    },
    <span>"openai-compatible-host"</span>: {
      <span>"flavor"</span>: <span><span>"</span>openai<span>"</span></span>,
      <span>"baseURL"</span>: <span><span>"</span>http://localhost:2000/...<span>"</span></span>,
      <span>"apiKey"</span>: <span><span>"</span>...<span>"</span></span>,
      <span>"headers"</span>: {
        <span>"foo"</span>: <span><span>"</span>bar<span>"</span></span>
      }
    },
    <span>"anthropic"</span>: {
      <span>"flavor"</span>: <span><span>"</span>anthropic<span>"</span></span>
    },
    <span>"google"</span>: {
      <span>"flavor"</span>: <span><span>"</span>google<span>"</span></span>
    },
    <span>"ollama"</span>: {
      <span>"flavor"</span>: <span><span>"</span>ollama<span>"</span></span>
    }
  },
  <span>"defaults"</span>: {
    <span>"provider"</span>: <span><span>"</span>openai<span>"</span></span>,
    <span>"model"</span>: <span><span>"</span>gpt-5<span>"</span></span>
  }
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Rowboat Classic UI</h2><a id="user-content-rowboat-classic-ui" aria-label="Permalink: Rowboat Classic UI" href="#rowboat-classic-ui"></a></p>
<p dir="auto">To use Rowboat Classic UI (not RowboatX), refer to <a href="https://docs.rowboatlabs.com/" rel="nofollow">Classic</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Court settlement calls for NPR to get $36M to operate US public radio system (119 pts)]]></title>
            <link>https://apnews.com/article/trump-npr-lawsuit-2cc4abfa8cf00fe6f89e387e63eb4a2a</link>
            <guid>45969974</guid>
            <pubDate>Tue, 18 Nov 2025 18:19:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/trump-npr-lawsuit-2cc4abfa8cf00fe6f89e387e63eb4a2a">https://apnews.com/article/trump-npr-lawsuit-2cc4abfa8cf00fe6f89e387e63eb4a2a</a>, See on <a href="https://news.ycombinator.com/item?id=45969974">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>WASHINGTON (AP) — National Public Radio will receive approximately $36 million in grant money to operate the nation’s public radio interconnection system under the terms of a <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://storage.courtlistener.com/recap/gov.uscourts.dcd.280953/gov.uscourts.dcd.280953.77.0.pdf" target="_blank" rel="noopener">court settlement</a></span> with the federal government’s steward of funding for public broadcasting stations.</p><p>The settlement, announced late Monday, partially resolves a legal dispute in which NPR accused the <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/public-broadcasting-defunding-pbs-npr-94708ffb8313d4811fa6ca199fe454ad">Corporation for Public Broadcasting</a></span> of bowing to pressure from President Donald Trump to cut off its funding. </p><p>On March 25, Trump said at a news conference that he would “love to” defund NPR and PBS because he believes they are biased in favor of Democrats.</p><p>NPR accused the CPB of violating its First Amendment free speech rights when it moved to cut off its access to grant money appropriated by Congress. NPR also claims Trump, a Republican, wants to punish it for the content of its journalism. </p>
    
<p>On April 2, the CPB’s board initially approved a three-year, roughly $36 million extension of a grant for NPR to operate the “interconnection” satellite system for public radio. NPR has been operating and managing the Public Radio Satellite System since 1985.</p>



<p>But corporation officials reversed course and announced that the federal funds would go to a entity called Public Media Infrastructure. <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://storage.courtlistener.com/recap/gov.uscourts.dcd.280953/gov.uscourts.dcd.280953.57.1.pdf" target="_blank" rel="noopener">NPR claimed</a></span> the CPB was under mounting pressure from the Trump administration when the agency redirected the money to PMI, a media coalition that didn’t exist and wasn’t statutorily authorized to receive the funds.</p>
    
    <div data-module-tracksubscribe="" data-gtm-topic="No Value" data-align-center="">
    <p>Stay up to date with the news and the best of AP by following our WhatsApp channel.</p>
    <p><a href="https://www.whatsapp.com/channel/0029Va7Tv2j59PwNEyqGCi1y" target="_blank" rel="noopener">
      <span>Follow on</span>
      <img src="https://dims.apnews.com/dims4/default/f50b139/2147483647/strip/true/crop/131x31+0+0/resize/131x31!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F8c%2Fe0%2F2615e5984b5ebb8b89fd3ade6941%2Fwhatsapp-logo.png" alt="WhatsApp">
    </a>
  </p></div>
    
<p>CPB attorneys denied that the agency retaliated against NPR to appease Trump. They had <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://storage.courtlistener.com/recap/gov.uscourts.dcd.280953/gov.uscourts.dcd.280953.65.0.pdf" target="_blank" rel="noopener">argued that NPR’s claims</a></span> are factually and legally meritless.</p>
    
    
    
<p>On May 1, Trump issued an executive order that called for federal agencies to stop funding for NPR and PBS. The settlement doesn’t end a lawsuit in which NPR seeks to block any implementation or enforcement of Trump’s executive order. U.S. District Judge Randolph Moss is scheduled to preside over another hearing for the case on Dec. 4.</p>
    
<p>The settlement says NPR and CPB agree that the executive order is unconstitutional and that CPB won’t enforce it unless a court orders it to do so.</p><p>NPR, meanwhile, agreed to drop its request for a court order blocking CPB from disbursing funds to PMI under a separate grant agreement.</p><p>Katherine Maher, NPR’s president and CEO, said the settlement is “a victory for editorial independence and a step toward upholding the First Amendment rights of NPR and the public media system.”</p><p>Patricia Harrison, the corporation’s CEO, said CPB is pleased that the litigation is over “and that our investment in the future through PMI marks an exciting new era for public media.”</p><p>On Aug. 1, CPB announced it would take steps toward closing itself down after being defunded by Congress.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I am stepping down as the CEO of Mastodon (561 pts)]]></title>
            <link>https://blog.joinmastodon.org/2025/11/my-next-chapter-with-mastodon/</link>
            <guid>45969909</guid>
            <pubDate>Tue, 18 Nov 2025 18:13:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.joinmastodon.org/2025/11/my-next-chapter-with-mastodon/">https://blog.joinmastodon.org/2025/11/my-next-chapter-with-mastodon/</a>, See on <a href="https://news.ycombinator.com/item?id=45969909">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>After nearly 10 years, I am stepping down as the CEO of Mastodon and transferring my ownership of the trademark and other assets to the Mastodon non-profit. Over the course of my time at Mastodon, I have centered myself less and less in our outward communications, and to some degree, this is the culmination of that trend. Mastodon is bigger than me, and though the technology we develop on is itself decentralized—with heaps of alternative fediverse projects demonstrating that participation in this ecosystem is possible without our involvement—it benefits our community to ensure that the project itself which so many people have come to love and depend on remains true to its values. There are too many examples of founder egos sabotaging thriving communities, and while I’d like to think myself an exception, I understand why people would prefer better guardrails.</p><p>But it would be uncouth for me to pretend that there isn’t some self-interest involved. Being in charge of a social media project is, turns out, quite the stressful endeavour, and I don’t have the right personality for it. I think I need not elaborate that the passion so many feel for social media does not always manifest in healthy ways. You are to be compared with tech billionaires, with their immense wealth and layered support systems, but with none of the money or resources. It manifests in what people expect of you, and how people talk about you. I remember somebody jokingly suggesting that I challenge Elon Musk to a fight (this was during his and Mark Zuckerberg’s martial arts feud), and quietly thinking to myself, I am literally not paid enough for that. I remember also, some Spanish newspaper article that for some reason, concluded that I don’t dress as fashionably as Jeff Bezos, based on the extremely sparse number of pictures of myself I have shared on the web. Over an entire decade, these tiny things chip away at you slowly. Some things chip faster. I steer clear of showing vulnerability online, but there was a particularly bad interaction with a user last summer that made me realise that I need to take a step back and find a healthier relationship with the project, ultimately serving as the impetus to begin this restructuring process.</p><p>As for what the legacy of my run will be, I find hard to answer. For one, I think it is not up for me to judge. On the other hand, it is as much about what didn’t happen as it is about what did. I’ve always thought that one of the most important responsibilities I had was to say “no”. It is not a popular thing to do, nor is it a fun thing to do, but being pulled into too many different directions at once can spell disaster for any project. I’d like to think I avoided some trouble by being careful. But I’m also aware that my aversion to public appearances cost Mastodon some opportunities in publicity. Ultimately, while I cannot take sole credit for it, I am nevertheless most proud of how far we’ve made it over these last 10 years. From the most barebones project written out of my childhood bedroom, to one of the last remaining and thriving pieces of the original, community-centred internet.</p><p>I have so much passion for Mastodon and the fediverse. The fediverse is an island within an increasingly dystopian capitalist hellscape. And from my perspective, Mastodon is our best shot at bringing this vision of a better future to the masses. This is why I’m sticking around, albeit in a more advisory, and less public, role.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pebble, Rebble, and a path forward (439 pts)]]></title>
            <link>https://ericmigi.com/blog/pebble-rebble-and-a-path-forward/</link>
            <guid>45969250</guid>
            <pubDate>Tue, 18 Nov 2025 17:24:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ericmigi.com/blog/pebble-rebble-and-a-path-forward/">https://ericmigi.com/blog/pebble-rebble-and-a-path-forward/</a>, See on <a href="https://news.ycombinator.com/item?id=45969250">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I believe the Pebble community, Core Devices, Rebble and I all want the same thing. We love our Pebbles and want them to keep working long into the future. We love the community that has sprung up around Pebble, and how it’s persevered - next year will be the 14th anniversary of the original Kickstarter campaign!</p><p>But I have to respond to claims made by Rebble posted on their blog yesterday. I will <a href="https://rebble.io/2025/11/17/core-devices-keeps-stealing-our-work.html" target="_blank" rel="noopener noreferrer">link to their post</a> so you can read their side of the story, and I’ve asked them to link back to this blog post from theirs.</p><p>Look - I’m the first person to call myself out when I fail. I wrote a detailed blog post about <a href="https://ericmigi.com/blog/success-and-failure-at-pebble">Success and Failure at Pebble</a> and often write in detail about learning from my mistakes. But in this specific case, you’ll find that I’ve done my utmost to respect the Pebble legacy and community. Rebble is misleading the community with false accusations.</p><hr><p><strong>For those just passing through, here’s the TLDR:</strong> </p><p>Core Devices is a small company I started in 2025 to relaunch Pebble and build new <a href="https://store.repebble.com/" target="_blank" rel="noopener noreferrer">Pebble smartwatches</a>. <a href="https://rebble.io/" target="_blank" rel="noopener noreferrer">Rebble</a> is a non-profit organization that has supported the Pebble community since 2017. Rebble has done a ton of great work over the years and deserves recognition and support for that.</p><p>Core Devices and Rebble negotiated an agreement where Core would pay $0.20/user/month to support Rebble services. But the agreement broke down after over the following disagreement. </p><p>Rebble believes that they ‘100%’ own the data of the Pebble Appstore. They’re attempting to create a walled garden around 13,000 apps and faces that individual Pebble developers created and uploaded to the Pebble Appstore between 2012 and 2016. Rebble later scraped this data in 2017. </p><p>I disagree. I’m working hard to keep the Pebble ecosystem open source. I believe the contents of the Pebble Appstore should be freely available and not controlled by one organization. </p><p>Rebble posted a blog post yesterday with a bunch of false accusations, and in this post I speak to each of them.</p><hr><p><strong>Sections</strong></p><ul><li><a href="https://ericmigi.com/blog/pebble-rebble-and-a-path-forward#short-history">Short history</a></li><li><a href="https://ericmigi.com/blog/pebble-rebble-and-a-path-forward#their-accusations">Their accusations</a></li><li><a href="https://ericmigi.com/blog/pebble-rebble-and-a-path-forward#backstory">Backstory</a></li><li><a href="https://ericmigi.com/blog/pebble-rebble-and-a-path-forward#our-disagreement">Our disagreement</a></li><li><a href="https://ericmigi.com/blog/pebble-rebble-and-a-path-forward#our-plan-for-the-fut">Our plan for the future</a></li></ul><h3 id="short-history"><a href="#short-history">Short history<span>#</span></a></h3><ul><li><strong>Dec 2016</strong> - <strong>Pebble shut down</strong>. Some IP was sold to Fitbit. I <a href="https://ericmigi.com/blog/success-and-failure-at-pebble">blogged</a> about why I think we failed. Fitbit continued to run the Pebble Appstore and web services for 1.5 years. I really appreciated that.<ul><li>Rebble organization grew out of the official Pebble Developers Discord.</li></ul></li><li><strong>July 2018</strong>, <strong>Fitbit shut down the Pebble appstore</strong>.<ul><li>Before it shut down, Rebble (and <a href="https://github.com/aveao/PebbleArchive/tree/master/PebbleAppStore/apps" target="_blank" rel="noopener noreferrer">others</a>) scraped all 13,000 apps and metadata from the Pebble Appstore. Rebble began hosting a copy of the <a href="https://apps.rebble.io/" target="_blank" rel="noopener noreferrer">appstore</a>. They created a new Dev Portal where developers could upload new apps, roughly 500 have been uploaded since July 2018.</li><li>Rebble also reverse engineered many Pebble web services (weather, timeline and voice transcription) and provided them as a paid service for the Pebble community.</li></ul></li><li><strong>Jan 2025</strong> - <strong>Google open sourced PebbleOS</strong>, breathing new life into the community.</li><li><strong>March 2025</strong> - <strong>I announced a new company</strong> (Core Devices) and 2 new watches - <a href="http://store.repebble.com/" target="_blank" rel="noopener noreferrer">store.rePebble.com</a></li><li><strong>November 2025</strong> - <strong>we finished shipping out 5,000 Pebble 2 Duos</strong>. We’re working hard on Pebble Time 2. We’re aiming to start shipping in January.</li></ul><h3 id="their-accusations"><a href="#their-accusations">Their accusations<span>#</span></a></h3><p><strong>Accusation 1</strong>: ‘Rebble paid for the work&nbsp;that <!-- -->[Eric]<!-- --> took as a base for his commercial watches’</p><p><strong>Facts:</strong></p><ul><li>I think they’re accusing me of ‘stealing’ open source contributions to PebbleOS that Rebble paid for. This is entirely false.</li><li><strong>We did not take any PebbleOS work</strong> <strong>Rebble paid for ‘as a base for <!-- -->[our]<!-- --> commercial watches’.</strong> <del>To my best of my knowledge</del><del>,</del> <del>Rebble never paid the</del> <del>developer who ported NimBLE into PebbleOS.</del> <del>My best guess is that they are referring to Rebble having paid CodeCoup, the company behind</del> <a href="https://ericmigi.com/blog/pebble-rebble-and-a-path-forward/github.com/apache/mynewt-nimble" target="_blank" rel="noopener noreferrer"><del>NimBLE</del></a><del>, to fix some bugs that affected older non-Core Devices watches. Any Rebble-sponsored CodeCoup commits are not present in our repo. In fact, the opposite is true - we paid Codecoup $10,000 to fix multiple BLE stack issues, some of them on the host side that benefit all devices, including old Pebbles.</del>  Update: I’m told Rebble did pay him, months later. My point is valid - when we shifted development to our repo, Rebble had not paid anything. More broadly, I reject the premise that using open source software under the terms of the license, regardless of who funds development, is ‘stealing’.</li><li>We started using our <a href="https://github.com/coredevices/pebbleos" target="_blank" rel="noopener noreferrer">own repo</a> for PebbleOS development because PRs on the <a href="https://github.com/pebble-dev/pebble-firmware" target="_blank" rel="noopener noreferrer">Rebble repo</a> reviews were taking too long. We only had one firmware engineer at the time (now we have a whopping 2!) and he felt like he was being slowed down too much. All of our contributions to PebbleOS have been <a href="https://github.com/coredevices/pebbleos" target="_blank" rel="noopener noreferrer">100% open source</a>.</li><li>Overall, the feedback that PebbleOS could benefit from open governance is well taken. Long term, PebbleOS would be a good fit for open source organization with experience in open governance, like Apache or Linux Foundation. I <a href="https://ericmigi.com/blog/how-to-build-a-smartwatch-software-setting-expectations-and-roadmap#pebbleos-firmware-pl">wrote about this</a> last week.</li><li>With our small team and fairly quick development schedule, it's true that we haven't PRed  our changes into Rebble’s repo. It’s tough to prioritize this while we are busy fixing bugs and getting ready for Pebble Time 2.</li></ul><p><strong>Accusation 2:</strong> ‘Core took Rebble’s work’ on <a href="https://github.com/pebble-dev/libpebblecommon" target="_blank" rel="noopener noreferrer"><code>libpebblecommon</code></a> to create <a href="https://github.com/coredevices/libpebble3" target="_blank" rel="noopener noreferrer"><code>libpebble3</code></a></p><p><strong>Facts:</strong></p><ul><li><p>The majority (&gt;90%) of our new open source<code>libpebble3</code> library was written by Core Devices employees.  The remainder comes from <code>libpebblecommon</code>, another open source library written by two people.</p></li><li><p>In April 2025, <strong>Core purchased the copyright to the</strong> <strong><code>libpebblecommon</code></strong> <strong>code from the two maintainers and incorporated it into</strong> <strong><code>libpebble3</code><sup><sup><sup>*</sup></sup></sup><sup><sup><sup>*</sup></sup></sup></strong>, which is also open source<sup><sup>*</sup></sup><sup><sup>*</sup></sup>.</p><p><img src="https://ericmigi.com/assets/pebble-rebble-and-a-path-forward-7-cleanshot_2025-11-17_at_23.18.292x.png"></p></li><li><p>All our contributions to <code>libpebble3</code> are GPL-3.0 licensed. <a href="https://ericmigi.notion.site/Core-Devices-Software-Licensing-1c0fbb55ea8480f88d27ccf20fcb84a8" target="_blank" rel="noopener noreferrer">Here’s the motivation</a> behind that our licensing strategy for this repo. We use the same CLA agreement as Matrix, QT and MySQL. Our CLA explicitly includes a clause that requires to Core Devices to distribute all contributions under an OSI-compatible FOSS license (e.g. GPLv3).</p></li><li><p>Note that neither Rebble <code>libpebblecommon</code> maintainer signed the Rebble blog post.</p></li></ul><p>Side note regarding <a href="https://github.com/pebble-dev/mobile-app" target="_blank" rel="noopener noreferrer">Cobble</a>, I don’t think Rebble even knows this but in 2024, I personally spent over $30,000 to support its development, way before PebbleOS was open source. It was my own way to support the community.</p><p><strong>Accusation 3: ‘</strong>Core promised that they would let Rebble maintain and own the developer site’</p><p><strong>Facts:</strong></p><ul><li>Nothing of the sort was agreed upon. See the full <a href="https://ericmigi.com/blog/pebble-rebble-and-a-path-forward#backstory"><strong>written agreement</strong></a> that Core Devices has with Rebble towards the bottom. Rebble agreed that Core would host the developer site.</li><li>I have been maintaining and updating the <a href="https://developer.repebble.com/" target="_blank" rel="noopener noreferrer">developer</a> site personally - all <a href="https://github.com/coredevices/sdk-docs" target="_blank" rel="noopener noreferrer">open source</a>. Having two sources of truth would be confusing for the community.</li></ul><p><img src="https://ericmigi.com/assets/pebble-rebble-and-a-path-forward-0-cleanshot_2025-11-17_at_23.24.362x.png"></p><p><strong>Accusation 4: ‘<!-- -->[Eric]</strong> scraped our app store, in violation of the agreement that we reached with him previously’</p><p><em>Note:</em> <em>‘scraping’ usually</em> <em>means to automated extraction of data from a website.</em></p><p><em><strong>Fact</strong></em><strong>s:</strong> </p><ul><li>Here’s what happened. I wanted to highlight some of my favourite watchfaces on the Pebble Appstore. Last Monday Nov 10, after I put my kids to sleep and between long calls with factories in Asia, I started building a <a href="https://bsky.app/profile/ericmigi.com/post/3m5rhwqhtl22c">webapp</a> to help me quickly go through Pebble Appstore and decide which were my top picks.</li><li>Let me be crystal clear - my little webapp did not download apps or ‘scrape’ anything from Rebble. The webapp displayed the name of each watchface and screenshots and let me click on my favs. I  used it to manually look through 6000 watchfaces with my own eyes. I still have 7,000 to go. Post your server logs, they will match up identically to the app I (well…Claude) wrote (<a href="https://github.com/coredevices/erics-appstore-picker" target="_blank" rel="noopener noreferrer">source code here</a>)</li><li>I integrated <a href="https://apps.repebble.com/en_US/watchfaces" target="_blank" rel="noopener noreferrer">these picks into the Pebble Appstore</a> on Saturday and posted about <a href="https://bsky.app/profile/ericmigi.com/post/3m5rhf4nsts2r">it on Sunday</a>.</li></ul><p>All of four of these accusations could have been clarified simply by asking me. Instead, Rebble decided to post them on their blog and threaten a lawsuit. </p><h3 id="backstory"><a href="#backstory">Backstory<span>#</span></a></h3><p><strong>How did we get here?</strong></p><p>Why are there dueling blog posts in the Pebbleverse? </p><p>I think most of the people are behind Rebble are great and the community overall is awesome. I know they truly mean well, but there are many aspects of the org that are severely troubling. I am very close with one of the Rebble board members, who I consider a personal friend. Over the years, I learned a lot about the organization and helped coach him through some major disputes between board members. </p><p><img src="https://ericmigi.com/assets/pebble-rebble-and-a-path-forward-1-cleanshot_2025-11-18_at_03.24.42.png"></p><p>I exchanged literally thousands of messages with my friend on this topic over the span of 3 years. I refrained from getting too involved, despite being asked several times to join Rebble as a board member or lead the organization. I demurred - I saw how painful it was for him and I had no interest in being part of that. </p><p><strong>Core Devices + Rebble: 2025</strong></p><p>PebbleOS is now <a href="https://ericmigi.com/blog/why-were-bringing-pebble-back">open source</a>! Yay. This is thanks to the work of many Googlers, ex-Pebblers and others - I called out (hopefully) all of them in <a href="https://ericmigi.com/blog/gratitude-and-faq">my blog post</a> in March. I really wanted Rebble to be a part of the Pebble revival going forward. I hired 3 people from Rebble to join Core Devices. I regularly <a href="https://ericmigi.com/blog/why-were-bringing-pebble-back/#todays-big-news-goog">brought up Rebble’s efforts</a> over the years.</p><p><img src="https://ericmigi.com/assets/pebble-rebble-and-a-path-forward-2-cleanshot_2025-11-18_at_03.49.052x.png"></p><p>I engaged with Rebble folks in discussions in the spring on how we could formally work together, and then made some concrete proposals in the summer. One difficulty was that Core Devices is a business with customers and schedules. This didn’t always sync up with the timeframes of a non-profit. Things became very drawn out. It was very hard to pin people down, even on simple stuff like what the goals of Rebble as an organization were. </p><p>Regardless, I continued pushing to make Rebble a key part of the Pebble relaunch.</p><p><img src="https://ericmigi.com/assets/pebble-rebble-and-a-path-forward-3-cleanshot_2025-11-18_at_03.36.13.png"></p><p>By August, we finally got close to an agreement.</p><p><img src="https://ericmigi.com/assets/pebble-rebble-and-a-path-forward-4-cleanshot_2025-11-18_at_03.47.21.png"></p><p>On September 30 2025, we agreed to the following document and published respective blog posts (<a href="https://ericmigi.com/blog/re-introducing-the-pebble-appstore">ours</a>, <a href="https://rebble.io/2025/10/09/rebbles-in-a-world-with-core.html" target="_blank" rel="noopener noreferrer">theres</a>). Core Devices would pay Rebble $0.20/user/month. I considered it a donation to a group that has done so much to support the community. But I purposely pushed for openness - no single group (Core Devices or Rebble) should be in control. </p><p><img src="https://ericmigi.com/assets/pebble-rebble-and-a-path-forward-5-rebble__core_agreement.png"></p><p>Notice the final bullet in the App store section: </p><blockquote><p>All binary/metadata (including historical apps) will be published as archive file (no scraping Rebble services)&nbsp;</p></blockquote><p>Looking back, we should have had more clear wording in this agreement. But this was after months of chat discussions and hours of Zoom calls. I honestly thought that we had reached an agreement to make the archive open, like in this message I received from a Rebble board member.</p><p><img src="https://ericmigi.com/assets/pebble-rebble-and-a-path-forward-6-image.png"></p><p>By the end of October, Rebble has changed their mind about providing an archive file.</p><h3 id="our-disagreement"><a href="#our-disagreement">Our disagreement<span>#</span></a></h3><p>Not withstanding their false accusations of theft, the crux of our disagreement is the archive of 13,000 Pebble apps and watchfaces that were uploaded to the Pebble Appstore in July 2018 before it was shut down. </p><ul><li>I believe that these apps and watchfaces should be archived publicly and freely accessible by anyone. They should not held behind a walled garden by one organization. I repeatedly advocated for hosting this data on a neutral 3rd party like <a href="http://archive.org/" target="_blank" rel="noopener noreferrer">Archive.org</a>.</li><li>Rebble believes ‘the data behind the Pebble App Store is 100% Rebble’ (this is a <a href="https://rebble.io/2025/11/17/core-devices-keeps-stealing-our-work.html" target="_blank" rel="noopener noreferrer">direct quote</a> from their blog post). They repeatedly refer to all watchfaces and watchapps as ‘our data’.</li></ul><p>This is just plainly false. The apps and watchfaces were originally uploaded by individual developers to an appstore run by a company that no longer exists. These folks created beautiful work and shared them freely with the Pebble community. I’ve spoken with numerous Pebble app developers about this. After the fall of Pebble Tech Corp, none of them envisioned one single organization claiming ownership of their work and restricting access, or charging money for access.</p><p>Let’s do the right thing - honour the original developers and create a free publicly available archive of their beautiful watchfaces and watchapps. </p><h3 id="our-plan-for-the-fut"><a href="#our-plan-for-the-fut">Our plan for the future<span>#</span></a></h3><p>It's easy to assume the worst in situations like this. But our plan for the appstore is pretty straightforward. We’re working on rewriting the <a href="https://apps.repebble.com/en_US/watchfaces" target="_blank" rel="noopener noreferrer">appstore frontend</a> to be native in the mobile app rather than a web view. Rebble’s appstore backend API will be the data source. Rebble’s dev portal is where developers upload apps. No subscription or Rebble account will not be required to download apps. We intend to curate how the appstore is displayed Pebble app.</p><p>We’re excited to see other Pebble-supporting mobile apps pop up - like <a href="https://github.com/matejdro/microPebble" target="_blank" rel="noopener noreferrer">MicroPebble</a> and <a href="https://gadgetbridge.org/" target="_blank" rel="noopener noreferrer">GadgetBridge</a>, offering different features and experiences. We’d love to support these efforts with open source code or financially.</p><p>Reading things like ‘<strong>We’re happy to let them build whatever they want as long as it doesn’t hurt Rebble</strong>’ in their blog post worries me. Take our voice-to-text and weather features. Rebble currently offers these as part of their paid subscription. Our new <a href="https://repebble.com/app" target="_blank" rel="noopener noreferrer">Pebble mobile app</a> includes a on-device speech-to-text feature. We’re planning to include weather for free in our app and make the data available to all watchfaces so you don’t need to configure each one separately. These features are better for users but would they ‘hurt’ Rebble? Will I need to ask permission from Rebble before building these features? It’s clear that the goals of a non-profit and device manufacturer will not always be in alignment.</p><p>Now consider the appstore. It’s a fundamental part of the Pebble experience. Even before yesterday’s accusations, I felt wary about relying too heavily on a 3rd party like Rebble to provide such a critical service. When people buy a watch from Core Devices, they expect to be able to download apps and watchfaces. If Rebble leadership changes their mind, how can I be certain I can deliver a good experience for our customers? This is one of the primary reasons I think it’s important for an archive of the Pebble Appstore to be freely available.</p><h3 id="rebble-still-has-the"><a href="#rebble-still-has-the">Rebble still has the chance to redeem itself and do right by the community<span>#</span></a></h3><p>Rebble - prove that you believe in an open, unrestricted Pebble community. Tear down the walled garden you are trying to create. Publish your copy of the Pebble Appstore archive. Stop saying that you ‘100%’ own other developers data. Let’s move on from this ridiculous sideshow and focus on making Pebble awesome!</p><p>I’ve worked hard to structure everything that we’re doing to be sustainable for the long term, and to do right by the Pebble community. I think Rebble should do the same. </p><p>I earned almost nothing from Pebble Tech Corp. I paid myself a $65,000 salary each year. I did not get any payout through the asset sale. I fought to make sure that all Pebble employees were taken care of as best as possible, and that the Pebble community would live on. I believe that at every turn, I’ve done right by the community.</p><p>I didn’t relaunch Pebble to make a lot of money. My goal this time round is to make it sustainable. I want to continue making more watches and cool gadgets. There are no investors. I am taking huge risks doing this. I relaunched it because <strong>I love Pebble and want it to live on long into the future.</strong> Generally, I am excited and positive for the future, despite everything.</p><p>For everyone else, again, I apologize for the extreme amounts of inside baseball and the better things you could be doing with your time. I’ll leave the comments open here. Please refrain from any personal attacks or vicious comments (at myself or other people) - follow the <a href="https://news.ycombinator.com/newsguidelines.html" target="_blank" rel="noopener noreferrer">HN guidelines</a>.</p><p>Eric Migicovsky</p></div></div>]]></description>
        </item>
    </channel>
</rss>