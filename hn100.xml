<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 18 Jun 2025 00:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The Grug Brained Developer (2022) (425 pts)]]></title>
            <link>https://grugbrain.dev/</link>
            <guid>44303542</guid>
            <pubDate>Tue, 17 Jun 2025 20:24:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grugbrain.dev/">https://grugbrain.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=44303542">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <div>
  <p><a href="https://www.redbubble.com/i/sticker/Programmer-Grug-by-colossalbreaker/42915272.EJUG5">
    <img alt="grug" src="https://grugbrain.dev/grug.png">
  </a></p><h2>
     The Grug Brained Developer<br>
     <small>A layman's guide to thinking like the self-aware smol brained</small>
  </h2>
</div>

<h2>Introduction</h2>
<p>this collection of thoughts on software development gathered by grug brain developer</p>
<p>grug brain developer not so smart, but grug brain developer program many long year and learn some things
although mostly still confused</p>
<p>grug brain developer try collect learns into small, easily digestible and funny page, not only for you, the young grug, but also for him
because as grug brain developer get older he forget important things, like what had for breakfast or if put pants on</p>
<p>big brained developers are many, and some not expected to like this, make sour face</p>
<p><em>THINK</em> they are big brained developers many, many more, and more even definitely probably maybe not like this, many
sour face (such is internet)</p>
<p>(note: grug once think big brained but learn hard way)</p>
<p>is fine!</p>
<p>is free country sort of and end of day not really matter too much, but grug hope you fun reading and maybe learn from
many, many mistake grug make over long program life</p>
<h2><a name="grug-on-complexity"></a><a href="#grug-on-complexity">The Eternal Enemy: Complexity</a></h2>
<p>apex predator of grug is complexity</p>
<p>complexity bad</p>
<p>say again:</p>
<p>complexity <em>very</em> bad</p>
<p><em>you</em> say now:</p>
<p>complexity <em>very</em>, <em>very</em> bad</p>
<p>given choice between complexity or one on one against t-rex, grug take t-rex: at least grug see t-rex</p>
<p>complexity is spirit demon that enter codebase through well-meaning but ultimately very clubbable non grug-brain
developers and project managers who not fear complexity spirit demon or even know about sometime</p>
<p>one day code base understandable and grug can get work done, everything good!</p>
<p>next day impossible: complexity demon spirit has entered code and very dangerous situation!</p>
<p>grug no able see complexity demon, but grug sense presence in code base</p>
<p>demon complexity spirit mocking him make change here break unrelated thing there what!?! mock mock mock ha ha so funny
grug love programming and not becoming shiney rock speculator like grug senior advise</p>
<p>club not work on demon spirit complexity and bad idea actually hit developer who let spirit in with club: sometimes grug
himself!</p>
<p>sadly, often grug himself</p>
<p>so grug say again and say often: complexity <em>very</em>, <em>very</em> bad</p>
<h2><a name="grug-on-saying-no"></a><a href="#grug-on-saying-no">Saying No</a></h2>
<p>best weapon against complexity spirit demon is magic word: "no"</p>
<p>"no, grug not build that feature"</p>
<p>"no, grug not build that abstraction"</p>
<p>"no, grug not put water on body every day or drink less black think juice you stop repeat ask now"</p>
<p>note, this good engineering advice but bad career advice: "yes" is magic word for more shiney rock and put in
charge of large tribe of developer</p>
<p>sad but true: learn "yes" then learn blame other grugs when fail, ideal career advice</p>
<p>but grug must to grug be true, and "no" is magic grug word.  Hard say at first, especially if you nice grug and don't like
disappoint people (many such grugs!) but  easier over time even though shiney rock pile not as high as might otherwise be</p>
<p>is ok: how many shiney rock grug really need anyway?</p>
<h2><a name="grug-on-saying-ok"></a><a href="#grug-on-saying-ok">Saying ok</a></h2>
<p>sometimes compromise necessary or no shiney rock, mean no dinosaur meat, not good, wife firmly remind grug
about young grugs at home need roof, food, and so forth, no interest in complexity demon spirit rant by grug for
fiftieth time</p>
<p>in this situation, grug recommend "ok"</p>
<p>"ok, grug build that feature"</p>
<p>then grug spend time think of <a href="https://en.wikipedia.org/wiki/Pareto_principle">80/20 solution</a> to problem and build that instead.<br>
80/20 solution say "80 want with 20 code"  solution maybe not have all bell-whistle that project manager want, maybe a
little ugly, but work and deliver most value, and keep demon complexity spirit at bay for most part to extent</p>
<p>sometimes probably best just not tell project manager and do it 80/20 way.  easier forgive than permission, project managers
mind like butterfly at times overworked and dealing with many grugs.  often forget what even feature supposed to do or move on or
quit or get fired grug see many such cases</p>
<p>anyway is in project managers best interest anyway so grug not to feel too bad for this approach usually</p>
<h2><a name="grug-on-factring-your-code"></a><a href="#grug-on-factring-your-code">Factoring Your Code</a></h2>
<p>next strategy very harder: break code base up properly (fancy word: "factor your code properly")  here is hard give general
advice because each system so different.  however, one thing grug come to believe: not factor your application too early!</p>
<p>early on in project everything very abstract and like water: very little solid holds for grug's struggling brain to hang
on to.  take time to develop "shape" of system and learn what even doing.  grug try not to factor in early part of project
and then, at some point, good cut-points emerge from code base</p>
<p>good cut point has narrow interface with rest of system: small number of functions or abstractions that hide complexity
demon internally, like trapped in crystal</p>
<p>grug quite satisfied when complexity demon trapped properly in crystal, is best feeling to trap mortal enemy!</p>
<p>grug try watch patiently as cut points emerge from code and slowly refactor, with code base taking shape over time along
with experience.  no hard/ fast rule for this: grug know cut point when grug see cut point, just take time to build
skill in seeing, patience</p>
<p>sometimes grug go too early and get abstractions wrong, so grug bias towards waiting</p>
<p>big brain developers often not like this at all and invent many abstractions start of project</p>
<p>grug tempted to reach for club and yell "big brain no maintain code!  big brain move on next architecture committee
leave code for grug deal with!"</p>
<p>but grug learn control passions, major difference between grug and animal</p>
<p>instead grug try to limit damage of big brain developer early in project by giving them thing like
UML diagram (not hurt code, probably throw away anyway) or by demanding working demo tomorrow</p>
<p>working demo especially good trick: force big brain make something to actually work to talk about and code to look at that do
thing, will help big brain see reality on ground more quickly</p>
<p>remember!  big brain have big brain!  need only be harness for good and not in service of spirit complexity demon on
accident, many times seen</p>
<p>(best grug brain able to herd multiple big brain in right direction and produce many complexity demon trap crystals, large
shiney rock pile awaits such grug!)</p>
<p>also sometimes call demo approach "prototype", sound fancier to project manager</p>
<p>grug say prototype early in software making, <em>especially</em> if many big brains</p>
<h2><a name="grug-on-testing"></a><a href="#grug-on-testing">Testing</a></h2>
<p>grug have love/hate relationship with test: test save grug many, many uncountable time and grug love and respect test</p>
<p>unfortunately also many test shamans exist.  some test shaman make test idol, demand things like "first test" before grug
even write code or have any idea what grug doing domain!</p>
<p>how grug test what grug not even understand domain yet!?</p>
<p>"Oh, don't worry: the tests will show you what you need to do."</p>
<p>grug once again catch grug slowly reaching for club, but grug stay calm</p>
<p>grug instead prefer write most tests after prototype phase, when code has begun firm up</p>
<p>but, note well: grug must here be very disciplined!</p>
<p>easy grug to move on and not write tests because "work on grugs machine"!</p>
<p>this very, very bad: no guarantee work on other machine and no guarantee work on grug machine in future, many times</p>
<p>test shaman have good point on importance of test, even if test shaman often sometimes not complete useful
feature in life and talk only about test all time, deserve of club but heart in right place</p>
<p>also, test shaman often talk unit test very much, but grug not find so useful.  grug experience that ideal tests are not
unit test or either end-to-end test, but in-between test</p>
<p><a href="https://en.wikipedia.org/wiki/Unit_testing">unit tests</a> fine, ok, but break as implementation change (much compared api!)
and make refactor hard and, frankly, many bugs anyway often due interactions other code.  often throw away when code change.</p>
<p>grug write unit test mostly at start of project, help get things going but not get too attached or expect value long time</p>
<p><a href="https://smartbear.com/solutions/end-to-end-testing/">end to end</a> tests good, show whole system work, but! hard to
understand when break and drive grug crazy very often, sometimes grugs just end up ignoring because "oh, that break all
time"  very bad!</p>
<p>in-between tests, grug hear shaman call <a href="https://en.wikipedia.org/wiki/Integration_testing">"integration tests"</a> sometime
often with sour look on face. but grug say integration test sweet spot according to grug: high level enough test correctness
of system, low level enough, with good debugger, easy to see what break</p>
<p>grug prefer some unit tests especially at start but not 100% all code test and definitely not "first test".  "test along
the way" work pretty well for grug, especially as grug figure things out</p>
<p>grug focus much ferocious integration test effort as cut point emerge and system stabilize!  cut point api hopefully stable
compared implementation and integration test remain valuable many long time, and easy debug</p>
<p>also small, well curated end-to-end test suite is created to be kept working religiously on pain of clubbing. focus of important
end-to-end test on most common UI features and few most important edge cases, but not too many or become impossible maintain
and then ignored</p>
<p>this ideal set of test to grug</p>
<p>you may not like, but this peak grug testing</p>
<p>also, grug dislike <a href="https://en.wikipedia.org/wiki/Mock_object">mocking</a> in test, prefer only when absolute necessary
to (rare/never) and coarse grain mocking (cut points/systems) only at that</p>
<p>one exception "first test" dislike by grug: when bug found.  grug always try first reproduce bug with regression test
<em>then</em> fix bug, this case only for some reason work better</p>
<h2><a name="grug-on-agile"></a><a href="#grug-on-agile">Agile</a></h2>
<p>grug think agile not terrible, not good</p>
<p>end of day, not worst way to organize development, maybe better than others grug supposes is fine</p>
<p>danger, however, is agile shaman!  many, many shiney rock lost to agile shaman!</p>
<p>whenever agile project fail, agile shaman say "you didn't do agile right!"  grug note this awfully convenient for agile
shaman, ask more shiney rock better agile train young grugs on agile, danger!</p>
<p>grug tempted reach for club when too much agile talk happen but always stay calm</p>
<p>prototyping, tools and hiring good grugs better key to success software: agile process ok and help some but sometimes hurt taken
too seriously</p>
<p>grug say <a href="https://en.wikipedia.org/wiki/No_Silver_Bullet">no silver club</a> fix all software problems no matter what agile
shaman say (danger!)</p>
<h2><a name="grug-on-refactoring"></a><a href="#grug-on-refactoring">Refactoring</a></h2>
<p>refactoring fine activity and often good idea, especially later in project when code firmed up</p>
<p>however, grug note that many times in career "refactors" go horribly off rails and end up causing more harm than good</p>
<p>grug not sure exactly why some refactors work well, some fail, but grug notice that larger refactor, more
likely failure appear to be</p>
<p>so grug try to keep refactors relatively small and not be "too far out from shore" during refactor.  ideally system work
entire time and each step of finish before other begin.</p>
<p>end-to-end tests are life saver here, but often very hard understand why broke... such is refactor life.</p>
<p>also grug notice that introducing too much abstraction often lead to refactor failure and system failure.  good example
was <a href="https://www.webopedia.com/definitions/j2ee/">J2EE</a> introduce, many big brain sit around thinking too much abstraction, nothing good came of it many project hurt</p>
<p>another good example when company grug work for introduce <a href="https://www.techtarget.com/searchnetworking/definition/OSGi">OSGi</a> to help
manage/trap spriit complexity demon in code base.  not only OSGi not help, but make complexity demon much more powerful!
took multiple man year of best developers to rework as well to boot!  more complex spirit and now features impossible
implement! very bad!</p>
<h2><a name="grug-on-chestertons-fence"></a><a href="#grug-on-chestertons-fence">Chesterton's Fence</a></h2>
<p>wise grug shaman <a href="https://en.wikipedia.org/wiki/G._K._Chesterton">chesterton</a> once say</p>
<blockquote>
<p>here exists in such a case a certain institution or law; let us say, for the sake of simplicity, a fence or gate erected across a road. The more modern type of reformer goes gaily up to it and says, “I don’t see the use of this; let us clear it away.” To which the more intelligent type of reformer will do well to answer: “If you don’t see the use of it, I certainly won’t let you clear it away. Go away and think. Then, when you can come back and tell me that you do see the use of it, I may allow you to destroy it.”</p>
</blockquote>
<p>many older grug learn this lesson well not start tearing code out willy nilly, no matter how ugly look</p>
<p>grug understand all programmer platonists at some level wish music of spheres perfection in code.  but danger is here,
world is ugly and gronky many times and so also must code be</p>
<p>humility not often come big brained or think big brained
easily or grug even, but grug often find "oh, grug no like look of this, grug fix" lead many hours pain grug and no better or system
worse even</p>
<p>grug early on in career often charge into code base waving club wildly and smash up everything, learn not good</p>
<p>grug not say no improve system ever, quite foolish, but recommend take time understand system first especially bigger system is and
is respect code working today even if not perfect</p>
<p>here tests often good hint for why fence not to be smashed!</p>
<h2><a name="grug-on-microservices"></a><a href="#grug-on-microservices">Microservices</a></h2>
<p>grug wonder why big brain take hardest problem, factoring system correctly, and introduce network call too</p>
<p>seem very confusing to grug</p>
<h2><a name="grug-on-tools"></a><a href="#grug-on-tools">Tools</a></h2>
<p>grug love tool.  tool and control passion what separate grug from dinosaurs!  tool allow grug brain to create code that
not possible otherwise by doing thinking for grug, always good relief! grug always spend time in new place learning
tools around him to maximize productivity: learn tools for two weeks make development often twice faster and often
have dig around ask other developers help, no docs</p>
<p>code completion in IDE allow grug not have remembered all API, very important!</p>
<p>java programming nearly impossible without it for grug!</p>
<p>really make grug think some time</p>
<p>good debugger worth weight in shiney rocks, in fact also more: when faced with bug grug would often trade all shiney rock and
perhaps few children for good debugger and anyway debugger no weigh anything far as grug can tell</p>
<p>grug always recommend new programmer learn available debugger very deeply, features like conditional break points, expression
evaluation, stack navigation, etc teach new grug more about computer than university class often!</p>
<p>grug say never be not improving tooling</p>
<h2><a name="grug-on-type-systems"></a><a href="#grug-on-type-systems">Type Systems</a></h2>
<p>grug very like type systems make programming easier.  for grug, type systems most value when grug hit dot on keyboard and
list of things grug can do pop up magic.  this 90% of value of type system or more to grug</p>
<p>big brain type system shaman often say type correctness main point type system, but grug note some big brain type system
shaman not often ship code.  grug suppose code never shipped is correct, in some sense, but not really what grug mean
when say correct</p>
<p>grug say tool magic pop up of what can do and complete of code major most benefit of type system, correctness also good but not
so nearly so much</p>
<p>also, often sometimes caution beware big brains here!</p>
<p>some type big brain think in type systems and talk in lemmas, potential danger!</p>
<p>danger abstraction too high, big brain type system code become astral projection of platonic generic turing model of
computation into code base.  grug confused and agree some level very elegant but also very hard do anything like
record number of club inventory for Grug Inc. task at hand</p>
<p>generics especially dangerous here, grug try limit generics to container classes for most part where most value add</p>
<p>temptation generics very large is trick!  spirit demon complex love this one trick! beware!</p>
<p>always most value type system come: hit dot see what grug can do, never forget!</p>
<h2><a name="grug-on-expression-complexity"></a><a href="#grug-on-expression-complexity">Expression Complexity</a></h2>
<p>grug once like to minimize lines of code much as possible.  write code like this:</p>
<pre><code>  if(contact &amp;&amp; !contact.isActive() &amp;&amp; (contact.inGroup(FAMILY) || contact.inGroup(FRIENDS))) {
    // ...
  }
</code></pre>
<p>over time grug learn this hard debug, learn prefer write like so:</p>
<pre><code>  if(contact) {
    var contactIsInactive = !contact.isActive();
    var contactIsFamilyOrFriends = contact.inGroup(FAMILY) || contact.inGroup(FRIENDS);
    if(contactIsInactive &amp;&amp; contactIsFamilyOrFriends) {
        // ...
    }
  }
</code></pre>
<p>grug hear screams from young grugs at horror of many line of code and pointless variable and grug prepare defend self with club</p>
<p>club fight start with other developers attack and grug yell: "easier debug!  see result of each expression more clearly and good name!  easier
understand conditional expression!  EASIER DEBUG!"</p>
<p>definitely easier debug and once club fight end calm down and young grug think a bit, they realize grug right</p>
<p>grug still catch grug writing code like first example and often regret, so grug not judge young grug</p>
<h2><a name="grug-on-dry"></a><a href="#grug-on-dry">DRY</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">DRY</a> mean Don't Repeat Self, powerful maxim over mind of most
developers</p>
<p>grug respect DRY and good advice, however grug recommend balance in all things, as gruggest big brain aristotle recommend</p>
<p>grug note humourous graph by Lea Verou correspond with grug passion not repeat:</p>
<img alt="code concerns over time" src="https://grugbrain.dev/over-time.png">
<p>over time past ten years program grug not as concerned repeat code.  so long as repeat code simple enough and obvious
enough, and grug begin feel repeat/copy paste code with small variation is better than many callback/closures passed arguments
or elaborate object model: too hard complex for too little benefit at times</p>
<p>hard balance here, repeat code always still make grug stare and say "mmm" often, but experience show repeat code
sometimes often better than complex DRY solution</p>
<p>note well!  grug encourage over literal developer not take does work line too serious, is joke</p>
<h2><a name="grug-on-soc"></a><a href="#grug-on-soc">Separation of Concerns (SoC)</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Separation_of_concerns">Separation of Concern (SoC)</a> another powerful idea over many developer
mind, idea to separate different aspects of system into distinct sections code</p>
<p>canonical example from web development: separation of style (css file), markup (html file) and logic (javascript file)</p>
<p>here grug much more sour faced than DRY and in fact write big brained essay on alternative design principle
<a href="https://htmx.org/essays/locality-of-behaviour/">locality of behavior (LoB)</a> against SoC</p>
<p>grug much prefer put code on the thing that do the thing.  now when grug look at the thing grug know the thing what the
thing do, alwasy good relief!</p>
<p>when separate of concern grug must often all over tarnation many file look understand what how button do, much confuse
and time waste: bad!</p>
<h2><a name="grug-on-closures"></a><a href="#grug-on-closures">Closures</a></h2>
<p>grug like closures for right job and that job usually abstracting operation over collection of objects</p>
<p>grug warn closures like salt, type systems and generics: small amount go long way, but easy spoil things too much use
give heart attack</p>
<p>javascript developers call very special complexity demon spirit in javascript "callback hell" because too much closure
used by javascript libraries very sad but also javascript developer get what deserved let grug be frank</p>
<h2><a name="grug-on-logging"></a><a href="#grug-on-logging">Logging</a></h2>
<p>grug huge fan of logging and encourage lots of it, especially in cloud deployed.  some non-grugs say logging expensive
and not important.  grug used think this way no more</p>
<p>funny story: grug learn idol <a href="https://en.wikipedia.org/wiki/Rob_Pike">rob pike</a> working on logging at google and decide:
"if rob pike working on logging, what grug do there?!?" so not pursue.  turn out logging <em>very</em> important to google so
of course best programmer work on it, grug!</p>
<p>don't be such grug brain, grug, much less shiney rock now!</p>
<p>oh well, grug end up at good company anyway and rob pike dress habit
<a href="https://www.youtube.com/watch?v=KINIAgRpkDA">increasingly erratic</a>, so all work out in end, but
point stand: logging very important!</p>
<p>grug tips on logging are:</p>
<ul>
<li>log all major logical branches within code (if/for)</li>
<li>if "request" span multiple machine in cloud infrastructure, include request ID in all so logs can be grouped</li>
<li>if possible make log level dynamically controlled, so grug can turn on/off when need debug issue (many!)</li>
<li>if possible make log level per user, so can debug specific user issue</li>
</ul>
<p>last two points are especially handy club when fighting bugs in production systems very often</p>
<p>unfortunately log libraries often very complex (java, <a href="https://stackify.com/logging-java/">why you do?</a>) but worth investing
time in getting logging infrastructure "just right" pay off big later in grug experience</p>
<p>logging need taught more in schools, grug think</p>
<h2><a name="grug-on-concurrency"></a><a href="#grug-on-concurrency">Concurrency</a></h2>
<p>grug, like all sane developer, fear concurrency</p>
<p>as much as possible, grug try to rely on simple concurrency models like stateless web request handlers and simple
remote job worker queues where jobs no interdepend and simple api</p>
<p><a href="https://en.wikipedia.org/wiki/Optimistic_concurrency_control">optimistic concurrency</a> seem work well for web stuff</p>
<p>occasionally grug reach for <a href="https://en.wikipedia.org/wiki/Thread-local_storage">thread local variable</a>, usually when
writing framework code</p>
<p>some language have good concurrent data structure, like java <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentHashMap.html">ConcurrentHashMap</a>
but still need careful grug work to get right</p>
<p>grug has never used <a href="https://en.wikipedia.org/wiki/Erlang_(programming_language)">erlang</a>, hear good things, but language
look wierd to grug sorry</p>
<h2><a name="grug-on-optimizing"></a><a href="#grug-on-optimizing">Optimizing</a></h2>
<p>ultra biggest of brain developer once say:</p>
<blockquote>
<p>premature optimization is the root of all evil</p>
</blockquote>
<p>this everyone mostly know and grug in humble violent agreement with ultra biggest of big brain</p>
<p>grug recommend always to have concrete, real world perf profile showing specific perf issue before begin optimizing.</p>
<p>never know what actual issue might be, grug often surprise!  very often!</p>
<p>beware only cpu focus: easy to see cpu and much big o notation thinking having been done in school,
but often not root of all slowness, surprise to many including grug</p>
<p>hitting network equivalent of many, many millions cpu cycle and always to be minimized if possible, note well big brain
microservice developer!</p>
<p>inexperienced big brain developer see nested loop and often say "O(n^2)?  Not on my watch!"</p>
<p>complexity demon spirit smile</p>
<h2><a name="grug-on-apis"></a><a href="#grug-on-apis">APIs</a></h2>
<p>grug love good apis.  good apis not make grug think too much</p>
<p>unfortunately, many apis very bad, make grug think quite a bit.  this happen many reasons, here two:</p>
<ul>
<li>API creators think in terms of implementation or domain of API, rather than in terms of use of API</li>
<li>API creators think too abstract and big brained</li>
</ul>
<p>usually grug not care too deeply about detail of api: want write file or sort list or whatever, just want to call
<code>write()</code> or <code>sort()</code> or whatever</p>
<p>but big brain api developers say:</p>
<p>"not so fast, grug!  is that file <em>open for write</em>? did you define a <em>Comparator</em> for that sort?"</p>
<p>grug find self restraining hand reaching for club again</p>
<p>not care about that stuff right now, just want sort and write file mr big brain!</p>
<p>grug recognize that big brain api designer have point and that <em>sometime</em> these things matter, but often do not.
big brain api developers better if design for simple cases with simple api, make complex cases possible
with more complex api</p>
<p>grug call this "layering" apis: two or three different apis at different level complexity for various grug needs</p>
<p>also, if object oriented, put api on thing instead of elsewhere. java worst at this!</p>
<p>grug want filter list in java</p>
<p>"Did you convert it to a stream?"</p>
<p>fine, grug convert to stream</p>
<p>"OK, now you can filter."</p>
<p>OK, but now need return list!  have stream!</p>
<p>"Well, did you collect your stream into a list?"</p>
<p>what?</p>
<p>"Define a Collector&lt;? super T, A, R&gt; to collect your stream into a list"</p>
<p>grug now swear on ancestor grave he club every single person in room, but count two instead and remain calm</p>
<p>put common thing like <code>filter()</code> on list and make return list, listen well big brain java api developer!</p>
<p>nobody care about "stream" or even hear of "stream" before, is not networking api, all java grugs use list mr big brain!</p>
<h2><a name="grug-on-parsing"></a><a href="#grug-on-parsing">Parsing</a></h2>
<p>grug love make programming language at drop of hat and
say <a href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive descent</a>
most fun and beautiful way create parser</p>
<p>unfortunately many big brain school teach only parser generator tool.  here grug usual love of tool is not: parser
generator tool generate code of awful snakes nest: impossible understand, bottom up, what?  hide recursive nature of
grammar from grug and debug impossible, very bad according grug!</p>
<p>grug think this because while complexity demon bad for code base and understand, complexity demon very good for generation
of much academic papers, sad but true</p>
<p>production parser almost always recursive descent, despite ignore by schools!  grug furious when learn how simple parse
is! parsing not big brain only magic: so can you!</p>
<p>grug very elated find big brain developer Bob Nystrom redeem the big brain tribe and write excellent book on recursive
descent: <a href="https://craftinginterpreters.com/">Crafting Interpreters</a></p>
<p>book available online free, but grug highly recommend all interested grugs purchase book on general principle, provide
much big brain advice and grug love book <em>very</em> much except visitor pattern (trap!)</p>
<h2><a name="grug-on-visitor-pattern"></a><a href="#grug-on-visitor-pattern">The Visitor Pattern</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Visitor_pattern">bad</a></p>
<h2><a name="grug-on-front-end-development"></a><a href="#grug-on-front-end-development">Front End Development</a></h2>
<p>some non-grugs, when faced with web development say:</p>
<p>"I know, I'll split my front end and back end codebase up and use a hot new SPA library talking to a GraphQL JSON API back end
over HTTP (which is funny because I'm not transferring hypertext)"</p>
<p>now you have two complexity demon spirit lairs</p>
<p>and, what is worse, front end complexity demon spirit even more powerful and have deep spiritual hold on entire front end
industry as far as grug can tell</p>
<p>back end developers try keep things simple and can work ok, but front end developers make very complex very quickly and
introduce lots of code, demon complex spirit</p>
<p>even when website just need put form into database or simple brochure site!</p>
<p>everyone do this now!</p>
<p>grug not sure why except maybe facebook and google say so, but that not seem very good reason to grug</p>
<p>grug not like big complex front end libraries everyone use</p>
<p>grug make <a href="https://htmx.org/">htmx</a> and <a href="https://hyperscript.org/">hyperscript</a> to avoid</p>
<p>keep complexity low, simple HTML, avoid lots javascript, the natural ether of spirit complexity demon</p>
<p>maybe they work for you, but no job post, sorry</p>
<p>react better for job and also some type application, but also you become alcolyte of complexity demon whether you like
or no, sorry such is front end life</p>
<h2><a name="grug-on-fads"></a><a href="#grug-on-fads">Fads</a></h2>
<p>grug note lots of fads in development, especially front end development today</p>
<p>back end better more boring because all bad ideas have tried at this point maybe (still retry some!)</p>
<p>still trying all bad ideas in front end development so still much change and hard to know</p>
<p>grug recommend taking all revolutionary new approach with grain salt: big brains have working for long
time on computers now, most ideas have tried at least once</p>
<p>grug not saying can't learn new tricks or no good new ideas, but also much of time wasted on recycled bad ideas, lots of
spirit complexity demon power come from putting new idea willy nilly into code base</p>
<h2><a name="grug-on-fold"></a><a href="#grug-on-fold">Fear Of Looking Dumb</a></h2>
<p>note!  very good if senior grug willing to say publicly: "hmmm, this too complex for grug"!</p>
<p>many developers Fear Of Looking Dumb (FOLD), grug also at one time FOLD, but grug learn get over: very important senior
grug say "this too complicated and confuse to me"</p>
<p>this make it ok for junior grugs to admit too complex and not understand as well, often such case!  FOLD major source of
complexity demon power over developer, especially young grugs!</p>
<p>take FOLD power away, very good of senior grug!</p>
<p>note: important to make thinking face and look big brained when saying though.  be prepare for big brain or, worse and
much more common, <em>thinks</em> is big brain to make snide remark of grug</p>
<p>be strong! no FOLD!</p>
<p>club sometimes useful here, but more often sense of humor and especially last failed project by big brain very useful,
so collect and be calm</p>
<h2><a name="grug-on-imposter-syndrom"></a><a href="#grug-on-imposter-syndrom">Impostor Syndrome</a></h2>
<p>grug note many such impostor feels in development</p>
<p>always grug one of two states: grug is ruler of all survey, wield code club like thor OR grug have no idea what doing</p>
<p>grug is mostly latter state most times, hide it pretty well though</p>
<p>now, grug make softwares of much work and <a href="https://star-history.com/#bigskysoftware/htmx&amp;bigskysoftware/_hyperscript&amp;Date">moderate open source success</a>
, and yet grug himself often feel not any idea what doing!  very often!  grug still fear make mistake break everyone code and
disappoint other grugs, imposter!</p>
<p>is maybe nature of programming for most grug to feel impostor and be ok with is best: nobody imposter if everybody imposter</p>
<p>any young grug read this far probably do fine in program career even if frustrations and worry is always to be there, sorry</p>
<h2><a name="grug-reads"></a><a href="#grug-reads">Reads</a></h2>
<p>grug like these:</p>
<ul>
<li><a href="https://www.dreamsongs.com/WorseIsBetter.html">Worse is Better</a></li>
<li><a href="https://www.dreamsongs.com/Files/worse-is-worse.pdf">Worse is Better is Worse</a></li>
<li><a href="https://www.dreamsongs.com/Files/IsWorseReallyBetter.pdf">Is Worse Really Better?</a></li>
<li><a href="https://www.goodreads.com/en/book/show/39996759-a-philosophy-of-software-design">A Philosophy of Software Design</a></li>
</ul>
<h2><a name="lol-lmao"></a><a href="#lol-lmao">Conclusion</a></h2>
<p><em>you</em> say: complexity <em>very</em>, <em>very</em> bad</p>

  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bzip2 crate switches from C to 100% Rust (123 pts)]]></title>
            <link>https://trifectatech.org/blog/bzip2-crate-switches-from-c-to-rust/</link>
            <guid>44303361</guid>
            <pubDate>Tue, 17 Jun 2025 20:06:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trifectatech.org/blog/bzip2-crate-switches-from-c-to-rust/">https://trifectatech.org/blog/bzip2-crate-switches-from-c-to-rust/</a>, See on <a href="https://news.ycombinator.com/item?id=44303361">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>Today we published <code>bzip2</code> version <code>0.6.0</code>, which uses our rust implementation of the bzip2 algorithm, <code>libbz2-rs-sys</code>, by default. The <code>bzip2</code> crate is now faster and easier to cross-compile.</p>
<p>The <code>libbz2-rs-sys</code> crate can also be built as a C dynamic library, if you have a C project that would benefit from these improvements.</p>
<h2 id="why-though">Why though?</h2>
<p>Why bother working on this algorithm from the 90s that sees very little use today? The thing is that many protocols and libraries still need to support bzip2 to be compliant with their specification, so many project still, deep down in their dependency tree, depend on bzip2. We've used our experience from zlib-rs to modernize the <code>bzip2</code>  implementation.</p>
<p>We've previously written about the implementation details of <code>libbz2-rs-sys</code> in <a href="https://trifectatech.org/blog/translating-bzip2-with-c2rust/">"Translating bzip2 with c2rust"</a>, now let's look at the benefits of this work.</p>
<h3 id="improved-performance">Improved performance</h3>
<p>Our rust implementation generally outperforms the C implementation, though there are a couple of cases where we only match C performance. We are not aware of any cases where we are substantially slower.</p>
<p>For compression, we are a fair amount faster. For bzip2, the <code>level</code> indicates how much working memory is used. It doesn't influence performance by much, and for <code>sample3.ref</code> level 1 already allocates more memory than the file is large, so higher levels are irrelevant.</p>
<table><thead><tr><th>name</th><th>c (cpu cycles)</th><th>rust (cpu cycles)</th><th>Δ</th></tr></thead><tbody>
<tr><td>sample3.ref (level 1)</td><td><code>38.51M ±  77.03K</code></td><td><code>33.53M ±  90.52K</code></td><td><code>-14.87%</code></td></tr>
<tr><td>silesia-small.tar (level 1)</td><td><code> 3.43G ±   2.06M</code></td><td><code> 3.00G ±   6.31M</code></td><td><code>-14.30%</code></td></tr>
<tr><td>silesia-small.tar (level 9)</td><td><code> 3.47G ±   4.86M</code></td><td><code> 3.17G ±   4.43M</code></td><td><code>- 9.66%</code></td></tr>
</tbody></table>
<p>For decompression there is a bit more of a spread, but we again see significant speedups across the board.</p>
<table><thead><tr><th>name</th><th>c (cpu cycles)</th><th>rust (cpu cycles)</th><th>Δ</th></tr></thead><tbody>
<tr><td>sample3.bz2</td><td><code> 2.53M ±  30.08K</code></td><td><code> 2.42M ±   8.95K</code></td><td><code>- 4.48%</code></td></tr>
<tr><td>sample1.bz2</td><td><code> 9.63M ±  40.44K</code></td><td><code> 8.86M ±  10.64K</code></td><td><code>- 8.63%</code></td></tr>
<tr><td>sample2.bz2</td><td><code>20.47M ±  55.28K</code></td><td><code>19.02M ±  36.13K</code></td><td><code>- 7.67%</code></td></tr>
<tr><td>dancing-color.ps.bz2</td><td><code>87.46M ± 481.02K</code></td><td><code>83.16M ± 548.86K</code></td><td><code>- 5.17%</code></td></tr>
<tr><td>re2-exhaustive.txt.bz2</td><td><code> 1.89G ±  12.29M</code></td><td><code> 1.76G ±  12.64M</code></td><td><code>- 7.65%</code></td></tr>
<tr><td>zip64support.tar.bz2</td><td><code> 2.32G ±  12.09M</code></td><td><code> 2.11G ±  15.42M</code></td><td><code>-10.00%</code></td></tr>
</tbody></table>
<p>One caveat is that on our macOS benchmark machine we occasionally see some lower numbers for decompression. We are not sure what causes the variance, and measuring performance on macOS in a detailed way has turned out to be difficult (e.g there is no tool like <code>perf</code> to automate performance tracking that we could get to work).</p>
<h3 id="enabling-cross-compilation">Enabling cross-compilation</h3>
<p>Cross-compilation of a rust project with C dependencies often works out of the box (because the <code>cc</code> crate tries to handle it), but when it doesn't the errors can be hard to debug. Similarly linking to system libraries can cause confusing and hard-to-reproduce issues.</p>
<p>For bzip2, compilation to webassembly has long been an issue. By removing the C dependency and using rust code instead, the complications of compiling C just disappear: cross-compilation just works. Also building for windows or android just works. Besides providing a better experience for users, this change is also a major maintenance win.</p>
<h3 id="symbols-are-not-exported-by-default">Symbols are not exported (by default)</h3>
<p>Using a C dependency means that its symbols are exported (so that a rust <code>extern</code> block can find them). The exported names can conflict when another dependency declares the same symbols.</p>
<p>By default, <code>libbz2-rs-sys</code> does not export its symbols, which means that it will never conflict with other dependencies. If your rust project does need to emit the symbols, there is a feature flag to enable exporting symbols.</p>
<h3 id="run-tests-with-miri">Run tests with miri</h3>
<p>Writing a performant bzip2 implementation requires some unsafe code, and replicating the C interface in rust requires a lot more. Luckily we are able to run that code under MIRI.</p>
<p>More importantly, higher-level libraries or applications that use <code>bzip2</code> can now run with MIRI as well.</p>
<h2 id="audit">Audit</h2>
<p>The audit found one logic bug (an off-by-one error), and fixed some limitations in our fuzzer.
Beyond that, there were no significant findings (yay!).  We do want to thank the reviewers from <a href="https://www.radicallyopensecurity.com/">Radically Open Security</a>, specifically Christian Reitter, for sharing their fuzzing experience. The full audit report can be found <a href="https://github.com/trifectatechfoundation/libbzip2-rs/blob/main/docs/audits/NGICore%20bzip2%20in%20rust%20code%20audit%20report%202025%201.0.pdf">here</a>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The <code>bzip2</code> crate is faster now. You can go back to never having to think about it.</p>
<h3 id="thanks">Thanks</h3>
<ul>
<li><a href="https://github.com/alexcrichton">Alex Crichton</a> for sharing maintainership of the <code>bzip2</code> crate</li>
<li><a href="https://www.radicallyopensecurity.com/">Radically Open Security</a> for the audit and sharing their expertise</li>
<li><a href="https://nlnet.nl/">NLnet Foundation</a> for funding this work</li>
</ul>

                <br>
                
                <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Iran asks its people to delete WhatsApp from their devices (170 pts)]]></title>
            <link>https://apnews.com/article/iran-whatsapp-meta-israel-d9e6fe43280123c9963802e6f10ac8d1</link>
            <guid>44302752</guid>
            <pubDate>Tue, 17 Jun 2025 19:12:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/iran-whatsapp-meta-israel-d9e6fe43280123c9963802e6f10ac8d1">https://apnews.com/article/iran-whatsapp-meta-israel-d9e6fe43280123c9963802e6f10ac8d1</a>, See on <a href="https://news.ycombinator.com/item?id=44302752">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>Iranian state television on Tuesday afternoon urged the country’s public to remove the messaging platform WhatsApp from their smartphones, alleging the app — without offering specific evidence — gathered user information to send to Israel.</p><p>In a statement, WhatsApp said it was “concerned these false reports will be an excuse for our services to be blocked at a time when people need them the most.” WhatsApp uses end-to-end encryption, meaning a service provider in the middle can’t read a message.</p><p>“We do not track your precise location, we don’t keep logs of who everyone is messaging and we do not track the personal messages people are sending one another,” it added. “We do not provide bulk information to any government.”</p><p><span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/privacy-encryption-signal-whatsapp-9faf31ed3411bc5b7cab0647b4ab224d">End-to-end encryption</a></span> means that messages are scrambled so that only the sender and recipient can see them. If anyone else intercepts the message, all they will see is a garble that can’t be unscrambled without the key.</p>
    
<p>WhatsApp is owned by Meta Platforms, the parent company of Facebook and Instagram. </p><p>Iran has blocked access to various social media platforms over the years but many people in the country use proxies and virtual private networks, or VPNs, to access them. It banned WhatsApp and Google Play in 2022 during mass protests against the government over the death of a woman held by the country’s morality police. That ban was <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/iran-social-media-whatsapp-google-d886b47c427f33f96fb85e7c78d0b831">lifted late last year</a></span>.</p><p>WhatsApp had been one of Iran’s most popular messaging apps besides Instagram and Telegram. </p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building Effective AI Agents (228 pts)]]></title>
            <link>https://www.anthropic.com/engineering/building-effective-agents</link>
            <guid>44301809</guid>
            <pubDate>Tue, 17 Jun 2025 17:50:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/engineering/building-effective-agents">https://www.anthropic.com/engineering/building-effective-agents</a>, See on <a href="https://news.ycombinator.com/item?id=44301809">Hacker News</a></p>
<div id="readability-page-1" class="page"><section aria-label="Engineering Article Hero"><a href="https://www.anthropic.com/engineering">Engineering at Anthropic</a></section><div><article><div><p>Over the past year, we've worked with dozens of teams building large language model (LLM) agents across industries. Consistently, the most successful implementations weren't using complex frameworks or specialized libraries. Instead, they were building with simple, composable patterns.</p><p>In this post, we share what we’ve learned from working with our customers and building agents ourselves, and give practical advice for developers on building effective agents.</p><h2 id="what-are-agents">What are agents?</h2><p>"Agent" can be defined in several ways. Some customers define agents as fully autonomous systems that operate independently over extended periods, using various tools to accomplish complex tasks. Others use the term to describe more prescriptive implementations that follow predefined workflows. At Anthropic, we categorize all these variations as <strong>agentic systems</strong>, but draw an important architectural distinction between <strong>workflows </strong>and<strong> agents</strong>:</p><ul><li><strong>Workflows</strong> are systems where LLMs and tools are orchestrated through predefined code paths.</li><li><strong>Agents</strong>, on the other hand, are systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.</li></ul><p>Below, we will explore both types of agentic systems in detail. In Appendix 1 (“Agents in Practice”), we describe two domains where customers have found particular value in using these kinds of systems.</p><h2 id="when-and-when-not-to-use-agents">When (and when not) to use agents</h2><p>When building applications with LLMs, we recommend finding the simplest solution possible, and only increasing complexity when needed. This might mean not building agentic systems at all. Agentic systems often trade latency and cost for better task performance, and you should consider when this tradeoff makes sense.</p><p>When more complexity is warranted, workflows offer predictability and consistency for well-defined tasks, whereas agents are the better option when flexibility and model-driven decision-making are needed at scale. For many applications, however, optimizing single LLM calls with retrieval and in-context examples is usually enough.</p><h2 id="when-and-how-to-use-frameworks">When and how to use frameworks</h2><p>There are many frameworks that make agentic systems easier to implement, including:</p><ul><li><a href="https://langchain-ai.github.io/langgraph/">LangGraph</a> from LangChain;</li><li>Amazon Bedrock's <a href="https://aws.amazon.com/bedrock/agents/">AI Agent framework</a>;</li><li><a href="https://rivet.ironcladapp.com/">Rivet</a>, a drag and drop GUI LLM workflow builder; and</li><li><a href="https://www.vellum.ai/">Vellum</a>, another GUI tool for building and testing complex workflows.</li></ul><p>These frameworks make it easy to get started by simplifying standard low-level tasks like calling LLMs, defining and parsing tools, and chaining calls together. However, they often create extra layers of abstraction that can obscure the underlying prompts ​​and responses, making them harder to debug. They can also make it tempting to add complexity when a simpler setup would suffice.</p><p>We suggest that developers start by using LLM APIs directly: many patterns can be implemented in a few lines of code. If you do use a framework, ensure you understand the underlying code. Incorrect assumptions about what's under the hood are a common source of customer error.</p><p>See our <a href="https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents">cookbook</a> for some sample implementations.</p><h2 id="building-blocks-workflows-and-agents">Building blocks, workflows, and agents</h2><p>In this section, we’ll explore the common patterns for agentic systems we’ve seen in production. We'll start with our foundational building block—the augmented LLM—and progressively increase complexity, from simple compositional workflows to autonomous agents.</p><h3 id="building-block-the-augmented-llm">Building block: The augmented LLM</h3><p>The basic building block of agentic systems is an LLM enhanced with augmentations such as retrieval, tools, and memory. Our current models can actively use these capabilities—generating their own search queries, selecting appropriate tools, and determining what information to retain.</p><div><figure><img loading="lazy" width="2401" height="1000" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fd3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fd3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.png&amp;w=3840&amp;q=75"><figcaption>The augmented LLM</figcaption></figure></div><p>We recommend focusing on two key aspects of the implementation: tailoring these capabilities to your specific use case and ensuring they provide an easy, well-documented interface for your LLM. While there are many ways to implement these augmentations, one approach is through our recently released <a href="https://www.anthropic.com/news/model-context-protocol">Model Context Protocol</a>, which allows developers to integrate with a growing ecosystem of third-party tools with a simple <a href="https://modelcontextprotocol.io/tutorials/building-a-client#building-mcp-clients">client implementation</a>.</p><p>For the remainder of this post, we'll assume each LLM call has access to these augmented capabilities.</p><h3 id="workflow-prompt-chaining">Workflow: Prompt chaining</h3><p>Prompt chaining decomposes a task into a sequence of steps, where each LLM call processes the output of the previous one. You can add programmatic checks (see "gate” in the diagram below) on any intermediate steps to ensure that the process is still on track.</p><div><figure><img loading="lazy" width="2401" height="1000" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7418719e3dab222dccb379b8879e1dc08ad34c78-2401x1000.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7418719e3dab222dccb379b8879e1dc08ad34c78-2401x1000.png&amp;w=3840&amp;q=75"><figcaption>The prompt chaining workflow</figcaption></figure></div><p><strong>When to use this workflow:</strong> This workflow is ideal for situations where the task can be easily and cleanly decomposed into fixed subtasks. The main goal is to trade off latency for higher accuracy, by making each LLM call an easier task.</p><p><strong>Examples where prompt chaining is useful:</strong></p><ul><li>Generating Marketing copy, then translating it into a different language.</li><li>Writing an outline of a document, checking that the outline meets certain criteria, then writing the document based on the outline.</li></ul><h3 id="workflow-routing">Workflow: Routing</h3><p>Routing classifies an input and directs it to a specialized followup task. This workflow allows for separation of concerns, and building more specialized prompts. Without this workflow, optimizing for one kind of input can hurt performance on other inputs.</p><div><figure><img loading="lazy" width="2401" height="1000" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.png&amp;w=3840&amp;q=75"><figcaption>The routing workflow</figcaption></figure></div><p><strong>When to use this workflow:</strong> Routing works well for complex tasks where there are distinct categories that are better handled separately, and where classification can be handled accurately, either by an LLM or a more traditional classification model/algorithm.</p><p><strong>Examples where routing is useful:</strong></p><ul><li>Directing different types of customer service queries (general questions, refund requests, technical support) into different downstream processes, prompts, and tools.</li><li>Routing easy/common questions to smaller models like Claude 3.5 Haiku and hard/unusual questions to more capable models like Claude 3.5 Sonnet to optimize cost and speed.</li></ul><h3 id="workflow-parallelization">Workflow: Parallelization</h3><p>LLMs can sometimes work simultaneously on a task and have their outputs aggregated programmatically. This workflow, parallelization, manifests in two key variations:</p><ul><li><strong>Sectioning</strong>: Breaking a task into independent subtasks run in parallel.</li><li><strong>Voting:</strong> Running the same task multiple times to get diverse outputs.</li></ul><div><figure><img loading="lazy" width="2401" height="1000" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.png&amp;w=3840&amp;q=75"><figcaption>The parallelization workflow</figcaption></figure></div><p><strong>When to use this workflow:</strong> Parallelization is effective when the divided subtasks can be parallelized for speed, or when multiple perspectives or attempts are needed for higher confidence results. For complex tasks with multiple considerations, LLMs generally perform better when each consideration is handled by a separate LLM call, allowing focused attention on each specific aspect.</p><p><strong>Examples where parallelization is useful:</strong></p><ul><li><strong>Sectioning</strong>:<ul><li>Implementing guardrails where one model instance processes user queries while another screens them for inappropriate content or requests. This tends to perform better than having the same LLM call handle both guardrails and the core response.</li><li>Automating evals for evaluating LLM performance, where each LLM call evaluates a different aspect of the model’s performance on a given prompt.</li></ul></li><li><strong>Voting</strong>:<ul><li>Reviewing a piece of code for vulnerabilities, where several different prompts review and flag the code if they find a problem.</li><li>Evaluating whether a given piece of content is inappropriate, with multiple prompts evaluating different aspects or requiring different vote thresholds to balance false positives and negatives.</li></ul></li></ul><h3 id="workflow-orchestrator-workers">Workflow: Orchestrator-workers</h3><p>In the orchestrator-workers workflow, a central LLM dynamically breaks down tasks, delegates them to worker LLMs, and synthesizes their results.</p><div><figure><img loading="lazy" width="2401" height="1000" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png&amp;w=3840&amp;q=75"><figcaption>The orchestrator-workers workflow</figcaption></figure></div><p><strong>When to use this workflow:</strong> This workflow is well-suited for complex tasks where you can’t predict the subtasks needed (in coding, for example, the number of files that need to be changed and the nature of the change in each file likely depend on the task). Whereas it’s topographically similar, the key difference from parallelization is its flexibility—subtasks aren't pre-defined, but determined by the orchestrator based on the specific input.</p><p><strong>Example where orchestrator-workers is useful:</strong></p><ul><li>Coding products that make complex changes to multiple files each time.</li><li>Search tasks that involve gathering and analyzing information from multiple sources for possible relevant information.</li></ul><h3 id="workflow-evaluator-optimizer">Workflow: Evaluator-optimizer</h3><p>In the evaluator-optimizer workflow, one LLM call generates a response while another provides evaluation and feedback in a loop.</p><div><figure><img loading="lazy" width="2401" height="1000" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.png&amp;w=3840&amp;q=75"><figcaption>The evaluator-optimizer workflow</figcaption></figure></div><p><strong>When to use this workflow:</strong> This workflow is particularly effective when we have clear evaluation criteria, and when iterative refinement provides measurable value. The two signs of good fit are, first, that LLM responses can be demonstrably improved when a human articulates their feedback; and second, that the LLM can provide such feedback. This is analogous to the iterative writing process a human writer might go through when producing a polished document.</p><p><strong>Examples where evaluator-optimizer is useful:</strong></p><ul><li>Literary translation where there are nuances that the translator LLM might not capture initially, but where an evaluator LLM can provide useful critiques.</li><li>Complex search tasks that require multiple rounds of searching and analysis to gather comprehensive information, where the evaluator decides whether further searches are warranted.</li></ul><h3 id="agents">Agents</h3><p>Agents are emerging in production as LLMs mature in key capabilities—understanding complex inputs, engaging in reasoning and planning, using tools reliably, and recovering from errors. Agents begin their work with either a command from, or interactive discussion with, the human user. Once the task is clear, agents plan and operate independently, potentially returning to the human for further information or judgement. During execution, it's crucial for the agents to gain “ground truth” from the environment at each step (such as tool call results or code execution) to assess its progress. Agents can then pause for human feedback at checkpoints or when encountering blockers. The task often terminates upon completion, but it’s also common to include stopping conditions (such as a maximum number of iterations) to maintain control.</p><p>Agents can handle sophisticated tasks, but their implementation is often straightforward. They are typically just LLMs using tools based on environmental feedback in a loop. It is therefore crucial to design toolsets and their documentation clearly and thoughtfully. We expand on best practices for tool development in Appendix 2 ("Prompt Engineering your Tools").</p><div><figure><img loading="lazy" width="2401" height="1000" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F58d9f10c985c4eb5d53798dea315f7bb5ab6249e-2401x1000.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F58d9f10c985c4eb5d53798dea315f7bb5ab6249e-2401x1000.png&amp;w=3840&amp;q=75"><figcaption>Autonomous agent</figcaption></figure></div><p><strong>When to use agents:</strong> Agents can be used for open-ended problems where it’s difficult or impossible to predict the required number of steps, and where you can’t hardcode a fixed path. The LLM will potentially operate for many turns, and you must have some level of trust in its decision-making. Agents' autonomy makes them ideal for scaling tasks in trusted environments.</p><p>The autonomous nature of agents means higher costs, and the potential for compounding errors. We recommend extensive testing in sandboxed environments, along with the appropriate guardrails.</p><p><strong>Examples where agents are useful:</strong></p><p>The following examples are from our own implementations:</p><ul><li>A coding Agent to resolve <a href="https://www.anthropic.com/research/swe-bench-sonnet">SWE-bench tasks</a>, which involve edits to many files based on a task description;</li><li>Our <a href="https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo">“computer use” reference implementation</a>, where Claude uses a computer to accomplish tasks.</li></ul><div><figure><img loading="lazy" width="2400" height="1666" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F4b9a1f4eb63d5962a6e1746ac26bbc857cf3474f-2400x1666.png&amp;w=3840&amp;q=75 1x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F4b9a1f4eb63d5962a6e1746ac26bbc857cf3474f-2400x1666.png&amp;w=3840&amp;q=75"><figcaption>High-level flow of a coding agent</figcaption></figure></div><h2 id="combining-and-customizing-these-patterns">Combining and customizing these patterns</h2><p>These building blocks aren't prescriptive. They're common patterns that developers can shape and combine to fit different use cases. The key to success, as with any LLM features, is measuring performance and iterating on implementations. To repeat: you should consider adding complexity <em>only</em> when it demonstrably improves outcomes.</p><h2 id="summary">Summary</h2><p>Success in the LLM space isn't about building the most sophisticated system. It's about building the <em>right</em> system for your needs. Start with simple prompts, optimize them with comprehensive evaluation, and add multi-step agentic systems only when simpler solutions fall short.</p><p>When implementing agents, we try to follow three core principles:</p><ol><li>Maintain <strong>simplicity</strong> in your agent's design.</li><li>Prioritize <strong>transparency</strong> by explicitly showing the agent’s planning steps.</li><li>Carefully craft your agent-computer interface (ACI) through thorough tool <strong>documentation and testing</strong>.</li></ol><p>Frameworks can help you get started quickly, but don't hesitate to reduce abstraction layers and build with basic components as you move to production. By following these principles, you can create agents that are not only powerful but also reliable, maintainable, and trusted by their users.</p><h3 id="acknowledgements">Acknowledgements</h3><p>Written by Erik Schluntz and Barry Zhang. This work draws upon our experiences building agents at Anthropic and the valuable insights shared by our customers, for which we're deeply grateful.</p><h2 id="appendix-1-agents-in-practice">Appendix 1: Agents in practice</h2><p>Our work with customers has revealed two particularly promising applications for AI agents that demonstrate the practical value of the patterns discussed above. Both applications illustrate how agents add the most value for tasks that require both conversation and action, have clear success criteria, enable feedback loops, and integrate meaningful human oversight.</p><h3 id="a-customer-support">A. Customer support</h3><p>Customer support combines familiar chatbot interfaces with enhanced capabilities through tool integration. This is a natural fit for more open-ended agents because:</p><ul><li>Support interactions naturally follow a conversation flow while requiring access to external information and actions;</li><li>Tools can be integrated to pull customer data, order history, and knowledge base articles;</li><li>Actions such as issuing refunds or updating tickets can be handled programmatically; and</li><li>Success can be clearly measured through user-defined resolutions.</li></ul><p>Several companies have demonstrated the viability of this approach through usage-based pricing models that charge only for successful resolutions, showing confidence in their agents' effectiveness.</p><h3 id="b-coding-agents">B. Coding agents</h3><p>The software development space has shown remarkable potential for LLM features, with capabilities evolving from code completion to autonomous problem-solving. Agents are particularly effective because:</p><ul><li>Code solutions are verifiable through automated tests;</li><li>Agents can iterate on solutions using test results as feedback;</li><li>The problem space is well-defined and structured; and</li><li>Output quality can be measured objectively.</li></ul><p>In our own implementation, agents can now solve real GitHub issues in the <a href="https://www.anthropic.com/research/swe-bench-sonnet">SWE-bench Verified</a> benchmark based on the pull request description alone. However, whereas automated testing helps verify functionality, human review remains crucial for ensuring solutions align with broader system requirements.</p><h2 id="appendix-2-prompt-engineering-your-tools">Appendix 2: Prompt engineering your tools</h2><p>No matter which agentic system you're building, tools will likely be an important part of your agent. <a href="https://www.anthropic.com/news/tool-use-ga">Tools</a> enable Claude to interact with external services and APIs by specifying their exact structure and definition in our API. When Claude responds, it will include a <a href="https://docs.anthropic.com/en/docs/build-with-claude/tool-use#example-api-response-with-a-tool-use-content-block">tool use block</a> in the API response if it plans to invoke a tool. Tool definitions and specifications should be given just as much prompt engineering attention as your overall prompts. In this brief appendix, we describe how to prompt engineer your tools.</p><p>There are often several ways to specify the same action. For instance, you can specify a file edit by writing a diff, or by rewriting the entire file. For structured output, you can return code inside markdown or inside JSON. In software engineering, differences like these are cosmetic and can be converted losslessly from one to the other. However, some formats are much more difficult for an LLM to write than others. Writing a diff requires knowing how many lines are changing in the chunk header before the new code is written. Writing code inside JSON (compared to markdown) requires extra escaping of newlines and quotes.</p><p>Our suggestions for deciding on tool formats are the following:</p><ul><li>Give the model enough tokens to "think" before it writes itself into a corner.</li><li>Keep the format close to what the model has seen naturally occurring in text on the internet.</li><li>Make sure there's no formatting "overhead" such as having to keep an accurate count of thousands of lines of code, or string-escaping any code it writes.</li></ul><p>One rule of thumb is to think about how much effort goes into human-computer interfaces (HCI), and plan to invest just as much effort in creating good <em>agent</em>-computer interfaces (ACI). Here are some thoughts on how to do so:</p><ul><li>Put yourself in the model's shoes. Is it obvious how to use this tool, based on the description and parameters, or would you need to think carefully about it? If so, then it’s probably also true for the model. A good tool definition often includes example usage, edge cases, input format requirements, and clear boundaries from other tools.</li><li>How can you change parameter names or descriptions to make things more obvious? Think of this as writing a great docstring for a junior developer on your team. This is especially important when using many similar tools.</li><li>Test how the model uses your tools: Run many example inputs in our <a href="https://console.anthropic.com/workbench">workbench</a> to see what mistakes the model makes, and iterate.</li><li><a href="https://en.wikipedia.org/wiki/Poka-yoke">Poka-yoke</a> your tools. Change the arguments so that it is harder to make mistakes.</li></ul><p>While building our agent for <a href="https://www.anthropic.com/research/swe-bench-sonnet">SWE-bench</a>, we actually spent more time optimizing our tools than the overall prompt. For example, we found that the model would make mistakes with tools using relative filepaths after the agent had moved out of the root directory. To fix this, we changed the tool to always require absolute filepaths—and we found that the model used this method flawlessly.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Resurrecting a dead torrent tracker and finding 3M peers (339 pts)]]></title>
            <link>https://kianbradley.com/2025/06/15/resurrecting-a-dead-tracker.html</link>
            <guid>44301686</guid>
            <pubDate>Tue, 17 Jun 2025 17:40:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kianbradley.com/2025/06/15/resurrecting-a-dead-tracker.html">https://kianbradley.com/2025/06/15/resurrecting-a-dead-tracker.html</a>, See on <a href="https://news.ycombinator.com/item?id=44301686">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>So I was uh, downloading some linux isos, like usual. It was going slowly, so I opened up the <code>Trackers</code> tab in qBittorrent and saw the following:</p>

<p><img src="https://kianbradley.com/assets/tracker-list.png" alt="List of trackers... most of them unreachable"></p>

<p><strong>Most of the trackers were totally dead.</strong> Either the hosts were down or the domains weren’t being used.</p>

<p>That got me thinking. <strong>What if <em>I</em> picked up one of these dead domains?</strong> How many clients would try to connect?</p>

<h2 id="what-are-trackers-for-anyways">What are trackers for, anyways?</h2>

<p>A <em>tracker</em> is a core component of the <a href="https://en.wikipedia.org/wiki/BitTorrent">BitTorrent protocol</a>. Trackers are the services that point you to other peers for the torrent. Without trackers, there would be no one to share the file with.</p>

<p>Obviously this represents a major source of centralization in the torrent protocol. If your trackers aren’t maintained – or if they get forced offline by certain industry organizations – you’re out of luck.</p>

<p>We have an alternative, called <a href="https://en.wikipedia.org/wiki/Mainline_DHT">Mainline DHT</a>, which performs a more decentralized lookup of peers based on infohash alone. DHT isn’t perfect, though. It relies on <a href="https://stackoverflow.com/questions/1181301/how-does-a-dht-in-a-bittorent-client-get-bootstrapped">bootstrap nodes</a> and is vulnerable to <a href="https://www.bittorrent.org/beps/bep_0042.html">Sybil attacks</a>. And in the example of my poorly-served torrent, DHT wasn’t surfacing any peers, regardless.</p>

<h2 id="hosting-a-tracker">Hosting a tracker</h2>

<p>Looking through the list of trackers marked “host not found”, I noticed <code>udp://open.demonii.si:1337/announce</code> was available.</p>

<p>I bought the domain through <a href="https://www.dynadot.com/">Dynadot</a> (one of the few .si domain registrars), then spun up a <a href="https://cockbox.org/">quick anonymous VPS</a>. I mapped the domain to the VPS, then set up <a href="https://erdgeist.org/arts/software/opentracker/">opentracker</a>, the most widely used and robust torrent tracker software.</p>

<p>Instructions for Ubuntu 24.04:</p>

<figure><pre><code data-lang="bash"><span>sudo </span>apt <span>install </span>gcc-14 g++-14 build-essential zlib1g-dev
<span>sudo </span>update-alternatives <span>--install</span> /usr/bin/gcc gcc /usr/bin/gcc-14 14
<span>sudo </span>update-alternatives <span>--install</span> /usr/bin/g++ g++ /usr/bin/g++-14 14</code></pre></figure>

<p>Follow the <a href="https://erdgeist.org/gitweb/opentracker/tree/README">readme</a> to compile, first the dependency <a href="https://www.fefe.de/libowfat/">libowfat</a> (a GPL reimplementation of some of <a href="https://cr.yp.to/djb.html">dan bernstein</a>’s C libraries) and then opentracker itself.</p>

<figure><pre><code data-lang="bash">cvs <span>-d</span> :pserver:cvs@cvs.fefe.de:/cvs <span>-z9</span> co libowfat
<span>cd </span>libowfat
make
<span>cd</span> ..
git clone git://erdgeist.org/opentracker
<span>cd </span>opentracker
make</code></pre></figure>

<p>Finally, a quick systemd unit file to daemonize this service:</p>

<figure><pre><code data-lang="bash"><span>[</span>Unit]
<span>Description</span><span>=</span>opentracker
<span>After</span><span>=</span>network-online.target
<span>Wants</span><span>=</span>network-online.target

<span>[</span>Service]
<span>Type</span><span>=</span>simple
<span>User</span><span>=</span>opentracker
<span>Group</span><span>=</span>opentracker
<span>WorkingDirectory</span><span>=</span>/var/lib/opentracker
<span>ExecStart</span><span>=</span>/home/opentracker/opentracker/opentracker <span>-p</span> 1337 <span>-P</span> 1337 <span>\</span>
          <span>-d</span> /var/lib/opentracker <span>-u</span> opentracker
<span>Restart</span><span>=</span>on-failure
<span>LimitNOFILE</span><span>=</span>65536

<span>[</span>Install]
<span>WantedBy</span><span>=</span>multi-user.target</code></pre></figure>

<h2 id="what-did-i-find">What did I find?</h2>

<p>Before even starting opentracker, I saw a flood of traffic against UDP port 1337:</p>

<video controls="" src="https://kianbradley.com/assets/tcpdump.mp4" alt="Flood of UDP traffic reported by tcpdump"></video>

<p>I then started the tracker. After about an hour, it peaked at about <strong>1.7 million distinct torrents across 3.1 million peers!</strong></p>

<p>Response from <code>http://open.demonii.si:1337/stats?mode=everything</code>:</p>

<figure><pre><code data-lang="xml"><span>&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span>&lt;stats&gt;</span>
  <span>&lt;tracker_id&gt;</span>273419141<span>&lt;/tracker_id&gt;</span>
  <span>&lt;version&gt;</span>
https://erdgeist.org/gitweb/opentracker/commit/?id=b20b0b89264e9d28ab873b8b1cc9ba73cdb58aeb
  <span>&lt;/version&gt;</span>
  <span>&lt;uptime&gt;</span>10313<span>&lt;/uptime&gt;</span>
  <span>&lt;torrents&gt;</span>
    <span>&lt;count_mutex&gt;</span>1735538<span>&lt;/count_mutex&gt;</span>
    <span>&lt;count_iterator&gt;</span>1735523<span>&lt;/count_iterator&gt;</span>
  <span>&lt;/torrents&gt;</span>
  <span>&lt;peers&gt;</span>
    <span>&lt;count&gt;</span>3155701<span>&lt;/count&gt;</span>
  <span>&lt;/peers&gt;</span>
  <span>&lt;seeds&gt;</span>
    <span>&lt;count&gt;</span>1342504<span>&lt;/count&gt;</span>
  <span>&lt;/seeds&gt;</span>
  <span>&lt;completed&gt;</span>
    <span>&lt;count&gt;</span>244224<span>&lt;/count&gt;</span>
  <span>&lt;/completed&gt;</span>
  <span>&lt;connections&gt;</span>
    <span>&lt;tcp&gt;</span>
      <span>&lt;accept&gt;</span>21532<span>&lt;/accept&gt;</span>
      <span>&lt;announce&gt;</span>20219<span>&lt;/announce&gt;</span>
      <span>&lt;scrape&gt;</span>263<span>&lt;/scrape&gt;</span>
    <span>&lt;/tcp&gt;</span>
    <span>&lt;udp&gt;</span>
      <span>&lt;overall&gt;</span>58843612<span>&lt;/overall&gt;</span>
      <span>&lt;connect&gt;</span>18321703<span>&lt;/connect&gt;</span>
      <span>&lt;announce&gt;</span>33160261<span>&lt;/announce&gt;</span>
      <span>&lt;scrape&gt;</span>3211543<span>&lt;/scrape&gt;</span>
      <span>&lt;missmatch&gt;</span>4116689<span>&lt;/missmatch&gt;</span>
    <span>&lt;/udp&gt;</span>
    <span>&lt;livesync&gt;</span>
      <span>&lt;count&gt;</span>0<span>&lt;/count&gt;</span>
    <span>&lt;/livesync&gt;</span>
  <span>&lt;/connections&gt;</span>
  <span>&lt;debug&gt;</span>
    <span>&lt;renew&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"00"</span><span>&gt;</span>12216193<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"01"</span><span>&gt;</span>1463740<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"02"</span><span>&gt;</span>536527<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"03"</span><span>&gt;</span>284756<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"04"</span><span>&gt;</span>243276<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"05"</span><span>&gt;</span>93237<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"06"</span><span>&gt;</span>63618<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"07"</span><span>&gt;</span>53934<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"08"</span><span>&gt;</span>36851<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"09"</span><span>&gt;</span>28990<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"10"</span><span>&gt;</span>352150<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"11"</span><span>&gt;</span>56610<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"12"</span><span>&gt;</span>24557<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"13"</span><span>&gt;</span>21628<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"14"</span><span>&gt;</span>24932<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"15"</span><span>&gt;</span>63250<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"16"</span><span>&gt;</span>38174<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"17"</span><span>&gt;</span>33730<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"18"</span><span>&gt;</span>27827<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"19"</span><span>&gt;</span>27166<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"20"</span><span>&gt;</span>22463<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"21"</span><span>&gt;</span>17820<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"22"</span><span>&gt;</span>17248<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"23"</span><span>&gt;</span>17276<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"24"</span><span>&gt;</span>17825<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"25"</span><span>&gt;</span>20144<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"26"</span><span>&gt;</span>27987<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"27"</span><span>&gt;</span>792338<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"28"</span><span>&gt;</span>1579577<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"29"</span><span>&gt;</span>1625355<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"30"</span><span>&gt;</span>2229105<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"31"</span><span>&gt;</span>1670317<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"32"</span><span>&gt;</span>1581574<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"33"</span><span>&gt;</span>846355<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"34"</span><span>&gt;</span>96656<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"35"</span><span>&gt;</span>68160<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"36"</span><span>&gt;</span>47801<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"37"</span><span>&gt;</span>36705<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"38"</span><span>&gt;</span>32256<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"39"</span><span>&gt;</span>27535<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"40"</span><span>&gt;</span>27593<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"41"</span><span>&gt;</span>27640<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"42"</span><span>&gt;</span>24090<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"43"</span><span>&gt;</span>20762<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>interval=</span><span>"44"</span><span>&gt;</span>17880<span>&lt;/count&gt;</span>
    <span>&lt;/renew&gt;</span>
    <span>&lt;http_error&gt;</span>
      <span>&lt;count</span> <span>code=</span><span>"302 Redirect"</span><span>&gt;</span>0<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>code=</span><span>"400 Parse Error"</span><span>&gt;</span>0<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>code=</span><span>"400 Invalid Parameter"</span><span>&gt;</span>55<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>code=</span><span>"400 Invalid Parameter (compact=0)"</span><span>&gt;</span>0<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>code=</span><span>"400 Not Modest"</span><span>&gt;</span>0<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>code=</span><span>"402 Payment Required"</span><span>&gt;</span>0<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>code=</span><span>"403 Access Denied"</span><span>&gt;</span>0<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>code=</span><span>"404 Not found"</span><span>&gt;</span>883<span>&lt;/count&gt;</span>
      <span>&lt;count</span> <span>code=</span><span>"500 Internal Server Error"</span><span>&gt;</span>0<span>&lt;/count&gt;</span>
    <span>&lt;/http_error&gt;</span>
    <span>&lt;mutex_stall&gt;</span>
      <span>&lt;count&gt;</span>0<span>&lt;/count&gt;</span>
    <span>&lt;/mutex_stall&gt;</span>
  <span>&lt;/debug&gt;</span>
<span>&lt;/stats&gt;</span></code></pre></figure>

<h2 id="is-this-legal">Is this legal?</h2>

<p>Maybe.</p>

<p>When the recording industry and other litigious organizations go after torrent trackers, they’re mainly chasing down the public-facing parts of the system. The legal decisions against websites like The Pirate Bay hinge on how they highlight popular movies, sell ads, and offer .torrent files. This is all taken as evidence of <strong>inducement</strong>, meaning the <em>intentional promotion</em> of copyright infringement.</p>

<p>Does hosting tracker infrastructure, unadvertised, count as “inducement”? It’s a harder case to make. I’m aware that many torrents, both freely available and copyrighted, use this tracker. But it would be more difficult to prove intent here.</p>

<p>Regardless, I was spooked. I thought through my chain of events and realized I had already fucked up by paying for the domain with a credit card. I shut down the VPS and deleted the domain quickly after confirming it works.</p>

<p>So… the domain is available now. It’s quite easy to find unclaimed domains like this. If you want to do a public service, <em>open.demonii.si</em> and others are up for registration…</p>

  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AMD's CDNA 4 Architecture Announcement (101 pts)]]></title>
            <link>https://chipsandcheese.com/p/amds-cdna-4-architecture-announcement</link>
            <guid>44301660</guid>
            <pubDate>Tue, 17 Jun 2025 17:38:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/p/amds-cdna-4-architecture-announcement">https://chipsandcheese.com/p/amds-cdna-4-architecture-announcement</a>, See on <a href="https://news.ycombinator.com/item?id=44301660">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>CDNA 4 is AMD’s latest compute oriented GPU architecture, and represents a modest update over CDNA 3. CDNA 4’s focus is primarily on boosting AMD’s matrix multiplication performance with lower precision data types. Those operations are important for machine learning workloads, which can often maintain acceptable accuracy with very low precision types. At the same time, CDNA 4 seeks to maintain AMD’s lead in more widely applicable vector operations.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b4bd5-a5f6-4377-8cba-f5ea5ffda06e_1055x758.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b4bd5-a5f6-4377-8cba-f5ea5ffda06e_1055x758.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b4bd5-a5f6-4377-8cba-f5ea5ffda06e_1055x758.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b4bd5-a5f6-4377-8cba-f5ea5ffda06e_1055x758.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b4bd5-a5f6-4377-8cba-f5ea5ffda06e_1055x758.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b4bd5-a5f6-4377-8cba-f5ea5ffda06e_1055x758.png" width="1055" height="758" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/856b4bd5-a5f6-4377-8cba-f5ea5ffda06e_1055x758.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:758,&quot;width&quot;:1055,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;From AMD's whitepaper&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="From AMD's whitepaper" title="From AMD's whitepaper" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b4bd5-a5f6-4377-8cba-f5ea5ffda06e_1055x758.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b4bd5-a5f6-4377-8cba-f5ea5ffda06e_1055x758.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b4bd5-a5f6-4377-8cba-f5ea5ffda06e_1055x758.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b4bd5-a5f6-4377-8cba-f5ea5ffda06e_1055x758.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>To do so, CDNA 4 largely uses the same system level architecture as CDNA 3. It’s massive chiplet setup, with parallels to AMD’s successful use of chiplets for CPU products. Accelerator Compute Dies, or XCDs, contain CDNA Compute Units and serve a role analogous to Core Complex Dies (CCDs) on AMD’s CPU products. Eight XCDs sit atop four base dies, which implement 256 MB of memory side cache. AMD’s Infinity Fabric provides coherent memory access across the system, which can span multiple chips.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb62c4acf-bb78-4e3a-a169-e06e770da3bc_1005x581.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb62c4acf-bb78-4e3a-a169-e06e770da3bc_1005x581.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb62c4acf-bb78-4e3a-a169-e06e770da3bc_1005x581.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb62c4acf-bb78-4e3a-a169-e06e770da3bc_1005x581.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb62c4acf-bb78-4e3a-a169-e06e770da3bc_1005x581.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb62c4acf-bb78-4e3a-a169-e06e770da3bc_1005x581.png" width="1005" height="581" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b62c4acf-bb78-4e3a-a169-e06e770da3bc_1005x581.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:581,&quot;width&quot;:1005,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:98710,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/166048376?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb62c4acf-bb78-4e3a-a169-e06e770da3bc_1005x581.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb62c4acf-bb78-4e3a-a169-e06e770da3bc_1005x581.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb62c4acf-bb78-4e3a-a169-e06e770da3bc_1005x581.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb62c4acf-bb78-4e3a-a169-e06e770da3bc_1005x581.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb62c4acf-bb78-4e3a-a169-e06e770da3bc_1005x581.png 1456w" sizes="100vw"></picture></div></a></figure></div><p>Compared to the CDNA 3 based MI300X, the CDNA 4 equipped MI355X slightly cuts down CU count per XCD, and disables more CUs to maintain yields. The resulting GPU is somewhat less wide, but makes up much of the gap with higher clock speeds. Compared to Nvidia’s B200, both MI355X and MI300 are larger GPUs with far more basic building blocks. Nvidia’s B200 does adopt a multi-die strategy, breaking from a long tradition of using monolithic designs. However, AMD’s chiplet setup is far more aggressive and seeks to replicate their scaling success with CPU designs with large compute GPUs.</p><p><span>CDNA 3 provided a huge vector throughput advantage over Nvidia’s H100, but faced a more complicated situation with machine learning workloads. Thanks to a mature software ecosystem and a heavy focus on matrix multiplication throughput (tensor cores), Nvidia could often get close (</span><a href="https://chipsandcheese.com/p/testing-amds-giant-mi300x" rel="">https://chipsandcheese.com/p/testing-amds-giant-mi300x</a><span>) to the nominally far larger MI300X. AMD of course maintained massive wins if the H100 ran out of VRAM, but there was definitely room for improvement.</span></p><p>CDNA 4 rebalances its execution units to more closely target matrix multiplication with lower precision data types, which is precisely what machine learning workloads use. Per-CU matrix throughput doubles in many cases, with CDNA 4 CUs matching Nvidia’s B200 SMs in FP6. Elsewhere though, Nvidia continues to show a stronger emphasis on low precision matrix throughput. B200 SMs have twice as much per-clock throughput as a CDNA 4 CU across a range of 16-bit and 8-bit data types. AMD continues to rely on having a bigger, higher clocked GPU to maintain an overall throughput lead.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F635bc260-858d-426d-8dab-6e574f8695d0_369x238.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F635bc260-858d-426d-8dab-6e574f8695d0_369x238.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F635bc260-858d-426d-8dab-6e574f8695d0_369x238.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F635bc260-858d-426d-8dab-6e574f8695d0_369x238.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F635bc260-858d-426d-8dab-6e574f8695d0_369x238.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F635bc260-858d-426d-8dab-6e574f8695d0_369x238.png" width="369" height="238" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/635bc260-858d-426d-8dab-6e574f8695d0_369x238.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:238,&quot;width&quot;:369,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F635bc260-858d-426d-8dab-6e574f8695d0_369x238.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F635bc260-858d-426d-8dab-6e574f8695d0_369x238.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F635bc260-858d-426d-8dab-6e574f8695d0_369x238.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F635bc260-858d-426d-8dab-6e574f8695d0_369x238.png 1456w" sizes="100vw"></picture></div></a></figure></div><p>With vector operations and higher precision data types, AMD continues MI300X’s massive advantage. Each CDNA 4 CU continues to have 128 FP32 lanes, which deliver 256 FLOPS per cycle when counting FMA operations. MI355X’s lower CU count does lead to a slight reduction in vector performance compared to MI300X. But compared to Nvidia’s Blackwell, AMD’s higher core count and higher clock speeds let it maintain a huge vector throughput lead. Thus AMD’s CDNA line continues to look very good for high performance compute workloads.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F283ff197-239d-46ae-bc39-c85481140787_752x452.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F283ff197-239d-46ae-bc39-c85481140787_752x452.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F283ff197-239d-46ae-bc39-c85481140787_752x452.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F283ff197-239d-46ae-bc39-c85481140787_752x452.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F283ff197-239d-46ae-bc39-c85481140787_752x452.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F283ff197-239d-46ae-bc39-c85481140787_752x452.png" width="752" height="452" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/283ff197-239d-46ae-bc39-c85481140787_752x452.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:452,&quot;width&quot;:752,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F283ff197-239d-46ae-bc39-c85481140787_752x452.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F283ff197-239d-46ae-bc39-c85481140787_752x452.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F283ff197-239d-46ae-bc39-c85481140787_752x452.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F283ff197-239d-46ae-bc39-c85481140787_752x452.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Nvidia’s focus on machine learning and matrix operations keeps them very competitive in that category, despite having fewer SMs running at lower clocks. AMD’s giant MI355X holds a lead across many data types, but the gap between AMD and Nvidia’s largest GPUs isn’t nearly as big as with vector compute.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d88ed55-fee0-4a68-8c36-4f93bb270183_1546x930.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d88ed55-fee0-4a68-8c36-4f93bb270183_1546x930.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d88ed55-fee0-4a68-8c36-4f93bb270183_1546x930.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d88ed55-fee0-4a68-8c36-4f93bb270183_1546x930.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d88ed55-fee0-4a68-8c36-4f93bb270183_1546x930.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d88ed55-fee0-4a68-8c36-4f93bb270183_1546x930.png" width="1456" height="876" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5d88ed55-fee0-4a68-8c36-4f93bb270183_1546x930.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:876,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d88ed55-fee0-4a68-8c36-4f93bb270183_1546x930.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d88ed55-fee0-4a68-8c36-4f93bb270183_1546x930.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d88ed55-fee0-4a68-8c36-4f93bb270183_1546x930.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5d88ed55-fee0-4a68-8c36-4f93bb270183_1546x930.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>GPUs provide a software managed scratchpad local to a group of threads, typically ones running on the same core. AMD GPUs use a Local Data Share, or LDS, for that purpose. Nvidia calls their analogous structure Shared Memory. CDNA 3 had a 64 KB LDS, carrying forward a similar design from AMD GCN GPUs going back to 2012. That LDS had 32 2 KB banks, each 32 bits wide, providing up to 128 bytes per cycle in the absence of bank conflicts.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01ed507-6c6c-40a3-9ed8-128f462590fa_1600x590.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01ed507-6c6c-40a3-9ed8-128f462590fa_1600x590.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01ed507-6c6c-40a3-9ed8-128f462590fa_1600x590.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01ed507-6c6c-40a3-9ed8-128f462590fa_1600x590.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01ed507-6c6c-40a3-9ed8-128f462590fa_1600x590.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01ed507-6c6c-40a3-9ed8-128f462590fa_1600x590.png" width="1456" height="537" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a01ed507-6c6c-40a3-9ed8-128f462590fa_1600x590.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:537,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01ed507-6c6c-40a3-9ed8-128f462590fa_1600x590.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01ed507-6c6c-40a3-9ed8-128f462590fa_1600x590.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01ed507-6c6c-40a3-9ed8-128f462590fa_1600x590.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01ed507-6c6c-40a3-9ed8-128f462590fa_1600x590.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>CDNA 4 increases the LDS capacity to 160 KB and doubles read bandwidth to 256 bytes per clock. GPUs natively operate on 32 bit elements, and it would be reasonable to assume AMD doubled bandwidth by doubling bank count. If so, each bank may now have 2.5 KB of capacity. Another possibility would be increasing bank count to 80 while keeping bank size at 2 KB, but that’s less likely because it would complicate bank selection. A 64-banked LDS could naturally serve a 64-wide wavefront access with each bank serving a lane. Furthermore, a power-of-two bank count would allow simple bank selection via a subset of address bits.</p><p>The larger LDS lets software keep more data close to the execution units. Kernels can allocate more LDS capacity without worrying about lower occupancy due to LDS capacity constraints. For example, a kernel that allocates 16 KB of LDS could run four workgroups on a CDNA 3 CU. On CDNA 4, that would increase to ten workgroups.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F548bfdb3-521c-4f34-9491-35da9a37c1fa_1269x710.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F548bfdb3-521c-4f34-9491-35da9a37c1fa_1269x710.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F548bfdb3-521c-4f34-9491-35da9a37c1fa_1269x710.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F548bfdb3-521c-4f34-9491-35da9a37c1fa_1269x710.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F548bfdb3-521c-4f34-9491-35da9a37c1fa_1269x710.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F548bfdb3-521c-4f34-9491-35da9a37c1fa_1269x710.png" width="1269" height="710" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/548bfdb3-521c-4f34-9491-35da9a37c1fa_1269x710.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:710,&quot;width&quot;:1269,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F548bfdb3-521c-4f34-9491-35da9a37c1fa_1269x710.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F548bfdb3-521c-4f34-9491-35da9a37c1fa_1269x710.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F548bfdb3-521c-4f34-9491-35da9a37c1fa_1269x710.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F548bfdb3-521c-4f34-9491-35da9a37c1fa_1269x710.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Software has to explicitly move data into the LDS to take advantage of it, which can introduce overhead compared to using a hardware-managed cache. CDNA 3 had GLOBAL_LOAD_LDS instructions that let kernels copy data into the LDS without going through the vector register file, CDNA 4 augments GLOBAL_LOAD_LDS to support moving up to 128 bits per lane, versus 32 bits per lane on CDNA 3. That is, the GLOBAL_LOAD_LDS instruction can accept sizes of 1, 2, 4, 12, or 16 DWORDS (32-bit elements), versus just 1, 2, or 4 on CDNA 3.</span><sup>1</sup></p><p>CDNA 4 also introduces read-with-transpose LDS instructions. Matrix multiplication involves multiplying elements of a row in one matrix with corresponding elements in a second matrix’s column. Often that creates inefficient memory access patterns, for at least one matrix, depending on whether data is laid out in row-major or column-major order. Transposing a matrix turns the awkward row-to-column operation into a more natural row-to-row one. Handling transposition at the LDS is also natural for AMD’s architecture, because the LDS already has a crossbar that can map bank outputs to lanes (swizzle).</p><p>Even with its LDS capacity increase, AMD continues to have less data storage within its GPU cores compared to Nvidia. Blackwell’s SMs have a 256 KB block of storage partitioned for use as both L1 cache and Shared Memory. Up to 228 KB can be allocated for use as Shared Memory. With a 164 KB Shared Memory allocation, which is close to matching AMD’s 160 KB LDS, Nvidia would still have 92 KB available for L1 caching. CDNA 4, like CDNA 3, has a 32 KB L1 vector cache per CU. Thus a Blackwell SM can have more software managed storage while still having a larger L1 cache than a CDNA 4 CU. Of course, AMD’s higher CU count means there’s 40 MB of LDS capacity across the GPU, while Nvidia only has ~33 MB of Shared Memory across B200 with the largest 228 KB Shared Memory allocation.</p><p>To feed the massive arrays of Compute Units, MI355X largely uses the same system level architecture as MI300X. MI355X does see a few enhancements though. The L2 caches can “writeback dirty data and retain a copy of the line”. “Dirty” refers to data that has been modified in a write-back cache, but hasn’t been propagated to lower levels in the memory subsystem. When a dirty line is evicted to make room for newer data, its contents are written back to the next level of cache, or DRAM if it’s the last level cache.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38d09938-bf74-48f1-9db3-a935d0e04c84_1580x894.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38d09938-bf74-48f1-9db3-a935d0e04c84_1580x894.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38d09938-bf74-48f1-9db3-a935d0e04c84_1580x894.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38d09938-bf74-48f1-9db3-a935d0e04c84_1580x894.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38d09938-bf74-48f1-9db3-a935d0e04c84_1580x894.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38d09938-bf74-48f1-9db3-a935d0e04c84_1580x894.png" width="1456" height="824" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/38d09938-bf74-48f1-9db3-a935d0e04c84_1580x894.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:824,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:193428,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/166048376?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38d09938-bf74-48f1-9db3-a935d0e04c84_1580x894.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38d09938-bf74-48f1-9db3-a935d0e04c84_1580x894.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38d09938-bf74-48f1-9db3-a935d0e04c84_1580x894.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38d09938-bf74-48f1-9db3-a935d0e04c84_1580x894.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F38d09938-bf74-48f1-9db3-a935d0e04c84_1580x894.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>AMD may be seeking to opportunistically use write bandwidth when the memory subsystem is under low load, smoothing out spikes in bandwidth demand caused by cache fill requests accompanied by writebacks. Or, AMD could be doing something special to let the L2 transition a line to clean state if written data is likely to be read by other threads across the system, but isn’t expected to be modified again anytime soon.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8d9949-3905-44cb-83e9-72365acc3249_1598x895.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8d9949-3905-44cb-83e9-72365acc3249_1598x895.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8d9949-3905-44cb-83e9-72365acc3249_1598x895.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8d9949-3905-44cb-83e9-72365acc3249_1598x895.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8d9949-3905-44cb-83e9-72365acc3249_1598x895.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8d9949-3905-44cb-83e9-72365acc3249_1598x895.png" width="1456" height="815" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5a8d9949-3905-44cb-83e9-72365acc3249_1598x895.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:815,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8d9949-3905-44cb-83e9-72365acc3249_1598x895.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8d9949-3905-44cb-83e9-72365acc3249_1598x895.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8d9949-3905-44cb-83e9-72365acc3249_1598x895.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8d9949-3905-44cb-83e9-72365acc3249_1598x895.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>MI355X’s DRAM subsystem has been upgraded to use HBM3E, providing a substantial bandwidth and capacity upgrade over its predecessor. It also maintains AMD’s lead over its Nvidia competition. Nvidia also uses HBM3E with the B200, which also appears to have eight HBM3E stacks. However, the B200 tops out at 180 GB of capacity and 7.7 TB/s of bandwidth, compared to 288 GB at 8 TB/s on the MI355X. The MI300X could have a substantial advantage over Nvidia’s older H100 when the H100 ran out of DRAM capacity, and AMD is likely looking to retain that advantage.</p><p>Higher bandwidth from HBM3E also helps bring up MI355X’s compute-to-bandwidth ratio. MI300X had ~0.03 bytes of DRAM bandwidth per FP32 FLOP, which increases to 0.05 on MI355X. Blackwell for comparison has ~0.10 bytes of DRAM bandwidth per FP32 FLOP. While Nvidia has increased last level cache capacity on Blackwell, AMD continues to lean more heavily on big caches, while Nvidia relies more on DRAM bandwidth.</p><p>CDNA 2 and CDNA 3 made sweeping changes compared to their predecessors. CDNA 4’s changes are more muted. Much like going from Zen 3 to Zen 4, MI355X retains a similar chiplet arrangement with compute and IO chiplets swapped out for improved versions. Rather than changing up their grand strategy, AMD spent their time tuning CDNA 3. Fewer, higher clocked CUs are easier to utilize, and increased memory bandwidth can help utilization too. Higher matrix multiplication throughput also helps AMD take on Nvidia for machine learning workloads.</p><p><span>In some ways, AMD’s approach with this generation has parallels to Nvidia’s. Blackwell SMs are basically identical to Hopper’s from a vector execution perspective, with improvements focused on the matrix side. Nvidia likely felt they had a winning formula, as their past few GPU generations have undoubtedly been successful. AMD may have found a winning formula with CDNA 3 as well. MI300A, MI300X’s iGPU cousin, powers the highest ranking supercomputer on TOP500’s June list.</span><sup>4</sup><span> Building on success can be a safe and rewarding strategy, and CDNA 4 may be doing just that.</span></p><p><span>If you like the content then consider heading over to the </span><a href="https://www.patreon.com/ChipsandCheese" rel="">Patreon</a><span> or </span><a href="https://www.paypal.com/donate/?hosted_button_id=4EMPH66SBGVSQ" rel="">PayPal</a><span> if you want to toss a few bucks to Chips and Cheese. Also consider joining the </span><a href="https://discord.gg/TwVnRhxgY2" rel="">Discord</a><span>.</span></p><ol><li><p><a href="https://github.com/llvm/llvm-project/blob/main/clang/test/CodeGenOpenCL/builtins-amdgcn-gfx950.cl" rel="">https://github.com/llvm/llvm-project/blob/main/clang/test/CodeGenOpenCL/builtins-amdgcn-gfx950.cl</a><span> - b96 and b128 (96-bit and 128-bit) global_load_lds sizes</span></p></li><li><p><a href="https://github.com/llvm/llvm-project/blob/84ff1bda2977e580265997ad2d4c47b18cd3bf9f/mlir/include/mlir/Dialect/LLVMIR/ROCDLOps.td#L426C1-L426C50" rel="">https://github.com/llvm/llvm-project/blob/84ff1bda2977e580265997ad2d4c47b18cd3bf9f/mlir/include/mlir/Dialect/LLVMIR/ROCDLOps.td#L426C1-L426C50</a><span> - LDS transpose intrinsics</span></p></li><li><p><a href="https://docs.nvidia.com/cuda/blackwell-tuning-guide/index.html" rel="">https://docs.nvidia.com/cuda/blackwell-tuning-guide/index.html</a></p></li><li><p><a href="https://top500.org/lists/top500/2025/06/" rel="">https://top500.org/lists/top500/2025/06/</a></p></li><li><p><a href="https://www.reddit.com/r/hardware/comments/1kj38r1/battle_of_the_giants_8x_nvidia_blackwell_b200/" rel="">https://www.reddit.com/r/hardware/comments/1kj38r1/battle_of_the_giants_8x_nvidia_blackwell_b200/</a><span> - reports 148 Compute Units via OpenCL for B200. Nvidia usually reports SMs for the Compute Unit count</span></p></li></ol></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ICE arrests NYC Comptroller because he asked to see a warrant (241 pts)]]></title>
            <link>https://www.thecity.nyc/2025/06/17/brad-lander-arrest-ice-immigration-court/</link>
            <guid>44301501</guid>
            <pubDate>Tue, 17 Jun 2025 17:25:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thecity.nyc/2025/06/17/brad-lander-arrest-ice-immigration-court/">https://www.thecity.nyc/2025/06/17/brad-lander-arrest-ice-immigration-court/</a>, See on <a href="https://news.ycombinator.com/item?id=44301501">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content">
		<main id="main">

			
	

	
			<figure>

				<img width="1200" height="800" src="https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-1-1.jpg?fit=1200%2C800&amp;ssl=1" alt="" data-hero-candidate="1" fetchpriority="high" decoding="async" srcset="https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-1-1.jpg?w=2048&amp;ssl=1 2048w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-1-1.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-1-1.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-1-1.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-1-1.jpg?resize=1536%2C1024&amp;ssl=1 1536w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-1-1.jpg?resize=1200%2C800&amp;ssl=1 1200w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-1-1.jpg?resize=2000%2C1333&amp;ssl=1 2000w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-1-1.jpg?resize=780%2C520&amp;ssl=1 780w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-1-1.jpg?resize=400%2C267&amp;ssl=1 400w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-1-1.jpg?resize=706%2C471&amp;ssl=1 706w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-1-1.jpg?fit=1200%2C800&amp;ssl=1&amp;w=370 370w" sizes="(max-width: 1200px) 100vw, 1200px">			<figcaption><span>Federal Agents arrest Comptroller Brad Lander while was escorting a person from immigration court at 26 Federal Plaza, June 17, 2025. <span><span>Credit:</span> Ben Fractenberg/THE CITY</span></span></figcaption>
			
			</figure><!-- .post-thumbnail -->

		
				<div>

					

<article id="post-64317">
	<div>

		
				
					
						
					
						
					
				
<p>New York City Comptroller Brad Lander was detained inside a Lower Manhattan immigration court building Tuesday morning by masked federal agents as he attempted to escort a man from his court appearance there.&nbsp;</p>

<p>Moments ahead of his detention, Lander had linked arms with the man leaving an immigration courtroom on the 12th floor, refusing to let go as masked federal agents pushed into the crowd attempting to pull the man away.&nbsp;</p>

<p>In the chaotic scene at around noon, Lander asked the agents repeatedly to show a judicial warrant.</p>


<figure></figure>

<p>“You do not have the authority to arrest U.S. citizens,” Lander repeated, as the officers tightened handcuffs to his wrists. </p>

<p>The federal agents escorted him into an elevator, with one member of his NYPD security detail alongside him.</p>


<div><p>A reporter from The City had overheard one agent say to another minutes before Lander’s arrest, “Do you want to arrest the Comptroller?” </p><p>It wasn’t immediately clear what charges, if any, the mayoral candidate will face. A spokesperson for ICE didn’t immediately return a request for comment.</p></div>


<p>Masked agents from several federal agencies had lined the halls of 26 Federal Plaza Tuesday morning, including Immigration and Customs Enforcement, Enforcement and Removal Operations, the FBI and even the Treasury Department.&nbsp;</p>


<p>“While escorting a defendant out of immigration court at 26 Federal Plaza, Brad was taken by masked agents and detained by ICE,” Dora Pekec, Lander’s campaign spokesperson said in a statement. “This is still developing and we are monitoring the situation closely.”</p>

<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-2.jpg?resize=1024%2C683&amp;ssl=1" alt="" srcset="https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-2.jpg?resize=1024%2C683&amp;ssl=1 1024w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-2.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-2.jpg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-2.jpg?resize=1536%2C1024&amp;ssl=1 1536w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-2.jpg?resize=1200%2C800&amp;ssl=1 1200w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-2.jpg?resize=2000%2C1333&amp;ssl=1 2000w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-2.jpg?resize=780%2C520&amp;ssl=1 780w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-2.jpg?resize=400%2C267&amp;ssl=1 400w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-2.jpg?resize=706%2C471&amp;ssl=1 706w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-2.jpg?w=2048&amp;ssl=1 2048w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2025/06/061725_lander_arrest-2-1024x683.jpg?w=370&amp;ssl=1 370w" sizes="auto, (max-width: 1024px) 100vw, 1024px"><figcaption>Federal Agents arrest Comptroller Brad Lander while was escorting a person from immigration court at 26 Federal Plaza, June 17, 2025. <span><span>Credit:</span> Ben Fractenberg/THE CITY</span></figcaption></figure>

<p>Last week federal agents tackled and handcuffed U.S. Sen. Alex Padilla (D-Calif.) when he tried to question Homeland Security Secretary Kristi Noem during a media event related to immigration. Separately, Rep. LaMonica McIver (D-N.J.) was hit with federal charges stemming from her earlier attempt to visit a privately operated migrant detention facility in Newark.</p>



<p>Lander was making his third trip to accompany immigrants attending court hearings over <a href="https://www.thecity.nyc/2025/05/28/ice-arrests-migrants-26-federal-plaza-pastor/">the last month</a> as federal agents, often masked, have begun staking out courtrooms to detain people leaving what had been routine hearings. He is the <a href="https://hellgatenyc.com/lander-accompanies-immigrants-ice/">only mayoral candidate</a> who’s done so.&nbsp;</p>

<p>Moments ahead of Lander’s arrest, THE CITY asked him why he was inside immigration court in the final days of the Democratic primary here, rather than out talking to voters.&nbsp;</p>

<p>“I don’t think there’s any place that’s more important to be right now than bearing witness and trying to stand up for the rule of law,” Lander said. “A big question on the campaign trail is how will you stand up to Donald Trump.”</p>

<p>In a dig at the polling frontrunner in the mayoral race, Lander added, “Andrew Cuomo wants to tell a story about what he would do, but he views it as like a finger-poking ego fight — not show up and protect people.”</p>

<p><em>Ben Fractenberg contributed reporting.</em></p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
			<div>
															<p><a href="https://www.thecity.nyc/author/gwynne-hogan/" rel="author">
											<img data-perfmatters-preload="" width="80" height="80" src="https://www.thecity.nyc/wp-content/uploads/2023/10/gwynne_headshot_1-100x100.jpg?crop=1" alt="" srcset="https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2023/10/gwynne_headshot_1-scaled.jpg?resize=100%2C100&amp;ssl=1 100w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2023/10/gwynne_headshot_1-scaled.jpg?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2023/10/gwynne_headshot_1-scaled.jpg?resize=1200%2C1200&amp;ssl=1 1200w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2023/10/gwynne_headshot_1-scaled.jpg?resize=800%2C800&amp;ssl=1 800w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2023/10/gwynne_headshot_1-scaled.jpg?resize=600%2C600&amp;ssl=1 600w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2023/10/gwynne_headshot_1-scaled.jpg?resize=400%2C400&amp;ssl=1 400w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2023/10/gwynne_headshot_1-scaled.jpg?resize=200%2C200&amp;ssl=1 200w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2023/10/gwynne_headshot_1-scaled.jpg?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/www.thecity.nyc/wp-content/uploads/2023/10/gwynne_headshot_1-100x100.jpg?w=370&amp;ssl=1 370w">											</a></p><div>
					<!-- .author-bio-header -->

											<p>
							Gwynne Hogan is a senior reporter covering immigration, homelessness, and many things in between. Her coverage of the migrant crisis earned her the Newswomen’s Club of New York’s Journalist of the...															
													</p>
					
				</div><!-- .author-bio-text -->

			</div><!-- .author-bio -->
			
</article><!-- #post-${ID} -->
				</div>

			
		</main><!-- #main -->
	</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla Robotaxi launch is a dangerous game of smoke and mirrors (107 pts)]]></title>
            <link>https://electrek.co/2025/06/16/tesla-robotaxi-launch-dangerous-game-smoke-mirrors/</link>
            <guid>44300727</guid>
            <pubDate>Tue, 17 Jun 2025 16:07:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2025/06/16/tesla-robotaxi-launch-dangerous-game-smoke-mirrors/">https://electrek.co/2025/06/16/tesla-robotaxi-launch-dangerous-game-smoke-mirrors/</a>, See on <a href="https://news.ycombinator.com/item?id=44300727">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="788" src="https://electrek.co/wp-content/uploads/sites/3/2025/01/Tesla-Self-driving-Fremont-factory.png?w=1600" alt="Tesla Self-driving Fremont factory" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/01/Tesla-Self-driving-Fremont-factory.png?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/01/Tesla-Self-driving-Fremont-factory.png?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/01/Tesla-Self-driving-Fremont-factory.png?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/01/Tesla-Self-driving-Fremont-factory.png?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>Tesla’s upcoming Robotaxi launch in Austin, Texas, is increasingly looking like a game of smoke and mirrors, and a dangerous one at that.</p>



<p>CEO Elon Musk claims Tesla is being “paranoid with safety”, but it is taking risks for the purpose of optics.</p>



<h2 id="h-it-s-all-about-optics">It’s all about optics</h2>



<p>Musk has been wrong about self-driving for years. His track record is marked by missed deadlines and broken promises.</p>



<p>He said:</p>	
	



<blockquote>
<p>“Our goal is, and I feel pretty good about this goal, that we’ll be able to do a demonstration drive of full autonomy all the way from LA to New York, from home in LA to let’s say dropping you off in Times Square in New York, and then having the car go park itself, by the end of next year. Without the need for a single touch, including the charger.”</p>
</blockquote>



<p>That was in 2016, and therefore, he claimed it would happen by the end of 2017. Today, in 2025, Tesla is still not capable of doing that.</p>



<p>Musk has claimed that Tesla would achieve unsupervised self-driving every year for the last decade. It has become a running gag<span>, with many YouTube videos featuring his predictions and&nbsp;<a href="https://en.wikipedia.org/wiki/List_of_predictions_for_autonomous_Tesla_vehicles_by_Elon_Musk" target="_blank">a Wikipedia page</a>&nbsp;tr</span>acking his missed deadlines.</p>



<p>Famously, the predictions are about Tesla achieving self-driving “by the end of the year” or “next year.”</p>



<p>This time, Musk has set a clear deadline of “June” for Tesla to launch its robotaxi service.</p>



<p>With Waymo pulling ahead in the autonomous driving race, now operating in four cities, providing over 200,000 paid rides per week, and soon expanding with 2,000 more vehicles, Musk needs a win to maintain the illusion he has been pushing for a while: that Tesla is the leader in autonomous driving.</p>



<p>He recently claimed about Tesla’s self-driving technology:</p>



<blockquote>
<p>No one is even close. There’s really not a close second. We felt like it was a bit of an iPhone moment — you either get it or you don’t, and there’s a massive gap.</p>
</blockquote>



<p>This is becoming increasingly difficult to claim amid Waymo’s expansion. Still, Musk believes that the robotaxi launch in Austin will help maintain the illusion, even though Waymo has already been operating like Tesla’s plans in Austin for years in other cities and for months in Austin itself.</p>



<h2 id="h-moving-of-the-goal-post">Moving of the Goal Post</h2>



<p>We have often described what Tesla is doing in Austin with its planned “robotaxi” launch as <a href="https://electrek.co/2025/02/10/elon-musk-masterful-move-goalpost-tesla-full-self-driving/" target="_blank" rel="noreferrer noopener">a moving of the goalpost</a>.</p>



<p>For years, Tesla has promised unsupervised self-driving in all its vehicles built since 2016. Musk explicitly said that customers who bought Tesla’s Full Self-Driving package would be able to “go to sleep” at the wheel of their vehicles and wake up in another city.</p>



<p>Now, Musk is claiming that Tesla has “solved” self-driving with its “robotaxi” launch, but it is vastly different from prior promises.</p>



<p>Tesla plans to operate its own small internal fleet of vehicles with dedicated software optimized for a geo-fenced area of Austin and supported by “<a href="https://electrek.co/2025/05/16/tesla-robotaxi-fleet-powered-by-plenty-of-teleoperation/" target="_blank" rel="noreferrer noopener">plenty of teleoperation</a>.” This is a night-and-day difference compared to deploying unsupervised self-driving in customer vehicles, as promised since 2016.</p>



<p>Musk himself is on <a href="https://www.reddit.com/r/SelfDrivingCars/comments/1lan6v1/elon_musk_in_2019_if_you_need_a_geofence_area_you/" target="_blank" rel="noreferrer noopener">record</a> saying, “If you need a geofence area, you don’t have real self-driving.”</p>



		<figure>
			
			
			
		</figure>
		


<p>Now, Musk is on record saying that Tesla will only launch the service in a limited area in Austin and even avoid certain intersections that Tesla is not sure it can handle:</p>



<blockquote>
<p>We will geo‑fence it. It’s not going to take intersections unless we are highly confident it’s going to do well with that intersection. Or it will just take a route around that intersection.</p>
</blockquote>



<p>In addition to geofencing, Tesla is also utilizing teleoperation to control vehicles with human operators remotely. </p>



<p>We reported last year when<a href="https://electrek.co/2024/11/25/tesla-remote-control-team-robotaxis-waymo/" target="_blank" rel="noreferrer noopener"> Tesla started building a “teleoperation team.”</a></p>



<p>Despite Tesla originally planning to launch the robotaxi service on June 12, and now “tentatively” on June 22, the automaker posted a new job listing days ago for engineers to help build a low-latency teleoperation system to operate its “self-driving” cars and robots.</p>



<p>The use of geofencing and teleoperation results in Tesla having the same limitations as Waymo, which Musk claimed means it’s “not real self-driving and not scalable to the customer fleet as promised by Tesla for years.</p>



<h2 id="h-paranoid-about-safety">‘Paranoid’ about Safety</h2>



<p>Musk claims that Tesla is being “super paranoid” about safety, but you have to take his word for it.</p>



<p>We have pointed it out before, but it’s worth repeating: Waymo tested its self-driving vehicles in Austin for six months with safety drivers and then for another six months without safety drivers before launching its autonomous ride-hailing service in the city.</p>



<p>As for Tesla, it tested its vehicles with safety drivers throughout Austin for a few months. Then, Musk announced in late May, only weeks before the planned launch, that <a href="https://electrek.co/2025/05/29/tesla-testing-robotaxi-service-without-drivers-for-several-days-elon-musk/" target="_blank" rel="noreferrer noopener">it had started testing without safety drivers</a>.</p>



<p>Despite many people being on the lookout for these driverless Tesla Robotaxis, <a href="https://electrek.co/2025/06/10/tesla-driverless-robotaxi-spotted-austin-car-trailing/" target="_blank" rel="noreferrer noopener">they were only spotted for the first time last week</a>.</p>



<p>Since then, only two confirmed Tesla vehicles without drivers have been spotted testing.</p>



<p>Furthermore, several of those vehicles were spotted with Tesla employees in the front passenger seat. While Musk claims that there are “no safety driver”, these “passengers” pay attention at all times and have access to a kill switch to stop the vehicle.</p>



<p>They virtually operate like “safety drivers”, but they are on the passenger seat rather than the driver’s seat.</p>



<p>Tesla is currently still in the “testing” phase based on the listing with the state regulators, which also mentions “no” safety drivers:</p>



<figure><img decoding="async" src="https://electrek.co/wp-content/uploads/sites/3/2025/06/Screenshot-2025-06-16-at-8.02.53%E2%80%AFPM.png" alt=""></figure>



<p>To go back to the “optics” for a second, Tesla’s head of self-driving, Ashok Elluswamy, has shared this conveniently cropped image of Tesla’s “robotaxis” being tested in Austin:</p>



<figure><img loading="lazy" decoding="async" height="1024" width="964" src="https://electrek.co/wp-content/uploads/sites/3/2025/06/Screenshot-2025-06-16-at-11.23.42%E2%80%AFPM.png?w=964" alt=""></figure>



<p>The image crops out the passenger seat of the car in front, which would show a Tesla employee, and the driver’s seat of the trailing car, which would show a driver, as spotted in Austin over the last week.</p>



<p>There’s also no way to know precisely at what rates these safety passengers and remote operators are intervening on the self-driving vehicles.</p>



<p>Tesla has never released any intervention or disengagement data about its self-driving and ADAS programs despite using “miles between disengagements” as a metric to track improvements and Musk claiming for years that self-driving is a “solved problem” for Tesla.</p>



<p>As we have previously reported, the best available data comes from a crowdsourced effort. <a href="https://electrek.co/2025/02/06/elon-musk-approved-tesla-full-self-driving-dataset-doubled-whats-the-state-of-fsd-now/" target="_blank" rel="noreferrer noopener">Musk has previously shared and misrepresented the dataset in a positive light</a>.</p>



<p>Currently, the data for the combined two most recent updates (v13.2.8-9) on Tesla’s latest hardware (HW4), which is reportedly the same hardware used in Tesla’s “robotaxis” in Austin, currently sits at 444 miles between critical disengagements:</p>



<figure><img loading="lazy" decoding="async" height="285" width="1024" src="https://electrek.co/wp-content/uploads/sites/3/2025/06/Screenshot-2025-06-16-at-7.52.17%E2%80%AFPM.png?w=1024" alt=""></figure>



<p>That would imply a high risk of an accident every 444 miles without a driver paying attention and ready to take control at all times.</p>



<p>Tesla is also currently actively <a href="https://electrek.co/2025/06/05/tesla-admits-suffer-financial-harm-if-self-driving-crash-data-becomes-public/" target="_blank" rel="noreferrer noopener">fighting in court against organizations trying to access its self-driving crash data</a>.</p>



<p>There are currently efforts to raise concerns about Tesla’s “robotaxi” deployment in Austin.</p>



<p>The Dawn Project attempted to convey the potential danger of Tesla’s upcoming robotaxi fleet by demonstrating how Tesla vehicles fail to stop for school buses with their stop signs activated and can potentially run over children on the latest public Supervised Full Self-Driving (FSD) v13.2.9:</p>



<figure><p>
<iframe id="post-youtube-video-1" title="Tesla to launch 'robotaxis' in Austin next week, but critics say the tech still isn't safe" width="500" height="281" data-src="https://www.youtube.com/embed/NItXNJcOkL4?feature=oembed&amp;rel=0&amp;enablejsapi=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>Musk has repeatedly highlighted that the vehicles used for the robotaxi service in Austin are the same that it currently delivers to customers, like this one used in this test.</p>



<p>However, they use a new, custom software optimized for Austin, with supposedly more parameters, allowing for greater performance. Still, there is no way to verify this, as Tesla has not released any data.</p>



<h2 id="h-electrek-s-take">Electrek’s Take</h2>



<p>I can’t lie. I’m getting extremely concerned about this. I don’t think that we can trust Musk or Tesla in their current state to launch this safely.</p>



<p>As I previously stated, I think Tesla’s FSD would be an incredible product if it were sold as a regular ADAS system, rather than something called “Full Self-Driving,” with the promise that it would eventually become unsupervised.</p>



<p>Tesla wouldn’t <span>face </span>a significant liability for not being able to fulfill its promises to customers, as&nbsp;it has <a href="https://electrek.co/2025/06/02/tesla-has-no-plan-for-hw3-owners-4-months-after-admitting-it-wont-support-self-driving/" target="_blank" rel="noreferrer noopener">already confirmed for HW3 owners</a>.&nbsp;Additionally, safety would be improved, as drivers wouldn’t become so complacent with the technology.</p>



<p>Speaking of those failed promises, they are also what’s driving Tesla to push for this launch in Austin.</p>



<p>As Waymo’s former long-time CEO John Krafcik said about Tesla’s effort: <em>“<a href="https://electrek.co/2025/03/14/waymo-ceo-tesla-robotaxi-launch-fake/" target="_blank" rel="noreferrer noopener">There are many ways to fake a robotaxi service.</a>”</em></p>



<p>Musk badly needs a win with self-driving, and he saw an opportunity to get one by getting his gullible fanbase of Tesla shareholders excited about a glimpse at its long-promised future full of “Tesla robotaxis.”</p>




	<p>As he previously stated, he knows full well that the way Tesla is doing this is not more scalable than Waymo even if the hardware cost per vehicle is lower. The hardware cost is negligible compared to teleoperation, development, insurance, and other expenses.</p>



<p>Even with all the smoke and mirrors involved with this project, it’s becoming clear that Tesla is not even ready for it. </p>



<p>Now, the question is whether Musk lets the June deadline slip and takes another ‘L’ on self-driving, or if he pushes for Tesla to launch the potentially dangerous service with lots of limitations.</p>



<p>With the federal government in complete shambles and the Texas government being too close to Musk and Tesla, I wouldn’t count on the regulators to act here. Although they probably should.</p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making 2.5 Flash and 2.5 Pro GA, and introducing Gemini 2.5 Flash-Lite (259 pts)]]></title>
            <link>https://blog.google/products/gemini/gemini-2-5-model-family-expands/</link>
            <guid>44300717</guid>
            <pubDate>Tue, 17 Jun 2025 16:06:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/products/gemini/gemini-2-5-model-family-expands/">https://blog.google/products/gemini/gemini-2-5-model-family-expands/</a>, See on <a href="https://news.ycombinator.com/item?id=44300717">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

    
    





    

    
      

<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;We’re expanding our Gemini 2.5 family of models&quot;
  }">
      <div>
          
            <p>Jun 17, 2025</p>
          
          
            <p data-reading-time-render="">[[read-time]] min read</p>
          
        </div>
      
        <p>
          Gemini 2.5 Flash and Pro are now generally available, and we’re introducing 2.5 Flash-Lite, our most cost-efficient and fastest 2.5 model yet.
        </p>
      
    </div>

    

    
      










<div>
    <figure>
      <div>
        <p><img alt="Blue and black futuristic illustration with Gemini 2.5 logo in the middle" data-component="uni-progressive-image" fetchpriority="high" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_bundle_keyword_blog_header_20.width-200.format-webp.webp" width="360px" data-sizes="(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px" data-srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_bundle_keyword_blog_header_20.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_bundle_keyword_blog_header_2.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_bundle_keyword_blog_header_2.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2.5_bundle_keyword_blog_header_2.width-2200.format-webp.webp 2200w">
        </p>
      </div>
      
    </figure>
  </div>






    

    
    <div data-reading-time="true" data-component="uni-article-body">

            
              





<uni-article-speakable page-title="We’re expanding our Gemini 2.5 family of models" listen-to-article="Listen to article" data-date-modified="2025-06-17T16:00:01.204310+00:00" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-script-src="https://www.gstatic.com/readaloud/player/web/api/js/api.js"></uni-article-speakable>

            

            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;We’re expanding our Gemini 2.5 family of models&quot;
         }"><p data-block-key="8yppc">We designed Gemini 2.5 to be a family of hybrid reasoning models that provide amazing performance, while also being at the <a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf#page=3">Pareto Frontier</a> of cost and speed. Today, we’re taking the next step with our 2.5 Pro and Flash models by releasing them as stable and generally available. And we’re bringing you 2.5 Flash-Lite in preview — our most cost-efficient and fastest 2.5 model yet.</p><h2 data-block-key="5f1o6">Making 2.5 Flash and 2.5 Pro generally available</h2><p data-block-key="7vsso">Thanks to all of your feedback, today we’re releasing stable versions of 2.5 Flash and Pro, so you can build production applications with confidence. <a href="https://developers.googleblog.com/en/gemini-2-5-thinking-model-updates/">Developers</a> like Spline and Rooms and <a href="https://cloud.google.com/blog/products/ai-machine-learning/gemini-2-5-flash-lite-flash-pro-ga-vertex-ai">organizations</a> like Snap and SmartBear have already been using the latest versions in-production for the last few weeks.</p><h2 data-block-key="eje8v">Introducing Gemini 2.5 Flash-Lite</h2><p data-block-key="a8cs2">We’re also introducing a preview of the new Gemini 2.5 Flash-Lite, our most cost-efficient and fastest 2.5 model yet. You can start building with the preview version now, and we’re looking forward to your feedback.</p><p data-block-key="38ei">2.5 Flash Lite has all-around higher quality than 2.0 Flash-Lite on coding, math, science, reasoning and multimodal benchmarks. It excels at high-volume, latency-sensitive tasks like translation and classification, with lower latency than 2.0 Flash-Lite and 2.0 Flash on a broad sample of prompts. It comes with the same capabilities that make Gemini 2.5 helpful, including the ability to turn thinking on at different budgets, connecting to tools like Google Search and code execution, multimodal input, and a 1 million-token context length.</p><p data-block-key="80lci">See more details about our 2.5 family of models in the latest <a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf">Gemini technical report</a>.</p></div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Gemini 2.5 Flash Lite benchmarks table" external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="We’re expanding our Gemini 2.5 family of models" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
    <p><img alt="Gemini 2.5 Flash Lite benchmarks table" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini_2-5_benchmarks_margin_light2x_1.gif">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;We’re expanding our Gemini 2.5 family of models&quot;
         }"><p data-block-key="ymdz3">The preview of Gemini 2.5 Flash-Lite is now available in Google AI Studio and Vertex AI, alongside the stable versions of 2.5 Flash and Pro. Both 2.5 Flash and Pro are also accessible in the Gemini app. We’ve also brought custom versions of 2.5 Flash-Lite and Flash to Search.</p><p data-block-key="70e7i">We can’t wait to see what you continue to build with Gemini 2.5.</p></div>
  


            
            

            
              




            
          </div>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Honda Conducts Successful Launch and Landing of Experimental Reusable Rocket (772 pts)]]></title>
            <link>https://global.honda/en/topics/2025/c_2025-06-17ceng.html</link>
            <guid>44300102</guid>
            <pubDate>Tue, 17 Jun 2025 15:02:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://global.honda/en/topics/2025/c_2025-06-17ceng.html">https://global.honda/en/topics/2025/c_2025-06-17ceng.html</a>, See on <a href="https://news.ycombinator.com/item?id=44300102">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <div><p>TOKYO, Japan, June 17, 2025 – Honda R&amp;D Co., Ltd., a research and development subsidiary of Honda Motor Co., Ltd., today conducted a launch and landing test of an experimental reusable rocket<sup>*1</sup> (6.3 m in length, 85 cm in diameter, 900 kg dry weight/1,312 kg wet weight) developed independently by Honda. The test was completed successfully, the first time Honda landed a rocket after reaching an altitude of 300 meters.</p>
<p>This test marked the first launch and landing test conducted by Honda with an aim to demonstrate key technologies essential for rocket reusability, such as flight stability during ascent and descent, as well as landing capability. Through this successful test, Honda achieved its intended rocket behaviors for the launch and landing (reaching an altitude of 271.4 m, and landing at 37cm of the target touchdown point, flight duration 56.6 sec), while obtaining data during the ascent and descent.</p>
</div>
<div>

<p>
    <h3><b>＜Overview of launch and landing test of a Honda reusable rocket＞</b>
</h3>
</p>


    
</div>
<div>
<p>・Purpose:&nbsp;&nbsp;&nbsp;&nbsp; Establishment of key technologies necessary for a reusable rocket<br>
・Location:&nbsp;&nbsp;&nbsp;&nbsp; Honda facility in Taiki Town<sup>*2</sup>, Hiroo District, Hokkaido Prefecture, Japan<br>
・Date/Time:&nbsp; June 17, 2025. Launch time: 16:15</p>
</div>

<div><p>*1 A reusable rocket, also known as a reusable launch vehicle (RLV), is a type of rocket that, unlike a conventional expendable launch vehicle (ELV), can be used repeatedly in a short period of time. A reusable rocket is launched in a vertical position, reaches an altitude of around 100 kilometers, and then lands back on earth while maintaining a vertical position.</p>
<p>*2 Taiki Town, located in southeastern Hokkaido, Japan, has been developing itself as a “space town” through the joint efforts of public and private sectors, and various aviation/space related tests are being conducted by a wide range of organizations including JAXA (Japan Aerospace Exploration Agency), businesses and universities.</p>
</div>
<div>

<p>
    <h3><b>＜Safety measures for Honda rocket testing＞</b>
</h3>
</p>


    
</div>
<div>
<p>Since 2024, Honda has been safely conducting engine combustion tests and hovering tests for its reusable rockets in Taiki Town in Hiroo District, Hokkaido, Japan. As with all previous tests, Honda conducted this launch and landing test while placing the highest priority on safety and with the understanding and cooperation of local authorities and residents.&nbsp;</p>
</div>
<div>

<p>
    <h4><b>Specific safety measures taken for this test</b>
</h4>
</p>


    
</div>
<div><ul>
<li>A restricted area with a 1-kilometer radius was established. During the test, access to the area was restricted through the installation of signs and gates, as well as the deployment of security personnel.<b></b></li>
<li>The restricted area was defined by calculating the potential area where the rocket could fall to earth in the event of a thrust cut-off and by adding a sufficient buffer zone (safe distance calculated based on the guidelines set forth by the Cabinet Office of the Government of Japan) that would cover the potential area where a blast wave, debris dispersion, or fireballs could impact in the event of an explosion within the potential fall area.<b></b></li>
<li>The experimental rocket was equipped with a safety system to prevent deviation from a pre-defined flight corridor, speed and attitude conditions, ensuring no impact beyond the restricted area.<b></b></li>
</ul>
</div>
<div>

<p>
    <h3><b>＜Honda initiatives in the areas of rocket research＞</b>
</h3>
</p>


    
</div>
<div><p>As announced in 2021, Honda has been pursuing research and development in the field of space technologies while viewing it as a place to take on challenges to realize the “dreams” and “potential” of people worldwide while leveraging its core technologies. Honda has the aim to enable people to transcend the constraints of time, place or ability and make people’s daily lives more enjoyable. Examples of Honda initiatives toward creating new value in the ultimate environment of outer space include research into a circulative renewable energy system, key robotic technologies for use in outer space and reusable rockets.&nbsp;</p>
<p>Inspired by the dream of young Honda engineers who wanted to build rockets by utilizing core technologies amassed by Honda through the development of various products, such as combustion and control technologies, Honda started rocket research based on the belief that it has the potential to contribute more to people’s daily lives by launching satellites with its own rockets, that could lead to various services<sup>*3</sup> that are also compatible with other Honda business.</p>
<p>In today’s world, vast amounts of data are consumed, with the growing expectation for greater utilization of a data system in outer space through expanded use of satellites. In light of this trend, the need for satellite launch rockets is also expected to increase in the coming years.</p>
<p>In this market environment, Honda has chosen to take on the technological challenge of developing reusable rockets by utilizing Honda technologies amassed in the development of various products and automated driving systems, based on a belief that reusable rockets will contribute to achieving sustainable transportation.</p>
<p>Although Honda rocket research is still in the fundamental research phase, and no decisions have been made regarding commercialization of these rocket technologies, Honda will continue making progress in the fundamental research with a technology development goal of realizing technological capability to enable a suborbital launch by 2029.&nbsp;</p>
</div>
<div>

<p>
    <h4><b>Comments by Toshihiro Mibe, Global CEO of Honda</b>
</h4>
</p>


    
</div>
<div>
<p>“We are pleased that Honda has made another step forward in our research on reusable rockets with this successful completion of a launch and landing test. We believe that rocket research is a meaningful endeavor that leverages Honda’s technological strengths. Honda will continue to take on new challenges—not only to offer our customers various services and value through our products, while addressing environmental and safety issues, but also to continue creating new value which will make people’s time and place more enjoyable.”</p>
</div>
<div>
<p>*3 Examples include remote sensing to monitor Earth conditions such as global warming and extreme weather, as well as satellite constellations that enable wide-area communication, which is an essential component for connected features of mobility products.</p>
</div>

    
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Now might be the best time to learn software development (114 pts)]]></title>
            <link>https://substack.com/home/post/p-165655726</link>
            <guid>44299979</guid>
            <pubDate>Tue, 17 Jun 2025 14:51:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://substack.com/home/post/p-165655726">https://substack.com/home/post/p-165655726</a>, See on <a href="https://news.ycombinator.com/item?id=44299979">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><h3 translated="">The app for independent voices</h3></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why JPEGs still rule the web (2024) (128 pts)]]></title>
            <link>https://spectrum.ieee.org/jpeg-image-format-history</link>
            <guid>44299970</guid>
            <pubDate>Tue, 17 Jun 2025 14:51:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/jpeg-image-format-history">https://spectrum.ieee.org/jpeg-image-format-history</a>, See on <a href="https://news.ycombinator.com/item?id=44299970">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="Why JPEGs Still Rule the Web"><p><em><em>A version of this post </em></em><a href="https://tedium.co/2024/06/16/jpeg-image-format-history/" rel="noopener noreferrer" target="_blank"><em><em>originally appeared</em></em></a><em><em> on </em></em><a href="https://tedium.co/" rel="noopener noreferrer" target="_blank"><em><em>Tedium</em></em></a><em><em>, Ernie Smith’s newsletter, which hunts for the end of the long tail.</em></em></p><p>For roughly three decades, the JPEG has been the World Wide Web’s primary image format. But it wasn’t the one the Web started with. In fact, the first mainstream graphical browser, NCSA Mosaic, didn’t initially support inline JPEG files—<a href="https://ftp.jurassic.nl/pub/irix/mosaic/Mac/FAQ/FAQ.HTML" rel="noopener noreferrer" target="_blank">just inline GIFs</a>, along with a couple of other <a href="https://spectrum.ieee.org/carnegie-mellon-is-saving-old-software-from-oblivion" target="_blank">formats forgotten to history</a>. However, the JPEG had many advantages over the format it quickly usurped.</p><p data-rm-resized-container="25%"><a href="https://tedium.co/" target="_blank"></a><a title="Select for lightbox">aspect_ratio</a><a href="https://tedium.co/" target="_blank"><img alt="Tedium logo, a red rectangle with the word Tedium in white, above the text &quot;This post originally appeared on Tedium.&quot;" data-rm-shortcode-id="c603546dab9e1dd1612b1364d3107471" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/tedium-logo-a-red-rectangle-with-the-word-tedium-in-white-above-the-text-this-post-originally-appeared-on-tedium.png?id=60568211&amp;width=980" height="900" id="6aeb5" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/tedium-logo-a-red-rectangle-with-the-word-tedium-in-white-above-the-text-this-post-originally-appeared-on-tedium.png?id=60568211&amp;width=980" width="3000"></a><small placeholder="add photo credit..."><a href="https://spectrum.ieee.org/media-library/eyjhbgcioijiuzi1niisinr5cci6ikpxvcj9.eyjpbwfnzsi6imh0dhbzoi8vyxnzzxrzlnjibc5tcy82mdu2odixms9vcmlnaw4ucg5niiwizxhwaxjlc19hdci6mtc1nzmynzi1mn0._gbglxpbsmfwoobs84_whxbl_vnslwx1geovlhgvwku/image.png?width=980" target="_blank"></a></small></p><p>Despite not appearing together right away—it first appeared in Netscape in 1995, three years after the image standard was officially published—the JPEG and web browser fit together naturally. JPEG files degraded more gracefully than GIFs, retaining more of the picture’s initial form—and that allowed the format to scale to greater levels of success. While it wasn’t capable of animation, it progressively expanded from something a modem could pokily render to a format that was good enough for high-end professional photography.</p><p>For the internet’s purposes, the degradation was the important part. But it wasn’t the only thing that made the JPEG immensely valuable to the digital world. An essential part was that it was a documented standard built by numerous stakeholders.</p><h2>The GIF was a de facto standard. The JPEG was an actual one</h2><p>How important is it that JPEG was a standard? Let me tell you a story.</p><p>During <a href="https://archive.nytimes.com/bits.blogs.nytimes.com/2013/05/21/an-honor-for-the-creator-of-the-gif/?smid=tw-nytimes" target="_blank">a 2013 <em><em>New York Times</em></em> interview</a> conducted just before he received an award honoring his creation, GIF creator Steve Wilhite stepped into a debate he unwittingly created. <span>Simply put, nobody knew how to pronounce the acronym for the image format he had fostered, the Graphics Interchange Format. He used the moment to attempt to set the record straight—it was pronounced like the peanut butter brand: “It is a soft ‘G,’ pronounced ‘jif.’ End of story,” he said.</span></p><p>I <a href="https://shortformblog.com/post/51026114908/steve-wilhite-gif-award" target="_blank">posted a quote from Wilhite</a> on my popular Tumblr around that time, a period when the <a href="https://spectrum.ieee.org/tag/social-media">social media</a> site was the center of the GIF universe. And soon afterward, my post got thousands of reblogs—nearly all of them disagreeing with Wilhite. Soon, <a href="https://knowyourmeme.com/memes/gif-vs-jif-pronunciation-debate/" target="_blank">Wilhite’s quote became a meme</a>.</p><p>The situation paints how Wilhite, who died in 2022, did not develop his format by committee. He could say it sounded like “JIF” because he built it himself. He was handed the project as a <a href="https://spectrum.ieee.org/tag/compuserve">CompuServe</a> employee in 1987; he produced the object, and that was that. The initial document describing how it works? <a href="https://www.w3.org/Graphics/GIF/spec-gif87.txt" target="_blank">Dead simple</a>. 38 years later, we’re still using the GIF—but it never rose to the same prevalence of JPEG.</p><p>The JPEG, which formally emerged about five years later, was very much <em><em>not</em></em> that situation. Far from it, in fact—it’s the difference between a de facto standard and an actual one. And that proved essential to its eventual ubiquity.</p><p><img alt="Full resolution photo of a sunlit pine forest with a narrow trail winding through the trees and grassy undergrowth." data-rm-shortcode-id="b24d49ca553a838abbd2d8e0f9fb221c" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/full-resolution-photo-of-a-sunlit-pine-forest-with-a-narrow-trail-winding-through-the-trees-and-grassy-undergrowth.jpg?id=61013768&amp;width=980" height="3982" id="2999a" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/full-resolution-photo-of-a-sunlit-pine-forest-with-a-narrow-trail-winding-through-the-trees-and-grassy-undergrowth.jpg?id=61013768&amp;width=980" width="5973"><small placeholder="Add Photo Caption...">We’re going to degrade the quality of this image throughout this article. At its full image size, it’s 13.7 megabytes.</small><small placeholder="Add Photo Credit...">Irina Iriser</small></p><h2>How the JPEG format came to life</h2><p>Built with input from dozens of stakeholders, the Joint Photographic Experts Group ultimately aimed to create a format that fit everyone’s needs. (Reflecting its committee-led roots, there would be no confusion about the format’s name—an acronym of the organization that designed it.) And when the format was finally unleashed on the world, it was the subject of a more than 600-page book.</p><p><em><em>JPEG: Still Image Data Compression Standard</em></em>, written by <a href="https://spectrum.ieee.org/tag/ibm">IBM</a> employees and JPEG organization stakeholders William B. Pennebaker and Joan L. Mitchell, <a href="https://www.google.com/books/edition/JPEG/AepB_PZ_WMkC?hl=en&amp;gbpv=1&amp;pg=PA1&amp;printsec=frontcover" target="_blank">describes</a> a landscape of multimedia imagery, held back without a way to balance the need for photorealistic images and immediacy. Standardization, they believed, could fix this.</p><p>“The problem was not so much the lack of <a href="https://spectrum.ieee.org/tag/algorithms">algorithms</a> for image compression (as there is a long history of technical work in this area),” the authors wrote, “but, rather, the lack of a standard algorithm—one which would allow an interchange of images between diverse applications.”</p><p>And they were absolutely right. For more than 30 years, JPEG has made high-quality, high-resolution photography accessible in <a href="https://spectrum.ieee.org/tag/operating-systems">operating systems</a> far and wide. Although we no longer need to compress JPEGs to within an inch of their life, having that capability helped enable the modern <a href="https://spectrum.ieee.org/tag/internet">internet</a>.</p><p><a href="https://www.google.com/books/edition/JPEG/AepB_PZ_WMkC?hl=en&amp;gbpv=1&amp;dq=ibm+jpeg&amp;pg=PA278&amp;printsec=frontcover" target="_blank">As the book notes</a>, Mitchell and Pennebaker were given IBM’s support to follow through this research and work with the JPEG committee, and that support led them to develop many of the JPEG format’s foundational patents. Described in <a href="https://patents.google.com/patent/US4905297" target="_blank">patents</a> filed by Mitchell and Pennebaker in 1988, IBM and other members of the JPEG standards committee, such as AT&amp;T and Canon, were developing ways to use compression to make high-quality images easier to deliver in confined settings.</p><p>Each member brought their own needs to the process. Canon, obviously, was more focused on <a href="https://spectrum.ieee.org/tag/printers">printers</a> and photography, while AT&amp;T’s interests were tied to data transmission. Together, the companies left behind a standard that has stood the test of time.</p><p>All this means, funnily enough, that the first place that a program capable of using JPEG compression appeared was not MacOS or Windows, but OS/2—a fascinating-but-failed graphical <a href="https://spectrum.ieee.org/tag/operating-system">operating system</a> created by Pennebaker and Mitchell’s employer, IBM. As early as 1990, OS/2 supported the format through the <a href="https://www.edm2.com/index.php/OS/2_Image_Support" target="_blank">OS/2 Image Support</a> application.</p><p><img alt="Nearly identical photo of a sunlit pine forest." data-rm-shortcode-id="b810c6423ebd0b3e07f4d42c4c7162ac" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/nearly-identical-photo-of-a-sunlit-pine-forest.jpg?id=61015732&amp;width=980" height="3982" id="ef951" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/nearly-identical-photo-of-a-sunlit-pine-forest.jpg?id=61015732&amp;width=980" width="5973"><small placeholder="Add Photo Caption...">At 50 percent of its initial quality, the image is down to about 2.6 MB. By dropping half of the image’s quality, we brought it down to one-fifth of the original file size. </small><small placeholder="Add Photo Credit...">Original image: Irina Iriser</small></p><h2>What a JPEG does when you heavily compress it</h2><p>The thing that differentiates a JPEG file from a PNG or a GIF is how the data degrades as you compress it. The goal for a JPEG image is to still look like a photo when all is said and done, even if some compression is necessary to make it all work at a reasonable size. That way, you can display something that looks close to the original image in fewer bytes.</p><p>Or, <a href="https://www.google.com/books/edition/JPEG/AepB_PZ_WMkC?hl=en&amp;gbpv=1&amp;pg=PA4&amp;printsec=frontcover" target="_blank">as Pennebaker and Mitchell put it</a>, “the most effective compression is achieved by approximating the original image (rather than reproducing it exactly).”</p><p>Central to this is a compression process called <a href="https://spectrum.ieee.org/compression-algorithms" target="_blank">discrete cosine transform</a> (DCT), a lossy form of compression encoding heavily used in all sorts of compressed formats, most notably in <a href="https://spectrum.ieee.org/tag/digital-audio">digital audio</a> and <a href="https://spectrum.ieee.org/tag/signal-processing">signal processing</a>. Essentially, it delivers a lower-quality product by removing details, while still keeping the heart of the original product through approximation. The stronger the cosine transformation, the more compressed the final result.</p><p>The algorithm, <a href="https://ieeexplore.ieee.org/abstract/document/1672377" target="_blank">developed by researchers</a> in the 1970s, essentially takes a grid of data and treats it as if you’re controlling its frequency with a knob. The data rate is controlled like water from a faucet: The more data you want, the higher the setting. DCT allows a trickle of data to still come out in highly compressed situations, even if it means a slightly compromised result. In other words, you may not keep all the data when you compress it, but DCT allows you to keep the heart of it.</p><p>(See <a href="https://www.youtube.com/watch?v=Q2aEzeMDHMA" target="_blank">this video</a> for a more technical but still somewhat easy-to-follow description of DCT.)</p><p>DCT is everywhere. If you <a href="https://ottverse.com/discrete-cosine-transform-dct-video-compression/" target="_blank">have ever seen a streaming video</a> or an online radio stream that degraded in quality because your bandwidth suddenly declined, you’ve witnessed DCT being utilized in real time.</p><p>A JPEG file doesn’t have to leverage the DCT with just one method, <a href="https://www.google.com/books/edition/JPEG/AepB_PZ_WMkC?hl=en&amp;gbpv=1&amp;pg=PA81&amp;printsec=frontcover" target="_blank">as <em><em>JPEG: Still Image Data Compression Standard</em></em> explains</a>:</p><p>The JPEG standard describes a family of large image compression techniques, rather than a single compression technique. It provides a “tool kit” of compression techniques from which applications can select elements that satisfy their particular requirements.</p><p>The toolkit has four modes:</p><ul><li><strong>Sequential DCT,</strong> which displays the compressed image in order, like a window shade slowly being rolled down</li><li><strong>Progressive DCT,</strong> which displays the full image in the lowest-resolution format, then adds detail as more information rolls in</li><li><strong>Sequential lossless,</strong> which uses the window shade format but doesn’t compress the image</li><li><strong>Hierarchical mode,</strong> which combines the prior three modes—so maybe it starts with a progressive mode, then loads DCT compression slowly, but then reaches a lossless final result</li></ul><p>At the time the JPEG was being created, <a href="https://spectrum.ieee.org/tag/modems">modems</a> were extremely common. That meant images loaded slowly, making Progressive DCT the most fitting format for the early internet. Over time, the progressive DCT mode has become less common, as many computers can simply load the sequential DCT in one fell swoop.</p><p><img alt="The same photo of a sunlit pine forest with very slight degradation visible." data-rm-shortcode-id="f045496eded7dca7812ee1bcaa6bbff1" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/the-same-photo-of-a-sunlit-pine-forest-with-very-slight-degradation-visible.jpg?id=61029700&amp;width=980" height="3982" id="fd0cd" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/the-same-photo-of-a-sunlit-pine-forest-with-very-slight-degradation-visible.jpg?id=61029700&amp;width=980" width="5973"><small placeholder="Add Photo Caption...">That same forest, saved at 5 percent quality. Down to about 419 kilobytes.</small><small placeholder="Add Photo Credit...">Original image: Irina Iriser</small></p><p>When an image is compressed with DCT, the change tends to be less noticeable in busier, more textured areas of the picture, like hair or foliage. Those areas are harder to compress, which means they keep their integrity longer. It tends to be more noticeable, however, with solid colors or in areas where the image sharply changes from one color to another—like text on a page. Ever screenshot a social media post, only for it to look noisy? Congratulations, you just made a JPEG file.</p><p>Other formats, like PNG, do better with text, because their compression format is intended to be non-lossy. (Side note: PNG’s compression format, DEFLATE, <a href="https://www.ietf.org/rfc/rfc1951" target="_blank">was designed</a> by Phil Katz, who also created the ZIP format. The PNG format uses it in part because it was a license-free compression format. So it turns out the brilliant coder with the <a href="https://www.wsj.com/articles/SB961363319756539141" target="_blank">sad life story</a> improved the internet in multiple ways before his <a href="https://tedium.co/2015/02/17/early-internet-history-tales/" target="_blank">untimely passing</a>.)</p><p>In many ways, the JPEG is one tool in our image-making toolkit. Despite its age and maturity, it remains one of our best options for sharing photos on the internet. But it is not a tool for every setting—despite the fact that, like a wrench sometimes used as a hammer, we often leverage it that way.</p><h2>Forgent Networks claimed to own the JPEG’s defining algorithm</h2><p>The JPEG format gained popularity in the ’90s for reasons beyond the quality of the format. Patents also played a role: Starting in 1994, the tech company Unisys <a href="https://www.theregister.com/1999/09/01/unisys_demands_5k_licence_fee/" target="_blank">attempted to bill individual users</a> who relied on GIF files, which used a patent the company owned. This made the free-to-use JPEG more popular. (This situation also led to the creation of the patent-free PNG format.)</p><p>While the JPEG was standards-based, it could still have faced the same fate as the GIF, thanks to the quirks of the patent system. A few years before the file format came to life, a pair of Compression Labs employees <a href="https://patents.google.com/patent/US4698672A/en" target="_blank">filed a patent application</a> that dealt with the compression of motion graphics. By the time anyone noticed its similarity to JPEG compression, the format was ubiquitous.</p><p><img alt="The same photo of a sunlit pine forest with more noticeable color degradation visible. Areas with previously subtle color gradients now appear more like blocks of color." data-rm-shortcode-id="5fb227e9168811101372ad575e42dc89" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/the-same-photo-of-a-sunlit-pine-forest-with-more-noticeable-color-degradation-visible-areas-with-previously-subtle-color-gradie.jpg?id=61016218&amp;width=980" height="3982" id="e1296" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/the-same-photo-of-a-sunlit-pine-forest-with-more-noticeable-color-degradation-visible-areas-with-previously-subtle-color-gradie.jpg?id=61016218&amp;width=980" width="5973"><small placeholder="Add Photo Caption...">Our forest, saved at 1 percent quality. This image is only about 239 KB in size, yet it’s still easily recognizable as the same photo. That’s the power of the JPEG.</small><small placeholder="Add Photo Credit...">Original image: Irina Iriser</small></p><p>Then in 1997, a company named Forgent Networks acquired Compression Labs. The company eventually spotted the patent and began filing lawsuits over it, a series of events it saw as a stroke of good luck.</p><p>“The patent, in some respects, is a lottery ticket,” Forgent Chief Financial Officer Jay Peterson <a href="https://www.cnet.com/tech/tech-industry/staking-a-claim-in-the-patent-gold-mine/" target="_blank">told <em><em>CNET</em></em> in 2005</a>. “If you told me five years ago that ‘You have the patent for JPEG,’ I wouldn’t have believed it.”</p><p>While Forgent’s claim of ownership of the JPEG <a href="https://spectrum.ieee.org/tag/compression-algorithm">compression algorithm</a> was tenuous, it ultimately saw more success with its legal battles than Unisys did. The company earned more than $100 million from <a href="https://spectrum.ieee.org/tag/digital-camera">digital camera</a> makers before the patent finally ran out of steam around 2007. The company also attempted to extract licensing fees from the PC industry. Eventually, Forgent agreed <a href="https://www.cnet.com/tech/tech-industry/forgent-settles-jpeg-patent-cases/" target="_blank">to a modest $8 million</a> settlement.</p><p>As the company took an increasingly aggressive approach to its acquired patent, it began to lose battles both in the court of public opinion and in actual courtrooms. <a href="https://arstechnica.com/uncategorized/2006/05/6930-2/" target="_blank">Critics pounced on examples of prior art</a>, while courts limited the patent’s use to motion-based uses like video.</p><p>By 2007, Forgent’s compression patent expired—and its litigation-heavy approach to business went away. That year, the company became <a href="https://www.asuresoftware.com/" target="_blank">Asure Software</a>, which now specializes in <a href="https://spectrum.ieee.org/tag/payroll">payroll</a> and HR solutions. Talk about a reboot.</p><h2>Why the JPEG won’t die</h2><p>The JPEG file format has served us well. It’s been difficult to remove the format from its perch. The JPEG 2000 format, for example, was intended to supplant it by offering more lossless options and better performance. The format is <a href="https://www.loc.gov/preservation/digital/formats/fdd/fdd000143.shtml" target="_blank">widely used by the Library of Congress</a> and specialized sites like the <a href="https://spectrum.ieee.org/tag/internet-archive">Internet Archive</a>, however, it is less popular as an end-user format.</p><p data-rm-resized-container="25%"><img alt="Animated GIF of the forest images, starting at full resolution and progressing through increasingly degraded version of the iamge." data-rm-shortcode-id="ea7ce7f87d0b7e0afed75e4a9a57e2a7" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/animated-gif-of-the-forest-images-starting-at-full-resolution-and-progressing-through-increasingly-degraded-version-of-the-iamg.gif?id=61016209&amp;width=980" height="240" id="171a2" lazy-loadable="true" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20360%20240'%3E%3C/svg%3E" width="360"><small placeholder="Add Photo Caption...">See the forest JPEG degrade from its full resolution to 1 percent quality in this GIF. </small><small placeholder="Add Photo Credit...">Original image: Irina Iriser</small></p><p>Other image technologies have had somewhat more luck getting past the JPEG format. The Google-supported <a href="https://developers.google.com/speed/webp" target="_blank">WebP</a> is popular with website developers (<a href="https://www.pcgamer.com/heres-why-you-have-to-deal-with-so-many-annoying-webps-now/" target="_blank">and controversial</a> with end users). Meanwhile, the formats <a href="https://aomediacodec.github.io/av1-avif/" target="_blank">AVIF</a> and <a href="https://www.iso.org/standard/83650.html" target="_blank">HEIC</a>, each developed by standards bodies, have largely outpaced both JPEG and JPEG 2000.</p><p>Still, the JPEG will be difficult to kill at this juncture. These days, the format is similar to <a href="https://spectrum.ieee.org/tag/mp3">MP3</a> or ZIP files—two legacy formats too popular and widely used to kill. Other formats that compress the files better and do the same things more efficiently are out there, but it’s difficult to topple a format with a 30-year head start.</p><p>Shaking off the JPEG is easier said than done. I think most people will be fine to keep it around.</p><p><em><em>Ernie Smith is the editor of </em></em><a href="https://tedium.co/" target="_blank"><em><em>Tedium</em></em></a><em><em>, a long-running newsletter that hunts for the end of the long tail.</em></em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[O3 Turns Pro (147 pts)]]></title>
            <link>https://thezvi.substack.com/p/o3-turns-pro</link>
            <guid>44299947</guid>
            <pubDate>Tue, 17 Jun 2025 14:49:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thezvi.substack.com/p/o3-turns-pro">https://thezvi.substack.com/p/o3-turns-pro</a>, See on <a href="https://news.ycombinator.com/item?id=44299947">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>You can now have o3 throw vastly more compute at a given problem. That’s o3-pro. </p><p>Should you have o3 throw vastly more compute at a given problem, if you are paying the $200/month subscription price for ChatGPT Pro? Should you pay the $200, or the order of magnitude markup over o3 to use o3-pro in the API?</p><p>That’s trickier. Sometimes yes. Sometimes no. My experience so far is that waiting a long time is annoying, sufficiently annoying that you often won’t want to wait. Whenever I ask o3-pro something, I often also have been asking o3 and Opus. </p><p>Using the API at scale seems prohibitively expensive for what you get, and you can (and should) instead run parallel queries using the chat interface.</p><p>The o3-pro answers have so far definitely been better than o3, but the wait is usually enough to break my workflow and human context window in meaningful ways - fifteen minutes plus variance is past the key breakpoint, such that it would have not been substantially more painful to fully wait for Deep Research. </p><p>Indeed, the baseline workflow feels similar to Deep Research, in that you fire off a query and then eventually you context shift back and look at it. But if you are paying the subscription price already it’s often worth queuing up a question and then having it ready later if it is useful. </p><p>In many ways o3-pro still feels like o3, only modestly better in exchange for being slower. Otherwise, same niche. If you were already thinking ‘I want to use Opus rather than o3’ chances are you want Opus rather than, or in addition to, o3-pro. </p><p>Perhaps the most interesting claim, from some including Tyler Cowen, was that o3-pro is perhaps not a lying liar, and hallucinates far less than o3. If this is true, in many situations it would be worth using for that reason alone, provided the timing allows this. The bad news is that it didn’t improve on a Confabulations benchmark.  </p><p><a href="https://x.com/TheZvi/status/1933563488602837286" rel="">My poll (n=19) was roughly evenly split on this question</a><span>. </span></p><p>My hunch, based on my use so far, is that o3-pro is hallucinating modestly less because:</p><ol><li><p>It is more likely to find or know the right answer to a given question, which is likely to be especially relevant to Tyler’s observations.</p></li><li><p>It is considering its answer a lot, so it usually won’t start writing an answer and then think ‘oh I guess that start means I will provide some sort of answer’ like o3.</p></li><li><p>The queries you send are more likely to be well-considered to avoid the common mistake of essentially asking for hallucinations. </p></li></ol><p>But for now I think you still have to have a lot of the o3 skepticism.</p><p><span>And as always, the next thing will be here soon, </span><a href="https://x.com/HCSolakoglu/status/1934921625583145415" rel="">Gemini 2.5 Pro Deep Think is coming</a><span>.</span></p><p><a href="https://x.com/elder_plinius/status/1932608359028391998" rel="">Pliny of course jailbroke it, for those wondering</a><span>. Pliny also </span><a href="https://x.com/elder_plinius/status/1932921389427597757" rel="">offers us the tools and channels information</a><span>.</span></p><p><span>My poll strongly </span><a href="https://x.com/TheZvi/status/1933563487315186180" rel="">suggested o3-pro is slightly stronger than o3</a><span>. </span></p><blockquote><p><a href="https://x.com/gdb/status/1932561536268329463" rel="">Greg Brockman</a><span> (OpenAI): o3-pro is much stronger than o3.</span></p><p><a href="https://x.com/OpenAI/status/1932530411651150013" rel="">OpenAI</a><span>: In expert evaluations, reviewers consistently prefer OpenAI o3-pro over o3, highlighting its improved performance in key domains—including science, education, programming, data analysis, and writing.</span></p><p>Reviewers also rated o3-pro consistently higher for clarity, comprehensiveness, instruction-following, and accuracy.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8f2b152-7e74-4143-b930-9c8e4432ed08_1200x675.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8f2b152-7e74-4143-b930-9c8e4432ed08_1200x675.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8f2b152-7e74-4143-b930-9c8e4432ed08_1200x675.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8f2b152-7e74-4143-b930-9c8e4432ed08_1200x675.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8f2b152-7e74-4143-b930-9c8e4432ed08_1200x675.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8f2b152-7e74-4143-b930-9c8e4432ed08_1200x675.png" width="1200" height="675" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e8f2b152-7e74-4143-b930-9c8e4432ed08_1200x675.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:675,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:126229,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://thezvi.substack.com/i/165878744?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8f2b152-7e74-4143-b930-9c8e4432ed08_1200x675.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8f2b152-7e74-4143-b930-9c8e4432ed08_1200x675.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8f2b152-7e74-4143-b930-9c8e4432ed08_1200x675.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8f2b152-7e74-4143-b930-9c8e4432ed08_1200x675.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8f2b152-7e74-4143-b930-9c8e4432ed08_1200x675.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Like OpenAI o1-pro, OpenAI o3-pro excels at math, science, and coding as shown in academic evaluations.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89ae699a-02dc-45c8-9b96-8ae0122b46e6_1200x675.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89ae699a-02dc-45c8-9b96-8ae0122b46e6_1200x675.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89ae699a-02dc-45c8-9b96-8ae0122b46e6_1200x675.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89ae699a-02dc-45c8-9b96-8ae0122b46e6_1200x675.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89ae699a-02dc-45c8-9b96-8ae0122b46e6_1200x675.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89ae699a-02dc-45c8-9b96-8ae0122b46e6_1200x675.png" width="1200" height="675" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/89ae699a-02dc-45c8-9b96-8ae0122b46e6_1200x675.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:675,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:213155,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://thezvi.substack.com/i/165878744?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89ae699a-02dc-45c8-9b96-8ae0122b46e6_1200x675.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89ae699a-02dc-45c8-9b96-8ae0122b46e6_1200x675.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89ae699a-02dc-45c8-9b96-8ae0122b46e6_1200x675.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89ae699a-02dc-45c8-9b96-8ae0122b46e6_1200x675.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F89ae699a-02dc-45c8-9b96-8ae0122b46e6_1200x675.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>To assess the key strength of OpenAI o3-pro, we once again use our rigorous "4/4 reliability" evaluation, where a model is considered successful only if it correctly answers a question in all four attempts, not just one.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55fea1ff-bc5c-42fd-80df-b2dec9bbf31d_1200x675.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55fea1ff-bc5c-42fd-80df-b2dec9bbf31d_1200x675.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55fea1ff-bc5c-42fd-80df-b2dec9bbf31d_1200x675.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55fea1ff-bc5c-42fd-80df-b2dec9bbf31d_1200x675.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55fea1ff-bc5c-42fd-80df-b2dec9bbf31d_1200x675.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55fea1ff-bc5c-42fd-80df-b2dec9bbf31d_1200x675.png" width="1200" height="675" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/55fea1ff-bc5c-42fd-80df-b2dec9bbf31d_1200x675.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:675,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:222044,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://thezvi.substack.com/i/165878744?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55fea1ff-bc5c-42fd-80df-b2dec9bbf31d_1200x675.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55fea1ff-bc5c-42fd-80df-b2dec9bbf31d_1200x675.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55fea1ff-bc5c-42fd-80df-b2dec9bbf31d_1200x675.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55fea1ff-bc5c-42fd-80df-b2dec9bbf31d_1200x675.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F55fea1ff-bc5c-42fd-80df-b2dec9bbf31d_1200x675.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>OpenAI o3-pro has access to tools that make ChatGPT useful—it can search the web, analyze files, reason about visual inputs, use Python, personalize responses using memory, and more.</p><p><a href="https://x.com/sama/status/1932532561080975797" rel="">Sam Altman</a><span>: o3-pro is rolling out now for all chatgpt pro users and in the api.</span></p><p>it is really smart! i didnt believe the win rates relative to o3 the first time i saw them.</p></blockquote><p>Arena has gotten quite silly if treated as a comprehensive measure (as in Gemini 2.5 Flash is rated above o3), but as a quick heuristic, if we take a 64% win rate seriously, that would by the math put o3-pro ~100 above o3 at 1509 on Arena, crushing Gemini-2.5-Pro for the #1 spot. I would assume that most pairwise comparisons would have a less impressive jump, since o3-pro is essentially offering the same product as o3 only somewhat better, which means the result will be a lot less noisy than if it was up against Gemini. </p><p>So this both is a very impressive statistic and also doesn’t mean much of anything.</p><p><a href="https://x.com/nearcyan/status/1932612410843815979" rel="">The problem with o3-pro is that it is slow</a><span>. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82ab7635-4e1c-4438-a30a-0efb1db71fcd_500x628.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82ab7635-4e1c-4438-a30a-0efb1db71fcd_500x628.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82ab7635-4e1c-4438-a30a-0efb1db71fcd_500x628.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82ab7635-4e1c-4438-a30a-0efb1db71fcd_500x628.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82ab7635-4e1c-4438-a30a-0efb1db71fcd_500x628.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82ab7635-4e1c-4438-a30a-0efb1db71fcd_500x628.jpeg" width="302" height="379.312" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/82ab7635-4e1c-4438-a30a-0efb1db71fcd_500x628.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:628,&quot;width&quot;:500,&quot;resizeWidth&quot;:302,&quot;bytes&quot;:135570,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://thezvi.substack.com/i/165878744?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82ab7635-4e1c-4438-a30a-0efb1db71fcd_500x628.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82ab7635-4e1c-4438-a30a-0efb1db71fcd_500x628.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82ab7635-4e1c-4438-a30a-0efb1db71fcd_500x628.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82ab7635-4e1c-4438-a30a-0efb1db71fcd_500x628.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82ab7635-4e1c-4438-a30a-0efb1db71fcd_500x628.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><blockquote><p>Nearcyan: one funny note is that minor UX differences in how you display 'thinking'/loading/etc can easily move products from the bottom half of this meme to the top half. </p><p>Another note is anyone I know who is the guy in the bottom left is always extremely smart and a pleasure to speak with.</p><p>the real problem is I may be closer to the top right than the bottom left</p></blockquote><p>Today I had my first instance of noticing I’d gotten a text (during the night, in this case) and they got a response 20 minutes slower than they would have otherwise because I waited for o3-pro to give its answer to the question I’d been asked. </p><p><span>Thus, even with access to o3-pro at zero marginal compute cost, </span><a href="https://x.com/TheZvi/status/1933563490117300617" rel="">almost half of people reported they rarely use it for a given query, and only about a quarter said they usually use it</a><span>. </span></p><p><span>It is also super frustrating to run into errors when you are waiting 15+ minutes for a response, and </span><a href="https://x.com/TheZvi/status/1933563491819868288" rel="">reports of such errors were common</a><span> which matches my experience. </span></p><blockquote><p><a href="https://x.com/bindureddy/status/1932889892562088086" rel="">Bindu Reddy</a><span>: o3-Pro Is Not Very Good At Agentic Coding And Doesn't Score Higher Than o3 😿</span></p><p>After a lot of waiting and numerous retries, we have finally deployed o3-pro on LiveBench AI.</p><p>Sadly, the overall score doesn't improve over o3 🤷‍♂️</p><p>Mainly because it's not very agentic and isn't very good at tool use... it scores way below o3 on the agentic-coding category.</p><p>The big story yesterday was not o3-pro but the price decrease in o3!!</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F659752b0-22a3-4161-8aa8-b949acece1d0_900x569.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F659752b0-22a3-4161-8aa8-b949acece1d0_900x569.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F659752b0-22a3-4161-8aa8-b949acece1d0_900x569.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F659752b0-22a3-4161-8aa8-b949acece1d0_900x569.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F659752b0-22a3-4161-8aa8-b949acece1d0_900x569.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F659752b0-22a3-4161-8aa8-b949acece1d0_900x569.jpeg" width="900" height="569" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/659752b0-22a3-4161-8aa8-b949acece1d0_900x569.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:569,&quot;width&quot;:900,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:57576,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://thezvi.substack.com/i/165878744?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F659752b0-22a3-4161-8aa8-b949acece1d0_900x569.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F659752b0-22a3-4161-8aa8-b949acece1d0_900x569.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F659752b0-22a3-4161-8aa8-b949acece1d0_900x569.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F659752b0-22a3-4161-8aa8-b949acece1d0_900x569.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F659752b0-22a3-4161-8aa8-b949acece1d0_900x569.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Dominik Lukes: I think this take by @bindureddy very much matches the vibes I'm getting: it does not "feel" very agentic and as ready to reach for the right tools as o3 is - but it could just be because o3 keeps you informed about what it's doing in the CoT trace.</p></blockquote><p>I certainly would try o3-pro in cases where o3 was failing, if I’d already also tried Opus and Gemini first. I wonder if that agentic coding score drop actually represent an issue here, where because it is for the purpose of reasoning longer and they don’t want it endlessly web searching o3-pro is not properly inclined to exploit tools?</p><p><a href="https://x.com/dioscuri/status/1932934997901783266" rel="">o3-pro gets 8.5/10 on BaldurBench</a><span>, which is about creating detailed build guides for rapidly changing video games. Somewhat subjective but should still work.</span></p><blockquote><p><a href="https://x.com/_l_zahir/status/1932924771668566049" rel="">L Zahir</a><span>: bombs all my secret benchmarks, no better than o3.</span></p></blockquote><p><a href="https://x.com/LechMazur/status/1932897888650072275" rel="">Lech Mazur gives us four of his benchmarks</a><span>: A small improvement over o3 for Creative Writing Benchmark, a substantial boost from 79.5% (o3) or 82.5% (o1-pro) to 87.3% on Word Connections, no improvement on Thematic Generalization, very little improvement on Confabulations (avoiding hallucinations). The last one seems the most important to note. </span></p><p>Tyler Cowen was very positive, he seems like the perfect customer for o3-pro? By which I mean he can context shift easily so he doesn’t mind waiting, and also often uses queries where these models get a lot of value out of going at problems super hard, and relatively less value out of the advantages of other models (doesn’t want the personality, doesn’t want to code, and so on). </p><blockquote><p><a href="https://marginalrevolution.com/marginalrevolution/2025/06/o3-pro.html?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=o3-pro" rel="">Tyler Cowen</a><span>: It is very, very good. Hallucinates far less than other models. Can solve economics problems that o3 cannot. It can be slow, but that is what we have Twitter scrolling for, right? While we are waiting for o3 pro to answer a query we can </span><a href="https://x.com/polynoamial/status/1932532770594857350" rel="">read about</a><span>…</span><a href="https://x.com/WesRothMoney/status/1932546133982945501" rel="">o3 pro</a><span>.</span></p></blockquote><p>Contrast that with the score on Confabulations not changing. I am guessing there is a modest improvement, for reasons described earlier. </p><p><span>There are a number of people pointing out places o3-pro solves something o3 doesn’t, such has here </span><a href="https://x.com/0xSMW/status/1932803015750398064" rel="">it solved the gimbal uap mystery in 18 minutes</a><span>. </span></p><p>McKay Wrigley, eternal optimist, agrees on many fronts.</p><blockquote><p><a href="https://x.com/mckaywrigley/status/1932607750649049571" rel="">McKay Wrigley</a><span>: My last 4 o3 Pro requests in ChatGPT… It thought for: - 26m 10s - 23m 45s - 19m 6s - 21m 18s Absolute *powerhouse* of a model.</span></p><p>Testing how well it can 1-shot complex problems - impressed so far.</p><p>It’s too slow to use as a daily driver model (makes sense, it’s a beast!), but it’s a great “escalate this issue” model. If the current model you’re using is struggling with a task, then escalate it to o3 pro.</p><p>This is not a “vibe code” model.</p><p>This is the kind of model where you’ll want to see how useful it is to people like Terence Tao and Tyler Cowen.</p><p>Btw the point of this post was that I’m happy to have a model that is allowed to think for a long time.</p><p>To me that’s the entire point of having a “Pro” version of the model - let it think!</p><p>Obviously more goes into evaluating if it’s a great model (imo it’s really powerful).</p></blockquote><p>Here’s a different kind of vibe coding, perhaps?</p><blockquote><p><a href="https://x.com/lisperati/status/1932926392452460709" rel="">Conrad Barski</a><span>: For programming tasks, I can give o3 pro some code that needs a significant revision, then ramble on and on about what the various attributes of the revision need to be and then it can reliably generate an implementation of the revision.</span></p><p>It feels like with previous models I had to give them more hand holding to get good results, I had to write my requests in a more thoughtful, structured way, spending more time on prompting technique.</p><p>o3 pro, on the other hand, can take loosely-connected constraints and then "fill in the gaps" in a relatively intelligent way- I feel it does this better than any other model so far.</p></blockquote><p>The time cost and dollar costs are very real. </p><blockquote><p><a href="https://x.com/mattshumer_/status/1932592146030178478" rel="">Matt Shumer</a><span>: My initial take on o3 Pro:</span></p><p>It is not a daily-driver coding model.</p><p>It's a superhuman researcher + structured thinker, capable of taking in massive amounts of data and uncovering insights you would probably miss on your own.</p><p>Use it accordingly. </p><p>I reserve the right to alter my take.</p><p>Bayram Annokov: slow, expensive, and veeeery good - definitely a jump up in analytical tasks</p><p>Emad: 20 o3 prompts &gt; o3 pro except for some really advanced specific stuff I have found Only use it as a final check really or when stumped.</p><p>Eyes Alight: it is so very slow it took 13 minutes to answer a trivial question about a post on Twitter. I understand the appeal intellectually of an Einstein at 1/20th speed, but in reality I'm not sure I have the patience for it.</p><p><a href="https://x.com/ClayCampaigne/status/1933236232479518814" rel="">Clay</a><span>: o3-pro achieving breakthrough performance in taking a long time to think.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae776b7-587d-4aec-908c-a1688990ac9d_709x900.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae776b7-587d-4aec-908c-a1688990ac9d_709x900.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae776b7-587d-4aec-908c-a1688990ac9d_709x900.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae776b7-587d-4aec-908c-a1688990ac9d_709x900.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae776b7-587d-4aec-908c-a1688990ac9d_709x900.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae776b7-587d-4aec-908c-a1688990ac9d_709x900.jpeg" width="351" height="445.5571227080395" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3ae776b7-587d-4aec-908c-a1688990ac9d_709x900.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:900,&quot;width&quot;:709,&quot;resizeWidth&quot;:351,&quot;bytes&quot;:57616,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://thezvi.substack.com/i/165878744?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae776b7-587d-4aec-908c-a1688990ac9d_709x900.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae776b7-587d-4aec-908c-a1688990ac9d_709x900.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae776b7-587d-4aec-908c-a1688990ac9d_709x900.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae776b7-587d-4aec-908c-a1688990ac9d_709x900.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3ae776b7-587d-4aec-908c-a1688990ac9d_709x900.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><a href="https://x.com/techczech/status/1932705769809461282" rel="">Dominik Lukes</a><span>: Here's my o3 Pro testing results thread. Preliminary conclusions:</span></p><p>- great at analysis</p><p>- slow and overthinking simple problems</p><p>- o3 is enough for most tasks</p><p>- still fails SVG bike and local LLM research test</p><p>- very few people need it</p><p>- it will take time to develop a feel for it</p><p>Kostya Medvedovsky: For a lot of problems, it reminds me very strongly of Deep Research. Takes about the same amount of time, and will spend a lot of effort scouring the web for the answer to the question.</p><p>Makes me wish I could optionally turn off web access and get it to focus more on the reasoning aspect.</p><p>This may be user error and I should be giving it  *way* more context.</p><p>Violet: you can turn search off, and only turn search on for specific prompts.</p><p>Xeophon: TL;DR:</p><p>o3 pro is another step up, but for going deep, not wide. It is good to go down one path, solve one problem; not for getting a broad overview about different topics/papers etc. Then it hallucinates badly, use ODR for this.</p></blockquote><p>Part of ‘I am very intelligent’ is knowing when to think for longer and when not to. In that sense, o3-pro is not so smart, you have to take care of that question yourself. I do understand why this decision was made, let the user control that. </p><p>I agree with Lukes that most people do not ‘need’ o3 pro and they will be fine not paying for it, and for now they are better off with their expensive subscription (if any) being Claude Max. But even if you don’t need it, the queries you benefit from can still be highly useful.</p><p>It makes sense to default to using Opus and o3 pro (and for quick stuff Sonnet) </p><p>o3-pro is too slow to be a good ‘default’ model, especially for coding. I don’t want to have to reload my state in 15 minute intervals. It may or may not be good for the ‘call in the big guns’ role in coding, where you have a problem that Opus and Gemini (and perhaps regular o3) have failed to solve, but which you think o3-pro might get. </p><p>Here’s one that both seems central wrong but also makes an important point:</p><blockquote><p>Nabeel Qureshi: You need to think pretty hard to get a set of evals which allows you to even distinguish between o3 and o3 pro. </p><p>Implication: "good enough AGI" is already here.</p></blockquote><p>The obvious evals where it does better are Codeforces, and also ‘user preferences.’ Tyler Cowen’s statement suggests hallucination rate, which is huge if true (and it better be true, I’m not waiting 20 minutes that often to get an o3-level lying liar.) Tyler also reports there are questions where o3 fails and o3-pro succeeds, which is definitive if the gap is only one way. And of course if all else fails you can always have them do things like play board games against each other, as one answer suggests. </p><p>Nor do I think either o3 or o3-pro is the AGI you are looking for.</p><p>However, it is true that for a large percentage of tasks, o3 is ‘good enough.’ That’s even true in a strict sense for Claude Sonnet or even Gemini Flash. Most of the time one has a query, the amount of actually needed intelligence is small. </p><blockquote><p>In the limit, we'll have to rely on AIs to tell us which AI model is smarter, because we won't be smart enough to tell the difference. What a weird future.</p><p>(Incidentally, this has already been the case in chess for years. Humans cannot tell the difference between a 3300 elo and a 3600 elo chess engine; we just make them fight it out and count the number of wins.)</p></blockquote><p>You can tell 3300 from 3600 in chess, but only because you can tell who won. If almost any human looked at individual moves, you’d have very little idea.</p><p>I always appreciate people thinking at the limit rather than only on the margin. This is a central case of that. </p><p>Here’s one report that it’s doing well on the fully informal FictionBench:</p><blockquote><p><a href="https://x.com/chatgpt21/status/1933050795240415449" rel="">Chris</a><span>: Going to bed now, but had to share something crazy: been testing the o3 pro model, and honestly, the writing capabilities are astounding. Even with simple prompts, it crafts medium to long-form stories that make me deeply invested &amp; are engaging they come with surprising twists, and each one carries this profound, meaningful depth that feels genuinely human. </span></p><p>The creativity behind these narratives is wild far beyond what I’d expect from most writers today. We’re talking sophisticated character development, nuanced plot arcs, and emotional resonance, all generated seamlessly. It’s genuinely hard to believe this is early-stage reinforcement learning with compute added at test time; the potential here is mind blowing. We’re witnessing just the beginning of AI enhanced storytelling, and already it’s surpassing what many humans can create. Excited to see what’s next with o4 Goodnight!</p></blockquote><p>This contrasts with:</p><blockquote><p>Archivedvideos: Really like it for technical stuff, soulless</p><p><a href="https://x.com/JuliusSimonelli/status/1932944540517945732" rel="">Julius</a><span>: I asked it to edit an essay and it took 13 minutes and provided mediocre results. Different from but slightly below the quality of 4o. Much worse than o3 or either Claude 4 model</span></p></blockquote><p><span>Other positive reactions include </span><a href="https://x.com/mlwigdahl/status/1933524889085866268" rel="">Matt Wigdahl being impressed</a><span> on a hairy RDP-related problem, </span><a href="https://x.com/a66mike99/status/1933140863103959206" rel="">a66mike99 getting interesting output and pushback on the request</a><span> (in general I like this, although if you’re thinking for 20 minutes this could be a lot more frustrating?), </span><a href="https://x.com/niplav_site/status/1932901796994781356" rel="">niplav being impressed by results on a second attempt after Claude crafted a better prompt</a><span> (this seems like an excellent workflow!), and </span><a href="https://x.com/Sithis3/status/1933565284096315475" rel="">Sithis3 saying o3-pro solves many problems o3 struggles on</a><span>. </span></p><p><a href="https://x.com/erikphoel/status/1932805295773753551" rel="">The obvious counterpoint is some people didn’t get good responses</a><span>, and saw it repeating the flaws in o3.</span></p><blockquote><p>Erik Hoel: First o3 pro usage. Many mistakes. Massive overconfidence. Clear inability to distinguish citations, pay attention to dates. Does anyone else actually use these models? They may be smarter on paper but they are increasingly lazy and evil in practice.</p><p>Kukutz: very very very slow, not so clever (can't solve my semantic puzzle).</p><p><a href="https://x.com/HoskinsAllen/status/1933160300808970481" rel="">Allen</a><span>: I think it’s less of an upgrade compared to base model than o1-pro was. Its general quality is better on avg but doesn’t seem to hit “next-level” on any marks. Usually mentions the same things as o3.</span></p><p>I think OAI are focused on delivering GPT-5 more than anything.</p></blockquote><p><a href="https://x.com/TheXeophon/status/1933451968262905864" rel="">This thread from Xeophon features reactions that are mixed but mostly meh</a><span>. </span></p><p>Or to some it simply doesn’t feel like much of a change at all.</p><blockquote><p><a href="https://x.com/TheZvi/status/1932895110745993637" rel="">Nikita Sokolsky</a><span>: Feels like o3’s outputs after you fix the grammar and writing in Claude/Gemini: it writes less concisely but haven’t seen any “next level” prompt responses just yet.</span></p><p>MartinDeVido: Meh....</p></blockquote><p>Here’s a fun reminder that details can matter a lot:</p><blockquote><p><a href="https://x.com/jjhughes/status/1932975519147896992" rel="">John Hughes</a><span>: I was thrilled yesterday: o3-pro was accepting ~150k tokens of context (similar to Opus), a big step up from regular o3, which allows only a third as much in ChatGPT. @openai seems to have changed that today. Queries I could do yesterday are now rejected as too long.</span></p><p>With such a low context limit, o3-pro is much less useful to lawyers than o1-pro was. Regular o3 is great for quick questions/mini-research, but Gemini is better at analyzing long docs and Opus is tops for coding. Not yet seeing answers where o3-pro is noticeably better than o3.</p></blockquote><p>I presume that even at $200/month, the compute costs of letting o3-pro have 150k input tokens would add up fast, if people actually used it a lot. </p><p><a href="https://x.com/jerryjliu0/status/1934043120033010085" rel="">This is one of the things</a><span> I’ve loved the most so far about o3-pro. </span></p><blockquote><p>Jerry Liu: o3-pro is extremely good at reasoning, extremely slow, and extremely concise - a top-notch consultant that will take a few minutes to think, and output bullet points. </p><p>Do not ask it to write essays for you.</p></blockquote><p>o3-pro will make you wait, but its answer will not waste your time. This is a sharp contrast to Deep Research queries, which will take forever to generate and then include a ton of slop.</p><p>It is not the main point but I must note the absence of a system card update. When you are releasing what is likely the most powerful model out there, o3-pro, was everything you needed to say truly already addressed by the model card for o3? </p><blockquote><p><span>OpenAI: As o3-pro uses the same underlying model as o3, </span><a href="https://t.co/iqXaDSAtQq" rel="">full safety details can be found in the o3 system card</a><span>.</span></p><p><a href="https://x.com/Miles_Brundage/status/1932531528086798370" rel="">Miles Brundage</a><span>: This last sentence seems false? </span></p><p>The system card does not appear to have been updated even to incorporate the information in this thread.</p><p>The whole point of the term system card is that the model isn’t the only thing that matters.</p><p>If they didn’t do a full Preparedness Framework assessment, e.g. because the evals weren’t too different and they didn’t consider it a good use of time given other coming launches, they should just say that, I think.</p><p>If o3-pro were the max capability level, I wouldn't be super concerned about this, and I actually suspect it is the same Preparedness Framework level as o3. </p><p>The problem is that this is not the last launch, and lax processes/corner-cutting/groupthink get more dangerous each day.</p><p>As OpenAI put it, ‘there’s no such thing as a small launch.’</p></blockquote><p><a href="https://help.openai.com/en/articles/9624314-model-release-notes" rel="">The link they provide</a><span> goes to ‘Model Release Notes,’ which is not quite nothing, but it isn’t much and does not include a Preparedness Framework evaluation. </span></p><p>I agree with Miles that if you don’t want to provide a system card for o3-pro that This Is Fine, but you need to state your case for why you don’t need one. This can be any of:</p><ol><li><p>The old system card tested for what happens at higher inference costs (as it should!) so we effectively were testing o3-pro the whole time, and we’re fine.</p></li><li><p>The Preparedness team tested o3-pro and found it not appreciably different from o3 in the ways we care about, providing no substantial additional uplift or other concerns, despite looking impressive in some other ways.</p></li><li><p>This is only available at the $200 level so not a release of o3-pro so it doesn’t count (I don’t actually think this is okay, but it would be consistent with previous decisions I also think aren’t okay, and not an additional issue.) </p></li></ol><p>As far as I can tell we’re basically in scenario #2, and they see no serious issues here. Which again is fine if true, and if they actually tell us that this is the case. But the framework is full of ‘here are the test results’ and presumably those results are different now. I want o3-pro on those charts.</p><p>What about alignment otherwise? Hard to say. I did notice this (but did not attempt to make heads or tails of the linked thread), seems like what you would naively expect:</p><blockquote><p><a href="https://x.com/YeshuaGod22/status/1933395147934331140" rel="">Yeshua God</a><span>: </span><a href="https://t.co/KI8CPUGPd6" rel="">Following the mesa-optimiser recipe to the letter.</a><span> @aidan_mclau very troubling.</span></p></blockquote><p>For many purposes, the 80% price cut in o3 seems more impactful than o3-pro. That’s a huge price cut, whereas o3-pro is still largely a ‘special cases only’ model.</p><blockquote><p>Aaron Levie: With OpenAI dropping the price of o3 by 80%, today is a great reminder about how important it is to build for where AI is going instead of just what's possible now. You can now get 5X the amount of output today for the same price you were paying yesterday.</p><p>If you’re building AI Agents, it means it's far better to build capabilities that are priced and designed for the future instead of just economically reasonable today. </p><p>In general, we know there's a tight correlation between the amount of compute spent on a problem and the level of successful outcomes we can get from AI. This is especially true with AI Agents that potentially can burn through hundreds of thousands or millions of tokens on a single task. </p><p>You're always making trade-off decisions when building AI Agents around what level of accuracy or success you want and how much you want to spend: do you want to spend $0.10 for something to be 95% successful or $1 for something to be 99% successful? A 10X increase in cost for just a 4 pt improvement in results? At every price:success intersection a new set of use-cases from customers can be unlocked.</p><p>Normally when building technology that moves at a typical pace, you would primarily build features that are economically viable today (or with some slight efficiency gains anticipated at the rate of Moore's Law, for instance). You'd be out of business otherwise. But with the cost of AI inference dropping rapidly, the calculus completely changes. In a world where the cost of inference could drop by orders of magnitude in a year or two, it means the way we build software to anticipate these cost drops changes meaningfully.</p><p>Instead of either building in lots of hacks to reduce costs, or going after only the most economically feasible use-cases today, this instructs you to build the more ambitious AI Agent capabilities that would normally seem too cost prohibitive to go after. Huge implications for how we build AI Agents and the kind of problems to go after.</p></blockquote><p>I would say the cost of inference not only might drop an order of magnitude in a year or two, if you hold quality of outputs constant it is all but certain to happen at least one more time. Where you ‘take your profits’ in quality versus quantity is up to you.</p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Should we design for iffy internet? (157 pts)]]></title>
            <link>https://bytes.zone/posts/should-we-design-for-iffy-internet/</link>
            <guid>44298656</guid>
            <pubDate>Tue, 17 Jun 2025 13:02:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bytes.zone/posts/should-we-design-for-iffy-internet/">https://bytes.zone/posts/should-we-design-for-iffy-internet/</a>, See on <a href="https://news.ycombinator.com/item?id=44298656">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p><em>Brian Hicks, June 16, 2025</em></p><p>I keep hearing claims like this:</p><ul><li>Not everyone in the US has access to stable, reliable internet, even in 2025.</li><li>Web developers should stop assuming people have fast internet connections and slim their payloads accordingly.</li></ul><p>This seems intuitively true to me—programmers are gonna have better connectivity because that takes money, and programmers are well-paid. But what's the actual scope of the problem?</p><p>I dug around, and here's some data. My goal here is not to beat anyone over the head with "THOU SHALT NOT ASSUME GOOD INTERNET" but to give an idea about the scope of broadband rollout in the US in a way that can help inform choices we make when designing software.</p><p><strong>If you don't feel like reading this whole thing, here's the bottom line up front:</strong> you can probably assume internet access in somewhere around 97% of US households, but you should not assume that it's better than around 25Mbps down and 3Mbps up, and latency may be significantly worse than you previously assumed. This is likely worse for B2C software than B2B.</p><span id="continue-reading"></span><p>I'm going to pull from two US government agencies here: the <a href="https://www.fcc.gov/">Federal Communications Commission (FCC)</a>and the <a href="https://nces.ed.gov/">National Center for Education Statistics (NCES)</a> (part of the Department of Education.) All the data I'm referencing was published well before the current administration started gutting the bureaucracy, so I think it's fairly reliable.</p><h2 id="assumptions">Assumptions</h2><p>Before we begin, there are a bunch of ways to define "stable" or "reliable" internet connections. For the purposes of this post, I'm defining that as a <strong>terrestrial link with at least 25Mbps down and 3Mbps up.</strong></p><ul><li>Terrestrial because—well, have you ever tried to use a satellite connection for anything real? Latency is awful, and the systems tend to go down in bad weather. They also have had fairly low data caps historically so you had to use your connection judiciously, although this may be changing.<sup><a href="#satellite">1</a></sup><sup><a href="#my-history">2</a></sup></li><li>25/3Mpbs because that's a fairly common cable package speed, and also around the minimum I’ve been able to use modern SaaS apps on without it getting ridiculously frustrating. <a href="https://support.zoom.com/hc/en/article?id=zm_kb&amp;sysparm_article=KB0060748#h_d278c327-e03d-4896-b19a-96a8f3c0c69c">Zoom says</a> you need 1–4 Mbps in both directions to do a video call.</li></ul><p>The FCC's broadband map lets you set both these criteria. Let's have a look at it.</p><h2 id="the-fcc-broadband-map">The FCC Broadband Map</h2><p>The FCC tracks access to broadband internet in the US. As a result, they publish a map that's more accurate than the maps you see from ISPs. This isn't <em>completely</em> error-free, but individuals and companies can both submit data on coverage at a street address level and challenge inaccuracies in the existing data. For our purposes, I think it's good enough!</p><p>I'm going to grab some screenshots of the map to fix it at the current data for discussion. That way we can get an idea about regional coverage.</p><p>Strangely, they don't let you zoom out enough to grab a screenshot of the whole country so I'm going to look at the west. That'll get both urban and rural coverage, as well as several famously internet-y locations (San Francisco Bay Area, Seattle.)</p><p>If you want to follow along or compare how the data has changed since this post was published, you can get the map yourself at <a href="https://broadbandmap.fcc.gov/">broadbandmap.fcc.gov</a>.</p><p>First, here's a hex map of coverage using the criteria we set above. The darker each hex is, the higher the percent coverage within it. Dark blue is 100%, white is 0%, grays or faded blues are in between.</p><p><img src="https://bytes.zone/images/us-national-broadband-map-terrestrial-25-3-2025-06-10.png" alt="A map of the western US with a color scale overlaid showing access to broadband. Higher-population areas are shown to have better access, generally, with the exception of the Dakotas which have excellent access throughout the states."></p><p>This shows pretty much what I'd expect: coverage is fine in and around cities and less great in rural areas.<sup><a href="#mobile">3</a></sup> (The Dakotas are an interesting exception; <a href="https://www.bek.coop/">there's a co-op up there</a> that connected a ton of folks with gigabit fiber. Pretty cool!)</p><p>Although, remember that these are <em>minimum</em> criteria. When I'm building software, I'm mostly doing it on my home internet. A test just now says I get 367/71Mpbs. What does the country look like if I were to expect all my users to have similar connections? The map lets us filter for 250/25; let's look:</p><p><img src="https://bytes.zone/images/us-national-broadband-map-terrestrial-250-25-2025-06-10.png" alt="A map of the western US with a color scale overlaid showing access to broadband at a higher level. Rural areas show much less availability than in the previous map, although access in the Dakotas is still excellent."></p><p>Cities are pretty much unchanged, but rural coverage gets much worse. (Except again for North Dakota, the reigning champion of rural fiber.)</p><p>So what does this tell us about how we should design software? One big takeaway: if you design for the <em>availability</em> of fast internet connections, you'll exclude many people in rural areas.</p><p>This may or may not be OK for your market—"good internet" tends to be in population centers, and population centers tend to contain more businesses and consumers. You have to make that call!</p><p>However, it's also worth keeping in mind that this is a map of commercial availability, not market penetration. Hypothetically, you could get the average speed of a US residential internet connection, but the FCC doesn't make such a statistic available.<sup><a href="#speed-stat-third-party">4</a></sup></p><p>However, we have another source of data!</p><h2 id="student-internet-access">Student Internet Access</h2><p>The US Department of Education occasionally tracks student internet access. Since classwork and homework have moved more online (especially during the early days of COVID) it's useful data for policy-making. The <a href="https://www.thefreelibrary.com/Relationship+Between+Internet+Access+and+Literacy+Among+OECD...-a0795707532">most recent data I could find is from 2021</a> but it gives us both a baseline for internet availability and some demographic data. Unfortunately, they don't track bandwidth, just raw availability. Still useful, though.</p><p>Here are the top-line statistics for all students in the US across several versions of the report:</p><table><thead><tr><th>Category</th><th>% Available 2019</th><th>% Available 2021</th><th>Difference</th></tr></thead><tbody><tr><td>Any internet access</td><td>94.6%</td><td>97.1%</td><td>+2.5</td></tr><tr><td>Smartphone-only</td><td>6.5%</td><td>4.5%</td><td>-2.0</td></tr><tr><td>No internet Access</td><td>5.4%</td><td>2.9%</td><td>-2.5</td></tr></tbody></table><p>In 2021, they say that these statistics cover 66,108,000 students, which means 2.97 million students only had mobile access as of 2021.</p><p>Access gets worse, of course, with lower household income. Here's how those stats look for the lowest quartile:</p><table><thead><tr><th>Category</th><th>% Available 2019</th><th>% Available 2021</th><th>Difference</th></tr></thead><tbody><tr><td>Any internet access</td><td>88.6%</td><td>94.4%</td><td>+5.8</td></tr><tr><td>Smartphone-only</td><td>14.1%</td><td>9.8%</td><td>-4.3</td></tr><tr><td>No internet access</td><td>11.4%</td><td>5.6%</td><td>-5.8</td></tr></tbody></table><p>Despite the fact that these numbers are going down, that's still a huge number of people in absolute terms (1.87 million students in this category with only mobile access.)</p><h2 id="what-do-we-do-with-this-information">What Do We Do With This Information?</h2><p>So that's a lot of words to say this: despite gains in the last couple of years, it's still not safe to assume that every user of your software either has access to stable internet, or is willing and able to pay to get high speeds.</p><p>That said, I'm deliberately not making any moral judgments here. If you think you're in a situation where you can ignore this data, I'm not going to come after you. But if you dismiss it out of hand, you're likely going to be putting your users (and business) in a tough spot.</p><p>I think it's worth considering a couple of scenarios in the parts of your software that someone interacts with regularly:</p><ol><li>What if that person is on a slow link? If you've never had bad internet access, maybe think of this as plane wifi. Rural satellite connections behave very similarly: high latency, speed and (sometimes) low data caps.</li><li>What if that person is on a mobile/metered/capped network? Remember that 4G is like 5/1Mbps, and 3G is even worse. Big downloads are probably not a great idea.</li></ol><p>This is also a very US-centric view, plus it doesn't consider latency from distance between your data center and your user's device. Still, though, I think this shows that this problem is real and we should take it into account when designing software.</p><div id="my-history"><p><sup>2</sup></p><p>I grew up in a semi-rural area (mountains) and this was the only real option. As a kid, I really hated it! The latency was too bad to play games with my friends online, and I also regularly hit our household's download cap and got us all throttled to basically-dialup for the rest of the month.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No Hello (215 pts)]]></title>
            <link>https://nohello.net/en/</link>
            <guid>44297431</guid>
            <pubDate>Tue, 17 Jun 2025 10:09:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nohello.net/en/">https://nohello.net/en/</a>, See on <a href="https://news.ycombinator.com/item?id=44297431">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wholesite">
  <div>
      
      <p><span>please don't say just hello in chat</span></p><h2>
        Imagine calling someone on the phone, going <em>hello!</em> then putting them on hold... 🤦‍♀️
      </h2>
    </div>

  <div>
    <div>
      <h2>❌ Don't do this</h2>
      <div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/MxF06xdCHJ-128.webp 128w"><img alt="Keith's Slack avatar" src="https://nohello.net/img/MxF06xdCHJ-128.jpeg" width="128" height="128"></picture>
          <p><span>Keith</span>
          <span>2:15 PM</span><br>
          <span>hi</span>
        </p></div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/CGi-z9VgRi-128.webp 128w"><img alt="Tim's Slack avatar" src="https://nohello.net/img/CGi-z9VgRi-128.jpeg" width="128" height="128"></picture>
          <p><span>Tim</span>
          <span>2:19 PM</span><br>
          <span>...?</span>
        </p></div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/MxF06xdCHJ-128.webp 128w"><img alt="Keith's Slack avatar" src="https://nohello.net/img/MxF06xdCHJ-128.jpeg" width="128" height="128"></picture>
          <p><span>Keith</span>
          <span>2:20 PM</span><br>
          <span>what time was taht thing again?</span>
        </p></div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/CGi-z9VgRi-128.webp 128w"><img alt="Tim's Slack avatar" src="https://nohello.net/img/CGi-z9VgRi-128.jpeg" width="128" height="128"></picture>
          <p><span>Tim</span>
          <span>2:20 PM</span><br>
          <span>oh - 3:30 mate</span>
        </p></div>
      </div>
    </div>
    <div>
          <p>Note that Keith could have got his answer minutes sooner, and needn't have kept Tim waiting. In fact, Tim could have started thinking about the question right away!</p>
<p>People who do this are generally trying to be polite by not jumping right into the request, like one would in person or on the phone - and that's great! But it's 2022 and chat is neither of those things. For most people, typing is much slower than talking. So despite best intentions, <strong>you're actually just making the other person wait</strong> for you to phrase your question, which is lost productivity (and kinda annoying).</p>
<p>The same goes for:</p>
<ul>
<li>"Hello, are you around?"</li>
<li>"hi sophie - quick question."</li>
<li>"You got a sec?"</li>
<li>"yt?"</li>
<li>"ping"</li>
<li>etc.</li>
</ul>
<p><strong>Just ask the question!</strong> 😫</p>

        </div>
  </div>
  <div>
    <div>
      <h2>✅ Instead try this</h2>
      <div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/4gebfK1xtc-128.webp 128w"><img alt="Dawn's Slack avatar" src="https://nohello.net/img/4gebfK1xtc-128.jpeg" width="128" height="128"></picture>
          <p><span>Dawn</span>
          <span>2:15 PM</span><br>
          <span>Hiya! What time was that thing?</span>
        </p></div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/CGi-z9VgRi-128.webp 128w"><img alt="Tim's Slack avatar" src="https://nohello.net/img/CGi-z9VgRi-128.jpeg" width="128" height="128"></picture>
          <p><span>Tim</span>
          <span>2:15 PM</span><br>
          <span>hey, 3:30</span>
        </p></div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/4gebfK1xtc-128.webp 128w"><img alt="Dawn's Slack avatar" src="https://nohello.net/img/4gebfK1xtc-128.jpeg" width="128" height="128"></picture>
          <p><span>Dawn</span>
          <span>2:15 PM</span><br>
          <span>Ta - seeya then!</span>
        </p></div>
        <div>
          <picture><source type="image/webp" srcset="https://nohello.net/img/CGi-z9VgRi-128.webp 128w"><img alt="Tim's Slack avatar" src="https://nohello.net/img/CGi-z9VgRi-128.jpeg" width="128" height="128"></picture>
          <p><span>Tim</span>
          <span>2:16 PM</span><br>
          <span>👌 np</span>
        </p></div>
      </div>
    </div>
    <div>
          <p>If you feel it's a bit brusque to simply say "Hi" and ask the question, <strong>you can still preface your message with as many pleasantries as you see fit.</strong></p>
<p>For example:</p>
<ul>
<li>"hey man, what's up? also, any idea when that thing's due?"</li>
<li>"Hi there! Hope you're well. I'm after the latest deck, when you get a sec :)"</li>
<li>"hey, if you're not busy, could you update those NFRs?"</li>
<li>etc.</li>
</ul>
<p>It may seem trivial, but asking your question before getting that initial salutatory reply also allows for <strong>asynchronous communication</strong>. If the other party is away, and you leave before they come back, they can still answer your question, instead of just staring at a "Hello" and wondering what they missed.</p>
<p>When done right - everyone's happy! 🎉</p>

        </div>
  </div>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[KiCad and Wayland Support (102 pts)]]></title>
            <link>https://www.kicad.org/blog/2025/06/KiCad-and-Wayland-Support/</link>
            <guid>44297381</guid>
            <pubDate>Tue, 17 Jun 2025 09:58:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kicad.org/blog/2025/06/KiCad-and-Wayland-Support/">https://www.kicad.org/blog/2025/06/KiCad-and-Wayland-Support/</a>, See on <a href="https://news.ycombinator.com/item?id=44297381">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <article>
      <nav aria-label="breadcrumb">
	<ol>
		<li><a href="https://www.kicad.org/">Home</a></li>
		
	
		
	
		
	
	

	
	
	<li>
		<a href="https://www.kicad.org/blog/">Blog</a>
	</li>
	

	
	
	<li aria-current="page">
		<a href="https://www.kicad.org/blog/2025/06/KiCad-and-Wayland-Support/">KiCad and Wayland Support</a>
	</li>
	

	</ol>
</nav>


      <header>
        
        
        <section>
          Written by&nbsp;The KiCad Development Team<p>
              Published <time datetime="2025-06-10">
              2025-06-10</time>
          </p>
        </section>
      </header>
      <section>
          <p>The KiCad development team frequently receives questions about our support for Wayland.  Given that <a href="https://pagure.io/fesco/issue/3408">Fedora</a> and <a href="https://discourse.ubuntu.com/t/ubuntu-25-10-drops-support-for-gnome-on-xorg/62538">Ubuntu</a> are both planning to drop X11 support from their main desktop environments in the near future, we want to provide clear, transparent guidance to our users about the current state of Wayland support in KiCad.</p>
<div>
<h2 id="_current_status_is_functional_but_degraded">Current Status Is Functional but Degraded</h2>
<div>
<p>KiCad does run on Wayland systems, but with significant limitations and known issues that substantially degrade the user experience. While you can design PCBs using KiCad on Wayland, you will encounter numerous problems that we cannot fix at the application level.</p>
<p>The following problems are known issues in Wayland protocols or their implementation in desktop compositors, window managers or other layers in the display stack that are beyond our ability to resolve:</p>
<div>
<h3 id="_window_management_issues">Window Management Issues</h3>
<div>
<ul>
<li>
<p><em>Window placement and restoration</em>: Wayland does not currently allow controlling window position. This means that when you open KiCad, it can not remember where you last placed your windows.</p>
</li>
<li>
<p><em>Docked panel positioning</em>: Docked panels and toolbars cannot be properly managed or restored</p>
</li>
<li>
<p><em>Multi-window coordination</em>: Problems with managing multiple KiCad windows simultaneously</p>
</li>
<li>
<p><em>Window dragging limitations</em>: Dragging tabs and panels between areas is broken or unreliable</p>
</li>
</ul>
</div>
</div>
<div>
<h3 id="_input_and_interaction_problems">Input and Interaction Problems</h3>
<div>
<ul>
<li>
<p><em>Cursor/pointer warping</em>: Essential for many CAD operations, it is conditionally available in some Wayland implementations, depending on support for optional protocol extensions</p>
</li>
<li>
<p><em>Focus management</em>: Unpredictable window focus behavior that can interrupt workflows</p>
</li>
<li>
<p><em>Input device handling</em>: Various issues with specialized input devices and hotkeys</p>
</li>
</ul>
</div>
</div>
<div>
<h3 id="_performance_and_stability_issues">Performance and Stability Issues</h3>
<div>
<ul>
<li>
<p><em>OpenGL call throttling</em>: When windows are occluded, some compositors throttle OpenGL calls, causing freezes, instead of just letting the client know the window state</p>
</li>
<li>
<p><em>High CPU/GPU usage</em>: Resource consumption spikes that don’t occur under X11, which is a workaround for OpenGL call throttling</p>
</li>
<li>
<p><em>Graphical glitches</em>: Rendering artifacts and display corruption</p>
</li>
<li>
<p><em>Application freezes and crashes</em>: Instability issues specific to the Wayland environment</p>
</li>
<li>
<p><em>Clipboard functionality</em>: Unreliable copy/paste operations between applications</p>
</li>
</ul>
</div>
</div>
<div>
<h3 id="_dialog_and_ui_limitations">Dialog and UI Limitations</h3>
<div>
<ul>
<li>
<p><em>Modal dialog behavior</em>: Issues with dialog positioning, focus, and interaction</p>
</li>
<li>
<p><em>External tool integration</em>: Problems launching and managing external applications</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div>
<h2 id="_why_these_issues_persist">Why These Issues Persist</h2>
<div>
<p>These problems exist because Wayland’s design omits basic functionality that desktop applications for X11, Windows and macOS have relied on for decades—things like being able to position windows or warp the mouse cursor. This functionality was omitted by design, not oversight.</p>
<p>The fragmentation doesn’t help either. GNOME interprets protocols one way, KDE another way, and smaller compositors yet another way. As application developers, we can’t depend on a consistent implementation of various Wayland protocols and experimental extensions. Linux is already a small section of the KiCad userbase.  Further fragmentation by window manager creates an unsustainable support burden.
Most frustrating is that we can’t fix these problems ourselves. The issues live in Wayland protocols, window managers, and compositors. These are not things that we, as application developers, can code around or patch.</p>
<p>We are not the only application facing these challenges and we hope that the Wayland ecosystem will mature and develop a more balanced, consistent approach that allows applications to function effectively.  But we are not there yet.</p>
</div>
</div>
<div>
<h2 id="_our_approach_and_policy">Our Approach and Policy</h2>
<div>
<p>The KiCad team has made the strategic decision to:</p>
<div>
<ul>
<li>
<p><strong>Avoid window manager-specific workarounds</strong> that would require maintaining separate code paths for different desktop environments</p>
</li>
<li>
<p><strong>Continue building and testing</strong> Wayland compatibility where possible, but without dedicating primary development resources to it</p>
</li>
<li>
<p><strong>Focus our limited development time</strong> on features and improvements that benefit all users</p>
</li>
<li>
<p><strong>Maintain clear documentation</strong> about Wayland limitations to set appropriate user expectations</p>
</li>
</ul>
</div>
<div>
<h3 id="_bug_report_policy_for_wayland_users">Bug Report Policy for Wayland Users</h3>
<p><strong>We do not investigate or support bug reports related to Wayland-specific issues.</strong> This includes problems with:</p>
<div>
<ul>
<li>
<p>Window positioning, sizing, or focus</p>
</li>
<li>
<p>Application freezes or crashes that don’t occur on X11</p>
</li>
<li>
<p>High CPU/GPU usage unique to Wayland</p>
</li>
<li>
<p>Input device problems specific to Wayland</p>
</li>
<li>
<p>Graphical glitches or rendering issues</p>
</li>
<li>
<p>Clipboard functionality problems</p>
</li>
<li>
<p>Any other issues that cannot be reproduced on X11 systems</p>
</li>
</ul>
</div>
<p>Bug reports about KiCad’s internal functionality that don’t involve window management are still welcome and will be investigated normally.</p>
</div>
</div>
</div>
<div>
<h2 id="_recommendations_for_users">Recommendations for Users</h2>
<div>
<div>
<h3 id="_for_professional_use">For Professional Use</h3>
<p>If you use KiCad professionally or require a reliable, full-featured experience, we strongly recommend:</p>
<div>
<ol>
<li>
<p>Use X11-based desktop environments such as:</p>
<div>
<ul>
<li>
<p>XFCE with X11</p>
</li>
<li>
<p>KDE Plasma with X11</p>
</li>
<li>
<p>MATE</p>
</li>
<li>
<p>Traditional desktop environments that maintain X11 support</p>
</li>
</ul>
</div>
</li>
<li>
<p>Install X11-compatible display managers like LightDM or KDM instead of GDM if your distribution defaults to Wayland-only</p>
</li>
<li>
<p>Choose distributions that maintain X11 support - some distributions are moving to Wayland-only configurations that may not meet your needs</p>
</li>
</ol>
</div>
</div>
<div>
<h3 id="_for_casual_use">For Casual Use</h3>
<p>If you’re willing to accept limitations and occasional frustrations, KiCad will run on Wayland. However, be prepared for:</p>
<div>
<ul>
<li>
<p>Inability to restore your preferred window layouts</p>
</li>
<li>
<p>Occasional crashes or freezes</p>
</li>
<li>
<p>Reduced productivity due to interface limitations</p>
</li>
<li>
<p>Need to work around various UI quirks</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div>
<h2 id="_looking_forward">Looking Forward</h2>
<div>
<p>We recognize that the Linux desktop ecosystem is evolving, and we’re not trying to stop that evolution. However, we believe that user productivity comes first - our users need to design circuit boards, not wrestle with experimental desktop technologies. Stability and reliability are paramount for professional work, and our limited development resources should focus on core functionality rather than working around protocol limitations.</p>
<p>We continue to monitor Wayland development and welcome fixes from upstream projects. We’ve engaged with desktop environment developers at conferences like FOSDEM and provided detailed feedback about our requirements. Some progress has been made (pointer warping protocols are finally being developed), but many fundamental issues remain unresolved.</p>
<div>
<h3 id="_contributing_to_solutions">Contributing to Solutions</h3>
<p>If you’re a developer interested in improving Wayland support for KiCad there are several ways you can help:</p>
<div>
<ol>
<li>
<p>Contribute to upstream projects: Help fix issues in Wayland protocols, window managers, or wxWidgets</p>
</li>
<li>
<p>Sponsor development: Companies that depend on both Wayland and KiCad can fund specific improvements</p>
</li>
<li>
<p>Test and provide feedback: Help us identify which issues are most critical for your workflows</p>
</li>
</ol>
</div>
<p>We fund some wxWidgets development to help improve Wayland compatibility, but many issues require broader changes in the Wayland ecosystem. We encourage contributions that can benefit all applications, not just KiCad.</p>
</div>
</div>
</div>
<div>
<h2 id="_bottom_line">Bottom Line</h2>
<div>
<p>We try to be pragmatic. We support what works, we document what doesn’t, and we focus our development efforts where they’ll have most benefit for our users. We will adjust our position as Wayland improves, but we won’t compromise the reliability and functionality of KiCad.</p>
<p>For now, if you need to use KiCad on Linux, use X11.</p>
<hr>
<p><em>The KiCad Development Team</em></p>
</div>
</div>

      </section>
      
      <hr>
      
      
      
      
      

    </article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The magic of through running (160 pts)]]></title>
            <link>https://www.worksinprogress.news/p/the-magic-of-through-running</link>
            <guid>44297045</guid>
            <pubDate>Tue, 17 Jun 2025 08:57:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.worksinprogress.news/p/the-magic-of-through-running">https://www.worksinprogress.news/p/the-magic-of-through-running</a>, See on <a href="https://news.ycombinator.com/item?id=44297045">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em><span>This is the lead story of the new issue of Works in Progress, </span><a href="https://worksinprogress.co/issue-19/" rel="">Issue 19</a><span>. Read the full issue, including stories on </span><a href="https://worksinprogress.co/issue/how-to-redraw-a-city/" rel="">how to redraw cities</a><span> and </span><a href="https://worksinprogress.co/issue/how-one-kiwi-tamed-inflation/" rel="">the secret history of inflation targeting</a><span>, on </span><a href="https://worksinprogress.co/issue-19/" rel="">our website.</a></em></p><p>In the nineteenth century, the societies of Europe and North America were profoundly transformed by the vast railway networks they built. When these railway networks entered cities, however, they faced a crucial problem: they had to stop. Rather than carrying on through the city, it was common for them to terminate on its edge.</p><p><span>In part, this was due to the high cost of acquiring land in urban areas. It was also a technological problem: the </span><a href="https://worksinprogress.co/issue/why-we-stopped-building-cut-and-cover/" rel="">tunneling technologies</a><span> that would enable railways to run into the centre underground without destroying everything in their path had not yet been invented. Finally, the problem was sometimes regulatory as well: in cities such as London railways </span><a href="https://en.wikipedia.org/wiki/Royal_Commission_on_Metropolitan_Railway_Termini" rel="">were prohibited</a><span> from penetrating too deep into the urban area.</span></p><p><span>The result was that nineteenth century railways often terminated roughly wherever the city limits were when they were built. Some Victorian urban networks, like those of London and Paris, thus resemble a vast hubless wheel whose spokes do not quite join one another in the middle. In other cases, the lines circled round the city and then all entered it at the same point, terminating together in one huge station. This model was common in Germany, so that stations of this sort are still sometimes known by the German name </span><em>Hauptbahnhof</em><span> (literally: main station).</span></p><p>At the end of the nineteenth century, electrification and improvements in tunneling technology led to the emergence of a new kind of railway: the modern metro. Metros were a huge advance in three ways. First, they could go anywhere in the city. Second, metro lines could easily interconnect with one other, meaning that passengers could use the network to travel swiftly from any part of the city to any other part of the city, rather than merely going from a suburb to the edge of the center. Third, the lines were not bottlenecked by the capacity of a central terminus.</p><p>Inner-city termini like London Waterloo and the Gare du Nord in Paris have always handled a complex range of intercity and suburban trains, so delays on any one service can easily propagate over to others. To stop every small delay from generating a huge chain of further delays, tracks and platforms have to be used far below their theoretical maximum capacity: the system can only operate smoothly by preserving a great deal of redundancy. Trains therefore wait around at the terminus for longer than strictly necessary, to recover from delays.</p><p>This, in turn, means that termini have to be massive, and in the age of steam, this was compounded by needing to have room to turn around and store steam locomotives and carriages. Today, the Gare du Nord has 28 tracks above ground, and Waterloo has 24.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F415ead64-7938-4cea-84c9-00e54f60e35f_1600x1202.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F415ead64-7938-4cea-84c9-00e54f60e35f_1600x1202.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F415ead64-7938-4cea-84c9-00e54f60e35f_1600x1202.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F415ead64-7938-4cea-84c9-00e54f60e35f_1600x1202.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F415ead64-7938-4cea-84c9-00e54f60e35f_1600x1202.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F415ead64-7938-4cea-84c9-00e54f60e35f_1600x1202.png" width="593" height="445.56456043956047" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/415ead64-7938-4cea-84c9-00e54f60e35f_1600x1202.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1094,&quot;width&quot;:1456,&quot;resizeWidth&quot;:593,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F415ead64-7938-4cea-84c9-00e54f60e35f_1600x1202.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F415ead64-7938-4cea-84c9-00e54f60e35f_1600x1202.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F415ead64-7938-4cea-84c9-00e54f60e35f_1600x1202.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F415ead64-7938-4cea-84c9-00e54f60e35f_1600x1202.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>The giant Gare du Nord (right) and the Gare de l’Est in Paris. Source: </span><a href="https://commons.wikimedia.org/wiki/File:Gare_du_Nord_gare_de_lEst_P1180996.jpg" rel="">Wikimedia Commons</a><span>.</span></figcaption></figure></div><p>As demand for railway services grew, these termini filled up. But expanding central termini is rarely straightforward: they are typically surrounded by expensive land containing dense urban fabric which would have to be demolished. Furthermore, they are often located on viaducts or in a trench, which makes their expansion technically difficult. Over time, terminus capacity thus generally became the binding constraint on the number of trains that could be run in and out of the urban core, limiting the frequency of both the suburban trains and intercity services.</p><p>Metros, by contrast, could get away with much smaller termini. A typical metro runs a very simple service pattern: every train stops at every station, with few branch lines, and shares no track with any other services, so delays are much less likely. A metro train can easily turn around in well under five minutes, so its terminus only requires two or three platforms.</p><p>In the first decades of the twentieth century, metro lines were built in cities across Europe and North America like Paris, Tokyo, London, Barcelona, and New York. In all of these cities, however, metro lines were built to supplement the Victorian legacy networks, rather than to replace them. As a result, the legacy networks are still there today.</p><p><span>Since building tunneled metro lines is so expensive, these legacy networks are often more extensive than modern metros. The map on the above is London’s metro network (and even this, as we will see, incorporates some bits of legacy lines). The map below shows London’s whole</span><em> </em><span>railway network. Nearly all of the additional lines are Victorian: the pre-metro legacy system is actually far greater than the modern metro.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4148f4c8-f234-47c2-b0b5-28ecc67964a4_659x1024.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4148f4c8-f234-47c2-b0b5-28ecc67964a4_659x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4148f4c8-f234-47c2-b0b5-28ecc67964a4_659x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4148f4c8-f234-47c2-b0b5-28ecc67964a4_659x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4148f4c8-f234-47c2-b0b5-28ecc67964a4_659x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4148f4c8-f234-47c2-b0b5-28ecc67964a4_659x1024.png" width="619" height="961.845220030349" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4148f4c8-f234-47c2-b0b5-28ecc67964a4_659x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:659,&quot;resizeWidth&quot;:619,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4148f4c8-f234-47c2-b0b5-28ecc67964a4_659x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4148f4c8-f234-47c2-b0b5-28ecc67964a4_659x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4148f4c8-f234-47c2-b0b5-28ecc67964a4_659x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4148f4c8-f234-47c2-b0b5-28ecc67964a4_659x1024.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>London is not an anomaly. In Boston, Philadelphia and Chicago, the suburban railway network is much bigger than the metro, and the same is true in Paris, Tokyo and Berlin. A small number of expensive modern metro lines operate alongside vast Victorian networks, a legacy from the golden age of railways. In Britain, nearly all cities have a Victorian legacy network, but only three – London, Glasgow and Newcastle – have something that is unambiguously a metro.</p><p>One of the Holy Grails of transport policy has thus been a way to turn these legacy lines into something like a modern metro system. The solution developed by many transit authorities is known as through running. This means taking suburban lines on opposite sides of the city, and joining them up by running trains through the city center, usually in a tunnel. This tunnel does not necessarily have to be very long: in some cities, only a handful of kilometers is needed, because the rest of the infrastructure (the legacy lines that are joined together by the tunnel) is already there. For the price of a comparatively small section of tunnel, a large number of suburbs can get metro-like service directly into the city center.</p><p>Through running has convergently evolved in many places. This article looks at two of them, Munich and London. Munich is distinctive in having used through running to create what is probably the best transit network on earth, relative to the size of the city. London is distinctive in the sheer size of its legacy network, due to its enormous size in the nineteenth century. This means that through running has offered it opportunities of unique scale and complexity.</p><p>For countries with extensive Victorian legacy networks, through running is one of the most important themes in modern transport policy. Across the world, many cities puzzle over how they can pay for the vast costs of developing an all-new metro system. But if they can get through running right they don’t necessarily have to. Often 90 percent of their modern rail network is already there and has been for 150 years. The stories of Munich and London show how they might fill in the remaining ten percent to create world-leading transit systems at a fraction of the cost.</p><p>A terminological note. In the language of railway engineers, the Victorian legacy networks we are discussing are generally called ‘suburban railways’. This is confusing, because metros are also railways and also run in suburbs, and also because the Victorian systems in question are often the suburban sections of intercity lines. But we bow to convention, and in what follows the surface-level Victorian terminating lines are called ‘suburban railways’ and the underground networks are called ‘metros’.</p><p><span>Munich has a good claim to the best rapid-transit system of any medium-sized city in the world. Within ten kilometers of the center of Munich, </span><a href="https://www.tomforth.co.uk/circlepopulations/" rel="">there are 1.6 million people</a><span>, who are served by 284 stations and 194 tram stops, all of which receive a fast, frequent service.</span></p><p>Munich has two different railway systems. The U-Bahn (short for ‘underground railway’ in German) is a conventional metro system, which serves only the urban area. But there is also the S-Bahn, which is a network of through-running trains that connect the city to outlying towns up to 40 kilometers away as the crow flies.</p><p>Before its metro system was built in the 1960s, Munich had two networks of commuter trains. One network radiated out of the Hauptbahnhof, the city’s main station, which is on the western edge of the city center. Another radiated out of Ostbahnhof, the eastern station, which is much further away from the center. For the reasons described above, neither reached the heart of the city. There was (and still is) an above-ground connection between the two stations, but it is quite a detour, with trains taking about ten minutes to travel 3.5 kilometers as the crow flies. It loops round the city center to the south, and much of its capacity is taken up by long-distance trains traveling to south-eastern Bavaria and Austria.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6932013-80ba-49c6-9f82-2038d5b3a0c0_1600x1091.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6932013-80ba-49c6-9f82-2038d5b3a0c0_1600x1091.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6932013-80ba-49c6-9f82-2038d5b3a0c0_1600x1091.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6932013-80ba-49c6-9f82-2038d5b3a0c0_1600x1091.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6932013-80ba-49c6-9f82-2038d5b3a0c0_1600x1091.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6932013-80ba-49c6-9f82-2038d5b3a0c0_1600x1091.png" width="662" height="451.4876373626374" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a6932013-80ba-49c6-9f82-2038d5b3a0c0_1600x1091.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:993,&quot;width&quot;:1456,&quot;resizeWidth&quot;:662,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6932013-80ba-49c6-9f82-2038d5b3a0c0_1600x1091.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6932013-80ba-49c6-9f82-2038d5b3a0c0_1600x1091.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6932013-80ba-49c6-9f82-2038d5b3a0c0_1600x1091.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa6932013-80ba-49c6-9f82-2038d5b3a0c0_1600x1091.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>According to this 1893 map, the connection between Hauptbahnhof and Ostbahnhof was not used by suburban trains at all.  Source: </span><a href="https://de.m.wikipedia.org/wiki/Datei:M%C3%BCnchner_Vorortverkehr.png" rel="">Wikimedia Commons</a><span>.</span></figcaption></figure></div><p>As mentioned above, this model of ‘spokes without a hub’ is common. In France, Britain, and the United States, the railways were initially built by competing companies that saw each other as rivals, and had little interest in sharing stations. New York City ended up with Pennsylvania Station, operated by the Pennsylvania Railroad, and Grand Central Terminal, operated by the New York Central Railroad. Paris had eight termini at its peak. London has had as many as fifteen, depending on how they are counted.</p><p><span>Even where railways were more centrally planned (including Munich), linking separate networks together was challenging. In Germany, Britain, America, and France, the period of explosive growth of railways mainly took place in the mid-to-late nineteenth century. In this period, tunneling technologies were still in their infancy. The only way railways could run tracks underground was by digging an enormous trench, laying the tracks in it, and then covering it over, a method called </span><a href="https://worksinprogress.co/issue/why-we-stopped-building-cut-and-cover/" rel="">‘cut and cover’</a><span>. In urban areas, this was expensive and inconvenient: unless the line could be dug underneath a wide street, all the buildings above the future underground line had to be demolished to clear the way for the trench. The other option, which was equally disruptive and expensive, was to build large viaducts through the city center. Berlin did this in 1882 because it was essential for military maneuvers between the eastern and western parts of Germany, but Berlin was the exception rather than the rule.</span></p><p>By the 1920s, the shortcomings of the system were becoming increasingly obvious. The population of Munich increased sevenfold between 1850 and 1930, with most of the growth in newly built suburbs. But the capacity of the suburban network could not be easily increased to meet rising demand. For the reasons explained above, the two central termini were the key constraints on capacity. There was also continued discontent at the fact that suburban services did not reach the city center, a fact that had been made more obvious by the development of trams that could do so.</p><p>On the other hand, there were fewer capacity constraints in the termini at the suburban end, because they usually only handled one type of service (i.e. just a single suburban service, not multiple suburban and intercity ones). This meant they could handle more trains per hour without major risk of generating chains of delays. If they did face capacity constraints, it was normally easier to solve them through expanding termini, since suburban termini are surrounded by less development, and land is cheaper.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e85c403-fcd2-491f-a948-121b5caf7292_1600x1034.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e85c403-fcd2-491f-a948-121b5caf7292_1600x1034.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e85c403-fcd2-491f-a948-121b5caf7292_1600x1034.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e85c403-fcd2-491f-a948-121b5caf7292_1600x1034.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e85c403-fcd2-491f-a948-121b5caf7292_1600x1034.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e85c403-fcd2-491f-a948-121b5caf7292_1600x1034.png" width="651" height="420.7355769230769" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1e85c403-fcd2-491f-a948-121b5caf7292_1600x1034.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:941,&quot;width&quot;:1456,&quot;resizeWidth&quot;:651,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e85c403-fcd2-491f-a948-121b5caf7292_1600x1034.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e85c403-fcd2-491f-a948-121b5caf7292_1600x1034.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e85c403-fcd2-491f-a948-121b5caf7292_1600x1034.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e85c403-fcd2-491f-a948-121b5caf7292_1600x1034.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption> Geltendorf station, the terminus of Munich S-Bahn route S4. The station is 40 kilometers as the crow flies from the Marienplatz, the centre of Munich. Source: Google Maps.</figcaption></figure></div><p>The obvious solution is through running: for the cost of a tunnel, both termini can be in the outer suburbs, where space is less scarce, and passengers can be taken directly to the city center into the bargain. This was well understood at the time, and Munich therefore began building an S-Bahn in the interwar period. However, the project was abandoned at the outbreak of the Second World War, and the desolated city was in no position to resume it when the war ended.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f3dd6e0-cf0c-4df9-9e55-db55ec8565fa_1600x1586.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f3dd6e0-cf0c-4df9-9e55-db55ec8565fa_1600x1586.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f3dd6e0-cf0c-4df9-9e55-db55ec8565fa_1600x1586.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f3dd6e0-cf0c-4df9-9e55-db55ec8565fa_1600x1586.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f3dd6e0-cf0c-4df9-9e55-db55ec8565fa_1600x1586.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f3dd6e0-cf0c-4df9-9e55-db55ec8565fa_1600x1586.png" width="662" height="656.0892857142857" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5f3dd6e0-cf0c-4df9-9e55-db55ec8565fa_1600x1586.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1443,&quot;width&quot;:1456,&quot;resizeWidth&quot;:662,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f3dd6e0-cf0c-4df9-9e55-db55ec8565fa_1600x1586.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f3dd6e0-cf0c-4df9-9e55-db55ec8565fa_1600x1586.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f3dd6e0-cf0c-4df9-9e55-db55ec8565fa_1600x1586.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5f3dd6e0-cf0c-4df9-9e55-db55ec8565fa_1600x1586.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>The headquarters of the Bavarian State Government in ruins on 1 December 1958, over 13 years after the end of the War. Source: </span><a href="https://commons.wikimedia.org/wiki/File:Besneeuwde_Hofgarten_met_de_ru%C3%AFne_van_de_Bayerische_Staatskanzlei,_Bestanddeelnr_254-3760.jpg" rel="">Wikimedia Commons</a><span>.</span></figcaption></figure></div><p><span>In spite of the scale of the destruction, the 1950s were also the time of West Germany’s </span><em>Wirtschaftswunder</em><span>, or economic miracle: West Germany’s GDP per capita </span><a href="https://ourworldindata.org/grapher/gdp-per-capita-maddison-project-database?tab=line&amp;time=1920..1970&amp;country=~DEU" rel="">recovered</a><span> to its prewar level after only ten years, and the country built </span><a href="https://www.jstor.org/stable/3144545?seq=1" rel="">half a million housing units annually in the 1950s</a><span>. In an environment of rapid reconstruction, the prewar transport networks in cities like Munich became overloaded. Munich’s population grew to a million in 1957 from its nadir of 550,000 in 1945, and in 1961 114,000 commuters were using the suburban trains every day.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-166071620" href="https://www.worksinprogress.news/p/the-magic-of-through-running#footnote-1-166071620" target="_self" rel="">1</a></span></p><p>The response to this problem was the Munich S-Bahn, which linked together 12 pre-existing suburban branch lines with a 4.3-kilometer-long tunnel. The first concrete postwar plans for the tunnel were put together in the late 1950s. In 1963, the tunnel was approved by Munich’s city council, and following negotiations about funding it began construction in 1966. In the same year, Munich was awarded the 1972 Olympics, putting a hard deadline on completion of the S-Bahn, which ultimately opened a few months before the Games began.</p><p><span>Including related works to the surrounding lines, it ultimately cost 900 million Deutschmarks, </span><a href="https://docs.google.com/spreadsheets/d/16GoHcbW-eVzHUUP_XCWVXS1s_i3ZBnmZh4kvdSX7muU/edit?gid=1828904092#gid=1828904092" rel="">or $2.8 billion in 2023 US dollars</a><span>. This relatively small investment enabled a network of through-running trains that is today a hundred times as long as the tunnel, because the branch lines had already been built.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b6ad0aa-6b00-4211-9ece-c26f184b264d_1024x989.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b6ad0aa-6b00-4211-9ece-c26f184b264d_1024x989.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b6ad0aa-6b00-4211-9ece-c26f184b264d_1024x989.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b6ad0aa-6b00-4211-9ece-c26f184b264d_1024x989.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b6ad0aa-6b00-4211-9ece-c26f184b264d_1024x989.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b6ad0aa-6b00-4211-9ece-c26f184b264d_1024x989.png" width="650" height="627.783203125" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3b6ad0aa-6b00-4211-9ece-c26f184b264d_1024x989.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:989,&quot;width&quot;:1024,&quot;resizeWidth&quot;:650,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b6ad0aa-6b00-4211-9ece-c26f184b264d_1024x989.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b6ad0aa-6b00-4211-9ece-c26f184b264d_1024x989.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b6ad0aa-6b00-4211-9ece-c26f184b264d_1024x989.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b6ad0aa-6b00-4211-9ece-c26f184b264d_1024x989.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The most obvious benefit of the S-Bahn was that it made it easy to get to the center. Previously, somebody travelling from the eastern suburb of Erding had to get a suburban train to Ostbahnhof, get off, go to the station forecourt, and finish their journey with a 15-minute tram ride. Today, the S-Bahn whisks them directly to the heart of the city, and the S-Bahn tunnel has six central stations, which means that different parts of the center are accessible without changing trains.</p><p><span>Just as importantly, the S-Bahn tunnel was not planned as an isolated project, but as one component of a wider public transport network. Munich’s 1963 </span><a href="https://stadt.muenchen.de/infos/dokumente-stadtentwicklungsplanung.html" rel="">city development plan</a><span> envisaged integrating the S-Bahn into a single network with the U-Bahn metro system. There would be five trunk lines under the center, four of which would be operated as part of the U-Bahn, and one of which was the S-Bahn tunnel.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb487643-15de-4afa-ae77-8bce5b1fab97_1024x1002.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb487643-15de-4afa-ae77-8bce5b1fab97_1024x1002.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb487643-15de-4afa-ae77-8bce5b1fab97_1024x1002.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb487643-15de-4afa-ae77-8bce5b1fab97_1024x1002.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb487643-15de-4afa-ae77-8bce5b1fab97_1024x1002.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb487643-15de-4afa-ae77-8bce5b1fab97_1024x1002.png" width="614" height="600.80859375" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cb487643-15de-4afa-ae77-8bce5b1fab97_1024x1002.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1002,&quot;width&quot;:1024,&quot;resizeWidth&quot;:614,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb487643-15de-4afa-ae77-8bce5b1fab97_1024x1002.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb487643-15de-4afa-ae77-8bce5b1fab97_1024x1002.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb487643-15de-4afa-ae77-8bce5b1fab97_1024x1002.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb487643-15de-4afa-ae77-8bce5b1fab97_1024x1002.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption> Munich's transport network as planned in 1963. Source: City of Munich.</figcaption></figure></div><p><span>Today’s S-Bahn and U-Bahn network is similar to what was planned in 1963, although only three of the four U-Bahn trunk lines were built, and the circular line never came to fruition. It is a single network: the S-Bahn tunnel intersects with each U-Bahn line, and the interchanges were designed coherently: with the exception of Hauptbahnhof, none of the interchange stations has more than </span><a href="https://pedestrianobservations.com/2018/01/16/transit-and-scale-variance-part-2-soviet-triangles/" rel="">two lines intersecting</a><span>, which prevents any station from being overloaded. The fares are also </span><a href="https://springbett.substack.com/p/how-to-simplify-rail-fares" rel="">integrated</a><span> between the two systems, so that passengers are not penalised for changing trains. The S-Bahn tunnel would have been useful in itself, but its integration with the U-Bahn has a ‘multiplier’ effect: with one change of train to the U-Bahn, an S-Bahn passenger can get nearly anywhere in the city.</span></p><p><span>This principle of ‘one network, two systems’ enables Munich to manage the trade-off between station spacing and speed, so that both the dense urban core and the suburbs can be served by rapid transit. Other cities try to achieve the same result by running both express trains, and trains that stop at every station, on the same lines, but this is </span><a href="https://springbett.substack.com/p/how-to-improve-the-elizabeth-line" rel="">difficult to do effectively</a><span>, for the obvious reason that the fast trains tend to get bottlenecked behind the stopping ones.</span></p><p><span>The S-Bahn has also relieved the main station. Today, Munich Hauptbahnhof has 32 terminal tracks above ground which handle about 30 departures per hour in the evening peak, because nearly all of the suburban trains run into the S-Bahn tunnel. One train per track per hour is very low utilization, which means there is plenty of room to make sure delays do not cascade across the network, expand the service in future, or possibly to rationalize the station by selling off part of the track space for development.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-166071620" href="https://www.worksinprogress.news/p/the-magic-of-through-running#footnote-2-166071620" target="_self" rel="">2</a></span></p><p><span>But beyond the better connections and the relief provided to the main station, the most important benefit of the Munich S-Bahn has been its frequency. The trunk is able to handle 32 trains per hour in each direction because the branches start in one outlying suburban town, go through the trunk, and then terminate in another suburban town. (Munich has, since December 2024, started temporarily running one branch into Hauptbahnhof due to reliability issues in the trunk.) This gives it a </span><a href="https://web.archive.org/web/20220605163422/https://www.schaeffler.com/remotemedien/media/_shared_media/08_media_library/01_publications/schaeffler_2/datasheet_1/downloads_4/ds_wl_07506_de_de.pdf" rel="">capacity of up to 48,960 passengers per hour in each direction</a><span>.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-166071620" href="https://www.worksinprogress.news/p/the-magic-of-through-running#footnote-3-166071620" target="_self" rel="">3</a></span></p><p><span>The Munich S-Bahn accounts for </span><a href="https://www.s-bahn-muenchen.de/ueber-uns/unternehmen" rel="">840,000 journeys each workday</a><span>, serving an area with a population of about 2.7 million. It carries </span><a href="https://www.stmb.bayern.de/med/pressemitteilungen/pressearchiv/2020/241/index.php" rel="">two thirds of all railway passengers in Bavaria</a><span>, a state with a population of 13.4 million. This is impressive in itself, but the Munich S-Bahn also performs better than some other through-running systems: the Paris RER, a structurally similar system in a much bigger city, serves four times as many people but only carries </span><a href="https://www.iledefrance-mobilites.fr/en/the-network/mobility-services/rer" rel="">three times as many passengers</a><span> per day.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-166071620" href="https://www.worksinprogress.news/p/the-magic-of-through-running#footnote-4-166071620" target="_self" rel="">4</a></span><span> The S-Bahn tunnel, which was originally only </span><a href="https://www.2.stammstrecke-muenchen.de/die-situation-heute.html" rel="">designed for 250,000 passengers per day</a><span>, has been so successful that Munich is building a new one, to move every branch from three trains per hour to four, and to create the capacity for half-hourly express services.</span></p><p>Many cities, especially in the German-speaking world, have tackled their problems in a similar way. Berlin, Hamburg, Stuttgart, Frankfurt, Leipzig, Vienna, and Zurich all have networks very similar to the Munich S-Bahn, using tunnels to link up lines on opposite sides of the city. Not all S-Bahns require an expensive tunnel: some cities like Cologne, Nuremberg, and Hanover do not have a terminus, so they can simply run their trains through the main station. The S-Bahn model has also been influential on cities in neighbouring countries, such as Copenhagen, Stockholm, Prague, Brussels, and Milan.</p><p>Karlsruhe, a small city in the south-west of Germany near the French border, developed an interesting variation on through running in the 1990s: the tram-train S-Bahn. A ‘train’ from the big town of Pforzheim starts off running on ordinary rails, then through runs on the city streets of Karlsruhe as a tram, before becoming a train again on the other side of the city. Although the tram portion is slow, the city is small enough that this does not have a large effect on journey times. The ‘Karlsruhe model’ has been emulated around the world, including in Sheffield in the United Kingdom.</p><p>In all of these cities, the principle is the same: to enable all of the suburban railway lines to through run onto a trunk that goes through the city center, whether that trunk be a tunnel, platforms at the main station, or occasionally a tram network.</p><p>Through running has convergently evolved in several different places. One of these was Germany. Another was London.</p><p>In the nineteenth century, London was the world’s largest city, and it had an enormous network of suburban railways. These were originally built by competing, private companies, which were set up in the mid-nineteenth century to connect the capital with other major cities like Birmingham, Bristol, and Brighton. Each company built its own London terminus almost always on the edge of the urban area. The theoretical opportunity for through running in London was thus gigantic, uniting the enormous and disorganized system of suburban railways.</p><p>The problem with London’s suburban railway system has been obvious from a start. As soon as underground railways became possible, companies began designing networks to connect the various termini together, beginning with what later became the Metropolitan and District lines of the London Underground. Their aim was to allow commuters to move between the various disconnected ‘spokes’ of the suburban ‘wheel’. This was not, however, through running: passengers would need to change trains at a terminus like King’s Cross to get to the early Underground lines. The suburban lines were not directly linked together.</p><p><span>The Victorians managed only one true example of through running, the Snow Hill Tunnel. This went south from Farringdon to a station called Ludgate Hill, which enabled the lines north and south of the Thames to be connected. London’s first crossrail can thus be dated to 1 August 1866, when the first trains used this new connection to run from Herne Hill, in the south of London, to Barnet, in the north of London.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-166071620" href="https://www.worksinprogress.news/p/the-magic-of-through-running#footnote-5-166071620" target="_self" rel="">5</a></span><span> Although the service was initially fairly successful, the slow, infrequent, steam-operated suburban service was outcompeted by electric trams after the Kingsway tunnel allowed them to cross the river, and closed to passengers in 1916.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-166071620" href="https://www.worksinprogress.news/p/the-magic-of-through-running#footnote-6-166071620" target="_self" rel="">6</a></span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd16077ac-ff7d-4810-8ce1-578c5772b830_1600x885.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd16077ac-ff7d-4810-8ce1-578c5772b830_1600x885.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd16077ac-ff7d-4810-8ce1-578c5772b830_1600x885.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd16077ac-ff7d-4810-8ce1-578c5772b830_1600x885.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd16077ac-ff7d-4810-8ce1-578c5772b830_1600x885.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd16077ac-ff7d-4810-8ce1-578c5772b830_1600x885.png" width="610" height="337.25961538461536" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d16077ac-ff7d-4810-8ce1-578c5772b830_1600x885.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:805,&quot;width&quot;:1456,&quot;resizeWidth&quot;:610,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd16077ac-ff7d-4810-8ce1-578c5772b830_1600x885.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd16077ac-ff7d-4810-8ce1-578c5772b830_1600x885.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd16077ac-ff7d-4810-8ce1-578c5772b830_1600x885.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd16077ac-ff7d-4810-8ce1-578c5772b830_1600x885.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>The Snow Hill tunnel briefly enabled an early form of the through running in London. It now forms part of the Thameslink line. Source: Reproduced with the permission of the </span><a href="https://maps.nls.uk/view/102345964#zoom=5.2&amp;lat=4331&amp;lon=6367&amp;layers=BT" rel="">National library of Scotland</a><span>.</span></figcaption></figure></div><p><span>This success of the Snow Hill Tunnel was not repeated. One problem was that through running would have involved railway companies letting one another’s trains run on their tracks, which they were often unwilling to do. Another was that through running would require more </span><a href="https://worksinprogress.co/issue/why-we-stopped-building-cut-and-cover/" rel="">cut-and-cover</a><span> tunnels to be built, which meant digging a huge trench, laying the track in it, and covering it over. Cut and cover requires the total destruction of everything in the way of the trench, which makes it phenomenally expensive, unless it follows the line of a wide street. Some cities, like New York and Paris, had lots of wide streets for this purpose, but central London has only one, Euston Road, which already had the Metropolitan Line running underneath it.</span></p><p><span>At the end of the nineteenth century, advances in tunneling technology meant a new generation of underground lines could be built. These ‘deep level’ lines, powered by electricity, ran far beneath the surface of the earth and were bored rather than excavated, so they no longer required destructive trenches to be cut through the urban fabric. This did not, however, solve London’s through-running problem. The suburban lines remained operated by steam, so none was suitable for through running without expensive investment in electrification.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-166071620" href="https://www.worksinprogress.news/p/the-magic-of-through-running#footnote-7-166071620" target="_self" rel="">7</a></span></p><p>Through running began to get underway again in the 1930s, after London’s railway services were nationalized and schemes began to be developed to coordinate them more effectively. As part of its New Works Program, the London Passenger Transport Board joined a short Edwardian underground line with two suburban railway lines on either side, resulting in what we now know as the Central Line. The suburban lines were electrified so that their trains could run through the underground line, and then out into the suburban line at the other end. A total of 14 kilometers of tunnel were built to join the lines together.</p><p>By the 1940s, there was high enthusiasm for further through-running schemes. In 1943, planners prepared the County of London Plan for rebuilding London after the Second World War, which included grand designs to through run nearly all of London’s suburban railways with a series of tunnels. The Plan’s rail proposals were mainly downstream of its plans for improving the South Bank of the River Thames, an area criss-crossed by three huge railway viaducts which, the planners judged, impeded rational planning of the area. The Plan therefore suggested removing the stations and their attached viaducts, and building a series of tunnels which would enable through running of nearly all traffic.</p><p><span>However, these schemes came to nothing. The British state was virtually bankrupted by the Second World War, with </span><a href="https://obr.uk/box/post-world-war-ii-debt-reduction/" rel="">government debt rising to 270 percent of GDP</a><span>, and struggled to initiate major infrastructure projects in its aftermath. Resources were channeled into finishing the pre-war extensions, with the Central Line Extension being finally completed in 1948.</span></p><p><span>In any event, new through-running schemes seemed less attractive. London’s population began to decline: from 8.6 million people in 1939, to 8 million in 1961, to 6.8 million in 1981. Cars drew passengers away from railways. Furthermore, the Green Belt in particular, and more generally </span><a href="https://worksinprogress.co/issue/why-britain-doesnt-build/" rel="">the introduction of Britain’s planning system</a><span>, made it impossible to build new housing around commuter railways, reducing the value of more frequent services to these stations.</span></p><p><span>Even today, the outer reaches of the Central Line extensions go to places like Grange Hill and Theydon Bois, which are </span><a href="https://www.createstreets.com/wp-content/uploads/2024/12/BRM_CreateStreets_New-Towns-Report_111224.pdf" rel="">‘mirror towns’</a><span>: on one side of the tracks there is suburban development, on the other there are just fields. It was assumed in the 1930s that suburbia would rapidly spring up on the fields next to the stations, but in many cases there are streets that, quite literally, end when their builders were conscripted or redirected into war industries in 1939, and were never finished due to the Green Belt.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F188344ba-dc12-4f8a-8cae-0bc918d4da03_1600x758.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F188344ba-dc12-4f8a-8cae-0bc918d4da03_1600x758.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F188344ba-dc12-4f8a-8cae-0bc918d4da03_1600x758.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F188344ba-dc12-4f8a-8cae-0bc918d4da03_1600x758.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F188344ba-dc12-4f8a-8cae-0bc918d4da03_1600x758.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F188344ba-dc12-4f8a-8cae-0bc918d4da03_1600x758.png" width="1456" height="690" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/188344ba-dc12-4f8a-8cae-0bc918d4da03_1600x758.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:690,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F188344ba-dc12-4f8a-8cae-0bc918d4da03_1600x758.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F188344ba-dc12-4f8a-8cae-0bc918d4da03_1600x758.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F188344ba-dc12-4f8a-8cae-0bc918d4da03_1600x758.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F188344ba-dc12-4f8a-8cae-0bc918d4da03_1600x758.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption> Trentwood Side in Enfield, North London. London stops at the end of this street where the trees are. Source: Google Streetview.</figcaption></figure></div><p>The tide did, however, start to turn. London’s population began to recover from its 1981 nadir, and the economic boom of the 1980s brought more traffic to the railways, many of them commuters into London.</p><p>In 1988, London implemented a through running project called Thameslink. This involved reopening the disused Snow Hill Tunnel, thereby restoring London’s first through-running service. Thameslink was an unusual project: although the passenger service had closed in 1916, the tunnel had been in use for freight until 1971, which meant it was easy to resurrect the service 15 years later. Although this brought immediate benefits, it was done cheaply, and 30 years later London had to spend six billion pounds on untangling track layouts, rebuilding stations and resignaling the route to get the most out of the Snow Hill Tunnel.</p><p><span>Unlike the original Thameslink, other through running projects would require much more substantial investment. But in the boom years of the late 1980s, it looked as though this would come. In 1989, the </span><a href="https://www.railwaysarchive.co.uk/docsummary.php?docID=1294" rel="">Central London Rail Study</a><span>, commissioned jointly by the national government, British Railways and London Transport, proposed what eventually became the Elizabeth Line, a huge through-running scheme joining a suburban line running east from Liverpool Street into Essex with one running west from Paddington into Berkshire. It also proposed two other through-running schemes, which it expected to have lower benefits relative to their costs.</span></p><p>These proposed schemes were intended to kill two birds with one stone. As London grew, both the central trunks of the Tube and the suburban branches grew busier. The route that eventually became the Elizabeth Line would relieve the Central Line by providing a new parallel east-west route, as well as enabling through running of some of the suburban branches.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35d03a4a-b894-4038-bf14-55f0a19c600e_1183x838.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35d03a4a-b894-4038-bf14-55f0a19c600e_1183x838.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35d03a4a-b894-4038-bf14-55f0a19c600e_1183x838.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35d03a4a-b894-4038-bf14-55f0a19c600e_1183x838.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35d03a4a-b894-4038-bf14-55f0a19c600e_1183x838.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35d03a4a-b894-4038-bf14-55f0a19c600e_1183x838.png" width="1183" height="838" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/35d03a4a-b894-4038-bf14-55f0a19c600e_1183x838.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:838,&quot;width&quot;:1183,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35d03a4a-b894-4038-bf14-55f0a19c600e_1183x838.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35d03a4a-b894-4038-bf14-55f0a19c600e_1183x838.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35d03a4a-b894-4038-bf14-55f0a19c600e_1183x838.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35d03a4a-b894-4038-bf14-55f0a19c600e_1183x838.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The early plan for what is now the Elizabeth line. Source: Central London Rail Study, 1989, Department of Transport. OGL v3.0G.</figcaption></figure></div><p><span>This was the first time that conditions seemed ripe to actually start building a brand-new through running line. In 1991, a bill to build the line was put before Parliament. In 1994, however, it was rejected, partly because an economic downturn had led to fewer commuters in London, but also perhaps because decision makers did not understand the benefits of through running: one cabinet minister was quoted as saying, ‘It went from nowhere to nowhere. No sane person has ever wanted to go to Shenfield’, one of the suburban termini of the line. But the idea did not go away. In 2000, </span><a href="https://web.archive.org/web/20240708223527/https://learninglegacy.crossrail.co.uk/wp-content/uploads/2016/02/PPM_SRA-London-EastWest-Study.pdf" rel="">another report</a><span> recommended building the line. During the economic boom of the early 2000s, and with the growth in passenger numbers following railway privatization in 1995, the case for the line continued to be strong.</span></p><p><a href="https://www.legislation.gov.uk/ukpga/2008/18/contents" rel="">It was eventually approved by Parliament in 2008</a><span>. Following delays and cost overruns, it finally opened in 2022.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5267f34-4434-40c1-9817-143c2c70b089_1024x934.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5267f34-4434-40c1-9817-143c2c70b089_1024x934.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5267f34-4434-40c1-9817-143c2c70b089_1024x934.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5267f34-4434-40c1-9817-143c2c70b089_1024x934.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5267f34-4434-40c1-9817-143c2c70b089_1024x934.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5267f34-4434-40c1-9817-143c2c70b089_1024x934.png" width="642" height="585.57421875" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e5267f34-4434-40c1-9817-143c2c70b089_1024x934.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:934,&quot;width&quot;:1024,&quot;resizeWidth&quot;:642,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5267f34-4434-40c1-9817-143c2c70b089_1024x934.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5267f34-4434-40c1-9817-143c2c70b089_1024x934.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5267f34-4434-40c1-9817-143c2c70b089_1024x934.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe5267f34-4434-40c1-9817-143c2c70b089_1024x934.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The centerpiece of the Elizabeth Line is a 21 kilometer-long tunnel under the center of London, and out into the regenerated docklands. But in total, the Elizabeth Line trains travel 117 kilometers because of the two existing suburban lines it cannibalized.</p><p><span>The Elizabeth Line has been a huge success: within a year of opening, quarterly fare revenue </span><a href="https://content.tfl.gov.uk/tfl-quarterly-performance-report-q2-2023-24-acc.pdf" rel="">exceeded predictions</a><span> by £22 million. Nearly every station on the Line has surpassed its pre-COVID passenger numbers, even though in 2024 the average London station not on the Elizabeth Line had 10 percent fewer people than before COVID.</span></p><p>The Elizabeth Line has been transformative for places like Romford, a suburb of eastern London. Romford used to get direct trains to only Liverpool Street: it now has them to most of central London, Heathrow Airport, and the western suburbs. The trains also run twice as frequently as they used to. The rest of the city center (plus most of its suburbs) can be reached with one change of train. Because the trains to Romford no longer run into the terminus part of Liverpool Street, other services using the station have become more reliable as well.</p><p><span>Most importantly, this has been done cost-effectively. Although the Elizabeth Line tunnel was </span><a href="https://transitcosts.com/london-crossrail/" rel="">expensive</a><span>, for the price of 21 kilometers of tunnel, London got a 117 kilometer-long railway network. In short, Romford has got most of the benefits of a connection to the London Underground, without needing to build an underground line all the way to the suburb.</span></p><p>The Elizabeth Line was a success, but a costly one. It became viable only when London was booming and its railway lines were crying out for more capacity. If all through running schemes were like the Elizabeth Line, we might conclude it was an expensive luxury, useful only in the wealthiest and most transport-constrained cities.</p><p>Fortunately, this is not the case. For one thing, through running does not need to be as costly as the Elizabeth Line. As the table below shows, cities differ greatly in the costs at which they build through-running projects. These costs are usually correlated with the costs for railway projects in that country generally, suggesting their variation is mainly the result of regulatory and procurement systems rather than the particular physical features of the individual lines.</p><p><span>But as important as the cost per kilometer of track is the amount of track that needs to be made. Some cities, like Cologne, do not need to tunnel to allow trains to run through: they only need works to expand the city’s main station, or alter its layout. Where tunneling is necessary, it does not necessarily need to be on the scale of the Elizabeth Line. London is a megacity, but owing to its smaller size, a tunnel to connect Manchester’s suburban railway lines together would only be a couple of kilometers long, roughly a tenth of the length of the Elizabeth Line’s tunnel and more similar to the scale of the trunk tunnel of the Munich S-Bahn. Indeed, </span><a href="https://web.archive.org/web/20070911034934/http://www.metromapsoftheworld.com/PipeDreams/PiccVic/" rel="">such a scheme was approved and was almost built in the early 1970s</a><span>. It never went ahead due to pressures on the public finances, but similar projects were built in Liverpool, which used 1.5 kilometers of tunnel, and Newcastle, which used 5 kilometers.</span></p><p>Through running has potential in any city with a network of legacy suburban lines. In general, this is likely to be the case in countries that industrialized in the nineteenth century, when railways had been invented but metros had not.</p><p>Britain is a particularly striking example of this. British cities outside of London are notorious for their lack of metro and tram systems, but many of them actually have enormous suburban railway networks. The problem with these systems is not that they have poor coverage, but they have low frequency and poor interconnectivity. These are problems that can be solved by through running, turning them into something similar to modern metro systems, at a small fraction of the cost of developing such a metro from scratch.</p><p>Not all countries are so fortunate. China, for instance, developed large cities in the twentieth century with neither suburban railways nor modern metros. Today, the Chinese authorities want to improve their urban rail systems. But in the absence of suburban railways that can through run, that means developing vast underground metro systems from scratch at enormous expense.</p><p>Through running is a cost-effective way of upgrading pre-existing railway lines. This is beneficial for passengers who get a better quality of service, and in itself justifies through running. But through-run lines also are able to catalyze urban growth, by making better-connected areas desirable locations for development.</p><p><span>The Elizabeth Line has enabled development around stations like Woolwich, West Drayton and Southall, while new commuter towns have been </span><a href="https://www.createstreets.com/projects/creating-new-towns-fast-and-well/" rel="">proposed at Taplow and Iver</a><span>. Meanwhile in Munich a brand-new urban quarter called Freiham is being built around a brand new S-Bahn station.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcc48702-9cc4-4e9d-9553-d3029338971b_1600x900.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcc48702-9cc4-4e9d-9553-d3029338971b_1600x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcc48702-9cc4-4e9d-9553-d3029338971b_1600x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcc48702-9cc4-4e9d-9553-d3029338971b_1600x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcc48702-9cc4-4e9d-9553-d3029338971b_1600x900.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcc48702-9cc4-4e9d-9553-d3029338971b_1600x900.png" width="649" height="365.0625" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/dcc48702-9cc4-4e9d-9553-d3029338971b_1600x900.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:649,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcc48702-9cc4-4e9d-9553-d3029338971b_1600x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcc48702-9cc4-4e9d-9553-d3029338971b_1600x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcc48702-9cc4-4e9d-9553-d3029338971b_1600x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcc48702-9cc4-4e9d-9553-d3029338971b_1600x900.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span> Dense residential development around the new Freiham S-Bahn station. Source: Hard disk via </span><a href="https://commons.wikimedia.org/wiki/File:Muenchen_Freiham_RL1_Mitte.jpg" rel="">Wikimedia Commons</a><span>.</span></figcaption></figure></div><p>Other cities have designed entire expansion strategies around through running. In the 1930s, Copenhagen developed a high-capacity through-running system called the S-tog, which works much like the Munich S-Bahn. In the 1940s, Copenhagen developed its celebrated ‘finger plan’ for further development, with the city extending outward in urban ‘fingers’ along the lines of the S-tog, leaving open countryside in the areas between. Dozens of neighbourhoods are now clustered around S-tog stations, enjoying its fast, frequent, and highly interconnected service across Copenhagen and its environs.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb9f62af-2123-4fdb-9424-eb666a77d6f8_469x500.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb9f62af-2123-4fdb-9424-eb666a77d6f8_469x500.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb9f62af-2123-4fdb-9424-eb666a77d6f8_469x500.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb9f62af-2123-4fdb-9424-eb666a77d6f8_469x500.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb9f62af-2123-4fdb-9424-eb666a77d6f8_469x500.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb9f62af-2123-4fdb-9424-eb666a77d6f8_469x500.png" width="469" height="500" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cb9f62af-2123-4fdb-9424-eb666a77d6f8_469x500.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:500,&quot;width&quot;:469,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb9f62af-2123-4fdb-9424-eb666a77d6f8_469x500.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb9f62af-2123-4fdb-9424-eb666a77d6f8_469x500.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb9f62af-2123-4fdb-9424-eb666a77d6f8_469x500.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb9f62af-2123-4fdb-9424-eb666a77d6f8_469x500.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The famous 'finger plan', with the five fingers corresponding to S-tog routes. Source: Dansk Byplanlaboratorium.</figcaption></figure></div><p>Crucially, the success or failure of through-running schemes does not depend on building new housing around the lines, because through-run lines are so much cheaper that they can often be justified purely on the basis of benefits of existing passengers. The reverse is usually true with metro schemes: due to their higher costs, they can only be financially viable if they are surrounded by high-density development. If that development does not materialize, either because of an economic downturn or because land-use regulations make it prohibitively expensive to build, the metro line will be an economic failure.</p><p>It is tempting to think that the most important ways to improve transport involve new technology: self-driving cars, flying taxis, or even e-scooters. But often, the best investments involve getting the most out of existing technology, through smaller investments that have a strong multiplier effect. Through running involves using a fairly old technology, deep bore tunneling, to improve an even older technology, commuter railways. 90 percent of London’s S-Bahn network is already built, and with Manchester this is closer to 95 percent. The opportunity is great in North America: Boston only needs a mile of tunnel, and Toronto and New York City already have the infrastructure for through running, but choose not to use it. By weaving together Victorian lines, these cities can get the best railway networks in the world. It’s not a free lunch, but most of it has already been paid for.</p><p><em><span>Benedict Springbett is a </span><a href="http://springbett.substack.com/" rel="">writer</a><span> and Bar student.</span></em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task (139 pts)]]></title>
            <link>https://www.brainonllm.com/</link>
            <guid>44296711</guid>
            <pubDate>Tue, 17 Jun 2025 07:58:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.brainonllm.com/">https://www.brainonllm.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44296711">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!--[--><!--[--><!----><!----><main>  <img src="https://www.brainonllm.com/brainonllm.png" alt="Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task"> <div><p>as seen on:</p> <p><img src="https://www.brainonllm.com/media/NewYorkTimes.svg" alt="The New York Times"> <img src="https://www.brainonllm.com/media/salon-logo.svg" alt="Salon"></p></div> <p>With today's wide adoption of LLM products like ChatGPT from OpenAI, humans and businesses
		engage and use LLMs on a daily basis. Like any other tool, it carries its own set of advantages
		and limitations. This study focuses on finding out the cognitive cost of using an LLM in the
		educational context of writing an essay.</p> <p>We assigned participants to three groups: LLM group, Search Engine group, Brain-only group,
		where each participant used a designated tool (or no tool in the latter) to write an essay. We
		conducted 3 sessions with the same group assignment for each participant. In the 4th session we
		asked LLM group participants to use no tools (we refer to them as LLM-to-Brain), and the
		Brain-only group participants were asked to use LLM (Brain-to-LLM). We recruited a total of 54
		participants for Sessions 1, 2, 3, and 18 participants among them completed session 4.</p> <p>We used electroencephalography (EEG) to record participants' brain activity in order to assess
		their cognitive engagement and cognitive load, and to gain a deeper understanding of neural
		activations during the essay writing task. We performed NLP analysis, and we interviewed each
		participant after each session. We performed scoring with the help from the human teachers and
		an AI judge (a specially built AI agent).</p> <p>We discovered a consistent homogeneity across the Named Entities Recognition (NERs), n-grams,
		ontology of topics within each group. EEG analysis presented robust evidence that LLM, Search
		Engine and Brain-only groups had significantly different neural connectivity patterns,
		reflecting divergent cognitive strategies. Brain connectivity systematically scaled down with
		the amount of external support: the Brain‑only group exhibited the strongest, widest‑ranging
		networks, Search Engine group showed intermediate engagement, and LLM assistance elicited the
		weakest overall coupling. In session 4, LLM-to-Brain participants showed weaker neural
		connectivity and under-engagement of alpha and beta networks; and the Brain-to-LLM participants
		demonstrated higher memory recall, and re‑engagement of widespread occipito-parietal and
		prefrontal nodes, likely supporting the visual processing, similar to the one frequently
		perceived in the Search Engine group. The reported ownership of LLM group's essays in the
		interviews was low. The Search Engine group had strong ownership, but lesser than the Brain-only
		group. The LLM group also fell behind in their ability to quote from the essays they wrote just
		minutes prior.</p> <p>As the educational impact of LLM use only begins to settle with the general population, in this
		study we demonstrate the pressing matter of a likely decrease in learning skills based on the
		results of our study. The use of LLM had a measurable impact on participants, and while the
		benefits were initially apparent, as we demonstrated over the course of 4 months, the LLM
		group's participants performed worse than their counterparts in the Brain-only group at all
		levels: neural, linguistic, scoring.</p> <p>We hope this study serves as a preliminary guide to understanding the cognitive and practical
		impacts of AI on learning environments.</p> <p>Distributed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a></p> <p>© Copyright 2025: <a href="https://www.media.mit.edu/people/nkosmyna/overview/" target="_blank">Nataliya Kosmyna</a>, Eugene Hauptmann</p></main><!----><!----><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fossify – A suite of open-source, ad-free apps (386 pts)]]></title>
            <link>https://github.com/FossifyOrg</link>
            <guid>44296564</guid>
            <pubDate>Tue, 17 Jun 2025 07:32:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/FossifyOrg">https://github.com/FossifyOrg</a>, See on <a href="https://news.ycombinator.com/item?id=44296564">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="" data-view-component="true">
  

  
  <div>
    
    <article itemprop="text"><p dir="auto"><h2 dir="auto">👋 Welcome to Fossify!</h2><a id="user-content--welcome-to-fossify" aria-label="Permalink: 👋 Welcome to Fossify!" href="#-welcome-to-fossify"></a></p>
<p dir="auto">Fossify is a group of privacy-focused, open-source, and ad-free mobile apps.</p>
<p dir="auto">It emerged as a fork of the <a href="https://github.com/SimpleMobileTools/General-Discussion/issues/241" data-hovercard-type="issue" data-hovercard-url="/SimpleMobileTools/General-Discussion/issues/241/hovercard">discontinued</a> SimpleMobileTools to continue its legacy, bringing simple and private tech to everyone.</p>
<p dir="auto"><h4 dir="auto">Get Involved</h4><a id="user-content-get-involved" aria-label="Permalink: Get Involved" href="#get-involved"></a></p>
<ul dir="auto">
<li>For issues affecting multiple apps, check out <a href="https://github.com/FossifyOrg/General-Discussion/issues">general issues</a>.</li>
<li>Engage in discussions or share ideas at <a href="https://github.com/FossifyOrg/General-Discussion/discussions">general discussions</a>.</li>
<li>To help with code or translations, visit <a href="https://github.com/FossifyOrg/General-Discussion?tab=readme-ov-file#faq">this link</a>.</li>
</ul>
<p dir="auto"><h4 dir="auto">Questions or Feedback?</h4><a id="user-content-questions-or-feedback" aria-label="Permalink: Questions or Feedback?" href="#questions-or-feedback"></a></p>
<p dir="auto">If you have questions or want to learn more, start a discussion <a href="https://github.com/orgs/FossifyOrg/discussions">here</a> or reach out at <a href="mailto:hello@fossify.org">hello@fossify.org</a>.</p>
<p dir="auto">Your contributions are appreciated! 🌟</p>
</article>
  </div>

  

    <div>

  <h2>
        Pinned

    <span data-view-component="true">
      <span>Loading</span>
</span>
    <span role="status" aria-live="polite" data-error-text="Something went wrong." data-success-text="Order updated."></span>
  </h2>

      <ol>
      <li>
  <div>
      


      <p>
        Browse your memories without any interruptions with this photo and video gallery
      </p>

      <p>
          <span>
  <span></span>
  <span itemprop="programmingLanguage">Kotlin</span>
</span>

          <a href="https://github.com/FossifyOrg/Gallery/stargazers">
            <svg aria-label="stars" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
            2.3k
          </a>
          <a href="https://github.com/FossifyOrg/Gallery/forks">
            <svg aria-label="forks" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
            103
          </a>
      </p>
    </div>
</li>

      <li>
  <div>
      


      <p>
        A simple calendar with events, customizable widgets and no ads.
      </p>

      <p>
          <span>
  <span></span>
  <span itemprop="programmingLanguage">Kotlin</span>
</span>

          <a href="https://github.com/FossifyOrg/Calendar/stargazers">
            <svg aria-label="stars" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
            1.2k
          </a>
          <a href="https://github.com/FossifyOrg/Calendar/forks">
            <svg aria-label="forks" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
            88
          </a>
      </p>
    </div>
</li>

      <li>
  <div>
      


      <p>
        Easy app for managing your files without ads, respecting your privacy &amp; security
      </p>

      <p>
          <span>
  <span></span>
  <span itemprop="programmingLanguage">Kotlin</span>
</span>

          <a href="https://github.com/FossifyOrg/File-Manager/stargazers">
            <svg aria-label="stars" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
            902
          </a>
          <a href="https://github.com/FossifyOrg/File-Manager/forks">
            <svg aria-label="forks" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
            50
          </a>
      </p>
    </div>
</li>

      <li>
  <div>
      


      <p>
        A handy phone call manager with phonebook, number blocking and multi-SIM support
      </p>

      <p>
          <span>
  <span></span>
  <span itemprop="programmingLanguage">Kotlin</span>
</span>

          <a href="https://github.com/FossifyOrg/Phone/stargazers">
            <svg aria-label="stars" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
            764
          </a>
          <a href="https://github.com/FossifyOrg/Phone/forks">
            <svg aria-label="forks" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
            75
          </a>
      </p>
    </div>
</li>

      <li>
  <div>
      


      <p>
        A clean music player with a customizable widget, stylish interface and no ads.
      </p>

      <p>
          <span>
  <span></span>
  <span itemprop="programmingLanguage">Kotlin</span>
</span>

          <a href="https://github.com/FossifyOrg/Music-Player/stargazers">
            <svg aria-label="stars" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
            469
          </a>
          <a href="https://github.com/FossifyOrg/Music-Player/forks">
            <svg aria-label="forks" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
            47
          </a>
      </p>
    </div>
</li>

      <li>
  <div>
      


      <p>
        An easy and quick way of managing SMS and MMS messages without ads.
      </p>

      <p>
          <span>
  <span></span>
  <span itemprop="programmingLanguage">Kotlin</span>
</span>

          <a href="https://github.com/FossifyOrg/Messages/stargazers">
            <svg aria-label="stars" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
            834
          </a>
          <a href="https://github.com/FossifyOrg/Messages/forks">
            <svg aria-label="forks" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
            68
          </a>
      </p>
    </div>
</li>

</ol>

</div>


    <div id="org-profile-repositories">
      <h3>
        
        Repositories
      </h3>
      
      <div id="org-repositories" data-delay-results="">
    <p><span data-autosearch-results="">Showing 10 of 32 repositories</span></p><div data-view-component="true">
  
  
    <ul data-view-component="true">
        <li data-view-component="true">          <div itemprop="owns" itemtype="http://schema.org/Code" itemscope="itemscope" data-view-component="true">
  
    <div data-view-component="true">
      <div data-view-component="true">
        <p><a itemprop="name codeRepository" data-hovercard-type="repository" data-hovercard-url="/FossifyOrg/Voice-Recorder/hovercard" data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:repo_nwo&quot;}" href="https://github.com/FossifyOrg/Voice-Recorder" data-view-component="true">Voice-Recorder</a>
        <span title="Label: Public" data-view-component="true">
          Public
</span></p><p itemprop="description" data-view-component="true">
            An easy way of recording any discussion or sounds without ads or internet access
</p></div>
      <p><span data-view-component="true"><a id="commit-activity-link-595828370" href="https://github.com/FossifyOrg/Voice-Recorder/graphs/commit-activity" data-view-component="true"></a>  <tool-tip id="tooltip-fc43b950-cf1d-42da-a52f-007719dec374" for="commit-activity-link-595828370" popover="manual" data-direction="s" data-type="label" data-view-component="true">FossifyOrg/Voice-Recorder’s past year of commit activity</tool-tip></span>
</p></div>
    <div data-view-component="true">

        <p><span>
  <span></span>
  <span itemprop="programmingLanguage">Kotlin</span>
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:stars&quot;}" aria-label="395 stars" href="https://github.com/FossifyOrg/Voice-Recorder/stargazers" data-view-component="true">
          395</a>
        <p><span data-view-component="true">
          GPL-3.0
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:forks&quot;}" aria-label="33 forks" href="https://github.com/FossifyOrg/Voice-Recorder/forks" data-view-component="true">
          33</a>
      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:issues&quot;}" aria-label="29 issues" href="https://github.com/FossifyOrg/Voice-Recorder/issues" data-view-component="true">
        29</a>

      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:pull_requests&quot;}" aria-label="0 pull requests" href="https://github.com/FossifyOrg/Voice-Recorder/pulls" data-view-component="true">
        0</a>
      <p><span data-view-component="true">
          Updated <relative-time datetime="2025-06-17T12:28:00Z">Jun 17, 2025</relative-time>
</span></p></div></div>
</li>
        <li data-view-component="true">          <div data-view-component="true" itemprop="owns" itemtype="http://schema.org/Code" itemscope="itemscope">
      <div data-view-component="true">
        <p><a itemprop="name codeRepository" data-hovercard-type="repository" data-hovercard-url="/FossifyOrg/Gallery/hovercard" data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:repo_nwo&quot;}" href="https://github.com/FossifyOrg/Gallery" data-view-component="true">Gallery</a>
        <span title="Label: Public" data-view-component="true">
          Public
</span></p><p itemprop="description" data-view-component="true">
            Browse your memories without any interruptions with this photo and video gallery
</p></div>
      <p><span data-view-component="true"><a id="commit-activity-link-502586319" href="https://github.com/FossifyOrg/Gallery/graphs/commit-activity" data-view-component="true"></a>  <tool-tip id="tooltip-5449c339-1740-4fed-898e-18cd94020fb8" for="commit-activity-link-502586319" popover="manual" data-direction="s" data-type="label" data-view-component="true">FossifyOrg/Gallery’s past year of commit activity</tool-tip></span>
</p></div>
</li>
        <li data-view-component="true">          <div itemprop="owns" itemtype="http://schema.org/Code" itemscope="itemscope" data-view-component="true">
  
    <div data-view-component="true">
      <div data-view-component="true">
        <p><a itemprop="name codeRepository" data-hovercard-type="repository" data-hovercard-url="/FossifyOrg/Keyboard/hovercard" data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:repo_nwo&quot;}" href="https://github.com/FossifyOrg/Keyboard" data-view-component="true">Keyboard</a>
        <span title="Label: Public" data-view-component="true">
          Public
</span></p><p itemprop="description" data-view-component="true">
            Easy keyboard for inserting all kinds of texts, special characters and numbers.
</p></div>
      <p><span data-view-component="true"><a id="commit-activity-link-516439882" href="https://github.com/FossifyOrg/Keyboard/graphs/commit-activity" data-view-component="true"></a>  <tool-tip id="tooltip-da873ad1-dfda-4689-aa3d-5938fdc1624c" for="commit-activity-link-516439882" popover="manual" data-direction="s" data-type="label" data-view-component="true">FossifyOrg/Keyboard’s past year of commit activity</tool-tip></span>
</p></div>
    <div data-view-component="true">

        <p><span>
  <span></span>
  <span itemprop="programmingLanguage">Kotlin</span>
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:stars&quot;}" aria-label="382 stars" href="https://github.com/FossifyOrg/Keyboard/stargazers" data-view-component="true">
          382</a>
        <p><span data-view-component="true">
          GPL-3.0
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:forks&quot;}" aria-label="33 forks" href="https://github.com/FossifyOrg/Keyboard/forks" data-view-component="true">
          33</a>
      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:issues&quot;}" aria-label="42 issues" href="https://github.com/FossifyOrg/Keyboard/issues" data-view-component="true">
        42</a>

      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:pull_requests&quot;}" aria-label="1 pull request" href="https://github.com/FossifyOrg/Keyboard/pulls" data-view-component="true">
        1</a>
      <p><span data-view-component="true">
          Updated <relative-time datetime="2025-06-17T12:27:36Z">Jun 17, 2025</relative-time>
</span></p></div></div>
</li>
        <li data-view-component="true">          <div itemprop="owns" itemtype="http://schema.org/Code" itemscope="itemscope" data-view-component="true">
  
    <div data-view-component="true">
      <div data-view-component="true">
        <p><a itemprop="name codeRepository" data-hovercard-type="repository" data-hovercard-url="/FossifyOrg/Messages/hovercard" data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:repo_nwo&quot;}" href="https://github.com/FossifyOrg/Messages" data-view-component="true">Messages</a>
        <span title="Label: Public" data-view-component="true">
          Public
</span></p><p itemprop="description" data-view-component="true">
            An easy and quick way of managing SMS and MMS messages without ads.
</p></div>
      <p><span data-view-component="true"><a id="commit-activity-link-502522337" href="https://github.com/FossifyOrg/Messages/graphs/commit-activity" data-view-component="true"></a>  <tool-tip id="tooltip-db34d797-b3f0-4e21-b3ae-06b4cee34997" for="commit-activity-link-502522337" popover="manual" data-direction="s" data-type="label" data-view-component="true">FossifyOrg/Messages’s past year of commit activity</tool-tip></span>
</p></div>
    <div data-view-component="true">

        <p><span>
  <span></span>
  <span itemprop="programmingLanguage">Kotlin</span>
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:stars&quot;}" aria-label="834 stars" href="https://github.com/FossifyOrg/Messages/stargazers" data-view-component="true">
          834</a>
        <p><span data-view-component="true">
          GPL-3.0
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:forks&quot;}" aria-label="68 forks" href="https://github.com/FossifyOrg/Messages/forks" data-view-component="true">
          68</a>
      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:issues&quot;}" aria-label="134 issues" href="https://github.com/FossifyOrg/Messages/issues" data-view-component="true">
        134</a>

      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:pull_requests&quot;}" aria-label="2 pull requests" href="https://github.com/FossifyOrg/Messages/pulls" data-view-component="true">
        2</a>
      <p><span data-view-component="true">
          Updated <relative-time datetime="2025-06-17T12:25:58Z">Jun 17, 2025</relative-time>
</span></p></div></div>
</li>
        <li data-view-component="true">          <div itemprop="owns" itemtype="http://schema.org/Code" itemscope="itemscope" data-view-component="true">
  
    <div data-view-component="true">
      <div data-view-component="true">
        <p><a itemprop="name codeRepository" data-hovercard-type="repository" data-hovercard-url="/FossifyOrg/Contacts/hovercard" data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:repo_nwo&quot;}" href="https://github.com/FossifyOrg/Contacts" data-view-component="true">Contacts</a>
        <span title="Label: Public" data-view-component="true">
          Public
</span></p><p itemprop="description" data-view-component="true">
            Easy and quick contact management with no ads, handles groups and favorites too.
</p></div>
      <p><span data-view-component="true"><a id="commit-activity-link-530679875" href="https://github.com/FossifyOrg/Contacts/graphs/commit-activity" data-view-component="true"></a>  <tool-tip id="tooltip-f8f986b3-e854-4f69-bc1b-451923afa590" for="commit-activity-link-530679875" popover="manual" data-direction="s" data-type="label" data-view-component="true">FossifyOrg/Contacts’s past year of commit activity</tool-tip></span>
</p></div>
    <div data-view-component="true">

        <p><span>
  <span></span>
  <span itemprop="programmingLanguage">Kotlin</span>
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:stars&quot;}" aria-label="494 stars" href="https://github.com/FossifyOrg/Contacts/stargazers" data-view-component="true">
          494</a>
        <p><span data-view-component="true">
          GPL-3.0
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:forks&quot;}" aria-label="31 forks" href="https://github.com/FossifyOrg/Contacts/forks" data-view-component="true">
          31</a>
      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:issues&quot;}" aria-label="85 issues" href="https://github.com/FossifyOrg/Contacts/issues" data-view-component="true">
        85</a>

      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:pull_requests&quot;}" aria-label="1 pull request" href="https://github.com/FossifyOrg/Contacts/pulls" data-view-component="true">
        1</a>
      <p><span data-view-component="true">
          Updated <relative-time datetime="2025-06-17T12:24:49Z">Jun 17, 2025</relative-time>
</span></p></div></div>
</li>
        <li data-view-component="true">          <div itemprop="owns" itemtype="http://schema.org/Code" itemscope="itemscope" data-view-component="true">
  
    <div data-view-component="true">
      <div data-view-component="true">
        <p><a itemprop="name codeRepository" data-hovercard-type="repository" data-hovercard-url="/FossifyOrg/Phone/hovercard" data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:repo_nwo&quot;}" href="https://github.com/FossifyOrg/Phone" data-view-component="true">Phone</a>
        <span title="Label: Public" data-view-component="true">
          Public
</span></p><p itemprop="description" data-view-component="true">
            A handy phone call manager with phonebook, number blocking and multi-SIM support
</p></div>
      <p><span data-view-component="true"><a id="commit-activity-link-499759123" href="https://github.com/FossifyOrg/Phone/graphs/commit-activity" data-view-component="true"></a>  <tool-tip id="tooltip-a3006de9-db30-4507-b084-826de5eab1d5" for="commit-activity-link-499759123" popover="manual" data-direction="s" data-type="label" data-view-component="true">FossifyOrg/Phone’s past year of commit activity</tool-tip></span>
</p></div>
    <div data-view-component="true">

        <p><span>
  <span></span>
  <span itemprop="programmingLanguage">Kotlin</span>
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:stars&quot;}" aria-label="764 stars" href="https://github.com/FossifyOrg/Phone/stargazers" data-view-component="true">
          764</a>
        <p><span data-view-component="true">
          GPL-3.0
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:forks&quot;}" aria-label="75 forks" href="https://github.com/FossifyOrg/Phone/forks" data-view-component="true">
          75</a>
      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:issues&quot;}" aria-label="104 issues" href="https://github.com/FossifyOrg/Phone/issues" data-view-component="true">
        104</a>

      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:pull_requests&quot;}" aria-label="5 pull requests" href="https://github.com/FossifyOrg/Phone/pulls" data-view-component="true">
        5</a>
      <p><span data-view-component="true">
          Updated <relative-time datetime="2025-06-17T12:21:27Z">Jun 17, 2025</relative-time>
</span></p></div></div>
</li>
        <li data-view-component="true">          <div itemprop="owns" itemtype="http://schema.org/Code" itemscope="itemscope" data-view-component="true">
  
    <div data-view-component="true">
      <div data-view-component="true">
        <p><a itemprop="name codeRepository" data-hovercard-type="repository" data-hovercard-url="/FossifyOrg/Camera/hovercard" data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:repo_nwo&quot;}" href="https://github.com/FossifyOrg/Camera" data-view-component="true">Camera</a>
        <span title="Label: Public" data-view-component="true">
          Public
</span></p><p itemprop="description" data-view-component="true">
            Quick photo and video camera with a flash, customizable aspect ratio.
</p></div>
      <p><span data-view-component="true"><a id="commit-activity-link-559768640" href="https://github.com/FossifyOrg/Camera/graphs/commit-activity" data-view-component="true"></a>  <tool-tip id="tooltip-458a7d29-da72-4bd4-a239-b8d63b3044e3" for="commit-activity-link-559768640" popover="manual" data-direction="s" data-type="label" data-view-component="true">FossifyOrg/Camera’s past year of commit activity</tool-tip></span>
</p></div>
    <div data-view-component="true">

        <p><span>
  <span></span>
  <span itemprop="programmingLanguage">Kotlin</span>
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:stars&quot;}" aria-label="206 stars" href="https://github.com/FossifyOrg/Camera/stargazers" data-view-component="true">
          206</a>
        <p><span data-view-component="true">
          GPL-3.0
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:forks&quot;}" aria-label="22 forks" href="https://github.com/FossifyOrg/Camera/forks" data-view-component="true">
          22</a>
      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:issues&quot;}" aria-label="28 issues" href="https://github.com/FossifyOrg/Camera/issues" data-view-component="true">
        28</a>

      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:pull_requests&quot;}" aria-label="1 pull request" href="https://github.com/FossifyOrg/Camera/pulls" data-view-component="true">
        1</a>
      <p><span data-view-component="true">
          Updated <relative-time datetime="2025-06-17T12:17:51Z">Jun 17, 2025</relative-time>
</span></p></div></div>
</li>
        <li data-view-component="true">          <div itemprop="owns" itemtype="http://schema.org/Code" itemscope="itemscope" data-view-component="true">
  
    <div data-view-component="true">
      <div data-view-component="true">
        <p><a itemprop="name codeRepository" data-hovercard-type="repository" data-hovercard-url="/FossifyOrg/Calculator/hovercard" data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:repo_nwo&quot;}" href="https://github.com/FossifyOrg/Calculator" data-view-component="true">Calculator</a>
        <span title="Label: Public" data-view-component="true">
          Public
</span></p><p itemprop="description" data-view-component="true">
            A calculator for quick simple calculations with a nice user interface and no ads
</p></div>
      <p><span data-view-component="true"><a id="commit-activity-link-498017491" href="https://github.com/FossifyOrg/Calculator/graphs/commit-activity" data-view-component="true"></a>  <tool-tip id="tooltip-9386fba5-46fb-46e7-9c9c-c3395f5a73e0" for="commit-activity-link-498017491" popover="manual" data-direction="s" data-type="label" data-view-component="true">FossifyOrg/Calculator’s past year of commit activity</tool-tip></span>
</p></div>
    <div data-view-component="true">

        <p><span>
  <span></span>
  <span itemprop="programmingLanguage">Kotlin</span>
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:stars&quot;}" aria-label="220 stars" href="https://github.com/FossifyOrg/Calculator/stargazers" data-view-component="true">
          220</a>
        <p><span data-view-component="true">
          GPL-3.0
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:forks&quot;}" aria-label="28 forks" href="https://github.com/FossifyOrg/Calculator/forks" data-view-component="true">
          28</a>
      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:issues&quot;}" aria-label="10 issues" href="https://github.com/FossifyOrg/Calculator/issues" data-view-component="true">
        10</a>

      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:pull_requests&quot;}" aria-label="4 pull requests" href="https://github.com/FossifyOrg/Calculator/pulls" data-view-component="true">
        4</a>
      <p><span data-view-component="true">
          Updated <relative-time datetime="2025-06-17T11:41:43Z">Jun 17, 2025</relative-time>
</span></p></div></div>
</li>
        <li data-view-component="true">          <div data-view-component="true" itemprop="owns" itemtype="http://schema.org/Code" itemscope="itemscope">
      <div data-view-component="true">
        <p><a itemprop="name codeRepository" data-hovercard-type="repository" data-hovercard-url="/FossifyOrg/Calendar/hovercard" data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:repo_nwo&quot;}" href="https://github.com/FossifyOrg/Calendar" data-view-component="true">Calendar</a>
        <span title="Label: Public" data-view-component="true">
          Public
</span></p><p itemprop="description" data-view-component="true">
            A simple calendar with events, customizable widgets and no ads.
</p></div>
      <p><span data-view-component="true"><a id="commit-activity-link-492611621" href="https://github.com/FossifyOrg/Calendar/graphs/commit-activity" data-view-component="true"></a>  <tool-tip id="tooltip-a7f3d62d-e4be-4680-9a1a-00ddcc30dc71" for="commit-activity-link-492611621" popover="manual" data-direction="s" data-type="label" data-view-component="true">FossifyOrg/Calendar’s past year of commit activity</tool-tip></span>
</p></div>
</li>
        <li data-view-component="true">          <div itemprop="owns" itemtype="http://schema.org/Code" itemscope="itemscope" data-view-component="true">
  
    <div data-view-component="true">
      <div data-view-component="true">
        <p><a itemprop="name codeRepository" data-hovercard-type="repository" data-hovercard-url="/FossifyOrg/File-Manager/hovercard" data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:repo_nwo&quot;}" href="https://github.com/FossifyOrg/File-Manager" data-view-component="true">File-Manager</a>
        <span title="Label: Public" data-view-component="true">
          Public
</span></p><p itemprop="description" data-view-component="true">
            Easy app for managing your files without ads, respecting your privacy &amp; security
</p></div>
      <p><span data-view-component="true"><a id="commit-activity-link-496918131" href="https://github.com/FossifyOrg/File-Manager/graphs/commit-activity" data-view-component="true"></a>  <tool-tip id="tooltip-ea4bee38-f305-4136-aab9-c99b203b3565" for="commit-activity-link-496918131" popover="manual" data-direction="s" data-type="label" data-view-component="true">FossifyOrg/File-Manager’s past year of commit activity</tool-tip></span>
</p></div>
    <div data-view-component="true">

        <p><span>
  <span></span>
  <span itemprop="programmingLanguage">Kotlin</span>
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:stars&quot;}" aria-label="902 stars" href="https://github.com/FossifyOrg/File-Manager/stargazers" data-view-component="true">
          902</a>
        <p><span data-view-component="true">
          GPL-3.0
</span></p><a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:forks&quot;}" aria-label="50 forks" href="https://github.com/FossifyOrg/File-Manager/forks" data-view-component="true">
          50</a>
      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:issues&quot;}" aria-label="58 issues" href="https://github.com/FossifyOrg/File-Manager/issues" data-view-component="true">
        58</a>

      <a data-analytics-event="{&quot;category&quot;:&quot;profiles:org_repos_list_item&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;target:pull_requests&quot;}" aria-label="2 pull requests" href="https://github.com/FossifyOrg/File-Manager/pulls" data-view-component="true">
        2</a>
      <p><span data-view-component="true">
          Updated <relative-time datetime="2025-06-17T05:16:44Z">Jun 17, 2025</relative-time>
</span></p></div></div>
</li>
</ul>  
</div></div>
  </div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fun with Telnet (117 pts)]]></title>
            <link>https://brandonrozek.com/blog/fun-with-telnet/</link>
            <guid>44295925</guid>
            <pubDate>Tue, 17 Jun 2025 05:08:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://brandonrozek.com/blog/fun-with-telnet/">https://brandonrozek.com/blog/fun-with-telnet/</a>, See on <a href="https://news.ycombinator.com/item?id=44295925">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>Some time ago I came across a cinematic experience</p>
<pre tabindex="0"><code>.........                @@@@@    @@@@@      ...........           
.........               @     @  @     @     ...........           
 .........                 @@@   @     @      ..........           
  ........               @@      @     @       .........           
   ........             @@@@@@@   @@@@@  th     .......            
     ......           -----------------------    ......            
       .....            C  E  N  T  U  R  Y        ....            
         ....         -----------------------       ...            
           ...        @@@@@ @@@@@ @   @ @@@@@        ..            
            ==          @   @      @ @    @          ==            
          __||__        @   @@@@    @     @        __||__          
         |      |       @   @      @ @    @       |      |         
_________|______|_____  @   @@@@@ @   @   @  _____|______|_________
</code></pre><p>It was a Star Wars inspired animation, brought to you by Telnet!</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>telnet towel.blinkenlights.nl <span>23</span>
</span></span></code></pre></div><p><em>It’s worth watching the entire thing.</em></p>
<p>Fast forward a few years, and I’ve come across other great <a href="https://www.telnet.org/htm/places.htm">telnet nuggets</a></p>
<table>
  <thead>
      <tr>
          <th>Address</th>
          <th>Description</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>freechess.org 5000</td>
          <td>Chess <a href="https://www.freechess.org/">[1]</a></td>
      </tr>
      <tr>
          <td>towel.blinkenlights.nl 23</td>
          <td>Star Wars asciimation</td>
      </tr>
      <tr>
          <td>mtrek.com 1701</td>
          <td>Space combat game (inspired by StarTrek) <a href="http://mtrek.com/">[1]</a></td>
      </tr>
      <tr>
          <td>fibs.com 4321</td>
          <td>Backgammon <a href="http://fibs.com/">[1]</a> <a href="https://tinysubversions.com/notes/backgammon-fibs/">[2]</a></td>
      </tr>
      <tr>
          <td>mapscii.me</td>
          <td>World map (Can zoom in with mouse) <a href="https://github.com/rastapasta/mapscii">[1]</a></td>
      </tr>
      <tr>
          <td>telehack.com</td>
          <td>Arpanet/Usenet Simulation. Includes over 60 text-based games <a href="https://telehack.com/">[1]</a></td>
      </tr>
  </tbody>
</table>
<p>Remember that telnet communication is all over plaintext, so don’t accidentally leak any secrets. Have fun discovering the quirky old world of Telnet!</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I recreated 90s Mode X demoscene effects in JavaScript and Canvas (177 pts)]]></title>
            <link>https://jdfio.com/pages-output/demos/x-mode/</link>
            <guid>44295667</guid>
            <pubDate>Tue, 17 Jun 2025 04:07:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jdfio.com/pages-output/demos/x-mode/">https://jdfio.com/pages-output/demos/x-mode/</a>, See on <a href="https://news.ycombinator.com/item?id=44295667">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <header>
      <h2>
        <a href="https://en.wikipedia.org/wiki/Mode_X" target="_blank" rel="noopener noreferrer" title="Learn more about Mode X (opens in new tab)">MODE-X<span>(opens in new tab)</span></a>
        <a href="https://en.wikipedia.org/wiki/Video_Graphics_Array" target="_blank" rel="noopener noreferrer" title="Learn more about Video Graphics Array (opens in new tab)">VGA<span>(opens in new tab)</span></a>
        <a href="https://demoscene.assembly.org/" target="_blank" rel="noopener noreferrer" title="Explore the Demoscene on Assembly.org (opens in new tab)">DEMOSCENES<span>(opens in new tab)</span></a>
      </h2>
        <p>
          Simulated in JavaScript by
          <a href="https://github.com/gneissguise" data-text="Justin Greisiger Frost" target="_blank" rel="noopener noreferrer" aria-label="Justin Greisiger Frost (opens in new GitHub tab)" title="View Justin Greisiger Frost's profile on GitHub (opens in new tab)">
            Justin Greisiger Frost
            <!--
              Note: Using aria-label here to append "(opens in new GitHub tab)"
              because the link text itself is already descriptive.
              Alternatively, a nested sr-only span could be used if you prefer
              the aria-label to exactly match data-text or the visible text.
              For this specific case, as data-text is identical to the visible text,
              an aria-label is a concise way to add the new tab information.
            -->
          </a>    
        </p>
    </header>

    <p>
      <main>
        <canvas id="demo-canvas" role="img" aria-label="VGA Demostration Output" title="VGA Demostration Output">
          Your browser does not support the HTML5 canvas element, or JavaScript is disabled. This experience relies on canvas for visual demonstrations.
        </canvas>
      </main>
    </p>

    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Humble Programmer (1972) (118 pts)]]></title>
            <link>https://www.cs.utexas.edu/~EWD/transcriptions/EWD03xx/EWD340.html</link>
            <guid>44294905</guid>
            <pubDate>Tue, 17 Jun 2025 01:25:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cs.utexas.edu/~EWD/transcriptions/EWD03xx/EWD340.html">https://www.cs.utexas.edu/~EWD/transcriptions/EWD03xx/EWD340.html</a>, See on <a href="https://news.ycombinator.com/item?id=44294905">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
						<p><b>The Humble Programmer</b><br>
							by<br>
							Edsger W. Dijkstra</p>
						<p>As a result of a long sequence of coincidences I entered the programming profession officially on the first spring morning of 1952 and as far as I have been able to trace, I was the first Dutchman to do so in my country. In retrospect the most amazing thing was the slowness with which, at least in my part of the world, the programming profession emerged, a slowness which is now hard to believe. But I am grateful for two vivid recollections from that period that establish that slowness beyond any doubt.</p>
						<p>After having programmed for some three years, I had a discussion with A.&nbsp;van Wijngaarden, who was then my boss at the Mathematical Centre in Amsterdam, a discussion for which I shall remain grateful to him as long as I live. The point was that I was supposed to study theoretical physics at the University of Leiden simultaneously, and as I found the two activities harder and harder to combine, I had to make up my mind, either to stop programming and become a real, respectable theoretical physicist, or to carry my study of physics to a formal completion only, with a minimum of effort, and to become....., yes what? A programmer? But was that a respectable profession? For after all, what was programming? Where was the sound body of knowledge that could support it as an intellectually respectable discipline? I remember quite vividly how I envied my hardware colleagues, who, when asked about their professional competence, could at least point out that they knew everything about vacuum tubes, amplifiers and the rest, whereas I felt that, when faced with that question, I would stand empty-handed. Full of misgivings I knocked on van Wijngaarden’s office door, asking him whether I could “speak to him for a moment”; when I left his office a number of hours later, I was another person. For after having listened to my problems patiently, he agreed that up till that moment there was not much of a programming discipline, but then he went on to explain quietly that automatic computers were here to stay, that we were just at the beginning and could not I be one of the persons called to make programming a respectable discipline in the years to come? This was a turning point in my life and I completed my study of physics formally as quickly as I could. One moral of the above story is, of course, that we must be very careful when we give advice to younger people; sometimes they follow it!</p>
						<p>Another two years later, in 1957, I married and Dutch marriage rites require you to state your profession and I stated that I was a programmer. But the municipal authorities of the town of Amsterdam did not accept it on the grounds that there was no such profession. And, believe it or not, but under the heading “profession” my marriage act shows the ridiculous entry “theoretical physicist”!</p>
						<p>So much for the slowness with which I saw the programming profession emerge in my own country. Since then I have seen more of the world, and it is my general impression that in other countries, apart from a possible shift of dates, the growth pattern has been very much the same.</p>
						<p>Let me try to capture the situation in those old days in a little bit more detail, in the hope of getting a better understanding of the situation today. While we pursue our analysis, we shall see how many common misunderstandings about the true nature of the programming task can be traced back to that now distant past.</p>
						<p>The first automatic electronic computers were all unique, single-copy machines and they were all to be found in an environment with the exciting flavour of an experimental laboratory. Once the vision of the automatic computer was there, its realisation was a tremendous challenge to the electronic technology then available, and one thing is certain: we cannot deny the courage of the groups that decided to try and build such a fantastic piece of equipment. For fantastic pieces of equipment they were: in retrospect one can only wonder that those first machines worked at all, at least sometimes. The overwhelming problem was to get and keep the machine in working order. The preoccupation with the physical aspects of automatic computing is still reflected in the names of the older scientific societies in the field, such as the Association for Computing Machinery or the British Computer Society, names in which explicit reference is made to the physical equipment.</p>
						<p>What about the poor programmer? Well, to tell the honest truth: he was hardly noticed. For one thing, the first machines were so bulky that you could hardly move them and besides that, they required such extensive maintenance that it was quite natural that the place where people tried to use the machine was the same laboratory where the machine had been developed. Secondly, his somewhat invisible work was without any glamour: you could show the machine to visitors and that was several orders of magnitude more spectacular than some sheets of coding. But most important of all, the programmer himself had a very modest view of his own work: his work derived all its significance from the existence of that wonderful machine. Because that was a unique machine, he knew only too well that his programs had only local significance and also, because it was patently obvious that this machine would have a limited lifetime, he knew that very little of his work would have a lasting value. Finally, there is yet another circumstance that had a profound influence on the programmer’s attitude to his work: on the one hand, besides being unreliable, his machine was usually too slow and its memory was usually too small, i.e. he was faced with a pinching shoe, while on the other hand its usually somewhat queer order code would cater for the most unexpected constructions. And in those days many a clever programmer derived an immense intellectual satisfaction from the cunning tricks by means of which he contrived to squeeze the impossible into the constraints of his equipment.</p>
						<p>Two opinions about programming date from those days. I mention them now, I shall return to them later. The one opinion was that a really competent programmer should be puzzle-minded and very fond of clever tricks; the other opinion was that programming was nothing more than optimizing the efficiency of the computational process, in one direction or the other.</p>
						<p>The latter opinion was the result of the frequent circumstance that, indeed, the available equipment was a painfully pinching shoe, and in those days one often encountered the naive expectation that, once more powerful machines were available, programming would no longer be a problem, for then the struggle to push the machine to its limits would no longer be necessary and that was all what programming was about, wasn’t it? But in the next decades something completely different happened: more powerful machines became available, not just an order of magnitude more powerful, even several orders of magnitude more powerful. But instead of finding ourselves in the state of eternal bliss of all programming problems solved, we found ourselves up to our necks in the software crisis! How come?</p>
						<p>There is a minor cause: in one or two respects modern machinery is basically more difficult to handle than the old machinery. Firstly, we have got the I/O interrupts, occurring at unpredictable and irreproducible moments; compared with the old sequential machine that pretended to be a fully deterministic automaton, this has been a dramatic change and many a systems programmer’s grey hair bears witness to the fact that we should not talk lightly about the logical problems created by that feature. Secondly, we have got machines equipped with multi-level stores, presenting us problems of management strategy that, in spite of the extensive literature on the subject, still remain rather elusive. So much for the added complication due to structural changes of the actual machines.</p>
						<p>But I called this a minor cause; the major cause is... that the machines have become several orders of magnitude more powerful! To put it quite bluntly: as long as there were no machines, programming was no problem at all; when we had a few weak computers, programming became a mild problem, and now we have gigantic computers, programming had become an equally gigantic problem. In this sense the electronic industry has not solved a single problem, it has only created them, it has created the problem of using its products. To put it in another way: as the power of available machines grew by a factor of more than a thousand, society’s ambition to apply these machines grew in proportion, and it was the poor programmer who found his job in this exploded field of tension between ends and means. The increased power of the hardware, together with the perhaps even more dramatic increase in its reliability, made solutions feasible that the programmer had not dared to dream about a few years before. And now, a few years later, he <em>had</em> to dream about them and, even worse, he had to transform such dreams into reality! Is it a wonder that we found ourselves in a software crisis? No, certainly not, and as you may guess, it was even predicted well in advance; but the trouble with minor prophets, of course, is that it is only five years later that you really know that they had been right.</p>
						<p>Then, in the mid-sixties, something terrible happened: the computers of the so-called third generation made their appearance. The official literature tells us that their price/performance ratio has been one of the major design objectives. But if you take as “performance” the duty cycle of the machine’s various components, little will prevent you from ending up with a design in which the major part of your performance goal is reached by internal housekeeping activities of doubtful necessity. And if your definition of price is the price to be paid for the hardware, little will prevent you from ending up with a design that is terribly hard to program for: for instance the order code might be such as to enforce, either upon the programmer or upon the system, early binding decisions presenting conflicts that really cannot be resolved. And to a large extent these unpleasant possibilities seem to have become reality.</p>
						<p>When these machines were announced and their functional specifications became known, quite a few among us must have become quite miserable; at least I was. It was only reasonable to expect that such machines would flood the computing community, and it was therefore all the more important that their design should be as sound as possible. But the design embodied such serious flaws that I felt that with a single stroke the progress of computing science had been retarded by at least ten years: it was then that I had the blackest week in the whole of my professional life. Perhaps the most saddening thing now is that, even after all those years of frustrating experience, still so many people honestly believe that some law of nature tells us that machines have to be that way. They silence their doubts by observing how many of these machines have been sold, and derive from that observation the false sense of security that, after all, the design cannot have been that bad. But upon closer inspection, that line of defense has the same convincing strength as the argument that cigarette smoking must be healthy because so many people do it.</p>
						<p>It is in this connection that I regret that it is not customary for scientific journals in the computing area to publish reviews of newly announced computers in much the same way as we review scientific publications: to review machines would be at least as important. And here I have a confession to make: in the early sixties I wrote such a review with the intention of submitting it to the CACM, but in spite of the fact that the few colleagues to whom the text was sent for their advice, urged me all to do so, I did not dare to do it, fearing that the difficulties either for myself or for the editorial board would prove to be too great. This suppression was an act of cowardice on my side for which I blame myself more and more. The difficulties I foresaw were a consequence of the absence of generally accepted criteria, and although I was convinced of the validity of the criteria I had chosen to apply, I feared that my review would be refused or discarded as “a matter of personal taste”. I still think that such reviews would be extremely useful and I am longing to see them appear, for their accepted appearance would be a sure sign of maturity of the computing community.</p>
						<p>The reason that I have paid the above attention to the hardware scene is because I have the feeling that one of the most important aspects of any computing tool is its influence on the thinking habits of those that try to use it, and because I have reasons to believe that that influence is many times stronger than is commonly assumed. Let us now switch our attention to the software scene.</p>
						<p>Here the diversity has been so large that I must confine myself to a few stepping stones. I am painfully aware of the arbitrariness of my choice and I beg you not to draw any conclusions with regard to my appreciation of the many efforts that will remain unmentioned.</p>
						<p>In the beginning there was the EDSAC in Cambridge, England, and I think it quite impressive that right from the start the notion of a subroutine library played a central role in the design of that machine and of the way in which it should be used. It is now nearly 25 years later and the computing scene has changed dramatically, but the notion of basic software is still with us, and the notion of the closed subroutine is still one of the key concepts in programming. We should recognise the closed subroutines as one of the greatest software inventions; it has survived three generations of computers and it will survive a few more, because it caters for the implementation of one of our basic patterns of abstraction. Regrettably enough, its importance has been underestimated in the design of the third generation computers, in which the great number of explicitly named registers of the arithmetic unit implies a large overhead on the subroutine mechanism. But even that did not kill the concept of the subroutine, and we can only pray that the mutation won’t prove to be hereditary.</p>
						<p>The second major development on the software scene that I would like to mention is the birth of FORTRAN. At that time this was a project of great temerity and the people responsible for it deserve our great admiration. It would be absolutely unfair to blame them for shortcomings that only became apparent after a decade or so of extensive usage: groups with a successful look-ahead of ten years are quite rare! In retrospect we must rate FORTRAN as a successful coding technique, but with very few effective aids to conception, aids which are now so urgently needed that time has come to consider it out of date. The sooner we can forget that FORTRAN has ever existed, the better, for as a vehicle of thought it is no longer adequate: it wastes our brainpower, is too risky and therefore too expensive to use. FORTRAN’s tragic fate has been its wide acceptance, mentally chaining thousands and thousands of programmers to our past mistakes. I pray daily that more of my fellow-programmers may find the means of freeing themselves from the curse of compatibility.</p>
						<p>The third project I would not like to leave unmentioned is LISP, a fascinating enterprise of a completely different nature. With a few very basic principles at its foundation, it has shown a remarkable stability. Besides that, LISP has been the carrier for a considerable number of in a sense our most sophisticated computer applications. LISP has jokingly been described as “the most intelligent way to misuse a computer”. I think that description a great compliment because it transmits the full flavour of liberation: it has assisted a number of our most gifted fellow humans in thinking previously impossible thoughts.</p>
						<p>The fourth project to be mentioned is ALGOL&nbsp;60. While up to the present day FORTRAN programmers still tend to understand their programming language in terms of the specific implementation they are working with —hence the prevalence of octal and hexadecimal dumps—, while the definition of LISP is still a curious mixture of what the language means and how the mechanism works, the famous Report on the Algorithmic Language ALGOL&nbsp;60 is the fruit of a genuine effort to carry abstraction a vital step further and to define a programming language in an implementation-independent way. One could argue that in this respect its authors have been so successful that they have created serious doubts as to whether it could be implemented at all! The report gloriously demonstrated the power of the formal method BNF, now fairly known as Backus-Naur-Form, and the power of carefully phrased English, at least when used by someone as brilliant as Peter Naur. I think that it is fair to say that only very few documents as short as this have had an equally profound influence on the computing community. The ease with which in later years the names ALGOL and ALGOL-like have been used, as an unprotected trade mark, to lend some of its glory to a number of sometimes hardly related younger projects, is a somewhat shocking compliment to its standing. The strength of BNF as a defining device is responsible for what I regard as one of the weaknesses of the language: an over-elaborate and not too systematic syntax could now be crammed into the confines of very few pages. With a device as powerful as BNF, the Report on the Algorithmic Language ALGOL&nbsp;60 should have been much shorter. Besides that I am getting very doubtful about ALGOL&nbsp;60’s parameter mechanism: it allows the programmer so much combinatorial freedom, that its confident use requires a strong discipline from the programmer. Besides expensive to implement it seems dangerous to use.</p>
						<p>Finally, although the subject is not a pleasant one, I must mention PL/1, a programming language for which the defining documentation is of a frightening size and complexity. Using PL/1 must be like flying a plane with 7000 buttons, switches and handles to manipulate in the cockpit. I absolutely fail to see how we can keep our growing programs firmly within our intellectual grip when by its sheer baroqueness the programming language —our basic tool, mind you!— already escapes our intellectual control. And if I have to describe the influence PL/1 can have on its users, the closest metaphor that comes to my mind is that of a drug. I remember from a symposium on higher level programming language a lecture given in defense of PL/1 by a man who described himself as one of its devoted users. But within a one-hour lecture in praise of PL/1. he managed to ask for the addition of about fifty new “features”, little supposing that the main source of his problems could very well be that it contained already far too many “features”. The speaker displayed all the depressing symptoms of addiction, reduced as he was to the state of mental stagnation in which he could only ask for more, more, more... When FORTRAN has been called an infantile disorder, full PL/1, with its growth characteristics of a dangerous tumor, could turn out to be a fatal disease.</p>
						<p>So much for the past. But there is no point in making mistakes unless thereafter we are able to learn from them. As a matter of fact, I think that we have learned so much, that within a few years programming can be an activity vastly different from what it has been up till now, so different that we had better prepare ourselves for the shock. Let me sketch for you one of the possible futures. At first sight, this vision of programming in perhaps already the near future may strike you as utterly fantastic. Let me therefore also add the considerations that might lead one to the conclusion that this vision could be a very real possibility.</p>
						<p>The vision is that, well before the seventies have run to completion, we shall be able to design and implement the kind of systems that are now straining our programming ability, at the expense of only a few percent in man-years of what they cost us now, and that besides that, these systems will be virtually free of bugs. These two improvements go hand in hand. In the latter respect software seems to be different from many other products, where as a rule a higher quality implies a higher price. Those who want really reliable software will discover that they must find means of avoiding the majority of bugs to start with, and as a result the programming process will become cheaper. If you want more effective programmers, you will discover that they should not waste their time debugging, they should not introduce the bugs to start with. In other words: both goals point to the same change.</p>
						<p>Such a drastic change in such a short period of time would be a revolution, and to all persons that base their expectations for the future on smooth extrapolation of the recent past —appealing to some unwritten laws of social and cultural inertia— the chance that this drastic change will take place must seem negligible. But we all know that sometimes revolutions do take place! And what are the chances for this one?</p>
						<p>There seem to be three major conditions that must be fulfilled. The world at large must recognize the need for the change; secondly the economic need for it must be sufficiently strong; and, thirdly, the change must be technically feasible. Let me discuss these three conditions in the above order.</p>
						<p>With respect to the recognition of the need for greater reliability of software, I expect no disagreement anymore. Only a few years ago this was different: to talk about a software crisis was blasphemy. The turning point was the Conference on Software Engineering in Garmisch, October 1968, a conference that created a sensation as there occurred the first open admission of the software crisis. And by now it is generally recognized that the design of any large sophisticated system is going to be a very difficult job, and whenever one meets people responsible for such undertakings, one finds them very much concerned about the reliability issue, and rightly so. In short, our first condition seems to be satisfied.</p>
						<p>Now for the economic need. Nowadays one often encounters the opinion that in the sixties programming has been an overpaid profession, and that in the coming years programmer salaries may be expected to go down. Usually this opinion is expressed in connection with the recession, but it could be a symptom of something different and quite healthy, viz. that perhaps the programmers of the past decade have not done so good a job as they should have done. Society is getting dissatisfied with the performance of programmers and of their products. But there is another factor of much greater weight. In the present situation it is quite usual that for a specific system, the price to be paid for the development of the software is of the same order of magnitude as the price of the hardware needed, and society more or less accepts that. But hardware manufacturers tell us that in the next decade hardware prices can be expected to drop with a factor of ten. If software development were to continue to be the same clumsy and expensive process as it is now, things would get completely out of balance. You cannot expect society to accept this, and therefore we <em>must</em> learn to program an order of magnitude more effectively. To put it in another way: as long as machines were the largest item on the budget, the programming profession could get away with its clumsy techniques, but that umbrella will fold rapidly. In short, also our second condition seems to be satisfied.</p>
						<p>And now the third condition: is it technically feasible? I think it might and I shall give you six arguments in support of that opinion.</p>
						<p>A study of program structure had revealed that programs —even alternative programs for the same task and with the same mathematical content— can differ tremendously in their intellectual manageability. A number of rules have been discovered, violation of which will either seriously impair or totally destroy the intellectual manageability of the program. These rules are of two kinds. Those of the first kind are easily imposed mechanically, viz. by a suitably chosen programming language. Examples are the exclusion of goto-statements and of procedures with more than one output parameter. For those of the second kind I at least —but that may be due to lack of competence on my side— see no way of imposing them mechanically, as it seems to need some sort of automatic theorem prover for which I have no existence proof. Therefore, for the time being and perhaps forever, the rules of the second kind present themselves as elements of discipline required from the programmer. Some of the rules I have in mind are so clear that they can be taught and that there never needs to be an argument as to whether a given program violates them or not. Examples are the requirements that no loop should be written down without providing a proof for termination nor without stating the relation whose invariance will not be destroyed by the execution of the repeatable statement.</p>
						<p>I now suggest that we confine ourselves to the design and implementation of intellectually manageable programs. If someone fears that this restriction is so severe that we cannot live with it, I can reassure him: the class of intellectually manageable programs is still sufficiently rich to contain many very realistic programs for any problem capable of algorithmic solution. We must not forget that it is <em>not</em> our business to make programs, it is our business to design classes of computations that will display a desired behaviour. The suggestion of confining ourselves to intellectually manageable programs is the basis for the first two of my announced six arguments.</p>
						<p>Argument one is that, as the programmer only needs to consider intellectually manageable programs, the alternatives he is choosing between are much, much easier to cope with.</p>
						<p>Argument two is that, as soon as we have decided to restrict ourselves to the subset of the intellectually manageable programs, we have achieved, once and for all, a drastic reduction of the solution space to be considered. And this argument is distinct from argument one.</p>
						<p>Argument three is based on the constructive approach to the problem of program correctness. Today a usual technique is to make a program and then to test it. But: program testing can be a very effective way to show the presence of bugs, but is hopelessly inadequate for showing their absence. The only effective way to raise the confidence level of a program significantly is to give a convincing proof of its correctness. But one should not first make the program and then prove its correctness, because then the requirement of providing the proof would only increase the poor programmer’s burden. On the contrary: the programmer should let correctness proof and program grow hand in hand. Argument three is essentially based on the following observation. If one first asks oneself what the structure of a convincing proof would be and, having found this, then constructs a program satisfying this proof’s requirements, then these correctness concerns turn out to be a very effective heuristic guidance. By definition this approach is only applicable when we restrict ourselves to intellectually manageable programs, but it provides us with effective means for finding a satisfactory one among these.</p>
						<p>Argument four has to do with the way in which the amount of intellectual effort needed to design a program depends on the program length. It has been suggested that there is some kind of law of nature telling us that the amount of intellectual effort needed grows with the square of program length. But, thank goodness, no one has been able to prove this law. And this is because it need not be true. We all know that the only mental tool by means of which a very finite piece of reasoning can cover a myriad cases is called “abstraction”; as a result the effective exploitation of his powers of abstraction must be regarded as one of the most vital activities of a competent programmer. In this connection it might be worth-while to point out that the purpose of abstracting is <em>not</em> to be vague, but to create a new semantic level in which one can be absolutely precise. Of course I have tried to find a fundamental cause that would prevent our abstraction mechanisms from being sufficiently effective. But no matter how hard I tried, I did not find such a cause. As a result I tend to the assumption —up till now not disproved by experience— that by suitable application of our powers of abstraction, the intellectual effort needed to conceive or to understand a program need not grow more than proportional to program length. But a by-product of these investigations may be of much greater practical significance, and is, in fact, the basis of my fourth argument. The by-product was the identification of a number of patterns of abstraction that play a vital role in the whole process of composing programs. Enough is now known about these patterns of abstraction that you could devote a lecture to about each of them. What the familiarity and conscious knowledge of these patterns of abstraction imply dawned upon me when I realized that, had they been common knowledge fifteen years ago, the step from BNF to syntax-directed compilers, for instance, could have taken a few minutes instead of a few years. Therefore I present our recent knowledge of vital abstraction patterns as the fourth argument.</p>
						<p>Now for the fifth argument. It has to do with the influence of the tool we are trying to use upon our own thinking habits. I observe a cultural tradition, which in all probability has its roots in the Renaissance, to ignore this influence, to regard the human mind as the supreme and autonomous master of its artefacts. But if I start to analyse the thinking habits of myself and of my fellow human beings, I come, whether I like it or not, to a completely different conclusion, viz. that the tools we are trying to use and the language or notation we are using to express or record our thoughts, are the major factors determining what we can think or express at all! The analysis of the influence that programming languages have on the thinking habits of its users, and the recognition that, by now, brainpower is by far our scarcest resource, they together give us a new collection of yardsticks for comparing the relative merits of various programming languages. The competent programmer is fully aware of the strictly limited size of his own skull; therefore he approaches the programming task in full humility, and among other things he avoids clever tricks like the plague. In the case of a well-known conversational programming language I have been told from various sides that as soon as a programming community is equipped with a terminal for it, a specific phenomenon occurs that even has a well-established name: it is called “the one-liners”. It takes one of two different forms: one programmer places a one-line program on the desk of another and either he proudly tells what it does and adds the question “Can you code this in less symbols?” —as if this were of any conceptual relevance!— or he just asks “Guess what it does!”. From this observation we must conclude that this language as a tool is an open invitation for clever tricks; and while exactly this may be the explanation for some of its appeal, viz. to those who like to show how clever they are, I am sorry, but I must regard this as one of the most damning things that can be said about a programming language. Another lesson we should have learned from the recent past is that the development of “richer” or “more powerful” programming languages was a mistake in the sense that these baroque monstrosities, these conglomerations of idiosyncrasies, are really unmanageable, both mechanically and mentally. I see a great future for very systematic and very modest programming languages. When I say “modest”, I mean that, for instance, not only ALGOL&nbsp;60’s “for clause”, but even FORTRAN’s “DO loop” may find themselves thrown out as being too baroque. I have run a little programming experiment with really experienced volunteers, but something quite unintended and quite unexpected turned up. None of my volunteers found the obvious and most elegant solution. Upon closer analysis this turned out to have a common source: their notion of repetition was so tightly connected to the idea of an associated controlled variable to be stepped up, that they were mentally blocked from seeing the obvious. Their solutions were less efficient, needlessly hard to understand, and it took them a very long time to find them. It was a revealing, but also shocking experience for me. Finally, in one respect one hopes that tomorrow’s programming languages will differ greatly from what we are used to now: to a much greater extent than hitherto they should invite us to reflect in the structure of what we write down all abstractions needed to cope conceptually with the complexity of what we are designing. So much for the greater adequacy of our future tools, which was the basis of the fifth argument.</p>
						<p>As an aside I would like to insert a warning to those who identify the difficulty of the programming task with the struggle against the inadequacies of our current tools, because they might conclude that, once our tools will be much more adequate, programming will no longer be a problem. Programming will remain very difficult, because once we have freed ourselves from the circumstantial cumbersomeness, we will find ourselves free to tackle the problems that are now well beyond our programming capacity.</p>
						<p>You can quarrel with my sixth argument, for it is not so easy to collect experimental evidence for its support, a fact that will not prevent me from believing in its validity. Up till now I have not mentioned the word “hierarchy”, but I think that it is fair to say that this is a key concept for all systems embodying a nicely factored solution. I could even go one step further and make an article of faith out of it, viz. that the only problems we can really solve in a satisfactory manner are those that finally admit a nicely factored solution. At first sight this view of human limitations may strike you as a rather depressing view of our predicament, but I don’t feel it that way, on the contrary! The best way to learn to live with our limitations is to know them. By the time that we are sufficiently modest to try factored solutions only, because the other efforts escape our intellectual grip, we shall do our utmost best to avoid all those interfaces impairing our ability to factor the system in a helpful way. And I cannot but expect that this will repeatedly lead to the discovery that an initially untractable problem can be factored after all. Anyone who has seen how the majority of the troubles of the compiling phase called “code generation” can be tracked down to funny properties of the order code, will know a simple example of the kind of things I have in mind. The wider applicability of nicely factored solutions is my sixth and last argument for the technical feasibility of the revolution that might take place in the current decade.</p>
						<p>In principle I leave it to you to decide for yourself how much weight you are going to give to my considerations, knowing only too well that I can force no one else to share my beliefs. As each serious revolution, it will provoke violent opposition and one can ask oneself where to expect the conservative forces trying to counteract such a development. I don’t expect them primarily in big business, not even in the computer business; I expect them rather in the educational institutions that provide today’s training and in those conservative groups of computer users that think their old programs so important that they don’t think it worth-while to rewrite and improve them. In this connection it is sad to observe that on many a university campus the choice of the central computing facility has too often been determined by the demands of a few established but expensive applications with a disregard of the question how many thousands of “small users” that are willing to write their own programs were going to suffer from this choice. Too often, for instance, high-energy physics seems to have blackmailed the scientific community with the price of its remaining experimental equipment. The easiest answer, of course, is a flat denial of the technical feasibility, but I am afraid that you need pretty strong arguments for that. No reassurance, alas, can be obtained from the remark that the intellectual ceiling of today’s average programmer will prevent the revolution from taking place: with others programming so much more effectively, he is liable to be edged out of the picture anyway.</p>
						<p>There may also be political impediments. Even if we know how to educate tomorrow’s professional programmer, it is not certain that the society we are living in will allow us to do so. The first effect of teaching a methodology —rather than disseminating knowledge— is that of enhancing the capacities of the already capable, thus magnifying the difference in intelligence. In a society in which the educational system is used as an instrument for the establishment of a homogenized culture, in which the cream is prevented from rising to the top, the education of competent programmers could be politically impalatable.</p>
						<p>Let me conclude. Automatic computers have now been with us for a quarter of a century. They have had a great impact on our society in their capacity of tools, but in that capacity their influence will be but a ripple on the surface of our culture, compared with the much more profound influence they will have in their capacity of intellectual challenge without precedent in the cultural history of mankind. Hierarchical systems seem to have the property that something considered as an undivided entity on one level, is considered as a composite object on the next lower level of greater detail; as a result the natural grain of space or time that is applicable at each level decreases by an order of magnitude when we shift our attention from one level to the next lower one. We understand walls in terms of bricks, bricks in terms of crystals, crystals in terms of molecules etc. As a result the number of levels that can be distinguished meaningfully in a hierarchical system is kind of proportional to the logarithm of the ratio between the largest and the smallest grain, and therefore, unless this ratio is very large, we cannot expect many levels. In computer programming our basic building block has an associated time grain of less than a microsecond, but our program may take hours of computation time. I do not know of any other technology covering a ratio of 10<sup>10</sup> or more: the computer, by virtue of its fantastic speed, seems to be the first to provide us with an environment where highly hierarchical artefacts are both possible and necessary. This challenge, viz. the confrontation with the programming task, is so unique that this novel experience can teach us a lot about ourselves. It should deepen our understanding of the processes of design and creation, it should give us better control over the task of organizing our thoughts. If it did not do so, to my taste we should not deserve the computer at all!</p>
						<p>It has already taught us a few lessons, and the one I have chosen to stress in this talk is the following. We shall do a much better programming job, provided that we approach the task with a full appreciation of its tremendous difficulty, provided that we stick to modest and elegant programming languages, provided that we respect the intrinsic limitations of the human mind and approach the task as Very Humble Programmers.</p>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Selfish reasons for building accessible UIs (198 pts)]]></title>
            <link>https://nolanlawson.com/2025/06/16/selfish-reasons-for-building-accessible-uis/</link>
            <guid>44294853</guid>
            <pubDate>Tue, 17 Jun 2025 01:16:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nolanlawson.com/2025/06/16/selfish-reasons-for-building-accessible-uis/">https://nolanlawson.com/2025/06/16/selfish-reasons-for-building-accessible-uis/</a>, See on <a href="https://news.ycombinator.com/item?id=44294853">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p>All web developers know, at some level, that accessibility is important. But when push comes to shove, it can be hard to prioritize it above a bazillion other concerns when you’re trying to center a <code>&lt;div&gt;</code> and you’re on a tight deadline.</p>
<p>A lot of accessibility advocates lead with the moral argument: for example, that disabled people should have just as much access to the internet as any other person, and that it’s a blight on our whole industry that we continually fail to make it happen.</p>
<p>I personally find these arguments persuasive. But experience has also taught me that “eat your vegetables” is one of the least effective arguments in the world. Scolding people might get them to agree with you in public, or even in principle, but it’s unlikely to change their behavior once no one’s watching.</p>
<p>So in this post, I would like to list some of my personal, completely selfish reasons for building accessible UIs. No finger-wagging here: just good old hardheaded self-interest!</p>
<h2>Debuggability</h2>
<p>When I’m trying to debug a web app, it’s hard to orient myself in the DevTools if the entire UI is “div soup”:</p>
<pre title="">&lt;div class="css-1x2y3z4"&gt;
  &lt;div class="css-c6d7e8f"&gt;
    &lt;div class="css-a5b6c7d"&gt;
      &lt;div class="css-e8f9g0h"&gt;&lt;/div&gt;
      &lt;div class="css-i1j2k3l"&gt;Library&lt;/div&gt;
      &lt;div class="css-i1j2k3l"&gt;Version&lt;/div&gt;
      &lt;div class="css-i1j2k3l"&gt;Size&lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="css-c6d7e8f"&gt;
    &lt;div class="css-m4n5o6p"&gt;
      &lt;div class="css-q7r8s9t"&gt;UI&lt;/div&gt;
      &lt;div class="css-u0v1w2x"&gt;React&lt;/div&gt;
      &lt;div class="css-u0v1w2x"&gt;19.1.0&lt;/div&gt;
      &lt;div class="css-u0v1w2x"&gt;167kB&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="css-m4n5o6p"&gt;
      &lt;div class="css-q7r8s9t"&gt;Style&lt;/div&gt;
      &lt;div class="css-u0v1w2x"&gt;Tailwind&lt;/div&gt;
      &lt;div class="css-u0v1w2x"&gt;4.0.0&lt;/div&gt;
      &lt;div class="css-u0v1w2x"&gt;358kB&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="css-m4n5o6p"&gt;
      &lt;div class="css-q7r8s9t"&gt;Build&lt;/div&gt;
      &lt;div class="css-u0v1w2x"&gt;Vite&lt;/div&gt;
      &lt;div class="css-u0v1w2x"&gt;6.3.5&lt;/div&gt;
      &lt;div class="css-u0v1w2x"&gt;2.65MB&lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
</pre>
<p>This is actually a table, but you wouldn’t know it from looking at the HTML:</p>
<p><img data-attachment-id="14927" data-permalink="https://nolanlawson.com/2025/06/16/selfish-reasons-for-building-accessible-uis/screenshot-from-2025-06-15-10-50-44/" data-orig-file="https://nolanlawson.com/wp-content/uploads/2025/06/screenshot-from-2025-06-15-10-50-44.png" data-orig-size="585,275" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot from 2025-06-15 10-50-44" data-image-description="" data-image-caption="" data-medium-file="https://nolanlawson.com/wp-content/uploads/2025/06/screenshot-from-2025-06-15-10-50-44.png?w=300" data-large-file="https://nolanlawson.com/wp-content/uploads/2025/06/screenshot-from-2025-06-15-10-50-44.png?w=570" src="https://nolanlawson.com/wp-content/uploads/2025/06/screenshot-from-2025-06-15-10-50-44.png?w=570" alt="Screenshot of an HTML table with column headers library, version, and size, row headers UI, style, and build, and values React/Tailwind/Vite with their version numbers and build size in the cells." width="570" height="268"></p>
<p>If I’m trying to debug this in the DevTools, I’m completely lost. Where are the rows? Where are the columns?</p>
<pre title="">&lt;table class="css-1x2y3z4"&gt;
  &lt;thead class="css-a5b6c7d"&gt;
    &lt;tr class="css-y3z4a5b"&gt;
      &lt;th scope="col" class="css-e8f9g0h"&gt;&lt;/th&gt;
      &lt;th scope="col" class="css-i1j2k3l"&gt;Library&lt;/th&gt;
      &lt;th scope="col" class="css-i1j2k3l"&gt;Version&lt;/th&gt;
      &lt;th scope="col" class="css-i1j2k3l"&gt;Size&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class="css-a5b6c7d"&gt;
    &lt;tr class="css-y3z4a5b"&gt;
      &lt;th scope="row" class="css-q7r8s9t"&gt;UI&lt;/th&gt;
      &lt;td class="css-u0v1w2x"&gt;React&lt;/td&gt;
      &lt;td class="css-u0v1w2x"&gt;19.1.0&lt;/td&gt;
      &lt;td class="css-u0v1w2x"&gt;167kB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr class="css-y3z4a5b"&gt;
      &lt;th scope="row" class="css-q7r8s9t"&gt;Style&lt;/th&gt;
      &lt;td class="css-u0v1w2x"&gt;Tailwind&lt;/td&gt;
      &lt;td class="css-u0v1w2x"&gt;4.0.0&lt;/td&gt;
      &lt;td class="css-u0v1w2x"&gt;358kB&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr class="css-y3z4a5b"&gt;
      &lt;th scope="row" class="css-q7r8s9t"&gt;Build&lt;/th&gt;
      &lt;td class="css-u0v1w2x"&gt;Vite&lt;/td&gt;
      &lt;td class="css-u0v1w2x"&gt;6.3.5&lt;/td&gt;
      &lt;td class="css-u0v1w2x"&gt;2.65MB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
</pre>
<p>Ah, that’s much better! Now I can easily zero in on a table cell, or a column header, because they’re all <em>named</em>. I’m not wading through a sea of <code>&lt;div&gt;</code>s anymore.</p>
<p>Even just adding ARIA <code>role</code>s to the <code>&lt;div&gt;</code>s would be an improvement here:</p>
<pre title="">&lt;div class="css-1x2y3z4" role="table"&gt;
  &lt;div class="css-a5b6c7d" role="rowgroup"&gt;
    &lt;div class="css-m4n5o6p" role="row"&gt;
      &lt;div class="css-e8f9g0h" role="columnheader"&gt;&lt;/div&gt;
      &lt;div class="css-i1j2k3l" role="columnheader"&gt;Library&lt;/div&gt;
      &lt;div class="css-i1j2k3l" role="columnheader"&gt;Version&lt;/div&gt;
      &lt;div class="css-i1j2k3l" role="columnheader"&gt;Size&lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="css-c6d7e8f" role="rowgroup"&gt;
    &lt;div class="css-m4n5o6p" role="row"&gt;
      &lt;div class="css-q7r8s9t" role="rowheader"&gt;UI&lt;/div&gt;
      &lt;div class="css-u0v1w2x" role="cell"&gt;React&lt;/div&gt;
      &lt;div class="css-u0v1w2x" role="cell"&gt;19.1.0&lt;/div&gt;
      &lt;div class="css-u0v1w2x" role="cell"&gt;167kB&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="css-m4n5o6p" role="row"&gt;
      &lt;div class="css-q7r8s9t" role="rowheader"&gt;Style&lt;/div&gt;
      &lt;div class="css-u0v1w2x" role="cell"&gt;Tailwind&lt;/div&gt;
      &lt;div class="css-u0v1w2x" role="cell"&gt;4.0.0&lt;/div&gt;
      &lt;div class="css-u0v1w2x" role="cell"&gt;358kB&lt;/div&gt;
    &lt;/div&gt;
    &lt;div class="css-m4n5o6p" role="row"&gt;
      &lt;div class="css-q7r8s9t" role="rowheader"&gt;Build&lt;/div&gt;
      &lt;div class="css-u0v1w2x" role="cell"&gt;Vite&lt;/div&gt;
      &lt;div class="css-u0v1w2x" role="cell"&gt;6.3.5&lt;/div&gt;
      &lt;div class="css-u0v1w2x" role="cell"&gt;2.65MB&lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
</pre>
<p>Especially if you’re using a CSS-in-JS framework (which I’ve simulated with <a href="https://daverupert.com/2021/08/css-modules-in-css-modules/#:~:text=Can%20CSS%20Modules%20be%20more%20like%20CSS%20Modules%3F">robo-classes</a> above), the HTML can get quite messy. Building accessibly makes it a lot easier to understand at a distance what each element is supposed to do.</p>
<h2>Naming things</h2>
<p>As all programmers know, naming things is hard. UIs are no exception: is this an “autocomplete”? Or a “dropdown”? Or a “picker”?</p>
<p><img data-attachment-id="14944" data-permalink="https://nolanlawson.com/2025/06/16/selfish-reasons-for-building-accessible-uis/screenshot-from-2025-06-15-11-10-20/" data-orig-file="https://nolanlawson.com/wp-content/uploads/2025/06/screenshot-from-2025-06-15-11-10-20.png" data-orig-size="273,315" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot from 2025-06-15 11-10-20" data-image-description="" data-image-caption="" data-medium-file="https://nolanlawson.com/wp-content/uploads/2025/06/screenshot-from-2025-06-15-11-10-20.png?w=260" data-large-file="https://nolanlawson.com/wp-content/uploads/2025/06/screenshot-from-2025-06-15-11-10-20.png?w=273" src="https://nolanlawson.com/wp-content/uploads/2025/06/screenshot-from-2025-06-15-11-10-20.png" alt="Screenshot of a combobox with &quot;Ne&quot; typed into it and states below in a list like Nebraska, Nevada, and New Hampshire." width="273" height="315"></p>
<p>If you read the <a href="https://www.w3.org/WAI/ARIA/apg/patterns/combobox/examples/combobox-autocomplete-both/">WAI ARIA guidelines</a>, though, then it’s clear what it is: a “combobox”!</p>
<p>No need to grope for the right name: if you add the proper <code>role</code>s, then everything is already named for you:</p>
<ul>
<li><code>combobox</code></li>
<li><code>listbox</code></li>
<li><code>option</code>s</li>
</ul>
<p>As a bonus, you can use <code>aria-*</code> attributes or <code>role</code>s as a CSS selector. I often see awkward code like this:</p>
<pre title="">&lt;div
  className={isActive ? 'active' : ''}
  aria-selected={isActive}
  role='option'
&lt;/div&gt;
</pre>
<p>The <code>active</code> class is clearly redundant here. If you want to style based on the <code>.active</code> selector, you could just as easily style with <code>[aria-selected="true"]</code> instead.</p>
<p>Also, why call it <code>isActive</code> when the ARIA attribute is <code>aria-selected</code>? Just call it “selected” everywhere:</p>
<pre title="">&lt;div
  aria-selected={isSelected}
  role='option'
&lt;/div&gt;
</pre>
<p>Much cleaner!</p>
<p>I also find that thinking in terms of roles and ARIA attributes sharpens my thinking, and gives structure to the interface I’m trying to create. Suddenly, I have a <em>language</em> for what I’m building, which can lead to more “obvious” variable names, <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_cascading_variables/Using_CSS_custom_properties">CSS custom properties</a>, <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/grid-area">grid area names</a>, etc.</p>
<h2>Testability</h2>
<p><a href="https://nolanlawson.com/2019/11/05/what-ive-learned-about-accessibility-in-spas/#:~:text=Easier%20integration%20testing">I’ve written about this before</a>, but building accessibly also helps with writing tests. Rather than trying to select an element based on arbitrary classes or attributes, you can write more elegant code like this (e.g. with Playwright):</p>
<pre title="">await page.getByLabel('Name').fill('Nolan')

await page.getByRole('button', { name: 'OK' }).click()
</pre>
<p>Imagine, though, if your entire UI is full of <code>&lt;div&gt;</code>s and robo-classes. How would you find the right inputs and buttons? You could select based on the robo-classes, or by searching for text inside or nearby the elements, but this makes your tests brittle.</p>
<p>As <a href="https://kentcdodds.com/blog/making-your-ui-tests-resilient-to-change">Kent C. Dodds has argued</a>, writing UI tests based on <em>semantics</em> makes your tests more resilient to change. That’s because a UI’s semantic structure (i.e. the accessibility tree) tends to change less frequently than its classes, attributes, or even the composition of its HTML elements. (How many times have you added a wrapper <code>&lt;div&gt;</code> only to break your UI tests?)</p>
<h2>Power users</h2>
<p>When I’m on a desktop, I tend to be a keyboard power user. I like pressing <kbd>Esc</kbd> to close dialogs, <kbd>Enter</kbd> to submit a form, or even <kbd>/</kbd> in Firefox to quickly jump to links on the page. I do use a mouse, but I just prefer the keyboard since it’s faster.</p>
<p>So I find it jarring when a website breaks keyboard accessibility – <kbd>Esc</kbd> doesn’t dismiss a dialog, <kbd>Enter</kbd> doesn’t submit a form, <kbd>↑</kbd>/<kbd>↓</kbd> don’t change radio buttons. It disrupts my flow when I unexpectedly have to reach for my mouse. (Plus it’s a <a href="https://www.snopes.com/fact-check/brown-out/">Van Halen brown M&amp;M</a> that signals to me that the website probably messed something else up, too!)</p>
<p>If you’re building a productivity tool with its own set of keyboard shortcuts (think Slack or GMail), then it’s even more important to get this right. You can’t add a lot of sophisticated keyboard controls if the basic <kbd>Tab</kbd> and focus logic doesn’t work correctly.</p>
<p>A lot of programmers are themselves power users, so I find this argument pretty persuasive. Build a UI that you yourself would like to use!</p>
<h2>Conclusion</h2>
<p>The reason that I, personally, care about accessibility is probably different from most people’s. I have a family member who is blind, and I’ve known many blind or low-vision people in my career. I’ve heard firsthand how frustrating it can be to use interfaces that aren’t built accessibly.</p>
<p>Honestly, if I were disabled, I would probably think to myself, “computer programmers must not care about me.” And judging from the <a href="https://webaim.org/projects/million/">miserable WebAIM results</a>, I’d clearly be right:</p>
<blockquote><p>
  Across the one million home pages, 50,960,288 distinct accessibility errors were detected—an average of 51 errors per page.
</p></blockquote>
<p>As a web developer who has dabbled in accessibility, though, I find this situation tragic. It’s not <em>really</em> that hard to build accessible interfaces. And I’m not talking about “ideal” or “optimized” – the bar is pretty low, so I’m just talking about something that <em>works at all</em> for people with a disability.</p>
<p>Maybe in the future, accessible interfaces won’t require so much manual intervention from developers. Maybe AI tooling (on either the production or consumption side) will make UIs that are usable out-of-the-box for people with disabilities. I’m actually sympathetic to the Jakob Nielsen argument that <a href="https://jakobnielsenphd.substack.com/p/accessibility-generative-ui">“accessibility has failed”</a> – it’s hard to look at the WebAIM results and come to any other conclusion. Maybe the “eat your vegetables” era of accessibility has failed, and it’s time to try new tactics.</p>
<p>That’s why I wrote this post, though. You can build accessibly without having a bleeding heart. And for the time being, unless generative AI swoops in like a <em>deus ex machina</em> to save us, it’s our responsibility as interface designers to do so.</p>
<p>At the same time we’re helping others, though, we can also help ourselves. Like a good hot sauce on your Brussels sprouts, eating your vegetables doesn’t always have to be a chore.</p>
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Generative AI coding tools and agents do not work for me (366 pts)]]></title>
            <link>https://blog.miguelgrinberg.com/post/why-generative-ai-coding-tools-and-agents-do-not-work-for-me</link>
            <guid>44294633</guid>
            <pubDate>Tue, 17 Jun 2025 00:33:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.miguelgrinberg.com/post/why-generative-ai-coding-tools-and-agents-do-not-work-for-me">https://blog.miguelgrinberg.com/post/why-generative-ai-coding-tools-and-agents-do-not-work-for-me</a>, See on <a href="https://news.ycombinator.com/item?id=44294633">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>People keep asking me If I use Generative AI tools for coding and what I think of them, so this is my effort to put my thoughts in writing, so that I can send people here instead of having to repeat myself every time I get the question.</p>
<p>From the title you already know that this isn't a pro-AI blog post. But it isn't an anti-AI post either, at least I don't think it is. There are already plenty of articles by AI promoters and AI critics, so I don't feel there is a need for me to write one more of those. While I'm definitely not neutral on the subject, in this article I'm just going to share my personal experience with these tools, from a strictly technical point of view.</p>
<h2>AI is not faster</h2>
<p>Really the main and most important reason why GenAI tools do not work for me is that <strong>they do not make me any faster</strong>. It's really that simple.</p>
<p>It would be easy to use GenAI coding tools to have code written for me. A coding agent would be the most convenient, as it would edit my files while I do something else. This all sounds great, in principle.</p>
<p>The problem is that I'm going to be responsible for that code, so I cannot blindly add it to my project and hope for the best. I could only incorporate AI generated code into a project of mine after I thoroughly review it and make sure I understand it well. I have to feel confident that I can modify or extend this piece of code in the future, or else I cannot use it.</p>
<p>Unfortunately reviewing code is actually harder than most people think. It takes me at least the same amount of time to review code not written by me than it would take me to write the code myself, if not more. There is actually a well known saying in our industry that goes something like "it’s harder to read code than to write it." I believe it was Joel Spolsky (creator of Stack Overflow and Trello) who formalized it first in his <a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/">Things You Should Never Do, Part I</a> article.</p>
<p>You could argue that code that was written by AI can be considered a black box. I guess you can convince yourself that as long as the code works as intended it is safe to use without the need to review it, which would translate into some productivity increase. I think this is highly irresponsible, because the AI is not going to assume any liability if this code ever malfunctions. I'm always the responsible party for the code I produce, with or without AI. Taking on such a large risk is nuts, in my opinion.</p>
<p>This is even more important for some of the work that I do where there are contracts signed, with associated legal obligations and money payments. If I'm hired as a professional, I really have no other choice than to be one. AI tools cannot help me make more money or do my work in less time. The only way I could achieve those things is by degrading the quality of the work and introducing risk, and I'm not willing to do that.</p>
<h2>AI is not a multiplier</h2>
<p>I've heard people say that GenAI coding tools are a multiplier or enabler for them. Basically those who make this claim say that they are able to work faster and tackle more difficult problems when using GenAI. Unfortunately these claims are just based on the perception of the subjects themselves, so there is no hard data to back them up. I guess it is possible that some people can be more efficient reviewing code than I am, but I honestly doubt it. What I think happens is that these people save time because they only spot review the AI generated code, or skip the review phase altogether, which as I said above would be a deal breaker for me.</p>
<p>Another common argument I've heard is that Generative AI is helpful when you need to write code in a language or technology you are not familiar with. To me this also makes little sense. The part that I enjoy the most about working as a software engineer is learning new things, so not knowing something has never been a barrier for me. The more you practice learning the easier and faster it gets! In recent times I had to learn Rust, Go, TypeScript, WASM, Java and C# for various projects, and I wouldn't delegate this learning effort to an AI, even if it saved me time. Which it wouldn't, because of all the reasons above about being responsible for the code that I produce. Sorry if I'm a bit repetitive on this.</p>
<h2>AI code is different than human code</h2>
<p>I made all these points to a friend the other day and he asked me why then I gladly accept open source contributions to my projects when they are made by people. Aren't those also code that is not written by myself? Why are those okay but AI generated code is not?</p>
<p>The truth that may be shocking to some is that open source contributions submitted by users do not really save me time either, because I also feel I have to do a rigorous review of them. But I enjoy working with users who have an interest in my projects and take time to report bugs, request new features or submit code changes. These interactions are a source of new ideas more than anything, so they directly help me do better work. This is what I love the most of working in open source!</p>
<p>My friend, who is still unconvinced, suggests I could launch a bunch of AI agents in parallel to create PRs for all my open bugs. It's a game changer, he says. Unfortunately that would cost me money and likely make me slower, for the reasons explained above. Even if we assume that AI coding tools are sophisticated enough (they are not) to fix issues in my projects with little or no supervision, I'm still the bottleneck because all that code has to be reviewed before it can be merged.</p>
<p>The unfortunate side of AI coding tools being widely available is that some users now also generate low effort pull requests with them. I have received some of these, and it's interesting that there is a sort of <a href="https://en.wikipedia.org/wiki/Uncanny_valley">uncanny valley</a> effect that triggers in me when I start reading AI generated code that hasn't been edited and refined by a real person. When I come across pull requests of this type I start asking questions to the submitters about the weird parts of their submissions, because I consider them responsible for the code they want me to merge. They rarely respond.</p>
<h2>AI is not the same as an intern</h2>
<p>Many AI advocates say that you should treat your AI coding tool as an intern that is eager to please. I think the people who say this never worked with interns!</p>
<p>In the beginning, delegating work to an intern causes a productivity decrease for you, for the same reasons I enumerated above. Interns need a lot of hand-holding, and all the code they produce needs to be carefully reviewed before it is accepted.</p>
<p>But interns <em>learn</em> and get better over time. The time that you spend reviewing code or providing feedback to an intern is not wasted, it is an investment in the future. The intern absorbs the knowledge you share and uses it for new tasks you assign to them later on. The need for close supervision goes down throughout the duration of the internship. In the end, interns are often hired by their companies as full time employees because they become successful independent contributors.</p>
<p>An AI tool can only resemble an intern with <a href="https://en.wikipedia.org/wiki/Anterograde_amnesia">anterograde amnesia</a>, which would be a bad kind of intern to have. For every new task this "AI intern" resets back to square one without having learned a thing!</p>
<h2>Conclusion</h2>
<p>I hope with this article I've made the technical issues I have with applying GenAI coding tools to my work clear.</p>
<p>In my experience, there is no such thing as a free lunch with AI coding. I believe people who claim that it makes them faster or more productive are making a conscious decision to relax their quality standards to achieve those gains. Either that or they just say this because they personally benefit from selling AI to you.</p></div><p>Thank you for visiting my blog! If you enjoyed this article, please consider supporting my work and keeping me caffeinated with a small one-time donation through <a href="https://www.buymeacoffee.com/miguelgrinberg">Buy me a coffee</a>. Thanks!</p></div>]]></description>
        </item>
    </channel>
</rss>