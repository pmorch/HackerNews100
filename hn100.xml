<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 11 Nov 2025 18:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[iPod Socks (166 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/IPod_Socks</link>
            <guid>45889602</guid>
            <pubDate>Tue, 11 Nov 2025 16:52:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/IPod_Socks">https://en.wikipedia.org/wiki/IPod_Socks</a>, See on <a href="https://news.ycombinator.com/item?id=45889602">Hacker News</a></p>
Couldn't get https://en.wikipedia.org/wiki/IPod_Socks: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox Expands Fingerprint Protections (107 pts)]]></title>
            <link>https://blog.mozilla.org/en/firefox/fingerprinting-protections/</link>
            <guid>45888891</guid>
            <pubDate>Tue, 11 Nov 2025 16:04:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.mozilla.org/en/firefox/fingerprinting-protections/">https://blog.mozilla.org/en/firefox/fingerprinting-protections/</a>, See on <a href="https://news.ycombinator.com/item?id=45888891">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
  <main id="main">

    
<article id="post-82478">
  

  <div>
    




<p>With Firefox 145, we’re rolling out major privacy upgrades that take on browser fingerprinting — a pervasive and hidden tracking technique that lets websites identify you even when cookies are blocked or you’re in private browsing. These protections build on Mozilla’s long-term goal of building a healthier, transparent and privacy-preserving web ecosystem.</p>



<p>Fingerprinting builds a secret digital ID of you by collecting subtle details of your setup — ranging from your time zone to your operating system settings — that together create a “fingerprint” identifiable across websites and across browser sessions. Having a unique fingerprint means fingerprinters can continuously identify you invisibly, allowing bad actors to track you without your knowledge or consent. Online fingerprinting is able to track you for months, even when you use any browser’s private browsing mode.</p>



<p>Protecting people’s privacy has always been core to Firefox. <a href="https://blog.mozilla.org/security/2020/01/07/firefox-72-fingerprinting/">Since 2020</a>, Firefox’s built-in <a href="https://support.mozilla.org/en-US/kb/enhanced-tracking-protection-firefox-desktop">Enhanced Tracking Protection</a> (ETP) has blocked known trackers and other invasive practices, while features like <a href="https://mzl.la/3db2drC">Total Cookie Protection</a> and now expanded fingerprinting defenses demonstrate a broader goal: prioritizing your online freedom through innovative privacy-by-design. Since 2021, Firefox has been incrementally enhancing anti-fingerprinting protections targeting the most common pieces of information collected for suspected fingerprinting uses.</p>



<p>Today, we are excited to announce the completion of the second phase of defenses against fingerprinters that linger across all your browsing but aren’t in the known tracker lists. With these fingerprinting protections, the amount of Firefox users trackable by fingerprinters is reduced by half.</p>



<h2>How we built stronger defenses</h2>



<p>Drawing from a global analysis of how real people’s browsers can be fingerprinted, Mozilla has developed new, unique and powerful defenses against real-world fingerprinting techniques. Firefox is the first browser with this level of insight into fingerprinting and the most effective deployed defenses to reduce it. Like <a href="https://blog.mozilla.org/en/mozilla/firefox-rolls-out-total-cookie-protection-by-default-to-all-users-worldwide/">Total Cookie Protection</a>, one of our most innovative privacy features, these new defenses are debuting in Private Browsing Mode and ETP Strict mode initially, while we work to enable them by default.</p>



<figure><img decoding="async" fetchpriority="high" width="1024" height="633" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-1024x633.png" alt="" title="Chart" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-1024x633.png 1024w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-300x186.png 300w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-768x475.png 768w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32-1000x618.png 1000w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/image-32.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>How Firefox protects you</h2>



<p>These fingerprinting protections work on multiple layers, building on Firefox’s already robust privacy features. For example, Firefox has long blocked known tracking and fingerprinting scripts as part of its <a href="https://support.mozilla.org/en-US/kb/enhanced-tracking-protection-firefox-desktop">Enhanced Tracking Protection</a>.&nbsp;</p>



<p>Beyond blocking trackers, Firefox also limits the information it makes available to websites — a privacy-by-design approach — that preemptively shrinks your fingerprint. Browsers provide a way for websites to ask for information that enables legitimate website features, e.g. your graphics hardware information, which allows sites to optimize games for your computer.&nbsp; But trackers can also ask for that information, for no other reason than to help build a fingerprint of your browser and track you across the web.&nbsp;&nbsp;</p>



<p>Since 2021, Firefox has been incrementally advancing fingerprinting protections, covering the most pervasive fingerprinting techniques. These include things like how your graphics card draws images, which fonts your computer has, and even tiny differences in how it performs math. The first phase plugged the biggest and most-common leaks of fingerprinting information.</p>



<p>Recent Firefox releases have tackled the next-largest leaks of user information used by online fingerprinters. This ranges from strengthening the font protections to preventing websites from getting to know your hardware details like the number of cores your processor has, the number of simultaneous fingers your touchscreen supports, and the dimensions of your dock or taskbar. The full list of detailed protections is <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_suspected-fingerprinters">available in our documentation</a>.</p>



<p>Our research shows these improvements <strong>cut the percentage of users seen as unique by almost half</strong>.</p>



<figure><img decoding="async" width="1024" height="1024" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections.png" alt="" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections.png 1024w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-300x300.png 300w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-150x150.png 150w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-768x768.png 768w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-1000x1000.png 1000w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2025/11/Fingerprinting-protections-800x800.png 800w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Firefox’s new protections are a balance of disrupting fingerprinters while maintaining web usability. More aggressive fingerprinting blocking might sound better, but is guaranteed to break legitimate website features. For instance, calendar, scheduling, and conferencing tools legitimately need your real time zone. Firefox’s approach is to target the most leaky fingerprinting vectors (the tricks and scripts used by trackers) while preserving functionality many sites need to work normally. The end result is a set of layered defenses that significantly reduce tracking without downgrading your browsing experience. More details are available about both the <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_suspected-fingerprinters">specific behaviors</a> and how to <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_how-can-i-tell-if-this-protection-broke-something">recognize a problem</a> on a site and <a href="https://support.mozilla.org/en-US/kb/firefox-protection-against-fingerprinting#w_how-do-i-disable-this-protection-for-a-website">disable protections</a> for that site alone, so you always stay in control. The goal: strong privacy protections that don’t get in your way.</p>



<h2>What’s next for your privacy</h2>



<p>If you open a Private Browsing window or use ETP Strict mode, Firefox is already working behind the scenes to make you harder to track. The latest phase of Firefox’s fingerprinting protections marks an important milestone in our mission to deliver: smart privacy protections that work automatically — no further extensions or configurations needed.&nbsp;As we head into the future, Firefox remains committed to fighting for your privacy, so you get to enjoy the web on your terms. <a href="https://firefox.com/">Upgrade to the latest Firefox and take back control of your privacy</a>.</p>



<a href="https://www.mozilla.org/firefox/new/?utm_source=blog.mozilla.org&amp;utm_medium=referral&amp;utm_campaign=blog-nav">
  <p><img width="800" height="800" src="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-800x800.png" alt="" decoding="async" srcset="https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-800x800.png 800w, https://blog.mozilla.org/wp-content/blogs.dir/278/files/2021/10/Visual-Guidelines-150x150.png 150w" sizes="(max-width: 800px) 100vw, 800px">  </p>
  <div>
     <h3>Take control of your internet</h3>      <p><span>Download Firefox</span>   </p></div>
</a>
  </div>

</article><!-- #post-82478 -->

  </main><!-- #main -->
  

<div id="related-articles">
    <h2>Related Articles</h2>
    
  </div>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Canada loses its measles-free status, with US on track to follow (158 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cy7e2lv4r8xo</link>
            <guid>45888697</guid>
            <pubDate>Tue, 11 Nov 2025 15:50:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cy7e2lv4r8xo">https://www.bbc.com/news/articles/cy7e2lv4r8xo</a>, See on <a href="https://news.ycombinator.com/item?id=45888697">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="byline-new" data-component="byline-block"><p><span data-testid="byline-new-contributors"><div data-testid="byline-new-contributors-contributor-0"><p><span>Nadine Yousif</span><span data-testid="byline-new-contributors-contributor-0-role-location">Senior Canada reporter</span></p></div></span></p></div><div data-component="text-block"><p>Canada has lost its measles elimination status, said the Pan American Health Organization (Paho) on Monday, after failing to curb an outbreak of the virus for 12 consecutive months.</p><p>Because Canada is no longer deemed measles-free, the Americas region as a whole has lost its elimination status, although individually the other countries are still considered to have stamped out the disease.</p><p>The US, however, risks losing its status as well if it does not stop an ongoing outbreak by January. Related cases have now been reported in Utah, Arizona and South Carolina.</p><p>Canada's outbreak began last October, with health officials attributing it to fewer people being vaccinated against measles.</p></div><div data-component="text-block"><p>At a news conference on Monday, Paho officials appealed to Canadian governments and the public to ramp up vaccinations, noting that 95% of the population needs to be immunised to stop the spread of measles.</p><p>"This loss represents a setback, but it is also reversible," said Dr Jarbas Barbosa, the health organisation's director.</p><ul><li><a target="_self" href="https://www.bbc.com/news/articles/c4g8d39gdr0o">How Canada became the centre of a measles outbreak in North America</a></li><li><a target="_self" href="https://www.bbc.com/news/articles/cwy747kdzdzo">More than 150 children quarantined as US measles cases hit 33-year high</a></li></ul><p>The Public Health Agency of Canada said in its own statement that it is collaborating with Paho and regional health authorities to improve vaccine rates and strengthen data sharing. </p><p>Prior to Monday, Canada had been declared measles-free for three decades. It can regain its elimination status if it can curb spread of the measles strain associated with the current outbreak for at least 12 months. </p><p>The country has reported more than 5,000 measles cases in 2025, with most of them in the provinces of Ontario and Alberta. That is three times the 1,681 cases reported in the US, despite Canada's much smaller population. </p><p>The bulk of the outbreak has been in "under-vaccinated communities", Canadian health officials have said. </p><p>Vaccination rates in Alberta, one of the provinces hit hard by the outbreak, are lower than the 95% threshold, according to provincial data. </p><p>One region, the South Zone, located south of the province's largest city Calgary, reported only 68% of children under the age of two were immunised against measles as of 2024.</p><p>The MMR vaccine is the most effective way to fight off the dangerous virus, which can lead to pneumonia, brain swelling and death. The jabs are 97% effective and also immunise against mumps and rubella.</p><p>Canadian immunologist Dawn Bowdish told the BBC that there are many reasons behind the low vaccination rates, including lack of access to general practitioners, the absence of a national vaccination registry that Canadians could use to check their immunisation status, and the spread of misinformation. </p><p>She also noted a lack of public health outreach to communities that have been hesitant or distrustful of vaccines.</p><p>"It highlights how many of our systems broke down to get us to this point," said Prof Bowdish of McMaster University in Hamilton, Ontario. </p><p>"I hope that it will be a wake-up call to policymakers, and that it will be enough of a national embarrassment that we remedy some of those systemic issues," she added</p><p>The Americas is the first and only region in the world to have been declared measles-free, starting in 2016. That status was then briefly lifted after outbreaks in Venezuela and Brazil. The two countries regained elimination status in 2024, in part through coordinated vaccine efforts where millions were immunised. </p><p>But measles has since spread again, now in North America. </p><p>Along with Canada and the United States, Mexico has also seen a surge in cases and now ranks among the top 10 countries with the largest outbreaks, according to the US Centers for Disease Control and Prevention.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI may not use lyrics without license, German court rules (186 pts)]]></title>
            <link>https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/</link>
            <guid>45886131</guid>
            <pubDate>Tue, 11 Nov 2025 11:20:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/">https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/</a>, See on <a href="https://news.ycombinator.com/item?id=45886131">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/german-court-sides-with-plaintiff-copyright-case-against-openai-2025-11-11/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[iPhone Pocket (273 pts)]]></title>
            <link>https://www.apple.com/newsroom/2025/11/introducing-iphone-pocket-a-beautiful-way-to-wear-and-carry-iphone/</link>
            <guid>45885813</guid>
            <pubDate>Tue, 11 Nov 2025 10:17:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2025/11/introducing-iphone-pocket-a-beautiful-way-to-wear-and-carry-iphone/">https://www.apple.com/newsroom/2025/11/introducing-iphone-pocket-a-beautiful-way-to-wear-and-carry-iphone/</a>, See on <a href="https://news.ycombinator.com/item?id=45885813">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    
    
	
	

</nav>





<main id="main" role="main"> 




<span id="opens-in-new-window">opens in new window</span>
<section>
<article data-analytics-activitymap-region-id="article">






    
    
    









    





    <div>
        
		
        

        <div>
                
                
                
                    <h2>
                        
    
        Introducing iPhone Pocket: a&nbsp;beautiful way to wear and carry iPhone
    

                    </h2>
                
            </div>

        <div>
                
                
                    Born out of a collaboration between ISSEY&nbsp;MIYAKE and Apple, iPhone&nbsp;Pocket features a singular 3D-knitted construction designed to fit any iPhone
                
            </div>

        
            
    
    
    
    
    

        

    </div>







    
    
    






  
    
    
    
    
      <figure aria-label="Media, Two users pose with iPhone Pocket in lemon and black.">
        <div>
             
              
              <div>
                iPhone Pocket, born out of a collaboration between ISSEY MIYAKE and Apple, will be available at select Apple Store locations beginning Friday, November 14.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-hero.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-hero_big" aria-label="Download media, Two users pose with iPhone Pocket in lemon and black."></a>
          </div>
      </figure>
    
  








    
    
    


     
     
    
    
        <div>
             
                 <div>ISSEY MIYAKE and Apple today unveiled <a href="https://www.apple.com/shop/product/HS8R2ZM/A" target="_blank">iPhone Pocket</a>. Inspired by the concept of “a piece of cloth,” its singular 3D-knitted construction is designed to fit any iPhone as well as all pocketable items. Beginning Friday, November 14, it will be available at select Apple Store locations and on <a href="https://www.apple.com/" target="_blank">apple.com</a> in France, Greater China, Italy, Japan, Singapore, South Korea, the UK, and the U.S.
</div>
                 
             
                 <div>iPhone Pocket features a ribbed open structure with the qualities of the original pleats by ISSEY MIYAKE. Born from the idea of creating an additional pocket, its understated design fully encloses iPhone, expanding to fit more of a user’s everyday items. When stretched, the open textile subtly reveals its contents and allows users to peek at their iPhone display. iPhone Pocket can be worn in a variety of ways — handheld, tied onto bags, or worn directly on the body. Featuring a playful color palette, the short strap design is available in eight colors, and the long strap design in three colors.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="iphone-pocket-color-options">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-500f573744cb93b53ae8377ed0858f3f" href="#gallery-500f573744cb93b53ae8377ed0858f3f" data-ac-gallery-trigger="gallery-500f573744cb93b53ae8377ed0858f3f"><span>All eight colors of iPhone Pocket short strap design.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-c4b99bd83aa685e677f8cc92bd31c905" href="#gallery-c4b99bd83aa685e677f8cc92bd31c905" data-ac-gallery-trigger="gallery-c4b99bd83aa685e677f8cc92bd31c905"><span>All three colors of iPhone Pocket long strap design.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-500f573744cb93b53ae8377ed0858f3f" aria-labelledby="gallery-dotnav-500f573744cb93b53ae8377ed0858f3f" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:short-strap-design">
                                
                                <div>
                                    <div>Featuring a playful color palette, the short strap design is available in eight colors: lemon, mandarin, purple, pink, peacock, sapphire, cinnamon, and black.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-short-strap-colors.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-short-strap-colors_big" aria-label="Download media, All eight colors of iPhone Pocket short strap design."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-c4b99bd83aa685e677f8cc92bd31c905" aria-labelledby="gallery-dotnav-c4b99bd83aa685e677f8cc92bd31c905" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:long-strap-design">
                                
                                <div>
                                    <div>The long strap design is available in three colors: sapphire, cinnamon, and black.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-long-strap-colors.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-long-strap-colors_big" aria-label="Download media, All three colors of iPhone Pocket long strap design."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <div>“The design of iPhone Pocket speaks to the bond between iPhone and its user, while keeping in mind that an Apple product is designed to be universal in aesthetic and versatile in use,” shared Yoshiyuki Miyamae, design director of MIYAKE DESIGN STUDIO. “iPhone Pocket explores the concept of ‘the joy of wearing iPhone in your own way.’ The simplicity of its design echoes what we practice at ISSEY MIYAKE — the idea of leaving things less defined to allow for possibilities and personal interpretation.”
</div>
                 
             
                 <div>“Apple and ISSEY MIYAKE share a design approach that celebrates craftsmanship, simplicity, and delight,” said Molly Anderson, Apple’s vice president of Industrial Design. “This clever extra pocket exemplifies those ideas and is a natural accompaniment to our products. The color palette of iPhone Pocket was intentionally designed to mix and match with all our iPhone models and colors — allowing users to create their own personalized combination. Its recognizable silhouette offers a beautiful new way to carry your iPhone, AirPods, and favorite everyday items.”
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="iphone-pocket-color-combos">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-0413a35321ffe4dbd41592bfeb2b2797" href="#gallery-0413a35321ffe4dbd41592bfeb2b2797" data-ac-gallery-trigger="gallery-0413a35321ffe4dbd41592bfeb2b2797"><span>iPhone Pocket in cinnamon paired with iPhone 17 Pro in cosmic orange.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-395d51cadfd7a3c84bd5bd1de138f580" href="#gallery-395d51cadfd7a3c84bd5bd1de138f580" data-ac-gallery-trigger="gallery-395d51cadfd7a3c84bd5bd1de138f580"><span>iPhone Pocket in sapphire paired with iPhone Air in sky blue.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-d57c53d12e0866bde9b77fabca8692fb" href="#gallery-d57c53d12e0866bde9b77fabca8692fb" data-ac-gallery-trigger="gallery-d57c53d12e0866bde9b77fabca8692fb"><span>iPhone Pocket in purple paired with iPhone 17 in lavender.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-0413a35321ffe4dbd41592bfeb2b2797" aria-labelledby="gallery-dotnav-0413a35321ffe4dbd41592bfeb2b2797" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:cinnamon-and-cosmic-orange-iphone-17-pro">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon-with-iPhone-17-Pro.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon-with-iPhone-17-Pro_big" aria-label="Download media, iPhone Pocket in cinnamon paired with iPhone 17 Pro in cosmic orange."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-395d51cadfd7a3c84bd5bd1de138f580" aria-labelledby="gallery-dotnav-395d51cadfd7a3c84bd5bd1de138f580" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:sapphire-and-sky-blue-iphone-air">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-sapphire-with-iPhone-Air.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-sapphire-with-iPhone-Air_big" aria-label="Download media, iPhone Pocket in sapphire paired with iPhone Air in sky blue."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-d57c53d12e0866bde9b77fabca8692fb" aria-labelledby="gallery-dotnav-d57c53d12e0866bde9b77fabca8692fb" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:purple-and-lavender-iphone-17">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-01.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-01_big" aria-label="Download media, iPhone Pocket in purple paired with iPhone 17 in lavender."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A Piece of Cloth</strong>
</h2>
                 
             
                 <div>Crafted in Japan, iPhone Pocket features a singular 3D-knitted construction that is the result of research and development carried out at ISSEY MIYAKE. The design drew inspiration from the concept of “a piece of cloth” and reinterpreted the everyday utility of the brand’s iconic pleated clothing. The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="singular-construction">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-8c54c3d4fde598029a7c6b36d27e85a3" href="#gallery-8c54c3d4fde598029a7c6b36d27e85a3" data-ac-gallery-trigger="gallery-8c54c3d4fde598029a7c6b36d27e85a3"><span>A user poses with iPhone Pocket in peacock.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-8ec946387230a363dbe25e38306bce4d" href="#gallery-8ec946387230a363dbe25e38306bce4d" data-ac-gallery-trigger="gallery-8ec946387230a363dbe25e38306bce4d"><span>A user poses with iPhone Pocket in cinnamon.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-1b5cfe3976c01fb7746de0602809af8b" href="#gallery-1b5cfe3976c01fb7746de0602809af8b" data-ac-gallery-trigger="gallery-1b5cfe3976c01fb7746de0602809af8b"><span>iPhone Pocket in pink paired with a black ISSEY MIYAKE handbag.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-2fe4cea23e1e990c69431e909557f742" href="#gallery-2fe4cea23e1e990c69431e909557f742" data-ac-gallery-trigger="gallery-2fe4cea23e1e990c69431e909557f742"><span>iPhone Pocket in black.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-8f771a17f3ddef3f19c8c979d8ed6291" href="#gallery-8f771a17f3ddef3f19c8c979d8ed6291" data-ac-gallery-trigger="gallery-8f771a17f3ddef3f19c8c979d8ed6291"><span>iPhone Pocket in lemon and mandarin.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-56d430360d60f74d93b475a57eb36ebd" href="#gallery-56d430360d60f74d93b475a57eb36ebd" data-ac-gallery-trigger="gallery-56d430360d60f74d93b475a57eb36ebd"><span>iPhone Pocket in purple.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-8c54c3d4fde598029a7c6b36d27e85a3" aria-labelledby="gallery-dotnav-8c54c3d4fde598029a7c6b36d27e85a3" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:peacock">
                                
                                <div>
                                    <div>iPhone Pocket features a singular 3D-knitted construction that is the result of research and development carried out at ISSEY MIYAKE.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-peacock.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-peacock_inline" aria-label="Download media, A user poses with iPhone Pocket in peacock."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-8ec946387230a363dbe25e38306bce4d" aria-labelledby="gallery-dotnav-8ec946387230a363dbe25e38306bce4d" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:cinnamon">
                                
                                <div>
                                    <div>iPhone Pocket features a singular 3D-knitted construction that is the result of research and development carried out at ISSEY MIYAKE.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-cinnamon_inline" aria-label="Download media, A user poses with iPhone Pocket in cinnamon."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-1b5cfe3976c01fb7746de0602809af8b" aria-labelledby="gallery-dotnav-1b5cfe3976c01fb7746de0602809af8b" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:pink-and-black-issey-miyake-bag">
                                
                                <div>
                                    <div>Users can create their own personalized color combinations with iPhone Pocket and iPhone.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-pink-with-BAO-BAO-bag.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-pink-with-BAO-BAO-bag_inline" aria-label="Download media, iPhone Pocket in pink paired with a black ISSEY MIYAKE handbag."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-2fe4cea23e1e990c69431e909557f742" aria-labelledby="gallery-dotnav-2fe4cea23e1e990c69431e909557f742" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:black">
                                
                                <div>
                                    <div>The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-black-with-iPhone-17-Pro.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-black-with-iPhone-17-Pro_inline" aria-label="Download media, iPhone Pocket in black."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-8f771a17f3ddef3f19c8c979d8ed6291" aria-labelledby="gallery-dotnav-8f771a17f3ddef3f19c8c979d8ed6291" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:lemon-and-mandarin">
                                
                                <div>
                                    <div>The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-lemon-and-mandarin-with-iPhone-17-and-iPhone-Air.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-lemon-and-mandarin-with-iPhone-17-and-iPhone-Air_inline" aria-label="Download media, iPhone Pocket in lemon and mandarin."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-56d430360d60f74d93b475a57eb36ebd" aria-labelledby="gallery-dotnav-56d430360d60f74d93b475a57eb36ebd" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:purple">
                                
                                <div>
                                    <div>The development and design of iPhone Pocket unfolded in close collaboration with the Apple Design Studio, which provided insight into design and production throughout.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/11/introducing-iphone-pocket-a-beautiful-and-wearable-carrier-for-iphone/article/Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-02.zip" download="" data-analytics-title="download image - Apple-iPhone-Pocket-and-ISSEY-MIYAKE-purple-with-iPhone-17-02_inline" aria-label="Download media, iPhone Pocket in purple."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Availability</strong>
</h2>
                 
             
                 <div>iPhone Pocket is a limited-edition release. The short strap design is available in lemon, mandarin, purple, pink, peacock, sapphire, cinnamon, and black; the long strap design is available in sapphire, cinnamon, and black. iPhone Pocket in the short strap design retails at $149.95 (U.S.), and the long strap design at $229.95 (U.S.).
</div>
                 
             
                 <div>Customers can purchase iPhone Pocket beginning Friday, November 14, at select Apple Store locations and <a href="https://www.apple.com/" target="_blank">apple.com</a> in France, Greater China, Italy, Japan, Singapore, South Korea, the UK, and the U.S. Just in time for the holidays, Apple Specialists in stores and online can help customers mix and match different lengths and colors with their iPhone, style iPhone Pocket, and purchase their new favorite accessory.
</div>
                 
             
                 <div><ul>
<li>Apple Canton Road, Hong Kong</li>
<li>Apple Ginza, Tokyo</li>
<li>Apple Jing’an, Shanghai</li>
<li>Apple Marché Saint-Germain, Paris</li>
<li>Apple Myeongdong, Seoul</li>
<li>Apple Orchard Road, Singapore</li>
<li>Apple Piazza Liberty, Milan</li>
<li>Apple Regent Street, London</li>
<li>Apple SoHo, New York City</li>
<li>Apple Xinyi A13, Taipei</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    






    















	

		
		
			
























		
		

</article>



</section>
</main>



<div>
            Stay up to date with the latest articles from Apple Newsroom.
        </div>
	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[SoftBank sells its entire stake in Nvidia for $5.83B (208 pts)]]></title>
            <link>https://www.cnbc.com/2025/11/11/softbank-sells-its-entire-stake-in-nvidia-for-5point83-billion.html</link>
            <guid>45884937</guid>
            <pubDate>Tue, 11 Nov 2025 07:32:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/11/11/softbank-sells-its-entire-stake-in-nvidia-for-5point83-billion.html">https://www.cnbc.com/2025/11/11/softbank-sells-its-entire-stake-in-nvidia-for-5point83-billion.html</a>, See on <a href="https://news.ycombinator.com/item?id=45884937">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-108065851" data-test="InlineImage"><p>Nvidia CEO Jensen Huang (L) and the CEO of the SoftBank Group Masayoshi Son pose during an AI event in Tokyo on November 13, 2024.</p><p>Akio Kon | Bloomberg | Getty Images</p></div><div><p><a id="107312506" href="https://www.cnbc.com/quotes/" type="security" brand="cnbc" section="[object Object]" contentclassification="">SoftBank</a> said Tuesday it has sold its entire stake in U.S. chipmaker <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-2"><a href="https://www.cnbc.com/quotes/NVDA/">Nvidia</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> for $5.83 billion as the Japanese giant looks to capitalize on its <a href="https://www.cnbc.com/2025/06/27/softbank-ceo-says-he-wanted-to-be-openai-early-investor.html">"all in"</a> bet on ChatGPT maker OpenAI. </p><p>The firm said in its earnings statement that it sold 32.1 million Nvidia shares in October. It also disclosed that it sold part of its T-Mobile stake for $9.17 billion.</p><p>"We want to provide a lot of investment opportunities for investors, while we can still maintain financial strength," said SoftBank's Chief Financial Officer Yoshimitsu Goto during an investor presentation. </p><p>"So through those options and tools we make sure that we are ready for funding in a very safe manner," he said in comments translated by the company, adding that the stake sales were part of the firm's strategy for "asset monetization."</p><p>Nvidia shares dipped 0.95% in premarket trade on Tuesday.</p><p>While the Nvidia exit may come as a surprise to some investors, it's not the first time SoftBank has cashed out of the American AI chip darling.</p><p>SoftBank's Vision Fund was an early backer of Nvidia, <a href="https://www.cnbc.com/2017/05/24/the-stock-markets-hottest-stock-nvidia-just-got-a-big-new-backer.html">reportedly amassing</a> a $4 billion stake in 2017 before <a href="https://www.cnbc.com/2019/02/06/softbank-vision-fund-sells-nvidia-stake.html">selling all</a> of its holdings in January 2019. Despite its latest sale, SoftBank's business interests remain heavily intertwined with Nvidia's.</p></div><div id="Placeholder-ArticleBody-Video-108212821" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000392166" aria-labelledby="Placeholder-ArticleBody-Video-108212821"><p><img src="https://image.cnbcfm.com/api/v1/image/108212822-17605971971760597195-42119380833-1080pnbcnews.jpg?v=1760597197&amp;w=750&amp;h=422&amp;vtcrop=y" alt="ABB CEO: Softbank will be good home for robotics business"><span></span><span></span></p></div><div><p>That Tokyo-based company is involved in a number of AI ventures that rely on Nvidia's technology, including the $500 billion Stargate project for data centers in the U.S.</p><p>"This should not be seen, in our view, as a cautious or negative stance on Nvidia, but rather in the context of SoftBank needing at least $30.5bn of capital for investments in the Oct-Dec quarter, including $22.5bn for OpenAI and $6.5bn for Ampere," Rolf Bulk, equity research analyst at New Street Research, told CNBC.</p><p>That amounts to "more in a single quarter than it has invested in aggregate over the two prior years combined," Bulk said.</p><p>Morningstar's Dan Baker added that he doesn't see the move as representing a fundamental shift in strategy for the company.</p><p>"[SoftBank] made a point of saying that it wasn't any view on NVIDIA... At the end of the day, they are using the money to invest in other AI related companies," he said.</p></div><h2><a id="headline0"></a>Vision fund posts blowout $19 billion gain</h2><div><p>The stake sales and a blowout gain of $19 billion from SoftBank's Vision Fund helped the company <a href="https://www.cnbc.com/2025/11/11/softbank-earnings-report-2q.html">double its profit</a> in its fiscal second quarter.</p><p>The Vision Fund has been aggressively pushing into artificial intelligence, investing and acquiring firms throughout the AI value chain from chips to large language models and robotics.</p><p>"The reason we were able to have this result is because of September last year, that was the first time we invested in OpenAI," said SoftBank's Goto. He added that OpenAI's <a href="https://www.cnbc.com/2025/10/02/openai-share-sale-500-billion-valuation.html">latest valuation milestone of $500 billion</a> marks one of the largest valuations in the world, according to fair value.  </p></div><div><div role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="256" height="256" viewBox="0 0 256 256" aria-labelledby="title desc" role="img" focusable="false" preserveAspectRatio="xMinYMin"><title>Stock Chart Icon</title><desc>Stock chart icon</desc><g transform="translate(1.4065934065934016 1.4065934065934016) scale(2.81 2.81)"><path d="M 87.994 0 H 69.342 c -1.787 0 -2.682 2.16 -1.418 3.424 l 5.795 5.795 l -33.82 33.82 L 28.056 31.196 l -3.174 -3.174 c -1.074 -1.074 -2.815 -1.074 -3.889 0 L 0.805 48.209 c -1.074 1.074 -1.074 2.815 0 3.889 l 3.174 3.174 c 1.074 1.074 2.815 1.074 3.889 0 l 15.069 -15.069 l 14.994 14.994 c 1.074 1.074 2.815 1.074 3.889 0 l 1.614 -1.614 c 0.083 -0.066 0.17 -0.125 0.247 -0.202 l 37.1 -37.1 l 5.795 5.795 C 87.84 23.34 90 22.445 90 20.658 V 2.006 C 90 0.898 89.102 0 87.994 0 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 65.626 37.8 v 49.45 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 23.518 L 65.626 37.8 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 47.115 56.312 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 42.03 L 47.115 56.312 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 39.876 60.503 c -1.937 0 -3.757 -0.754 -5.127 -2.124 l -6.146 -6.145 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 59.844 C 41.952 60.271 40.933 60.503 39.876 60.503 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 22.937 46.567 L 11.051 58.453 c -0.298 0.298 -0.621 0.562 -0.959 0.8 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 48.004 L 22.937 46.567 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path></g></svg><p><img src="https://static-redesign.cnbcfm.com/dist/a54b41835a8b60db28c2.svg" alt="hide content"></p></div><p>Softbank's shares this year</p></div><div><p>The Japanese conglomerate's stock has slumped in the past week as <a href="https://www.cnbc.com/2025/11/07/ai-valuation-fears-grip-investors-as-tech-bubble-concerns-heighten.html">concerns of an AI bubble</a> sent jitters through global markets. </p><p>"Our share price recently has been going up and down dynamically… we want to provide as many invest opportunities as possible," said Goto Tuesday, adding that the company's announced four-for-one stock split is part of its strategy to provide as many investment opportunities for shareholders as possible.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI documentation you can talk to, for every repo (147 pts)]]></title>
            <link>https://deepwiki.com/</link>
            <guid>45884169</guid>
            <pubDate>Tue, 11 Nov 2025 04:38:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepwiki.com/">https://deepwiki.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45884169">Hacker News</a></p>
<div id="readability-page-1" class="page"><div tabindex="138"><a href="https://deepwiki.com/bregman-arie/devops-exercises"><div><div><p><span>bregman-arie</span>/<span>devops-exercises</span></p></div><p>Linux, Jenkins, AWS, SRE, Prometheus, Docker, Python, Ansible, Git, Kubernetes, Terraform, OpenStack, SQL, NoSQL, Azure, GCP, DNS, Elastic, Network, Virtualization. DevOps Interview Questions</p><div><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="currentColor" viewBox="0 0 256 256"><path d="M239.18,97.26A16.38,16.38,0,0,0,224.92,86l-59-4.76L143.14,26.15a16.36,16.36,0,0,0-30.27,0L90.11,81.23,31.08,86a16.46,16.46,0,0,0-9.37,28.86l45,38.83L53,211.75a16.38,16.38,0,0,0,24.5,17.82L128,198.49l50.53,31.08A16.4,16.4,0,0,0,203,211.75l-13.76-58.07,45-38.83A16.43,16.43,0,0,0,239.18,97.26Zm-15.34,5.47-48.7,42a8,8,0,0,0-2.56,7.91l14.88,62.8a.37.37,0,0,1-.17.48c-.18.14-.23.11-.38,0l-54.72-33.65a8,8,0,0,0-8.38,0L69.09,215.94c-.15.09-.19.12-.38,0a.37.37,0,0,1-.17-.48l14.88-62.8a8,8,0,0,0-2.56-7.91l-48.7-42c-.12-.1-.23-.19-.13-.5s.18-.27.33-.29l63.92-5.16A8,8,0,0,0,103,91.86l24.62-59.61c.08-.17.11-.25.35-.25s.27.08.35.25L153,91.86a8,8,0,0,0,6.75,4.92l63.92,5.16c.15,0,.24,0,.33.29S224,102.63,223.84,102.73Z"></path></svg><p><span>74.0k</span></p></div></div></a></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hiring a developer as a small indie studio in 2025 (106 pts)]]></title>
            <link>https://www.ballardgames.com/tales/hiring-dev-2025/</link>
            <guid>45883995</guid>
            <pubDate>Tue, 11 Nov 2025 04:04:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ballardgames.com/tales/hiring-dev-2025/">https://www.ballardgames.com/tales/hiring-dev-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=45883995">Hacker News</a></p>
Couldn't get https://www.ballardgames.com/tales/hiring-dev-2025/: Error: unsuitable certificate purpose]]></description>
        </item>
        <item>
            <title><![CDATA[The 'Toy Story' You Remember (1003 pts)]]></title>
            <link>https://animationobsessive.substack.com/p/the-toy-story-you-remember</link>
            <guid>45883788</guid>
            <pubDate>Tue, 11 Nov 2025 03:17:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://animationobsessive.substack.com/p/the-toy-story-you-remember">https://animationobsessive.substack.com/p/the-toy-story-you-remember</a>, See on <a href="https://news.ycombinator.com/item?id=45883788">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!oYAZ!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!oYAZ!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 424w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 848w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 1272w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png" width="1456" height="782" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:782,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1780036,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!oYAZ!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 424w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 848w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 1272w, https://substackcdn.com/image/fetch/$s_!oYAZ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcdc6e58-e9e5-4bc7-8d8e-5193a840a9e0_1863x1000.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><span>A still from </span><em>Toy Story</em><span> on 35 mm film</span></figcaption></figure></div><p><strong>Welcome!</strong><span> Glad you could join us for another Sunday edition of the </span><em>Animation Obsessive</em><span> newsletter. This is our slate:</span></p><ul><li><p><strong>1)</strong><span> Digital animation on film stock.</span></p></li><li><p><strong>2)</strong><span> Animation newsbits.</span></p></li></ul><p>With that, let’s go!</p><p><em>Toy Story</em><span> used to look different. It’s a little tricky to explain.</span></p><p><span>Back in 1995, CG animation was </span><em>the</em><span> topic in the industry, and Pixar was central to the hype. The studio had already </span><a href="https://animationobsessive.substack.com/p/when-disney-went-digital" rel="">shifted Disney to computers</a><span> and won the first Oscar for a CG short (</span><em><a href="https://www.youtube.com/watch?v=DWi2WTqD59A" rel="">Tin Toy</a></em><span>). Giant movies like </span><em>Jurassic Park</em><span> incorporated Pixar’s software.</span></p><p><span>The next step was </span><em>Toy Story</em><span>, billed as the first animated feature to go all-CG.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-1-178330349" target="_self" rel="">1</a></span><span> Even after Pixar’s successes, that was a risk. Would a fully digital movie sell tickets? </span></p><p><span>It clearly worked out. </span><em>Toy Story</em><span> appeared 30 years ago this month — and its popularity created the animation world that exists now. A new process took over the business.</span></p><p><span>But not </span><em>entirely</em><span> new — not at first. There was something old about </span><em>Toy Story</em><span>’s tech, too, back in 1995. Pixar made the thing with computers, but it still needed to screen in theaters. And computers couldn’t really </span><em>do</em><span> that yet. From its early years, Pixar had relied on physical film stock. According to authors Bill Kinder and Bobbie O’Steen:</span></p><blockquote><p><span>[Pixar’s Ed]</span><em> Catmull recognized that his studio’s pixels needed to merge with that world-standard distribution freeway, 35 mm film. Computer chips were not fast enough, nor disks large enough, nor compression sophisticated enough to display even 30 minutes of standard-definition motion pictures. It was axiomatic that for a filmgoing audience to be going to a film, it would be a... film.</em><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-2-178330349" target="_self" rel="">2</a></span></p></blockquote><p><em>Toy Story</em><span> was a transitional project. Since Pixar couldn’t send digital data to theaters, every one of the movie’s frames was printed on analog film. When </span><em>Toy Story</em><span> originally hit home video, that 35 mm version was its source. Only years later, after technology advanced, did Pixar start doing digital transfers — cutting out the middleman. And </span><em>Toy Story</em><span>’s look changed with the era.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-3-178330349" target="_self" rel="">3</a></span><span> </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!rk4n!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!rk4n!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 424w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 848w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!rk4n!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png" width="1456" height="1688" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1688,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4835256,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!rk4n!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 424w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 848w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!rk4n!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30fe34c-5024-4f38-87f9-77fa779a3286_1863x2160.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Toy Story</em><span>’s original release on 35 mm (top), and the version currently streaming on Disney+ (bottom). See the film’s trailer on 35 mm </span><a href="https://www.youtube.com/watch?v=LoBFN_V66P0" rel="">here</a><span>.</span></figcaption></figure></div><p><span>While making </span><em>Toy Story</em><span>, Pixar’s team knew that the grain, softness, colors and contrasts of analog film weren’t visible on its monitors. They were different mediums. </span></p><p><span>So, to get the right look, the studio had to keep that final, physical output in mind. The digital colors were tailored with an awareness that they would change after printing. “Greens go dark really fast, while the reds stay pretty true,” said </span><em>Toy Story</em><span>’s art director, Ralph Eggleston. “Blues have to be less saturated to look fully saturated on film, while the oranges look really bad on computer screens, but look really great on film.”</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-4-178330349" target="_self" rel="">4</a></span></p><p>The team checked its work along the way. In the words of Pixar’s William Reeves:</p><blockquote><p><em>During production, we’re working mostly from computer monitors. We’re rarely seeing the images on film. So, we have five or six extremely high-resolution monitors that have better color and picture quality. We put those in general work areas, so people can go and see how their work looks. Then, when we record, we try to calibrate to the film stock, so the image we have on the monitor looks the same as what we’ll get on film.</em></p></blockquote><p><span>Behind the final images was a “painstaking transfer process,” according to the press. Leading it was David DiFrancesco, one of Pixar’s early MVPs, who began working with Ed Catmull before Pixar even existed. He broke ground in film printing — specifically, in putting digital images on analog film.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-5-178330349" target="_self" rel="">5</a></span></p><p><span>He and his team in Pixar’s photoscience department used their expertise here. Their tools were “commercial grade” film printers, DiFrancesco noted: modified Solitaire Cine II machines. He’d invented more advanced stuff, but it wasn’t viable for a project of </span><em>Toy Story</em><span>’s size. Using the best equipment would’ve taken “several terabytes of data,” he said.</span></p><p><span>Their system was fairly straightforward. Every frame of </span><em>Toy Story</em><span>’s negative was exposed, three times, in front of a CRT screen that displayed the movie. “Since all film and video images are composed of combinations of red, green and blue light, the frame is separated into its discrete red, green and blue elements,” noted the studio. Exposures, filtered through each color, were layered to create each frame.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-6-178330349" target="_self" rel="">6</a></span><span> </span></p><p><span>It reportedly took nine hours to print 30 seconds of </span><em>Toy Story</em><span>. But it had to be done: it was the only way to screen the film.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!5nPg!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!5nPg!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 424w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 848w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 1272w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!5nPg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png" width="1456" height="882" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:882,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2072015,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!5nPg!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 424w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 848w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 1272w, https://substackcdn.com/image/fetch/$s_!5nPg!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c12dbf0-039e-4de3-8dac-e3231210eb69_2000x1211.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Examples of green, blue and red exposures, and the final scene on 35 mm film. Courtesy of the </span><em>Ultimate Toy Box</em><span> DVD.</span></figcaption></figure></div><p>In 1999, Pixar made history again.</p><p><span>Its second feature, </span><em>A Bug’s Life</em><span>, reached theaters in 1998. Once more, the studio designed its visuals for analog film (</span><a href="https://www.youtube.com/watch?v=izmlSjjOEdo" rel="">see the trailer on 35 mm</a><span>). Its people knew the ins-and-outs of this process, down to the amount of detail that film stock could accept and a projector could show. That’s partly how they got away with the movie’s tiny 2048×862 resolution, for example.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-7-178330349" target="_self" rel="">7</a></span></p><p><span>Still, the team struggled with one thing: the dip in image quality when film got converted to home video. That’s how </span><em>Toy Story</em><span> was released, but there </span><em>had</em><span> to be a better way.</span></p><p><span>For the home version of</span><em> A Bug’s Life</em><span>, Pixar devised a method of “go[ing] from our digital image within our system … straight to video,” John Lasseter said. He called it “a real pure version of our movie straight from our computers.” </span><em>A Bug’s Life</em><span> became the first digital-to-digital transfer on DVD. Compared to the theatrical release, the look had changed. It was sharp and grainless, and the colors were kind of different.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-8-178330349" target="_self" rel="">8</a></span></p><p><span>A digital transfer of </span><em>Toy Story</em><span> followed in the early 2000s. And it wasn’t </span><em>quite</em><span> the same movie that viewers had seen in the ‘90s. “The colors are vivid and lifelike, [and] not a hint of grain or artifacts can be found,” raved one reviewer. It was a crisp, blazingly bright, digital image now — totally different from the softness, texture and deep, muted warmth of physical film, on which </span><em>Toy Story </em><span>was created to be seen.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!P-J7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!P-J7!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 424w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 848w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!P-J7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png" width="1456" height="1676" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1676,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3528708,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!P-J7!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 424w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 848w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!P-J7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffd4e3796-6331-4286-bb6c-0bd7870c05d4_1876x2160.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Toy Story</em><span> on 35 mm (top) and the Disney+ edition (bottom)</span></figcaption></figure></div><p><span>Quickly, digital transfers became a standard thing. Among others by Pixar, </span><em>The Incredibles</em><span> puts off a very different vibe between its theatrical and later releases (see </span><a href="https://www.youtube.com/watch?v=M_nSbqsLmEk" rel="">the 35 mm trailer</a><span> for reference). </span></p><p>Pixar wasn’t the only studio to make the leap, either. Disney did as well. </p><p><span>Like </span><em>Toy Story</em><span>, the Disney renaissance work of the ‘90s was transitional. </span><em>The Lion King</em><span>, </span><em>Mulan</em><span> and the rest existed as </span><a href="https://animationobsessive.substack.com/p/when-disney-went-digital" rel="">files in computer systems</a><span> — and the idea was always to record them on analog film at the end. Early home releases were based on those 35 mm versions. Later releases, like the ones Disney streams today, were direct transfers of the digital data. </span></p><p><span>At times, especially in the colors, they’re almost unrecognizable. And the images feel less cohesive — like something’s missing that was </span><em>supposed</em><span> to bring all the elements together. These aren’t quite the same films that ruled the ‘90s.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!6IkD!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!6IkD!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 424w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 848w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 1272w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!6IkD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png" width="1456" height="1633" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1633,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4330548,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!6IkD!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 424w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 848w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 1272w, https://substackcdn.com/image/fetch/$s_!6IkD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca25faad-c263-42fd-b261-3e9b4e3197ba_1892x2122.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Aladdin</em><span> on 35 mm film (top) versus Blu-ray (bottom). See a clip from the film on 35 mm </span><a href="https://www.youtube.com/watch?v=AuhNnovKXLA" rel="">here</a><span>.</span></figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!qdDU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!qdDU!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 424w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 848w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!qdDU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png" width="1456" height="1662" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/de166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1662,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4506414,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!qdDU!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 424w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 848w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 1272w, https://substackcdn.com/image/fetch/$s_!qdDU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fde166f83-da65-4ce8-a57f-043b50348abb_1892x2160.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>The Lion King</em><span> on 35 mm film (top) versus Blu-ray. See a clip from the film on 35 mm </span><a href="https://www.youtube.com/watch?v=uivXq3tXOhg" rel="">here</a><span>.</span></figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!T9lv!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!T9lv!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 424w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 848w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 1272w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!T9lv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png" width="1456" height="1702" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1702,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3824553,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://animationobsessive.substack.com/i/178330349?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!T9lv!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 424w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 848w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 1272w, https://substackcdn.com/image/fetch/$s_!T9lv!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c2f5eb-b4f8-4249-af6f-0441c97c78b1_1814x2120.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Mulan</em><span> on 35 mm film (top) versus Blu-ray. See the film’s trailer on 35 mm </span><a href="https://www.youtube.com/watch?v=2z2KsFZs-8I" rel="">here</a><span>.</span></figcaption></figure></div><p><span>For a number of years, there’s been talk in film-preservation circles about </span><em>Toy Story</em><span> and the Disney renaissance. This work sits in an odd place. The world was still pretty analog when the computer animation boom arrived: out of necessity, these projects became hybrids of new and old. What’s the</span><em> right </em><span>way to see digital movies that were designed for 35 mm film?</span></p><p><span>The studios themselves haven’t quite figured it out. On Disney+, the colors of </span><em>Toy Story</em><span> feel a bit raw — searing greens that were meant to darken on film, for example. Meanwhile, the newer </span><em>Toy Story</em><span> Blu-ray shares more in common with the original colors, but it’s still an altered, colder look.</span></p><p><span>When digital transfers first showed up, people were thrilled, including at Pixar. Movies became “crisper, clearer and more stunning on home video systems” than in theaters, some claimed.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-9-178330349" href="https://animationobsessive.substack.com/p/the-toy-story-you-remember#footnote-9-178330349" target="_self" rel="">9</a></span><span> Even so, it’s a little disquieting to think that </span><em>Toy Story</em><span>, the film that built our current world, is barely available in the form that wowed audiences of the ‘90s. The same goes for many other movies from the transitional era.</span></p><p><span>The good news is that this conversation gets bigger all the time. In those film-preservation circles, a dedicated few are trying to save the old work. More and more </span><a href="https://www.youtube.com/watch?v=BMvgu_KdpjA" rel="">comparison videos</a><span> are popping up on YouTube. If you get the chance to see one of the old Disney or Pixar films on 35 mm, it’s always worthwhile.</span></p><p><span>These companies, ultimately, decide how </span><em>Toy Story</em><span> looks today. Still, for some, it’s nice to see the original version of the film again — the version Pixar originally intended to make. It’s evidence that the film </span><em>did</em><span> feel</span><em> </em><span>different back then. The memories were real.</span></p><ul><li><p><em>I Am Frankelda</em><span> continues its strong performance in </span><strong>Mexican</strong><span> theaters. Analyst Edgar Apanco </span><a href="https://x.com/elapanco/status/1987639735091921274" rel="">reports</a><span> that 658,000 people have gone to see it, surpassing the popular </span><em>Chainsaw Man</em><span> movie. Revenues are </span><a href="https://x.com/elapanco/status/1987660916633325574" rel="">over $2.15 million</a><span> and climbing — having fallen </span><a href="https://palomaynacho.com/blog/chainsaw-y-frankelda-se-enfrentan-en-un-halloween-complicado/" rel="">just 17%</a><span> in week two, and an estimated 20% in week three.</span></p></li><li><p><span>In </span><strong>Japan</strong><span>, Goro Miyazaki </span><a href="https://ghibli.jpn.org/news/goro-talk-4/" rel="">revealed</a><span> that his father is still going to Studio Ghibli to draw for a few hours each day.</span></p></li><li><p><span>An exhibition in </span><strong>Taiwan</strong><span> </span><a href="https://reading.udn.com/read/story/124410/9126552" rel="">brought</a><span> the films of Karel Zeman to the country, reportedly for the first time. </span><em>The Fabulous Baron Munchausen</em><span> and </span><em>Invention for Destruction</em><span> are showing, among others.</span></p></li><li><p><span>In </span><strong>Nigeria</strong><span>, animator Gabriel Ugbodaga had </span><a href="https://www.arise.tv/gabriel-ugbodaga-nigeria-has-enough-animation-talent-what-we-lack-is-training-and-exposure/" rel="">a televised interview</a><span> about his well-received film </span><em>Vainglorious</em><span> (</span><a href="https://www.youtube.com/watch?v=6tVVWgz1cEk" rel="">watch</a><span>) and the state of the country’s industry. “When it comes to 2D hand-drawn animation,” he said, “there’s a lot of talent in Nigeria.”</span></p></li><li><p><span>If you missed that </span><em>Baahubali: The Eternal War</em><span> teaser this week, </span><a href="https://www.youtube.com/watch?v=RdUPs9e1bUk" rel="">see it here</a><span>. It’s an </span><strong>Indian</strong><span> feature presented by S. S. Rajamouli (</span><em>RRR</em><span>).</span></p></li><li><p><span>In </span><strong>Germany</strong><span>, Werner Herzog’s animated film </span><em>The Twilight World</em><span> </span><a href="https://cineuropa.org/en/newsdetail/485526" rel="">picked up</a><span> “€100,000 for production preparation support,” reports </span><em>Cineuropa</em><span>.</span></p></li><li><p><em>Infinity Castle</em><span> will reach </span><strong>China</strong><span> next weekend, and forecasters </span><a href="https://cn.investing.com/news/stock-market-news/article-3066545" rel="">believe</a><span> it could earn a billion yuan (over $140 million) and become the highest-grossing anime film in the country.</span></p></li><li><p><span>Also </span><a href="https://weibo.com/7985578740/Qcrf6p4D6" rel="">happening</a><span> in </span><strong>China</strong><span> next weekend: the latest edition of Feinaki Beijing Animation Week. The festival posted </span><a href="https://www.bilibili.com/video/BV1rMyzBxE9w/" rel="">55 trailers</a><span> for its selections this year.</span></p></li><li><p><span>The </span><strong>Japanese</strong><span> journalist Atsushi Matsumoto is raising concerns that the anime boom of the 2020s </span><a href="https://news.yahoo.co.jp/expert/articles/55f696fd42ce9a821f4bf682327f452bf3b7245c" rel="">could be a bubble</a><span>. (Meanwhile, despite huge industry profits, analysis suggests that studio closures are </span><a href="https://prtimes.jp/main/html/rd/p/000001179.000043465.html" rel="">set to rise</a><span> for the third year in a row.)</span></p></li><li><p><span>In</span><strong> America</strong><span>, for those in New York, there’s an interesting series of stop-motion screenings </span><a href="https://www.eastman.org/stop-motion-artform" rel="">at the Eastman Museum</a><span> this month — including </span><em>The Wolf House</em><span>.</span></p></li><li><p><span>Last of all: we wrote about a handful of </span><a href="https://animationobsessive.substack.com/p/free-films-worth-seeing" rel="">recent, free films worth seeing</a><span>. </span></p></li></ul><p><em><strong>Until next time!</strong></em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I hate screenshots of text (313 pts)]]></title>
            <link>https://parkscomputing.com/page/i-hate-screenshots-of-text</link>
            <guid>45883124</guid>
            <pubDate>Tue, 11 Nov 2025 01:36:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://parkscomputing.com/page/i-hate-screenshots-of-text">https://parkscomputing.com/page/i-hate-screenshots-of-text</a>, See on <a href="https://news.ycombinator.com/item?id=45883124">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        




<article>
    
    <div>
        
<p>During the course of a regular working day, I receive a lot of screenshots like this from well-meaning colleagues:</p>
<p> <img src="https://parkscomputing.com/images/screenshots.png" alt="A screenshot of some text">
</p><p>It's almost always in a chat about some issue that occurred in the code, or perhaps code that's somehow related to the code in the screenshot, or… well, how am I supposed to even know? Upon seeing this code, I might think, “How is <code>slug</code> defined? Is <code>slug</code> being used to create the <code>baseUrl</code>? Why is the domain name hard-coded in that URL? What happens if an exception is thrown? <em>What module is this code even in?</em>”</p>
<p>I have to either very carefully type some of the code into a search box or (these days) get my coding agent to find the relevant module for me.</p>
<p>Why couldn't my colleague have just used copy &amp; paste? I could have seen a bit more of the context, even if the same lines were selected, and I could copy-and-paste <em>that</em> text into my IDE's search function so much more easily.</p>
<p>In fact, why couldn't they just send me the file, or even a link to the file (since everybody and their dog use GitHub, anyway).</p>
<p>It gets worse. Sometimes, I'll get a screenshot of an error log. “Hey, Paul, the build is failing. Can you look at this?”</p>
<p> <img src="https://parkscomputing.com/images/screenshots-errors2.png" alt="A screenshot of some build errors">
</p><p>What were you building? What line did it fail on? <em>What even was the error?</em></p>
<p>Of course, if I do a full rebuild of everything on my workstation, it'll succeed.</p>
<p>It would have been SO easy to just copy all of the error log, or even dump the log into a file, and just send me that.</p>
<p> <img src="https://parkscomputing.com/images/banging-head-against-wall-cracked.gif" alt="Me reading a screenshot of some build errors">
</p><p>Please, don't take screenshots of text unless it's to demonstrate a cosmetic issue related to the display of the text, or there is truly something relevant about the content of the screenshot that would be lost in a purely textual context.</p>

    </div>
</article>



    

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Warren Buffett's final shareholder letter [pdf] (362 pts)]]></title>
            <link>https://berkshirehathaway.com/news/nov1025.pdf</link>
            <guid>45882837</guid>
            <pubDate>Tue, 11 Nov 2025 00:51:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://berkshirehathaway.com/news/nov1025.pdf">https://berkshirehathaway.com/news/nov1025.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=45882837">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[High-performance 2D graphics rendering on the CPU using sparse strips [pdf] (271 pts)]]></title>
            <link>https://github.com/LaurenzV/master-thesis/blob/main/main.pdf</link>
            <guid>45881568</guid>
            <pubDate>Mon, 10 Nov 2025 22:05:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/LaurenzV/master-thesis/blob/main/main.pdf">https://github.com/LaurenzV/master-thesis/blob/main/main.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=45881568">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            


<react-partial partial-name="marketing-navigation" data-ssr="true" data-attempted-ssr="true" data-react-profiling="false">
  
  
  <div data-target="react-partial.reactRoot"><nav aria-label="Global"><ul><li><div><ul><li><div><p><span>AI CODE CREATION</span></p><ul><li><a href="https://github.com/features/copilot" data-analytics-event="{&quot;action&quot;:&quot;github_copilot&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_copilot_link_platform_navbar&quot;}"><div><p><span>GitHub Copilot</span><span>Write better code with AI</span></p></div></a></li><li><a href="https://github.com/features/spark" data-analytics-event="{&quot;action&quot;:&quot;github_spark&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_spark_link_platform_navbar&quot;}"><div><p><span>GitHub Spark</span><span>Build and deploy intelligent apps</span></p></div></a></li><li><a href="https://github.com/features/models" data-analytics-event="{&quot;action&quot;:&quot;github_models&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_models_link_platform_navbar&quot;}"><div><p><span>GitHub Models</span><span>Manage and compare prompts</span></p></div></a></li><li><a href="https://github.com/mcp" data-analytics-event="{&quot;action&quot;:&quot;mcp_registry&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;mcp_registry_link_platform_navbar&quot;}"><div><p><span>MCP Registry<sup>New</sup></span><span>Discover and integrate external tools</span></p></div></a></li></ul></div></li><li><div><p><span>DEVELOPER WORKFLOWS</span></p><ul><li><a href="https://github.com/features/actions" data-analytics-event="{&quot;action&quot;:&quot;actions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;actions_link_platform_navbar&quot;}"><div><p><span>Actions</span><span>Automate any workflow</span></p></div></a></li><li><a href="https://github.com/features/codespaces" data-analytics-event="{&quot;action&quot;:&quot;codespaces&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;codespaces_link_platform_navbar&quot;}"><div><p><span>Codespaces</span><span>Instant dev environments</span></p></div></a></li><li><a href="https://github.com/features/issues" data-analytics-event="{&quot;action&quot;:&quot;issues&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;issues_link_platform_navbar&quot;}"><div><p><span>Issues</span><span>Plan and track work</span></p></div></a></li><li><a href="https://github.com/features/code-review" data-analytics-event="{&quot;action&quot;:&quot;code_review&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;code_review_link_platform_navbar&quot;}"><div><p><span>Code Review</span><span>Manage code changes</span></p></div></a></li></ul></div></li><li><div><p><span>APPLICATION SECURITY</span></p><ul><li><a href="https://github.com/security/advanced-security" data-analytics-event="{&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_advanced_security_link_platform_navbar&quot;}"><div><p><span>GitHub Advanced Security</span><span>Find and fix vulnerabilities</span></p></div></a></li><li><a href="https://github.com/security/advanced-security/code-security" data-analytics-event="{&quot;action&quot;:&quot;code_security&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;code_security_link_platform_navbar&quot;}"><div><p><span>Code security</span><span>Secure your code as you build</span></p></div></a></li><li><a href="https://github.com/security/advanced-security/secret-protection" data-analytics-event="{&quot;action&quot;:&quot;secret_protection&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;secret_protection_link_platform_navbar&quot;}"><div><p><span>Secret protection</span><span>Stop leaks before they start</span></p></div></a></li></ul></div></li><li><div><p><span>EXPLORE</span></p><ul><li><a href="https://github.com/why-github" data-analytics-event="{&quot;action&quot;:&quot;why_github&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;why_github_link_platform_navbar&quot;}"><span>Why GitHub</span></a></li><li><a href="https://docs.github.com/" data-analytics-event="{&quot;action&quot;:&quot;documentation&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;documentation_link_platform_navbar&quot;}" target="_blank" rel="noreferrer"><span>Documentation</span></a></li><li><a href="https://github.blog/" data-analytics-event="{&quot;action&quot;:&quot;blog&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;blog_link_platform_navbar&quot;}" target="_blank" rel="noreferrer"><span>Blog</span></a></li><li><a href="https://github.blog/changelog" data-analytics-event="{&quot;action&quot;:&quot;changelog&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;changelog_link_platform_navbar&quot;}" target="_blank" rel="noreferrer"><span>Changelog</span></a></li><li><a href="https://github.com/marketplace" data-analytics-event="{&quot;action&quot;:&quot;marketplace&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;marketplace_link_platform_navbar&quot;}"><span>Marketplace</span></a></li></ul></div></li></ul><p><a href="https://github.com/features" data-analytics-event="{&quot;action&quot;:&quot;view_all_features&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_features_link_platform_navbar&quot;}"><span>View all features</span></a></p></div></li><li><div><ul><li><div><p><span>BY COMPANY SIZE</span></p><ul><li><a href="https://github.com/enterprise" data-analytics-event="{&quot;action&quot;:&quot;enterprises&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;enterprises_link_solutions_navbar&quot;}"><span>Enterprises</span></a></li><li><a href="https://github.com/team" data-analytics-event="{&quot;action&quot;:&quot;small_and_medium_teams&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;small_and_medium_teams_link_solutions_navbar&quot;}"><span>Small and medium teams</span></a></li><li><a href="https://github.com/enterprise/startups" data-analytics-event="{&quot;action&quot;:&quot;startups&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;startups_link_solutions_navbar&quot;}"><span>Startups</span></a></li><li><a href="https://github.com/solutions/industry/nonprofits" data-analytics-event="{&quot;action&quot;:&quot;nonprofits&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;nonprofits_link_solutions_navbar&quot;}"><span>Nonprofits</span></a></li></ul></div></li><li><div><p><span>BY USE CASE</span></p><ul><li><a href="https://github.com/solutions/use-case/app-modernization" data-analytics-event="{&quot;action&quot;:&quot;app_modernization&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;app_modernization_link_solutions_navbar&quot;}"><span>App Modernization</span></a></li><li><a href="https://github.com/solutions/use-case/devsecops" data-analytics-event="{&quot;action&quot;:&quot;devsecops&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;devsecops_link_solutions_navbar&quot;}"><span>DevSecOps</span></a></li><li><a href="https://github.com/solutions/use-case/devops" data-analytics-event="{&quot;action&quot;:&quot;devops&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;devops_link_solutions_navbar&quot;}"><span>DevOps</span></a></li><li><a href="https://github.com/solutions/use-case/ci-cd" data-analytics-event="{&quot;action&quot;:&quot;ci/cd&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;ci/cd_link_solutions_navbar&quot;}"><span>CI/CD</span></a></li><li><a href="https://github.com/solutions/use-case" data-analytics-event="{&quot;action&quot;:&quot;view_all_use_cases&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_use_cases_link_solutions_navbar&quot;}"><span>View all use cases</span></a></li></ul></div></li><li><div><p><span>BY INDUSTRY</span></p><ul><li><a href="https://github.com/solutions/industry/healthcare" data-analytics-event="{&quot;action&quot;:&quot;healthcare&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;healthcare_link_solutions_navbar&quot;}"><span>Healthcare</span></a></li><li><a href="https://github.com/solutions/industry/financial-services" data-analytics-event="{&quot;action&quot;:&quot;financial_services&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;financial_services_link_solutions_navbar&quot;}"><span>Financial services</span></a></li><li><a href="https://github.com/solutions/industry/manufacturing" data-analytics-event="{&quot;action&quot;:&quot;manufacturing&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;manufacturing_link_solutions_navbar&quot;}"><span>Manufacturing</span></a></li><li><a href="https://github.com/solutions/industry/government" data-analytics-event="{&quot;action&quot;:&quot;government&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;government_link_solutions_navbar&quot;}"><span>Government</span></a></li><li><a href="https://github.com/solutions/industry" data-analytics-event="{&quot;action&quot;:&quot;view_all_industries&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_industries_link_solutions_navbar&quot;}"><span>View all industries</span></a></li></ul></div></li></ul><p><a href="https://github.com/solutions" data-analytics-event="{&quot;action&quot;:&quot;view_all_solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_solutions_link_solutions_navbar&quot;}"><span>View all solutions</span></a></p></div></li><li><div><ul><li><div><p><span>EXPLORE BY TOPIC</span></p><ul><li><a href="https://github.com/resources/articles?topic=ai" data-analytics-event="{&quot;action&quot;:&quot;ai&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;ai_link_resources_navbar&quot;}"><span>AI</span></a></li><li><a href="https://github.com/resources/articles?topic=software-development" data-analytics-event="{&quot;action&quot;:&quot;software_development&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;software_development_link_resources_navbar&quot;}"><span>Software Development</span></a></li><li><a href="https://github.com/resources/articles?topic=devops" data-analytics-event="{&quot;action&quot;:&quot;devops&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;devops_link_resources_navbar&quot;}"><span>DevOps</span></a></li><li><a href="https://github.com/resources/articles?topic=security" data-analytics-event="{&quot;action&quot;:&quot;security&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;security_link_resources_navbar&quot;}"><span>Security</span></a></li><li><a href="https://github.com/resources/articles" data-analytics-event="{&quot;action&quot;:&quot;view_all_topics&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_topics_link_resources_navbar&quot;}"><span>View all topics</span></a></li></ul></div></li><li><div><p><span>EXPLORE BY TYPE</span></p><ul><li><a href="https://github.com/customer-stories" data-analytics-event="{&quot;action&quot;:&quot;customer_stories&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}"><span>Customer stories</span></a></li><li><a href="https://github.com/resources/events" data-analytics-event="{&quot;action&quot;:&quot;events__webinars&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;events__webinars_link_resources_navbar&quot;}"><span>Events &amp; webinars</span></a></li><li><a href="https://github.com/resources/whitepapers" data-analytics-event="{&quot;action&quot;:&quot;ebooks__reports&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;ebooks__reports_link_resources_navbar&quot;}"><span>Ebooks &amp; reports</span></a></li><li><a href="https://github.com/solutions/executive-insights" data-analytics-event="{&quot;action&quot;:&quot;business_insights&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;business_insights_link_resources_navbar&quot;}"><span>Business insights</span></a></li><li><a href="https://skills.github.com/" data-analytics-event="{&quot;action&quot;:&quot;github_skills&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_skills_link_resources_navbar&quot;}" target="_blank" rel="noreferrer"><span>GitHub Skills</span></a></li></ul></div></li><li><div><p><span>SUPPORT &amp; SERVICES</span></p><ul><li><a href="https://docs.github.com/" data-analytics-event="{&quot;action&quot;:&quot;documentation&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;documentation_link_resources_navbar&quot;}" target="_blank" rel="noreferrer"><span>Documentation</span></a></li><li><a href="https://support.github.com/" data-analytics-event="{&quot;action&quot;:&quot;customer_support&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;customer_support_link_resources_navbar&quot;}" target="_blank" rel="noreferrer"><span>Customer support</span></a></li><li><a href="https://github.com/orgs/community/discussions" data-analytics-event="{&quot;action&quot;:&quot;community_forum&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;community_forum_link_resources_navbar&quot;}"><span>Community forum</span></a></li><li><a href="https://github.com/trust-center" data-analytics-event="{&quot;action&quot;:&quot;trust_center&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;trust_center_link_resources_navbar&quot;}"><span>Trust center</span></a></li><li><a href="https://github.com/partners" data-analytics-event="{&quot;action&quot;:&quot;partners&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}"><span>Partners</span></a></li></ul></div></li></ul></div></li><li><div><ul><li><div><p><span>COMMUNITY</span></p><ul><li><a href="https://github.com/sponsors" data-analytics-event="{&quot;action&quot;:&quot;github_sponsors&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}"><div><p><span>GitHub Sponsors</span><span>Fund open source developers</span></p></div></a></li></ul></div></li><li><div><p><span>PROGRAMS</span></p><ul><li><a href="https://securitylab.github.com/" data-analytics-event="{&quot;action&quot;:&quot;security_lab&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;security_lab_link_open_source_navbar&quot;}" target="_blank" rel="noreferrer"><span>Security Lab</span></a></li><li><a href="https://maintainers.github.com/" data-analytics-event="{&quot;action&quot;:&quot;maintainer_community&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;maintainer_community_link_open_source_navbar&quot;}" target="_blank" rel="noreferrer"><span>Maintainer Community</span></a></li><li><a href="https://github.com/accelerator" data-analytics-event="{&quot;action&quot;:&quot;accelerator&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;accelerator_link_open_source_navbar&quot;}"><span>Accelerator</span></a></li><li><a href="https://archiveprogram.github.com/" data-analytics-event="{&quot;action&quot;:&quot;archive_program&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;archive_program_link_open_source_navbar&quot;}" target="_blank" rel="noreferrer"><span>Archive Program</span></a></li></ul></div></li><li><div><p><span>REPOSITORIES</span></p><ul><li><a href="https://github.com/topics" data-analytics-event="{&quot;action&quot;:&quot;topics&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;topics_link_open_source_navbar&quot;}"><span>Topics</span></a></li><li><a href="https://github.com/trending" data-analytics-event="{&quot;action&quot;:&quot;trending&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;trending_link_open_source_navbar&quot;}"><span>Trending</span></a></li><li><a href="https://github.com/collections" data-analytics-event="{&quot;action&quot;:&quot;collections&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;collections_link_open_source_navbar&quot;}"><span>Collections</span></a></li></ul></div></li></ul></div></li><li><div><ul><li><div><p><span>ENTERPRISE SOLUTIONS</span></p><ul><li><a href="https://github.com/enterprise" data-analytics-event="{&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}"><div><p><span>Enterprise platform</span><span>AI-powered developer platform</span></p></div></a></li></ul></div></li><li><div><p><span>AVAILABLE ADD-ONS</span></p><ul><li><a href="https://github.com/security/advanced-security" data-analytics-event="{&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_advanced_security_link_enterprise_navbar&quot;}"><div><p><span>GitHub Advanced Security</span><span>Enterprise-grade security features</span></p></div></a></li><li><a href="https://github.com/features/copilot/copilot-business" data-analytics-event="{&quot;action&quot;:&quot;copilot_for_business&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;copilot_for_business_link_enterprise_navbar&quot;}"><div><p><span>Copilot for Business</span><span>Enterprise-grade AI features</span></p></div></a></li><li><a href="https://github.com/premium-support" data-analytics-event="{&quot;action&quot;:&quot;premium_support&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;premium_support_link_enterprise_navbar&quot;}"><div><p><span>Premium Support</span><span>Enterprise-grade 24/7 support</span></p></div></a></li></ul></div></li></ul></div></li><li><a href="https://github.com/pricing" data-analytics-event="{&quot;action&quot;:&quot;pricing&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;pricing&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;pricing_link_pricing_navbar&quot;}"><span>Pricing</span></a></li></ul></nav></div>
</react-partial>



        <div>
                


<qbsearch-input data-scope="repo:LaurenzV/master-thesis" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="gjP2bom9MneAfFMoYIHRW9za-u5vhVJJHm5vfaTlEdG8qH4iHCp0pF2ISxvbOvUB2fGhWK-mx5easnUWe2Sacw" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="LaurenzV/master-thesis" data-current-org="" data-current-owner="LaurenzV" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        <div data-view-component="true">        <!-- '"` --><!-- </textarea></xmp> --><form id="code-search-feedback-form" data-turbo="false" action="/search/feedback" accept-charset="UTF-8" method="post">
          <p>We read every piece of feedback, and take your input very seriously.</p>
          
          
          <label for="include_email">Include my email address so I can be contacted</label>
</form></div>
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            <div>
              <p><a href="https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FLaurenzV%2Fmaster-thesis%2Fblob%2Fmain%2Fmain.pdf" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/LaurenzV/master-thesis/blob/main/main.pdf&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="d4712b985595d0ee9eef3ef57900e345d9365d3b9bb74c25427d77c8aca3315c" data-analytics-event="{&quot;category&quot;:&quot;Marketing nav&quot;,&quot;action&quot;:&quot;click to go to homepage&quot;,&quot;label&quot;:&quot;ref_page:Marketing;ref_cta:Sign in;ref_loc:Header&quot;}">
                Sign in
              </a>
            </p></div>

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=LaurenzV%2Fmaster-thesis" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/LaurenzV/master-thesis/blob/main/main.pdf&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="d4712b985595d0ee9eef3ef57900e345d9365d3b9bb74c25427d77c8aca3315c" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-a472a9ef-fa55-4047-8728-a57ca0e96a26" for="icon-button-0e257615-683d-47b5-9a35-75c50f858c72" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.2ed7297523f7a189873b.module.css">
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.6c63a6de228d6520804d.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false" data-react-profiling="false">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spatial intelligence is AI’s next frontier (222 pts)]]></title>
            <link>https://drfeifei.substack.com/p/from-words-to-worlds-spatial-intelligence</link>
            <guid>45880939</guid>
            <pubDate>Mon, 10 Nov 2025 21:07:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://drfeifei.substack.com/p/from-words-to-worlds-spatial-intelligence">https://drfeifei.substack.com/p/from-words-to-worlds-spatial-intelligence</a>, See on <a href="https://news.ycombinator.com/item?id=45880939">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><p><span>In 1950, when computing was little more than automated arithmetic and simple logic, Alan Turing asked a question that still reverberates today: can machines think? It took remarkable imagination to see what he saw: that intelligence might someday be built rather than born. That insight later launched a relentless scientific quest called Artificial Intelligence (AI). Twenty-five years into my own career in AI, I still find myself inspired by Turing’s vision. But how close are we? The answer isn’t simple.</span></p><p><span>Today, leading AI technology such as large language models (LLMs) have begun to transform how we access and work with abstract knowledge. Yet they remain wordsmiths in the dark; eloquent but inexperienced, knowledgeable but ungrounded. </span><strong>Spatial intelligence will transform how we create and interact with real and virtual worlds—revolutionizing storytelling, creativity, robotics, scientific discovery, and beyond. This is AI’s next frontier.</strong></p></div><p><span>The pursuit of visual and spatial</span><em> </em><span>intelligence has been the North Star guiding me since I entered the field. It’s why I spent years building ImageNet, the first large-scale visual learning and benchmarking dataset and one of three key elements enabling the birth of modern AI, along with neural network algorithms and modern compute like graphics processing units (GPUs). It’s why </span><a href="https://svl.stanford.edu/" rel="">my academic lab at Stanford</a><span> has spent the last decade combining computer vision with robotic learning. And it’s why my cofounders Justin Johnson, Christoph Lassner, Ben Mildenhall, and I created </span><a href="https://www.worldlabs.ai/" rel="">World Labs</a><span> more than one year ago: to realize this possibility in full, for the first time.</span></p><p>In this essay, I’ll explain what spatial intelligence is, why it matters, and how we’re building the world models that will unlock it—with impact that will reshape creativity, embodied intelligence, and human progress.</p><p>AI has never been more exciting. Generative AI models such as LLMs have moved from research labs to everyday life, becoming tools of creativity, productivity, and communication for billions of people. They have demonstrated capabilities once thought impossible, producing coherent text, mountains of code, photorealistic images, and even short video clips with ease. It’s no longer a question of whether AI will change the world. By any reasonable definition, it already has.</p><p>Yet so much still lies beyond our reach. The vision of autonomous robots remains intriguing but speculative, far from the fixtures of daily life that futurists have long promised. The dream of massively accelerated research in fields like disease curation, new material discovery, and particle physics remains largely unfulfilled. And the promise of AI that truly understands and empowers human creators—whether students learning intricate concepts in molecular chemistry, architects visualizing spaces, filmmakers building worlds, or anyone seeking fully immersive virtual experiences—remains beyond reach.</p><p>To learn why these capabilities remain elusive, we need to examine how spatial intelligence evolved, and how it shapes our understanding of the world.</p><p>Vision has long been a cornerstone of human intelligence, but its power emerged from something even more fundamental. Long before animals could nest, care for their young, communicate with language, or build civilizations, the simple act of sensing quietly sparked an evolutionary journey toward intelligence.</p><p><span>This seemingly isolated ability to glean information from the external world, whether a glimmer of light or the feeling of texture, created a bridge between perception and survival that only grew stronger and more elaborate as the generations passed. Layer upon layer of neurons grew from that bridge, forming nervous systems that interpret the world and coordinate interactions between an organism and its surroundings. Thus, many scientists have conjectured that </span><strong>perception and action became the core loop driving the evolution of intelligence</strong><span>, and the foundation on which nature created our species—the ultimate embodiment of perceiving, learning, thinking, and doing.</span></p><p>Spatial intelligence plays a fundamental role in defining how we interact with the physical world. Every day, we rely on it for the most ordinary acts: parking a car by imagining the narrowing gap between bumper and curb, catching a set of keys tossed across the room, navigating a crowded sidewalk without collision, or sleepily pouring coffee into a mug without looking. In more extreme circumstances, firefighters navigate collapsing buildings through shifting smoke, making split-second judgements about stability and survival, communicating through gestures, body language and a shared professional instinct for which there’s no linguistic substitute. And children spend the entirety of their pre-verbal months or years learning the world through playful interactions with their environments. All of this happens intuitively, automatically—a fluency machines have yet to achieve.</p><div><p><span>Spatial Intelligence is also foundational to our imagination and creativity. Storytellers create uniquely rich worlds in their minds and leverage many forms of visual media to bring them to others, from ancient cave painting to modern cinema to immersive video games. Whether it’s children building sandcastles on the beach or playing Minecraft on the computer, spatially-grounded imagination forms the basis for interactive experiences in real or virtual worlds. And in many industry applications, simulations of objects, scenes and dynamic interactive environments power countless numbers of critical business use cases from industrial design to digital twins to robotic training. </span></p><p><span>History is full of civilization-defining moments where spatial intelligence played central roles. In ancient Greece, Eratosthenes transformed shadows into geometry—measuring a 7-degree angle in Alexandria at the exact moment the sun cast no shadow in Syene—to calculate the Earth’s circumference. Hargreave’s “Spinning Jenny” revolutionized textile manufacturing through a spatial insight: arranging multiple spindles side-by-side in a single frame allowed one worker to spin multiple threads simultaneously, increasing productivity eightfold. Watson and Crick discovered DNA’s structure by physically building 3D molecular models, manipulating metal plates and wire until the spatial arrangement of base pairs clicked into place. In each case, spatial intelligence drove civilization forward when scientists and inventors had to manipulate objects, visualize structures, and reason about physical spaces - none of which can be captured in text alone.</span></p></div><p><strong>Spatial Intelligence is the scaffolding upon which our cognition is built.</strong><span> It’s at work when we passively observe or actively seek to create. It drives our reasoning and planning, even on the most abstract topics. And it’s essential to the way we interact—verbally or physically, with our peers or with the environment itself. While most of us aren’t revealing new truths on the level of Eratosthenes most days, we </span><em>routinely</em><span> think in the same way—making sense of a complex world by perceiving it through our senses, then leveraging an intuitive understanding of how it works in physical, spatial terms.</span></p><div><p><span>Unfortunately, today’s AI doesn’t think like this yet.</span></p><p><span>Tremendous progress has indeed been made in the past few years. Multimodal LLMs (MLLMs), trained with voluminous multimedia data in addition to textual data, have introduced some basics of spatial awareness, and today’s AI can analyze pictures, answer questions about them, and generate hyperrealistic images and short videos. And through breakthroughs in sensors and haptics, our most advanced robots can begin to manipulate objects and tools in highly constrained environments.</span></p></div><p>Yet the candid truth is that AI’s spatial capabilities remain far from human level. And the limits reveal themselves quickly. State-of-the-art MLLM models rarely perform better than chance on estimating distance, orientation, and size—or “mentally” rotating objects by regenerating them from new angles. They can’t navigate mazes, recognize shortcuts, or predict basic physics. AI-generated videos—nascent and yes, very cool—often lose coherence after a few seconds.</p><p>While current state-of-the-art AI can excel at reading, writing, research, and pattern recognition in data, these same models bear fundamental limitations when representing or interacting with the physical world. Our view of the world is holistic—not just what we’re looking at, but how everything relates spatially, what it means, and why it matters. Understanding this through imagination, reasoning, creation, and interaction—not just descriptions—is the power of spatial intelligence. Without it, AI is disconnected from the physical reality it seeks to understand. It cannot effectively drive our cars, guide robots in our homes and hospitals, enable entirely new ways of immersive and interactive experiences for learning and recreation, or accelerate discovery in materials science and medicine.</p><p>The philosopher Wittgenstein once wrote that “the limits of my language mean the limits of my world.” I’m not a philosopher. But I know at least for AI, there is more than just words. Spatial intelligence represents the frontier beyond language—the capability that links imagination, perception and action, and opens possibilities for machines to truly enhance human life, from healthcare to creativity, from scientific discovery to everyday assistance.</p><p>So how do we build spatially-intelligent AI? What’s the path to models capable of reasoning with the vision of Eratosthenes, engineering with the precision of an industrial designer, creating with the imagination of a storyteller, and interacting with their environment with the fluency of a first responder?</p><p>Building spatially intelligent AI requires something even more ambitious than LLMs: world models, a new type of generative models whose capabilities of understanding, reasoning, generation and interaction with the semantically, physically, geometrically and dynamically complex worlds - virtual or real - are far beyond the reach of today’s LLMs. The field is nascent, with current methods ranging from abstract reasoning models to video generation systems. World Labs was founded in early 2024 on this conviction: that foundational approaches are still being established, making this the defining challenge of the next decade.</p><p><span>In this emerging field, what matters most is establishing the principles that guide development. For spatial intelligence, I define world models through </span><strong>three essential capabilities:</strong></p><p><span>World models that unlock spatial understanding and reasoning must also generate simulated worlds of their own. They must be capable of spawning endlessly varied and diverse simulated worlds that follow semantic or perceptual instructions—</span><em>while</em><span> remaining geometrically, physically, and dynamically consistent—whether representing real or virtual spaces. The research community is actively exploring whether these worlds should be represented implicitly or explicitly in terms of the innate geometric structures. Furthermore, in addition to powerful latent representations, I believe the outputs of a universal world model must also allow the generation of an explicit, observable state of the worlds for many different use cases. In particular, its understanding of the present must be tied coherently to its past; to the previous states of the world that led to the current one.</span></p><p><span>Just as animals and humans do, a world model should be able to process inputs—known as “prompts” in the generative AI realm—in a wide range of forms. Given partial information—whether images, videos, depth maps, text instructions, gestures, or actions—world models should predict or generate world states as </span><em>complete </em><span>as possible. This requires processing visual inputs with the fidelity of real vision while interpreting semantic instructions with equal facility. This enables both agents and humans to communicate with the model about the world through diverse inputs and receive diverse outputs in return.</span></p><p><span>Finally, if actions and/or goals are part of the prompt to a world model, its outputs must include the </span><em>next</em><span> state of the world, represented either implicitly or explicitly. When given only an action with or without a goal state as the input, the world model should produce an output consistent with the world’s previous state, the intended goal state if any, and its semantic meanings, physical laws, and dynamical behaviors. As spatially intelligent world models become more powerful and robust in their reasoning and generation capabilities, it is conceivable that in the case of a given goal, the world models themselves would be able to predict not only the next state of the world, but also the next actions based on the new state.</span></p><p><strong>The scope of this challenge exceeds anything AI has faced before.</strong></p><p>While language is a purely generative phenomenon of human cognition, worlds play by much more complex rules. Here on Earth, for instance, gravity governs motion, atomic structures determine how light produces colors and brightness, and countless physical laws constrain every interaction. Even the most fanciful, creative worlds are composed of spatial objects and agents that obey the physical laws and dynamical behaviors that define them. Reconciling all of this consistently—the semantic, the geometric, the dynamic, and physical—demands entirely new approaches. The dimensionality of representing a world is vastly more complex than that of a one-dimensional, sequential signal like language. Achieving world models that deliver the kind of universal capabilities we enjoy as humans will require overcoming several formidable technical barriers. At World Labs, our research teams are devoted to making fundamental progress toward that goal.</p><p>Here are some examples of our current research topics:</p><ul><li><p><strong>A new, universal task function for training: </strong><span>Defining a universal task function as simple and elegant as next-token prediction in LLMs has long been a central goal of world model research. The complexities of both their input and output spaces make such a function inherently more difficult to formulate. But while much remains to be explored, this objective function and corresponding representations must reflect the laws of geometry and physics, honoring the fundamental nature of world models as grounded representations of both imagination and reality.</span></p></li><li><p><strong>Large-scale training data</strong><span>:</span><strong> </strong><span>Training world models requires far more complex data than text curation. The promising news: massive data sources already exist. Internet-scale collections of images and videos represent abundant, accessible training material—the challenge lies in developing algorithms that can extract deeper spatial information from these two-dimensional image or video frame-based signals (i.e. RGB). Research over the past decade has shown the power of scaling laws linking data volume and model size in language models; the key unlock for world models is building architectures that can leverage existing visual data at comparable scale. In addition, I would not underestimate the power of high-quality synthetic data and additional modalities like depth and tactile information. They supplement the internet scale data in critical steps of the training process. But the path forward depends on better sensor systems, more robust signal extraction algorithms, and far more powerful neural simulation methods.</span></p></li><li><p><strong>New model architecture and representational learning: </strong><span>World model research will inevitably drive advances in model architecture and learning algorithms, particularly beyond the current MLLM and video diffusion paradigms. Both of these typically tokenize data into 1D or 2D sequences, which makes simple spatial tasks unnecessarily difficult - like counting unique chairs in a short video, or remembering what a room looked like an hour ago. Alternative architectures may help, such as 3D or 4D-aware methods for tokenization, context, and memory. For example, at World Labs, our recent work on a real-time generative frame-based model called RTFM has demonstrated this shift, which uses spatially-grounded frames as a form of spatial memory to achieve efficient real-time generation while maintaining persistence in the generated world.</span></p></li></ul><p>Clearly, we are still facing daunting challenges before we can fully unlock spatial intelligence through world modeling. This research isn’t just a theoretical exercise. It is the core engine for a new class of creative and productivity tools. And the progress within World Labs has been encouraging. We recently shared with a limited number of users a glimpse of Marble, the first ever world model that can be prompted by multimodal inputs to generate and maintain consistent 3D environments for users and storytellers to explore, interact with, and build further in their creative workflow. And we are working hard to make it available to the public soon!</p><p>Marble is only our first step in creating a truly spatially intelligent world model. As the progress accelerates, researchers, engineers, users, and business leaders alike are beginning to recognize its extraordinary potential. The next generation of world models will enable machines to achieve spatial intelligence on an entirely new level—an achievement that will unlock essential capabilities still largely absent from today’s AI systems.</p><p><strong>It matters what motivates the development of AI. </strong><span>As one of the scientists who helped usher in the era of modern AI, my motivation has always been clear: AI must augment human capability, not replace it. For years, I’ve worked to align AI development, deployment, and governance with human needs. Extreme narratives of techno-utopia and apocalypse are abundant these days, but I continue to hold a more pragmatic view: AI is developed by people, used by people, and governed by people. It must always respect the agency and dignity of people. Its magic lies in extending our capabilities; making us more creative, connected, productive, and fulfilled. Spatial intelligence represents this vision—AI that empowers human creators, caregivers, scientists, and dreamers to achieve what was once impossible. This belief is what drives my commitment to spatial intelligence as AI’s next great frontier. </span></p><p>The applications of spatial intelligence span varying timelines. Creative tools are emerging now—World Labs’ Marble already puts these capabilities in creators’ and storytellers’ hands. Robotics represents an ambitious mid-term horizon as we refine the loop between perception and action. The most transformative scientific applications will take longer but promise a profound impact on human flourishing.</p><p>Across all these timelines, several domains stand out for their potential to reshape human capability. It will take significant collective effort, more than a single team or a company can possibly achieve. It will require participation across the entire AI ecosystem—researchers, innovators, entrepreneurs, companies, and even policymakers—working toward a shared vision. But this vision is worth pursuing. Here’s what that future holds:</p><p>“Creativity is intelligence having fun.” This is one of my favorite quotes by my personal hero Albert Einstein. Long before written language, humans told stories—painted them on cave walls, passed them through generations, built entire cultures on shared narratives. Stories are how we make sense of the world, connect across distance and time, explore what it means to be human, and most importantly, find meaning in life and love within ourselves. Today, spatial intelligence has the potential to transform how we create and experience narratives in ways that honor their fundamental importance, and extend their impacts from entertainment to education, from design to construction.</p><p>World Labs’ Marble platform will be putting unprecedented spatial capabilities and editorial controllability in the hands of filmmakers, game designers, architects, and storytellers of all kinds, allowing them to rapidly create and iterate on fully explorable 3D worlds without the overhead of conventional 3D design software. The creative act remains as vital and human as ever; the AI tools simply amplify and accelerate what creators can achieve. This includes:</p><ul><li><p>Narrative experiences in new dimensions: Filmmakers and game designers are using Marble to conjure entire worlds without the constraints of budget or geography, exploring varieties of scenes and perspectives that would have been intractable to explore within a traditional production pipeline. As the lines between different forms of media and entertainment blur, we’re approaching fundamentally new kinds of interactive experiences that blend art, simulation, and play—personalized worlds where anyone, not just studios, can create and inhabit their own stories. With the rise of newer, more rapid ways to lift concepts and storyboards into full experiences, narratives will no longer be bound to a single medium, with creators free to build worlds with shared throughlines across myriad surfaces and platforms.</p></li><li><p>Spatial narratives through design: Essentially every manufactured object or constructed space must be designed in virtual 3D before its physical creation. This process is highly iterative and costly in terms of both time and money. With spatially intelligent models at their disposal, architects can quickly visualize structures before investing months into designs, walking through spaces that don’t yet exist—essentially telling stories about how we might live, work, and gather. Industrial and fashion designers can translate imagination into form instantly, exploring how objects interact with human bodies and spaces.</p></li><li><p>New immersive and interactive experiences: Experience itself is one of the deepest ways that we, as a species, create meaning. For the entirety of human history, there has been one singular 3D world: the physical one we all share. Only in recent decades, through gaming and early virtual reality ( VR), have we begun to glimpse what it means to share alternate worlds of our own creation. Now, spatial intelligence combined with new form factors, like VR and extended reality (XR) headsets and immersive displays, elevates these experiences in unprecedented ways. We’re approaching a future where stepping into fully realized multi-dimensional worlds becomes as natural as opening a book. Spatial intelligence makes world-building accessible not just to studios with professional production teams but to individual creators, educators, and anyone with a vision to share.</p></li></ul><p>Animals from insects to humans depend on spatial intelligence to understand, navigate and interact with their worlds. Robots will be no different. Spatially-aware machines have been the dream of the field since its inception, including my own work with my students and collaborators at my Stanford research lab. This is also why I’m so excited by the possibility of bringing them about using the kinds of models World Labs is building.</p><ul><li><p><strong>Scaling robotic learning via world models:</strong><span> The progress of robotic learning hinges on a scalable solution of viable training data. Given the enormous state spaces of possibilities that robots have to learn to understand, reason, plan, and interact with, many have conjectured that a combination of internet data, synthetic simulation, and real-world capture of human demonstration are required to truly create generalizable robots. But unlike language models, training data is scarce for today’s robotic research. World models will play a defining role in this. As they increase their perceptual fidelity and computational efficiency, outputs of world models can rapidly close the gap between simulation and reality. This will in turn help train robots across simulations of countless states, interactions and environments.</span></p></li><li><p><strong>Companions and collaborators: </strong><span>Robots as human collaborators, whether aiding scientists at the lab bench or assisting seniors living alone, can expand part of the workforce in dire need of more labour and productivity. But doing so demands spatial intelligence that perceives, reasons, plans, and acts while—and this is most important—staying empathetically aligned with human goals and behaviors. For instance, a lab robot might handle instruments so the scientist can focus on tasks needing dexterity or reasoning, while a home assistant might help an elderly person cook without diminishing their joy or autonomy. Truly spatially intelligent world models that can predict the next state or possibly even actions consistent with this expectation are critical for achieving this goal.</span></p></li><li><p><strong>Expanding forms of embodiment: </strong><span>Humanoid robots play a role in the world we’ve built for ourselves. But the full benefit of innovation will come from a far more diverse range of designs: nanobots that deliver medicine, soft robots that navigate tight spaces, and machines built for the deep sea or outer space. Whatever their form, future spatial intelligence models must integrate both the environments these robots inhabit and their own embodied perception and movement. But a key challenge in developing these robots is the lack of training data in these wide varieties of embodied form factors. World models will play a critical role in simulation data, training environments, and benchmarking tasks for these efforts.</span></p></li></ul><p>In addition to creative and robotics applications, spatial intelligence’ profound impact will also extend to fields where AI can enhance human capability in ways that save lives and accelerate discovery. I highlight below three areas of applications that can be deeply transformative, though it goes without saying the use cases of spatial intelligence are truly expansive across many more industries.</p><p><span>In </span><strong>scientific research,</strong><span> spatially intelligent systems can simulate experiments, test hypotheses in parallel, and explore environments inaccessible to humans—from deep oceans to distant planets. This technology can transform computational modeling in fields like climate science and materials research. By integrating multi-dimensional simulation with real-world data collection, these tools can lower compute barriers and extend what every laboratory can observe and understand.</span></p><p><span>In </span><strong>healthcare</strong><span>, spatial intelligence will reshape everything from laboratory to bedside. At Stanford, my students and collaborators have spent many years working with hospitals, elder care facilities, and patients at home. This experience has convinced me of spatial intelligence’s transformative potential here. AI can accelerate drug discovery by modeling molecular interactions in multi-dimensions, enhance diagnostics by helping radiologists spot patterns in medical imaging, and enable ambient monitoring systems that support patients and caregivers without replacing the human connection that healing requires, not to mention the potential of robots in helping our healthcare workers and patients in many different settings.</span></p><p><span>In </span><strong>education,</strong><span> spatial intelligence can enable immersive learning that makes abstract or complex concepts tangible, and create iterative experiences so essential to how our brains and bodies are wired in learning. In the age of AI, the need for faster and more effective learning and reskilling is particularly important for both school-aged children and adults. Students can explore cellular machinery or walk through historical events in multi-dimenality. Teachers gain tools to personalize instruction through interactive environments. Professionals—from surgeons to engineers—can safely practice complex skills in realistic simulations.</span></p><p>Across all these domains, the possibilities are boundless, but the goal remains constant: AI that augments human expertise, accelerates human discovery, and amplifies human care—not replacing the judgment, creativity, and empathy that are central for being humans.</p><p>The last decade has seen AI become a global phenomenon and an inflection point in technology, the economy, and even geopolitics. But as a researcher, educator, and now, entrepreneur, it’s still the spirit behind Turing’s 75-year-old question that inspires me most. I still share his sense of wonder. It’s what energizes me every day by the challenge of spatial intelligence.</p><p>For the first time in history, we’re poised to build machines so in tune with the physical world that we can rely on them as true partners in the greatest challenges we face. Whether accelerating how we understand diseases in the lab, revolutionizing how we tell stories, or supporting us in our most vulnerable moments due to sickness, injury, or age, we’re on the cusp of technology that elevates the aspects of life we care about most. This is a vision of deeper, richer, more empowered lives.</p><p>Almost a half billion years after nature unleashed the first glimmers of spatial intelligence in the ancestral animals, we’re lucky enough to find ourselves among the generation of technologists who may soon endow machines with the same capability—and privileged enough to harness those capabilities for the benefits of people everywhere. Our dreams of truly intelligent machines will not be complete without spatial intelligence.</p><p><span>This quest is my North Star. </span><a href="https://www.worldlabs.ai/" rel="">Join me</a><span> in pursuing it.</span></p><p data-attrs="{&quot;url&quot;:&quot;https://drfeifei.substack.com/p/from-words-to-worlds-spatial-intelligence?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://drfeifei.substack.com/p/from-words-to-worlds-spatial-intelligence?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using Generative AI in Content Production (177 pts)]]></title>
            <link>https://partnerhelp.netflixstudios.com/hc/en-us/articles/43393929218323-Using-Generative-AI-in-Content-Production</link>
            <guid>45879793</guid>
            <pubDate>Mon, 10 Nov 2025 19:28:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://partnerhelp.netflixstudios.com/hc/en-us/articles/43393929218323-Using-Generative-AI-in-Content-Production">https://partnerhelp.netflixstudios.com/hc/en-us/articles/43393929218323-Using-Generative-AI-in-Content-Production</a>, See on <a href="https://news.ycombinator.com/item?id=45879793">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main" id="content">

        <p><br><a href="#h_01K39BXBFJKBC2HEXRP00QCG8J"><em>Skip to Translations</em></a></p><h2 id="h_01K1BTNMB992RYKRQRNKWD40A6">
    <span><span><strong>Introduction&nbsp;</strong></span></span>
  </h2><p><span>Generative AI tools (GenAI)&nbsp; that allow users to rapidly generate new and creatively unique media (video, sound, text, and image) are increasingly being used across creative workflows in Content Production. At Netflix, we see these tools as valuable creative aids when used transparently and responsibly.</span></p><p>
    <span>This guidance helps filmmakers, production partners, and vendors understand when and how to use GenAI tools in production. It also offers</span><a href="#h_01K1BTNMC4RTXXMXPKW2TJJ2ZJ"><span><span><span> a practical tool</span></span></span></a><span> for assessing and enabling confident GenAI use when producing content for Netflix.&nbsp;</span>
  </p><p><span>To support global productions and stay aligned with best practices, we expect all production partners to share any intended use of GenAI with their Netflix contact, especially as new tools continue to emerge with different capabilities and risks.&nbsp;</span></p><p><span>Most low-risk use cases that follow the guiding principles below are unlikely to require legal review. However, if the output includes final deliverables, talent likeness, personal data, or third-party IP, written approval will be required before you proceed.</span></p><hr><h2 id="h_01K1BTQC952EKYY3T7SQ98G4NJ">
    <span><span><strong>TABLE OF CONTENTS</strong></span></span>
  </h2>
  <p>
    <a href="#h_01K1BTNMBC8DKAF1607XQ3S9AK"><span><span>Guiding Principles</span></span></a>
  </p>
  <p>
    <a href="#h_01K1BTNMBHW1JSCHK4914BAXDE"><span><span>What use cases always require written approval?</span></span></a>
  </p>
  <p>
    <a href="#h_01K1BTNMBHB5GW4FJW8X64KHNN"><span><span>1. Data Use</span></span></a>
  </p>
  <p>
    <a href="#h_01K1BTNMBKMP99CP2PCXZ8W3H5"><span><span>2. Creative Output</span></span></a>
  </p>
  <p>
    <a href="#h_01K1BTNMBP76KFGEWAFWAH22TA"><span><span>3. Talent &amp; Performance</span></span></a>
  </p>
  <p>
    <a href="#h_01K1BTNMBRSBGNTCCTY9DBXMV2"><span><span>4. Ethics &amp; Representation</span></span></a>
  </p>
  <p>
    <a href="#h_01K1BTNMBS130Y200ZWV3H6ZAT"><span><span>How can I ensure confidentiality and data protection?</span></span></a>
  </p>
  <p>
    <a href="#h_01K1BTNMBVFQYQNJCCMKR254VK"><span><span>Are the considerations different for final output vs temporary media?</span></span></a>
  </p>
  <p>
    <a href="#h_01K1BTNMBWWPTJJA79EFPY8NRJ"><span><span>What should we consider before using GenAI for talent enhancement?</span></span></a>
  </p>
  <p>
    <a href="#h_01K1BTNMC21630W4ZWFFS0EYP2"><span><span>What if I’m using a custom workflow or working with a vendor who is?</span></span></a>
  </p>
  <p>
    <a href="#h_01K1BTNMC3K7ECQKP84CDSQVZG"><span><span>Appendix</span></span></a>
  </p>
  <p>
    <a href="#h_01K1BTNMC4RTXXMXPKW2TJJ2ZJ"><span><span>Proposed Use Case Matrix</span></span></a>
  </p><hr><h2 id="h_01K1BTNMBC8DKAF1607XQ3S9AK">
    <span><span><strong>Guiding Principles&nbsp;</strong></span></span>
  </h2><p><span>Given the sensitivities surrounding the use of these tools and the evolving legal landscape, it is essential to act responsibly when employing generative workflows. Netflix asks partners to consider the following guiding principles before leveraging GenAI in any creative workflow:&nbsp;</span></p><ol>
    <li>
      <span>The outputs do not replicate or substantially recreate identifiable characteristics of unowned or copyrighted material, or infringe any copyright-protected works</span>
    </li>
    <li>
      <span>The generative tools used do not store, reuse, or train on production data inputs or outputs.</span>
    </li>
    <li>
      <span>Where possible, generative tools are used in an </span><a href="#h_01K1BTNMBS130Y200ZWV3H6ZAT"><span><span><span>enterprise-secured environment</span></span></span></a><span> to safeguard inputs.</span>
    </li>
    <li>
      <span>Generated material is temporary and not part of the</span><a href="#h_01K1BTNMBVFQYQNJCCMKR254VK"><span> </span><span><span><span>final deliverables</span></span></span></a><span>.</span>
    </li>
    <li>
      <span>GenAI is not used to replace or generate new </span><a href="#h_01K1BTNMBWWPTJJA79EFPY8NRJ"><span><span><span>talent performances</span></span></span><span><span> </span></span></a><span>or union-covered work without consent.</span>
    </li>
  </ol><p><span>If you can confidently say "yes" to all the above, socializing the intended use with your Netflix contact may be sufficient. If you answer “no” or “unsure” to any of these principles, escalate to your Netflix contact for more guidance before proceeding, as written approval may be required.&nbsp;</span></p><p>
    <span>If your partner vendor is using a custom GenAI workflow — meaning a pipeline built from multiple tools or models — the same principles apply. More details can be found </span><a href="#h_01K1BTNMC21630W4ZWFFS0EYP2"><span><span><span>here</span></span></span></a><span>.&nbsp;</span>
  </p><hr><h2 id="h_01K1BTNMBHW1JSCHK4914BAXDE">
    <span><span><strong>What use cases always require written approval?</strong></span></span>
  </h2><p><span>Below are a few examples of situations that, in addition to reporting intended use, always require escalation and written approval before proceeding.&nbsp;</span></p><h4 id="h_01K1BTNMBHB5GW4FJW8X64KHNN">
    <span><span><strong>1. Data Use&nbsp;</strong></span></span>
  </h4><p><span>Protecting personal data and creative rights is essential when working with GenAI. These tools often require input data to generate outputs, and how that data is handled matters. Before using any GenAI tool, especially third-party or off-the-shelf options, consider whether you are using material that requires special handling, clearance, or consent.</span></p><ul>
<li data-list-item-id="eadab2bf1f9f6c9e08da9a9e4c1e9e80b"><span>Use of Proprietary or Personal Information: Do not input Netflix-owned materials (e.g., unreleased assets, scripts, production images) or personal data (e.g., cast or crew details) into tools unless explicitly approved.</span></li>
<li data-list-item-id="eebe54d8bab43f122ac308fb7d5628a48"><span>Third-Party or Unowned Talent Assets: Do not train or fine-tune models using material from artists, performers, or other rights holders unless you have the proper legal clearance.</span></li>
</ul><p><span>Example: Training an image model in the style of another artist using a library of their past work, where Netflix or the talent has not cleared rights.</span></p><h4 id="h_01K1BTNMBKMP99CP2PCXZ8W3H5">
    <span><span><strong>2. Creative Output&nbsp;&nbsp;</strong></span></span>
  </h4><p><span>AI-generated content must be used with care, especially when it forms a visible or story-critical part of the production. Whether you're designing a world, a character, or artwork that appears in a scene, the same creative and legal standards apply as with traditionally produced assets.</span></p><ul>
    <li>
      <span>Generation of Key Creative Elements: GenAI should not be used to generate main characters, key visual elements, or fictional settings that are central to the story without written approval.</span>
      <ul>
        <li>
          <span>Examples: GenAI is used to generate a second killer doll to play the red light/green light game with Young-hee in Squid Game.</span>
        </li>
      </ul>
    </li>
    <li>
      <span>Copyrighted or Estate-Controlled: Avoid using inputs (e.g., prompts, images) that reference copyrighted materials or likenesses of public figures or deceased individuals without appropriate permissions.</span>
      <ul>
        <li>
          <span>Example: “Create an image inspired by </span><a href="https://www.stevemccurry.com/posters/p/afghan-girl"><span><span><span>McCurry’s Afghan Girl</span></span></span></a><span>” or referencing distinctive features of a known performer (e.g., “Create a character with Meryl Streep’s nose”).</span>
        </li>
      </ul>
    </li>
  </ul><h4 id="h_01K1BTNMBP76KFGEWAFWAH22TA">
    <span><span><strong>3. Talent &amp; Performance&nbsp;</strong></span></span>
  </h4><p><span>Respect for performers and their work is foundational to the responsible use of GenAI. Whether enhancing a recorded performance or generating a digital likeness, the threshold for consent and care is exceptionally high when the intent or character of a performance may be altered.</span></p><ul>
<li data-list-item-id="e4d40cb1df5caa3a3682badc50d00f86f"><span>Synthetic or Digital Replicas - Do not create digital performers, voices, or likenesses of real talent without explicit and documented consent and complying with guild requirements (where applicable).</span></li>
<li data-list-item-id="edbd78f2c674b7bf80443280ebdfc5961"><span>Significant Digital Alterations to Performances - Be cautious when making changes that affect a performance's emotional tone, delivery, or intent, as even subtle edits may have legal or reputational implications.</span></li>
</ul><p><span>Examples include visual ADR (altering lip-sync or facial performance to match new, unscripted dialogue).</span></p><h4 id="h_01K1BTNMBRSBGNTCCTY9DBXMV2">
    <span><span><strong>4. Ethics &amp; Representation</strong></span></span>
  </h4><p><span>Audiences should be able to trust what they see and hear on screen. GenAI (if used without care) can blur the line between fiction and reality or unintentionally mislead viewers. That’s why we ask you to consider both the intent and the impact of your AI-generated content.</span></p><ul>
<li data-list-item-id="e888ce79e22790a32566543967d72f687">
<span>Misleading or Misrepresentative Content: Avoid creating content that could be mistaken for real events, people, or statements if they never actually occurred (e.g., fabricated footage, dialogue, or scenes presented as authentic).</span><ul><li data-list-item-id="ed46505213321fa75e536d07d6eb5161d"><span>Example: using GenAI to create a fake news segment featuring a real journalist delivering a fabricated statement, even if intended as background.</span></li></ul>
</li>
<li data-list-item-id="ee334b51a1afff56655a98d7ab8cd583e"><span>Impact on Union Roles: Ensure that your use of GenAI does not replace or materially impact work typically done by union-represented individuals, including actors, writers, or crew members, without proper approvals or agreements.</span></li>
</ul><hr><h2 id="h_01K1BTNMBS130Y200ZWV3H6ZAT">
    <span><span><strong>How can I ensure confidentiality and data protection?</strong></span></span>
  </h2><p><span>The use of tools covered by Netflix Enterprise Agreements provides an additional level of security to protect input data. Speak with your Netflix primary contact about available tools and the onboarding process. These tools:</span></p><ul>
<li data-list-item-id="e68332c5bcee6dff16288681e7b954f32"><span>Prevent capture, training, or resale of your inputs</span></li>
<li data-list-item-id="ee904f7888a03c5358236991d6cc536f9"><span>Protect sensitive inputs like scripts, production images, or talent visuals</span></li>
</ul><p><span>Even with secure tools, any use of sensitive information (e.g., talent likeness, unreleased footage, contracts) requires escalation to your Netflix contact.</span></p><p><span>When not using enterprise tools, ensure that any AI tools, plugins, or workflows you use do not train on inputs or outputs, as using the wrong license tier or missing pre-negotiated data terms could compromise confidentiality. You are responsible for reviewing the terms and conditions (T&amp;Cs). Please check with your Netflix contact if you have any further questions.</span></p><h2 id="h_01K1BTNMBVFQYQNJCCMKR254VK">
    <span><span><strong>Are the considerations different for final output vs temporary media?</strong></span></span>
  </h2><p><span>If created with GenAI, content that appears in the final cut—even in the background—can raise legal, copyright, or trust issues with the audience. That’s why we ask you to flag any GenAI-generated elements early, especially if they will be seen or heard on screen.</span></p><p><span>If your proposed use case includes visual, audio, or text elements generated by AI (e.g., posters, documents, signage, or news clippings), contact your Netflix representative as early as possible for legal guidance. These items may require rights clearance before they can be included in final deliverables.</span></p><p><span>Some GenAI-generated props or set pieces may be considered incidental, for example, a historical document shown briefly in the background and not referenced in the scene. However, if the element is prominent (e.g., a character reads it aloud or it contributes to the story), it must be treated with greater care.</span></p><p><span>In these cases, you can use GenAI to explore ideas or mockups. Still, the final version should involve meaningful human input and follow the legal review process through your Netflix contact.</span></p><hr><h2 id="h_01K1BTNMBWWPTJJA79EFPY8NRJ">
    <span><span><strong>What should we consider before using GenAI for talent enhancement?</strong></span></span>
  </h2><p><span>There is a long tradition of digitally altering performances in post-production and VFX. However, the use of AI to modify or replicate a performer's likeness or voice introduces new legal, ethical, and reputational challenges. Therefore, obtaining consent when appropriate and exercising caution are crucial. Many talent enhancement use cases require legal review, so please plan accordingly. Here are some guidelines to consider:&nbsp;</span></p><ul><li data-list-item-id="ee650de448e890ec3259cea9e3f215d7e"><span>If creating a Digital Replica (i.e., a generated output recognizable as the voice and/or likeness of an identifiable performer for the purpose of portraying them in photography or soundtrack, they did not perform), consent is required. No further consent is needed to use the Digital Replica if the performance output: (1)&nbsp; remains substantially as scripted, performed, or recorded (e.g. reshoots); (2) depicts activities incapable of being performed by a human for safety reasons; or (3) results in the performer being unrecognizable (e.g. wearing a mask).</span></li></ul><ul><li data-list-item-id="eb553309b5b4c9280624005c8b8dc3be7">
<span>Digital Alterations: Consent is generally required for digital alterations, except for those customarily done in the entertainment and film industry, such as:</span><ul>
<li data-list-item-id="eabb77a1e3013a0ba03166f275032945d"><span>Alterations where the photography or soundtrack remains substantially as scripted, performed, or recorded.</span></li>
<li data-list-item-id="efca531cce7e6caef547165f10ea1d4b8"><span>Post-production changes for cosmetics, wardrobe, noise reduction, timing, continuity, pitch, clarity, and similar purposes.</span></li>
<li data-list-item-id="eff26a574f34290ce1b409f9286abfc71"><span>Circumstances where dubbing or using a double is permitted under existing agreements.</span></li>
</ul>
</li></ul><ul>
<li data-list-item-id="e8933fe8b834666f88ca2ce7cbdcac1e3">
<span>Model Usage:</span><ul>
<li data-list-item-id="ed72a3c2d1a0ab668c016f69220395448"><span>Any models trained to perform talent enhancement manipulation should be used solely for the production in question and within the scope of work agreed upon with the talent.</span></li>
<li data-list-item-id="e6803efcc74ee2497779461493a153e3b"><span>Models must not be used to create an actor's performance in another production, pitch, or concept without the express consent of all parties involved.</span></li>
</ul>
</li>
<li data-list-item-id="e77b0d872f73d494f71a7f67478e8f380">
<span>Quality Assurance:</span><ul>
<li data-list-item-id="e53f9b4c6a212869163f0a58c2be99a55"><span>Perform early tests to ensure that the quality of the outputs is acceptable both creatively and technically, so as not to adversely affect the talent’s original performance.</span></li>
<li data-list-item-id="ed9502f1976cbd6ba189c9683079d054a"><span>Where applicable and practical, plan dedicated data capture sessions with the talent to ensure the best possible outcomes.</span></li>
<li data-list-item-id="ee61ab0b5412c6f71ec8bcbc931106d3d"><span>Avoid enhancements that could harm the actor’s reputation, dignity, or personal image.</span></li>
</ul>
</li>
</ul><p><span>By following these guidelines, you can navigate the complexities of using AI in creative workflows while respecting the rights and integrity of performers.</span></p><hr><h2 id="h_01K1BTNMC21630W4ZWFFS0EYP2">
    <span><span><strong>What if I’m using a custom workflow or working with a vendor who is?</strong></span></span>
  </h2><p><span>For vendors: If you're delivering work to Netflix using a custom GenAI workflow built from multiple tools, each step in the pipeline must meet our standards for data protection, consent, and content integrity as outlined in this document.&nbsp;</span></p><p><span>For production partners: If you're hiring a vendor or AI studio, use this guidance as a framework to help assess how they manage data, creative control, and final outputs. If you are unsure whether the pipeline meets the expectations outlined in this guidance, seek guidance from your Netflix contact.&nbsp;</span></p><hr><h2 id="h_01K1BTNMC3K7ECQKP84CDSQVZG">
    <span><span><strong>Appendix</strong></span></span>
  </h2>
  <h3 id="h_01K1BTNMC4RTXXMXPKW2TJJ2ZJ">
    <span><span><strong>Proposed Use Case Matrix</strong></span></span>
  </h3><p><span>We have provided a&nbsp; Proposed Use Case Matrix at the end of this guidance as a tool to triage your proposed use case quickly.&nbsp;</span></p><div><figure><table>
<colgroup>
<col>
<col>
<col>
</colgroup>
<tbody>
<tr>
<td><span><strong>Proposed Use Case</strong></span></td>
<td><span><strong>Action&nbsp;</strong></span></td>
<td><span><strong>Rationale</strong></span></td>
</tr>
<tr>
<td><span>Using GenAI for ideation only (moodboards, reference images)</span></td>
<td><span>✅</span></td>
<td><span>Low risk, non-final, likely not needing escalation if guiding principles are followed.</span></td>
</tr>
<tr>
<td><span>Using GenAI to generate background elements (e.g., signage, posters) that appear on camera</span></td>
<td><span><img src="https://partnerhelp.netflixstudios.com/hc/article_attachments/43813746061587" alt=":warning:" width="23" height="23"></span></td>
<td><span>Use judgment: Incidental elements may be low risk, but if story-relevant, please escalate.&nbsp;</span></td>
</tr>
<tr>
<td><span>Using GenAI to create final character designs or key visuals</span></td>
<td><span><img src="https://partnerhelp.netflixstudios.com/hc/article_attachments/43813724428819" alt=":octagonal_sign:" width="23" height="23">&nbsp;</span></td>
<td><span>Requires escalation as it could impact legal rights, audience perception, or union roles.</span></td>
</tr>
<tr>
<td><span>Using GenAI for talent replication (re-ageing, or synthetic voices)</span></td>
<td><span><img src="https://partnerhelp.netflixstudios.com/hc/article_attachments/43813724428819" alt=":octagonal_sign:" width="23" height="23"></span></td>
<td><span>Requires escalation for consent and legal review.&nbsp;</span></td>
</tr>
<tr>
<td><span>Using unowned&nbsp; training data (e.g., celebrity faces, copyrighted art)</span></td>
<td><span><img src="https://partnerhelp.netflixstudios.com/hc/article_attachments/43813724428819" alt=":octagonal_sign:" width="23" height="23"></span></td>
<td><span>Needs escalation due to copyright and other rights risk.</span></td>
</tr>
<tr>
<td><span>Using Netflix's proprietary material</span></td>
<td><span><img src="https://partnerhelp.netflixstudios.com/hc/article_attachments/43813746061587" alt=":warning:" width="23" height="23"></span></td>
<td>
<p><span>Needs escalation for review if outside secure enterprise tools.</span></p>

</td>
</tr>
</tbody>
</table></figure></div><h3 id="h_01K39BXBFJKBC2HEXRP00QCG8J">
  <br>
  <span><span><strong>Translations</strong></span></span>
</h3><p><a href="https://drive.google.com/file/d/1OhOJXv6cwcc8Ob61K_zuxOxxzJst5V-V/view?usp=drive_link" target="_blank" rel="noopener noreferrer"><span data-sheets-root="1">Español (Latinoamérica)</span></a></p><p><a href="https://drive.google.com/file/d/1PcVBUivo-CYSIj_fXMjPwS9lh6WC9WlT/view?usp=sharing" target="_blank" rel="noopener noreferrer"><span data-sheets-root="1">Français</span></a></p><p><a href="https://drive.google.com/file/d/16v2PFCYKk08s0o37kHJ4LZmr6n5cdxia/view?usp=drive_link" target="_blank" rel="noopener noreferrer"><span data-sheets-root="1">Português</span></a></p><p><a href="https://drive.google.com/file/d/122a0P_EASxSQ2CklK2Tnm6N4CjrbC92h/view?usp=drive_link" target="_blank" rel="noopener noreferrer"><span data-sheets-root="1">ไทย</span></a></p><p><a href="https://drive.google.com/file/d/1Gr8ml-b9QSoWLkZkN18p03uNVQs5Aj2X/view?usp=drive_link" target="_blank" rel="noopener noreferrer"><span data-sheets-root="1">Türkçe</span></a></p><p><a href="https://drive.google.com/file/d/1wU1Q6zTd7zt7G7umgtk2VRepkGAwruA8/view?usp=drive_link" target="_blank" rel="noopener noreferrer"><span data-sheets-root="1">繁體中文</span></a></p>
        
        
        <section>

          <span>Was this article helpful?</span>
          
          <small>
            <span data-helper="vote" data-item="article" data-type="label" data-id="43393929218323" data-upvote-count="121" data-vote-count="128" data-vote-sum="114" data-vote-url="/hc/en-us/articles/43393929218323/vote" data-value="null" data-label="121 out of 128 found this helpful">121 out of 128 found this helpful</span>
          </small>
        </section>
        
   
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Redmond, WA, turns off Flock Safety cameras after ICE arrests (352 pts)]]></title>
            <link>https://www.seattletimes.com/seattle-news/law-justice/redmond-turns-off-flock-safety-cameras-after-ice-arrests/</link>
            <guid>45879101</guid>
            <pubDate>Mon, 10 Nov 2025 18:30:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seattletimes.com/seattle-news/law-justice/redmond-turns-off-flock-safety-cameras-after-ice-arrests/">https://www.seattletimes.com/seattle-news/law-justice/redmond-turns-off-flock-safety-cameras-after-ice-arrests/</a>, See on <a href="https://news.ycombinator.com/item?id=45879101">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-content">
    <p>Redmond police turned off their city’s Flock Safety cameras last week after masked, unidentified officers — later identified as U.S. Immigration and Customs Enforcement agents — arrested seven people, at least three less than a mile from  one or more of the city’s cameras.</p><p>During a City Council session Oct. 27, Redmond police Chief Darrell Lowe said no federal agency had accessed the city’s Flock data, but agreed to suspend officers’ access to the system until city officials had discussed ending Redmond’s contract with the company.&nbsp;</p><p>Redmond City Council member Angie Nuevacamina said Thursday the proximity of the arrests to some of the city’s cameras was coincidental, and not because ICE had “somehow tapped into” Redmond’s Flock cameras or data. The city suspended its Flock system because city officials could not guarantee they wouldn’t be forced to release data collected by those devices someday, she said.</p><p>Their concerns may have been prescient.</p><p>On Thursday, a Skagit County Superior Court judge ruled that pictures taken by Flock cameras in the cities of Sedro-Woolley and Stanwood qualify as public records, and therefore must be released as required by the state’s Public Records Act, court records show<strong>.</strong></p><p>Flock’s cameras, also called automated license plate readers, continuously and indiscriminately capture time- and location-stamped photos of any passing vehicles. Those images are then stored, and information about the vehicles, including their condition, make, model and license plate number, is added to a searchable database controlled by the customer.</p><p>Last week’s Skagit County ruling could oblige the dozens of Washington police agencies which use Flock cameras, ostensibly to help them find stolen vehicles, crime suspects and missing people, to release the photos and data they collect — an outcome privacy advocates warned was possible.</p>
<div>
      <h3>
        Related
        
      </h3>
      

      
        
    

      </div><p>The ruling also exacerbated concerns about potential misuse of Flock data, which swelled after University of Washington researchers released <a href="https://www.seattletimes.com/seattle-news/law-justice/feds-searched-flock-security-systems-at-18-wa-police-agencies-report/">a report Oct. 21</a> showing federal immigration agencies like ICE and Border Patrol had accessed the data of at least 18 Washington cities, often without their police departments’ knowing. The report raised concerns that the agencies might be using the data to target and arrest immigrants as part of Trump’s immigration crackdown.</p><p>Redmond was the latest in a string of Flock-using, Seattle-area cities to <a href="https://www.seattletimes.com/seattle-news/law-justice/feds-searched-flock-security-systems-at-18-wa-police-agencies-report/">change their surveillance programs</a> in the last three weeks in response to those concerns.</p><p>Police officials in Renton, Auburn, Mukilteo and Lakewood, Pierce County, changed their Flock settings after the UW report showed federal agencies had accessed their Flock data. The agencies never requested permission to access their cities’ data, and the respective police departments weren’t aware it happened until after UW researchers notified them or they saw the report, the officials said.</p><p>Redmond’s Police Department was not among those listed in the report, and has never allowed external agencies to access their Flock data without requesting and receiving permission from the police chief first, according to an <a href="https://www.redmond.gov/CivicAlerts.aspx?AID=2698" target="_blank">Oct. 24 statement</a> by Lowe.</p><p>But concerns about the cameras, and potential misuse of the data they collect, still swirled among Redmond residents and City Council members after photos and videos began circulating online last Monday of masked, unidentified officers emerging from unmarked cars and arresting people in town.</p><p>Three arrests by ICE at Redmond’s Bear Creek Village shopping center, the parking lot of a Home Depot and near the intersection of Avondale Road Northeast and Novelty Hill Road Northeast all happened within a half-mile of at least one of Redmond’s 24 Flock cameras, according to a partial list of their locations provided through a public disclosure request.</p>
<p>The city installed most of its cameras on Redmond’s “main thoroughfares” in May and began using them in June, according to Nuevacamina and Redmond police spokesperson Jill Green. </p><p>Though Lowe confirmed no federal agencies had accessed Redmond’s Flock system, Nuevacamina said residents’ and city officials’ concerns about the technology were still strong enough to support turning the cameras off. The step was also one of the few things city officials could do to help residents who felt powerless that day, as Redmond’s police officers were not allowed to intervene in ICE activity, and residents could not either without risking arrest or their own personal safety, she said.</p><p>Turning off Redmond’s Flock cameras was what the city had in its “tool belt to be able to protect and stand up for (their) community,” Nuevacamina said.</p><p>In a statement Saturday, Tricia McLaughlin, the Department of Homeland Security’s assistant secretary, confirmed ICE agents arrested seven people Nov. 3 in Redmond. McLaughlin’s statement did not identify those arrested but accused all of them of being in the country illegally.</p><p>Flock Safety is communicating with Redmond city officials to address their concerns and hopefully convince them to reverse their decision, the company’s chief legal officer, Dan Haley, said in a phone call Friday. The company is also advocating for legislation that would prevent people from “taking advantage of” Washington’s public records law, Haley said.</p><p>Flock can be made to release data collected by its technology through a subpoena or court order, Haley said, but the company would not do so without notifying and involving its customer first. The cameras also only capture what anyone could see on a public road, where there is no legal expectation of privacy, he said.  </p>
<p>Communities must balance concerns they have about Flock cameras against what Haley called the “very real outcomes” of using the technology: “these are kidnapped kids returned home, elderly people with dementia found quickly.”</p><p>For now, all Redmond police officers’ access to the city’s Flock data has been turned off. Two Police Department employees can access the data, but only to fulfill public records requests, and two police administrators can access — but not search — the data. A “disconnect signal” was also sent Tuesday morning to all of the cameras, which will stop them from taking and storing photos, Redmond police officials said.</p><p>During the Oct. 27 City Council session, Lowe said he would meet with Redmond Mayor Angela Birney Nov. 18 to “see where we go from here.”</p><p>Redmond City Council President Vanessa Kristzer said she had “grave concerns” about continuing to use Flock’s technology.</p><p>“We will continue to explore every avenue to be able to keep our community members safe and their dignity and human rights protected,” Kristzer said.</p>    
        <div>
   <p><span>Catalina Gaitán</span>:       <span>206-464-8276</span> or <span><a href="mailto:cgaitan@seattletimes.com">cgaitan@seattletimes.com</a></span>. <span>Catalina Gaitán is a breaking news reporter at The Seattle Times.</span>   </p>
</div>
  </div></div>]]></description>
        </item>
    </channel>
</rss>