<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 19 Jun 2025 16:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: Claude Code Usage Monitor ‚Äì real-time tracker to dodge usage cut-offs (114 pts)]]></title>
            <link>https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor</link>
            <guid>44317012</guid>
            <pubDate>Thu, 19 Jun 2025 09:46:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor">https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor</a>, See on <a href="https://news.ycombinator.com/item?id=44317012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">üéØ Claude Code Usage Monitor</h2><a id="user-content--claude-code-usage-monitor" aria-label="Permalink: üéØ Claude Code Usage Monitor" href="#-claude-code-usage-monitor"></a></p>
<p dir="auto"><a href="https://python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/dec1d99c8e1ae20b8b158f2c346d5762e185f4b00fce1ef873f83115b84ee974/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362b2d626c75652e737667" alt="Python Version" data-canonical-src="https://img.shields.io/badge/python-3.6+-blue.svg"></a>
<a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/6cd0120cc4c5ac11d28b2c60f76033b52db98dac641de3b2644bb054b449d60c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/License-MIT-yellow.svg"></a>
<a href="http://makeapullrequest.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/d88d8d77fa79e828eea397f75a1ebd114d13488aeec4747477ffbd2274de95ed/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e737667" alt="PRs Welcome" data-canonical-src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg"></a></p>
<p dir="auto">A beautiful real-time terminal monitoring tool for Claude AI token usage. Track your token consumption, burn rate, and get predictions about when you'll run out of tokens.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/doc/sc.png"><img src="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/raw/main/doc/sc.png" alt="Claude Token Monitor Screenshot"></a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üìë Table of Contents</h2><a id="user-content--table-of-contents" aria-label="Permalink: üìë Table of Contents" href="#-table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#-key-features">‚ú® Key Features</a></li>
<li><a href="#-installation">üöÄ Installation</a>
<ul dir="auto">
<li><a href="#-quick-start">‚ö° Quick Start</a></li>
<li><a href="#-production-setup-recommended">üîí Production Setup (Recommended)</a></li>
<li><a href="#virtual-environment-setup">Virtual Environment Setup</a></li>
</ul>
</li>
<li><a href="#-usage">üìñ Usage</a>
<ul dir="auto">
<li><a href="#basic-usage">Basic Usage</a></li>
<li><a href="#configuration-options">Configuration Options</a></li>
<li><a href="#available-plans">Available Plans</a></li>
</ul>
</li>
<li><a href="#-features--how-it-works">‚ú® Features &amp; How It Works</a>
<ul dir="auto">
<li><a href="#current-features">Current Features</a></li>
<li><a href="#understanding-claude-sessions">Understanding Claude Sessions</a></li>
<li><a href="#token-limits-by-plan">Token Limits by Plan</a></li>
<li><a href="#smart-detection-features">Smart Detection Features</a></li>
</ul>
</li>
<li><a href="#-usage-examples">üöÄ Usage Examples</a>
<ul dir="auto">
<li><a href="#common-scenarios">Common Scenarios</a></li>
<li><a href="#best-practices">Best Practices</a></li>
</ul>
</li>
<li><a href="#-contact">üìû Contact</a></li>
<li><a href="#-additional-documentation">üìö Additional Documentation</a></li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">‚ú® Key Features</h2><a id="user-content--key-features" aria-label="Permalink: ‚ú® Key Features" href="#-key-features"></a></p>
<ul dir="auto">
<li><strong>üîÑ Real-time monitoring</strong> - Updates every 3 seconds with smooth refresh</li>
<li><strong>üìä Visual progress bars</strong> - Beautiful color-coded token and time progress bars</li>
<li><strong>üîÆ Smart predictions</strong> - Calculates when tokens will run out based on current burn rate</li>
<li><strong>ü§ñ Auto-detection</strong> - Automatically switches to custom max when Pro limit is exceeded</li>
<li><strong>üìã Multiple plan support</strong> - Works with Pro, Max5, Max20, and auto-detect plans</li>
<li><strong><g-emoji alias="warning">‚ö†Ô∏è</g-emoji> Warning system</strong> - Alerts when tokens exceed limits or will deplete before session reset</li>
<li><strong>üíº Professional UI</strong> - Clean, colorful terminal interface with emojis</li>
<li><strong>‚è∞ Customizable scheduling</strong> - Set your own reset times and timezones</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üöÄ Installation</h2><a id="user-content--installation" aria-label="Permalink: üöÄ Installation" href="#-installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">‚ö° Quick Start</h3><a id="user-content--quick-start" aria-label="Permalink: ‚ö° Quick Start" href="#-quick-start"></a></p>
<p dir="auto">For immediate testing (not recommended for regular use):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install dependencies
npm install -g ccusage
pip install pytz

# Clone and run
git clone https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor.git
cd Claude-Code-Usage-Monitor
python ccusage_monitor.py"><pre><span><span>#</span> Install dependencies</span>
npm install -g ccusage
pip install pytz

<span><span>#</span> Clone and run</span>
git clone https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor.git
<span>cd</span> Claude-Code-Usage-Monitor
python ccusage_monitor.py</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">üîí Production Setup (Recommended)</h3><a id="user-content--production-setup-recommended" aria-label="Permalink: üîí Production Setup (Recommended)" href="#-production-setup-recommended"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Prerequisites</h4><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<ol dir="auto">
<li><strong>Python 3.6+</strong> installed on your system</li>
<li><strong>Node.js</strong> for ccusage CLI tool</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Virtual Environment Setup</h3><a id="user-content-virtual-environment-setup" aria-label="Permalink: Virtual Environment Setup" href="#virtual-environment-setup"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Why Use Virtual Environment?</h4><a id="user-content-why-use-virtual-environment" aria-label="Permalink: Why Use Virtual Environment?" href="#why-use-virtual-environment"></a></p>
<p dir="auto">Using a virtual environment is <strong>strongly recommended</strong> because:</p>
<ul dir="auto">
<li><strong>üõ°Ô∏è Isolation</strong>: Keeps your system Python clean and prevents dependency conflicts</li>
<li><strong>üì¶ Portability</strong>: Easy to replicate the exact environment on different machines</li>
<li><strong>üîÑ Version Control</strong>: Lock specific versions of dependencies for stability</li>
<li><strong>üßπ Clean Uninstall</strong>: Simply delete the virtual environment folder to remove everything</li>
<li><strong>üë• Team Collaboration</strong>: Everyone uses the same Python and package versions</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installing virtualenv (if needed)</h4><a id="user-content-installing-virtualenv-if-needed" aria-label="Permalink: Installing virtualenv (if needed)" href="#installing-virtualenv-if-needed"></a></p>
<p dir="auto">If you don't have <code>venv</code> module available:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Ubuntu/Debian
sudo apt-get update
sudo apt-get install python3-venv

# Fedora/RHEL/CentOS
sudo dnf install python3-venv

# macOS (usually comes with Python)
# If not available, install Python via Homebrew:
brew install python3

# Windows (usually comes with Python)
# If not available, reinstall Python from python.org
# Make sure to check &quot;Add Python to PATH&quot; during installation"><pre><span><span>#</span> Ubuntu/Debian</span>
sudo apt-get update
sudo apt-get install python3-venv

<span><span>#</span> Fedora/RHEL/CentOS</span>
sudo dnf install python3-venv

<span><span>#</span> macOS (usually comes with Python)</span>
<span><span>#</span> If not available, install Python via Homebrew:</span>
brew install python3

<span><span>#</span> Windows (usually comes with Python)</span>
<span><span>#</span> If not available, reinstall Python from python.org</span>
<span><span>#</span> Make sure to check "Add Python to PATH" during installation</span></pre></div>
<p dir="auto">Alternatively, use the <code>virtualenv</code> package:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install virtualenv via pip
pip install virtualenv

# Then create virtual environment with:
virtualenv venv
# instead of: python3 -m venv venv"><pre><span><span>#</span> Install virtualenv via pip</span>
pip install virtualenv

<span><span>#</span> Then create virtual environment with:</span>
virtualenv venv
<span><span>#</span> instead of: python3 -m venv venv</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step-by-Step Setup</h4><a id="user-content-step-by-step-setup" aria-label="Permalink: Step-by-Step Setup" href="#step-by-step-setup"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# 1. Install ccusage globally
npm install -g ccusage

# 2. Clone the repository
git clone https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor.git
cd Claude-Code-Usage-Monitor

# 3. Create virtual environment
python3 -m venv venv
# Or if using virtualenv package:
# virtualenv venv

# 4. Activate virtual environment
# On Linux/Mac:
source venv/bin/activate
# On Windows:
# venv\Scripts\activate

# 5. Install Python dependencies
pip install pytz

# 6. Make script executable (Linux/Mac only)
chmod +x ccusage_monitor.py

# 7. Run the monitor
python ccusage_monitor.py"><pre><span><span>#</span> 1. Install ccusage globally</span>
npm install -g ccusage

<span><span>#</span> 2. Clone the repository</span>
git clone https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor.git
<span>cd</span> Claude-Code-Usage-Monitor

<span><span>#</span> 3. Create virtual environment</span>
python3 -m venv venv
<span><span>#</span> Or if using virtualenv package:</span>
<span><span>#</span> virtualenv venv</span>

<span><span>#</span> 4. Activate virtual environment</span>
<span><span>#</span> On Linux/Mac:</span>
<span>source</span> venv/bin/activate
<span><span>#</span> On Windows:</span>
<span><span>#</span> venv\Scripts\activate</span>

<span><span>#</span> 5. Install Python dependencies</span>
pip install pytz

<span><span>#</span> 6. Make script executable (Linux/Mac only)</span>
chmod +x ccusage_monitor.py

<span><span>#</span> 7. Run the monitor</span>
python ccusage_monitor.py</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Daily Usage</h4><a id="user-content-daily-usage" aria-label="Permalink: Daily Usage" href="#daily-usage"></a></p>
<p dir="auto">After initial setup, you only need:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Navigate to project directory
cd Claude-Code-Usage-Monitor

# Activate virtual environment
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Run monitor
./ccusage_monitor.py  # Linux/Mac
# python ccusage_monitor.py  # Windows

# When done, deactivate
deactivate"><pre><span><span>#</span> Navigate to project directory</span>
<span>cd</span> Claude-Code-Usage-Monitor

<span><span>#</span> Activate virtual environment</span>
<span>source</span> venv/bin/activate  <span><span>#</span> Linux/Mac</span>
<span><span>#</span> venv\Scripts\activate   # Windows</span>

<span><span>#</span> Run monitor</span>
./ccusage_monitor.py  <span><span>#</span> Linux/Mac</span>
<span><span>#</span> python ccusage_monitor.py  # Windows</span>

<span><span>#</span> When done, deactivate</span>
deactivate</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Pro Tip: Shell Alias</h4><a id="user-content-pro-tip-shell-alias" aria-label="Permalink: Pro Tip: Shell Alias" href="#pro-tip-shell-alias"></a></p>
<p dir="auto">Create an alias for quick access:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Add to ~/.bashrc or ~/.zshrc
alias claude-monitor='cd ~/Claude-Code-Usage-Monitor &amp;&amp; source venv/bin/activate &amp;&amp; ./ccusage_monitor.py'

# Then just run:
claude-monitor"><pre><span><span>#</span> Add to ~/.bashrc or ~/.zshrc</span>
<span>alias</span> claude-monitor=<span><span>'</span>cd ~/Claude-Code-Usage-Monitor &amp;&amp; source venv/bin/activate &amp;&amp; ./ccusage_monitor.py<span>'</span></span>

<span><span>#</span> Then just run:</span>
claude-monitor</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üìñ Usage</h2><a id="user-content--usage" aria-label="Permalink: üìñ Usage" href="#-usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic Usage</h3><a id="user-content-basic-usage" aria-label="Permalink: Basic Usage" href="#basic-usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Default (Pro plan - 7,000 tokens)
./ccusage_monitor.py

# Exit the monitor
# Press Ctrl+C to gracefully exit"><pre><span><span>#</span> Default (Pro plan - 7,000 tokens)</span>
./ccusage_monitor.py

<span><span>#</span> Exit the monitor</span>
<span><span>#</span> Press Ctrl+C to gracefully exit</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configuration Options</h3><a id="user-content-configuration-options" aria-label="Permalink: Configuration Options" href="#configuration-options"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Specify Your Plan</h4><a id="user-content-specify-your-plan" aria-label="Permalink: Specify Your Plan" href="#specify-your-plan"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Pro plan (~7,000 tokens) - Default
./ccusage_monitor.py --plan pro

# Max5 plan (~35,000 tokens)
./ccusage_monitor.py --plan max5

# Max20 plan (~140,000 tokens)
./ccusage_monitor.py --plan max20

# Auto-detect from highest previous session
./ccusage_monitor.py --plan custom_max"><pre><span><span>#</span> Pro plan (~7,000 tokens) - Default</span>
./ccusage_monitor.py --plan pro

<span><span>#</span> Max5 plan (~35,000 tokens)</span>
./ccusage_monitor.py --plan max5

<span><span>#</span> Max20 plan (~140,000 tokens)</span>
./ccusage_monitor.py --plan max20

<span><span>#</span> Auto-detect from highest previous session</span>
./ccusage_monitor.py --plan custom_max</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Custom Reset Times</h4><a id="user-content-custom-reset-times" aria-label="Permalink: Custom Reset Times" href="#custom-reset-times"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Reset at 3 AM
./ccusage_monitor.py --reset-hour 3

# Reset at 10 PM
./ccusage_monitor.py --reset-hour 22"><pre><span><span>#</span> Reset at 3 AM</span>
./ccusage_monitor.py --reset-hour 3

<span><span>#</span> Reset at 10 PM</span>
./ccusage_monitor.py --reset-hour 22</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Timezone Configuration</h4><a id="user-content-timezone-configuration" aria-label="Permalink: Timezone Configuration" href="#timezone-configuration"></a></p>
<p dir="auto">The default timezone is <strong>Europe/Warsaw</strong>. Change it to any valid timezone:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Use US Eastern Time
./ccusage_monitor.py --timezone US/Eastern

# Use Tokyo time
./ccusage_monitor.py --timezone Asia/Tokyo

# Use UTC
./ccusage_monitor.py --timezone UTC

# Use London time
./ccusage_monitor.py --timezone Europe/London"><pre><span><span>#</span> Use US Eastern Time</span>
./ccusage_monitor.py --timezone US/Eastern

<span><span>#</span> Use Tokyo time</span>
./ccusage_monitor.py --timezone Asia/Tokyo

<span><span>#</span> Use UTC</span>
./ccusage_monitor.py --timezone UTC

<span><span>#</span> Use London time</span>
./ccusage_monitor.py --timezone Europe/London</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Available Plans</h3><a id="user-content-available-plans" aria-label="Permalink: Available Plans" href="#available-plans"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Plan</th>
<th>Token Limit</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>pro</strong></td>
<td>~7,000</td>
<td>Light usage, testing (default)</td>
</tr>
<tr>
<td><strong>max5</strong></td>
<td>~35,000</td>
<td>Regular development</td>
</tr>
<tr>
<td><strong>max20</strong></td>
<td>~140,000</td>
<td>Heavy usage, large projects</td>
</tr>
<tr>
<td><strong>custom_max</strong></td>
<td>Auto-detect</td>
<td>Uses highest from previous sessions</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">‚ú® Features &amp; How It Works</h2><a id="user-content--features--how-it-works" aria-label="Permalink: ‚ú® Features &amp; How It Works" href="#-features--how-it-works"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Current Features</h3><a id="user-content-current-features" aria-label="Permalink: Current Features" href="#current-features"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">üîÑ Real-time Monitoring</h4><a id="user-content--real-time-monitoring" aria-label="Permalink: üîÑ Real-time Monitoring" href="#-real-time-monitoring"></a></p>
<ul dir="auto">
<li>Updates every 3 seconds with smooth refresh</li>
<li>No screen flicker - intelligent display updates</li>
<li>Live token consumption tracking across multiple sessions</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">üìä Visual Progress Bars</h4><a id="user-content--visual-progress-bars" aria-label="Permalink: üìä Visual Progress Bars" href="#-visual-progress-bars"></a></p>
<ul dir="auto">
<li><strong>Token Progress</strong>: Color-coded bars showing current usage vs limits</li>
<li><strong>Time Progress</strong>: Visual countdown to next session reset</li>
<li><strong>Burn Rate Indicator</strong>: Real-time consumption velocity</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">üîÆ Smart Predictions</h4><a id="user-content--smart-predictions" aria-label="Permalink: üîÆ Smart Predictions" href="#-smart-predictions"></a></p>
<ul dir="auto">
<li>Calculates when tokens will run out based on current burn rate</li>
<li>Warns if tokens will deplete before next session reset</li>
<li>Analyzes usage patterns from the last hour</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">ü§ñ Auto-Detection System</h4><a id="user-content--auto-detection-system" aria-label="Permalink: ü§ñ Auto-Detection System" href="#-auto-detection-system"></a></p>
<ul dir="auto">
<li><strong>Smart Plan Switching</strong>: Automatically switches from Pro to custom_max when limits exceeded</li>
<li><strong>Limit Discovery</strong>: Scans previous sessions to find your actual token limits</li>
<li><strong>Intelligent Notifications</strong>: Shows when automatic switches occur</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Understanding Claude Sessions</h3><a id="user-content-understanding-claude-sessions" aria-label="Permalink: Understanding Claude Sessions" href="#understanding-claude-sessions"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">How Claude Code Sessions Work</h4><a id="user-content-how-claude-code-sessions-work" aria-label="Permalink: How Claude Code Sessions Work" href="#how-claude-code-sessions-work"></a></p>
<p dir="auto">Claude Code operates on a <strong>5-hour rolling session window system</strong>:</p>
<ol dir="auto">
<li><strong>Session Start</strong>: Begins with your first message to Claude</li>
<li><strong>Session Duration</strong>: Lasts exactly 5 hours from that first message</li>
<li><strong>Token Limits</strong>: Apply within each 5-hour session window</li>
<li><strong>Multiple Sessions</strong>: Can have several active sessions simultaneously</li>
<li><strong>Rolling Windows</strong>: New sessions can start while others are still active</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Session Reset Schedule</h4><a id="user-content-session-reset-schedule" aria-label="Permalink: Session Reset Schedule" href="#session-reset-schedule"></a></p>
<p dir="auto"><strong>Default reference times</strong> (in your configured timezone):</p>
<ul dir="auto">
<li><code>04:00</code>, <code>09:00</code>, <code>14:00</code>, <code>18:00</code>, <code>23:00</code></li>
</ul>
<blockquote>
<p dir="auto"><strong><g-emoji alias="warning">‚ö†Ô∏è</g-emoji> Important</strong>: These are reference times for planning. Your actual token refresh happens exactly 5 hours after YOUR first message in each session.</p>
</blockquote>
<p dir="auto"><strong>Example Session Timeline:</strong></p>
<div data-snippet-clipboard-copy-content="10:30 AM - First message (Session A starts)
03:30 PM - Session A expires (5 hours later)

12:15 PM - First message (Session B starts) 
05:15 PM - Session B expires (5 hours later)"><pre><code>10:30 AM - First message (Session A starts)
03:30 PM - Session A expires (5 hours later)

12:15 PM - First message (Session B starts) 
05:15 PM - Session B expires (5 hours later)
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Burn Rate Calculation</h4><a id="user-content-burn-rate-calculation" aria-label="Permalink: Burn Rate Calculation" href="#burn-rate-calculation"></a></p>
<p dir="auto">The monitor calculates burn rate using sophisticated analysis:</p>
<ol dir="auto">
<li><strong>Data Collection</strong>: Gathers token usage from all sessions in the last hour</li>
<li><strong>Pattern Analysis</strong>: Identifies consumption trends across overlapping sessions</li>
<li><strong>Velocity Tracking</strong>: Calculates tokens consumed per minute</li>
<li><strong>Prediction Engine</strong>: Estimates when current session tokens will deplete</li>
<li><strong>Real-time Updates</strong>: Adjusts predictions as usage patterns change</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Token Limits by Plan</h3><a id="user-content-token-limits-by-plan" aria-label="Permalink: Token Limits by Plan" href="#token-limits-by-plan"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Standard Plans</h4><a id="user-content-standard-plans" aria-label="Permalink: Standard Plans" href="#standard-plans"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Plan</th>
<th>Approximate Limit</th>
<th>Typical Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Claude Pro</strong></td>
<td>~7,000 tokens</td>
<td>Light coding, testing, learning</td>
</tr>
<tr>
<td><strong>Claude Max5</strong></td>
<td>~35,000 tokens</td>
<td>Regular development work</td>
</tr>
<tr>
<td><strong>Claude Max20</strong></td>
<td>~140,000 tokens</td>
<td>Heavy usage, large projects</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Auto-Detection Plans</h4><a id="user-content-auto-detection-plans" aria-label="Permalink: Auto-Detection Plans" href="#auto-detection-plans"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Plan</th>
<th>How It Works</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>custom_max</strong></td>
<td>Scans all previous sessions, uses highest token count found</td>
<td>Users with variable/unknown limits</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Smart Detection Features</h3><a id="user-content-smart-detection-features" aria-label="Permalink: Smart Detection Features" href="#smart-detection-features"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Automatic Plan Switching</h4><a id="user-content-automatic-plan-switching" aria-label="Permalink: Automatic Plan Switching" href="#automatic-plan-switching"></a></p>
<p dir="auto">When using the default Pro plan:</p>
<ol dir="auto">
<li><strong>Detection</strong>: Monitor notices token usage exceeding 7,000</li>
<li><strong>Analysis</strong>: Scans previous sessions for actual limits</li>
<li><strong>Switch</strong>: Automatically changes to custom_max mode</li>
<li><strong>Notification</strong>: Displays clear message about the change</li>
<li><strong>Continuation</strong>: Keeps monitoring with new, higher limit</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Limit Discovery Process</h4><a id="user-content-limit-discovery-process" aria-label="Permalink: Limit Discovery Process" href="#limit-discovery-process"></a></p>
<p dir="auto">The auto-detection system:</p>
<ol dir="auto">
<li><strong>Scans History</strong>: Examines all available session blocks</li>
<li><strong>Finds Peaks</strong>: Identifies highest token usage achieved</li>
<li><strong>Validates Data</strong>: Ensures data quality and recency</li>
<li><strong>Sets Limits</strong>: Uses discovered maximum as new limit</li>
<li><strong>Learns Patterns</strong>: Adapts to your actual usage capabilities</li>
</ol>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üöÄ Usage Examples</h2><a id="user-content--usage-examples" aria-label="Permalink: üöÄ Usage Examples" href="#-usage-examples"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Common Scenarios</h3><a id="user-content-common-scenarios" aria-label="Permalink: Common Scenarios" href="#common-scenarios"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">üåÖ Morning Developer</h4><a id="user-content--morning-developer" aria-label="Permalink: üåÖ Morning Developer" href="#-morning-developer"></a></p>
<p dir="auto"><strong>Scenario</strong>: You start work at 9 AM and want tokens to reset aligned with your schedule.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Set custom reset time to 9 AM
./ccusage_monitor.py --reset-hour 9

# With your timezone
./ccusage_monitor.py --reset-hour 9 --timezone US/Eastern"><pre><span><span>#</span> Set custom reset time to 9 AM</span>
./ccusage_monitor.py --reset-hour 9

<span><span>#</span> With your timezone</span>
./ccusage_monitor.py --reset-hour 9 --timezone US/Eastern</pre></div>
<p dir="auto"><strong>Benefits</strong>:</p>
<ul dir="auto">
<li>Reset times align with your work schedule</li>
<li>Better planning for daily token allocation</li>
<li>Predictable session windows</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">üåô Night Owl Coder</h4><a id="user-content--night-owl-coder" aria-label="Permalink: üåô Night Owl Coder" href="#-night-owl-coder"></a></p>
<p dir="auto"><strong>Scenario</strong>: You often work past midnight and need flexible reset scheduling.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Reset at midnight for clean daily boundaries
./ccusage_monitor.py --reset-hour 0

# Late evening reset (11 PM)
./ccusage_monitor.py --reset-hour 23"><pre><span><span>#</span> Reset at midnight for clean daily boundaries</span>
./ccusage_monitor.py --reset-hour 0

<span><span>#</span> Late evening reset (11 PM)</span>
./ccusage_monitor.py --reset-hour 23</pre></div>
<p dir="auto"><strong>Strategy</strong>:</p>
<ul dir="auto">
<li>Plan heavy coding sessions around reset times</li>
<li>Use late resets to span midnight work sessions</li>
<li>Monitor burn rate during peak hours</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">üîÑ Heavy User with Variable Limits</h4><a id="user-content--heavy-user-with-variable-limits" aria-label="Permalink: üîÑ Heavy User with Variable Limits" href="#-heavy-user-with-variable-limits"></a></p>
<p dir="auto"><strong>Scenario</strong>: Your token limits seem to change, and you're not sure of your exact plan.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Auto-detect your highest previous usage
./ccusage_monitor.py --plan custom_max

# Monitor with custom scheduling
./ccusage_monitor.py --plan custom_max --reset-hour 6"><pre><span><span>#</span> Auto-detect your highest previous usage</span>
./ccusage_monitor.py --plan custom_max

<span><span>#</span> Monitor with custom scheduling</span>
./ccusage_monitor.py --plan custom_max --reset-hour 6</pre></div>
<p dir="auto"><strong>Approach</strong>:</p>
<ul dir="auto">
<li>Let auto-detection find your real limits</li>
<li>Monitor for a week to understand patterns</li>
<li>Note when limits change or reset</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">üåç International User</h4><a id="user-content--international-user" aria-label="Permalink: üåç International User" href="#-international-user"></a></p>
<p dir="auto"><strong>Scenario</strong>: You're working across different timezones or traveling.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# US East Coast
./ccusage_monitor.py --timezone America/New_York

# Europe
./ccusage_monitor.py --timezone Europe/London

# Asia Pacific
./ccusage_monitor.py --timezone Asia/Singapore

# UTC for international team coordination
./ccusage_monitor.py --timezone UTC --reset-hour 12"><pre><span><span>#</span> US East Coast</span>
./ccusage_monitor.py --timezone America/New_York

<span><span>#</span> Europe</span>
./ccusage_monitor.py --timezone Europe/London

<span><span>#</span> Asia Pacific</span>
./ccusage_monitor.py --timezone Asia/Singapore

<span><span>#</span> UTC for international team coordination</span>
./ccusage_monitor.py --timezone UTC --reset-hour 12</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">‚ö° Quick Check</h4><a id="user-content--quick-check" aria-label="Permalink: ‚ö° Quick Check" href="#-quick-check"></a></p>
<p dir="auto"><strong>Scenario</strong>: You just want to see current status without configuration.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Just run it with defaults
./ccusage_monitor.py

# Press Ctrl+C after checking status"><pre><span><span>#</span> Just run it with defaults</span>
./ccusage_monitor.py

<span><span>#</span> Press Ctrl+C after checking status</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Plan Selection Strategies</h3><a id="user-content-plan-selection-strategies" aria-label="Permalink: Plan Selection Strategies" href="#plan-selection-strategies"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">How to Choose Your Plan</h4><a id="user-content-how-to-choose-your-plan" aria-label="Permalink: How to Choose Your Plan" href="#how-to-choose-your-plan"></a></p>
<p dir="auto"><strong>Start with Default (Recommended for New Users)</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Pro plan detection with auto-switching
./ccusage_monitor.py"><pre><span><span>#</span> Pro plan detection with auto-switching</span>
./ccusage_monitor.py</pre></div>
<ul dir="auto">
<li>Monitor will detect if you exceed Pro limits</li>
<li>Automatically switches to custom_max if needed</li>
<li>Shows notification when switching occurs</li>
</ul>
<p dir="auto"><strong>Known Subscription Users</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# If you know you have Max5
./ccusage_monitor.py --plan max5

# If you know you have Max20
./ccusage_monitor.py --plan max20"><pre><span><span>#</span> If you know you have Max5</span>
./ccusage_monitor.py --plan max5

<span><span>#</span> If you know you have Max20</span>
./ccusage_monitor.py --plan max20</pre></div>
<p dir="auto"><strong>Unknown Limits</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Auto-detect from previous usage
./ccusage_monitor.py --plan custom_max"><pre><span><span>#</span> Auto-detect from previous usage</span>
./ccusage_monitor.py --plan custom_max</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Best Practices</h3><a id="user-content-best-practices" aria-label="Permalink: Best Practices" href="#best-practices"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Setup Best Practices</h4><a id="user-content-setup-best-practices" aria-label="Permalink: Setup Best Practices" href="#setup-best-practices"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Start Early in Sessions</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Begin monitoring when starting Claude work
./ccusage_monitor.py"><pre><span><span>#</span> Begin monitoring when starting Claude work</span>
./ccusage_monitor.py</pre></div>
<ul dir="auto">
<li>Gives accurate session tracking from the start</li>
<li>Better burn rate calculations</li>
<li>Early warning for limit approaches</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Use Virtual Environment</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Production setup with isolation
python3 -m venv venv
source venv/bin/activate
pip install pytz"><pre><span><span>#</span> Production setup with isolation</span>
python3 -m venv venv
<span>source</span> venv/bin/activate
pip install pytz</pre></div>
<ul dir="auto">
<li>Prevents dependency conflicts</li>
<li>Clean uninstallation</li>
<li>Reproducible environments</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Custom Shell Alias</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Add to ~/.bashrc or ~/.zshrc
alias claude-monitor='cd ~/Claude-Code-Usage-Monitor &amp;&amp; source venv/bin/activate &amp;&amp; ./ccusage_monitor.py'"><pre><span><span>#</span> Add to ~/.bashrc or ~/.zshrc</span>
<span>alias</span> claude-monitor=<span><span>'</span>cd ~/Claude-Code-Usage-Monitor &amp;&amp; source venv/bin/activate &amp;&amp; ./ccusage_monitor.py<span>'</span></span></pre></div>
</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Usage Best Practices</h4><a id="user-content-usage-best-practices" aria-label="Permalink: Usage Best Practices" href="#usage-best-practices"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Monitor Burn Rate Velocity</strong></p>
<ul dir="auto">
<li>Watch for sudden spikes in token consumption</li>
<li>Adjust coding intensity based on remaining time</li>
<li>Plan big refactors around session resets</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Strategic Session Planning</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Plan heavy usage around reset times
./ccusage_monitor.py --reset-hour 9"><pre><span><span>#</span> Plan heavy usage around reset times</span>
./ccusage_monitor.py --reset-hour 9</pre></div>
<ul dir="auto">
<li>Schedule large tasks after resets</li>
<li>Use lighter tasks when approaching limits</li>
<li>Leverage multiple overlapping sessions</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Timezone Awareness</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Always use your actual timezone
./ccusage_monitor.py --timezone Europe/Warsaw"><pre><span><span>#</span> Always use your actual timezone</span>
./ccusage_monitor.py --timezone Europe/Warsaw</pre></div>
<ul dir="auto">
<li>Accurate reset time predictions</li>
<li>Better planning for work schedules</li>
<li>Correct session expiration estimates</li>
</ul>
</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Optimization Tips</h4><a id="user-content-optimization-tips" aria-label="Permalink: Optimization Tips" href="#optimization-tips"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Terminal Setup</strong></p>
<ul dir="auto">
<li>Use terminals with at least 80 character width</li>
<li>Enable color support for better visual feedback</li>
<li>Consider dedicated terminal window for monitoring</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Workflow Integration</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Start monitoring with your development session
tmux new-session -d -s claude-monitor './ccusage_monitor.py'

# Check status anytime
tmux attach -t claude-monitor"><pre><span><span>#</span> Start monitoring with your development session</span>
tmux new-session -d -s claude-monitor <span><span>'</span>./ccusage_monitor.py<span>'</span></span>

<span><span>#</span> Check status anytime</span>
tmux attach -t claude-monitor</pre></div>
</li>
<li>
<p dir="auto"><strong>Multi-Session Strategy</strong></p>
<ul dir="auto">
<li>Remember sessions last exactly 5 hours</li>
<li>You can have multiple overlapping sessions</li>
<li>Plan work across session boundaries</li>
</ul>
</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Real-World Workflows</h4><a id="user-content-real-world-workflows" aria-label="Permalink: Real-World Workflows" href="#real-world-workflows"></a></p>
<p dir="auto"><strong>Large Project Development</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Setup for sustained development
./ccusage_monitor.py --plan max20 --reset-hour 8 --timezone America/New_York"><pre><span><span>#</span> Setup for sustained development</span>
./ccusage_monitor.py --plan max20 --reset-hour 8 --timezone America/New_York</pre></div>
<p dir="auto"><strong>Daily Routine</strong>:</p>
<ol dir="auto">
<li><strong>8:00 AM</strong>: Fresh tokens, start major features</li>
<li><strong>10:00 AM</strong>: Check burn rate, adjust intensity</li>
<li><strong>12:00 PM</strong>: Monitor for afternoon session planning</li>
<li><strong>2:00 PM</strong>: New session window, tackle complex problems</li>
<li><strong>4:00 PM</strong>: Light tasks, prepare for evening session</li>
</ol>
<p dir="auto"><strong>Learning &amp; Experimentation</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Flexible setup for learning
./ccusage_monitor.py --plan pro"><pre><span><span>#</span> Flexible setup for learning</span>
./ccusage_monitor.py --plan pro</pre></div>
<p dir="auto"><strong>Sprint Development</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# High-intensity development setup
./ccusage_monitor.py --plan max20 --reset-hour 6"><pre><span><span>#</span> High-intensity development setup</span>
./ccusage_monitor.py --plan max20 --reset-hour 6</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üìû Contact</h2><a id="user-content--contact" aria-label="Permalink: üìû Contact" href="#-contact"></a></p>
<p dir="auto">Have questions, suggestions, or want to collaborate? Feel free to reach out!</p>
<p dir="auto"><strong>üìß Email</strong>: <a href="mailto:maciek@roboblog.eu">maciek@roboblog.eu</a></p>
<p dir="auto">Whether you need help with setup, have feature requests, found a bug, or want to discuss potential improvements, don't hesitate to get in touch. I'm always happy to help and hear from users of the Claude Code Usage Monitor!</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üìö Additional Documentation</h2><a id="user-content--additional-documentation" aria-label="Permalink: üìö Additional Documentation" href="#-additional-documentation"></a></p>
<ul dir="auto">
<li><strong><a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/DEVELOPMENT.md">Development Roadmap</a></strong> - ML features, PyPI package, Docker plans</li>
<li><strong><a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/CONTRIBUTING.md">Contributing Guide</a></strong> - How to contribute, development guidelines</li>
<li><strong><a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/TROUBLESHOOTING.md">Troubleshooting</a></strong> - Common issues and solutions</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üìù License</h2><a id="user-content--license" aria-label="Permalink: üìù License" href="#-license"></a></p>
<p dir="auto"><a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/LICENSE">MIT License</a> - feel free to use and modify as needed.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üôè Acknowledgments</h2><a id="user-content--acknowledgments" aria-label="Permalink: üôè Acknowledgments" href="#-acknowledgments"></a></p>
<p dir="auto">This tool builds upon the excellent <a href="https://github.com/ryoppippi/ccusage">ccusage</a> by <a href="https://github.com/ryoppippi">@ryoppippi</a>, adding a real-time monitoring interface with visual progress bars, burn rate calculations, and predictive analytics.</p>
<hr>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Base44 sells to Wix for $80M cash (107 pts)]]></title>
            <link>https://techcrunch.com/2025/06/18/6-month-old-solo-owned-vibe-coder-base44-sells-to-wix-for-80m-cash/</link>
            <guid>44316920</guid>
            <pubDate>Thu, 19 Jun 2025 09:31:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/06/18/6-month-old-solo-owned-vibe-coder-base44-sells-to-wix-for-80m-cash/">https://techcrunch.com/2025/06/18/6-month-old-solo-owned-vibe-coder-base44-sells-to-wix-for-80m-cash/</a>, See on <a href="https://news.ycombinator.com/item?id=44316920">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">There‚Äôs a lot of talk in the startup world about how AI makes individuals so productive that it could give rise to a generation of <a href="https://www.amazon.com/Single-Handed-Unicorn-Billion-Dollar-Solopreneurs-Business/dp/B0DWSRS62N" target="_blank" rel="noreferrer noopener nofollow">‚Äúsolo unicorns‚Äù</a> ‚Äî one-person companies worth over $1 billion.</p>

<p>While an actual solo unicorn remains a mythical creature, Israeli developer Maor Shlomo provided compelling evidence Wednesday that the concept might not be impossible.&nbsp;</p>







<p>Shlomo sold his 6-month-old, bootstrapped vibe-coding startup Base44 to Wix for $80 million, Wix <a href="https://www.globenewswire.com/news-release/2025/06/18/3101508/0/en/Wix-Further-Expands-into-Vibe-Coding-with-Acquisition-of-Base44-a-Hyper-Growth-Startup-that-Simplifies-Web-and-App-Creation-with-AI.html" target="_blank" rel="noreferrer noopener nofollow">announced</a> Wednesday. And the deal was cash, Wix confirmed to TechCrunch.&nbsp;</p>

<p>Admittedly, this wasn‚Äôt a billion dollars or close to it. And Shlomo wasn‚Äôt truly solo ‚Äî he had eight employees, Wix confirmed. They will collectively receive $25 million of the $80 million as a ‚Äúretention‚Äù bonus. Wix declined to give details on that part of the deal, like how long they have to stay in their jobs to get full payouts.</p>

<p>Still, Base44‚Äôs rapid rise and impressive sale price have been the talk of the <a href="https://x.com/benln/status/1935327374079574427" target="_blank" rel="noreferrer noopener nofollow">vibe-coding community</a>.&nbsp;</p>

<p>In its six months as a stand-alone company, Base44 reportedly grew to 250,000 users, hitting 10,000 users within its first three weeks. According to <a href="https://www.linkedin.com/feed/update/urn:li:activity:7336025796509077504/" target="_blank" rel="noreferrer noopener nofollow">Shlomo‚Äôs posts</a> on X and LinkedIn, the company was profitable, generating $189,000 in profit in May even after covering high LLM token costs, which he also documented publicly.</p>

<p>Base44 spread mostly through word of mouth as Shlomo, a 31-year-old programmer, shared his building journey on LinkedIn and Twitter. The project began as a side venture, he told <a href="https://www.calcalistech.com/ctechnews/article/s1iflnlelx" target="_blank" rel="noreferrer noopener nofollow">Israeli tech news site CTech</a>.&nbsp;&nbsp;</p>


<p>‚ÄúBase44 is a moonshot experiment ‚Äî helping everyone, technical or not, build software without coding at all,‚Äù he <a rel="nofollow" href="https://www.linkedin.com/posts/maor-shlomo-1088b4144_excited-to-share-a-project-ive-been-working-activity-7297302969652277252-vcj8?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAEjzLUBg333G2D9H7FJaye0FUkOP4V2yos">explained on LinkedIn</a> when he launched it to the public.</p>

<p>It‚Äôs one of the newer crop of vibe-coding products designed for non-programmers. Users enter text prompts, and the platform builds complete applications, with database, storage, authentication, analytics, and integration. It also supports email, texting, and maps, with a roadmap for more enterprise-grade security support.</p>

<p>Base44 isn‚Äôt unique in this area. Other vibe coders like <a href="https://techcrunch.com/2025/04/22/adaptive-computer-wants-to-reinvent-the-pc-with-vibe-coding-for-non-programmers/">Adaptive Computer</a> handle similar infrastructure work. But Base44‚Äôs fast rise was astounding all the same.</p>







<p>Shlomo was already known in the Israeli startup community through his previous startup, the Insight Partners-backed data analytics company <a href="https://techcrunch.com/2021/05/18/explorium-scores-75m-series-c-just-10-months-after-b-round/">Explorium</a>. His brother is also a co-founder of an <a href="https://techcrunch.com/2025/01/27/hackers-are-targeting-machine-identities-token-security-just-raised-20m-to-stop-them/">AI security startup, Token Security,</a> which just raised $20 million led by Notable Capital (formerly GGV Capital) and a bunch of Israeli tech angels.</p>

<p>He quickly gained partnership agreements  for Base44 with big Israeli tech companies like eToro and Similarweb.</p>

<p>After posting about his decision to use Anthropic‚Äôs Claude LLM through AWS instead of models by OpenAI ‚Äî mostly for cost-per-performance reasons ‚Äî Amazon invited Base44 to demo at a Tel Aviv AWS event last month, which <a href="https://www.linkedin.com/posts/maor-shlomo-1088b4144_it-was-an-honor-to-present-base44-on-the-activity-7333519004138942464-EVoB/?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAEjzLUBg333G2D9H7FJaye0FUkOP4V2yos" target="_blank" rel="noreferrer noopener nofollow">Shlomo documented.</a></p>

<p>‚ÄúCrazy f***ing journey so far,‚Äù Shlomo <a href="https://www.linkedin.com/feed/update/urn:li:activity:7341088575049891840/" target="_blank" rel="noreferrer noopener nofollow">posted on LinkedIn</a> when announcing the news of the acquisition. Despite the growth and the profits ‚Äî or really because of it ‚Äî he sold his still-bootstrapped company because ‚Äúthe scale and volume we need is not something we can organically grow into&nbsp;‚Ä¶ If we were able to get so far organically, bootstrapped, I‚Äôm excited to see our new pace now that we have all the resources in place,‚Äù he wrote.</p>

<p>For its part, Wix picked up a proven, fast-growing, local vibe-coding platform for a relative song because of its youth. <a href="https://techcrunch.com/2025/04/22/why-openai-wanted-to-buy-cursor-but-opted-for-the-fast-growing-windsurf/">OpenAI paid $3 billion for Windsurf,</a> which was founded in 2021.&nbsp;</p>

<p>Wix, of course, offers no-code website building that look professionally designed. Adding a profitable LLM vibe-coding product to its offerings is a logical move.</p>

<p>Shlomo could not be immediately reached for additional comment.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SpaceX Starship 36 Anomaly (245 pts)]]></title>
            <link>https://twitter.com/NASASpaceflight/status/1935548909805601020</link>
            <guid>44315529</guid>
            <pubDate>Thu, 19 Jun 2025 04:49:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/NASASpaceflight/status/1935548909805601020">https://twitter.com/NASASpaceflight/status/1935548909805601020</a>, See on <a href="https://news.ycombinator.com/item?id=44315529">Hacker News</a></p>
Couldn't get https://twitter.com/NASASpaceflight/status/1935548909805601020: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Elliptic Curves as Art (157 pts)]]></title>
            <link>https://elliptic-curves.art/</link>
            <guid>44315321</guid>
            <pubDate>Thu, 19 Jun 2025 04:02:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://elliptic-curves.art/">https://elliptic-curves.art/</a>, See on <a href="https://news.ycombinator.com/item?id=44315321">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

    

<p>Welcome to the website for our project visualizing elliptic curves.
    Be patient with us, this page is under construction!</p>

    <p> - Nadir Hajouji and Steve Trettel</p>



    <a href="https://elliptic-curves.art/papers/">
        <h2>Papers</h2>
    </a>


        <div>

    <p><img src="https://elliptic-curves.art/papers/bridges/screenshot_hu_94859ba4994302a8.webp">

    </p>

    
  </div>




    <a href="https://elliptic-curves.art/art/">
        <h2>Some Beautiful Illustrations</h2>
    </a>



        
    </div><div>
    <p>
       ¬© 2025 Copyright: Nadir Hajouji &amp; Steve Trettel 
    </p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dr. Demento Announces Retirement After 55-Year Radio Career (111 pts)]]></title>
            <link>https://sopghreporter.com/2025/06/01/dr-demento-announces-retirement/</link>
            <guid>44315185</guid>
            <pubDate>Thu, 19 Jun 2025 03:27:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sopghreporter.com/2025/06/01/dr-demento-announces-retirement/">https://sopghreporter.com/2025/06/01/dr-demento-announces-retirement/</a>, See on <a href="https://news.ycombinator.com/item?id=44315185">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content">
		<main id="main">

			
	

	
			<figure>

				<img width="1200" height="800" src="https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-1200x800.jpg" alt="" data-hero-candidate="1" fetchpriority="high" decoding="async" srcset="https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-1200x800.jpg 1200w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-300x200.jpg 300w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-1024x683.jpg 1024w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-768x512.jpg 768w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-1536x1024.jpg 1536w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-2000x1333.jpg 2000w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-780x520.jpg 780w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped-400x267.jpg 400w, https://sopghreporter.com/wp-content/uploads/2025/06/dr.demento-1984-la-times-cropped.jpg 2048w" sizes="(max-width: 1200px) 100vw, 1200px">			<figcaption><span>Westwood One radio disc jockey, Dr. Demento, (aka Barrett Hanson), 1984. CC-BY 4.0 <span><span>Credit:</span> <a href="https://digital.library.ucla.edu/catalog/ark:/21198/zz0002tppx">Martha Hartnett / Los Angeles Times Photographic Collection</a></span></span></figcaption>
			
			</figure><!-- .post-thumbnail -->

		
				<div>

					

<article id="post-3712">
	<div>

		
		
<p>Radio personality Barret ‚Äú<strong><a href="https://www.drdemento.com/" target="_blank" rel="noopener">Dr. Demento</a></strong>‚Äù Hansen announced his retirement this week, ending a 55-year career devoted to comedy and novelty music when his show concludes in October.</p>



<p>Hansen, 84, revealed the decision during his weekly program, saying the current episode would be his final regular show. The announcement comes as the program approaches its 55th anniversary this fall.</p>



<p><em>The Dr. Demento Show</em> will continue with retrospective episodes through October, culminating in a final broadcast featuring the top 40 songs in the program‚Äôs history. Hansen plans to host the remaining episodes, which will chronicle different decades of the show‚Äôs run.</p>



<p>Dr. Demento debuted in October 1970 on KPPC Pasadena, California, now known as KROQ-FM. The program initially featured freeform rock before Hansen shifted focus to comedy and novelty music that became his trademark.</p>





<p>The show gained popularity across multiple Los Angeles stations, including a notable run on KMET from 1972 until the station‚Äôs closure in 1987. A syndicated version launched in 1974, originally distributed on reel-to-reel tape. Over time, the show reflected changes in audio technology, <a href="https://dmdb.org/images/drddj.html" target="_blank" rel="noopener">syndicating via LPs, cassettes, and CD-Rs</a> until the end of its syndicated run in 2010.</p>



<p>The show then transitioned to an online format with a subscription service. Beginning in 2006, the show offered pay-per-show audio streaming through its official website.</p>



<p>Hansen, who grew up in Minneapolis, was inspired to pursue novelty music after his father brought home Spike Jones‚Äô ‚ÄúCocktails for Two.‚Äù The bells, whistles and chaotic sound effects of the song inspired him to seek similar music, leading him to become an avid collector before and during his radio career. By his own estimates, Hansen has gathered more than 300,000 albums in his Lakewood, CA. library, many from bands seeking airplay. </p>



<p>Dr. Demento introduced audiences to comedy songs, parodies, and musical oddities that traditional radio avoided. Throughout the years, the two most requested songs were Barnes &amp; Barnes‚Äô ‚ÄúFish Heads‚Äù and Bill Fenzer‚Äôs ‚ÄúDead Puppies Aren‚Äôt Much Fun,‚Äù followed by ‚ÄúWeird Al‚Äù Yankovic‚Äôs catalog, who Hansen is largely credited for discovering. Rainn Wilson played a fictionalized Dr. Demento in <em>Weird: The Al Yankovic Story</em>.</p>


<div>
<figure><img decoding="async" width="1024" height="683" src="https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-1024x683.jpg" alt="" srcset="https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-1024x683.jpg 1024w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-300x200.jpg 300w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-768x512.jpg 768w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-1536x1025.jpg 1536w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-1200x800.jpg 1200w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-2000x1334.jpg 2000w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-780x520.jpg 780w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87-400x267.jpg 400w, https://sopghreporter.com/wp-content/uploads/2025/06/dr-demento-tape-87.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A few Bootleg Dr. Demento Tapes from the 1980‚Äôs. Fans recorded and traded programs to collect and share with friends outside of syndicated areas. <span><span>Credit:</span> Foo Conner / The Pittsburgh Reporter</span></figcaption></figure></div>


<p>The Radio Hall of Fame inducted Dr. Demento (Barret Hansen) in 2009, recognizing his contributions to broadcast entertainment.</p>



<p>The remaining episodes will include decade-by-decade retrospectives and classic show reruns from the 1970s and 1980s. Hansen has scheduled shows featuring his personal favorites and listener requests before the October finale.</p>



<p>Past episodes dating to 1974 are available on the show‚Äôs website, along with select archives from the early 1970s. <a href="https://www.drdemento.com/online.html" target="_blank" rel="noopener">Upcoming episodes will be posted</a> as they are produced.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
			<div>
															<p><a href="https://sopghreporter.com/author/foo/" rel="author">
											<img alt="Avatar photo" src="https://sopghreporter.com/wp-content/uploads/2023/12/foo-conner-square-profile-1-80x80.jpg" srcset="https://sopghreporter.com/wp-content/uploads/2023/12/foo-conner-square-profile-1-160x160.jpg 2x" height="80" width="80">											</a></p><div>
					<!-- .author-bio-header -->

											<p>
							Foo, editor of The Pittsburgh Reporter, guides our newsrooms and meets neighbors. He shares heartfelt stories often overlooked.															<a href="https://sopghreporter.com/author/foo/" rel="author">
								More by Foo Conner								</a>
													</p>
					
				</div><!-- .author-bio-text -->

			</div><!-- .author-bio -->
			
</article><!-- #post-${ID} -->
				</div>

			
		</main><!-- #main -->
	</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Zed Debugger Is Here (426 pts)]]></title>
            <link>https://zed.dev/blog/debugger</link>
            <guid>44314977</guid>
            <pubDate>Thu, 19 Jun 2025 02:42:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zed.dev/blog/debugger">https://zed.dev/blog/debugger</a>, See on <a href="https://news.ycombinator.com/item?id=44314977">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Over 2,000 developers asked, and we delivered.</p>
<p>Debugging in Zed is now a reality‚Äîand it's a big leap toward Zed 1.0.</p>
<h2 id="overview"><a href="#overview" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>Overview</span></a></h2>
<p>We set out to build a debugger with three primary focuses:</p>
<ul>
<li>Fast: Spend less time context switching and more time debugging</li>
<li>Familiar: In line with Zed's design language and supports everything expected from a typical debugger flow</li>
<li>Configurable: You're able to customize the UI, keybindings, debug configurations and more</li>
</ul>
<p>Out of the box, Zed supports debugging popular languages including Rust, C/C++, JavaScript, Go, and Python.
With our extension system, Zed can support any debug adapter that implements the <a href="https://microsoft.github.io/debug-adapter-protocol/">Debug Adapter Protocol (DAP)</a>.</p>
<p>To simplify the setup process, we've introduced locators, a system that translates build configurations into debug configurations. Meaning that you can write a build task once in <code>tasks.json</code> and reference it from <code>debug.json</code> ‚Äî or, even better, rely on Zed's automatic configuration.</p>
<p>Zed automatically runs locators on built-in or language server-generated runnables, so in many cases you won't even need to write a debug configuration to get up and running.</p>
<p>We currently support locators for Cargo, Python, JavaScript, and Go, with more coming in the future.
For more information on configuring a debug session, <a href="https://zed.dev/docs/debugger">see our documentation</a>.</p>
<p>Once in a debug session, Zed makes it easy to inspect your program's state, such as threads, variables, breakpoints, the call stack, and more.</p>
<p><figure><video src="https://customer-snccc0j9v3kfzkif.cloudflarestream.com/fd34bd93b1ec8d7c5554daf0ffdb909e/downloads/default.mp4" width="3280" height="2160" poster="https://zed.dev/img/debugger/zero-setup-poster.webp" controls=""></video><figcaption>Setting some breakpoints and running the test in a debug session.</figcaption></figure></p>
<p>The debugger panel is fully customizable too, just drag and rearrange tabs in whatever order you want; you can even move the debug panel around so it fits your workflow.</p>
<p>Zed also supports keyboard-driven debugging for users that prefer to keep their hands on the keyboard.
You can step through code, toggle breakpoints, and navigate a debug session without ever touching the mouse.</p>
<p><figure><video src="https://customer-snccc0j9v3kfzkif.cloudflarestream.com/642d476eeaab0423087c9c19aab53828/downloads/default.mp4" width="3280" height="2160" poster="https://zed.dev/img/debugger/keyboard-poster.webp" controls=""></video><figcaption>Navigating through the Debugger surfaces using only the keyboard.</figcaption></figure></p>
<h2 id="a-special-thanks"><a href="#a-special-thanks" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>A Special Thanks</span></a></h2>
<p>The debugger started as a community-led project with some impressive stats: <a href="https://github.com/zed-industries/zed/pull/13433/commits">8 months of development, 977 commits, and 25k+ lines of code</a>. The community built the core foundation that made today‚Äôs launch possible.</p>
<p>Special thanks to <a href="https://github.com/RemcoSmitsDev">Remco Smits</a> for driving a lot of the heavy lifting on this project‚Äîyour contributions have been critical to getting us here.</p>
<h2 id="under-the-hood"><a href="#under-the-hood" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>Under the Hood</span></a></h2>
<p>Zed's debugger supports debugging a variety of languages through the Debug Adapter Protocol.
But simply implementing the protocol wasn't enough‚Äîwe needed an architecture that could scale to collaborative debugging, support extensions, and efficiently cache and manage responses from debug adapters.</p>
<p>To achieve this, we built a two-layer architecture: a data layer that communicates directly with the debug adapters, and a UI layer that fetches data from the data layer to render the interface.</p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="rust" data-theme="dark-plus light-plus"><span data-line=""><span>/// All functions are cheap to call, as they grab current state of the debug session and schedule refreshing on a background</span></span>
<span data-line=""><span>/// thread if that state is outdated.</span></span>
<span data-line=""><span>pub</span><span> fn</span><span> modules</span><span>(&amp;</span><span>mut</span><span> self</span><span>, </span><span>cx</span><span>: &amp;</span><span>mut</span><span> Context</span><span>&lt;</span><span>Self</span><span>&gt;) -&gt; &amp;[</span><span>Module</span><span>] {</span></span>
<span data-line=""><span>    /// Kick off a fresh request to a DAP for modules list if we don't have an up-to-date state.</span></span>
<span data-line=""><span>    /// This is a no-op in case we've ran that request already. In case we did not, it kicks off a background task.</span></span>
<span data-line=""><span>    self</span><span>.</span><span>fetch</span><span>(</span></span>
<span data-line=""><span>        /// We cache request results based on it's arguments. `Modules` request does not take any arguments</span></span>
<span data-line=""><span>        dap_command</span><span>::</span><span>ModulesCommand</span><span>,</span></span>
<span data-line=""><span>        /// Callback invoked with the result of a request.</span></span>
<span data-line=""><span>        |</span><span>this</span><span>, </span><span>result</span><span>, </span><span>cx</span><span>| {</span></span>
<span data-line=""><span>            let</span><span> Some</span><span>(</span><span>result</span><span>) = </span><span>result</span><span>.</span><span>log_err</span><span>() </span><span>else</span><span> {</span></span>
<span data-line=""><span>                return</span><span>;</span></span>
<span data-line=""><span>            };</span></span>
<span data-line=""> </span>
<span data-line=""><span>            this</span><span>.modules = </span><span>result</span><span>;</span></span>
<span data-line=""><span>            cx</span><span>.</span><span>emit</span><span>(</span><span>SessionEvent</span><span>::</span><span>Modules</span><span>);</span></span>
<span data-line=""><span>            cx</span><span>.</span><span>notify</span><span>();</span></span>
<span data-line=""><span>        },</span></span>
<span data-line=""><span>        cx</span><span>,</span></span>
<span data-line=""><span>    );</span></span>
<span data-line=""> </span>
<span data-line=""><span>    /// Returns a current list of modules; it might be outdated at the time the new request is underway,</span></span>
<span data-line=""><span>    /// but once it is done, the return value of this function will reflect that.</span></span>
<span data-line=""><span>    &amp;</span><span>self</span><span>.modules</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="rust" data-theme="dark-plus light-plus"><span data-line=""><span>/// This function is called from the Module list render function in the UI layer whenever the data layer invalidates the module list state.</span></span>
<span data-line=""><span>fn</span><span> schedule_rebuild</span><span>(&amp;</span><span>mut</span><span> self</span><span>, </span><span>cx</span><span>: &amp;</span><span>mut</span><span> Context</span><span>&lt;</span><span>Self</span><span>&gt;) {</span></span>
<span data-line=""><span>    /// Setting the task drops any current work in progress that is out of date</span></span>
<span data-line=""><span>    self</span><span>._rebuild_task = </span><span>Some</span><span>(</span><span>cx</span><span>.</span><span>spawn</span><span>(</span><span>async</span><span> move</span><span> |</span><span>this</span><span>, </span><span>cx</span><span>| {</span></span>
<span data-line=""><span>        this</span><span>.</span><span>update</span><span>(</span><span>cx</span><span>, |</span><span>this</span><span>, </span><span>cx</span><span>| {</span></span>
<span data-line=""><span>            /// The UI layer queries the data layer for modules and clones the data</span></span>
<span data-line=""><span>            let</span><span> modules</span><span> = </span><span>this</span></span>
<span data-line=""><span>                .session</span></span>
<span data-line=""><span>                .</span><span>update</span><span>(</span><span>cx</span><span>, |</span><span>session</span><span>, </span><span>cx</span><span>| </span><span>session</span><span>.</span><span>modules</span><span>(</span><span>cx</span><span>).</span><span>to_owned</span><span>());</span></span>
<span data-line=""><span>            this</span><span>.entries = </span><span>modules</span><span>;</span></span>
<span data-line=""><span>            cx</span><span>.</span><span>notify</span><span>();</span></span>
<span data-line=""><span>        })</span></span>
<span data-line=""><span>        .</span><span>ok</span><span>();</span></span>
<span data-line=""><span>    }));</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>This separation means the UI layer only requests what it needs, allowing the data layer to lazily fetch information and avoid unnecessary requests.
It also makes the data layer solely responsible for maintaining session state, caching responses, and invalidating stale data.
This architecture will make implementing collaborative debugging significantly easier, since the same UI code can be reused across multiplayer sessions‚Äîand we only send essential data across the wire, preserving bandwidth.</p>
<p>Supporting every debug adapter out of the box wasn't feasible‚Äîthere are over <a href="https://microsoft.github.io/debug-adapter-protocol/implementors/adapters/">70 DAP implementations</a>, each with its own quirks.
To solve this, we <a href="https://zed.dev/docs/extensions/debugger-extensions">extended</a> Zed's extension API to support debugger integration.</p>
<figure data-rehype-pretty-code-figure=""><div><pre><code data-language="rust" data-theme="dark-plus light-plus"><span data-line=""><span>    /// Returns the debug adapter binary for the specified adapter name and configuration.</span></span>
<span data-line=""><span>    fn</span><span> get_dap_binary</span><span>(</span></span>
<span data-line=""><span>        &amp;</span><span>mut</span><span> self</span><span>,</span></span>
<span data-line=""><span>        _adapter_name</span><span>: </span><span>String</span><span>,</span></span>
<span data-line=""><span>        _config</span><span>: </span><span>DebugTaskDefinition</span><span>,</span></span>
<span data-line=""><span>        _user_provided_debug_adapter_path</span><span>: </span><span>Option</span><span>&lt;</span><span>String</span><span>&gt;,</span></span>
<span data-line=""><span>        _worktree</span><span>: &amp;</span><span>Worktree</span><span>,</span></span>
<span data-line=""><span>    ) -&gt; </span><span>Result</span><span>&lt;</span><span>DebugAdapterBinary</span><span>, </span><span>String</span><span>&gt; {</span></span>
<span data-line=""><span>        Err</span><span>(</span><span>"`get_dap_binary` not implemented"</span><span>.</span><span>to_string</span><span>())</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    /// Determines whether the specified adapter configuration should *launch* a new debuggee process</span></span>
<span data-line=""><span>    /// or *attach* to an existing one. This function should not perform any further validation (outside of determining the kind of a request).</span></span>
<span data-line=""><span>    /// This function should return an error when the kind cannot be determined (rather than fall back to a known default).</span></span>
<span data-line=""><span>    fn</span><span> dap_request_kind</span><span>(</span></span>
<span data-line=""><span>        &amp;</span><span>mut</span><span> self</span><span>,</span></span>
<span data-line=""><span>        _adapter_name</span><span>: </span><span>String</span><span>,</span></span>
<span data-line=""><span>        _config</span><span>: </span><span>serde_json</span><span>::</span><span>Value</span><span>,</span></span>
<span data-line=""><span>    ) -&gt; </span><span>Result</span><span>&lt;</span><span>StartDebuggingRequestArgumentsRequest</span><span>, </span><span>String</span><span>&gt; {</span></span>
<span data-line=""><span>        Err</span><span>(</span><span>"`dap_request_kind` not implemented"</span><span>.</span><span>to_string</span><span>())</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>    /// Converts a high-level definition of a debug scenario (originating in a new session UI) to a "low-level" configuration suitable for a particular adapter.</span></span>
<span data-line=""><span>    ///</span></span>
<span data-line=""><span>    /// In layman's terms: given a program, list of arguments, current working directory and environment variables,</span></span>
<span data-line=""><span>    /// create a configuration that can be used to start a debug session.</span></span>
<span data-line=""><span>    fn</span><span> dap_config_to_scenario</span><span>(&amp;</span><span>mut</span><span> self</span><span>, </span><span>_config</span><span>: </span><span>DebugConfig</span><span>) -&gt; </span><span>Result</span><span>&lt;</span><span>DebugScenario</span><span>, </span><span>String</span><span>&gt; {</span></span>
<span data-line=""><span>        Err</span><span>(</span><span>"`dap_config_to_scenario` not implemented"</span><span>.</span><span>to_string</span><span>())</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    /// Locators are entities that convert a Zed task into a debug scenario.</span></span>
<span data-line=""><span>    ///</span></span>
<span data-line=""><span>    /// They can be provided even by extensions that don't provide a debug adapter.</span></span>
<span data-line=""><span>    /// For all tasks applicable to a given buffer, Zed will query all locators to find one that can turn the task into a debug scenario.</span></span>
<span data-line=""><span>    /// A converted debug scenario can include a build task (it shouldn't contain any configuration in such case); a build task result will later</span></span>
<span data-line=""><span>    /// be resolved with [`Extension::run_dap_locator`].</span></span>
<span data-line=""><span>    ///</span></span>
<span data-line=""><span>    /// To work through a real-world example, take a `cargo run` task and a hypothetical `cargo` locator:</span></span>
<span data-line=""><span>    /// 1. We may need to modify the task; in this case, it is problematic that `cargo run` spawns a binary. We should turn `cargo run` into a debug scenario with</span></span>
<span data-line=""><span>    /// `cargo build` task. This is the decision we make at `dap_locator_create_scenario` scope.</span></span>
<span data-line=""><span>    /// 2. Then, after the build task finishes, we will run `run_dap_locator` of the locator that produced the build task to find the program to be debugged. This function</span></span>
<span data-line=""><span>    /// should give us a debugger-agnostic configuration for launching a debug target (that we end up resolving with [`Extension::dap_config_to_scenario`]). It's almost as if the user</span></span>
<span data-line=""><span>    /// found the artifact path by themselves.</span></span>
<span data-line=""><span>    ///</span></span>
<span data-line=""><span>    /// Note that you're not obliged to use build tasks with locators. Specifically, it is sufficient to provide a debug configuration directly in the return value of</span></span>
<span data-line=""><span>    /// `dap_locator_create_scenario` if you're able to do that. Make sure to not fill out `build` field in that case, as that will prevent Zed from running second phase of resolution in such case.</span></span>
<span data-line=""><span>    /// This might be of particular relevance to interpreted languages.</span></span>
<span data-line=""><span>    fn</span><span> dap_locator_create_scenario</span><span>(</span></span>
<span data-line=""><span>        &amp;</span><span>mut</span><span> self</span><span>,</span></span>
<span data-line=""><span>        _locator_name</span><span>: </span><span>String</span><span>,</span></span>
<span data-line=""><span>        _build_task</span><span>: </span><span>TaskTemplate</span><span>,</span></span>
<span data-line=""><span>        _resolved_label</span><span>: </span><span>String</span><span>,</span></span>
<span data-line=""><span>        _debug_adapter_name</span><span>: </span><span>String</span><span>,</span></span>
<span data-line=""><span>    ) -&gt; </span><span>Option</span><span>&lt;</span><span>DebugScenario</span><span>&gt; {</span></span>
<span data-line=""><span>        None</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    /// Runs the second phase of locator resolution.</span></span>
<span data-line=""><span>    /// See [`Extension::dap_locator_create_scenario`] for a hefty comment on locators.</span></span>
<span data-line=""><span>    fn</span><span> run_dap_locator</span><span>(</span></span>
<span data-line=""><span>        &amp;</span><span>mut</span><span> self</span><span>,</span></span>
<span data-line=""><span>        _locator_name</span><span>: </span><span>String</span><span>,</span></span>
<span data-line=""><span>        _build_task</span><span>: </span><span>TaskTemplate</span><span>,</span></span>
<span data-line=""><span>    ) -&gt; </span><span>Result</span><span>&lt;</span><span>DebugRequest</span><span>, </span><span>String</span><span>&gt; {</span></span>
<span data-line=""><span>        Err</span><span>(</span><span>"`run_dap_locator` not implemented"</span><span>.</span><span>to_string</span><span>())</span></span>
<span data-line=""><span>    }</span></span></code></pre></div></figure>
<p>Adding DAP support via an extension involves defining a custom schema that integrates with our JSON server, implementing logic for downloading and launching the adapter, processing debug configuration to add sane default values, and integrating with locators for automatic configuration.
This design follows our approach to LSP extensions, giving extension authors full control to bring their own debug adapters to Zed with minimal friction.</p>
<p>We also wanted inline variable values to work out of the box.
Surprisingly, the <a href="https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/#textDocument_inlineValue">inline values request</a> is a part of the <a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol (LSP)</a> instead of the DAP.
Using the inline values approach would limit Zed to only showing inline values for DAPs which integrate with LSPs, which isn't many.
A naive workaround might be to use regular expressions to match variable names between the source code and debugger values, but that quickly breaks down when dealing with scopes, and comments.
Instead, we turned to <a href="https://tree-sitter.github.io/tree-sitter/">Tree-sitter</a>. After all Zed is built by the creators of Tree-sitter!</p>
<div><figure><img src="https://zed.dev/img/debugger/inline-values.webp" alt="An inline value example."><figcaption>An inline value example.</figcaption></figure></div>
<p>Through Tree-sitter queries, we can accurately identify variables within the current execution scope, and easily support any language through <code>.scm</code> files without relying on an LSP server to be tightly integrated with a debug adapter.
At launch, inline values are supported for Python, Rust, and Go.
More languages will be supported in the coming weeks.</p>
<h2 id="whats-next"><a href="#whats-next" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>What's Next</span></a></h2>
<p>When we set out to build the debugger, we wanted to make it seamless to use, out of the way, and in line with Zed's high standard of quality.
Now that we've built a strong foundation that is compatible with any debug adapter, we're ready to explore and implement advanced features such as:</p>
<ul>
<li>New views: While we support all the fundamental views, we're planning on adding more advanced views such as a watch list, memory view, disassembly view, and a stack trace view</li>
<li>Automatic configuration: We're going to add support for more languages and build systems</li>
<li>Polish and more: reach out to us <a href="https://discord.com/invite/qSDQ8VWc7k">on Discord</a> or <a href="https://github.com/zed-industries/zed/issues">on Zed's GitHub repo</a> to let us know!</li>
</ul><hr></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TI to invest $60B to manufacture foundational semiconductors in the U.S. (251 pts)]]></title>
            <link>https://www.ti.com/about-ti/newsroom/news-releases/2025/texas-instruments-plans-to-invest-more-than--60-billion-to-manufacture-billions-of-foundational-semiconductors-in-the-us.html</link>
            <guid>44314759</guid>
            <pubDate>Thu, 19 Jun 2025 01:50:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ti.com/about-ti/newsroom/news-releases/2025/texas-instruments-plans-to-invest-more-than--60-billion-to-manufacture-billions-of-foundational-semiconductors-in-the-us.html">https://www.ti.com/about-ti/newsroom/news-releases/2025/texas-instruments-plans-to-invest-more-than--60-billion-to-manufacture-billions-of-foundational-semiconductors-in-the-us.html</a>, See on <a href="https://news.ycombinator.com/item?id=44314759">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-lid="richText_218e"><p><b>NEWS HIGHLIGHTS:</b></p>
<ul>
<li>More than $60 billion investment includes seven U.S. semiconductor fabs across three manufacturing mega-sites in Texas and Utah supporting more than 60,000 new U.S. jobs</li>
<li>Largest investment in foundational semiconductor manufacturing in&nbsp;U.S.&nbsp;history, building on TI‚Äôs almost-100-year legacy</li>
<li>TI‚Äôs largest mega-site in Sherman, Texas includes investment of up to $40 billion dollars for four fabs: SM1 and SM2 ‚Äì already underway ‚Äì and two additional fabs, SM3 and SM4</li>
<li>Leverages TI‚Äôs strengths as a global technology and manufacturing leader to advance critical innovations from vehicles to smartphones to data centers</li>
</ul>
<p><b>DALLAS, </b>June 18, 2025 ‚Äì Texas Instruments (TI) (Nasdaq: TXN) today announced its plans to invest more than $60 billion across seven U.S. semiconductor fabs, making this the largest investment in foundational semiconductor manufacturing in U.S. history. Working with the Trump administration and building on the company‚Äôs nearly 100-year legacy, TI is expanding its U.S. manufacturing capacity to supply the growing need for semiconductors that will advance critical innovations from vehicles to smartphones to data centers. Combined, TI‚Äôs new manufacturing mega-sites in Texas and Utah will support more than 60,000 U.S. jobs.</p>
<p>‚ÄúTI is building dependable, low-cost 300mm capacity at scale to deliver the analog and embedded processing chips that are vital for nearly every type of electronic system,‚Äù said Haviv Ilan, president and CEO of Texas Instruments. ‚ÄúLeading U.S. companies such as Apple, Ford, Medtronic, NVIDIA and SpaceX rely on TI‚Äôs world-class technology and manufacturing expertise, and we are honored to work alongside them and the U.S. government to unleash what‚Äôs next in American innovation.‚Äù</p>
<p>‚ÄúFor nearly a century, Texas Instruments has been a bedrock American company driving innovation in technology and manufacturing,‚Äù said U.S. Secretary of Commerce, Howard Lutnick. ‚ÄúPresident Trump has made it a priority to increase semiconductor manufacturing in America ‚Äì including these foundational semiconductors that go into the electronics that people use every day. Our partnership with TI will support U.S. chip manufacturing for decades to come.‚Äù</p>
</div><div data-lid="richText_402c"><p><b>Unleashing what‚Äôs next in American innovation</b></p>
<p>Today, TI is the largest foundational semiconductor manufacturer in the U.S., producing analog and embedded processing chips that are critical for smartphones, vehicles, data centers, satellites and nearly every other electronic device. In order to meet the steadily growing demand for these essential chips, TI is building on its legacy of technology leadership and expanding its U.S. manufacturing presence to help its customers pioneer the next wave of technological breakthroughs.</p>
<p><b>Igniting intelligence with Apple</b></p>
<p>‚ÄúTexas Instruments' American-made chips help bring Apple products to life, and together, we‚Äôll continue to create opportunity, drive innovation, and invest in the future of advanced manufacturing across the U.S.,‚Äù said Apple‚Äôs CEO Tim Cook.</p>
<p><b>Fueling the future with Ford</b></p>
<p>Ford and TI are working to strengthen American manufacturing, combining Ford‚Äôs automotive expertise with TI‚Äôs semiconductor technology to help drive innovation and secure a robust, domestic supply chain for the future of mobility. ‚ÄúAt Ford, 80% of the vehicles we sell in the U.S. are assembled in the U.S., and we are proud to stand with technology leaders like TI that continue to invest in manufacturing in the U.S.,‚Äù said Jim Farley, President and CEO of Ford Motor Company.</p>
<p><b>Connecting patient care with Medtronic</b></p>
<p>Medtronic and TI are partnering to improve lives when it matters most. ‚ÄúAt Medtronic, our life-saving medical technologies rely on semiconductors to deliver precision, performance, and innovation at scale,‚Äù said Geoff Martha, Medtronic chairman and CEO. ‚ÄúTexas Instruments has been a vital partner ‚Äì especially during the global chip shortages ‚Äì helping us maintain supply continuity and accelerate the development of breakthrough therapies. We‚Äôre proud to leverage TI‚Äôs U.S.-manufactured semiconductors as we work to transform healthcare and improve outcomes for patients around the world.‚Äù</p>
<p><b>Advancing AI with NVIDIA</b></p>
<p>NVIDIA is partnering with TI to unleash the next generation of artificial intelligence architectures. ‚ÄúNVIDIA and TI share the goal to revitalize U.S. manufacturing by building more of the infrastructure for AI factories here in the U.S.,‚Äù said Jensen Huang, founder and CEO of NVIDIA. ‚ÄúWe look forward to continuing our collaboration with TI by developing products for advanced AI infrastructure.‚Äù</p>
<p><b>Securing high-speed satellite internet with SpaceX</b></p>
<p>SpaceX is increasingly leveraging TI‚Äôs high-speed process technology to connect its Starlink satellite internet service with TI‚Äôs latest 300mm SiGe technology manufactured in Sherman, Texas. ‚ÄúOur fundamental mission is to revolutionize global connectivity and eliminate the digital divide. Core to this mission is constantly pushing the boundaries of what is possible,‚Äù said Gwynne Shotwell, president and COO of SpaceX. ‚ÄúSpaceX is manufacturing tens of thousands of Starlink kits a day ‚Äì all right here in the U.S. ‚Äì and we are making huge investments in PCB manufacturing and silicon packaging to expand even further. TI‚Äôs U.S.-made semiconductors are crucial for securing a U.S. supply chain for our products, and their advanced silicon manufacturing capabilities provide the performance and reliability needed to help us meet the growing demand for high-speed internet all around the world.‚Äù</p>
</div><div data-lid="richText_8687"><p><b>Backed by the strength of TI‚Äôs U.S. manufacturing presence</b></p>
<p>TI is a driving force behind the return and expansion of semiconductor manufacturing in the U.S. The company‚Äôs more than $60 billion investment in U.S. manufacturing includes building and ramping seven, large-scale, connected fabs. Combined, these fabs across three manufacturing mega-sites in Texas and Utah will manufacture hundreds of millions of U.S.-made chips daily that will ignite a bold new chapter in American innovation.</p>
<ul>
<li><b>Sherman, Texas: </b>SM1, TI‚Äôs first new fab in Sherman will begin initial production this year, just three years after breaking ground. Construction is also complete on the exterior shell of SM2, TI‚Äôs second new fab in Sherman. Incremental investment plans include two additional fabs, SM3 and SM4, to support future demand.</li>
<li><b>Richardson, Texas:</b> TI‚Äôs second fab in Richardson, RFAB2, continues to ramp to full production and builds on the company‚Äôs legacy of introducing the world‚Äôs first 300mm analog fab, RFAB1, in 2011.</li>
<li><b>Lehi, Utah: </b>TI is ramping LFAB1, the company‚Äôs first 300mm wafer fab in Lehi. Construction is also well underway on LFAB2, TI‚Äôs second Lehi fab that will connect to LFAB1.</li>
</ul>
<p><b>Learn more</b></p>
<ul>
<li><a href="https://www.ti.com/about-ti/newsroom/media-resources/press-kits/ti-invests-60-billion-in-us-manufacturing.html">Press kit</a> (includes images, video b-roll and fact sheet)</li>
<li>Additional press kits (<a href="https://www.ti.com/about-ti/newsroom/media-resources/press-kits/sherman-texas-press-kit.html">Sherman, Texas</a>, <a href="https://www.ti.com/about-ti/newsroom/media-resources/press-kits/lehi-utah-press-kit.html">Lehi, Utah</a>, and <a href="https://www.ti.com/about-ti/newsroom/media-resources/press-kits/richardson-texas-press-kit.html">Richardson, Texas</a>)</li>
</ul>
<p><b>About Texas Instruments</b></p>
<p>Texas Instruments Incorporated (Nasdaq: TXN) is a global semiconductor company that designs, manufactures, and sells analog and embedded processing chips for markets such as industrial, automotive, personal electronics, communications equipment and enterprise systems. At our core, we have a passion to create a better world by making electronics more affordable through semiconductors. This passion is alive today as each generation of innovation builds upon the last to make our technology more reliable, more affordable and lower power, making it possible for semiconductors to go into electronics everywhere. Learn more at&nbsp;<a href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=4167832-1&amp;h=2361819976&amp;u=https%3A%2F%2Fc212.net%2Fc%2Flink%2F%3Ft%3D0%26l%3Den%26o%3D2849181-1%26h%3D2359332189%26u%3Dhttp%253A%252F%252Fwww.ti.com%252F%26a%3DTI.com&amp;a=TI.com">TI.com</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Andrej Karpathy: Software in the era of AI [video] (825 pts)]]></title>
            <link>https://www.youtube.com/watch?v=LCEmiRjPEtQ</link>
            <guid>44314423</guid>
            <pubDate>Thu, 19 Jun 2025 00:33:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=LCEmiRjPEtQ">https://www.youtube.com/watch?v=LCEmiRjPEtQ</a>, See on <a href="https://news.ycombinator.com/item?id=44314423">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[MCP Specification ‚Äì version 2025-06-18 changes (168 pts)]]></title>
            <link>https://modelcontextprotocol.io/specification/2025-06-18/changelog</link>
            <guid>44314289</guid>
            <pubDate>Wed, 18 Jun 2025 23:59:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://modelcontextprotocol.io/specification/2025-06-18/changelog">https://modelcontextprotocol.io/specification/2025-06-18/changelog</a>, See on <a href="https://news.ycombinator.com/item?id=44314289">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><main><span></span><div id="content-container"><div id="content-area">
<p>This document lists changes made to the Model Context Protocol (MCP) specification since
the previous revision, <a href="https://modelcontextprotocol.io/specification/2025-03-26">2025-03-26</a>.</p>
<h2 id="major-changes"><span>Major changes</span></h2>
<ol>
<li>Remove support for JSON-RPC <strong><a href="https://www.jsonrpc.org/specification#batch" target="_blank" rel="noreferrer">batching</a></strong>
(PR <a href="https://github.com/modelcontextprotocol/specification/pull/416" target="_blank" rel="noreferrer">#416</a>)</li>
<li>Add support for <a href="https://modelcontextprotocol.io/specification/2025-06-18/server/tools#structured-content">structured tool output</a>
(PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/371" target="_blank" rel="noreferrer">#371</a>)</li>
<li>Classify MCP servers as <a href="https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization#authorization-server-discovery">OAuth Resource Servers</a>,
adding protected resource metadata to discover the corresponding Authorization server.
(PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/338" target="_blank" rel="noreferrer">#338</a>)</li>
<li>Require MCP clients to implement Resource Indicators as described in <a href="https://www.rfc-editor.org/rfc/rfc8707.html" target="_blank" rel="noreferrer">RFC 8707</a> to prevent
malicious servers from obtaining access tokens.
(PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/734" target="_blank" rel="noreferrer">#734</a>)</li>
<li>Clarify <a href="https://modelcontextprotocol.io/specification/2025-06-18/basic/authorization#security-considerations">security considerations</a> and best practices
in the authorization spec and in a new <a href="https://modelcontextprotocol.io/specification/2025-06-18/basic/security_best_practices">security best practices page</a>.</li>
<li>Add support for <strong><a href="https://modelcontextprotocol.io/specification/2025-06-18/client/elicitation">elicitation</a></strong>, enabling servers to request additional
information from users during interactions.
(PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/382" target="_blank" rel="noreferrer">#382</a>)</li>
<li>Add support for <strong><a href="https://modelcontextprotocol.io/specification/2025-06-18/server/tools#resource-links">resource links</a></strong> in
tool call results. (PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/603" target="_blank" rel="noreferrer">#603</a>)</li>
<li>Require <a href="https://modelcontextprotocol.io/specification/2025-06-18/basic/transports#protocol-version-header">negotiated protocol version to be specified</a>
via <code>MCP-Protocol-Version</code> header in subsequent requests when using HTTP (PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/548" target="_blank" rel="noreferrer">#548</a>).</li>
<li>Change <strong>SHOULD</strong> to <strong>MUST</strong> in <a href="https://modelcontextprotocol.io/specification/2025-06-18/basic/lifecycle#operation">Lifecycle Operation</a></li>
</ol>
<h2 id="other-schema-changes"><span>Other schema changes</span></h2>
<ol>
<li>Add <code>_meta</code> field to additional interface types (PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/710" target="_blank" rel="noreferrer">#710</a>),
and specify <a href="https://modelcontextprotocol.io/specification/2025-06-18/basic#meta">proper usage</a>.</li>
<li>Add <code>context</code> field to <code>CompletionRequest</code>, providing for completion requests to include
previously-resolved variables (PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/598" target="_blank" rel="noreferrer">#598</a>).</li>
<li>Add <code>title</code> field for human-friendly display names, so that <code>name</code> can be used as a programmatic
identifier (PR <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/663" target="_blank" rel="noreferrer">#663</a>)</li>
</ol>
<h2 id="full-changelog"><span>Full changelog</span></h2>
<p>For a complete list of all changes that have been made since the last protocol revision,
<a href="https://github.com/modelcontextprotocol/specification/compare/2025-03-26...2025-06-18" target="_blank" rel="noreferrer">see GitHub</a>.</p></div><div id="content-side-layout"><ul id="table-of-contents-content"><li data-depth="0"><a href="#major-changes">Major changes</a></li><li data-depth="0"><a href="#other-schema-changes">Other schema changes</a></li><li data-depth="0"><a href="#full-changelog">Full changelog</a></li></ul></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Unregistry ‚Äì "docker push" directly to servers without a registry (532 pts)]]></title>
            <link>https://github.com/psviderski/unregistry</link>
            <guid>44314085</guid>
            <pubDate>Wed, 18 Jun 2025 23:17:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/psviderski/unregistry">https://github.com/psviderski/unregistry</a>, See on <a href="https://news.ycombinator.com/item?id=44314085">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
  <p><a target="_blank" rel="noopener noreferrer" href="https://github.com/psviderski/unregistry/blob/main/.github/images/logo-light.svg#gh-light-mode-only"><img src="https://github.com/psviderski/unregistry/raw/main/.github/images/logo-light.svg#gh-light-mode-only" alt="Unregistry logo"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/psviderski/unregistry/blob/main/.github/images/logo-dark.svg#gh-dark-mode-only"><img src="https://github.com/psviderski/unregistry/raw/main/.github/images/logo-dark.svg#gh-dark-mode-only" alt="Unregistry logo"></a></p><p dir="auto"><strong>‚ñ∏ Push docker images directly to remote servers without an external registry ‚óÇ</strong></p>
  <p dir="auto">
    <a href="https://discord.gg/eR35KQJhPu" rel="nofollow"><img src="https://camo.githubusercontent.com/bce982f6fd064725216dd2c5bbfc5fa12afeaee92ae5d356ea3f5abf78d0ad88/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646973636f72642d3538363546322e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d646973636f7264266c6f676f436f6c6f723d7768697465" alt="Join Discord" data-canonical-src="https://img.shields.io/badge/discord-5865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white"></a>
    <a href="https://x.com/psviderski" rel="nofollow"><img src="https://camo.githubusercontent.com/7ef3b84c3487de0b84ead3bc3ac609c4cbaa26f231976bbdf4e56b855dfaf42d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f666f6c6c6f772d626c61636b3f7374796c653d666f722d7468652d6261646765266c6f676f3d58266c6f676f436f6c6f723d7768696c65" alt="Follow on X" data-canonical-src="https://img.shields.io/badge/follow-black?style=for-the-badge&amp;logo=X&amp;logoColor=while"></a>
  </p>
</div>
<p dir="auto">Unregistry is a lightweight container image registry that stores and serves images directly from your Docker daemon's
storage.</p>
<p dir="auto">The included <code>docker pussh</code> command (extra 's' for SSH) lets you push images straight to remote Docker servers over SSH.
It transfers only the missing layers, making it fast and efficient.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description docker-pussh-demo.mp4">docker-pussh-demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/783910/456396282-9d704b87-8e0d-4c8a-9544-17d4c63bd050.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAyOTY5MDEsIm5iZiI6MTc1MDI5NjYwMSwicGF0aCI6Ii83ODM5MTAvNDU2Mzk2MjgyLTlkNzA0Yjg3LThlMGQtNGM4YS05NTQ0LTE3ZDRjNjNiZDA1MC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjE5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYxOVQwMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04NWQzNjViYWFlNTI3MjA0MTgxOTUyZWZiMDc5NTkxMThmMjM2MjQwNDI3MWU3ZDc1YTg0NGRmMjcyNTFmYWNiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.kp-WEQJdsYOZa8e8DyU8_JbguC9jt8GXLWSwGsF4o4k" data-canonical-src="https://private-user-images.githubusercontent.com/783910/456396282-9d704b87-8e0d-4c8a-9544-17d4c63bd050.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAyOTY5MDEsIm5iZiI6MTc1MDI5NjYwMSwicGF0aCI6Ii83ODM5MTAvNDU2Mzk2MjgyLTlkNzA0Yjg3LThlMGQtNGM4YS05NTQ0LTE3ZDRjNjNiZDA1MC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjE5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYxOVQwMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04NWQzNjViYWFlNTI3MjA0MTgxOTUyZWZiMDc5NTkxMThmMjM2MjQwNDI3MWU3ZDc1YTg0NGRmMjcyNTFmYWNiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.kp-WEQJdsYOZa8e8DyU8_JbguC9jt8GXLWSwGsF4o4k" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">The problem</h2><a id="user-content-the-problem" aria-label="Permalink: The problem" href="#the-problem"></a></p>
<p dir="auto">You've built a Docker image locally. Now you need it on your server. Your options suck:</p>
<ul dir="auto">
<li><strong>Docker Hub / GitHub Container Registry</strong> - Your code is now public, or you're paying for private repos</li>
<li><strong>Self-hosted registry</strong> - Another service to maintain, secure, and pay for storage</li>
<li><strong>Save/Load</strong> - <code>docker save | ssh | docker load</code> transfers the entire image, even if 90% already exists on the server</li>
<li><strong>Rebuild remotely</strong> - Wastes time and server resources. Plus now you're debugging why the build fails in production</li>
</ul>
<p dir="auto">You just want to move an image from A to B. Why is this so hard?</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The solution</h2><a id="user-content-the-solution" aria-label="Permalink: The solution" href="#the-solution"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="docker pussh myapp:latest user@server"><pre>docker pussh myapp:latest user@server</pre></div>
<p dir="auto">That's it. Your image is on the remote server. No registry setup, no subscription, no intermediate storage, no
exposed ports. Just a <strong>direct transfer</strong> of the <strong>missing layers</strong> over SSH.</p>
<p dir="auto">Here's what happens under the hood:</p>
<ol dir="auto">
<li>Establishes SSH tunnel to the remote server</li>
<li>Starts a temporary unregistry container</li>
<li>Forwards a random localhost port to the unregistry port over the tunnel</li>
<li><code>docker push</code> to unregistry through the forwarded port, transferring only the layers that don't already exist
remotely. The transferred image is instantly available on the remote Docker daemon</li>
<li>Stops the unregistry container and closes the SSH tunnel</li>
</ol>
<p dir="auto">It's like <code>rsync</code> for Docker images ‚Äî simple and efficient.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Unregistry was created for <a href="https://github.com/psviderski/uncloud">Uncloud</a>, a lightweight tool for deploying
containers across multiple Docker hosts. We needed something simpler than a full registry but more efficient than
save/load.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">macOS/Linux via Homebrew</h3><a id="user-content-macoslinux-via-homebrew" aria-label="Permalink: macOS/Linux via Homebrew" href="#macoslinux-via-homebrew"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="brew install psviderski/tap/docker-pussh"><pre>brew install psviderski/tap/docker-pussh</pre></div>
<p dir="auto">After installation, to use <code>docker-pussh</code> as a Docker CLI plugin (<code>docker pussh</code> command) you need to create a symlink:</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir -p ~/.docker/cli-plugins
ln -sf $(brew --prefix)/bin/docker-pussh ~/.docker/cli-plugins/docker-pussh"><pre>mkdir -p <span>~</span>/.docker/cli-plugins
ln -sf <span><span>$(</span>brew --prefix<span>)</span></span>/bin/docker-pussh <span>~</span>/.docker/cli-plugins/docker-pussh</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">macOS/Linux via direct download</h3><a id="user-content-macoslinux-via-direct-download" aria-label="Permalink: macOS/Linux via direct download" href="#macoslinux-via-direct-download"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download the latest version
curl -sSL https://raw.githubusercontent.com/psviderski/unregistry/main/docker-pussh \
  -o ~/.docker/cli-plugins/docker-pussh

# Make it executable
chmod +x ~/.docker/cli-plugins/docker-pussh"><pre><span><span>#</span> Download the latest version</span>
curl -sSL https://raw.githubusercontent.com/psviderski/unregistry/main/docker-pussh \
  -o <span>~</span>/.docker/cli-plugins/docker-pussh

<span><span>#</span> Make it executable</span>
chmod +x <span>~</span>/.docker/cli-plugins/docker-pussh</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Windows</h3><a id="user-content-windows" aria-label="Permalink: Windows" href="#windows"></a></p>
<p dir="auto">Windows is not currently supported, but you can try using <a href="https://docs.docker.com/desktop/features/wsl/" rel="nofollow">WSL 2</a>
with the above Linux instructions.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Verify installation</h3><a id="user-content-verify-installation" aria-label="Permalink: Verify installation" href="#verify-installation"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Push an image to a remote server. Please make sure the SSH user has permissions to run <code>docker</code> commands (user is
<code>root</code> or non-root user is in <code>docker</code> group). If <code>sudo</code> is required, ensure the user can run <code>sudo docker</code> without
a password prompt.</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker pussh myapp:latest user@server.example.com"><pre>docker pussh myapp:latest user@server.example.com</pre></div>
<p dir="auto">With SSH key authentication if the private key is not added to your SSH agent:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker pussh myapp:latest ubuntu@192.168.1.100 -i ~/.ssh/id_rsa"><pre>docker pussh myapp:latest ubuntu@192.168.1.100 -i <span>~</span>/.ssh/id_rsa</pre></div>
<p dir="auto">Using a custom SSH port:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker pussh myapp:latest user@server:2222"><pre>docker pussh myapp:latest user@server:2222</pre></div>
<p dir="auto">Push a specific platform for a multi-platform image. The local Docker has to use
<a href="https://docs.docker.com/desktop/features/containerd/" rel="nofollow">containerd image store</a> to support multi-platform images.</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker pussh myapp:latest user@server --platform linux/amd64"><pre>docker pussh myapp:latest user@server --platform linux/amd64</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Use cases</h2><a id="user-content-use-cases" aria-label="Permalink: Use cases" href="#use-cases"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Deploy to production servers</h3><a id="user-content-deploy-to-production-servers" aria-label="Permalink: Deploy to production servers" href="#deploy-to-production-servers"></a></p>
<p dir="auto">Build locally and push directly to your production servers. No middleman.</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker build --platform linux/amd64 -t myapp:1.2.3 .
docker pussh myapp:1.2.3 deploy@prod-server
ssh deploy@prod-server docker run -d myapp:1.2.3"><pre>docker build --platform linux/amd64 -t myapp:1.2.3 <span>.</span>
docker pussh myapp:1.2.3 deploy@prod-server
ssh deploy@prod-server docker run -d myapp:1.2.3</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">CI/CD pipelines</h3><a id="user-content-cicd-pipelines" aria-label="Permalink: CI/CD pipelines" href="#cicd-pipelines"></a></p>
<p dir="auto">Skip the registry complexity in your pipelines. Build and push directly to deployment targets.</p>
<div dir="auto" data-snippet-clipboard-copy-content="- name: Build and deploy
  run: |
    docker build -t myapp:${{ github.sha }} .
    docker pussh myapp:${{ github.sha }} deploy@staging-server"><pre>- <span>name</span>: <span>Build and deploy</span>
  <span>run</span>: <span>|</span>
<span>    docker build -t myapp:${{ github.sha }} .</span>
<span>    docker pussh myapp:${{ github.sha }} deploy@staging-server</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Homelab and air-gapped environments</h3><a id="user-content-homelab-and-air-gapped-environments" aria-label="Permalink: Homelab and air-gapped environments" href="#homelab-and-air-gapped-environments"></a></p>
<p dir="auto">Distribute images in isolated networks without exposing them to the internet.</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker pussh image:latest user@192.168.1.100"><pre>docker pussh image:latest user@192.168.1.100</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">On local machine</h3><a id="user-content-on-local-machine" aria-label="Permalink: On local machine" href="#on-local-machine"></a></p>
<ul dir="auto">
<li>Docker CLI with plugin support (Docker 19.03+)</li>
<li>OpenSSH client</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">On remote server</h3><a id="user-content-on-remote-server" aria-label="Permalink: On remote server" href="#on-remote-server"></a></p>
<ul dir="auto">
<li>Docker is installed and running</li>
<li>SSH user has permissions to run <code>docker</code> commands (user is <code>root</code> or non-root user is in <code>docker</code> group)</li>
<li>If <code>sudo</code> is required, ensure the user can run <code>sudo docker</code> without a password prompt</li>
</ul>
<div dir="auto"><p dir="auto">Tip</p><p dir="auto">The remote Docker daemon works best with <a href="https://docs.docker.com/engine/storage/containerd/" rel="nofollow">containerd image store</a>
enabled. This allows unregistry to access images more efficiently.</p>
<p dir="auto">Add the following configuration to <code>/etc/docker/daemon.json</code> on the remote server and restart the <code>docker</code> service:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;features&quot;: {
    &quot;containerd-snapshotter&quot;: true
  }
}"><pre>{
  <span>"features"</span>: {
    <span>"containerd-snapshotter"</span>: <span>true</span>
  }
}</pre></div>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Advanced usage</h2><a id="user-content-advanced-usage" aria-label="Permalink: Advanced usage" href="#advanced-usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running unregistry standalone</h3><a id="user-content-running-unregistry-standalone" aria-label="Permalink: Running unregistry standalone" href="#running-unregistry-standalone"></a></p>
<p dir="auto">Sometimes you want a local registry without the overhead. Unregistry works great for this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Run unregistry locally and expose it on port 5000
docker run -d -p 5000:5000 --name unregistry \
  -v /run/containerd/containerd.sock:/run/containerd/containerd.sock \
  ghcr.io/psviderski/unregistry

# Use it like any registry
docker tag myapp:latest localhost:5000/myapp:latest
docker push localhost:5000/myapp:latest"><pre><span><span>#</span> Run unregistry locally and expose it on port 5000</span>
docker run -d -p 5000:5000 --name unregistry \
  -v /run/containerd/containerd.sock:/run/containerd/containerd.sock \
  ghcr.io/psviderski/unregistry

<span><span>#</span> Use it like any registry</span>
docker tag myapp:latest localhost:5000/myapp:latest
docker push localhost:5000/myapp:latest</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Custom SSH options</h3><a id="user-content-custom-ssh-options" aria-label="Permalink: Custom SSH options" href="#custom-ssh-options"></a></p>
<p dir="auto">Need custom SSH settings? Use the standard SSH config file:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# ~/.ssh/config
Host prod-server
    HostName server.example.com
    User deploy
    Port 2222
    IdentityFile ~/.ssh/deploy_key

# Now just use
docker pussh myapp:latest prod-server"><pre><span><span>#</span> ~/.ssh/config</span>
Host prod-server
    HostName server.example.com
    User deploy
    Port 2222
    IdentityFile <span>~</span>/.ssh/deploy_key

<span><span>#</span> Now just use</span>
docker pussh myapp:latest prod-server</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Found a bug or have a feature idea? We'd love your help!</p>
<ul dir="auto">
<li>üêõ Found a bug? <a href="https://github.com/psviderski/unregistry/issues">Open an issue</a></li>
<li>üí° Have ideas or need help? <a href="https://discord.gg/eR35KQJhPu" rel="nofollow">Join Uncloud Discord community</a> where we discuss features,
roadmap, implementation details, and help each other out.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Inspiration &amp; acknowledgements</h2><a id="user-content-inspiration--acknowledgements" aria-label="Permalink: Inspiration &amp; acknowledgements" href="#inspiration--acknowledgements"></a></p>
<ul dir="auto">
<li><a href="https://github.com/spegel-org/spegel">Spegel</a> - P2P container image registry that inspired me to implement a
registry that uses containerd image store as a backend.</li>
<li><a href="https://github.com/distribution/distribution">Docker Distribution</a> - the bulletproof Docker registry implementation
that unregistry uses as a base.</li>
</ul>

<p>
  Built with ‚ù§Ô∏è by <a href="https://github.com/psviderski">Pasha Sviderski</a> who just wanted to deploy his images
</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New US visa rules will force foreign students to unlock social media profiles (418 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2025/jun/18/social-media-student-visa-screening</link>
            <guid>44314054</guid>
            <pubDate>Wed, 18 Jun 2025 23:11:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2025/jun/18/social-media-student-visa-screening">https://www.theguardian.com/us-news/2025/jun/18/social-media-student-visa-screening</a>, See on <a href="https://news.ycombinator.com/item?id=44314054">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Foreign students will be required to unlock their social media profiles to allow US diplomats to review their online activity before receiving educational and exchange visas, the state department has announced. Those who fail to do so will be suspected of hiding that activity from US officials.</p><p>The new guidance, unveiled by the state department on Wednesday, directs US diplomats to conduct an online presence review to look for ‚Äúany indications of hostility toward the citizens, culture, government, institutions, or founding principles of the United States‚Äù.</p><p>A cable separately obtained by Politico also instructs diplomats to flag any ‚Äúadvocacy for, aid or support for foreign terrorists and other threats to US national security‚Äù and ‚Äúsupport for unlawful antisemitic harassment or violence‚Äù.</p><p>The screening for ‚Äúantisemitic‚Äù activity matches similar guidance given at US Citizenship and Immigration Services under the Department of Homeland Security and has been criticised as an effort to crack down on opposition to the conduct of Israel‚Äôs war in Gaza.</p><p>The new state department checks are directed at students and other applicants for visas in the F, M and J categories, which refer to academic and vocational education, as well as cultural exchanges.</p><p>‚ÄúIt is an expectation from American citizens that their government will make every effort to make our country safer, and that is exactly what the <a href="https://www.theguardian.com/us-news/trump-administration" data-link-name="in body link" data-component="auto-linked-tag">Trump administration</a> is doing every single day,‚Äù said a senior state department official, adding that Marco Rubio was ‚Äúhelping to make America and its universities safer while bringing the state Department into the 21st century‚Äù.</p><figure id="2c0c0441-fde7-4b33-9f05-c7264f202232" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:6,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;US issues broad order to consulates to vet student visas over ‚Äòterrorist activity‚Äô&quot;,&quot;elementId&quot;:&quot;2c0c0441-fde7-4b33-9f05-c7264f202232&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/us-news/2025/mar/28/student-visa-applications-denials&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>The Trump administration paused the issuance of new education visas late last month as it mulled new social media vetting strategies. The US had also targeted Chinese students for special scrutiny amid a tense negotiation over tariffs and the supply of rare-earth metals and minerals to the United States.</p><p>The state department directive allowed diplomatic posts to resume the scheduling of interviews for educational and exchange visas, but added that consular officers would conduct a ‚Äúcomprehensive and thorough vetting‚Äù of all applicants applying for F, M and J visas.</p><p>‚ÄúTo facilitate this vetting, all applicants for F, M and J non-immigrant visas will be asked to adjust the privacy settings on all their social media profiles to ‚Äòpublic‚Äô‚Äù, the official said. ‚ÄúThe enhanced social media vetting will ensure we are properly screening every single person attempting to visit our country.‚Äù</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fang, the CLI Starter Kit (128 pts)]]></title>
            <link>https://github.com/charmbracelet/fang</link>
            <guid>44313901</guid>
            <pubDate>Wed, 18 Jun 2025 22:40:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/charmbracelet/fang">https://github.com/charmbracelet/fang</a>, See on <a href="https://news.ycombinator.com/item?id=44313901">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Fang</h2><a id="user-content-fang" aria-label="Permalink: Fang" href="#fang"></a></p>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/25087/453127263-3f34ea01-3750-4760-beb2-a1b700e110f5.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTg1MDMsIm5iZiI6MTc1MDMxODIwMywicGF0aCI6Ii8yNTA4Ny80NTMxMjcyNjMtM2YzNGVhMDEtMzc1MC00NzYwLWJlYjItYTFiNzAwZTExMGY1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjE5VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWRiYjlmMzhlMjYxZDQ3NDE3YjcxZWM0NmQyYzgzN2ZhNjE3NTMzZjRhNDZkMGUyMDliMDBjZTlhNGNmODE4OWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.qNmzqtvKLyQgIWOFwgomip_UNof2pDx-LF94v9UhF8M"><img width="485" alt="Charm Fang" src="https://private-user-images.githubusercontent.com/25087/453127263-3f34ea01-3750-4760-beb2-a1b700e110f5.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTg1MDMsIm5iZiI6MTc1MDMxODIwMywicGF0aCI6Ii8yNTA4Ny80NTMxMjcyNjMtM2YzNGVhMDEtMzc1MC00NzYwLWJlYjItYTFiNzAwZTExMGY1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjE5VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWRiYjlmMzhlMjYxZDQ3NDE3YjcxZWM0NmQyYzgzN2ZhNjE3NTMzZjRhNDZkMGUyMDliMDBjZTlhNGNmODE4OWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.qNmzqtvKLyQgIWOFwgomip_UNof2pDx-LF94v9UhF8M"></a>   
</p>
<p dir="auto">
    <a href="https://github.com/charmbracelet/fang/releases"><img src="https://camo.githubusercontent.com/2491a6829151430ac84c5b91f8de86767fdbf15d6f42e35ea9796c0976ca1f6b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f636861726d62726163656c65742f66616e672e737667" alt="Latest Release" data-canonical-src="https://img.shields.io/github/release/charmbracelet/fang.svg"></a>
    <a href="https://pkg.go.dev/github.com/charmbracelet/fang?tab=doc" rel="nofollow"><img src="https://camo.githubusercontent.com/085bf6223c42adfef9036b4df0988091acacbcc7178b35906aa685b6aec2fe19/68747470733a2f2f676f646f632e6f72672f6769746875622e636f6d2f636861726d62726163656c65742f66616e673f7374617475732e737667" alt="GoDoc" data-canonical-src="https://godoc.org/github.com/charmbracelet/fang?status.svg"></a>
    <a href="https://github.com/charmbracelet/fang/actions"><img src="https://github.com/charmbracelet/fang/workflows/build/badge.svg" alt="Build Status"></a>
</p>
<p dir="auto">The CLI starter kit. A small, experimental library for batteries-included <a href="https://github.com/spf13/cobra">Cobra</a> applications.</p>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/25087/456775205-5c35e1fa-9577-4f81-a879-3ddb4d4a43f0.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTg1MDMsIm5iZiI6MTc1MDMxODIwMywicGF0aCI6Ii8yNTA4Ny80NTY3NzUyMDUtNWMzNWUxZmEtOTU3Ny00ZjgxLWE4NzktM2RkYjRkNGE0M2YwLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjE5VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZkYmZhYTVhZTZkZGE4N2QzNTIwYTUwZGI3MTc3NDMyMjY0N2JmZDM1NDMwZjBlZGI2ZDExOTUxN2I4MzQ5OGUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.7PlqhcO-1c4KQCButUYJuiPZ4VZfGu8CAdHDd5_U6W8"><img width="859" alt="The Charm Fang mascot and title treatment" src="https://private-user-images.githubusercontent.com/25087/456775205-5c35e1fa-9577-4f81-a879-3ddb4d4a43f0.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTg1MDMsIm5iZiI6MTc1MDMxODIwMywicGF0aCI6Ii8yNTA4Ny80NTY3NzUyMDUtNWMzNWUxZmEtOTU3Ny00ZjgxLWE4NzktM2RkYjRkNGE0M2YwLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjE5VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZkYmZhYTVhZTZkZGE4N2QzNTIwYTUwZGI3MTc3NDMyMjY0N2JmZDM1NDMwZjBlZGI2ZDExOTUxN2I4MzQ5OGUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.7PlqhcO-1c4KQCButUYJuiPZ4VZfGu8CAdHDd5_U6W8"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>Fancy output</strong>: fully styled help and usage pages</li>
<li><strong>Fancy errors</strong>: fully styled errors</li>
<li><strong>Automatic <code>--version</code></strong>: set it to the <a href="https://pkg.go.dev/runtime/debug#BuildInfo" rel="nofollow">build info</a>, or a version of your choice</li>
<li><strong>Manpages</strong>: Adds a hidden <code>man</code> command to generate <em>manpages</em> using
<a href="https://github.com/muesli/mango">mango</a><sup><a href="#user-content-fn-1-0d05681b58ad0244d82fd35e6e8dccb1" id="user-content-fnref-1-0d05681b58ad0244d82fd35e6e8dccb1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup></li>
<li><strong>Completions</strong>: Adds a <code>completion</code> command to generate shell completions</li>
<li><strong>Themeable</strong>: use the built-in theme, or make your own</li>
<li><strong>UX</strong>: Silent <code>usage</code> output (help is not shown after a user error)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">To use it, invoke <code>fang.Execute</code> passing your root <code>*cobra.Command</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
	&quot;os&quot;

	&quot;github.com/charmbracelet/fang&quot;
	&quot;github.com/spf13/cobra&quot;
)

func main() {
	cmd := &amp;cobra.Command{
		Use:   &quot;example&quot;,
		Short: &quot;A simple example program!&quot;,
	}
	if err := fang.Execute(context.TODO(), cmd); err != nil {
		os.Exit(1)
	}
}"><pre><span>package</span> main

<span>import</span> (
	<span>"os"</span>

	<span>"github.com/charmbracelet/fang"</span>
	<span>"github.com/spf13/cobra"</span>
)

<span>func</span> <span>main</span>() {
	<span>cmd</span> <span>:=</span> <span>&amp;</span>cobra.<span>Command</span>{
		<span>Use</span>:   <span>"example"</span>,
		<span>Short</span>: <span>"A simple example program!"</span>,
	}
	<span>if</span> <span>err</span> <span>:=</span> <span>fang</span>.<span>Execute</span>(<span>context</span>.<span>TODO</span>(), <span>cmd</span>); <span>err</span> <span>!=</span> <span>nil</span> {
		<span>os</span>.<span>Exit</span>(<span>1</span>)
	}
}</pre></div>
<p dir="auto">That's all there is to it!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">See <a href="https://github.com/charmbracelet/fang/contribute">contributing</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feedback</h2><a id="user-content-feedback" aria-label="Permalink: Feedback" href="#feedback"></a></p>
<p dir="auto">We‚Äôd love to hear your thoughts on this project. Feel free to drop us a note!</p>
<ul dir="auto">
<li><a href="https://twitter.com/charmcli" rel="nofollow">Twitter</a></li>
<li><a href="https://charm.sh/chat" rel="nofollow">Discord</a></li>
<li><a href="https://mastodon.social/@charmcli" rel="nofollow">The Fediverse</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto"><a href="https://github.com/charmbracelet/gum/raw/main/LICENSE">MIT</a></p>
<hr>
<p dir="auto">Part of <a href="https://charm.sh/" rel="nofollow">Charm</a>.</p>
<p dir="auto"><a href="https://charm.sh/" rel="nofollow"><img alt="The Charm logo" src="https://camo.githubusercontent.com/bdbe361924a6bb7fbc7e80f53ac2a8dd50c1a85ff952a3063c0fc0cba3a09d6d/68747470733a2f2f73747566662e636861726d2e73682f636861726d2d62616467652e6a7067" width="400" data-canonical-src="https://stuff.charm.sh/charm-badge.jpg"></a></p>
<p dir="auto">CharmÁÉ≠Áà±ÂºÄÊ∫ê ‚Ä¢ Charm loves open source</p>
<section data-footnotes="">
<ol dir="auto">
<li id="user-content-fn-1-0d05681b58ad0244d82fd35e6e8dccb1">
<p dir="auto">Default cobra man pages generates one man page for each command. This is
generally fine for programs with a lot of sub commands, like git, but its an
overkill for smaller programs.
Mango also uses <em>roff</em> directly instead of converting from markdown, so it
should render better looking man pages. <a href="#user-content-fnref-1-0d05681b58ad0244d82fd35e6e8dccb1" data-footnote-backref="" aria-label="Back to reference 1">‚Ü©</a></p>
</li>
</ol>
</section>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Missing 11th of the Month (189 pts)]]></title>
            <link>https://drhagen.com/blog/the-missing-11th-of-the-month/</link>
            <guid>44313550</guid>
            <pubDate>Wed, 18 Jun 2025 21:45:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://drhagen.com/blog/the-missing-11th-of-the-month/">https://drhagen.com/blog/the-missing-11th-of-the-month/</a>, See on <a href="https://news.ycombinator.com/item?id=44313550">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
          
        
      
      <main data-md-component="main">
        <div data-md-component="content">
    
    <article>
      
        


  

<figure>
    <img alt="In months other than September, the 11th is mentioned substantially less often than any other date. It's been that way since long before 9/11 and I have no idea why." src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/calendar_of_meaningful_dates_light.png#only-light">
    <img alt="In months other than September, the 11th is mentioned substantially less often than any other date. It's been that way since long before 9/11 and I have no idea why." src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/calendar_of_meaningful_dates_dark.png#only-dark">
    Source <a href="https://xkcd.com/1140/">xkcd</a>. Image licensed under <a href="https://creativecommons.org/licenses/by-nc/2.5/">CC-BY-NC</a>.
</figure>
<p>On November 28th, 2012, Randall Munroe published <a href="https://xkcd.com/1140/">an xkcd&nbsp;comic</a>&nbsp;that was&nbsp;a calendar in which&nbsp;the size of each date was&nbsp;proportional to&nbsp;how often each date is referenced by its ordinal name&nbsp;(e.g. "October 14th") in the <a href="https://books.google.com/ngrams">Google Ngrams database</a> since 2000. Most of the large&nbsp;days are pretty much what you would expect:&nbsp;<a href="https://en.wikipedia.org/wiki/Independence_Day_(United_States)">July 4th</a>, <a href="https://en.wikipedia.org/wiki/Christmas">December 25th</a>, the 1st of every month, the last day of most months, and of course a <a href="https://en.wikipedia.org/wiki/September_11_attacks">September 11th</a> that shoves&nbsp;its neighbors&nbsp;into the margins. There are not many days that seem to be smaller than the typical size. <a href="https://en.wikipedia.org/wiki/Leap_year">February 29th</a> is a tiny speck, for instance. But if&nbsp;you stare at the comic&nbsp;long enough, you may get the impression that the 11th of most&nbsp;months is unusually small. The title&nbsp;text of the comic concurs, reading "In months other than September, the 11th is mentioned substantially less often than any other date. It's been that way since long before 9/11 and I have no idea why." After digging into the raw data, I believe I have figured out why.</p>
<!-- more -->

<p>First I confirmed&nbsp;that the <code>11th</code> is actually interesting. There are 31 days and one of them <em>has</em> to be smallest. Maybe the <code>11th</code> isn't an outlier; it's just on the smaller end and our eyes&nbsp;are picking up on a pattern that doesn't exist. To confirm this is real,&nbsp;I compared actual numbers, not text size. The Ngrams database returns the total number times a phrase is mentioned in a given year normalized by the total number of books published that year. The database only goes up to the year 2008, so it is presumably unchanged from when Randall queried it in 2012.</p>
<p>I&nbsp;retrieved the count for each day for the year (<code>January 1st</code>, <code>January 2nd</code> etc.) and took the median over the months for each day (median of <code>January 1st</code>, <code>February 1st</code>, etc.) for&nbsp;each year. This summarizes&nbsp;how often the <code>11th</code> and the other 30 days of the month appear in a given year. Using the median prevents outlier days like <code>July 4th</code> from dragging up the average for its&nbsp;corresponding ordinal&nbsp;(the <code>4th</code>). Only if a ordinal&nbsp;is unusual for at least 6&nbsp;of the 12 months will its median appear unusual.</p>
<p>I took the&nbsp;median for each ordinal over the years 2000-2008. The graph below is a histogram of the 31 medians. The <code>1st</code> of the month stands out far above them all&nbsp;and the <code>15th</code> just barely distinguishes itself from the remainder. Being the first day and the middle day of the month, these two make sense.&nbsp;However, the <code>11th</code> stands out as the lowest by a significant&nbsp;margin (p-value &lt; 0.05), with no immediate explanation.</p>
<figure>
    <img alt="histogram_2000-2008" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/histogram_2000-2008_light.png#only-light">
    <img alt="histogram_2000-2008" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/histogram_2000-2008_dark.png#only-dark">
</figure>
<p>This deficit&nbsp;has been around for a long time. Below is all the ordinals for every year in the data set, 1800-2008. The data is smoothed over eleven&nbsp;years to flatten out the noise. Even at the beginning, the <code>11th</code> is significantly lower than the main group. This mild deficit continues for a few decades and then something weird happens in 1860s; the&nbsp;11th suddenly diverges from its place just below the pack. The gap between the <code>11th</code> and the ordinary ordinals expands rapidly until the <code>11th</code> is about half of what one would expect it to be throughout the first half of the twentieth century. The gap shrinks in the second half of the twentieth century, but still&nbsp;persists at a smaller level&nbsp;until&nbsp;the end.</p>
<figure>
    <img alt="ordinals_1800-2008" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/ordinals_1800-2008_light.png#only-light">
    <img alt="ordinals_1800-2008" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/ordinals_1800-2008_dark.png#only-dark">
</figure>
<p>Astute graph readers will notice that something else weird is going on. There are four other lines that are much lower than they should be. From highest to lowest, they are the <code>2nd</code>, the <code>3rd</code>, the <code>22nd</code>, and the <code>23rd</code>.&nbsp;They were&nbsp;even lower than the <code>11th</code> from 1800 until&nbsp;the 1890s. However, starting around 1900, their gaps started shrinking even as the <code>11th</code> diverged until the gap disappeared completely in the 1930s. There is an interesting story there, but because their effect doesn't persist to the present, I'll continue to focus on the <code>11th</code> and leave the others&nbsp;for a <a href="https://drhagen.com/blog/the-missing-23rd-of-the-month/">future post</a>.</p>
<h2 id="typographical-hijinks">Typographical hijinks</h2>
<p>When I began this study, I was hoping to find a hidden taboo of holding events on the 11th or typographical&nbsp;bias&nbsp;against the&nbsp;shorthand ordinal. Alas, the reason is far is far more mundane: a numeral <code>1</code> looks a lot like a capital <code>I</code> or a lowercase <code>l</code> or a lowercase <code>i</code> in most of the fonts used for printing books. An <code>11</code> also looks like an <code>n</code>, apparently. Google's&nbsp;algorithms made mistakes when reading the <code>11th</code> from a page, interpreting&nbsp;the ordinal&nbsp;as some other word.</p>
<p>We can find some of these mistakes by directly searching for nonsense phrases like <code>March&nbsp;llth</code> or <code>July IIth</code> or <code>May iith</code>. There are nine possible combinations&nbsp;of <code>I</code>, <code>l</code>, and <code>i</code> that a <code>11</code> could be mistaken for. &nbsp;Five of them can actually be found in the database for at least one month: <code>IIth</code>, <code>Ilth</code>, <code>iith</code>, <code>lith</code>, and <code>llth</code>. Also found was <code>1lth</code>, <code>1ith</code>, and <code>l1th</code>, in which only one letter was misread. I collectively refer to these errors as&nbsp;<code>xxth</code>.&nbsp;<a href="https://books.google.com/">Google books</a>&nbsp;queries a newer database than the one on which Ngrams was built, but bona fide examples of the misreads can still be found. <a href="https://books.google.com/books?id=OJo3AAAAMAAJ&amp;dq=%22January%20IIth%22&amp;pg=RA3-PA34#v=onepage&amp;q=%22January%20IIth%22&amp;f=false">Here is something</a> that Google books thinks says <code>January IIth</code>: <img alt="January IIth" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/January_IIth_light.png#only-light"><img alt="January IIth" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/January_IIth_dark.png#only-dark">. <a href="https://books.google.com/books?id=EcJQAQAAIAAJ&amp;dq=%22February%20llth%22&amp;pg=RA1-PA79#v=onepage&amp;q=%22February%20llth%22&amp;f=false">And here is one</a> for <code>February llth</code>: <img alt="February llth" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/February_llth_light.png#only-light"><img alt="February llth" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/February_llth_dark.png#only-dark">. <a href="https://books.google.com/books?id=zYHk_df06QsC&amp;dq=%22March%20lith%22&amp;pg=PA402#v=onepage&amp;q=%22March%20lith%22&amp;f=false">And finally one</a>&nbsp;for <code>March lith</code>: <img alt="March lith" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/March_lith_light.png#only-light"><img alt="March lith" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/March_lith_dark.png#only-dark">. There are hordes of these in the database. You can find other ordinals that were misread as well, but the <code>11th</code> with its slender and ambiguous <code>1</code>s was misread far more often than the others.</p>
<p>I added back in every instance of <code>January IIth</code>, <code>January llth</code>, etc. to <code>January 11th</code> and did the same to the other months. The graph below shows that the <code>11th</code> gets a big&nbsp;boost by adding back&nbsp;the&nbsp;nonsense phrases. Before the 1860s,&nbsp;the difference between the <code>11th</code> and the main group&nbsp;is erased. After the 1860s, about a quarter to a third of the difference is erased.</p>
<figure>
    <img alt="xxth_1800-2008" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/xxth_1800-2008_light.png#only-light">
    <img alt="xxth_1800-2008" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/xxth_1800-2008_dark.png#only-dark">
</figure>
<h2 id="to-the-nth-degree">To the nth degree</h2>
<p>So where did&nbsp;the rest of the missing <code>11th</code> go? Well, starting in the 1860s, the Google algorithm starts to make a rather peculiar error‚Äîit misreads <code>11th</code> as <code>nth</code>. <a href="https://books.google.com/books?id=r7QaAAAAYAAJ&amp;dq=%22january%20nth%22&amp;pg=RA1-PA82#v=onepage&amp;q=%22january%20nth%22&amp;f=false">Here is one&nbsp;example from a page full</a> of <code>January nth</code>s: <img alt="January nth" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/January_nth_light.png#only-light"><img alt="January nth" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/January_nth_dark.png#only-dark">. In some years, the number of incorrect reads actually exceeds the number of correct reads. I added <code>January nth</code> to <code>January 11th</code> and did the same for all the months. The graph below shows both the&nbsp;<code>nth</code>&nbsp;and its sum with the <code>11th</code>.&nbsp;There was&nbsp;little impact&nbsp;before the 1860s, but then this error alone accounts for nearly all of the missing <code>11th</code>.</p>
<figure>
    <img alt="nth_1800-2008" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/nth_1800-2008_light.png#only-light">
    <img alt="nth_1800-2008" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/nth_1800-2008_dark.png#only-dark">
</figure>
<h2 id="combined-graph">Combined&nbsp;graph</h2>
<p>When the <code>xxth</code> misreads and&nbsp;<code>nth</code> misreads are both added back into&nbsp;the <code>11th</code>, the gap disappears across the entire timeline and the <code>11th</code>&nbsp;looks like an ordinary day of the year.&nbsp;This suggests that the misreading of the <code>11th</code> as <code>nth</code>, <code>IIth</code>, <code>llth</code>, etc. is sufficient to explain the unusually low incidence of the <code>11th</code> as a day of the month.</p>
<figure>
    <img alt="total_1800-2008" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/total_1800-2008_light.png#only-light">
    <img alt="total_1800-2008" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/total_1800-2008_dark.png#only-dark">
</figure>
<h2 id="typographical-machines">Typographical machines</h2>
<p>While it makes sense that the <code>11th</code> was&nbsp;misread more than others, why is the misread rate not uniform? What happened in the 1860s that caused the dramatic rise in the error rate? I suspect that it has something to do with&nbsp;a special device invented in the 1860s_‚Äî_the typewriter. <a href="https://web.archive.org/web/20190706134959/https://chronicle.com/blogs/linguafranca/2012/03/14/old-style-versus-lining-figures/">The earliest typewriters did not have a separate key for the numeral <code>1</code>.</a>&nbsp;Typists were expected to use the lowercase <code>l</code> to represent a <code>1</code>. When the algorithm read <code>October llth</code>, it was far more&nbsp;correct than we have been&nbsp;giving it credit. There are not that many documents in Google books that are typewritten, but&nbsp;this popular new contraption had a powerful effect on the evolution of fonts. The <code>1</code> and <code>l</code> were identical on the increasingly familiar typewriters, and&nbsp;the fonts even of printed materials began to reflect this expectation. Compare the <code>l</code>s and <code>1</code>s in this font <a href="https://books.google.com/books?id=i-lOAAAAYAAJ&amp;dq=%22january%2011th%22%201850&amp;pg=PA115#v=onepage&amp;q&amp;f=false">from&nbsp;1850</a>: <img alt="council_meeting" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/council_meeting_light.png#only-light"><img alt="council_meeting" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/council_meeting_dark.png#only-dark">.&nbsp;There is a clear difference between an <code>l</code> with no serifs on the top and the <code>1</code> with a pronounced serif. Compare that to a font <a href="https://books.google.com/books?id=STtaT_fheaMC&amp;lpg=PA334&amp;dq=%22january%2011th%22%201920&amp;pg=PA334#v=onepage&amp;q&amp;f=false">from 1920</a>: <img alt="hotel_on_sunday" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/hotel_on_sunday_light.png#only-light"><img alt="hotel_on_sunday" src="https://drhagen.com/blog/2015-12-29-the-missing-11th-of-the-month/images/hotel_on_sunday_dark.png#only-dark">.&nbsp;The characters are identical except for the kerning. Even to this day, most fonts represent both the <code>1</code> and the <code>l</code> as tall characters with two serifs on the bottom and one left-facing serif at the top. The only difference is that the serif on the <code>1</code> is slightly more angled than on the <code>l</code>. (In this post, I used a special monospace font to make it easier to tell the difference.)&nbsp;The print quality of more recent books (post 1970s) has reduced the rate of&nbsp;failure, but it still has not gone away entirely, so that the remaining failures were noticeable in the xkcd comic.</p>
<p>The largest open question is why <code>nth</code> was chosen so often. It seems like such a strange error to make. The word <code>nth</code> is a legal word&nbsp;in mathematical and scientific publications, so that should help its chances of getting picked. In most fonts the top of the <code>n</code> is really thin, and is likely invisible in many texts on which they trained the algorithm. But there is a big different in height between <code>1</code> and <code>n</code>, especially in the typewriter era, which is where the errors occur. And the phrase <code>January nth</code> is nonsense so that should have hurt its chances of being selected. Is it possible there&nbsp;was an error in one of the modern training texts that had an <code>11th</code> labeled as <code>nth</code>, thereby confusing the algorithm? The only way to know for sure would be to crack open the source code of Google's text-reading algorithm. This is left as an exercise for the reader.</p>
<h6 id="the-code-used-for-the-analysis-in-this-post-is-available-on-github">The <a href="https://github.com/drhagen/xkcd11th">code used for the analysis in this post</a> is available on&nbsp;Github.</h6>







  
  




  



<!--  Disqus needs `color-scheme: light;` as the base color scheme -->




      
    </article>
  </div>
        
      </main>
      
        
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bento: A Steam Deck in a Keyboard (256 pts)]]></title>
            <link>https://github.com/lunchbox-computer/bento</link>
            <guid>44313379</guid>
            <pubDate>Wed, 18 Jun 2025 21:21:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lunchbox-computer/bento">https://github.com/lunchbox-computer/bento</a>, See on <a href="https://news.ycombinator.com/item?id=44313379">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Bento</h2><a id="user-content-bento" aria-label="Permalink: Bento" href="#bento"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/19628643/455292447-d9bac3c8-aa03-4546-88ae-747c9bedbc12.jpeg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTEzMDEsIm5iZiI6MTc1MDMxMTAwMSwicGF0aCI6Ii8xOTYyODY0My80NTUyOTI0NDctZDliYWMzYzgtYWEwMy00NTQ2LTg4YWUtNzQ3YzliZWRiYzEyLmpwZWc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjE5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYxOVQwNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0zZjQ0MGY2OTM3NGRlY2FlMjAyZGM2YTRiNmU5N2I2YTM4Yzk3NTc1OTUzZDdiYmVhMDUwNjMwZDY1M2ZlYzA4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.6co6OoyR31ORb0-X9jAkTpHmIrEO2HqaPL4as2Q9mrY"><img src="https://private-user-images.githubusercontent.com/19628643/455292447-d9bac3c8-aa03-4546-88ae-747c9bedbc12.jpeg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTEzMDEsIm5iZiI6MTc1MDMxMTAwMSwicGF0aCI6Ii8xOTYyODY0My80NTUyOTI0NDctZDliYWMzYzgtYWEwMy00NTQ2LTg4YWUtNzQ3YzliZWRiYzEyLmpwZWc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjE5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYxOVQwNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0zZjQ0MGY2OTM3NGRlY2FlMjAyZGM2YTRiNmU5N2I2YTM4Yzk3NTc1OTUzZDdiYmVhMDUwNjMwZDY1M2ZlYzA4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.6co6OoyR31ORb0-X9jAkTpHmIrEO2HqaPL4as2Q9mrY" alt="A photo of Bento, a computer in a keyboard"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is Bento?</h2><a id="user-content-what-is-bento" aria-label="Permalink: What is Bento?" href="#what-is-bento"></a></p>
<p dir="auto">Bento is a computer. Its name come from it's distinctly bento box look, and it takes inspiration from the Comodore 64, and the many creations on r/cyberdeck.</p>
<p dir="auto">It fit perfectly underneath a keyboard, which acts as a lid! Giving you easy access to the internals, as well as a compartment to store various small peripherals.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/19628643/455292895-4a38fb38-fbdb-43cf-b44e-4cf81801ce72.jpeg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTEzMDEsIm5iZiI6MTc1MDMxMTAwMSwicGF0aCI6Ii8xOTYyODY0My80NTUyOTI4OTUtNGEzOGZiMzgtZmJkYi00M2NmLWI0NGUtNGNmODE4MDFjZTcyLmpwZWc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjE5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYxOVQwNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1mNDFkN2I1NTE5ZWIyOGYwNjk1YmM1NDRhNTI3OTAwNzE4YWM5MjJkMjljMzRiMDYzMjkyYjk3MmJlNmE3MDY3JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.66KoyEW-xLdExMDUGGzvmbxga2HlQiXO1VorsV4rtI8"><img src="https://private-user-images.githubusercontent.com/19628643/455292895-4a38fb38-fbdb-43cf-b44e-4cf81801ce72.jpeg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTEzMDEsIm5iZiI6MTc1MDMxMTAwMSwicGF0aCI6Ii8xOTYyODY0My80NTUyOTI4OTUtNGEzOGZiMzgtZmJkYi00M2NmLWI0NGUtNGNmODE4MDFjZTcyLmpwZWc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjE5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYxOVQwNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1mNDFkN2I1NTE5ZWIyOGYwNjk1YmM1NDRhNTI3OTAwNzE4YWM5MjJkMjljMzRiMDYzMjkyYjk3MmJlNmE3MDY3JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.66KoyEW-xLdExMDUGGzvmbxga2HlQiXO1VorsV4rtI8" alt="Inside bento"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">There is no display</h2><a id="user-content-there-is-no-display" aria-label="Permalink: There is no display" href="#there-is-no-display"></a></p>
<p dir="auto">This is key. Bento is meant to be used with an external display, particularly spatial displays like the XREAL One‚Äôs, but obviously it still works with any external monitor with USB-C.</p>
<p dir="auto">The reason for this is to eliminate redundancy. As I find myself using XREAL more and more, the built in display for my laptop or my steam deck goes unused and is simply added weight. Bento removes all that is non-essential, cutting back on weight and making it even more portable.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What‚Äôs inside?</h2><a id="user-content-whats-inside" aria-label="Permalink: What‚Äôs inside?" href="#whats-inside"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/19628643/455292501-3f0a9b38-8294-42f1-bb01-9b6f2e007e9c.jpeg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTEzMDEsIm5iZiI6MTc1MDMxMTAwMSwicGF0aCI6Ii8xOTYyODY0My80NTUyOTI1MDEtM2YwYTliMzgtODI5NC00MmYxLWJiMDEtOWI2ZjJlMDA3ZTljLmpwZWc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjE5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYxOVQwNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wNzgyYjA0OTM4YTUwMWJkMWRjODk5YmNlM2JmMTAzYmY4ZjVmODI2YmUyNTMxMzVhMjMyOGRmY2Y2YmNjMmZkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.rrVvKlrlVuGO_uEkcUEiT2WRF_FI1dRNvsH4d0H_78w"><img src="https://private-user-images.githubusercontent.com/19628643/455292501-3f0a9b38-8294-42f1-bb01-9b6f2e007e9c.jpeg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTEzMDEsIm5iZiI6MTc1MDMxMTAwMSwicGF0aCI6Ii8xOTYyODY0My80NTUyOTI1MDEtM2YwYTliMzgtODI5NC00MmYxLWJiMDEtOWI2ZjJlMDA3ZTljLmpwZWc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjE5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYxOVQwNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wNzgyYjA0OTM4YTUwMWJkMWRjODk5YmNlM2JmMTAzYmY4ZjVmODI2YmUyNTMxMzVhMjMyOGRmY2Y2YmNjMmZkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.rrVvKlrlVuGO_uEkcUEiT2WRF_FI1dRNvsH4d0H_78w" alt="a look under the hood"></a></p>
<p dir="auto">This version is powered by the main board of a Steam Deck OLED. It uses the same cooler and battery as well. I chose this board because it was the thinnest and most powerful available. But it can easily fit other SBCs that are more readily available.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why build this</h2><a id="user-content-why-build-this" aria-label="Permalink: Why build this" href="#why-build-this"></a></p>
<p dir="auto">Primarily out of frustration. The dominant players in XR keep promoting their hardware as ‚Äúcomputers‚Äù, when really they‚Äôre an iPad for your face. The most you can do is browse the web, play games, and consume content. They‚Äôre overweight and over constrained.</p>
<p dir="auto">If you want to do any <em>real</em> work, the best you can do is mirror your screen from a <em>real</em> computer. This is one of the most popular use cases outside of gaming.</p>
<p dir="auto">If this is true, then we should lean into it! Create a spatial display and ship a computer explicitly designed for it.</p>
<p dir="auto">This is why I built Bento, a computer designed to be used with spatial displays. I propose to you that it is closer to a ‚Äúspatial computer‚Äù than anything else we‚Äôve seen.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What you'll find in this repo</h2><a id="user-content-what-youll-find-in-this-repo" aria-label="Permalink: What you'll find in this repo" href="#what-youll-find-in-this-repo"></a></p>
<p dir="auto">All the STEP, 3MF, and STL files for bento, as well as a few periperhals like a Magic Trackpad tray.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/19628643/455293199-d634d455-5398-438e-89d9-d4f9e7b7ca3c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTEzMDEsIm5iZiI6MTc1MDMxMTAwMSwicGF0aCI6Ii8xOTYyODY0My80NTUyOTMxOTktZDYzNGQ0NTUtNTM5OC00MzhlLTg5ZDktZDRmOWU3YjdjYTNjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjE5VDA1MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTJlNGE2NzBhMjBmMzU1MWEzMWZkOTlkOTI2NjM4MzRhNGJlOGFiODk0ZmUyOTA1ZTVlYzUyMjliZmExMjMyYWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Sbc-wHMOYw3kd4X872F9A5MGDsEt4Sy_0ACxYa6H77M"><img src="https://private-user-images.githubusercontent.com/19628643/455293199-d634d455-5398-438e-89d9-d4f9e7b7ca3c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTAzMTEzMDEsIm5iZiI6MTc1MDMxMTAwMSwicGF0aCI6Ii8xOTYyODY0My80NTUyOTMxOTktZDYzNGQ0NTUtNTM5OC00MzhlLTg5ZDktZDRmOWU3YjdjYTNjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjE5VDA1MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTJlNGE2NzBhMjBmMzU1MWEzMWZkOTlkOTI2NjM4MzRhNGJlOGFiODk0ZmUyOTA1ZTVlYzUyMjliZmExMjMyYWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Sbc-wHMOYw3kd4X872F9A5MGDsEt4Sy_0ACxYa6H77M" alt="A screenshot of Bento in Shapr3D"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Request for Contribution</h2><a id="user-content-request-for-contribution" aria-label="Permalink: Request for Contribution" href="#request-for-contribution"></a></p>
<p dir="auto">I intend to keep working on this project, but I‚Äôm open sourcing it because I can only do so much on my own. I‚Äôm currently working on a ‚Äúpro‚Äù version with a switch 2 like mounting system to support modules. But here are some things I could use help with:</p>
<ul dir="auto">
<li><strong>Support for other keyboard</strong>: I picked the Magic Keyboard due to how ubiquitous it is, but there are better keyboards out there.</li>
<li><strong>Raspberry Pi 5 variant</strong>: this is crucial, but I can‚Äôt find a <em>good</em> battery solution (i.e. a HAT of some kind.)</li>
<li><strong>A framework variant</strong>:  This may require a larger base keyboard and will likely eliminate storage (physical, not digital.)</li>
<li>Support for other SBCs in general.</li>
<li><strong>Peripherals</strong>: I have some sketches for a gamepad and a mouse that could fit perfectly in the compartment, but I would happily acquiesce to someone else with board design skills.</li>
</ul>
<p dir="auto">If you do decide to create your own variant, all I ask is that you <strong>make a PR back to this repository</strong>, so that other‚Äôs might benefit from your work.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Websites Are Tracking You via Browser Fingerprinting (315 pts)]]></title>
            <link>https://engineering.tamu.edu/news/2025/06/websites-are-tracking-you-via-browser-fingerprinting.html</link>
            <guid>44313206</guid>
            <pubDate>Wed, 18 Jun 2025 20:55:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://engineering.tamu.edu/news/2025/06/websites-are-tracking-you-via-browser-fingerprinting.html">https://engineering.tamu.edu/news/2025/06/websites-are-tracking-you-via-browser-fingerprinting.html</a>, See on <a href="https://news.ycombinator.com/item?id=44313206">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent" name="Main Page Content" role="main" aria-labelledby="maincontent">
						
					
																																		                	            	     			<div aria-label="Websites Are Tracking You Via Browser Fingerprinting content 0" role="region"><p>Clearing your cookies is not enough to protect your privacy online.&nbsp;</p>
<p><a href="https://dl.acm.org/doi/10.1145/3696410.3714548" rel="noopener" target="_blank">New research</a> led by Texas A&amp;M University found that websites are covertly using browser fingerprinting ‚Äî a method to uniquely identify a web browser ‚Äî to track people across browser sessions and sites.</p>
<p>‚ÄúFingerprinting has always been a concern in the privacy community, but until now, we had no hard proof that it was actually being used to track users,‚Äù said Dr. Nitesh Saxena, cybersecurity researcher, professor of computer science and engineering and associate director of the Global Cyber Research Institute&nbsp;at Texas A&amp;M. ‚ÄúOur work helps close that gap.‚Äù</p>
<p>When you visit a website, your browser shares a surprising amount of information, like your screen resolution, time zone, device model and more. When combined, these details create a ‚Äúfingerprint‚Äù that‚Äôs often unique to your browser. Unlike cookies ‚Äî which users can delete or block ‚Äî fingerprinting is much harder to detect or prevent. Most users have no idea it‚Äôs happening, and even privacy-focused browsers struggle to fully block it.</p>
<p>‚ÄúThink of it as a digital signature you didn‚Äôt know you were leaving behind,‚Äù explained co-author Zengrui Liu, a former doctoral student in Saxena‚Äôs lab. ‚ÄúYou may look anonymous, but your device or browser gives you away.‚Äù</p>
<p>This research marks a turning point in how computer scientists understand the real-world use of browser fingerprinting by connecting it with the use of ads.</p>
<p>‚ÄúWhile prior works have studied browser fingerprinting and its usage on different&nbsp;websites, ours is the first to correlate browser fingerprints and ad behaviors, essentially establishing the relationship between web tracking and fingerprinting,‚Äù said co-author Dr. Yinzhi Cao, associate professor of computer science and technical director of the Information Security Institute at Johns Hopkins University.</p></div>
				
			
																																					
	
	
		
	
				
																		
																								
								
						
						
										
						
						
								
								
						
						
						
						
														
		
									        	        		<div>
        			<p>Think of it as a digital signature you didn‚Äôt know you were leaving behind. You may look anonymous, but your device or browser gives you away.</p>
        			<p><cite>Zengrui Liu</cite>
        		</p></div>
        	        				
			
																																		                	            	     			<div aria-label="Websites Are Tracking You Via Browser Fingerprinting content 1" role="region"><p>To investigate whether websites are using fingerprinting data to track people, the researchers had to go beyond simply scanning websites for the presence of fingerprinting code. They developed a measurement framework called FPTrace, which assesses fingerprinting-based user tracking by analyzing how ad systems respond to changes in browser fingerprints. This approach is based on the insight that if browser fingerprinting influences tracking, altering fingerprints should affect advertiser bidding ‚Äî where ad space is sold in real time based on the profile of the person viewing the website ‚Äî and HTTP records ‚Äî records of communication between a server and a browser.&nbsp;</p>
<p>‚ÄúThis kind of analysis lets us go beyond the surface,‚Äù said co-author Jimmy Dani, Saxena‚Äôs doctoral student. ‚ÄúWe were able to detect not just the presence of fingerprinting, but whether it was being used to <i>identify</i> and <i>target</i> users ‚Äî which is much harder to prove.‚Äù</p>
<p>The researchers found that tracking occurred even when users cleared or deleted cookies. The results showed notable differences in bid values and a decrease in HTTP records and syncing events when fingerprints were changed, suggesting an impact on targeting and tracking.</p>
<p>Additionally, some of these sites linked fingerprinting behavior to backend bidding processes ‚Äî meaning fingerprint-based profiles were being used in real time, likely to tailor responses to users or pass along identifiers to third parties.&nbsp;</p>
<p>Perhaps more concerning, the researchers found that even users who explicitly opt out of tracking under privacy laws like Europe‚Äôs General Data Protection Regulation (GDPR) and California‚Äôs California Consumer Privacy Act (CCPA) may still be silently tracked across the web through browser fingerprinting.</p>
<p>Based on the results of this study, the researchers argue that current privacy tools and policies are not doing enough. They call for stronger defenses in browsers and new regulatory attention on fingerprinting practices. They hope that their FPTrace framework can help regulators audit websites and providers who participate in such activities, especially without user consent.&nbsp;</p>
<p>This research was conducted in collaboration with Johns Hopkins University and presented at the ACM Web Conference (WWW) 2025.</p>
<p>Funding for this research is administered by the Texas A&amp;M Engineering Experiment Station (TEES), the official research agency for Texas A&amp;M Engineering.</p></div>
				
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PWM flicker: Invisible light that's harming our health? (138 pts)]]></title>
            <link>https://caseorganic.medium.com/the-invisible-light-thats-harming-our-health-and-how-we-can-light-things-better-d3916de90521</link>
            <guid>44311781</guid>
            <pubDate>Wed, 18 Jun 2025 17:32:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://caseorganic.medium.com/the-invisible-light-thats-harming-our-health-and-how-we-can-light-things-better-d3916de90521">https://caseorganic.medium.com/the-invisible-light-thats-harming-our-health-and-how-we-can-light-things-better-d3916de90521</a>, See on <a href="https://news.ycombinator.com/item?id=44311781">Hacker News</a></p>
Couldn't get https://caseorganic.medium.com/the-invisible-light-thats-harming-our-health-and-how-we-can-light-things-better-d3916de90521: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Game Hacking ‚Äì Valve Anti-Cheat (VAC) (148 pts)]]></title>
            <link>https://codeneverdies.github.io/posts/gh-2/</link>
            <guid>44311682</guid>
            <pubDate>Wed, 18 Jun 2025 17:19:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codeneverdies.github.io/posts/gh-2/">https://codeneverdies.github.io/posts/gh-2/</a>, See on <a href="https://news.ycombinator.com/item?id=44311682">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><hr><blockquote><h2 id="intro">Intro</h2></blockquote><p>In 2002 Valve created an Anti-Cheat solution called ‚ÄúValve Anti-Cheat‚Äù aka <strong>VAC</strong>.
The first game they implemented VAC into was Counter-Strike. When <strong>VAC</strong> was introduced it only operated in
User Mode (Still does) meaning it runs entirely in user space <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> and has no kernel component.</p><p>Below is a list of games that use <strong>VAC</strong>.. <sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p><pre><code>Call of Duty: Modern Warfare 2
Call of Duty: Modern Warfare 3
Counter-Strike (video game)
Counter-Strike: Condition Zero
Counter-Strike: Source
Counter-Strike 2
Day of Defeat
Day of Defeat: Source
Deathmatch Classic
Half-Life 2: Deathmatch
Half-Life Deathmatch: Source
Ricochet
Team Fortress
Team Fortress Classic
</code></pre><p>A longer list can be found here <sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.</p><hr><blockquote><h2 id="vac-cident">VAC-cident?</h2></blockquote><p>So.. if you don‚Äôt know <strong>VAC</strong> has been around for quite a while, at the time of writing it‚Äôll be 23 years.
Over the time they‚Äôve made some mistakes but who doesn‚Äôt? (Taken from wikipedia) <sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> <sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup></p><pre><code>- In July 2010, [snip] Approximately 12,000 owners of Call of Duty: Modern Warfare 2 were 
banned when Steam updated a DLL file on disk after it had been loaded into memory by the 
game, causing a false positive detection. These bans were revoked and those affected received 
a free copy of Left 4 Dead 2 or an extra copy to send as a gift. 

- In October 2023, certain users of AMD graphics cards were banned from Counter-Strike 2 
after AMD added support for their "Anti-Lag+" feature via a driver update, which the game 
flagged as a cheat due to it detouring certain DLL functions. AMD subsequently withdrew the 
driver update and Valve pledged to unban any affected users.
</code></pre><p>This post isn‚Äôt created to bash Valve they clean up after their mistakes and listen to their community,
gotta love devs when they do that. I also commend them because getting <strong>VAC</strong> banned isn‚Äôt such a slap
on the wrist. Getting <strong>VAC</strong> banned has some stipulations such as:</p><ul><li>Having the <strong>VAC</strong> ban show on your Steam profile</li><li>Being banned from all <strong>‚ÄúGoldSrc‚Äù</strong> games</li><li>Being banned from all <strong>‚ÄúSource engine‚Äù</strong> games (The Counter-Strike serise)</li><li>Not being able to <strong>refund</strong> the game you‚Äôre <strong>VAC</strong> banned on</li></ul><p>Knowing what‚Äôll happen if you get <strong>VAC</strong> banned is important to know because regardless if
you‚Äôre cheating or not false bans are no good. People in the community took it upon themselves
to reverse engineer the Anti-Cheat and understand what it does (some did it just to cheat).</p><hr><blockquote><h2 id="vac-what">VAC what?</h2></blockquote><p>The previous section brings us to a term you may have heard before, the infamous <strong>‚ÄúVAC Bypass‚Äù</strong>.
Searching online for information about bypassing <strong>VAC</strong> brings many blogs and repos that all seem to do/talk about something
similar and that‚Äôs ‚ÄúDumping the <strong>VAC</strong> modules‚Äù. Let me explain, <strong>VAC</strong> is <strong>NOT</strong> just one executable on the system it streams it‚Äôs
Anti-Cheat modules (DLLs) from a server, once a module is recieved by some routine in <strong>steamservice.dll</strong> inside <strong>steamservice.exe</strong>
(or <strong>steam.exe</strong> if <strong>ran as admin</strong>) it will be loaded using one of the two methods below. <sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> <sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup> <sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup> <sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup> <sup id="fnref:10"><a href="#fn:10" role="doc-noteref">10</a></sup> <sup id="fnref:11"><a href="#fn:11" role="doc-noteref">11</a></sup> <sup id="fnref:12"><a href="#fn:12" role="doc-noteref">12</a></sup> <sup id="fnref:13"><a href="#fn:13" role="doc-noteref">13</a></sup></p><ul><li><strong>Reflectively load</strong> the DLL into memory</li><li>Use the WinAPI function <strong>LoadLibrary</strong></li></ul><p>By default the Anti-Cheat modules are reflectively loaded into memory. The goal is to force <strong>LoadLibrary</strong> into being used,
then someone can hook that function and dump the modules (DLLs) to disk, allowing someone to analyse the dumped DLLs and understand
what they‚Äôre doing to detect cheating.</p><hr><blockquote><h2 id="dumping-vac-modules-in-the-big-25">Dumping VAC Modules in the big ‚Äò25</h2></blockquote><p>To kick start the journey on dumping the <strong>VAC</strong> modules load <strong>steamservice.dll</strong> into <strong>Binary Ninja</strong>. Once the binary is fully analyzed
go to ‚ÄúTriage Summary‚Äù</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-1.png" data-src="/VAC-1.png" data-srcset="/VAC-1.png, /VAC-1.png 1.5x, /VAC-1.png 2x" data-sizes="auto" alt="/VAC-1.png" title="VAC-1" srcset="https://codeneverdies.github.io/VAC-1.png, https://codeneverdies.github.io/VAC-1.png 1.5x, https://codeneverdies.github.io/VAC-1.png 2x"></p></blockquote><p>It is <strong>VERY</strong> important to take note that this is a 32-bit process, so all pointers will be 32-bits in size you‚Äôll see why this is important later.</p><p>Next we‚Äôll search for calls to <strong>LoadLibrary*</strong> I‚Äôll save the reader some time and tell you that we should be looking
for calls to <strong>LoadLibraryW</strong> it will be called in a very important function that we can use to back track.</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-2.png" data-src="/VAC-2.png" data-srcset="/VAC-2.png, /VAC-2.png 1.5x, /VAC-2.png 2x" data-sizes="auto" alt="/VAC-2.png" title="VAC-2" srcset="https://codeneverdies.github.io/VAC-2.png, https://codeneverdies.github.io/VAC-2.png 1.5x, https://codeneverdies.github.io/VAC-2.png 2x"></p></blockquote><p>Following the reference takes us to an interesting function <strong>sub_10086f80</strong></p><blockquote><p><img src="https://codeneverdies.github.io/VAC-3.png" data-src="/VAC-3.png" data-srcset="/VAC-3.png, /VAC-3.png 1.5x, /VAC-3.png 2x" data-sizes="auto" alt="/VAC-3.png" title="VAC-3" srcset="https://codeneverdies.github.io/VAC-3.png, https://codeneverdies.github.io/VAC-3.png 1.5x, https://codeneverdies.github.io/VAC-3.png 2x"></p></blockquote><p>Judging by the return value <strong>HMODULE</strong> and the calls to LoadLibrary* it‚Äôs safe to say this function‚Äôs job is to load
some kind of module and return a handle to it. Following references to where this function is called leads us to another interesting
function <strong>sub_10086c40</strong>.</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-4.png" data-src="/VAC-4.png" data-srcset="/VAC-4.png, /VAC-4.png 1.5x, /VAC-4.png 2x" data-sizes="auto" alt="/VAC-4.png" title="VAC-4" srcset="https://codeneverdies.github.io/VAC-4.png, https://codeneverdies.github.io/VAC-4.png 1.5x, https://codeneverdies.github.io/VAC-4.png 2x"></p></blockquote><p>The beginning of the <strong>sub_10086c40</strong> function didn‚Äôt look too important (at the time) but we should remember that this function also returns a handle to a module.
I looked at the references and it shows that this function is called once in the function <strong>sub_10059040</strong>.</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-17.png" data-src="/VAC-17.png" data-srcset="/VAC-17.png, /VAC-17.png 1.5x, /VAC-17.png 2x" data-sizes="auto" alt="/VAC-17.png" title="VAC-17" srcset="https://codeneverdies.github.io/VAC-17.png, https://codeneverdies.github.io/VAC-17.png 1.5x, https://codeneverdies.github.io/VAC-17.png 2x"></p></blockquote><p>We can see <strong>sub_10086c40</strong> being called if we trace back the <strong>first</strong> argument passed to that function,
we‚Äôll see that it was used by another function <strong>sub_100859d0</strong>. If that function call is successful
execution carries on, so it‚Äôs safe to say it‚Äôs important. Let‚Äôs take a look at this function.</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-18.png" data-src="/VAC-18.png" data-srcset="/VAC-18.png, /VAC-18.png 1.5x, /VAC-18.png 2x" data-sizes="auto" alt="/VAC-18.png" title="VAC-5" srcset="https://codeneverdies.github.io/VAC-18.png, https://codeneverdies.github.io/VAC-18.png 1.5x, https://codeneverdies.github.io/VAC-18.png 2x"></p></blockquote><p>This function makes two WinAPI calls</p><ul><li><p><strong>GetTempPathW</strong>
: Retrieves the path of the directory designated for temporary files.</p></li><li><p><strong>GetTempFileNameW</strong>
: Creates a name for a temporary file. If a unique file name is generated, an empty file is created and the handle to it is released; otherwise, only a file name is generated.</p></li></ul><p>The combination of these calls tells us that we need to be looking for any <code>.TMP</code> files being accessed, the names are usually in this format <code>&lt;uuuu&gt;.TMP</code>.</p><p>Now there‚Äôs a path to a DLL floating in memory how does it get used? Look no more.</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-5.png" data-src="/VAC-5.png" data-srcset="/VAC-5.png, /VAC-5.png 1.5x, /VAC-5.png 2x" data-sizes="auto" alt="/VAC-5.png" title="VAC-5" srcset="https://codeneverdies.github.io/VAC-5.png, https://codeneverdies.github.io/VAC-5.png 1.5x, https://codeneverdies.github.io/VAC-5.png 2x"></p></blockquote><pre tabindex="0"><code>100591f7   HMODULE eax_13 = sub_10086c40(edi_1, 0)
100591ff   *(esi + 4) = eax_13
100591ff   
10059204   if (eax_13 != 0)
10059215       int32_t eax_14 = sub_10086c20(eax_13, "_runfunc@20")
1005921d       *(esi + 0xc) = eax_14
</code></pre><p>The path <code>edi_1</code> is used by <strong>sub_10086c40</strong>, this function is used to get a handle to a module <code>eax_13</code> then it‚Äôs passing that handle to <strong>sub_10086c20</strong>.
<strong>sub_10086c20</strong> takes two arguments we know the first is a handle to a module the second is from what we can see here a string <code>_runfunc@20</code>, the return value
<code>int32_t</code> looks a little weird but this is a 32-bit process remember ;) so this could be a pointer to something dont ya think? Here‚Äôs the function prototype</p><pre tabindex="0"><code>int32_t sub_10086c20(HMODULE arg1, PSTR arg2)
</code></pre><p>Place your bets on it being a GetProcAddress wrapper.. Drum roll please‚Ä¶ It is‚Ä¶</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-6.png" data-src="/VAC-6.png" data-srcset="/VAC-6.png, /VAC-6.png 1.5x, /VAC-6.png 2x" data-sizes="auto" alt="/VAC-6.png" title="VAC-6" srcset="https://codeneverdies.github.io/VAC-6.png, https://codeneverdies.github.io/VAC-6.png 1.5x, https://codeneverdies.github.io/VAC-6.png 2x"></p></blockquote><p>So with this bit of information we know <strong>steamservice.dll</strong> recieves the <strong>VAC</strong> modules, it‚Äôs using a function <strong>sub_10086c40</strong> which calls
<strong>sub_10086f80</strong> to load the Anti-Cheat module and return a handle, then that handle is passed to <strong>sub_10086c20</strong> to get the address
of a function named <code>_runfunc@20</code>. By default as said earlier the modules are reflectively loaded so this isn‚Äôt the regular control flow of
<strong>steamservice.dll</strong>, this can be confirmed if you scroll up a bit in <strong>sub_10059040</strong> you‚Äôll see a flag being checked.</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-7.png" data-src="/VAC-7.png" data-srcset="/VAC-7.png, /VAC-7.png 1.5x, /VAC-7.png 2x" data-sizes="auto" alt="/VAC-7.png" title="VAC-7" srcset="https://codeneverdies.github.io/VAC-7.png, https://codeneverdies.github.io/VAC-7.png 1.5x, https://codeneverdies.github.io/VAC-7.png 2x"></p></blockquote><p><strong>steamservice.dll</strong> will most likely take this path unless we can do something about it</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-8.png" data-src="/VAC-8.png" data-srcset="/VAC-8.png, /VAC-8.png 1.5x, /VAC-8.png 2x" data-sizes="auto" alt="/VAC-8.png" title="VAC-8" srcset="https://codeneverdies.github.io/VAC-8.png, https://codeneverdies.github.io/VAC-8.png 1.5x, https://codeneverdies.github.io/VAC-8.png 2x"></p></blockquote><p>Let‚Äôs look at it in assembly</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-9.png" data-src="/VAC-9.png" data-srcset="/VAC-9.png, /VAC-9.png 1.5x, /VAC-9.png 2x" data-sizes="auto" alt="/VAC-9.png" title="VAC-9" srcset="https://codeneverdies.github.io/VAC-9.png, https://codeneverdies.github.io/VAC-9.png 1.5x, https://codeneverdies.github.io/VAC-9.png 2x"></p></blockquote><p>Take a look at <code>je 0x10059127</code> ( <code>0x74 0x47</code> )</p><p><code>0x74</code> is the jump if equal instruction and <code>0x47</code> is how many bytes forward to jump (71) in hex</p><p>What we wan‚Äôt to do is change the first instruction at <strong>steamservice.dll</strong> + 0x590DE (0x100590de)</p><ul><li>to <code>jne 0x10059127</code> ( <code>0x75 0x47</code> )</li></ul><p>we‚Äôre changing the first byte of this instruction to be <code>0x75</code> which is jump if <strong>NOT</strong>
zero/equal. (Inverting)</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-10.png" data-src="/VAC-10.png" data-srcset="/VAC-10.png, /VAC-10.png 1.5x, /VAC-10.png 2x" data-sizes="auto" alt="/VAC-10.png" title="VAC-10" srcset="https://codeneverdies.github.io/VAC-10.png, https://codeneverdies.github.io/VAC-10.png 1.5x, https://codeneverdies.github.io/VAC-10.png 2x"></p></blockquote><p>Now that we have a potential way of dumping the <strong>VAC</strong> modules let‚Äôs test it! first we start steam and launch <strong>x32dbg</strong> as
admin we should remember the offset to our instructions <strong>steamservice.dll</strong> + 0x590DE.</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-11.png" data-src="/VAC-11.png" data-srcset="/VAC-11.png, /VAC-11.png 1.5x, /VAC-11.png 2x" data-sizes="auto" alt="/VAC-11.png" title="VAC-11" srcset="https://codeneverdies.github.io/VAC-11.png, https://codeneverdies.github.io/VAC-11.png 1.5x, https://codeneverdies.github.io/VAC-11.png 2x"></p></blockquote><p>Once <strong>x32dbg</strong> is loaded attach to <strong>steamservice.dll</strong></p><blockquote><p><img src="https://codeneverdies.github.io/VAC-12.png" data-src="/VAC-12.png" data-srcset="/VAC-12.png, /VAC-12.png 1.5x, /VAC-12.png 2x" data-sizes="auto" alt="/VAC-12.png" title="VAC-12" srcset="https://codeneverdies.github.io/VAC-12.png, https://codeneverdies.github.io/VAC-12.png 1.5x, https://codeneverdies.github.io/VAC-12.png 2x"></p></blockquote><p>Press <code>CTRL+G</code> and enter <code>steamservice.dll + 0x590DE</code></p><blockquote><p><img src="https://codeneverdies.github.io/VAC-13.png" data-src="/VAC-13.png" data-srcset="/VAC-13.png, /VAC-13.png 1.5x, /VAC-13.png 2x" data-sizes="auto" alt="/VAC-13.png" title="VAC-13" srcset="https://codeneverdies.github.io/VAC-13.png, https://codeneverdies.github.io/VAC-13.png 1.5x, https://codeneverdies.github.io/VAC-13.png 2x"></p></blockquote><p>Now we‚Äôre where we need to patch</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-14.png" data-src="/VAC-14.png" data-srcset="/VAC-14.png, /VAC-14.png 1.5x, /VAC-14.png 2x" data-sizes="auto" alt="/VAC-14.png" title="VAC-14" srcset="https://codeneverdies.github.io/VAC-14.png, https://codeneverdies.github.io/VAC-14.png 1.5x, https://codeneverdies.github.io/VAC-14.png 2x"></p></blockquote><p>Right click on that instruction and click ‚ÄúAssemble‚Äù then enter <code>jnz 0x10059127</code> and hit ok</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-15.png" data-src="/VAC-15.png" data-srcset="/VAC-15.png, /VAC-15.png 1.5x, /VAC-15.png 2x" data-sizes="auto" alt="/VAC-15.png" title="VAC-15" srcset="https://codeneverdies.github.io/VAC-15.png, https://codeneverdies.github.io/VAC-15.png 1.5x, https://codeneverdies.github.io/VAC-15.png 2x"></p></blockquote><p>It should be changed</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-16.png" data-src="/VAC-16.png" data-srcset="/VAC-16.png, /VAC-16.png 1.5x, /VAC-16.png 2x" data-sizes="auto" alt="/VAC-16.png" title="VAC-16" srcset="https://codeneverdies.github.io/VAC-16.png, https://codeneverdies.github.io/VAC-16.png 1.5x, https://codeneverdies.github.io/VAC-16.png 2x"></p></blockquote><p>The next step is to open <strong>Procmon</strong> play a game that uses <strong>VAC</strong> (I chose CSGO) and wait for
<strong>steamservice.exe</strong> to access some <code>.TMP</code> files.</p><p>Here are the <strong>Procmon</strong> filters</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-19.png" data-src="/VAC-19.png" data-srcset="/VAC-19.png, /VAC-19.png 1.5x, /VAC-19.png 2x" data-sizes="auto" alt="/VAC-19.png" title="VAC-19" srcset="https://codeneverdies.github.io/VAC-19.png, https://codeneverdies.github.io/VAC-19.png 1.5x, https://codeneverdies.github.io/VAC-19.png 2x"></p></blockquote><p>While loading the game we see our first TMP file <code>C:\Windows\Temp\D54A.tmp</code></p><blockquote><p><img src="https://codeneverdies.github.io/VAC-20.png" data-src="/VAC-20.png" data-srcset="/VAC-20.png, /VAC-20.png 1.5x, /VAC-20.png 2x" data-sizes="auto" alt="/VAC-20.png" title="VAC-20" srcset="https://codeneverdies.github.io/VAC-20.png, https://codeneverdies.github.io/VAC-20.png 1.5x, https://codeneverdies.github.io/VAC-20.png 2x"></p></blockquote><p>Let‚Äôs join a public match and see if there are others</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-21.png" data-src="/VAC-21.png" data-srcset="/VAC-21.png, /VAC-21.png 1.5x, /VAC-21.png 2x" data-sizes="auto" alt="/VAC-21.png" title="VAC-21" srcset="https://codeneverdies.github.io/VAC-21.png, https://codeneverdies.github.io/VAC-21.png 1.5x, https://codeneverdies.github.io/VAC-21.png 2x"></p></blockquote><p>And some more..</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-22.png" data-src="/VAC-22.png" data-srcset="/VAC-22.png, /VAC-22.png 1.5x, /VAC-22.png 2x" data-sizes="auto" alt="/VAC-22.png" title="VAC-22" srcset="https://codeneverdies.github.io/VAC-22.png, https://codeneverdies.github.io/VAC-22.png 1.5x, https://codeneverdies.github.io/VAC-22.png 2x"></p></blockquote><p>We can also look at these files in the temp directory..</p><blockquote><p><img src="https://codeneverdies.github.io/VAC-23.png" data-src="/VAC-23.png" data-srcset="/VAC-23.png, /VAC-23.png 1.5x, /VAC-23.png 2x" data-sizes="auto" alt="/VAC-23.png" title="VAC-23" srcset="https://codeneverdies.github.io/VAC-23.png, https://codeneverdies.github.io/VAC-23.png 1.5x, https://codeneverdies.github.io/VAC-23.png 2x"></p></blockquote><p>I copied all of these files to a new directory and loaded <code>D54A.tmp</code> into <strong>PE-bear</strong></p><blockquote><p><img src="https://codeneverdies.github.io/VAC-24.png" data-src="/VAC-24.png" data-srcset="/VAC-24.png, /VAC-24.png 1.5x, /VAC-24.png 2x" data-sizes="auto" alt="/VAC-24.png" title="VAC-24" srcset="https://codeneverdies.github.io/VAC-24.png, https://codeneverdies.github.io/VAC-24.png 1.5x, https://codeneverdies.github.io/VAC-24.png 2x"></p></blockquote><p>We see something familiar <code>_runfunc@20</code> this is the function that was found using <strong>sub_10086c20</strong>.</p><hr><blockquote><h2 id="to-be-continued">To be continued</h2></blockquote><p>In the next post we will be doing analysis on these Anti-Cheat Modules to get a better understanding of what‚Äôs going on.
I hope you enjoyed this post and most importantly learned a thing or two. Stay tuned!</p><hr><blockquote><h2 id="references">References</h2></blockquote></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Andrej Karpathy's YC AI SUS talk on the future of the industry (235 pts)]]></title>
            <link>https://www.donnamagi.com/articles/karpathy-yc-talk</link>
            <guid>44311509</guid>
            <pubDate>Wed, 18 Jun 2025 16:56:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.donnamagi.com/articles/karpathy-yc-talk">https://www.donnamagi.com/articles/karpathy-yc-talk</a>, See on <a href="https://news.ycombinator.com/item?id=44311509">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://www.donnamagi.com/">back</a></p><p>This is a transcript of Andrej Karpathy's talk on Software 3.0 on June 17th. I was in the audience, and it was recorded in a noisy environment - set your expectations accordingly.</p><p>YC has said the official video will take a few weeks to release, by which Karpathy himself agrees the talk will be deprecated.<!-- --> <a href="https://x.com/karpathy/status/1935077692258558443" target="_blank" referrerpolicy="origin">https://x.com/karpathy/status/1935077692258558443</a></p><p>and ok wow, this is going viral. let's<!-- --> <a href="https://x.com/DonnaMagi" target="_blank" referrerpolicy="origin">keep in touch</a>?</p><p>I think it's actually an extremely unique and very interesting time to enter the industry right now. And I think fundamentally the reason for that is that software is changing. Again. And I say again because I actually gave this talk already. But the problem is that software keeps changing, so I actually have a lot of material to create new talks. And I think it's changing quite fundamentally. I think broadly speaking, software has not changed much at such a fundamental level for 70 years. And then it's changed, I think, about twice quite rapidly in the last few years. And so there's just a huge amount of work to do, a huge amount of software to write and rewrite.</p><p>So let's take a look at maybe the realm of software. So if we're going to think of this as like a map of software, this is a really cool tool called Map. This is kind of like all the software that's written. These aren't instructions. Computer for clearing out tasks in digital space. So if you zoom in here, these are all different kinds of repositories. And this is all the code that has been written. And a few years ago, I kind of observed that software was kind of changing and there was kind of like a new type of software around. And I called this Software 2.0 at the time. And the idea here was that Software 1.0 is the code you write on the computer. Software 2.0 are basically neural networks. In particular, the weights of the neural network. And you're not writing this code correctly. You're more like tuning the data sets and then you're running an optimizer to create the parameters. And I think at the time, neural networks were kind of seen as just a different kind of classifier, like a decision tree or something like that. And so I think this training was a lot more appropriate.</p><p>And now actually what we have is kind of like an equivalent of GitHub in the realm of Software 2.0. And I think the hugging face is basically an equivalent of GitHub in Software 2.0. And there's also a model atlas and you can visualize all the code written there. In case you're curious, by the way, the giant circle, the point in the middle, these are the parameters of Flux, the image generator. And so any time someone tunes a lower on top of a Flux model, you basically create a GitHub event in this space and create a different kind of image generator. So basically what we have is Software 1.0 is the computer code that programs the computer. Software 2.0 are the weights which program neural networks. And here's an example of AlexNet image recognizer neural network. Now so far, all of the neural networks that we've been familiar with until recently were kind of like fixed-functional computers. Image categories or something like that. And I think what's changed, and I think it's a fundamental change, is that neural networks became programmable with large libraries. And so I see this as quite new, unique. It's a new kind of computer. And in my mind, it's worth giving it the designation of a Software 3.0. And basically your products are now programs that program people all over. And remarkably, these products are written in English. So it's kind of a very interesting programming language.</p><p>So maybe to summarize the business, if you're doing central classification, for example, you can imagine writing some Python to basically do central classification. Or you can train neural networks. Or you can drop a large amount of code. So here I'm just using SoftPrompt, and you can imagine changing it and programming the computer's life. So basically we have Software 1.0, Software 2.0. And I think we're seeing, I mean, you've seen a lot of GitHub code is not just like code anymore. There's a bunch of English interspersed with code. And so I think there's a growing category of that kind of code. So not only is it a new programming paradigm, it's also remarkable to me that it's in our native language of English. And so this blew my mind a few years ago now. I tweeted this, and I think it captured the attention of a lot of people. And one of the things that I currently pinpoint to them is that arguably we're not programming computers in English.</p><p>Now when I was at Tesla, we were working on the Autopilot, and we were trying to get the car to drive. And I sort of showed this slide at the time where you can imagine that the inputs for the car are on the bottom, and they're going through the software stack to produce the steering and acceleration. And I made the observation at the time that there was a ton of C++ code around in the Autopilot, which was the software model development. And that there were some neural nets in there doing the interactions. And I kind of observed that over time as we made the Autopilot better, basically the neural network grew in capability and size. And in addition to that, all this C++ code was being completed. And a lot of the capabilities and functionality that was originally in 1.0 was migrated to 2.0. So as an example, a lot of the stitching up of information across images from the different cameras across time was done by neural network, and we were able to delete a lot of code. And so the software development stack was quite literally made through the software stack of the Autopilot. So I thought this was a brilliant model at the time. And I think we're seeing the same thing again, where basically we have a new kind of software, and it's being through the stack, made through a completely different programming paradigm.</p><p>And I think if you're entering the industry, it's a very good idea to be fluent in all of them. Because they all have slight pros and cons, and you may want to program some functionality in 1.0 or 2.0, or 3.0, or you're going to train in LLM, or you're going to just run from LLM, that shouldn't be any software that's explicit, etc. So we don't have to make these decisions to actually potentially fluidly transition to LLMs.</p><p>So what I want to get into now is, first I want to, in the first part, talk about LLMs, and what I think of this new paradigm in the ecosystem, and what that looks like. What is this new computer? What does it look like? And what does the ecosystem look like? I was struck by this quote from Andrew, actually many years ago now, I think. And I think Andrew is going to speak right after me. But he said that the term AI is probably not his thing. And I do think that it captures something very interesting, in that LLMs certainly feel like they have properties of utilities, right? So, LLM labs, like OpenAI, Gemini, Fungi, etc, they spend time to train the LLMs, and this is kind of equivalent to a built-in AI algorithm, and then there's op-ecs to serve them intelligence over APIs to all of us. And this is done through internet access, where we pay per million tokens or something like that, and we have a lot of demands that are very utility-like demands out of this API. We demand low latency, high uptime, etc.</p><p>In electricity, you would have a transfer switch, so you can transfer your electricity source from, like, grid, solar, or battery, or generator. In LLMs, we have maybe open router, and easily switch between the different types of LLMs that exist. Because the LLMs are software, they don't need more physical space, so it's okay to have, basically, like six electricity providers that you can switch between, right? Because they don't need this directly. And I think what's also really fascinating, and we saw this in the last few days, actually, a lot of the LLMs went down, and people were kind of stuck and unable to work.</p><p>And I think it's kind of fascinating to me that when the state-of-the-art LLMs go down, it's actually kind of like an intelligence brownout in the world. It's kind of like when the voltage is unreliable on the grid, and the planet just gets smaller. The more reliance we have on these models, which already is, like, really dramatic, and I think will continue to grow. But LLMs don't only have case of utilities. I think it's also fair to say that they have some power tools called CAPs. And the reason for this is that the CAPs required for building LLMs is actually quite large. It's not just like building some power station or something like that, right? You're investing a huge amount of money, and I think the technology is growing quite rapidly. So we're in a world where we have, sort of, deep tech trees, research and development, secrets, that are centralizing our shiny LLM labs. But I think the analogy varies a little bit also, because, as I mentioned, this is software. And software is a bit less expensive, but because it is so valuable. And so I think that's just an interesting kind of thing to think about.</p><p>There's many analogies you can make, like a formatted data process, and maybe, for instance, something like a cluster with certain max-ops. And you can think about, when you're using it, you actually use it only through the software, not through the hardware. That's kind of what the CAPs are. But if you're actually also building it on hardware, and you're sharing it using Google, that's kind of like an integral on your platform. So I think there's analogies here that make sense. But actually, I think the analogy that makes the most sense, perhaps, is that, in my mind, LLM's have very strong analogies to operating systems, in that this is not just electricity or power. It's not something that comes automatically to happen. It's a commodity. These are now increasingly complex software ecosystems. So they're not just simple commodities like electricity. And it's kind of interesting to me that the ecosystem is shaping in a very similar kind of way, where you have a few closed-source providers, like Windows and macOS, and then you have an open-source alternative, like Linux. And I think for LLM's as well, we have a few competing closed-source providers. And then maybe the LLM ecosystem is currently maybe a close approximation to something that may grow into something like Linux. Again, I think it's still very early, because these are just simple LLMs. And I'm starting to see that these are going to get a lot more complicated. It's not just about the LLM itself, but it's about the tool use, the full-time analogies, how all that works. And so when I sort of have this realization about that, I try to sketch it out. And it kind of seems to me like LLMs are kind of like a new operating system, right? So the LLM is a new kind of computer. It's kind of like a CPU equivalent. The context windows are kind of like the memory. And then the LLM is orchestrating memory and compute for problem solving using all these capabilities. And so definitely, if you look at it, it looks very much like software. from that perspective.</p><p>A few more analogies, for example, if you want to download an app, say I go to VS Code and I go to Download, you can download VS Code and you can run it on Windows, Linux, or Mac, in the same way as you can take an LLM app, like a cursor, and you can run it on GBT, or Blob, or JPEG streams, right? It's just a drop-in. So it's kind of like similar in that way as well. The more analogies that I can describe to you is that we're kind of like in this 1960s-ish era, where LLM compute is still very expensive for this new kind of a computer, and that forces the LLMs to be centralized in the cloud, and we're all just sort of fake clients that interact with it over the network, and none of us have full utilization of these computers. And therefore, it makes sense to use timesharing, where we're all just, you know, at the mission of the batch, when they're running the computer in the cloud. And this is very much what the computers used to look like. During this time, the operating systems were in the cloud, everything was streamed around them, and they were batching. And so the personal computing revolution hasn't happened yet, because it's just not that common, and it doesn't make sense, but I think some people are trying. And it turns out that Mac minis, for example, are a very good fit for some of the LLMs, because it's all purely batch-run inference, this is all super-memory-bound, so this actually works. And I think these are some early indications that you have personal computing, but this hasn't really happened yet, and it's not clear what this looks like. Maybe some of you guys are interested in talking about what this is, or how it works, or what it should be.</p><p>Maybe one more analogy that I'll mention is, whenever I talk to ChartsQt or some LLM directly in text, I feel like I'm talking to an operating system through the terminal. Like, it's text, it's direct access to the operating system, and I think a GUI hasn't yet really been invented in a general way, like ChartsQt had a GUI, but different than just a text box. Certainly some of the apps that we're going to go into in a bit have GUI, but there's no GUI across all the tasks and devices. There are some ways in which LLMs are different from operating systems in some kind of unique way, and from early computing. And I wrote about this one particular property that strikes me as very different. It's that LLMs, they flip the direction of technology that is usually present in technology. So for example, with electricity, the economy is getting quite expensive, and lots of new transformative technologies have not been around, particularly in government-owned corporations that are the first officers, because it's new and expensive, etc. And only later did they fix it to consumers. But I feel like LLMs are kind of what flipped around. So maybe with early computers, it was all about ballistics and military use, but with LLMs, it's all about up the oil bank or something like that. This is certainly like a lot of minds.</p><p>And so it's really fascinating to me that we have a new magical computer, and it's like helping the oil bank. It's not helping the government to do something really crazy like some military ballistics or some special technology. Indeed, corporations are now getting the lagging, apparently not, of all of us, of all these technologies. So it's just backwards. And I think it informs me in some of the uses of how we want to use this technology, or like where I saw the first apps in the store.</p><p>So in summary so far, LLMs, app LLMs, I think it's accurate language to use. LLMs are complicated operating systems. They're circa 1960s computing, or we do computing already. And they're currently available via time-sharing and distributed like a utility. What is new and unprecedented is that they're not in the hands of a few governments and corporations. They're in the hands of all of us, because we all have a computer, and it's all just software. And Chachapitibos leans down to our computers that collect billions of people like this and play it overnight. And this is insane. And it's kind of insane to me that this is the case. And now it is our time to enter the industry and program these computers. It's crazy.</p><p>So I think this is a better part. Before we program LLMs, we have to kind of like spend some time to think about what these things are. And I especially like to talk about their psychology. So the way I like to think about LLMs is that they're kind of like little spirits. They are stochastic simulations of, and the simulator in this case happens to be an autoregressive transformer. So a transformer is a neural network. And it just kind of like goes from level of focus, it goes chunk, chunk, chunk, chunk, chunk. And there's an almost equal amount of compute for every single chunk. And this simulator, of course, is just, it's basically there's some weights involved and we fit it to all the text that we have on the internet and so on. And you end up with this kind of a simulator. And because it is trained in humans, it's got this emergent psychology that is human-like.</p><p>So the first thing you'll notice is, of course, LLMs have this type of deep knowledge and memory. And they can remember lots of things, a lot more than any single individual can because they've read so many things. It actually kind of reminds me of this movie Rain Man, which I actually really recommend people watch. It's an amazing movie. I love this movie. Dustin Hoffman here is an autistic sponge who has almost perfect memory. So he can read like a notebook and remember all of the names and phone numbers. And I kind of feel like LLMs are kind of like very similar. They can remember shock hashes and lots of different kinds of things, very, very easily. So they certainly have superpowers and stuff in some respect, but they also have a bunch of, I would say, cognitive deficits. So they hallucinate quite a bit and they kind of make up stuff and don't have a very good sort of internal model of self-knowledge, but not sufficient at least. And this has gotten better, but not perfect. They display jagged intelligence. So they're going to be superhuman in some problem-solving ways, and then they're going to make mistakes that basically no human will make, like, you know, it will insist that 9.11 is greater than 9.9, or that there are two bars of strawberry. These are some famous examples. But basically there are rough edges that you can trip on. So that's kind of, I think, also kind of cool. They also kind of suffer from internal brain amnesia. So, and I think alluding to the fact that if you have a coworker, which is your organization, this coworker will, over time, learn your organization and they will understand and gain, like, a huge amount of context on the organization and they go home and they sleep and they consolidate knowledge and they build expertise over time. LLMs don't natively do this. This is not something that has really been solved in R&amp;D with LLMs by them. And so context windows are really kind of like a working memory that you have to sort of program the working memory quite directly because they don't just kind of, like, get borrowed by people. And I think a lot of people get tripped up by analogies in this way. In popular culture, I recommend people watch these two movies, Memento and First Dates. In both of these movies, the protagonists, their ways are mixed, and their context windows get wiped every single morning. And it's really problematic to go to work or have relationships when this happens. And this happens to a lot of us all the time.</p><p>I guess one more thing I would point to is security-related limitations on the use of LLMs. So, for example, LLMs are quite vulnerable. They are susceptible to conflict-injection risks. They might leak your data, etc. And there's many other considerations security-related. So, basically, long story short, you have to simultaneously think through this superhuman thing that has a bunch of cognitive deficits and issues. How do we enhance them? They are extremely likely usable. And so how do we program them? And how do we work around their deficits and toy with their superhuman powers?</p><p>So what I'm going to switch to now is talk about the operators. How do we use these models? And what are some of the biggest operators? This is not a comprehensive list of some of the things that I thought were interesting in this stuff. The first thing I'm kind of excited about is what I would call partial autonomy apps. So, for example, let's work with the example of coding. You can certainly go to chat.gt directly, and you can start copy-pasting code around, and copy-pasting awkward words and stuff around, and then code, and copy-pasting everything around. Why would you do that? Why would you go directly to the operators? It makes a lot more sense to have an app dedicated for this. And so I think many of you use Cursor. I do as well. And Cursor is kind of like the thing you want instead. You don't want to just directly go to the chat.gt. And I think Cursor is a very good example of an early LLM app that has a bunch of properties that I think are useful across all the LLMs. So in particular, you will notice that we have a traditional interface that allows a human to go in and do all the work manually, just as before. But in addition to that, we now have this LLM integration that allows us to go in bigger chunks. And so some of the properties of LLM apps that I think are shared are useful. Number one, the LLMs basically do a ton of good context management. Number two, they orchestrate multiple calls to LLMs. So in the case of Cursor, there's under-the-hood eventing models for all your files, the actual chat models, models that apply ifs to the code, and this whole orchestra is for you. A really big one that I think also may be not fully appreciated in all this is application-specific and the importance of it. Because you don't just want to talk to the operating system directly in text. Text is very hard to read, interpret, understand, and also you don't want to take some of these actions natively in text. So it's much better to just see the bit as like red and green change, and you can see what's the matter of subtracting. It's much easier to just do command Y to accept or command N to reject. You don't have to type it in text. So it really allows the human to audit the work of these fabulous systems and to grow faster. We're going to come back to this in a little bit later as well. And the last kind of feature I want to point out is that there's what I call the autonomous slider. So for example, in Cursor, you can just do calculation. You're mostly in charge. You can select a chunk of code and command K to change a static chunk of code. You can do Command L to change this entire file, or you can do Command I, which just, you know, for better or worse, it packages up a lot of things, makes sure that it orchestrates people all at once. It's got a GUI that allows you to audit some of its work. So, for example, it will cite sources that you can imagine inspecting them, and it's got an autonomy slider. You can either just do a quick search, or you can do research, or you can do deep research and come back to all this later. So this is all just very well-structured, automated, and optimized.</p><p>So I guess my question is, I feel like a lot of software will become partially autonomous. And I'm trying to think through, like, what does that look like? In fact, many of you maintain products and services. How are you going to make your products and services partially autonomous? Can an LLM see everything that a human can see? Can an LLM act in all the ways that a human can act? And can humans supervise and stay in the loop of this activity? Because, again, these are allowable systems that aren't yet perfect. And what does the diff look like on Photoshop? There's a lot of things we don't know. And also, a lot of the traditional software right now has all these switches and all this kind of stuff. It's all designed for people. All this has to change and become accessible to LLMs.</p><p>So one thing I wanted to stress with a lot of these LLM apps that I'm not sure gets as much attention as it should, is LLM. We're now kind of, like, cooperating with the apps. And usually, they are doing a generation, and we assume this sort of verification. It is in our interest to make this move as fast as possible, so we're getting a lot of work. There are two major ways that I think this can be done. Number one, you can speed up verification a lot. And I think GUIs, for example, are extremely important for this, because a GUI utilizes your computer vision GPU in all of our head. Reading text is effortful, and it's not looking at stuff. It's on a headset. It's just a, like, a highway to your brain. So I think GUIs are very useful for auditing systems and visual representations in general. And number two, I would say is, we have to keep the AI in a leash. I think a lot of people are getting way overexcited with AI engines, and it's not useful to me to get the diff of 1,000 lines of code into my repo. Like, I have to, I'm still the bottom line, right? Even though the 1,000 lines come out instantly, I have to make sure that this thing is not introducing bugs. It's just like, and that it's doing the correct thing, right, and that there's no security issues and so on. So I think that, yeah, basically, you have to sort of, like, it's in our interest to make the flow of these two go very, very fast, and we have to somehow keep the AI in a leash because it gets way too overactive. It's kind of like this. This is how I feel when I do AI-assisted coding. If I'm just live coding, everything is nice and great, but if I'm actually trying to get work done, it's not so great to have an overactive engine doing all this kind of stuff. So this slide is not very good, I'm sorry, but I guess I'm trying to develop, like many of you, some ways of utilizing these engines in my career to look at AI-assisted coding, and if I don't work, I'm always scared to get way too big bits. I always go with small incremental chunks. I want to make sure that everything is good. I want to spin this thing very, very fast, and I sort of work on small chunks of single-token thing, and so I think many of you probably have a little bit similar ways to work with algorithms.</p><p>I also saw a number of blog posts that try to develop these best practices for working with algorithms, and here's one that I recently came across that's quite good, and it kind of discusses some techniques, and some of them have to do with how you keep the AI on a leash. And so as an example, if you're on prompting, if your prompt is vague, then the AI might not do exactly what you want it, and in that case, the verification will fail. You're gonna ask for something else. If the verification fails, then you're gonna start spinning. So it makes a lot more sense to spend a bit more time to be more complete in your prompts, which increases the probability of a successful verification, and you can move forward. And so I think a lot of us are gonna end up finding techniques like this.</p><p>I think in my own work as well, I'm very interested in what education looks like, and together with, now that we have an AI, and a lens for what does education look like, and I think a large amount of thought for me goes into how we keep AI on a leash. I don't think it just works to go through trashy ATM, you know, like the aging business. I don't think this works, because the AI is like, it gets lost in the woods. And so for me, this is actually two separate apps, for example, there's an app for a teacher that creates courses, and then there's an app that takes courses and serves them to students. And in both cases, we now have this intermediate artifact of a course that is auditable, we can make sure it's good, we can make sure it's consistent, and the AI is kept on a leash with respect to a certain syllabus, a certain progression of projects, and so on. And so this is one way of keeping AI on a leash that I think has a much higher likelihood of working. And the AI is not getting lost in the woods.</p><p>One more kind of methodology I wanted to sort of allude to is I'm not a most major to partial autonomy, I've kind of worked on this, I think, for five years for Tesla, and this is also a partial autonomy product that shares a lot of features, like for example, right there, the instrument panel has the weight of the product, so it's showing me what the neuron sees, and so on. And then the autonomy slide, where over the course of my tenure there, we did more and more autonomous tasks for Google News. And maybe the story that I wanted to tell very briefly is, actually the first time I drove a self-driving vehicle was in 2013, and I had a friend who works at Rainbow, and he offered to give me a drive around Palo Alto. I took this picture using a moving bus at the time, and many of you are so young that you might not even know what that is, but yeah, this was like all the rage at the time. And we got into this car, and we went for about a 40-minute drive around Palo Alto, and the highways, the streets, and so on, and this drive was perfect. There was zero traffic issues. And this was in 2013, which is now 12 years ago. And it kind of struck me, because at the time when I had this perfect drive, it was a perfect gift, I felt like, wow, self-driving was imminent, because this just worked, this is incredible. But here we are 12 years later, and we are still working on the tunnel. We are still working on the driving engines. And even now, we haven't actually like fully solved the problem. Like, you may see way-bos going around, and they look driverless, but there's still a lot of tool operation, and a lot of human input of what was driving. So we still haven't even like declared success, but I think it's definitely like going to succeed at this, but it just took a long time. And so I think, to me, what I found there is that there's a very large, what I call network-to-product gap that people don't intuitively always understand very well. And look, if you imagine works as like this binary array of a different situation, of like what works and doesn't work, then that is worse than many in products, in like works at all. In the sense that, if anything works, you can make demos. But in many cases, lots of things must work, but very few people are new to the product. And this is especially the case in high-reliability areas. Not all the areas are like this, but for sure in high-reliability cases, it means. And I would say autonomy, of course, because like this thing is going to crash, which would be bad. But I would also say software is like this. If you make a single mistake in software, we know that there could be a code path that's going to break, or it's going to introduce a security issue, or a zero-day, or something like that. Like, look, software is really tricky, I think, in the same way that driving is tricky. And so when I see things like, oh, 2035 is the year of agents, I get very concerned, and I kind of feel like, you know, this is the decade of agents, and this is going to be, by some time, you do this carefully, and this is software. Let's be serious here, okay?</p><p>One more kind of analogy that I always think through is the Iron Man suit. I think this is, I always love Iron Man, I think it's like so correct in a bunch of ways, with respect to technology and how it will play out. And what I love about the Iron Man suit is that it's both an augmentation, and twin-star mechanic driver. And it's also an agent, and in some of the movies, the Iron Man suit is quite autonomous, and you can fly around, climb trees, and all this kind of stuff. And so this is the autonomy sluggish, it can be, we can build augmentations, or we can build agents, and we kind of want to do a bit of both, but at this stage, I would say, working with Palo Alto LMS itself, I would say, you know, it's less Iron Man robots, and more Iron Man suits that you want to build. It's less, like, building flashy demos of autonomous agents, and more, building partial autonomy products. And these products affect who you speak, and we're trying to, and this is done so that the generation verification of the human is very, very fast. But we are not losing the sight of the fact that it is, in principle, possible to automate this work, and there should be an autonomy slider in your product, and you should be thinking about how you can slide that autonomy slider, and make your product sort of more autonomous over time. But this is kind of how, I think there's lots of opportunities in these kinds of products.</p><p>I want to now switch gears a little bit, and talk about one other dimension that I think is very important. Not only is there a new type of programmer language that allows for autonomy in software, but also, as I mentioned, it's programmed in English, which is this natural interface. And suddenly, everyone is a programmer, because everyone speaks natural language, like English. So this is extremely bullish, and very interesting to me, and also completely unprecedented, I would say. It used to be the case that you need to spend five to 10 years studying something to be able to do something that software can do. This is not the case anymore.</p><p>So I think that, by chance, anyone has heard of IBM? Okay. This is the tweet that introduced this, but I'm told that this is now a major meme. A story about this is that, I've been on Twitter for 15 years, or something like that, at this point, and I still have no clue which tweet will become viral, and which tweet this will send over the years. And I thought that this tweet was going to be, I'm going to just have a shower of thoughts, but this became a total meme, and I really just can't tell, but I guess it's working. Or even name something that everyone is calling, but can apply it to the same words. Now they're speaking Yiddish and everything. This is life. Yeah, this is like a major contribution now or something like that, so.</p><p>So Tom Wolfe from Hugging Feet shared this beautiful video that I really love. These are kids vibe coding. And I find that this is such a wholesome video, like, I love this video. Like, how can you look at this video and feel bad about the future? The future is great. I think this will end up being like a gateway drug to software development. I'm not a doer about the future of the generation, and I think, yeah, I love this video. So, I tried vibe coding a little bit as well, because it's so fun. So, vibe coding is so great when you want to build something super duper custom that doesn't appear to exist, and you just want to wing it because it's a Saturday or something like that. So, I built this iOS app, and I built into the, I can't actually program it in Swift, but I was really shocked that I was able to build a super basic app, and I'm not going to explain it, that's really dumb. But, I kind of like, this was just like a day of work, and this was running on my phone like later that day, and I was like, wow, this is amazing. I didn't have to like leave from Swift for like five days or something like that to like get started. I also vibe coded this app with a menu gem, and this is a lot, you can try a menu gem on that. And, I basically have this problem where I show up at a restaurant, I reach for the menu, and I have no idea what any of the things are, and I need pictures. So, this doesn't exist, so I was like, hey, I'm going to vibe code it. So, this is what it looks like. You go to menu gem, that app, and take a picture of the menu, and then menu gem generates the images. And, everyone gets five dollars in credits for free when you sign up, and therefore, this is a major cost center in my life. So, this is a negative revenue app for me right now. I lost a huge amount of money on menu gem. Okay.</p><p>But, the fascinating thing about menu gem for me is that the code, well, the vibe coding part, the code was actually an easy part of vibe coding menu gem. And, most of it actually was when I tried to make it real so that you can actually have authentication, payments, domain name, and personal deployment. This was really hard, and all of this was not code. All of this DevOps stuff was me and the browser clicking stuff. And, this was an extreme spot into another room. So, it was really fascinating that I had the menu gem basically demo working on my laptop in a few hours, and then it took me a week because I was trying to make it do it. And, the reason for this is this was just really annoying. So, for example, if you try to add Google log into your webpage, I know this is very small, but just a huge amount of instructions of this important library telling you how to integrate this, and this is crazy, like it's telling me, go to this URL, click on this dropdown, choose this, go to this, and click on that, and it's like telling me what to do. Like, the computer is telling me the actions I should be taking, like, you do it. What do I do? What the hell? I had to follow all these instructions. This was crazy.</p><p>So, I think the last part of my talk, therefore, focuses on can we just build for agents? I don't want to do this work anymore. Thank you. Okay.</p><p>So, roughly speaking, I think there's a new category of consumer and manipulator of digital information. It used to be just humans through GUIs, or computers, or APIs. And now it's a completely new thing. And agents are computers, but they are human-like. Kind of, right? They're people spirits. There's people spirits on the internet, and they need to interact with our software infrastructure. Can we build for them? It's a new thing. So, as an example, you can have robots.txt in your domain, and you can instruct, or advise, I suppose, web crawlers on how to behave with your website. In the same way, you can have maybe LLMs.txt file, which is just a simple markdown that's telling LLMs what this domain is about. And this is very readable to an LLM. If it had to be said, get the HTML of your webpage and try to parse it. This is very error-prone and difficult, and it will screw it up, and it's not going to work. So, we can just directly speak to the LLM, and it's worth it. 5.1. I see some of the services now are transitioning a lot of their docs to be specifically for LLMs. So, for Cell and Stripe, as an example, are early users here. But there are a few more that I've seen before. And they offer their documentation in Markdown. Markdown is crazy for LLMs to understand. This is great. Maybe one simple example from my experience as well. Maybe someone you know from Google Brown who makes beautiful animation videos. Yeah, I love this library that he wrote, Mavic. And I wanted to make my own. And there's extensive documentation on how to use M. So, I didn't want to actually read through it. So, I copy-pasted the whole thing to an LLM. And I just grabbed what I wanted, and it just worked out of the box. But LLM just byte-coded the animation exactly what I wanted. And I was like, wow, this is amazing. So, if we can make docs legible to LLMs, it's going to unlock a huge amount of objectives. And I think this is one of the core issues that should happen.</p><p>The other thing I wanted to point out is that we do unfortunately have to. It's not just about taking your docs and making them appear in Markdown. That's the easy part. We actually have to change the docs. Because any time your docs say, like, this is bad. And LLM will not be able to agent-maintain this action right now. So, Purcell, for example, is replacing every occurrence of play with an equivalent program that your LLM agent could take on your behalf. And so, I think this is very interesting. And then, of course, there's a model context protocol from them. And this is also another way. It's a protocol that's given directly to agents. It's a new consumer and particular commercial application. So, I'm very bullish on this.</p><p>The other thing I really like is the number of little tools here and there that are helping ingest data in very LLM-friendly formats. So, for example, when I go to a GitHub repo, I can't feed this to an LLM and ask questions about it. Because this is a human interface from GitHub. So, when you just change the URL from GitHub to GitHub Ingest, then this will actually concatenate all the files into a single giant text. And it will create a directory structure. It's ready to copy-paste it into a favorite LLM. And you can use it. Maybe even more of a dramatic example of this is Eclipse, where it's not just the raw content of its files. This is from Devon. But also, they have Devon basically do analysis of the GitHub repo. Devon basically builds up a whole box of pages just for your repo. And you can imagine that this is even more helpful to copy-paste into your LLM. So, I love all the little tools that basically just change the URL and make something accessible to an LLM. So, this is all well and great. And I think there's more to come.</p><p>One little note I wanted to make is that it is absolutely possible that in the future, LLMs will be able to, it's not even future, this is today, they'll be able to go around and they'll be able to put stuff at home. But I still think it's very worth basically eating LLM's pathway and making it easier for them to access all this information. Because this is still fairly expensive, I would say, to do this. And a lot more difficult. And so, I do think that lots of software that are being long-tailed, where it won't let them gap. Because these are not live layers or repositories or traditional infrastructure. And we will need these tools. But I think for everyone else, I think it's very worth it. So, I'm bullish on both.</p><p>So, in summary, what an amazing time to give to the industry. We need to rewrite a ton of code. A ton of code will be written by professionals and by players. These LLM's are kind of like utilities, kind of like labs, but they're kind of, especially, like operating systems. But it's so early. It's like 1960s operating systems. And I think a lot of the analogies cross over. And these LLM's are kind of like these fallible people spirits that we have to learn to work with. And in order to do that properly, we need to adjust our infrastructure. So, when you're building these LLM's, it's practical ways of working effectively with these LLM's and some of the tools that make that possible. And how you can spin this very, very quickly and basically create partial time for products. And then, yeah, a lot of code has to be written for the agents. But, in any case, going back to the Iron Man suit analogy, I think what we'll see over the next decade, roughly, is we're going to take the slider from left to right. Very interesting. It's going to be very interesting to see what that looks like. So, with all of you. Thank you.</p><p>that's all. let's keep in touch?</p></div></div>]]></description>
        </item>
    </channel>
</rss>