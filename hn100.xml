<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 14 Jan 2026 15:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[SparkFun Officially Dropping AdaFruit due to CoC Violation (141 pts)]]></title>
            <link>https://www.sparkfun.com/official-response</link>
            <guid>46616488</guid>
            <pubDate>Wed, 14 Jan 2026 14:34:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sparkfun.com/official-response">https://www.sparkfun.com/official-response</a>, See on <a href="https://news.ycombinator.com/item?id=46616488">Hacker News</a></p>
<div id="readability-page-1" class="page">
        <ul><li data-bind="scope: 'compareProducts'" data-role="compare-products-link" role="region" aria-label="comparison">
    
</li>


</ul>




    <!-- GOOGLE TAG MANAGER -->
    
    <!-- END GOOGLE TAG MANAGER -->



    
    <!-- ko scope: 'gdpr-cookie-modal' -->
        <!--ko template: getTemplate()--><!-- /ko -->
    <!-- /ko -->
    


<div><main id="maincontent">
<a id="contentarea" tabindex="-1"></a>
<div>





<div data-enable-parallax="0" data-parallax-speed="0.5" data-background-images="{}" data-background-type="image" data-video-loop="true" data-video-play-only-visible="true" data-video-lazy-load="true" data-video-fallback-src="" data-background-image-format="webply" data-element="main" data-pb-style="LJB28AC" data-content-type="row" data-appearance="contained"><div data-content-type="text" data-appearance="default" data-element="main">
<p><br>Due to recent activities that are in direct violation of our <a tabindex="0" href="https://www.sparkfun.com/support#code-of-conduct">Code of Conduct,&nbsp;which is publicly available on our website</a>, SparkFun has determined that it can no longer transact with Adafruit Industries. Please see the official communication we sent to Adafruit below. Without oversharing, recent violations include:</p>
<ul>
<li>Sending and forwarding offensive, antagonistic, and derogatory emails and material to SparkFun employees, former employees and customers</li>
<li>Inappropriately involving a SparkFun customer with a private matter</li>
</ul>
<p>We understand this may be frustrating. From time to time, we have to make difficult business decisions and this decision was made after thoughtful consideration. We wish Adafruit the best in future endeavors. Please note, SparkFun continues to embrace our strong reseller network - for SparkFun-original products, Teensy, and a multitude of other products. Please see our distributor map below.</p>
<p>Communication sent to Adafruit:&nbsp;</p></div><figure data-content-type="image" data-appearance="full-width" data-element="main" data-pb-style="HOSRCV6"><img src="https://www.sparkfun.com/media/.renditions/wysiwyg/2025_DEC8_ADAFRUIT_TERMINATION_LETTER.png?format=webpll" alt="Termination Letter" title="" loading="lazy" data-image-format="webpll" data-element="desktop_image" data-pb-style="IG7TTRH"><img src="https://www.sparkfun.com/media/.renditions/wysiwyg/2025_DEC8_ADAFRUIT_TERMINATION_LETTER.png?format=webpll" alt="Termination Letter" title="" loading="lazy" data-image-format="webpll" data-element="mobile_image" data-pb-style="V1CG9NO"></figure></div><div data-enable-parallax="0" data-parallax-speed="0.5" data-background-images="{}" data-background-type="image" data-video-loop="true" data-video-play-only-visible="true" data-video-lazy-load="true" data-video-fallback-src="" data-background-image-format="webply" data-element="main" data-pb-style="DCCH1XA" data-content-type="row" data-appearance="contained"><h2 data-content-type="heading" data-appearance="default" data-element="main" data-pb-style="PEKJ8SI">Distributor Map</h2></div>



        
</div></main>








</div>    

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Servo 2025 Stats (137 pts)]]></title>
            <link>https://blogs.igalia.com/mrego/servo-2025-stats/</link>
            <guid>46615167</guid>
            <pubDate>Wed, 14 Jan 2026 12:14:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blogs.igalia.com/mrego/servo-2025-stats/">https://blogs.igalia.com/mrego/servo-2025-stats/</a>, See on <a href="https://news.ycombinator.com/item?id=46615167">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="skip">
				




<ul>
	<li><time datetime="2026-01-14">14 January 2026</time></li>
	<li><a href="https://blogs.igalia.com/mrego/tags/english/">English</a></li>
	<li><a href="https://blogs.igalia.com/mrego/tags/planet/">Planet</a></li>
	<li><a href="https://blogs.igalia.com/mrego/tags/servo/">Servo</a></li>
</ul>


<p>This is a brief blog post to highlight the growth of the Servo community in recent years, particularly since <a href="https://igalia.com/">Igalia</a> took over the project maintenance in 2023.</p>
<p>Note that this doesn’t talk about the technical achievements, though there have been tons of them in the last years. <em>A picture is worth a thousand words</em> so just take a look at <a href="https://blogs.igalia.com/mrego/servo-a-new-web-engine-written-in-rust/">this slide from my latest Servo talk</a> which shows how <a href="https://www.google.com/">google.com</a> was rendered with Servo at the beginning of 2023 vs September 2025.</p>
<figure>
<p><img src="https://blogs.igalia.com/mrego/files/2025/09/servo-talk-at-gosim/slide-11.png" alt="Slide showing screenshots of Servo rendering google.com in January 2025 vs September 2025"></p>
  <figcaption>Slide showing screenshots of Servo rendering google.com in January 2023 vs September 2025</figcaption>
</figure>
<h2 id="prs-numbers" tabindex="-1">PRs numbers <a href="#prs-numbers">#</a></h2>
<p>So like <a href="https://blogs.igalia.com/mrego/servo-revival-2023-2024/">we did last year</a>, let’s take a look at the PRs merged on the main <a href="https://github.com/servo/servo">Servo repository on GitHub</a> since 2018.</p>
<div>
  <table>
    <thead>
      <tr>
        <th></th>
        <th>2018</th>
        <th>2019</th>
        <th>2020</th>
        <th>2021</th>
        <th>2022</th>
        <th>2023</th>
        <th>2024</th>
        <th>2025</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>PRs</strong></td>
        <td>1,188</td>
        <td>986</td>
        <td>669</td>
        <td>118</td>
        <td>65</td>
        <td>776</td>
        <td>1,771</td>
        <td>3,183</td>
      </tr>
      <tr>
        <td><strong>Contributors</strong></td>
        <td>27.33</td>
        <td>27.17</td>
        <td>14.75</td>
        <td>4.92</td>
        <td>2.83</td>
        <td>11.33</td>
        <td>26.33</td>
        <td>42.42</td>
      </tr>
      <tr>
        <td><strong>Contributors ≥ 10</strong></td>
        <td>2.58</td>
        <td>1.67</td>
        <td>1.17</td>
        <td>0.08</td>
        <td>0.00</td>
        <td>1.58</td>
        <td>4.67</td>
        <td>8.50</td>
    </tr>
    </tbody>
  </table>
</div>
<ul>
<li><strong>PRs</strong>: total number of PRs merged.</li>
<li><strong>Contributors</strong>: average number of contributors per month.</li>
<li><strong>Contributors ≥ 10</strong>: average number of contributors that have merged more than 10 PRs per month.</li>
</ul>
<p>As a clarification, these numbers don’t include PRs from bots (<code>dependabot</code> and <code>Servo WPT Sync</code>).</p>
<p>Checking this we can see we are close to <strong>double the numbers from last year</strong>! The numbers in 2025 are way bigger than in the previous years (even checking the numbers from 2018-2019), showing a healthy community working on Servo.</p>



<p>The next chart is a different view of the same data but split per month, with the number of PRs landed every month, the number of contributors and the number of contributors with more than 10 patches. It shows the evolution over the years and the high activity last year.</p>


<h2 id="number-of-contributors" tabindex="-1">Number of contributors <a href="#number-of-contributors">#</a></h2>
<p>Now let’s focus on the last 3 years, since the project reactivation, and the numbers of contributors to the Servo project.</p>
<div>
  <table>
    <thead>
      <tr>
        <th></th>
        <th>2023</th>
        <th>2024</th>
        <th>2025</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>Contributors</strong></td>
        <td>54</td>
        <td>129</td>
        <td>146</td>
      </tr>
      <tr>
        <td><strong>≥ 100 PRs</strong></td>
        <td>1 (2%)</td>
        <td>3 (2%)</td>
        <td>8 (5%)</td>
      </tr>
      <tr>
        <td><strong>≥ 10 PRs</strong></td>
        <td>8 (15%)</td>
        <td>29 (22%)</td>
        <td>43 (29%)</td>
      </tr>
      <tr>
        <td><strong>Only 1 PR</strong></td>
        <td>31 (57%)</td>
        <td>53 (41%)</td>
        <td>55 (38%)</td>
      </tr>
    </tbody>
  </table>
</div>
<p>The number of contributors to Servo has tripled since 2023, reaching <strong>146 different contributors in 2025</strong>.</p>
<p>If we analyze the rest of the data in this table, we can see that the percentage of contributors that do a single PR to Servo in a year has been reduced, meaning that Servo contributors are now usually doing more than one PR to the project.</p>
<p>If we check the number of contributors that have done more than 10 PRs in a year, we see the percentage almost doubling from 15% to 29% in the last 3 years.</p>
<p>And for the top contributors doing more than 100 PRs in a year, we have gone from 1 in 2023 and 3 in 2024 to 8 last year, which represent the 5% of the Servo contributors, showing a good team of very active contributors to the project.</p>
<h2 id="wpt-pass-rate" tabindex="-1">WPT pass-rate <a href="#wpt-pass-rate">#</a></h2>
<p>Let’s take a look at <a href="https://web-platform-tests.org/">WPT</a> evolution in 2025.</p>
<div>
<table>
<thead>
<tr>
<th>2025</th>
<th>January 1st</th>
<th>December 31st</th>
<th>Diff</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Score %</strong></td>
<td>48.2%</td>
<td>61.6%</td>
<td><strong>+13.4%</strong></td>
</tr>
<tr>
<td><strong>Subtests (passed/total)</strong></td>
<td>1396647/1998146</td>
<td>1866247/1998146</td>
<td><strong>+469,600</strong></td>
</tr>
<tr>
<td><strong>Subtests %</strong></td>
<td>69.9%</td>
<td>93.4%</td>
<td><strong>+23.5%</strong></td>
</tr>
</tbody>
</table>
</div>
<figure>
<p><img src="https://blogs.igalia.com/mrego/files/2026/01/wpt.png" alt="Evolution of WPT pass rates for Servo in 2025"></p>
  <figcaption>Evolution of WPT pass rates for Servo in 2025</figcaption>
</figure>
<p>You can check more information about WPT pass-rates at <a href="https://servo.org/wpt/">Servo’s website</a> (where you can also find an explanation of the <em>Score</em> number).</p>
<p>Note that these numbers differ from <a href="https://wpt.fyi/">wpt.fyi</a> because we’re still not running all the WPT tests in Servo, so the total numbers here are smaller.</p>
<p>It’s not easy to extract conclusions from this data, but it shows the Servo project keeps progressing and supporting more web platform features as time passes.</p>
<p>Sometimes these numbers grow artificially as new tests are added to WPT for features that Servo already supports (for example, the biggest jump last year was in October getting 188,281 new subtests passing without any change in Servo, just because new tests were added to WPT).</p>
<h2 id="github-stars" tabindex="-1">GitHub stars <a href="#github-stars">#</a></h2>
<figure>
<p><img src="https://blogs.igalia.com/mrego/files/2026/01/github-stars.png" alt="Evolution of GitHub stars for Servo from https://www.star-history.com/#servo/servo"></p>
  <figcaption>Evolution of GitHub stars for Servo from <a href="https://www.star-history.com/#servo/servo">start-history.com</a></figcaption>
</figure>
<p>We are about to reach <strong>35,000 stars on GitHub</strong>. It’s good to see the project has not stopped growing since the beginning, and the curve has become steeper in recent years.</p>
<h2 id="other" tabindex="-1">Other <a href="#other">#</a></h2>
<p>If we check to the <a href="https://github.com/servo/project/blob/main/governance/README.md">official project roles</a>, we have now:</p>
<ul>
<li>5 administrators</li>
<li>17 TSC members</li>
<li>25 maintainers</li>
<li>18 contributors</li>
</ul>
<p>We have also started doing <a href="https://servo.org/blog/2025/10/20/servo-0.0.1-release/"><strong>Servo releases</strong></a>, we have done <a href="https://github.com/servo/servo/releases">3 so far</a>.</p>
<p>Also the TSC has setup <a href="https://servo.org/blog/2025/11/21/sponsorship-tiers/">sponsorship tiers</a> for donations. We got <a href="https://servo.org/#acknowledgements"><strong>4 bronze sponsors</strong></a> in 2025 and we hope to increase the number of sponsorships in 2026.</p>
<p>Regarding donations, we have defined a <a href="https://github.com/servo/project/blob/main/FUNDING_REQUEST.md"><strong>funding process</strong></a> to request usage of that money. We are currently using it to sponsor <a href="https://servo.org/blog/2025/09/17/your-donations-at-work-funding-jdm/">Josh Matthews’ contributions</a>, and <a href="https://www.azabani.com/2025/12/18/shoestring-web-engine-ci.html">pay for self-hosted runners to speed up CI times</a>.</p>
<p>Servo has been present in several events last year, we ended up giving <a href="https://servo.org/about/"><strong>10 talks</strong></a> all around the globe.</p>
<h2 id="wrap-up" tabindex="-1">Wrap-up <a href="#wrap-up">#</a></h2>
<p>The idea here was to do a quick recap of the Servo stats in 2025. Taking a look at these numbers every now and then is useful, and gives you a different perspective about the status of the project, that one can easily ignore during the day-to-day tasks.</p>
<p>In general things have grown a lot in 2025, who knows what would happen in 2026, but we hope we can at least keep similar numbers or maybe even keep growing them further. That would be really great news for the Servo project.</p>
<p>Igalia is really proud of what the whole Servo community has achieved together in the recent years, and we hope for a bright future for the project going forward.</p>
<p>As an aside note, by the end of the month I’ll be at <a href="https://pretalx.fosdem.org/fosdem-2026/talk/review/PQPRDZ8DM7L8SYHBKGNZUJZUWGEXQTTP">FOSDEM talking about Servo</a>, other Servo folks like <a href="https://www.igalia.com/team/dazabani">Delan Azabani</a> and <a href="https://www.igalia.com/team/mrobinson">Martin Robinson</a> will also be there. If you are around, don’t hesitate to say hi and ask anything about the project.</p>


<ul><li>Previous: <a href="https://blogs.igalia.com/mrego/blog/2025-12-02/">Short 2025-12-02</a></li>
</ul>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Hate GitHub Actions with Passion (158 pts)]]></title>
            <link>https://xlii.space/eng/i-hate-github-actions-with-passion/</link>
            <guid>46614558</guid>
            <pubDate>Wed, 14 Jan 2026 10:53:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xlii.space/eng/i-hate-github-actions-with-passion/">https://xlii.space/eng/i-hate-github-actions-with-passion/</a>, See on <a href="https://news.ycombinator.com/item?id=46614558">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <p>
    <time datetime="2026-01-14 00:00:00 +0000 UTC">
      2026-01-14
    </time>
  </p>
  


  


  

  
  


  <p>I can’t overstate how much I hate GitHub Actions. I don’t even remember hating any other piece of technology I used. Sure, I still make fun of PHP that I remember from times of PHP4<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, but even then I didn’t <em>hate</em> it. Merely I found it subpar technology to other emerging at the time (like Ruby on Rails or Django). And yet I hate GitHub Actions.</p>
<p>With Passion<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>





    <img src="https://xlii.space/images/github-actions-workflow-failed-small_hu_41b5aaa5fc955172.jpg" width="659" height="400" alt="">
  


<h2 id="road-to-hell">Road to Hell</h2>
<p>Day before writing these words I was implementing <code>build.rs</code> for my <a href="https://github.com/exlee/tmplr">tmplr</a> project. To save you a click - it is a file/project scaffold tool with human readable (and craftable) template files. I (personally) use it very often, given how easy it is to craft new templates, by hand or with aid of the tool, so check it out if you need a similar tool.</p>
<p>The <code>build.rs</code> used <code>CUE</code> to generate <code>README.md</code>, <code>CHANGELOG.md</code> and also a version/help file to guarantee consistency. It was fun thing to do, it took approx. 1.5h and I even <a href="https://dev.to/exlee/buildrs-ing-documentation-with-cuelang-3h2a">wrote an article</a> about it. For myself and future generations.</p>
<p>I was happy with the results and didn’t check CI output which, quite unsurprisingly, failed. I was using <code>cue</code> binary inside <code>build.rs</code> and without it build simply couldn’t progress. When I woke up next day and saw e-mail from CI notifying me about failed build I immediatelly knew my day isn’t going to start with puppies and rainbows.</p>
<p>It took couple attempts to search and push GitHub Action that would install <code>CUE</code> and then I got the worst of the worst results: One system in matrix failing to build.</p>
<p>A word of explanation. I’m building <code>tmplr</code> for 4 platforms:</p>
<ul>
<li>Linux ARM</li>
<li>macOS ARM</li>
<li>Linux x86_64</li>
<li>macOS x86_64</li>
</ul>
<p>Makes sense, right? Even though my user base can be counted on a fingers of one-arm-less and second-arm-hook-equipped pirate, it’s still a thing “One Should Do”.</p>
<p>And with all that - Linux ARM failed with “command can’t be found”. <code>CUE</code> installed and ran nicely for all other 3 targets, but for some reason it failed for Linux ARM.</p>
<p>In case you don’t care about <em>why</em> I hate GitHub but your mind started to wonder to “what went wrong” let me tell you; because I know.</p>
<p>So supposedly cross build that happens in matrix is heavily isolated. When I install <code>CUE</code> I install it only on x86_64 Linux host and macOS ARM host. macOS has zero issues running x86_64 binary and no issues are raised when Linux x86_64 tries to run x86_64 binary. But GitHub Actions is nice enough to <strong>hide</strong> x86_64 binary from arm64 runner, so that it won’t break.</p>
<p>Thank you GitHub Actions. What would’ve I done without you.</p>
<h2 id="broken-loop">Broken Loop</h2>
<p>And so my least favorite feedback loop started and went like this:</p>
<ol>
<li>Search for possible fix</li>
<li>Change <code>ci.yml</code></li>
<li><code>jj squash --ignore-immutable &amp;&amp; jj git push</code> <sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></li>
<li>Open “Actions” tab</li>
<li>Open latest run</li>
<li>Open Linux ARM run</li>
<li>Wait couple of seconds</li>
<li>Hate Life</li>
<li>Offer the Universe choice words it won’t soon forget</li>
<li>Rinse &amp; repeat</li>
</ol>
<p>I got quite efficient when it comes to points 8 and 9 but otherwise the whole loop still took around 2-3 minutes to execute.</p>
<p>FOR. A. SINGLE. CHANGE.</p>
<p>Yes. For a single change. Like having an editor with 2 minute save lag, pushing commit using program running on cassette tapes<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> or playing chess over snail-mail. It’s 2026 for Pete’s sake, and we<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> won’t tolerate this behavior!</p>
<p>Now of course, in some Perfect World, GitHub could have a local runner with all the bells and whistles. Or maybe something that would allow me to quickly check for progress upon the push<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> or even something like a “scratch commit”, i.e. a way that I could testbed different runs without polluting history of both Git and Action runs.</p>
<p>But no such perfect world exists and one is at the whim of heartless YAML-based system.</p>
<h2 id="breaking-off">Breaking off</h2>
<p>I suffered only 30 minutes of such loops. Could’ve done it for longer but I was out of colorful language to use and felt without it the process just isn’t the same.</p>
<p>There is a wise saying in the internet that goes like:</p>
<p><strong>For the love of all that is holy, don’t let GitHub Actions manage your logic. Keep your scripts under your own damn control and just make the Actions call them!</strong></p>
<p>This is what everyone should do. This is what I did.</p>
<p>I deleted <code>build.rs</code> (with a sliver of sadness because it was really nice - but sacrifices had to be made). I moved all the generation from <code>build.rs</code> to GNU Makefile, committed the darn files into repository, reverted changes to CI and called it a day. Problem solved.</p>
<h2 id="exit-code-0">Exit Code: 0</h2>
<p>GitHub Actions, Friends &amp; Gentlefolk, is the reason why we can’t have (some) nice things. I can’t count how many hours I’ve lost debugging the runners or trying to optimize the build process. It’s a sorry process every single time, a time that would be better spent elsewhere.</p>
<p>And yet there are some benefits, like macOS builds that would be quite hard to get otherwise. I don’t know any other system that would be easier to setup than GitHub Actions (if you know one, let me know) but it seems there’s no escape.</p>
<p>We are all doomed to GitHub Actions.</p>
<p>…but at least I dodged the bullet early.</p>


</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I’m leaving Redis for SolidQueue (191 pts)]]></title>
            <link>https://www.simplethread.com/redis-solidqueue/</link>
            <guid>46614037</guid>
            <pubDate>Wed, 14 Jan 2026 09:25:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.simplethread.com/redis-solidqueue/">https://www.simplethread.com/redis-solidqueue/</a>, See on <a href="https://news.ycombinator.com/item?id=46614037">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<article id="post-7470">
	<!-- .entry-header -->

	<div>

          <p><img width="1644" height="1362" src="https://www.simplethread.com/wp-content/uploads/2025/11/redis-tattoo-mattK.jpg" alt="I Love You, Redis, But I’m Leaving You for SolidQueue" decoding="async" fetchpriority="high" srcset="https://www.simplethread.com/wp-content/uploads/2025/11/redis-tattoo-mattK.jpg 1644w, https://www.simplethread.com/wp-content/uploads/2025/11/redis-tattoo-mattK-300x249.jpg 300w, https://www.simplethread.com/wp-content/uploads/2025/11/redis-tattoo-mattK-1024x848.jpg 1024w, https://www.simplethread.com/wp-content/uploads/2025/11/redis-tattoo-mattK-768x636.jpg 768w, https://www.simplethread.com/wp-content/uploads/2025/11/redis-tattoo-mattK-1536x1273.jpg 1536w" sizes="(max-width: 1644px) 100vw, 1644px">			</p><!-- .st-post-thumbnail -->

		    
		
<p><a href="https://rubyonrails.org/">Rails 8</a>, the latest release of the popular web application framework based on Ruby, excised <a href="https://redis.io/">Redis</a>&nbsp;from its standard technology stack. Redis is no longer required to queue jobs, cache partials and data, and send real-time messages. Instead, Rails’s new features—<a href="https://github.com/rails/solid_queue">SolidQueue</a>&nbsp;for job queuing, <a href="https://github.com/rails/solid_cache">SolidCache</a>&nbsp;for caching, and <a href="https://github.com/rails/solid_cable">SolidCable</a>&nbsp;for transiting ActionCable messages—run entirely on your application’s existing relational database service. For most Rails applications, Redis can be discarded.</p>
<p>I know how that sounds. The Redis key-value store is fast, adept, and robust, and its reliability made it the preferred infrastructure for Rails job queueing and caching for more than a decade. Countless applications depend on Redis every day.</p>
<p>However, Redis does add complexity. SolidQueue, SolidCache, and SolidCable sparked something of an epiphany for me: <a href="https://boringtechnology.club/">boring technology</a>&nbsp;such as relational database tables can be just as capable as a specialized solution.</p>
<p>Here, let’s examine the true cost of running Redis, discover how SolidQueue works and supplants a key-value store, and learn how to use SolidQueue to migrate an application’s job queues to vanilla PostgreSQL (or SQLite or MySQL). Web development is already too complicated—let’s <em>simplify</em>.</p>
<h2 id="h.r03o9apwrc9f">The True Cost of Redis</h2>
<p>What does Redis cost beyond its monthly hosting bill? Setup and ongoing maintenance are not free. To use Redis you must:</p>
<ul>
<li>Deploy, version, patch, and monitor the server software</li>
<li><a href="https://redis.io/docs/latest/operate/oss_and_stack/management/persistence">Configure a persistence strategy</a>. Do you choose RDB snapshots, AOF logs, or both?</li>
<li>Set and watch <a href="https://redis.io/docs/latest/operate/rs/databases/memory-performance/memory-limit/)">memory limits</a>&nbsp;and establish <a href="https://redis.io/docs/latest/operate/rs/databases/memory-performance/eviction-policy">eviction policies</a></li>
</ul>
<p>In addition to those taxes, there are other ongoing burdens to infrastructure and interoperability. You must also:</p>
<ul>
<li>Sustain network connectivity, including firewall rules, between Rails and Redis</li>
<li>Authenticate your Redis clients</li>
<li>Build and care for a high availability (HA) Redis cluster</li>
<li>Orchestrate the lifecycles of Sidekiq processes across deployments</li>
</ul>
<p>Further, when something goes wrong with a job, you’re faced with debugging Redis and your RDBMS, two data stores with very different semantics, switching context between different query languages and tools. And then there’s the issue of two separate backup strategies. (You tested them both, right?)</p>
<p>In a “Redis-less” Rails stack, things are simpler. If Rails or PostgreSQL fails, everything stops.</p>
<h2 id="h.35fl6getq7lw">How SolidQueue Works</h2>
<p>Redis is a very different data store than PostgreSQL. In many ways, Redis is treated as if it’s memory: atomic, volatile, and very fast. So how does SolidQueue manage to replace it with PostgreSQL?</p>
<p><a href="https://www.postgresql.org/docs/9.5/sql-select.html#sql-for-update-share">PostgreSQL 9.5</a>&nbsp;enhanced its SQL <code>FOR UPDATE</code>&nbsp;clause to add &nbsp;<code>SKIP LOCKED</code>. The <code>FOR UPDATE</code>&nbsp;clause creates an exclusive row lock. <code>SKIP LOCKED</code>&nbsp;further skips any rows currently locked. This mechanism makes running database-backed job queues viable, even at scale.</p>
<p>Here’s what happens when a worker needs a job:</p>
<pre><code>
SELECT * FROM solid_queue_ready_executions
WHERE queue_name = 'default'
ORDER BY priority DESC, job_id ASC
LIMIT 1
FOR UPDATE SKIP LOCKED
</code></pre>
<p>A free worker always picks up the next available job.</p>
<p>This database optimization solves the fundamental problem that plagued earlier database queue implementations: <em>lock contention</em>. A worker never waits for another and a worker never blocks. Multiple workers can query simultaneously and PostgreSQL guarantees each claims a unique job. When a worker finishes processing, it releases the lock and deletes the execution record.</p>

<p>The SolidQueue architecture centers on three tables:</p>
<ol start="1">
<li>All jobs are stored in <code>solid_queue_jobs</code>. The table persists job metadata, such as the name of the job, its Ruby class, and timestamps to record when the job started and finished. By default, every queueing request &nbsp;is recorded in this table and retained permanently, even after the job completes.</li>
<li>A scheduled job waits in <code>solid_queue_scheduled_executions</code>&nbsp;until its scheduled time arrives.</li>
<li>A job ready to run immediately is queued to solid_queue_ready_executions, where a worker &nbsp;claims it.</li>
</ol>
<p>Job tables can churn rapidly and steadily (there are hordes of inserts and deletes), but PostgreSQL’s MVCC design handles this fine with its built-in autovacuum process. No special tuning required.</p>
<p>A handful of processes coordinate this flow.</p>
<ul>
<li>Workers poll <code>solid_queue_ready_executions</code>&nbsp;at configurable intervals (as fast as 0.1 seconds for high-priority queue/se</li>
<li>Jobs are claimed and subsequently executed with <code>FOR UPDATE SKIP LOCKED</code>&nbsp;to control concurrency.</li>
<li>Dispatchers poll <code>solid_queue_scheduled_executions</code>&nbsp;once per second, moving due jobs into the ready table.</li>
<li>Schedulers manage recurring tasks by enqueueing jobs per defined timetables.</li>
<li>A supervisor process monitors all these, tracking heartbeats and restarting crashed processes.</li>
</ul>
<p>These separate concerns may be SolidQueue’s most elegant feature. Each process type operates on different tables with different polling intervals optimized for its workload. The processes never interfere with each other, and the database handles all coordination through vanilla transactional database semantics.</p>
<h2 id="h.sihc6y9b6bdz">Scheduling Recurring Jobs with SolidQueue</h2>
<p>Recurring jobs add to the costs inherent with Redis, as you often must integrate yet another library to schedule regular jobs. For example, assuming an application uses <a href="https://sidekiq.org/">Sidekiq</a>&nbsp;for its <a href="https://guides.rubyonrails.org/active_job_basics.html">ActiveJob</a>&nbsp;adapter, <a href="https://github.com/sidekiq-cron/sidekiq-cron">sidekiq-cron</a>&nbsp;and <a href="https://github.com/javan/whenever">whenever</a>&nbsp;are two popular solutions to schedule repetitive jobs.</p>
<p>Nothing supplemental is required; however, if you use SolidQueue. It includes <em>cron</em>-style recurring jobs out of the box. Simply edit <em>config/recurring.yml</em>. The configuration file should look hauntingly familiar:</p>
<pre><code>
# config/recurring.yml
production:

&nbsp; cleanup_old_sessions:
&nbsp; &nbsp; class: CleanupSessionsJob
&nbsp; &nbsp; schedule: every day at 2am
&nbsp; &nbsp; queue: maintenance

&nbsp; send_daily_digest:
&nbsp; &nbsp; class: DailyDigestJob
&nbsp; &nbsp; schedule: every day at 9am
&nbsp; &nbsp; queue: mailers

&nbsp; refresh_cache:
&nbsp; &nbsp; class: CacheWarmupJob
&nbsp; &nbsp; schedule: every hour
&nbsp; &nbsp; queue: default</code></pre>
<p>Here’s how SolidQueue’s recurring jobs work in practice.</p>
<ul>
<li>When the scheduler runs it finds the jobs due and enqueues each job to run. In the list above, for example, the task <strong>refresh_cache</strong>&nbsp;causes CacheWarmupJob&nbsp;to run at the top of each hour.</li>
<li>Concurrently, the scheduler also queues a new job to run at the time of the next occurrence in the series. Continuing the example, an hourly task that runs at 8:00 AM schedules itself to run again at 9:00 AM.</li>
<li>The 9:00 AM task schedules itself for 10:00 AM, ad infinitum.</li>
</ul>
<p>This pattern is borrowed from <a href="https://github.com/bensheldon/good_job">GoodJob</a>, another database-backed queue system. It’s crash-resistant because schedules are deterministic. “Every hour” always resolves to the top of the hour, regardless of when the scheduler process starts.</p>

<p>If you want more detail on everything SolidQueue is doing under the hood, <a href="https://blog.appsignal.com/authors/hans-j%C3%B6rg-schnedlitz.html)">Hans-Jörg Schnedlitz</a>&nbsp;over at AppSignal gives a really <a href="https://blog.appsignal.com/2025/06/18/a-deep-dive-into-solid-queue-for-ruby-on-rails.html">thorough treatment</a>&nbsp;of all its pulleys and belts.</p>
<h2 id="h.fcj9kedvqxg0">Job Concurrency: The Feature You Didn’t Know You Needed</h2>
<p>If you’ve historically used Rails at mere mortal scale, you may be unaware that Sidekiq also offers <a href="https://github.com/sidekiq/sidekiq/wiki/Ent-Rate-Limiting">concurrency limits as a paid feature</a>&nbsp;in Sidekiq Enterprise. If you’re considering using Sidekiq, concurrency limiting alone is worth the additional expense for the Enterprise edition.</p>
<p>But SolidQueue gives you this, and more, for free! Simply add <code>limits_concurrency</code>&nbsp;to any job.</p>
<pre><code>class ProcessUserOnboardingJob &lt; ApplicationJob
&nbsp; limits_concurrency to: 1, 
&nbsp; &nbsp; key: -&gt;(user) { user.id }, 
&nbsp; &nbsp; duration: 15.minutes

def perform(user)&lt;
&nbsp; &nbsp; # Complex onboarding workflow
&nbsp; end
end
</code></pre>
<p><code>limits_concurrency to: 1</code> ensures only one <code>ProcessUserOnboardingJob</code>&nbsp;job runs per user at any one time.</p>
<p>The <code>duration</code>&nbsp;parameter is also essential, as it defines how long SolidQueue guarantees the concurrency limit. If a job crashes, say, the semaphore eventually expires, preventing deadlocks caused by crashed workers that never release their locks.</p>

<p>The implementation uses two tables: <code>solid_queue_semaphores</code>&nbsp;to track concurrency limits and <code>solid_queue_blocked_executions</code>&nbsp;to hold jobs waiting for semaphore release. When a job finishes, it releases its semaphore and triggers a dispatcher to unblock the next waiting job. It’s elegant, database-native, and requires zero external coordination.</p>
<h2 id="h.7uttb9o3suc">Monitor SolidQueue with Mission Control</h2>
<p>The no-fee version of Sidekiq’s web user interface is okay. <a href="https://sidekiq.org/">Sidekiq Pro</a>&nbsp;($949/year) and Sidekiq Enterprise (starting at $1,699/year) offer enhanced dashboards.</p>
<p><a href="https://github.com/rails/mission_control-jobs">Mission Control Jobs</a>&nbsp;is free, open source, and designed specifically for Rails 8’s SolidQueue ecosystem:</p>
<pre><code># config/routes.rb
mount MissionControl::Jobs::Engine, at: "/jobs"</code></pre>
<p>With this single line in your routes, you now have:</p>
<ul>
<li>“Real-time” job status across all queues</li>
<li>Failed job inspection with full stack traces</li>
<li>Retry and discard controls with batch operations</li>
<li>Scheduled job timeline visualization</li>
<li>Recurring job management</li>
<li>Queue-specific metrics and throughput graphs</li>
</ul>
<p>Even better, Mission Control can inspect your database schema. When you inspect a failed job, you can see its job arguments (just like Sidekiq), but you can also query the job data with everyone’s favorite query language, SQL:</p>
<pre><code>SELECT j.queue_name, COUNT(*) as failed_count
FROM solid_queue_failed_executions fe
JOIN solid_queue_jobs j ON j.id = fe.job_id
WHERE fe.created_at &gt; NOW() - INTERVAL '1 hour'
GROUP BY j.queue_name;</code></pre>
<p>SQL is a language you already know running in tools you already use. No external parsing. No timestamp arithmetic. Just SQL.</p>
<h2 id="h.uutpk7t1qdui">The Migration Path: From Sidekiq to SolidQueue</h2>
<p>It’s almost trivial to migrate from Sidekiq to SolidQueue.</p>
<h4 id="h.6tqlll68u3lx"><strong>Step 1: Change the Rails queue adapter</strong></h4>
<p>Rails’s queue adapter setting specifies which queuing backend is used for processing background jobs asynchronously. Set it to <code>:solid_queue</code>.</p>
<pre><code># config/environments/production.rb
config.active_job.queue_adapter = :solid_queue</code></pre>
<h4 id="h.48tk995bmllm"><strong>Step 2: Install SolidQueue</strong></h4>
<p>The SolidQueue gem must be installed separately from Rails. The gem includes two tasks to add SolidQueue’s tables to the application’s database.</p>
<pre><code>$ bundle add solid_queue
$ rails solid_queue:install
$ rails db:migrate
</code></pre>
<h4 id="h.lgvjgjkwngjq"><strong>Step 3: Replace sidekiq-cron schedules</strong></h4>
<p>Assuming you are using Sidekiq, convert your <em>config/sidekiq.yml</em>&nbsp;cron schedules to <em>config/recurring.yml</em>. The config is similarly shaped, but you’ll need to update key names and convert classic cron strings to Fugit’s preferred natural language:</p>
<pre><code># OLD: config/sidekiq.yml
:schedule:
&nbsp; cleanup_job:
&nbsp; &nbsp; cron: '0 2 * * *'
&nbsp; &nbsp; class: CleanupJob
# NEW: config/recurring.yml
production:
&nbsp; cleanup_job:
&nbsp; &nbsp; class: CleanupJob
&nbsp; &nbsp; schedule: every day at 2am</code></pre>
<h4 id="h.okb5m1d38hf6"><strong>Step 4: Update your Procfile</strong></h4>
<p>A <em>Procfile</em>&nbsp;enumerates the processes to launch on application start. To kick off SolidQueue, add the task <code>solid_queue:start</code>&nbsp;(replacing Sidekiq, say).</p>
<pre><code>web: bundle exec puma -C config/puma.rb
jobs: bundle exec rake solid_queue:start</code></pre>
<h4 id="h.kcexuaodcr9"><strong>Step 5: Blast the old stack</strong></h4>
<p>Redis and Sidekiq are now obsolete. You can remove any corresponding gems from the <em>Gemfile</em>. Run Bundler to remove the dependencies from <em>Gemfile.lock</em>.</p>
<pre><code># Gemfile - DELETE
# gem "redis"&lt;
# gem "sidekiq"
# gem "sidekiq-cron"

$ bash
$ bundle install
$ bundle clean --force
</code></pre>
<p>Your existing ActiveJob jobs work without modification. All retry strategies, error handling, and job options transfer directly.</p>
<h2 id="h.wlovlujo8ygl">When NOT To Use SolidQueue</h2>
<p>Some applications <em>need</em>&nbsp;Redis. Here are some candidates:</p>
<ul>
<li>You’re processing thousands of jobs per second sustained (not spikes, but consistent, sustained load).</li>
<li><a href="https://redis.io/docs/latest/develop/use/patterns/twitter-clone">Job latency under 1ms</a>&nbsp;is critical to your business. This is a real and pressing concern for real-time bidding, high frequency trading (HFT), and other applications in the same ilk.</li>
<li>You have complex <a href="https://redis.io/docs/latest/develop/interact/pubsub">pub/sub</a>&nbsp;patterns across multiple services</li>
<li>You require intensive <a href="https://redis.io/commands/incr">rate limiting or counters</a>&nbsp;that benefit from Redis’s atomic operations.</li>
</ul>
<p>As a benchmark, Shopify engineer John Duff presented some numbers at <a href="https://www.youtube.com/watch?v=lsKXPnB6SvQ">Big Ruby 2013</a>: 833 requests/second, 72ms average response time, 53 servers with 1,172 worker processes. At that scale—twelve years ago—Shopify needed Redis-level infrastructure. Are you there yet?</p>
<p>You definitely do not need Redis if processing is less than 100 jobs/second or job latency tolerance is greater than 100ms. You may need Redis if processing 100-1000 jobs/second (test both, measure), traffic is spiky, (Black Friday sales, ticket releases), or sub-100ms job queue latency is required.</p>
<h2 id="h.89fwv929byv">Practical Implementation Guide</h2>
<p>Let’s walk through a real-world setup.</p>
<h4 id="h.z0h9xlzcbc5g"><strong>Step 1: Generate a New Rails 8 App</strong></h4>
<pre><code>$ rails new myapp --database=postgresql
$ cd myapp</code></pre>
<p>Rails 8 auto-configures SolidQueue, SolidCache, and SolidCable. You’re halfway done already.</p>
<h4 id="h.zg9fxrl7idv2"><strong>Step 2: Set Up Queue Database</strong></h4>
<p>SolidQueue needs to know where to store its tables. The recommended approach is a separate database connection (even if it’s the same physical database server).</p>
<p>Update your <em>config/database.yml</em>:</p>
<pre><code>development:
&nbsp; primary: &amp;primary_development
&nbsp; &nbsp; &lt;&lt;: *default
&nbsp; &nbsp; database: myapp_development
&nbsp; queue:
&nbsp; &nbsp; &lt;&lt;: *primary_development
 &nbsp; database: myapp_queue_development
&nbsp; &nbsp; migrations_paths: db/queue_migrate
</code></pre>
<p>If you’re using SQLite or MySQL, the <a href="https://github.com/rails/solid_queue#usage-in-development-and-other-non-production-environments">official SolidQueue documentation</a>&nbsp;has examples for those setups.</p>
<p>Now tell SolidQueue to use its own connection in <em>config/environments/development.rb</em>:</p>
<pre><code>Rails.application.configure do
&nbsp; config.active_job.queue_adapter = :solid_queue
&nbsp; config.solid_queue.connects_to = { database: { writing: :queue } }
end</code></pre>
<p>Run db:prepare&nbsp;and Rails handles everything automatically:</p>
<pre><code>$ rails db:prepare</code></pre>
<p>Rails creates the queue database and loads the schema. No custom rake tasks needed.</p>
<h4 id="h.pa0mbxf4u4v9"><strong>Step 3: Configure Mission Control Authentication</strong></h4>
<pre><code># config/environments/development.rb (add to existing config block)
config.mission_control.jobs.http_basic_auth_user = "dev"
config.mission_control.jobs.http_basic_auth_password = "dev"</code></pre>
<h4 id="h.r2b45yiwzwp1"><strong>Step 4: Mount Mission Control</strong></h4>
<pre><code># config/routes.rb
mount MissionControl::Jobs::Engine, at: "/jobs"</code></pre>
<h4 id="h.c01npuo8gacb"><strong>Step 5: Create Procfile.dev</strong></h4>
<pre><code>web: bin/rails server
jobs: bundle exec rake solid_queue:start</code></pre>
<h4 id="h.xbucvuurw84q"><strong>Step 6: Start Everything</strong></h4>
<pre><code># Start all the servers for Rails from the shell
$ bin/dev</code></pre>
<h2 id="h.uwzeg39z7ejc">How to Test SolidQueue</h2>
<p>Create a test job, enqueue it, and watch it in Mission Control:</p>
<pre><code># Generate a new job class from the shell
$ rails generate job EmailReport</code></pre>
<p>Open the new Ruby file and add this code.</p>
<pre><code># Job definition
class EmailReportJob &lt; ApplicationJob
&nbsp; queue_as :default
&nbsp; retry_on StandardError, wait: :exponentially_longer, attempts: 5
&nbsp; def perform(user_id)
&nbsp; &nbsp; user = User.find(user_id)
&nbsp; &nbsp; ReportMailer.weekly_summary(user).deliver_now
&nbsp; end
end</code></pre>
<p>Next, run the Rails console and queue an immediate job.</p>
<pre><code>console&gt; EmailReportJob.perform_later(User.first.id)</code></pre>
<p>While in the console, queue a scheduled job, too.</p>
<pre><code>console&gt; EmailReportJob
.set(wait: &nbsp;1.week)
.perform_later(User.first.id)</code></pre>
<p>Make it recurring in <em>config/recurring.yml</em>:</p>
<pre><code>production:
&nbsp; weekly_reports:&lt;
&nbsp; &nbsp; class: EmailReportJob
&nbsp; &nbsp; schedule: every monday at 8am
&nbsp; &nbsp; queue: mailers
</code></pre>
<p>Finally, you might want to kick over your server and visit <em>http://localhost:3000/jobs</em>&nbsp;to admire your handiwork in Mission Control Jobs.</p>
<h2 id="h.bnimljph36vz">Common Gotchas</h2>
<h4 id="h.tdrame9uyjrz"><strong>Single Database Setup (Alternative)</strong></h4>
<p>SolidQueue recommends the use of a separate database connection, but you can run everything in one database, if you prefer.</p>
<ol start="1">
<li>Copy the contents of <em>db/queue_schema.rb</em>&nbsp;into a regular migration</li>
<li>Delete <em>db/queue_schema.rb</em></li>
<li>Remove <strong>config.solid_queue.connects_to</strong>&nbsp;from your environment configs</li>
<li>Run rails db:migrate</li>
</ol>
<p>This works fine for smaller apps, but at the cost of operational flexibility. The Rails team recommends the separate connection approach. See the <a href="https://github.com/rails/solid_queue#single-database-configuration">official docs</a>&nbsp;for details.</p>
<h4 id="h.kihrnukaqm9t"><strong>Mission Control in Production</strong></h4>
<p>Don’t forget to add authentication to limit access to Mission Control in production environments! The development example uses Basic Auth, but you’ll want something more robust for production:</p>
<pre><code># config/initializers/mission_control.rb
Rails.application.configure do
&nbsp; config.mission_control.jobs.base_controller_class = 
&nbsp; &nbsp; "AdminController"
end</code></pre>
<h4 id="h.c9ykr0ue1yq7"><strong>Polling Intervals</strong></h4>
<p>The default polling interval is 1 second for scheduled jobs and 0.2 seconds for ready jobs. If you’re migrating from Sidekiq and notice jobs feel “slower,” check your expectations. In my experience, SolidQueue’s defaults work well for most applications. Sub-second latency usually doesn’t matter for background jobs.</p>
<h4 id="h.ravxl7lujbix"><strong>ActionCable and Turbo Streams</strong></h4>
<p>If you’re using ActionCable (or anything that depends on it like Turbo Streams), you’ll need to configure SolidCable with its own database connection too. Add a cable database to your database.yml:</p>
<pre><code># config/database.yml
production:
&nbsp; primary:
&nbsp; &nbsp; &lt;&lt;: *default
&nbsp; &nbsp; database: myapp_production
&nbsp; cable:
&nbsp; &nbsp; &lt;&lt;: *default
&nbsp; &nbsp; database: myapp_cable_production
&nbsp; &nbsp; migrations_paths: db/cable_migrate</code></pre>
<p>Then in <em>config/cable.yml</em>:</p>
<pre><code>production:
&nbsp; adapter: solid_cable
&nbsp; connects_to:
&nbsp; &nbsp; database:
&nbsp; &nbsp; &nbsp; writing: cable
&nbsp; polling_interval: 0.1.seconds
&nbsp; message_retention: 1.day</code></pre>
<h4 id="h.xrhl635f4dkm"><strong>Polling Interval</strong></h4>
<p>The polling_interval of 0.1 seconds means your ActionCable server polls the database 10 times per second—light enough for PostgreSQL to handle without breaking a sweat. This gives you 100ms latency for real-time updates, which feels plenty snappy for Turbo Streams, live notifications, or even chat.</p>
<h2 id="h.dxpb7fhjiuyb">Does it Scale</h2>
<p>You may be asking the <a href="https://www.youtube.com/watch?v=VBwWbFpkl">timeless question</a>:</p>

<p><strong>bUT doES iT ScALe?</strong></p>
<p>The answer is yes, it scales. A better question, though, is “Does it scale enough for me?” To answer, you can start with this lovely formula from Nate Berkopec’s 2015 article <a href="https://www.speedshop.co/2015/07/29/scaling-ruby-apps-to-1000-rpm.html">“Scaling Ruby Apps to 1000 RPM”</a>.</p>
<p><strong>Required app instances = request rate (req/sec) × average response time (sec)</strong></p>
<p>Let’s do the math for a typical app. Say your app is getting 100 requests per minute, with a 200ms average response time. That’s ~1.67 requests per second. Multiply by 0.2 seconds and you get 0.083 application instances required. You need 8% of one application instance to handle your load.</p>
<p>As an anecdote, 37signals <a href="https://blog.appsignal.com/2025/06/18/a-deep-dive-into-solid-queue-for-ruby-on-rails.html">processes 20 million jobs per day</a>. That’s roughly 230 jobs per second running all on PostgreSQL sans Redis. Unless you’re processing millions of jobs per day, PostgreSQL can handle your load.</p>
<p>Here’s a side by side comparison of Redis and Sidekiq versus SolidQueue.</p>

<div tabindex="0" role="region">
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Redis + Sidekiq</th>
<th>SolidQueue</th>
</tr>
</thead>
<tbody>
<tr>
<td>Setup complexity</td>
<td>Separate service + config</td>
<td>Already there</td>
</tr>
<tr>
<td>Query language</td>
<td>Redis commands</td>
<td>SQL</td>
</tr>
<tr>
<td>Monitoring</td>
<td>Separate dashboard</td>
<td>Same as your app</td>
</tr>
<tr>
<td>Failure modes</td>
<td>6+ distinct scenarios</td>
<td>2 scenarios</td>
</tr>
<tr>
<td>Job throughput</td>
<td>~1000s/sec</td>
<td>~200-300/sec</td>
</tr>
<tr>
<td>Good enough for</td>
<td>99.9% of apps</td>
<td>95% of apps</td>
</tr>
</tbody>
</table>
</div>
<h2 id="h.ppt79y831p8v">The Bottom Line</h2>
<p>Redis and Sidekiq are masterfully engineered and Rails applications have benefited immeasurably from the combination for over a decade. But for most Rails apps, Redis and Sidekiq solve a problem you don’t have at a cost you can’t afford.</p>
<p>Give SolidQueue a spin. Your infrastructure simplifies, your operational burden lightens, and you can focus on building a product instead of maintaining a stack.</p>
<p><em>A lot of these practices are still emerging in our community. If you have corrections, criticisms, or feedback, please reach out and let me know. I would love to hear from you.</em></p>
    <div>
  <div>
    <p>
      Loved the article? Hated it? Didn’t even read it?
    </p>
    <p>
      We’d love to hear from you.
    </p>
  </div>
  <p><a href="https://www.simplethread.com/contact">Reach Out</a>
</p></div>
  </div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-7470 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[1000 Blank White Cards (275 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/1000_Blank_White_Cards</link>
            <guid>46611823</guid>
            <pubDate>Wed, 14 Jan 2026 03:08:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/1000_Blank_White_Cards">https://en.wikipedia.org/wiki/1000_Blank_White_Cards</a>, See on <a href="https://news.ycombinator.com/item?id=46611823">Hacker News</a></p>
Couldn't get https://en.wikipedia.org/wiki/1000_Blank_White_Cards: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The Gleam Programming Language (204 pts)]]></title>
            <link>https://gleam.run/</link>
            <guid>46611667</guid>
            <pubDate>Wed, 14 Jan 2026 02:49:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gleam.run/">https://gleam.run/</a>, See on <a href="https://news.ycombinator.com/item?id=46611667">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main"><section><p>The power of a type system, the expressiveness of functional
              programming, and the reliability of the highly concurrent, fault
              tolerant Erlang runtime, with a familiar and modern syntax.</p><pre><code><span>import</span> <span>gleam/io</span>

<span>pub</span> <span>fn</span> <span>main</span>() {
  <span>io</span>.<span>println</span>(<span>"hello, friend!"</span>)
}</code></pre></section><section><div><h2>Reliable and scalable</h2><p>Running on the battle-tested Erlang virtual machine that powers
              planet-scale systems such as WhatsApp and Ericsson, Gleam is ready for
              workloads of any size.</p><p>Thanks to its multi-core actor based concurrency system that can run
              millions of concurrent green threads, fast immutable data
              structures, and a concurrent garbage collector that never stops
              the world, your service can scale and stay lightning fast with ease.</p></div><pre><code><span>pub</span> <span>fn</span> <span>main</span>() -&gt; <span>Nil</span> {
  <span>// Run loads of green threads, no problem</span>
  <span>list</span>.<span>range</span>(<span>0</span>, <span>200_000</span>)
  <span>|&gt;</span> <span>list</span>.<span>each</span>(spawn_greeter)
}

<span>fn</span> <span>spawn_greeter</span>(i: <span>Int</span>) {
  <span>process</span>.<span>spawn</span>(<span>fn</span>() {
    <span>let</span> n = <span>int</span>.<span>to_string</span>(i)
    <span>io</span>.<span>println</span>(<span>"Hello from "</span> <span>&lt;&gt;</span> n)
  })
}</code></pre></section><section><div><h2>Ready when you are</h2><p>Gleam comes with compiler, build tool, formatter, editor integrations,
              and package manager all built in, so creating a Gleam project is just
              running <code>gleam new</code></p><p>As part of the wider BEAM ecosystem, Gleam programs can use thousands of
              published packages, whether they are written in Gleam, Erlang, or
              Elixir.</p></div><pre><code><span>➜ (main)</span> gleam add gleam_json
<span>  Resolving</span> versions
<span>Downloading</span> packages
<span> Downloaded</span> 2 packages in 0.01s
<span>      Added</span> gleam_json v0.5.0
<span>➜ (main)</span> gleam test
<span> Compiling</span> thoas
<span> Compiling</span> gleam_json
<span> Compiling</span> app
<span>  Compiled</span> in 1.67s
<span>   Running</span> app_test.main
<span>.
1 tests, 0 failures</span></code></pre></section><section><div><h2>Here to help</h2><p>No null values, no exceptions, clear error messages, and a practical
              type system. Whether you're writing new code or maintaining old code,
              Gleam is designed to make your job as fun and stress-free as possible.</p></div><pre><code><span>error:</span> Unknown record field

  ┌─ ./src/app.gleam:8:16
  │
8 │ user.alias
  │ <span>    ^^^^^^ Did you mean `name`?</span>

The value being accessed has this type:
    User

It has these fields:
    .name
</code></pre></section><section><div><h2>Multilingual</h2><p>Gleam makes it easy to use code written in other BEAM languages such as
              Erlang and Elixir, so there's a rich ecosystem of thousands of open
              source libraries for Gleam users to make use of.</p><p>Gleam can additionally compile to JavaScript, enabling you to use your
              code in the browser, or anywhere else JavaScript can run. It also
              generates TypeScript definitions, so you can interact with your Gleam
              code confidently, even from the outside.</p></div><pre><code><span>@external</span>(erlang, <span>"Elixir.HPAX"</span>, <span>"new"</span>)
<span>pub</span> <span>fn</span> <span>new</span>(size: <span>Int</span>) -&gt; <span>Table</span>



<span>pub</span> <span>fn</span> <span>register_event_handler</span>() {
  <span>let</span> el = <span>document</span>.<span>query_selector</span>(<span>"a"</span>)
  <span>element</span>.<span>add_event_listener</span>(el, <span>fn</span>() {
    <span>io</span>.<span>println</span>(<span>"Clicked!"</span>)
  })
}</code></pre></section><section><div><h2>Friendly 💜</h2><p>As a community, we want to be friendly too. People from around the
              world, of all backgrounds, genders, and experience levels are welcome
              and respected equally. See our community code of conduct for more.</p><p>Black lives matter. Trans rights are human rights. No nazi bullsh*t.
            <!-- Hello! If you make a PR changing this I will ban you. -->
            </p></div><img alt="a soft wavey boundary between two sections of the website" src="https://gleam.run/images/waves.svg"></section><div><h2>You're still here?</h2><p>Well, that's all this page has to say. Maybe you should go read the language tour!</p><p><a href="https://tour.gleam.run/">Let's go!</a></p><hr><h3>Wanna keep in touch?</h3><p>Subscribe to the Gleam newsletter</p><p>We send emails at most a few times a year, and we'll never share your
              email with anyone else.</p><p>This site is protected by reCAPTCHA and the Google <a href="https://policies.google.com/privacy">Privacy Policy</a> and <a href="https://policies.google.com/terms">Terms of Service</a> apply.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop using natural language interfaces (104 pts)]]></title>
            <link>https://tidepool.leaflet.pub/3mcbegnuf2k2i</link>
            <guid>46611550</guid>
            <pubDate>Wed, 14 Jan 2026 02:29:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tidepool.leaflet.pub/3mcbegnuf2k2i">https://tidepool.leaflet.pub/3mcbegnuf2k2i</a>, See on <a href="https://news.ycombinator.com/item?id=46611550">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p id="0" data-index="0"><span>Natural language is a wonderful interface, but just because we suddenly </span><span>can </span><span>doesn't mean we always </span><span>should. </span><span>LLM inference is slow and expensive, often taking tens of seconds to complete. Natural language interfaces have orders of magnitude more latency than normal graphic user interfaces. This doesn't mean we shouldn't use LLMs, it just means we need to be smart about how we build interfaces around them.</span></p><h2 id="2" data-index="2"><span>The Latency Problem</span></h2><p id="3" data-index="3"><span>There's a classic CS diagram visualizing latency numbers for various compute operations: nanoseconds to lock a mutex, microseconds to reference memory, milliseconds to read 1 MB from disk. LLM inference usually takes 10s of seconds to complete. Streaming responses help compensate, but it's </span><span>slow.</span></p><p><img height="512" width="1024" src="https://tidepool.leaflet.pub/api/atproto_images?did=did:plc:qvywnipfiyrd6v4qdf4x27wy&amp;cid=bafkreieb5yelu7aryalqfyl36vlr4uxtw7kr2qfi2ycod3r3fpn4gao77u"></p><p id="5" data-index="5"><span>Compare interacting with an LLM over multiple turns to filling in a checklist, selecting items from a pulldown menu, setting a value on a slider bar, stepping through a series of such interactions as you fill out a multi-field dialogue. Graphic user interfaces are fast, with responses taking milliseconds, not seconds. But. But: they're not smart, they're not responsive, they don't shape themselves to the conversation with the full benefits of semantic understanding.</span></p><div id="6" data-index="6"><p><img alt="A popup dialogue with multiple conditional checkboxes, sliders, and text areas" height="523" width="903" src="https://tidepool.leaflet.pub/api/atproto_images?did=did:plc:qvywnipfiyrd6v4qdf4x27wy&amp;cid=bafkreie73h5hzlxwldypecvxfoakvb2vjwlnkeo3xfca2i56btk7pupepq"></p></div><p id="7" data-index="7"><span>This is a post about how to provide the best of both worlds: the clean affordances of structured user interfaces with the flexibility of natural language. Every part of the above interface was generated on the fly by an LLM.</span></p><h2 id="9" data-index="9"><span>Popup-MCP</span></h2><p id="10" data-index="10"><span>This is a post about a tool I made called </span><a href="https://github.com/inanna-malick/popup-mcp" target="_blank">popup-mcp</a><span> (MCP is a standardized tool-use interface for LLMs). I built it about 6 months ago and have been experimenting with it as a core part of my LLM interaction modality ever since. It's a big part of what has made me so fond of them, from such an early stage. Popup provides a single tool that when invoked spawns a popup with an arbitrary collection of GUI elements.</span></p><p id="12" data-index="12"><span>You can find popup </span><a href="https://github.com/inanna-malick/popup-mcp" target="_blank">here</a><span>, along with instructions on how to use it. It's a local MCP tool that uses stdio, which means the process needs to run on the same computer as your LLM client. Popup supports structured GUIs made up of elements including multiple choice checkboxes, drop downs, sliders, and text boxes. These let LLMs render popups like the following:</span></p><p><img height="321" width="826" src="https://tidepool.leaflet.pub/api/atproto_images?did=did:plc:qvywnipfiyrd6v4qdf4x27wy&amp;cid=bafkreiaudad7f2bb5emzzjsibxirsqmxyvu4vydvdv24szpxe6qgumhjj4"></p><p id="14" data-index="14"><span>The popup tool supports conditional visibility to allow for context-specific followup questions. Some elements start hidden, only becoming visible when conditions like 'checkbox clicked', 'slider value &gt; 7', or 'checkbox A clicked &amp;&amp; slider B &lt; 7 &amp;&amp; slider C &gt; 8' become true. This lets LLMs construct complex and nuanced structures capturing not just their next stage of the conversation but </span><span>where they think the conversation might go from there</span><span>. Think of these as being a bit like conditional dialogue trees in CRPGs like Baldur's Gate or interview trees as used in consulting. The previous dialog, for example, expands as follows:</span></p><p><img height="618" width="1148" src="https://tidepool.leaflet.pub/api/atproto_images?did=did:plc:qvywnipfiyrd6v4qdf4x27wy&amp;cid=bafkreieh3yet67ktdel4v4lq7unu6s247q5p5q37wmqyn2jcnos6wivwxm"></p><p id="16" data-index="16"><span>Because constructing this tree requires registering nested hypotheticals about how a conversation might progress, it provides a useful window into an LLM's internal cognitive state. You don't just see the question it wants to ask you, you see the followup questions it would ask based on various answer combinations. This is incredibly useful and often shows where the LLM is making incorrect assumptions. More importantly, this is </span><span>fast</span><span>. You can quickly explore counterfactuals without having to waste minutes on back-and-forth conversational turns and restarting conversations from checkpoints.</span></p><p><img height="495" width="1157" src="https://tidepool.leaflet.pub/api/atproto_images?did=did:plc:qvywnipfiyrd6v4qdf4x27wy&amp;cid=bafkreid56ezwkkrojlnrftxqpbyjvazkmv7qaiyqsjn52x337inbpwk7yi"></p><p id="19" data-index="19"><span>Speaking of incorrect LLM assumptions: every multiselect or dropdown automatically includes an 'Other' option, which - when selected - renders a textbox for the user to elaborate on what the LLM missed. This escape hatch started as an emergent pattern, but I recently modified the tool to _always_ auto-include an escape hatch option on all multiselects and dropdown menus.</span></p><p id="20" data-index="20"><span>This means that you can always intervene to </span><span>steer </span><span>the LLM when it has the wrong idea about where a conversation should go.</span></p><h2 id="22" data-index="22"><span>Why This Matters</span></h2><p id="23" data-index="23"><span>Remember how I started by talking about latency, about how long a single LLM response takes? This combination of nested dialogue trees and escape hatches cuts that by ~25-75%, depending on how well the LLM anticipates where the conversation is going. It's surprising how often a series dropdown with its top 3-5 predictions will contain your next answer, especially when defining technical specs, and when it doesn't there's always the natural-language escape hatch offered by 'Other'.</span></p><p id="25" data-index="25"><span>Imagine generating a new RPG setting. Your LLM spawns a popup with options for the 5 most common patterns, with focused followup questions for each.</span></p><p><img height="532" width="1152" src="https://tidepool.leaflet.pub/api/atproto_images?did=did:plc:qvywnipfiyrd6v4qdf4x27wy&amp;cid=bafkreieorvdy22u4m7mm7bk26rteg2u2pi777nftvwxaoerdtpoe7dd5ze"></p><p id="27" data-index="27"><span>This isn't a generic GUI; it's fully specialized using everything the LLM knows about you, your project, and the interaction style you prefer. This captures 90% of what you're trying to do, so you select the relevant options and use 'Other' escape hatches to clarify as necessary.</span></p><p><img height="697" width="1620" src="https://tidepool.leaflet.pub/api/atproto_images?did=did:plc:qvywnipfiyrd6v4qdf4x27wy&amp;cid=bafkreiboyo3ocrfgqeixutelvsztbj4f3behvjxbvcnejyinfsiaszhtcu"></p><p id="29" data-index="29"><span>These interactions have latency measured in milliseconds: when you check the 'Other' checkbox, a text box instantly appears, without even a network round-trip's worth of latency. When you're done, your answers are returned to the LLM as a JSON tool response.</span></p><p id="31" data-index="31"><span>You should think of this pattern as providing a reduction in amortized interaction latency: it'll still take 10s of seconds to produce a followup response when you submit a popup dialog, but if your average popup replaces &gt; 1 rounds of chat you're still taking less time per unit of information exchanged.  That's what I mean by amortized latency: that single expensive LLM invocation is amortized over multiple cheap interactions with deterministically rendered GUI run on your local machine.</span></p><h2 id="33" data-index="33"><span>Claude Code Planning Mode</span></h2><p id="34" data-index="34"><span>I started hacking on this a few months before Claude Code released their AskUser tool (as used in planning mode). The AskUser tool provides a limited selection of TUI (terminal user interface) elements: multiple-choice and single-choice (with an always-included ‘Other’ option) and single-choice drop-downs. I originally chose not to publicize my library because of this, but I believe the addition of conditional elements is worth talking about.</span></p><p><img height="396" width="1518" src="https://tidepool.leaflet.pub/api/atproto_images?did=did:plc:qvywnipfiyrd6v4qdf4x27wy&amp;cid=bafkreie5ayfyu6dyvhxsjjbvcabyycftya4okv6f26xndqrf45lhc3prxy"></p><p id="36" data-index="36"><span>Further, I have some feature requests for Claude Code. If anyone at Anthropic happens to be reading this these would all be pretty easily to implement:</span></p><ul><li><p id="37.0" data-index="37.0"><span>Make the TUI interface used by the AskUserQuestion tool open and scriptable, such that plugins and user code can directly modify LLM-generated TUI interfaces, or directly generate their own without requiring a round-trip through the LLM to invoke the tool.</span></p></li><li><p id="37.1" data-index="37.1"><span>Provide pre and post-AskUser tool hooks so users can directly invoke code using TUI responses (eg filling templated prompts using TUI interface responses in certain contexts).</span></p></li><li><p id="37.2" data-index="37.2"><span>Extend the AskUser tool to support conditionally-rendered elements.</span></p></li></ul><h2 id="39" data-index="39"><span>Conclusion</span></h2><p id="40" data-index="40"><span>If you have an LLM chat app you should add inline structured GUI elements with conditionally visible followup questions to reduce amortized interaction latency. If you'd like to build on my library or tool definition, or just to talk shop, please reach out. I'd be happy to help. This technique is equally applicable to OS-native popups, terminal user interfaces, and web UIs.</span></p><p id="42" data-index="42"><span>I'll be writing more here. Publishing what I build is one of my core resolutions for 2026, and I have one hell of a backlog. Watch this space.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ASCII Clouds (270 pts)]]></title>
            <link>https://caidan.dev/portfolio/ascii_clouds/</link>
            <guid>46611507</guid>
            <pubDate>Wed, 14 Jan 2026 02:20:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://caidan.dev/portfolio/ascii_clouds/">https://caidan.dev/portfolio/ascii_clouds/</a>, See on <a href="https://news.ycombinator.com/item?id=46611507">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="controlsContent" data-astro-cid-pjaj6nma="">  <div data-astro-cid-pjaj6nma=""> <p>Presets</p>   </div> <div data-astro-cid-pjaj6nma=""> <p>Noise</p> <p><label data-astro-cid-pjaj6nma="">
Cell Size
 <span id="cellSizeValue" data-astro-cid-pjaj6nma="">18</span> </label> <label data-astro-cid-pjaj6nma="">
Wave Amplitude
 <span id="waveAmplitudeValue" data-astro-cid-pjaj6nma="">0.50</span> </label> <label data-astro-cid-pjaj6nma="">
Wave Speed
 <span id="waveSpeedValue" data-astro-cid-pjaj6nma="">1.00</span> </label> <label data-astro-cid-pjaj6nma="">
Noise Intensity
 <span id="noiseIntensityValue" data-astro-cid-pjaj6nma="">0.125</span> </label> <label data-astro-cid-pjaj6nma="">
Time Speed
 <span id="timeSpeedValue" data-astro-cid-pjaj6nma="">1.5</span> </label> <label data-astro-cid-pjaj6nma="">
Seed
 </label> </p></div> <div data-astro-cid-pjaj6nma=""> <p>Vignette</p> <p><label data-astro-cid-pjaj6nma="">
Intensity
 <span id="vignetteIntensityValue" data-astro-cid-pjaj6nma="">0.50</span> </label> <label data-astro-cid-pjaj6nma="">
Radius
 <span id="vignetteRadiusValue" data-astro-cid-pjaj6nma="">0.50</span> </label> </p></div> <div data-astro-cid-pjaj6nma=""> <p>Color</p> <p><label data-astro-cid-pjaj6nma="">
Hue
 <span id="hueValue" data-astro-cid-pjaj6nma="">180</span> </label> <label data-astro-cid-pjaj6nma="">
Saturation
 <span id="saturationValue" data-astro-cid-pjaj6nma="">0.50</span> </label> <label data-astro-cid-pjaj6nma="">
Brightness
 <span id="brightnessAdjustValue" data-astro-cid-pjaj6nma="">0.00</span> </label> <label data-astro-cid-pjaj6nma="">
Contrast
 <span id="contrastAdjustValue" data-astro-cid-pjaj6nma="">1.25</span> </label> </p></div> <div data-astro-cid-pjaj6nma=""> <p>Glyph Thresholds</p> <p><label data-astro-cid-pjaj6nma=""> <span data-astro-cid-pjaj6nma="">. dot</span>  <span id="threshold1Value" data-astro-cid-pjaj6nma="">0.25</span> </label> <label data-astro-cid-pjaj6nma=""> <span data-astro-cid-pjaj6nma="">- dash</span>  <span id="threshold2Value" data-astro-cid-pjaj6nma="">0.30</span> </label> <label data-astro-cid-pjaj6nma=""> <span data-astro-cid-pjaj6nma="">+ plus</span>  <span id="threshold3Value" data-astro-cid-pjaj6nma="">0.40</span> </label> <label data-astro-cid-pjaj6nma=""> <span data-astro-cid-pjaj6nma="">O ring</span>  <span id="threshold4Value" data-astro-cid-pjaj6nma="">0.50</span> </label> <label data-astro-cid-pjaj6nma=""> <span data-astro-cid-pjaj6nma="">X cross</span>  <span id="threshold5Value" data-astro-cid-pjaj6nma="">0.65</span> </label> </p></div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Minor says ICE took his iPhone, later found in used-electronics vending machine (147 pts)]]></title>
            <link>https://www.propublica.org/article/videos-ice-dhs-immigration-agents-using-chokeholds-citizens</link>
            <guid>46611375</guid>
            <pubDate>Wed, 14 Jan 2026 02:00:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.propublica.org/article/videos-ice-dhs-immigration-agents-using-chokeholds-citizens">https://www.propublica.org/article/videos-ice-dhs-immigration-agents-using-chokeholds-citizens</a>, See on <a href="https://news.ycombinator.com/item?id=46611375">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div>
	

<h3>Reporting Highlights</h3>



<ul>
<li><strong>Chokeholds:</strong> We found over 40 cases of agents using chokeholds and other moves that can block breathing. “I felt like I was going to pass out and die,” said a 16-year-old citizen.</li>



<li><strong>Former Police Are Appalled:</strong> We showed former police and immigration officials videos of incidents. They said agents are out of control. One said it’s “the kind of action which should get you fired.”</li>



<li><strong>Banned Tactics, No Punishment:</strong> There is a federal ban on chokeholds and similar tactics. But there is no sign of punishment for officers who’ve used them.</li>
</ul>



<p>These highlights were written by the reporters and editors who worked on this story.</p>

</div>


<figure>
	
</figure>



<p>Immigration agents have put civilians’ lives at risk using more than their guns.</p>



<p>An agent in Houston put a teenage citizen into a chokehold, <a href="https://www.instagram.com/p/DQUtnnViSSc/?hl=en">wrapping his arm around the boy’s neck</a>, choking him so hard that his neck had red welts hours later. A black-masked agent in Los Angeles pressed his knee into a woman’s neck while she was handcuffed; she then appeared to <a href="https://www.tiktok.com/@trendy_viewz_1/video/7539167585011551501">pass out</a>. An agent in Massachusetts jabbed his finger and thumb into the neck and arteries of a young father who refused to be separated from his wife and 1-year-old daughter. The man’s <a href="https://www.youtube.com/watch?v=cy-q83KCOZw">eyes rolled back in his head and he started convulsing</a>.</p>



<p>After George Floyd’s murder by a police officer six years ago in Minneapolis — less than a mile from where an Immigration and Customs Enforcement agent shot and killed Renee Good last week — police departments and federal agencies banned chokeholds and other moves that can restrict breathing or blood flow.</p>



<p>But those tactics are back, now at the hands of agents conducting President Donald Trump’s mass deportation campaign.</p>



<p>Examples are scattered across social media. ProPublica found more than 40 cases over the past year of immigration agents using these life-threatening maneuvers on immigrants, citizens and protesters. The agents are usually masked, their identities secret. The government won’t say if any of them have been punished.</p>



<p>In nearly 20 cases, agents appeared to use chokeholds and other neck restraints that the Department of Homeland Security prohibits “<a href="https://www.dhs.gov/sites/default/files/2023-02/23_0206_s1_use-of-force-policy-update.pdf">unless deadly force is authorized</a>.”</p>




<p>About two dozen videos show officers kneeling on people’s necks or backs or keeping them face down on the ground while already handcuffed. Such tactics are not prohibited outright but are often discouraged, including by federal trainers, in part because using them for a prolonged time risks asphyxiation.</p>



<p>We reviewed footage with a panel of eight former police officers and law enforcement experts. They were appalled.</p>



<p>This is what bad policing looks like, they said. And it puts everyone at risk.</p>



<p>“I arrested dozens upon dozens of drug traffickers, human smugglers, child molesters — some of them will resist,” said Eric Balliet, who spent more than two decades working at Homeland Security Investigations and Border Patrol, including in the first Trump administration. “I don’t remember putting anybody in a chokehold. Period.”</p>



<p>“If this was one of my officers, he or she would be facing discipline,” said Gil Kerlikowske, a longtime police chief in Seattle who also served as Customs and Border Protection commissioner under President Barack Obama. “You have these guys running around in fatigues, with masks, with ‘Police’ on their uniform,” but they aren’t acting like professional police.</p>



<p>Over the past week, the conduct of agents has come under intense scrutiny after an ICE officer in Minneapolis killed Good, a mother of three. The next day, a Border Patrol agent in Portland, Oregon, <a href="https://www.oregonlive.com/crime/2026/01/portland-police-responding-to-report-of-shooting-by-federal-immigration-agent.html">shot a man and woman</a> in a hospital parking lot.</p>



<p>Top administration officials rushed to defend the officers. Speaking about the agent who shot Good, DHS Secretary Kristi Noem said, “This is an experienced officer who followed his training.”</p>



<p>Officials said the same thing to us after we showed them footage of officers using prohibited chokeholds. Federal agents have “followed their training to use the least amount of force necessary,” department spokesperson Tricia McLaughlin said.</p>



<p>“Officers act heroically to enforce the law and protect American communities,” White House spokesperson Abigail Jackson said.</p>



<p>Both DHS and the White House lauded the “utmost professionalism” of their agents.</p>



<p>Our compilation of incidents is far from complete. Just as the government does not count <a href="https://www.propublica.org/article/immigration-dhs-american-citizens-arrested-detained-against-will">how often it detains citizens</a> or <a href="https://projects.propublica.org/trump-ice-smashed-windows-deportation-arrests/">smashes through vehicle windows</a> during immigration arrests, it does not publicly track how many times agents have choked civilians or otherwise inhibited their breathing or blood flow. We gathered cases by searching legal filings, social media posts and local press reports in English and Spanish.</p>



<p>Given the lack of any count over time, it’s impossible to know for certain how agents’ current use of the banned and dangerous tactics compares with earlier periods.</p>




<p>But former immigration officials told us they rarely heard of such incidents during their long tenures. They also recalled little pushback when DHS formally banned chokeholds and other tactics in 2023; it was merely codifying the norm.</p>



<p>That norm has now been broken.</p>



<h3>One of the citizens whom agents put in a chokehold was 16 years old.</h3>



<figure><img fetchpriority="high" decoding="async" height="682" width="2560" src="https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg?w=2560" alt="Two men, wearing black armored vests, pin and choke a young man on the ground of a large warehouse store." srcset="https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg 3445w, https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg?resize=300,80 300w, https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg?resize=768,205 768w, https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg?resize=1024,273 1024w, https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg?resize=1536,409 1536w, https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg?resize=2048,546 2048w, https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg?resize=863,230 863w, https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg?resize=422,112 422w, https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg?resize=552,147 552w, https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg?resize=558,149 558w, https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg?resize=527,140 527w, https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg?resize=752,200 752w, https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg?resize=1149,306 1149w, https://www.propublica.org/wp-content/uploads/2025/12/Bazan.jpg?resize=2000,533 2000w" sizes="(max-width: 2560px) 100vw, 2560px"><figcaption><span>American citizen Arnoldo Bazan was hospitalized after being choked and pinned to the ground at a restaurant supply store in Houston during the arrest of his father nearby.</span> <span>Courtesy of the Bazan family</span></figcaption></figure>



<figure><img decoding="async" width="689" height="918" src="https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Bazan.jpg" alt="Two men, wearing black armored vests, pin and choke a young man on the ground of a large warehouse store." srcset="https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Bazan.jpg 689w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Bazan.jpg?resize=225,300 225w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Bazan.jpg?resize=422,562 422w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Bazan.jpg?resize=552,735 552w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Bazan.jpg?resize=558,743 558w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Bazan.jpg?resize=527,702 527w" sizes="(max-width: 689px) 100vw, 689px"><figcaption><span>American citizen Arnoldo Bazan was hospitalized after being choked and pinned to the ground at a restaurant supply store in Houston during the arrest of his father nearby.</span> <span>Courtesy of the Bazan family</span></figcaption></figure>



<p>Tenth grader Arnoldo Bazan and his father were getting McDonald’s before school when their car was pulled over by unmarked vehicles. Masked immigration agents started banging on their windows. As Arnoldo’s undocumented father, Arnulfo Bazan Carrillo, drove off, the terrified teenager began filming on his phone. The video shows the agents repeatedly ramming the Bazans’ car during a slow chase through the city.</p>



<p>Bazan Carrillo eventually parked and ran into a restaurant supply store. When Arnoldo saw agents taking his father violently to the ground, Arnoldo went inside too, yelling at the agents to stop.</p>



<p>One agent put Arnoldo in a chokehold while another pressed a knee into his father’s neck. “I was going to school!” the boy pleaded. He said later that when he told the agent he was a citizen and a minor, the agent didn’t stop.</p>



<p>“I started screaming with everything I had, because I couldn’t even breathe,” Arnoldo told ProPublica, showing where the agent’s hands had closed around his throat. “I felt like I was going to pass out and die.”</p>



<p>DHS’ McLaughlin accused Arnoldo’s dad of ramming his car “into a federal law enforcement vehicle,” but he was never charged for that, and the videos we reviewed do not support this claim. Our examination of his criminal history — separate from any immigration violations — found only that Bazan Carrillo pleaded guilty a decade ago to misdemeanor driving while intoxicated.</p>



<p>McLaughlin also said the younger Bazan elbowed an officer in the face as he was detained, which the teen denies. She said that Arnoldo was taken into custody to confirm his identity and make sure he didn’t have any weapons. McLaughlin did not answer whether the agent’s conduct was justified.</p>



<p>Experts who reviewed video of the Bazans’ arrests could make no sense of the agents’ actions.</p>



<p>“Why are you in the middle of a store trying to grab somebody?” said Marc Brown, a former police officer turned instructor who taught ICE and Border Patrol officers at the Federal Law Enforcement Training Centers. “Your arm underneath the neck, like a choking motion? No! The knee on the neck? Absolutely not.”</p>



<p>DHS revamped its training curriculum after George Floyd’s murder to underscore those tactics were out of bounds, Brown said. “DHS specifically was very big on no choking,” he said. “We don’t teach that. They were, like, hardcore against it. They didn’t want to see anything with the word ‘choke.’”</p>



<h3>After agents used another banned neck restraint — a carotid hold — a man started convulsing and passed out.</h3>



<figure><img decoding="async" width="3000" height="1920" src="https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg" alt="A man wearing a white shirt and baseball hat convulses in the driver’s seat of a car while a black-gloved hand presses into his neck." srcset="https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg 3000w, https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg?resize=300,192 300w, https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg?resize=768,492 768w, https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg?resize=1024,655 1024w, https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg?resize=1536,983 1536w, https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg?resize=2048,1311 2048w, https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg?resize=863,552 863w, https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg?resize=422,270 422w, https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg?resize=552,353 552w, https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg?resize=558,357 558w, https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg?resize=527,337 527w, https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg?resize=752,481 752w, https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg?resize=1149,735 1149w, https://www.propublica.org/wp-content/uploads/2025/12/CarlosSebastianZapataRivera.jpg?resize=2000,1280 2000w" sizes="(max-width: 3000px) 100vw, 3000px"><figcaption><span>Officers used a carotid hold on Carlos Sebastian Zapata Rivera while arresting his wife in Massachusetts.</span> <span>Newsflare</span></figcaption></figure>



<figure><img loading="lazy" decoding="async" width="1080" height="1920" src="https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Newsflare.jpg" alt="A man wearing a white shirt and baseball hat convulses in the driver’s seat of a car while a black-gloved hand presses into his neck." srcset="https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Newsflare.jpg 1080w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Newsflare.jpg?resize=169,300 169w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Newsflare.jpg?resize=768,1365 768w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Newsflare.jpg?resize=576,1024 576w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Newsflare.jpg?resize=864,1536 864w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Newsflare.jpg?resize=863,1534 863w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Newsflare.jpg?resize=422,750 422w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Newsflare.jpg?resize=552,981 552w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Newsflare.jpg?resize=558,992 558w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Newsflare.jpg?resize=527,937 527w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Newsflare.jpg?resize=752,1337 752w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2Newsflare.jpg?resize=900,1600 900w" sizes="auto, (max-width: 1080px) 100vw, 1080px"><figcaption><span>Officers used a carotid hold on Carlos Sebastian Zapata Rivera while arresting his wife in Massachusetts.</span> <span>Newsflare</span></figcaption></figure>



<p>In early November, ICE agents in Fitchburg, Massachusetts, stopped a young father, Carlos Sebastian Zapata Rivera, as he drove with his family. They had come for his undocumented wife, whom they targeted after she was charged with assault for allegedly stabbing a co-worker in the hand with scissors.</p>




<p>Body camera footage from the local police, obtained by ProPublica, captured much of what happened. The couple’s 1-year-old daughter began crying. Agents surrounded the car, looking in through open doors.</p>



<p>According to the footage, an agent told Zapata Rivera that if his wife wouldn’t come out, they would have to arrest him, too — and their daughter would be sent into the foster system. The agent recounted the conversation to a local cop: “Technically, I can arrest both of you,” he said. “If you no longer have a child, because the child is now in state custody, you’re both gonna be arrested. Do you want to give your child to the state?”</p>



<p>Zapata Rivera, who has a pending asylum claim, clung to his family. His wife kept saying she wouldn’t go anywhere without her daughter, whom she said was still breastfeeding. Zapata Rivera wouldn’t let go of either of them.</p>



<p>Federal agents seemed conflicted on how to proceed. “I refuse to have us videotaped throwing someone to the ground while they have a child in their hands,” one ICE agent told a police officer at the scene.</p>



<p>But after more than an hour, agents held down Zapata Rivera’s arms. One, who Zapata Rivera’s lawyer says wore a baseball cap reading “Ne Quis Effugiat” — Latin for “So That None Will Escape” — pressed his thumbs into the arteries on Zapata Rivera’s neck. The young man then appeared to pass out as bystanders screamed.</p>



<p>The technique is known as a carotid restraint. The two carotid arteries carry 70% of the brain’s blood flow; block them, and a person can quickly lose consciousness. The tactic can cause <a href="https://jamanetwork.com/journals/jamaneurology/fullarticle/2774482">strokes, seizures, brain damage — and death</a>.</p>



<p>“Even milliseconds or seconds of interrupted blood flow to the brain can have serious consequences,” Dr. Altaf Saadi, a neurologist and associate professor at Harvard Medical School, told us. Saadi said she couldn’t comment on specific cases, “but there is no amount of training or method of applying pressure on the neck that is foolproof in terms of avoiding neurologic damage.”</p>



<p>In a bystander video of Zapata Rivera’s arrest, his eyes roll back in his head and he suffers an apparent seizure, convulsing so violently that his daughter, seated in his lap, shakes with him.</p>



<figure><video controls="" poster="https://www.propublica.org/wp-content/uploads/2026/01/Newsflare-807969-distressing-moment-man-appears-fallback_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg" src="https://www.propublica.org/wp-content/uploads/2026/01/Newsflare-807969-distressing-moment-man-appears-1_2.mp4" playsinline=""></video><figcaption><span>Video of Zapata Rivera’s arrest shows him shaking violently while suffering an apparent seizure in the front seat of his car, with officers continuing to attempt the arrest.</span> <span>Newsflare</span></figcaption></figure>



<p>“Carotid restraints are prohibited unless deadly force is authorized,” DHS’ <a href="https://www.dhs.gov/sites/default/files/2023-02/23_0206_s1_use-of-force-policy-update.pdf">use-of-force policy</a> states. Deadly force is authorized only when an officer believes there’s an “imminent threat of death or serious bodily injury” and there is “no alternative.”</p>



<p>In a social media post after the incident and in its statement to ProPublica, DHS did not cite a deadly threat. Instead, it referenced the charges against Zapata Rivera’s wife and suggested <a href="https://x.com/dhsgov/status/1986881395432820927">he had only pretended to have a medical crisis</a> while refusing help from paramedics. “Imagine FAKING a seizure to help a criminal escape justice,” the post said.</p>



<p><a href="https://www.courtlistener.com/docket/72041374/zapata-rivera-v-unknown-federal-agent-john-doe/">“These statements were lies,”</a> Zapata Rivera alleges in an ongoing civil rights lawsuit he filed against the ICE agent who used the carotid restraint. His lawyer told ProPublica that Zapata Rivera was disoriented after regaining consciousness; the lawsuit says he was denied medical attention. (Representatives for Zapata Rivera declined our requests for an interview with him. His wife has been released on bond, and her assault case awaits trial.)</p>



<p>A police report and bodycam footage from Fitchburg officers at the scene, obtained via a public records request, back up Zapata Rivera’s account of being denied assistance. “He’s fine,” an agent told paramedics, according to footage. The police report says Zapata Rivera wanted medical attention but “agents continued without stopping.”</p>




<p>Saadi, the Harvard neurologist, said that as a general matter, determining whether someone had a seizure is “not something even neurologists can do accurately just by looking at it.”</p>



<h3>DHS policy bars using chokeholds and carotid restraints just because someone is resisting arrest. Agents are doing it anyway.</h3>



<figure><img loading="lazy" decoding="async" width="1920" height="527" src="https://www.propublica.org/wp-content/uploads/2025/12/LuisHipolito2.jpg" alt="Federal officers arrested American citizen Luis Hipolito with a chokehold, pinning him to the ground in Los Angeles on June 24." srcset="https://www.propublica.org/wp-content/uploads/2025/12/LuisHipolito2.jpg 1920w, https://www.propublica.org/wp-content/uploads/2025/12/LuisHipolito2.jpg?resize=300,82 300w, https://www.propublica.org/wp-content/uploads/2025/12/LuisHipolito2.jpg?resize=768,211 768w, https://www.propublica.org/wp-content/uploads/2025/12/LuisHipolito2.jpg?resize=1024,281 1024w, https://www.propublica.org/wp-content/uploads/2025/12/LuisHipolito2.jpg?resize=1536,422 1536w, https://www.propublica.org/wp-content/uploads/2025/12/LuisHipolito2.jpg?resize=863,237 863w, https://www.propublica.org/wp-content/uploads/2025/12/LuisHipolito2.jpg?resize=422,116 422w, https://www.propublica.org/wp-content/uploads/2025/12/LuisHipolito2.jpg?resize=552,152 552w, https://www.propublica.org/wp-content/uploads/2025/12/LuisHipolito2.jpg?resize=558,153 558w, https://www.propublica.org/wp-content/uploads/2025/12/LuisHipolito2.jpg?resize=527,145 527w, https://www.propublica.org/wp-content/uploads/2025/12/LuisHipolito2.jpg?resize=752,206 752w, https://www.propublica.org/wp-content/uploads/2025/12/LuisHipolito2.jpg?resize=1149,315 1149w" sizes="auto, (max-width: 1920px) 100vw, 1920px"><figcaption><span>Federal officers arrested American citizen Luis Hipolito with a chokehold, pinning him to the ground in Los Angeles on June 24.</span> <span>@the_moxie_report</span></figcaption></figure>



<figure><img loading="lazy" decoding="async" width="480" height="527" src="https://www.propublica.org/wp-content/uploads/2025/12/MOBILEv2LuisHipolito2.jpg" alt="Federal officers arrested American citizen Luis Hipolito with a chokehold, pinning him to the ground in Los Angeles on June 24." srcset="https://www.propublica.org/wp-content/uploads/2025/12/MOBILEv2LuisHipolito2.jpg 480w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEv2LuisHipolito2.jpg?resize=273,300 273w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEv2LuisHipolito2.jpg?resize=422,463 422w" sizes="auto, (max-width: 480px) 100vw, 480px"><figcaption><span>Federal officers arrested American citizen Luis Hipolito with a chokehold, pinning him to the ground in Los Angeles on June 24.</span> <span>@the_moxie_report</span></figcaption></figure>



<p>When DHS issued restrictions on chokeholds and carotid restraints, it stated that the moves “must not be used as a means to control non-compliant subjects or persons resisting arrest.” Deadly force “shall not be used solely to prevent the escape of a fleeing subject.”</p>



<p>But videos reviewed by ProPublica show that agents have been using these restraints to do just that.</p>



<p>In Los Angeles in June, masked officers from ICE, Border Patrol and other federal agencies pepper-sprayed and then tackled another citizen, Luis Hipolito. As Hipolito struggled to get away, one of the agents put him in a chokehold. Another pointed a Taser at bystanders filming.</p>



<p>Then Hipolito’s body began to convulse — a possible seizure. An onlooker warned the agents, “You gonna let him die.”</p>



<figure><video controls="" poster="https://www.propublica.org/wp-content/uploads/2026/01/LuisHipolito-fallback_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg" src="https://www.propublica.org/wp-content/uploads/2025/12/LuisHipolito.mp4" playsinline=""></video><figcaption><span>In the video of Hipolito’s arrest, four agents can be seen pulling at his body, choking him and pinning him to the pavement.</span> <span>@the_moxie_report</span></figcaption></figure>



<p>When officers make a mistake in the heat of the moment, said Danny Murphy, a former deputy commissioner of the Baltimore Police Department, they need to “correct it as quickly as possible.”</p>



<p>That didn’t happen in Hipolito’s case. The footage shows the immigration agent not only wrapping his arm around Hipolito’s neck as he takes him down but also sticking with the chokehold after Hipolito is pinned on the ground.</p>



<p>The agent’s actions are “dangerous and unreasonable,” Murphy said.</p>



<p>Asked about the case, McLaughlin, the DHS spokesperson, said that Hipolito was arrested for assaulting an ICE officer. Hipolito’s lawyers did not respond to ProPublica’s requests for comment.</p>



<p>According to the Los Angeles Times, Hipolito <a href="https://www.latimes.com/california/story/2025-06-27/are-you-gonna-let-him-die-agents-pile-on-protester-who-convulses-and-struggles-to-breathe">limped into court days after the incident</a>. Another citizen who was with him the day of the incident was also charged, but her case was dropped. Hipolito pleaded not guilty and goes to trial in February.</p>



<h3>Some of the conduct in the footage isn’t banned — but it’s discouraged and dangerous.</h3>



<figure><img loading="lazy" decoding="async" height="911" width="2560" src="https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg?w=752" alt="A woman wearing a white mask and blue jacket is pinned to the ground and handcuffed by two men wearing blue jeans and covering their faces with their shirts." srcset="https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg 4800w, https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg?resize=300,107 300w, https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg?resize=768,273 768w, https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg?resize=1024,364 1024w, https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg?resize=1536,547 1536w, https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg?resize=2048,729 2048w, https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg?resize=863,307 863w, https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg?resize=422,150 422w, https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg?resize=552,196 552w, https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg?resize=558,199 558w, https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg?resize=527,188 527w, https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg?resize=752,268 752w, https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg?resize=1149,409 1149w, https://www.propublica.org/wp-content/uploads/2025/12/AmandaTrebach.jpg?resize=2000,712 2000w" sizes="auto, (max-width: 2560px) 100vw, 2560px"><figcaption><span>An officer kneels on the neck of nurse and activist Amanda Trebach, a U.S. citizen, during an arrest in Los Angeles.</span> <span>Courtesy of Union del Barrio</span></figcaption></figure>



<figure><img loading="lazy" decoding="async" width="960" height="1708" src="https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2AmandaTrebach.jpg" alt="A woman wearing a white mask and blue jacket is pinned to the ground and handcuffed by two men wearing blue jeans and covering their faces with their shirts." srcset="https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2AmandaTrebach.jpg 960w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2AmandaTrebach.jpg?resize=169,300 169w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2AmandaTrebach.jpg?resize=768,1366 768w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2AmandaTrebach.jpg?resize=576,1024 576w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2AmandaTrebach.jpg?resize=863,1535 863w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2AmandaTrebach.jpg?resize=422,751 422w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2AmandaTrebach.jpg?resize=552,982 552w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2AmandaTrebach.jpg?resize=558,993 558w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2AmandaTrebach.jpg?resize=527,938 527w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2AmandaTrebach.jpg?resize=752,1338 752w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEV2AmandaTrebach.jpg?resize=899,1600 899w" sizes="auto, (max-width: 960px) 100vw, 960px"><figcaption><span>An officer kneels on the neck of nurse and activist Amanda Trebach, a U.S. citizen, during an arrest in Los Angeles.</span> <span>Courtesy of Union del Barrio</span></figcaption></figure>



<p>A video from Los Angeles shows a Colombian-born TikTokker who often filmed ICE apparently <a href="https://www.tiktok.com/@trendy_viewz_1/video/7539167585011551501">passed out</a> after officers <a href="https://x.com/WUTangKids/status/1956854632203878890">pulled her from her Tesla and knelt on her neck</a>. Another video shows a DoorDash driver in Portland, Oregon, <a href="https://www.oregonlive.com/portland/2025/10/i-cant-breathe-man-tells-ice-agents-in-spanish-five-times-during-portland-arrest.html">screaming for air as four officers pin him face down in the street</a>. “Aire, aire, aire,”<em> </em>he says. “No puedo respirar” — I can’t breathe. Then: “Estoy muriendo”<em> </em>— I’m dying. A third video, from Chicago, <a href="https://spaces.hightail.com/space/ERClkyY4Cj/files/fi-ee68b78b-2ba0-4355-b2a1-49e1d5243c7c/fv-946d3e13-2b8d-4317-bb54-fbe69fd3ef09/2025.10.31.MP4">shows an agent straddling a citizen and repeatedly pressing his face into the asphalt</a>. Onlookers yell that the man can’t breathe.</p>



<p>Placing a knee on a prone subject’s neck or weight on their back isn’t banned under DHS’ use-of-force policy, but it can be dangerous — and the longer it goes on, the higher the risk that the person won’t be able to breathe.</p>




<p>“You really don’t want to spend that amount of time just trying to get somebody handcuffed,” said Kerlikowske, the former CPB commissioner, of the video of the arrest in Portland.</p>



<p>Brown, the former federal instructor and now a lead police trainer at the University of South Carolina, echoed that. “Once you get them handcuffed, you get them up, get them out of there,” he said. “If they’re saying they can’t breathe, hurry up.”</p>



<figure><p>
<iframe loading="lazy" title="“I can’t breathe,” man tells ICE agents in Spanish five times during his arrest in Portland." width="500" height="281" src="https://www.youtube-nocookie.com/embed/mSeAwZN8mnU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p><figcaption><span>DoorDash driver Victor José Brito Vallejo was pinned to the ground by federal agents in Portland, Oregon, on Sept. 11.</span> <span>The Oregonian</span></figcaption></figure>



<p>Taking a person down to the ground and restraining them there can be an appropriate way to get them in handcuffs, said Seth Stoughton, a former police officer turned law professor who also works at the University of South Carolina. But officers have long known to make it quick. By the mid-1990s, the federal government was advising officers against keeping people prolongedly in a prone position.</p>



<p>When a federal agent kneeled on the neck of an intensive care nurse in August, she said she understood the danger she was in and tried to scream.</p>



<p>“I knew that the amount of pressure being placed on the back of my neck could definitely hurt me,” said Amanda Trebach, a citizen and activist who was arrested in Los Angeles while monitoring immigration agents. “I was having a hard time breathing because my chest was on the ground.”</p>



<p>McLaughlin, the DHS spokesperson, said Trebach impeded agents’ vehicles and struck them with her signs and fists.</p>



<p>Trebach denies this. She was released without any charges.</p>



<h3 id="h-protesters-have-also-been-choked-and-strangled"><strong>Protesters have also been choked and strangled.</strong></h3>



<figure><img loading="lazy" decoding="async" height="1183" width="2560" src="https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg?w=2560" alt="A uniformed Border Patrol officer with a large gun slung around his back has his hands around the neck of a man wearing jeans, a white T-shirt and a baseball hat in a residential neighborhood lined with houses." srcset="https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg 3116w, https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg?resize=300,139 300w, https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg?resize=768,355 768w, https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg?resize=1024,473 1024w, https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg?resize=1536,710 1536w, https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg?resize=2048,946 2048w, https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg?resize=863,399 863w, https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg?resize=422,195 422w, https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg?resize=552,255 552w, https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg?resize=558,258 558w, https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg?resize=527,244 527w, https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg?resize=752,348 752w, https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg?resize=1149,531 1149w, https://www.propublica.org/wp-content/uploads/2025/12/ChicagoSlam.jpg?resize=2000,924 2000w" sizes="auto, (max-width: 2560px) 100vw, 2560px"><figcaption><span>A Border Patrol agent chokes and then slams down a protester in Chicago on Oct. 7.</span> <span>Storyful</span></figcaption></figure>



<figure><img loading="lazy" decoding="async" width="808" height="1440" src="https://www.propublica.org/wp-content/uploads/2025/12/MOBILEChicagoSlam.jpg" alt="A uniformed Border Patrol officer with a large gun slung around his back has his hands around the neck of a man wearing jeans, a white T-shirt and a baseball hat in a residential neighborhood lined with houses." srcset="https://www.propublica.org/wp-content/uploads/2025/12/MOBILEChicagoSlam.jpg 808w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEChicagoSlam.jpg?resize=168,300 168w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEChicagoSlam.jpg?resize=768,1369 768w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEChicagoSlam.jpg?resize=575,1024 575w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEChicagoSlam.jpg?resize=422,752 422w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEChicagoSlam.jpg?resize=552,984 552w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEChicagoSlam.jpg?resize=558,994 558w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEChicagoSlam.jpg?resize=527,939 527w, https://www.propublica.org/wp-content/uploads/2025/12/MOBILEChicagoSlam.jpg?resize=752,1340 752w" sizes="auto, (max-width: 808px) 100vw, 808px"><figcaption><span>A Border Patrol agent chokes and then slams down a protester in Chicago on Oct. 7.</span> <span>Storyful</span></figcaption></figure>



<p>In the fall, a protester in Chicago refused to stand back after a federal agent told him to do so. Suddenly, the <a href="https://www.youtube.com/shorts/51miOmd1qUM">agent grabbed the man by the throat and slammed him to the ground</a>.</p>



<p>“No, no!” one bystander exclaims. “He’s not doing anything!”</p>



<p>DHS’ McLaughlin did not respond to questions about the incident.</p>



<p>Along with two <a href="https://x.com/fordfischer/status/1969150886422155594">similar</a> <a href="https://www.huffpost.com/entry/ice-throw-elderly-woman-to-the-ground_n_690271b2e4b0e763a61c8a22">choking incidents</a> at protests outside of ICE facilities, this is one of the few videos in which the run-up to the violence is clear. And the experts were aghast.</p>



<p>“Without anything I could see as even remotely a deadly force threat, he immediately goes for the throat,” said Ashley Heiberger, a retired police captain from Pennsylvania who frequently testifies in use-of-force cases. Balliet, the former immigration official, said the agent turned the scene into a “pissing contest” that was “explicitly out of control.”</p>




<p>“It’s so clearly excessive and ridiculous,” Murphy said. “That’s the kind of action which should get you fired.”</p>



<p>“How big a threat did you think he was?” Brown said, noting that the officer slung his rifle around his back before grabbing and body-slamming the protester. “You can’t go grab someone just because they say, ‘F the police.’”</p>



<h3>Roving patrols + unplanned arrests = unsafe tactics.</h3>



<figure><img loading="lazy" decoding="async" height="561" width="2560" src="https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg" alt="Two uniformed federal officers wearing tactical vests subdue a man wearing a gray sweatshirt and black pants in an industrial kitchen. One officer has his arm around that man’s neck, and the other is holding his wrist." srcset="https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg 3000w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg?resize=300,66 300w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg?resize=768,168 768w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg?resize=1024,225 1024w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg?resize=1536,337 1536w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg?resize=2048,449 2048w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg?resize=863,189 863w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg?resize=422,93 422w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg?resize=552,121 552w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg?resize=558,122 558w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg?resize=527,116 527w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg?resize=752,165 752w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg?resize=1149,252 1149w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2246878719-copy.jpg?resize=2000,439 2000w" sizes="auto, (max-width: 2560px) 100vw, 2560px"><figcaption><span>Two federal officers arrest a construction worker in Charlotte, North Carolina, on Nov. 19.</span> <span>Ryan Murphy/Getty Images</span></figcaption></figure>



<figure><img loading="lazy" decoding="async" width="5579" height="3719" src="https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg" alt="Two uniformed federal officers wearing tactical vests subdue a man wearing a gray sweatshirt and black pants in an industrial kitchen. One officer has his arm around that man’s neck, and the other is holding his wrist." srcset="https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg 5579w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg?resize=300,200 300w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg?resize=768,512 768w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg?resize=1024,683 1024w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg?resize=1536,1024 1536w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg?resize=2048,1365 2048w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg?resize=863,575 863w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg?resize=422,281 422w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg?resize=552,368 552w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg?resize=558,372 558w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg?resize=527,351 527w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg?resize=752,501 752w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg?resize=1149,766 1149w, https://www.propublica.org/wp-content/uploads/2025/12/GettyImages-2251575611.jpg?resize=2000,1333 2000w" sizes="auto, (max-width: 5579px) 100vw, 5579px"><figcaption><span>Two federal officers arrest a construction worker in Charlotte, North Carolina, on Nov. 19.</span> <span>Ryan Murphy/Getty Images</span></figcaption></figure>



<p>In November, Border Patrol agents rushed into the construction site of a future Panda Express in Charlotte, North Carolina, to check workers’ papers. When one man tried to run, an officer put him in a chokehold and later marched him out, bloodied, to a waiting SUV.</p>



<p>The <a href="https://www.dhs.gov/news/2025/11/15/dhs-launches-operation-charlottes-web-target-criminal-illegal-aliens-terrorizing">Charlotte operation</a> was one of Border Patrol’s many forays into American cities, as agents led by <a href="https://x.com/CMDROpAtLargeCA/status/1995599514078732776?s=20">commander-at-large Gregory Bovino</a> claimed to target “criminal illegal aliens” but frequently <a href="https://x.com/CMDROpAtLargeCA/status/1995599514078732776?s=20">chased down</a> <a href="https://www.youtube.com/watch?v=vuaPCS67Ii8">landscapers</a>, construction workers and <a href="https://www.charlotteobserver.com/news/local/article312950879.html">U.S. citizens</a> in roving patrols through predominantly immigrant or Latino communities.</p>



<p>Freelance photographer <a href="https://www.ryanmurphyphoto.com/bio">Ryan Murphy</a>, who had been following Border Patrol’s convoys around Charlotte, documented the Panda Express arrest.</p>



<p>“Their tactics are less sophisticated than you would think,” he told ProPublica. “They sort of drive along the streets, and if they see somebody who looks to them like they could potentially be undocumented, they pull over.”</p>



<p>Experts told ProPublica that if officers are targeting a specific individual, they can minimize risks by deciding when, where and how to take them into custody. But when they don’t know their target in advance, chaos — and abuse — can follow.</p>



<p>“They are encountering people they don’t know anything about,” said Scott Shuchart, a former assistant director at ICE.</p>



<p>“The stuff that I’ve been seeing in the videos,” Kerlikowske said, “has been just ragtag, random.”</p>



<p>There may be other factors, too, our experts said, including quotas and a <a href="https://www.propublica.org/article/homeland-security-crcl-civil-rights-immigration-border-patrol-trump-kristi-noem">lack of consequences amid gutted oversight</a>. With officers wearing masks, Shuchart said, “even if they punch grandma in the face, they won’t be identified.”</p>



<p>As they sweep into American cities, immigration officers are unconstrained — and, the experts said, unprepared. Even well-trained officers may not be trained for the environments where they now operate. Patrolling a little-populated border region takes one set of skills. Working in urban areas, <a href="https://www.propublica.org/article/immigration-agents-detained-mistreated-citizens-congressional-investigation">where citizens — and protesters — abound</a>, takes another.</p>



<p>DHS and Bovino did not respond to questions about their agents’ preparation or about the chokehold in Charlotte.</p>




<h3>Experts may think there’s abuse. But holding officers to account? That’s another matter.</h3>



<figure><img loading="lazy" decoding="async" height="681" width="1024" src="https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?w=1024" alt="A young man with black curly hair and a thin goatee, wearing a gray long-sleeve shirt and blue jeans, poses for a picture alongside a woman with black hair and a gold locket around her neck, wearing a leopard-print shirt." srcset="https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg 3000w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=300,199 300w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=768,510 768w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=1024,681 1024w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=1536,1021 1536w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=2048,1361 2048w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=863,574 863w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=422,280 422w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=552,367 552w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=558,371 558w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=527,350 527w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=752,500 752w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=1149,764 1149w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-03_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=2000,1329 2000w" sizes="auto, (max-width: 1024px) 100vw, 1024px"><figcaption><span>Arnoldo, 16, and his sister, Maria Bazan, 27, at their home in Houston. Maria brought her brother to the hospital after his detention by federal officers.</span> <span>Danielle Villasana for ProPublica</span></figcaption></figure>



<figure><img loading="lazy" decoding="async" width="2000" height="3000" src="https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg" alt="A young man with black curly hair and a thin goatee, wearing a gray long-sleeve shirt and blue jeans, poses for a picture alongside a woman with black hair and a gold locket around her neck, wearing a leopard-print shirt." srcset="https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg 2000w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=200,300 200w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=768,1152 768w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=683,1024 683w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=1024,1536 1024w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=1365,2048 1365w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=863,1295 863w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=422,633 422w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=552,828 552w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=558,837 558w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=527,791 527w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=752,1128 752w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=1149,1724 1149w, https://www.propublica.org/wp-content/uploads/2026/01/20251217-Villasana-Immigration-Agents-Restricting-Breathing-05_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=1067,1600 1067w" sizes="auto, (max-width: 2000px) 100vw, 2000px"><figcaption><span>Arnoldo, 16, and his sister, Maria Bazan, 27, at their home in Houston. Maria brought her brother to the hospital after his detention by federal officers.</span> <span>Danielle Villasana for ProPublica</span></figcaption></figure>



<p>Back in Houston, immigration officers dropped 16-year-old Arnoldo off at the doorstep of his family home a few hours after the arrest. His neck was bruised, and his new shirt was shredded. Videos taken by his older sisters show the soccer star struggling to speak through sobs.</p>



<p>Uncertain what exactly had happened to him, his sister Maria Bazan took him to Texas Children’s Hospital, where staff identified signs of the chokehold and moved him to the trauma unit. Hospital records show he was given morphine for pain and that doctors ordered a dozen CT scans and X-rays, including of his neck, spine and head.</p>



<p>From the hospital, Maria called the Houston Police Department and tried to file a report, the family said. After several unsuccessful attempts, she took Arnoldo to the department in person, where she says officers were skeptical of the account and their own ability to investigate federal agents.</p>



<p>Arnoldo had filmed much of the incident, but agents had taken his phone. He used Find My to locate the phone — at a vending machine for used electronics miles away, close to an ICE detention center. The footage, which ProPublica has reviewed, backed the family’s account of the chase.</p>



<figure><img loading="lazy" decoding="async" height="1024" width="956" src="https://www.propublica.org/wp-content/uploads/2026/01/Bazan-Hospital_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?w=956" alt="First image: A young man with a torn gray T-shirt sits on a medical examination bed in a doctor’s office. Second image: Two medical staffers wearing black scrubs assist a young man wearing a neck brace on a hospital gurney with a blue sheet." srcset="https://www.propublica.org/wp-content/uploads/2026/01/Bazan-Hospital_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg 1494w, https://www.propublica.org/wp-content/uploads/2026/01/Bazan-Hospital_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=280,300 280w, https://www.propublica.org/wp-content/uploads/2026/01/Bazan-Hospital_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=768,822 768w, https://www.propublica.org/wp-content/uploads/2026/01/Bazan-Hospital_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=956,1024 956w, https://www.propublica.org/wp-content/uploads/2026/01/Bazan-Hospital_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=1434,1536 1434w, https://www.propublica.org/wp-content/uploads/2026/01/Bazan-Hospital_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=863,924 863w, https://www.propublica.org/wp-content/uploads/2026/01/Bazan-Hospital_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=422,452 422w, https://www.propublica.org/wp-content/uploads/2026/01/Bazan-Hospital_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=552,591 552w, https://www.propublica.org/wp-content/uploads/2026/01/Bazan-Hospital_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=558,598 558w, https://www.propublica.org/wp-content/uploads/2026/01/Bazan-Hospital_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=527,564 527w, https://www.propublica.org/wp-content/uploads/2026/01/Bazan-Hospital_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=752,805 752w, https://www.propublica.org/wp-content/uploads/2026/01/Bazan-Hospital_preview_maxWidth_3000_maxHeight_3000_ppi_72_embedColorProfile_true_quality_95.jpg?resize=1149,1231 1149w" sizes="auto, (max-width: 956px) 100vw, 956px"><figcaption><span>After Arnoldo was choked by a federal officer, his sister took him to the hospital, where doctors quickly moved him to the trauma unit.</span> <span>Courtesy of the Bazan family</span></figcaption></figure>



<p>The family says Houston police still haven’t interviewed them. A department spokesperson told ProPublica it was not investigating the case, referring questions to DHS. But the police have also not released bodycam footage and case files aside from a top sheet, citing an open investigation.</p>



<p>“We can’t do anything,” Maria said one officer told her. “What can HPD do to federal agents?”</p>



<p>Elsewhere in the country, some officials are trying to hold federal immigration officers to account.</p>



<p>In California, the state Legislature passed bills prohibiting immigration officers from wearing masks and requiring them to display identification during operations.</p>



<p>In Illinois, Gov. JB Pritzker signed a law that allows residents to sue any officer who violates state or federal constitutional rights. (The Trump administration quickly filed legal challenges against California and Illinois, claiming their new laws are unconstitutional.)</p>



<p>In Colorado, Durango’s police chief saw a recent <a href="https://www.youtube.com/watch?v=St5aTGJd4Rw">video of an immigration officer using a chokehold on a protester</a> and <a href="https://www.nytimes.com/2025/11/03/us/politics/durango-colorado-ice-protester.html">reported it to the Colorado Bureau of Investigation</a>, which announced it was looking into the incident.</p>



<p>In Minnesota, state and local leaders are collecting evidence in Renee Good’s killing even as the federal government <a href="https://www.mprnews.org/story/2026/01/08/fbi-will-investigate-after-ice-agent-shoots-renee-good-in-minneapolis">cut the state out</a> of its investigation.</p>



<p>Arnoldo is still waiting for Houston authorities to help him, still terrified that a masked agent will come first. Amid soccer practice and making up schoolwork he missed while recovering, he watches and rewatches the videos from that day. The car chase, the chokehold, his own screams at the officers to leave his dad alone. His father in the driver’s seat, calmly handing Arnoldo his wallet and phone while stopping mid-chase for red lights.</p>




<p>The Bazan family said agents threatened to charge Arnoldo if his dad didn’t agree to be deported. DHS spokesperson McLaughlin did not respond when asked about the alleged threat. Arnoldo’s dad is now in Mexico.&nbsp;</p>



<p>Asked why an officer choked Arnoldo, McLaughlin pointed to the boy’s alleged assault with his elbow, adding, “The federal law enforcement officer graciously chose not to press charges.”</p>



<h3>How We Did It</h3>



<p>ProPublica journalists Nicole Foy, McKenzie Funk, Joanna Shan, Haley Clark and Cengiz Yar gathered videos via Spanish and English social media posts, local press reports and court records. We then sent a selection of these videos to eight police experts and former immigration officials, along with as much information as we could gather about the lead-up to and context of each incident. The experts analyzed the videos with us, explaining when and how officers used dangerous tactics that appeared to go against their training or that have been banned under the Department of Homeland Security’s use-of-force policy.</p>



<p>We also tried to contact every person we could identify being choked or kneeled on. In some cases, we also reached out to bystanders.</p>



<p>Research reporter Mariam Elba conducted criminal record searches of every person we featured in this story. She also attempted to fact-check the allegations that DHS made about the civilians and their arrests. Our findings are not comprehensive because there is no universal criminal record database.</p>



<p>We also sent every video cited in this story to the White House, DHS, CBP, ICE, border czar Tom Homan and Border Patrol’s Gregory Bovino. DHS spokesperson Tricia McLaughlin provided a statement responding to some of the incidents we found but she did not explain why agents used banned tactics or whether any of the agents have been disciplined for doing so.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: OSS AI agent that indexes and searches the Epstein files (145 pts)]]></title>
            <link>https://epstein.trynia.ai/</link>
            <guid>46611348</guid>
            <pubDate>Wed, 14 Jan 2026 01:56:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://epstein.trynia.ai/">https://epstein.trynia.ai/</a>, See on <a href="https://news.ycombinator.com/item?id=46611348">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><span>archive</span></p><p>Indexed emails, messages, flight logs, court documents, and other records from the Epstein archive.</p></div><p><img alt="Epstein" width="180" height="180" decoding="async" data-nimg="1" srcset="https://epstein.trynia.ai/_next/image?url=%2Fepstein123.png&amp;w=256&amp;q=75 1x, https://epstein.trynia.ai/_next/image?url=%2Fepstein123.png&amp;w=384&amp;q=75 2x" src="https://epstein.trynia.ai/_next/image?url=%2Fepstein123.png&amp;w=384&amp;q=75"></p><p>Search the Epstein archive — emails, messages, and documents. Powered by<!-- --> <a href="https://trynia.ai/" target="_blank" rel="noopener noreferrer">Nia</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: The $LANG Programming Language (239 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=46610557</link>
            <guid>46610557</guid>
            <pubDate>Wed, 14 Jan 2026 00:17:19 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=46610557">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="46611320"><td></td></tr><tr id="46611998"><td></td></tr><tr id="46611368"><td></td></tr><tr id="46611546"><td></td></tr><tr id="46612233"><td></td></tr><tr id="46611608"><td></td></tr><tr id="46612224"><td></td></tr><tr id="46612234"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46612234" href="https://news.ycombinator.com/vote?id=46612234&amp;how=up&amp;goto=item%3Fid%3D46610557"></a></center></td><td><br>
<div><p>Likewise. Thought it'd be pronounced "slang", and thought the semantics would be you define LANG=&lt;name of a language&gt; at the top of the file (like a hashbang) and then write in whatever language you please. $LANG is a neato language because it has all the coolest features rolled into one unified design: polymorphic lifetime borrowing, endofunctor monoid monads, (stacked) coroutines, and even quantum data types.</p></div></td></tr></tbody></table></td></tr><tr id="46611222"><td></td></tr><tr id="46611454"><td></td></tr><tr id="46610750"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46610750" href="https://news.ycombinator.com/vote?id=46610750&amp;how=up&amp;goto=item%3Fid%3D46610557"></a></center></td><td><br>
<div><p>Yikes, I tanked HN's performance by posting this! Probably because of loading all those old threads over and over.</p><p>I've moved the URL out of the link at the top, which seems to be helping for now.</p><p>(now I have to decide whether to go down another rabbit hole and fix that)</p></div></td></tr></tbody></table></td></tr><tr id="46611918"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46611918" href="https://news.ycombinator.com/vote?id=46611918&amp;how=up&amp;goto=item%3Fid%3D46610557"></a></center></td><td><br>
<div><p>That reminds me, I really should blog my design ideas for my spiritual successor to Python....</p></div></td></tr></tbody></table></td></tr><tr id="46611323"><td></td></tr><tr id="46610695"><td></td></tr><tr id="46610699"><td></td></tr><tr id="46610744"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46610744" href="https://news.ycombinator.com/vote?id=46610744&amp;how=up&amp;goto=item%3Fid%3D46610557"></a></center></td><td><br>
<div><p>Alas, yes, at least for now. Seems like an LLM could be good at finding them though. A regex is probably too crude.</p></div></td></tr></tbody></table></td></tr><tr id="46611138"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46611138" href="https://news.ycombinator.com/vote?id=46611138&amp;how=up&amp;goto=item%3Fid%3D46610557"></a></center></td><td><br>
<div><p>The old lesson from the Wizard of Oz experiment says that a regular expression probably <i>isn't</i> too crude, if you're willing to take the time to design it. Though you could <i>probably</i> get away with running a regex golf algorithm (e.g. <a href="https://nbviewer.org/url/norvig.com/ipython/xkcd1313.ipynb" rel="nofollow">https://nbviewer.org/url/norvig.com/ipython/xkcd1313.ipynb</a>) over the list of matching titles, and the union of some list of non-matching-but-close titles (chosen to get good discrimination) with some list of way-off titles (to avoid overfitting). (You <i>could</i> treat the whole HN title database, other than the ones you've identified, as losers, but that risks hardcoding the absence of a post you accidentally missed, and would also take slightly longer – though Peter Norvig's first algorithm takes time linear in the number of losers, so it might not be too expensive. I don't know how expensive his improved versions are, given large lists of losers: <a href="https://nbviewer.org/url/norvig.com/ipython/xkcd1313-part2.ipynb" rel="nofollow">https://nbviewer.org/url/norvig.com/ipython/xkcd1313-part2.i...</a>. Better algorithms are surely available.)</p></div></td></tr></tbody></table></td></tr><tr id="46611515"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46611515" href="https://news.ycombinator.com/vote?id=46611515&amp;how=up&amp;goto=item%3Fid%3D46610557"></a></center></td><td><br>
<div><p>I did a Show HN for a language called Tsonic yesterday, which is a variant of TypeScript (all tsonic is valid typescript) requiring stronger typing which compiles to  x64/ARM native code via .Net/NativeAOT. <a href="https://news.ycombinator.com/item?id=46604308">https://news.ycombinator.com/item?id=46604308</a></p><p>It didn't appear in Show HN at all. Perhaps because another user posted it as a regular topic just a few minutes earlier, which drops off very quickly (within minutes) - but I think the issue is wider.</p><p>For a while now, I've felt that the new topics stream requires you to promote the topic outside of HN to be seen on HN - sometimes by adding a "Discuss on HN" link in the blog, or on social networks etc. The problem is quite fundamental: the "Show" link gets a small fraction of clicks. The "Show New" (two clicks away) probably gets tinier, miniscule fraction of clicks. The intersection of people who are interested in the project and those who have clicked "Show New" would be very nearly null. So upvotes will have to come from outside.</p></div></td></tr></tbody></table></td></tr><tr id="46611822"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46611822" href="https://news.ycombinator.com/vote?id=46611822&amp;how=up&amp;goto=item%3Fid%3D46610557"></a></center></td><td><br>
<div><p>That's great! It didn't make the /show page because some of the upvotes were dropped by our software. We can re-up it, but first can you add some text to the post, explaining the background and what's different about it? If you look at what I told the Lax guys earlier (<a href="https://news.ycombinator.com/item?id=46608577">https://news.ycombinator.com/item?id=46608577</a>), that might give some ideas.</p><p>Also, if you're ok with changing the title to "Show HN: The Tsonic Programming Language" then I could add it to <a href="https://news.ycombinator.com/showlang">https://news.ycombinator.com/showlang</a> :)</p></div></td></tr></tbody></table></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A 40-line fix eliminated a 400x performance gap (313 pts)]]></title>
            <link>https://questdb.com/blog/jvm-current-thread-user-time/</link>
            <guid>46609630</guid>
            <pubDate>Tue, 13 Jan 2026 23:00:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://questdb.com/blog/jvm-current-thread-user-time/">https://questdb.com/blog/jvm-current-thread-user-time/</a>, See on <a href="https://news.ycombinator.com/item?id=46609630">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>I have a habit of skimming the OpenJDK commit log every few weeks. Many commits are too complex for me to grasp in the limited time I have reserved for this ... <em>special hobby</em>. But occasionally something catches my eye.</p>
<p>Last week, <a href="https://github.com/openjdk/jdk/commit/858d2e434dd">this commit</a> stopped me mid-scroll:</p>
<div><pre><p><span>858d2e434dd 8372584: [Linux]: Replace reading proc to get thread CPU</span></p><p><span>time with clock_gettime</span></p></pre></div>
<p>The diffstat was interesting: <code>+96 insertions, -54 deletions</code>. The changeset adds a 55-line JMH benchmark, which means the production code itself is actually reduced.</p>
<h2 id="the-deleted-code"><a href="#the-deleted-code">The Deleted Code</a></h2>
<p>Here's what got removed from <code>os_linux.cpp</code>:</p>
<div><pre><p><span>static jlong user_thread_cpu_time(Thread *thread) {</span></p><p><span>  pid_t  tid = thread-&gt;osthread()-&gt;thread_id();</span></p><p><span>  char *s;</span></p><p><span>  char stat[2048];</span></p><p><span>  size_t statlen;</span></p><p><span>  char proc_name[64];</span></p><p><span>  int count;</span></p><p><span>  long sys_time, user_time;</span></p><p><span>  char cdummy;</span></p><p><span>  int idummy;</span></p><p><span>  long ldummy;</span></p><p><span>  FILE *fp;</span></p><p><span>  os::snprintf_checked(proc_name, 64, "/proc/self/task/%d/stat", tid);</span></p><p><span>  fp = os::fopen(proc_name, "r");</span></p><p><span>  if (fp == nullptr) return -1;</span></p><p><span>  statlen = fread(stat, 1, 2047, fp);</span></p><p><span>  stat[statlen] = '\0';</span></p><p><span>  fclose(fp);</span></p><p><span>  // Skip pid and the command string. Note that we could be dealing with</span></p><p><span>  // weird command names, e.g. user could decide to rename java launcher</span></p><p><span>  // to "java 1.4.2 :)", then the stat file would look like</span></p><p><span>  //                1234 (java 1.4.2 :)) R ... ...</span></p><p><span>  // We don't really need to know the command string, just find the last</span></p><p><span>  // occurrence of ")" and then start parsing from there. See bug 4726580.</span></p><p><span>  s = strrchr(stat, ')');</span></p><p><span>  if (s == nullptr) return -1;</span></p><p><span>  // Skip blank chars</span></p><p><span>  do { s++; } while (s &amp;&amp; isspace((unsigned char) *s));</span></p><p><span>  count = sscanf(s,"%c %d %d %d %d %d %lu %lu %lu %lu %lu %lu %lu",</span></p><p><span>                 &amp;cdummy, &amp;idummy, &amp;idummy, &amp;idummy, &amp;idummy, &amp;idummy,</span></p><p><span>                 &amp;ldummy, &amp;ldummy, &amp;ldummy, &amp;ldummy, &amp;ldummy,</span></p><p><span>                 &amp;user_time, &amp;sys_time);</span></p><p><span>  if (count != 13) return -1;</span></p><p><span>  return (jlong)user_time * (1000000000 / os::Posix::clock_tics_per_second());</span></p><p><span>}</span></p></pre></div>
<p>This was the implementation behind <code>ThreadMXBean.getCurrentThreadUserTime()</code>. To get the current thread's user CPU time, the old code was:</p>
<ol>
<li>Formatting a path to <code>/proc/self/task/&lt;tid&gt;/stat</code></li>
<li>Opening that file</li>
<li>Reading into a stack buffer</li>
<li>Parsing through a hostile format where the command name can contain parentheses (hence the <code>strrchr</code> for the last <code>)</code>)</li>
<li>Running <code>sscanf</code> to extract fields 13 and 14</li>
<li>Converting clock ticks to nanoseconds</li>
</ol>
<p>For comparison, here's what <code>getCurrentThreadCpuTime()</code> does and has always done:</p>
<div><pre><p><span>jlong os::current_thread_cpu_time() {</span></p><p><span>  return os::Linux::thread_cpu_time(CLOCK_THREAD_CPUTIME_ID);</span></p><p><span>}</span></p><p><span>jlong os::Linux::thread_cpu_time(clockid_t clockid) {</span></p><p><span>  struct timespec tp;</span></p><p><span>  clock_gettime(clockid, &amp;tp);</span></p><p><span>  return (jlong)(tp.tv_sec * NANOSECS_PER_SEC + tp.tv_nsec);</span></p><p><span>}</span></p></pre></div>
<p>Just a single <code>clock_gettime()</code> call. There is no file I/O, no complex parsing and no buffer to manage.</p>

<p>The <a href="https://bugs.openjdk.org/browse/JDK-8210452">original bug report</a>, filed back in 2018, quantified the difference:</p>
<blockquote>
<p>"getCurrentThreadUserTime is 30x-400x slower than getCurrentThreadCpuTime"</p>
</blockquote>
<p>The gap widens under concurrency. Why is <code>clock_gettime()</code> so much faster? Both approaches require kernel entry, but the difference is in what happens next.</p>
<p><strong>The <code>/proc</code> path:</strong></p>
<ul>
<li><code>open()</code> syscall</li>
<li>VFS dispatch + dentry lookup</li>
<li>procfs synthesizes file content at read time</li>
<li>kernel formats string into buffer</li>
<li><code>read()</code> syscall, copy to userspace</li>
<li>userspace <code>sscanf()</code> parsing</li>
<li><code>close()</code> syscall</li>
</ul>
<p><strong>The <code>clock_gettime(CLOCK_THREAD_CPUTIME_ID)</code> path:</strong></p>
<ul>
<li>single syscall → <code>posix_cpu_clock_get()</code> → <code>cpu_clock_sample()</code> → <code>task_sched_runtime()</code> → reads directly from <a href="https://github.com/torvalds/linux/blob/8449d3252c2603a51ffc7c36cb5bd94874378b7d/include/linux/sched.h#L586"><code>sched_entity</code></a></li>
</ul>
<p>The <code>/proc</code> path involves multiple syscalls, VFS machinery, string formatting kernel-side, and parsing userspace-side. The <code>clock_gettime()</code> path is one syscall with a direct function call chain.</p>
<p>Under concurrent load, the <code>/proc</code> approach also suffers from kernel lock contention. The <a href="https://bugs.openjdk.org/browse/JDK-8372584">bug report</a> notes:</p>
<blockquote>
<p>"Reading proc is slow (hence why this procedure is put under the method slow_thread_cpu_time(...)) and may lead to noticeable spikes in case of contention for kernel resources."</p>
</blockquote>
<h2 id="why-two-implementations?"><a href="#why-two-implementations?">Why Two Implementations?</a></h2>
<p>So why didn't <code>getCurrentThreadUserTime()</code> just use <code>clock_gettime()</code> from the start?</p>
<p>The answer is (probably) POSIX. The standard mandates that <code>CLOCK_THREAD_CPUTIME_ID</code> returns total CPU time (user + system). There's no portable way to request user time only. Hence the <code>/proc</code>-based implementation.</p>
<p>The Linux port of OpenJDK isn't limited to what POSIX defines, it can use Linux-specific features. Let's see how.</p>
<h2 id="the-clockid-bit-hack"><a href="#the-clockid-bit-hack">The Clockid Bit Hack</a></h2>
<p>Linux kernels since 2.6.12 (released in 2005) <a href="https://github.com/torvalds/linux/blob/eee51b0ae5c52a77ed65ad59b55002d1397b40d5/include/linux/posix-timers_types.h#L10-L19">encode clock type information directly</a> into the <code>clockid_t</code> value. When you call <a href="https://man7.org/linux/man-pages/man3/pthread_getcpuclockid.3.html"><code>pthread_getcpuclockid()</code></a>, you get back a clockid with a specific bit pattern:</p>
<div><pre><p><span>Bit 2:    Thread vs process clock</span></p><p><span>Bits 1-0: Clock type</span></p><p><span>  00 = PROF</span></p><p><span>  01 = VIRT  (user time only)</span></p><p><span>  10 = SCHED (user + system, POSIX-compliant)</span></p><p><span>  11 = FD</span></p></pre></div>
<p>The remaining bits encode the target PID/TID. We’ll come back to that in the bonus section.</p>
<p>The POSIX-compliant <code>pthread_getcpuclockid()</code> returns a clockid with bits <code>10</code> (SCHED). But if you flip those low bits to <code>01</code> (VIRT), <code>clock_gettime()</code> will return user time only.</p>
<p>The new implementation:</p>
<div><pre><p><span>static bool get_thread_clockid(Thread* thread, clockid_t* clockid, bool total) {</span></p><p><span>  constexpr clockid_t CLOCK_TYPE_MASK = 3;</span></p><p><span>  constexpr clockid_t CPUCLOCK_VIRT = 1;</span></p><p><span>  int rc = pthread_getcpuclockid(thread-&gt;osthread()-&gt;pthread_id(), clockid);</span></p><p><span>  if (rc != 0) {</span></p><p><span>    // Thread may have terminated</span></p><p><span>    assert_status(rc == ESRCH, rc, "pthread_getcpuclockid failed");</span></p><p><span>    return false;</span></p><p><span>  }</span></p><p><span>  if (!total) {</span></p><p><span>    // Flip to CPUCLOCK_VIRT for user-time-only</span></p><p><span>    *clockid = (*clockid &amp; ~CLOCK_TYPE_MASK) | CPUCLOCK_VIRT;</span></p><p><span>  }</span></p><p><span>  return true;</span></p><p><span>}</span></p><p><span>static jlong user_thread_cpu_time(Thread *thread) {</span></p><p><span>  clockid_t clockid;</span></p><p><span>  bool success = get_thread_clockid(thread, &amp;clockid, false);</span></p><p><span>  return success ? os::Linux::thread_cpu_time(clockid) : -1;</span></p><p><span>}</span></p></pre></div>
<p>And that's it. The new version has no file I/O, no buffer and certainly no <code>sscanf()</code> with thirteen format specifiers.</p>
<h2 id="profiling-time!"><a href="#profiling-time!">Profiling time!</a></h2>
<p>Let's have a look at how it performs in practice. For this exercise, I am taking the <a href="https://github.com/openjdk/jdk/commit/858d2e434dd#diff-0151b4192746117a72e6da834a5e97aaad57c4d99b0438ae7eba9c0002826f0a">JMH test included in the fix</a>, the only change is that I increased the number of threads from 1 to 16
and added a <code>main()</code> method for simple execution from an IDE:</p>
<div><pre><p><span>@State(Scope.Benchmark)</span></p><p><span>@Warmup(iterations = 2, time = 5)</span></p><p><span>@Measurement(iterations = 5, time = 5)</span></p><p><span>@BenchmarkMode(Mode.SampleTime)</span></p><p><span>@OutputTimeUnit(TimeUnit.MICROSECONDS)</span></p><p><span>@Threads(16)</span></p><p><span>@Fork(value = 1)</span></p><p><span>public class ThreadMXBeanBench {</span></p><p><span>    static final ThreadMXBean mxThreadBean = ManagementFactory.getThreadMXBean();</span></p><p><span>    static long user; // To avoid dead-code elimination</span></p><p><span>    @Benchmark</span></p><p><span>    public void getCurrentThreadUserTime() throws Throwable {</span></p><p><span>        user = mxThreadBean.getCurrentThreadUserTime();</span></p><p><span>    }</span></p><p><span>    public static void main(String[] args) throws RunnerException {</span></p><p><span>        Options opt = new OptionsBuilder()</span></p><p><span>                .include(ThreadMXBeanBench.class.getSimpleName())</span></p><p><span>                .build();</span></p><p><span>        new Runner(opt).run();</span></p><p><span>    }</span></p><p><span>}</span></p></pre></div>
<blockquote>
<p>Aside: This is a rather unscientific benchmark, I have other processes running on my desktop etc. Anyway, here is the setup: Ryzen 9950X, JDK main branch at commit <a href="https://github.com/openjdk/jdk/commit/8ab7d3b89f656e5c">8ab7d3b89f656e5c</a>. For the "before" case, I reverted the fix rather than checking out an older revision.</p>
</blockquote>
<p>Here is the result:</p>
<div><pre><p><span>Benchmark                                             Mode      Cnt     Score   Error  Units</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime          sample  8912714    11.186 ± 0.006  us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.00    sample              2.000          us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.50    sample             10.272          us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.90    sample             17.984          us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.95    sample             20.832          us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.99    sample             27.552          us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.999   sample             56.768          us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.9999  sample             79.709          us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p1.00    sample           1179.648          us/op</span></p></pre></div>
<p>We can see that a single invocation took 11 microseconds on average and the median was about 10 microseconds per invocation.</p>
<p>The CPU profile looks like this:</p>
<figure><div><p><img alt="CPU profile before the fix" src="https://questdb.com/images/blog/2026-01-13/before.svg" loading="lazy"></p><figcaption>Click to zoom, open in a new tab for interactivity</figcaption></div></figure>
<p>The CPU profile confirms that each invocation of <code>getCurrentThreadUserTime()</code> does multiple syscalls. In fact, most of the CPU time
is spent in syscalls. We can see files being opened and closed. Closing alone results in multiple syscalls, including futex locks.</p>
<p>Let's see the benchmark result with the fix applied:</p>
<div><pre><p><span>Benchmark                                             Mode       Cnt     Score   Error  Units</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime          sample  11037102     0.279 ± 0.001  us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.00    sample               0.070          us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.50    sample               0.310          us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.90    sample               0.440          us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.95    sample               0.530          us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.99    sample               0.610          us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.999   sample               1.030          us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.9999  sample               3.088          us/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p1.00    sample            1230.848          us/op</span></p></pre></div>
<p>The average went down from 11 microseconds to 279 nanos. This means the latency of the fixed version is 40x lower
than the old version. While this is not a 400x improvement, it's within the 30x - 400x range from the original report. Chances are
the delta would be higher with a different setup.
Let's have a look at the new profile:</p>
<figure><div><p><img alt="CPU profile after the fix" src="https://questdb.com/images/blog/2026-01-13/after.svg" loading="lazy"></p><figcaption>Click to zoom, open in a new tab for interactivity</figcaption></div></figure>
<p>The profile is much cleaner. There is just a single syscall. If the profile is to be trusted then most of the time is spent in JVM, outside of the kernel.</p>
<h2 id="how-documented-is-this?"><a href="#how-documented-is-this?">How Documented Is This?</a></h2>
<p>Barely. The bit encoding is stable. It hasn't changed in 20 years, but you won't find it in the <a href="https://linux.die.net/man/3/clock_gettime"><code>clock_gettime(2)</code> man page</a>.
The closest thing to official documentation is the kernel source itself, in <a href="https://github.com/torvalds/linux/blob/4702f4eceb639b6af199151e352e570943619d98/kernel/time/posix-cpu-timers.c"><code>kernel/time/posix-cpu-timers.c</code></a> and the <a href="https://github.com/torvalds/linux/blob/eee51b0ae5c52a77ed65ad59b55002d1397b40d5/include/linux/posix-timers_types.h"><code>CPUCLOCK_*</code> macros</a>.</p>
<p>The kernel's policy is clear: <a href="https://lkml.org/lkml/2012/12/23/75">don't break userspace</a>.</p>
<figure><div><p><img alt="Linus on kernel stability: Don't break userspace" src="https://questdb.com/images/blog/2026-01-13/linus.webp" loading="lazy"></p><figcaption>Linus's position on ABI stability is... unambiguous.</figcaption></div></figure>
<p>My take: If <a href="https://github.com/bminor/glibc/blob/bd569425330c6f5644c232b4b253e9ab905fcdba/sysdeps/unix/sysv/linux/kernel-posix-cpu-timers.h">glibc depends on it</a>, it's not going away.</p>
<h2 id="pushing-further"><a href="#pushing-further">Pushing Further</a></h2>
<p>When looking at profiler data from the 'after' run, I spotted a further optimization opportunity: A good portion of the remaining syscall is spent inside a radix tree lookup. Have a look:</p>
<figure><div><p><img alt="Zoomed-in CPU profile showing radix tree lookup" src="https://questdb.com/images/blog/2026-01-13/radix.webp" loading="lazy"></p><figcaption>Click to zoom</figcaption></div></figure>
<p>When the JVM calls <code>pthread_getcpuclockid()</code>, it receives a <code>clockid</code> that encodes the thread's ID. When this <code>clockid</code> is passed to <code>clock_gettime()</code>,
the kernel extracts the thread ID and performs a radix tree lookup to find the <a href="https://github.com/torvalds/linux/blob/8ec7c826d97b390879df2a03dfb035c70af86779/include/linux/pid.h#L57"><code>pid</code> structure</a> associated with that ID.</p>
<p>However, the Linux kernel has a fast-path. If the encoded PID in the <code>clockid</code> is 0, the kernel interprets this as "the current thread" and skips the radix tree lookup entirely, jumping to the current task's structure directly.</p>
<p>The OpenJDK fix currently obtains the specific TID, flips the bits, and passes it to <code>clock_gettime()</code>. This forces the kernel to take the "generalized path" (the radix tree lookup).</p>
<p>The <a href="https://github.com/torvalds/linux/blob/4702f4eceb639b6af199151e352e570943619d98/kernel/time/posix-cpu-timers.c#L57-L95">source code</a> looks like this:</p>
<div><pre><p><span>/*</span></p><p><span> * Functions for validating access to tasks.</span></p><p><span> */</span></p><p><span>static struct pid *pid_for_clock(const clockid_t clock, bool gettime)</span></p><p><span>{</span></p><p><span>[...]</span></p><p><span>  /*</span></p><p><span>  * If the encoded PID is 0, then the timer is targeted at current</span></p><p><span>  * or the process to which current belongs.</span></p><p><span>  */</span></p><p><span>  if (upid == 0)</span></p><p><span>      // the fast path: current task lookup, cheap</span></p><p><span>      return thread ? task_pid(current) : task_tgid(current);</span></p><p><span>  // the generalized path: radix tree lookup, more expensive</span></p><p><span>  pid = find_vpid(upid);</span></p><p><span>  [...]</span></p></pre></div>
<p>If the JVM constructed the entire <code>clockid</code> manually with PID=0 encoded (rather than obtaining the <code>clockid</code> via <code>pthread_getcpuclockid()</code>), the kernel could take the fast-path and avoid the radix tree lookup altogether.
The JVM already pokes bits in the <code>clockid</code>, so constructing it entirely from scratch wouldn't be a bigger leap compatibility-wise.</p>
<p>Let's try it!</p>
<p>First, a refresher on the <code>clockid</code> encoding. The <code>clockid</code> is constructed like this:</p>
<div><pre><p><span>clockid for TID=42, user-time-only:</span></p><p><span>  1111_1111_1111_1111_1111_1110_1010_1101</span></p><p><span>  └───────────────~42────────────────┘│└┘</span></p><p><span>                                      │ └─ 01 = VIRT (user time only)</span></p><p><span>                                      └─── 1 = per-thread</span></p></pre></div>
<p>For the current thread, we want PID=0 encoded, which gives <code>~0</code> in the upper bits:</p>
<div><pre><p><span>  1111_1111_1111_1111_1111_1111_1111_1101</span></p><p><span>  └─────────────── ~0 ───────────────┘│└┘</span></p><p><span>                                      │ └─ 01 = VIRT (user time only)</span></p><p><span>                                      └─── 1 = per-thread</span></p></pre></div>
<p>We can translate this into C++ as follows:</p>
<div><pre><p><span>// Linux Kernel internal bit encoding for dynamic CPU clocks:</span></p><p><span>// [31:3] : Bitwise NOT of the PID or TID (~0 for current thread)</span></p><p><span>// [2]    : 1 = Per-thread clock, 0 = Per-process clock</span></p><p><span>// [1:0]  : Clock type (0 = PROF, 1 = VIRT/User-only, 2 = SCHED)</span></p><p><span>static_assert(sizeof(clockid_t) == 4, "Linux clockid_t must be 32-bit");</span></p><p><span>constexpr clockid_t CLOCK_CURRENT_THREAD_USERTIME = static_cast&lt;clockid_t&gt;(~0u &lt;&lt; 3 | 4 | 1);</span></p></pre></div>
<p>And then make a tiny teensy change to <code>user_thread_cpu_time()</code>:</p>
<div><pre><p><span>jlong os::current_thread_cpu_time(bool user_sys_cpu_time) {</span></p><p><span>  if (user_sys_cpu_time) {</span></p><p><span>    return os::Linux::thread_cpu_time(CLOCK_THREAD_CPUTIME_ID);</span></p><p><span>  } else {</span></p><p><span>   - return user_thread_cpu_time(Thread::current());</span></p><p><span>   + return os::Linux::thread_cpu_time(CLOCK_CURRENT_THREAD_USERTIME);</span></p><p><span>  }</span></p></pre></div>
<p>The <a href="https://github.com/openjdk/jdk/compare/master...jerrinot:jdk:jh_faster_getCurrentThreadUserTime?diff=unified&amp;w">change above</a> is sufficient to make <code>getCurrentThreadUserTime()</code> use the fast-path in the kernel.</p>
<p>Given that we are in nanoseconds territory already, we tweak the test a bit:</p>
<ul>
<li>Increase the iteration and fork count</li>
<li>Use just a single thread to minimize noise</li>
<li>Switch to nanos</li>
</ul>
<p>The benchmark changes are meant to eliminate noise from the rest of my system and get a more precise measurement of the small delta we expect:</p>
<div><pre><p><span>@State(Scope.Benchmark)</span></p><p><span>@Warmup(iterations = 4, time = 5)</span></p><p><span>@Measurement(iterations = 10, time = 5)</span></p><p><span>@BenchmarkMode(Mode.SampleTime)</span></p><p><span>@OutputTimeUnit(TimeUnit.NANOSECONDS)</span></p><p><span>@Threads(1)</span></p><p><span>@Fork(value = 3)</span></p><p><span>public class ThreadMXBeanBench {</span></p><p><span>    static final ThreadMXBean mxThreadBean = ManagementFactory.getThreadMXBean();</span></p><p><span>    static long user; // To avoid dead-code elimination</span></p><p><span>    @Benchmark</span></p><p><span>    public void getCurrentThreadUserTime() throws Throwable {</span></p><p><span>        user = mxThreadBean.getCurrentThreadUserTime();</span></p><p><span>    }</span></p><p><span>    public static void main(String[] args) throws RunnerException {</span></p><p><span>        Options opt = new OptionsBuilder()</span></p><p><span>                .include(ThreadMXBeanBench.class.getSimpleName())</span></p><p><span>                .build();</span></p><p><span>        new Runner(opt).run();</span></p><p><span>    }</span></p><p><span>}</span></p></pre></div>
<p>The version currently in JDK main branch gives:</p>
<div><pre><p><span>Benchmark                                             Mode      Cnt       Score   Error  Units</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime          sample  4347067      81.746 ± 0.510  ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.00    sample               69.000          ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.50    sample               80.000          ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.90    sample               90.000          ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.95    sample               90.000          ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.99    sample               90.000          ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.999   sample              230.000          ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.9999  sample             1980.000          ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p1.00    sample           653312.000          ns/op</span></p></pre></div>
<p>With the manual <code>clockid</code> construction, which uses the kernel fast-path, we get:</p>
<div><pre><p><span>Benchmark                                             Mode      Cnt       Score   Error  Units</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime          sample  5081223      70.813 ± 0.325  ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.00    sample               59.000          ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.50    sample               70.000          ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.90    sample               70.000          ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.95    sample               70.000          ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.99    sample               80.000          ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.999   sample              170.000          ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p0.9999  sample             1830.000          ns/op</span></p><p><span>ThreadMXBeanBench.getCurrentThreadUserTime:p1.00    sample           425472.000          ns/op</span></p></pre></div>
<p>The average went down from 81.7 ns to 70.8 ns, so about a 13% improvement. The improvements are visible across all percentiles as well.
Is it worth the loss of clarity from constructing the <code>clockid</code> manually rather than using <code>pthread_getcpuclockid()</code>?
I am not entirely sure. The absolute gain is small and makes additional assumptions about kernel internals, including the size of <code>clockid_t</code>. On the other hand, it's still a gain without any downside in practice. <em>(famous last words...)</em></p>
<h2 id="browsing-for-gems"><a href="#browsing-for-gems">Browsing for Gems</a></h2>
<p>This is why I like browsing commits of large open source projects. A 40-line deletion eliminated a 400x performance gap. The fix required no new kernel features, just knowledge of a stable-but-obscure Linux ABI detail.</p>
<p>The lessons:</p>
<p><strong>Read the kernel source.</strong> POSIX tells you what's portable. The kernel source code tells you what's possible. Sometimes there's a 400x difference between the two. Whether it is worth exploiting is a different question.</p>
<p><strong>Check the old assumptions.</strong> The <code>/proc</code> parsing approach made sense when it was written, before anyone realized it could be exploited this way. Assumptions get baked into code. Revisiting them occasionally pays off.</p>
<p>The change landed on December 3, 2025. Just one day before the <a href="https://openjdk.org/projects/jdk/26/">JDK 26 feature freeze</a>. If you're using <code>ThreadMXBean.getCurrentThreadUserTime()</code>, JDK 26 (releasing March 2026) brings you a free 30-400x speedup!</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The insecure evangelism of LLM maximalists (235 pts)]]></title>
            <link>https://lewiscampbell.tech/blog/260114.html</link>
            <guid>46609591</guid>
            <pubDate>Tue, 13 Jan 2026 22:57:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lewiscampbell.tech/blog/260114.html">https://lewiscampbell.tech/blog/260114.html</a>, See on <a href="https://news.ycombinator.com/item?id=46609591">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <i>1/14/2026</i>
    
    <p>I am an LLM productivity skeptic.</p>
<p>I find LLMs useful as a sort of digital clerk - searching the web for me, finding documentation, looking up algorithms. I even find them useful<sup><a id="footnote-ref-1" href="#footnote-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup> in a limited coding capacity; with a small context and clear guidelines.</p>
<p>But doing "prompt-driven development" or "vibe coding" with an Agentic LLM was an incredibly disapointing experience for me. It required an immense amount of baby sitting, for small code changes, made slowly, which were often wrong. All the while I sat there feeling dumber and dumber, as my tokens drained away.</p>
<p>Of course that was <em>my</em> experience, and <em>my</em> preference. I genuinely don't mind if other people vibe code. Go for it! I do not deny this kind of coding is enabling a lot of people - who aren't experienced devs - to create things they would never otherwise be able to create. (Also, sometimes they pay me to clean them up afterwards, which is nice.)</p>
<p>But that is not enough for the vocal proponents. It's the future! You'll be left behind! Software has changed forever! And then, inevitably, comes the character evaluation, which goes something like this:</p>
<blockquote>
<p>You - a senior dev - are resisting this change due to deeply held psychological fears of being made irrelevant and/or having to learn new things. You are stuck in your ways and unwilling to change them because you are afraid.</p>
</blockquote>
<p>This has always baffled me, because quite frankly I <em>like</em> the idea of agentic coding. I often feel the actual implementation is a bottleneck to the things I want to create. I would love it if I could just sit around making specs (yes I am a programmer who enjoys this) and have little machines implement it for me perfectly. It's a wonderful fantasy world, and I wish I could inhabit it. That's why I was so disappointed.</p>
<p>And it made me think - why are these people so insistent, and hostile? Why can't they live and let live? Why do they need to convince the rest of us? And to be honest, I am developing my own character evaluation. It's not very charitable, but it is making a lot of sense to me:</p>
<blockquote>
<p>You tried agentic coding. You realised it was better at programming than you are. You see a lot of accomplished, prominent developers<sup><a id="footnote-ref-2" href="#footnote-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup> claiming they are more productive without it. Could they just be that much better at programming than I am? No! They are just threatened. They are the ones who are insecure! I'm a great developer!</p>
</blockquote>
<p>It's projection. Their evangelism is born of insecurity.</p>
<h2>An Open Question</h2>
<p>I am still willing to admit I am wrong. That I'm not holding the agents properly. That doing this is it's own skill and I have not spent enough time with it. I have changed my mind on tech before, and I'm sure I will do so again.</p>
<p>LLM evangelists - are you willing to admit that you just might not be that good at programming computers? Maybe you once were. Maybe you never were.</p>
<section data-footnotes="">

<ol>
<li id="footnote-1">
<p><a href="https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/">There is some evidence to suggest this is a placebo.</a> <a href="#footnote-ref-1" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="footnote-2">
<p>Just to forestall this; I am not claiming I am one of them. <a href="#footnote-ref-2" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
</ol>
</section>

    <hr>
    <br>
    <a href="https://outdata.net/">I'm available for hire.</a>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When hardware goes end-of-life, companies need to open-source the software (348 pts)]]></title>
            <link>https://www.marcia.no/words/eol</link>
            <guid>46609492</guid>
            <pubDate>Tue, 13 Jan 2026 22:49:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.marcia.no/words/eol">https://www.marcia.no/words/eol</a>, See on <a href="https://news.ycombinator.com/item?id=46609492">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><section id="home"><p><small>January 13, 2026<!-- --> ·<!-- --> 2 min read</small></p></section><section><p>When hardware products reach end-of-life (EOL), companies should be forced to open-source the software.</p><br></section><section><p>I think we've made strides in this area with the "<a href="https://repair.eu/" target="_blank" rel="noopener noreferrer">Right to Repair</a>"-movement, but let's go one step further. Preferably with the power of the European Commission: enforce that when something goes end-of-life, companies need to open-source the software.</p><br></section><section><p>I have a "smart" weight scale. It still connects via Bluetooth just fine (meaning: I see it connect on my phone) but because the app is no longer in development, it's essentially useless. A perfect piece of hardware, "dead" because the company behind it stopped supporting it. (I'm exaggerating a bit; it shows the weight on its display, but the app used to store data for up to 5 users to keep track over time. I miss that!) It's infuriating that we allow this to happen with all the wasteful electronics already lying around. We deserve better.</p><br></section><section><p>I thought of this while reading <a href="https://arstechnica.com/gadgets/2026/01/bose-open-sources-its-soundtouch-home-theater-smart-speakers-ahead-of-eol/" target="_blank" rel="noopener noreferrer">this article.</a> It's great that Bose does this, but it's rare. When <a href="https://www.musicbusinessworldwide.com/spotifys-car-thing-officially-non-operational-less-than-three-years-after-it-rolled-out-in-the-us/" target="_blank" rel="noopener noreferrer">Spotify killed off its $200 Car Thing</a> at the end of 2024, we just accepted it and moved on, even though that's $200 of hardware turned into e-waste overnight. Out of sustainability concerns, but also just out of doing what's right: this should not be able to happen.</p><br></section><section><p>Now, I'm not asking companies to open-source their entire codebase. That's unrealistic when an app is tied to a larger platform. What I am asking for: publish a basic GitHub repo with the hardware specs and connection protocols. Let the community build their own apps on top of it.</p><br></section><section><p>And here's the thing: with vibe-coding making development more accessible than ever, this isn't just for hardcore developers anymore. Regular users can actually tinker with this stuff now.</p><br></section><section><p>The worst you can do is break the software. But the hardware was bricked already anyway :-)</p></section><div><h4>Can I keep you updated?</h4><p>Starting in 2026, I'll share more focused notes on product design, technology, and business. If you'd like them in your inbox, leave your email below. I'm always happy to connect via <a href="mailto:ik@marcianoplanque.nl">email</a>, <a href="https://bsky.app/profile/marciplan.bsky.social" target="_blank">Bluesky</a>, or <a href="https://www.linkedin.com/in/marciano-planque" target="_blank">LinkedIn (blergh)</a>.</p><br></div><p><h6>© <!-- -->2026<!-- --> | Marciano Planque. <a href="mailto:ik@marcianoplanque.nl">Say Hi.</a></h6></p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why we don’t use AI (107 pts)]]></title>
            <link>https://yarnspinner.dev/blog/why-we-dont-use-ai/</link>
            <guid>46609279</guid>
            <pubDate>Tue, 13 Jan 2026 22:30:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yarnspinner.dev/blog/why-we-dont-use-ai/">https://yarnspinner.dev/blog/why-we-dont-use-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=46609279">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

    <div>
      <p>We get asked about AI a lot. Whether we’re going to add it to Yarn Spinner, whether we use it ourselves, what we think about it. Fair questions. Time to write it all down.</p>
<p>Yarn Spinner doesn’t use the technology that’s currently being called AI. We don’t have generative AI features in the product, and we don’t use code generation tools to build it, and we don’t accept contributions we know contain generated material. Let’s talk about why.</p>
<p>TL;DR: AI companies make tools for hurting people and we don’t want to support that.</p>
<h2 id="the-past">The Past</h2>
<p>A little history first. We come from a background that did a decent amount of work with AI and ML (terms we shouldn’t but will use interchangeably because everyone else does).</p>
<p>We gave talks about it for game developers and non-programmers. We wrote little ML bots for games. We did research and academic work. We wrote books<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> about using ML in games, mostly for procedural animation. It was a fun series of techniques to explore, and explore we did.</p>
<p><img src="https://yarnspinner.dev/images/oreilly-ai-ml-books.png" alt="O’Reilly books on AI and ML that we wrote"></p>
<p>When we started at university, neural networks and deep learning (the main underlying techniques most AI products use today) were just too slow and hard to work with. By the time we finished our doctorates, that had changed. Tools like TensorFlow made this stuff easier and fun, and the increase in GPU access made training and inference possible for people without Big Tech budgets. For quite a while, we were genuinely excited about the potential.</p>
<p>Then things started to change.</p>
<p>It’s hard to say exactly when. Maybe it was always like this and we just didn’t see it. But by the end of 2020 (a year famous for absolutely nothing world changing whatsoever happening /s) it was clear that the AI we liked was not what the tech companies were interested in. They were increasingly about generative imagery, chatbots writing your material for you, and summaries of art instead of exposure to it. Efforts to mitigate known problems (reinforcing cultural biases, being difficult to make deterministic or explainable) were disparaged and diminished. Researchers and developers who raised concerns were being fired.</p>
<p>Things have only gotten worse since.</p>
<p>If you look at what AI companies promote now, it’s not what we wanted. When you boil down everything they say and strip it right back, what they make are tools to either fire people or demand more work without hiring anyone new to help. That’s the problem AI companies want to solve.</p>
<p>Anything else they achieve is a happy accident on the road to firing as many of your friends and colleagues as possible.</p>
<p>AI is now a tool for firing people, in a time when getting re-employed is especially difficult and being unemployed can be life-threatening. We don’t want to be part of that. Until this is fixed we won’t use AI in our work, nor integrate it into Yarn Spinner for others to use.</p>
<p>We don’t want to support the companies making these tools or normalise their behaviour. So we don’t.</p>
<h2 id="the-future">The Future</h2>
<p>There’s a comment we see every so often, always phrased as a <em>fait accompli</em>: “you’ll be left behind if you don’t adopt AI”, or its cousin, “everyone is using it”. We disagree.</p>
<p>This isn’t the right approach regardless of our opinions on AI. It’s tool driven development. The goal should never be “we use this tool”. It should be “how do we help you make better games?”.</p>
<p>Great games are made when people are passionate about an idea and push it into existence. Often this means reduction, not addition. Changing ideas. Keeping yourself and colleagues healthy. Being willing to adapt and take feedback. Good tools need to do the same.</p>
<p>We’re constantly asking “how would this help make better games?” and following where that leads. The exploration matters, and most of the time we find an idea doesn’t survive even a little scrutiny. We’d rather have fewer polished features that solve real problems than a load of garbage that exists for the sake of marketing copy.</p>
<p>We’re proud of Yarn Spinner. We don’t think it’s a coincidence it’s used in <a href="https://yarnspinner.dev/showcase/">so many games</a>. Our process works, and we’re always adding new features. We also change and remove features if they don’t meet the needs of devs. We’re always chatting, internally and with other game devs and even non-devs, about potential ideas and approaches. We’re going to keep asking “how would this help make better games?” and ship what survives that gauntlet.</p>
<p>Who knows. Maybe the world will change and we can take another look at ML.</p>
<h2 id="likely-to-be-frequently-asked-questions">Likely to be Frequently Asked Questions</h2>
<div>
<p><strong>Why do you only care about people getting fired? I read that AI is also bad for SOME OTHER REASON!</strong> There are so many issues AI (and in particular the companies making it) have. Some are potential or even hypothetical concerns that might eventuate. Some are very real and happening right now in front of our eyes. Some are <strong>much</strong> worse than people being fired. Some of these worse issues appeared between us starting this blog post and publishing it. If the labour concerns around AI suddenly vanished, there are still many issues we’d need to see fixed before we’d be comfortable using it. But it’s stronger to argue a single point at a time. The labour concerns can be fixed and should be pushed back on. Once that’s sorted we can look at the next issue.</p>
<p><strong>Why don’t you do ML correctly so no one gets hurt?</strong> Given our background and experience, we probably could make our own AI tooling in a way we feel is helpful, ethical, and doesn’t fund companies we disagree with. Two problems with this. First, these things take a lot of time to make, and like we said, most ideas don’t survive initial exploration. It would be very difficult to balance exploring an idea while also building new models to test it. Second, while we could make our own tools, most people can’t. If they saw us using a technique and wanted to try it, they’d end up supporting the very companies we object to. We don’t want to normalise it, so we have to not use it.</p>
<p><strong>My boss wants me to use AI for work, am I part of the problem?</strong> Getting and keeping a job is a necessity, and this has only gotten worse recently. If you can push back on this, do. But no one will fault you for wanting to keep your job.</p>
<p><strong>Are you going to ban people who use AI from using Yarn Spinner?</strong> No. While we wish you didn’t use it, we get this is <em>our</em> line in the sand, not yours. We’ll still advocate against these tools and we’re still concerned about the harm they do. You need to realise that if you use them, you’re both financially and socially supporting dodgy companies doing dodgy things. They will use your support to push their agenda. If these tools are working for you, we’re genuinely pleased. But please also stop using them.</p>
<p><strong>I kinda like using AI and no one at my work is getting fired?</strong> This comment pops up a few times, often from programmers. Unfortunately, because of how messy the term AI now is, the same concerns still apply. Your adoption helps promote the companies making these tools. People see you using it and force it onto others at the studio, or at other workplaces entirely. From what we’ve seen, this is followed by people getting fired and overworked. If it isn’t happening to you and your colleagues, great. But you’re still helping it happen elsewhere. And as we said, even if you fixed the labour concerns tomorrow, there are still many other issues. There’s more than <em>just</em> being fired to worry about.</p>
<p><strong>Are you zealots or luddites who just hate AI?</strong> Nah. Just upset at the people making these things. There’s great potential in AI and machine learning, and it’s being squandered to make already dodgy rich people richer and more dodgy. We still keep up with developments because we hope one day we can explore it again. But for now, the people pushing these tools aren’t people we want to give money or support to.</p>
</div>
<p><em>Header image: <a href="https://commons.wikimedia.org/wiki/File:WGA_Strike_6.21.2023_020_(52992516978).jpg">WGA Strike, June 21, 2023</a> via Wikimedia Commons</em></p>


    </div>

    

  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We can't have nice things because of AI scrapers (423 pts)]]></title>
            <link>https://blog.metabrainz.org/2025/12/11/we-cant-have-nice-things-because-of-ai-scrapers/</link>
            <guid>46608840</guid>
            <pubDate>Tue, 13 Jan 2026 21:57:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.metabrainz.org/2025/12/11/we-cant-have-nice-things-because-of-ai-scrapers/">https://blog.metabrainz.org/2025/12/11/we-cant-have-nice-things-because-of-ai-scrapers/</a>, See on <a href="https://news.ycombinator.com/item?id=46608840">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
		<p><a href="#content">
			Skip to content		</a></p><!-- .site-header -->

		<div id="content">
	<main id="main">
		
<article id="post-12864">
	<!-- .entry-header -->

	
	
	<div>
		
<p>In the past few months the MetaBrainz team has been fighting a battle against unscrupulous AI companies ignoring common courtesies (such as robots.txt) and <a href="https://www.theregister.com/2025/08/29/ai_web_crawlers_are_destroying/">scraping the Internet in order to build up their AI models</a>. Rather than downloading our dataset in one complete download, they insist on loading all of MusicBrainz <strong>one page at a time</strong>. This of course would take hundreds of years to complete and is utterly pointless. In doing so, they are overloading our servers and preventing legitimate users from accessing our site.</p>
<p>Now the AI scrapers have found ListenBrainz and are hitting a number of our API endpoints for their nefarious data gathering purposes. In order to protect our services from becoming overloaded, we’ve made the following changes:</p>
<ul>
<li>The <a href="https://listenbrainz.readthedocs.io/en/latest/users/api/metadata.html#post--1-metadata-lookup-">/metadata/lookup</a> API endpoints (GET and POST versions) now require the caller to send an <a href="https://listenbrainz.readthedocs.io/en/latest/users/api/index.html#authentication">Authorization token</a> in order for this endpoint to work.</li>
<li>The <a href="https://labs.api.listenbrainz.org/">ListenBrainz Labs API</a> endpoints for mbid-mapping, mbid-mapping-release and mbid-mapping-explain have been removed. Those were always intended for debugging purposes and will also soon be replaced with a new endpoints for our upcoming improved mapper.</li>
<li>LB Radio will now require users to be logged in to use it (and API endpoint users will need to send the Authorization header). The error message for logged in users is a bit clunky at the moment; we’ll fix this once we’ve finished the work for this year’s Year in Music.</li>
</ul>
<p>Sorry for these hassles and no-notice changes, but they were required in order to keep our services functioning at an acceptable level.</p>


	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-12864 -->

<!-- .comments-area -->

	<nav aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
	</main><!-- .site-main -->

	
</div><!-- .site-content -->

		<!-- .site-footer -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Games Workshop bans staff from using AI (224 pts)]]></title>
            <link>https://www.ign.com/articles/warhammer-maker-games-workshop-bans-its-staff-from-using-ai-in-its-content-or-designs-says-none-of-its-senior-managers-are-currently-excited-about-the-tech</link>
            <guid>46607681</guid>
            <pubDate>Tue, 13 Jan 2026 20:45:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ign.com/articles/warhammer-maker-games-workshop-bans-its-staff-from-using-ai-in-its-content-or-designs-says-none-of-its-senior-managers-are-currently-excited-about-the-tech">https://www.ign.com/articles/warhammer-maker-games-workshop-bans-its-staff-from-using-ai-in-its-content-or-designs-says-none-of-its-senior-managers-are-currently-excited-about-the-tech</a>, See on <a href="https://news.ycombinator.com/item?id=46607681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-cy="page-header"><h2 data-cy="article-sub-headline">The Emperor protects.</h2></div><div><section data-cy="article-content"><p data-cy="paragraph">Warhammer maker Games Workshop has banned the use of AI in its content production and its design process, insisting that none of its senior managers are currently excited about the technology.</p><p data-cy="paragraph">Delivering the UK company’s impressive financial results, CEO Kevin Rountree addressed the issue of AI and how Games Workshop is handling it. He said GW staff are barred from using it to actually produce anything, but admitted a “few” senior managers are experimenting with it.</p><p data-cy="paragraph">Rountree said AI was “a very broad topic and to be honest I’m not an expert on it,” then went on to lay down the company line:</p><p data-cy="paragraph">"We do have a few senior managers that are [experts on AI]: none are that excited about it yet. We have agreed an internal policy to guide us all, which is currently very cautious e.g. we do not allow AI generated content or AI to be used in our design processes or its unauthorised use outside of GW including in any of our competitions. We also have to monitor and protect ourselves from a data compliance, security and governance perspective, the AI or machine learning engines seem to be automatically included on our phones or laptops whether we like it or not.</p><p data-cy="paragraph">“We are allowing those few senior managers to continue to be inquisitive about the technology. We have also agreed we will be maintaining a strong commitment to protect our intellectual property and respect our human creators. In the period reported, we continued to invest in our Warhammer Studio — hiring more creatives in multiple disciplines from concepting and art to writing and sculpting. Talented and passionate individuals that make Warhammer the rich, evocative IP that our hobbyists and we all love.”</p><output data-cy="article-video"></output><p data-cy="paragraph">Games Workshop owns and operates a number of hugely popular tabletop war games, including Warhammer 40,000 and Age of Sigmar. Its core business is selling miniatures and box sets that are used by fans to play these games, but there are a number of other creative aspects of the hobby that Games Workshop invests in, such as book selling, art sales, and animation production.</p><p data-cy="paragraph">Last month, <a data-cy="styled-link" href="https://www.ign.com/articles/displate-denies-warhammer-40000-ai-art-accusations-says-red-flags-in-official-fulgrim-poster-are-the-result-of-human-error">Displate was forced to deny that one of its pieces of official Warhammer 40,000 artwork was the product of generative AI</a>, insisting “red flags” spotted by fans were the result of human error.</p><p data-cy="paragraph"><a data-cy="styled-link" href="https://www.ign.com/articles/new-horus-heresy-book-era-of-ruin-gets-warhammer-40000-lore-fans-talking-with-tantalizing-insight-into-the-carrion-emperor-and-the-golden-thrones-true-nature"><u>The Warhammer 40,000 setting is in many ways built upon the evocative and enduring art drawn by the likes of John Blanche</u></a>, who shaped its "grimdark" aesthetic alongside other key Games Workshop staff. This official, human-made Warhammer 40,000 artwork is beloved by fans, most of whom take a dim view of the mere whiff of generative AI “art” sold or released in any official capacity by either Games Workshop itself, or its partners.</p><p data-cy="paragraph">Indeed, Games Workshop sells expensive Warhammer 40,000 ‘codex’ rulebooks that are packed with stunning official art as well as lore. Any suggestion that this art was created either in part or entirely by generative AI tools would likely cause a community uproar.</p><output><figure><a href="https://assets-prd.ignimgs.com/2026/01/13/ow852ulpdo731-1751405677082-1766411683253-1768309174083.jpg" target="_blank" rel="noopener noreferrer"><img alt="null" decoding="async" loading="lazy" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-cy="progressive-image"></a><figcaption data-cy="caption">The God-Emperor, by John Blanche. Image credit: Games Workshop.</figcaption></figure></output><p data-cy="paragraph">Games Workshop’s ban on AI is in contrast to some entertainment companies, some of whom have gone all-in on the tech despite various backlashes to their use. The CEO of Genvid — the company behind choose-your-own-adventure interactive series like Silent Hill Ascension — has <a data-cy="styled-link" href="https://www.ign.com/articles/gen-z-loves-ai-slop-former-square-enix-exec-claims-a-lot-of-ai-sentiment-is-driven-by-emotion-rather-than-logic"><u>claimed "consumers generally do not care" about generative AI, and stated that: "Gen Z loves AI slop."</u></a></p><p data-cy="paragraph">EA CEO Andrew Wilson has <a data-cy="styled-link" href="https://www.ign.com/articles/ea-says-ai-is-the-very-core-of-its-business-what-does-that-mean"><u>said AI is "the very core of our business,"</u></a> and Square Enix recently implemented mass layoffs and reorganized, saying it needed to <a data-cy="styled-link" href="https://www.ign.com/articles/square-enix-undergoes-mass-layoffs-as-it-reorganizes-to-consolidate-development-in-japan"><u>be "aggressive in applying AI."</u></a> Dead Space creator Glen Schofield also recently detailed <a data-cy="styled-link" href="https://www.ign.com/articles/dead-space-creator-glen-schofield-thinks-the-games-industry-is-broken-beaten-and-battered"><u>his plans to “fix” the industry in part via the use of generative AI in game development</u></a>, and former God of War dev Meghan Morgan Juinio said: "... if we don’t embrace [AI], <a data-cy="styled-link" href="https://www.ign.com/articles/former-god-of-war-dev-on-the-use-of-ai-in-games-development-if-we-dont-embrace-it-were-selling-ourselves-short"><u>I think we’re selling ourselves short</u></a>.”</p><p data-cy="paragraph"><em>Wesley is Director, News at IGN. Find him on Twitter at @wyp100. You can reach Wesley at wesley_yinpoole@ign.com or confidentially at wyp100@proton.me.</em></p></section><div><h3 data-cy="title3"><svg data-cy="icon-logo" viewBox="0 0 76 24" title="IGN"><title>IGN Logo</title><path fill="currentColor" stroke="none" d="M5.38 7.65a7.85 7.85 0 0 1 2.26-2.26c.13-1.18.31-2.26.52-3.21a10.605 10.605 0 0 0-6 6c.95-.22 2.03-.39 3.21-.52M16.34 5.36v.02c.9.59 1.67 1.37 2.27 2.27 1.18.13 2.26.31 3.21.52a10.627 10.627 0 0 0-6.02-6.01c.22.95.4 2.02.54 3.2M7.64 18.62c-.9-.59-1.67-1.37-2.27-2.27h-.03c-1.19-.14-2.26-.32-3.19-.54 1.07 2.75 3.26 4.95 6.01 6.02-.22-.95-.39-2.03-.52-3.21M18.64 16.35h-.03c-.59.9-1.37 1.67-2.27 2.27v.03c-.14 1.17-.32 2.25-.54 3.19a10.59 10.59 0 0 0 6.03-6.03c-.94.22-2 .4-3.19.54M10.04 0h3.9c.85 1.85 1.2 4.59 1.3 5.52.04.22.06.43.06.63L12 9.11 8.7 6.15c0-.17.02-.35.05-.55.1-.95.43-3.75 1.29-5.61M8.7 17.83c0 .17.02.35.05.55.1.95.43 3.75 1.29 5.61h3.9c.85-1.84 1.2-4.59 1.3-5.52.04-.22.06-.43.06-.64L12 14.87l-3.3 2.96ZM6.16 8.68c-.17 0-.35.02-.55.05-.95.12-3.75.45-5.61 1.31v3.9c1.84.85 4.59 1.19 5.52 1.3.22.04.43.06.64.06L9.11 12 6.16 8.7ZM24 10.02c-1.86-.86-4.66-1.19-5.61-1.29-.2-.03-.38-.05-.55-.05l-2.96 3.3 2.96 3.3c.2 0 .41-.02.64-.06.93-.11 3.68-.45 5.52-1.3v-3.9Z"></path><path fill="currentColor" stroke="none" d="M42.83 13.9V10h10.45c1.06 0 1.93.86 1.93 1.92v4.63c0 2.38-1.91 4.36-4.33 4.36h-6.69c-4.96 0-8.97-4-8.97-8.94s4.04-8.95 8.98-8.95h10.36v4.11H44.2c-2.67 0-4.86 2.17-4.86 4.84s2.16 4.83 4.86 4.83h6.91v-2.91h-8.27ZM33.86 3h-4.07v16.02c0 1.05.86 1.91 1.91 1.91h2.15V3M74.37 3.01h-2.18v13.81s0 .08-.03.11a.29.29 0 0 1-.24.14c-.09 0-.16-.04-.25-.15L64.83 4.93a4.347 4.347 0 0 0-3.72-2.11h-.07c-2.39 0-4.32 1.93-4.32 4.32v11.88c0 1.05.86 1.91 1.91 1.91h2.17V7.14s.02-.09.04-.13a.29.29 0 0 1 .24-.14c.09 0 .18.03.24.14l6.88 12.07c.76 1.27 2.12 2.05 3.69 2.05h.07c2.39 0 4.32-1.93 4.32-4.32V4.92c0-1.05-.85-1.91-1.91-1.91"></path></svg>Recommends</h3></div></div><div><h3 data-cy="object-summary-embed-title">In This Article</h3><div data-cy="objectcard-view-trigger"><a href="https://www.ign.com/games/warhammer-40000-500-worlds"><div data-cy="object-thumbnail"><figure><img alt="Warhammer 40,000: 500 Worlds" decoding="async" loading="lazy" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-cy="progressive-image"></figure></div></a></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Instagram AI Influencers Are Defaming Celebrities with Sex Scandals (107 pts)]]></title>
            <link>https://www.404media.co/instagram-ai-influencers-are-defaming-celebrities-with-sex-scandals/</link>
            <guid>46606633</guid>
            <pubDate>Tue, 13 Jan 2026 19:39:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/instagram-ai-influencers-are-defaming-celebrities-with-sex-scandals/">https://www.404media.co/instagram-ai-influencers-are-defaming-celebrities-with-sex-scandals/</a>, See on <a href="https://news.ycombinator.com/item?id=46606633">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
          <div>
              
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p>AI generated influencers are sharing fake images on Instagram that appear to show them having sex with celebrities like LeBron James, iShowSpeed, and Dwayne “The Rock” Johnson. One AI influencer even shared an image of her in bed with Venezuela’s president Nicolás Maduro. The images are AI generated but are not disclosed as such, and funnel users to an adult content site where the AI generated influencers sell nude images.&nbsp;</p><p>This recent trend is the latest strategy from the growing business of monetizing AI generated porn by harvesting attention on Instagram with shocking or salacious content. As with previous schemes we’ve covered, the Instagram posts that pretend to show attractive young women in bed with celebrities are created without the celebrities’ consent and are not disclosed as being AI generated, violating two of Instagram’s policies and showing once again that Meta is unable or unwilling to reign in AI generated content on its platform.&nbsp;</p><p>Most of the Reels in this genre that I have seen follow a highly specific formula and started to appear around December 2025. First, we see a still image of an AI-generated influencer next to a celebrity, often in the form of a selfie with both of them looking at the camera. The text on the screen says “How it started.” Then, the video briefly cuts to another still image or videos of the AI generated influencer and the celebrity post coitus, sweaty, with tussled hair and sometimes smeared makeup. Many of these posts use the same handful of audio clips. Since Instagram allows users to browse Reels that use the same audio, clicking on one of these will reveal dozens of examples of similar Reels.&nbsp;</p><p><a href="https://www.instagram.com/reels/DTDODMdiC1d/?ref=404media.co"><u>LeBron James</u></a> and adult film star <a href="https://www.instagram.com/reel/DS51AdUElNm/?ref=404media.co"><u>Johnny Sins</u></a> are frequent targets of these posts, but I’ve also seen similar Reels with the likeness of Twitch streamer iShowSpeed, Dwayne “The Rock” Johnson, MMA fighters Jon Jones and <a href="https://www.instagram.com/reels/DTLOnUukU-6/?ref=404media.co"><u>Connor McGregor</u></a>, soccer player Cristiano Ronaldo, and many others, far too many to name them all. The AI influencer accounts obviously don’t care whether it's believable that these fake women are actually sleeping with celebrities and will include any known person who is likely to earn engagement. Amazingly, one AI influencer applied the same formula to Venezuela’s president Maduro shortly after he was captured by the United States.&nbsp;</p><figure><img src="https://www.404media.co/content/images/2026/01/data-src-image-c6a4bd72-a4a8-4960-bdf6-da57238154b5.png" alt="" loading="lazy" width="463" height="850"></figure><p>These Instagram Reels frequently have hundreds of thousands and sometimes millions of views. A post from one of these AI influencers that <a href="https://www.instagram.com/reel/DTUCOjYCjwW/?ref=404media.co"><u>shows her in bed with Jon Jones</u></a> has has 7.7 million views. A video showing another AI influencer in a bed with iShowSpeed has 14.5 million views.&nbsp;</p><p>Users who stumble upon one of these videos might be inclined to click on the AI-influencer's username to check her bio and see if she has an OnlyFans account, as is the case with many adult content creators who promote their work on Instagram. What these users will find is an account bio that doesn’t disclose its AI generated, and a link to Fanvue, an OnlyFans competitor with more permissive policies around AI generated content. On Fanvue, these accounts do disclose that they are “AI-generated or enhanced,” and sell access to nude images and videos.&nbsp;</p><p>Meta did not respond to a request for comment, but removed some of the Reels I flagged. </p><p>Posting provocative AI generated media in order to funnel eyeballs to adult content platforms where AI generated porn can be monetized is now an established business. Sometimes, these AI influencers <a href="https://www.404media.co/inside-the-booming-ai-pimping-industry-3/"><u>steal directly from real adult content creators</u></a> by faceswapping themselves into their existing videos. Once in a while a new “meta” strategy for AI influencers will emerge and dominate the algorithm. For example, last year I wrote about people using AI to create <a href="https://www.404media.co/people-are-using-ai-to-create-influencers-with-down-syndrome-who-sell-nudes/"><u>influencers with down syndrome who sell nudes</u></a>.&nbsp;&nbsp;</p><p>Some other video formats I’ve seen from AI influencers recently follow the formula I describe in this article, but rather than suggesting the influencer slept with a celebrity, it shows them sleeping with <a href="https://www.instagram.com/reel/DTVLswbjAvA/?ref=404media.co"><u>entire sports teams</u></a>, <a href="https://www.instagram.com/reel/DTU3HCADHic/?ref=404media.co"><u>African tribal chiefs</u></a>, <a href="https://www.instagram.com/reel/DTAznwLCOka/?ref=404media.co"><u>Walmart managers</u></a>, and <a href="https://www.instagram.com/reels/DSwxJGyjEkh/?ref=404media.co"><u>sharing a man with their mom</u></a>.</p><p>Notably, celebrities are better equipped than adult content creators to take on AI accounts that are using their likeness without consent, and last year LeBron James, a frequent target of this latest meta, <a href="https://www.404media.co/lebron-james-lawyers-send-cease-and-desist-to-ai-company-making-pregnant-videos-of-him/"><u>sent a cease-and-desist notice</u></a> to a company that was making AI videos of him and sharing them on Instagram.&nbsp;</p>
<!--kg-card-begin: html-->

<!--kg-card-end: html-->

                    <div>
    <div>
      <p>About the author</p>
      <p>Emanuel Maiberg is interested in little known communities and processes that shape technology, troublemakers, and petty beefs. Email him at emanuel@404media.co
</p>
      
    </div>
      <p><img data-src="/content/images/2023/08/headshot-1.jpg" alt="Emanuel Maiberg" src="https://www.404media.co/content/images/2023/08/headshot-1.jpg">  
      </p>
  </div>
          </div>
        </article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A university got itself banned from the Linux kernel (2021) (134 pts)]]></title>
            <link>https://www.theverge.com/2021/4/30/22410164/linux-kernel-university-of-minnesota-banned-open-source</link>
            <guid>46605950</guid>
            <pubDate>Tue, 13 Jan 2026 18:58:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2021/4/30/22410164/linux-kernel-university-of-minnesota-banned-open-source">https://www.theverge.com/2021/4/30/22410164/linux-kernel-university-of-minnesota-banned-open-source</a>, See on <a href="https://news.ycombinator.com/item?id=46605950">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="zephr-anchor"><p>On the evening of April 6th, a student <a href="https://lore.kernel.org/linux-nfs/20210407001658.2208535-1-pakki001@umn.edu/">emailed</a> a patch to a list of developers. Fifteen days later, the University of Minnesota was <a href="https://www.theverge.com/2021/4/22/22398156/university-minnesota-linux-kernal-ban-research">banned</a> from contributing to the Linux kernel.</p><p>“I suggest you find a different community to do experiments on,” wrote Linux Foundation fellow Greg Kroah-Hartman in a livid email. “You are not welcome here.”</p><p>How did one email lead to a university-wide ban? I’ve spent the past week digging into this world — the players, the jargon, the university’s turbulent history with open-source software, the devoted and principled Linux kernel community. None of the University of Minnesota researchers would talk to me for this story. But among the other major characters — the Linux developers — there was no such hesitancy. This was a community eager to speak; it was a community betrayed.</p><p>The story begins in 2017, when a systems-security researcher named Kangjie Lu became an assistant professor at the University of Minnesota.</p><p>Lu’s research, per his <a href="https://www-users.cs.umn.edu/~kjlu/">website</a>, concerns “the intersection of security, operating systems, program analysis, and compilers.” But Lu had his eye on Linux — most of his papers involve the Linux kernel in some way.</p><p>The Linux kernel is, at a basic level, the core of any Linux operating system. It’s the liaison between the OS and the device on which it’s running. A Linux user doesn’t interact with the kernel, but it’s essential to getting things done — it manages memory usage, writes things to the hard drive, and decides what tasks can use the CPU when. The kernel is open-source, meaning its millions of lines of code are publicly available for anyone to view and contribute to.</p><div><p>Getting a patch on people’s computers is no easy task</p></div><p>Well, “anyone.” Getting a patch onto people’s computers is no easy task. A submission needs to pass through a large web of developers and “maintainers” (<a href="https://www.kernel.org/doc/html/latest/process/maintainers.html">thousands</a> of volunteers, who are each responsible for the upkeep of different parts of the kernel) before it ultimately ends up in the mainline repository. Once there, it goes through a long testing period before eventually being incorporated into the “stable release,” which will go out to mainstream operating systems. It’s a rigorous system designed to weed out both malicious and incompetent actors. But — <a href="https://gizmodo.com/a-teen-threw-scots-wiki-into-chaos-and-it-highlights-a-1844851959">as is always the case with crowdsourced operations</a> — there’s room for human error.</p><p>Some of Lu’s recent work has revolved around studying that potential for human error and reducing its influence. He’s <a href="https://www-users.cs.umn.edu/~kjlu/papers/lrsan.pdf">proposed</a> <a href="https://www-users.cs.umn.edu/~kjlu/papers/deadline.pdf">systems</a> to automatically detect various types of bugs in open source, using the Linux kernel as a test case. These experiments tend to involve reporting bugs, submitting patches to Linux kernel maintainers, and reporting their acceptance rates. In <a href="https://www-users.cs.umn.edu/~kjlu/papers/crix.pdf">a 2019 paper</a>, for example, Lu and two of his PhD students, Aditya Pakki and Qiushi Wu, presented a system (“Crix”) for detecting a certain class of bugs in OS kernels. The trio found 278 of these bugs with Crix and submitted patches for all of them — the fact that maintainers accepted 151 meant the tool was promising.</p><p>On the whole, it was a useful body of work. Then, late last year, Lu took aim not at the kernel itself, but at its community.</p><p>In “On the Feasibility of Stealthily Introducing Vulnerabilities in Open-Source Software via Hypocrite Commits,” Lu and Wu <a href="https://linuxreviews.org/images/d/d9/OpenSourceInsecurity.pdf">explained</a> that they’d been able to introduce vulnerabilities into the Linux kernel by submitting patches that appeared to fix real bugs but also introduced serious problems. The group called these submissions “hypocrite commits.” (Wu didn’t respond to a request for comment for this story; Lu referred me to Mats Heimdahl, the head of the university’s department of computer science and engineering, who referred me to the <a href="https://cse.umn.edu/cs/linux-incident">department’s website</a>.)</p><p>The explicit goal of this experiment, as the researchers have since emphasized, was to improve the security of the Linux kernel by demonstrating to developers how a malicious actor might slip through their net. One could argue that their process was similar, in principle, to that of <a href="https://www.theverge.com/2021/4/13/22382243/counter-strike-global-offensive-game-engine-bug-take-over-pc">white-hat hacking</a>: play around with software, find bugs, let the developers know.</p><p>But the loudest reaction the paper received, on Twitter and across the Linux community, wasn’t gratitude — it was outcry.</p><p>“That paper, it’s just a lot of crap,” says <a href="https://www.dgregscott.com/">Greg Scott</a>, an IT professional who has worked with open-source software for over 20 years.</p><p>“In my personal view, it was completely unethical,” says security researcher Kenneth White, who is co-director of the Open Crypto Audit Project.</p><p>The frustration had little to do with the hypocrite commits themselves. In their paper, Lu and Wu claimed that none of their bugs had actually made it to the Linux kernel — in all of their test cases, they’d eventually pulled their bad patches and provided real ones. Kroah-Hartman, of the Linux Foundation, contests this — he told <em>The Verge </em>that one patch from the study did make it into repositories, though he notes it didn’t end up causing any harm.</p><div><p>“In my personal view, it was completely unethical.”</p></div><p>Still, the paper hit a number of nerves among a very passionate (and very online) community when Lu first shared its abstract on Twitter. Some developers were angry that the university had intentionally wasted the maintainers’ time — which is a key difference between Minnesota’s work and a white-hat hacker poking around the Starbucks app for a bug bounty. “The researchers crossed a line they shouldn’t have crossed,” Scott says. “Nobody hired this group. They just chose to do it. And a whole lot of people spent a whole lot of time evaluating their patches.”</p><p>“If I were a volunteer putting my personal time into commits and testing, and then I found out someone’s experimenting, I would be unhappy,” Scott adds.</p><p>Then, there’s the dicier issue of whether an experiment like this amounts to human experimentation. It doesn’t, according to the University of Minnesota’s Institutional Review Board. Lu and Wu applied for approval in response to the outcry, and they were granted a formal letter of exemption.</p><p>The community members I spoke to didn’t buy it. “The researchers attempted to get retroactive Institutional Review Board approval on their actions that were, at best, wildly ignorant of the tenants of basic human subjects’ protections, which are typically taught by senior year of undergraduate institutions,” says White.</p><p>“It is generally not considered a nice thing to try to do ‘research’ on people who do not know you are doing research,” says Kroah-Hartman. “No one asked us if it was acceptable.”</p><div><p>“That paper, it’s just a lot of crap.”</p></div><p>That thread ran through many of the responses I got from developers — that regardless of the harms or benefits that resulted from its research, the university was messing around not just with community members but with the community’s underlying philosophy. Anyone who uses an operating system places some degree of trust in the people who contribute to and maintain that system. That’s especially true for people who use open-source software, and it’s a principle that some Linux users take very seriously.</p><p>“By definition, open source depends on a lively community,” Scott says. “There have to be people in that community to submit stuff, people in the community to document stuff, and people to use it and to set up this whole feedback loop to constantly make it stronger. That loop depends on lots of people, and you have to have a level of trust in that system ... If somebody violates that trust, that messes things up.”</p><p>After the paper’s release, it was clear to many Linux kernel developers that something needed to be done about the University of Minnesota — previous submissions from the university needed to be reviewed. “Many of us put an item on our to-do list that said, ‘Go and audit all umn.edu submissions,’” said Kroah-Hartman, who was, above all else, annoyed that the experiment had put another task on his plate. But many kernel maintainers are volunteers with day jobs, and a large-scale review process didn’t materialize. At least, not in 2020.</p><p>On April 6th, 2021, Aditya Pakki, using his own email address, submitted a patch.</p><p>There was some brief discussion from other developers on the email chain, which fizzled out within a few days. Then Kroah-Hartman took a look. He was already on high alert for bad code from the University of Minnesota, and Pakki’s email address set off alarm bells. What’s more, the patch Pakki submitted didn’t appear helpful. “It takes a lot of effort to create a change that looks correct, yet does something wrong,” Kroah-Hartman told me. “These submissions all fit that pattern.”</p><p>So on April 20th, Kroah-Hartman put his foot down.</p><p>“Please stop submitting known-invalid patches,” he wrote to Pakki. “Your professor is playing around with the review process in order to achieve a paper in some strange and bizarre way.”</p><p>Maintainer Leon Romanovsky then chimed in: he’d taken a look at four previously accepted patches from Pakki and found that three of them added “various severity” security vulnerabilities.</p><div><p>There’s the dicier issue of whether an experiment like this amounts to human experimentation</p></div><p>Kroah-Hartman hoped that his request would be the end of the affair. But then Pakki lashed back. “I respectfully ask you to cease and desist from making wild accusations that are bordering on slander,” he wrote to Kroah-Hartman in what appears to be a private message.</p><p>Kroah-Hartman responded. “You and your group have publicly admitted to sending known-buggy patches to see how the kernel community would react to them, and published a paper based on that work. Now you submit a series of obviously-incorrect patches again, so what am I supposed to think of such a thing?” he wrote back on the morning of April 21st.</p><p>Later that day, Kroah-Hartman made it official. “Future submissions from anyone with a umn.edu address should be default-rejected unless otherwise determined to actually be a valid fix,” he wrote in an <a href="https://lore.kernel.org/lkml/20210421130105.1226686-1-gregkh@linuxfoundation.org/">email</a> to a number of maintainers, as well as Lu, Pakki, and Wu. Kroah-Hartman reverted 190 submissions from Minnesota affiliates — 68 couldn’t be reverted but still needed manual review.</p><p>It’s not clear what experiment the new patch was part of, and Pakki declined to comment for this story. <a href="https://www-users.cs.umn.edu/~kjlu/">Lu’s website</a> includes a brief reference to “superfluous patches from Aditya Pakki for a new bug-finding project.”</p><p>What is clear is that Pakki’s antics have finally set the delayed review process in motion; Linux developers began digging through all patches that university affiliates had submitted in the past. Jonathan Corbet, the founder and editor in chief of <a href="http://lwn.net/"><em>LWN.net</em></a><em>, </em>recently provided an update on that review process. Per his assessment, “Most of the suspect patches have turned out to be acceptable, if not great.” Of over 200 patches that were flagged, 42 are still set to be removed from the kernel.</p><p>Regardless of whether their reaction was justified, the Linux community gets to decide if the University of Minnesota affiliates can contribute to the kernel again. And that community has made its demands clear: the school needs to convince them its future patches won’t be a waste of anyone’s time.</p><p>What will it take to do that? In a statement released the same day as the ban, the university’s computer science department suspended its research into Linux-kernel security and <a href="https://cse.umn.edu/cs/statement-cse-linux-kernel-research-april-21-2021">announced</a> that it would investigate Lu’s and Wu’s research method.</p><p>But that wasn’t enough for the Linux Foundation. Mike Dolan, Linux Foundation SVP and GM of projects, wrote a letter to the university on April 23rd, which <em>The Verge</em> has viewed. Dolan made four demands. He asked that the school release “all information necessary to identify all proposals of known-vulnerable code from any U of MN experiment” to help with the audit process. He asked that the paper on hypocrite commits be withdrawn from publication. He asked that the school ensure future experiments undergo IRB review before they begin, and that future IRB reviews ensure the subjects of experiments provide consent, “per usual research norms and laws.”</p><div><p>The school needs to convince them its future patches won’t be a waste of anyone’s time</p></div><p>Two of those demands have since been met. Wu and Lu have <a href="https://www-users.cs.umn.edu/~kjlu/papers/withdrawal-letter.pdf">retracted</a> the paper and have <a href="https://www-users.cs.umn.edu/~kjlu/papers/full-disclosure.pdf">released</a> all the details of their study.</p><p>The university’s status on the third and fourth counts is unclear. In a <a href="https://drive.google.com/file/d/1z3Nm2bfR4tH1nOGBpuOmLyoJVEiO9cUq/view">letter</a> sent to the Linux Foundation on April 27th, Heimdahl and Loren Terveen (the computer science and engineering department’s associate department head) maintain that the university’s IRB “acted properly,” and argues that human-subjects research “has a precise technical definition according to US federal regulations ... and this technical definition may not accord with intuitive understanding of concepts like ‘experiments’ or even ‘experiments on people.’” They do, however, commit to providing more ethics training for department faculty. Reached for comment, university spokesperson Dan Gilchrist referred me to the computer science and engineering department’s website.</p><p>Meanwhile, Lu, Wu, and Pakki apologized to the Linux community this past Saturday in an <a href="https://lore.kernel.org/lkml/CAK8KejpUVLxmqp026JY7x5GzHU2YJLPU8SzTZUNXU2OXC70ZQQ@mail.gmail.com/">open letter</a> to the kernel mailing list, which contained some apology and some defense. “We made a mistake by not finding a way to consult with the community and obtain permission before running this study; we did that because we knew we could not ask the maintainers of Linux for permission, or they would be on the lookout for hypocrite patches,” the researchers wrote, before going on to reiterate that they hadn’t put any vulnerabilities into the Linux kernel, and that their other patches weren’t related to the hypocrite commits research.</p><p>Kroah-Hartman wasn’t having it. “The Linux Foundation and the Linux Foundation’s Technical Advisory Board submitted a letter on Friday to your university,” he responded. “Until those actions are taken, we do not have anything further to discuss.”</p><div><div><p><a href="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0,0,100,100" data-pswp-height="1951" data-pswp-width="3600" target="_blank" rel="noreferrer"><img alt="Coronavirus in Minnesota" data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px" srcset="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=256 256w, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=376 376w, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=384 384w, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=415 415w, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=480 480w, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=540 540w, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=640 640w, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=750 750w, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=828 828w, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1080 1080w, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1200 1200w, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1440 1440w, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=1920 1920w, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2048 2048w, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400 2400w" src="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22479520/1220247994.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=2400"></a></p></div><p><cite>Photo by Glen Stubbe / Star Tribune via Getty Images</cite></p></div><p>From the University of Minnesota researchers’ perspective, they didn’t set out to troll anyone — they were trying to point out a problem with the kernel maintainers’ review process. Now the Linux community has to reckon with the fallout of their experiment and what it means about the security of open-source software.</p><p>Some <a href="https://twitter.com/rakyll/status/1385075395884556293?s=20">developers</a> rejected University of Minnesota researchers’ perspective outright, claiming the fact that it’s possible to fool maintainers should be obvious to anyone familiar with open-source software. “If a sufficiently motivated, unscrupulous person can put themselves into a trusted position of updating critical software, there’s honestly little that can be done to stop them,” says White, the security researcher.</p><p>On the other hand, it’s clearly important to be vigilant about potential vulnerabilities in any operating system. And for others in the Linux community, as much ire as the experiment drew, its point about hypocrite commits appears to have been somewhat well taken. The incident has ignited conversations about patch-acceptance policies and how maintainers should handle submissions from new contributors, across Twitter, <a href="https://lore.kernel.org/ksummit/a72a13e56ee5f19b0dee9ae8c1928b020e8809c2.camel@HansenPartnership.com/">email lists</a>, and forums. “Demonstrating this kind of ‘attack’ has been long overdue, and kicked off a very important discussion,” wrote maintainer Christoph Hellwig in an email thread with other maintainers. “I think they deserve a medal of honor.”</p><p>“This research was clearly unethical, but it did make it plain that the OSS development model is vulnerable to bad-faith commits,” one user wrote in a <a href="https://lobste.rs/s/9miojb/hypocrite_commits_apology_letter">discussion post</a>. “It now seems likely that Linux has some devastating back doors.”</p><p>Corbet also called for more scrutiny around new changes in his <a href="https://lwn.net/SubscriberLink/854645/e7eff3462424263e/">post</a> about the incident. “If we cannot institutionalize a more careful process, we will continue to see a lot of bugs, and it will not really matter whether they were inserted intentionally or not,” he wrote.</p><p>And even for some of the paper’s most ardent critics, the process did prove a point — albeit, perhaps, the opposite of the one Wu, Lu, and Pakki were trying to make. It demonstrated that the system worked.</p><p>Eric Mintz, who manages 25 Linux servers, says this ban has made him much more confident in the operating system’s security. “I have more trust in the process because this was caught,” he says. “There may be compromises we don’t know about. But because we caught this one, it’s less likely we don’t know about the other ones. Because we have something in place to catch it.”</p><p>To Scott, the fact that the researchers were caught and banned is an example of Linux’s system functioning exactly the way it’s supposed to. “This method worked,” he insists. “The <a href="https://www.theverge.com/2021/1/26/22248631/solarwinds-hack-cybersecurity-us-menn-decoder-podcast">SolarWinds</a> method, where there’s a big corporation behind it, that system didn’t work. This system did work.”</p><p>“Kernel developers are happy to see new tools created and — if the tools give good results — use them. They will also help with the testing of these tools, but they are less pleased to be recipients of tool-inspired patches that lack proper review,” Corbet writes. The community seems to be open to the University of Minnesota’s feedback — but as the Foundation has made clear, it’s on the school to make amends.</p><p>“The university could repair that trust by sincerely apologizing, and not fake apologizing, and by maybe sending a lot of beer to the right people,” Scott says. “It’s gonna take some work to restore their trust. So hopefully they’re up to it.”</p><div><p><span><strong>Follow topics and authors</strong> from this story to see more like this in your personalized homepage feed and to receive email updates.</span></p><ul><li id="follow-author-article_footer-dmcyOmF1dGhvclByb2ZpbGU6ODQ1Mw=="><span aria-expanded="false" aria-haspopup="true" role="button" tabindex="0"><span><span><svg width="9" height="9" viewBox="0 0 9 9" fill="none" xmlns="http://www.w3.org/2000/svg" aria-label="Follow"><path d="M5 0H4V4H0V5H4V9H5V5H9V4H5V0Z"></path></svg></span><span>Monica Chin</span></span></span></li><li></li><li></li><li></li></ul></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No management needed: anti-patterns in early-stage engineering teams (252 pts)]]></title>
            <link>https://www.ablg.io/blog/no-management-needed</link>
            <guid>46605854</guid>
            <pubDate>Tue, 13 Jan 2026 18:54:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ablg.io/blog/no-management-needed">https://www.ablg.io/blog/no-management-needed</a>, See on <a href="https://news.ycombinator.com/item?id=46605854">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section><p>January 10, 2026</p><article><p>This article is for early-stage (Seed, Series A) founders who think they have engineering management problems (<em>building eng teams, motivating and performance-managing engineers, structuring work/projects, prioritizing, shipping on time</em>).</p>
<p>The gist: if you <em>think</em> you have these problems, it is likely that the correct solution is to <strong>do nothing, to not manage, and to go back to building product and talking to users</strong>. Put another way, and having managed teams at all scales, I don’t think it’s a good use of your time as a founder to be "managing" engineers at such an early stage.</p>
<p>In the following sections, I'll go through the most typical anti-patterns I've seen, and try to highlight a better use of your time if you think you've hit the situation in question.</p>
<h2 id="do-not-try-to-motivate-your-engineers"><a href="#do-not-try-to-motivate-your-engineers"></a>Do not try to "motivate" your engineers</h2>
<p>A common concern of many founders is making sure that their engineers are working hard. This could mean putting in long hours, working more than competitors, completing heroic codebase rewrites, etc. When these external <em>signs of effort</em> seem to be missing, founders worry that the team is not "motivated", and it can be very tempting to treat symptoms over causes. For example:</p>
<ul>
<li>creating cultural norms around putting in long hours (996-style culture) by either requiring or celebrating them</li>
<li>scheduling recurring or non-urgent meetings on weekends (e.g. standup on Saturdays)</li>
<li>micro-managing tasks, or asking people for status reports and other evidence they worked hard</li>
</ul>
<p>These anti-patterns share one thing in common: they start with founders trying to actively <em>do something</em> to motivate the team. This has 2 consequences:</p>
<ol>
<li>This can cause the very engineers you want to retain (those who have many options) to self-select out of your engineering culture. I know several top 1% engineers in the Valley who disengage from recruiting processes when 996 or something similar is mentioned.</li>
<li>You are wasting your mental energy on the wrong problem</li>
</ol>
<p>All of this is a long way of saying that <strong>motivation is an inherent trait</strong> of great startup engineers. Your only job is to hire these engineers, and then to maintain an environment where they want to do their best work. And yes, at that point, you may see them working long hours and doing heroic actions you did not even think were possible.</p>
<blockquote>
<p>Motivation is a hired trait. The only place where managers motivate people is in management books.</p>
</blockquote>
<p>I'll dedicate a post to specific ways you can identify motivation during hiring, but in short, look for:</p>
<ul>
<li>the obvious one: evidence that they indeed exhibited these external signs of motivation (in an unforced way!) in past jobs</li>
<li>signs of grit in their career and life paths (how did they respond to adversity, how have they put their past successes or reputation on the line for some new challenge)</li>
<li>intellectual curiosity in the form of hobbies, nerdy interests that they can talk about with passion</li>
<li>bias for action and fast decision speed</li>
</ul>
<p>Finally, as a founder, you should definitely be the most motivated person, in an authentic way (maybe it's some piece of heroic coding, maybe it's taking 2am meetings with European customers, maybe it's something else unique to you). Cultivating your own inner motivation is the most effective way to set the tone for the team.</p>
<h2 id="do-not-hire-managers-too-soon"><a href="#do-not-hire-managers-too-soon"></a>Do not hire managers too soon</h2>
<p>The most obvious external sign that a startup has switched from building a product to building a company is to add management roles. When this switch happens prematurely, a lot of energy gets spent on stage-irrelevant problems.</p>
<p>By definition, an engineering manager needs to manage a team and projects, but if the team is still working on defining what they should be building, there is nothing to manage. Even the most intellectually honest manager will start outputting "management work", such as having 1:1s with everyone, doing some career coaching, applying order to the chaos of potential features by putting them in JIRA tickets or issues, etc. Here's what it means for you as a founder:</p>
<ul>
<li>you are still trying to find product-market fit and build your initial product</li>
<li>an engineering manager is helping you do it in a more optimized way, but they are optimizing a moving target so it does not really improve anything</li>
<li>you don't know if this engineering manager is bad at their job, or if the engineers are not performing, or if the product has no market anyway, or all of the above</li>
</ul>
<p>So how do you define "too soon"? Let's look at a few typical inflection points, assuming at least one founder is technical:</p>
<h3 id="the-founding-stage-5-6-engineers-including-founders"><a href="#the-founding-stage-5-6-engineers-including-founders"></a>The founding stage (5-6 engineers including founders)</h3>
<p>Obviously too soon to hire managers or turn someone into a manager. The only management-like tasks for the founders are hiring and firing, other than that the team should largely be self-organizing and self-sustaining with lightweight tooling (a simple doc can even be used as a task tracker, 1:1s happen organically and are infrequent, etc.).</p>
<p>In general, the bias should be towards doing nothing in terms of management and everything in terms of hiring exceptional people who inherently work well together.</p>
<h3 id="the-multi-team-stage-2-or-3-sub-teams-of-5-engineers-10-15-people-total"><a href="#the-multi-team-stage-2-or-3-sub-teams-of-5-engineers-10-15-people-total"></a>The multi-team stage (2 or 3 sub-teams of 5 engineers, 10-15 people total)</h3>
<p>This might be late seed or series A, with an inkling of a working product. Many teams will decide to implement management at this stage, because it seems like the natural next step. The decision is full of nuances, but I would strongly advise to have all the engineers still report into a single person (ideally the co-founder CTO). Why? Speed of execution and culture, mainly:</p>
<ul>
<li>at 15 engineers, it is very doable for a single person to keep track of everyone's work and ensure alignment.</li>
<li>this is the critical moment where you build the engineering culture that will bring you from here to hundreds of engineers (how do we hire, what do we value, how do we work together, etc.). It's much easier to do this as a flat team with a single leader.</li>
<li>pivots and radical decisions could still happen frequently, which will be exponentially harder if you have to manage these engineers through 2 or 3 line managers.</li>
</ul>
<p>The only nuance I would add, if you really need to start structuring the team, is to go with hybrid roles: maybe it's a very hands-on manager who still codes 70% of the time, maybe it's elevating a few key engineers into <em>informal</em> tech lead positions</p>
<h3 id="the-early-growth-stage-going-from-20-to-50-engineers"><a href="#the-early-growth-stage-going-from-20-to-50-engineers"></a>The early growth stage (going from 20 to 50 engineers)</h3>
<p>This is the sweet spot where the benefit of adding more management and more structure should outweigh the cost of letting the inevitable chaos of a larger team take a life of its own. Still, I would highly recommend a less-is-more approach.</p>
<p>Here are a few signs you've reached that stage:</p>
<ul>
<li>the CTO / whoever is managing everyone shows signs of burning out under the load</li>
<li>adding more engineers no longer increases output, meaning you are constrained by team inefficiency</li>
<li>the team excels at week-to-week impact, but nobody seems able to play out what will happen in 3 to 6 months</li>
</ul>
<p>This is a vast topic, and I'll dedicate a future article to that specific stage, including how to hire your first head of engineering.</p>
<h2 id="do-not-copy-google"><a href="#do-not-copy-google"></a>Do not copy Google</h2>
<p>This section addresses two sides of the same coin, both related to the <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Halo_effect">halo effect</a> surrounding great companies and more specifically their management practices:</p>
<ul>
<li>Applying management ideas that Google (or other successful company) have talked about and made popular</li>
<li>Applying the <em>meta-idea</em> of innovating in the field of management (like Google did in their time)</li>
</ul>
<p>I'll skip to the conclusion and explain it below:</p>
<blockquote>
<p>When in doubt, always pick the "node &amp; postgres" stack of management. Do not innovate, keep it boring.</p>
</blockquote>
<h3 id="what-i-mean-by-the-node-and-postgres-of-management"><a href="#what-i-mean-by-the-node-and-postgres-of-management"></a>What I mean by the "node &amp; postgres" of management</h3>
<p>Node &amp; postgres share these common traits: they have huge communities, their bugs and quirks have been explored by millions of people, and so they are great choices for early-stage startups compared to, say, C++ and OracleDB. No matter what you think about their technical merits, it would be very hard to point to them as a reason why a startup failed. They are just solid, boring tools, and they work at the early stage.</p>
<p>You should use the same type of boring, widely used, stage-appropriate tools when it comes to managing your startup. Every ounce of "innovation" you spend on your organizational structure, title philosophy, or new-age 1:1 is an ounce you aren't spending on your product. At the seed stage, your culture shouldn't be unique because of your clever peer feedback system, it should be unique because of the speed at which you solve customer problems.</p>
<h3 id="what-is-the-boring-stack-of-seed-stage-management"><a href="#what-is-the-boring-stack-of-seed-stage-management"></a>What is the boring stack of seed stage management</h3>
<p>As a conclusion to this section and to the entire article, I want to share, somewhat paradoxically, a few useful management activities specifically for the early stage. They almost all share the same "reluctant" approach to engineering management, which I think is a healthy leadership approach at that particular stage.</p>
<ul>
<li><strong>Hire inherently motivated people</strong>: see first section</li>
<li><strong>Don't manage around a hiring mistake</strong>, let them go quickly and gracefully</li>
<li><strong>Asynchronous status updates</strong>: do not adopt all the "Scrum rituals" like standups, retros, etc. wholesale, and if you do, keep them asynchronous. There is little added value to a voiced update, even if it makes you feel good that people are indeed working hard and showing up to the standup on time!</li>
<li><strong>An avoidant relationship to Slack</strong>: while Slack is a given in today's distributed or hybrid teams, it can quickly become an attention destroyer, especially for engineers who need uninterrupted time to work. Keep it in check.</li>
<li><strong>Organic 1:1s</strong> (as opposed to recurring ones): keep them topic-heavy and ad-hoc, as opposed to relationship maintenance like in the corporate world.</li>
<li><strong>Unstructured documents over systems of records</strong>: unless you need to itemize tasks for audit purposes, a few notion or google docs can actually scale for 10-15 engineers, especially given current AI tools. They have very little overhead and are unbeatable in terms of flexibility.</li>
<li><strong>Extreme transparency</strong>: give everyone access to everything (customer call notes, investor updates, budgets, etc.). Not only will you build trust with the team, but you will also remove the need to "communicate" (as in, filtering and processing information), which is a typical management task.</li>
</ul>
<p>To be clear, many of these practices do not scale past 20-25 engineers, but that's part of the point.</p>
<p>I hope you found this post actionable, good luck with building your team!</p></article></section><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Nogic – VS Code extension that visualizes your codebase as a graph (116 pts)]]></title>
            <link>https://marketplace.visualstudio.com/items?itemName=Nogic.nogic</link>
            <guid>46605675</guid>
            <pubDate>Tue, 13 Jan 2026 18:43:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marketplace.visualstudio.com/items?itemName=Nogic.nogic">https://marketplace.visualstudio.com/items?itemName=Nogic.nogic</a>, See on <a href="https://news.ycombinator.com/item?id=46605675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="vss_1">
<p><strong>Visualize your codebase structure with interactive diagrams</strong></p>
<p><a href="https://nogic.dev/" target="_blank" rel="noreferrer noopener nofollow"><img src="https://img.shields.io/badge/Website-nogic.dev-0066cc?logo=googlechrome&amp;logoColor=white" alt="Website"></a>
<a href="https://discord.gg/rXfZQXPc" target="_blank" rel="noreferrer noopener nofollow"><img src="https://img.shields.io/badge/Discord-Join_Us-5865F2?logo=discord&amp;logoColor=white" alt="Discord"></a></p>
<p><img src="https://rosfsmrtaygjjzoskzic.supabase.co/storage/v1/object/public/nogic/demo.gif" alt="Nogic Demo"></p>
<hr>
<h2 id="supported-languages">📦 Supported Languages</h2>
<p><a href="#" rel="noreferrer noopener nofollow"><img src="https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&amp;logo=javascript&amp;logoColor=000" alt="JavaScript"></a>
<a href="#" rel="noreferrer noopener nofollow"><img src="https://img.shields.io/badge/TypeScript-3178C6?style=for-the-badge&amp;logo=typescript&amp;logoColor=fff" alt="TypeScript"></a>
<a href="#" rel="noreferrer noopener nofollow"><img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&amp;logo=python&amp;logoColor=fff" alt="Python"></a></p>
<p>More languages and frameworks coming soon! 🎉</p>
<h2 id="getting-started">🚀 Getting Started</h2>
<ol>
<li>Open the Command Palette (<code>Cmd+Shift+P</code> / <code>Ctrl+Shift+P</code>)</li>
<li>Run <strong><code>Nogic: Open Visualizer</code></strong></li>
<li>Right-click files or folders in the Explorer and select <strong><code>Add to Nogic Board</code></strong></li>
</ol>
<p>Your codebase is automatically indexed when you open the visualizer, if given permission.</p>
<h2 id="features">✨ Features</h2>
<ul>
<li>🌲 <strong>Unified View</strong> — Browse files, classes, and functions in an interactive hierarchical graph</li>
<li>📋 <strong>Boards</strong> — Create custom boards to organize and focus on specific parts of your codebase</li>
<li>🎯 <strong>Class Diagrams</strong> — View class relationships, inheritance, and method structures</li>
<li>🔄 <strong>Call Graphs</strong> — Trace function calls and dependencies across your codebase</li>
<li>🔍 <strong>Quick Search</strong> — Find elements instantly with <code>Cmd/Ctrl+K</code></li>
<li>⚡ <strong>Auto-sync</strong> — Changes to your code are automatically reflected in the visualization</li>
</ul>
<h2 id="commands">📖 Commands</h2>
<table>
<thead>
<tr>
<th>Command</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Nogic: Open Visualizer</code></td>
<td>Open the interactive visualizer</td>
</tr>
<tr>
<td><code>Nogic: Create New Board</code></td>
<td>Create a new board</td>
</tr>
<tr>
<td><code>Add to Nogic Board</code></td>
<td>Add a file/folder to a board (right-click menu)</td>
</tr>
</tbody>
</table>
<h2 id="tips">💡 Tips</h2>
<ul>
<li>🖱️ Right-click files or folders in the Explorer to add them to a board</li>
<li>👆 Double-click nodes to open files in the editor</li>
<li>📂 Click nodes to expand and see methods</li>
<li>🖐️ Drag to pan, scroll to zoom</li>
</ul>
<hr>
<p>Made with ❤️ by the Nogic team • <a href="https://nogic.dev/" target="_blank" rel="noreferrer noopener nofollow">nogic.dev</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Let's be honest, Generative AI isn't going all that well (195 pts)]]></title>
            <link>https://garymarcus.substack.com/p/lets-be-honest-generative-ai-isnt</link>
            <guid>46605587</guid>
            <pubDate>Tue, 13 Jan 2026 18:37:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://garymarcus.substack.com/p/lets-be-honest-generative-ai-isnt">https://garymarcus.substack.com/p/lets-be-honest-generative-ai-isnt</a>, See on <a href="https://news.ycombinator.com/item?id=46605587">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>Some recent news, all long anticipated by this newsletter:</p><ol><li><p>LLMs can still cannot be trusted:</p></li></ol><ol start="2"><li><p><span>A large fraction of what LLMs do is mostly just memorization</span><em> </em><span>(and Hinton was on the wrong side of </span><a href="https://open.substack.com/pub/garymarcus/p/deconstructing-geoffrey-hintons-weakest?r=8tdk6&amp;utm_medium=ios&amp;shareImageVariant=overlay" rel="">this argument</a><span>)</span><em>:</em></p></li></ol><ol start="3"><li><p>They still aren’t adding a lot of quantifiable value to the world:</p></li></ol><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Vc9J!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c6f67d7-fc7d-4bbd-a881-42aa4f5d35df_900x1314.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Vc9J!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c6f67d7-fc7d-4bbd-a881-42aa4f5d35df_900x1314.png 424w, https://substackcdn.com/image/fetch/$s_!Vc9J!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c6f67d7-fc7d-4bbd-a881-42aa4f5d35df_900x1314.png 848w, https://substackcdn.com/image/fetch/$s_!Vc9J!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c6f67d7-fc7d-4bbd-a881-42aa4f5d35df_900x1314.png 1272w, https://substackcdn.com/image/fetch/$s_!Vc9J!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c6f67d7-fc7d-4bbd-a881-42aa4f5d35df_900x1314.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Vc9J!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c6f67d7-fc7d-4bbd-a881-42aa4f5d35df_900x1314.png" width="900" height="1314" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8c6f67d7-fc7d-4bbd-a881-42aa4f5d35df_900x1314.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1314,&quot;width&quot;:900,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:290336,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/184340736?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c6f67d7-fc7d-4bbd-a881-42aa4f5d35df_900x1314.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Vc9J!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c6f67d7-fc7d-4bbd-a881-42aa4f5d35df_900x1314.png 424w, https://substackcdn.com/image/fetch/$s_!Vc9J!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c6f67d7-fc7d-4bbd-a881-42aa4f5d35df_900x1314.png 848w, https://substackcdn.com/image/fetch/$s_!Vc9J!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c6f67d7-fc7d-4bbd-a881-42aa4f5d35df_900x1314.png 1272w, https://substackcdn.com/image/fetch/$s_!Vc9J!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c6f67d7-fc7d-4bbd-a881-42aa4f5d35df_900x1314.png 1456w" sizes="100vw"></picture></div></a><figcaption>via newsletter</figcaption></figure></div><p><em><span>Update: This is consistent with the finding of the</span><a href="https://arxiv.org/abs/2510.26787" rel=""> Remote Labor Index</a><span> that AI could only do about 2.5% of jobs,</span><a href="https://www.washingtonpost.com/technology/interactive/2026/ai-jobs-automation/" rel=""> reported recently by the Washington Post</a><span>.</span></em></p><ol start="4"><li><p>Scaling isn’t going all that well, anymore, and probably won’t cure these problems.</p></li></ol><p>Trying to orient our economy and geopolitical policy around such shoddy technology — particularly on the unproven hopes that it will dramatically improve– is a mistake.</p></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Signal leaders warn agentic AI is an insecure, unreliable surveillance risk (331 pts)]]></title>
            <link>https://coywolf.com/news/productivity/signal-president-and-vp-warn-agentic-ai-is-insecure-unreliable-and-a-surveillance-nightmare/</link>
            <guid>46605553</guid>
            <pubDate>Tue, 13 Jan 2026 18:35:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://coywolf.com/news/productivity/signal-president-and-vp-warn-agentic-ai-is-insecure-unreliable-and-a-surveillance-nightmare/">https://coywolf.com/news/productivity/signal-president-and-vp-warn-agentic-ai-is-insecure-unreliable-and-a-surveillance-nightmare/</a>, See on <a href="https://news.ycombinator.com/item?id=46605553">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<article id="top">
				
				<p>With agentic AI embedded at the OS level, databases storing entire digital lives accessible to malware, tasks whose reliability quickly breaks down at each step, and being opted-in without consent, Signal leadership is sounding the alarm for the industry to pull back until threats can be mitigated.</p>				
				
<p>At the <a href="https://events.ccc.de/congress/2025/">39th Chaos Communication Congress</a> (39C3) in Hamburg, Germany, Signal President <a href="https://en.wikipedia.org/wiki/Meredith_Whittaker">Meredith Whittaker</a> and VP of Strategy and Global Affairs <a href="https://www.linkedin.com/in/udbhav-tiwari-b4919839/">Udbhav Tiwari</a> gave a presentation titled <a href="https://media.ccc.de/v/39c3-ai-agent-ai-spy#t=2374">AI Agent, AI Spy</a>. In it, they shared the many vulnerabilities and concerns they have about how agentic AI is being implemented, the very real threat it’s bringing to enterprise companies, and how they recommend the industry change to mitigate a disaster in the making.</p>



<figure>

<figcaption>“AI Agent, AI Spy” presented by Meredith Whittaker and Udbhav Tiwari at <abbr title="39th Chaos Communication Congress">39C3</abbr> – <a href="https://creativecommons.org/licenses/by/4.0/"><abbr title="Creative Commons">CC</abbr> BY 4.0</a></figcaption>
</figure>





<p>A key component of AI agents is that they must know enough about you and have access to sensitive data so that they can autonomously take actions on your behalf, such as making purchases, scheduling events, and responding to messages. However, <strong>the way AI agents are being implemented is making them insecure, unreliable, and open to surveillance</strong>.</p>



<h2 id="h-how-ai-agents-are-vulnerable-to-threats">How AI agents are vulnerable to threats</h2>



<p>Microsoft is trying to bring agentic AI to its Windows 11 users via <a href="https://en.wikipedia.org/wiki/Windows_Recall">Recall</a>. Recall takes a screenshot of your screen every few seconds, OCRs the text, and does semantic analysis of the context and actions. It then creates a forensic dossier of everything you do into a single database on your computer. The database includes a precise timeline of actions, full raw text (via OCR), dwell time, and focus on specific apps and actions. Additionally, it assigns topics to specific activities.</p>



<p><strong>Tiwari says the problem with this approach is that it doesn’t mitigate the threat of malware (via online attacks) and indirect (hidden) prompt injection attacks, which can all gain access to the database.</strong> These vulnerabilities subsequently circumvent end-to-end encryption (E2EE), prompting Signal to add a flag in its app to prevent its screen from being recorded, but Tiwari says that’s not a reliable or long-term solution.</p>



<h2 id="h-why-complex-agentic-tasks-aren-t-reliable">Why complex agentic tasks aren’t reliable</h2>



<p>Whittaker emphasized that agentic AI isn’t just intrusive and vulnerable to threats; it’s also unreliable. She said <strong>AI agents are probabilistic, not deterministic, and that each step they take in a task degrades their accuracy and the final action</strong>.</p>



<p>She said if an AI agent could perform each step with 95% accuracy–which currently isn’t possible–a 10-step task would yield an action with a ~59.9% success rate. And if you had a 30-step task, the success rate would be ~21.4%. Furthermore, if we used a more realistic accuracy rate of 90%, then a 30-step task would drop down to a success rate of 4.2%. She added that <strong>the best agent models failed 70% of the time</strong>.</p>



<h2 id="h-how-to-make-ai-agents-private-and-secure">How to make AI agents private and secure</h2>



<p><strong>Whittaker said there currently isn’t a solution for making AI agents preserve privacy, security, and control; there’s only triage</strong>, but companies can take steps now to mitigate it.</p>



<ol>
<li>Stop the reckless deployment of AI agents to avoid plain-text database access to malware.</li>



<li>Make opting out the default, with mandatory developer opt-ins.</li>



<li>AI companies must provide radical (or any) transparency about how everything works and make it auditable at the granular level.</li>
</ol>



<p>If the industry doesn’t heed Whittaker’s and Tiwari’s warnings, the age of agentic AI could be in jeopardy, primarily because consumers could quickly lose their trust in a technology that is already overhyped and over-invested in.</p>
									
				
									
					
												
				<div>
					<p><img alt="Headshot for Jon Henshaw" src="https://coywolf.com/wp-content/uploads/2025/06/b23d2a8517f1c253b8b922857a9bd192be8e87a3008ab90ac57c32e4cb382584-150x150.jpeg" srcset="https://coywolf.com/wp-content/uploads/2025/06/b23d2a8517f1c253b8b922857a9bd192be8e87a3008ab90ac57c32e4cb382584.jpeg 2x" height="120" width="120" decoding="async">	            	</p>
					<div>
						<p><strong><a rel="author" href="https://coywolf.com/jon-henshaw/">Jon Henshaw</a></strong></p>
						<p><small>Jon Henshaw is the founder of <a href="https://coywolf.com/">Coywolf</a> and an industry veteran with almost three decades of <abbr title="Search Engine Optimization">SEO</abbr>, digital marketing, and web technologies experience. Follow <a rel="noopener author" target="_blank" onclick="window.open(this.href); return false;" onkeypress="window.open(this.href); return false;" href="https://henshaw.social/@jon">@jon@henshaw.social</a></small></p>
					</div>
				</div>				

							</article>
			
						
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Generated Music Barred from Bandcamp (849 pts)]]></title>
            <link>https://old.reddit.com/r/BandCamp/comments/1qbw8ba/ai_generated_music_on_bandcamp/</link>
            <guid>46605490</guid>
            <pubDate>Tue, 13 Jan 2026 18:31:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/BandCamp/comments/1qbw8ba/ai_generated_music_on_bandcamp/">https://old.reddit.com/r/BandCamp/comments/1qbw8ba/ai_generated_music_on_bandcamp/</a>, See on <a href="https://news.ycombinator.com/item?id=46605490">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Happy New Year, <a href="https://old.reddit.com/r/bandcamp">r/bandcamp</a>!</p>

<p>Hope you all enjoyed the Holiday Guide (<a href="http://bandcamp.com/2025">bandcamp.com/2025</a>) and your 2025 Bandcamp recaps.</p>

<p>Something that always strikes us as we put together a roundup like this is the sheer quantity of human creativity and passion that artists express on Bandcamp every single day. The fact that Bandcamp is home to such a vibrant community of real people making incredible music is something we want to protect and maintain.    </p>

<p>Today, in line with that goal, we’re articulating our policy on generative AI. We want musicians to keep making music, and for fans to have confidence that the music they find on Bandcamp was created by humans.</p>

<p>Our guidelines for generative AI in music and audio are as follows:</p>

<ul>
<li>Music and audio that is generated wholly or in substantial part by AI is <strong>not permitted</strong> on Bandcamp.&nbsp;</li>
<li>Any use of AI tools to impersonate other artists or styles is <strong>strictly prohibited</strong> in accordance with our existing policies prohibiting impersonation and intellectual property infringement.</li>
</ul>

<p>If you encounter music or audio that appears to be made entirely or with heavy reliance on generative AI, please use our reporting tools to flag the content for review by our team<strong>. We reserve the right to remove any music on suspicion of being AI generated.</strong></p>

<p>We will be sure to communicate any updates to the policy as the rapidly changing generative AI space develops. Given the response around this to our previous posts, we hope this news is welcomed. We wish you all an amazing 2026.</p>

<p>Thank you.</p>

<p>Bandcamp Support</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The truth behind the 2026 J.P. Morgan Healthcare Conference (247 pts)]]></title>
            <link>https://www.owlposting.com/p/the-truth-behind-the-2026-jp-morgan</link>
            <guid>46605332</guid>
            <pubDate>Tue, 13 Jan 2026 18:22:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.owlposting.com/p/the-truth-behind-the-2026-jp-morgan">https://www.owlposting.com/p/the-truth-behind-the-2026-jp-morgan</a>, See on <a href="https://news.ycombinator.com/item?id=46605332">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!lWP8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc78ed1c-c69b-4c4a-9665-dd9f856bcf6e_2912x1632.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!lWP8!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc78ed1c-c69b-4c4a-9665-dd9f856bcf6e_2912x1632.png 424w, https://substackcdn.com/image/fetch/$s_!lWP8!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc78ed1c-c69b-4c4a-9665-dd9f856bcf6e_2912x1632.png 848w, https://substackcdn.com/image/fetch/$s_!lWP8!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc78ed1c-c69b-4c4a-9665-dd9f856bcf6e_2912x1632.png 1272w, https://substackcdn.com/image/fetch/$s_!lWP8!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc78ed1c-c69b-4c4a-9665-dd9f856bcf6e_2912x1632.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!lWP8!,w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc78ed1c-c69b-4c4a-9665-dd9f856bcf6e_2912x1632.png" width="1200" height="672.5274725274726" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cc78ed1c-c69b-4c4a-9665-dd9f856bcf6e_2912x1632.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:816,&quot;width&quot;:1456,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:7187804,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.owlposting.com/i/178015385?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc78ed1c-c69b-4c4a-9665-dd9f856bcf6e_2912x1632.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:&quot;center&quot;,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!lWP8!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc78ed1c-c69b-4c4a-9665-dd9f856bcf6e_2912x1632.png 424w, https://substackcdn.com/image/fetch/$s_!lWP8!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc78ed1c-c69b-4c4a-9665-dd9f856bcf6e_2912x1632.png 848w, https://substackcdn.com/image/fetch/$s_!lWP8!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc78ed1c-c69b-4c4a-9665-dd9f856bcf6e_2912x1632.png 1272w, https://substackcdn.com/image/fetch/$s_!lWP8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcc78ed1c-c69b-4c4a-9665-dd9f856bcf6e_2912x1632.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><em><span>Note: I am co-hosting </span><a href="https://luma.com/yklbzuqc" rel="">an event in SF on Friday, Jan 16th</a><span>.</span></em></p><p><span>In 1654, a Jesuit polymath named </span><em><a href="https://en.wikipedia.org/wiki/Athanasius_Kircher" rel="">Athanasius Kircher</a></em><span> published </span><em><a href="https://en.wikipedia.org/wiki/Mundus_Subterraneus" rel="">Mundus Subterraneus</a></em><span>, a comprehensive geography of the Earth’s interior. It had maps and illustrations and rivers of fire and vast subterranean oceans and air channels connecting every volcano on the planet. He wrote that “</span><em><a href="https://publicdomainreview.org/essay/athanasius-underground/" rel="">the whole Earth is not solid but everywhere gaping, and hollowed with empty rooms and spaces, and hidden burrows.</a></em><span>”. Alongside comments like this, </span><em>Athanasius</em><span> identified the legendary lost island of Atlantis, pondered where one could find the remains of giants, and detailed the kinds of animals that lived in this lower world, including dragons. The book was based entirely on secondhand accounts, like travelers tales, miners reports, classical texts, so it was as comprehensive as it could’ve possibly been. </span></p><p><span>But </span><em>Athanasius</em><span> had never been underground and neither had anyone else, not really, not in a way that mattered. </span></p><p><span>Today, I am in San Francisco, the site of the 2026 J.P. Morgan Healthcare Conference, and it feels a lot like </span><em>Mundus Subterraneus</em><span>.</span></p><p><span>There is ostensibly plenty of evidence to believe that the conference exists, that it actually occurs between January 12, 2026 to January 16, 2026 at the </span><a href="https://en.wikipedia.org/wiki/Westin_St._Francis" rel="">Westin St. Francis Hotel</a><span>, 335 Powell Street, San Francisco, and that it has done so for the last forty-four years, just like everyone has told you. There is a </span><a href="https://jpmannualhealthcareconference.com/" rel="">website</a><span> for it, there are articles about it, there are dozens of AI-generated posts on Linkedin about how excited people were about it. But I have never met anyone who has actually been </span><em>inside</em><span> the conference. </span></p><p><span>I have never been approached by one, or seated next to one, or introduced to one. They do not appear in my life. They do not appear in anyone’s life that I know. I have put my boots on the ground to rectify this, and asked around, first casually and then less casually, “</span><em>Do you know anyone who has attended the JPM conference?</em><span>”, and then they nod, and then I refine the question to be, “</span><em>No, no, like, someone who has actually been in the physical conference space</em><span>”, then they look at me like I’ve asked if they know anyone who’s been to the moon. They know it happens. They assume someone goes. Not them, because, just like me, ordinary people like them do not go to the moon, but rather exist around the moon, having coffee chats and organizing little parties around it, all while trusting that the moon is being attended to.</span></p><p><a href="https://jpmannualhealthcareconference.com/" rel="">The conference has six focuses: </a><em>AI in Drug Discovery and Development, AI in Diagnostics, AI for Operational Efficiency, AI in Remote and Virtual Healthcare, AI and Regulatory Compliance</em><span>, and </span><em>AI Ethics and Data Privacy. </em><span>There is also a seventh theme over ‘</span><em>Keynote Discussions</em><span>’, the three of which are </span><em>The Future of AI in Precision Medicine</em><span>, </span><em>Ethical AI in Healthcare</em><span>, and </span><em>Investing in AI for Healthcare. </em><span>Somehow, every single thematic concept at this conference has converged onto artificial intelligence as the only thing worth seriously discussing.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!_Yfq!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8d65dc-907f-41fb-bda4-2bfc815b24c9_2012x1290.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!_Yfq!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8d65dc-907f-41fb-bda4-2bfc815b24c9_2012x1290.png 424w, https://substackcdn.com/image/fetch/$s_!_Yfq!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8d65dc-907f-41fb-bda4-2bfc815b24c9_2012x1290.png 848w, https://substackcdn.com/image/fetch/$s_!_Yfq!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8d65dc-907f-41fb-bda4-2bfc815b24c9_2012x1290.png 1272w, https://substackcdn.com/image/fetch/$s_!_Yfq!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8d65dc-907f-41fb-bda4-2bfc815b24c9_2012x1290.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!_Yfq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8d65dc-907f-41fb-bda4-2bfc815b24c9_2012x1290.png" width="1456" height="934" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7a8d65dc-907f-41fb-bda4-2bfc815b24c9_2012x1290.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:934,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:353633,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.owlposting.com/i/178015385?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8d65dc-907f-41fb-bda4-2bfc815b24c9_2012x1290.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!_Yfq!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8d65dc-907f-41fb-bda4-2bfc815b24c9_2012x1290.png 424w, https://substackcdn.com/image/fetch/$s_!_Yfq!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8d65dc-907f-41fb-bda4-2bfc815b24c9_2012x1290.png 848w, https://substackcdn.com/image/fetch/$s_!_Yfq!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8d65dc-907f-41fb-bda4-2bfc815b24c9_2012x1290.png 1272w, https://substackcdn.com/image/fetch/$s_!_Yfq!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a8d65dc-907f-41fb-bda4-2bfc815b24c9_2012x1290.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Isn’t this strange? Surely, you must feel the same thing as me, the inescapable suspicion that the whole show is being put on by an unconscious Chinese Room, its only job to pass over semi-legible symbols over to us with no regards as to what they actually mean. In fact, this pattern is consistent across not only how the conference communicates itself, but also how biopharmaceutical news outlets discuss it. </p><p><span>Each year, </span><a href="https://endpoints.news/" rel="">Endpoints News</a><span> and </span><a href="https://www.statnews.com/" rel="">STAT</a><span> and </span><a href="https://www.biocentury.com/home" rel="">BioCentury</a><span> and </span><a href="https://www.fiercepharma.com/" rel="">FiercePharma</a><span> all publish extensive coverage of the J.P. Morgan Healthcare Conference. I have read the articles they have put out, and none of it feels like it was written by someone who actually was at the event</span><strong>. </strong><span>There is no emotional energy, no personal anecdotes, all of it has been removed, shredded into one homogeneous, smoothie-like texture. The coverage contains phrases like “</span><em>pipeline updates</em><span>” and “</span><em>strategic priorities</em><span>” and “</span><em>catalysts expected in the second half</em><span>.” If the writers of these articles ever approach a human-like tenor, it is in reference to the conference’s “</span><em>tone</em><span>”. The tone is “</span><em>cautiously optimistic</em><span>.” The tone is “</span><em>more subdued than expected</em><span>.” The tone is “</span><em>mixed</em><span>.” What does this mean? What is a mixed tone? What is a cautiously optimistic tone? These are not descriptions of a place. They are more accurately descriptions of a sentiment, abstracted from any physical reality, hovering somewhere above the conference like a weather system.</span></p><p><span>I could write this coverage. I could write it from my horrible apartment in New York City, without attending anything at all. I could say: “</span><em>The tone at this year’s J.P. Morgan Healthcare Conference was cautiously optimistic, with executives expressing measured enthusiasm about near-term catalysts while acknowledging macroeconomic headwinds</em><span>.” I made that up in fifteen seconds. Does it sound fake? It shouldn’t, because it sounds exactly like the coverage of a supposedly real thing that has happened every year for the last forty-four years. </span></p><p><span>Speaking of the astral body I mentioned earlier, there is an interesting historical parallel to draw there. In 1835, the </span><a href="https://www.nysun.com/" rel="">New York Sun</a><span> published a series of articles claiming that the astronomer </span><a href="https://en.wikipedia.org/wiki/John_Herschel" rel="">Sir John Herschel</a><span> had discovered life on the moon. Bat-winged humanoids, unicorns, temples made of sentient sapphire, that sort of stuff. The articles were detailed, describing not only these creatures appearance, but also their social behaviors and mating practices. All of these cited Herschel’s observations through a powerful new telescope. The series was a sensation. It was also, obviously, a hoax, the </span><a href="https://en.wikipedia.org/wiki/Great_Moon_Hoax" rel="">Great Moon Hoax</a><span> as it came to be known. Importantly, the hoax worked not because the details were plausible, but because they had the energy of genuine reporting: Herschel was a real astronomer, and telescopes were real, and the moon was real, so how could any combination that involved these three be fake?</span></p><p>To clarify: I am not saying the J.P. Morgan Healthcare Conference is a hoax. </p><p>What I am saying is that I, nor anybody, can tell the difference between the conference coverage and a very well-executed hoax. Consider that the Great Moon Hoax was walking a very fine tightrope between giving the appearance of seriousness, while also not giving away too many details that’d let the cat out of the bag. Here, the conference rhymes. </p><p>For example: photographs. You would think there would be photographs. The (claimed) conference attendees number in the thousands, many of them with smartphones, all of them presumably capable of pointing a camera at a thing and pressing a button. But the photographs are strange, walking that exact snickering line that the New York Sun walked. They are mostly photographs of the outside of the Westin St. Francis, or they are photographs of people standing in front of step-and-repeat banners, or they are photographs of the schedule, displayed on a screen, as if to prove that the schedule exists. But photographs of the inside with the panels, audience, the keynotes in progress; these are rare. And when I do find them, they are shot from angles that reveal nothing, that could be anywhere, that could be a Marriott ballroom in Cleveland.</p><p><span>Is this a conspiracy theory? You can call it that, but I have a very professional online presence, so I personally wouldn’t. In fact, I wouldn’t even say that the  J.P. Morgan Healthcare Conference is not real, but rather that it is </span><em>real</em><span>, but not actually </span><em>materially</em><span> real. </span></p><p><span>To explain what I mean, we can rely on economist </span><a href="https://en.wikipedia.org/wiki/Thomas_Schelling" rel="">Thomas Schelling</a><span> to help us out. Sixty-six years ago, Schelling proposed a thought experiment: if you had to meet a stranger in New York City on a specific day, with no way to communicate beforehand, where would you go? The answer, for most people, is Grand Central Station, at noon. Not because Grand Central Station is special. Not because noon is special. But because everyone knows that everyone </span><strong>else</strong><span> knows that Grand Central Station at noon is the obvious choice, and this mutual knowledge of mutual knowledge is enough to spontaneously produce coordination out of nothing. This, Grand Central Station and places just like it, are what’s known as a </span><a href="https://en.wikipedia.org/wiki/Focal_point_(game_theory)" rel="">Schelling point</a><span>. </span></p><p>Schelling points appear when they are needed, burnt into our genetic code, Pleistocene subroutines running on repeat, left over from when we were small and furry and needed to know, without speaking, where the rest of the troop would be when the leopards came. The J.P. Morgan Healthcare Conference, on the second week of January, every January, Westin St. Francis, San Francisco, is what happened when that ancient coordination instinct was handed an industry too vast and too abstract to organize by any other means. Something deep drives us to gather here, at this time, at this date. </p><p>To preempt the obvious questions: I don’t know why this particular location or time or demographic were chosen. I especially don’t know why J.P. Morgan of all groups was chosen to organize the whole thing. All of this simply is. </p><p>If you find any of this hard to believe, observe that the whole event is, structurally, a religious pilgrimage, and has all the quirks you may expect of a religious pilgrimage. And I don’t mean that as a metaphor, I mean it literally, in every dimension except the one where someone official admits it, and J.P. Morgan certainly won’t. </p><p>Consider the elements. A specific place, a specific time, an annual cycle, a journey undertaken by the faithful, the presence of hierarchy and exclusion, the production of meaning through ritual rather than content. The hajj requires Muslims to circle the Kaaba seven times. The J.P. Morgan Healthcare Conference requires devotees of the biopharmaceutical industry to slither into San Francisco for five days, nearly all of them—in my opinion, all of them—never actually entering the conference itself, but instead orbiting it, circumambulating it, taking coffee chats in its gravitational field. The Kaaba is a cube containing, according to tradition, nothing, an empty room, the holiest empty room in the world. The Westin St. Francis is also, roughly, a cube. I am not saying these are the same thing. I am saying that we have, as a species, a deep and unexamined relationship to cubes. </p><p>This is my strongest theory so far. That the J.P. Morgan Healthcare conference isn’t exactly real or unreal, but a mass-coordination social contract that has been unconsciously signed by everyone in this industry, transcending the need for an underlying referent. </p><p>My skeptical readers will protest at this, and they would be correct to do so. The story I have written out is clean, but it cannot be fully correct. Thomas Schelling was not so naive as to believe that Schelling points spontaneously generate out of thin air, there is always a reason, a specific, grounded reason, that their concepts become the low-energy metaphysical basins that they are. Grand Central Station is special because of the cultural gravitas it has accumulated through popular media. Noon is special because that is when the sun reaches its zenith. The Kaaba was worshipped because it was not some arbitrary cube; the cube itself was special, that it contained The Black Stone, set into the eastern corner, a relic that predates Islam itself, that some traditions claim fell from heaven.</p><p><span>And there are signs, if you know where to look, that the underlying referent for the Westin St. Francis status being a gathering area is </span><strong>physical</strong><span>. Consider the heat. It is January in San Francisco, usually brisk, yet the interior of the Westin St. Francis maintains a distinct, humid microclimate. Consider the low-frequency vibration in the lobby that ripples the surface of water glasses, but doesn’t seem to register on local, public seismographs. There is something about the building itself that feels distinctly alien. But, upon standing outside the building for long enough, you’ll have the nagging sensation that it is not something about the hotel that feels off, but rather, what lies within, underneath, and around the hotel. </span></p><p>There’s no easy way to sugarcoat this, so I’ll just come out and say it: it is possible that the entirety of California is built on top of one immensely large organism, and the particular spot in which the Westin St. Francis Hotel stands—335 Powell Street, San Francisco, 94102—is located directly above its beating heart. And that this is the primary organizing focal point for both the location and entire reason for the J.P. Morgan Healthcare Conference. </p><p><span>I believe that the hotel maintains dozens of meter-thick polyvinyl chloride plastic tubes that have been threaded down through the basement, through the bedrock, through geological strata, and into the cardiovascular system of something that has been lying beneath the Pacific coast since before the Pacific coast existed. That the hotel is a singular, thirty-two story </span><a href="https://en.wikipedia.org/wiki/Central_venous_catheter" rel="">central line.</a><span> That, during the week of the conference, hundreds of gallons of drugs flow through these tubes, into the pulsating mass of the being, pouring down arteries the size of canyons across California. The dosing takes five days; hence the length of the conference.</span></p><p>And I do not believe that the drugs being administered here are simply sedatives. They are, in fact, the opposite of sedatives. The drugs are keeping the thing beneath California alive. There is something wrong with the creature, and a select group of attendees at the J.P. Morgan Healthcare Conference have become its primary caretakers. </p><p>Why? The answer is obvious: there is nothing good that can come from having an organic creature that spans hundreds of thousands of square miles suddenly die, especially if that same creatures mass makes up a substantial portion of the fifth-largest economy on the planet, larger than India, larger than the United Kingdom, larger than most countries that we think of as significant. Maybe letting the nation slide off into the sea was an option at one point, but not anymore. California produces more than half of the fruits, vegetables, and nuts grown in the United States. California produces the majority of the world’s entertainment. California produces the technology that has restructured human communication. Nobody can afford to let the whole thing collapse. </p><p>So, perhaps it was decided that California must survive, at least for as long as possible. Hence Amgen. Hence Genentech. Hence the entire biotech revolution, which we are taught to understand as a triumph of science and entrepreneurship, a story about venture capital and recombinant DNA and the genius of the California business climate. The story is not false, but incomplete. The reason for the revolution was, above all else, because the creature needed medicine, and the old methods of making medicine were no longer adequate, and someone decided that the only way to save the patient was to create an entire industry dedicated to its care. </p><p>Why is drug development so expensive? Because the real R&amp;D costs are for the primary patient, the being underneath California, and human applications are an afterthought, a way of recouping investment. Why do so many clinical trials fail? For the same reason; the drugs are not meant for our species. Why is the industry concentrated in San Francisco, San Diego, Boston? Because these are monitoring stations, places where other intravenous lines have been drilled into other organs, other places where the creature surfaces close enough to reach. </p><p><span>Finally, consider the hotel itself. The </span><a href="https://en.wikipedia.org/wiki/Westin_St._Francis" rel="">Westin St. Francis was built in 1904</a><span>, and, throughout its entire existence, it has never, ever, even once, closed or stopped operating. The </span><a href="https://en.wikipedia.org/wiki/1906_San_Francisco_earthquake" rel="">1906 earthquake </a><span>leveled most of San Francisco, and the Westin St. Francis did not fall. It was damaged, yes, but it did not fall. The </span><a href="https://en.wikipedia.org/wiki/1989_Loma_Prieta_earthquake" rel="">1989 Loma Prieta earthquake</a><span> killed sixty-three people and collapsed a section of the Bay Bridge. Still, the Westin St. Francis did not fall. It cannot fall, because if it falls, the central line is severed, and if the central line is severed, the creature dies, and if the creature dies, we lose California, and if we lose California, our civilization loses everything that California has been quietly holding together. And so the Westin St. Francis has hosted every single J.P. Morgan Healthcare Conference since 1983, has never missed one, has never even come close to missing one, and will not miss the next one, or the one after that, or any of the ones that follow.</span></p><p><span>If you think about it, this all makes a lot of sense. It may also seem very unlikely, but unlikely things have been known to happen throughout history. </span><em>Mundus Subterraneus</em><span> had a section on the “</span><em>seeds of metals</em><span>,” a theory that gold and silver grew underground like plants, sprouting from mineral seeds in the moist, oxygen-poor darkness. This was wrong, but the intuition beneath it was not entirely misguided. We now understand that the Earth’s mantle is a kind of eternal engine of astronomical size, cycling matter through subduction zones and volcanic systems, creating and destroying crust. </span><em>Athanasius</em><span> was wrong about the mechanism, but right about the structure. The earth is not solid. It is everywhere gaping, hollowed with empty rooms, and it is alive.</span></p></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to make a damn website (2024) (197 pts)]]></title>
            <link>https://lmnt.me/blog/how-to-make-a-damn-website.html</link>
            <guid>46604250</guid>
            <pubDate>Tue, 13 Jan 2026 17:23:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lmnt.me/blog/how-to-make-a-damn-website.html">https://lmnt.me/blog/how-to-make-a-damn-website.html</a>, See on <a href="https://news.ycombinator.com/item?id=46604250">Hacker News</a></p>
<div id="readability-page-1" class="page">
		<header>
			
			
			
		</header>
		<p>A lot of people want to make a website but don’t know where to start or they get stuck. That’s in part because our perception of what websites <strong>should be</strong> has changed so dramatically over the last 20 years.</p>
		<hr>
		<h2>The “Hard” Way</h2>
		<p>It’s easy to forget how simple a website <strong>can</strong> be. A website can be just <strong>one page</strong>. It doesn’t even need CSS. You don’t need a content management system like <em>Wordpress</em>. All you have to do is write some HTML and drag that file to a server over FTP.</p>
		<p>For years now, people have tried to convince us that this is the “hard” way of making a website, but in reality, it may be the easiest.</p>
		<p>It doesn’t have to be super complicated. However, with this post, I will assume you’ve written at least some HTML and CSS before, and that you know how to upload files to a server. If you’ve never done these things, it may seem like I’m skipping over some things. I am.</p>
		<hr>
		<h2>Baby’s First HTML</h2>
		<p>Let me begin with what I think you <strong>shouldn’t</strong> start with. Don’t shop around for a CMS. Don’t even design or outline your website. Don’t buy a domain or hosting yet. Don’t set up a <em>GitHub</em> repository; I don’t care how fast you can make one.</p>
		<p>Instead, <strong>just write your first blog post</strong>. The very first thing I did was open <em>TextEdit</em> and write <a href="https://lmnt.me/blog/teenage-web.html">my first post</a> with HTML, <strong>ye olde way</strong>. Not with <em>Markdown</em>. Not with <em><a href="https://nova.app/">Nova</a></em> or <em><a href="http://www.barebones.com/products/bbedit/index.html">BBEdit</a></em> or another code editor. Just <em>TextEdit</em> <small>(in plain text)</small>. Try it, even if just this once. It’s kinda refreshing. You can go back to using a code editor later.</p>
		<p>Here’s what a draft of this blog post looks like:</p>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
	&lt;head&gt;
		&lt;meta charset="utf-8"&gt;
		&lt;title&gt;How to Make a Damn Website&lt;/title&gt;
	&lt;/head&gt;
	&lt;body&gt;

		&lt;h1&gt;&lt;a href="how-to-make-a-damn-website.html"&gt;How to Make a Damn Website&lt;/a&gt;&lt;/h1&gt;
		&lt;p&gt;A lot of people want to make a website but don’t know where to start or they get stuck.&lt;/p&gt;

	&lt;/body&gt;
&lt;/html&gt;</code></pre>
		<p>This is honestly all you need. It’s kind of charming.</p>
		<p>Make sure you rely exclusively on HTML elements for your formatting. Your page should render clearly with raw HTML. Do not let yourself get distracted by writing CSS. Don’t even imagine the CSS you’ll use later. Don’t write in IDs or classes yet. Do yourself a favor and don’t make a single <code>div</code> element.</p>
		<p>Just write the post in the <strong>plainest HTML</strong>. And don’t you dare write a “Hello World” post or a “Lorem Ipsum” post. Write an <strong>actual blog post</strong>. If you want, make it about why you’re making a website.</p>
		<p>Writing this way helps you stay focused on writing <strong>for the web</strong>. The most important thing here is <strong>shipping something</strong>. You can <small>(and should)</small> update your site later. Now, name the HTML file something sensible, like the post name.</p>
		<pre><code>how-to-make-a-damn-website.html</code></pre>
		<p>Finished? Great. If you have a domain and hosting, make a new folder on your server called <strong>blog</strong> and upload your first post in there. Don’t worry about index pages yet. You have only one post, there’s not much to index. We’ll get there.</p>
		<p>If you <strong>don’t</strong> have a domain or hosting yet, now’s the time to buckle down and do that. Unfortunately, I don’t have good advice for you here. Just know that it’s going to be stupid and tedious and bad and unfun. That’s just the way this is.</p>
		<p>Try not to let it deter you. Once you have the ability to upload files to an FTP server, you’ve reached the “set it and forget it” phase.</p>
		<p>Direct your web browser to the HTML file you uploaded. <strong>Wow!</strong> There it is. A real, actual page on the web! You shipped it. Congratulations. Times New Roman, black on white. Hyperlinks that are blue and underlined. Useful. Classic.</p>
		<p>Look at your unstyled HTML page and appreciate it for what it is. Always remember, <strong>this is all a website has to be</strong>. Good websites can be reduced to this and still work.</p>
		<p><strong>A broken escalator is just stairs.</strong> Even if it’s a little less convenient, it remains <strong>functional</strong>. This is important.</p>
		<p>If you get this far, I want you to know <strong>this is truly the hardest part</strong>. Some people will ignore what I’ve said. They will spend significant time designing a website, hunting around for a good CMS, doing a wide variety of busywork, neglecting the part where they write actual content for their site. But if you shipped a single blog post, <strong>you have a website</strong>, and <strong>they don’t</strong>.</p>
		<p>A website is <strong>nothing</strong> without content. You can spend months preparing to make a website, tacking up what I’m sure was intended to be a “temporary” page telling people that you’re “working on a new website,” but it will inevitably become a permanent reminder that you haven’t done it yet. So focus on what matters, and ship <strong>one blog post</strong>. Do the rest later.</p>
		<hr>
		<h2>Really Simple Syndication</h2>
		<p>You may think CSS is the next logical step, or maybe an index page, but I don’t think so. It takes only a few minutes to <strong>hand-write an XML file</strong>, and once it’s done, people will be able to read your blog via an RSS reader.</p>
		<p>On your site, <strong>you’re in control of publishing now</strong>. When you post to your blog, part of the process is syndicating it to those who want to stay updated. If you provide an RSS feed, people can follow it. If you don’t, they can’t.</p>
		<p><strong>While the best time to make an RSS feed was 20 years ago, the second best time is now.</strong></p>
		<p>It should be noted that most people who have an RSS feed are probably <strong>not</strong> making it manually, so you won’t find a lot of documentation out there for doing it this way. But it’s not too hard. And once you make a habit, it’ll be a totally reasonable component of your publishing flow.</p>
		<p>Here’s what my XML file looks like <small>(without any entries)</small>:</p>
<pre><code>&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"&gt;
	&lt;channel&gt;

		&lt;title&gt;LMNT&lt;/title&gt;
		&lt;link&gt;https://lmnt.me/&lt;/link&gt;
		&lt;description&gt;Louie Mantia’s weblog.&lt;/description&gt;
		&lt;language&gt;en-us&lt;/language&gt;
		&lt;atom:link href="https://lmnt.me/feed.xml" rel="self" type="application/rss+xml" /&gt;

	&lt;/channel&gt;
&lt;/rss&gt;</code></pre>
		<p>The elements inside the <code>channel</code> element are for your feed as a whole <small>(<code>title</code>, <code>link</code>, <code>description</code>, <code>language</code>, and <code>atom:link</code>)</small>. After the ones about your feed’s metadata, we can add a blog post to the XML file, which will look like this:</p>
<pre><code>&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"&gt;
	&lt;channel&gt;
		&lt;title&gt;LMNT&lt;/title&gt;
		&lt;link&gt;https://lmnt.me/&lt;/link&gt;
		&lt;description&gt;Louie Mantia’s weblog.&lt;/description&gt;
		&lt;language&gt;en-us&lt;/language&gt;
		&lt;atom:link href="https://lmnt.me/feed.xml" rel="self" type="application/rss+xml" /&gt;

		&lt;item&gt;
			&lt;title&gt;How to Make a Damn Website&lt;/title&gt;
			&lt;pubDate&gt;Mon, 25 Mar 2024 09:05:00 GMT&lt;/pubDate&gt;
			&lt;guid&gt;C5CC4199-E380-4851-B621-2C1AEF2CE7A1&lt;/guid&gt;
			&lt;link&gt;https://lmnt.me/blog/how-to-make-a-damn-website.html&lt;/link&gt;
			&lt;description&gt;&lt;![CDATA[

				&lt;h1&gt;&lt;a href="how-to-make-a-damn-website.html"&gt;How to Make a Damn Website&lt;/a&gt;&lt;/h1&gt;
				&lt;p&gt;A lot of people want to make a website but don’t know where to start or they get stuck.&lt;/p&gt;

			]]&gt;&lt;/description&gt;
		&lt;/item&gt;

	&lt;/channel&gt;
&lt;/rss&gt;</code></pre>
		<p>The <code>item</code> element represents an entry, and goes inside the <code>channel</code> element as well. There are a few self-explanatory elements for the post metadata <small>(<code>title</code>, <code>pubDate</code>, <code>guid</code>, and <code>link</code>)</small>, but the content inside the <code>description</code> element can be the <strong>same HTML</strong> from your actual post. Handy!</p>
		<p>Writing your first post with HTML and understanding how it looks “unstyled” really works in your favor here, because <strong>RSS readers use their own stylesheets</strong>. How they render pages will not be too different from how a raw HTML page is rendered in your browser. If you make your own stylesheet too early, you may neglect how the raw HTML could be parsed in an RSS reader.</p>
		<p>For the <code>pubDate</code>, you can use <strong>GMT</strong> time. Ask Siri what time it is in Reykjavik, and enter that. You can use your local time zone instead, but be sure it’s <a href="https://validator.w3.org/feed/docs/error/InvalidRFC2822Date.html">formatted correctly</a>. Also, note that it needs to be <strong>24-hour time</strong>.</p>
		<p>If you have images or other media in your post, be sure to use the <strong>absolute URL</strong> to a resource rather than a <strong>relative</strong> one. Relative URLs are fine for content that only lives on your site, but when you syndicate via RSS, that content loads outside of your website. Absolute URLs are better for content <strong>inside</strong> your blog posts, especially in the XML.</p>
		<p>Once you’ve got your first post in the XML file, upload it to the root folder of your website. If you don’t already have an RSS reader, get one. I recommend <em><a href="https://netnewswire.com/">NetNewsWire</a></em>. Go to the XML file in your browser, and it should automatically open in your RSS reader and let you subscribe.</p>
		<p>There it is! Your blog post is on the web and now <strong>also</strong> available via RSS! You can share that link now.</p>
		<p>Now would be a good time to reference your RSS feed <strong>in your HTML</strong>. You’ll want to do this on all pages going forward, too. It helps browsers and plugins detect that there’s an RSS feed for people to subscribe to.</p>
		<pre><code>&lt;link rel="alternate" type="application/rss+xml" title="LMNT" href="https://lmnt.me/feed.xml" /&gt;</code></pre>
		<p>When you add a new <code>item</code> <small>(a new blog post)</small>, put it <strong>above the previous one</strong> in your XML file. Keep in mind that your XML file will be updated periodically from devices that subscribe to it. RSS readers will be downloading this file when updating, so keep an eye on the file size. It probably won’t ever be that big, because it’s just text, but it’s customary to keep only a certain amount of recent entries in the XML file, or a certain time period. But there’s no rule here.</p>
		<p>The <code>guid</code> should be a unique string. Some people use URLs thinking they’re unique, but those can change. The <strong>right</strong> way is to generate a unique string for each post, which you can do easily with my app <em><a href="https://lmnt.me/apps/#tulip">Tulip</a></em>.</p>
		<p>Changing the <code>guid</code> <small>(unique identifier)</small> for your posts makes an RSS reader think it’s a different entry, resulting in a post being marked “unread.” If you go the route of using a URL as your <code>guid</code> for each post, you’ll want to think harder about the file structure of your website, right? It’s <strong>probably</strong> fine if you change your file structure once or twice <small>(I did)</small>, but just be sure to update your <code>link</code> elements in the RSS feed, and <strong>redirect</strong> old URLs to new ones with an <strong>.htaccess</strong> file. Just don’t change the contents of the <code>guid</code> element.</p>
		<hr>
		<h2>Indexing…</h2>
		<p>Alright, we can make index pages now. This is going to be super easy, because you don’t have a lot to index yet.</p>
		<p>At the <strong>root</strong>, you want a link to the <strong>blog</strong> directory, and at the <strong>blog</strong> directory, you want a link to your <strong>first post</strong>. Put titles on each page, maybe a link back to the home page from your blog index. If you want, write a little description of your site on the root index.</p>
		<p>Keep using basic HTML! Titles can be <code>h1</code>, and descriptions can be <code>p</code>. Keep it simple.
		</p><p>Once you got those uploaded, you got <strong>three pages</strong> and an <strong>RSS feed</strong>. You’re doing great!</p>
		<hr>
		<h2>Developing Blogging Habits</h2>
		<p>I recommend writing a couple more posts next. Try using some HTML elements that you didn’t use in the first post, maybe an <code>hr</code> element. Fancy! <code>ol</code> and <code>ul</code>. Maybe some <code>img</code>, <code>video</code>, and <code>audio</code> elements.</p>
		<p>In addition to being more posts for your blog, these will also help prioritize which elements need styling, providing you with a few sample pages to check while you write CSS.</p>
		<p>Upload the posts as you write them, one after the next, adding them to your XML file. Don’t forget to update your index pages, too. Always check your links and your feed.</p>
		<hr>
		<h2>One Style at a Time</h2>
		<p>Before you get ahead of yourself with <strong>layout</strong>, I recommend first styling the <strong>basic HTML elements</strong> you already defined in your first few posts: <code>h1</code>, <code>h2</code>, <code>h3</code>, <code>hr</code>, <code>p</code>, <code>strong</code>, <code>em</code>, <code>ol</code>, <code>ul</code>. Define the <code>body</code> font and width, text sizes, and colors.</p>
		<p>Like the rest of your site, stylesheets are <strong>mutable</strong>. Expect them to change with your website. <strong>Incremental updates</strong> are what makes this whole process work. Ship <strong>tiny</strong> updates to your CSS. You can upload your stylesheet in a second. Heck, work directly on the server if you want. <strong>I did that.</strong></p>
		<hr>
		<h2>Then Keep Doing It</h2>
		<p>If you’ve done all this, then you’ve cleared the hurdle. Now you get to just keep doing the fun stuff. Write more blog posts. Make more web pages. It’s your website, you can make pages for <strong>anything you want</strong>. You can style them however you want. You can update people via RSS whenever you make something new.</p>
		<p>Manually making a website like this may seem silly to engineers who would rather build or rely on systems that automate this stuff. But it doesn’t seem like there’s actually a whole lot that needs automation, does it?</p>
		<p>A lot of modern solutions <strong>may not save time</strong> as much as they <strong>introduce complexity</strong> and reliance on more tools than you need. This whole process is not that complex.</p>
		<p>It’s not doing this manually that’s hard.</p>
		<p><strong>The hard part is just shipping.</strong></p>
		
	
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Tulip Creative Computer (216 pts)]]></title>
            <link>https://github.com/shorepine/tulipcc</link>
            <guid>46603995</guid>
            <pubDate>Tue, 13 Jan 2026 17:10:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/shorepine/tulipcc">https://github.com/shorepine/tulipcc</a>, See on <a href="https://news.ycombinator.com/item?id=46603995">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Tulip Creative Computer - a portable programmable device for music, graphics, code and writing</h2><a id="user-content-tulip-creative-computer---a-portable-programmable-device-for-music-graphics-code-and-writing" aria-label="Permalink: Tulip Creative Computer - a portable programmable device for music, graphics, code and writing" href="#tulip-creative-computer---a-portable-programmable-device-for-music-graphics-code-and-writing"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/tulip_hero.jpg"><img src="https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/tulip_hero.jpg" alt="Tulip"></a></p>
<p dir="auto">Welcome to the Tulip Creative Computer (Tulip CC)!</p>
<p dir="auto">Tulip is a low power and affordable self-contained portable computer, with a touchscreen display and sound. It's fully programmable - you write code to define your music, games or anything else you can think of. It boots instantaneously into a Python prompt with a lot of built in support for music synthesis, fast graphics and text, hardware MIDI, network access and external sensors. Dive right into making something without distractions or complications.</p>
<p dir="auto">The entire system is dedicated to your code, the display and sound, running in real time, on specialized hardware. The hardware and software are fully open source and anyone can <a href="https://tulip.computer/" rel="nofollow">buy one</a> or <a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_build.md">build one</a>. You can use Tulip to make music, code, art, games, or just write.</p>
<p dir="auto">You can now even <a href="https://tulip.computer/run" rel="nofollow">run Tulip on the web</a> and share your creations with anyone!</p>
<p dir="auto">Tulip is powered by <a href="https://micropython.org/" rel="nofollow">MicroPython</a>, <a href="https://github.com/shorepine/amy">AMY</a>, and <a href="https://lvgl.io/" rel="nofollow">LVGL</a>. The Tulip hardware runs on the ESP32-S3 chip using the <a href="https://github.com/espressif/esp-idf">ESP-IDF</a>.</p>
<ul dir="auto">
<li><a href="https://tulip.computer/" rel="nofollow"><strong>Get a Tulip</strong> from our friends at Makerfabs for only US$59</a></li>
<li><a href="https://github.com/shorepine/tulipcc/blob/main/docs/getting_started.md">Just got a Tulip CC? <strong>Check out our getting started guide!</strong></a></li>
<li><a href="https://github.com/shorepine/tulipcc/blob/main/docs/music.md">Want to make music with your Tulip? <strong>See our music tutorial</strong></a></li>
<li><a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_api.md">See the full <strong>Tulip API</strong></a></li>
<li><a href="https://tulip.computer/run/" rel="nofollow"><strong>Try out Tulip on the web!</strong></a></li>
</ul>
<p dir="auto"><a href="https://discord.gg/TzBFkUb8pG" rel="nofollow"><img src="https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/shorepine100.png" alt="shore pine sound systems discord"> <strong>Chat about Tulip on our Discord!</strong></a></p>
<p dir="auto"><strong>Check out this video!</strong></p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=1lYFjQp7Xrw" title="Tulip, a musical computer based on Micropython" rel="nofollow"><img src="https://camo.githubusercontent.com/0f84a83846a382780198e3f12941550cdcbefc41d30e7878b6f7a59361b3a850/68747470733a2f2f692e7974696d672e636f6d2f76692f316c59466a5170375872772f6d617872657364656661756c742e6a7067" alt="Tulip, a musical computer based on Micropython " data-canonical-src="https://i.ytimg.com/vi/1lYFjQp7Xrw/maxresdefault.jpg"></a></p>
<p dir="auto">You can use Tulip one of three ways:</p>
<ul dir="auto">
<li>Tulip is available both as an <a href="https://tulip.computer/" rel="nofollow">off the shelf or DIY hardware project (Tulip CC)</a></li>
<li><a href="https://tulip.computer/run" rel="nofollow">Tulip runs on the web</a> with (almost) all the same features.</li>
<li>Tulip can also run as a native app for Mac or Linux (or WSL in Windows) as <a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_desktop.md">Tulip Desktop</a></li>
</ul>
<p dir="auto">If you're nervous about getting or building the hardware, <a href="https://tulip.computer/run" rel="nofollow">try it out on the web!</a></p>
<p dir="auto"><a href="https://tulip.computer/run/" rel="nofollow"><img src="https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/tulipweb.png" alt="Tulip Web"></a></p>
<p dir="auto">The hardware Tulip CC supports:</p>
<ul dir="auto">
<li>8.5MB of RAM - 2MB is available to MicroPython, and 1.5MB is available for OS memory. The rest is used for the graphics framebuffers (which you can use as storage) and the firmware cache.</li>
<li>32MB flash storage, as a filesystem accesible in Python (24MB left over after OS in ROM)</li>
<li>An <a href="https://github.com/shorepine/amy">AMY</a> stereo 120-voice synthesizer engine running locally, or as a wireless controller for an <a href="https://github.com/shorepine/alles">Alles</a> mesh. Tulip's synth supports additive and subtractive oscillators, an excellent FM synthesis engine, samplers, karplus-strong, high quality analog style filters, a sequencer, and much more. We ship Tulip with a drum machine, voices / patch app, and Juno-6 editor.</li>
<li>Text frame buffer layer, 128 x 50, with ANSI support for 256 colors, inverse, bold, underline, background color</li>
<li>Up to 32 sprites on screen, drawn per scanline, with collision detection, from a total of 32KB of bitmap memory (1 byte per pixel)</li>
<li>A 1024 (+128 overscan) by 600 (+100 overscan) background frame buffer to draw arbitrary bitmaps to, or use as RAM, and which can scroll horizontally / vertically</li>
<li>WiFi, access http via Python requests or TCP / UDP sockets</li>
<li>Adjustable display clock and resolution, defaults to 30 FPS at 1024x600.</li>
<li>256 colors</li>
<li>Can load PNGs from disk to set sprites or background, or generate bitmap data from code</li>
<li>Built in code and text editor</li>
<li>Built in BBS chat room and file transfer area called <strong>TULIP ~ WORLD</strong></li>
<li>USB keyboard, MIDI and mouse support, including hubs</li>
<li>Capactive multi-touch support (mouse on Tulip Desktop and Tulip Web)</li>
<li>MIDI input and output</li>
<li>I2C / Grove / Mabee connector, compatible with <a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_api.md#i2c--grove--mabee">many I2C devices like joysticks, keyboard, GPIO, DACs, ADCs, hubs</a></li>
<li>575mA power usage @ 5V including display, at medium display brightness, can last for hours on LiPo, 18650s, or USB battery pack</li>
</ul>
<p dir="auto">I've been working on Tulip on and off for years over many hardware iterations and hope that someone out there finds it as fun as I have, either making things with Tulip or working on Tulip itself. I'd love feedback, your own Tulip experiments or pull requests to improve the system.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/tulip4.png"><img src="https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/tulip4.png" alt="Tulip"></a></p>
<ul dir="auto">
<li><a href="https://github.com/shorepine/tulipcc/blob/main/docs/troubleshooting.md"><strong>Any issues with your Tulip CC? Here's our troubleshooting guide</strong></a></li>
<li><a href="https://github.com/orgs/shorepine/projects/1"><strong>Learn about our roadmap and find out what we're working on next</strong></a></li>
<li><a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_build.md"><strong>Build your own Tulip</strong></a></li>
<li><strong><a href="https://notes.variogram.com/2024/07/30/tulip-available/" rel="nofollow">You can read more about the "why" or "how" of Tulip on my website!</a></strong></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">T-Deck Tulip CC</h2><a id="user-content-t-deck-tulip-cc" aria-label="Permalink: T-Deck Tulip CC" href="#t-deck-tulip-cc"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/shorepine/tulipcc/blob/main/docs/pics/tdeck_editor.jpg"><img src="https://github.com/shorepine/tulipcc/raw/main/docs/pics/tdeck_editor.jpg" alt="T-Deck"></a></p>
<p dir="auto">A <strong>new</strong> small option: get yourself a <a href="https://www.aliexpress.us/item/3256805505920840.html?gatewayAdapt=glo2usa4itemAdapt" rel="nofollow">T-Deck</a> and install Tulip CC on it directly! <a href="https://github.com/shorepine/tulipcc/blob/main/tulip/tdeck/README.md">Check out our T-Deck page for more detail.</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting started" href="#getting-started"></a></p>
<p dir="auto">Once you've <a href="https://tulip.computer/" rel="nofollow">bought a Tulip</a>, <a href="https://tulip.computer/run" rel="nofollow">opened Tulip Web</a>, <a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_build.md">built a Tulip</a> or <a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_desktop.md">installed Tulip Desktop</a>, you'll see that Tulip boots right into a Python prompt and all interaction with the system happens there. You can make your own Python programs with Tulip's built in editor and execute them, or just experiment on the Tulip REPL prompt in real time.</p>
<p dir="auto"><a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_api.md"><strong>See the full Tulip API</strong></a> for more details on all the graphics, sound and input functions.</p>
<p dir="auto">Below are a few getting started tips and small examples. The <a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_api.md">full API</a> page has more detail on everything you can do on a Tulip. <a href="https://github.com/shorepine/tulipcc/blob/main/docs/getting_started.md"><strong>See a more complete getting started page</strong></a> or <a href="https://github.com/shorepine/tulipcc/blob/main/docs/music.md"><strong>a music making tutorial</strong></a> as well!</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Run a saved Python file. Control-C stops it
cd('ex') # The ex folder has a few examples and graphics in it
execfile(&quot;parallax.py&quot;)
# If you want to run a Tulip package (folder with other files in it)
run(&quot;game&quot;)"><pre><span># Run a saved Python file. Control-C stops it</span>
<span>cd</span>(<span>'ex'</span>) <span># The ex folder has a few examples and graphics in it</span>
<span>execfile</span>(<span>"parallax.py"</span>)
<span># If you want to run a Tulip package (folder with other files in it)</span>
<span>run</span>(<span>"game"</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">The Tulip Editor</h3><a id="user-content-the-tulip-editor" aria-label="Permalink: The Tulip Editor" href="#the-tulip-editor"></a></p>
<p dir="auto">Tulip ships with a text editor, based on pico/nano. It supports syntax highlighting, search, save/save-as.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Opens the Tulip editor to the given filename. 
edit(&quot;game.py&quot;)"><pre><span># Opens the Tulip editor to the given filename. </span>
<span>edit</span>(<span>"game.py"</span>)</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/editor.png"><img src="https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/editor.png" alt="Editor"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Input and user interface</h3><a id="user-content-input-and-user-interface" aria-label="Permalink: Input and user interface" href="#input-and-user-interface"></a></p>
<p dir="auto">Tulip supports USB keyboard and mice input as well as touch input. (On Tulip Desktop and Web, mouse clicks act as touch points.) It also comes with UI elements like buttons and sliders to use in your applications, and a way to run mulitple applications as once using callbacks. More in the <a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_api.md">full API</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="(x0, y0, x1, y1, x2, y2) = tulip.touch()"><pre>(<span>x0</span>, <span>y0</span>, <span>x1</span>, <span>y1</span>, <span>x2</span>, <span>y2</span>) <span>=</span> <span>tulip</span>.<span>touch</span>()</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/sliders.png"><img src="https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/sliders.png" alt="UI demo"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Network</h3><a id="user-content-network" aria-label="Permalink: Network" href="#network"></a></p>
<p dir="auto">Tulip CC has the capability to connect to a Wi-Fi network, and Python's native requests library will work to access TCP and UDP. We ship a few convenience functions to grab data from URLs as well. More in the <a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_api.md">full API</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Join a wifi network (not needed on Tulip Desktop or Web)
tulip.wifi(&quot;ssid&quot;, &quot;password&quot;)

# Get IP address or check if connected
ip_address = tulip.ip() # returns None if not connected

# Save the contents of a URL to disk (needs wifi)
bytes_read = tulip.url_save(&quot;https://url&quot;, &quot;filename.ext&quot;)"><pre><span># Join a wifi network (not needed on Tulip Desktop or Web)</span>
<span>tulip</span>.<span>wifi</span>(<span>"ssid"</span>, <span>"password"</span>)

<span># Get IP address or check if connected</span>
<span>ip_address</span> <span>=</span> <span>tulip</span>.<span>ip</span>() <span># returns None if not connected</span>

<span># Save the contents of a URL to disk (needs wifi)</span>
<span>bytes_read</span> <span>=</span> <span>tulip</span>.<span>url_save</span>(<span>"https://url"</span>, <span>"filename.ext"</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Music / sound</h3><a id="user-content-music--sound" aria-label="Permalink: Music / sound" href="#music--sound"></a></p>
<p dir="auto">Tulip comes with the AMY synthesizer, a very full featured 120-oscillator synth that supports FM, PCM, additive synthesis, partial synthesis, filters, and much more. We also provide a useful "music computer" for scales, chords and progressions. More in the <a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_api.md">full API</a> and in the <a href="https://github.com/shorepine/tulipcc/blob/main/docs/music.md">music tutorial.</a> Tulip's version of AMY comes with stereo sound, which you can set per oscillator with the <code>pan</code> parameter.</p>
<div dir="auto" data-snippet-clipboard-copy-content="amy.drums() # plays a test song
amy.send(volume=4) # change volume
amy.reset() # stops all music / sounds playing"><pre><span>amy</span>.<span>drums</span>() <span># plays a test song</span>
<span>amy</span>.<span>send</span>(<span>volume</span><span>=</span><span>4</span>) <span># change volume</span>
<span>amy</span>.<span>reset</span>() <span># stops all music / sounds playing</span></pre></div>
<details open="">
  <summary>
    
    <span>music.mov</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/76612/215893940-658144b7-0c6f-42e2-9836-bd271597aab3.mov?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgzMzY1MDEsIm5iZiI6MTc2ODMzNjIwMSwicGF0aCI6Ii83NjYxMi8yMTU4OTM5NDAtNjU4MTQ0YjctMGM2Zi00MmUyLTk4MzYtYmQyNzE1OTdhYWIzLm1vdj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNjAxMTMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjYwMTEzVDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU2MGRkYTBkYTgzNzMxN2FhZDU2MDA0NTFhYWZlNDY0MGEzNGRhYTMyNjVjYWQ4NzE3MDM5YjIwYjEwZDVhODImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.lE3Z72Q6WGafgg9TsFaC0jOWyVppev8haPyJfc60o38" data-canonical-src="https://private-user-images.githubusercontent.com/76612/215893940-658144b7-0c6f-42e2-9836-bd271597aab3.mov?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgzMzY1MDEsIm5iZiI6MTc2ODMzNjIwMSwicGF0aCI6Ii83NjYxMi8yMTU4OTM5NDAtNjU4MTQ0YjctMGM2Zi00MmUyLTk4MzYtYmQyNzE1OTdhYWIzLm1vdj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNjAxMTMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjYwMTEzVDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU2MGRkYTBkYTgzNzMxN2FhZDU2MDA0NTFhYWZlNDY0MGEzNGRhYTMyNjVjYWQ4NzE3MDM5YjIwYjEwZDVhODImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.lE3Z72Q6WGafgg9TsFaC0jOWyVppev8haPyJfc60o38" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h3 tabindex="-1" dir="auto">MIDI</h3><a id="user-content-midi" aria-label="Permalink: MIDI" href="#midi"></a></p>
<p dir="auto">Tulip supports MIDI in and out to connect to external music hardware. You can set up a Python callback to respond immediately to any incoming MIDI message. You can also send messages out to MIDI out. More in the <a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_api.md">full API</a> and <a href="https://github.com/shorepine/tulipcc/blob/main/docs/music.md">music tutorial</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="m = tulip.midi_in() # returns bytes of the last MIDI message received
tulip.midi_out((144,60,127)) # sends a note on message
tulip.midi_out(bytes) # Can send bytes or list"><pre><span>m</span> <span>=</span> <span>tulip</span>.<span>midi_in</span>() <span># returns bytes of the last MIDI message received</span>
<span>tulip</span>.<span>midi_out</span>((<span>144</span>,<span>60</span>,<span>127</span>)) <span># sends a note on message</span>
<span>tulip</span>.<span>midi_out</span>(<span>bytes</span>) <span># Can send bytes or list</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Graphics system</h3><a id="user-content-graphics-system" aria-label="Permalink: Graphics system" href="#graphics-system"></a></p>
<p dir="auto">The Tulip GPU supports a scrolling background layer, hardware sprites, and a text layer. Much more in the <a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_api.md">full API</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Set or get a pixel on the BG
pal_idx = tulip.bg_pixel(x,y)

# Set the contents of a PNG file on the background.
tulip.bg_png(png_filename, x, y)

tulip.bg_scroll(line, x_offset, y_offset, x_speed, y_speed)"><pre><span># Set or get a pixel on the BG</span>
<span>pal_idx</span> <span>=</span> <span>tulip</span>.<span>bg_pixel</span>(<span>x</span>,<span>y</span>)

<span># Set the contents of a PNG file on the background.</span>
<span>tulip</span>.<span>bg_png</span>(<span>png_filename</span>, <span>x</span>, <span>y</span>)

<span>tulip</span>.<span>bg_scroll</span>(<span>line</span>, <span>x_offset</span>, <span>y_offset</span>, <span>x_speed</span>, <span>y_speed</span>)</pre></div>
<details open="">
  <summary>
    
    <span>scroll.mov</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/76612/215895305-7b02ad27-b02a-429a-92ef-f13136e9f9d2.mov?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgzMzY1MDEsIm5iZiI6MTc2ODMzNjIwMSwicGF0aCI6Ii83NjYxMi8yMTU4OTUzMDUtN2IwMmFkMjctYjAyYS00MjlhLTkyZWYtZjEzMTM2ZTlmOWQyLm1vdj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNjAxMTMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjYwMTEzVDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWI3YTJlYTRjZGI4NjBhNmU2YTdkYTRhOTE3ZmQyMTMwZjJlYTFkNmFhNmM4NDJlNjlhZDhhZDJmMjg2MTNkMzQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.ptdHP3G4KFDpMNhrp-qD2pP-mrGEsH0yEAM8r-25ijY" data-canonical-src="https://private-user-images.githubusercontent.com/76612/215895305-7b02ad27-b02a-429a-92ef-f13136e9f9d2.mov?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgzMzY1MDEsIm5iZiI6MTc2ODMzNjIwMSwicGF0aCI6Ii83NjYxMi8yMTU4OTUzMDUtN2IwMmFkMjctYjAyYS00MjlhLTkyZWYtZjEzMTM2ZTlmOWQyLm1vdj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNjAxMTMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjYwMTEzVDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWI3YTJlYTRjZGI4NjBhNmU2YTdkYTRhOTE3ZmQyMTMwZjJlYTFkNmFhNmM4NDJlNjlhZDhhZDJmMjg2MTNkMzQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.ptdHP3G4KFDpMNhrp-qD2pP-mrGEsH0yEAM8r-25ijY" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Hardware sprites are supported. They draw over the background and text layer per scanline per frame:</p>
<div dir="auto" data-snippet-clipboard-copy-content="(w, h, bytes) = tulip.sprite_png(&quot;filename.png&quot;, mem_pos)

...

# Set a sprite x and y position
tulip.sprite_move(12, x, y)"><pre>(<span>w</span>, <span>h</span>, <span>bytes</span>) <span>=</span> <span>tulip</span>.<span>sprite_png</span>(<span>"filename.png"</span>, <span>mem_pos</span>)

...

<span># Set a sprite x and y position</span>
<span>tulip</span>.<span>sprite_move</span>(<span>12</span>, <span>x</span>, <span>y</span>)</pre></div>
<details open="">
  <summary>
    
    <span>game.mov</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/76612/215896311-fc0823aa-44bc-4305-85db-a6773db11a98.mov?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgzMzY1MDEsIm5iZiI6MTc2ODMzNjIwMSwicGF0aCI6Ii83NjYxMi8yMTU4OTYzMTEtZmMwODIzYWEtNDRiYy00MzA1LTg1ZGItYTY3NzNkYjExYTk4Lm1vdj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNjAxMTMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjYwMTEzVDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWVmMDRkNzUzMGY5NDFkMGM3ZjYxMjc5NTU3OWIyYzdjOGQ2MzkxN2FjYzQ5NDQxZmZhYTlmMmY0MTI0YTA0YTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.IrI5FnTSBPqNPABVXWk92Ddo-B0JX0bDW7kSETMtlsM" data-canonical-src="https://private-user-images.githubusercontent.com/76612/215896311-fc0823aa-44bc-4305-85db-a6773db11a98.mov?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgzMzY1MDEsIm5iZiI6MTc2ODMzNjIwMSwicGF0aCI6Ii83NjYxMi8yMTU4OTYzMTEtZmMwODIzYWEtNDRiYy00MzA1LTg1ZGItYTY3NzNkYjExYTk4Lm1vdj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNjAxMTMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjYwMTEzVDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWVmMDRkNzUzMGY5NDFkMGM3ZjYxMjc5NTU3OWIyYzdjOGQ2MzkxN2FjYzQ5NDQxZmZhYTlmMmY0MTI0YTA0YTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.IrI5FnTSBPqNPABVXWk92Ddo-B0JX0bDW7kSETMtlsM" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h3 tabindex="-1" dir="auto">Tulip World</h3><a id="user-content-tulip-world" aria-label="Permalink: Tulip World" href="#tulip-world"></a></p>
<p dir="auto">Still very much early days, but Tulip supports a native chat and file sharing BBS called <strong>TULIP ~ WORLD</strong> where you can hang out with other Tulip owners. You're able to pull down the latest messages and files and send messages and files yourself. More in the <a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_api.md">full API</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import world
world.post_message(&quot;hello!!&quot;) # Sends a message to Tulip World. username required. will prompt if not set
world.upload(filename) # Uploads a file to Tulip World. username required
world.ls() # lists most recent unique filenames/usernames"><pre><span>import</span> <span>world</span>
<span>world</span>.<span>post_message</span>(<span>"hello!!"</span>) <span># Sends a message to Tulip World. username required. will prompt if not set</span>
<span>world</span>.<span>upload</span>(<span>filename</span>) <span># Uploads a file to Tulip World. username required</span>
<span>world</span>.<span>ls</span>() <span># lists most recent unique filenames/usernames</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to build, compile and help develop Tulip</h2><a id="user-content-how-to-build-compile-and-help-develop-tulip" aria-label="Permalink: How to build, compile and help develop Tulip" href="#how-to-build-compile-and-help-develop-tulip"></a></p>
<ul dir="auto">
<li><a href="https://tulip.computer/" rel="nofollow">Get a Tulip!</a></li>
<li><a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_build.md">Build your own Tulip Creative Computer</a> with FOUR different options.</li>
<li><a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_flashing.md">How to compile and flash Tulip hardware</a></li>
<li><a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_desktop.md">How to run or compile Tulip Desktop</a></li>
<li><a href="https://github.com/shorepine/tulipcc/blob/main/docs/tulip_api.md">The full Tulip API</a></li>
<li><a href="https://github.com/shorepine/tulipcc/issues">File any code issues or pull requests!</a></li>
</ul>
<p dir="auto"><a href="https://discord.gg/TzBFkUb8pG" rel="nofollow"><img src="https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/shorepine100.png" alt="shore pine sound systems discord"> <strong>Chat about Tulip on our Discord!</strong></a></p>
<p dir="auto">Two important development guidelines if you'd like to help contribute!</p>
<ul dir="auto">
<li>Be nice and helpful and don't be afraid to ask questions! We're all doing this for fun and to learn.</li>
<li>Any change or feature must be equivalent across Tulip Desktop and Tulip CC. There are of course limited exceptions to this rule, but please test on hardware before proposing a new feature / change.</li>
</ul>
<p dir="auto">Have fun!</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/tulip4.png"><img src="https://raw.githubusercontent.com/shorepine/tulipcc/main/docs/pics/tulip4.png" alt="Tulip"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[90M people. 118 hours of silence. One nation erased from the internet (265 pts)]]></title>
            <link>https://state-of-iranblackout.whisper.security/</link>
            <guid>46603910</guid>
            <pubDate>Tue, 13 Jan 2026 17:05:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://state-of-iranblackout.whisper.security/">https://state-of-iranblackout.whisper.security/</a>, See on <a href="https://news.ycombinator.com/item?id=46603910">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header><div><p><a href="https://whisper.security/" target="_blank" rel="noopener noreferrer"><img alt="Whisper" width="100" height="32" decoding="async" data-nimg="1" srcset="https://state-of-iranblackout.whisper.security/_next/image?url=%2Fwhisper-logo.png&amp;w=128&amp;q=75 1x, https://state-of-iranblackout.whisper.security/_next/image?url=%2Fwhisper-logo.png&amp;w=256&amp;q=75 2x" src="https://state-of-iranblackout.whisper.security/_next/image?url=%2Fwhisper-logo.png&amp;w=256&amp;q=75"></a></p><div><p><span></span><span>LIVE</span></p><p><span>Streaming via WhisperGraph™</span></p></div></div></header><div><h2>THE <br><span>BLACKOUT</span></h2><p>90 million people. <!-- -->120<!-- -->+ hours of silence. One nation erased from the internet.<span>This is how they did it</span></p><div><p><span>Day --</span><span>|</span><span>--h --m</span><span>|</span><span>--% connectivity</span><span>|</span><span>-- networks monitored</span></p><div><p><span>Auto-updates every 5s</span><a href="https://state-of-iranblackout.whisper.security/status">Full status →</a></p></div></div></div><div><p>JOINT STATEMENT FROM INTERNET ARCHITECTS &amp; LEADERS</p><blockquote>"By severing the digital lifelines of over 90 million people, the authorities are inflicting profound harm on their own citizens."</blockquote><p><span><strong>Esther Dyson</strong> · ICANN Founder</span><span><strong>Bruce Schneier</strong> · Cryptographer</span><span><strong>Meredith Whittaker</strong> · Signal President</span><span><strong>Lawrence Lessig</strong> · Harvard Law</span><span>+30 more signatories</span></p><p><a href="https://www.linkedin.com/pulse/joint-statement-internet-architects-leaders-condemn-iran-ranjbar-t0rre" target="_blank" rel="noopener noreferrer">Read Full Statement →</a></p></div><div><div><div><div><h3>BGP Routing Activity</h3><p>Telecommunication Company of Iran (AS58224)</p></div><div><h3>Route Instability (Flapping)</h3><p>BGP UPDATE MESSAGES • HIGH VOLUME = ROUTERS LOSING &amp; RE-LEARNING PATHS</p><p>CLICK CHART FOR DETAILED ANALYSIS</p></div></div><div><div><h2>ACT I — THE CALM</h2><h3>A Nation Connected</h3><p>December 2025. The Rial has collapsed. Inflation hits 42%. Protests erupt in the Grand Bazaar and spread to 31 provinces.</p><p>But the internet still works. TCI, the national backbone, hums along at <strong>1.2 million routing updates daily</strong>—the steady heartbeat of a connected nation.</p></div><div><h2>ACT II — THE SCREAM</h2><h3>January 8th, 03:00 UTC</h3><p>Then came the order. Not a shutdown—something worse. The routers didn't go silent. <strong>They screamed.</strong></p><p>BGP announcements exploded from 1.2 million to <strong>5.6 million</strong> in hours. Filtering rules conflicted. Routes flapped. The network began eating itself alive.</p><div><blockquote>"<!-- -->Iran is technically connected to the internet, even if no one can communicate there. They've kind of just turned it off, even though they're connected.<!-- -->"</blockquote><div><p>— <span>Doug Madory</span>, <!-- -->Director of Internet Analysis<!-- --> at <!-- -->Kentik</p><a href="https://techcrunch.com/2026/01/08/internet-collapses-in-iran-amid-protests-over-economic-crisis/" target="_blank" rel="noopener noreferrer">Source </a></div></div></div></div></div><div><div><h3>System-Wide Instability</h3><p>BGP UPDATE VOLUME (% CHANGE FROM BASELINE) • <!-- -->10<!-- --> NETWORKS MONITORED</p><p>CLICK LEGEND ITEMS FOR DETAILED ASN ANALYSIS</p></div><div><div><h2>ACT III — THE CONTAGION</h2><h3>Everyone Falls Together</h3><p>It wasn't just the backbone. Watch the chart: <strong>every major network in Iran spiked in exact unison</strong>.</p><p>Irancell. MCI. Rightel. Shatel. Afranet. Ten networks. Ten simultaneous failures. This wasn't a cascade—it was <strong>coordinated demolition</strong>.</p><div><blockquote>"<!-- -->In over 20 years of research, I've never seen anything like it.<!-- -->"</blockquote><div><p>— <span>Amir Rashidi</span>, <!-- -->Director of Internet Security<!-- --> at <!-- -->Miaan Group</p><a href="https://www.techradar.com/vpn/vpn-privacy-security/i-have-never-seen-such-a-thing-in-my-life-iran-completely-shuts-down-the-internet-amid-protests-starlink-also-affected" target="_blank" rel="noopener noreferrer">Source </a></div></div></div><div><h2>KEY FINDINGS</h2><h3>What the Data Proves</h3><div><div><h4>Evidence A: Synchronization</h4><p><strong>10 out of 10 networks</strong> destabilized in the exact same 3-hour window. Mobile carriers. Fixed lines. Hosting providers. All at once. <span>This is not congestion—it's a command.</span></p></div><div><h4>Evidence B: Intranet Isolation</h4><p>Afranet hosts Iran's domestic services—banks, taxis, food delivery. Its <strong>341% spike</strong> proves this wasn't just about blocking the outside world. It was a <span>reconfiguration of the entire National Information Network</span>.</p></div><div><p>January 8th was a <strong>stress-test for total disconnection</strong>. BGP withdrawals reveal route leaks from a <span>"Filter-First, Route-Second"</span> policy being forced onto core gateways.</p></div></div></div><div><h2>THE HUMAN COST</h2><h3>Behind the Numbers</h3><p>While routers screamed and protocols collapsed, <strong>real people</strong> were being silenced. The blackout wasn't just technical—it was a cover for violence.</p><div><div><p><span>12,000+</span></p><div><p><span>estimated killed</span></p><p>Over two nights (Jan 8-9). Largest killing in Iran's modern history.</p></div></div><div><p><span>648+</span></p><div><p><span>independently verified</span></p><p>By Iran Human Rights. True toll hidden by blackout.</p></div></div><div><p><span>16,784+</span></p><div><p><span>arrests</span></p><p>Journalists. Students. Lawyers. Parents.</p></div></div><div><p><span>606+</span></p><div><p><span>protest locations</span></p><p>187 cities. All 31 provinces.</p></div></div><div><p><span>2,000+</span></p><div><p><span>admitted by regime</span></p><p>First official acknowledgment of mass casualties.</p></div></div></div><p>Sources: Iran International, Iran Human Rights, HRANA, Reuters — Updated Jan 13, 2026</p></div></div></div><div><div><h3>Structural Damage: The Protocol Gravesite</h3><p>NORMALIZED REACHABILITY (BASELINE = 100) • REAL RIPE RIS DATA • <span>Note: Rapid jumps indicate route flapping/instability.</span></p></div><div><h2>ACT IV — THE EXTINCTION</h2><h3>Killing the Future</h3><p>IPv6 is the modern internet. Faster. More secure. <strong>The future of connectivity.</strong></p><p>Watch the purple line: it doesn't degrade. It <strong>flatlines to zero</strong>. The regime's filtering boxes couldn't handle IPv6 traffic properly. Their solution? <strong>Delete it entirely.</strong></p></div></div><div><div><h2>ACT V — THE HUNT</h2><h3>Hunting the Workarounds</h3><p>Citizens didn't give up. They turned to VPNs. Encrypted messengers. Tor.<strong>The regime was ready.</strong></p><p>OONI probes captured a three-stage "Kill Chain": <strong>Inspect. Inject. Silence.</strong>Every privacy tool was being actively hunted.</p></div><div><h2>CONFIRMED TARGETS</h2><h3>Session &amp; Psiphon Blocked</h3><p>OONI probes confirmed <strong>DNS Injection</strong> targeting Session Messenger and <strong>Middlebox Interference</strong> against Psiphon VPN.</p><ul><li>&gt; GET session.org -&gt; [DNS SPOOF LOGGED]</li><li>&gt; CONNECT psiphon -&gt; [HTTP HEADER MANIPULATED]</li></ul><div><blockquote>"<!-- -->This blanket internet shutdown not only hides human rights violations but amounts to a serious human rights violation in itself.<!-- -->"</blockquote><div><p>— <span>Rebecca White</span>, <!-- -->Iran Researcher<!-- --> at <!-- -->Amnesty International</p><a href="https://www.amnesty.org/en/latest/news/2026/01/internet-shutdown-in-iran-hides-violations-in-escalating-protests/" target="_blank" rel="noopener noreferrer">Source </a></div></div></div></div><div><div><div><h3>Protocol-Level Degradation</h3><p>BGP peer visibility during the blackout period (Jan 7-12, 2026)</p></div><div><div><p>82%</p><p>IPv4 Peer Drop</p><p>313 → 56 peers</p></div><div><p>100%</p><p>IPv6 Blackout</p><p>No visibility after Jan 9</p></div><div><p>3,278</p><p>Pre-Blackout Prefixes</p><p>IPv4 baseline</p></div><div><p>93</p><p>IPv6 Prefixes Lost</p><p>Complete withdrawal</p></div></div><div><h4>BGP Peer Visibility (Higher = More Global Visibility)</h4></div><div><h4>Active Prefix Announcements</h4></div><p><strong>Key Finding:</strong> IPv6 connectivity was<strong> completely severed</strong> after January 9th, while IPv4 experienced severe degradation with peer visibility dropping<strong> from 313 to as low as 56 peers</strong> (82% reduction). This indicates a targeted, protocol-aware shutdown strategy.</p></div><div><div><h2>PROTOCOL ANALYSIS</h2><h3>IPv6: Complete Erasure</h3><p>The modern internet runs on two protocols: IPv4 (legacy) and IPv6 (future). During the blackout, <strong>IPv6 was completely severed</strong>.</p><p>After January 9th, zero IPv6 prefixes were visible to global BGP peers. This wasn't degradation—it was <strong>digital amputation</strong>.</p></div><div><h2>IPv4: SEVERE DEGRADATION</h2><h3>82% Visibility Loss</h3><p>IPv4 peer visibility crashed from <strong>313 peers</strong> to just <strong>56 peers</strong>—an 82% reduction.</p><p>This explains why some connectivity remained: the state couldn't completely kill IPv4 without severing its own access. IPv6, with no such dependencies, was simply switched off.</p></div></div></div><div><div><h2>ACT VI — THE LAST HOPE</h2><h3>Looking to the Sky</h3><p>When the ground-based internet died, people looked up.<strong>Starlink</strong>—Elon Musk's satellite network—became the last lifeline.</p><p>Small dishes, smuggled across borders, beamed hope from orbit. For a moment, it seemed the sky might save them.</p></div><div><h2>THE DARKEST HOUR</h2><h3>Even Space Wasn't Safe</h3><p>The regime deployed military-grade GPS jammers—<strong>Murmansk-BN</strong> and <strong>Krasukha-4</strong> systems, likely supplied by Russia.</p><p>Signal quality crashed from <strong>99%</strong> to <strong>15%</strong>. Packet loss hit <strong>85%</strong>. The satellites were useless.</p><p>SpaceX pushed emergency firmware updates. But for <!-- -->120<!-- -->+ hours, 90 million people had nowhere left to turn.</p></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Influencers and OnlyFans models are dominating U.S. O-1 visa requests (373 pts)]]></title>
            <link>https://www.theguardian.com/us-news/2026/jan/11/onlyfans-influencers-us-o-1-visa</link>
            <guid>46603535</guid>
            <pubDate>Tue, 13 Jan 2026 16:47:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/2026/jan/11/onlyfans-influencers-us-o-1-visa">https://www.theguardian.com/us-news/2026/jan/11/onlyfans-influencers-us-o-1-visa</a>, See on <a href="https://news.ycombinator.com/item?id=46603535">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><span>C</span>ontent creators and influencers in the US are now increasingly applying for O-1 work visas. Astoundingly, the number of O-1 visas granted each year increased by 50% between 2014 and 2024, as noted by recent reporting in the <a href="https://www.ft.com/content/8816fcec-4148-4cda-be7f-fc59d5bcbf59" data-link-name="in body link">Financial Times</a>.</p><p>These visas allow non-immigrants to work temporarily in the US. The O-1 category includes the O-1A, which is designated for individuals with extraordinary ability in the sciences, education, business or athletics and the O-1B, reserved for those with <a href="https://www.uscis.gov/working-in-the-united-states/temporary-workers/o-1-visa-individuals-with-extraordinary-ability-or-achievement" data-link-name="in body link">“extraordinary ability or achievement”</a>.</p><p>The Guardian spoke with some influencers who have had success in obtaining or are still trying to obtain the coveted O-1 visa and talked about what was involved in their process.</p><p>Julia Ain decided to post some videos of herself on social media at the height of the Covid-19 lockdown, when she was a student at McGill University.</p><p>“I was bored during the pandemic – like everyone else – and started posting on TikTok,” she told the Guardian. “I started livestreaming, and I grew a fanbase kind of quickly.”</p><p>Five years later, the 25-year-old Canadian content creator now has 1.3 million followers combined across various social media platforms. Her influencer success led her to an O-1 visa.</p><figure id="d2677417-2ce5-49ab-8225-74a6914185ce" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:7,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Despair for would-be US citizens as American dream blocked by Trump&quot;,&quot;elementId&quot;:&quot;d2677417-2ce5-49ab-8225-74a6914185ce&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/us-news/2025/dec/30/us-citizenship-immigration-trump&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:10,&quot;display&quot;:0,&quot;theme&quot;:0},&quot;isInStarRatingVariant&quot;:false}"></gu-island></figure><p>“It became really obvious that you could make a lot of money doing this in a short period of time,” she said. “It felt like a very time-sensitive thing. Nobody knows how long this is going to last for.”</p><p>Ain posts photos and videos across Instagram, TikTok, X and Snapchat, sometimes in collaboration with other creators. Of her brand, she says: “My whole thing is being the funny Jewish girl with big boobs.” The majority of Ain’s income is from <a href="https://www.fanfix.io/" data-link-name="in body link">Fanfix</a>, a safe-for-work subscription based platform for influencers to monetize their content. She first applied for the O-1B Visa after launching on the platform in August 2023, and the company ended up sponsoring her application. She now says she makes five figures per month on the platform.</p><p>Luca Mornet also began making content during the pandemic while he was a student at the Fashion Institute of Technology in New York. Mornet, who is from France, realized soon that his F-1 student visa was holding him back from making money as an influencer.</p><p>“I became friends with so many [other influencers], and I would always see them work with so many people and brands and agencies. And I always was so annoyed that I couldn’t because I was a student,” he said.</p><p>He applied for the O-1B Visa shortly after graduating, during which he could finally make money from influencing while on his OPT, a 12-month work authorization for international students post-graduation.</p><p>The O-1B visa, once reserved for Hollywood titans and superstar musicians, has evolved over the years.</p><figure id="65bcceed-4b8a-4a1e-9b18-7b815a65338d" data-spacefinder-role="supporting" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/5c47c280e161c200a35239aa6b98fb264af43c49/0_210_2448_3054/master/2448.jpg?width=380&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5c47c280e161c200a35239aa6b98fb264af43c49/0_210_2448_3054/master/2448.jpg?width=380&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/5c47c280e161c200a35239aa6b98fb264af43c49/0_210_2448_3054/master/2448.jpg?width=300&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5c47c280e161c200a35239aa6b98fb264af43c49/0_210_2448_3054/master/2448.jpg?width=300&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/5c47c280e161c200a35239aa6b98fb264af43c49/0_210_2448_3054/master/2448.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5c47c280e161c200a35239aa6b98fb264af43c49/0_210_2448_3054/master/2448.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/5c47c280e161c200a35239aa6b98fb264af43c49/0_210_2448_3054/master/2448.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5c47c280e161c200a35239aa6b98fb264af43c49/0_210_2448_3054/master/2448.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/5c47c280e161c200a35239aa6b98fb264af43c49/0_210_2448_3054/master/2448.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5c47c280e161c200a35239aa6b98fb264af43c49/0_210_2448_3054/master/2448.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="two men smile side by side " src="https://i.guim.co.uk/img/media/5c47c280e161c200a35239aa6b98fb264af43c49/0_210_2448_3054/master/2448.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="555.1593137254902" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Michael Wildes and his client, Pelé.</span> Photograph: Courtesy of Michael Wildes</figcaption></figure><p>“We started doing [O-1 visa applications] for kids who are e-sport players and influencers and the OnlyFans crew,” said Michael Wildes, an immigration attorney and managing partner of Wildes &amp; Weinberg. “It’s the new, sexy medium for people to be a part of.”</p><p>Wildes has worked with the likes of musician Sinéad O’Connor, soccer star Pelé, and restaurateur Jean-Georges Vongerichten. His father, Leon Wildes, who started the firm in 1960, defended John Lennon and Yoko Ono against deportation during the Nixon administration, and helped facilitate the creation of the O-1B visa, which was established by the Immigration Act of 1990. Wildes’s client roster now includes social media influencers and Twitch streamers.</p><p>To qualify for an O-1B visa, applicants must submit evidence of at least three of the six <a href="https://www.wildeslaw.com/misc-content/foreigners-with-extraordinary-ability-the-o-1-visa/" data-link-name="in body link">regulatory criteria</a>, which include performing in a distinguished production or event, national or international recognition for achievements, and a record of commercial or critically acclaimed successes. In 2026, though, these criteria are being stretched to encompass the accolades of an influencer.</p><p>In Ain’s application, she highlighted her sizable income and social media metrics.</p><p>“Part of my application was: ‘I have 200,000 followers on this app, 300,000 followers on this app, 10 million people watch me here every month,’” she said. “This isn’t just, ‘Oh, you had one viral video and people watched that.’ No, you’ve got a following now that are not only watching you, but also paying for your content actively month after month.”</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><gu-island name="EmailSignUpWrapper" priority="feature" deferuntil="visible" props="{&quot;index&quot;:20,&quot;listId&quot;:6042,&quot;identityName&quot;:&quot;the-stakes-us-election-edition&quot;,&quot;description&quot;:&quot;A deep dive into the policies, controversies and oddities surrounding the Trump administration&quot;,&quot;name&quot;:&quot;This Week in Trumpland&quot;,&quot;frequency&quot;:&quot;At least once a week&quot;,&quot;successDescription&quot;:&quot;You are subscribed&quot;,&quot;theme&quot;:&quot;news&quot;,&quot;idApiUrl&quot;:&quot;https://idapi.theguardian.com&quot;,&quot;hideNewsletterSignupComponentForSubscribers&quot;:true}"></gu-island></figure><figure id="07a0e2c5-34af-47e8-9a5d-f35e7cca20b7" data-spacefinder-role="supporting" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/12bb850eb45f83da147134e90b9ab2acd2108996/0_0_1470_2205/master/1470.jpg?width=380&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/12bb850eb45f83da147134e90b9ab2acd2108996/0_0_1470_2205/master/1470.jpg?width=380&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/12bb850eb45f83da147134e90b9ab2acd2108996/0_0_1470_2205/master/1470.jpg?width=300&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/12bb850eb45f83da147134e90b9ab2acd2108996/0_0_1470_2205/master/1470.jpg?width=300&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/12bb850eb45f83da147134e90b9ab2acd2108996/0_0_1470_2205/master/1470.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/12bb850eb45f83da147134e90b9ab2acd2108996/0_0_1470_2205/master/1470.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/12bb850eb45f83da147134e90b9ab2acd2108996/0_0_1470_2205/master/1470.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/12bb850eb45f83da147134e90b9ab2acd2108996/0_0_1470_2205/master/1470.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/12bb850eb45f83da147134e90b9ab2acd2108996/0_0_1470_2205/master/1470.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/12bb850eb45f83da147134e90b9ab2acd2108996/0_0_1470_2205/master/1470.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="three men wear pink jumpsuits outside next to a poster that says Boy Throb and shows another man making a hand heart" src="https://i.guim.co.uk/img/media/12bb850eb45f83da147134e90b9ab2acd2108996/0_0_1470_2205/master/1470.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="667.5" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Members of Boy Throb (left to right): Anthony Key, Zachary Sobania, Evan Papier and Darshan Magdum (pictured on poster).</span> Photograph: Courtesy of Boy Throb</figcaption></figure><p>Social media was an integral part of the O-1B visa application of Dina Belenkaya, a Russian Israeli chess player and content creator – which was approved in December 2023.</p><p>“My followings on Instagram (1.2 million), Twitch (108,000) and YouTube (799,000) were included as part of my profile, and I listed my follower counts on each platform,” she said. After her visa approval, she moved to Charlotte, North Carolina – widely considered the chess capital of the United States.</p><p>While a certain number of followers may not be an automatic ticket to the US, one viral music group has been trying their luck. <a href="https://www.tiktok.com/@boy.throb" data-link-name="in body link">Boy Throb</a>, comprising Anthony Key, Evan Papier, Zachary Sobania and Darshan Magdum, spent the past few months campaigning to reach 1 million followers on TikTok so that Magdum could use the stat on his O-1 visa application. Clad in matching pink jumpsuits, the three US-based bandmates danced together on screen to parody lyrics of hit songs, while Magdum was edited in from India.</p><p>Within a month of their first post, Boy Throb <a href="https://www.teenvogue.com/story/is-boy-throb-real-or-fake-meet-the-divisive-boy-band-visa-issues-interview" data-link-name="in body link">reached their goal of 1 million followers.</a> Whether it will help Magdum get a visa remains unclear.</p><p>“Honestly, the entire immigration process has been so complicated and there have been so many people who don’t believe us when we say we’re doing everything in our power to get Darshan here,” the group said.</p><p>“We’re not sure how much longer we want to keep going without Darshan here and the process has been really expensive,” they added. In total, the band has spent more than $10,000 in legal and processing fees.</p><p>The rise in content creators applying for visas given out on the basis of “extraordinary ability” has garnered a variety of reactions. Dominic Michael Tripi, a political analyst and writer, <a href="https://x.com/DMichaelTripi/status/2008237290943041601?s=20" data-link-name="in body link">posted on X </a>that the trend was indicative of “end-stage empire conditions. It’s sad.” Legal professionals like Wildes, however, argue that the creator economy is the next frontier of American exceptionalism.</p><p>“Influencers are filling a large gap in the retail and commercial interests of the world,” he said. “They’re moving content and purchases like no other. Immigration has to keep up with this.”</p><figure id="386712dc-ffdd-4915-a17f-b6b6df105461" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-4"><picture><source srcset="https://i.guim.co.uk/img/media/737f45d7ac0b1556995c8dab859a87b2cd4a97f0/0_0_1200_960/master/1200.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/737f45d7ac0b1556995c8dab859a87b2cd4a97f0/0_0_1200_960/master/1200.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/737f45d7ac0b1556995c8dab859a87b2cd4a97f0/0_0_1200_960/master/1200.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/737f45d7ac0b1556995c8dab859a87b2cd4a97f0/0_0_1200_960/master/1200.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/737f45d7ac0b1556995c8dab859a87b2cd4a97f0/0_0_1200_960/master/1200.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/737f45d7ac0b1556995c8dab859a87b2cd4a97f0/0_0_1200_960/master/1200.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="two women side by side " src="https://i.guim.co.uk/img/media/737f45d7ac0b1556995c8dab859a87b2cd4a97f0/0_0_1200_960/master/1200.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="356" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Julia Ain and Dina Belenkaya</span> Photograph: Courtesy of Julia Ain and  Dina Belenkaya</figcaption></figure><p>Ain also takes issue with the criticism of influencers applying for O-1 visas, as well as the notion that influencing is not a legitimate profession.</p><p>“I don’t think [people] realize how much work actually goes into it,” she said. “You might not agree with the way the money is being made, or what people are watching, but people are still watching and paying for it.”</p><p>She continued: “Maybe 50 years ago, this isn’t what people imagined the American dream would look like. But this is what the American dream is now.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scott Adams has died (418 pts)]]></title>
            <link>https://www.usatoday.com/story/entertainment/celebrities/2026/01/13/scott-adams-dead-dilbert-creator-prostate-cancer/88158828007/</link>
            <guid>46603431</guid>
            <pubDate>Tue, 13 Jan 2026 16:41:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.usatoday.com/story/entertainment/celebrities/2026/01/13/scott-adams-dead-dilbert-creator-prostate-cancer/88158828007/">https://www.usatoday.com/story/entertainment/celebrities/2026/01/13/scott-adams-dead-dilbert-creator-prostate-cancer/88158828007/</a>, See on <a href="https://news.ycombinator.com/item?id=46603431">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><article><p><a href="https://www.usatoday.com/story/entertainment/celebrities/2026/01/02/dilbert-cartoonist-scott-adams-cancer-update/87992710007/" target="_blank" rel="noreferrer noopener">Scott Adams</a>, the author and cartoonist whose <a href="https://www.usatoday.com/story/entertainment/celebrities/2025/05/19/scott-adams-joe-biden-cancer-dilbert-comic/83728060007/" target="_blank" rel="noreferrer noopener">"Dilbert" comic strip</a> satirized corporate life to wide acclaim before <a href="https://www.usatoday.com/story/news/nation/2023/02/26/newspapers-dilbert-comic-scott-adams-racist-comments/11354547002/" target="_blank" rel="noreferrer noopener">racist comments he made sidelined him</a>, has died following a <a href="https://www.usatoday.com/story/entertainment/celebrities/2025/05/19/scott-adams-joe-biden-cancer-dilbert-comic/83728060007/" target="_blank" rel="noreferrer noopener">battle with cancer</a>. He was 68.</p><partner-banner util-module-path="elements/partner" min-height="600" fluid="" outstream="" momentum=""></partner-banner><p>Adams' ex-wife, Shelly Miles, confirmed Adams' death during a livestream on the <a href="https://www.youtube.com/watch?v=Rs_JrOIo3SE" target="_blank" rel="noreferrer noopener">"Real Coffee with Scott Adams"</a> show on Tuesday, Jan. 13.</p><p>"Hi, everyone. Unfortunately, this isn't good news," Miles said. "Of course, he waited 'til just before the show started, but he's not with us anymore."</p><media-gallery-promo asset-id="77406937007"></media-gallery-promo><p>Adams shared in May that he was diagnosed with prostate cancer that had spread to his bones. During a New Year's Day broadcast of "Real Coffee with Scott Adams," Adams revealed that his health outlook had worsened, telling fans that his chances of recovery were "essentially zero."</p><partner-banner util-module-path="elements/partner" fluid="" bottom="" lazy="" min-height="390" outstream=""></partner-banner><p>USA TODAY has reached out to representatives for Adams for comment.</p><p>Following the announcement of Adams' death, Miles read a "final message" from the cartoonist, which he wrote on New Year's Day.</p><media-gallery-promo asset-id="3364175002"></media-gallery-promo><p>"If you are reading this, things did not go well for me," Adams wrote. "I have a few things to say before I go. My body fell before my brain. ... If you wonder about any of my choices for my estate or anything else, please know I'm free of any crazen or any inappropriate influence of any sort, I promise."</p><partner-inline util-module-path="elements/partner" placement="native-article_link" sizes="[[300, 250], [3, 3]]" min-height="250" fluid="" outstream=""></partner-inline><cta-atoms-container-inline util-module-path="elements/cta"></cta-atoms-container-inline><p>Adams also revealed in the open letter that he was dedicating his life to Jesus Christ at the persuasion of his Christian friends (Adams described himself as "not a believer").</p><p>"I accept Jesus Christ as my lord and savior and look forward to spending an eternity with him," Adams wrote. "The part about me not being a believer should be quickly resolved if I wake up in heaven. I won't need any more convincing than that. I hope I'm still qualified for entry."</p><partner-banner util-module-path="elements/partner" fluid="" bottom="" lazy="" min-height="600" outstream="" momentum=""></partner-banner><media-image image-set="https://www.gannett-cdn.com/authoring/authoring-images/2026/01/13/USAT/88158763007-19990125-t-000000-z-1238593826-rp-1-drifqykad-rtrmadp-3-dilbert-1.JPG bestCrop, https://www.gannett-cdn.com/authoring/authoring-images/2026/01/13/USAT/88158763007-19990125-t-000000-z-1238593826-rp-1-drifqykad-rtrmadp-3-dilbert-1.JPG?crop=1905,1428,x0,y0 4:3, https://www.gannett-cdn.com/authoring/authoring-images/2026/01/13/USAT/88158763007-19990125-t-000000-z-1238593826-rp-1-drifqykad-rtrmadp-3-dilbert-1.JPG?crop=1071,1428,x819,y0 3:4, https://www.gannett-cdn.com/authoring/authoring-images/2026/01/13/USAT/88158763007-19990125-t-000000-z-1238593826-rp-1-drifqykad-rtrmadp-3-dilbert-1.JPG?crop=2047,1152,x0,y138 16:9" image-alt="" credit="Reuters Photographer, REUTERS" caption="Scott Adams takes aim at the 14 ball at his home in Blackhawk, California, on Dec. 22, 1998." orientation="horizontal" util-module-path="elements/media"></media-image><p>Adams' comic strip "Dilbert," which centered on an engineer named Dilbert and his white-collar office, was first published in 1989. Over the next decade, the observational comedy cartoon would earned Adams acclaim, with the illustrator receiving the National Cartoonists Society's Reuben Award in 1997.</p><partner-inline util-module-path="elements/partner" placement="native-article_link" sizes="[[300, 250], [3, 3]]" min-height="250" fluid="" outstream=""></partner-inline><p>By 2013, the series was reportedly featured in 2,000 newspapers in 65 countries and translated into 25 languages.</p><p>However, the pop cultural legacy of "Dilbert" screeched to a halt in 2023 after&nbsp;<a href="https://www.usatoday.com/story/news/nation/2023/02/26/newspapers-dilbert-comic-scott-adams-racist-comments/11354547002/" target="_blank" rel="noreferrer noopener">numerous newspapers, including the USA TODAY Network,</a>&nbsp;announced they would stop running the strip due to racist comments made by Adams, who said that white people should "get the hell away from Black people." Adams said at the time that his comments were meant to be hyperbolic.</p><p>The comic strip was later relaunched as a webcomic on Locals under the name "Daily Dilbert Reborn."</p><partner-banner util-module-path="elements/partner" fluid="" bottom="" lazy="" min-height="390" outstream=""></partner-banner><p>"I had an amazing life," Adams wrote in his New Year's Day letter. "I gave it everything I had. If I got any benefits from my work, I'm asking that you pay it forward as best as you can. That's the legacy I want: be useful. And please know, I loved you all to the very end."</p><p><em>This story was updated to add new information.</em></p><p><em>Contributing: Anna Kaufman, USA TODAY</em></p><lit-timestamp slot="timestamp" publishdate="2026-01-13 16:07:11.488998528 +0000 UTC" updatedate="2026-01-13 17:06:01.354115089 +0000 UTC"></lit-timestamp><p><a alt="Post the article to your Facebook Timeline" data-size="large" onclick="fireNavShareAnalytics('facebook');" rel="noopener" target="_blank"><svg view-box="0 0 24 24">
                <path d="M12.6143832,21 L3.99346182,21 C3.44462725,21 3,20.5550968 3,20.006476 L3,3.99345411 C3,3.44469364 3.44469709,3 3.99346182,3 L20.006608,3 C20.5552331,3 21,3.44469364 21,3.99345411 L21,20.006476 C21,20.5551667 20.5551632,21 20.006608,21 L15.4197395,21 L15.4197395,14.029408 L17.7594454,14.029408 L18.1097832,11.3128446 L15.4197395,11.3128446 L15.4197395,9.57849053 C15.4197395,8.79198274 15.6381418,8.25600363 16.7659836,8.25600363 L18.2044917,8.25537504 L18.2044917,5.82565895 C17.9557072,5.79255313 17.1017938,5.71858885 16.108332,5.71858885 C14.0343128,5.71858885 12.6143832,6.98457234 12.6143832,9.30945332 L12.6143832,11.3128446 L10.2686707,11.3128446 L10.2686707,14.029408 L12.6143832,14.029408 L12.6143832,21 L12.6143832,21 Z"></path>
            </svg><span>Facebook</span></a>
<a alt="Tweet about this article" data-size="large" onclick="fireNavShareAnalytics('twitter')" rel="noopener" target="_blank"><svg view-box="0 0 24 24">
                <path d="M21,6.77573131 C20.338616,7.07692308 19.6265188,7.28060672 18.8795563,7.3716143 C19.6423666,6.9035753 20.2276809,6.16143012 20.5034337,5.27735645 C19.7892235,5.71072589 19,6.02600217 18.1568938,6.19501625 C17.4849445,5.45937161 16.5245642,5 15.461701,5 C13.4236661,5 11.770206,6.69555796 11.770206,8.78656555 C11.770206,9.08342362 11.8019017,9.3716143 11.8652932,9.64897075 C8.79609086,9.4907909 6.07554147,7.98483207 4.25303751,5.69122427 C3.93502377,6.2524377 3.75330164,6.9035753 3.75330164,7.59696641 C3.75330164,8.91007584 4.40517697,10.0693391 5.39619651,10.7486457 C4.79186476,10.7302275 4.22134179,10.5579632 3.72266244,10.276273 L3.72266244,10.3228602 C3.72266244,12.1581798 4.9957739,13.6890574 6.68621236,14.035753 C6.37665082,14.1245937 6.05018489,14.1690141 5.71315372,14.1690141 C5.47543582,14.1690141 5.24300053,14.1462622 5.01796091,14.1018418 C5.4881141,15.6056338 6.85103011,16.7009751 8.46751189,16.7302275 C7.20390914,17.7464789 5.61067089,18.3521127 3.88114105,18.3521127 C3.58320127,18.3521127 3.28843106,18.3347779 3,18.3001083 C4.63444268,19.3726977 6.57633386,20 8.66085578,20 C15.4543053,20 19.1679873,14.2307692 19.1679873,9.22643554 C19.1679873,9.06175515 19.1648177,8.89707476 19.1584786,8.73564464 C19.8800845,8.20151679 20.5066033,7.53521127 21,6.77573131"></path>
            </svg><span>Twitter</span></a>
<a alt="Email this article" onclick="fireNavShareAnalytics('email')" rel="noopener" target="_blank"><svg view-box="0 0 24 24">
            <path d="M3,5.8757627 C3,5.39209232 3.39269552,5 3.8926228,5 L20.1073772,5 C20.6003592,5 21,5.40389442 21,5.8757627 L21,18.1242373 C21,18.6079077 20.6073045,19 20.1073772,19 L3.8926228,19 C3.39964084,19 3,18.5961056 3,18.1242373 L3,5.8757627 Z M12,11.09375 L3,6.74107143 L3,8.48214286 L12,12.8348214 L21,8.48214286 L21,6.74107143 L12,11.09375 Z"></path>
        </svg><span>Email</span></a></p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Are two heads better than one? (145 pts)]]></title>
            <link>https://eieio.games/blog/two-heads-arent-better-than-one/</link>
            <guid>46603111</guid>
            <pubDate>Tue, 13 Jan 2026 16:22:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eieio.games/blog/two-heads-arent-better-than-one/">https://eieio.games/blog/two-heads-arent-better-than-one/</a>, See on <a href="https://news.ycombinator.com/item?id=46603111">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><a href="https://eieio.games/blog/two-heads-arent-better-than-one/"></a><div><p>Three heads are certainly more fun</p><p>Dec 9, 2025</p></div></div>
<p>You’re playing a game with your lying friends Alice and Bob.</p>
<p>Bob flips a coin and shows it to Alice. Alice tells you what she saw - but she lies 20% of the time. Then you take your best guess on whether the coin is heads or tails.</p>
<p>Your best strategy is to trust whatever Alice says. You’re right 80% of the time.</p>
<p>Now Bob joins in. He makes up his mind independent of Alice, and he <em>also</em> lies 20% of the time <a>1</a>.</p>
<div data-is-footnote="true"><p><span>1</span></p><p>Your friends are all liars!</p></div>
<p>You were right 80% of the time by trusting Alice.</p>
<p>How much better can you do with Bob’s help?</p>
<!-- -->
<h2 id="toc:heres-some-empty-space-for-you-to-think">Here’s some empty space for you to think</h2>
<p>I’m going to give you the answer below. So here’s some empty space for you to think in case you want to do the math yourself.</p>
<!-- -->

<h2 id="toc:alright-lets-do-some-math">Alright, let’s do some math</h2>
<p>The answer is 0% - you don’t do any better! You’re still exactly 80% to get the right answer.</p>
<p>To establish this, let’s write a simple simulation. We’ll flip a coin a million times, ask our friends what they saw, and observe the results.</p>
<p>For our strategy, we’ll look at a fact pattern (like “Alice says heads”), figure out what’s most likely (“the coin is heads”), and say “we guess the coin flip correctly whenever the most likely outcome occurs for this fact pattern” <a>2</a>.</p>
<div data-is-footnote="true"><p><span>2</span></p><p>Given that Bob and Alice decide independently and aren’t playing
adversarially, “guess the most likely outcome” is optimal here. It may not be
optimal if the game was adversarial, although I think that’s a trickier
question than it might first seem.</p></div>
<p>Here’s the code for that simulation. We’ll start with the easy case (just Alice):</p>
<details><summary><svg xmlns="http://www.w3.org/2000/svg" width="20px" height="20px" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path><circle cx="12" cy="12" r="3"></circle></svg> <!-- -->The simulation code</summary><pre><code><span><span># heads.py</span>
</span><span>
</span><span><span>from</span> random <span>import</span> random
</span><span><span>from</span> collections <span>import</span> defaultdict
</span><span>
</span><span>table <span>=</span> defaultdict<span>(</span><span>lambda</span><span>:</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>]</span><span>)</span>
</span><span>LYING_PROB <span>=</span> <span>0.2</span>
</span><span>LYING_FRIENDS <span>=</span> <span>[</span><span>"Alice"</span><span>]</span>
</span><span>ITERATIONS <span>=</span> <span>1_000_000</span>
</span><span>
</span><span><span>for</span> _ <span>in</span> <span>range</span><span>(</span>ITERATIONS<span>)</span><span>:</span>
</span><span>    is_heads <span>=</span> random<span>(</span><span>)</span> <span>&gt;</span> <span>0.5</span>
</span><span>    keys <span>=</span> <span>[</span><span>]</span>
</span><span>    <span>for</span> lying_friend <span>in</span> LYING_FRIENDS<span>:</span>
</span><span>        lied <span>=</span> random<span>(</span><span>)</span> <span>&lt;</span> LYING_PROB
</span><span>        answer <span>=</span> <span>None</span>
</span><span>        <span>if</span> is_heads<span>:</span> answer <span>=</span> <span>"T"</span> <span>if</span> lied <span>else</span> <span>"H"</span>
</span><span>        <span>else</span><span>:</span> answer <span>=</span> <span>"H"</span> <span>if</span> lied <span>else</span> <span>"T"</span>
</span><span>        keys<span>.</span>append<span>(</span><span><span>f"</span><span><span>{</span>lying_friend<span>[</span><span>0</span><span>]</span><span>}</span></span><span>:</span><span><span>{</span>answer<span>}</span></span><span>"</span></span><span>)</span>
</span><span>
</span><span>    key <span>=</span> <span>", "</span><span>.</span>join<span>(</span>keys<span>)</span>
</span><span>
</span><span>    table_idx <span>=</span> <span>0</span> <span>if</span> is_heads <span>else</span> <span>1</span>
</span><span>    table<span>[</span>key<span>]</span><span>[</span>table_idx<span>]</span> <span>+=</span> <span>1</span>
</span><span>
</span><span>total_times_we_are_right <span>=</span> <span>0</span>
</span><span><span>for</span> key<span>,</span> <span>(</span>times_heads<span>,</span> times_tails<span>)</span> <span>in</span> table<span>.</span>items<span>(</span><span>)</span><span>:</span>
</span><span>    total <span>=</span> times_heads <span>+</span> times_tails
</span><span>    heads_chance <span>=</span> <span>100</span> <span>*</span> <span>round</span><span>(</span>times_heads <span>/</span> total<span>,</span> <span>2</span><span>)</span>
</span><span>    tails_chance <span>=</span> <span>100</span> <span>*</span> <span>round</span><span>(</span>times_tails <span>/</span> total<span>,</span> <span>2</span><span>)</span>
</span><span>    pattern_chance <span>=</span> <span>100</span> <span>*</span> <span>round</span><span>(</span>total <span>/</span> ITERATIONS<span>,</span> <span>2</span><span>)</span>
</span><span>
</span><span>    <span>print</span><span>(</span><span><span>f"</span><span><span>{</span>key<span>}</span></span><span> - chances -  H </span><span><span>{</span>heads_chance<span>:</span><span>4</span><span>}</span></span><span>% | T </span><span><span>{</span>tails_chance<span>:</span><span>4</span><span>}</span></span><span>% | occurs </span><span><span>{</span>pattern_chance<span>}</span></span><span>% of the time"</span></span><span>)</span>
</span><span>
</span><span>    <span># We look at key, and guess whichever outcome is more likely. So we're right, on average,</span>
</span><span>    <span># the max of times_heads and times_tails</span>
</span><span>    total_times_we_are_right <span>+=</span> <span>max</span><span>(</span>times_heads<span>,</span> times_tails<span>)</span>
</span><span>
</span><span>accuracy <span>=</span> <span>round</span><span>(</span>total_times_we_are_right <span>/</span> ITERATIONS<span>,</span> <span>2</span><span>)</span>
</span><span><span>print</span><span>(</span><span><span>f"\nOur accuracy: </span><span><span>{</span><span>100</span><span>*</span>accuracy<span>}</span></span><span>%"</span></span><span>)</span>
</span></code></pre></details>
<p>This gives us:</p>
<pre><code><span>% python heads.py
</span><span>A:T - chances -  H 20.0% | T 80.0% | occurs 50.0% of the time
</span><span>A:H - chances -  H 80.0% | T 20.0% | occurs 50.0% of the time
</span><span>
</span><span>Our accuracy: 80.0%
</span></code></pre>
<p>Now let’s add Bob to the simulation. We see something like this:</p>
<pre><code><span>% python heads.py
</span><span>A:T, B:T - chances -  H  6.0% | T 94.0% | occurs 34.0% of the time
</span><span>A:H, B:T - chances -  H 50.0% | T 50.0% | occurs 16.0% of the time
</span><span>A:H, B:H - chances -  H 94.0% | T  6.0% | occurs 34.0% of the time
</span><span>A:T, B:H - chances -  H 50.0% | T 50.0% | occurs 16.0% of the time
</span><span>
</span><span>Our accuracy: 80.0%
</span></code></pre>
<p>That’s weird! But perhaps this gives you an intuition for what’s happening. By introducing a second player, <em>we introduce the possibility of a tie</em>.</p>
<p>A decent amount of the time, Alice and Bob agree. <em>Most</em> (~94%) of the time when that happens, they’re telling the truth. Occasionally they’re both lying, but that’s pretty unlikely.</p>
<p>But a meaningful portion of the time (32%) Alice says heads and Bob says tails, or vice versa. And in that case we don’t know anything at all! Alice and Bob are equally trustworthy and they disagreed - we’d be better off if we’d just gone and asked Alice <a>3</a>!</p>
<div data-is-footnote="true"><p><span>3</span></p><p>I am deeply curious whether anyone else was read the book “Go Ask Alice” by
their middle school science teacher in order to scare them straight or whether
that was specific to my middle school experience.</p></div>
<h3 id="toc:lets-prove-it">Let’s prove it</h3>
<p>Now that we’ve simulated this result, let’s walk through each case assuming that the coin landed on heads.</p>
<pre><code><span>- both tell the truth
</span><span>Alice: Heads (80%), Bob: Heads (80%)
</span><span>happens 80% * 80% = 64% of the time
</span><span>we always guess correctly in this case
</span><span>
</span><span>- both lie
</span><span>Alice: Tails (20%), Bob: Tails (20%)
</span><span>happens 20% * 20% = 4% of the time
</span><span>we never guess correctly in this case
</span><span>
</span><span>- alice tells the truth, bob lies
</span><span>Alice: Heads (80%), Bob: Tails (20%)
</span><span>happens 80% * 20% = 16% of the time
</span><span>we guess at random in this case; we're right 50% of the time
</span><span>
</span><span>- alice lies, bob tells the truth
</span><span>Alice: Tails (20%), Bob: Heads (80%)
</span><span>happens 20% * 80% = 16% of the time
</span><span>we guess at random in this case; we're right 50% of the time
</span><span>
</span><span>Our total chance to guess correctly is:
</span><span>64% + 16% / 2 + 16% / 2 = 64% + 8% + 8% = 80%
</span></code></pre>
<p>There’s something beautiful here. Our total chance to guess remains at 80% because our additional chance to guess correctly when Alice and Bob agree is perfectly offset by the chance that Alice and Bob disagree!</p>
<h3 id="toc:meet-charlie-and-david">Meet Charlie (and David)</h3>
<p>If our friend Charlie - who also lies 20% of the time - joins the fun, our odds improve substantially. If Bob and Alice disagree, Charlie can act as a tiebreaker.</p>
<pre><code><span>% python heads.py
</span><span>A:H, B:H, C:H - chances -  H 98.0% | T  2.0% | occurs 26.0% of the time
</span><span>A:T, B:T, C:T - chances -  H  2.0% | T 98.0% | occurs 26.0% of the time
</span><span>A:T, B:H, C:H - chances -  H 80.0% | T 20.0% | occurs 8.0% of the time
</span><span>A:H, B:T, C:T - chances -  H 20.0% | T 80.0% | occurs 8.0% of the time
</span><span>A:H, B:H, C:T - chances -  H 80.0% | T 20.0% | occurs 8.0% of the time
</span><span>A:H, B:T, C:H - chances -  H 80.0% | T 20.0% | occurs 8.0% of the time
</span><span>A:T, B:T, C:H - chances -  H 20.0% | T 80.0% | occurs 8.0% of the time
</span><span>A:T, B:H, C:T - chances -  H 20.0% | T 80.0% | occurs 8.0% of the time
</span><span>
</span><span>Our accuracy: 90.0%
</span></code></pre>
<p>But if David joins, the pattern repeats. David introduces the possibility of a 2-2 split, and our odds don’t improve at all!</p>
<pre><code><span>% python heads.py
</span><span>A:T, B:T, C:T, D:T - chances -  H  0.0% | T 100.0% | occurs 21.0% of the time
</span><span>A:T, B:H, C:H, D:H - chances -  H 94.0% | T  6.0% | occurs 5.0% of the time
</span><span>A:T, B:H, C:T, D:T - chances -  H  6.0% | T 94.0% | occurs 5.0% of the time
</span><span>A:H, B:H, C:H, D:H - chances -  H 100.0% | T  0.0% | occurs 21.0% of the time
</span><span>A:H, B:T, C:H, D:T - chances -  H 50.0% | T 50.0% | occurs 3.0% of the time
</span><span>A:T, B:T, C:H, D:H - chances -  H 50.0% | T 50.0% | occurs 3.0% of the time
</span><span>A:H, B:T, C:H, D:H - chances -  H 94.0% | T  6.0% | occurs 5.0% of the time
</span><span>A:T, B:T, C:T, D:H - chances -  H  6.0% | T 94.0% | occurs 5.0% of the time
</span><span>A:H, B:T, C:T, D:T - chances -  H  6.0% | T 94.0% | occurs 5.0% of the time
</span><span>A:H, B:H, C:H, D:T - chances -  H 94.0% | T  6.0% | occurs 5.0% of the time
</span><span>A:H, B:H, C:T, D:T - chances -  H 50.0% | T 50.0% | occurs 3.0% of the time
</span><span>A:T, B:T, C:H, D:T - chances -  H  6.0% | T 94.0% | occurs 5.0% of the time
</span><span>A:H, B:H, C:T, D:H - chances -  H 94.0% | T  6.0% | occurs 5.0% of the time
</span><span>A:T, B:H, C:T, D:H - chances -  H 50.0% | T 50.0% | occurs 3.0% of the time
</span><span>A:H, B:T, C:T, D:H - chances -  H 50.0% | T 50.0% | occurs 3.0% of the time
</span><span>A:T, B:H, C:H, D:T - chances -  H 50.0% | T 50.0% | occurs 3.0% of the time
</span><span>
</span><span>Our accuracy: 90.0%
</span></code></pre>
<p>And this continues, on and on, forever (as long as we have enough friends). If our number <code>N</code> of friends is odd, our chances of guessing correctly don’t improve when we move to <code>N+1</code> friends.</p>
<h2 id="toc:is-there-a-name-for-this">Is there a name for this?</h2>
<p>As far as I can tell, there’s no name for this weird little phenomenon. But it <em>does</em> appear, implicitly, in voting literature.</p>
<p><a href="https://en.wikipedia.org/wiki/Condorcet%27s_jury_theorem">Condorcet’s jury theorem</a> is a famous theorem in political science. It states:</p>
<ul>
<li>If you have a group of voters of size <code>N</code></li>
<li>…and they all vote, independently, on an issue with a correct answer</li>
<li>…and each voter votes the “right” way with probability <code>P</code></li>
<li>…and we make whatever decision the majority of the voters vote for</li>
<li>…then if <code>P &gt; 50%</code>, the chance that we make the right decision approaches 100% as we add more voters</li>
</ul>
<p>Sounds a fair bit like our coin flipping problem. Here’s a simplifying assumption that Wikipedia makes when proving the theorem:</p>
<p><img alt="A screenshot from the wikipedia article on Condorcet's Jury Theorem. Full text: Proof 1: Calculating the probability that two additional voters change the outcome
To avoid the need for a tie-breaking rule, we assume n is odd. Essentially the same argument works for even n if ties are broken by adding a single voter." loading="lazy" width="1156" height="270" decoding="async" data-nimg="1" src="https://eieio.games/images/two-heads-arent-better-than-one/from-wikipedia.webp"></p>
<p>Hah! The proof explicitly recognizes (and dodges) the even-voter case precisely because that voter doesn’t add any information.</p>
<h2 id="toc:why-did-i-write-this">Why did I write this?</h2>
<p>I stumbled upon this result while writing a simulation for a more complex problem. I was <em>so</em> surprised at the simulation results that I assumed that I had a bug in my code. And when I walked through the math by hand I was absolutely delighted.</p>
<p>I suspect some of the surprise for me was because I typically encounter problems like these in the context of betting, not voting. If we’re <em>betting</em> on coin flips, we’re certainly excited to bet more if Alice and Bob agree than if we’re just listening to Alice.</p>
<p>But voting is a different beast; our outcome is binary. There’s no way to harvest the additional <a href="https://en.wikipedia.org/wiki/Expected_value">EV</a> from the increased confidence Bob sometimes gives us.</p>
<p>By the way - I encountered this problem while working with a friend at <a href="https://www.recurse.com/scout/click?t=4d29374c1894b0c33520021a254e0591">The Recurse Center</a> (a writers retreat for programmers). It’s a great place to get nerd sniped by silly math problems; If you enjoyed this blog consider <a href="https://www.recurse.com/apply">applying</a>!</p>
<p>Anyway. I hope this delights you like it did me.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every GitHub object has two IDs (160 pts)]]></title>
            <link>https://www.greptile.com/blog/github-ids</link>
            <guid>46602591</guid>
            <pubDate>Tue, 13 Jan 2026 15:52:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.greptile.com/blog/github-ids">https://www.greptile.com/blog/github-ids</a>, See on <a href="https://news.ycombinator.com/item?id=46602591">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>I was recently building a feature for Greptile (an AI-powered code review tool), when I hit a weird snag with GitHub's API.</p>
<p>The feature should have been simple: I wanted to add clickable links to GitHub PR comments, so users could jump directly from our reviews to relevant GitHub discussions. We already stored the comment IDs, so I just needed to construct the URLs.</p>
<p>The problem was, when I tested it, the links didn't work.</p>
<p>Searching through <a target="_blank" rel="noopener noreferrer" href="https://docs.github.com/en/graphql/guides/using-global-node-ids">GitHub's documentation</a> for answers revealed that their team maintains two separate ID systems. We'd been using GitHub's GraphQL API, which returns <a target="_blank" rel="noopener noreferrer" href="https://docs.github.com/en/graphql/reference/scalars#id">node IDs</a> like <code>PRRC_kwDOL4aMSs6Tkzl8</code>. GitHub designed these node IDs to uniquely identify any object across its entire system. But web URLs required database IDs, integer values visible in URLs and often associated with REST responses, like <code>2475899260</code>.</p>
<p>I was looking at either backfilling millions of records or migrating our entire database, and neither sounded fun. So I did what any annoyed engineer would do: I stared at these IDs for way too long, looking for a way out of the migration.</p>
<p>And I found it.</p>

<p>I looked for a relationship between these two ID formats. I pulled up a few of our stored node IDs and opened the corresponding PR comments from the same pull request in my editor:</p>
<div><table><thead><tr><th>Node ID</th><th>Database ID</th></tr></thead><tbody><tr><td><span>PRRC_kwDOL4aMSs</span><span>6Tkzl8</span></td><td>2475<span>899260</span></td></tr><tr><td><span>PRRC_kwDOL4aMSs</span><span>6Tkzya</span></td><td>2475<span>900058</span></td></tr><tr><td><span>PRRC_kwDOL4aMSs</span><span>6Tkz3e</span></td><td>2475<span>900382</span></td></tr></tbody></table></div>
<p>The database IDs incremented sequentially, and the node IDs were almost identical too, differing only in their last few characters. GitHub's documentation mentioned that node IDs are base64 encoded. I tried decoding just the part after <code>PRRC_</code>:</p>
<pre><div><pre><code>def base64_2_int(s):
    base64_part = s.split("_")[1]
    return int.from_bytes(base64.b64decode(base64_part))
</code></pre></div></pre>
<p>The decoded values were very long (96 bit) integers:</p>
<div><table><thead><tr><th>Node ID</th><th>Decoded Integer</th><th>Database ID</th></tr></thead><tbody><tr><td><span>PRRC_kwDOL4aMSs6Tkz</span><span>l8</span></td><td><span>454952701279253740627272</span><span>15484</span></td><td>24758992<span>60</span></td></tr><tr><td><span>PRRC_kwDOL4aMSs6Tkz</span><span>ya</span></td><td><span>454952701279253740627272</span><span>16282</span></td><td>24759000<span>58</span></td></tr><tr><td><span>PRRC_kwDOL4aMSs6Tkz</span><span>3e</span></td><td><span>454952701279253740627272</span><span>16606</span></td><td>24759003<span>82</span></td></tr></tbody></table></div>
<p>The decoded integers were incremented by 798, exactly matching the database ID increment. The database ID had to be embedded in there somewhere.</p>

<p>Since both values were changing by the same amount, and the decoded value was 96 bits, I figured the database ID was likely embedded in the lower 32 bits of the node ID. I wrote a quick test:</p>
<pre><div><pre><code>def node_id_to_database_id(s):
    decoded = int.from_bytes(base64.b64decode(s.split("_")[1]))
    # Mask to keep only the lower 32 bits
    return decoded &amp; ((1 &lt;&lt; 32) - 1)

node_id_to_database_id("PRRC_kwDOL4aMSs6Tkzl8")
# Returns: 2475899260
</code></pre></div></pre>
<p>It worked! The database ID was just the last 32 bits of the decoded node ID. I could skip the entire migration, and extract what I needed with a simple bitmask operation.</p>
<p>After the relief sunk in, I couldn't help but ask, "If the database ID only used the last 32 bits out of the 96 total bits, what were the first 64 bits being used for?"</p>
<p>Since the node ID is a global identifier across all of GitHub, I assumed that the extra 64 bits had to encode either the object type or an id to another resource that "owned" the current node. I wanted to see if I could decode them the same way I'd decoded the database ID.</p>

<p>To understand what was in those 64 bits, I started <a target="_blank" rel="noopener noreferrer" href="https://docs.github.com/en/graphql/overview/explorer">querying different GitHub objects</a>. My test repository returned the familiar <code>PRRC_</code> format for everything. I tried the first famous repository that came to mind, <code>torvalds/linux</code>, to see if the pattern held.</p>
<p>The response was a completely different base64 encoded string:</p>
<pre><code>MDEwOlJlcG9zaXRvcnkyMzI1Mjk4
MDQ6VHJlZTIzMjUyOTg6NzIwMWJmYjkyOGIyOWU4MGIwMDVkYTE1OTc4MzQ1ZjIzYmEwZmY5Yg==
MDQ6QmxvYjIzMjUyOTg6ZjM3MWExM2I0ZDE5MmQyZTM3ZDcwMTdiNjNlMzNkZmE3YzY3Mzc4Zg==
</code></pre>
<p>When I decoded these they showed the following:</p>
<pre><div><pre><code>base64.b64decode("MDEwOlJlcG9zaXRvcnkyMzI1Mjk4")
# Returns: b'010:Repository2325298'
</code></pre></div></pre>
<p>The Linux repository was using a completely different format. I realized the repository was created in 2011. By picking an old repository, I'd accidentally stumbled onto GitHub's legacy ID format which was quite simple:</p>
<pre><code>[Object Type Number]:[Object Type Name][Database ID]
</code></pre>
<p>That repository ID (<code>010:Repository2325298</code>) had a clear structure: <code>010</code> is some type enum, followed by a colon, the word <code>Repository</code>, and then the database ID <code>2325298</code>. Since repositories are just containers, I wanted to see if git objects like trees would reveal more complexity:</p>
<pre><div><pre><code>base64.b64decode("MDQ6VHJlZTIzMjUyOTg6NzIwMWJmYjkyOGI...")
# Returns: b'04:Tree2325298:7201bfb928b29e80b005da15978345f23ba0ff9b'
</code></pre></div></pre>
<p>That's the enum again, the word <code>Tree</code>, the repository ID, and the tree SHA.</p>
<p>It was apparent that GitHub had two systems for ID'ing their internal objects. Somewhere in GitHub's codebase, there's an if-statement checking when a repository was created to decide which ID format to return.</p>
<p>I started mapping out which objects used which format. The pattern wasn't as simple as "old repos use old IDs, new repos use new IDs":</p>
<div><table><thead><tr><th>Format</th><th>Example</th><th>Usage</th></tr></thead><tbody><tr><td>Legacy</td><td>MDEwOlJlcG9zaXRvcnkyMzI1Mjk4</td><td>Old repositories like torvalds/linux</td></tr><tr><td>New</td><td>PRRC_kwDOL4aMSs6Tkzl8</td><td>Newer repositories and most objects</td></tr></tbody></table></div>
<p>Old repositories kept their legacy IDs, while newer ones were issued IDs following the new format. But the split isn't clean; GitHub still uses the legacy format for some object types, like Users, even when newly created. New objects in old repositories sometimes get new IDs, sometimes don't. It depends on their creation date.</p>
<p>Surely the new format had some benefit that warranted this messy migration. It shouldn't be too hard to create a more efficient IDing system than base64 encoding the string representation of an enum and the object name. This information could easily be packed into those 64 extra bits that I still had to understand.</p>

<p>GitHub's <a target="_blank" rel="noopener noreferrer" href="https://docs.github.com/en/graphql/guides/migrating-graphql-global-node-ids">migration guide</a> tells developers to treat the new IDs as opaque strings and treat them as references. However it was clear that there was some underlying structure to these IDs as we just saw with the bitmasking. My best guess was that it used some binary serialization format, so I could just test a bunch to see what worked.</p>
<p>This is when I came across <a target="_blank" rel="noopener noreferrer" href="https://msgpack.org/">MessagePack</a>, a compact binary serialization format. It seemed promising as it was frequently used in Ruby projects, and GitHub's backend is built on Ruby. I tried decoding it:</p>
<pre><div><pre><code>import msgpack
import base64

def decode_new_node_id(node_id):
    prefix, encoded = node_id.split('_')
    packed = base64.b64decode(encoded)
    return msgpack.unpackb(packed)

decode_new_node_id("PRRC_kwDOL4aMSs6Tkzl8")
# Returns: [0, 47954445, 2475899260]
</code></pre></div></pre>
<p>It worked. The new format uses MessagePack to encode the relevant IDs into an array.</p>
<p>The structure made sense once I saw it:</p>
<ul>
<li><strong>First element (0):</strong> Still unclear. Probably a version identifier, but if you know what this is for, please email me at <a target="_blank" rel="noopener noreferrer" href="mailto:soohoon@greptile.com">soohoon@greptile.com</a>.</li>
<li><strong>Second element (47954445):</strong> The repository's database ID. This provides the context needed to make the ID global. Pull requests, issues, and comments are all usually scoped to a repository.</li>
<li><strong>Third element (2475899260):</strong> The object's database ID.</li>
</ul>
<p>Different object types sometimes have different array lengths. Repositories only need <code>[0, repository_database_id]</code>. Commits include the git SHA: <code>[0, repository_database_id, commit_sha]</code>. The first element is always 0, and repository-scoped objects include both the repository ID and the specific object identifier. Since the database ID of the comment is the last element in the array, when bitmasking for the lower 32 bits we are able extract just that.</p>

<p>What started as a URL generation problem turned into "reverse-engineering" and exploring of GitHub's ID system.</p>
<p>Putting it all together, for modern GitHub node IDs you can use:</p>
<pre><div><pre><code>import base64
import msgpack

def node_id_to_database_id(node_id):
    prefix, encoded = node_id.split('_')
    packed = base64.b64decode(encoded)
    array = msgpack.unpackb(packed)
    return array[-1]
</code></pre></div></pre>
<p>to extract the database ID for pull request comments. Should I have made sure that we were storing the right ID in the first place? Probably, but then I wouldn't have had much fun uncovering all of this. And my deepest condolences to the GitHub engineer who has to deal with supporting these two different node ID formats.</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What a year of solar and batteries saved us in 2025 (235 pts)]]></title>
            <link>https://scotthelme.co.uk/what-a-year-of-solar-and-batteries-really-saved-us-in-2025/</link>
            <guid>46602532</guid>
            <pubDate>Tue, 13 Jan 2026 15:49:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scotthelme.co.uk/what-a-year-of-solar-and-batteries-really-saved-us-in-2025/">https://scotthelme.co.uk/what-a-year-of-solar-and-batteries-really-saved-us-in-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=46602532">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-main">

        <article>

            


                <section>
                    <div>
                        <p>Throughout 2025, I spoke a few times about our home energy solution, including our grid usage, our solar array and our Tesla Powerwall batteries. Now that I have a full year of data, I wanted to take a look at exactly how everything is working out, and, in alignment with our objectives, how much money we've saved!</p><h4 id="our-setup">Our setup</h4><p>Just to give a quick overview of what we're working with, here are the details on our solar, battery and tariff situation:</p><ul><li>☀️Solar Panels: We have 14x Perlight solar panels managed by Enphase that make up the 4.2kWp array on our roof, and they produce energy when the sun shines, which isn't as often as I'd like in the UK!</li><li>🔋Tesla Powerwalls: We have 3x Tesla Powerwall 2 in our garage that were purchased to help us load-shift our energy usage. Electricity is very expensive in the UK and moving from peak usage which is 05:30 to 23:30 at ~£0.28/kWh, to off-peak usage, which is 23:30 - 05:30 at ~£0.07/kWh, is a significant cost saving.</li><li>💡Smart Tariff: My wife and I both drive electric cars and our electricity provider, Octopus Energy, has a Smart Charging tariff. If we plug in one of our cars, and cheap electricity is available, they will activate the charger and allow us to use the off-peak rate, even at peak times.</li></ul><p>Now that we have some basic info, let's get into the details!</p><h4 id="grid-import">Grid Import</h4><p>I have 3 sources of data for our grid import, and all of them align pretty well in terms of their measurements. I have the amount our electricity supplier charged us for, I have my own CT Clamp going via a Shelly EM that feeds in to Home Assistant, and I have the Tesla Gateway which controls all grid import into our home.</p><p>Starting with my Home Assistant data, these are the relevant readings. </p><p>Jan 1st 2025 - 15,106.10 kWh<br>Dec 31st 2025 - 36,680.90 kWh<br>Total: 21,574.80 kWh<br><strong>Total Import: 21.6 MWh</strong></p><figure><img src="https://scotthelme.co.uk/content/images/2026/01/image-3.png" alt="" loading="lazy" width="1138" height="503" srcset="https://scotthelme.co.uk/content/images/size/w600/2026/01/image-3.png 600w, https://scotthelme.co.uk/content/images/size/w1000/2026/01/image-3.png 1000w, https://scotthelme.co.uk/content/images/2026/01/image-3.png 1138w" sizes="(min-width: 720px) 720px"></figure><p>As you can see in the graph, during the summer months we have slightly lower grid usage and the graph line climbs at a lower rate, but overall, we have pretty consistent usage. Looking at what our energy supplier charged, us for, that comes in slightly lower.</p><p><strong>Total Import: 20.1 MWh</strong></p><figure><img src="https://scotthelme.co.uk/content/images/2026/01/image-8.png" alt="" loading="lazy" width="997" height="577" srcset="https://scotthelme.co.uk/content/images/size/w600/2026/01/image-8.png 600w, https://scotthelme.co.uk/content/images/2026/01/image-8.png 997w" sizes="(min-width: 720px) 720px"></figure><p>I'm going to use the figure provided by our energy supplier in my calculations because their equipment is likely more accurate than mine, and also, what they're charging me is the ultimate thing that matters. The final source is our Tesla Gateway, which shows us having imported 21.0 MWh.</p><figure><img src="https://scotthelme.co.uk/content/images/2026/01/image-11.png" alt="" loading="lazy" width="1290" height="1568" srcset="https://scotthelme.co.uk/content/images/size/w600/2026/01/image-11.png 600w, https://scotthelme.co.uk/content/images/size/w1000/2026/01/image-11.png 1000w, https://scotthelme.co.uk/content/images/2026/01/image-11.png 1290w" sizes="(min-width: 720px) 720px"></figure><p>It's great to see how all of these sources of data align so poorly! 😅</p><h4 id="grid-export">Grid Export</h4><p>Looking at our export, the graph tells a slightly different story because, as you can see, we didn't really start exporting properly until June, when our export tariff was activated. Prior to June, it simply wasn't worth exporting as we were only getting £0.04/kWh but at the end of May, our export tariff went live and we were then getting paid £0.15/kWh for export. My <a href="https://scotthelme.co.uk/automation-improvements-after-a-tesla-powerwall-outage/?ref=scotthelme.co.uk" rel="noreferrer">first</a> and <a href="https://scotthelme.co.uk/v2-hacking-my-tesla-powerwalls-to-be-the-ultimate-home-energy-solution/?ref=scotthelme.co.uk" rel="noreferrer">second</a> blog posts cover the full details of this change when it happened if you'd like to read them but for now, just note that it will change the calculations a little later as we only had export for 60% of the year.</p><p><strong>Total Export: 6.0 MWh</strong></p><figure><img src="https://scotthelme.co.uk/content/images/2026/01/image-9.png" alt="" loading="lazy" width="989" height="582" srcset="https://scotthelme.co.uk/content/images/size/w600/2026/01/image-9.png 600w, https://scotthelme.co.uk/content/images/2026/01/image-9.png 989w" sizes="(min-width: 720px) 720px"></figure><p>With our grid export covered the final piece of the puzzle is to look at our solar.</p><h4 id="solar-production">Solar Production</h4><p>We're really not in the best part of the world for generating solar power, but we've still managed to produce quite a bit of power. Even in the most ideal, perfect scenario, our solar array can only generate 4.2kW of power, and we're definitely never getting near that. Our peak production was 2.841kW on 8th July at 13:00, and you can see our full annual production graph here. </p><figure><img src="https://scotthelme.co.uk/content/images/2026/01/image-12.png" alt="" loading="lazy" width="1582" height="513" srcset="https://scotthelme.co.uk/content/images/size/w600/2026/01/image-12.png 600w, https://scotthelme.co.uk/content/images/size/w1000/2026/01/image-12.png 1000w, https://scotthelme.co.uk/content/images/2026/01/image-12.png 1582w" sizes="(min-width: 720px) 720px"></figure><p>Looking at the total energy production for the entire array, you can see it pick up through the sunnier months but remain quite flat during the darker days of the year.</p><figure><img src="https://scotthelme.co.uk/content/images/2026/01/image-2.png" alt="" loading="lazy" width="1132" height="504" srcset="https://scotthelme.co.uk/content/images/size/w600/2026/01/image-2.png 600w, https://scotthelme.co.uk/content/images/size/w1000/2026/01/image-2.png 1000w, https://scotthelme.co.uk/content/images/2026/01/image-2.png 1132w" sizes="(min-width: 720px) 720px"></figure><p>Jan 1st 2025 - 2.709 MWh<br>Dec 31st 2025 - 5.874 MWh<br><strong>Solar Production: 3.2 MWh</strong></p><p>Just to confirm, I also took a look at the Enphase app, which is drawing it's data from the same source to be fair, and it agrees with the 3.2 MWh of generation.</p><figure><img src="https://scotthelme.co.uk/content/images/2026/01/image-4.png" alt="" loading="lazy" width="1157" height="560" srcset="https://scotthelme.co.uk/content/images/size/w600/2026/01/image-4.png 600w, https://scotthelme.co.uk/content/images/size/w1000/2026/01/image-4.png 1000w, https://scotthelme.co.uk/content/images/2026/01/image-4.png 1157w" sizes="(min-width: 720px) 720px"></figure><h4 id="calculating-the-savings">Calculating the savings</h4><p>This isn't exactly straightforward because of the combination of our solar array and excess import/export due to the batteries, but here are the numbers I'm currently working on.</p><p><strong>Total Import: 20.1 MWh<br>Total Export: 6.0 MWh<br>Solar Production: 3.2 MWh</strong></p><p>That gives us a total household usage of 17.3 MWh.</p><p>(20.1 MWh import + 3.2 MWh solar) − 6.0 MWh export = 17.3 MWh usage</p><p>If we didn't have the solar array providing power, the full 17.3 MWh of consumption would have been chargeable from our provider. If we had only the solar and no battery, assuming a perfect ability to utilise our solar generation, only 14.1 MWh of our usage would need to be imported. The cost of those units of solar generation can be viewed at the peak and off-peak rates as follows.</p><p>Peak rate: 3,200 kWh x £0.28/kWh = £896<br>Off-peak rate: 3,200 kWh x £0.07/kWh = £224</p><p>Given that solar panels only produce during peak electricity rates, it would be reasonable to use the higher price here. A consideration for us though is that we do have batteries, and we're able to load-shift all of our usage into the off-peak rate, so arguably the solar panels only made £224 of electricity. </p><p>The bigger savings come when we start to look at the cost of the grid import. Assuming we had no solar panels, we'd have imported 17.3 MWh of electricity, and with the solar panels and perfect utilisation, we'd have imported 14.1 MWh of electricity. That's quite a lot of electricity and calculating the different costs of peak vs. off-peak by using batteries to load shift our usage gives some quite impressive results.</p><p>Peak rate: 17,300 kWh x £0.28/kWh = £4,844<br>Peak rate with solar: 14,100 kWh x £0.28 = £3,948</p><p>Off-peak rate: 17,300 kWh x £0.07/kWh = £1,211<br>Off-peak rate with solar: 14,100 kWh x £0.07/kWh = £987</p><p>This means there's a potential swing from £4,844 down to £987 with solar and battery, a total potential saving of £3,857!</p><p>This also tracks if we look at our monthly spend on electricity which went from £350-£400 per month down to £50-£100 per month depending on the time of year. But it gets better.</p><h4 id="exporting-excess-energy">Exporting excess energy</h4><p>Our solar array generates almost nothing in the winter months so our batteries are sized to allow for a full day of usage with basically no solar support. We can go from the start of the peak rate at 05:30 all the way to the off-peak rate at 23:30 without using any grid power. When it comes to the summer months, though, our solar array is producing a lot of power and we clearly have a capability to export a lot more. The batteries can fill up on the off-peak rate overnight at £0.07/kWh, and then export it during the peak rate for £0.15/kWh, meaning any excess solar production or battery capacity can be exported for a reasonable amount.</p><p>If we take a look at the billing information from our energy supplier, we can see that during July, our best month for solar production, we exported a lot of energy. We exported so much energy that it actually fully offset our electricity costs and allowed us to go negative, meaning we were earning money back.</p><p>Here is our electricity import data:</p><figure><img src="https://scotthelme.co.uk/content/images/2026/01/image-7.png" alt="" loading="lazy" width="988" height="623" srcset="https://scotthelme.co.uk/content/images/size/w600/2026/01/image-7.png 600w, https://scotthelme.co.uk/content/images/2026/01/image-7.png 988w" sizes="(min-width: 720px) 720px"></figure><p>And here is our electricity export data:</p><figure><img src="https://scotthelme.co.uk/content/images/2026/01/image-6.png" alt="" loading="lazy" width="983" height="706" srcset="https://scotthelme.co.uk/content/images/size/w600/2026/01/image-6.png 600w, https://scotthelme.co.uk/content/images/2026/01/image-6.png 983w" sizes="(min-width: 720px) 720px"></figure><p>That's a pretty epic scenario, despite us being such high energy consumers, to still have the ability to full cover our costs and even earn something back! For clarity, we will still have the standing charge component of our bill, which is £0.45/day so about £13.50 per month to go on any given month, but looking at the raw energy costs, it's impressive.</p><h4 id="the-final-calculation">The final calculation</h4><p>I pulled all of our charges for electricity in 2025 to see just how close my calculations were and to double check everything I was thinking. Earlier, I gave these figures:</p><p>Off-peak rate: 17,300 kWh x £0.07/kWh = £1,211</p><p>If 100% of our electricity usage was at the off-peak rate, we should have paid £1,211 for the year. Adding up all of our monthly charges, our total for the year was £1,608.11 all in, but we need to subtract our standing charge from that.</p><p>Total cost = £1,608.11 - (365 * £0.45)<br><strong>Total import = £1,443.86</strong></p><p>This means that we got almost all of our usage at the off-peak rate which is an awesome achievement! After the charges for electricity, I then tallied up all of our payments for export.</p><p><strong>Total export = £886.49</strong></p><p>Another pretty impressive achievement, earning so much in export, which also helps to bring our net electricity cost in 2025 to <strong>£557.37</strong>! To put this another way, the effective rate of our electricity is now just £0.03/kWh.</p><p>£557.37 / 17,300kWh = <strong>£0.03/kWh</strong></p><h4 id="but-was-it-all-worth-it">But was it all worth it?</h4><p>That's a tricky question to answer, and everyone will have different objectives and desired outcomes, but ours was pretty clear. Running two Electric Vehicles, having two adults working from home full time, me having servers and equipment at home, along with a power hungry hot tub, we were spending too much per month in electricity alone, and our goal was to reduce that.</p><p>Of course, it only makes sense to spend money reducing our costs if we reduce them enough to pay back the investment in the long term, and things are looking good so far. Here are the costs for our installations:</p><p>£17,580 - Powerwalls #1 and #2 installed.<br>£13,940 - Solar array installed.<br>£7,840  - Powerwall #3 installed.<br>Total cost = £39,360</p><p>If we assume even a generous 2/3 - 1/3 split between peak and off-peak usage, with no Powerwalls or solar array, our electricity costs for 2025 would have been £3,632.86:</p><p>11,533 kWh x £0.28/kWh = £3,229.24<br>5,766 kWh x £0.07/kWh = £403.62<br>Total = £3,632.86</p><p>Instead, our costs were only £557.37, meaning we saved £3,078.49 this year. We also only had export capabilities for 7 months of 2025, so in 2026 when we will have 12 months of export capabilities, we should further reduce our costs. I anticipate that in 2026 our electricity costs for the year will be ~£0, and that's our goal.</p><p>Having our full costs returned in ~11 years is definitely something we're happy with, and we've also had protection against several power outages in our area along the way, which is a very nice bonus. Another way to look at this is that the investment is returning ~9%/year.</p><table>
<thead>
<tr>
<th>Year</th>
<th>Cumulative savings (£)</th>
<th>ROI (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>3,632.86</td>
<td>9.23%</td>
</tr>
<tr>
<td>2</td>
<td>7,265.72</td>
<td>18.46%</td>
</tr>
<tr>
<td>3</td>
<td>10,898.58</td>
<td>27.69%</td>
</tr>
<tr>
<td>4</td>
<td>14,531.44</td>
<td>36.92%</td>
</tr>
<tr>
<td>5</td>
<td>18,164.30</td>
<td>46.15%</td>
</tr>
<tr>
<td>6</td>
<td>21,797.16</td>
<td>55.38%</td>
</tr>
<tr>
<td>7</td>
<td>25,430.02</td>
<td>64.61%</td>
</tr>
<tr>
<td>8</td>
<td>29,062.88</td>
<td>73.84%</td>
</tr>
<tr>
<td>9</td>
<td>32,695.74</td>
<td>83.07%</td>
</tr>
<tr>
<td>10</td>
<td>36,328.60</td>
<td>92.30%</td>
</tr>
<tr>
<td>15</td>
<td>54,492.90</td>
<td>138.43%</td>
</tr>
<tr>
<td>20</td>
<td>72,657.20</td>
<td>184.61%</td>
</tr>
<tr>
<td>25</td>
<td>90,821.50</td>
<td>230.76%</td>
</tr>
</tbody>
</table>
<p>Of course, at some point during that period, the effective value of the installation will reduce to almost £0, and we have to consider that, but it's doing pretty darn good. If we hadn't needed to add that third Powerwall, this would have been so much better too. We'll see what the future holds, but with the inevitable and continued rise of energy costs, and talk of moving the standing charge on to our unit rate, things might look even better in the future.</p><h4 id="onwards-to-2026">Onwards to 2026!</h4><p>Now that we have everything properly set up, and I'm happy with all of our Home Assistant automations, we're going to see how 2026 goes. I will definitely circle back in a year from now and see how the numbers played out, and until then, I hope the information here has been useful or interesting 👍</p>
                    </div>
					<br>Have you enjoyed this post or found it helpful?
					<br>☕️ Consider <a href="https://donate.stripe.com/4gMeVd3xm0sOcRzexF93y00" target="_blank">buying me a coffee</a> to say thanks!
					<br>🔔 Subscribe for <a href="https://scotthelme.ghost.io/#/portal/signup" target="_blank">free notifications</a> when I publish!
					<br>🤩 Become a <a href="https://scotthelme.ghost.io/#/portal/signup" target="_blank">member</a> and support my content!
					<p>
		        <i></i>
		        Tags: <a href="https://scotthelme.co.uk/tag/tesla-powerwall/">Tesla Powerwall</a>, <a href="https://scotthelme.co.uk/tag/solar-power/">Solar Power</a>, <a href="https://scotthelme.co.uk/tag/octopus-energy/">Octopus Energy</a></p>
                </section>


        </article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Self-host Reddit – 2.38B posts, works offline, yours forever (206 pts)]]></title>
            <link>https://github.com/19-84/redd-archiver</link>
            <guid>46602324</guid>
            <pubDate>Tue, 13 Jan 2026 15:35:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/19-84/redd-archiver">https://github.com/19-84/redd-archiver</a>, See on <a href="https://news.ycombinator.com/item?id=46602324">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Redd-Archiver</h2><a id="user-content-redd-archiver" aria-label="Permalink: Redd-Archiver" href="#redd-archiver"></a></p>
<p dir="auto"><a href="http://unlicense.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/f56402b65984387744b74789a0f5878c88867bccd32059aff5f72a9df726c441/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d556e6c6963656e73652d626c75652e737667" alt="License: Unlicense" data-canonical-src="https://img.shields.io/badge/license-Unlicense-blue.svg"></a>
<a href="https://www.python.org/downloads/" rel="nofollow"><img src="https://camo.githubusercontent.com/b413597d37ccc8eae784ee4f9979e61fe739bbdcd0f6247e4aa0d68c6f1659ca/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e372b2d626c75652e737667" alt="Python 3.7+" data-canonical-src="https://img.shields.io/badge/python-3.7+-blue.svg"></a>
<a href="https://www.postgresql.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/dddcfe8d0d1074a2f5d1e5beed134242fa669f7256804926cc28c472ff8437fa/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f506f737467726553514c2d72657175697265642d626c75652e737667" alt="PostgreSQL Required" data-canonical-src="https://img.shields.io/badge/PostgreSQL-required-blue.svg"></a>
<a href="https://github.com/19-84/redd-archiver/blob/main"><img src="https://camo.githubusercontent.com/9b8a63eb5a126d3f3cbb0562344d18b70c87ad94abe2d66bbf324e05c489cfb2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f76657273696f6e2d312e302e302d627269676874677265656e2e737667" alt="Version 1.0.0" data-canonical-src="https://img.shields.io/badge/version-1.0.0-brightgreen.svg"></a>
<a href="https://github.com/19-84/redd-archiver/blob/main"><img src="https://camo.githubusercontent.com/e8843ce331d1dd0e934d491d5309eab745b9546e838c9566ba718290ab52827e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d732d526564646974253230253743253230566f61742532302537432532305275717175732d6f72616e67652e737667" alt="Multi-Platform" data-canonical-src="https://img.shields.io/badge/platforms-Reddit%20%7C%20Voat%20%7C%20Ruqqus-orange.svg"></a>
<a href="https://github.com/19-84/redd-archiver/blob/main"><img src="https://camo.githubusercontent.com/2fa061a2680c6ce892ccf3da22b0f52b9a8c9cad6c540e665572176ad8051b07/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d43502d3239253230746f6f6c732d707572706c652e737667" alt="MCP Server" data-canonical-src="https://img.shields.io/badge/MCP-29%20tools-purple.svg"></a></p>
<p dir="auto">Transform compressed data dumps into browsable HTML archives with flexible deployment options. Redd-Archiver supports offline browsing via sorted index pages OR full-text search with Docker deployment. Features mobile-first design, multi-platform support, and enterprise-grade performance with PostgreSQL full-text indexing.</p>
<p dir="auto"><strong>Supported Platforms</strong>:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Platform</th>
<th>Format</th>
<th>Status</th>
<th>Available Posts</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Reddit</strong></td>
<td>.zst JSON Lines (Pushshift)</td>
<td>✅ Full support</td>
<td>2.38B posts (40,029 subreddits, through Dec 31 2024)</td>
</tr>
<tr>
<td><strong>Voat</strong></td>
<td>SQL dumps</td>
<td>✅ Full support</td>
<td>3.81M posts, 24.1M comments (22,637 subverses, complete archive)</td>
</tr>
<tr>
<td><strong>Ruqqus</strong></td>
<td>.7z JSON Lines</td>
<td>✅ Full support</td>
<td>500K posts (6,217 guilds, complete archive)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><em>Tracked content: <strong>2.384 billion posts across 68,883 communities</strong> (Reddit full Pushshift dataset through Dec 31 2024, Voat/Ruqqus complete archives)</em></p>
<p dir="auto"><strong>Version 1.0</strong> features multi-platform archiving, REST API with 30+ endpoints, MCP server for AI integration, and PostgreSQL-backed architecture for large-scale processing.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Quick Start</h2><a id="user-content--quick-start" aria-label="Permalink: 🚀 Quick Start" href="#-quick-start"></a></p>
<p dir="auto"><strong>Try the live demo:</strong> <a href="https://online-archives.github.io/redd-archiver-example/" rel="nofollow">Browse Example Archive →</a></p>
<p dir="auto"><strong>New to Redd-Archiver? Start here:</strong> <a href="https://github.com/19-84/redd-archiver/blob/main/QUICKSTART.md">QUICKSTART.md</a></p>
<p dir="auto">Get running in 2-15 minutes with our step-by-step guide covering:</p>
<ul dir="auto">
<li>Local testing (5 minutes)</li>
<li>Tor homelab deployment (2 minutes) - no domain or port forwarding needed!</li>
<li>Production HTTPS (15 minutes)</li>
<li>Example data testing</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎯 Key Features</h2><a id="user-content--key-features" aria-label="Permalink: 🎯 Key Features" href="#-key-features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🌐 Multi-Platform Support</h3><a id="user-content--multi-platform-support" aria-label="Permalink: 🌐 Multi-Platform Support" href="#-multi-platform-support"></a></p>
<p dir="auto">Archive content from multiple link aggregator platforms in a single unified archive:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Platform</th>
<th>Format</th>
<th>CLI Flag</th>
<th>URL Prefix</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Reddit</strong></td>
<td>.zst JSON Lines</td>
<td><code>--subreddit</code></td>
<td><code>/r/</code></td>
</tr>
<tr>
<td><strong>Voat</strong></td>
<td>SQL dumps</td>
<td><code>--subverse</code></td>
<td><code>/v/</code></td>
</tr>
<tr>
<td><strong>Ruqqus</strong></td>
<td>.7z JSON Lines</td>
<td><code>--guild</code></td>
<td><code>/g/</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<ul dir="auto">
<li><strong>Automatic Detection</strong>: Platform auto-detected from file extensions</li>
<li><strong>Unified Search</strong>: PostgreSQL FTS searches across all platforms</li>
<li><strong>Mixed Archives</strong>: Combine Reddit, Voat, and Ruqqus in single archive</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">🤖 MCP Server (AI Integration)</h3><a id="user-content--mcp-server-ai-integration" aria-label="Permalink: 🤖 MCP Server (AI Integration)" href="#-mcp-server-ai-integration"></a></p>
<p dir="auto">29 MCP tools auto-generated from OpenAPI for AI assistants:</p>
<ul dir="auto">
<li><strong>Full Archive Access</strong>: Query posts, comments, users, search via Claude Desktop or Claude Code</li>
<li><strong>Token Overflow Prevention</strong>: Built-in LLM guidance with field selection and truncation</li>
<li><strong>5 MCP Resources</strong>: Instant access to stats, top posts, subreddits, search help</li>
<li><strong>Claude Code Ready</strong>: Copy-paste configuration for immediate use</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;mcpServers&quot;: {
    &quot;reddarchiver&quot;: {
      &quot;command&quot;: &quot;uv&quot;,
      &quot;args&quot;: [&quot;--directory&quot;, &quot;/path/to/mcp_server&quot;, &quot;run&quot;, &quot;python&quot;, &quot;server.py&quot;],
      &quot;env&quot;: { &quot;REDDARCHIVER_API_URL&quot;: &quot;http://localhost:5000&quot; }
    }
  }
}"><pre>{
  <span>"mcpServers"</span>: {
    <span>"reddarchiver"</span>: {
      <span>"command"</span>: <span><span>"</span>uv<span>"</span></span>,
      <span>"args"</span>: [<span><span>"</span>--directory<span>"</span></span>, <span><span>"</span>/path/to/mcp_server<span>"</span></span>, <span><span>"</span>run<span>"</span></span>, <span><span>"</span>python<span>"</span></span>, <span><span>"</span>server.py<span>"</span></span>],
      <span>"env"</span>: { <span>"REDDARCHIVER_API_URL"</span>: <span><span>"</span>http://localhost:5000<span>"</span></span> }
    }
  }
}</pre></div>
<p dir="auto">See <a href="https://github.com/19-84/redd-archiver/blob/main/mcp_server/README.md">MCP Server Documentation</a> for complete setup guide.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Core Functionality</h3><a id="user-content-core-functionality" aria-label="Permalink: Core Functionality" href="#core-functionality"></a></p>
<ul dir="auto">
<li><strong>📱 Mobile-First Design</strong>: Responsive layout optimized for all devices with touch-friendly navigation</li>
<li><strong>🔍 Advanced Search System (Server Required)</strong>: PostgreSQL full-text search optimized for Tor network. Search by keywords, subreddit, author, date, score. <em>Requires Docker deployment - offline browsing uses sorted index pages.</em></li>
<li><strong>⚡ JavaScript Free</strong>: Complete functionality without JS, pure CSS interactions</li>
<li><strong>🎨 Theme Support</strong>: Built-in light/dark theme toggle with CSS-only implementation</li>
<li><strong>♿ Accessibility</strong>: WCAG compliant with keyboard navigation and screen reader support</li>
<li><strong>🚄 Performance</strong>: Optimized CSS (29KB), designed for low-bandwidth networks</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Technical Excellence</h3><a id="user-content-technical-excellence" aria-label="Permalink: Technical Excellence" href="#technical-excellence"></a></p>
<ul dir="auto">
<li><strong>🏗️ Modular Architecture</strong>: 18 specialized modules for maintainability and extensibility</li>
<li><strong>🗄️ PostgreSQL Backend</strong>: Large-scale processing with constant memory usage regardless of dataset size</li>
<li><strong>⚡ Lightning-Fast Search</strong>: PostgreSQL full-text search with GIN indexing</li>
<li><strong>🌐 REST API v1</strong>: 30+ endpoints with MCP/AI optimization for programmatic access to posts, comments, users, statistics, search, aggregations, and exports</li>
<li><strong>🧅 Tor-Optimized</strong>: Zero JavaScript, server-side search, no external dependencies</li>
<li><strong>📊 Rich Statistics</strong>: Comprehensive analytics dashboard with file size tracking</li>
<li><strong>🔗 SEO Optimized</strong>: Complete meta tags, XML sitemaps, and structured data</li>
<li><strong>💾 Streaming Processing</strong>: Memory-efficient with automatic resume capability</li>
<li><strong>📈 Progress Tracking</strong>: Real-time transfer rates, ETAs, and database metrics</li>
<li><strong>🏆 Instance Registry</strong>: Leaderboard system with completeness-weighted scoring for distributed archives</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Deployment Options</h3><a id="user-content-deployment-options" aria-label="Permalink: Deployment Options" href="#deployment-options"></a></p>
<ul dir="auto">
<li><strong>🏠 Local/Homelab</strong>: HTTP on localhost or LAN (2 commands)</li>
<li><strong>🌐 Production HTTPS</strong>: Automated Let's Encrypt setup (5 minutes)</li>
<li><strong>🧅 Tor Hidden Service</strong>: .onion access, zero networking config (2 minutes)</li>
<li><strong>🔀 Dual-Mode</strong>: HTTPS + Tor simultaneously</li>
<li><strong>📄 Static Hosting</strong>: GitHub/Codeberg Pages for small archives (browse-only, no search)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">📦 Deployment Options</h2><a id="user-content--deployment-options" aria-label="Permalink: 📦 Deployment Options" href="#-deployment-options"></a></p>
<p dir="auto">Redd-Archiver generates static HTML files that can be browsed offline OR deployed with full-text search:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Mode</th>
<th>Search</th>
<th>Server</th>
<th>Setup Time</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Offline Browsing</strong></td>
<td>❌ Browse-only</td>
<td>None</td>
<td>0 min</td>
<td>USB drives, local archives, offline research</td>
</tr>
<tr>
<td><strong>Static Hosting</strong></td>
<td>❌ Browse-only</td>
<td>GitHub/Codeberg Pages</td>
<td>10 min</td>
<td>Free public hosting (size limits)</td>
</tr>
<tr>
<td><strong>Docker Local</strong></td>
<td>✅ PostgreSQL FTS</td>
<td>localhost</td>
<td>5 min</td>
<td>Development, testing</td>
</tr>
<tr>
<td><strong>Docker + Tor</strong></td>
<td>✅ PostgreSQL FTS</td>
<td>.onion hidden service</td>
<td>2 min</td>
<td>Private sharing, no port forwarding</td>
</tr>
<tr>
<td><strong>Docker + HTTPS</strong></td>
<td>✅ PostgreSQL FTS</td>
<td>Public domain</td>
<td>15 min</td>
<td>Production public archives</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Offline Browsing Features</strong>:</p>
<ul dir="auto">
<li>Sorted index pages (by score, comments, date)</li>
<li>Pagination for large subreddits</li>
<li>Full comment threads and user pages</li>
<li>Works by opening HTML files directly</li>
</ul>
<p dir="auto"><strong>With Search Server</strong>:</p>
<ul dir="auto">
<li>PostgreSQL full-text search with GIN indexing</li>
<li>Search by keywords, subreddit, author, date, score</li>
<li>Sub-second results, Tor-compatible</li>
<li>Requires Docker deployment</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚨 Get Involved: Help Preserve Internet History</h2><a id="user-content--get-involved-help-preserve-internet-history" aria-label="Permalink: 🚨 Get Involved: Help Preserve Internet History" href="#-get-involved-help-preserve-internet-history"></a></p>
<p dir="auto">Internet content disappears every day. Communities get banned, platforms shut down, and valuable discussions vanish. <strong>You can help prevent this.</strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">📥 Download &amp; Mirror Data Now</h3><a id="user-content--download--mirror-data-now" aria-label="Permalink: 📥 Download &amp; Mirror Data Now" href="#-download--mirror-data-now"></a></p>
<p dir="auto"><strong>Don't wait for content to disappear.</strong> Download these datasets today:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Platform</th>
<th>Size</th>
<th>Posts</th>
<th>Download</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Reddit</strong></td>
<td>3.28TB</td>
<td>2.38B posts</td>
<td><a href="https://academictorrents.com/details/1614740ac8c94505e4ecb9d88be8bed7b6afddd4" rel="nofollow">Academic Torrents</a> · Magnet Link</td>
</tr>
<tr>
<td><strong>Voat</strong></td>
<td>~15GB</td>
<td>3.8M posts</td>
<td><a href="https://archive.org/details/voat-archive-2021" rel="nofollow">Archive.org</a> †</td>
</tr>
<tr>
<td><strong>Ruqqus</strong></td>
<td>~752MB</td>
<td>500K posts</td>
<td><a href="https://archive.org/details/ruqqus-archive-2021" rel="nofollow">Archive.org</a> ‡</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">† <strong>Voat Performance Tip</strong>: Use <a href="https://github.com/19-84/redd-archiver/blob/main/tools/README_VOAT_SPLITTER.md">pre-split files</a> for 1000x faster imports (2-5 min vs 30+ min per subverse)
‡ <strong>Ruqqus</strong>: Docker image includes p7zip for automatic .7z decompression</p>
<p dir="auto"><strong>Every mirror matters.</strong> Store locally, seed torrents, share with researchers. Be part of the preservation network.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🌐 Join the Registry: Deploy Your Instance</h3><a id="user-content--join-the-registry-deploy-your-instance" aria-label="Permalink: 🌐 Join the Registry: Deploy Your Instance" href="#-join-the-registry-deploy-your-instance"></a></p>
<p dir="auto"><strong>Already running an archive?</strong> Register it on our public leaderboard:</p>
<ol dir="auto">
<li>Deploy your instance (<a href="https://github.com/19-84/redd-archiver/blob/main/QUICKSTART.md">Quick Start</a> - 2-15 minutes)</li>
<li>Submit via <a href="https://github.com/19-84/redd-archiver/blob/main/.github/ISSUE_TEMPLATE/register-instance.yml">Registry Template</a></li>
<li>Join coordinated preservation efforts with other teams</li>
</ol>
<p dir="auto"><strong>Benefits</strong>:</p>
<ul dir="auto">
<li>Public visibility and traffic</li>
<li>Coordinated archiving to avoid duplication</li>
<li>Team collaboration opportunities</li>
<li>Leaderboard recognition</li>
</ul>
<p dir="auto">👉 <strong><a href="https://github.com/19-84/redd-archiver/blob/main/.github/ISSUE_TEMPLATE/register-instance.yml">Register Your Instance Now →</a></strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🆕 Submit New Data Sources</h3><a id="user-content--submit-new-data-sources" aria-label="Permalink: 🆕 Submit New Data Sources" href="#-submit-new-data-sources"></a></p>
<p dir="auto"><strong>Found a new platform dataset?</strong> Help expand the archive network:</p>
<ul dir="auto">
<li>Lemmy databases</li>
<li>Hacker News archives</li>
<li>Alternative Reddit archives</li>
<li>Other link aggregator platforms</li>
</ul>
<p dir="auto">👉 <strong><a href="https://github.com/19-84/redd-archiver/blob/main/.github/ISSUE_TEMPLATE/submit-data-source.yml">Submit Data Source →</a></strong></p>
<p dir="auto"><strong>Why submit?</strong></p>
<ul dir="auto">
<li>Makes data discoverable for other archivists</li>
<li>Prevents duplicate preservation efforts</li>
<li>Builds comprehensive multi-platform archive ecosystem</li>
<li>Tracks data availability before platforms disappear</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📸 Screenshots</h2><a id="user-content--screenshots" aria-label="Permalink: 📸 Screenshots" href="#-screenshots"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dashboard</h3><a id="user-content-dashboard" aria-label="Permalink: Dashboard" href="#dashboard"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/screenshots/01-dashboard.png"><img src="https://github.com/19-84/redd-archiver/raw/main/screenshots/01-dashboard.png" alt="Dashboard"></a></p>
<p dir="auto">Main landing page showing archive overview with statistics for 9,592 posts across Reddit, Voat, and Ruqqus. Features customizable branding (site name, project URL), responsive cards, activity metrics, and content statistics. <em>(Works offline)</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Subreddit Index</h3><a id="user-content-subreddit-index" aria-label="Permalink: Subreddit Index" href="#subreddit-index"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/screenshots/02-subreddit-index.png"><img src="https://github.com/19-84/redd-archiver/raw/main/screenshots/02-subreddit-index.png" alt="Subreddit Index"></a></p>
<p dir="auto">Post listing with sorting options (score, comments, date), pagination, and badge coloring. Includes navigation and theme toggle. <em>(Works offline - sorted by score/comments/date)</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Post Page with Comments</h3><a id="user-content-post-page-with-comments" aria-label="Permalink: Post Page with Comments" href="#post-page-with-comments"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/screenshots/03-post-page.png"><img src="https://github.com/19-84/redd-archiver/raw/main/screenshots/03-post-page.png" alt="Post Page"></a></p>
<p dir="auto">Individual post displaying nested comment threads with collapsible UI, user flair, and timestamps. Comments include anchor links for direct navigation from user pages. <em>(Works offline)</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mobile Responsive Design</h3><a id="user-content-mobile-responsive-design" aria-label="Permalink: Mobile Responsive Design" href="#mobile-responsive-design"></a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/screenshots/05-mobile-dashboard.png"><img src="https://github.com/19-84/redd-archiver/raw/main/screenshots/05-mobile-dashboard.png" width="375" alt="Mobile Dashboard"></a>
</p>
<p dir="auto">Fully optimized for mobile devices with touch-friendly navigation and responsive layout.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Search Interface</h3><a id="user-content-search-interface" aria-label="Permalink: Search Interface" href="#search-interface"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/screenshots/07-search-form.png"><img src="https://github.com/19-84/redd-archiver/raw/main/screenshots/07-search-form.png" alt="Search Form"></a></p>
<p dir="auto">PostgreSQL full-text search with Google-style operators. Supports filtering by subreddit, author, date range, and score. <em>(Requires Docker deployment)</em></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/screenshots/08-search-results.png"><img src="https://github.com/19-84/redd-archiver/raw/main/screenshots/08-search-results.png" alt="Search Results"></a></p>
<p dir="auto">Search results with highlighted excerpts using PostgreSQL <code>ts_headline()</code>. Sub-second response times with GIN indexing. <em>(Server-based, Tor-compatible)</em></p>
<blockquote>
<p dir="auto"><strong>Sample Archive</strong>: Multi-platform archive featuring programming and technology communities from Reddit, Voat, and Ruqqus · <a href="https://github.com/19-84/redd-archiver/blob/main/screenshots">See all screenshots →</a></p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">🛠️ Installation</h2><a id="user-content-️-installation" aria-label="Permalink: 🛠️ Installation" href="#️-installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Prerequisites</h3><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<ul dir="auto">
<li><strong>Python 3.7 or higher</strong></li>
<li><strong>PostgreSQL 12+</strong> (required for v1.0+)</li>
<li>4GB+ RAM (PostgreSQL uses constant memory)</li>
<li>Disk space: ~1.5-2x your input .zst file size for PostgreSQL database</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python Dependencies</h3><a id="user-content-python-dependencies" aria-label="Permalink: Python Dependencies" href="#python-dependencies"></a></p>
<p dir="auto">Redd-Archiver uses modern, performance-focused dependencies:</p>
<p dir="auto"><strong>Core:</strong></p>
<ul dir="auto">
<li><code>psycopg[binary,pool]==3.2.3</code> - PostgreSQL adapter with connection pooling</li>
<li><code>zstandard==0.23.0</code> - Fast .zst decompression</li>
<li><code>psutil==6.1.1</code> - System resource monitoring</li>
</ul>
<p dir="auto"><strong>HTML Generation:</strong></p>
<ul dir="auto">
<li><code>jinja2&gt;=3.1.6</code> - Modern template engine with inheritance</li>
<li><code>rcssmin&gt;=1.1.2</code> - CSS minification for smaller file sizes</li>
</ul>
<p dir="auto"><strong>Performance:</strong></p>
<ul dir="auto">
<li><code>orjson&gt;=3.11.4</code> - Fast JSON parsing</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Quick Start</h3><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Option 1: Docker (Recommended)</h4><a id="user-content-option-1-docker-recommended" aria-label="Permalink: Option 1: Docker (Recommended)" href="#option-1-docker-recommended"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/19-84/redd-archiver.git
cd redd-archiver

# Create required directories
mkdir -p data output logs tor-public

# Copy environment template and configure
cp .env.example .env
# Edit .env with your settings (change default passwords!)

# Start PostgreSQL container
docker-compose up -d

# Install Python dependencies
pip install -r requirements.txt

# Configure database connection
export DATABASE_URL=&quot;postgresql://reddarchiver:your_password_here@localhost:5432/reddarchiver&quot;

# Run the archive generator
python reddarc.py /path/to/data/ --output my-archive/"><pre>git clone https://github.com/19-84/redd-archiver.git
<span>cd</span> redd-archiver

<span><span>#</span> Create required directories</span>
mkdir -p data output logs tor-public

<span><span>#</span> Copy environment template and configure</span>
cp .env.example .env
<span><span>#</span> Edit .env with your settings (change default passwords!)</span>

<span><span>#</span> Start PostgreSQL container</span>
docker-compose up -d

<span><span>#</span> Install Python dependencies</span>
pip install -r requirements.txt

<span><span>#</span> Configure database connection</span>
<span>export</span> DATABASE_URL=<span><span>"</span>postgresql://reddarchiver:your_password_here@localhost:5432/reddarchiver<span>"</span></span>

<span><span>#</span> Run the archive generator</span>
python reddarc.py /path/to/data/ --output my-archive/</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Option 2: Local PostgreSQL</h4><a id="user-content-option-2-local-postgresql" aria-label="Permalink: Option 2: Local PostgreSQL" href="#option-2-local-postgresql"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/19-84/redd-archiver.git
cd redd-archiver

# Install PostgreSQL (Ubuntu/Debian)
sudo apt update &amp;&amp; sudo apt install postgresql postgresql-contrib

# Or on macOS
brew install postgresql@16 &amp;&amp; brew services start postgresql@16

# Create database
sudo -u postgres createuser redd-archiver
sudo -u postgres createdb -O redd-archiver redd-archiver
sudo -u postgres psql -c &quot;ALTER USER redd-archiver WITH PASSWORD 'your_password_here';&quot;

# Install Python dependencies
pip install -r requirements.txt

# Configure database connection
export DATABASE_URL=&quot;postgresql://reddarchiver:your_password_here@localhost:5432/reddarchiver&quot;

# Run the archive generator
python reddarc.py /path/to/data/ --output my-archive/"><pre>git clone https://github.com/19-84/redd-archiver.git
<span>cd</span> redd-archiver

<span><span>#</span> Install PostgreSQL (Ubuntu/Debian)</span>
sudo apt update <span>&amp;&amp;</span> sudo apt install postgresql postgresql-contrib

<span><span>#</span> Or on macOS</span>
brew install postgresql@16 <span>&amp;&amp;</span> brew services start postgresql@16

<span><span>#</span> Create database</span>
sudo -u postgres createuser redd-archiver
sudo -u postgres createdb -O redd-archiver redd-archiver
sudo -u postgres psql -c <span><span>"</span>ALTER USER redd-archiver WITH PASSWORD 'your_password_here';<span>"</span></span>

<span><span>#</span> Install Python dependencies</span>
pip install -r requirements.txt

<span><span>#</span> Configure database connection</span>
<span>export</span> DATABASE_URL=<span><span>"</span>postgresql://reddarchiver:your_password_here@localhost:5432/reddarchiver<span>"</span></span>

<span><span>#</span> Run the archive generator</span>
python reddarc.py /path/to/data/ --output my-archive/</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Upgrading?</h4><a id="user-content-upgrading" aria-label="Permalink: Upgrading?" href="#upgrading"></a></p>
<p dir="auto">Review the CHANGELOG.md for version updates and changes.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📊 Usage</h2><a id="user-content--usage" aria-label="Permalink: 📊 Usage" href="#-usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">1. Prepare Your Data</h3><a id="user-content-1-prepare-your-data" aria-label="Permalink: 1. Prepare Your Data" href="#1-prepare-your-data"></a></p>
<p dir="auto">Redd-Archiver processes data dumps from multiple platforms:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Platform</th>
<th>Format</th>
<th>Data Sources</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Reddit</strong></td>
<td>.zst JSON Lines</td>
<td><a href="https://academictorrents.com/details/1614740ac8c94505e4ecb9d88be8bed7b6afddd4" rel="nofollow">Pushshift Complete Dataset</a> · Magnet Link · 3.28TB · 2.38B posts · 40K subreddits</td>
</tr>
<tr>
<td><strong>Voat</strong></td>
<td>SQL dumps</td>
<td><a href="https://archive.org/details/voat-archive-2021" rel="nofollow">Voat Archive 2021</a> · 22,637 subverses · 3.8M posts · 24M comments · Complete archive</td>
</tr>
<tr>
<td><strong>Ruqqus</strong></td>
<td>.7z JSON Lines</td>
<td><a href="https://archive.org/details/ruqqus-archive-2021" rel="nofollow">Ruqqus Archive 2021</a> · 6,217 guilds · Complete archive</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">2. Identify High-Priority Communities (Optional)</h3><a id="user-content-2-identify-high-priority-communities-optional" aria-label="Permalink: 2. Identify High-Priority Communities (Optional)" href="#2-identify-high-priority-communities-optional"></a></p>
<p dir="auto"><strong>Scanner Tools</strong> help you identify which communities to archive first based on priority scores:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Scan Reddit data (generates subreddits_complete.json)
python tools/find_banned_subreddits.py /path/to/reddit-data/ --output tools/subreddits_complete.json

# Scan Voat data (generates subverses.json)
python tools/scan_voat_subverses.py /path/to/voat-data/ --output tools/subverses.json

# Scan Ruqqus data (generates guilds.json)
python tools/scan_ruqqus_guilds.py /path/to/ruqqus-data/ --output tools/guilds.json"><pre><span><span>#</span> Scan Reddit data (generates subreddits_complete.json)</span>
python tools/find_banned_subreddits.py /path/to/reddit-data/ --output tools/subreddits_complete.json

<span><span>#</span> Scan Voat data (generates subverses.json)</span>
python tools/scan_voat_subverses.py /path/to/voat-data/ --output tools/subverses.json

<span><span>#</span> Scan Ruqqus data (generates guilds.json)</span>
python tools/scan_ruqqus_guilds.py /path/to/ruqqus-data/ --output tools/guilds.json</pre></div>
<p dir="auto"><strong>What the scanners do</strong>:</p>
<ul dir="auto">
<li>Calculate archive priority scores (0-100) for each community</li>
<li>Track post counts, activity periods, deletion rates, NSFW content</li>
<li>Identify restricted, quarantined, or banned communities (highest priority)</li>
<li>Sort communities by archival importance</li>
</ul>
<p dir="auto"><strong>Example output</strong>:</p>
<ul dir="auto">
<li><strong>Reddit</strong>: 40,029 subreddits from 2.38B posts analyzed</li>
<li><strong>Voat</strong>: 15,545 subverses from 3.81M posts + 24.1M comments analyzed</li>
<li><strong>Ruqqus</strong>: 6,217 guilds from 500K posts analyzed</li>
<li><strong>Status breakdown</strong> (Reddit): 26,552 active, 8,642 restricted, 4,803 inactive, 32 quarantined</li>
</ul>
<p dir="auto"><strong>Use cases</strong>:</p>
<ul dir="auto">
<li><strong>Targeted archiving</strong>: Archive high-risk communities first (restricted, quarantined)</li>
<li><strong>Storage planning</strong>: Identify largest communities before downloading</li>
<li><strong>Historical research</strong>: Find communities with high deletion/removal rates</li>
</ul>
<p dir="auto"><strong>Output files</strong> (included in <code>tools/</code> directory):</p>
<ul dir="auto">
<li><code>subreddits_complete.json</code> - Reddit subreddit statistics (40,029 communities, 46MB)</li>
<li><code>subverses.json</code> - Voat subverse statistics (22,585 communities, 14MB)</li>
<li><code>guilds.json</code> - Ruqqus guild statistics (6,217 communities, 3.6MB)</li>
</ul>
<p dir="auto">View the <a href="https://github.com/19-84/redd-archiver/blob/main/tools/README.md">complete data catalog</a> to browse all communities and their priority scores.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">3. Configure PostgreSQL</h3><a id="user-content-3-configure-postgresql" aria-label="Permalink: 3. Configure PostgreSQL" href="#3-configure-postgresql"></a></p>
<p dir="auto">Ensure DATABASE_URL is set (see Installation above):</p>
<div dir="auto" data-snippet-clipboard-copy-content="export DATABASE_URL=&quot;postgresql://reddarchiver:password@localhost:5432/reddarchiver&quot;"><pre><span>export</span> DATABASE_URL=<span><span>"</span>postgresql://reddarchiver:password@localhost:5432/reddarchiver<span>"</span></span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">4. Generate Your Archive</h3><a id="user-content-4-generate-your-archive" aria-label="Permalink: 4. Generate Your Archive" href="#4-generate-your-archive"></a></p>
<p dir="auto"><strong>Reddit Archives (.zst files):</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Auto-discovery (processes all .zst files in directory)
python reddarc.py /path/to/pushshift-data/ --output my-archive/

# Single subreddit
python reddarc.py /data --subreddit privacy \
  --comments-file /data/privacy_comments.zst \
  --submissions-file /data/privacy_submissions.zst \
  --output my-archive/"><pre><span><span>#</span> Auto-discovery (processes all .zst files in directory)</span>
python reddarc.py /path/to/pushshift-data/ --output my-archive/

<span><span>#</span> Single subreddit</span>
python reddarc.py /data --subreddit privacy \
  --comments-file /data/privacy_comments.zst \
  --submissions-file /data/privacy_submissions.zst \
  --output my-archive/</pre></div>
<p dir="auto"><strong>Voat Archives (SQL dumps):</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Import Voat subverses
python reddarc.py /data --subverse voatdev,pics --output my-archive/ --import-only

# Export HTML after import
python reddarc.py /data --output my-archive/ --export-from-database"><pre><span><span>#</span> Import Voat subverses</span>
python reddarc.py /data --subverse voatdev,pics --output my-archive/ --import-only

<span><span>#</span> Export HTML after import</span>
python reddarc.py /data --output my-archive/ --export-from-database</pre></div>
<p dir="auto"><strong>Ruqqus Archives (.7z files):</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Import Ruqqus guilds
python reddarc.py /data --guild Quarantine,News --output my-archive/ --import-only

# Export HTML after import
python reddarc.py /data --output my-archive/ --export-from-database"><pre><span><span>#</span> Import Ruqqus guilds</span>
python reddarc.py /data --guild Quarantine,News --output my-archive/ --import-only

<span><span>#</span> Export HTML after import</span>
python reddarc.py /data --output my-archive/ --export-from-database</pre></div>
<p dir="auto"><strong>Multi-Platform Mixed Archive:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Import from multiple platforms into single archive
python reddarc.py /reddit-data --subreddit privacy --output unified-archive/ --import-only
python reddarc.py /voat-data --subverse technology --output unified-archive/ --import-only
python reddarc.py /ruqqus-data --guild Tech --output unified-archive/ --import-only

# Generate HTML for all platforms
python reddarc.py /any-path --output unified-archive/ --export-from-database"><pre><span><span>#</span> Import from multiple platforms into single archive</span>
python reddarc.py /reddit-data --subreddit privacy --output unified-archive/ --import-only
python reddarc.py /voat-data --subverse technology --output unified-archive/ --import-only
python reddarc.py /ruqqus-data --guild Tech --output unified-archive/ --import-only

<span><span>#</span> Generate HTML for all platforms</span>
python reddarc.py /any-path --output unified-archive/ --export-from-database</pre></div>
<p dir="auto"><strong>With filtering and SEO:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="python reddarc.py /data/ --output my-archive/ \
  --min-score 100 --min-comments 50 \
  --base-url https://example.com \
  --site-name &quot;My Archive&quot;"><pre>python reddarc.py /data/ --output my-archive/ \
  --min-score 100 --min-comments 50 \
  --base-url https://example.com \
  --site-name <span><span>"</span>My Archive<span>"</span></span></pre></div>
<p dir="auto"><strong>Import/Export workflow (for large datasets):</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Import data to PostgreSQL (no HTML generation)
python reddarc.py /data/ --output my-archive/ --import-only

# Export HTML from PostgreSQL (no data import)
python reddarc.py /data/ --output my-archive/ --export-from-database"><pre><span><span>#</span> Import data to PostgreSQL (no HTML generation)</span>
python reddarc.py /data/ --output my-archive/ --import-only

<span><span>#</span> Export HTML from PostgreSQL (no data import)</span>
python reddarc.py /data/ --output my-archive/ --export-from-database</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">4. Deploy Your Archive</h3><a id="user-content-4-deploy-your-archive" aria-label="Permalink: 4. Deploy Your Archive" href="#4-deploy-your-archive"></a></p>
<p dir="auto">Multiple deployment options available:</p>
<p dir="auto"><strong>Local/Development</strong> (HTTP):</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker compose up -d
# Access: http://localhost"><pre>docker compose up -d
<span><span>#</span> Access: http://localhost</span></pre></div>
<p dir="auto"><strong>Production HTTPS</strong> (Let's Encrypt):</p>
<div dir="auto" data-snippet-clipboard-copy-content="./docker/scripts/init-letsencrypt.sh
# Access: https://your-domain.com"><pre>./docker/scripts/init-letsencrypt.sh
<span><span>#</span> Access: https://your-domain.com</span></pre></div>
<p dir="auto"><strong>Homelab/Tor</strong> (.onion hidden service):</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker compose -f docker-compose.yml -f docker-compose.tor-only.yml --profile tor up -d
# Access: http://[your-address].onion (via Tor Browser)
# No port forwarding or domain required!"><pre>docker compose -f docker-compose.yml -f docker-compose.tor-only.yml --profile tor up -d
<span><span>#</span> Access: http://[your-address].onion (via Tor Browser)</span>
<span><span>#</span> No port forwarding or domain required!</span></pre></div>
<p dir="auto"><strong>Dual-Mode</strong> (HTTPS + Tor):</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker compose --profile production --profile tor up -d
# Access: Both https://your-domain.com and http://[address].onion"><pre>docker compose --profile production --profile tor up -d
<span><span>#</span> Access: Both https://your-domain.com and http://[address].onion</span></pre></div>
<p dir="auto"><strong>Static Hosting</strong> (GitHub/Codeberg Pages):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Generate archive locally, push to GitHub/Codeberg
python reddarc.py /data --output archive/
cd archive/
git init &amp;&amp; git add . &amp;&amp; git commit -m &quot;Initial archive&quot;
git remote add origin https://github.com/username/repo.git
git push -u origin main
# Enable Pages in repository settings"><pre><span><span>#</span> Generate archive locally, push to GitHub/Codeberg</span>
python reddarc.py /data --output archive/
<span>cd</span> archive/
git init <span>&amp;&amp;</span> git add <span>.</span> <span>&amp;&amp;</span> git commit -m <span><span>"</span>Initial archive<span>"</span></span>
git remote add origin https://github.com/username/repo.git
git push -u origin main
<span><span>#</span> Enable Pages in repository settings</span></pre></div>
<p dir="auto"><strong>See deployment guides</strong>:</p>
<ul dir="auto">
<li><a href="https://github.com/19-84/redd-archiver/blob/main/docker/README.md">Docker Deployment Guide</a> - Complete Docker setup with HTTPS and Tor</li>
<li><a href="https://github.com/19-84/redd-archiver/blob/main/docs/TOR_DEPLOYMENT.md">Tor Deployment Guide</a> - Tor hidden service for homelab and privacy</li>
<li><a href="https://github.com/19-84/redd-archiver/blob/main/docs/STATIC_DEPLOYMENT.md">Static Deployment Guide</a> - GitHub Pages / Codeberg Pages (browse-only)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">5. Advanced CLI Options</h3><a id="user-content-5-advanced-cli-options" aria-label="Permalink: 5. Advanced CLI Options" href="#5-advanced-cli-options"></a></p>
<p dir="auto"><strong>Processing Control:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="--hide-deleted-comments    # Hide [deleted]/[removed] comments in output
--no-user-pages           # Skip user page generation (saves memory)
--dry-run                 # Preview discovered files without processing
--force-rebuild           # Ignore resume state and rebuild from scratch
--force-parallel-users    # Override auto-detection for parallel processing"><pre>--hide-deleted-comments    <span><span>#</span> Hide [deleted]/[removed] comments in output</span>
--no-user-pages           <span><span>#</span> Skip user page generation (saves memory)</span>
--dry-run                 <span><span>#</span> Preview discovered files without processing</span>
--force-rebuild           <span><span>#</span> Ignore resume state and rebuild from scratch</span>
--force-parallel-users    <span><span>#</span> Override auto-detection for parallel processing</span></pre></div>
<p dir="auto"><strong>Logging:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="--log-file <path>         # Custom log file location (default: output/.archive-error.log)
--log-level DEBUG         # Set logging verbosity (DEBUG, INFO, WARNING, ERROR, CRITICAL)"><pre>--log-file <span>&lt;</span>path<span>&gt;</span>         <span><span>#</span> Custom log file location (default: output/.archive-error.log)</span>
--log-level DEBUG         <span><span>#</span> Set logging verbosity (DEBUG, INFO, WARNING, ERROR, CRITICAL)</span></pre></div>
<p dir="auto"><strong>Performance Tuning:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="--debug-memory-limit 8.0      # Override memory limit in GB (default: auto-detect)
--debug-max-connections 8     # Override DB connection pool size (default: auto-detect)
--debug-max-workers 4         # Override parallel workers (default: auto-detect)"><pre>--debug-memory-limit 8.0      <span><span>#</span> Override memory limit in GB (default: auto-detect)</span>
--debug-max-connections 8     <span><span>#</span> Override DB connection pool size (default: auto-detect)</span>
--debug-max-workers 4         <span><span>#</span> Override parallel workers (default: auto-detect)</span></pre></div>
<p dir="auto"><strong>Environment Variables:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Required
DATABASE_URL=postgresql://user:pass@host:5432/reddarchiver

# Optional Performance Tuning (auto-detected if not set)
REDDARCHIVER_MAX_DB_CONNECTIONS=8       # Connection pool size
REDDARCHIVER_MAX_PARALLEL_WORKERS=4     # Parallel processing workers
REDDARCHIVER_USER_BATCH_SIZE=2000       # User page batch size
REDDARCHIVER_QUEUE_MAX_BATCHES=10       # Queue backpressure control
REDDARCHIVER_CHECKPOINT_INTERVAL=10     # Progress save frequency
REDDARCHIVER_USER_PAGE_WORKERS=4        # User page generation workers"><pre><span><span>#</span> Required</span>
DATABASE_URL=postgresql://user:pass@host:5432/reddarchiver

<span><span>#</span> Optional Performance Tuning (auto-detected if not set)</span>
REDDARCHIVER_MAX_DB_CONNECTIONS=8       <span><span>#</span> Connection pool size</span>
REDDARCHIVER_MAX_PARALLEL_WORKERS=4     <span><span>#</span> Parallel processing workers</span>
REDDARCHIVER_USER_BATCH_SIZE=2000       <span><span>#</span> User page batch size</span>
REDDARCHIVER_QUEUE_MAX_BATCHES=10       <span><span>#</span> Queue backpressure control</span>
REDDARCHIVER_CHECKPOINT_INTERVAL=10     <span><span>#</span> Progress save frequency</span>
REDDARCHIVER_USER_PAGE_WORKERS=4        <span><span>#</span> User page generation workers</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🏗️ Architecture</h2><a id="user-content-️-architecture" aria-label="Permalink: 🏗️ Architecture" href="#️-architecture"></a></p>
<p dir="auto">Redd-Archiver features a clean modular architecture with specialized components:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Project Structure</h3><a id="user-content-project-structure" aria-label="Permalink: Project Structure" href="#project-structure"></a></p>
<div data-snippet-clipboard-copy-content="reddarc.py              # Main CLI entry point
search_server.py        # Flask search API server
version.py              # Version metadata

core/                   # Core processing &amp; database
├── postgres_database.py    # PostgreSQL backend
├── postgres_search.py      # PostgreSQL FTS implementation
├── write_html.py           # HTML generation coordinator
├── watchful.py             # .zst streaming utilities
├── incremental_processor.py # Incremental processing
└── importers/              # Multi-platform importers
    ├── base_importer.py        # Abstract base class
    ├── reddit_importer.py      # .zst JSON Lines parser
    ├── voat_importer.py        # SQL dump coordinator
    ├── voat_sql_parser.py      # SQL INSERT parser
    └── ruqqus_importer.py      # .7z JSON Lines parser

api/                    # REST API v1
├── __init__.py             # Blueprint registration
└── routes.py               # 30+ API endpoints

mcp_server/             # MCP Server for AI integration
├── server.py               # FastMCP server (29 tools)
├── README.md               # MCP documentation
└── tests/                  # MCP server tests

utils/                  # Utility functions
├── console_output.py       # Console output formatting
├── error_handling.py       # Error handling utilities
├── input_validation.py     # Input validation
├── regex_utils.py          # Regular expression utilities
├── search_operators.py     # Search query parsing
└── simple_json_utils.py    # JSON utilities

processing/             # Data processing modules
├── parallel_user_processing.py  # Parallel user page generation
├── batch_processing_utils.py    # Batch processing utilities
└── incremental_statistics.py    # Statistics tracking

monitoring/             # Performance &amp; monitoring
├── performance_monitor.py      # Performance monitoring
├── performance_phases.py       # Phase tracking
├── performance_timing.py       # Timing utilities
├── auto_tuning_validator.py    # Auto-tuning validation
├── streaming_config.py         # Auto-detecting configuration
└── system_optimizer.py         # System optimization"><pre><code>reddarc.py              # Main CLI entry point
search_server.py        # Flask search API server
version.py              # Version metadata

core/                   # Core processing &amp; database
├── postgres_database.py    # PostgreSQL backend
├── postgres_search.py      # PostgreSQL FTS implementation
├── write_html.py           # HTML generation coordinator
├── watchful.py             # .zst streaming utilities
├── incremental_processor.py # Incremental processing
└── importers/              # Multi-platform importers
    ├── base_importer.py        # Abstract base class
    ├── reddit_importer.py      # .zst JSON Lines parser
    ├── voat_importer.py        # SQL dump coordinator
    ├── voat_sql_parser.py      # SQL INSERT parser
    └── ruqqus_importer.py      # .7z JSON Lines parser

api/                    # REST API v1
├── __init__.py             # Blueprint registration
└── routes.py               # 30+ API endpoints

mcp_server/             # MCP Server for AI integration
├── server.py               # FastMCP server (29 tools)
├── README.md               # MCP documentation
└── tests/                  # MCP server tests

utils/                  # Utility functions
├── console_output.py       # Console output formatting
├── error_handling.py       # Error handling utilities
├── input_validation.py     # Input validation
├── regex_utils.py          # Regular expression utilities
├── search_operators.py     # Search query parsing
└── simple_json_utils.py    # JSON utilities

processing/             # Data processing modules
├── parallel_user_processing.py  # Parallel user page generation
├── batch_processing_utils.py    # Batch processing utilities
└── incremental_statistics.py    # Statistics tracking

monitoring/             # Performance &amp; monitoring
├── performance_monitor.py      # Performance monitoring
├── performance_phases.py       # Phase tracking
├── performance_timing.py       # Timing utilities
├── auto_tuning_validator.py    # Auto-tuning validation
├── streaming_config.py         # Auto-detecting configuration
└── system_optimizer.py         # System optimization
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">HTML Modules (18 specialized modules)</h3><a id="user-content-html-modules-18-specialized-modules" aria-label="Permalink: HTML Modules (18 specialized modules)" href="#html-modules-18-specialized-modules"></a></p>
<div data-snippet-clipboard-copy-content="html_modules/
├── html_seo.py                # SEO, meta tags, sitemaps
├── html_pages_jinja.py        # Jinja2-based page generation
├── html_statistics.py         # Analytics and metrics
├── dashboard_helpers.py       # Dashboard utility functions
├── html_field_generation.py   # Dynamic field generation
├── jinja_filters.py           # Custom Jinja2 filters
├── html_pages.py              # Core page generation
├── html_comments.py           # Comment threading system
├── __init__.py                # Public API exports
├── jinja_env.py               # Jinja2 environment setup
├── html_utils.py              # File operations, utilities
├── html_dashboard_jinja.py    # Jinja2 dashboard rendering
├── css_minifier.py            # CSS minification
├── html_scoring.py            # Dynamic score badges
├── html_templates.py          # Template management
├── html_url.py                # URL processing, domains
├── html_dashboard.py          # Dashboard generation
└── html_constants.py          # Configuration values"><pre><code>html_modules/
├── html_seo.py                # SEO, meta tags, sitemaps
├── html_pages_jinja.py        # Jinja2-based page generation
├── html_statistics.py         # Analytics and metrics
├── dashboard_helpers.py       # Dashboard utility functions
├── html_field_generation.py   # Dynamic field generation
├── jinja_filters.py           # Custom Jinja2 filters
├── html_pages.py              # Core page generation
├── html_comments.py           # Comment threading system
├── __init__.py                # Public API exports
├── jinja_env.py               # Jinja2 environment setup
├── html_utils.py              # File operations, utilities
├── html_dashboard_jinja.py    # Jinja2 dashboard rendering
├── css_minifier.py            # CSS minification
├── html_scoring.py            # Dynamic score badges
├── html_templates.py          # Template management
├── html_url.py                # URL processing, domains
├── html_dashboard.py          # Dashboard generation
└── html_constants.py          # Configuration values
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Jinja2 Templates (15 templates)</h3><a id="user-content-jinja2-templates-15-templates" aria-label="Permalink: Jinja2 Templates (15 templates)" href="#jinja2-templates-15-templates"></a></p>
<div data-snippet-clipboard-copy-content="templates_jinja2/
├── base/
│   └── base.html              # Master layout template
├── components/
│   ├── dashboard_card.html    # Dashboard statistics cards
│   ├── footer.html            # Site footer
│   ├── global_summary.html    # Global statistics summary
│   ├── navigation.html        # Site navigation bar
│   ├── post_card.html         # Post display card
│   ├── user_comment.html      # User comment display
│   └── user_post.html         # User post display
├── macros/
│   ├── comment_macros.html    # Comment rendering macros
│   └── reddit_macros.html     # Reddit-specific macros
└── pages/
    ├── global_search.html     # Global search page
    ├── index.html             # Dashboard homepage
    ├── link.html              # Individual post page
    ├── subreddit.html         # Subreddit listing page
    └── user.html              # User profile page"><pre><code>templates_jinja2/
├── base/
│   └── base.html              # Master layout template
├── components/
│   ├── dashboard_card.html    # Dashboard statistics cards
│   ├── footer.html            # Site footer
│   ├── global_summary.html    # Global statistics summary
│   ├── navigation.html        # Site navigation bar
│   ├── post_card.html         # Post display card
│   ├── user_comment.html      # User comment display
│   └── user_post.html         # User post display
├── macros/
│   ├── comment_macros.html    # Comment rendering macros
│   └── reddit_macros.html     # Reddit-specific macros
└── pages/
    ├── global_search.html     # Global search page
    ├── index.html             # Dashboard homepage
    ├── link.html              # Individual post page
    ├── subreddit.html         # Subreddit listing page
    └── user.html              # User profile page
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Database Schema</h3><a id="user-content-database-schema" aria-label="Permalink: Database Schema" href="#database-schema"></a></p>
<div data-snippet-clipboard-copy-content="sql/
├── schema.sql                 # PostgreSQL table definitions
├── indexes.sql                # Performance indexes (GIN, B-tree)
├── fix_statistics.sql         # Statistics maintenance queries
└── migrations/
    └── 003_add_total_activity_column.sql  # Schema migration"><pre><code>sql/
├── schema.sql                 # PostgreSQL table definitions
├── indexes.sql                # Performance indexes (GIN, B-tree)
├── fix_statistics.sql         # Statistics maintenance queries
└── migrations/
    └── 003_add_total_activity_column.sql  # Schema migration
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔍 PostgreSQL Full-Text Search</h2><a id="user-content--postgresql-full-text-search" aria-label="Permalink: 🔍 PostgreSQL Full-Text Search" href="#-postgresql-full-text-search"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Lightning-Fast Database Search</h3><a id="user-content-lightning-fast-database-search" aria-label="Permalink: Lightning-Fast Database Search" href="#lightning-fast-database-search"></a></p>
<p dir="auto">Redd-Archiver v1.0 uses PostgreSQL full-text search with GIN indexing for blazing-fast search capabilities:</p>
<p dir="auto"><strong>Key Features:</strong></p>
<ul dir="auto">
<li><strong>Database-Powered</strong>: Native PostgreSQL indexing with constant memory usage</li>
<li><strong>Large-Scale</strong>: Efficiently search large datasets (tested with hundreds of GB)</li>
<li><strong>Relevance Ranking</strong>: PostgreSQL <code>ts_rank()</code> for intelligent result ordering</li>
<li><strong>Highlighted Excerpts</strong>: <code>ts_headline()</code> shows matching content in context</li>
<li><strong>Advanced Filters</strong>: Search by subreddit, author, date range, score</li>
<li><strong>Concurrent Queries</strong>: Handle multiple search requests simultaneously</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Search API</h3><a id="user-content-search-api" aria-label="Permalink: Search API" href="#search-api"></a></p>
<p dir="auto">PostgreSQL search is exposed via <code>postgres_search.py</code> (CLI) and <code>search_server.py</code> (Web API):</p>
<p dir="auto"><strong>Command-Line Interface:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Search command-line interface
python postgres_search.py &quot;your query&quot; --subreddit technology --limit 50

# Example: Search for posts about &quot;machine learning&quot; with high scores
python postgres_search.py &quot;machine learning&quot; --min-score 100 --limit 20"><pre><span><span>#</span> Search command-line interface</span>
python postgres_search.py <span><span>"</span>your query<span>"</span></span> --subreddit technology --limit 50

<span><span>#</span> Example: Search for posts about "machine learning" with high scores</span>
python postgres_search.py <span><span>"</span>machine learning<span>"</span></span> --min-score 100 --limit 20</pre></div>
<p dir="auto"><strong>Web API</strong> (✅ Implemented):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Start search server with Docker Compose (recommended)
docker-compose up -d reddarchiver-search-server

# Or run directly
export DATABASE_URL=&quot;postgresql://user:pass@localhost:5432/reddarchiver&quot;
python search_server.py

# Access at http://localhost:5000"><pre><span><span>#</span> Start search server with Docker Compose (recommended)</span>
docker-compose up -d reddarchiver-search-server

<span><span>#</span> Or run directly</span>
<span>export</span> DATABASE_URL=<span><span>"</span>postgresql://user:pass@localhost:5432/reddarchiver<span>"</span></span>
python search_server.py

<span><span>#</span> Access at http://localhost:5000</span></pre></div>
<p dir="auto"><strong>Features:</strong></p>
<ul dir="auto">
<li>RESTful search API with JSON responses</li>
<li>Real-time search with PostgreSQL FTS</li>
<li>Rate limiting and CSRF protection</li>
<li>Health check endpoint: <code>GET /health</code></li>
<li>Search endpoint: <code>GET /search?q=query&amp;subreddit=optional&amp;limit=50</code></li>
<li>Result highlighting with <code>ts_headline()</code></li>
<li>Search suggestions and trending searches</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🌐 REST API &amp; Registry</h2><a id="user-content--rest-api--registry" aria-label="Permalink: 🌐 REST API &amp; Registry" href="#-rest-api--registry"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">REST API v1</h3><a id="user-content-rest-api-v1" aria-label="Permalink: REST API v1" href="#rest-api-v1"></a></p>
<p dir="auto">Full-featured API with 30+ endpoints for programmatic access and MCP/AI integration:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Category</th>
<th>Endpoints</th>
<th>Key Features</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>System</strong> (5)</td>
<td><code>/health</code>, <code>/stats</code>, <code>/schema</code>, <code>/openapi.json</code></td>
<td>Health checks, statistics, capability discovery, OpenAPI spec</td>
</tr>
<tr>
<td><strong>Posts</strong> (13)</td>
<td><code>/posts</code>, <code>/posts/{id}</code>, <code>/posts/{id}/comments</code>, <code>/posts/{id}/context</code>, <code>/posts/{id}/comments/tree</code>, <code>/posts/{id}/related</code>, <code>/posts/random</code>, <code>/posts/aggregate</code>, <code>/posts/batch</code></td>
<td>List, single, comments, context, tree, related, random, aggregate, batch</td>
</tr>
<tr>
<td><strong>Comments</strong> (7)</td>
<td><code>/comments</code>, <code>/comments/{id}</code>, <code>/comments/random</code>, <code>/comments/aggregate</code>, <code>/comments/batch</code></td>
<td>List, single, random, aggregate, batch</td>
</tr>
<tr>
<td><strong>Users</strong> (8)</td>
<td><code>/users</code>, <code>/users/{username}</code>, <code>/users/{username}/summary</code>, <code>/users/{username}/posts</code>, <code>/users/{username}/comments</code>, <code>/users/aggregate</code>, <code>/users/batch</code></td>
<td>List, profiles, summary, activity, aggregate, batch</td>
</tr>
<tr>
<td><strong>Subreddits</strong> (4)</td>
<td><code>/subreddits</code>, <code>/subreddits/{name}</code>, <code>/subreddits/{name}/summary</code></td>
<td>List, statistics, summary</td>
</tr>
<tr>
<td><strong>Search</strong> (3)</td>
<td><code>/search</code>, <code>/search/explain</code></td>
<td>Full-text search with operators, query debugging</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>MCP/AI-Optimized Features</strong>:</p>
<ul dir="auto">
<li><strong>Field Selection</strong>: <code>?fields=id,title,score</code> for token optimization</li>
<li><strong>Truncation Controls</strong>: <code>?max_body_length=500&amp;include_body=false</code> for response size management</li>
<li><strong>Export Formats</strong>: <code>?format=csv|ndjson</code> for data analysis</li>
<li><strong>Batch Endpoints</strong>: Reduce N requests to 1 with <code>/posts|comments|users/batch</code></li>
<li><strong>Context Endpoints</strong>: Single-call discussion retrieval with <code>/posts/{id}/context</code></li>
<li><strong>Search Operators</strong>: Google-style syntax (<code>"exact"</code>, <code>OR</code>, <code>-exclude</code>, <code>sub:</code>, <code>author:</code>, <code>score:</code>)</li>
</ul>
<p dir="auto">Rate limited to 100 requests/minute. See <a href="https://github.com/19-84/redd-archiver/blob/main/docs/API.md">API Documentation</a> for complete reference.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Instance Registry &amp; Leaderboard</h3><a id="user-content-instance-registry--leaderboard" aria-label="Permalink: Instance Registry &amp; Leaderboard" href="#instance-registry--leaderboard"></a></p>
<p dir="auto">Redd-Archiver supports a distributed registry system for tracking archive instances:</p>
<ul dir="auto">
<li><strong>Instance Metadata</strong>: Configure via environment variables or CLI flags (<code>--site-name</code>, <code>--contact</code>, <code>--team-id</code>)</li>
<li><strong>Leaderboard Generator</strong>: Automated scoring based on archive completeness and content risk</li>
<li><strong>Team Grouping</strong>: Group multiple instances under a team ID for coordinated archiving</li>
</ul>
<p dir="auto">See <a href="https://github.com/19-84/redd-archiver/blob/main/docs/REGISTRY_SETUP.md">Registry Setup Guide</a> for configuration.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📈 Performance &amp; Optimization</h2><a id="user-content--performance--optimization" aria-label="Permalink: 📈 Performance &amp; Optimization" href="#-performance--optimization"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">PostgreSQL Backend Performance (v1.0+)</h3><a id="user-content-postgresql-backend-performance-v10" aria-label="Permalink: PostgreSQL Backend Performance (v1.0+)" href="#postgresql-backend-performance-v10"></a></p>
<p dir="auto"><strong>Constant Memory Usage:</strong></p>
<ul dir="auto">
<li><strong>4GB RAM</strong>: Process large datasets efficiently (tested with hundreds of GB)</li>
<li><strong>8GB RAM</strong>: Optimal for concurrent operations</li>
<li><strong>16GB+ RAM</strong>: Ideal for parallel user page generation</li>
</ul>
<p dir="auto"><strong>Database Storage:</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Input (.zst)</th>
<th>PostgreSQL DB</th>
<th>HTML Output</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>93.6MB</td>
<td>~150MB</td>
<td>1.4GB</td>
<td>r/technology</td>
</tr>
<tr>
<td>100MB</td>
<td>~160MB</td>
<td>~1.5GB</td>
<td>Small archives</td>
</tr>
<tr>
<td>500MB</td>
<td>~800MB</td>
<td>~7.5GB</td>
<td>Research projects</td>
</tr>
<tr>
<td>2GB</td>
<td>~3.2GB</td>
<td>~30GB</td>
<td>Large collections</td>
</tr>
<tr>
<td>100GB</td>
<td>~160GB</td>
<td>~1.5TB</td>
<td>Enterprise-scale</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Processing Speed:</strong></p>
<ul dir="auto">
<li><strong>Data Import</strong>: Fast streaming ingestion to PostgreSQL</li>
<li><strong>HTML Generation</strong>: Efficient database-backed rendering</li>
<li><strong>Search Index</strong>: Instant with PostgreSQL GIN indexes</li>
<li><strong>Performance</strong>: Scales with dataset size, optimized for large archives</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Search Performance</h3><a id="user-content-search-performance" aria-label="Permalink: Search Performance" href="#search-performance"></a></p>
<p dir="auto">Performance varies based on dataset size, query complexity, and hardware:</p>
<ul dir="auto">
<li><strong>PostgreSQL FTS</strong>: Fast indexed search for large datasets</li>
<li><strong>GIN Indexes</strong>: Optimized index lookups for text search</li>
<li><strong>Concurrent Queries</strong>: Supports multiple simultaneous searches with connection pooling</li>
<li><strong>Memory Efficient</strong>: Constant memory usage with streaming results</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Architecture Benefits</h3><a id="user-content-architecture-benefits" aria-label="Permalink: Architecture Benefits" href="#architecture-benefits"></a></p>
<p dir="auto"><strong>PostgreSQL v1.0 Features</strong>:</p>
<ul dir="auto">
<li><strong>Large-Scale Processing</strong>: Efficiently handle large datasets (tested with hundreds of GB)</li>
<li><strong>Constant Memory</strong>: 4GB RAM regardless of dataset size</li>
<li><strong>Fast Search</strong>: PostgreSQL FTS with GIN indexing</li>
<li><strong>Resume Capability</strong>: Database-backed progress tracking</li>
<li><strong>Concurrent Processing</strong>: Multi-connection pool for parallel operations</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔀 Scaling for Very Large Archives</h2><a id="user-content--scaling-for-very-large-archives" aria-label="Permalink: 🔀 Scaling for Very Large Archives" href="#-scaling-for-very-large-archives"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Single Instance Limits</h3><a id="user-content-single-instance-limits" aria-label="Permalink: Single Instance Limits" href="#single-instance-limits"></a></p>
<p dir="auto">Redd-Archiver has been tested with archives up to hundreds of gigabytes. For optimal performance:</p>
<ul dir="auto">
<li><strong>Tested scale</strong>: Hundreds of GB per instance</li>
<li><strong>Memory usage</strong>: Constant 4GB RAM regardless of dataset size</li>
<li><strong>Database</strong>: PostgreSQL handles large datasets efficiently</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Horizontal Scaling Strategy</h3><a id="user-content-horizontal-scaling-strategy" aria-label="Permalink: Horizontal Scaling Strategy" href="#horizontal-scaling-strategy"></a></p>
<p dir="auto">For very large archive collections (multiple terabytes), deploy <strong>multiple instances divided by topic</strong>:</p>
<p dir="auto"><strong>Architecture</strong>:</p>
<div data-snippet-clipboard-copy-content="┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│  Instance 1     │     │  Instance 2     │     │  Instance 3     │
│  Technology     │     │  Gaming         │     │  Science        │
│  Subreddits     │     │  Subreddits     │     │  Subreddits     │
└─────────────────┘     └─────────────────┘     └─────────────────┘"><pre><code>┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│  Instance 1     │     │  Instance 2     │     │  Instance 3     │
│  Technology     │     │  Gaming         │     │  Science        │
│  Subreddits     │     │  Subreddits     │     │  Subreddits     │
└─────────────────┘     └─────────────────┘     └─────────────────┘
</code></pre></div>
<p dir="auto"><strong>Benefits</strong>:</p>
<ul dir="auto">
<li><strong>Efficient search</strong>: Each database stays manageable size</li>
<li><strong>Distributed load</strong>: Parallel processing across instances</li>
<li><strong>Topic organization</strong>: Logical grouping of related content</li>
<li><strong>Independent scaling</strong>: Scale individual topics as needed</li>
</ul>
<p dir="auto"><strong>Deployment Options</strong>:</p>
<ol dir="auto">
<li><strong>Single server</strong>: Multiple Docker Compose stacks with different ports</li>
<li><strong>Multiple servers</strong>: One instance per physical/virtual machine</li>
<li><strong>Topic-based domains</strong>: tech.archive.com, gaming.archive.com, etc.</li>
</ol>
<p dir="auto"><strong>Example Multi-Instance Setup</strong>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Instance 1: Technology topics (port 8080)
cd /archives/tech
docker compose up -d

# Instance 2: Gaming topics (port 8081)
cd /archives/gaming
docker compose -f docker-compose.yml up -d

# Instance 3: Science topics (port 8082)
cd /archives/science
docker compose -f docker-compose.yml up -d"><pre><span><span>#</span> Instance 1: Technology topics (port 8080)</span>
<span>cd</span> /archives/tech
docker compose up -d

<span><span>#</span> Instance 2: Gaming topics (port 8081)</span>
<span>cd</span> /archives/gaming
docker compose -f docker-compose.yml up -d

<span><span>#</span> Instance 3: Science topics (port 8082)</span>
<span>cd</span> /archives/science
docker compose -f docker-compose.yml up -d</pre></div>
<p dir="auto"><strong>When to Use</strong>:</p>
<ul dir="auto">
<li>Archive collection exceeds 500GB</li>
<li>Search performance degrades with single instance</li>
<li>Logical topic divisions exist in your archive</li>
<li>Want to distribute load across multiple servers</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎯 Use Cases</h2><a id="user-content--use-cases" aria-label="Permalink: 🎯 Use Cases" href="#-use-cases"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Research &amp; Academia</h3><a id="user-content-research--academia" aria-label="Permalink: Research &amp; Academia" href="#research--academia"></a></p>
<ul dir="auto">
<li>Studying online discourse and community dynamics</li>
<li>Analyzing social movements and trends</li>
<li>Preserving internet culture</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Community Archiving</h3><a id="user-content-community-archiving" aria-label="Permalink: Community Archiving" href="#community-archiving"></a></p>
<ul dir="auto">
<li>Backing up subreddits before potential removal</li>
<li>Creating offline-accessible community resources</li>
<li>Distributing knowledge repositories</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Investigation &amp; Analysis</h3><a id="user-content-investigation--analysis" aria-label="Permalink: Investigation &amp; Analysis" href="#investigation--analysis"></a></p>
<ul dir="auto">
<li>Pattern analysis in deleted/removed content</li>
<li>User behavior studies</li>
<li>Content moderation research</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">📚 Documentation</h2><a id="user-content--documentation" aria-label="Permalink: 📚 Documentation" href="#-documentation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Deployment Guides</h3><a id="user-content-deployment-guides" aria-label="Permalink: Deployment Guides" href="#deployment-guides"></a></p>
<ul dir="auto">
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/docker/README.md">Docker Deployment Guide</a></strong> - Complete Docker setup including PostgreSQL, nginx, HTTPS, and Tor</li>
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/docs/TOR_DEPLOYMENT.md">Tor Deployment Guide</a></strong> - Tor hidden service setup for homelab and privacy deployments</li>
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/docs/STATIC_DEPLOYMENT.md">Static Deployment Guide</a></strong> - GitHub Pages and Codeberg Pages deployment (browse-only, no search)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">API &amp; Integration</h3><a id="user-content-api--integration" aria-label="Permalink: API &amp; Integration" href="#api--integration"></a></p>
<ul dir="auto">
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/docs/API.md">REST API Documentation</a></strong> - Complete API reference with 30+ endpoints</li>
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/mcp_server/README.md">MCP Server Documentation</a></strong> - AI integration with Claude Desktop/Claude Code</li>
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/docs/REGISTRY_SETUP.md">Registry Setup Guide</a></strong> - Instance registry configuration</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Project Documentation</h3><a id="user-content-project-documentation" aria-label="Permalink: Project Documentation" href="#project-documentation"></a></p>
<ul dir="auto">
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a></strong> - Development guidelines and contribution procedures</li>
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/SECURITY.md">SECURITY.md</a></strong> - Security policy and vulnerability reporting</li>
<li><strong><a href="https://github.com/19-84/redd-archiver/blob/main/LICENSE">LICENSE</a></strong> - Unlicense (public domain)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🤝 Contributing</h2><a id="user-content--contributing" aria-label="Permalink: 🤝 Contributing" href="#-contributing"></a></p>
<p dir="auto">We welcome contributions! Please see <a href="https://github.com/19-84/redd-archiver/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for development guidelines, code structure, and testing procedures.</p>
<p dir="auto">Key areas for contribution:</p>
<ul dir="auto">
<li>PostgreSQL query optimizations</li>
<li>Additional export formats</li>
<li>Enhanced search features</li>
<li>Documentation improvements</li>
</ul>
<p dir="auto">See our modular architecture (18 specialized modules) for easy entry points to contribute.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📝 License</h2><a id="user-content--license" aria-label="Permalink: 📝 License" href="#-license"></a></p>
<p dir="auto">This is free and unencumbered software released into the public domain. See the <a href="https://github.com/19-84/redd-archiver/blob/main/LICENSE">LICENSE</a> file (Unlicense) for details.</p>
<p dir="auto">Anyone is free to copy, modify, publish, use, compile, sell, or distribute this software for any purpose, commercial or non-commercial, and by any means.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📦 Data Sources</h2><a id="user-content--data-sources" aria-label="Permalink: 📦 Data Sources" href="#-data-sources"></a></p>
<p dir="auto">This project leverages public datasets from the following sources:</p>
<ul dir="auto">
<li><strong><a href="https://github.com/pushshift/api">Pushshift</a></strong> - Reddit data access and archival infrastructure</li>
<li><strong><a href="https://github.com/Watchful1/PushshiftDumps">Watchful1's PushshiftDumps</a></strong> - Comprehensive data dump tools and torrent management</li>
<li><strong><a href="https://github.com/ArthurHeitmann/arctic_shift">Arctic Shift</a></strong> - Making Reddit data accessible to researchers and the public</li>
<li><strong><a href="https://archive.org/details/ruqqus-public-dataset" rel="nofollow">Ruqqus Public Dataset</a></strong> - 752 MB Ruqqus archive (comments and submissions)</li>
<li><strong><a href="https://archive.org/details/searchvoat.co" rel="nofollow">SearchVoat Archive</a></strong> - 16.8 GB Voat.co complete backup</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🙏 Acknowledgments</h2><a id="user-content--acknowledgments" aria-label="Permalink: 🙏 Acknowledgments" href="#-acknowledgments"></a></p>
<p dir="auto">This project builds upon the work of several excellent archival projects:</p>
<ul dir="auto">
<li><strong><a href="https://github.com/libertysoft3/reddit-html-archiver">reddit-html-archiver</a></strong> by libertysoft3 - Original inspiration and foundation for static HTML generation</li>
<li><strong><a href="https://github.com/Yakabuff/redarc">redarc</a></strong> - Self-hosted Reddit archiving with PostgreSQL and full-text search</li>
<li><strong><a href="https://github.com/sys-nyx/red-arch">red-arch</a></strong> - Static website generator for Reddit subreddit archives</li>
<li><strong><a href="https://github.com/ArthurHeitmann/zst_blocks_format">zst_blocks_format</a></strong> - Efficient block-based compression format for processing large datasets</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">📧 Contact</h2><a id="user-content--contact" aria-label="Permalink: 📧 Contact" href="#-contact"></a></p>
<ul dir="auto">
<li><strong>GitHub Issues</strong>: <a href="https://github.com/19-84/redd-archiver/issues">Report bugs or request features</a></li>
<li><strong>GitHub Discussions</strong>: <a href="https://github.com/19-84/redd-archiver/discussions">Ask questions or share ideas</a></li>
<li><strong>Security Issues</strong>: <a href="https://github.com/19-84/redd-archiver/security/advisories/new">Report via GitHub Security Advisories</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">💰 Support the Project</h2><a id="user-content--support-the-project" aria-label="Permalink: 💰 Support the Project" href="#-support-the-project"></a></p>
<p dir="auto"><strong>Redd-Archiver was built by one person over 6 months</strong> as a labor of love to preserve internet history before it disappears forever.</p>
<p dir="auto">This isn't backed by a company or institution—just an individual committed to keeping valuable discussions accessible. Your support helps:</p>
<ul dir="auto">
<li>Continue development and bug fixes</li>
<li>Maintain documentation and support</li>
<li>Cover infrastructure costs (servers, storage, bandwidth)</li>
<li>Preserve more data sources and platforms</li>
</ul>
<p dir="auto">Every donation, no matter the size, helps keep this preservation effort alive.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bitcoin (BTC)</h3><a id="user-content-bitcoin-btc" aria-label="Permalink: Bitcoin (BTC)" href="#bitcoin-btc"></a></p>
<div data-snippet-clipboard-copy-content="bc1q8wpdldnfqt3n9jh2n9qqmhg9awx20hxtz6qdl7"><pre><code>bc1q8wpdldnfqt3n9jh2n9qqmhg9awx20hxtz6qdl7
</code></pre></div>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/qr-codes/btc.jpg"><img src="https://github.com/19-84/redd-archiver/raw/main/qr-codes/btc.jpg" width="400" alt="Bitcoin QR Code"></a>
  <br>
  <em>Scan to donate Bitcoin</em>
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Monero (XMR)</h3><a id="user-content-monero-xmr" aria-label="Permalink: Monero (XMR)" href="#monero-xmr"></a></p>
<div data-snippet-clipboard-copy-content="42zJZJCqxyW8xhhWngXHjhYftaTXhPdXd9iJ2cMp9kiGGhKPmtHV746EknriN4TNqYR2e8hoaDwrMLfv7h1wXzizMzhkeQi"><pre><code>42zJZJCqxyW8xhhWngXHjhYftaTXhPdXd9iJ2cMp9kiGGhKPmtHV746EknriN4TNqYR2e8hoaDwrMLfv7h1wXzizMzhkeQi
</code></pre></div>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/19-84/redd-archiver/blob/main/qr-codes/xmr.jpg"><img src="https://github.com/19-84/redd-archiver/raw/main/qr-codes/xmr.jpg" width="400" alt="Monero QR Code"></a>
  <br>
  <em>Scan to donate Monero</em>
</p>
<p dir="auto"><strong>Thank you for supporting internet archival efforts!</strong> Every contribution helps maintain and improve this project.</p>
<hr>
<p dir="auto">This software is provided "as is" under the Unlicense. See <a href="https://github.com/19-84/redd-archiver/blob/main/LICENSE">LICENSE</a> for details. Users are responsible for compliance with applicable laws and terms of service when processing data.</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>