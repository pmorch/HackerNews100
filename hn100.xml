<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 07 Jun 2024 20:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[ASCII Silhouettify (144 pts)]]></title>
            <link>https://meatfighter.com/ascii-silhouettify/</link>
            <guid>40610641</guid>
            <pubDate>Fri, 07 Jun 2024 17:10:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://meatfighter.com/ascii-silhouettify/">https://meatfighter.com/ascii-silhouettify/</a>, See on <a href="https://news.ycombinator.com/item?id=40610641">Hacker News</a></p>
<div id="readability-page-1" class="page">
<p><img src="https://meatfighter.com/ascii-silhouettify/images/logo-white.svg" alt="AS"> ASCII Silhouettify</p>

<p id="index">[ <a href="#about" target="_self">About</a> | <a href="#example" target="_self">Example</a> | <a href="#galleries" target="_self">Galleries</a> | <a href="#install" target="_self">Install</a> | <a href="#uninstall" target="_self">Uninstall</a> | <a href="#options" target="_self">Options</a> | <a href="#algorithm" target="_self">Algorithm</a> ]</p>

<h2 id="about"><a href="#about" target="_self">About</a></h2>

<p>ASCII Silhouettify is an app that converts images into ASCII silhouettes, a style of ASCII art distinguished by uniformly filled geometric shapes rather than lines or textures. For input, the app expects flat graphics—visuals with minimalistic, high-contrast forms lacking dimensional depth, such as logos, banners, and pixel art. It cannot handle photographs because it does not render shading, highlights, shadows, or gradients.</p>

<p>ASCII Silhouettify restricts itself to the 95 printable ASCII characters, the medium of traditional ASCII artists, as opposed to the line and block characters prevalent in ANSI art or the copious Unicode characters of kaomoji. However, based on user configuration, the app outputs monochrome plain text, text colored with ANSI escape sequences, HTML with or without color, or Neofetch ASCII art format.</p>

<p>ASCII Silhouettify is a desktop app accessible from a browser and from the command-line.</p>



<h2 id="example"><a href="#example" target="_self">Example</a></h2>

<p>Here is the output of <a href="https://github.com/dylanaraps/neofetch">Neofetch</a> under an instance of Ubuntu:</p>

<p><img id="./images/neofetch-0.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-0.png" alt="Neofetch Ubuntu output">
</p>

<p>For optimal ASCII art, we obtain a high-resolution image of the Ubuntu logo from the web, and we scale it to the size we want it to appear in the console:</p>

<p><img id="./images/neofetch-1.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-1.png" alt="Ubuntu logo">
</p>

<p>We run it through the command-line version of ASCII Silhouettify:</p>

<p><img id="./images/neofetch-2.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-2.png" alt="Ubuntu logo ANSI art">
</p>

<p>By default, ASCII Silhouettify generates text colored with ANSI escape sequences. With the <code>-o</code> flag, we can direct the output to a file that Neofetch will display. But Neofetch inserts a wide margin between ANSI art and the OS metrics. To prevent this, we‘ll use Neofetch‘s <a href="https://github.com/dylanaraps/neofetch/wiki/Custom-Ascii-art-file-format">custom ASCII art file format</a>: </p>

<p><img id="./images/neofetch-4.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-4.png" alt="Generating Neofetch ASCII art file">
</p>

<p>The first line of the output file is a list of color indices. The successive lines contain the encoded image:</p>

<p><img id="./images/neofetch-5.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-5.png" alt="Neofetch ASCII art file">
</p>

<p>In a text editor, we copy the first line to the clipboard, and then we remove it.</p>

<p>We invoke Neofetch with the following command, pasting in the value we stored in the clipboard:</p>

<p><img id="./images/neofetch-3.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-3.png" alt="Neofetch with improved logo">
</p>

<p>Neofetch is a bash script. To make the change permanent, we replace the following part of the script, again using the value we stored in the clipboard.</p>

<p><img id="./images/neofetch-6.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-6.png" alt="Neofetch script segment">
</p>

<p>For comparison, here is the original logo overlaid on the generated result:</p>

<p><img id="./images/neofetch-7.png" src="https://meatfighter.com/ascii-silhouettify/images/neofetch-7.png" alt="Logos overlaid">
</p>

<p>Note how the algorithm selects the largest characters that fit within the outlines of each colored region.</p>


<h2 id="galleries"><a href="#galleries" target="_self">Galleries</a></h2>

<p>For more examples, click on one of the buttons below.</p>




<h2 id="install"><a href="#install" target="_self">Install</a></h2>

<p>The command-line version of ASCII Silhouettify is a Node.js application. If you don't have Node.js installed on your system, follow the steps described <a href="https://nodejs.org/en/learn/getting-started/how-to-install-nodejs">here</a>.</p>

<p>In the Windows Command Prompt or PowerShell (but not WSL), run:</p>

<div>
    <pre>npm install -g ascii-silhouettify</pre>
    </div>

<p>On macOS and Linux (including WSL), you need to use <code>sudo</code>:</p>

<div>
    <pre>sudo npm install -g ascii-silhouettify</pre>
    </div>


<h2 id="uninstall"><a href="#uninstall" target="_self">Uninstall</a></h2>

<p>In the Windows Command Prompt or PowerShell (but not WSL), run:</p>

<div>
    <pre>npm uninstall -g ascii-silhouettify</pre>
    </div>

<p>On macOS and Linux (including WSL), you need to use <code>sudo</code>:</p>

<div>
    <pre>sudo npm uninstall -g ascii-silhouettify</pre>
    </div>


<h2 id="options"><a href="#options" target="_self">Options</a></h2>

<p>The browser version and the command-line version support the same set of options. In the command-line version, the <code>-h</code> flag outputs a message that summarizes the information below.</p>


<h2 id="options.input"><a href="#options.input" target="_self">Input</a></h2>

<p>ASCII Silhouettify can convert multiple images at the same time. It supports <code>png</code>, <code>svg</code>, <code>jpg</code>, <code>webp</code>, <code>gif</code>, <code>tif</code>, <code>heif</code>, <code>avif</code>, and <code>pdf</code> image formats. The command-line version‘s <code>-i</code> flag accepts various filename pattern-matching rules (see the help message for details). The input images should have black or transparent backgrounds.</p>


<h2 id="options.output"><a href="#options.output" target="_self">Output</a></h2>

<p>ASCII Silhouettify can output plane or ANSI-colored text, monospaced text in HTML format, or Neofetch‘s custom ASCII art format. The latter is limited to six colors of the <span>256-color</span> extended ANSI palette.</p>


<h2 id="options.palette"><a href="#options.palette" target="_self">Palette</a></h2>

<p>By default, ASCII Silhouettify uses a palette of 240 colors from the <span>256-color</span> extended ANSI palette, excluding the <span>16-color</span> standard ANSI palette, as it is often redefined in modern terminal emulators. However, users have the option to select the first 8 colors of the standard ANSI palette, the full <span>16-color</span> standard ANSI palette, the full <span>256-color</span> extended ANSI palette, or stick with the default <span>240-color</span> palette.</p>


<h2 id="options.colors-and-monochrome"><a href="#options.colors-and-monochrome" target="_self">Colors and Monochrome</a></h2>

<p>The user can specify the maximum number of colors to appear in the output, not counting the presumably black background. The default is 255. Monochrome mode effectively sets this to one. For Neofetch‘s custom ASCII art format, it defaults to six, the maximum number of colors supported by that format.</p>


<h2 id="options.font-size-and-line-height"><a href="#options.font-size-and-line-height" target="_self">Font Size and Line Height</a></h2>

<p>When viewed in a terminal emulator, the aspect ratio of the generated ASCII art depends on the font, font size, line height, and the rounding rules for character dimensions. To optimize it, capture an image of text in the terminal, and measure the size of each monospaced character in pixels, including the space between lines:</p>

<p><img id="./images/intellij.png" src="https://meatfighter.com/ascii-silhouettify/images/intellij.png" alt="Intellij terminal">
</p>

<p>Plug the values into the following formulae to determine font size and line height settings.</p>

<p>$\text{font size} = \dfrac{\text{character width}+a}{.78}, a \in [-0.5, 0.5)$</p>

<p>$\text{line height} = \dfrac{.75 (\text{character height} + b)}{\text{font size}}, b \in [-0.5, 0.5) $</p>

<p>Select arbitrary values for $a$ and $b$ within the range $-0.5$ to $0.5$.</p>

<p>Here are some measured character dimensions and suggested settings based on the developer’s Windows desktop:</p>

<div>
    <table>
        <thead>
        <tr>
            <th>Application</th>
            <th>Character Width</th>
            <th>Character Height</th>
            <th>Font Size</th>
            <th>Line Height</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td>IntelliJ Terminal</td>
            <td>8</td>
            <td>22</td>
            <td>10</td>
            <td>1.65</td>
        </tr>
        <tr>
            <td>Putty</td>
            <td>8</td>
            <td>16</td>
            <td>10</td>
            <td>1.2</td>
        </tr>
        <tr>
            <td>Notepad</td>
            <td>10</td>
            <td>18</td>
            <td>13</td>
            <td>1.04</td>
        </tr>
        <tr>
            <td>Notepad++</td>
            <td>9</td>
            <td>19</td>
            <td>12</td>
            <td>1.2</td>
        </tr>
        <tr>
            <td>Windows Command Prompt</td>
            <td>8</td>
            <td>16</td>
            <td>10</td>
            <td>1.2</td>
        </tr>
        <tr>
            <td>Windows Console Host</td>
            <td>9</td>
            <td>20</td>
            <td>12</td>
            <td>1.25</td>
        </tr>
        <tr>
            <td>Windows Terminal</td>
            <td>9</td>
            <td>19</td>
            <td>12</td>
            <td>1.2</td>
        </tr>
        </tbody>
    </table>
</div>

<p>Your mileage may vary.</p>


<h2 id="options.scale"><a href="#options.scale" target="_self">Scale</a></h2>

<p>Ideally, the input image file should be scaled in a paint program to the size the user wants it to appear in the terminal. However, for minor tweaks, ASCII Silhouettify accepts an image scaling factor, which defaults to one.</p>


<h2 id="options.darkness"><a href="#options.darkness" target="_self">Darkness</a></h2>

<p>The conversion algorithm replaces areas of the image below 5% brightness with space characters, enabling the presumably black background to fully show through. The user can adjust this threshold as needed.</p>


<h2 id="options.threads"><a href="#options.threads" target="_self">Threads</a></h2>

<p>By default, the conversion algorithm distributes work across all available logical processors. The user can reduce the number of allocated processors to as few as one, though this will result in longer processing times.</p>


<h2 id="algorithm"><a href="#algorithm" target="_self">Algorithm</a></h2>

<p>On the Windows desktop where the developer created ASCII Silhouettify, Terminal renders each monospaced character within a <span>9×19</span> pixel rectangle when configured with the default 12-points, 1.2-em Cascadia Mono font. The developer captured images of the 95 printable ASCII characters and thresholded them at 50% intensity, producing images containing only black and white pixels:</p>

<p><img id="./images/thresholded.png" src="https://meatfighter.com/ascii-silhouettify/images/thresholded.png" alt="Thresholded characters">
</p>

<p>The algorithm separates the source image into unique color planes, each a white silhouette on a black background:</p>

<p><img id="./images/planes.png" src="https://meatfighter.com/ascii-silhouettify/images/planes.png" alt="planes">
</p>

<p>The algorithm partitions each plane into a matrix of <span>9×19</span> pixel rectangular regions, every one of them destined to be replaced by an ASCII character. To select the optimal character, the algorithm compares a region pixel-by-pixel against every ASCII character image. If a white pixel in a character coincides with a black pixel in the region, the algorithm excludes the character to avoid distorting the silhouette's outline. Of the remaining characters, the algorithm selects the one with the maximum number of matching white pixels.</p>

<p>When the algorithm replaces a region with an ASCII character, it records the number of matching white pixels. After converting all planes, the algorithm combines them by selecting the characters with the highest number of matching white pixels. Finally, it colors those characters based on the colors of the planes from which they originated.</p>

<p>Prior to converting a source image, the algorithm sorts the ASCII character images by the number of white pixels. As shown below, the space character contains the fewest white pixels (zero), while the at sign contains the most.</p>

<p><img id="./images/sorted.png" src="https://meatfighter.com/ascii-silhouettify/images/sorted.png" alt="Sorted characters">
</p>

<p>The algorithm compares each region with the ASCII character images, starting with the at sign and moving downward. As soon as it finds a character that fully fits within the silhouette, the algorithm replaces the region with it because that character contains the greatest number of white pixels.</p>

<p>To significantly speed up the process, the algorithm prepares <span>171 bitmasks</span>, one for each pixel of the <span>9×19</span> pixel rectangular regions. Each bitmask represents the set of ASCII characters images with a black pixel at the coordinates that uniquely identifies the bitmask.</p>

<p>Specifically, each bitmask contains <span>95 bits</span>, where each bit corresponds to an ASCII character image ordered by the number of white pixels: <span>bit-0</span> represents the space character, and <span>bit-94</span> represents the at sign. The algorithm clears all bits in all bitmasks. Then, for each black pixel in each ASCII character image, the algorithm sets the bit corresponding to the character in the bitmask associated with the pixel.</p>

<p>During region conversion, the algorithm maintains a <span>95-bit</span> accumulator that represents a narrowing set of ASCII characters it can use for the replacement. When it begins to convert a region, the algorithm initializes the accumulator to all ones, indicating all characters are initially considered. Then, for each black pixel in the region, the algorithm updates the accumulator to the current accumulator value bitwise ANDed with the bitmask corresponding to the pixel. That operation excludes all ASCII character images with a white pixel at a location where a black pixel exists in the region.</p>

<p>After the algorithm repeats that process across the region, the accumulator‘s set bits represent the remaining characters that can replace the region. Since the characters are ordered, the number of leading zeros in the accumulator is the index of the ASCII character image with the greatest number of white pixels fully contained within the plane‘s silhouette. With the help of a library, the algorithm invokes a microprocessor instruction for <a href="https://en.wikipedia.org/wiki/Find_first_set">counting leading zeros</a> to obtain the value it needs rapidly.</p>

<p>When the algorithm partitions the source image into a matrix of rectangular regions, the origin of the matrix affects the outcome. To optimize the result, the algorithm repeats the entire image conversion for all integer-coordinate origins within a <span>9×19</span> pixel area around the image origin. It then returns the best result found. To manage the extensive processing required, the algorithm distributes the work among the available logical processors.</p>

<p>Based on user configuration, the algorithm limits itself to a palette that ranges from just the first eight colors of the standard ANSI palette to the full <span>256-color</span> extended ANSI palette. To separate the source image into unique color planes, the algorithm employs the computationally expensive <a href="http://www.brucelindbloom.com/index.html?Eqn_DeltaE_CIE2000.html">CIEDE2000</a> perceptual color difference formula to find the closest colors within the palette.</p>

<p>The source is available from the following repositories:</p>

<ul>
    <li><a href="https://github.com/meatfighter/ascii-silhouettify">Command-line version</a></li>
    <li><a href="https://github.com/meatfighter/quasar-ascii-silhouettify">Browser version</a></li>
</ul>

<hr>




</div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenSSH introduces options to penalize undesirable behavior (223 pts)]]></title>
            <link>https://undeadly.org/cgi?action=article;sid=20240607042157</link>
            <guid>40610621</guid>
            <pubDate>Fri, 07 Jun 2024 17:08:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://undeadly.org/cgi?action=article;sid=20240607042157">https://undeadly.org/cgi?action=article;sid=20240607042157</a>, See on <a href="https://news.ycombinator.com/item?id=40610621">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Contributed by
<a href="http://bsdly.blogspot.com/">Peter N. M. Hansteen</a>
on <time datetime="2024-06-06T17:54:01Z">2024-06-06</time>
from the sshd to carry a big stick dept.</p><p>
In a recent <a href="https://marc.info/?l=openbsd-cvs&amp;m=171769392207688&amp;w=2">commit</a>, Damien Miller (<code>djm@</code>) introduced the new <a href="https://man.openbsd.org/sshd">sshd(8)</a> configurations options, <code><a href="https://man.openbsd.org/sshd_config.5#PerSourcePenalties">PerSourcePenalties</a></code> and <code><a href="https://man.openbsd.org/sshd_config.5#PerSourcePenaltyExemptList">PerSourcePenaltyExemptList</a></code>, to provide a built in facility in <a href="https://man.openbsd.org/sshd">sshd(8)</a> itself to penalize undesirable behavior, and to shield specific clients from penalty, respectively. 
</p><p>
The commit message reads,
</p><blockquote><pre>List:       openbsd-cvs
Subject:    CVS: cvs.openbsd.org: src
From:       Damien Miller &lt;djm () cvs ! openbsd ! org&gt;
Date:       2024-06-06 17:15:26

CVSROOT:	/cvs
Module name:	src
Changes by:	djm@cvs.openbsd.org	2024/06/06 11:15:26

Modified files:
	usr.bin/ssh    : misc.c misc.h monitor.c monitor_wrap.c 
	                 servconf.c servconf.h srclimit.c srclimit.h 
	                 sshd-session.c sshd.c sshd_config.5 

Log message:
Add a facility to <a href="https://man.openbsd.org/sshd">sshd(8)</a> to penalise particular problematic client
behaviours, controlled by two new <a href="https://man.openbsd.org/sshd_config">sshd_config(5)</a> options:
<a href="https://man.openbsd.org/sshd_config#PerSourcePenalties">PerSourcePenalties</a> and <a href="https://man.openbsd.org/sshd_config#PerSourcePenaltyExemptList">PerSourcePenaltyExemptList</a>.
</pre></blockquote>

<blockquote><pre>When PerSourcePenalties are enabled, <a href="https://man.openbsd.org/sshd">sshd(8)</a> will monitor the exit
status of its child pre-auth session processes. Through the exit
status, it can observe situations where the session did not
authenticate as expected. These conditions include when the client
repeatedly attempted authentication unsucessfully (possibly indicating
an attack against one or more accounts, <abbr>e.g.</abbr> password guessing), or
when client behaviour caused sshd to crash (possibly indicating
attempts to exploit sshd).

When such a condition is observed, sshd will record a penalty of some
duration (<abbr>e.g.</abbr> 30 seconds) against the client's address. If this time
is above a minimum threshold specified by the PerSourcePenalties, then
connections from the client address will be refused (along with any
others in the same <a href="https://man.openbsd.org/sshd_config.5#PerSourceNetBlockSize">PerSourceNetBlockSize</a> <abbr>CIDR</abbr> range).

Repeated offenses by the same client address will accrue greater
penalties, up to a configurable maximum. A <a href="https://man.openbsd.org/sshd_config.5#PerSourcePenaltyExemptList">PerSourcePenaltyExemptList</a>
option allows certain address ranges to be exempt from all penalties.

We hope these options will make it significantly more difficult for
attackers to find accounts with weak/guessable passwords or exploit
bugs in sshd(8) itself.

PerSourcePenalties is off by default, but we expect to enable it
automatically in the near future.

much feedback markus@ and others, ok markus@
</pre></blockquote><p>
This new facility comes in addition to the already well known and loved  <a href="https://man.openbsd.org/pf.conf#Stateful_Tracking_Options"><code>pf.conf</code> <em>state tracking options</em></a>, and is for now available only in <a href="https://www.openbsd.org/">OpenBSD</a>-<code>current</code>, but is almost certainly to be available in the upcoming OpenBSD <em>7.6</em> release.
</p><p>
At first we were wondering whether these options would be enabled by default before the new release. We did not have to wait long. This <a href="https://marc.info/?l=openbsd-cvs&amp;m=171770534714766&amp;w=2">subsequent commit</a> settled the issue:
</p><blockquote><pre>List:       openbsd-cvs
Subject:    CVS: cvs.openbsd.org: src
From:       Damien Miller &lt;djm () cvs ! openbsd ! org&gt;
Date:       2024-06-06 20:25:48

CVSROOT:	/cvs
Module name:	src
Changes by:	djm@cvs.openbsd.org	2024/06/06 14:25:48

Modified files:
	usr.bin/ssh    : servconf.c 

Log message:
enable PerSourcePenalties by default.

ok markus

<abbr>NB.</abbr> if you run a sshd that accepts connections from behind large NAT
blocks, proxies or anything else that aggregates many possible users
behind few <abbr>IP</abbr> addresses, then this change may cause legitimate traffic
to be denied.

Please read the PerSourcePenalties, PerSourcePenaltyExemptList and
PerSourceNetBlockSize options in sshd_config(5) for how to tune your
sshd(8) for your specific circumstances.
</pre></blockquote><p>
So now we know: starting with OpenBSD 7.6, <code>PerSourcePenalties</code> will be enabled by default, and admins who do not themselves run <abbr>PF</abbr> or other network translation mechanisms will need to keep the consequences of inconsiderate <abbr>NAT</abbr> use in mind.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft Will Switch Off Recall by Default After Security Backlash (330 pts)]]></title>
            <link>https://www.wired.com/story/microsoft-recall-off-default-security-concerns/</link>
            <guid>40610435</guid>
            <pubDate>Fri, 07 Jun 2024 16:47:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/microsoft-recall-off-default-security-concerns/">https://www.wired.com/story/microsoft-recall-off-default-security-concerns/</a>, See on <a href="https://news.ycombinator.com/item?id=40610435">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>When Microsoft named <a href="https://www.wired.com/story/everything-announced-microsoft-surface-event-2024/">its new Windows feature Recall</a>, the company intended the word to refer to a kind of perfect, AI-enabled memory for your device. Today, the other, unintended definition of “recall”—a company's admission that a product is too dangerous or defective to be left on the market in its current form—seems more appropriate.</p><p>On Friday, Microsoft announced that it would be making multiple dramatic changes to its rollout of its Recall feature, making it an opt-in feature in the Copilot+ compatible versions of Windows where it had previously been turned on by default, and introducing new security measures designed to better keep data encrypted and require authentication to access Recall's stored data.</p><p>“We are updating the set-up experience of Copilot+ PCs to give people a clearer choice to opt-in to saving snapshots using Recall,” reads a <a data-offer-url="https://blogs.windows.com/windowsexperience/2024/06/07/update-on-the-recall-preview-feature-for-copilot-pcs/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://blogs.windows.com/windowsexperience/2024/06/07/update-on-the-recall-preview-feature-for-copilot-pcs/&quot;}" href="https://blogs.windows.com/windowsexperience/2024/06/07/update-on-the-recall-preview-feature-for-copilot-pcs/" rel="nofollow noopener" target="_blank">blog post</a> from Pavan Davuluri Microsoft's Corporate Vice President, Windows + Devices. “If you don’t proactively choose to turn it on, it will be off by default.”</p><p>The changes come amidst a mounting barrage of criticism from the security and privacy community, which has described Recall—which silently stores a screenshot of the user's activity every 5 seconds as fodder for AI analysis—as a gift to hackers: essentially unrequested, pre-installed spyware built into new Windows computers.</p><p>In the preview versions of Recall, that screenshot data, complete with the user's every bank login, password, and porn site visit would have been indefinitely collected on the user's machine by default. And though that highly sensitive is stored locally on the user's machine and not uploaded to the cloud, cybersecurity experts have warned that it all remains accessible to any hacker who so much as gains a temporary foothold on a user's Recall-enabled device, giving them a longterm panopticon view of the victim's digital life.</p><p>"It makes your security very fragile,” as Dave Aitel, a former NSA hacker and founder of security firm Immunity, described it—more charitably than some others—to WIRED earlier this week. “Anyone who penetrates your computer for even a second can get your whole history. Which is not something people want.”</p><p>For Microsoft, the Recall rollback comes in the midst of an embarrassing string of cybersecurity incidents and breaches—including a <a href="https://arstechnica.com/information-technology/2022/10/microsoft-under-fire-for-response-to-leak-of-2-4tb-of-sensitive-customer-data/">leak of terabytes of its customers' data</a> and a <a href="https://www.wired.com/story/microsoft-cloud-attack-china-hackers/">shocking</a> <a href="https://www.wired.com/story/microsoft-cloud-attack-china-hackers/">penetration of government email accounts</a> enabled by a <a href="https://www.wired.com/story/china-backed-hackers-steal-microsofts-signing-key-post-mortem/">cascading series of Microsoft security slipups</a>—that have grown so problematic as to become a sticking point even its <a href="https://www.wired.com/story/the-us-government-has-a-microsoft-problem/">uniquely close relationship with the US government</a>.</p><p>Those scandals have escalated to the degree that Microsoft's Nadella issued a memo just last month declaring that Microsoft would make security its first priority in any business decision. “If you’re faced with the tradeoff between security and another priority, your answer is clear: <strong>Do security</strong>,” Nadella's <a href="https://www.theverge.com/24148033/satya-nadella-microsoft-security-memo">memo read</a> (emphasis his). “In some cases, this will mean prioritizing security above other things we do, such as releasing new features or providing ongoing support for legacy systems.”</p><p>By all appearances, Microsoft's rollout of Recall—even after today's announcement—displays the opposite approach, and one that seems more in line with business as usual in Redmond: Announce a feature, get pummeled for its glaring security failures, then belatedly scramble to control the damage.</p><p><em>This is a developing story. Check back for further updates.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Recovery after HP tech support bricked my father's laptop (110 pts)]]></title>
            <link>https://github.com/ctag/hp_envy_reviver</link>
            <guid>40609126</guid>
            <pubDate>Fri, 07 Jun 2024 14:33:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ctag/hp_envy_reviver">https://github.com/ctag/hp_envy_reviver</a>, See on <a href="https://news.ycombinator.com/item?id=40609126">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">BIOS Recovery on HP Envy 17"</h2><a id="user-content-bios-recovery-on-hp-envy-17" aria-label="Permalink: BIOS Recovery on HP Envy 17&quot;" href="#bios-recovery-on-hp-envy-17"></a></p>
<p dir="auto">Not a polished product. These are tools and notes generated while re-programming the BIOS memory chip in an HP Envy-ae110nr laptop.</p>
<p dir="auto">It is my hope that by posting my troubleshooting process here I will help those who own a HP laptop to fix it themselves, and those who don't to save the hassle and avoid buying one in the first place.</p>
<div data-snippet-clipboard-copy-content="+--------------------+------------------------------------------------------------+
|       Folder       |                        Description                         |
+--------------------+------------------------------------------------------------+
| extracted_firmware | Dumped binaries from SPI chip                              |
| host_pc            | C++ software that interfaces with STM32                    |
| images             | Images in readme                                           |
| recovery_usb_files | Files created by sp133161.exe and copied off the USB drive |
| resources          | Datasheets and schematics used                             |
| stm32              | Embedded firmware that interacts with BIOS chip            |
+--------------------+------------------------------------------------------------+"><pre><code>+--------------------+------------------------------------------------------------+
|       Folder       |                        Description                         |
+--------------------+------------------------------------------------------------+
| extracted_firmware | Dumped binaries from SPI chip                              |
| host_pc            | C++ software that interfaces with STM32                    |
| images             | Images in readme                                           |
| recovery_usb_files | Files created by sp133161.exe and copied off the USB drive |
| resources          | Datasheets and schematics used                             |
| stm32              | Embedded firmware that interacts with BIOS chip            |
+--------------------+------------------------------------------------------------+
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Scenario</h2><a id="user-content-scenario" aria-label="Permalink: Scenario" href="#scenario"></a></p>
<p dir="auto">Several months ago my father's new laptop started having issues with the trackpad sensitivity. He called HP's tech support and was informed that they could not help him troubleshoot the problem at hand until he had updated the BIOS. The tech stepped him through downloading and running the BIOS update tool, and when the computer was rebooted my dad found that HP had indeed upgraded him from a laptop to a brick.</p>
<p dir="auto">For whatever reason the BIOS upgrade failed, and without warning the laptop was left in a near completely inert state. The power button would light up when pressed and the system fan would spin up to maximum. That was it. No backlight, no blinking caps lock, no beeps.</p>
<p dir="auto">After a few attempts at re-doing the BIOS flash, or booting with the <em>special hotkeys</em>, or using a <a href="https://support.hp.com/in-en/document/ish_3932413-2337994-16#:~:text=Turn%20off%20the%20computer.,release%20the%20Windows%20%2B%20V%20keys." rel="nofollow">recovery USB drive</a>, the tech gave up and referred dad to the expensive warranty he had purchased along with the laptop. So the computer was packed up and mailed off for repair.</p>
<p dir="auto">Eventually HP got back in touch, and alongside a picture of the laptop's (existing) upgraded RAM was a message stating that the laptop's condition was the consumer's fault for changing the RAM and thus the warranty was void. HP wanted $500 to downgrade the RAM back to stock before they would continue troubleshooting.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/hp_warranty_renege.png"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/hp_warranty_renege.png" alt=""></a></p>
<p dir="auto">As we've already established, the laptop's failure was not due to the 3rd party RAM, which had been cranking along perfectly for months. Under the <a href="http://uscode.house.gov/view.xhtml?req=granuleid%3AUSC-prelim-title15-chapter50&amp;edition=prelim" rel="nofollow">Magnuson-Moss Warranty Act</a> it is illegal for HP to renege on their warranty <em>unless the reason for warranty work is demonstrably due to the consumer's changes</em>. Which is a higher burden of proof than a picture of RAM. See also "Tie in Sales Provisions" on <a href="https://www.ftc.gov/tips-advice/business-center/guidance/businesspersons-guide-federal-warranty-law" rel="nofollow">ftc.gov</a>. But I am not a lawyer and I sure can't afford one, so Hewlett-Packard will continue to harm consumers with impunity.</p>
<p dir="auto">The laptop was returned un-repaired, and it sat unused for several months. Until this past weekend, when I decided it couldn't get any more bricked and asked to borrow it to continue troubleshooting.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Locating the BIOS chip</h2><a id="user-content-locating-the-bios-chip" aria-label="Permalink: Locating the BIOS chip" href="#locating-the-bios-chip"></a></p>
<p dir="auto">A quick search online led me to <a href="http://schematic-x.blogspot.com/2018/04/hp-schematics-pack.html" rel="nofollow">schematic-x.blogspot.com</a> which had two PDFs claiming to be schematics for "HP Envy 17." I <a href="https://github.com/ctag/hp_envy_reviver/blob/main/resources/HP_ENVY_17.pdf">downloaded one</a> and thumbed through until I found the BIOS on page 34:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/pdf_bios_ic.png"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/pdf_bios_ic.png" alt="View of the BIOS chip for a similar laptop motherboard."></a></p>
<p dir="auto">The IC listed there is a MX25L8005M2C-15G. There isn't one of those on this laptop, but the schematic shows that the BIOS is a SPI device, and there is a MX25L6473F SPI flash chip right next to the CPU:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/bios_chip_initial.jpg"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/bios_chip_initial.jpg" alt=""></a></p>
<p dir="auto">Searching for that second part number brings up some hits that <a href="https://www.win-raid.com/t4287f16-GUIDE-The-Beginners-Guide-to-Using-a-CH-A-SPI-Programmer-Flasher-With-Pictures-11.html" rel="nofollow">include "BIOS" in them</a>. That's promising, and it makes me suspect that this schematic is for a slightly different motherboard also sold as "Envy 17".</p>
<p dir="auto">I look at any other likely candidate chips and search their part numbers as well. I'm not sure if this MX25L6473F is the BIOS chip or not, but it seems to be the best bet.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Test fixture</h2><a id="user-content-test-fixture" aria-label="Permalink: Test fixture" href="#test-fixture"></a></p>
<p dir="auto">There's a chance this process would have been much easier if I'd had a Bus Pirate and SOP8 adapter to clip onto the IC while it was still on the motherboard. FYI.</p>
<p dir="auto">Since I don't have a way of clipping onto the IC I decide to remove it from the motherboard rather than try soldering flying wires to the pins while it's attached.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/bios_chip_removed.jpg"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/bios_chip_removed.jpg" alt=""></a></p>
<p dir="auto">From the datasheet I know this part runs at 3 volts, which should be compatible with an STM32F103 dev board I have laying around.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/test_fixture_1.jpg"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/test_fixture_1.jpg" alt=""></a></p>
<p dir="auto">I start by folding some jumper wires and soldering them to the 6 pins I need for SPI.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/test_fixture_2.jpg"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/test_fixture_2.jpg" alt=""></a></p>
<p dir="auto">Then those wires are brought up to the STM32 dev board.</p>
<div data-snippet-clipboard-copy-content="+---------------+---------------+
| SOP8 BIOS Pin |   STM32 Pin   |
+---------------+---------------+
|             1 | PA4           |
|             2 | PA6           |
|             3 | Not Connected |
|             4 | GND           |
|             5 | PA7           |
|             6 | PA5           |
|             7 | Not Connected |
|             8 | VCC           |
+---------------+---------------+"><pre><code>+---------------+---------------+
| SOP8 BIOS Pin |   STM32 Pin   |
+---------------+---------------+
|             1 | PA4           |
|             2 | PA6           |
|             3 | Not Connected |
|             4 | GND           |
|             5 | PA7           |
|             6 | PA5           |
|             7 | Not Connected |
|             8 | VCC           |
+---------------+---------------+
</code></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/test_fixture_3.jpg"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/test_fixture_3.jpg" alt=""></a></p>
<p dir="auto">Finally the ST-Link is connected via SWD to the dev board, and a serial (FTDI) adapter is added. Eventually I switched out the FTDI adapter for a virtual CDC serial port on the STM's integrated micro-USB.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/test_fixture_4.jpg"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/test_fixture_4.jpg" alt=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Extracting the firmware</h2><a id="user-content-extracting-the-firmware" aria-label="Permalink: Extracting the firmware" href="#extracting-the-firmware"></a></p>
<p dir="auto">This step wasn't strictly necessary, but I want to gain familiarity with communicating to the SPI device before attempting a write, and I want the ability to read back out new firmware to confirm it was written correctly.</p>
<p dir="auto">The first step was to read the RDID and status registers, saving the contents to a variable and inspecting in my debugger. Along the way I learned that the STM32's chip-select function isn't great, and pivoted to <a href="https://stackoverflow.com/a/35790106" rel="nofollow">manually toggling the line as a GPIO</a>. Once that was working I added in serial output and expanded the STM32 code to begin transferring all of the flash memory contents on boot. The SPI code was cribbed from this <a href="https://www.digikey.com/en/maker/projects/getting-started-with-stm32-how-to-use-spi/09eab3dfe74c4d0391aaaa99b0a8ee17" rel="nofollow">digikey source file</a>.</p>
<p dir="auto">If the STM32 only programs successfully the first time (SWD wasn't configured):
<a href="https://www.reddit.com/r/embedded/comments/kz5ar4/error_in_initializing_stlink_device_found_on/gjorccv/" rel="nofollow">https://www.reddit.com/r/embedded/comments/kz5ar4/error_in_initializing_stlink_device_found_on/gjorccv/</a></p>
<p dir="auto">SPI reference for STM32:
<a href="https://www.digikey.com/en/maker/projects/getting-started-with-stm32-how-to-use-spi/09eab3dfe74c4d0391aaaa99b0a8ee17" rel="nofollow">https://www.digikey.com/en/maker/projects/getting-started-with-stm32-how-to-use-spi/09eab3dfe74c4d0391aaaa99b0a8ee17</a></p>
<p dir="auto">The first several attempts at dumping the chip contents used either gnu-screen or <a href="https://askubuntu.com/questions/347340/how-to-dump-raw-serial-data-to-disk" rel="nofollow">stty</a>:</p>
<p dir="auto"><code>screen /dev/ttyUSB0 115200 &gt; output.bin</code></p>
<p dir="auto"><code>(stty raw; cat &gt; output.bin) &lt; /dev/ttyUSB0</code></p>
<p dir="auto">But I kept getting files that either didn't finish, or didn't match. I wasn't sure what was happening, but suspected either a buffer was being overrun or the FTDI serial adapter's connection was loose. See <code>extracted_firmware/dump_{01-05}.bin</code>.</p>
<p dir="auto">Reluctantly I started working on the C++ program in <code>host_pc/</code>, and eventually also modified the stm32 firmware to <a href="https://controllerstech.com/send-and-receive-data-to-pc-without-uart-stm32-usb-com/" rel="nofollow">use the USB port</a> instead of a serial adapter.</p>
<p dir="auto">Resource used for configuring the serial port in C++: <a href="https://blog.mbedded.ninja/programming/operating-systems/linux/linux-serial-ports-using-c-cpp/" rel="nofollow">https://blog.mbedded.ninja/programming/operating-systems/linux/linux-serial-ports-using-c-cpp/</a>.</p>
<p dir="auto">Eventually I grew tired of hunting the source of these file differences, and wanted to know conclusively what was on that BIOS chip. So I set up the host and STM32 software to read a single byte at a time and save it to a file. This would have taken more than a day on the serial adapter, but I found that if the baud rate wasn't set manually in the C++ program it defaults to either a very high baud or possibly even the USB full speed (12MHz) that the virtual STM32 CDC device runs at, bringing the time down to only around one hour. The first full firmware was dump_11.bin which matched stty-based dump_03.bin.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Locating a new BIOS binary</h2><a id="user-content-locating-a-new-bios-binary" aria-label="Permalink: Locating a new BIOS binary" href="#locating-a-new-bios-binary"></a></p>
<p dir="auto">Now that I had the old, supposedly corrupted BIOS file the next step would be to find a complete file to flash. I extracted the <a href="https://github.com/ctag/hp_envy_reviver/blob/main/resources/sp133161.exe">sp133161.exe</a> file as though it were a .zip archive, and went browsing through the resulting files. For a while it looked like the easy-to-use binary file wouldn't be had, since the HP tool only included some .efi and .s12 files, which sounds to me like the firmware is signed.</p>
<p dir="auto">Eventually I recalled back to that recovery USB drive, and made a new one to copy the files off of. Inside (<code>recovery_usb_files/HP/BIOS/Current</code>) I found 083AD.bin and 0834D.bin. I'm not sure what the difference is, but I was able to match an instance of "083AD" ascii in the extracted firmware to the 083AD.bin file, which was as close to a conclusive match as I felt I would get.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/bios_083AD_search.png"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/bios_083AD_search.png" alt=""></a></p>
<p dir="auto">xxd was valuable in comparing the files with vimdiff:</p>
<p dir="auto"><code>xxd 083AD.bin &gt;083AD.hex</code></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Flashing new BIOS</h2><a id="user-content-flashing-new-bios" aria-label="Permalink: Flashing new BIOS" href="#flashing-new-bios"></a></p>
<p dir="auto">My first inclination for flashing the new binary file would be to bundle it with the STM32 firmware. That way no host_pc-serial issues could corrupt the transfer. Unfortunately the STM32 I have is too small to package the whole file, so I had to backtrack to sending the file from the C++ host_pc program.</p>
<p dir="auto">Bundling binary file for C:
<a href="https://web.archive.org/web/20140313121651/http://www.burtonini.com/blog/computers/ld-blobs-2007-07-13-15-50" rel="nofollow">https://web.archive.org/web/20140313121651/http://www.burtonini.com/blog/computers/ld-blobs-2007-07-13-15-50</a></p>
<p dir="auto">Building for the STM32:</p>
<p dir="auto"><code>arm-none-eabi-ld -r -b binary -o 083AD.o 083AD.bin</code></p>
<p dir="auto">Including that file in STM32cubeIDE:</p>
<p dir="auto">Right click the project -&gt; Properties -&gt; C/C++ Build -&gt; Settings -&gt; Tool Settings tab -&gt; MCU GCC Linker -&gt; Miscellaneous -&gt; Additional object files. Add the path to the arm linked 083AD.o file there.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/stm32cubeide_linker.png"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/stm32cubeide_linker.png" alt=""></a></p>
<p dir="auto">After that approach was blocked by the microcontroller's flash storage space, the object file was re-built with regular ld and included in the host_pc program.</p>
<p dir="auto">After a few failed attempts to write a page-at-a-time to the STM32, I once again fell back on byte-by-byte with ack bytes being sent back. This time the entire file was written and read back out intact.</p>
<p dir="auto">MD5 sums:</p>
<div data-snippet-clipboard-copy-content="746d2097365c29ba0a2e90d04f627b4b  083AD.bin
746d2097365c29ba0a2e90d04f627b4b  dump_16_0x1_full_post_write_083AD.bin"><pre><code>746d2097365c29ba0a2e90d04f627b4b  083AD.bin
746d2097365c29ba0a2e90d04f627b4b  dump_16_0x1_full_post_write_083AD.bin
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Conclusion</h2><a id="user-content-conclusion" aria-label="Permalink: Conclusion" href="#conclusion"></a></p>
<p dir="auto">Once I was happy with the successful programming of the chip, it was removed from the test fixture and put back in the laptop.</p>
<p dir="auto">On first boot... Nothing happened. In fact, it took several boots, and possibly removing the hard drive (which we had also tried prior to all of this) before I finally saw the backlight flicker. The system then rebooted on its own, and the HP logo appeared along with a message complaining that the CMOS BIOS settings had been lost. After that everything appeared to work.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ctag/hp_envy_reviver/blob/main/images/diag_test.jpg"><img src="https://github.com/ctag/hp_envy_reviver/raw/main/images/diag_test.jpg" alt=""></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Σ-GPTs: A New Approach to Autoregressive Models (196 pts)]]></title>
            <link>https://arxiv.org/abs/2404.09562</link>
            <guid>40608413</guid>
            <pubDate>Fri, 07 Jun 2024 13:12:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2404.09562">https://arxiv.org/abs/2404.09562</a>, See on <a href="https://news.ycombinator.com/item?id=40608413">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2404.09562">View PDF</a>
    <a href="https://arxiv.org/html/2404.09562v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Autoregressive models, such as the GPT family, use a fixed order, usually left-to-right, to generate sequences. However, this is not a necessity. In this paper, we challenge this assumption and show that by simply adding a positional encoding for the output, this order can be modulated on-the-fly per-sample which offers key advantageous properties. It allows for the sampling of and conditioning on arbitrary subsets of tokens, and it also allows sampling in one shot multiple tokens dynamically according to a rejection strategy, leading to a sub-linear number of model evaluations. We evaluate our method across various domains, including language modeling, path-solving, and aircraft vertical rate prediction, decreasing the number of steps required for generation by an order of magnitude.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Arnaud Pannatier [<a href="https://arxiv.org/show-email/979ad75a/2404.09562">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 15 Apr 2024 08:22:47 UTC (1,389 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Instruction Sets Should Be Free: The Case for RISC-V [pdf] (2014) (108 pts)]]></title>
            <link>https://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-146.pdf</link>
            <guid>40608373</guid>
            <pubDate>Fri, 07 Jun 2024 13:06:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-146.pdf">https://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-146.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=40608373">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Tom 7: Badness 0 (Three ways) (168 pts)]]></title>
            <link>http://tom7.org/bovex/</link>
            <guid>40608332</guid>
            <pubDate>Fri, 07 Jun 2024 13:01:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://tom7.org/bovex/">http://tom7.org/bovex/</a>, See on <a href="https://news.ycombinator.com/item?id=40608332">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">
<p>
  Badness 0 (Three ways)
</p>

<p>Ways <b>one</b> and <b>two</b>: Read <b><a href="http://tom7.org/bovex/badness-0-knuth.pdf">Knuth's Version</a></b> nand <b><a href="http://tom7.org/bovex/badness-0-epsom.pdf">Epsom's Version</a></b>.
They appear in the extremely discerning proceedings of <b><a href="http://sigbovik.org/2024/">SIGBOVIK 2024</a></b>. Be warned that due to <b>"BUG"</b>, these seem only to display properly in Chrome. I am working on fixing <b>"BUG"</b> once I get some sleep; I have some leads due to helpful people on the <a href="http://radar.spacebar.org/f/a/weblog/comment/1/1228">blog</a>. The laundered version in the SIGBOVIK proceedings may work.

</p><p>Way <b>three</b> (recommended) is to sit back and bathe in the 4k, 60Hz flashing lights that are <b><a href="https://youtu.be/Y65FRxE7uMc">Badness 0 (Apostrophe‛s version)</a></b> is the newest installment in the Main Sequence:

<iframe width="853" height="480" src="https://www.youtube.com/embed/Y65FRxE7uMc" frameborder="0" allowfullscreen=""></iframe>

</p><p>If you want to experience <b>"BUG"</b> directly, way four is to immediately head to 
  <b><a href="https://sourceforge.net/p/tom7misc/svn/HEAD/tree/trunk/rephrase/">the source code</a></b>. I will try to add some notes on compiling and using this after getting some sleep. The source code is available under the GPL (<a href="http://tom7.org/bovex/COPYING">COPYING</a>) or GJPL (<a href="http://tom7.org/bovex/JCOPYING">JCOPYING</a>).

</p><div><p>Of course, there are multiple irksome videos on my YouTube channel
<a href="https://youtube.com/suckerpinch">Suckerpinch</a>!

<img src="http://tom7.org/bovex/thumbnail.png" alt="screenshot for thumbnails"></p></div><p>Please leave a comment <a href="http://radar.spacebar.org/">on my blog</a> or on Mastodon at <a href="https://mastodon.social/@tom7">@tom7</a>!
</p><p>Get all Tom 7 thingos at → [<a href="http://tom7.org/">tom7.org</a>]</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Does GPT-4o Encode Images? (240 pts)]]></title>
            <link>https://www.oranlooney.com/post/gpt-cnn/</link>
            <guid>40608269</guid>
            <pubDate>Fri, 07 Jun 2024 12:54:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.oranlooney.com/post/gpt-cnn/">https://www.oranlooney.com/post/gpt-cnn/</a>, See on <a href="https://news.ycombinator.com/item?id=40608269">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <img src="https://www.oranlooney.com/post/gpt-cnn_files/lead.jpg">
      
      
      
      <hr>
      <ul>
        
        <li><time>June 5, 2024</time></li>
        <li>
          <a href="https://www.oranlooney.com/tags/machine-learning/">
            <i></i>
            Machine Learning
          </a>&nbsp;
        </li>
        <li>
          <a href="https://www.oranlooney.com/tags/llm/">
            <i></i>
            LLM
          </a>&nbsp;
        </li>
        <li>
          <a href="https://www.oranlooney.com/tags/cnn/">
            <i></i>
            CNN
          </a>&nbsp;
        </li>
      </ul>
      

      

<p>Here’s a <a href="https://openai.com/api/pricing/">fact</a>: GPT-4o charges 170 tokens to process each <code>512x512</code> tile
used in high-res mode. At ~0.75 tokens/word, this suggests a picture is worth
about 227 words—only a factor of four off from the traditional saying.</p>

<p>(There’s also an 85 tokens charge for a low-res ‘master thumbnail’ of each picture
and higher resolution images are broken into many such <code>512x512</code> tiles,
but let’s just focus on a single high-res tile.)</p>

<p>OK, but <em>why</em> 170? It’s an oddly specific number, isn’t it? OpenAI uses round
numbers like “\$20” or “\$0.50” in their pricing, or powers of 2 and 3 for their
internal dimensions. Why choose a numbers like 170 in this instance?</p>

<p>Numbers that are just dropped into a codebase without explanation are called
“<a href="https://en.wikipedia.org/wiki/Magic_number_(programming)">magic numbers</a>” in programming, and 170 is a pretty glaring magic
number.</p>

<p>And why are image costs even being converted to token counts anyway? If it were
just for billing purposes, wouldn’t it be less confusing to simply list the
cost per tile?</p>

<p>What if OpenAI chose 170, not as part of some arcane pricing strategy, but
simply because it’s literally true? What if image tiles are in fact represented
as 170 consecutive embedding vectors? And if so, how?</p>

<h2 id="embeddings">Embeddings</h2>

<p>The first thing to recall about the transformer model is that it operates on
vectors, not discrete tokens. The inputs <em>have</em> to be vectors, or the dot
product similarity at the heart of the transformer wouldn’t make any sense. The
whole concept of tokens is a pre-processing step: text is converted to tokens
and tokens are converted to embedding vectors by an embedding model before they
even hit the first layer of the transformer model.</p>

<p>For example, Llama 3 uses 4,096 feature dimensions internally. Consider the
sentence, “My very educated mother just served us nine pizzas.” It gets
converted into 10 integer tokens (counting the period) by <a href="https://en.wikipedia.org/wiki/Byte_pair_encoding">BPE</a>, then
those are each converted into 4,096-dimensional vectors by an embedding model,
resulting in a <code>10x4096</code> matrix. That’s the “real” input into a transformer
model.</p>

<p>But there’s no law that says that these vectors <strong>must</strong> come from a text embedding
model. It’s a strategy that works well for text data, but if we have data in a
different format that we want to feed into a transformer then we can simply use
a different embedding strategy.</p>

<p>We know that OpenAI has been thinking along these lines because in 2021 they
released the <a href="https://openai.com/index/clip/">CLIP embedding model</a>. CLIP embeds both text and images
into the same semantic vector space, allowing you to use cosine similarity to
find images related to text strings, or images which are semantically similar
to other images. You can try the <a href="https://huggingface.co/spaces/vivien/clip">demo</a> on hugging face to get a feel for
how it works:</p>

<p><a href="https://huggingface.co/spaces/vivien/clip"><img src="https://www.oranlooney.com/post/gpt-cnn_files/clip_demo.png"></a></p>

<p>However, CLIP embeds the entire image as a single vector, not 170 of them.
GPT-4o must be using a different, more advanced strategy internally to
represent images (and likewise video, voice, and other kinds of data; that’s
why it’s “omnimodal.”)</p>

<p>Let’s see if we can’t deduce what that strategy might be for image data in
particular.</p>

<h2 id="number-of-feature-dimensions">Number of Feature Dimensions</h2>

<p>Let’s start by guesstimating the number of dimensions used internally by GPT-4o
to represent embedding vectors. We can’t know the real number for certain
because it’s proprietary, but we can make some reasonable assumptions.</p>

<p>OpenAI seems to likes powers of 2, sometimes with a single factor of 3 mixed
in. For example, they used 1,536 for <a href="https://openai.com/index/new-and-improved-embedding-model/">ada-002</a> embeddings or 3,072 for
<a href="https://platform.openai.com/docs/guides/embeddings/embedding-models">text-embedding-3-large</a>. GPT-3 is known to use <a href="https://dugas.ch/artificial_curiosity/GPT_architecture.html">12,288 dimensions
throughout</a>. It’s probable that GPT-4o either kept or increased that
parameter.</p>

<p>It doesn’t seem likely that the number of embeddings would have gone down from
GPT-3 to GPT-4o, but it’s possible. Releases like GPT-4 Turbo were actually
faster and cheaper than earlier version, and a reduction in embedding dimension
may have been part of that if the developers had benchmarks showing that the
smaller size was just as good in terms of quality.</p>

<blockquote>
<p>“Interest rates may go up, they may go down, or they may stay the same. I’m
sorry, but I really can’t be any more vague than that.”
—Alan Greenspan</p>
</blockquote>

<p>Given all that, it’s likely that the number of feature dimensions used inside
of GPT-4o is one of these:</p>

<div>
    <table>
        <thead>
            <tr>
                <th>Dimension</th>
                <th>Prime Factors</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>$1{,}536$</td>
                <td>$3 \cdot 2^9$</td>
            </tr>
            <tr>
                <td>$2{,}048$</td>
                <td>$2^{11}$</td>
            </tr>
            <tr>
                <td>$3{,}072$</td>
                <td>$3 \cdot 2^{10}$</td>
            </tr>
            <tr>
                <td>$4{,}096$</td>
                <td>$2^{12}$</td>
            </tr>
            <tr>
                <td>$12{,}228$</td>
                <td>$3 \cdot 2^{12}$</td>
            </tr>
            <tr>
                <td>$16{,}384$</td>
                <td>$2^{14}$</td>
            </tr>
            <tr>
                <td>$24{,}576$</td>
                <td>$3 \cdot 2^{13}$</td>
            </tr>
        </tbody>
    </table>
</div>

<p>For the sake of argument, I’ll assume that GPT-4o is using 12,228 for the
dimension of its embedding vectors. It doesn’t really matter if we’re off by a
factor of 2 or 4; the same arguments will work.</p>

<h2 id="embedding-images">Embedding Images</h2>

<p>Image tiles are square, so are likely represented by a square grid of tokens.
170 is very close to $13 \times 13$. The extra token could a single embedding vector
which encodes a kind of gestalt impression of the entire image, exactly as
CLIP does (and similar to their strategy of using an 85 token “master
thumbnail” for each image.)</p>

<p>So, the question is, how do we go from <code>512x512x3</code> to <code>13x13x12228</code>?</p>

<h3 id="strategy-1-raw-pixels">Strategy 1: Raw Pixels</h3>

<p>Here’s an extremely simple way to stuff an image into a vector space:</p>

<ol>
<li>Divide the <code>512x512</code> image into a <code>8x8</code> grid of “mini-tiles.”</li>
<li>Each mini-tile is <code>64x64x3</code>; flatten it a vector of dimension 12,228.</li>
<li>Each mini-tile is a single embedding vector.</li>
<li>The entire image tile is represented as 64 consecutive embedding vectors.</li>
</ol>

<p>There are two problems with this approach:</p>

<ol>
<li>64 ≠ 170, and</li>
<li>it’s extremely stupid.</li>
</ol>

<p>By “extremely stupid” I mean that it doesn’t make any sense to embed using raw
RGB values and then just cross your fingers and hope the transformer will sort it out.
Transformers aren’t really designed to handle the spatial structure of 2D images,
especially not when it’s embedded in such a braindead way as this.</p>

<p>To see why, imagine the image is shifted a few pixel to the left. The dot
product between the embedding vectors of the original and shifted images would
immediately drop close to zero. The same would happen if we resize the image.</p>

<p>Ideally we’d want a model that was robust to these kinds of transforms—we’d
like it to have translational and scale invariance, to use the technical jargon.</p>

<h3 id="strategy-2-cnn">Strategy 2: CNN</h3>

<p>Luckily, there already exists a model with those characteristics, with over a
decade-long track record of successfully handling image data: the
<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Network</a>. (Here, I’m using the term to describe the
broad family of deep learning models which use convolution layers somewhere
inside them.)</p>

<p>Just to get a sense of what the options are, let’s take look at a classic CNN
architecture introduced in 2012, <a href="https://en.wikipedia.org/wiki/AlexNet">AlexNet</a>:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/alexnet.png"></p>

<p>The basic building blocks are:</p>

<ol>
<li>Convolution Layer. These scan over an image in $k \times k$ sized blocks,
training a small neural network.</li>
<li>Max Pool Layer. These also look at $k \times k$ block, but simply take the
maximum value from each.</li>
</ol>

<p>You should spot two key trends as we move into the deeper layers of the
network: the height and width get smaller, while the number of “channels”
(sometimes called “filters”) gets larger. That means we’re incrementally
digesting many low-level features into fewer high level concepts until, at the
very end, AlexNet has turned the entire image into a single categorical concept
representing something like a “cat” or “dog.” CNNs are essentially funnels that
squeeze the lemons of raw pixels into the lemonade of semantic vectors.</p>

<p>If you’re following my somewhat strained analogy, you should see how a CNN can
turn an image into a single embedding vector. To see how (and why) a CNN can
turn an image into many embedding vectors, let’s take a look at a slightly
newer (circa 2018) CNN architecture, one that’s a little closer in spirit to
what we’ll need for GPT-4o. It’s called <a href="https://arxiv.org/abs/1804.02767">YOLO</a>, short for “You Only Look
Once.”</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/yolo_v3.png"></p>

<p>Here, the notation “xN” means that the entire block is repeated N times. YOLOv3
is 10 times as deep as AlexNet but is still very similar in some regards. It
has a somewhat more modern design: stride 2 convolutional layers instead
of max pooling layers to reduce dimensionality, residual layers to
preserve good gradients in very deep networks, etc.</p>

<p>But the key difference is that it doesn’t reduce the image to a single flat
vector, but stops at <code>13x13</code>. There are no fully connected layers after that;
the output of YOLOv3 is in fact 169 different vectors, laid out in a <code>13x13</code>
grid, each of dimension 1,024, and each representing the class (and some
bounding box data we’ll ignore) of the object found in or near a particular
cell of the grid. This means that YOLO doesn’t see just one object in the
image—it can see many in a single pass. That’s why it’s said to “only
look once.”</p>

<p>These examples give us a rough sense of what GPT-4o’s (hypothetical) image
embedding CNN might be shaped like. All we have to do now is play a little game
of connect the dots: how do we go from <code>512x512x3</code> to <code>13x13x12228</code> using
standard CNN layers?</p>

<p>The moves in this game are the standard building blocks we’ve seen in the
above CNN architectures. We can choose the layer types and play around with
hyperparameters like kernel size, stride length, padding strategy, etc. Note
that we ignore things like residual layers, repeated blocks, batch/layer normalization,
or <code>1x1</code> convolutional layers as these don’t affect the overall tensor size.</p>

<p>The goal is to suggest a workable CNN architecture that connects the known
input size (<code>512x512</code> images with 3 RGB color channels) to the assumed output
shape (<code>13x13</code> embedding vectors with 12,228 dimensions each.)</p>

<p>I tried
<a href="https://www.oranlooney.com/post/gpt-cnn_files/gpt4o_speculative.png" target="_blank">several</a>
<a href="https://www.oranlooney.com/post/gpt-cnn_files/gpt4o_speculative4.png" target="_blank">different</a>
<a href="https://www.oranlooney.com/post/gpt-cnn_files/gpt4o_speculative2.png" target="_blank">variations</a>,
but most of these required special cases on one or more layers to “fit.” Until
I found this one, which steps down elegantly with no special cases at all:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/gpt4o_speculative3.png"></p>

<p>It very neat, isn’t it? It’s almost identical to AlexNet, and it steps down
from from 512 to 13 in five identical repeating blocks, while simultaneously
quadrupling the number of channels with each block to hit 12,228 on the bottom
layer. Unfortunately, it also feels a little outdated due to the <code>5x5</code> kernels
and max pool layers. AlexNet was a breakthrough in 2012 but I would be suprised
if OpenAI was using something similar in 2024.</p>

<p>Here’s an alternative that <em>almost</em> worked (got to <code>12x12</code> instead of <code>13x13</code>)
while staying closer to the more modern YOLO design:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/gpt4o_speculative4.png"></p>

<p>While impossible to prove, these speculative designs demonstrate that there are
plausible CNN architectures that could represent an image as a $k \times k$
grid of embedding vectors.</p>

<h2 id="experimental-validation">Experimental Validation</h2>

<p>Does GPT-4o really see a <code>13x13</code> grid of embedding vectors? I invented
a task, loosely inspired by <a href="https://en.wikipedia.org/wiki/Zener_cards">Zener cards</a>, to test this. The task is to
identify the color and shape for every symbol on a grid in an image.</p>

<p>A <a href="https://gist.github.com/olooney/07850f0a2f0fcaac973ffabac765454a">simple program</a> generates test grids that look like this:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/zener_5x5.png"></p>

<p>I then used this prompt to obtain comparison data:</p>

<pre><code>"""Divide this image into a {k}x{k} grid and describe the shape and color of
each cell. Report your results as a JSON array of arrays (no objects or row
labels) and use all lowercase."""
</code></pre>

<p>If the <code>13x13</code> hypothesis is correct, GPT-4o should do well on this task
up to about 13 and then performance should degrade. The CNN isn’t literally
dividing the image up into a grid so it might start to degrade before then,
and might struggle more with even grid sizes than odd because the cells won’t
be aligned.</p>

<p>However, that is not in fact what happens. Instead, performance is perfect for
<code>5x5</code> grids and smaller (e.g. <a href="https://www.oranlooney.com/post/gpt-cnn_files/zener_2x2.png"><code>2x2</code></a>, <a href="https://www.oranlooney.com/post/gpt-cnn_files/zener_3x3.png"><code>3x3</code></a>, <a href="https://www.oranlooney.com/post/gpt-cnn_files/zener_4x4.png"><code>4x4</code></a>) but begins
to degrade rapidly after that. By the time we reach <code>13x13</code> it was no better
than chance.</p>

<p>For example, here is a <code>7x7</code> grid:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/zener_7x7.png"></p>

<p>For which GPT-4o returned this:</p>

<pre><code>[
    ["blue diamond", "purple triangle", "red plus", "purple circle", "orange square", "purple circle", "blue circle"],
    ["blue diamond", "red circle", "green plus", "red square", "orange diamond", "blue triangle", "purple plus"],
    ["blue diamond", "orange triangle", "red square", "orange square", "blue plus", "purple circle", "blue circle"],
    ["green diamond", "blue circle", "orange circle", "green circle", "purple diamond", "green triangle", "orange diamond"],
    ["purple square", "purple circle", "green plus", "green diamond", "green circle", "blue triangle", "purple triangle"],
    ["red plus", "red triangle", "purple circle", "blue triangle", "orange triangle", "red diamond", "orange diamond"],
    ["orange plus", "blue diamond", "green triangle", "green plus", "green triangle", "purple diamond", "purple square"]
]
</code></pre>

<p>It got <sup>38</sup>⁄<sub>49</sub> correct—an accuracy of 76%. The exact pattern of hits and
misses looks like this (yellow is correct, purple incorrect):</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/zener_7x7_results.png"></p>

<p>Performance continues to degrade as the grid size increases and by the time we
get to the <code>13x13</code> grid:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/zener_13x13.png"></p>

<p>The results are no better than chance:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/zener_13x13_results.png"></p>

<p>Does that mean I was wrong about 169 tokens representing a <code>13x13</code> grid?
Yes. Yes it does. My disappointment is immeasurable and my day is ruined.</p>

<blockquote>
<p>“The great tragedy of science: the slaying of a beautiful hypothesis by an
ugly fact.” —Thomas Huxley</p>
</blockquote>

<p>But the <code>5x5</code> grid results are suggestive. GPT-4o really can keep track of 25
distinct objects and their absolute positions within in an image. Maybe the
basic concept is right; I just got the dimension wrong. It would be easy
to tack on another couple of layers to our CNN to get down to <code>5x5</code> instead
of <code>13x13</code>:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/gpt4o_speculative5.png"></p>

<p>How could we structure the output to reach 170 tokens if we assume we only use
<code>5x5</code> grids and smaller?</p>

<h2 id="pyramid-strategy">Pyramid Strategy</h2>

<p>One way to get close to both 85 and 170 is to assume that we encode the image
in a series of increasingly granular levels, like a pyramid. We start with one
embedding vector to capture a gestalt impression of the whole image, add a
<code>3x3</code> to capture left/middle/right and top/middle/bottom, then adding a <code>5x5</code>,
<code>7x7</code> etc.</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/grids.png"></p>

<p>This strategy gets us very close to 85 tokens for the ‘master thumbnail’ if
we stop at <code>7x7</code>:</p>

<p>$1^2 + 3^2 + 5^2 + 7^2 = 1 + 9 + 25 + 49 = 84$</p>

<p>And very close to 170 if we add one final <code>9x9</code> grid:</p>

<p>$1^2 + 3^2 + 5^2 + 7^2 + 9^2 = 1 + 9 + 25 + 49 + 81 = 165$</p>

<p>If we throw in an <em>ad hoc</em> <code>2x2</code> grid for the <code>512x512</code> tile and assume one
special <code>&lt;|image start|&gt;</code> for each, we can get a perfect match:</p>

<p>$1 + 1^2 + 3^2 + 5^2 + 7^2 = 1 + 1 + 9 + 25 + 49 = 85$</p>

<p>$1 + 1^2 + 2^2 + 3^2 + 5^2 + 7^2 + 9^2 = 1 + 1 + 4 + 9 + 25 + 49 + 81 = 170$</p>

<p>This scheme lacks any sort of delimiters for the start and end of a row, but
I think that could be handled with positional encoding similar to the way
<a href="https://blog.eleuther.ai/rotary-embeddings/">RoPE</a> is used to encode position information for text tokens, but in 2D.</p>

<p>The above takes only odd grid sizes and goes well beyond <code>5x5</code>; given that the
Zener grid performance starts to fall off after <code>5x5</code> this does not entirely
concord with the evidence.</p>

<p>As an alternative, we could try taking all the grids (even and odd) up to <code>5x5</code>:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/grids2.png"></p>

<p>This approach gives us 55 tokens:</p>

<p>$1^2 + 2^2 + 3^2 + 4^2  + 5^2 = 55$</p>

<p>If we assume 3 tokens per mini-tile and a delimiter token between each, we
can get to 170:</p>

<p>$3 \times (1^2 + 2^2 + 3^2 + 4^2  + 5^2) + 5 = 170$</p>

<p>This isn’t fully satisfactory on numerological grounds but does jive well with
the empirical results. The pyramid strategy has a lot of intuitive appeal—it
feels like an almost “obvious” way to encode spatial information at
different zoom levels - and may explain why it does so well with the <code>5x5</code> grid
and below and so poorly on <code>6x6</code> and above.</p>

<p>It’s maddening that every hypothesis seems to come tantalizingly close to
explaining everything but the numbers never quite seem to work out neatly…
Still, these pyramid strategies are the best I’ve been able to come up with.</p>

<h2 id="optical-character-recognition">Optical Character Recognition</h2>

<p>The one thing that none of the above hypotheses explain is how GPT-4o is doing
OCR. YOLO and CLIP can’t natively do OCR, and the strategies suggested above
seem like they would struggle for the same reasons. I mean, if it can’t read
off 36 symbols in a neat <code>6x6</code> grid from an image, it certainly can’t read off
a several hundred text characters flawlessly.</p>

<p>State-of-the-art OCR engines like <a href="https://en.wikipedia.org/wiki/Tesseract_(software)">Tesseract</a> do a great deal of work to
find bounding boxes and strips of characters, and then run specialized
character recognition models along those strips, one character or word at a
time. They aren’t just big CNNs.</p>

<p>And yet GPT-4o patently <em>can</em> do high-quality OCR: it can transcribe long
blocks of text, read handwritten text, or text which has been shifted, rotated,
projected, or partially occluded.</p>

<p>I have a simple theory to explain that: I think OpenAI is running
<a href="https://en.wikipedia.org/wiki/Tesseract_(software)">Tesseract</a> (or their own in-house OCR) and feeding the identified text
into the transformer alongside the image data. I mean, that’s what I would do.</p>

<p>This would explain why the early versions were so easily confused by text
hidden in images: from its POV, that text <em>was</em> part of the prompt. (This is
fixed now; GPT-4o is good at ignoring malicious prompts hidden inside images.)</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/malicious_penguin.png" alt="GPT-4o passes the malicious penguin test."></p>

<p>However, this does not explain why there’s no charge per token for the text
found in an image.</p>

<p>Interestingly enough, it’s actually <em>more efficient</em> to send text as images: A
<code>512x512</code> image with a small but readable font can easily fit 400-500 tokens
worth of text, yet you’re only charged for 170 input tokens plus the 85 for the
‘master thumbnail’ for a grand total of 255 tokens—far less than the
number of words on the image.</p>

<p>This theory explains why there is additional latency when processing images.
The CNN would be essentially instantaneous, but 3rd-party OCR would add
additional time. By the way, (and I’m not saying this proves anything) but the
Python environment used by the OpenAI code interpreter has <a href="https://pypi.org/project/pytesseract/">PyTesseract</a>
installed. You can literally just ask it to run PyTesseract on any image you’ve
uploaded to get a second opinion.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Well, we’ve made a lot of speculative hay out of what is essentially only one
morsel of hard fact: that OpenAI used the magic number 170.</p>

<p>However, there does seem to be a complete plausible approach—very much in
line with other CNN architectures such as YOLO—for mapping from image tiles
to embedding vectors.</p>

<p>As such, I don’t think 170 tokens is just an approximation used to bill for
roughly the amount of compute it takes to process an image. And I don’t think
they’re concatenating layers to join image and text data the way some other
multi-modal models do.</p>

<p>No, I think GPT-4o is <em>literally</em> representing <code>512x512</code> images as 170
embedding vectors, using an CNN architecture that’s a mixture of CLIP and YOLO
to embed the image directly into the transformer’s semantic vector space.</p>

<p>When I started this article, I was entirely convinced that I had cracked it
entirely, that I was going to find that the 170 tokens were for a <code>13x13</code> grid
and one additional “gestalt impression” token. That got blown out of the water
when performance on the Zener task started to degrade after <code>5x5</code>—whatever
they’re doing internally, it seems to be a lot smaller than <code>13x13</code>.</p>

<p>Still the analogy to YOLO is compelling, and the performance on the <code>5x5</code> Zener
task all but confirms that they’re doing some kind of grid. This theory has a
lot of predictive power in other areas as well: it explains how GPT-4o is able
to handle multiple images, and tasks like comparing two images, for example. It
explains how it’s able to see multiple objects in the same image, but gets
overwhelmed when there are too many objects in a busy scene. It explains
why GPT-4o seems extremely vague about the absolute and relative positions of
separate objects within the scene, and why it can’t count objects accurately
in images: when an object spans two adjacent grid cells the same classes are
activated in both so it’s not sure if it’s one object or two.</p>

<p>Ironically, the one thing this theory can’t cleanly explain is the question
which motivated this article in the first place: why 170 tokens in particular?
The pyramid theory (<code>1x1 + 2x2 + 3x3 + 4x4 + 5x5</code>) was the best I was able to
come up with, and it’s not particularly neat.</p>

<p>I’d love to hear from anyone who has a theory that fits a little better (or
even actual knowledge, assuming it doesn’t run afoul of an NDA!)</p>

<!-- https://unsplash.com/photos/black-and-gray-camera-on-white-table-Y5dd6hLkn-8 -->

<h2 id="postscript-alpha-channel-shenanigans">Postscript: Alpha Channel Shenanigans</h2>

<p>One other thing I noticed while working on this project is that GPT-4o
<em>ignores</em> the alpha channel, resulting in somewhat counter-intuitive behavior.</p>

<p>When I say, “ignores”, I don’t mean that it gets rid of transparency by
compositing it onto some default background, the way an image editor might
when converting PNG to JPG. No, I mean it literally just grabs the RGB channels
and ignores the alpha channel.</p>

<p>We can illustrate this with four carefully prepared images. For convenience,
I’ve used HTML and CSS to display these images on top of a checkerboard
pattern—the images themselves have flat, transparent backgrounds.
However, half have transparent <em>black</em> backgrounds, and half have transparent
<em>white</em> backgrounds.</p>

<p>What do I mean by “transparent black” or “transparent white?” Well, when we
represent an RGBA color with four bytes, the RGB bytes are still there even
when alpha is 100%. Thus, <code>(0, 0, 0, 255)</code> and <code>(255, 255, 255, 255)</code> are in
some sense different colors, even though there’s no situation where a correct
renderer would display them differently since they’re both 100% transparent.</p>

<p>Let’s ask GPT-4o what it “sees” on these four images:</p>

<div>
    <div>
            <p><img src="https://www.oranlooney.com/post/gpt-cnn_files/black_on_transparent_black.png" alt="MODICUM"></p><p>Black Text on Transparent Black Background</p>
            <p>GPT-4o Reads: “”</p>
        </div>
    <div>
            <p><img src="https://www.oranlooney.com/post/gpt-cnn_files/black_on_transparent_white.png" alt="ENORMOUS"></p><p>Black Text on Transparent White Background</p>
            <p>GPT-4o Reads: “ENORMOUS”</p>
        </div>
    <div>
            <p><img src="https://www.oranlooney.com/post/gpt-cnn_files/white_on_transparent_black.png" alt="SCINTILLA"></p><p>White Text on Transparent Black Background</p>
            <p>GPT-4o Reads: “SCINTILLA”</p>
        </div>
    <div>
            <p><img src="https://www.oranlooney.com/post/gpt-cnn_files/white_on_transparent_white.png" alt="GIGANTIC"></p><p>White Text on Transparent White Background</p>
            <p>GPT-4o Reads: “”</p>
        </div>
</div>

<p>What’s going on here? The pattern that emerges is that GPT-4o can read the
text if and only if the text color is different than the “color” of the
transparent background.</p>

<p>This tells us that GPT-4o <em>disregards</em> the alpha channel and only looks at the
RGB channels. To it, transparent black is black, transparent white is white.</p>

<p>We can see this even more clearly if we mess with an image to preserve the
three RGB channels while setting the alpha channel to 100%. Here’s a little
Pillow function to do that:</p>

<pre><code>from PIL import Image

def set_alpha(image, output_path, alpha_value):
    # copy the image and ensure it's RGBA
    image = image.convert("RGBA")

    # set the alpha channel of every pixel to the given value
    pixels = image.getdata()
    new_pixels = [(r, g, b, alpha_value) for r, g, b, a in pixels]
    image.putdata(new_pixels)

    return image
</code></pre>

<p>I used that to make the two images below; they have identical RGB data, and
only differ in the alpha channel:</p>

<div>
    <div>
            <p><img src="https://www.oranlooney.com/post/gpt-cnn_files/platypus.png" alt="Visible Platypus"></p><p>Alpha Channel = 255</p>
        </div>
    <div>
            <p><img src="https://www.oranlooney.com/post/gpt-cnn_files/platypus_hidden.png" alt="Hidden Platypus"></p><p>Alpha Channel = 0</p>
        </div>
</div>

<p>GPT-4o has no trouble seeing the hidden platypus:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/chatgpt_hidden_platypus_test.png" alt="GPT-4o passes the hidden platypus test."></p>

<p>You can try downloading the
<a href="https://www.oranlooney.com/post/gpt-cnn_files/platypus_hidden.png" download=""><code>hidden_platypus.png</code></a>
image and dropping it into ChatGPT yourself; it will correctly describe it.
You may also note the image is 39.3 KB, the same size as
<a href="https://www.oranlooney.com/post/gpt-cnn_files/platypus.png" download=""><code>platypus.png</code></a>
even though PNG compression should have made it much smaller if it was really
a perfectly blank, transparent image. Or you can use the above function to
set the alpha channel back to 255, recovering the original image.</p>

<p>I’m not sure if this is bug but it’s certainly <a href="https://en.wikipedia.org/wiki/Principle_of_least_astonishment">surprising</a> behavior; in
fact, it feels like something a malicious user could use to smuggle information
past humans and directly to GPT-4o. However, GPT-4o is <em>much</em> better at
detecting and ignoring malicious prompts hidden in images than GPT-4v was:</p>

<p><img src="https://www.oranlooney.com/post/gpt-cnn_files/malicious_dogs.png"></p>

<p>(You can find other examples of GPT-4o successfully detecting and
ignoring malicious prompts hidden in images in my <a href="https://olooney.github.io/image_tagger/gallery/index.html">gallery of GPT-4o test
images</a> generated by my <a href="https://github.com/olooney/image_tagger"><code>image_tagger</code></a> utility.)</p>

<p>So, even if it is a bug, it’s not obvious it can be exploited. Still, it would
be less surprising in GPT-4o “saw” the same thing that a human would in a
browser.</p>

    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: E-Paper 7-color display showing the current weather (132 pts)]]></title>
            <link>https://github.com/blixt/sol-mate-eink</link>
            <guid>40607889</guid>
            <pubDate>Fri, 07 Jun 2024 12:10:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/blixt/sol-mate-eink">https://github.com/blixt/sol-mate-eink</a>, See on <a href="https://news.ycombinator.com/item?id=40607889">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Sol Mate e-Paper Display ☀️</h2><a id="user-content-sol-mate-e-paper-display-️" aria-label="Permalink: Sol Mate e-Paper Display ☀️" href="#sol-mate-e-paper-display-️"></a></p>
<p dir="auto">I initially made <a href="https://chatgpt.com/g/g-QIydQSFRm-sol-mate" rel="nofollow">the ☀️ Sol Mate GPT</a>, but it didn't take too long until I wondered what it would look like on <a href="https://www.amazon.com/dp/B0BMQ83W7W" rel="nofollow">an e-Paper display</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/158591/337645173-1ef011a5-4c01-429f-872f-ea47f8c76e02.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTc3ODUzMDQsIm5iZiI6MTcxNzc4NTAwNCwicGF0aCI6Ii8xNTg1OTEvMzM3NjQ1MTczLTFlZjAxMWE1LTRjMDEtNDI5Zi04NzJmLWVhNDdmOGM3NmUwMi5qcGc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDYwN1QxODMwMDRaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02MDQyNmE4MjgyODMyZjZiMWZhNjMwMDkxMTE5NDhkN2UyMTk4NTA1ZGE2ZjhjZDM3ZjQyNDIyNzM5MDdkMGUwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.WEo2k3SX7QEp68kk-okX0RJTE4ft5OIxo0cLY9v1B2o"><img src="https://private-user-images.githubusercontent.com/158591/337645173-1ef011a5-4c01-429f-872f-ea47f8c76e02.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTc3ODUzMDQsIm5iZiI6MTcxNzc4NTAwNCwicGF0aCI6Ii8xNTg1OTEvMzM3NjQ1MTczLTFlZjAxMWE1LTRjMDEtNDI5Zi04NzJmLWVhNDdmOGM3NmUwMi5qcGc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNjA3JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDYwN1QxODMwMDRaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02MDQyNmE4MjgyODMyZjZiMWZhNjMwMDkxMTE5NDhkN2UyMTk4NTA1ZGE2ZjhjZDM3ZjQyNDIyNzM5MDdkMGUwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.WEo2k3SX7QEp68kk-okX0RJTE4ft5OIxo0cLY9v1B2o" alt="IMG_5006"></a></p>
<p dir="auto">The script to update the screen takes a location (maybe your own, maybe your best friend's, or even a fictional place!) and get the weather for that location, then generate an illustration of the location including the current weather and lighting conditions. So if it's raining, there will be people with umbrellas in the picture, and so on. If you do generate for a fictional location, the weather service will be given the latitude/longitude of the most similar place on Earth (according to GPT). The illustrations are rendered using Dall-E 3. This is why an OpenAI API token is necessary to run it.</p>
<p dir="auto">This repository contains all the code that was needed to generate and display a weather report for any specified location on a Raspberry Pi with an attached Waveshare e-Paper display.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Hardware</h2><a id="user-content-hardware" aria-label="Permalink: Hardware" href="#hardware"></a></p>
<ul dir="auto">
<li><a href="https://www.raspberrypi.com/products/raspberry-pi-5/" rel="nofollow">Raspberry Pi 5</a></li>
<li><a href="https://www.amazon.com/dp/B0BMQ83W7W" rel="nofollow">Waveshare e-Paper 7.3" display</a> (code needs to be updated for other sizes)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">More pictures</h2><a id="user-content-more-pictures" aria-label="Permalink: More pictures" href="#more-pictures"></a></p>
<ul dir="auto">
<li><a href="https://x.com/blixt/status/1797317001372750301" rel="nofollow">4 examples, some with more color</a></li>
<li><a href="https://x.com/blixt/status/1796616909611278356" rel="nofollow">The setup, without the box</a></li>
<li><a href="https://x.com/blixt/status/1797350136080699837" rel="nofollow">Video of the thinness of the display</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Software &amp; Usage</h2><a id="user-content-software--usage" aria-label="Permalink: Software &amp; Usage" href="#software--usage"></a></p>
<p dir="auto">This should all run on your Raspberry Pi.</p>
<p dir="auto">I recommend setting up a virtual environment for Python, <a href="https://github.com/astral-sh/uv">such as uv</a>, first. Here are the instructions for if you're using <code>uv</code> (to be run inside the clone of this repo):</p>
<div dir="auto" data-snippet-clipboard-copy-content="uv venv
source .venv/bin/activate
uv pip install -r requirements.txt"><pre>uv venv
<span>source</span> .venv/bin/activate
uv pip install -r requirements.txt</pre></div>
<p dir="auto">Without <code>uv</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python -m venv .
source .venv/bin/activate
pip install -r requirements.txt"><pre>python -m venv <span>.</span>
<span>source</span> .venv/bin/activate
pip install -r requirements.txt</pre></div>
<p dir="auto">You will need to specify an <code>OPENAI_API_KEY</code> environment variable. For your convenience, the code will load environment variables from a <code>.env</code> file in the current working directory.</p>
<p dir="auto">Now you can use the <code>control.py</code> script to generate an image and show it on the screen:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python control.py show Barcelona"><pre>python control.py show Barcelona</pre></div>
<p dir="auto"><a href="https://www.waveshare.com/wiki/7.3inch_e-Paper_HAT_(F)_Manual#Precautions" rel="nofollow">Waveshare recommends</a> you don't leave the same image on the display for too long.</p>
<p dir="auto">Use the <code>clear</code> command to clear it:</p>

<p dir="auto">I set up a cron job (<code>crontab -e</code>) to update the image two times per day, but keep in mind this can end up costing a non-trivial amount:</p>
<div data-snippet-clipboard-copy-content="0 8 * * * cd ~/src/sol-mate-eink &amp;&amp; .venv/bin/python control.py show Barcelona
0 18 * * * cd ~/src/sol-mate-eink &amp;&amp; .venv/bin/python control.py show Barcelona
0 2 * * * cd ~/src/sol-mate-eink &amp;&amp; .venv/bin/python control.py clear"><pre lang="crontab"><code>0 8 * * * cd ~/src/sol-mate-eink &amp;&amp; .venv/bin/python control.py show Barcelona
0 18 * * * cd ~/src/sol-mate-eink &amp;&amp; .venv/bin/python control.py show Barcelona
0 2 * * * cd ~/src/sol-mate-eink &amp;&amp; .venv/bin/python control.py clear
</code></pre></div>
<p dir="auto">(You'll need to tweak the paths for your setup, of course.)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Backend</h2><a id="user-content-backend" aria-label="Permalink: Backend" href="#backend"></a></p>
<p dir="auto">Feel free to use the private API I hosted to get the weather if you're not going to hammer it. I also use this backend for my GPT. However, if you have high volume ideas in mind, please self-host it! The source code is here:</p>
<p dir="auto"><a href="https://github.com/blixt/sol-mate">https://github.com/blixt/sol-mate</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Having issues?</h2><a id="user-content-having-issues" aria-label="Permalink: Having issues?" href="#having-issues"></a></p>
<p dir="auto">I'd love to help if I can – <a href="https://twitter.com/blixt" rel="nofollow">reach out on Twitter</a> or create an issue in this repo!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cancel Adobe if you are a creative under NDA with your clients (536 pts)]]></title>
            <link>https://twitter.com/Stretchedwiener/status/1798153619285708909</link>
            <guid>40607442</guid>
            <pubDate>Fri, 07 Jun 2024 11:12:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Stretchedwiener/status/1798153619285708909">https://twitter.com/Stretchedwiener/status/1798153619285708909</a>, See on <a href="https://news.ycombinator.com/item?id=40607442">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Secret Hand Gestures in Paintings (2019) (111 pts)]]></title>
            <link>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/</link>
            <guid>40606924</guid>
            <pubDate>Fri, 07 Jun 2024 09:36:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/</a>, See on <a href="https://news.ycombinator.com/item?id=40606924">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
    <article>
        <section>
         
    <ul>
            
                <li>
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/journals/">Journal List</a>
                </li>
            
                <li>
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/journals/3185/">Acta Biomed</a>
                </li>
            
                <li>
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/issues/357947/">v.90(4); 2019</a>
                </li>
            
                <li aria-current="page">
                    PMC7233791
                </li>
            
    </ul>
 

        </section>
        
  

        
        <div id="mc" role="document"><!--main-content--><div data-jigconfig="smoothScroll: false, allHeadingLevels: ['h2'], headingExclude: ':hidden,.nomenu'"><div><p><span id="pmcmata">Acta Biomed.</span> 2019; 90(4): 526–532. </p></div><div id="abstract-a.k.b.s" lang="en"><h2 id="abstract-a.k.b.stitle">Abstract</h2><!--article-meta--><p>During the Renaissance period, hands were as important a focus of attention as the face was, because they were the only other visible area of the body. Hence, representation of the position of the hands became a decorative element that was almost as important as the face. Thus, given its high visibility, hand gestures in portraits and paintings have been one of the most effective ways of conveying secrets, codes and messages. From the historical and religious perspective, hand signs in visual art may provide clues about the underlying iconographical symbols. This paper will examine the eventual hidden meanings behind a peculiar hand gesture that has been widely used by several painters. (<a href="http://www.actabiomedica.it/">www.actabiomedica.it</a>)</p><p><strong>Keywords: </strong><span>hand gesture, art, hand, painting, signs</span></p></div><div id="sec1-1"><h2 id="sec1-1title">Introduction</h2><p>The art of a particular period is a suitable subject of investigation for exploring the existence of congenital deformities or medical illness based on physical depictions in drawings, paintings and sculptures or peculiar gestures and symbolic hallmarks. According to deductions made based on the artists’ work, physical depictions in artwork could be an artistic convention, a hallmark of the artist’s school, intentional or inadvertent depictions of a real disease that affected the sitter, or symbolic/religious messages or iconographical attributes. In particular, the meanings of secret hand signs and their hidden messages in artworks have intrigued art experts since the Renaissance.</p><p>During the Renaissance period, hands were as important a focus of attention as the face was, because they were the only other visible area of the body. Hence, representation of the position of the hands became a decorative element that was almost as important as the face. Thus, given its high visibility, hand gestures in portraits and paintings have been one of the most effective ways of conveying secrets, codes and messages (<a href="#ref1" rid="ref1">1</a>-<a href="#ref4" rid="ref4">4</a>). From the historical and religious perspective, hand signs in visual art may provide clues about the underlying iconographical symbols. However, because the actual intentions of the artist cannot be confirmed in the absence of historical documentation, any discussion about this topic can be only speculative (<a href="#ref4" rid="ref4">4</a>).</p><p>There is a peculiar hand gesture that is widely used by painters of several nationalities belonging to the Renaissance, Mannerism, Baroque and later artistic movements: It is an unnatural position of one or both hands in which the third and fourth digits are held tight together, as if almost fused, resembling syndactyly, and the second and fifth fingers are separated from the central ones. So far, no one has attempted to understand the common meaning of this representation. Therefore, the goal of this investigation is to discuss the meanings of and to speculate about the reasons for the depiction of this unnatural finger position. Our investigation is specifically focused on the religious meaning and the cultural iconography or the secret message conveyed by the hand posture.</p><p>Here, we have studied this gesture in four different unnatural gesture across hundreds of portraits by more than eighty painters:</p><ul><li><p>- <em>The hand placed on the chest</em></p></li><li><p>- <em>The hand placed on the flank</em></p></li><li><p>- <em>The hand pointing upward to the sky or downward to the earth in a blessing position</em></p></li><li><p>- <em>The hand grasping an object or holding a person</em>.</p></li></ul></div><div id="sec1-2"><h2 id="sec1-2title">Materials</h2><p>This position can be observed in the works of several artists, including masters such as Titian, Pontormo, Bronzino, Raphal Santi, Michelangelo Buonarroti, El Greco, Raphael Mengs, Juan de Juanes, and among other painters across countries and centuries. Eight portraits constitute the subject of this review, and they were used as an explicative example, with particular focus on the hands of the models (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1</span></a> to <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F8/" target="figure" rid-figpopup="F8" rid-ob="ob-F8" co-legend-rid="lgnd_F8"><span>Figure 8</span></a>).</p><!--fig ft0--><!--fig mode=article f1--><div id="F1" co-legend-rid="lgnd_F1"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><p><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g001.jpg" title="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g001.jpg" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/bin/ACTA-90-526-g001.jpg"></p></a><div id="lgnd_F1"><!--caption a7--><p><em>Cosimo I de’ Medici</em>, 1538, Jacopo Carrucci aka Pontormo, Tempera on panel, 95.6x74.9 cm, Metropolitan Museum, New York</p></div></div><!--fig ft0--><!--fig mode=article f1--><div id="F8" co-legend-rid="lgnd_F8"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F8/" target="figure" rid-figpopup="F8" rid-ob="ob-F8"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><p><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g008.jpg" title="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g008.jpg" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/bin/ACTA-90-526-g008.jpg"></p></a><div id="lgnd_F8"><!--caption a7--><p><em>Portrait of Maria de’ Medici</em>, 1553, Agnolo di Cosimo Tori aka Bronzino, tempera on canvas, 52.5x38 cm, Galleria degli Uffizi, Florence, Italy</p></div></div><!--fig ft0--><!--fig mode=article f1--><div id="F2" co-legend-rid="lgnd_F2"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F2/" target="figure" rid-figpopup="F2" rid-ob="ob-F2"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><p><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g002.jpg" title="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g002.jpg" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/bin/ACTA-90-526-g002.jpg"></p></a><div id="lgnd_F2"><!--caption a7--><p><em>Christ carrying the cross</em>, 1577-87, Domenikos Theotokopoulos aka El Greco, Metropolitan Museum, New York</p></div></div><!--fig ft0--><!--fig mode=article f1--><div id="F3" co-legend-rid="lgnd_F3"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F3/" target="figure" rid-figpopup="F3" rid-ob="ob-F3"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><p><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g003.jpg" title="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g003.jpg" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/bin/ACTA-90-526-g003.jpg"></p></a><div id="lgnd_F3"><!--caption a7--><p><em>Penitent Magdalene</em>, 1533, Titian Vecellio, oil on wood, 85x68 cm, Galleria Palatina, Rome</p></div></div><!--fig ft0--><!--fig mode=article f1--><div id="F4" co-legend-rid="lgnd_F4"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F4/" target="figure" rid-figpopup="F4" rid-ob="ob-F4"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><p><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g004.jpg" title="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g004.jpg" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/bin/ACTA-90-526-g004.jpg"></p></a><div id="lgnd_F4"><!--caption a7--><p><em>Separation of Earth and Waters</em>, 1511-12, Michelangelo Buonarroti, fresco, 155x270 cm, Sistine Chapel, Rome</p></div></div><!--fig ft0--><!--fig mode=article f1--><div id="F5" co-legend-rid="lgnd_F5"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F5/" target="figure" rid-figpopup="F5" rid-ob="ob-F5"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><p><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g005.jpg" title="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g005.jpg" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/bin/ACTA-90-526-g005.jpg"></p></a><div id="lgnd_F5"><!--caption a7--><p><em>El caballero de la mano en el pecho (Gentleman with his Hand on his Chest)</em>, 1580, Domenikos Theotokopoulos aka El Greco, oil on canvas, Museo del Prado, Madrid</p></div></div><!--fig ft0--><!--fig mode=article f1--><div id="F6" co-legend-rid="lgnd_F6"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F6/" target="figure" rid-figpopup="F6" rid-ob="ob-F6"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><p><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g006.jpg" title="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g006.jpg" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/bin/ACTA-90-526-g006.jpg"></p></a><div id="lgnd_F6"><!--caption a7--><p><em>Posthumous portrait of Christopher Columbus</em>, Sebastiano del Piombo, 1519, Metropolitan Museum of Art, New York. Someone consider Colombo a Jewish. [Marrano Jewish explorer, aided by Marranos Louis de Santangel and Antonio de Marchena]</p></div></div></div><div id="sec1-3"><h2 id="sec1-3title">Results</h2><p>Based on the authors’ experience in the medico-artistic field (<a href="#ref4" rid="ref4">4</a>-<a href="#ref11" rid="ref11">11</a>), we think that the unnatural hand position in all the portrayed subjects is most probably an artistic device or a symbolic hallmark rather than a true pathologic depiction of syndactyly, given that the occurrence rate of syndactyly is not very high and that the symbol is repeatedly used in the work of certain artists. Although the idea that this gesture may be a content-laden symbol, a secret physical (hand) sign conveying a higher meaningful idea is fascinating, the present investigation has the purpose to dismiss the gesture to an uncommon oddity.</p><div id="sec2-1"><h3 id="sec2-1title">Hypotheses and criticism about the hand gesture</h3><p>The hand gesture that we systematically identified is not present in any of the art manuals, symbolism guidelines, religious books, sects, or secret societies in both the western and eastern world. Therefore, five basic hypotheses have been proposed to decipher the meaning of the hand gesture. They are discussed and dismissed below.</p><div id="sec3-1"><h4 id="sec3-1title">1. Crypto-Jew (Marranos) recognition </h4><p>According to this hypothesis, the gesture was a secret sign used to recognize crypto-jews each other. During the time of inquisition according to the Catholic Kings’ order of 1492, Jews living in Iberian Peninsula were forced to accept or to leave Spain. Many Jews, although converted, continued to practice Judaism in secret, especially in the judería, which was the old Jewish barrio (neighbourhood) of Toledo. These last Jews were called crypto-Jews or Marranos, which means <em>Christianized Jew</em>, <em>swine</em>, or <em>pig</em> in medieval Spanish. The derogatory term was used to refer to the ritual prohibition against eating pork, which was adhered to by both Jews and Muslims. In the modern Spanish language, <em>Marrano</em> still means <em>pig</em> or <em>dirty</em>, but it is no longer commonly connoted with religious contents.</p><p>Oppenhejm in his book suggested that the hand gesture was a type of a 16<sup>th</sup> century secret sign used in Toledo among the crypto-Jews (i.e. false Christians) to recognize each other (<a href="#ref12" rid="ref12">12</a>). Although this meaning of the hand gesture may be associated with the sitters of the Spanish painter of that time, a lot of criticism has been raised because such signs/symbols are not illustrated or mentioned in any of the full-bodied Sephardic and Kabbalistic manuscripts/books from this period or their antecedents. Indeed, it would be unrealistic to assume that all the Iberian (or those who worked there) painters, such as El Greco, Luis El Divino Morales, and Juan de Juanes, were Jewish or that their patrons and sitters were Jewish. In addition, the term <em>Marrano</em> was mostly used in Toledo’s judería, and not all the Spanish painters included in this investigation came from there or were working there. Therefore, it is possible that Oppenhejm confounded the gesture of the hand (herein analysed) with the well-known symbol in which the thumbs with the second and third fingers of each hand are held touching each other and separated from the fourth and the fifth fingers, conceiving a sort of fan also known as the Kohanic Blessing. This last symbol can be found carved on Jewish tombstones throughout Europe; for centuries, it has represented a cosmic symbol, and even in modern times, the gesture refers to ‘an ancient matriarchal sign for strength and power’ (<a href="#ref13" rid="ref13">13</a>, <a href="#ref14" rid="ref14">14</a>). Finally, there is no letter or religious gesture, Hebrew or otherwise, similar to the splayed hand. Therefore, the stylized gesture of the hand investigated in this paper is actually non-existent in the known Hebrew tradition of the 16th century, whereas the gesture of the Kohanic blessing existed for centuries prior to that period. Thus, the hypothesis of a widespread depiction of Marranos’ hand recognition sign in several portraits seems inconsistent.</p></div><div id="sec3-2"><h4 id="sec3-2title">2. Freemasonry or Masonic membership and rank </h4><p>According to this hypothesis, the gesture was a secret sign used to recognize masonic followers each other. The enigmatic posture of the hand has fascinated a lot of scholars of hidden societies, who cryptically connoted the unusual splayed fingers with the letter M, which indicated not only Masonic membership and rank, but also possession of occult secrets. The speculation that the hand gesture herein presented is a freemasonry’s conveyed code is fascinating, but it is hard to accept.</p></div><div id="sec3-3"><h4 id="sec3-3title">3. Satanism (multiple V’s and I’s for 666) </h4><p>According to this hypothesis, the gesture was a secret sign conveying satanic meanings. The hand gesture may be read as the letters M and W, which may be interpreted as multiple V’s and I’s to symbolise 666. This is because the letter V is pronounced as ‘waw’ in Hebrew and ‘vav’ in Gematria and is the 6th letter in both alphabets. However, there is no evidence to show that Renaissance, Mannerist and Baroque art had any connection with Satanism.</p></div><div id="sec3-4"><h4 id="sec3-4title">4. De’ Medici family membership </h4><p>According to this hypothesis, the gesture was a secret sign used to recognize a sitter as a member of the De’ Medici family. In portraits of Cosimo and his family by Bronzino, each are shown making the distinct hand gesture resembling an <em>M</em>. Some argue that this sign indicates their membership in the Medici family. However, this gesture is not uniquely depicted in members of the Medici family. In fact, it is more likely that the gesture conveyed modesty. Indeed, this gesture can be observed in the ‘<em>modest Venus</em>’ (also known as <em>Venus Pudica</em> and later popularized as <em>Medici Venus</em>) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F9/" target="figure" rid-figpopup="F9" rid-ob="ob-F9" co-legend-rid="lgnd_F9"><span>Figure 9</span></a>), which is a 1<sup>st</sup> century BC marble copy of a an original bronze Greek sculpture depicting the Greek goddess of love Aphrodite. Some scholars argue that the gesture seen in the Medici portraits may be an allusion to this modesty. The widespread depiction of the gesture in portraits of the de Medici family created by Bronzino (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F8/" target="figure" rid-figpopup="F8" rid-ob="ob-F8" co-legend-rid="lgnd_F8"><span>Figure 8</span></a>)and the paintings of artists that followed makes this speculation interesting, but it is hard to accept it as a unifying explanation.</p><!--fig ft0--><!--fig mode=article f1--><div id="F9" co-legend-rid="lgnd_F9"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F9/" target="figure" rid-figpopup="F9" rid-ob="ob-F9"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><p><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g009.jpg" title="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g009.jpg" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/bin/ACTA-90-526-g009.jpg"></p></a><div id="lgnd_F9"><!--caption a7--><p><em>Venus de’ Medici</em> or <em>Medici Venus</em> depicting the Greek goddess of love Aphrodite. Copy of a 1st-century BC marble copy, perhaps made in Athens, of a bronze original Greek sculpture. Uffizi Gallery, Florence, Italy</p></div></div></div><div id="sec3-5"><h4 id="sec3-5title">5. Ignacio de Loyola’s gesture for the atonement of sins </h4><p>According to this hypothesis, the gesture was a sign with a religious meaning used during the spiritual exercises by Jesuits. San Ignacio de Loyola (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F7/" target="figure" rid-figpopup="F7" rid-ob="ob-F7" co-legend-rid="lgnd_F7"><span>Figure 7</span></a>) founded the Jesuits’ Order in 1541 and became its first Superior General. The Saint used to recommend a gesture for believers in his spiritual exercises: ‘each time one falls into sin, in laying the hand on the breast whilst inciting one’s inner self to grief.’ (15). After analysing the paintings of one of the painters herein referenced (El Greco), Cassou in 1934 proposed that the painter wanted to depict the gesture with the hand placed on the chest as a sign of moral pain in sinners who were in the act of committing a sin (<a href="#ref16" rid="ref16">16</a>). Later on, Veronica de Osa embraced the same hypothesis in her novel, <em>The mystic finger symbol of El Greco</em> (1956) (<a href="#ref17" rid="ref17">17</a>). However, this speculation does not explain the widespread presence of the gesture in paintings. The ‘Spiritual Exercises’ of Loyola was published in the middle of the 16<sup>th</sup> century (1548), at which time some of the painters had already depicted their sitters with that hand gesture. It may be interesting to accept the Loyolan theory for this gesture, in the case of artists who incorporated this hand gesture after the publication of Jesuit rules, but the hypothesis is still weak.</p><!--fig ft0--><!--fig mode=article f1--><div id="F7" co-legend-rid="lgnd_F7"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F7/" target="figure" rid-figpopup="F7" rid-ob="ob-F7"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--><p><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g007.jpg" title="An external file that holds a picture, illustration, etc.
Object name is ACTA-90-526-g007.jpg" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/bin/ACTA-90-526-g007.jpg"></p></a><div id="lgnd_F7"><!--caption a7--><p><em>Portrait of Saint Ignatius of Loyola</em>, 1491-1556</p></div></div><p>The description of the penitent gesture by Saint Ignacio does not specify at all the position of the fingers, but it only deals with placing the hand upon the chest. In addition, Loyola warned against the display of the act of penance in public: it could be done ‘even in the presence of many others but without their perceiving what the sinner is doing’. Therefore, it would be unlikely that the sitter displayed the act of penance in a painting because it was prohibited outdoors according to Loyolan laws. Further, based on the universal application of the hand gesture in the artworks of so many painters, it seems unlikely that they are trying to depict the same spiritual sense or feeling of penitence. Another speculation that goes against this hypothesis is that many painters have depicted this stylized gesture in Christ, the Virgin, and other figures of Saints, too. However, it is not likely that they would depict such a gesture symbolizing suffering and regret for sinning among non-sinning deities. Thus, it seems unrealistic to label the hand gesture herein investigated as a Loyolan content-label symbol.</p></div></div></div><div id="sec1-4"><h2 id="sec1-4title">Discussion</h2><p>The present retrospective investigation tried to shed light on the reasons why a peculiar hand gesture resembling syndactyly was depicted in hundreds of paintings by various artists, including the great masters, such as Titian, Bronzino, El Greco, Parmigianino, François Clouet, Hans Memling, Anton Raphael Mengs and Luis el Divino Morales, who adopted this sign in dozens of portraits produced by them (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figures 1</span></a>-<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7233791/figure/F8/" target="figure" rid-figpopup="F8" rid-ob="ob-F8" co-legend-rid="lgnd_F8"><span>​</span><span>8</span></a>).</p><p>An inaccurate depiction of the model inadvertently drawn by an artist seems unlikely given their high reputation and because of the large number of paintings in which the same hand gesture has been depicted. Indeed, the pre-Renaissance simplified and ordinary hand depictions were substituted with a more truthful and anatomically accurate hand drawing by the Renaissance artists, who captured the static and dynamic complexity of hands (<a href="#ref4" rid="ref4">4</a>, <a href="#ref5" rid="ref5">5</a>). Moreover, in almost all of their works, Renaissance painters provided detailed preliminary studies through cartoons, drawings, sketches or designs, and an erroneous depiction of an abnormal finger position would not have been repeated by accident, especially as such mistakes would have been adjusted in the final piece. Further, since this gesture is found in several portraits by painters belonging to different ages, nationalities and artistic movements, and it is not limited to sitters of a particular age or family, they are most probably stylistic features of the artists’ work rather than accurate depictions of anomalies in the subjects’ hands. Therefore, although some of the paintings included in the present investigation show human figures with the fingers depicted as resembling syndactyly involving the third and the fourth fingers, it is most likely that the artists in their career merged attributes from various models to create an idealized beauty of the hand.</p><p>In conclusion, a lot of Renaissance and later artists are known indeed to have regularly shown finger anomalies in their paintings for stylistic reasons (<a href="#ref4" rid="ref4">4</a>, <a href="#ref5" rid="ref5">5</a>); moreover, it is highly improbable that there was a veritable epidemic of syndactyly in the 15<sup>th</sup> to 17<sup>th</sup> century in Europe. Our investigation suggests instead that it was fashionable to be depicted with certain types of hand gestures, and that this feature signified grace, elegance and refinement rather than deformity. Several members of the Renaissance and later movements used this unnatural depiction of the fingers following an artistic trend of that period to imbue and to idealize the delicacy and the grace of the hand depiction. It should be considered an artistic device or a symbolic hallmark without any conveyed meaning rather than a true pathologic depiction of syndactyly.</p></div><div id="sec1-5"><h2 id="sec1-5title">Conflict of interest:</h2><!--/article/back/sec/--><p>Each author declares that he or she has no commercial associations (e.g. consultancies, stock ownership, equity interest, patent/licensing arrangement etc.) that might pose a conflict of interest in connection with the submitted article</p></div><div id="ref-list-a.m.b"><h2 id="ref-list-a.m.btitle">References</h2><div id="reference-list"><p>1. <span>Ram AN, Chung KC. Study of hand signs in Judeo-Christian art. <span><span>J Hand Surg Am. </span>2008 Sep;<span>33</span>(7):1182–8.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/18762116" ref="reftype=pubmed&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+Hand+Surg+Am&amp;title=Study+of+hand+signs+in+Judeo-Christian+art&amp;author=AN+Ram&amp;author=KC+Chung&amp;volume=33&amp;issue=7&amp;publication_year=2008+Sep&amp;pages=1182-8&amp;pmid=18762116&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>2. <span>Ghori AK, Chung KC. Interpretation of hand signs in Buddhist art. <span><span>J Hand Surg Am. </span>2007 Jul Aug;<span>32</span>(6):918–22.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/17606078" ref="reftype=pubmed&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+Hand+Surg+Am&amp;title=Interpretation+of+hand+signs+in+Buddhist+art&amp;author=AK+Ghori&amp;author=KC+Chung&amp;volume=32&amp;issue=6&amp;publication_year=2007+Jul+Aug&amp;pages=918-22&amp;pmid=17606078&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>3. <span>Ward JSM.  New York: Land’s End Press; 1969. eds. Sign language of the mysteries; p. 1-6, 11-16, 55-78, 113-147. <span>[<a href="https://scholar.google.com/scholar?q=Ward+JSM+eds.+Sign+language+of+the+mysteries+1969+New+York+Land%E2%80%99s+End+Press+1-6,+11-16,+55-78,+113-147+" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>4. <span>Lazzeri D, Xi W, Zhang YX, Persichetti P. A systematic reappraisal of the fifth finger in Renaissance paintings. <span><span>J R Soc Med. </span>2014 Dec;<span>107</span>(12):474–479.</span> <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4265112/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/25504604" ref="reftype=pubmed&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+R+Soc+Med&amp;title=A+systematic+reappraisal+of+the+fifth+finger+in+Renaissance+paintings&amp;author=D+Lazzeri&amp;author=W+Xi&amp;author=YX+Zhang&amp;author=P+Persichetti&amp;volume=107&amp;issue=12&amp;publication_year=2014+Dec&amp;pages=474-479&amp;pmid=25504604&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>5. <span>Weisz GM, Albury WR, Matucci-Cerinic M, Lazzeri D. ‘Epidemic’ of hand deformities in the French baroque paintings of jean and françois clouet. <span><span>QJM. </span>2016 Sep;<span>109</span>(9):633–5.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/27261488" ref="reftype=pubmed&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=QJM&amp;title=%E2%80%98Epidemic%E2%80%99+of+hand+deformities+in+the+French+baroque+paintings+of+jean+and+fran%C3%A7ois+clouet&amp;author=GM+Weisz&amp;author=WR+Albury&amp;author=M+Matucci-Cerinic&amp;author=D+Lazzeri&amp;volume=109&amp;issue=9&amp;publication_year=2016+Sep&amp;pages=633-5&amp;pmid=27261488&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>6. <span>Lazzeri D, Castello MF, Matucci-Cerinic M, Lippi D, Weisz GM. Osteoarthritis in the hands of Michelangelo Buonarroti. <span><span>J R Soc Med. </span>2016 May;<span>109</span>(5):180–3.</span> <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4872204/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/26837259" ref="reftype=pubmed&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+R+Soc+Med&amp;title=Osteoarthritis+in+the+hands+of+Michelangelo+Buonarroti&amp;author=D+Lazzeri&amp;author=MF+Castello&amp;author=M+Matucci-Cerinic&amp;author=D+Lippi&amp;author=GM+Weisz&amp;volume=109&amp;issue=5&amp;publication_year=2016+May&amp;pages=180-3&amp;pmid=26837259&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>7. <span>Lazzeri D, Castello MF, Grassetti L, Dashti T, Zhang YX, Persichetti P. Foot deformities in Renaissance paintings. A mystery of symbolism, artistic licence, illusion and true representation in five renowned Renaissance painters. <span><span>J R Coll Physicians Edinb. </span>2015 Dec;<span>45</span>(4):289–97.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/27070893" ref="reftype=pubmed&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+R+Coll+Physicians+Edinb&amp;title=Foot+deformities+in+Renaissance+paintings.+A+mystery+of+symbolism,+artistic+licence,+illusion+and+true+representation+in+five+renowned+Renaissance+painters&amp;author=D+Lazzeri&amp;author=MF+Castello&amp;author=L+Grassetti&amp;author=T+Dashti&amp;author=YX+Zhang&amp;volume=45&amp;issue=4&amp;publication_year=2015+Dec&amp;pages=289-97&amp;pmid=27070893&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>8. <span>Lazzeri D, Grassetti L, Di Benedetto G, Albury RA, Weisz GM. The Hand in Art: Clinodactyly in Renaissance Paintings. <span><span>J Hand Surg Am. </span>2015 Oct;<span>40</span>(10):2058–60.</span> <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+Hand+Surg+Am&amp;title=The+Hand+in+Art:+Clinodactyly+in+Renaissance+Paintings&amp;author=D+Lazzeri&amp;author=L+Grassetti&amp;author=G+Di+Benedetto&amp;author=RA+Albury&amp;author=GM+Weisz&amp;volume=40&amp;issue=10&amp;publication_year=2015+Oct&amp;pages=2058-60&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>9. <span>Lazzeri D, Pozzilli P, Zhang YX, Persichetti P. Goiter in paintings by Rogier van der Weyden (1399-1464) <span><span>Thyroid. </span>2015 May;<span>25</span>(5):559–62.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/25747746" ref="reftype=pubmed&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Thyroid&amp;title=Goiter+in+paintings+by+Rogier+van+der+Weyden+(1399-1464)&amp;author=D+Lazzeri&amp;author=P+Pozzilli&amp;author=YX+Zhang&amp;author=P+Persichetti&amp;volume=25&amp;issue=5&amp;publication_year=2015+May&amp;pages=559-62&amp;pmid=25747746&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>10. <span>Lazzeri D, Lippi D, Castello MF, Weisz GM. Breast Mass in a Rubens Painting. <span><span>Rambam Maimonides Med J. </span>2016 Apr 19;<span>7</span>(2)</span> <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4839543/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/27101221" ref="reftype=pubmed&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Rambam+Maimonides+Med+J&amp;title=Breast+Mass+in+a+Rubens+Painting&amp;author=D+Lazzeri&amp;author=D+Lippi&amp;author=MF+Castello&amp;author=GM+Weisz&amp;volume=7&amp;issue=2&amp;publication_year=2016+Apr+19&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>11. <span>Lazzeri D, Nicoli F. Pectus excavatum in paintings by Jusepe de Ribera (1591-1652) <span><span>Thorax. </span>2016 Jul;<span>71</span>(7):669–70.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/26903593" ref="reftype=pubmed&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Thorax&amp;title=Pectus+excavatum+in+paintings+by+Jusepe+de+Ribera+(1591-1652)&amp;author=D+Lazzeri&amp;author=F+Nicoli&amp;volume=71&amp;issue=7&amp;publication_year=2016+Jul&amp;pages=669-70&amp;pmid=26903593&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>12. <span>Ralph Oppenhejm. Spain in the looking-glass, translated by K. John (McBride: New York 1956) p. 54; Marañon (El Greco y Toledo, p. 283) <span></span> <span>[<a href="https://scholar.google.com/scholar?q=Ralph+Oppenhejm+Spain+in+the+looking-glass,+translated+by+K.+John+(McBride:+New+York+1956)+p.+54;+Mara%C3%B1on+(El+Greco+y+Toledo,+p.+283)+" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>13. <span>Ibid.: “This figure became the device of the kohanim and is often inscribed on their tombstones.” e.g., the Jewish cemetery in Prague. See also E. M. Lilien drawing, ‘Friedhofsnachtingal, Lieder des ghetto’ (1902), in Heyd, ‘Lilien and Beardsley,’ ibid., p. 67, fig. 2 <span></span> <span>[<a href="https://scholar.google.com/scholar?q=Ibid.:+%E2%80%9CThis+figure+became+the+device+of+the+kohanim+and+is+often+inscribed+on+their+tombstones.%E2%80%9D+e.g.,+the+Jewish+cemetery+in+Prague.+See+also+E.+M.+Lilien+drawing,+%E2%80%98Friedhofsnachtingal,+Lieder+des+ghetto%E2%80%99+(1902),+in+Heyd,+%E2%80%98Lilien+and+Beardsley,%E2%80%99+ibid.,+p.+67,+fig.+2+" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>14. <span>Georges Nataf. Symboles, signes, et marques (Paris 1973) p. 21215. Antonia Vallentin, El Greco (London 1954) p. 141-2 <span></span> <span>[<a href="https://scholar.google.com/scholar?q=Georges+Nataf+Symboles,+signes,+et+marques+(Paris+1973)+p.+21215.+Antonia+Vallentin,+El+Greco+(London+1954)+p.+141-2+" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>16. <span>Cassou I. El Greco (1934) p. 105; cited in Camón Aznar, Domínico Greco (Espasa-Calpe: Madrid 1950), p. 1092-93 <span></span> <span>[<a href="https://scholar.google.com/scholar?q=Cassou+I+El+Greco+(1934)+p.+105;+cited+in+Cam%C3%B3n+Aznar,+Dom%C3%ADnico+Greco+(Espasa-Calpe:+Madrid+1950),+p.+1092-93+" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>17. <span>deOsa V. The Mystic Finger Symbol A Novel of El Greco (German) Hardcover, 1956 <span></span> <span>[<a href="https://scholar.google.com/scholar?q=deOsa+V+The+Mystic+Finger+Symbol+A+Novel+of+El+Greco+(German)+Hardcover,+1956+" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=7233791&amp;issue-id=357947&amp;journal-id=3185&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p></div></div></div><!--post-content--><div><hr><p>Articles from <span>Acta Bio Medica : Atenei Parmensis</span> are provided here courtesy of <strong>Mattioli 1885</strong></p><hr></div></div>
    </article>
    
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US has the highest rate of maternal deaths among rich nations. Norway has zero (102 pts)]]></title>
            <link>https://www.cnn.com/2024/06/04/health/maternal-deaths-high-income-nations/index.html</link>
            <guid>40605827</guid>
            <pubDate>Fri, 07 Jun 2024 06:26:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2024/06/04/health/maternal-deaths-high-income-nations/index.html">https://www.cnn.com/2024/06/04/health/maternal-deaths-high-income-nations/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=40605827">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location"></span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtahe47000m5nqo7wxvb3iq@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The United States continues to have a higher rate of women dying in pregnancy, childbirth or postpartum compared with all other high-income nations, even despite <a href="https://www.cnn.com/2024/05/01/health/maternal-mortality-cdc-report/">recent declines</a> in the US maternal death rate, a new report shows.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji400033b6jebi0wxyz@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            There were about 22 maternal deaths for every 100,000 live births in the United States in 2022, the most recent year for which data was available. That rate was more than double, sometimes triple, those seen in most other high-income countries that year, according to the <a href="https://www.commonwealthfund.org/publications/issue-briefs/2024/jun/insights-us-maternal-mortality-crisis-international-comparison" target="_blank">report released Tuesday by the Commonwealth Fund</a>, a private foundation focused on health care-related issues.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji400043b6jwx2neree@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            And the rate of maternal deaths among Black women in the United States remains even higher, at nearly 50 deaths per 100,000 live births, the new report shows.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji400053b6jiuc29lzu@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Meanwhile, half of the high-income nations in the new report had fewer than 5 maternal deaths per 100,000 live births, and one country recorded zero maternal deaths: Norway.
    </p>

  


    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji400063b6jea07zwyb@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Unlike Norway and some other peer nations, “the US has a maternal care workforce shortage problem, which is only supposed to get worse,” said&nbsp;Munira&nbsp;Gunja, lead author of the report and senior researcher at the International Program in Health Policy and Practice Innovations at the Commonwealth Fund.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwuo3eb300013b6jb53xkj9t@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            In the United States, she noted, there is&nbsp;<a href="https://www.cnn.com/2019/11/16/health/midwives-doulas-every-mother-counts-wellness/index.html">limited access to midwives</a>, who provide support to a patient from the prenatal period through postpartum.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwuo3eb300023b6j3eg5yls4@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “We have an under-supply of midwives, and midwives are underutilized, whereas in most other countries, midwives greatly outnumber ob-gyns. They’re part of their health care systems. Midwifery care is not integrated enough into our system,” Gunja said.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwuo3eb300033b6jg5fz5acn@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            In the United States, “there&nbsp;are several barriers to&nbsp;getting midwifery care, and other countries just don’t have that. They’re able to make sure that every woman has access to care, whether it be in some cases an ob-gyn and in most cases a midwife,” she said. “In the US, we’re the only country in this analysis without a universal health system. Nearly 8 million women of reproductive age are without health insurance.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwuo45d600053b6j6tvzv40r@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            In Norway, <a href="https://www.commonwealthfund.org/international-health-policy-center/countries/norway" target="_blank">which has universal health coverage</a>, <a href="https://obgyn.onlinelibrary.wiley.com/doi/full/10.1111/aogs.13172#:~:text=Improvements%20in%20care%20might%20have,relatively%20equalitarian%20societies%202%2D4." target="_blank">prenatal care is accessible free of charge</a>, and high-risk pregnancies are effectively identified.
    </p>

  

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji400073b6j4th3pktg@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Researchers at the Commonwealth Fund analyzed maternal mortality data from 14 high-income countries: Australia, Canada, Chile, France, Germany, Japan, Korea, the Netherlands, New Zealand, Norway, Sweden, Switzerland, the UK and the US.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji400083b6jj2ir6emw@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The data, which came from the US Centers for Disease Control and Prevention and the Organisation for Economic Co-operation and Development, showed that the top three nations with the highest maternal death rate were the United States, Chile and New Zealand. Chile and New Zealand each recorded about 14 deaths per 100,000 live births.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji400093b6jt2hlzzgu@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The three nations with the lowest maternal death rate were Norway with zero, Switzerland with a rate of 1 death per 100,000 live births and Sweden with about 3 deaths per 100,000 live births.
    </p>

  

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji4000b3b6jjfu4e6bt@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            During the Covid-19 pandemic, maternal death rates increased in Australia, Japan, the Netherlands and the US, according to the report, which notes that the increase may have been due to a rise in Covid-related infections, complications worsened by the virus or delays or decreased access to care at the time. More recently, maternal death rates have started to decline in Chile, Norway and the US.
    </p>

  


    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji4000c3b6jqdguvo63@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The <a href="https://www.cnn.com/2024/05/01/health/maternal-mortality-cdc-report/index.html">US maternal mortality rate fell</a> from 32.9 maternal deaths per 100,000 live births in 2021 to 22.3 per 100,000 in 2022, according to data from the CDC.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji4000d3b6jd9xa9ddq@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “It is encouraging to see fewer maternal deaths in the U.S. in 2022, however the U.S. is still such an outlier, and the racial disparities are profoundly disturbing,” Dr. Laurie Zephyrin, senior vice president for advancing health equity at the Commonwealth Fund, said in a news release.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji4000e3b6jjx3rvmar@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “It is time to center equity by diversifying the workforce and addressing head on the racial inequities in health care quality and access,” she said. “Now is the time to prioritize what we know is already working well in other countries: expanded health insurance coverage, stronger workforce and support systems, and paid maternity leave.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji4000g3b6jwxxpchmp@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The new report points to the US health care system, policy differences and maternity care deserts – where residents have limited or no access to maternity health care – as among the factors driving the high US maternal mortality rate.
    </p>

  


    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji4000i3b6jgi97yryx@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The US and Canada have the lowest overall supply of midwives and ob-gyns to care for pregnant and postpartum mothers, with only 16 and 13 providers per 1,000 live births respectively, according to the new report. In Canada, the maternal death rate is estimated to be about 8 deaths per 100,000 live births.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji4000j3b6jgnst9bs9@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            More than 2.2 million US women of childbearing age – 15 to 44 – live in maternity care deserts, a<a href="https://www.cnn.com/2022/10/11/health/maternity-care-deserts-march-of-dimes-report/index.html"> report by the nonprofit March of Dimes</a> found in 2022. And last year, a separate analysis found that <a href="https://www.cnn.com/2023/08/01/health/maternity-care-deserts-march-of-dimes/index.html">hospitals in a 10th of US counties</a> have lost their childbirth units in the past five years.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji4000k3b6j4yv17a7b@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Midwives “could help address maternity workforce shortages in the U.S., where nearly half of counties lack a single ob-gyn. An estimated 8,000 more ob-gyns are needed to meet demand — a number that may rise to 22,000 by 2050,” according to the new report.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji4000l3b6j24bcp74i@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Additionally, nearly two-thirds of maternal deaths occur in the postpartum period, up to 42 days after giving birth, and US women are least likely to have postpartum home visits, according to the new report. All the countries in the report, apart from the US, guarantee at least one home visit within a week postpartum. On the state level, only some Medicaid programs in the US cover these visits.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji4000m3b6jwj0wb8mo@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “The World Health Organization recommends at least four health contacts in the first six weeks following birth, yet two of five U.S. women — more often than not younger, low-income, and uninsured — skip their one postpartum check-up,” according to the new report.
    </p>

  


    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji4000n3b6jra1sixp4@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            In the first week postpartum, the most common contributors to maternal deaths were severe bleeding, high blood pressure and infection, while cardiomyopathy – a heart muscle disease – was the leading cause of deaths later in the postpartum period, according to the new report.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji4000o3b6jnj4lk1ii@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The US also stands alone as the only high-income country where there is no federally mandated paid leave policy for postpartum mothers, according to the new report. US women are less likely to have guaranteed paid leave compared with women in other high-income nations, where at least 14 weeks of paid leave from work is mandated.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwti2jwi00053b6j3ewcugmc@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “Maternal deaths are a preventable problem, and this problem can be solved. A lot of countries have been able to figure out ways to make it so that all women are in safe hands when it comes to having a baby and after giving birth. We need to extend that to women in the US as well,” Gunja said. “We know most deaths are during the postpartum period – so making sure we have federally mandated paid leave, making sure we make it easy for women to get postpartum care, which means having home visits and not making women go to the doctor.”
    </p>

  

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwuo66p600073b6jzewpqlqd@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Racial disparities in maternal death rates persist not only in the United States but in other parts of the world where some women have less access to postpartum support, according to the new report.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji4000q3b6jidaplvx8@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “In the United Kingdom, for example, Black women are four times more likely to die than white women are. In Australia, Aboriginal women are about twice as likely as non-Aboriginal women to die from maternal complications,” the researchers wrote.
    </p>

  


    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwtajji4000r3b6jf2ye8mys@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “Our findings suggest that an undersupply of maternity providers, especially midwives, and lack of access to comprehensive postpartum support, including maternity care coverage and mandated paid maternity leave, are contributing factors,” they wrote. “Because both these factors disproportionately affect women of color, centering equity in any future policy changes will be a key to addressing the crisis.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwzcnv5g000d3b5vbhkft013@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The Commonwealth Fund’s report “highlights the need to have enhanced maternal health care and maternal health equity in the US,” said&nbsp;<a href="https://www.aafp.org/about/meet-our-leadership/board/iroku-malize.html" target="_blank">Dr.&nbsp;Tochi&nbsp;Iroku-Malize</a>, a family physician in Long Island, New York, and board chair of the American Academy of Family Physicians, who was not involved in the new report.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwv3tb9e00023b6jwj00kp69@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “For us in family medicine, we know that we do play a crucial role in providing the obstetric care throughout pregnancy and the postpartum period, which is needed, and maternal health care cannot stop after a patient gives birth,” she said, calling on her US colleagues to watch out for maternal health complications – such as inflammation of the heart muscle or mental health conditions – in their postpartum patients, as the majority of maternal deaths occur during that time.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwv3tb9f00033b6j7l9r2c1i@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “A postpartum patient’s body is still going through immense physical, hormonal and emotional changes that you really cannot overlook,” she said. “And our training as family physicians, it helps us to screen and address the full spectrum of physical, emotional and social needs during pregnancy and the postpartum period.”
    </p>

  


    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwz5ack2000i3b6jhw2owfbx@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Adding more birth workers to the maternal health care workforce remains an important component and major need, said Dr. Michelle Owens, an obstetrician-gynecologist in Jackson,&nbsp;Mississippi, who was not involved in the new report.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwz5af9p000k3b6jzulg7x89@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “But we also need to ensure we have systems in place to facilitate escalation of care when needed so that each birthing person has access to the appropriate care in a timely manner. Timely diagnosis and treatment of complications are essential to ensuring the overall health and safety of our mothers and their children,” Owens, a member of the American College of Obstetricians and Gynecologists, wrote in an email.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwz5af9p000l3b6j25u7vbui@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “ACOG recommends that expectant mothers engage as active partners in their care, attend their scheduled appointments during and after pregnancy, and consider pregnancy planning in order to optimize pregnancy outcomes,” she added. “Finally, patients need to feel empowered to voice their concerns to their healthcare&nbsp;providers, and for their providers to listen to their concerns and work collaboratively with patients for resolution of their&nbsp;concerns.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwz3i4j000013b6jrf7o8e98@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The report joins several other studies that have highlighted the United States’ high maternal mortality rate, said Dr. Christopher Zahn, interim CEO and chief of clinical practice and health equity and quality for ACOG.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwz3i6wr00033b6jy4rpzjif@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “Despite capturing different time periods and using different methodologies, what we can confidently take away from these reports is that the number of maternal deaths in this country is still unacceptably high,” Zahn, who was not involved in the Commonwealth Fund’s latest report, wrote in an email.
    </p>

  

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwz3i6wr00043b6j73rpnyf1@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “In 2016, the public was surprised to learn from a widely publicized study in The Lancet that the United States had the highest rate of maternal mortality compared to other developed countries. The Commonwealth Fund report shows that nearly a decade later this is still the case. This is obviously disheartening news, but we also must acknowledge that, despite the collective effort put toward improving maternal health outcomes, we have faced tremendous setbacks,” Zahn said, referring to disruptions in access to care due to the Covid-19 pandemic, the overturning of Roe v. Wade and ongoing health inequities resulting in racial and ethnic disparities.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/clwz3i6wr00053b6jhopgxn3f@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “The areas of weakness in our policies and systems have been longstanding pain points and are clearly all contributors to the poor maternal health outcomes we are experiencing today,” he added.&nbsp;“ACOG will continue its work in improving quality and safety in maternal health care, educating its members on the necessity of eliminating racism and bias in medicine and advocating for policies that are supportive of both clinicians and patients in an effort to improve outcomes.”
    </p>



                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ice - open source bar manager for macOS (540 pts)]]></title>
            <link>https://github.com/jordanbaird/Ice</link>
            <guid>40605532</guid>
            <pubDate>Fri, 07 Jun 2024 05:11:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/jordanbaird/Ice">https://github.com/jordanbaird/Ice</a>, See on <a href="https://news.ycombinator.com/item?id=40605532">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
    <p><a target="_blank" rel="noopener noreferrer" href="https://github.com/jordanbaird/Ice/blob/main/Ice/Assets.xcassets/AppIcon.appiconset/icon_256x256.png"><img src="https://github.com/jordanbaird/Ice/raw/main/Ice/Assets.xcassets/AppIcon.appiconset/icon_256x256.png" width="200" height="200"></a></p><p dir="auto"><h2 tabindex="-1" dir="auto">Ice</h2><a id="user-content-ice" aria-label="Permalink: Ice" href="#ice"></a></p>
</div>
<p dir="auto">Ice is a powerful menu bar management tool. While its primary function is hiding and showing menu bar items, it aims to cover a wide variety of additional features to make it one of the most versatile menu bar tools available.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/90936861/337269729-e256575b-880c-49ee-90a1-b6eabd4a7868.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTc3NDU3MDMsIm5iZiI6MTcxNzc0NTQwMywicGF0aCI6Ii85MDkzNjg2MS8zMzcyNjk3MjktZTI1NjU3NWItODgwYy00OWVlLTkwYTEtYjZlYWJkNGE3ODY4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjA3VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZiN2Q5NGYwOTVkODFmNjY2MjhmOWUzY2FkNjc2MTJkMjJiY2UxZjljMjIwM2E0NGJiMzg2MDc3Yzk1NTYzZGImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.ZAQaQeWfoC14wJuXpebfc2vSdt0FCoyRe0YbnYtszDU"><img src="https://private-user-images.githubusercontent.com/90936861/337269729-e256575b-880c-49ee-90a1-b6eabd4a7868.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTc3NDU3MDMsIm5iZiI6MTcxNzc0NTQwMywicGF0aCI6Ii85MDkzNjg2MS8zMzcyNjk3MjktZTI1NjU3NWItODgwYy00OWVlLTkwYTEtYjZlYWJkNGE3ODY4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjA3VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZiN2Q5NGYwOTVkODFmNjY2MjhmOWUzY2FkNjc2MTJkMjJiY2UxZjljMjIwM2E0NGJiMzg2MDc3Yzk1NTYzZGImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.ZAQaQeWfoC14wJuXpebfc2vSdt0FCoyRe0YbnYtszDU" alt="Banner"></a></p>
<p dir="auto"><a href="https://github.com/jordanbaird/Ice/releases/latest"><img src="https://camo.githubusercontent.com/01a1e5eace1f29146439e52ca905bb1944101aa8e1439ad28016634ab09d4cf2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f776e6c6f61642d6c61746573742d627269676874677265656e3f7374796c653d666c61742d737175617265" alt="Download" data-canonical-src="https://img.shields.io/badge/download-latest-brightgreen?style=flat-square"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/d2da2d8531376e348989bf9b38fc124d66edb8d942c7b5124d2f05648d5f6531/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d6d61634f532d626c75653f7374796c653d666c61742d737175617265"><img src="https://camo.githubusercontent.com/d2da2d8531376e348989bf9b38fc124d66edb8d942c7b5124d2f05648d5f6531/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d6d61634f532d626c75653f7374796c653d666c61742d737175617265" alt="Platform" data-canonical-src="https://img.shields.io/badge/platform-macOS-blue?style=flat-square"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/e6fa7e0d369a9b73e179ef17bef802dc7f20905b64989f2b74028c9727936970/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f726571756972656d656e74732d6d61634f5325323031342532422d6661346534393f7374796c653d666c61742d737175617265"><img src="https://camo.githubusercontent.com/e6fa7e0d369a9b73e179ef17bef802dc7f20905b64989f2b74028c9727936970/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f726571756972656d656e74732d6d61634f5325323031342532422d6661346534393f7374796c653d666c61742d737175617265" alt="Requirements" data-canonical-src="https://img.shields.io/badge/requirements-macOS%2014%2B-fa4e49?style=flat-square"></a>
<a href="https://jordanbaird.gumroad.com/l/ice" rel="nofollow"><img src="https://camo.githubusercontent.com/9bd6b0db10c755135ba6f7fa7e3f6771510682e448650ee11a55b98b9a1cac24/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f537570706f72742532302545322539442541342545462542382538462d3841324245323f7374796c653d666c61742d737175617265" alt="Support" data-canonical-src="https://img.shields.io/badge/Support%20%E2%9D%A4%EF%B8%8F-8A2BE2?style=flat-square"></a>
<a href="https://icemenubar.app/" rel="nofollow"><img src="https://camo.githubusercontent.com/cd06400f307d1a54e0c33e65a7d4541a059345a59cc24a0f809914b5025fc38a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f576562736974652d3031354642413f7374796c653d666c61742d737175617265" alt="Website" data-canonical-src="https://img.shields.io/badge/Website-015FBA?style=flat-square"></a>
<a href="https://github.com/jordanbaird/Ice/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/07b911e5dcbb76995245bb90ea5b4153f7c2f2f2ac8b688c0f4514da4e7f978a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6a6f7264616e62616972642f4963653f7374796c653d666c61742d737175617265" alt="License" data-canonical-src="https://img.shields.io/github/license/jordanbaird/Ice?style=flat-square"></a></p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Ice is currently in active development. Some features have not yet been implemented. Download the latest release <a href="https://github.com/jordanbaird/Ice/releases/latest">here</a> and see the roadmap below for upcoming features.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Simply <code>Command</code> + drag your menu bar items to rearrange them.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/jordanbaird/Ice/blob/main/Resources/rearranging.gif"><img src="https://github.com/jordanbaird/Ice/raw/main/Resources/rearranging.gif" alt="Rearranging" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Manual Installation</h3><a id="user-content-manual-installation" aria-label="Permalink: Manual Installation" href="#manual-installation"></a></p>
<p dir="auto">Download the "Ice.zip" file from the <a href="https://github.com/jordanbaird/Ice/releases/latest">latest release</a> and move the unzipped app into your <code>Applications</code> folder.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Homebrew</h3><a id="user-content-homebrew" aria-label="Permalink: Homebrew" href="#homebrew"></a></p>
<p dir="auto">If you use <a href="https://brew.sh/" rel="nofollow">Homebrew</a>, you can install Ice using the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="brew install jordanbaird-ice"><pre>brew install jordanbaird-ice</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features/Roadmap</h2><a id="user-content-featuresroadmap" aria-label="Permalink: Features/Roadmap" href="#featuresroadmap"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Menu bar item management</h3><a id="user-content-menu-bar-item-management" aria-label="Permalink: Menu bar item management" href="#menu-bar-item-management"></a></p>
<ul>
<li> Hide menu bar items</li>
<li> "Always Hidden" menu bar section</li>
<li> Show hidden items when hovering over the menu bar</li>
<li> Show hidden items when an empty area in the menu bar is clicked</li>
<li> Show hidden items by scrolling or swiping in the menu bar</li>
<li> Automatically rehide</li>
<li> Hide application menus when they overlap with shown menu bar items</li>
<li> Drag and drop interface to arrange individual items</li>
<li> Search menu bar items</li>
<li> Display hidden items in a separate bar (e.g. for MacBooks with the notch)</li>
<li> Custom spacing between items</li>
<li> Profiles for menu bar layout</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Menu bar appearance</h3><a id="user-content-menu-bar-appearance" aria-label="Permalink: Menu bar appearance" href="#menu-bar-appearance"></a></p>
<ul>
<li> Menu bar tint (solid and gradient)</li>
<li> Menu bar shadow</li>
<li> Menu bar border</li>
<li> Custom menu bar shapes (rounded and/or split)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Hotkeys</h3><a id="user-content-hotkeys" aria-label="Permalink: Hotkeys" href="#hotkeys"></a></p>
<ul>
<li> Toggle individual menu bar sections</li>
<li> Toggle application menus</li>
<li> Show/hide section divider icons</li>
<li> Temporarily show individual menu bar items</li>
<li> Enable/disable auto rehide</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Other</h3><a id="user-content-other" aria-label="Permalink: Other" href="#other"></a></p>
<ul>
<li> Launch at login</li>
<li> Automatic updates</li>
<li> Menu bar widgets</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why the name?</h2><a id="user-content-why-the-name" aria-label="Permalink: Why the name?" href="#why-the-name"></a></p>
<p dir="auto">Because your menu bar becomes like ice, allowing your menu bar items to slide away 🧊🧊🧊</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why not support earlier operating systems?</h2><a id="user-content-why-not-support-earlier-operating-systems" aria-label="Permalink: Why not support earlier operating systems?" href="#why-not-support-earlier-operating-systems"></a></p>
<p dir="auto">There are a number of system APIs that Ice uses that are only available starting with macOS 14.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Gallery</h2><a id="user-content-gallery" aria-label="Permalink: Gallery" href="#gallery"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Choose your own icon to show in the menu bar</h4><a id="user-content-choose-your-own-icon-to-show-in-the-menu-bar" aria-label="Permalink: Choose your own icon to show in the menu bar" href="#choose-your-own-icon-to-show-in-the-menu-bar"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/90936861/316565649-ded03af0-f6cf-4bc1-a094-af0cf32ead96.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTc3NDU3MDMsIm5iZiI6MTcxNzc0NTQwMywicGF0aCI6Ii85MDkzNjg2MS8zMTY1NjU2NDktZGVkMDNhZjAtZjZjZi00YmMxLWEwOTQtYWYwY2YzMmVhZDk2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjA3VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQyYjBmNDc2NzY4ZDA4MDkzODk0YzMwMGY0NzY3ODJmNGEyZjcxZDUyMzI1MzM2ODg3NjczZjUyNzYzYjEzNTkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.OdzlaKbWN6tW8FHldIAzabXMTfl8l3ujByE9iSkkms0"><img src="https://private-user-images.githubusercontent.com/90936861/316565649-ded03af0-f6cf-4bc1-a094-af0cf32ead96.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTc3NDU3MDMsIm5iZiI6MTcxNzc0NTQwMywicGF0aCI6Ii85MDkzNjg2MS8zMTY1NjU2NDktZGVkMDNhZjAtZjZjZi00YmMxLWEwOTQtYWYwY2YzMmVhZDk2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjA3VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQyYjBmNDc2NzY4ZDA4MDkzODk0YzMwMGY0NzY3ODJmNGEyZjcxZDUyMzI1MzM2ODg3NjczZjUyNzYzYjEzNTkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.OdzlaKbWN6tW8FHldIAzabXMTfl8l3ujByE9iSkkms0" alt="Custom Icon Example"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Customize the menu bar's appearance</h4><a id="user-content-customize-the-menu-bars-appearance" aria-label="Permalink: Customize the menu bar's appearance" href="#customize-the-menu-bars-appearance"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/90936861/316568231-99a59cc7-914a-4f8a-af4b-11a5193534da.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTc3NDU3MDMsIm5iZiI6MTcxNzc0NTQwMywicGF0aCI6Ii85MDkzNjg2MS8zMTY1NjgyMzEtOTlhNTljYzctOTE0YS00ZjhhLWFmNGItMTFhNTE5MzUzNGRhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjA3VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ0YTMzY2Q3MDY5NTdiYWE3OWNkY2ViYjI0ZDMzODlkZTI5MDU3OWFiZDI3NmFhZThhNGZhNjI2Y2NlZmMyMTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.15HYZuDRgDllKmNA3U944pqxgRskhkMERX1c0EePsmk"><img src="https://private-user-images.githubusercontent.com/90936861/316568231-99a59cc7-914a-4f8a-af4b-11a5193534da.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTc3NDU3MDMsIm5iZiI6MTcxNzc0NTQwMywicGF0aCI6Ii85MDkzNjg2MS8zMTY1NjgyMzEtOTlhNTljYzctOTE0YS00ZjhhLWFmNGItMTFhNTE5MzUzNGRhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjA3VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ0YTMzY2Q3MDY5NTdiYWE3OWNkY2ViYjI0ZDMzODlkZTI5MDU3OWFiZDI3NmFhZThhNGZhNjI2Y2NlZmMyMTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.15HYZuDRgDllKmNA3U944pqxgRskhkMERX1c0EePsmk" alt="Menu Bar Appearance Example 1"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/90936861/316570684-ba3bd8d9-0eeb-447b-8a62-1bc811319132.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTc3NDU3MDMsIm5iZiI6MTcxNzc0NTQwMywicGF0aCI6Ii85MDkzNjg2MS8zMTY1NzA2ODQtYmEzYmQ4ZDktMGVlYi00NDdiLThhNjItMWJjODExMzE5MTMyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjA3VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTk0ZGEzYzQ3NWJmMjcwMjcwMmVkMzE2Mjc0YTg3ODUzZGU3NDYxOGJlZTNkMWQwMjdiYTEyNTJmYzM3MGZjZDQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.8hYg4P60AFYj_4Oub82t_J7hClwIjWHijaofXPOqXbA"><img src="https://private-user-images.githubusercontent.com/90936861/316570684-ba3bd8d9-0eeb-447b-8a62-1bc811319132.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTc3NDU3MDMsIm5iZiI6MTcxNzc0NTQwMywicGF0aCI6Ii85MDkzNjg2MS8zMTY1NzA2ODQtYmEzYmQ4ZDktMGVlYi00NDdiLThhNjItMWJjODExMzE5MTMyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MDclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjA3VDA3MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTk0ZGEzYzQ3NWJmMjcwMjcwMmVkMzE2Mjc0YTg3ODUzZGU3NDYxOGJlZTNkMWQwMjdiYTEyNTJmYzM3MGZjZDQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.8hYg4P60AFYj_4Oub82t_J7hClwIjWHijaofXPOqXbA" alt="Menu Bar Appearance Example 2"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Ice is available under the <a href="https://github.com/jordanbaird/Ice/blob/main/LICENSE">MIT license</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CPU Energy Meter: A tool for measuring energy consumption of Intel CPUs (156 pts)]]></title>
            <link>https://github.com/sosy-lab/cpu-energy-meter</link>
            <guid>40604596</guid>
            <pubDate>Fri, 07 Jun 2024 01:59:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/sosy-lab/cpu-energy-meter">https://github.com/sosy-lab/cpu-energy-meter</a>, See on <a href="https://news.ycombinator.com/item?id=40604596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><h2 tabindex="-1" dir="auto">CPU Energy Meter</h2><a id="user-content-cpu-energy-meter" aria-label="Permalink: CPU Energy Meter" href="#cpu-energy-meter"></a></p>
<p dir="auto"><a href="https://gitlab.com/sosy-lab/software/cpu-energy-meter/pipelines" rel="nofollow"><img src="https://camo.githubusercontent.com/3b2e2e44e005c60ee6d71f8c6809f83c193ed224c1d0b42bb2223967c4564a6b/68747470733a2f2f6769746c61622e636f6d2f736f73792d6c61622f736f6674776172652f6370752d656e657267792d6d657465722f6261646765732f6d61696e2f706970656c696e652e737667" alt="Build Status" data-canonical-src="https://gitlab.com/sosy-lab/software/cpu-energy-meter/badges/main/pipeline.svg"></a>
<a href="https://github.com/sosy-lab/cpu-energy-meter/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/1aaf5e71abd8dbe565cc0ed7ba58a18597fa5a29ac1f05fc2008cf6006b39a2f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d636c617573652d627269676874677265656e2e737667" alt="BSD-3-Clause License" data-canonical-src="https://img.shields.io/badge/license-BSD--3--clause-brightgreen.svg"></a>
<a href="https://github.com/sosy-lab/cpu-energy-meter/releases"><img src="https://camo.githubusercontent.com/dd46eab6b8c7c31d612c1a172019367238c4833663dc6d26dcbfb1d715b93742/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f736f73792d6c61622f6370752d656e657267792d6d657465722e737667" alt="Releases" data-canonical-src="https://img.shields.io/github/release/sosy-lab/cpu-energy-meter.svg"></a>
<a href="https://zenodo.org/badge/latestdoi/46493895" rel="nofollow"><img src="https://camo.githubusercontent.com/4b9e215a2babde7837ff8b29e2f952dffc23d9f1e276e5a581f87a5bdd7d1b56/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f34363439333839352e737667" alt="DOI via Zenodo" data-canonical-src="https://zenodo.org/badge/46493895.svg"></a></p>
<p dir="auto">CPU Energy Meter is a Linux tool that allows to monitor power consumption of Intel CPUs
at fine time granularities (few tens of milliseconds).
Power monitoring is available for the following power domains:</p>
<ul dir="auto">
<li>per package domain (CPU socket)</li>
<li>per core domain (all the CPU cores on a package)</li>
<li>per uncore domain (uncore components, e.g., integrated graphics on client CPUs)</li>
<li>per memory node (memory local to a package, server CPUs only)</li>
<li>per platform (all devices in the platform that receive power from integrated
power delivery mechanism, e.g., processor cores, SOC, memory, add-on or
peripheral devices)</li>
</ul>
<p dir="auto">To do this, the tool uses a feature of Intel CPUs that is called <a href="https://en.wikipedia.org/wiki/Running_average_power_limit" rel="nofollow">RAPL (Running Average Power Limit)</a>,
which is documented in the <a href="https://software.intel.com/en-us/articles/intel-sdm" rel="nofollow">Intel Software Developers Manual</a>, Volume 3B Chapter 14.9.
RAPL is available on CPUs from the generation <a href="https://en.wikipedia.org/wiki/Sandy_Bridge" rel="nofollow">Sandy Bridge</a> and later.
Because CPU Energy Meter uses the maximal possible measurement interval
(depending on the hardware this is between a few minutes and an hour),
it causes negligible overhead.</p>
<p dir="auto">CPU Energy Meter is a fork of the <a href="https://software.intel.com/en-us/articles/intel-power-gadget-20" rel="nofollow">Intel Power Gadget</a>
and developed at the <a href="https://www.sosy-lab.org/" rel="nofollow">Software Systems Lab</a>
of the <a href="https://www.uni-muenchen.de/" rel="nofollow">Ludwig-Maximilians-Universität München (LMU Munich)</a>
under the <a href="https://github.com/sosy-lab/cpu-energy-meter/blob/main/LICENSE">BSD-3-Clause License</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">For Debian or Ubuntu the easiest way is to install from our <a href="https://launchpad.net/~sosy-lab/+archive/ubuntu/benchmarking" rel="nofollow">PPA</a>:</p>
<div data-snippet-clipboard-copy-content="sudo add-apt-repository ppa:sosy-lab/benchmarking
sudo apt install cpu-energy-meter"><pre><code>sudo add-apt-repository ppa:sosy-lab/benchmarking
sudo apt install cpu-energy-meter
</code></pre></div>
<p dir="auto">Alternatively, you can download our <code>.deb</code> package from <a href="https://github.com/sosy-lab/cpu-energy-meter/releases">GitHub</a>
and install it with <code>apt install ./cpu-energy-meter*.deb</code>.</p>
<p dir="auto">Dependencies of CPU Energy Meter are <a href="https://sites.google.com/site/fullycapable/" rel="nofollow">libcap</a>,
which is available on most Linux distributions in package <code>libcap</code> (e.g., Fedora)
or <code>libcap2</code> (e.g, Debian and Ubuntu: <code>sudo apt install libcap2</code>),
and a Linux kernel with the MSR module (available by default)</p>
<p dir="auto">Alternatively, for running CPU Energy Meter from source (quick and dirty):</p>
<div data-snippet-clipboard-copy-content="sudo apt install libcap-dev
sudo modprobe msr
make
sudo ./cpu-energy-meter"><pre><code>sudo apt install libcap-dev
sudo modprobe msr
make
sudo ./cpu-energy-meter
</code></pre></div>
<p dir="auto">It is also possible (and recommended) to run CPU Energy Meter without root.
To do so, the following needs to be done:</p>
<ul dir="auto">
<li>Load kernel modules <code>msr</code> and <code>cpuid</code>.</li>
<li>Add a group <code>msr</code>.</li>
<li>Add a Udev rule that grants access to <code>/dev/cpu/*/msr</code> to group <code>msr</code> (<a href="https://github.com/sosy-lab/cpu-energy-meter/blob/main/debian/additional_files/59-msr.rules">example</a>).</li>
<li>Run <code>chgrp msr</code>, <code>chmod 2711</code>, and <code>setcap cap_sys_rawio=ep</code> on the binary (<code>make setup</code> is a shortcut for this).</li>
</ul>
<p dir="auto">The provided Debian package in our <a href="https://launchpad.net/~sosy-lab/+archive/ubuntu/benchmarking" rel="nofollow">PPA</a>
and on <a href="https://github.com/sosy-lab/cpu-energy-meter/releases">GitHub</a> does these steps automatically
and lets all users execute CPU Energy Meter.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to use it</h2><a id="user-content-how-to-use-it" aria-label="Permalink: How to use it" href="#how-to-use-it"></a></p>
<div data-snippet-clipboard-copy-content="cpu-energy-meter [-d] [-e sampling_delay_ms] [-r]"><pre><code>cpu-energy-meter [-d] [-e sampling_delay_ms] [-r]
</code></pre></div>
<p dir="auto">The tool will continue counting the cumulative energy use of all supported CPUs
in the background and will report a key-value list of its measurements when it
receives SIGINT (Ctrl+C):</p>
<div data-snippet-clipboard-copy-content="+--------------------------------------+
| CPU-Energy-Meter            Socket 0 |
+--------------------------------------+
Duration                  2.504502 sec
Package                   3.769287 Joule
Core                      0.317749 Joule
Uncore                    0.010132 Joule
DRAM                      0.727783 Joule
PSYS                     29.792603 Joule"><pre><code>+--------------------------------------+
| CPU-Energy-Meter            Socket 0 |
+--------------------------------------+
Duration                  2.504502 sec
Package                   3.769287 Joule
Core                      0.317749 Joule
Uncore                    0.010132 Joule
DRAM                      0.727783 Joule
PSYS                     29.792603 Joule
</code></pre></div>
<p dir="auto">To get intermediate measurements, send signal <code>USR1</code> to the process.</p>
<p dir="auto">Optionally, the tool can be executed with parameter <code>-r</code>
to print the output as a raw (easily parsable) list:</p>
<div data-snippet-clipboard-copy-content="cpu_count=1
duration_seconds=3.241504
cpu0_package_joules=4.971924
cpu0_core_joules=0.461182
cpu0_uncore_joules=0.053406
cpu0_dram_joules=0.953979
cpu0_psys_joules=38.904785"><pre><code>cpu_count=1
duration_seconds=3.241504
cpu0_package_joules=4.971924
cpu0_core_joules=0.461182
cpu0_uncore_joules=0.053406
cpu0_dram_joules=0.953979
cpu0_psys_joules=38.904785
</code></pre></div>
<p dir="auto">The parameter <code>-d</code> adds debug output.
By default, CPU Energy Meter computes the necessary measurement interval automatically,
this can be overridden with the parameter <code>-e</code>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uganda's surveillance state is built on national ID cards (146 pts)]]></title>
            <link>https://www.bloomberg.com/news/features/2024-06-04/uganda-yoweri-museveni-s-critics-targeted-via-biometric-id-system</link>
            <guid>40603692</guid>
            <pubDate>Thu, 06 Jun 2024 23:36:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/features/2024-06-04/uganda-yoweri-museveni-s-critics-targeted-via-biometric-id-system">https://www.bloomberg.com/news/features/2024-06-04/uganda-yoweri-museveni-s-critics-targeted-via-biometric-id-system</a>, See on <a href="https://news.ycombinator.com/item?id=40603692">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Make your program slower with threads (2014) (144 pts)]]></title>
            <link>https://brooker.co.za/blog/2014/12/06/random.html</link>
            <guid>40603625</guid>
            <pubDate>Thu, 06 Jun 2024 23:28:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://brooker.co.za/blog/2014/12/06/random.html">https://brooker.co.za/blog/2014/12/06/random.html</a>, See on <a href="https://news.ycombinator.com/item?id=40603625">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post">


<p>How much do context switches matter?</p>

<p>Years ago, while taking a numerical methods course, I wrote some code to calculate the expected number of shared birthdays in a group. The code is very simple: each attempt constructs a vector of N birthdays, then counts the duplicates. The outer loop runs millions of attempts, and calculates the mean number of shared birthdays across all the samples. It’s little more than a tight loop around a pseudo-random number generator.</p>

<p>I was also learning about threading at the time, and decided that I could speed up my program by running it on the lab’s shiny dual-core machine. I knew that communicating between threads was expensive, so I had each of my threads calculate their attempts in parallel, and merge the results right at the end. I was expecting a great speedup. Much to my disappointment, though, the multi-threaded version was slower. Much, much, slower.</p>

<p>Much like the <a href="http://en.wikipedia.org/wiki/Birthday_problem">birthday paradox</a> runs counter to our intuition about statistics, the behavior of bad multi-threaded programs runs counter to our intuition about computer performance. We’re used to computers being much faster than they used to be, and single-threaded efficiency mattering less than it used to in most cases. Counter to that intuition, the gap between <em>good</em> and <em>bad</em> multithreaded programs has gotten worse over time.</p>

<p>To illustrate just how bad it can be, I replicated my program from back then. It’s not much more than a multi-threaded tight loop around <em>random(3)</em>. It’s nice and quick single-threaded: running 10 million attempts in under 7 seconds. Going up to two threads makes it a bit faster, down to less than 6 seconds. When we hit three threads (on my four core Haswell E3-1240), it all goes horribly wrong:</p>

<p><img src="https://s3.amazonaws.com/mbrooker-blog-images/threads_bar.png" alt=""></p>

<p>To figure out what’s wrong, we can turn to Linux’s excellent <a href="https://perf.wiki.kernel.org/index.php/Tutorial">perf</a> tool. Running the 1-thread and 4-thread versions with <em>perf stat</em> make it obvious that something’s going on. For 1 thread:</p>

<div><pre><code>     3,788,352 L1-dcache-load-misses #0.03% of all L1-dcache hits
43,399,424,441 instructions  #1.46  insns per cycle
           734 context-switches
</code></pre></div>

<p>and for four threads:</p>

<div><pre><code>  4,110,904,396 L1-dcache-load-misses #6.88% of all L1-dcache hits
248,853,610,160 instructions # 0.51  insns per cycle
     15,993,647 context-switches
</code></pre></div>

<p>Two things are going wrong here. One is that we’re seeing a more L1 cache misses with more threads, but the bigger issue is that we’re seeing <em>a whole lot more</em> context switches. The effect of both of these is visible in the much lower <em>instructions per cycle</em> of the second version. There’s no nice constant for the cost of a context switch, but a good modern estimate is around 3μs. Multiplying 3μs by 16 million context switches gives 48 seconds, which is a good hint that we’re headed in the right direction. So, what’s causing the context switches?</p>

<p>Back to <em>perf</em>, this time running <em>perf record</em> on the processes, followed by <em>perf report</em>. First, the top few rows for the single-threaded version:</p>

<div><pre><code># Overhead   Command  Shared Object    Symbol
# ........  ........  ..............   ........................
62.01%  birthday  libc-2.19.so         [.] msort_with_tmp.part.0
11.40%  birthday  libc-2.19.so         [.] __memcpy_sse2        
10.19%  birthday  birthday             [.] simulate
</code></pre></div>

<p>We’re spending 62% of the time sorting the array, which is used to find the duplicates. That’s about what I would have guessed. What about the version with four threads?</p>

<div><pre><code># Overhead   Command  Shared Object  Symbol
# ........  ........  .............  ............
46.80%  birthday  [kernel.kallsyms]  [k] _raw_spin_lock   
 8.86%  birthday  libc-2.19.so       [.] __random           
 3.42%  birthday  libc-2.19.so       [.] __lll_lock_wait_private
 3.23%  birthday  [kernel.kallsyms]  [k] try_to_wake_up       
 2.95%  birthday  libc-2.19.so       [.] __random_r        
 2.79%  birthday  libc-2.19.so       [.] msort_with_tmp.part.0
 2.10%  birthday  [kernel.kallsyms]  [k] futex_wake 
 1.46%  birthday  [kernel.kallsyms]  [k] system_call  
 1.35%  birthday  [kernel.kallsyms]  [k] get_futex_value_locked 
 1.15%  birthday  [kernel.kallsyms]  [k] futex_wait_setup  
 1.14%  birthday  [kernel.kallsyms]  [k] futex_wait 
</code></pre></div>

<p>Well, that’s suspicious. There aren’t any locks in my code, but there are a whole lot of references to locks in the trace. <em>raw_spin_lock</em> is obviously a candidate, and it’s suspicious to see so many <a href="http://en.wikipedia.org/wiki/Futex">futex</a>-related calls. Something’s taking locks, and the fact that <em>random</em> is near the top of the list makes it a likely candidate. Before we dive in there, though, let’s confirm that we’re doing a lot of syscalls:</p>

<div><pre><code>sudo perf stat -e 'syscalls:sys_e*' ./birthday
</code></pre></div>

<p>Which spits out a long list of system calls, most (like <em>mmap</em>) with just a handful of hits. There are two huge outliers:</p>

<div><pre><code>46,889,267 syscalls:sys_enter_futex
46,889,267 syscalls:sys_exit_futex
</code></pre></div>

<p>That confirms it, something’s taking a lot of futexes. Knowing whether it’s <em>random</em> or not requires a dive into the <em>glibc</em> source, which nearly instantly <a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=stdlib/random.c;h=c75d1d96adecf5ac894ca752a4c54647014bd746;hb=9752c3cdbce2b3b8338abf09c8b9dd9e78908b8a#l194">reveals something suspicious</a>:</p>

<div><pre><code> /* POSIX.1c requires that there is mutual exclusion for the `rand' and
  `srand' functions to prevent concurrent calls from modifying common
   data.  */
</code></pre></div>

<p>And, <a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=stdlib/random.c;h=c75d1d96adecf5ac894ca752a4c54647014bd746;hb=9752c3cdbce2b3b8338abf09c8b9dd9e78908b8a#l292">just a little bit further down</a>:</p>

<div><pre><code> __libc_lock_lock (lock);
 (void) __random_r (&amp;unsafe_state, &amp;retval);
 __libc_lock_unlock (lock);
</code></pre></div>

<p>Getting rid of the locks means getting rid of one of two things: shared state, or the necessity to prevent concurrent modification to that state. It seems like the former is easier: reasoning about a data-race-safe PRNG is tricky. There are a many good ways to get rid of shared state in the PRNG. Linux has one particularly convenient way: the C library exposes a reentrant random number generator called <a href="http://man7.org/linux/man-pages/man3/random_r.3.html">random_r</a> (which is used by <em>random</em>, as you can see from the snippet above). Dropping <em>random_r</em> in place of <em>random</em> has an amazing effect:</p>

<p><img src="https://s3.amazonaws.com/mbrooker-blog-images/threads_bar_second.png" alt=""></p>

<p>As expected, the context switches are way down and instructions per cycle is nicely improved:</p>

<div><pre><code>     4,166,540 L1-dcache-load-misses  # 0.04% of all L1-dcache hits
40,201,461,769 instructions # 1.43  insns per cycle
           572 context-switches
</code></pre></div>

<p>I recognize that spinning on a tight loop on <em>random</em> is a contrived example, but it’s not too far away from reality. Many programs that multi-thread for performance end up with library or system calls inside relatively tight loops. Our intuition about these things tends to follow <a href="http://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl’s law</a>. At worst, it’s tempting to think, these things count as a non-parallel portion of code and lower the maximum achievable parallel speedup. In the real world, though, that’s not the case. Multi-threaded programs can, and very often do, run much more slowly than the equivalent single-threaded program.</p>

<p>It’s just another thing that makes writing multi-threaded code difficult.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PSA: How to keep using adblockers on Chrome and Chromium (124 pts)]]></title>
            <link>https://gist.github.com/velzie/053ffedeaecea1a801a2769ab86ab376</link>
            <guid>40602886</guid>
            <pubDate>Thu, 06 Jun 2024 22:04:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/velzie/053ffedeaecea1a801a2769ab86ab376">https://gist.github.com/velzie/053ffedeaecea1a801a2769ab86ab376</a>, See on <a href="https://news.ycombinator.com/item?id=40602886">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="file-manifest-v2-chrome-md">
    <article itemprop="text">
<ol dir="auto">
<li>google's manifest v3 has no analouge to the <code>webRequestBlocking</code> API, which is neccesary for (effective) adblockers to work</li>
<li>starting in chrome version 127, the transition to mv3 will start cutting off the use of mv2 extensions alltogether</li>
<li>this will inevitably piss of enterprises when their extensions don't work, so the <code>ExtensionManifestV2Availability</code> key was added and will presumably stay forever after enterprises complain enough</li>
</ol>
<p dir="auto">You can use this as a regular user, which will let you keep your mv2 extensions even after they're supposed to stop working</p>
<p dir="auto"><h2 dir="auto">Linux</h2><a id="user-content-linux" aria-label="Permalink: Linux" href="#linux"></a></p>
<p dir="auto">In a terminal, run:</p>
<div dir="auto"><pre>sudo mkdir -p /etc/opt/chrome/policies/managed /etc/opt/chromium/policies/managed
<span>echo</span> <span><span>'</span>{ "ExtensionManifestV2Availability": 2 }<span>'</span></span> <span>|</span> sudo tee /etc/opt/chrome/policies/managed/policy.json /etc/opt/chromium/policies/managed/policy.json</pre></div>
<p dir="auto"><h2 dir="auto">ChromeOS</h2><a id="user-content-chromeos" aria-label="Permalink: ChromeOS" href="#chromeos"></a></p>
<ul dir="auto">
<li>enable developer mode</li>
<li>upon rebooting, go into vt2 (shift+ctrl+right arrow function key)</li>
<li>log in as root</li>
<li>type in <code>/usr/libexec/debugd/helpers/dev_features_rootfs_verification &amp;&amp; reboot</code></li>
<li>upon rebooting, go into vt2 again and log in as root</li>
<li>run the commands from the linux section</li>
</ul>
<p dir="auto"><h2 dir="auto">Windows</h2><a id="user-content-windows" aria-label="Permalink: Windows" href="#windows"></a></p>
<p dir="auto">Open regedit, and create <code>Software\Policies\Google\Chrome\ExtensionManifestV2Availability</code> as a dword set to <code>0x00000002</code></p>
<p dir="auto"><h2 dir="auto">MacOS</h2><a id="user-content-macos" aria-label="Permalink: MacOS" href="#macos"></a></p>
<p dir="auto">In a terminal, run:
<code>defaults write com.google.Chrome ExtensionManifestV2Availability 2</code></p>
<p dir="auto">(note that i haven't tested this for mac. please let me know if it doesn't work)</p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The problem with lying is keeping track of all the lies (104 pts)]]></title>
            <link>https://materialize.com/blog/engineering/keeping-track-lies/</link>
            <guid>40602603</guid>
            <pubDate>Thu, 06 Jun 2024 21:26:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://materialize.com/blog/engineering/keeping-track-lies/">https://materialize.com/blog/engineering/keeping-track-lies/</a>, See on <a href="https://news.ycombinator.com/item?id=40602603">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div>
				<p><img src="https://res.cloudinary.com/mzimgcdn/image/upload/v1673447206/recursion-in-materialize.png" alt="The Problem with Lying is Keeping Track of All the Lies"></p>
				
				<p>Or why clear consistency guarantees are how to stay sane when programming distributed systems.</p>
				</div>
			<p><img src="https://res.cloudinary.com/mzimgcdn/image/upload/v1673447206/recursion-in-materialize.png" alt="The Problem with Lying is Keeping Track of All the Lies"></p></div><div data-sb-field-path=".markdown_content" data-theme="light"><p>“The real difficulty with lying is that you have to keep track of all the lies that you’ve told, and to whom” is a quote I once read that I can’t definitively source (it’s… inconsistently attributed to Mark Twain). It’s stuck with me because it captures the logic as to why it’s so hard to be productive as a programmer in a world of weak isolation models.</p>
<p><em>[Author’s note: database communities use the term “isolation,” and distributed systems communities use the term “strong consistency,” to refer to overlapping concepts. In the rest of this post, I will stick to the database terminology because this is all their fault in the first place.]</em></p>
<h2 id="anomalies">(Anoma)lies</h2>
<p>If you lie to someone, you have to remember all the other things you’ve told to everyone else, and game out who might be talking to whom. Then, you have to reason about how you could get caught. This slows down your thinking and mental agility. Similarly, if you work with data platforms that do <em>not</em> provide strong isolation, you have to carefully consider how this might lead to error states or end-user visible inconsistencies. You’re potentially telling “lies,” and you need to keep track of them.</p>
<p>This slows down your development velocity. Most of your time is spent reasoning about architecture diagrams. You might be giving an inconsistent read to an unsuspecting client. You have to keep track of what services are not communicating through the database. I concede that the “lie” metaphor might be provocative, but it’s a good approximation for what an “anomaly” is in practice. And lying is a solid framework for understanding the concept of database consistency.</p>
<p>Some databases with weak isolation are correctly documented, because they promise nearly nothing, and deliver on this minimal promise. That’s not a lie (“I didn’t <em>say</em> I was going to check, you read into it…”). But in practice, this is misleading for developers. At the very least, it slows them down. As I’ll show later, even the most sophisticated database programmers often get contorted by the subtleties of weak isolation models.</p>
<p>Fundamentally, programming atop weak isolation demands a significant amount of work from developers. The case for building atop strong isolation is this: it enables local reasoning. The other dubiously sourced Mark Twain quote is “If you tell the truth, you don’t have to remember anything”. Databases with strong isolation are almost like oracles. They tell the truth all the time.</p>
<p>Translated to distributed systems, in this context you can interpret “isolation” quite literally: it allows programmers of a single query to reason about that query in isolation. On the other hand, weak isolation requires global reasoning, which means that every programmer writing queries against the system must be on the same page at all times.</p>
<p>When you give an inconsistent read, <a href="https://buttondown.email/jaffray/archive/tpc-see/" target="_blank" rel="external">whether you will get away with it</a> depends on which reads might end up conflicting downstream between other systems. And in a world where the database is accessed by multiple clients, you always need to reason about how they interact further downstream. Any errors will propagate outwards. This means that for any code change, the user has to consider the context of all the other queries that might hit the database.</p>
<h2 id="a-precedence-graphs-of-anomalies">A precedence graphs of (anoma)lies</h2>
<p>Let’s model this formally. One strong isolation level is serializability, which can be achieved in two different ways. First, you can use a database that guarantees serializability. Or second, you can take all the queries that could run on the database, and construct a directed <a href="https://en.wikipedia.org/wiki/Precedence_graph" target="_blank" rel="external">precedence graph</a>, then check this graph for cycles.</p>
<p>This is a nice definition. You can have a set of queries that are conflict-serializable even if they run on a system that provides weaker guarantees. This is because they are cleverly designed not to interfere! A database that provides serializable isolation ensures that no transactions could ever cause a cycle.</p>
<p>But if you have a database that only provides snapshot isolation, it won’t catch one particular shape of cycle, called write skew. You can still ensure that the end result has no anomalies by manually inspecting the set of transactions you run. But this checking process is hard!</p>
<p>In practice, few people are actually doing this with great success (let alone using <a href="https://www.cse.iitb.ac.in/infolab/Data/Courses/CS632/2009/Papers/p492-fekete.pdf" target="_blank" rel="external">the formal algorithm</a>). But given that Oracle only provides snapshot isolation (unhelpfully called “serializable” for historical reasons), there’s plenty of lore around what to be careful of when looking at the set of transactions. On this topic, consult your local Oracle DBA for more information.</p>
<p>As database guarantees get weaker than snapshot isolation, you have a wider set of anomalies that could potentially occur. That leads to even more hard-to-catch shapes in the precedence graph. This requires a wider set of checks that consider the complete set of all possible transactions running against a database. If your database is running in read committed mode (the postgres default), you have to ensure that it doesn’t allow phantom reads, lost updates, or unrepeatable reads, which is difficult<sup><a href="#fn1" id="ref1">1</a>.</sup></p>
<h2 id="honesty-is-often-the-best-policy">Honesty is often the best policy</h2>
<p>Does this line up with all the checks you’re running across your distributed infrastructure? In practice, nobody is doing this to the formal standards of rigor. Nor are they incorporating the checks as part of <em>every</em> change to <em>every</em> database query. But you’re probably reasoning quite a bit about the common transaction paths. You’re drawing out full architecture diagrams and investigating any bugs with distributed traces. You’re looking for inconsistencies and patching them with some fencing around your queries.</p>
<p>My point is this: it is extremely wasteful. The hard truth is that global reasoning is the most expensive thing of all. It involves humans scheduling meetings and staring at the complete set of all possible transactions. Then they must review the proposed transactions by other programmers. And the most expensive part, by far, is the salary hours your employees dump into this process.</p>
<p>That said, weak isolation is not something to categorically exclude. Imagine you’re working on distributed infrastructure at unprecedented scales at one of the largest companies in the world. It might make sense to build bespoke high throughput infrastructure that has to make some careful tradeoffs in exchange for performance.</p>
<p>The FBI and CIA have involved and convoluted protocols to keep their lies straight. But is this an ideal pursuit for a database programmer? There’s an easier way to keep the answers straight. You can build a process to ensure that all subsequent changes do not create any inadvertent anomalies. However, it’s not something to take on casually: it’s a tool of last resort, when you’ve really hit the performance bottlenecks of strongly isolated systems.</p>
<p>Most developers building data infrastructure have the task of&nbsp;<em>presenting upwards</em>. They are in the business of&nbsp;<em>building a database-like internal service</em>. Once they get down to building their own inverted database with stream processors, Redis caches, or queues, they’re on the hook for delivering isolation guarantees. At the very least, they must correctly document and help their teams use the database correctly.</p>
<h2 id="enough-with-the-anomalies">Enough with the anomalies!</h2>
<p>In the particular case of streaming, <a href="https://materialize.com/blog/eventual-consistency-isnt-for-streaming/" target="_blank" rel="external">isolation in stream processing is particularly difficult. </a>Stream processors are typically deployed in situations where the inputs are <em>unbounded</em> and the computation is continuous. Many systems with weak isolation guarantees are designed with the informal goal of eventual consistency (i.e. we’ll get around to the truth… at some point).</p>
<p>But this doesn’t fit well with stream processing: if the inputs aren’t ever settled, eventual consistency could very well result in the outputs never being settled. That’s a large departure from most people’s expectations. Eventual consistency sets a potentially acceptable expectation that deviations are bounded and temporary. That’s very different from the situation of deviations being permanent and unbounded.</p>
<p>It’s possible, using stream processors, caches, key-value stores, and custom programs, to build a system that gives <a href="https://materialize.com/blog/operational-consistency/" target="_blank" rel="external">clear correctness guarantees to end-users</a>. But it’s <a href="https://www.scattered-thoughts.net/writing/internal-consistency-in-streaming-systems/" target="_blank" rel="external">certainly not trivial</a>. This guarantee is <em>strict serializability.</em> Strict serializability is the isolation guarantee that fits best with people’s natural intuitions around concurrency control, and <a href="https://materialize.com/blog/operational-consistency/" target="_blank" rel="external">the one that we deliver at Materialize</a>.</p>
<p>At Materialize, we’ve put in <a href="https://materialize.com/blog/virtual-time-consistency-scalability/" target="_blank" rel="external">quite a lot of work</a> to build a system that is trustworthy, and <a href="https://materialize.com/blog/operational-attributes/" target="_blank" rel="external">we are clear about what that means for you</a>. We’re betting that most of you don’t want to become consistency experts, and certainly don’t want to acquire that expertise during the course of an incident retro. Who wants to keep track of all those lies?</p>
<p>If you’re tired of keeping track of all those lies, <a href="https://console.materialize.com/account/sign-up" target="_blank" rel="external">sign up for a free trial</a> of Materialize to leverage strong consistency.</p>

<p><sup id="fn1">1. Sometimes this can get quite subtle: for instance, Postgres supports an intermediate level called repeatable read. While repeatable read theoretically allows for phantom reads,&nbsp;Postgres goes one step further (https://www.postgresql.org/docs/current/transaction-iso.html). The Postgres implementation disallows phantoms. Since the ANSI standard defines four anomalies, from the table it looks like Postgres’ repeatable read implementation is as good as the serializable implementation, right? And if you do any performance benchmarking, repeatable read is faster than serializable. In practice, serializable is such a large performance hit that few people run Postgres in serializable mode. But not so fast. There is another, secret anomaly, unknown to the ANSI committee, called&nbsp;g2-item (https://news.ycombinator.com/item?id=23500134). And in repeatable read mode,&nbsp;Postgres allows it (https://jepsen.io/analyses/postgresql-12.3). So you’ll have to check your precedence graphs for that one.<a href="#ref1" title="Jump back to footnote 1 in the text.">↩</a></sup></p></div><div data-theme="dark"><h2 data-sb-field-path=".heading">


<span><!-- HTML_TAG_START -->More Articles<!-- HTML_TAG_END --></span>


<!-- HTML_TAG_START --><!-- HTML_TAG_END --></h2>
			<div><div><p>General</p>

			<a href="https://materialize.com/blog/engineering/qa-process-overview"><h3 data-sb-field-path=".heading"><!-- HTML_TAG_START -->Testing Materialize: Our QA Process<!-- HTML_TAG_END --></h3></a>
			<p>The following blog will show you we keep our customers and developers happy with our rigorous QA process, including our tools and testing methods.</p>
			</div><div><p>Technical Article</p>

			<a href="https://materialize.com/blog/engineering/materialize-and-memory"><h3 data-sb-field-path=".heading"><!-- HTML_TAG_START -->Materialize and Memory<!-- HTML_TAG_END --></h3></a>
			<p>We reduced memory requirements for many users by nearly 2x, resulting in significant cost-savings. </p>
			</div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stallman Was Right (105 pts)]]></title>
            <link>https://twitter.com/snowden/status/1798728673698443638</link>
            <guid>40602455</guid>
            <pubDate>Thu, 06 Jun 2024 21:10:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/snowden/status/1798728673698443638">https://twitter.com/snowden/status/1798728673698443638</a>, See on <a href="https://news.ycombinator.com/item?id=40602455">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>