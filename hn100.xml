<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 26 Dec 2023 03:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Fed court rules for retired engineer told by state to not talk about math (137 pts)]]></title>
            <link>https://www.wect.com/2023/12/20/federal-court-decides-favor-retired-engineer-told-by-state-not-talk-about-math-public/</link>
            <guid>38767936</guid>
            <pubDate>Tue, 26 Dec 2023 01:01:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wect.com/2023/12/20/federal-court-decides-favor-retired-engineer-told-by-state-not-talk-about-math-public/">https://www.wect.com/2023/12/20/federal-court-decides-favor-retired-engineer-told-by-state-not-talk-about-math-public/</a>, See on <a href="https://news.ycombinator.com/item?id=38767936">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>WILMINGTON, N.C. (WECT) - Chief Judge Richard Myers ruled on Wednesday that the state violated the First Amendment when it told retired engineer Wayne Nutt to stop expressing his opinions about engineering without a state license, per an Institute for Justice announcement.</p><p>Nutt used his experience as an engineer to give his opinions about the designs of public works on the Internet. The NC Board of Examiners and Surveyors claimed that this was punishable by a misdemeanor unless he obtained a professional engineer’s license from the state.</p><p>“This is a win for more than just me,” said Wayne. “There are a lot of people in the same situation—people who have expertise that they’ve been blocked from talking about. This decision is an affirmation that the First Amendment protects all of our rights to share what we know.”</p><p>You can read the full opinion <a href="https://ij.org/wp-content/uploads/2023/12/Nutt-v.-Ritter-opinion.pdf" target="_blank">online here</a> and find WECT’s previous coverage below:</p><p><i>Copyright 2023 WECT. All rights reserved.</i></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nintendo Network shutdown – The beginning of the end (115 pts)]]></title>
            <link>https://pretendo.network/blog/12-23-23</link>
            <guid>38766570</guid>
            <pubDate>Mon, 25 Dec 2023 22:04:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pretendo.network/blog/12-23-23">https://pretendo.network/blog/12-23-23</a>, See on <a href="https://news.ycombinator.com/item?id=38766570">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

			
			<div>
				<p><span>Published by</span></p><p><img src="https://www.github.com/jonbarrow.png" alt="Jon">
					<span>Jon</span>
				</p>
				<p><span>on
					<span>December 23, 2023</span>
				</span>
			</p></div>

			<h2 id="intro">Intro</h2>
<p>First, we would like to apologize for the lack of blog posts this year. We planned to do more, but other priorities kept getting in the way. We continued to provide updates through our Discord and social medias during this time, but we plan to use this blog more often now.</p>
<p>This blog post will be a bit more serious than previous posts, as the subject matter is rather somber. We apologize for the lack of energy and quips you may have enjoyed in previous posts. This post will have information regarding several aspects of the shutdown, some of which have been covered on other social media posts. Please use the table of contents below to jump to your desired section.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#the-shutdown">The Shutdown</a></li>
<li><a href="#super-mario-maker">Super Mario Maker</a></li>
<li><a href="#new-accounts-prerequisite">New Accounts (Prerequisite)</a></li>
<li><a href="#new-accounts">New Accounts</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="the-shutdown">The Shutdown</h2>
<p>In October of 2023, Nintendo <a href="https://en-americas-support.nintendo.com/app/answers/detail/a_id/63227/~/announcement-of-discontinuation-of-online-services-for-nintendo-3ds-and-wii-u">announced the shutdown of Nintendo Network</a> for April of 2024. It was stated that a specific date and time would be announced later, and as of this post that has not happened yet. There have been no public announcements of any services shutting down early, though Nintendo stated they reserve they right to do so if:</p>
<blockquote>
<p><em>"an event occurs that would make it difficult to continue online services for Nintendo 3DS and Wii U software"</em></p>
</blockquote>
<p>However, it appears that Nintendo has begun a slow rollout of shutdowns. Intentional or not.</p>
<h2 id="super-mario-maker">Super Mario Maker</h2>
<p>This information was also detailed in a <a href="https://twitter.com/PretendoNetwork/status/1736325668412031255">Twitter thread</a>. You may read this there if you wish, or read the repost below.</p>
<p>Some time in early December 2023, Super Mario Maker began throwing error <code>106-0502</code> very often when trying to connect. It is unclear when this truly began, but the earliest occurrences we could find were around the 8th of December. Upon inspection, the cause for this error was clear: the server the game was attempting to connect to no longer existed. Our first assumption was that this was the beginning of the shutdown early, that Nintendo may have started turning off games without notice. After some more research, however, we discovered some users able to still connect.</p>
<p>Games on Nintendo Network function using 3 servers:</p>
<ol>
<li>The account server, which tells the client the location of the game's authentication server and provides the client with a token to connect with.</li>
<li>The game's authentication server, which logs the user in using the internal NEX account (details on this in the <a href="#new-accounts-prerequisite">New Accounts (Prerequisite)</a> section), and tells the client the location of the game's secure server.</li>
<li>The game's secure server, which is where all the game play content happens at.</li>
</ol>
<p>Every game on Nintendo Network uses the same 2 authentication servers. However each game has many dedicated secure servers. When logging in, the authentication server gives one of many randomly selected addresses to connect to. We believe this is some form of load balancing, splitting connections between many servers. The issue resulting in <code>106-0502</code> is that the authentication server is now giving clients addresses to dead servers. So far, we have only been able to identify a single working address for the game.</p>
<p>We believe this is due to Nintendo attempting to scale back how many servers are running for each game, to save on costs as the shutdown date approaches. They most likely made an error in their presumed load balancer to not remove these now dead servers from the pool of available addresses. We believe this was done completely unintentionally, however Nintendo shows no signs of fixing this error.</p>
<h2 id="new-accounts-prerequisite">New Accounts (Prerequisite)</h2>
<p>As briefly touched on in <a href="#super-mario-maker">Super Mario Maker</a>, Nintendo actually uses a series of internal accounts for several services. For games, these are called "NEX accounts". Some background knowledge is required for this section, which will be gone over now.</p>
<p>NEX is the software Nintendo uses for all 3DS and WiiU games (and some Switch games). It is based on a library called Rendez-Vous, made by Canadian software company <a href="https://web.archive.org/web/20040610104624/http://www.quazal.com/modules.php?op=modload&amp;name=Sections&amp;file=index&amp;req=viewarticle&amp;artid=101&amp;page=1">Quazal</a>. Quazal, before being bought out by Ubisoft, would license Rendez-Vous to anyone. Many games, on many platforms, by many developers, all use some variation of Rendez-Vous as it was highly extensible. This is why our server libraries are <a href="https://twitter.com/PretendoNetwork/status/1727016210435641508">theoretically compatible with Ubisoft games</a>.</p>
<p>Nintendo licensed Rendez-Vous and modified it quite a bit, stripping out some more complex features and adding in some custom protocols, rebranding it to NEX. The important takeaway here is that Nintendo did not build this system from scratch, and instead modified a system made for generic game server usage.</p>
<h2 id="new-accounts">New Accounts</h2>
<p>Some time in late December 2023, new accounts could no longer go online in any games on both the WiiU and 3DS.</p>
<p>As mentioned in <a href="#new-accounts-prerequisite">New Accounts (Prerequisite)</a>, Nintendo did not make their game server software from scratch. Rendez-Vous comes with its own account system, likely due to it being designed for use in one-off games. At the time of its development, online multiplayer games were still very new and the concept of a unified account system (such as Nintendo Network or Uplay) spanning many different games made by the same company, was not a thing. Therefore, Nintendo needed to cope with this existing account system in some way.</p>
<p>On the 3DS, the console registers a new NEX account on the Friends server once during the console's setup process. Each 3DS, under normal circumstances, will only ever have a single account at a time (though this is not <em>always</em> true, but not relevant). This is why a NNID is not required to play most games online on the 3DS, as games use your NEX account to login to all game servers. Because of this, a new NEX account will never be created again unless the old one is removed using CFW or by factory resetting the console.</p>
<p>On the WiiU, a new NEX account is created automatically when the NNID is registered, and the NEX account is linked to this NNID. The console then alerts the Friends server of the new NEX account, much like 3DS. Despite using NNIDs, the WiiU also uses these NEX accounts to go online in all games.</p>
<p>Once a NEX account has been created, the Friends server synchronizes this account with all other game servers on Nintendo Network. This is due to the aforementioned account system provided by Rendez-Vous. Due to each game having their own server, and Rendez-Vous not having the concept of a unified account system, each game server has its own account system internally, which is synchronized with other games. It is actually possible to create accounts in other servers besides the Friends server if using a modified client, and those accounts will be usable in other games.</p>
<p>This synchronization process has been stopped. New NEX accounts are no longer being synchronized with any other servers on the network. This affects all games. Because of this, any attempt to connect to any game using an account made after this change was made will result in error <code>106-0303</code> on the WiiU and <code>006-0303</code> on the 3DS, internally called <code>RendezVous::InvalidUsername</code>.</p>
<p>It is not clear at this time whether this was intentional or not.</p>
<h2 id="conclusion">Conclusion</h2>
<p>We ask that you do not spam Nintendo's support lines with these issues. Doing so may cause Nintendo to pull the plug entirely early. There are only 3 possible scenarios:</p>
<ol>
<li>Nintendo is aware of these issues already, and spam would annoy them to the point of pulling the plug.</li>
<li>Nintendo is not aware of these issues, and alerting them may cause them to pull the plug. They have already stated that anything making things "difficult" may come with an early shutdown.</li>
<li>These issues were intentional, and spam would annoy them to the point of pulling the plug.</li>
</ol>


		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How many legs do ten elephants have, if two of them are legless? (158 pts)]]></title>
            <link>https://bard.google.com/share/038d1dc14e78?hl=en</link>
            <guid>38766512</guid>
            <pubDate>Mon, 25 Dec 2023 21:56:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bard.google.com/share/038d1dc14e78?hl=en">https://bard.google.com/share/038d1dc14e78?hl=en</a>, See on <a href="https://news.ycombinator.com/item?id=38766512">Hacker News</a></p>
<div id="readability-page-1" class="page"><header ng-non-bindable="" id="gb" role="banner"><div><div ng-non-bindable="" data-ogsr-up=""><p><a aria-label="Sign in" href="https://accounts.google.com/ServiceLogin?passive=1209600&amp;continue=https://bard.google.com/share/038d1dc14e78?hl%3Den%26ucbcb%3D1&amp;followup=https://bard.google.com/share/038d1dc14e78?hl%3Den%26ucbcb%3D1&amp;hl=en&amp;ec=GAZAkgU" target="_top"><span>Sign in</span></a></p></div></div></header><chat-app id="app-root"></chat-app><div ng-non-bindable=""><p>Google apps</p><p>Main menu</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A recent software update was not successful. Your vehicle cannot be driven (201 pts)]]></title>
            <link>https://twitter.com/danluu/status/1739387245034139692</link>
            <guid>38766178</guid>
            <pubDate>Mon, 25 Dec 2023 21:13:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/danluu/status/1739387245034139692">https://twitter.com/danluu/status/1739387245034139692</a>, See on <a href="https://news.ycombinator.com/item?id=38766178">Hacker News</a></p>
Couldn't get https://twitter.com/danluu/status/1739387245034139692: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Stirling-PDF: local web application to perform various operations on PDFs (292 pts)]]></title>
            <link>https://github.com/Frooodle/Stirling-PDF</link>
            <guid>38765627</guid>
            <pubDate>Mon, 25 Dec 2023 20:02:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Frooodle/Stirling-PDF">https://github.com/Frooodle/Stirling-PDF</a>, See on <a href="https://news.ycombinator.com/item?id=38765627">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/Frooodle/Stirling-PDF/main/docs/stirling.png"><img src="https://raw.githubusercontent.com/Frooodle/Stirling-PDF/main/docs/stirling.png" width="80"></a><br></p><h2 tabindex="-1" dir="auto">Stirling-PDF</h2>

<p dir="auto"><a href="https://hub.docker.com/r/frooodle/s-pdf" rel="nofollow"><img src="https://camo.githubusercontent.com/1166269d9e92a3a8ef7066d21b0ce2a6c7121e4b32ff3f070a0ccf5d3e3ebe79/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f70756c6c732f66726f6f6f646c652f732d706466" alt="Docker Pulls" data-canonical-src="https://img.shields.io/docker/pulls/frooodle/s-pdf"></a>
<a href="https://discord.gg/Cn8pWhQRxZ" rel="nofollow"><img src="https://camo.githubusercontent.com/e94b5453a9362ba070c2d624f30ab2bf95583271e65fcd90e56d10f748783d1e/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313036383633363734383831343438333731383f6c6162656c3d446973636f7264" alt="Discord" data-canonical-src="https://img.shields.io/discord/1068636748814483718?label=Discord"></a>
<a href="https://github.com/Frooodle/Stirling-PDF/"><img src="https://camo.githubusercontent.com/d0d3f1eb1fe5ce6f6501cbff2d5268e25a157b82270681c9fd595fa7ea57643f/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f762f66726f6f6f646c652f732d7064662f6c6174657374" alt="Docker Image Version (tag latest semver)" data-canonical-src="https://img.shields.io/docker/v/frooodle/s-pdf/latest"></a>
<a href="https://github.com/Frooodle/stirling-pdf"><img src="https://camo.githubusercontent.com/7f44a2bae76231cdbe660f80d46afde828d8b889e7c38de6e21d23281e11c540/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f66726f6f6f646c652f737469726c696e672d7064663f7374796c653d736f6369616c" alt="GitHub Repo stars" data-canonical-src="https://img.shields.io/github/stars/frooodle/stirling-pdf?style=social"></a>
<a href="https://www.paypal.com/paypalme/froodleplex" rel="nofollow"><img src="https://camo.githubusercontent.com/9aa713d44fdde8ecaf479b9c9bbd322e787457a7c7102146a6c2ede75027152c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f50617970616c253230446f6e6174652d79656c6c6f773f7374796c653d666c6174266c6f676f3d70617970616c" alt="Paypal Donate" data-canonical-src="https://img.shields.io/badge/Paypal%20Donate-yellow?style=flat&amp;logo=paypal"></a>
<a href="https://github.com/sponsors/Frooodle"><img src="https://camo.githubusercontent.com/b6676fe8b703d9d2f85537103bbb564c34e66201fea6fb017e5e12ae8053215d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f47697468756225323053706f6e736f722d79656c6c6f773f7374796c653d666c6174266c6f676f3d676974687562" alt="Github Sponser" data-canonical-src="https://img.shields.io/badge/Github%20Sponsor-yellow?style=flat&amp;logo=github"></a></p>
<p dir="auto"><a href="https://cloud.digitalocean.com/apps/new?repo=https://github.com/Frooodle/Stirling-PDF/tree/digitalOcean&amp;refcode=c3210994b1af" rel="nofollow"><img src="https://camo.githubusercontent.com/df21703b4229f8d44f76c2d56073657a4ab450ca4566ba5d24d05bf528c298f8/68747470733a2f2f7777772e6465706c6f79746f646f2e636f6d2f646f2d62746e2d626c75652e737667" alt="Deploy to DO" data-canonical-src="https://www.deploytodo.com/do-btn-blue.svg"></a></p>
<p dir="auto">This is a powerful locally hosted web based PDF manipulation tool using docker that allows you to perform various operations on PDF files, such as splitting merging, converting, reorganizing, adding images, rotating, compressing, and more. This locally hosted web application started as a 100% ChatGPT-made application and has evolved to include a wide range of features to handle all your PDF needs.</p>
<p dir="auto">Stirling PDF makes no outbound calls for any record keeping or tracking.</p>
<p dir="auto">All files and PDFs are either purely client side, in server memory only during the execution of the task or within a temporay file only for execution of the task.
Any file which has been downloaded by the user will have already been deleted from the server by that time.</p>
<p dir="auto">Feel free to request any features or bug fixes either in github issues or our <a href="https://discord.gg/Cn8pWhQRxZ" rel="nofollow">Discord</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Frooodle/Stirling-PDF/blob/main/images/stirling-home.png"><img src="https://github.com/Frooodle/Stirling-PDF/raw/main/images/stirling-home.png" alt="stirling-home"></a></p>
<h2 tabindex="-1" dir="auto">Features</h2>
<ul dir="auto">
<li>Dark mode support.</li>
<li>Custom download options (see <a href="https://github.com/Frooodle/Stirling-PDF/blob/main/images/settings.png">here</a> for example)</li>
<li>Parallel file processing and downloads</li>
<li>API for integration with external scripts</li>
<li>Optional Login and Authentication support (see <a href="https://github.com/Frooodle/Stirling-PDF/tree/main#login-authentication">here</a> for documentation)</li>
</ul>
<h2 tabindex="-1" dir="auto"><strong>PDF Features</strong></h2>
<h3 tabindex="-1" dir="auto"><strong>Page Operations</strong></h3>
<ul dir="auto">
<li>View and modify PDFs - View multi page PDFs with custom viewing sorting and searching. Plus on page edit features like annotate, draw and adding text and images. (Using PDF.js with Joxit and Liberation.Liberation fonts)</li>
<li>Full interactive GUI for merging/splitting/rotating/moving PDFs and their pages.</li>
<li>Merge multiple PDFs together into a single resultant file.</li>
<li>Split PDFs into multiple files at specified page numbers or extract all pages as individual files.</li>
<li>Reorganize PDF pages into different orders.</li>
<li>Rotate PDFs in 90-degree increments.</li>
<li>Remove pages.</li>
<li>Multi-page layout (Format PDFs into a multi-paged page).</li>
<li>Scale page contents size by set %.</li>
<li>Adjust Contrast.</li>
<li>Crop PDF.</li>
<li>Auto Split PDF (With physically scanned page dividers).</li>
<li>Extract page(s).</li>
<li>Convert PDF to a single page.</li>
</ul>
<h3 tabindex="-1" dir="auto"><strong>Conversion Operations</strong></h3>
<ul dir="auto">
<li>Convert PDFs to and from images.</li>
<li>Convert any common file to PDF (using LibreOffice).</li>
<li>Convert PDF to Word/Powerpoint/Others (using LibreOffice).</li>
<li>Convert HTML to PDF.</li>
<li>URL to PDF.</li>
<li>Markdown to PDF.</li>
</ul>
<h3 tabindex="-1" dir="auto"><strong>Security &amp; Permissions</strong></h3>
<ul dir="auto">
<li>Add and remove passwords.</li>
<li>Change/set PDF Permissions.</li>
<li>Add watermark(s).</li>
<li>Certify/sign PDFs.</li>
<li>Sanitize PDFs.</li>
<li>Auto-redact text.</li>
</ul>
<h3 tabindex="-1" dir="auto"><strong>Other Operations</strong></h3>
<ul dir="auto">
<li>Add/Generate/Write signatures.</li>
<li>Repair PDFs.</li>
<li>Detect and remove blank pages.</li>
<li>Compare 2 PDFs and show differences in text.</li>
<li>Add images to PDFs.</li>
<li>Compress PDFs to decrease their filesize (Using OCRMyPDF).</li>
<li>Extract images from PDF.</li>
<li>Extract images from Scans.</li>
<li>Add page numbers.</li>
<li>Auto rename file by detecting PDF header text.</li>
<li>OCR on PDF (Using OCRMyPDF).</li>
<li>PDF/A conversion (Using OCRMyPDF).</li>
<li>Edit metadata.</li>
<li>Flatten PDFs.</li>
<li>Get all information on a PDF to view or export as JSON.</li>
</ul>
<p dir="auto">For a overview of the tasks and the technology each uses please view <a href="https://github.com/Frooodle/Stirling-PDF/blob/main/Endpoint-groups.md">Endpoint-groups.md</a>
Hosted instance/demo of the app can be seen <a href="https://pdf.adminforge.de/" rel="nofollow">here</a> hosted by the team at adminforge.de</p>
<h2 tabindex="-1" dir="auto">Technologies used</h2>
<ul dir="auto">
<li>Spring Boot + Thymeleaf</li>
<li>PDFBox</li>
<li><a href="https://www.libreoffice.org/discover/libreoffice/" rel="nofollow">LibreOffice</a> for advanced conversions</li>
<li><a href="https://github.com/ocrmypdf/OCRmyPDF">OcrMyPdf</a></li>
<li>HTML, CSS, JavaScript</li>
<li>Docker</li>
<li>PDF.js</li>
<li>PDF-LIB.js</li>
</ul>
<h2 tabindex="-1" dir="auto">How to use</h2>
<h3 tabindex="-1" dir="auto">Locally</h3>
<p dir="auto">Please view <a href="https://github.com/Frooodle/Stirling-PDF/blob/main/LocalRunGuide.md">https://github.com/Frooodle/Stirling-PDF/blob/main/LocalRunGuide.md</a></p>
<h3 tabindex="-1" dir="auto">Docker / Podman</h3>
<p dir="auto"><a href="https://hub.docker.com/r/frooodle/s-pdf" rel="nofollow">https://hub.docker.com/r/frooodle/s-pdf</a></p>
<p dir="auto">Stirling PDF has 3 different versions, a Full version, Lite, and ultra-Lite. Depending on the types of features you use you may want a smaller image to save on space.
To see what the different versions offer please look at our <a href="https://github.com/Frooodle/Stirling-PDF/blob/main/Version-groups.md">version mapping</a>
For people that don't mind about space optimization just use the latest tag.
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/f62ffe2cde232a8d2ab3fb82349b814e515940c3ef42c7036de69822fc2e0fdc/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f696d6167652d73697a652f66726f6f6f646c652f732d7064662f6c61746573743f6c6162656c3d537469726c696e672d50444625323046756c6c"><img src="https://camo.githubusercontent.com/f62ffe2cde232a8d2ab3fb82349b814e515940c3ef42c7036de69822fc2e0fdc/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f696d6167652d73697a652f66726f6f6f646c652f732d7064662f6c61746573743f6c6162656c3d537469726c696e672d50444625323046756c6c" alt="Docker Image Size (tag)" data-canonical-src="https://img.shields.io/docker/image-size/frooodle/s-pdf/latest?label=Stirling-PDF%20Full"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/a9d3adb2e0126586820c4a13dc201254b77d4cec8accd44d579337eeab51a614/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f696d6167652d73697a652f66726f6f6f646c652f732d7064662f6c61746573742d6c6974653f6c6162656c3d537469726c696e672d5044462532304c697465"><img src="https://camo.githubusercontent.com/a9d3adb2e0126586820c4a13dc201254b77d4cec8accd44d579337eeab51a614/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f696d6167652d73697a652f66726f6f6f646c652f732d7064662f6c61746573742d6c6974653f6c6162656c3d537469726c696e672d5044462532304c697465" alt="Docker Image Size (tag)" data-canonical-src="https://img.shields.io/docker/image-size/frooodle/s-pdf/latest-lite?label=Stirling-PDF%20Lite"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/e62edb45593482bb4a6ce9e78882bd07f8995dbadf693926df2528773dd57f2a/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f696d6167652d73697a652f66726f6f6f646c652f732d7064662f6c61746573742d756c7472612d6c6974653f6c6162656c3d537469726c696e672d504446253230556c7472612d4c697465"><img src="https://camo.githubusercontent.com/e62edb45593482bb4a6ce9e78882bd07f8995dbadf693926df2528773dd57f2a/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f696d6167652d73697a652f66726f6f6f646c652f732d7064662f6c61746573742d756c7472612d6c6974653f6c6162656c3d537469726c696e672d504446253230556c7472612d4c697465" alt="Docker Image Size (tag)" data-canonical-src="https://img.shields.io/docker/image-size/frooodle/s-pdf/latest-ultra-lite?label=Stirling-PDF%20Ultra-Lite"></a></p>
<p dir="auto">Docker Run</p>
<div data-snippet-clipboard-copy-content="docker run -d \
  -p 8080:8080 \
  -v /location/of/trainingData:/usr/share/tesseract-ocr/5/tessdata \
  -v /location/of/extraConfigs:/configs \
  -v /location/of/logs:/logs \
  -e DOCKER_ENABLE_SECURITY=false \
  --name stirling-pdf \
  frooodle/s-pdf:latest
  
  
  Can also add these for customisation but are not required
  
  -v /location/of/customFiles:/customFiles \"><pre><code>docker run -d \
  -p 8080:8080 \
  -v /location/of/trainingData:/usr/share/tesseract-ocr/5/tessdata \
  -v /location/of/extraConfigs:/configs \
  -v /location/of/logs:/logs \
  -e DOCKER_ENABLE_SECURITY=false \
  --name stirling-pdf \
  frooodle/s-pdf:latest
  
  
  Can also add these for customisation but are not required
  
  -v /location/of/customFiles:/customFiles \
</code></pre></div>
<p dir="auto">Docker Compose</p>
<div data-snippet-clipboard-copy-content="version: '3.3'
services:
  stirling-pdf:
    image: frooodle/s-pdf:latest
    ports:
      - '8080:8080'
    volumes:
      - /location/of/trainingData:/usr/share/tesseract-ocr/5/tessdata #Required for extra OCR languages
      - /location/of/extraConfigs:/configs
#      - /location/of/customFiles:/customFiles/
#      - /location/of/logs:/logs/
    environment:
      - DOCKER_ENABLE_SECURITY=false"><pre><code>version: '3.3'
services:
  stirling-pdf:
    image: frooodle/s-pdf:latest
    ports:
      - '8080:8080'
    volumes:
      - /location/of/trainingData:/usr/share/tesseract-ocr/5/tessdata #Required for extra OCR languages
      - /location/of/extraConfigs:/configs
#      - /location/of/customFiles:/customFiles/
#      - /location/of/logs:/logs/
    environment:
      - DOCKER_ENABLE_SECURITY=false
</code></pre></div>
<p dir="auto">Note: Podman is CLI-compatible with Docker, so simply replace "docker" with "podman".</p>
<h2 tabindex="-1" dir="auto">Enable OCR/Compression feature</h2>
<p dir="auto">Please view <a href="https://github.com/Frooodle/Stirling-PDF/blob/main/HowToUseOCR.md">https://github.com/Frooodle/Stirling-PDF/blob/main/HowToUseOCR.md</a></p>
<h2 tabindex="-1" dir="auto">Want to add your own language?</h2>
<p dir="auto">Stirling PDF currently supports 20!</p>
<ul dir="auto">
<li>English (English) (en_GB)</li>
<li>English (US) (en_US)</li>
<li>Arabic (العربية) (ar_AR)</li>
<li>German (Deutsch) (de_DE)</li>
<li>French (Français) (fr_FR)</li>
<li>Spanish (Español) (es_ES)</li>
<li>Chinese (简体中文) (zh_CN)</li>
<li>Catalan (Català) (ca_CA)</li>
<li>Italian (Italiano) (it_IT)</li>
<li>Swedish (Svenska) (sv_SE)</li>
<li>Polish (Polski) (pl_PL)</li>
<li>Romanian (Română) (ro_RO)</li>
<li>Korean (한국어) (ko_KR)</li>
<li>Portuguese Brazilian (Português) (pt_BR)</li>
<li>Russian (Русский) (ru_RU)</li>
<li>Basque (Euskara) (eu_ES)</li>
<li>Japanese (日本語) (ja_JP)</li>
<li>Dutch (Nederlands) (nl_NL)</li>
<li>Greek (el_GR)</li>
<li>Turkish (Türkçe) (tr_TR)</li>
</ul>
<p dir="auto">If you want to add your own language to Stirling-PDF please refer
<a href="https://github.com/Frooodle/Stirling-PDF/blob/main/HowToAddNewLanguage.md">https://github.com/Frooodle/Stirling-PDF/blob/main/HowToAddNewLanguage.md</a></p>
<p dir="auto">And please create a PR to merge it back in so others can use it!</p>
<h2 tabindex="-1" dir="auto">How to View</h2>
<ol dir="auto">
<li>Open a web browser and navigate to <code>http://localhost:8080/</code></li>
<li>Use the application by following the instructions on the website.</li>
</ol>
<h2 tabindex="-1" dir="auto">Customisation</h2>
<p dir="auto">Stirling PDF allows easy customization of the app.
Includes things like</p>
<ul dir="auto">
<li>Custom application name</li>
<li>Custom slogans, icons, images, and even custom HTML (via file overrides)</li>
</ul>
<p dir="auto">There are two options for this, either using the generated settings file <code>settings.yml</code>
This file is located in the <code>/configs</code> directory and follows standard YAML formatting</p>
<p dir="auto">Environment variables are also supported and would override the settings file
For example in the settings.yml you have</p>
<div data-snippet-clipboard-copy-content="system:
  defaultLocale: 'en-US'"><pre><code>system:
  defaultLocale: 'en-US'
</code></pre></div>
<p dir="auto">To have this via an environment variable you would have <code>SYSTEM_DEFAULTLOCALE</code></p>
<p dir="auto">The Current list of settings is</p>
<div data-snippet-clipboard-copy-content="security:
  enableLogin: false # set to 'true' to enable login
  csrfDisabled: true

system:
  defaultLocale: 'en-US' # Set the default language (e.g. 'de-DE', 'fr-FR', etc)
  googlevisibility: false # 'true' to allow Google visibility (via robots.txt), 'false' to disallow
  customStaticFilePath: '/customFiles/static/' # Directory path for custom static files

#ui:
#  appName: exampleAppName # Application's visible name
#  homeDescription: I am a description # Short description or tagline shown on homepage.
#  appNameNavbar: navbarName # Name displayed on the navigation bar

endpoints:
  toRemove: [] # List endpoints to disable (e.g. ['img-to-pdf', 'remove-pages'])
  groupsToRemove: [] # List groups to disable (e.g. ['LibreOffice'])

metrics:
  enabled: true # 'true' to enable Info APIs endpoints (view http://localhost:8080/swagger-ui/index.html#/API to learn more), 'false' to disable"><pre><code>security:
  enableLogin: false # set to 'true' to enable login
  csrfDisabled: true

system:
  defaultLocale: 'en-US' # Set the default language (e.g. 'de-DE', 'fr-FR', etc)
  googlevisibility: false # 'true' to allow Google visibility (via robots.txt), 'false' to disallow
  customStaticFilePath: '/customFiles/static/' # Directory path for custom static files

#ui:
#  appName: exampleAppName # Application's visible name
#  homeDescription: I am a description # Short description or tagline shown on homepage.
#  appNameNavbar: navbarName # Name displayed on the navigation bar

endpoints:
  toRemove: [] # List endpoints to disable (e.g. ['img-to-pdf', 'remove-pages'])
  groupsToRemove: [] # List groups to disable (e.g. ['LibreOffice'])

metrics:
  enabled: true # 'true' to enable Info APIs endpoints (view http://localhost:8080/swagger-ui/index.html#/API to learn more), 'false' to disable
</code></pre></div>
<h3 tabindex="-1" dir="auto">Extra notes</h3>
<ul dir="auto">
<li>Endpoints. Currently, the endpoints ENDPOINTS_TO_REMOVE and GROUPS_TO_REMOVE can include comma separate lists of endpoints and groups to disable as example ENDPOINTS_TO_REMOVE=img-to-pdf,remove-pages would disable both image-to-pdf and remove pages, GROUPS_TO_REMOVE=LibreOffice Would disable all things that use LibreOffice. You can see a list of all endpoints and groups <a href="https://github.com/Frooodle/Stirling-PDF/blob/main/Endpoint-groups.md">here</a></li>
<li>customStaticFilePath. Customise static files such as the app logo by placing files in the /customFiles/static/ directory. An example of customising app logo is placing a /customFiles/static/favicon.svg to override current SVG. This can be used to change any images/icons/css/fonts/js etc in Stirling-PDF</li>
</ul>
<h3 tabindex="-1" dir="auto">Environment only parameters</h3>
<ul dir="auto">
<li><code>SYSTEM_ROOTURIPATH</code> ie set to <code>/pdf-app</code> to Set the application's root URI to <code>localhost:8080/pdf-app</code></li>
<li><code>SYSTEM_CONNECTIONTIMEOUTMINUTES</code> to set custom connection timeout values</li>
<li><code>DOCKER_ENABLE_SECURITY</code> to tell docker to download security jar (required as true for auth login)</li>
</ul>
<h2 tabindex="-1" dir="auto">API</h2>
<p dir="auto">For those wanting to use Stirling-PDFs backend API to link with their own custom scripting to edit PDFs you can view all existing API documentation
<a href="https://app.swaggerhub.com/apis-docs/Frooodle/Stirling-PDF/" rel="nofollow">here</a> or navigate to /swagger-ui/index.html of your stirling-pdf instance for your versions documentation (Or by following the API button in your settings of Stirling-PDF)</p>
<h2 tabindex="-1" dir="auto">Login authentication</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Frooodle/Stirling-PDF/blob/main/images/login-light.png"><img src="https://github.com/Frooodle/Stirling-PDF/raw/main/images/login-light.png" alt="stirling-login"></a></p>
<h3 tabindex="-1" dir="auto">Prerequisites:</h3>
<ul dir="auto">
<li>User must have the folder ./configs volumed within docker so that it is retained during updates.</li>
<li>Docker uses must download the security jar version by setting <code>DOCKER_ENABLE_SECURITY</code> to <code>true</code> in environment variables.</li>
<li>Then either enable login via the settings.yml file or via setting <code>SECURITY_ENABLE_LOGIN</code> to <code>true</code></li>
<li>Now the initial user will be generated with username <code>admin</code> and password <code>stirling</code>. On login you will be forced to change the password to a new one. You can also use the environment variables <code>SECURITY_INITIALLOGIN_USERNAME</code> and  <code>SECURITY_INITIALLOGIN_PASSWORD</code> to set your own straight away (Recommended to remove them after user creation).</li>
</ul>
<p dir="auto">Once the above has been done, on restart, a new stirling-pdf-DB.mv.db will show if everything worked.</p>
<p dir="auto">When you login to Stirling PDF you will be redirected to /login page to login with those default credentials. After login everything should function as normal</p>
<p dir="auto">To access your account settings go to Account settings in the settings cog menu (top right in navbar) This Account settings menu is also where you find your API key.</p>
<p dir="auto">To add new users go to the bottom of Account settings and hit 'Admin Settings', here you can add new users. The different roles mentioned within this are for rate limiting. This is a Work in progress which will be expanding on more in future</p>
<p dir="auto">For API usage you must provide a header with 'X-API-Key' and the associated API key for that user.</p>
<h2 tabindex="-1" dir="auto">FAQ</h2>
<h3 tabindex="-1" dir="auto">Q1: What are your planned features?</h3>
<ul dir="auto">
<li>Progress bar/Tracking</li>
<li>Full custom logic pipelines to combine multiple operations together.</li>
<li>Folder support with auto scanning to perform operations on</li>
<li>Redact text (Via UI not just automated way)</li>
<li>Add Forms</li>
<li>Multi page layout (Stich PDF pages together) support x rows y columns and custom page sizing</li>
<li>Fill forms mannual and automatic</li>
</ul>
<h3 tabindex="-1" dir="auto">Q2: Why is my application downloading .htm files?</h3>
<p dir="auto">This is a issue caused commonly by your NGINX congifuration. The default file upload size for NGINX is 1MB, you need to add the following in your Nginx sites-available file. <code>client_max_body_size SIZE;</code> Where "SIZE" is 50M for example for 50MB files.</p>
<h3 tabindex="-1" dir="auto">Q3: Why is my download timing out</h3>
<p dir="auto">NGINX has timeout values by default so if you are running Stirling-PDF behind NGINX you may need to set a timeout value such as adding the config <code>proxy_read_timeout 3600;</code></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DIY Night Clock Projector (2018) (130 pts)]]></title>
            <link>https://microengineer.eu/2018/05/01/diy-night-clock-projector/</link>
            <guid>38765196</guid>
            <pubDate>Mon, 25 Dec 2023 19:12:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://microengineer.eu/2018/05/01/diy-night-clock-projector/">https://microengineer.eu/2018/05/01/diy-night-clock-projector/</a>, See on <a href="https://news.ycombinator.com/item?id=38765196">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-52">
			<!-- .entry-header -->
		<div>
			<p>A Clock Projector can project the time to a ceiling in the night.</p>
<p><img data-attachment-id="66" data-permalink="https://microengineer.eu/2018/05/01/diy-night-clock-projector/dsc00244/" data-orig-file="https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg" data-orig-size="1200,797" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="DSC00244" data-image-description="" data-image-caption="" data-medium-file="https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=300" data-large-file="https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=1000" src="https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=1000" alt="DSC00244" srcset="https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg 1200w, https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=150&amp;h=100 150w, https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=300&amp;h=199 300w, https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=768&amp;h=510 768w, https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=1024&amp;h=680 1024w" sizes="(max-width: 1200px) 100vw, 1200px"></p>
<p>There are lots of commercial alarm clocks with integrated clock projector on the market but I thought, it would be fun to build one myself.</p>
<p>Moreover it was a good project for becoming&nbsp;accustomed to the process of 3d-designing cases which can be 3d printed and to learn about designing tolerances.</p>
<p>The principle is easy – basically it works like a video beamer (or any other projecting clock^^).</p>
<p><img data-attachment-id="80" data-permalink="https://microengineer.eu/2018/05/01/diy-night-clock-projector/principle/" data-orig-file="https://microengineer332294991.files.wordpress.com/2018/05/principle.png" data-orig-size="600,364" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="principle" data-image-description="" data-image-caption="" data-medium-file="https://microengineer332294991.files.wordpress.com/2018/05/principle.png?w=300" data-large-file="https://microengineer332294991.files.wordpress.com/2018/05/principle.png?w=600" src="https://microengineer332294991.files.wordpress.com/2018/05/principle.png?w=394&amp;h=239" alt="principle" width="394" height="239" srcset="https://microengineer332294991.files.wordpress.com/2018/05/principle.png?w=394&amp;h=239 394w, https://microengineer332294991.files.wordpress.com/2018/05/principle.png?w=150&amp;h=91 150w, https://microengineer332294991.files.wordpress.com/2018/05/principle.png?w=300&amp;h=182 300w, https://microengineer332294991.files.wordpress.com/2018/05/principle.png 600w" sizes="(max-width: 394px) 100vw, 394px"></p>
<h2>LCD and Calculations</h2>
<p>I choosed a small negative (background black) 64×32 LCD which has the dimensions of just 15mm x 12mm (active area 11.18mm x 5.58mm).</p>
<p><img data-attachment-id="53" data-permalink="https://microengineer.eu/2018/05/01/diy-night-clock-projector/lcd/" data-orig-file="https://microengineer332294991.files.wordpress.com/2018/05/lcd.png" data-orig-size="398,347" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lcd" data-image-description="" data-image-caption="" data-medium-file="https://microengineer332294991.files.wordpress.com/2018/05/lcd.png?w=300" data-large-file="https://microengineer332294991.files.wordpress.com/2018/05/lcd.png?w=398" src="https://microengineer332294991.files.wordpress.com/2018/05/lcd.png?w=1000" alt="lcd" srcset="https://microengineer332294991.files.wordpress.com/2018/05/lcd.png 398w, https://microengineer332294991.files.wordpress.com/2018/05/lcd.png?w=150&amp;h=131 150w, https://microengineer332294991.files.wordpress.com/2018/05/lcd.png?w=300&amp;h=262 300w" sizes="(max-width: 398px) 100vw, 398px"></p>
<p>The goal was to build a complete projector with not more than 50mm x 50mm x 50mm (which I didn’t managed … But close to^^).</p>
<p>A small LCD has the advantage that everything becomes smaller and cheaper – this influences heavily costs for optics because a smaller LCD needs smaller optics to project an low distorted image.</p>
<p>Moreover a smaller LCD needs smaller focal length for a decent sized imaged on the ceiling. A good distance would be 2m from LCD to ceiling.</p>
<p>The formula for image width depending from the focal length is defined as:</p>
<p><img data-attachment-id="78" data-permalink="https://microengineer.eu/2018/05/01/diy-night-clock-projector/lens3-svg/" data-orig-file="https://microengineer332294991.files.wordpress.com/2018/05/lens3-svg.png" data-orig-size="600,286" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Lens3.svg" data-image-description="" data-image-caption="" data-medium-file="https://microengineer332294991.files.wordpress.com/2018/05/lens3-svg.png?w=300" data-large-file="https://microengineer332294991.files.wordpress.com/2018/05/lens3-svg.png?w=600" loading="lazy" src="https://microengineer332294991.files.wordpress.com/2018/05/lens3-svg.png?w=1000" alt="Lens3.svg" srcset="https://microengineer332294991.files.wordpress.com/2018/05/lens3-svg.png 600w, https://microengineer332294991.files.wordpress.com/2018/05/lens3-svg.png?w=150&amp;h=72 150w, https://microengineer332294991.files.wordpress.com/2018/05/lens3-svg.png?w=300&amp;h=143 300w" sizes="(max-width: 600px) 100vw, 600px"></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7Bf%7D%3D%5Cfrac%7B1%7D%7BS_1%7D%2B%5Cfrac%7B1%7D%7BS_2%7D%5Chspace%7B20mm%7D%5Cfrac%7BW_1%7D%7BW_2%7D%3D%5Cfrac%7BS_1%7D%7BS_2%7D+&amp;bg=fffdfd&amp;fg=606666&amp;s=4&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7Bf%7D%3D%5Cfrac%7B1%7D%7BS_1%7D%2B%5Cfrac%7B1%7D%7BS_2%7D%5Chspace%7B20mm%7D%5Cfrac%7BW_1%7D%7BW_2%7D%3D%5Cfrac%7BS_1%7D%7BS_2%7D+&amp;bg=fffdfd&amp;fg=606666&amp;s=4&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7Bf%7D%3D%5Cfrac%7B1%7D%7BS_1%7D%2B%5Cfrac%7B1%7D%7BS_2%7D%5Chspace%7B20mm%7D%5Cfrac%7BW_1%7D%7BW_2%7D%3D%5Cfrac%7BS_1%7D%7BS_2%7D+&amp;bg=fffdfd&amp;fg=606666&amp;s=4&amp;c=20201002&amp;zoom=4.5 4x" alt="\frac{1}{f}=\frac{1}{S_1}+\frac{1}{S_2}\hspace{20mm}\frac{W_1}{W_2}=\frac{S_1}{S_2} "></p>
<p>with:<br>
– S2 distance from lens to LCD and<br>
– S1 distance from lens to ceiling<br>
– W2 is the width of the LCD<br>
– W1 is the width of the projected image</p>
<p>The formulas show that the smaller the focal length the larger the projected image will be.</p>
<p>I decided to go for 25mm because there are cheap lenses which can be obtained for about $12 in china.</p>
<p>For our values that would magnify the image by about x80 – 11.1mm LCD width would become 88.1cm image width on the ceiling in a distance of 2m.</p>
<h2>Light and Condensor Lens</h2>
<p>It was not really clear how strong a LED has to be in order to get a reasonable well readable picture in the night on the ceiling.</p>
<p>To be sure – actually I wasn’t really – I decided to use a high power LED with 1W and use a cheap chinese condensor lense to parallelize the light before it passes the LCD (this has do be done anyway but a condensor lens makes it possible to use more light because condensors are shaped in a way that allowes to get the lens as near to the LED as possible – so catching more light).</p>

<p>The two pictures show the condensor-lense which is directly mounted to the PCB the resulting light spot on the ceiling. It is a really gread lens which is made for my LED – so it fits perfectly and parallelizes the light nicely.</p>
<h2>Electronics Construction</h2>
<p>Two PCBs were designed – one holding the LCD and the actual projecting board.</p>

<p>The latter is equipped with 1W LED driver, STM32F103 Cortex ARM, a rotary encoder (for changing settings like brightness, standby-timer, time, …), USB, IR (both not used yet).</p>
<h2>Mechanics Construction</h2>
<p>Originally, I aimed for 50mm x 50mm x 50mm but I only managed to get to 60mm x 60mm x 60mm 😥 😉</p>
<p>Here an overview about all I designed:</p>
<p><img data-attachment-id="68" data-permalink="https://microengineer.eu/2018/05/01/diy-night-clock-projector/spectacle-j23956/" data-orig-file="https://microengineer332294991.files.wordpress.com/2018/05/spectacle-j23956.png" data-orig-size="1028,647" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Spectacle.J23956" data-image-description="" data-image-caption="" data-medium-file="https://microengineer332294991.files.wordpress.com/2018/05/spectacle-j23956.png?w=300" data-large-file="https://microengineer332294991.files.wordpress.com/2018/05/spectacle-j23956.png?w=1000" loading="lazy" src="https://microengineer332294991.files.wordpress.com/2018/05/spectacle-j23956.png?w=1000" alt="Spectacle.J23956" srcset="https://microengineer332294991.files.wordpress.com/2018/05/spectacle-j23956.png 1028w, https://microengineer332294991.files.wordpress.com/2018/05/spectacle-j23956.png?w=150&amp;h=94 150w, https://microengineer332294991.files.wordpress.com/2018/05/spectacle-j23956.png?w=300&amp;h=189 300w, https://microengineer332294991.files.wordpress.com/2018/05/spectacle-j23956.png?w=768&amp;h=483 768w, https://microengineer332294991.files.wordpress.com/2018/05/spectacle-j23956.png?w=1024&amp;h=644 1024w" sizes="(max-width: 1028px) 100vw, 1028px"></p>
<p>From left to right: Case with DIY projection lens (I skip this part – it worked but not really well), Sony E-Mount, C-Mount. In the middle the rest.</p>
<h3>LCD-Holder</h3>
<p>A custom LCD-holder was designed to perfectly mount the LCD on the right place on the PCB.</p>

<h3>Case – C-Mount Variant</h3>
<p>There are incredibly cheap chinase C-Mount lenses with a focal length of 25mm. They are sooo cheap that image quality is really really bad when using for fotography.</p>
<p><img data-attachment-id="69" data-permalink="https://microengineer.eu/2018/05/01/diy-night-clock-projector/23380257_1223416981124165_4793755427854490814_n/" data-orig-file="https://microengineer332294991.files.wordpress.com/2018/05/23380257_1223416981124165_4793755427854490814_n.jpg" data-orig-size="352,305" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="23380257_1223416981124165_4793755427854490814_n" data-image-description="" data-image-caption="" data-medium-file="https://microengineer332294991.files.wordpress.com/2018/05/23380257_1223416981124165_4793755427854490814_n.jpg?w=300" data-large-file="https://microengineer332294991.files.wordpress.com/2018/05/23380257_1223416981124165_4793755427854490814_n.jpg?w=352" loading="lazy" src="https://microengineer332294991.files.wordpress.com/2018/05/23380257_1223416981124165_4793755427854490814_n.jpg?w=1000" alt="23380257_1223416981124165_4793755427854490814_n" srcset="https://microengineer332294991.files.wordpress.com/2018/05/23380257_1223416981124165_4793755427854490814_n.jpg 352w, https://microengineer332294991.files.wordpress.com/2018/05/23380257_1223416981124165_4793755427854490814_n.jpg?w=150&amp;h=130 150w, https://microengineer332294991.files.wordpress.com/2018/05/23380257_1223416981124165_4793755427854490814_n.jpg?w=300&amp;h=260 300w" sizes="(max-width: 352px) 100vw, 352px"></p>
<p>But surprisingly it works (almost) perfect for the Mini DIY Projector 😀</p>
<p><img data-attachment-id="70" data-permalink="https://microengineer.eu/2018/05/01/diy-night-clock-projector/23559568_1223771867755343_5931761190105667111_n/" data-orig-file="https://microengineer332294991.files.wordpress.com/2018/05/23559568_1223771867755343_5931761190105667111_n.jpg" data-orig-size="307,726" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="23559568_1223771867755343_5931761190105667111_n" data-image-description="" data-image-caption="" data-medium-file="https://microengineer332294991.files.wordpress.com/2018/05/23559568_1223771867755343_5931761190105667111_n.jpg?w=127" data-large-file="https://microengineer332294991.files.wordpress.com/2018/05/23559568_1223771867755343_5931761190105667111_n.jpg?w=307" loading="lazy" src="https://microengineer332294991.files.wordpress.com/2018/05/23559568_1223771867755343_5931761190105667111_n.jpg?w=1000" alt="23559568_1223771867755343_5931761190105667111_n" srcset="https://microengineer332294991.files.wordpress.com/2018/05/23559568_1223771867755343_5931761190105667111_n.jpg 307w, https://microengineer332294991.files.wordpress.com/2018/05/23559568_1223771867755343_5931761190105667111_n.jpg?w=63&amp;h=150 63w, https://microengineer332294991.files.wordpress.com/2018/05/23559568_1223771867755343_5931761190105667111_n.jpg?w=127&amp;h=300 127w" sizes="(max-width: 307px) 100vw, 307px"></p>
<p>The pillow-effect (optical distortion where the edges are not straight but bent outwards) is almost neglectable – resulting a much better image than I expected (after reading reviews to this lense)</p>
<p><img data-attachment-id="71" data-permalink="https://microengineer.eu/2018/05/01/diy-night-clock-projector/23559460_1223772024421994_2585757183464992038_n/" data-orig-file="https://microengineer332294991.files.wordpress.com/2018/05/23559460_1223772024421994_2585757183464992038_n.jpg" data-orig-size="420,272" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="23559460_1223772024421994_2585757183464992038_n" data-image-description="" data-image-caption="" data-medium-file="https://microengineer332294991.files.wordpress.com/2018/05/23559460_1223772024421994_2585757183464992038_n.jpg?w=300" data-large-file="https://microengineer332294991.files.wordpress.com/2018/05/23559460_1223772024421994_2585757183464992038_n.jpg?w=420" loading="lazy" src="https://microengineer332294991.files.wordpress.com/2018/05/23559460_1223772024421994_2585757183464992038_n.jpg?w=1000" alt="23559460_1223772024421994_2585757183464992038_n" srcset="https://microengineer332294991.files.wordpress.com/2018/05/23559460_1223772024421994_2585757183464992038_n.jpg 420w, https://microengineer332294991.files.wordpress.com/2018/05/23559460_1223772024421994_2585757183464992038_n.jpg?w=150&amp;h=97 150w, https://microengineer332294991.files.wordpress.com/2018/05/23559460_1223772024421994_2585757183464992038_n.jpg?w=300&amp;h=194 300w" sizes="(max-width: 420px) 100vw, 420px"></p>
<h3>Case – Sony E-Mount Variant</h3>
<p>Just for fun – and because I have a 3d printer which works reliably without much attention – I did a variant for Sony E-Mount.</p>
<p><img data-attachment-id="67" data-permalink="https://microengineer.eu/2018/05/01/diy-night-clock-projector/spectacle-tw9321/" data-orig-file="https://microengineer332294991.files.wordpress.com/2018/05/spectacle-tw9321.png" data-orig-size="819,702" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Spectacle.Tw9321" data-image-description="" data-image-caption="" data-medium-file="https://microengineer332294991.files.wordpress.com/2018/05/spectacle-tw9321.png?w=300" data-large-file="https://microengineer332294991.files.wordpress.com/2018/05/spectacle-tw9321.png?w=819" loading="lazy" src="https://microengineer332294991.files.wordpress.com/2018/05/spectacle-tw9321.png?w=397&amp;h=340" alt="Spectacle.Tw9321" width="397" height="340" srcset="https://microengineer332294991.files.wordpress.com/2018/05/spectacle-tw9321.png?w=397&amp;h=340 397w, https://microengineer332294991.files.wordpress.com/2018/05/spectacle-tw9321.png?w=794&amp;h=680 794w, https://microengineer332294991.files.wordpress.com/2018/05/spectacle-tw9321.png?w=150&amp;h=129 150w, https://microengineer332294991.files.wordpress.com/2018/05/spectacle-tw9321.png?w=300&amp;h=257 300w, https://microengineer332294991.files.wordpress.com/2018/05/spectacle-tw9321.png?w=768&amp;h=658 768w" sizes="(max-width: 397px) 100vw, 397px"></p>
<p>Here the projector with Walimex Pro 10mm 2.8 lens.</p>
<p><img data-attachment-id="65" data-permalink="https://microengineer.eu/2018/05/01/diy-night-clock-projector/23380218_1219804668152063_8622113328646516671_n/" data-orig-file="https://microengineer332294991.files.wordpress.com/2018/05/23380218_1219804668152063_8622113328646516671_n.jpg" data-orig-size="462,583" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="23380218_1219804668152063_8622113328646516671_n" data-image-description="" data-image-caption="" data-medium-file="https://microengineer332294991.files.wordpress.com/2018/05/23380218_1219804668152063_8622113328646516671_n.jpg?w=238" data-large-file="https://microengineer332294991.files.wordpress.com/2018/05/23380218_1219804668152063_8622113328646516671_n.jpg?w=462" loading="lazy" src="https://microengineer332294991.files.wordpress.com/2018/05/23380218_1219804668152063_8622113328646516671_n.jpg?w=264&amp;h=333" alt="23380218_1219804668152063_8622113328646516671_n" width="264" height="333" srcset="https://microengineer332294991.files.wordpress.com/2018/05/23380218_1219804668152063_8622113328646516671_n.jpg?w=264&amp;h=333 264w, https://microengineer332294991.files.wordpress.com/2018/05/23380218_1219804668152063_8622113328646516671_n.jpg?w=119&amp;h=150 119w, https://microengineer332294991.files.wordpress.com/2018/05/23380218_1219804668152063_8622113328646516671_n.jpg?w=238&amp;h=300 238w, https://microengineer332294991.files.wordpress.com/2018/05/23380218_1219804668152063_8622113328646516671_n.jpg 462w" sizes="(max-width: 264px) 100vw, 264px"></p>
<p>I have to admit – it isn’t that bright in reality but it’s still very readable although it is so large.</p>
<p><img data-attachment-id="66" data-permalink="https://microengineer.eu/2018/05/01/diy-night-clock-projector/dsc00244/" data-orig-file="https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg" data-orig-size="1200,797" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="DSC00244" data-image-description="" data-image-caption="" data-medium-file="https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=300" data-large-file="https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=1000" loading="lazy" src="https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=408&amp;h=271" alt="DSC00244" width="408" height="271" srcset="https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=408&amp;h=271 408w, https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=816&amp;h=542 816w, https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=150&amp;h=100 150w, https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=300&amp;h=199 300w, https://microengineer332294991.files.wordpress.com/2018/05/dsc00244.jpg?w=768&amp;h=510 768w" sizes="(max-width: 408px) 100vw, 408px"></p>
<p>The image has more than 2m in width! And distortions almost non-existent 🙂</p>
<h2>Downloads</h2>
<p>Followig GitHub-Repository contains:<br>
– <strong>Schematic</strong><br>
– <strong>Layout<br>
</strong>– <strong>Bill of material</strong><br>
– <strong>STM32 Cortex ARM Source</strong><br>
– <strong>3D-STL-Files</strong><br>
– <strong>Images</strong></p>
<p><a href="https://github.com/shufps/diy-projector-clock" target="_blank" rel="noopener">Link to GitHub Repository</a></p>
<p><a href="https://www.thingiverse.com/thing:2887852">STL-Files on Thingiverse</a></p>
					</div><!-- .content-wrapper -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Share your favorite software blog posts of 2023 (148 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38765176</link>
            <guid>38765176</guid>
            <pubDate>Mon, 25 Dec 2023 19:09:29 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38765176">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="38765176">
      <td><span></span></td>      <td><center><a id="up_38765176" href="https://news.ycombinator.com/vote?id=38765176&amp;how=up&amp;goto=item%3Fid%3D38765176"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=38765176">Ask HN: Share your favorite software blog posts of 2023</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_38765176">106 points</span> by <a href="https://news.ycombinator.com/user?id=devta">devta</a> <span title="2023-12-25T19:09:29"><a href="https://news.ycombinator.com/item?id=38765176">5 hours ago</a></span> <span id="unv_38765176"></span> | <a href="https://news.ycombinator.com/hide?id=38765176&amp;goto=item%3Fid%3D38765176">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Share%20your%20favorite%20software%20blog%20posts%20of%202023&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=38765176&amp;auth=b4b7592d1637c7f504709e73c4d7684cdf4db864">favorite</a> | <a href="https://news.ycombinator.com/item?id=38765176">23&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>Hey folks, I'm on the lookout for standout software engineering blog posts this year! Interested in anything from system scaling to crafty architectures, optimization, programming languages, and cool features. Whether it's from open-source projects, companies, or individuals, what are your absolute favorite blogs for tech insights in 2023?</p><p>P.S. Wishing you all a Merry Christmas and Happy Holidays!</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table><table>
            <tbody><tr id="38767021"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38767021" href="https://news.ycombinator.com/vote?id=38767021&amp;how=up&amp;goto=item%3Fid%3D38765176"></a></center>    </td><td><br><div>
                  <p><span>This post is a hilarious example of how little most users on HN pay attention to the actual content at hand. The title is explicit about asking for specific posts, yet almost all the comments as of right now just link to a whole blog.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38767080"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38767080" href="https://news.ycombinator.com/vote?id=38767080&amp;how=up&amp;goto=item%3Fid%3D38765176"></a></center>    </td><td><br><div>
                  <p><span>Your comment (and hypocritically, this comment as well) is also a hilarious example of how some people on HN also disregard the actual content of the parent post and instead point out/share their negative meta-observations of the HN community at large.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38767060"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38767060" href="https://news.ycombinator.com/vote?id=38767060&amp;how=up&amp;goto=item%3Fid%3D38765176"></a></center>    </td><td><p><span>&gt;&gt; <i>"what are your absolute favorite blogs"</i><p>A reasonable person could infer from the title and this line that OP is fine with both.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38767185"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38767185" href="https://news.ycombinator.com/vote?id=38767185&amp;how=up&amp;goto=item%3Fid%3D38765176"></a></center>    </td><td><p><span>Working With Discovery Trees: <a href="https://www.industriallogic.com/blog/discovery-trees/" rel="nofollow noreferrer">https://www.industriallogic.com/blog/discovery-trees/</a><p>Happened to see Paige Watson present about FaST Agile at the PhillyXP meetup group and then tried some of the concepts with my team at work to great success. We were looking for a good way to turn high-level product asks into actionable work and Discovery Trees fit the bill for us.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38767143"><td></td></tr>
            <tr id="38767127"><td></td></tr>
            <tr id="38765826"><td></td></tr>
                <tr id="38767481"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38767481" href="https://news.ycombinator.com/vote?id=38767481&amp;how=up&amp;goto=item%3Fid%3D38765176"></a></center>    </td><td><p><span>My opinion on methodologies is that if it is too often misunderstood, then it is wrong.<p>The entire point of giving a methodology a name and writing about it is to get everyone on the same page. So if people have different ideas on what TDD is, then people should stop talking about TDD until everyone agree what is and what is not TDD.</p><p>And only after everyone agrees, one should talk about the pros and cons and assess the success of the methodology depending on the situation. "you are doing it wrong" is not helpful.</p><p>Back to the article. I think not mentioning TDD at all would make it a better article.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38767702"><td></td></tr>
                  <tr id="38767618"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38767618" href="https://news.ycombinator.com/vote?id=38767618&amp;how=up&amp;goto=item%3Fid%3D38765176"></a></center>    </td><td><br><div>
                  <p><span>The biggest missing element, in my mind, of the pro-"classicist" and anti-"mockist" view is that the practice of writing unit tests with mocking leads to refactoring your code until it works with that approach, which in turn leads to better-designed code. I don't like the emphasis of "yeah but refactoring code leads to needing to rewrite mocked tests", because if you've designed your code well, then the need to adjust an api boundary should be less frequent than the need to adjust the internal implementation details. Focusing on integration tests means you can get away with poorly designed code full of corner cases that your integration tests can't catch. Besides, "we can keep the fast feedback loop with parallel tests" really increases the demands on complicated tooling that breaks often.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38767632"><td></td></tr>
            <tr id="38767754"><td></td></tr>
            <tr id="38767432"><td></td></tr>
            <tr id="38767214"><td></td></tr>
            <tr id="38766639"><td></td></tr>
                <tr id="38766958"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38766958" href="https://news.ycombinator.com/vote?id=38766958&amp;how=up&amp;goto=item%3Fid%3D38765176"></a></center>    </td><td><br><div>
                  <p><span>do you have a specific post?
I think entire blog would be too big to check out, just to be in line with this post</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38767802"><td></td></tr>
            <tr id="38767110"><td></td></tr>
                        <tr id="38767847"><td></td></tr>
            <tr id="38767173"><td></td></tr>
            <tr id="38765828"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38765828" href="https://news.ycombinator.com/vote?id=38765828&amp;how=up&amp;goto=item%3Fid%3D38765176"></a></center>    </td><td><p><span>I've greatly enjoyed reading this Mainlining blog series from ichernev, about porting an Android phone to PostmarketOS:<p><a href="https://mainlining.dev/" rel="nofollow noreferrer">https://mainlining.dev/</a></p><p>It teaches you how to probe the system, scrape out the proprietary microcode, and use it to build against a newer kernel (albeit with much tweaking)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38765843"><td></td></tr>
            <tr id="38766295"><td></td></tr>
            </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[2023: The Year of AI (107 pts)]]></title>
            <link>https://journal.everypixel.com/2023-the-year-of-ai</link>
            <guid>38765027</guid>
            <pubDate>Mon, 25 Dec 2023 18:52:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://journal.everypixel.com/2023-the-year-of-ai">https://journal.everypixel.com/2023-the-year-of-ai</a>, See on <a href="https://news.ycombinator.com/item?id=38765027">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>AI has undoubtedly made waves in 2023 and here we spotlight the most significant stories of the year poised to shape the future of this groundbreaking industry:</p>



<p><em>Correction: In the original blog post published on December 22, 2023, the title “AI Releases” caused confusion as the content encompassed announcements and updates in addition to releases. We clarified the title of the text and infographic. The mention of Stability AI open-sourcing its LLM was excluded from the infographic but left in the article, underscoring its significance in promoting accessibility rather than focusing on tech improvement. The infographic initially featured the establishment of the xAI startup, now removed because of irrelevance. Additionally, the mention of Apple Vision Pro was excluded as the article focuses on software. We also included Midjourney V.6 in the list as it is a very recent release.</em> <em>These adjustments aim to improve accuracy and coherence. We apologize for any confusion and appreciate your understanding!</em></p>



<h4><strong>AI Advancements</strong></h4>



<p>In the landscape of AI advancements this year, notable progress was made, refining existing technologies rather than introducing groundbreaking innovations akin to the&nbsp;<a href="https://journal.everypixel.com/ai-highlights-2022" target="_blank" rel="noopener" title="">ChatGPT or image generators of the previous year</a>. While there was no wow effect and the real Artificial General Intelligence (AGI) is still far away, this year marked an intermediate stage between prior breakthroughs and something even more powerful to come. To showcase this evolution, we crafted a visual timeline, highlighting the most remarkable AI advancements that have shaped this year of AI:</p>



<figure>
<figure><img data-lazy-fallback="1" decoding="async" fetchpriority="high" width="925" height="1024" data-id="1172" src="https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/Frame-1-1.png?resize=925%2C1024&amp;ssl=1" alt="2023: The Year of AI " srcset="https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/Frame-1-1.png?resize=925%2C1024&amp;ssl=1 925w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/Frame-1-1.png?resize=271%2C300&amp;ssl=1 271w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/Frame-1-1.png?resize=768%2C850&amp;ssl=1 768w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/Frame-1-1.png?resize=1387%2C1536&amp;ssl=1 1387w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/Frame-1-1.png?resize=1850%2C2048&amp;ssl=1 1850w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/Frame-1-1.png?w=1970&amp;ssl=1 1970w" sizes="(max-width: 925px) 100vw, 925px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/Frame-1-1.png?resize=925%2C1024&amp;ssl=1 925w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/Frame-1-1.png?resize=271%2C300&amp;ssl=1 271w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/Frame-1-1.png?resize=768%2C850&amp;ssl=1 768w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/Frame-1-1.png?resize=1387%2C1536&amp;ssl=1 1387w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/Frame-1-1.png?resize=1850%2C2048&amp;ssl=1 1850w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/Frame-1-1.png?w=1970&amp;ssl=1 1970w" data-lazy-src="https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/Frame-1-1.png?resize=925%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</figure>



<p><strong>Image Generation</strong></p>



<ul>
<li><strong>Adobe Firefly:</strong>&nbsp;<a href="https://journal.everypixel.com/top-ai-news-march-2023" target="_blank" rel="noopener" title="">Adobe’s Firefly</a>&nbsp;and&nbsp;<a href="https://www.adobe.com/products/photoshop/generative-fill.html" target="_blank" rel="noopener nofollow" title="">Generative Fill</a>&nbsp;empowered diverse visual content creation, including illustrations, art concepts, and photo manipulation.&nbsp;<a href="https://journal.everypixel.com/top-ai-news-may-2023" target="_blank" rel="noopener" title="">Integrated into Photoshop</a>, Adobe Firefly democratized AI, extending its power to a broad user base at once. The release of the&nbsp;<a href="https://www.adobe.com/products/firefly/features/text-effects.html" target="_blank" rel="noopener nofollow" title="">Text Effect feature</a>&nbsp;also marked a significant stride, allowing users to apply styles or textures to words and phrases.</li>



<li><strong>Midjourney:</strong> <a href="https://journal.everypixel.com/top-ai-news-march-2023" target="_blank" rel="noopener" title="Midjourney's V.5 model">Midjourney’s V.5 model</a> marked a milestone in image generation, showcasing improved efficiency, coherence, and higher resolution. The latest alpha-version, <a href="https://mid-journey.ai/midjourney-v6-release/" target="_blank" rel="noopener nofollow" title="Midjourney V.6">Midjourney V.6</a>, brought additional enhancements such as more accurate prompt following, increased model knowledge, and minor text drawing ability. </li>



<li><strong>DALL·E 3:</strong>&nbsp;Built on ChatGPT,&nbsp;<a href="https://journal.everypixel.com/top-ai-news-september-2023" target="_blank" rel="noopener" title="">DALL·E 3</a>&nbsp;simplified image generation, eliminating the need for complex prompt engineering. In addition, ChatGPT introduced a feature to help users refine prompts and make image adjustments based on feedback.</li>



<li><strong>Shutterstock.AI:</strong>&nbsp;The stock image giant&nbsp;<a href="https://journal.everypixel.com/top-ai-news-january-2023" target="_blank" rel="noopener" title="">integrated AI capabilities</a>, allowing users to transform prompts into license-ready imagery. Recognizing and rewarding contributing artists, Shutterstock made the first step in ethical AI.</li>
</ul>



<figure>
<figure><img data-lazy-fallback="1" decoding="async" width="659" height="1024" data-id="1138" src="https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.-1-1.png?resize=659%2C1024&amp;ssl=1" alt="2023: The Year of AI " srcset="https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.-1-1.png?resize=659%2C1024&amp;ssl=1 659w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.-1-1.png?resize=193%2C300&amp;ssl=1 193w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.-1-1.png?w=746&amp;ssl=1 746w" sizes="(max-width: 659px) 100vw, 659px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.-1-1.png?resize=659%2C1024&amp;ssl=1 659w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.-1-1.png?resize=193%2C300&amp;ssl=1 193w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.-1-1.png?w=746&amp;ssl=1 746w" data-lazy-src="https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.-1-1.png?resize=659%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The Evolution of Text-to-Image Algorithms, 2007 vs 2023</figcaption></figure>
</figure>



<p><strong>Video Generation</strong></p>



<ul>
<li><strong>Stability AI:</strong>&nbsp;Stability AI&nbsp;<a href="https://journal.everypixel.com/top-ai-news-november-2023" target="_blank" rel="noopener" title="">introduced Stable Video Diffusion</a>, a groundbreaking model for generative video, with open-source access on GitHub. Drawing a parallel to&nbsp;<a href="https://journal.everypixel.com/ai-image-statistics" target="_blank" rel="noopener" title="">AI image generation trends</a>, it’s highly possible that the Stable Video Diffusion model will play a pivotal role in the creation of a significant portion of AI-generated videos.</li>



<li><strong>HeyGen:</strong>&nbsp;AI startup unveiled&nbsp;<a href="https://the-decoder.com/heygen-offers-ai-powered-video-translation-with-impressive-lip-syncing-capabilities/" target="_blank" rel="noopener nofollow" title="">a tool for voice cloning</a>, lip movement adjustments, and language translation in videos.</li>



<li><strong>Runway Gen-2</strong>:&nbsp;<a href="https://research.runwayml.com/gen2" target="_blank" rel="noopener nofollow" title="">Runway launched the Gen-2</a>&nbsp;model, enabling users to effortlessly generate full-blown videos from just text prompts, images, or other videos. Just have a look at the example below.&nbsp;</li>



<li><strong>Pika and Pika 1.0</strong>: With its initial release, Pika garnered half a million users, generating millions of videos weekly. Then upgraded AI model in&nbsp;<a href="https://pika.art/launch" target="_blank" rel="noopener nofollow" title="">Pika 1.0</a>&nbsp;empowered users to create and edit videos in various styles, including 3D animation, anime, cartoon, and cinematic.</li>



<li><strong>Codec avatars by Meta:</strong>&nbsp;<a href="https://youtu.be/MVYrJJNdrEg?si=NR3DJMeYOfbiAunX" target="_blank" rel="noopener nofollow" title="">Meta’s Pixel Codec Avatars</a>&nbsp;(PiCA) model for 3D human faces in videos brought us closer to photorealistic telepresence.</li>
</ul>



<figure></figure>



<p><strong>Text Generation</strong></p>



<ul>
<li><strong>Bard and Gemini:</strong>&nbsp;<a href="https://journal.everypixel.com/top-ai-news-march-2023" target="_blank" rel="noopener" title="">Google’s Bard</a>&nbsp;added human-like emotion and sentiment to the chatbot landscape. Introduced into Bard chatbot and trained on a multimodal dataset,&nbsp;<a href="https://blog.google/technology/ai/google-gemini-ai/" target="_blank" rel="noopener nofollow" title="">Google’s Gemini</a>&nbsp;emerged as the “most capable” AI model and the closest competitor to OpenAI’s ChatGPT.</li>



<li><strong>Grok:</strong>&nbsp;<a href="https://journal.everypixel.com/top-ai-news-april-2023" target="_blank" rel="noopener" title="">Elon Musk’s startup xAI</a>&nbsp;signaled a commitment to AI development, potentially competing with OpenAI, by&nbsp;<a href="https://journal.everypixel.com/top-ai-news-november-2023" target="_blank" rel="noopener" title="">unveiling “Grok”</a>&nbsp;— a chatbot with humor, rebelliousness, and real-time knowledge via the 𝕏 platform. The xAI promised that Grok <a href="https://x.ai/" target="_blank" rel="noopener nofollow" title="was designed to answer provocative questions">was designed to answer provocative questions</a> rejected by other AI systems.</li>



<li><strong>OverflowAI:</strong>&nbsp;<a href="https://journal.everypixel.com/top-ai-news-july-2023" target="_blank" rel="noopener" title="">Stack Overflow’s OverflowAI</a>&nbsp;enhanced knowledge curation, enabling AI-powered search for relevant answers in Visual Studio Code and Slack.</li>



<li><strong>Llama 2:</strong>&nbsp;<a href="https://journal.everypixel.com/top-ai-news-july-2023" target="_blank" rel="noopener" title="">Meta released Llama 2</a>, the next generation of its open-source large language model, showcasing enhanced efficiency. Meta’s fine-tuned LLM was also optimized for dialogue use cases and outperformed other open-source models on most benchmarks.</li>



<li><strong>GPT-4:</strong>&nbsp;<a href="https://journal.everypixel.com/top-ai-news-march-2023" target="_blank" rel="noopener" title="">OpenAI’s GPT-4</a>&nbsp;now handles image input, generates captions, classifications, hears, and responds in a back-and-forth conversation, and supports&nbsp;<a href="https://journal.everypixel.com/top-ai-news-september-2023" target="_blank" rel="noopener" title="">real-time web browsing</a>. OpenAI also extended support for plugins, fostering a landscape enriched with open-source competitors. GPT-4 is the next step in OpenAI’s journey to develop AGI.</li>



<li><strong>Mistral 7B:</strong>&nbsp;<a href="https://mistral.ai/" target="_blank" rel="noopener nofollow" title="">Mistral AI</a>,&nbsp;<a href="https://www.nytimes.com/2023/12/10/technology/mistral-ai-funding.html" target="_blank" rel="noopener nofollow" title="">valued at around $2 billion</a>&nbsp;this year, released Mistral 7B, a large language model challenging GPT-4 and Claude 2. Emphasizing an open technology approach, Mistral AI offered its model for free download.</li>



<li><strong>Mixtral 8x7B:</strong>&nbsp;<a href="https://mistral.ai/news/mixtral-of-experts/" target="_blank" rel="noopener nofollow" title="">Mistral AI also introduced Mixtral 8x7B</a>, a high-quality sparse mixture of expert model (SMoE) with open weights, featuring 46.7B total parameters, pioneering openness in models with enhanced truthfulness and reduced biases.</li>



<li><strong>Yi-34B llm:</strong>&nbsp;<a href="https://techcrunch.com/2023/11/05/valued-at-1b-kai-fu-lees-llm-startup-unveils-open-source-model/" target="_blank" rel="noopener nofollow" title="">Valued at $1 billion</a>&nbsp;this year, Kai-Fu Lee’s startup&nbsp;<a href="http://01.ai/" target="_blank" rel="noopener nofollow" title="">01.AI</a>&nbsp;released Yi-34B — an open-source neural network that outperformed competing models with significantly higher parameter counts, emphasizing its cost-efficiency.</li>
</ul>



<p><strong>Other Advancements:</strong></p>



<ul>
<li><strong>Segment Anything Model (SAM):</strong>&nbsp;<a href="https://segment-anything.com/" target="_blank" rel="noopener nofollow" title="">Meta AI presented SAM</a>, a segmentation model capable of “cutting out” objects in images without additional training, underscoring its adaptability. SAM was trained on a vast dataset, showcasing its robust performance in object segmentation.</li>



<li><strong>Direct Preference Optimization (DPO):</strong>&nbsp;<a href="https://arxiv.org/abs/2305.18290" target="_blank" rel="noopener nofollow" title="">DPO emerged</a>&nbsp;as a stable and efficient method for fine-tuning large-scale unsupervised language models and teaching text-to-image models. It achieved precise control without complex reinforcement learning from human feedback (RLHF).</li>



<li><strong>Zephyr Direct Distillation of LM Alignment:</strong>&nbsp;<a href="https://arxiv.org/abs/2310.16944" target="_blank" rel="noopener nofollow" title="">Zephyr-7B</a>, a result of distilled direct preference optimization (dDPO), set the benchmark for chat models with 7B parameters, enhancing intent alignment without extensive training.</li>



<li><strong>Autonomous AI Agents:</strong>&nbsp;<a href="https://journal.everypixel.com/top-ai-news-april-2023" target="_blank" rel="noopener" title="">Autonomous AI agents emerged</a>&nbsp;as a notable trend, showcasing a transformative shift toward advanced and autonomous AI systems. AI Agents are considered a first glimpse of AGI as they can generate self-directed tasks and instructions based on a user’s goal, and work on them autonomously until the goal is achieved.</li>



<li><strong>EvoDiff:</strong>&nbsp;<a href="https://journal.everypixel.com/top-ai-news-september-2023" target="_blank" rel="noopener" title="">Microsoft’s EvoDiff</a>, an open-source AI framework for fast and cost-saving protein generation, promised advancements in therapeutics and industrial applications.</li>



<li><strong>Stable Audio:</strong>&nbsp;<a href="https://journal.everypixel.com/top-ai-news-september-2023" target="_blank" rel="noopener" title="">Stability AI launched</a>&nbsp;a tool for generating short high-quality audio clips from simple text prompts.</li>



<li><strong>GPT Store, Copyright Shield, ChatGPT Bot Constructor:</strong>&nbsp;<a href="https://journal.everypixel.com/top-ai-news-november-2023" target="_blank" rel="noopener" title="">OpenAI introduced</a>&nbsp;the GPT Store to sell custom GPT bots, Copyright Shield to cover legal costs related to copyright infringement claims, and a no-code platform for custom ChatGPT versions.</li>



<li><strong>Stability AI Open-Sourced its LLM:</strong>&nbsp;<a href="https://journal.everypixel.com/top-ai-news-april-2023" target="_blank" rel="noopener" title="">Stability AI has open-sourced its models</a>, StableLM-Alpha and Stable Vicuna, renowned for their impressive performance in generating text and code. Stable Vicuna is the first open-source chatbot trained using reinforcement learning from human feedback (RLHF). Furthermore, Stability AI&nbsp;<a href="https://journal.everypixel.com/top-ai-news-november-2023" target="_blank" rel="noopener" title="">unveiled SDXL Turbo</a>, a real-time text-to-image generation model.</li>
</ul>



<h4><strong>Partnerships</strong></h4>



<p>In the dynamic realm of 2023, significant collaborations have surfaced among industry leaders, shaping the trajectory of the future. Here are the top merges and partnerships that were defining the AI landscape in this year 2023:</p>



<p><strong>Stability AI and Init ML</strong></p>



<p>Stability AI has made a significant move by&nbsp;<a href="https://journal.everypixel.com/top-ai-news-march-2023" target="_blank" rel="noopener" title="">acquiring Init ML</a>, the brains behind the popular editing app ClipDrop. The objective was clear: <a href="https://stability.ai/news/stability-ai-acquires-init-ml-makers-of-clipdrop-application" target="_blank" rel="noopener nofollow" title="integrate Stability AI's advanced technologies">integrate Stability AI’s advanced technologies</a> into ClipDrop’s ecosystem. The collaboration has already resulted in the <a href="https://journal.everypixel.com/top-ai-news-november-2023" target="_blank" rel="noopener" title="development of SDXL Turbo">development of SDXL Turbo</a>.</p>



<p><strong>Runway and Getty</strong>&nbsp;<strong>Images</strong></p>



<p><a href="https://runwayml.com/blog/runway-partners-with-getty-images/" target="_blank" rel="noopener nofollow" title="">Runway has joined forces with Getty Images</a>&nbsp;in a strategic partnership to introduce a new video generation model RGM (The Runway and Getty Images Model). The model combines Runway’s AI capabilities with Getty Images’ licensed creative content library. The collaboration aims to revolutionize content creation workflows, enabling companies to generate high-quality, customized videos tailored to their brand identities.</p>



<p><strong>Snowflake and Neeva</strong></p>



<p>Snowflake, a major player in the data warehouse platform,&nbsp;<a href="https://www.snowflake.com/blog/snowflake-acquires-neeva-to-accelerate-search-in-the-data-cloud-through-generative-ai/" target="_blank" rel="noopener nofollow" title="">has acquired Neeva</a>, a startup known for using generative AI to enhance the search experience. Neeva had recently closed its subscription-based, ad-free search engine. The founders of Neeva also acknowledged the challenge of convincing users to try a new search engine.</p>



<p><strong>Shutterstock and OpenAI</strong></p>



<p><a href="https://investor.shutterstock.com/news-releases/news-release-details/shutterstock-expands-partnership-openai-signs-new-six-year" target="_blank" rel="noopener nofollow" title="">Shutterstock and OpenAI have committed</a>&nbsp;to an extended 6-year partnership. OpenAI gained access to high-quality data from Shutterstock, enriching its model training datasets with a diverse range of images, videos, and music libraries. Shutterstock continued to leverage OpenAI’s technologies, leading to the launch of Shutterstock’s AI image-generating tool.</p>



<h4><strong>Legal Landscape</strong></h4>



<p>In the ever-evolving legal realm of AI, 2023 finds itself amidst a landscape filled with uncertainties and ongoing debates. As new challenges emerge, discussions surrounding copyright, corporate policies, and the broader regulatory framework continue, shaping the contours of AI’s legal landscape. Here are the most important legal issues of the year 2023:</p>



<p><strong>European AI Act</strong></p>



<p>The&nbsp;<a href="https://www.europarl.europa.eu/news/en/headlines/society/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence" target="_blank" rel="noopener nofollow" title="">European Union introduced the AI Act</a>, the world’s first comprehensive law, to regulate the use of AI. The act classifies AI systems based on the risk they pose and sets forth regulations accordingly. Although the AI Act has been provisionally agreed upon, its implementation faces delays, and the enforcement won’t commence until 2025.</p>



<p><strong>U.S. Copyright Office Stance on Registration of AI-Generated Content</strong></p>



<p>The U.S. Copyright Office took a decisive stance,&nbsp;<a href="https://journal.everypixel.com/top-ai-news-february-2023" target="_blank" rel="noopener" title="">denying copyright</a>&nbsp;registration for images created by the AI algorithm Midjourney. The rejection set a precedent, asserting that AI artworks solely created by AI, without human involvement, are ineligible for copyright protection. In the same vein, the&nbsp;<a href="https://journal.everypixel.com/top-ai-news-march-2023" target="_blank" rel="noopener" title="">U.S. Copyright Office issued guidance</a>&nbsp;on AI-assisted works, clarifying that works created by humans using AI tools may be eligible for copyright protection. The guidance confirmed that works created by humans using AI tools should be evaluated based on whether the human role in the creation of those works was determinative.</p>



<blockquote>
<p><em>“Currently, the existing legal system is not prepared to acknowledge copyright for works created with AI, given that AI learns from existing data, the rights to which belong to other people, challenging the attribution of ownership. The practice for addressing this issue is expected to develop next year, facilitated by public participation through <a href="https://www.copyright.gov/policy/artificial-intelligence/" target="_blank" rel="noopener nofollow" title="state-conducted surveys">state-conducted surveys</a>. Resolving this matter independently is now difficult without broader public engagement.” </em></p>
<cite>Daria Kuznetsova, Corporate Lawyer of Everypixel</cite></blockquote>



<p><a href="https://www.mckinsey.com/featured-insights/2023-year-in-review/2023-the-year-in-charts" target="_blank" rel="noopener nofollow" title="">McKinsey</a>&nbsp;also released a comprehensive graph capturing the most important AI governance-related policy and regulatory efforts in 2023. The visual representation highlights the significant contributions of 2023 in shaping the legal landscape of AI.</p>



<figure>
<figure><img data-lazy-fallback="1" decoding="async" width="729" height="1024" data-id="1139" src="https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.png?resize=729%2C1024&amp;ssl=1" alt="2023: The Year of AI " srcset="https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.png?resize=729%2C1024&amp;ssl=1 729w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.png?resize=214%2C300&amp;ssl=1 214w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.png?resize=768%2C1079&amp;ssl=1 768w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.png?w=860&amp;ssl=1 860w" sizes="(max-width: 729px) 100vw, 729px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.png?resize=729%2C1024&amp;ssl=1 729w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.png?resize=214%2C300&amp;ssl=1 214w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.png?resize=768%2C1079&amp;ssl=1 768w, https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.png?w=860&amp;ssl=1 860w" data-lazy-src="https://i0.wp.com/journal.everypixel.com/wp-content/uploads/2023/12/The-Year-of-AI-2023.png?resize=729%2C1024&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Source:&nbsp;<a href="https://www.mckinsey.com/featured-insights/2023-year-in-review/2023-the-year-in-charts" target="_blank" rel="noopener nofollow" title="">McKinsey</a></figcaption></figure>
</figure>



<h4><strong>Debates</strong></h4>



<p>The year 2023 was abuzz with intriguing debates and discussions, grappling with uncertainties and the evolving norms of the AI landscape. As the industry shapes its course, these debates become inevitable, promising more thought-provoking dialogues and challenges on the horizon. Here are some of the most noteworthy debates that defined the year:</p>



<p><strong>Corporate Restrictions on ChatGPT</strong></p>



<p>Major financial institutions, including JP Morgan, Citigroup, Bank of America, Deutsche Bank, Goldman Sachs, and Wells Fargo &amp; Co,&nbsp;<a href="https://journal.everypixel.com/top-ai-news-february-2023" target="_blank" rel="noopener" title="">have restricted ChatGPT usage</a>&nbsp;due to security and privacy concerns. This reflected a broader trend where companies were issuing warnings to employees about the legal considerations associated with AI applications in corporate environments.</p>



<p><strong>OpenAI’s Use of Low-Paid Workers</strong></p>



<p>Time’s investigation exposed OpenAI’s collaboration with Sama,&nbsp;<a href="https://journal.everypixel.com/top-ai-news-january-2023" target="_blank" rel="noopener" title="">employing low-paid workers in Kenya</a>&nbsp;to sift through sensitive content for ChatGPT. The revelation raised ethical questions about the treatment of workers and the impact of content moderation on mental well-being.</p>



<p><strong>Leadership Transition at OpenAI</strong></p>



<p><a href="https://journal.everypixel.com/top-ai-news-november-2023" target="_blank" rel="noopener" title="">Sam Altman’s departure</a>&nbsp;and quick return made headlines last month. A leadership transition unfolded at OpenAI as Sam Altman stepped down amid communication inconsistencies with the board. Interim CEO Mira Murati, along with a majority of staff, advocated for Altman’s return. This unprecedented situation attracted widespread attention, leaving questions about the true reasons behind the transition and future implications.</p>



<p><strong>Adobe and Figma</strong></p>



<p><a href="https://news.adobe.com/news/news-details/2022/Adobe-to-Acquire-Figma/default.aspx" target="_blank" rel="noopener nofollow" title="">Adobe’s $20 billion acquisition plan for Figma</a>&nbsp;encountered regulatory hurdles, prompting investigations by the European Commission and the UK Competition and Markets Authority over potential antitrust issues. The proposed deal’s impact also extended beyond design considerations, as Adobe’s dominance in customer data platforms raised concerns among Chief Information Officers (CIOs) about its potential influence on cloud software spending. However,&nbsp;<a href="https://news.adobe.com/news/news-details/2023/Adobe-and-Figma-Mutually-Agree-to-Terminate-Merger-Agreement/default.aspx" target="_blank" rel="noopener nofollow" title="">Adobe abandoned the deal</a>&nbsp;due to challenges in securing antitrust approvals in Europe and the UK, resulting in a termination fee of $1 billion to Figma.</p>



<p><strong>Photographer Hacked the World Photography Awards</strong></p>



<p>Photographer Boris Eldagsen&nbsp;<a href="https://journal.everypixel.com/top-ai-news-april-2023" target="_blank" rel="noopener" title="">disrupted the Sony World Photography Awards</a>&nbsp;by submitting AI-generated artwork. Eldagsen’s refusal to accept the prize sparked a debate on the place of AI-generated images in traditional photography competitions, challenging perceptions of authenticity and creativity.</p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Navalny Found in Arctic Prison After 3-Week Disappearance (101 pts)]]></title>
            <link>https://www.themoscowtimes.com/2023/12/25/navalny-found-in-arctic-prison-after-3-week-disappearance-a83563</link>
            <guid>38764866</guid>
            <pubDate>Mon, 25 Dec 2023 18:34:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.themoscowtimes.com/2023/12/25/navalny-found-in-arctic-prison-after-3-week-disappearance-a83563">https://www.themoscowtimes.com/2023/12/25/navalny-found-in-arctic-prison-after-3-week-disappearance-a83563</a>, See on <a href="https://news.ycombinator.com/item?id=38764866">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="article-block-type">
								<p><span>Jailed Kremlin critic Alexei Navalny has been located in a prison colony in northern Russia after going missing for nearly three weeks, his spokeswoman <a href="https://x.com/Kira_Yarmysh/status/1739263623237607623?s=20" title="said">said</a> Monday.</span></p>
<p><span>The disappearance of Russia's most prominent opposition figure, who mobilized huge protests before being jailed in 2021, had spurred concerns from allies, rights groups and Western governments.</span></p>
<p><span>“We have found Alexei Navalny. He is now in IK-3 in the settlement of Kharp in the Yamal-Nenets autonomous district,” Kira Yarmysh wrote on X, formerly Twitter.</span></p>
<p><span>She said Navalny’s lawyer visited him earlier in the day, adding that the anti-corruption crusader is “doing well.”</span></p>
<p>The district of Kharp, home to about 5,000 people, is located above the Arctic Circle.</p>
<p><span>Exiled Navalny aide Ivan Zhdanov <a href="https://twitter.com/ioannZH/status/1739264737945215094" title="called">called</a> IK-3 “one of the most northern and remote” prison colonies in Russia.</span></p>
<p><span>“Conditions there are harsh, with a special regime in the permafrost zone. It’s very difficult to reach and there are no systems to deliver letters or [make calls],” Zhdanov wrote.</span></p>
<p><span>“The situation with Alexei is a vivid example of how the system treats political prisoners, trying to isolate and suppress them,” he said, linking Navalny’s isolation to Russia’s 2024 presidential elections in which President Vladimir Putin is expected to win a fifth term.</span></p>															</div><div data-id="article-block-type">
								 <p><span>IK-3 is famous for at one point in the 2000s holding <a href="https://www.themoscowtimes.com/2015/02/18/a-year-after-being-freed-khodorkovsky-associate-still-trapped-in-russia-a44044" title="Platon Lebedev">Platon Lebedev</a>, a one-time business partner of exiled former oligarch Mikhail Khodorkovsky who was convicted of tax evasion, money laundering and fraud in what he and his supporters maintained was a politically motivated case.<br></span></p>
<p><span>Navalny’s location and condition had been unknown since his lawyers last met with him on Dec. 5, sparking <a href="https://www.themoscowtimes.com/2023/12/11/navalny-missing-for-6-days-after-serious-health-related-incident-team-says-a83376" title="claimed">worries</a>&nbsp;that the 47-year-old’s life may be in danger.</span></p>
<p><span>He was expected to be transferred to a new prison colony as part of his new 19-year <a href="https://www.themoscowtimes.com/2023/08/04/russia-sentences-navalny-to-19-years-behind-bars-in-extremism-trial-a82056" title="jail term">jail term</a> for “extremism.”</span></p>
<p><span>He was previously held at the IK-2 prison colony in central Russia’s Vladimir region, where he was serving a sentence on fraud charges.</span></p> 															</div><div data-id="article-block-type">
								 <div data-id="article-block-type">
<p>His allies linked the timing of his disappearance to Putin’s Dec. 8 announcement to seek re-election in the 2024 presidential race.</p>
<p>Navalny has <a href="https://www.themoscowtimes.com/2023/12/07/navalny-urges-supporters-to-vote-for-anyone-but-putin-in-2024-election-a83346" title="urged">urged</a> Russians to “vote for any other candidate” besides Putin in the March 15-17 election.</p>
<p><span>Navalny was jailed in 2021 after returning to Moscow from Germany, where he recovered from a nearly fatal poisoning attack with the Soviet-designed nerve agent Novichok. He claimes the poisoning was orchestrated by Putin, an assertion the Kremlin denies.</span></p>
<p><span>His activist and political groups were banned as “extremist” organizations in summer 2021, forcing his closest associates into exile.</span></p>
</div>
<p><em>AFP contributed reporting.</em></p> 															</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reproducible Git Bundles (104 pts)]]></title>
            <link>https://baecher.dev/stdout/reproducible-git-bundles/</link>
            <guid>38764452</guid>
            <pubDate>Mon, 25 Dec 2023 17:40:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://baecher.dev/stdout/reproducible-git-bundles/">https://baecher.dev/stdout/reproducible-git-bundles/</a>, See on <a href="https://news.ycombinator.com/item?id=38764452">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <p><a href="https://baecher.dev/">Home</a></p>

    

    <p>
      December 2023
    </p>

    <p>
      As part of a backup script for my entire system I wanted to back up all my git repositories.
      Some of them don't have a remote anywhere, so I cannot rely on implicit backups in The Cloud.
      The naive solution of simply backing up the entire file-system tree is clearly not desirable since that would clutter the backup with useless build artifacts.
      One solution is to create a fresh clone (with <kbd>--mirror</kbd>), but that will typically consist of many small files which isn't ideal for backups, either.
      Conveniently git can create a single-file archive of a repository via <kbd>git bundle create</kbd> which appears to be the perfect fit for backups.
    </p>

    <p>
      After a few test runs of my backup I noticed that a small but fixed subset of repositories are getting backed up despite having no changes made.
      That is odd because I would think that repeated bundling of the same repository state should create the exact same bundle. However:
    </p>

    <pre>$ git bundle create -q /tmp/a --all
$ git bundle create -q /tmp/b --all
$ md5sum /tmp/a /tmp/b
44891a87b08b75c1b518889fcba73204  /tmp/a
a37a81710313cdbb5f065ddb2c797630  /tmp/b</pre>

    <p>
      Huh?
    </p>
    <p>
      Turns out that for <em>some repositories</em> bundling is nondeterministic.
      After browsing some vaguely-related Stackoverflow answers and several AI hallucinations later I decided to dig into the bundles to see what the differences are.
      Bundling reorganizes all git objects into a single <em>pack</em>, which is an internal git data structure to aggregate many objects into one file and apply some optimizations like delta coding along the way.
    </p>
    <p>
      Both bundles contained a single pack in my case but each pack had a fairly different structure, as revealed by <kbd>git verify-pack -v</kbd>!
      At this point, having looked at many outputs from <kbd>git bundle create</kbd>, I had a suspicion:
    </p>

    <pre>Enumerating objects: 733, done.
Counting objects: 100% (733/733), done.
Delta compression using up to 8 threads
Compressing objects: 100% (598/598), done.
Writing objects: 100% (733/733), 97.15 KiB | 6.48 MiB/s, done.
Total 733 (delta 419), reused 0 (delta 0), pack-reused 0</pre>

    <p>
      What caught my eye was <kbd>Delta compression using up to 8 threads</kbd>—parallelism is a classic source of inherent (as opposed to accidental) nondeterminism.
      Testing this hypothesis should be quite simple.
      Having browsed my fair share of git manpages in the past I knew that many commands have a <kbd>--threads</kbd> option, but git bundle does not.
      Luckily any git subcommand can be run with ad-hoc configuration options, and the relevant option here turns out to be <kbd>pack.threads</kbd>.
    </p>

    <pre>$ for i in $(seq 1 100); do \
&gt; git -c 'pack.threads=1' bundle create -q /tmp/bundle-$i --all; \
&gt; done
$ md5sum /tmp/bundle-* | cut -f 1 -d ' ' | uniq -c
    100 4898971d4d3b8ddd59022d28c467ffca</pre>

    <p>
      Success!
    </p>
    <p>
      Forcing git to be single threaded makes the output deterministic.
      In case you are wondering, using just one thread instead of eight does not have any discernible performance impact on my personal repositories, so I'm very happy to trade performance for reproducibility.
    </p>
    <hr>

    <p>
      <a href="#top">Return to top</a>
    </p>
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[TKey is a RISC-V computer in a USB-C case, that can run security applications (134 pts)]]></title>
            <link>https://dev.tillitis.se/intro/</link>
            <guid>38764353</guid>
            <pubDate>Mon, 25 Dec 2023 17:26:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dev.tillitis.se/intro/">https://dev.tillitis.se/intro/</a>, See on <a href="https://news.ycombinator.com/item?id=38764353">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><img src="https://dev.tillitis.se/images/tkey-case-interaction-points.png" alt="TKey with interaction points marked" title="TKey with interaction points marked" width="85%"><p>The Tillitis TKey is a small computer in a USB stick form factor that
can run small device applications that are loaded onto it. The
purpose of the TKey is to be a secure environment for applications that
provide some kind of security function. Some examples of such security
functions are:</p><ul><li>Time-based one-time password (TOTP) token generators</li><li>Signing oracles</li><li>Secure random numbers</li><li>Encryption</li></ul><p>There is no way of storing a device application (or any other data) on
the TKey. A device app has to be loaded onto the TKey every time you
plug it in.</p><h2 id="tkey-specifications">TKey specifications
<a href="#tkey-specifications">#</a></h2><ul><li>32-bit RISC-V CPU running at 18 MHz</li><li>Execution monitor</li><li>Hardware-assisted address randomization and RAM scrambling</li><li>128 kiB RAM for TKey device applications</li><li>2 kiB firmware RAM</li><li>6 kiB ROM</li><li>True random number generator</li><li>USB CDC (Communications Device Class) over a Type-C connector</li><li>Timer</li><li>Two levels of hardware privilege modes: firmware mode and application mode</li><li>CPU-controlled LED</li><li>No persistent storage</li></ul><blockquote><strong>Note well</strong>: In the end-user version (not TKey Unlocked) the FPGA
configuration is locked down. This means you cannot change the FPGA
bitstream or read out the bitstream (or the Unique Device Secret, UDS)
from the configuration memory, even if you break the case and insert
it into a programmer board.</blockquote><h2 id="measured-boot--secrets">Measured boot &amp; secrets
<a href="#measured-boot--secrets">#</a></h2><p>A unique feature of the TKey is that it measures the loaded device
application before starting it. A hash digest measurement (using
BLAKE2s) combined with a Unique Device Secret (UDS) makes up a base
secret we call a Compound Device Identifier (CDI) which can then used
by the TKey device app.</p><p>If the TKey device app is altered in any way the CDI is also changed.
If the keys derived from the CDI are the same as the last time the
given device app was loaded onto the same TKey the device app’s
integrity is guaranteed.</p><p>The UDS is unique per TKey. The same device app loaded onto another
TKey results in a different CDI.</p><p>The key derivation can also include a User Supplied Secret (USS). Then
the keys are based on both something the user has – the specific TKey
– and something the user knows – the USS.</p><p>This is the algorithm for the CDI:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>cdi</span> = <span>blake2s</span>(<span>UDS</span>, <span>blake2s</span>(<span>device_app</span>), <span>USS</span>)
</span></span></code></pre></div><p>All of the TKey software, firmware, FPGA Verilog source code,
schematics, and PCB design files are released under open
source/hardware licenses, like all trustworthy security software and
hardware should be. This, in itself, makes the TKey different, as
other security tokens use at least some closed source hardware for
security-critical operations.</p><h2 id="getting-started">Getting Started
<a href="#getting-started">#</a></h2><ul><li><a href="https://tillitis.se/getstarted">Get started using your TKey</a>.</li><li><a href="https://dev.tillitis.se/tools/">Tools &amp; Libraries</a>, setup and introduction for
application developers.</li><li><a href="https://dev.tillitis.se/unlocked/">Tkey Unlocked</a>, instructions for the provisioning
process</li></ul></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[War of the workstations: How the lowest bidders shaped today's tech landscape (118 pts)]]></title>
            <link>https://www.theregister.com/2023/12/25/the_war_of_the_workstations/</link>
            <guid>38763933</guid>
            <pubDate>Mon, 25 Dec 2023 16:38:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/12/25/the_war_of_the_workstations/">https://www.theregister.com/2023/12/25/the_war_of_the_workstations/</a>, See on <a href="https://news.ycombinator.com/item?id=38763933">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Feature</span> Digging into stories of 1980s OSes, a forgotten war for the future of computing emerges. It was won by the lowest bidders, and then the poor users and programmers forgot it ever happened.</p>
<p>Retrocomputing is a substantial, and still growing, interest for many techies and hobbyists, and has been for a decade or two now. There's only so much you can write about a game that's decades old, but operating systems and the different paths they've taken still have rich veins to be explored.</p>
<p>Anyone who played with 1980s computers remembers the <a target="_blank" href="https://www.theregister.com/2015/07/24/amiga_turns_30/">Amiga versus the Atari ST</a> and other battles. But digging down past the stratum of cheap home computers and gaming reveals bigger, more profound differences. The winners of the battles got to write the histories, as they always do, and that means that what is now received wisdom, shared and understood by almost everyone, contains and conceals propaganda and dogma. Things that were once just marketing BS are now holy writ, and when you discover how the <em>other</em> side saw it, dogma is uncovered as just big fat lies.</p>
<h3>The biggest lie</h3>
<p>The first of the big lies is the biggest, but it's also one of the simplest, one that you've probably never questioned.</p>
<p>It's this: <em>Computers today are better than they have ever been before.</em> Not just that they have thousands of times more storage and more speed, but that everything, the whole stack – hardware, operating systems, networking, programming languages and libraries and apps – are better than ever.</p>

    

<p>The myth is that early computers were simple, and they were replaced by better ones that could do more. Gradually, they evolved, getting more sophisticated and more capable, until now, we have multi-processor multi-gigabyte supercomputers in our pockets.</p>

        


        

<p>Which gives me an excuse to use my favorite German quote, generally attributed to physicist Wolfgang Pauli: "Das ist nicht nur nicht richtig; es ist nicht einmal falsch!" (That is not only not right, it is not even wrong!)</p>
<p>Though probably apocryphal, someone asked John Glenn, America's first person in space, what it felt like just before launch. Supposedly, he replied: "I felt about as good as anybody would, sitting in a capsule above a rocket that were both built by the lowest bidder."</p>

        

<p>Well, that is where we are today.</p>
<p>The story about evolution is totally wrong. What really happened is that, time after time, each generation of computers developed until it was very capable and sophisticated, and then it was totally replaced by a new generation of relatively simple, stupid ones. Then those were improved, usually completely ignoring all the lessons learned in the previous generation, until the new generation gets replaced in turn by something smaller, cheaper, and far more stupid.</p>
<h3>Evolution</h3>
<p>The first computers, of course, were huge room-sized things that cost millions. They evolved into mainframes: very big, very expensive, but a whole company could share one, running batch jobs submitted on punched cards and stuff like that.</p>
<p>After a couple of decades, mainframes were replaced by minicomputers, shrunk to the size of filing cabinets, but cheap enough for a mere department to afford. They were also fast enough that multiple users could use them <em>at the same time</em>, using interactive terminals.</p>
<p>All the mainframes' intelligent peripherals, networked to their CPUs, and their sophisticated, hypervisor-based, operating systems, with rich role-based security just thrown away.</p>

        

<p>Then, it gets more complicated. The conventional story, for those who have looked back to the 1970s, is that microcomputers came along, based on cheap single-chip microprocessors, and swept away minicomputers. Then they gradually evolved until they caught up.</p>
<p>But that's not really true.</p>
<p>First, and less visibly because they were so expensive, department-scale minicomputers shrank down to desk-sized, and then desk-side, and later desk-<strong>top</strong>, <em>workstations</em>. Instead of being shared by a department, these were single-user machines. Very powerful, very expensive, but just about affordable for one person – as long as they were someone important enough.</p>
<p>Unfortunately, though, in the course of being shrunk down to single-user boxes, most of their ancestors' departmental-scale sophistication was thrown away. Rich file systems, with built-in version tracking, because hard disks cost as much as cars: gone. Clustering, enabling a handful of machines costing hundreds of thousands to work as a seamless whole? Not needed, gone. Rich built-in groupware, enabling teams to cooperate and work on shared documents? Forgotten. Plain-text email was enough.</p>
<p>Meanwhile, down at the budget end and at the same time as these tens-of-thousands-of-dollar single-user workstations, dumb terminals evolved into microcomputers. Every computer in the world today is, at heart, a "micro."</p>
<p>At first, they were feeble. They could hardly do anything. So, this time around, we lost <em>tons</em> of stuff.</p>
<p>Hard disks? Too expensive. Dropped. Multitasking? Not enough memory. Removed. Choice of programming languages? Retained in the 1970s CP/M machines, then when they got cheaper still in the early '80s, dropped: kids don't need that. Shove BASIC in a ROM, that will do. The machines mostly got used for playing games anyway.</p>
<p>Early micros could handle floppy disk drives and had a DOS, but over the longer run, even those got eliminated: too expensive. Instead, you got an audio cassette recorder.</p>
<h3>How we got here</h3>
<p>Those early-1980s micros, the weakest, feeblest, most pathetic computers since the first 1940s mainframes, the early eight-bit micros, <em>those</em> are the ancestors of the computers you use today.</p>
<p>In fact, of all the early 1980s computers, the one with the most boring, unoriginal design, the one with <em>no</em> graphics and <em>no</em> sound – that, with a couple of exceptions, is the ancestor of what you use today. <a target="_blank" href="https://www.theregister.com/2007/11/17/tob_ibm_personal_computer/">The IBM PC</a>, which got expanded and enhanced over and over again to catch up and eventually, over about 15 years, exceed the abilities of its cheaper but cleverer rivals.</p>
<p>It is <a target="_blank" href="https://en.wikipedia.org/wiki/Dollo%27s_law_of_irreversibility" rel="nofollow">a sort of law of nature</a> that when you try to replace features that you eliminated, the result is never as good as if you designed it in at the beginning.</p>
<p>We run the much-upgraded descendants of the simplest, stupidest, and most boring computer that anyone could get to market. They were the easiest to build and to get working. Easy means cheap, and cheap sells more and makes more profit. So they are the ones that won.</p>
<p>There's a proverb about choosing a product: "You can have good, fast, and cheap. Choose any two!"</p>
<p>We got "fast" and "cheap." We lost "good", replaced by "reliable," which is definitely a virtue, but one that comes with an extremely high price.</p>
<h3>What we lost</h3>
<p>Like many a middle-aged geek, there was a time when I collected 1980s hardware, because what was inaccessible when it was new – because I couldn't afford it – was being given away for free. However, it got bulky and I gave most of it away, focusing on battery-powered portable kit instead, partly because it's interesting in its own way, and partly because it doesn't take up much room. You don't need to keep big screens and keyboards around.</p>
<p>That led me to an interesting machine: the <em>other</em> line of Apple computers, the ones that Steve Jobs had no hand in at all.</p>
<p>The machine that inspired Jobs, which led to the Lisa and then the Mac, was of course <a target="_blank" href="https://www.theregister.com/2023/03/16/the_xerox_alto_50_years/">the Xerox Alto</a>, a $30,000 deskside workstation. In Jobs' own words, he saw three amazing technologies that day, but he was so dazzled by one of them that he missed the other two. He was so impressed by the GUI that he missed the object-oriented graphical programming language, Smalltalk, and the Alto's <a target="_blank" href="https://www.theregister.com/2023/06/30/ethernet_50th_birthday/">built-in ubiquitous networking, Ethernet</a>.</p>
<p>The Lisa had none of that. The Mac had less. Apple spent much of the next 20 years trying to put them back. In that time, Steve Jobs hired John Sculley from PepsiCo to run Apple, and in return, Sculley fired Jobs. What Apple came up with during Sculley's reign was <a target="_blank" href="https://www.theregister.com/2010/07/26/newton_messagepad_120/">the Newton</a>.</p>
<p>I have two Newtons, an Original MessagePad and a 2100. I love them. They're a vision of a different future. But I never used them much: <a target="_blank" href="https://www.theregister.com/2014/03/07/bugger_my_jetpack_wheres_my_21stcentury_psion/?page=2">I used Psions</a>, which had a far simpler and less ambitious design, meaning that they were cheaper but did the job. This should be an industry proverb.</p>
<p>The Newton that shipped was a pale shadow of the Newton that Apple originally planned. There are traces of that machine out there, though, and that's what led to me uncovering the great computing war.</p>
<p>The Newton was – indeed, still is – a radical machine. It's designed to live in your pocket, store and track your information and habits. It had an address book, a diary, a note-taking app, astonishing handwriting recognition, and a primitive AI assistant. You could write "lunch with Alice" on the screen, and it would work out what you wrote, analyze it, work out from your diary when you normally had lunch, from your call history where you took lunch most often and which Alice you contacted most often, book a time slot in your diary and send her a message to ask her if she'd like to come.</p>
<p>It was something like Siri, but 20 years earlier, and in that time, Apple seems to have forgotten all this: It had to buy Siri in.</p>
<p>NewtonOS also had no file system. I don't mean it wasn't visible to the user; I mean there wasn't one. It had some non-volatile memory on board, expandable via memory cards – huge PCMCIA ones the size of half-centimetre-thick credit cards – and it kept stuff in a sort of OS-integrated object database, segregated by function. The stores were called "soups" and the OS kept track of what was stored where. No file names, no directories, nothing like that at all.</p>
<p>Apps, and some of the OS itself, were written in a language called NewtonScript, which is very distantly related to both AppleScript on modern macOS and JavaScript. But that was not the original plan. That was for a far more radical OS, in a more radical language, one that could be developed in an astounding graphical environment.</p>
<p>The language was called <a target="_blank" href="https://www.schneier.com/essays/archives/1992/09/dylan_a_new_language.html" rel="nofollow">Dylan</a>, which is short for Dynamic Language. It <a target="_blank" href="https://opendylan.org/" rel="nofollow">still exists</a> as a FOSS compiler. Apple seems to have forgotten about it too, because it reinvented that wheel, worse, with Swift.</p>
<p>Have a look. Dylan is amazing, and its <a target="_blank" href="https://opendylan.org/history/apple-dylan/eulogy.html" rel="nofollow">SK8 IDE</a> even more so (a few <a target="_blank" href="https://www.macintoshrepository.org/2625-apple-sk8" rel="nofollow">screenshots and downloads</a> are left). Dylan is very readable, very high-level, and before the commercial realities of time and money prevailed, Apple planned to write an OS, and the apps for that OS, in Dylan.</p>
<p>Now <em>that</em> is radical: Using the same, very high-level, language for both the OS and the apps. It was feasible because Dylan is built as a layer on top of one of the oldest programming languages that's still in active use, Lisp.</p>
<p>Both Smalltalk and Lisp are very much still around. For both, there are commercial and FOSS versions. Both can run on the .NET CLR and on the JVM. There's even a Smalltalk that <a target="_blank" href="https://amber-lang.net/" rel="nofollow">runs in your browser</a> on the JavaScript engine. The primary text editor of the Lisp environment is still widely used today, mostly by old-timers.</p>
<p>But these are only traces. They are faint memorials left after the war. Because once, these things were not just slightly weird languages that ran on commodity OSes.</p>
<h3>They were OSes in their own right</h3>
<p>I started digging into that, and that's when the ground crumbled away, and I found that, like some very impressive CGI special effects, I wasn't excavating a graveyard but a whole, hidden, ruined city.</p>
<p>Once, Lisp ran on the bare metal, on purpose-built computers that ran operating systems written in Lisp, ones with GUIs that could connect to the internet.</p>
<p>And if you find the people who used Lisp machines ... wow. They loved them, with a passion that makes Amiga owners look like, well, amateurs, hobbyists. This level of advocacy makes Vi versus Emacs look like a playground squabble.</p>
<p>Some of the references are easy to find. There's a wonderful book called <a target="_blank" href="https://web.mit.edu/~simsong/www/ugh.pdf" rel="nofollow">The Unix-Haters Handbook</a> [PDF] which I highly recommend. It's easy to read and genuinely funny. It's a digest of a long-running internet community from the time when universities were getting rid of Lisp machines and replacing them with cheaper, faster Unix workstations – Sun boxes and things like that.</p>
<p>Lisp machine users were not impressed. For them, Unix was a huge step <em>backwards</em>. The code was all compiled, whereas Lisp OSes ran a sort of giant shared dynamic environment (it's hard to explain something when the words for it have been lost). On a Unix machine, if you didn't like the way a program did something, you had to go find the source code, edit it, save it in a new file, compile that file, restart the program to try it ... and if it worked, find your existing binary, and replace it with the new one. Then you would probably find that you'd made a mistake and it didn't work, and try again.</p>
<p>This is why, apart from the hardcore Gentoo users, we all outsource this stuff to OS vendors and Linux distributors.</p>
<p>On the Lisp machines, your code wasn't trapped inside frozen blocks. You could just edit the live running code and the changes would take effect immediately. You could inspect or even change the values of variables, as the code ran. Developer and blogger Steve Yegge called it "<a target="_blank" href="https://steve-yegge.blogspot.com/2007/01/pinocchio-problem.html" rel="nofollow">living software</a>."</p>
<p>Lisp machines booted slowly, but that didn't matter much because you rarely cold booted them. At the end of the day, the OS wrote the values of all its objects and variables to disk – called "saving a world" – and then just stopped. When you turned it back on, it reread these values into memory, and resumed exactly where it was.</p>
<p>Most of this, incidentally, also applies to Smalltalk machines. That's why these two are sometimes called <a target="_blank" href="http://onsmalltalk.com/languages-of-the-gods" rel="nofollow">languages of the gods</a>.</p>
<p><em>This</em> is what Steve Jobs missed. He was distracted by the shiny. He brought the world the GUI, but he got his team to reimplement it on top of fairly conventional OSes, originally in a mixture of assembly and Pascal.</p>
<p>He left behind the amazing rich development environment, where it was objects all the way down.</p>
<h3>And we never got it back</h3>
<p>We got networking back, sure, but not this.</p>
<p>Now Lisp and Smalltalk are just niche languages – but once, both of them were whole other universes. Full-stack systems, all live, all dynamic, all editable on the fly.</p>
<p>The closest thing we have today is probably JavaScript apps running in web browsers, and they are crippled little things by comparison.</p>
<p>The difference, though, is where the biggest losses in the war came.</p>
<p>Smalltalk machines ran on relatively normal processors. Smalltalk is all about objects, and you can't really handle objects at hardware level.</p>
<p>(Well, you <em>can</em> – a very expensive Hi-Fi manufacturer called <a target="_blank" href="https://www.theregister.com/2023/07/10/jony_ive_linn_turntable/">Linn</a> tried with a machine called the Rekursiv, but it flopped badly. So did Intel's attempt to do a chip that implemented high-level stuff in hardware – not the Itanium, no, long before that, the iAPX 432.)</p>
<p>But <a target="_blank" href="https://www.lispmachine.net/" rel="nofollow">Lisp machines</a> ran on dedicated chips, and this is where stuff gets real. As in, the <em>stuff</em> that hits the fan.</p>
<p>There were several big vendors of Lisp machines. As <a target="_blank" href="https://www.theregister.com/2023/11/23/medley_interlisp_revival/">we covered recently</a>, Xerox sold them, and its Lisp OS is now FOSS.</p>
<p>But the bigger one, and the most influential, was <a target="_blank" href="https://www.ifis.uni-luebeck.de/~moeller/symbolics-info/index.html" rel="nofollow">Symbolics</a>. At risk of sounding like a hipster, "you've probably never heard of it." Forgotten as it is now, as an indication of how significant the company was, it owned <a target="_blank" href="https://www.theguardian.com/media/pda/2008/dec/22/internet-domains" rel="nofollow">the first ever dot-com domain</a> on the internet. It launched in 1980 with a commercial version of the <a target="_blank" href="https://www.theregister.com/2023/03/31/mit_cadr_software_recovered/">MIT CADR Lisp machine</a>, and made dedicated Lisp hardware until 1993.</p>
<ul>

<li><a href="https://www.theregister.com/2023/11/23/medley_interlisp_revival/">Revival of Medley/Interlisp: Elegant weapon for a more civilized age sharpened up again</a></li>

<li><a href="https://www.theregister.com/2023/03/31/mit_cadr_software_recovered/">Version 100 of the MIT Lisp Machine software recovered</a></li>

<li><a href="https://www.theregister.com/2023/02/16/bulletproof_linux/">The quest to make Linux bulletproof</a></li>

<li><a href="https://www.theregister.com/2022/09/16/rust_in_the_linux_kernel/">Linux luminaries discuss efforts to bring Rust to the kernel</a></li>
</ul>
<p>The company's dead, but the OS, OpenGenera, is still <a target="_blank" href="https://archive.org/details/OpenGenera" rel="nofollow">out there</a> and you can <a target="_blank" href="https://jaoswald.blogspot.com/2020/05/open-genera-vlm-on-linux.html" rel="nofollow">run it on an emulator</a> on Linux. It's the end result of several decades of totally separate evolution from the whole Mac/Windows/Unix world, so it's kind of arcane, but it's out there.</p>
<p>There are a lot of accounts of the power and the productivity possible in Lisp and on Lisp machines.</p>
<p>One of the more persuasive is from a man called Kalman Reti, the last working Symbolics engineer. So loved are these machines that people are still working on their 30-year-old hardware, and Reti maintains them. He's made some YouTube videos demonstrating OpenGenera on Linux.</p>
<p>He <a target="_blank" href="https://docs.google.com/file/d/0Bw4Wz8Ir0pl1cmNRaHYwdU1wdXM/" rel="nofollow">talks about</a> [video] the process of implementing the single-chip Lisp machine processors.</p>

<p>Now that is significant.</p>
<p>When different people tell you that they can achieve such a huge differential in productivity – one tenth of the people taking one tenth of the time to do the same job – you have to pay attention.</p>
<p>
  <a href="https://youtu.be/OBfB2MJw3qg?si=kLqyzm4v19TCYrdB" data-media="x-videoplayer">Youtube Video</a>
</p>
<h3>'Better is the enemy of good'</h3>
<p>I am <em>not</em> here to tell you that Lisp machines were some ultimate super workstation. An environment that is mostly semi-interpreted code, running in a single shared memory space, is not very stable ... and when it crashes, if you don't have a snapshot to go back to, you have pain in store.</p>
<p>The point here is not that this long-gone technology was better in every way. It wasn't. But it did have advantages, and it's instructive to look at some of these that were shared by both Lisp and Smalltalk machines.</p>
<p>They were written in one language, or mostly in one, all the way down. As original Smalltalk implementer Dan Ingalls put it: "An operating system is a collection of things that don't fit inside a language; there shouldn't be one."</p>
<p>They had a pervasive model of data, all the way down the stack. In Smalltalk, everything is objects. In Lisp, everything is lists. What the Unix&nbsp;model offers by comparison is weak stuff: Everything is a file.</p>
<h3>More big lies</h3>
<p>The Unix model of computation was designed in response to Multics, the original all-singing, all-dancing 1960s OS. Unix was intended, in contrast, to be the ultimate in minimalism (although it very much&nbsp;is not anymore).</p>
<p>This shows up another of the big lies that everyone just takes as read, but this one has layers like a cabbage:</p>
<ul>
<li>For speed, you need a language that's close to the metal. That means it must be very simple. This has costs, but they're worth it: the programmer must manually manage their memory, meaning that they must be very, <em>very</em> careful.</li>

<li>But that's hard, so to keep life easier, you layer simpler languages on top. Early on, AWK and SED and so on; later, Perl and Python; then later still, runtimes such as the JVM and WASM, and languages on top of that, such as Clojure or Scala.</li>

<li>As the stack matures, it grows ever more layers. The higher layers are ever further from the metal.</li>

<li>Many of these languages are much easier but slower. In the old days, you needed to rewrite code in a lower-level language for speed, such as C++. So what if it's huge? You don't need all of it! So what if it's hard to read? It was hard to write!</li>

<li>Then, in time, computers keep getting faster, so you can retain the inefficient implementation and keep going.</li>
</ul>
<p>The result is a folk belief that there is a necessary, implicit contrast between "readable" and "fast." This is one of the big assumptions behind both the Unix and Windows schools of OS design, that different languages are best for different jobs, and so you need a mixture of them. That means that the layers are sealed off from one another, because of different models of variable storage, of memory management, etc.</p>
<p>That's one big lie.</p>
<p>Firstly, because the layers are <em>not</em> sealed off: higher-level languages are usually implemented in lower-level ones, and vulnerabilities in those permeate the stack.</p>
<p>For instance, a common way of trying to make stuff safer is to wrap it in a runtime or VM, but that doesn't solve the problem, it creates new ones. Problem: The language eliminates whole types of error, but they persist in the VM. Problem: Now, your code is dependent on the performance of the VM. Problem: Try to fix either of these, you risk breaking the code. Problem: Because the VM isn't part of the OS, you end up with multiple VMs, all sharing these issues.</p>
<p>Secondly, there is the <a target="_blank" href="https://sites.millersville.edu/bikenaga/math-proof/existence-proofs/existence-proofs.html" rel="nofollow">existence&nbsp;proof</a> that multiple projects and products, successful in their time, show that if you pick the right language, you can built your entire stack all in one.</p>
<p>Lisp code is structured as lists, which is the data structure that Lisp is designed to manipulate. That is the reason for its <a target="_blank" href="https://toggl.com/blog/save-princess-8-programming-languages" rel="nofollow">legendary plethora of parentheses</a>. It also makes it very easy to write macros that manipulate program code, meaning programs can modify themselves. This sort of thing is why Neal Stephenson <a target="_blank" href="https://web.stanford.edu/class/cs81n/command.txt" rel="nofollow">referred to it</a> thus:</p>

<p>It is highly readable, and vastly powerful. Alan Kay, the designer of Smalltalk, <a target="_blank" href="https://queue.acm.org/detail.cfm?id=1039523" rel="nofollow">said of Lisp</a>:</p>

<p>These are powerful qualities – but possibly only to a certain type of mind.</p>
<p>Dylan, however, shows that it need not be like that. If you lose the list-based notation, yes, there is a price in efficiency and power, but the result is readable by mere mortals. Dylan was not the only attempt to do this. There are quite a few – <a target="_blank" href="http://users.rcn.com/david-moon/PLOT/" rel="nofollow">PLOT</a>, <a target="_blank" href="https://dspace.mit.edu/handle/1721.1/41951" rel="nofollow">CGOL</a>, <a target="_blank" href="https://readable.sourceforge.io/" rel="nofollow">sweet expressions</a>, the cancelled <a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/1464291.1464362" rel="nofollow">Lisp 2 project</a>, and more.</p>
<p>The plan was that the Newton would be a Dylan-based Lisp machine in your pocket. The Newton was Sculley's baby. Jobs didn't invent it, so he didn't like it, derided it as a "<a target="_blank" href="https://allthingsd.com/20120113/former-apple-ceo-says-newton-scribble-thing-was-15-years-ahead-of-its-time/" rel="nofollow">scribble thing</a>," and on his return to Apple he killed it <a target="_blank" href="http://www.loper-os.org/?p=568" rel="nofollow">along with Hypercard</a>.</p>
<p>In 1993, the Newton was Apple's first Arm-powered computer, a CPU architecture it returned to 17 years later. It was planned to be the a pocket Lisp workstation, and it launched the same year that Symbolics quit making Lisp processors and <a target="_blank" href="http://pt.withington.org/publications/VLM.pdf" rel="nofollow">moved to the DEC Alpha</a> [PDF] instead.</p>
<p>In the end, the big fight was between dedicated hardware, with custom processors running custom operating systems, versus a shared, lowest-common-denominator technology: UNIX, running at first on off-the-shelf chips such as the <a target="_blank" href="https://www.historyofinformation.com/detail.php?id=960" rel="nofollow">Sun-1's Motorola 68000</a> and later on RISC chips such as Sun's SPARC and the MIPS R2000, launched the same year as <a target="_blank" href="https://www.theregister.com/2022/06/21/risc_os_35/">Acorn's RISC OS 2 on its ARM chips</a>. A cross-platform OS, its development sponsored by Bell Labs and refined at the University of California, compiled from source written in a <a target="_blank" href="https://www.theregister.com/2020/05/15/algol_60_at_60/">cut-down form of BCPL</a>.</p>
<p>As is usually the way, the cheaper, simpler solution won. Commodity chips were replaced with faster RISC chips, broadly speaking designed to run compiled C code efficiently. Then, decades later, the PC caught up: 32-bit x86 processors became comparable in performance to the RISC chips, and we ended up with a few varieties of Unix on x86, plus Windows NT. Unix, of course, was originally developed on the DEC PDP-7, moved to the PDP-11, and later its 32-bit successor the VAX. Windows NT, meanwhile, was <a target="_blank" href="https://www.theregister.com/2023/10/30/arm_intel_comment/">designed by the chief architect</a> of the VAX's native OS, VMS. That's why it's so visibly influenced by it. Instead of DEC's BLISS language, NT is implemented in Unix's native language, C.</p>
<p>From the perspective of a Smalltalk or Lisp machine, they are siblings, almost twins, with deep roots in DEC. They are representatives of a school of design called the "New Jersey approach" by Lisp luminary Richard Gabriel in his essay "<a target="_blank" href="https://www.dreamsongs.com/Files/LispGoodNewsBadNews.pdf" rel="nofollow">Lisp: Good News, Bad News, How to Win Big</a>" [PDF]. He compares it to what he calls the "MIT approach," and his summary of the New Jersey way is called "<a target="_blank" href="https://www.dreamsongs.com/RiseOfWorseIsBetter.html" rel="nofollow">Worse is Better</a>."</p>
<p>It's well worth reading at least the summary, but the key points are this.</p>

<p>He continues:</p>

<p>The conclusion, though, is the stinger:</p>

<p>Time has certainly proved Dr Gabriel correct. Systems of the New Jersey school so dominate the modern computing industry that the <em>other</em> way of writing software is banished to a tiny niche.</p>
<p>Smalltalk&nbsp;evolved into Self, which begat JavaScript, which in the hands of a skilled Smalltalker <a target="_blank" href="https://www.theregister.com/2023/03/23/croquet_for_unity/">can do amazing things</a> – but only its visual design transformed the computer industry.</p>
<p>The Lisp text editor is now just one of the more arcane options on Linux boxes. Lisp itself is a fringe programming language, <a target="_blank" href="http://www.paulgraham.com/avg.html" rel="nofollow">beloved by some industry heroes</a> but ignored by most – even those who <a target="_blank" href="https://flownet.com/gat/jpl-lisp.html" rel="nofollow">need the very best tools</a>. As one famous Lisp programmer <a target="_blank" href="https://www.marktarver.com/bipolar.html" rel="nofollow">put it</a>:</p>

<p>If you want to become a billionaire from software, you don't want rockstar geniuses; you need <a target="_blank" href="http://www.loper-os.org/?p=69" rel="nofollow">fungible cogs</a>, interchangeable and inexpensive.</p>
<p>Software built with tweezers and glue is not robust, no matter how many layers you add. It's terribly fragile, and needs armies of workers constantly fixing its millions of cracks and holes.</p>
<p>There was once a better way, but it lost out to cold hard cash, and now, only a few historians even remember it existed. ®</p>
<h3>Bootnote</h3>
<p>For a look at a Lisp machine in action, as well as BTRON and IBM i, this talk from the Chaos Computer Congress entitled "<a target="_blank" rel="nofollow" href="https://media.ccc.de/v/rc3-525180-what_have_we_lost#l=eng&amp;t=0">What have we lost?</a>" is worth a watch.</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Matter, set to fix smart home standards in 2023, stumbled in the real market (112 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/12/matter-was-more-of-a-nice-smart-home-concept-than-useful-reality-in-2023/</link>
            <guid>38763743</guid>
            <pubDate>Mon, 25 Dec 2023 16:15:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/12/matter-was-more-of-a-nice-smart-home-concept-than-useful-reality-in-2023/">https://arstechnica.com/gadgets/2023/12/matter-was-more-of-a-nice-smart-home-concept-than-useful-reality-in-2023/</a>, See on <a href="https://news.ycombinator.com/item?id=38763743">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      A matter for the future    —
</h4>
            
            <h2 itemprop="description">Gadget makers, unsurprisingly, are hesitant to compete purely on device quality.</h2>
                    </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/matter2-800x450.jpg" alt="Illustration of Matter protocol simplifying a home network">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/matter2.jpg" data-height="864" data-width="1536">Enlarge</a> <span>/</span> The Matter standard's illustration of how the standard <em>should</em> align a home and all its smart devices.</p><p>CSA</p></figcaption>  </figure>

  




<!-- cache hit 308:single/related:19963e8f694f57cfa48aa8c975960d5e --><!-- empty -->
<p>Matter, as <a href="https://arstechnica.com/gadgets/2022/10/matter-and-thread-could-fix-smart-home-compatibility-but-dont-get-excited-yet/">a smart home standard</a>, would make everything about owning a smart home better. Devices could be set up with any phone, for either remote or local control, put onto any major platform (like Alexa, Google, or HomeKit) or combinations of them, and avoid being orphaned if their device maker goes out of business. Less fragmentation, more security, fewer junked devices: win, win, win.</p>
<p>Matter, as it exists in late 2023, more than a year after its 1.0 specification was published and just under a year after the first devices came online, is more like the <a href="https://xkcd.com/927/">xkcd scenario</a> that lots of people might have expected. It's another home automation standard at the moment, and one that isn't particularly better than the others, at least how it works today. I wish it was not so.</p>
<p>Setting up a Matter device isn't easy, nor is making it work across home systems. Lots of devices with Matter support still require you to download their maker's specific app to get full functionality. Even if you were an early adopting, Matter-T-shirt-wearing enthusiast, you're still buying devices that don't work quite as well, and still generally require a major tech company's gear to act as your bridge or router.</p>
<figure><img alt="CSA's illustration of how smart homes worked before Matter, which is unfortunately a lot like how they still work, after." src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/matter1.jpg" width="1536" height="863"><figcaption><p>CSA's illustration of how smart homes worked before Matter, which is unfortunately a lot like how they still work, after.</p><p>CSA</p></figcaption></figure>
<h2>Lights that Matter, but do less</h2>
<p>Jennifer Pattison Tuohy at The Verge has done more Matter writing, and testing, than just about anybody out there who doesn't work for the Connectivity Standards Alliance that oversees the spec. As <a href="https://www.theverge.com/23997548/matter-smart-home-2023-platforms">she puts it</a>:</p>                                            
                                                        
<blockquote><p>I’ve been testing Matter devices all year, and it has been the most frustrating year of my decade-plus experience with smart home devices. Twelve months in, I do not have one Matter-based device working reliably in my home. To make matters worse (yeah, I know), the one system that’s always been rock solid, my Philips Hue smart lights, is basically unusable in any of my smart home platforms since I moved it to Matter.</p></blockquote>
<p>When the Matter upgrade for Hue lights rolled out in September, I didn't move to switch my bulbs over. For one thing, it wouldn't result in a net loss of limited-purpose hardware (i.e. hubs). If you wanted to move your Hue bulbs over to Matter and control them through Google's Home app, you'd need a Google Home Hub or Home Mini to act as a Matter bridge device. The same goes for Alexa (Echo devices), Samsung SmartThings (a Hub), or Apple Home (an Apple TV or HomePod/mini). You also lose some Hue-specific function, like gradient lighting and scenes (like holiday green/red schemes). And, as Tuohy has noted, it's likely not a more reliable network than the proprietary Zigbee setup that Hue ran on before.</p>
<p>The smart home and automation market is like that pretty much everywhere. Aqara offers a <a href="https://www.aqara.com/en/product/led-strip-t1/">Matter-compliant light strip, the T1</a>, but it requires a hub, and using Matter means you can't use Apple's light-sensing adaptive brightness, because Matter doesn't support that yet. The same goes for Nanoleaf's Matter-friendly <a rel="nofollow" href="https://www.amazon.com/dp/B0C1JD5YXW/?tag=arstech20-20">bulbs</a> and <a href="https://nanoleaf.me/en-US/products/essentials/lightstrips/?category=lightstrips&amp;standard=matter&amp;pack=smarter-kit&amp;size=2">strips</a>, which are Matter and Thread capable but require Nanoleaf's own app to provide Nanoleaf's version of adaptive lighting.</p>
<figure><img src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/homekit_button.png" width="1200" height="630"><figcaption><p>Apple Developer</p></figcaption></figure>

                                                </div>

            
            
                            <nav>Page: <span>1 <a href="https://arstechnica.com/gadgets/2023/12/matter-was-more-of-a-nice-smart-home-concept-than-useful-reality-in-2023/2/">2</a> <a href="https://arstechnica.com/gadgets/2023/12/matter-was-more-of-a-nice-smart-home-concept-than-useful-reality-in-2023/2/"><span>Next <span>→</span></span></a></span></nav>
            
        </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stupid Patent of the Month: Selfie Contests (168 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2023/12/stupid-patent-month-selfie-contests</link>
            <guid>38763566</guid>
            <pubDate>Mon, 25 Dec 2023 15:51:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2023/12/stupid-patent-month-selfie-contests">https://www.eff.org/deeplinks/2023/12/stupid-patent-month-selfie-contests</a>, See on <a href="https://news.ycombinator.com/item?id=38763566">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>Patents are supposed to be an incentive to invent. Too often, they end up being a way to try to claim “ownership” of what should be basic building blocks of human activity, culture, and knowledge. This is especially true of </span><a href="https://www.eff.org/issues/patents"><span>software patents</span></a><span>, an area EFF has been speaking out about for more than 20 years now.&nbsp;</span></p>
<p><span>This month’s Stupid Patent, No. </span><a href="https://patents.google.com/patent/US8655715B2/"><span>8,655,715</span></a><span>, continues the tradition of trying to use software language to capture a monopoly on a basic human cultural activity–in this case, contests.&nbsp;</span></p>
<p><span>A company called Opus One, which does business under the name “Contest Factory,” claims this patent and </span><a href="https://patents.google.com/patent/US10891642B2/en"><span>a related one</span></a><span> cover a huge array of online contests. So far, they’ve filed five lawsuits against other companies that help build online contests, and even threatened a small photo company that organizes mostly non-commercial contests online.&nbsp;</span></p>
<p><span>The patents held by Contest Factory are a good illustration of why EFF has been concerned about out-of-control software patents. It’s not just that wrongly issued patents extort a vast tax on the U.S. economy (although they do—one study </span><a href="https://hbr.org/2014/07/the-evidence-is-in-patent-trolls-do-hurt-innovation"><span>estimated $29 billion in annual direct costs</span></a><span>). The worst software patents also harm peoples’ rights to express themselves and participate in online culture. Just as we’re free in the physical world to </span><a href="https://www.eff.org/deeplinks/2023/01/stupid-patent-month-digital-verification-systems-patents-e-signatures"><span>sign documents</span></a><span>, </span><a href="https://www.eff.org/deeplinks/2019/12/how-patent-sorting-photos-got-used-sue-free-software-group"><span>sort photos</span></a><span>, </span><a href="https://arstechnica.com/tech-policy/2015/10/east-texas-judge-throws-out-168-patent-cases-in-one-fell-swoop/"><span>store and label information</span></a><span>, </span><a href="https://www.eff.org/deeplinks/2023/02/stupid-patent-month-clocking-work-app"><span>clock in to work</span></a><span>, </span><a href="https://www.eff.org/deeplinks/2022/05/patent-troll-uses-ridiculous-people-finder-patent-sue-small-dating-companies"><span>find people to date</span></a><span>, or </span><a href="https://www.eff.org/deeplinks/2018/07/effs-help-language-teacher-responds-ridiculous-patent-threat"><span>teach foreign languages</span></a><span>, without paying extortionate fees to others, we must also be free to do so online.&nbsp;</span></p>
<h3><strong><span>Patenting Contests</span></strong></h3>
<p><span>Claim 1 of the ‘715 patent has steps that claim:&nbsp;</span></p>
<ul>
<li><span>Receiving, storing, and accessing data on a computer;&nbsp;</span></li>
<li><span>Sorting it and generating “contest data”;&nbsp;</span></li>
<li><span>Tabulating votes and picking a winner.</span></li>
</ul>
<p>The patent also uses other terms for common activities of general purpose computers, such as “transmitting” and “displaying” data.&nbsp;</p>
<p><span>In other words, the patent describes everyday use of computers, plus the idea of users participating in a contest. This is a classic abstract idea, and it never should have been eligible for a patent.&nbsp;</span></p>
<p><span>In a </span><a href="https://gamification.cioreview.com/vendor/2017/contest_factory"><span>2017 article in CIO Review</span></a><span>, the company acknowledges how incredibly broad its claims are. Contest Factory claims it patented “voting in online contests long before TV contest shows with public voting components made their appearance,” and that it holds patents “associated with online contests and integrating online voting with virtually any type of contest.”&nbsp;</span></p>
<h3><strong>Lawsuit Over Radio Station Contest&nbsp;</strong></h3>
<p><span>In its most recent lawsuit, Contest Factory says that a Minneapolis radio station’s “Mother’s Day Giveaway” for a mother/daughter spa day infringed its patent. The radio station asked people to post mother-daughter selfies online and share their entry to collect votes.&nbsp;</span></p>
<p><span>Contest Factory sued Pancake Labs (</span><a href="https://www.eff.org/document/contest-factory-v-pancake-labs"><span>complaint</span></a><span>), the company that helped the radio station put the contest online. Contest Factory also claimed a </span><a href="https://www.shortstack.com/blog/how-pbs-maximizes-shortstacks-scalability-versatility-and-customizability-when-creating-digital-marketing-campaigns"><span>PBS contest</span></a><span> in which viewers created short films and voted on them was an example of infringement.&nbsp;</span></p>
<p><span>For the “Mother’s Day Giveaway” contest, the patent infringement accusation reads in part that, “the executable instructions … cause the generation of a contest and the transmission of the first and second content data to at least one user to view and rate the content.”&nbsp;</span></p>
<p><span>Contest Factory has sued over quite a few internet contests, dating back more than a decade. Its 2016 lawsuits, based on the ‘715 patent and two earlier related patents,&nbsp;were filed against three small online marketing firms: Vancouver-based </span><a href="https://www.strutta.com/about/"><span>Strutta</span></a><span>, Florida-based </span><a href="https://www.linkedin.com/company/elettro"><span>Elettro</span></a><span>, and California-based </span><a href="https://www.votigo.com/"><span>Votigo</span></a><span>, for contests that go back to 2011. We don’t know how many more companies or online communities have been threatened in all.&nbsp;</span></p>
<p><span>Sharing user-generated content like photos—cooperatively or competitively—is the kind of sharing that the digital world is ideal for. When patent owners demand a toll for these activities, it doesn’t matter whether they’re patent “trolls” or operating companies seeking to extract settlements from competitors. They threaten our freedoms in unacceptable ways.&nbsp;</span></p>
<p><span>The government shouldn’t be issuing patents like these, and it certainly shouldn’t be making them </span><a href="https://www.eff.org/deeplinks/2023/11/publics-right-fight-bad-patents-must-be-protected"><span>harder to challenge</span></a><span>.&nbsp;</span></p>

<ul>
<li><span>Opus One d/b/a Contest Factory v. Pancake Labs </span><a href="https://www.eff.org/document/contest-factory-v-pancake-labs"><span>complaint</span></a></li>
<li><span>Opus One d/b/a Contest Factory v. Telescope </span><a href="https://www.eff.org/document/contest-factory-v-telescope"><span>complaint&nbsp;</span></a></li>
<li><span>Opus One d/b/a Contest Factory v. Elletro </span><a href="https://www.eff.org/document/contest-factory-v-elletro"><span>complaint&nbsp;</span></a></li>
<li><span>Opus One d/b/a Contest Factory v. Votigo </span><a href="https://www.eff.org/document/contest-factory-v-votigo"><span>complaint&nbsp;</span></a></li>
<li><span>Opus One d/b/a Contest Factory v. Strutta </span><a href="https://www.eff.org/document/contest-factory-v-strutta-complaint"><span>complaint</span></a></li>
</ul>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unblocking User Freedom: the right to use adblockers (146 pts)]]></title>
            <link>https://fsfe.org/news/2023/news-20231220-01.en.html</link>
            <guid>38763165</guid>
            <pubDate>Mon, 25 Dec 2023 15:06:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fsfe.org/news/2023/news-20231220-01.en.html">https://fsfe.org/news/2023/news-20231220-01.en.html</a>, See on <a href="https://news.ycombinator.com/item?id=38763165">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">


<p id="category"><a href="https://fsfe.org/news/news.en.html">News</a></p>

<p><span>on: </span><time>2023-12-20</time>
</p>

<p>Companies increasingly aim to control how users interact with their 
content online, threatening user freedom. As more companies crack down 
on browser extensions and other third-party software used by internet 
users to customise their experiences, two recent German court cases on 
adblockers could strengthen the legal case for user control over 
technology.</p>

<figure>
  <img src="https://pics.fsfe.org/uploads/medium/c2/a1/d5fc8d5a7998f9146d7be156e0f2.png" alt="An illustration about privacy showing eyes behind some bars">
  <figcaption>
    CC-BY-NC-SA by <a href="http://rahak.net/work.html">Rahak</a>
  </figcaption>
</figure>

	
<p>Advertisements are a part of our lives, including our digital ones. 
They are in the websites we browse, the search results we receive, and 
the online news we read. Tired of receiving so many ads, some users try 
to avoid them by installing an adblocker. But is this a legal practice? 
Is using adblockers an act of restricting market autonomy, or do they 
help achieve user freedom?</p>

<p>Imagine a scenario where website owners hold copyright over their 
websites, including whatever ads they place, and could effectively sue 
for copyright infringement if users were to remove or suppress ads when 
visiting these websites. This hypothetical situation would enable any 
website copyright holder to use the legal system to stop any ordinary 
user on the internet who tries to bypass these ads. This would 
lead to an internet where unsolicited information 
and advertisements are imposed on users. Fortunately, recent court 
decisions have at least prevented this hypothetical from becoming a 
reality in Germany.</p> 

<h2 id="id-is-it-legal-to-use-adblockers-the-lawsuit-in-question">Is it legal to use adblockers? The lawsuit in question</h2>

<p>Using an adblocker is the main way in which many internet users 
bypass ads and pop-ups when accessing websites. Adblockers usually come 
in the form of browser extensions and plugins that filter out unwanted 
ads for an ad-free internet browsing experience.</p> 

<p>As the use of these adblockers increases, some companies have begun 
considering whether it is legal for  users to be able to block their 
ads. This was the case in Germany when Axel Springer SE (Axel 
Springer), one of Germany’s largest publishing companies, engaged in 
lawsuits against Eyeo GmbH (Eyeo), the creator of <a href="https://adblockplus.org/en/about#whymoney">Adblock Plus</a> (a 
Free 
Software adblocking tool licensed under the GPLv3). These lawsuits have 
resulted in a legal battle for user freedom and an open internet.</p>

<p>In the case of Adblock Plus, ads are blocked according to filter rules 
maintained in a so-called “black list”, which users use as a default 
setting. The extension offers ad providers the possibility of having 
their ads excluded from this black list (and included in a “white 
list”) by complying with <a href="https://acceptableads.com/standard/">“acceptable advertising 
standards”,</a> disclosing 
their annual turnover, and paying a sum to Eyeo. Users will only see 
ads that have been included in the white list, but they also have the 
option of blocking ads from both white and black lists altogether.</p>

<div>
<p>Axel Springer filed several suits in Germany against Eyeo on the grounds 
that the Adblock Plus extension interfered with their business, 
alleging that by blocking its advertisements, Eyeo had engaged in 
anti-competitive measures. According to Axel Springer, Eyeo’s business 
model constituted:</p>
<ol>
<li>Targeted obstruction and aggressive business practice; and </li>
<li>A violation of freedom of the press.</li>
</ol>
</div>

<h3 id="id-the-right-not-to-be-advertised-to">The right not to be advertised to</h3> 
<p>After ruling that the option to use adblockers is a decision that internet users should be able to make, 
the courts in Germany ruled that user rights not only include the 
freedom to express an opinion and to receive information, but also the 
rights to refrain from expressing an opinion and to refuse to receive 
imposed information. In doing so, the rulings considered a user’s 
interest in being spared from obtrusive advertising.</p>

<p>Accordingly, internet users are simply exercising their right to not 
have certain forms of advertising displayed when visiting internet 
websites when they choose to make use of an adblocker. Adblock Plus’s 
business model, according to the courts, was therefore a marketable 
service offer which was not primarily aimed at impairing the 
competitive development of Axel Springer. In the opinion of the courts, 
Adblock Plus also does not directly interfere with the business, as 
users retain autonomy to do as they wish with the settings of the 
add-on after installation. Users can block or wish to see only the ads 
in the whitelist. Adblock Plus is therefore merely a product whose use 
is decided solely by the internet user.</p>

<h3 id="id-the-html-argument-does-the-use-of-adblockers-constitute-a-modification-of-a-computer-program">The HTML argument: does the use of adblockers constitute a modification of a computer program?</h3>

<p>Axel Springer also submitted an argument to the German courts that their
websites would be protected under German copyright law as a copyrighted 
computer program, and that their HTML code would similarly be covered 
under this ambit because of the control components it included. Because 
of how Adblock Plus interacts with its website, Axel Springer therefore 
claimed that copies and adaptations of the code in its website were 
violations of copyright made without permission.</p>

<p>In both the initial court ruling and the decision on the subsequent appeal in favour 
of Eyeo, the court disagreed with Axel Springer and held that the use 
of Adblock Plus solely affects the program flow through external 
commands, without altering the program’s essence or generating a 
changed version. Thus, the use of the extension results in a mere 
browser configuration carried out by users according to their 
preferences.</p>

<p>The courts noted that internet users do not require permission from 
website owners when they want to make the website look better for 
themselves. Modern websites are made up of many separate parts that can 
be technically distinguished from each other, including text, images, and 
videos, as well as software that is embedded in the HTML page. For the 
courts, it wasn’t enough that these software components were used in 
the website’s HTML page to mean that the website itself was a 
protectable computer program. We can therefore infer that adblockers 
do not infringe upon a program’s protections.</p>

<h2 id="id-downsides-of-the-case">Downsides of the case</h2> 
<p>Nevertheless, some aspects in the judgments are still not ideal in 
promoting the average user’s rights. While user freedom  means that 
users are able to use the tools that they wish to when browsing the 
World Wide Web, the court nevertheless preserved Axel 
Springer’s right to exclude users with an activated adblocker from 
accessing its content. This can be understood as an approval on the use 
of adblock detection tools by companies like Axel Springer.</p> 

<p>Unfortunately, the court also mentioned that Axel Springer can convert 
its content into a paid access model, justifying this measure as an 
element inherent for competition. We fear that this tacit approval can 
result in paywalls and adblock detection tools becoming the basic 
standard on the internet.</p> 

<p>More importantly, tools to detect the use of adblockers go against <a href="https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32002L0058">Art. 
5(3) of the ePrivacy directive</a>, which mandates that websites must seek 
consent before accessing or storing information about a user’s device. 
The EU commission has confirmed that, Art. 5(3) of the ePrivacy directive 
<a href="https://forum.adblockplus.org/viewtopic.php?t=45001">is not 
just limited to cookies but ‘all types of information’ stored or 
accessed</a> in the user’s terminal device. This applies to the storage by 
websites of scripts in users’ terminal equipment to detect if users 
have installed or are using adblockers.</p> 

<h2 id="id-a-win-for-user-freedom">A win for user freedom?</h2> 

<p>With many service providers and websites on the internet following the 
trend of restricting users with adblockers from accessing their services, these court 
decisions in Germany help build precedents that uphold and recognize 
principles of user freedom.</p> 

<p>Indeed, these decisions support the principles of a <a href="https://fsfe.org/activities/ngi/ngi.en.html">Next Generation 
Internet</a>, including ensuring that internet users can make individual 
choices and exercise their freedom of expression, in ways in which they 
can freely develop and use new extensions and browser features to 
enhance their online experience and user control.</p>  

<p>Despite the steps forward for user control found in these judgments, 
they do not go as far as we would hope to secure user freedom when 
using the internet, and are still subject to appeals and therefore may 
not be final. We will keep an eye on the legal proceedings in this case 
and keep you updated when new developments occur. In the meantime, the 
court cases can be read on the <a href="https://juris.bundesgerichtshof.de/cgi-bin/rechtsprechung/document.py?Gericht=bgh&amp;Art=en&amp;nr=8849">Bundesgerichtshof</a> 
and <a href="https://www.landesrecht-hamburg.de/bsha/document/JURE220021753">Landesgerichts</a> 
websites. If you are aware of any similar cases or other developments to 
support user freedom in any other member states in the EU, then please 
do share and reach out to us!</p>


<p id="discussion-link"><a href="https://community.fsfe.org/t/1114">Discuss this </a></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Non-interactive SSH password authentication (222 pts)]]></title>
            <link>https://vincent.bernat.ch/en/blog/2023-sshpass-without-sshpass</link>
            <guid>38762214</guid>
            <pubDate>Mon, 25 Dec 2023 12:55:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vincent.bernat.ch/en/blog/2023-sshpass-without-sshpass">https://vincent.bernat.ch/en/blog/2023-sshpass-without-sshpass</a>, See on <a href="https://news.ycombinator.com/item?id=38762214">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="lf-text">

<p>SSH offers several forms of authentication, such as <strong>passwords</strong> and
<strong>public keys</strong>. The latter are considered more secure. However, password
authentication remains prevalent, particularly with network equipment.<sup id="fnref-why"><a href="#fn-why">1</a></sup></p>
<p>A classic solution to avoid typing a password for each connection is
<a href="https://sourceforge.net/projects/sshpass/" title="sshpass: Non-interactive ssh password auth">sshpass</a>, or its more correct variant <a href="https://github.com/clarkwang/passh">passh</a>. Here is a wrapper for <em>Zsh</em>,
getting the password from <a href="https://www.passwordstore.org/" title="The standard UNIX password manager">pass</a>, a simple password manager:<sup id="fnref-security"><a href="#fn-security">2</a></sup></p>
<div><pre><span></span>pssh<span>()</span><span> </span><span>{</span>
<span>  </span>passh<span> </span>-p<span> </span>&lt;<span>(</span>pass<span> </span>show<span> </span>network/ssh/password<span> </span><span>|</span><span> </span>head<span> </span>-1<span>)</span><span> </span>ssh<span> </span><span>"</span><span>$@</span><span>"</span>
<span>}</span>
compdef<span> </span><span>pssh</span><span>=</span>ssh
</pre></div>


<p>This approach is a bit brittle as it requires to parse the output of the <code>ssh</code>
command to look for a password prompt. Moreover, if no password is required, the
password manager is still invoked. Since <a href="https://www.openssh.com/txt/release-8.4" title="OpenSSH 8.4 release notes">OpenSSH 8.4</a>, we can use
<code>SSH_ASKPASS</code> and <code>SSH_ASKPASS_REQUIRE</code> instead:</p>
<div><pre><span></span>ssh<span>()</span><span> </span><span>{</span>
<span>  </span><span>set</span><span> </span>-o<span> </span>localoptions<span> </span>-o<span> </span>localtraps
<span>  </span><span>local</span><span> </span><span>passname</span><span>=</span>network/ssh/password
<span>  </span><span>local</span><span> </span><span>helper</span><span>=</span><span>$(</span>mktemp<span>)</span>
<span>  </span><span>trap</span><span> </span><span>"command rm -f </span><span>$helper</span><span>"</span><span> </span>EXIT<span> </span>INT
<span>  </span>&gt;<span> </span><span>$helper</span><span> </span><span>&lt;&lt;EOF</span>
<span>#!$SHELL</span>
<span>pass show $passname | head -1</span>
<span>EOF</span>
<span>  </span>chmod<span> </span>u+x<span> </span><span>$helper</span>
<span>  </span><span>SSH_ASKPASS</span><span>=</span><span>$helper</span><span> </span><span>SSH_ASKPASS_REQUIRE</span><span>=</span>force<span> </span><span>command</span><span> </span>ssh<span> </span><span>"</span><span>$@</span><span>"</span>
<span>}</span>
</pre></div>


<p>If the password is incorrect, we can display a prompt on the second
tentative:</p>
<div><pre><span></span>ssh<span>()</span><span> </span><span>{</span>
<span>  </span><span>set</span><span> </span>-o<span> </span>localoptions<span> </span>-o<span> </span>localtraps
<span>  </span><span>local</span><span> </span><span>passname</span><span>=</span>network/ssh/password
<span>  </span><span>local</span><span> </span><span>helper</span><span>=</span><span>$(</span>mktemp<span>)</span>
<span>  </span><span>trap</span><span> </span><span>"command rm -f </span><span>$helper</span><span>"</span><span> </span>EXIT<span> </span>INT
<span>  </span>&gt;<span> </span><span>$helper</span><span> </span><span>&lt;&lt;EOF</span>
<span>#!$SHELL</span>
<span>if [ -k $helper ]; then</span>
<span>  {</span>
<span>    oldtty=\$(stty -g)</span>
<span>    trap 'stty \$oldtty &lt; /dev/tty 2&gt; /dev/null' EXIT INT TERM HUP</span>
<span>    stty -echo</span>
<span>    print "\rpassword: "</span>
<span>    read password</span>
<span>    printf "\n"</span>
<span>  } &gt; /dev/tty &lt; /dev/tty</span>
<span>  printf "%s" "\$password"</span>
<span>else</span>
<span>  pass show $passname | head -1</span>
<span>  chmod +t $helper</span>
<span>fi</span>
<span>EOF</span>
<span>  </span>chmod<span> </span>u+x<span> </span><span>$helper</span>
<span>  </span><span>SSH_ASKPASS</span><span>=</span><span>$helper</span><span> </span><span>SSH_ASKPASS_REQUIRE</span><span>=</span>force<span> </span><span>command</span><span> </span>ssh<span> </span><span>"</span><span>$@</span><span>"</span>
<span>}</span>
</pre></div>


<p>A possible improvement is to use a different password entry depending on the
remote host:<sup id="fnref-zsh"><a href="#fn-zsh">3</a></sup></p>
<div><pre><span></span>ssh<span>()</span><span> </span><span>{</span>
<span>  </span><span># Grab login information</span>
<span>  </span><span>local</span><span> </span>-A<span> </span>details
<span>  </span><span>details</span><span>=(</span><span>${</span><span>=</span><span>${</span><span>(M)</span><span>${</span><span>:-</span><span>"</span><span>${</span><span>(@f)</span><span>$(</span><span>command</span><span> </span>ssh<span> </span>-G<span> </span><span>"</span><span>$@</span><span>"</span><span> </span><span>2</span>&gt;/dev/null<span>)</span><span>}</span><span>"</span><span>}</span><span>:#(host|hostname|user) *</span><span>}}</span><span>)</span>
<span>  </span><span>local</span><span> </span><span>remote</span><span>=</span><span>${</span><span>details</span><span>[host]</span><span>:-</span><span>details</span><span>[hostname]</span><span>}</span>
<span>  </span><span>local</span><span> </span><span>login</span><span>=</span><span>${</span><span>details</span><span>[user]</span><span>}</span>@<span>${</span><span>remote</span><span>}</span>

<span>  </span><span># Get password name</span>
<span>  </span><span>local</span><span> </span>passname
<span>  </span><span>case</span><span> </span><span>"</span><span>$login</span><span>"</span><span> </span><span>in</span>
<span>    </span>admin@*.example.net<span>)</span><span>  </span><span>passname</span><span>=</span>company1/ssh/admin<span> </span><span>;;</span>
<span>    </span>bernat@*.example.net<span>)</span><span> </span><span>passname</span><span>=</span>company1/ssh/bernat<span> </span><span>;;</span>
<span>    </span>backup@*.example.net<span>)</span><span> </span><span>passname</span><span>=</span>company1/ssh/backup<span> </span><span>;;</span>
<span>  </span><span>esac</span>

<span>  </span><span># No password name? Just use regular SSH</span>
<span>  </span><span>[[</span><span> </span>-z<span> </span><span>$passname</span><span> </span><span>]]</span><span> </span><span>&amp;&amp;</span><span> </span><span>{</span>
<span>    </span><span>command</span><span> </span>ssh<span> </span><span>"</span><span>$@</span><span>"</span>
<span>    </span><span>return</span><span> </span><span>$?</span>
<span>  </span><span>}</span>

<span>  </span><span># Invoke SSH with the helper for SSH_ASKPASS</span>
<span>  </span><span># […]</span>
<span>}</span>
</pre></div>


<p>It is also possible to make <code>scp</code> invoke our custom <code>ssh</code> function:</p>
<div><pre><span></span>scp<span>()</span><span> </span><span>{</span>
<span>  </span><span>set</span><span> </span>-o<span> </span>localoptions<span> </span>-o<span> </span>localtraps
<span>  </span><span>local</span><span> </span><span>helper</span><span>=</span><span>$(</span>mktemp<span>)</span>
<span>  </span><span>trap</span><span> </span><span>"command rm -f </span><span>$helper</span><span>"</span><span> </span>EXIT<span> </span>INT
<span>  </span>&gt;<span> </span><span>$helper</span><span> </span><span>&lt;&lt;EOF </span>
<span>#!$SHELL</span>
<span>source ${(%):-%x}</span>
<span>ssh "\$@"</span>
<span>EOF</span>
<span>  </span><span>command</span><span> </span>scp<span> </span>-S<span> </span><span>$helper</span><span> </span><span>"</span><span>$@</span><span>"</span>
<span>}</span>
</pre></div>


<p>For the complete code, have a look at my <a href="https://github.com/vincentbernat/zshrc/blob/master/rc/ssh.zsh">zshrc</a>. As an alternative, you can
put the <code>ssh()</code> function body into its own script file and replace <code>command ssh</code>
with <code>/usr/bin/ssh</code> to avoid an unwanted recursive call. In this case, the
<code>scp()</code> function is not needed anymore.</p>
<div>
<hr>
<ol>
<li id="fn-why">
<p>First, some vendors make it <a href="https://vincent.bernat.ch/en/blog/2020-syncing-ssh-keys-iosxr-ansible" title="Syncing SSH keys on Cisco IOS-XR with a custom Ansible module">difficult to associate an SSH key with a
user</a>. Then, many vendors do not support certificate-based
authentication, making it difficult to scale. Finally, interactions between
public-key authentication and finer-grained authorization methods like
TACACS+ and Radius are still uncharted territory.&nbsp;<a href="#fnref-why" title="Jump back to footnote 1 in the text">↩︎</a></p>
</li>
<li id="fn-security">
<p>The clear-text password never appears on the command line, in the
environment, or on the disk, making it difficult for a third party without
elevated privileges to capture it. On Linux, <em>Zsh</em> provides the password
through a file descriptor.&nbsp;<a href="#fnref-security" title="Jump back to footnote 2 in the text">↩︎</a></p>
</li>
<li id="fn-zsh">
<p>To decipher the fourth line, you may get help from <code>print -l</code> and the
<a href="https://manpages.debian.org/bookworm/zsh-common/zshexpn.1.en.html" title="zshexpn(1) manual page">zshexpn(1)</a> manual page. <code>details</code> is an <a href="https://scriptingosx.com/2019/11/associative-arrays-in-zsh/" title="Associative arrays in zsh">associative array</a> defined
from an array alternating keys and values.&nbsp;<a href="#fnref-zsh" title="Jump back to footnote 3 in the text">↩︎</a></p>
</li>
</ol>
</div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I told the flight attendant "the WiFi isn't working" (214 pts)]]></title>
            <link>https://x.com/erratarob/status/1739132876732674539?s=46&amp;t=FFxXRm_qmWG4nJwsccRUbA</link>
            <guid>38762065</guid>
            <pubDate>Mon, 25 Dec 2023 12:27:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://x.com/erratarob/status/1739132876732674539?s=46&#x26;t=FFxXRm_qmWG4nJwsccRUbA">https://x.com/erratarob/status/1739132876732674539?s=46&#x26;t=FFxXRm_qmWG4nJwsccRUbA</a>, See on <a href="https://news.ycombinator.com/item?id=38762065">Hacker News</a></p>
Couldn't get https://x.com/erratarob/status/1739132876732674539?s=46&t=FFxXRm_qmWG4nJwsccRUbA: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[A nano like text editor built with pure C (132 pts)]]></title>
            <link>https://github.com/proh14/ptext</link>
            <guid>38761708</guid>
            <pubDate>Mon, 25 Dec 2023 11:21:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/proh14/ptext">https://github.com/proh14/ptext</a>, See on <a href="https://news.ycombinator.com/item?id=38761708">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">
  <br>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/proh14/ptext/blob/main/images/logo.png"><img src="https://github.com/proh14/ptext/raw/main/images/logo.png" alt="ptext logo" width="200"></a>
  <br>
  ptext
  <br>
</h2>
<h4 tabindex="-1" dir="auto">A nano like text editor built with pure C </h4>
<p dir="auto">ptext is a text editor based on kilo. <br>
My goal in making this was to learn more about managing tui interfaces not using ncurses.<br></p>
<h3 tabindex="-1" dir="auto">Preview🙈:</h3>
<details open="">
  <summary>
    
    <span aria-label="Video description preview.mp4">preview.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/95998030/292609812-08ee068b-fe9b-4d3f-b3e4-49d3a66855d5.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDM1MzQ3MDMsIm5iZiI6MTcwMzUzNDQwMywicGF0aCI6Ii85NTk5ODAzMC8yOTI2MDk4MTItMDhlZTA2OGItZmU5Yi00ZDNmLWIzZTQtNDlkM2E2Njg1NWQ1Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMjUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjI1VDIwMDAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTAzZWYwMjBhZTVlYTczZjZlMGM4YmZmMjdkMzRiMjVhMDY1YmViYjY0MzM5ZGUwZjhmYTQ3OTk5MWVlYjZlYWUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.TiFj_i06r1I0M-Z2LhuBDjtcFb83tauArj5EX-SY6hI" data-canonical-src="https://private-user-images.githubusercontent.com/95998030/292609812-08ee068b-fe9b-4d3f-b3e4-49d3a66855d5.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDM1MzQ3MDMsIm5iZiI6MTcwMzUzNDQwMywicGF0aCI6Ii85NTk5ODAzMC8yOTI2MDk4MTItMDhlZTA2OGItZmU5Yi00ZDNmLWIzZTQtNDlkM2E2Njg1NWQ1Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMjUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjI1VDIwMDAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTAzZWYwMjBhZTVlYTczZjZlMGM4YmZmMjdkMzRiMjVhMDY1YmViYjY0MzM5ZGUwZjhmYTQ3OTk5MWVlYjZlYWUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.TiFj_i06r1I0M-Z2LhuBDjtcFb83tauArj5EX-SY6hI" controls="controls" muted="muted">

  </video>
</details>

<h3 tabindex="-1" dir="auto">How to install⬇️:</h3>
<ol dir="auto">
<li>Clone this repo.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/proh14/ptext.git
cd ptext"><pre>git clone https://github.com/proh14/ptext.git
<span>cd</span> ptext</pre></div>
<ol start="2" dir="auto">
<li>Run <code>make</code> inside this repo's main directory.</li>
</ol>

<ol start="3" dir="auto">
<li>go to build directory</li>
</ol>

<ol start="4" dir="auto">
<li>run ptext!</li>
</ol>

<p dir="auto">OR to install you may run the command</p>

<p dir="auto">then restart your shell and run</p>

<p dir="auto">to start the editor.</p>
<h2 tabindex="-1" dir="auto">To exit you may press Ctrl+q and Ctrl + s to save the file</h2>
<h3 tabindex="-1" dir="auto">Goals🥅:</h3>
<ol dir="auto">
<li>Fix syntax highlighting.</li>
<li>Add a plugin system.</li>
<li>Add windows.</li>
</ol>
<h3 tabindex="-1" dir="auto">Work in progress⚒️:</h3>
<p dir="auto">This is still a work in progress project!</p>
<h3 tabindex="-1" dir="auto">Contributions💖:</h3>
<p dir="auto">I appreciate contributions but first of all, you must read the <br>
Read the <a href="https://github.com/proh14/ptext/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> Then you can send your pr!</p>
<h3 tabindex="-1" dir="auto">Thank you Stargazers⭐:</h3>
<p dir="auto"><a href="https://github.com/proh14/ptext/stargazers"><img src="https://camo.githubusercontent.com/95e23a5593f15b8200045035a55dfa170c169163cd266027eb99e0f7a281f15e/687474703a2f2f7265706f726f737465722e636f6d2f73746172732f70726f6831342f7074657874" alt="Stargazers repo roster for @proh14/ptext" data-canonical-src="http://reporoster.com/stars/proh14/ptext"></a></p>
<h3 tabindex="-1" dir="auto">Thank you Forkers🍴:</h3>
<p dir="auto"><a href="https://github.com/proh14/ptext/network/members"><img src="https://camo.githubusercontent.com/820d6956ecb1bf7abaa336f0991e4fdb04051b000857b24fab46ca4234d2ba25/687474703a2f2f7265706f726f737465722e636f6d2f666f726b732f70726f6831342f7074657874" alt="Forkers repo roster for @proh14/ptext" data-canonical-src="http://reporoster.com/forks/proh14/ptext"></a></p>
<h3 tabindex="-1" dir="auto">A huge thanks to🙏:</h3>
<ol dir="auto">
<li><a href="https://viewsourcecode.org/" rel="nofollow">viewsourcecode</a></li>
<li><a href="https://github.com/antirez/kilo">kilo</a></li>
</ol>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Breakdown of faults by car brand: Tesla has replaced Dacia at the bottom (398 pts)]]></title>
            <link>https://www.tuvsud.com/en/press-and-media/2023/november/regular-servicing-makes-all-the-difference</link>
            <guid>38760933</guid>
            <pubDate>Mon, 25 Dec 2023 08:51:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tuvsud.com/en/press-and-media/2023/november/regular-servicing-makes-all-the-difference">https://www.tuvsud.com/en/press-and-media/2023/november/regular-servicing-makes-all-the-difference</a>, See on <a href="https://news.ycombinator.com/item?id=38760933">Hacker News</a></p>
Couldn't get https://www.tuvsud.com/en/press-and-media/2023/november/regular-servicing-makes-all-the-difference: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Zotero for Android available for beta tests (262 pts)]]></title>
            <link>https://forums.zotero.org/discussion/110371/available-for-beta-testing-zotero-for-android</link>
            <guid>38760864</guid>
            <pubDate>Mon, 25 Dec 2023 08:30:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forums.zotero.org/discussion/110371/available-for-beta-testing-zotero-for-android">https://forums.zotero.org/discussion/110371/available-for-beta-testing-zotero-for-android</a>, See on <a href="https://news.ycombinator.com/item?id=38760864">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="Discussion_110371"><p>
                    We're happy to announce the beta of Zotero for Android.</p><p>You can install the app from the Google Play Store:</p><p><a href="https://play.google.com/store/apps/details?id=org.zotero.android" rel="nofollow">https://play.google.com/store/apps/details?id=org.zotero.android</a></p><p>Current features:
</p><ul><li>Sync personal and group libraries</li><li>Edit item data and notes</li><li>Organize items into collections</li><li>Download and upload files via Zotero Storage</li><li>View PDFs and snapshots</li><li>Annotate PDFs (highlight, note, image, and ink annotations)</li></ul><p>
Not yet implemented:
</p><ul><li>Saving from the browser</li><li>Adding items via identifier or barcode scanning</li><li>Citation/bibliography generation</li><li>WebDAV file syncing</li></ul><p>
This is an early beta, so we don't recommend using it if you're in the middle of an important project. If you do want to try it, be sure you’ve made a backup of the <a rel="nofollow" href="https://www.zotero.org/support/zotero_data">Zotero data directory</a> on your computer before installing the app.</p><p>The beta is currently limited to 1,000 testers, but we'll increase that limit once the app has gone through a bit more testing.</p><p>Please create new threads in these forums for any bug reports or feature requests. Be sure to put "Android" in your thread title so it's clear what you're referring to.</p><p>Thanks for helping to test the app!                </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ruby 3.3 (554 pts)]]></title>
            <link>https://www.ruby-lang.org/en/news/2023/12/25/ruby-3-3-0-released/</link>
            <guid>38760477</guid>
            <pubDate>Mon, 25 Dec 2023 07:01:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ruby-lang.org/en/news/2023/12/25/ruby-3-3-0-released/">https://www.ruby-lang.org/en/news/2023/12/25/ruby-3-3-0-released/</a>, See on <a href="https://news.ycombinator.com/item?id=38760477">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-wrapper">
    <p>Posted by naruse on 25 Dec 2023</p>

    
<p>We are pleased to announce the release of Ruby 3.3.0. Ruby 3.3 adds a new parser named Prism, uses Lrama as a parser generator, adds a new pure-Ruby JIT compiler named RJIT, and many performance improvements especially YJIT.</p>

<h2>Prism</h2>

<ul>
  <li>Introduced <a href="https://github.com/ruby/prism">the Prism parser</a> as a default gem
    <ul>
      <li>Prism is a portable, error tolerant, and maintainable recursive descent parser for the Ruby language</li>
    </ul>
  </li>
  <li>Prism is production ready and actively maintained, you can use it in place of Ripper
    <ul>
      <li>There is <a href="https://ruby.github.io/prism/">extensive documentation</a> on how to use Prism</li>
      <li>Prism is both a C library that will be used internally by CRuby and a Ruby gem that can be used by any tooling which needs to parse Ruby code</li>
      <li>Notable methods in the Prism API are:
        <ul>
          <li><code>Prism.parse(source)</code> which returns the AST as part of a parse result object</li>
          <li><code>Prism.parse_comments(source)</code> which returns the comments</li>
          <li><code>Prism.parse_success?(source)</code> which returns true if there are no errors</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>You can make pull requests or issues directly on <a href="https://github.com/ruby/prism">the Prism repository</a> if you are interested in contributing</li>
  <li>You can now use <code>ruby --parser=prism</code> or <code>RUBYOPT="--parser=prism"</code> to experiment with the Prism compiler. Please note that this flag is for debugging only.</li>
</ul>

<h2>Use Lrama instead of Bison</h2>

<ul>
  <li>Replace Bison with <a href="https://github.com/ruby/lrama">Lrama LALR parser generator</a> <a href="https://bugs.ruby-lang.org/issues/19637">[Feature #19637]</a>
    <ul>
      <li>If you have interest, please see <a href="https://rubykaigi.org/2023/presentations/spikeolaf.html">The future vision of Ruby Parser</a></li>
      <li>Lrama internal parser is replaced with LR parser generated by Racc for maintainability</li>
      <li>Parameterizing Rules <code>(?, *, +)</code> are supported, it will be used in Ruby parse.y</li>
    </ul>
  </li>
</ul>

<h2>YJIT</h2>

<ul>
  <li>Major performance improvements over Ruby 3.2
    <ul>
      <li>Support for splat and rest arguments has been improved.</li>
      <li>Registers are allocated for stack operations of the virtual machine.</li>
      <li>More calls with optional arguments are compiled. Exception handlers are also compiled.</li>
      <li>Unsupported call types and megamorphic call sites no longer exit to the interpreter.</li>
      <li>Basic methods like Rails <code>#blank?</code> and
<a href="https://github.com/rails/rails/pull/49909">specialized <code>#present?</code></a> are inlined.</li>
      <li><code>Integer#*</code>, <code>Integer#!=</code>, <code>String#!=</code>, <code>String#getbyte</code>,
<code>Kernel#block_given?</code>, <code>Kernel#is_a?</code>, <code>Kernel#instance_of?</code>, and <code>Module#===</code>
are specially optimized.</li>
      <li>Compilation speed is now slightly faster than Ruby 3.2.</li>
      <li>Now more than 3x faster than the interpreter on Optcarrot!</li>
    </ul>
  </li>
  <li>Significantly improved memory usage over Ruby 3.2
    <ul>
      <li>Metadata for compiled code uses a lot less memory.</li>
      <li><code>--yjit-call-threshold</code> is automatically raised from 30 to 120
when the application has more than 40,000 ISEQs.</li>
      <li><code>--yjit-cold-threshold</code> is added to skip compiling cold ISEQs.</li>
      <li>More compact code is generated on Arm64.</li>
    </ul>
  </li>
  <li>Code GC is now disabled by default
    <ul>
      <li><code>--yjit-exec-mem-size</code> is treated as a hard limit where compilation of new code stops.</li>
      <li>No sudden drops in performance due to code GC.
Better copy-on-write behavior on servers reforking with
<a href="https://github.com/shopify/pitchfork">Pitchfork</a>.</li>
      <li>You can still enable code GC if desired with <code>--yjit-code-gc</code></li>
    </ul>
  </li>
  <li>Add <code>RubyVM::YJIT.enable</code> that can enable YJIT at run-time
    <ul>
      <li>You can start YJIT without modifying command-line arguments or environment variables.
Rails 7.2 will <a href="https://github.com/rails/rails/pull/49947">enable YJIT by default</a>
using this method.</li>
      <li>This can also be used to enable YJIT only once your application is
done booting. <code>--yjit-disable</code> can be used if you want to use other
YJIT options while disabling YJIT at boot.</li>
    </ul>
  </li>
  <li>More YJIT stats are available by default
    <ul>
      <li><code>yjit_alloc_size</code> and several more metadata-related stats are now available by default.</li>
      <li><code>ratio_in_yjit</code> stat produced by <code>--yjit-stats</code> is now available in release builds,
a special stats or dev build is no longer required to access most stats.</li>
    </ul>
  </li>
  <li>Add more profiling capabilities
    <ul>
      <li><code>--yjit-perf</code> is added to facilitate profiling with Linux perf.</li>
      <li><code>--yjit-trace-exits</code> now supports sampling with <code>--yjit-trace-exits-sample-rate=N</code></li>
    </ul>
  </li>
  <li>More thorough testing and multiple bug fixes</li>
</ul>

<h2>RJIT</h2>

<ul>
  <li>Introduced a pure-Ruby JIT compiler RJIT and replaced MJIT.
    <ul>
      <li>RJIT supports only x86-64 architecture on Unix platforms.</li>
      <li>Unlike MJIT, it doesn’t require a C compiler at runtime.</li>
    </ul>
  </li>
  <li>RJIT exists only for experimental purposes.
    <ul>
      <li>You should keep using YJIT in production.</li>
    </ul>
  </li>
  <li>If you are interested in developing JIT for Ruby, please check out <a href="https://rubykaigi.org/2023/presentations/k0kubun.html#day3">k0kubun’s presentation on Day 3 of RubyKaigi</a>.</li>
</ul>

<h2>M:N thread scheduler</h2>

<ul>
  <li>M:N thread scheduler was introduced. <a href="https://bugs.ruby-lang.org/issues/19842">[Feature #19842]</a>
    <ul>
      <li>M Ruby threads are managed by N native threads (OS threads) so the thread creation and management cost are reduced.</li>
      <li>It can break C-extension compatibility so that M:N thread scheduler is disabled on the main Ractor by default.
        <ul>
          <li><code>RUBY_MN_THREADS=1</code> environment variable enables M:N threads on the main Ractor.</li>
          <li>M:N threads are always enabled on non-main Ractors.</li>
        </ul>
      </li>
      <li><code>RUBY_MAX_CPU=n</code> environment variable sets maximum number of <code>N</code> (maximum number of native threads). The default value is 8.
        <ul>
          <li>Since only one Ruby thread per Ractor can run at the same time, the number of native threads will be used, which is the smaller of the number specified in <code>RUBY_MAX_CPU</code> and the number of running Ractors. So that single Ractor applications (most of applications) will only use 1 native thread.</li>
          <li>To support blocking operations, more than <code>N</code> native threads can be used.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2>Performance improvements</h2>

<ul>
  <li><code>defined?(@ivar)</code> is optimized with Object Shapes.</li>
  <li>Name resolution such as <code>Socket.getaddrinfo</code> can now be interrupted (in environments where pthreads are available). <a href="https://bugs.ruby-lang.org/issues/19965">[Feature #19965]</a></li>
  <li>Several performance improvements to the Garbage Collector
    <ul>
      <li>Young objects referenced by old objects are no longer immediately
  promoted to the old generation. This significantly reduces the frequency of
  major GC collections. <a href="https://bugs.ruby-lang.org/issues/19678">[Feature #19678]</a></li>
      <li>A new <code>REMEMBERED_WB_UNPROTECTED_OBJECTS_LIMIT_RATIO</code> tuning variable was
  introduced to control the number of unprotected objects cause a major GC
  collection to trigger. The default is set to <code>0.01</code> (1%). This significantly
  reduces the frequency of major GC collection. <a href="https://bugs.ruby-lang.org/issues/19571">[Feature #19571]</a></li>
      <li>Write Barriers were implemented for many core types that were missing them,
  notably <code>Time</code>, <code>Enumerator</code>, <code>MatchData</code>, <code>Method</code>, <code>File::Stat</code>, <code>BigDecimal</code>
  and several others. This significantly reduces minor GC collection time and major
  GC collection frequency.</li>
      <li>Most core classes are now using Variable Width Allocation, notably <code>Hash</code>, <code>Time</code>,
  <code>Thread::Backtrace</code>, <code>Thread::Backtrace::Location</code>, <code>File::Stat</code>, <code>Method</code>.
  This makes these classes faster to allocate and free, use less memory and reduce
  heap fragmentation.</li>
      <li>Support for weak references has been added to the garbage collector. <a href="https://bugs.ruby-lang.org/issues/19783">[Feature #19783]</a></li>
    </ul>
  </li>
</ul>

<h2>Other notable changes since 3.2</h2>

<h3>IRB</h3>

<p>IRB has received several enhancements, including but not limited to:</p>

<ul>
  <li>Advanced <code>irb:rdbg</code> integration that provides an equivalent debugging experience to <code>pry-byebug</code> (<a href="https://github.com/ruby/irb#debugging-with-irb">doc</a>).</li>
  <li>Pager support for <code>ls</code>, <code>show_source</code> and <code>show_cmds</code> commands.</li>
  <li>More accurate and helpful information provided by the <code>ls</code> and <code>show_source</code> commands.</li>
  <li>Experimental autocompletion using type analysis (<a href="https://github.com/ruby/irb#type-based-completion">doc</a>).</li>
  <li>It is now possible to change the font color and font style in the completion dialog by a newly introduced class Reline::Face (<a href="https://github.com/ruby/ruby/blob/master/doc/reline/face.md">doc</a>)</li>
</ul>

<p>In addition, IRB has also undergone extensive refactoring and received dozens of bug fixes to facilitate easier future enhancements.</p>

<h2>Compatibility issues</h2>

<p>Note: Excluding feature bug fixes.</p>

<ul>
  <li><code>it</code> calls without arguments in a block with no ordinary parameters are
deprecated. <code>it</code> will be a reference to the first block parameter in Ruby 3.4.
<a href="https://bugs.ruby-lang.org/issues/18980">[Feature #18980]</a></li>
</ul>

<h3>Removed environment variables</h3>

<p>The following deprecated methods are removed.</p>

<ul>
  <li>Environment variable <code>RUBY_GC_HEAP_INIT_SLOTS</code> has been deprecated and is a no-op. Please use environment variables <code>RUBY_GC_HEAP_{0,1,2,3,4}_INIT_SLOTS</code> instead. <a href="https://bugs.ruby-lang.org/issues/19785">[Feature #19785]</a></li>
</ul>

<h2>Stdlib compatibility issues</h2>

<h3><code>ext/readline</code> is retired</h3>

<ul>
  <li>We have <code>reline</code> that is pure Ruby implementation compatible with <code>ext/readline</code> API. We rely on <code>reline</code> in the future. If you need to use <code>ext/readline</code>, you can install <code>ext/readline</code> via rubygems.org with <code>gem install readline-ext</code>.</li>
  <li>We no longer need to install libraries like <code>libreadline</code> or <code>libedit</code>.</li>
</ul>

<h2>Standard library updates</h2>

<p>RubyGems and Bundler warn if users do <code>require</code> the following gems without adding them to Gemfile or gemspec. This is because they will become the bundled gems in the future version of Ruby.</p>

<p>This warning is suppressed if you use bootsnap gem. We recoomend to run your application with <code>DISABLE_BOOTSNAP=1</code> environmental variable at least once. This is limitation of this version.</p>

<p>Targeted libraries are:</p>
<ul>
  <li>abbrev</li>
  <li>base64</li>
  <li>bigdecimal</li>
  <li>csv</li>
  <li>drb</li>
  <li>getoptlong</li>
  <li>mutex_m</li>
  <li>nkf</li>
  <li>observer</li>
  <li>racc</li>
  <li>resolv-replace</li>
  <li>rinda</li>
  <li>syslog</li>
</ul>

<p>The following default gem is added.</p>

<ul>
  <li>prism 0.19.0</li>
</ul>

<p>The following default gems are updated.</p>

<ul>
  <li>RubyGems 3.5.3</li>
  <li>abbrev 0.1.2</li>
  <li>base64 0.2.0</li>
  <li>benchmark 0.3.0</li>
  <li>bigdecimal 3.1.5</li>
  <li>bundler 2.5.3</li>
  <li>cgi 0.4.1</li>
  <li>csv 3.2.8</li>
  <li>date 3.3.4</li>
  <li>delegate 0.3.1</li>
  <li>drb 2.2.0</li>
  <li>english 0.8.0</li>
  <li>erb 4.0.3</li>
  <li>error_highlight 0.6.0</li>
  <li>etc 1.4.3</li>
  <li>fcntl 1.1.0</li>
  <li>fiddle 1.1.2</li>
  <li>fileutils 1.7.2</li>
  <li>find 0.2.0</li>
  <li>getoptlong 0.2.1</li>
  <li>io-console 0.7.1</li>
  <li>io-nonblock 0.3.0</li>
  <li>io-wait 0.3.1</li>
  <li>ipaddr 1.2.6</li>
  <li>irb 1.11.0</li>
  <li>json 2.7.1</li>
  <li>logger 1.6.0</li>
  <li>mutex_m 0.2.0</li>
  <li>net-http 0.4.0</li>
  <li>net-protocol 0.2.2</li>
  <li>nkf 0.1.3</li>
  <li>observer 0.1.2</li>
  <li>open-uri 0.4.1</li>
  <li>open3 0.2.1</li>
  <li>openssl 3.2.0</li>
  <li>optparse 0.4.0</li>
  <li>ostruct 0.6.0</li>
  <li>pathname 0.3.0</li>
  <li>pp 0.5.0</li>
  <li>prettyprint 0.2.0</li>
  <li>pstore 0.1.3</li>
  <li>psych 5.1.2</li>
  <li>rdoc 6.6.2</li>
  <li>readline 0.0.4</li>
  <li>reline 0.4.1</li>
  <li>resolv 0.3.0</li>
  <li>rinda 0.2.0</li>
  <li>securerandom 0.3.1</li>
  <li>set 1.1.0</li>
  <li>shellwords 0.2.0</li>
  <li>singleton 0.2.0</li>
  <li>stringio 3.1.0</li>
  <li>strscan 3.0.7</li>
  <li>syntax_suggest 2.0.0</li>
  <li>syslog 0.1.2</li>
  <li>tempfile 0.2.1</li>
  <li>time 0.3.0</li>
  <li>timeout 0.4.1</li>
  <li>tmpdir 0.2.0</li>
  <li>tsort 0.2.0</li>
  <li>un 0.3.0</li>
  <li>uri 0.13.0</li>
  <li>weakref 0.1.3</li>
  <li>win32ole 1.8.10</li>
  <li>yaml 0.3.0</li>
  <li>zlib 3.1.0</li>
</ul>

<p>The following bundled gem is promoted from default gems.</p>

<ul>
  <li>racc 1.7.3</li>
</ul>

<p>The following bundled gems are updated.</p>

<ul>
  <li>minitest 5.20.0</li>
  <li>rake 13.1.0</li>
  <li>test-unit 3.6.1</li>
  <li>rexml 3.2.6</li>
  <li>rss 0.3.0</li>
  <li>net-ftp 0.3.3</li>
  <li>net-imap 0.4.9</li>
  <li>net-smtp 0.4.0</li>
  <li>rbs 3.4.0</li>
  <li>typeprof 0.21.9</li>
  <li>debug 1.9.1</li>
</ul>

<p>See GitHub releases like <a href="https://github.com/ruby/logger/releases">Logger</a> or
changelog for details of the default gems or bundled gems.</p>

<p>See <a href="https://github.com/ruby/ruby/blob/v3_3_0/NEWS.md">NEWS</a>
or <a href="https://github.com/ruby/ruby/compare/v3_2_0...v3_3_0">commit logs</a>
for more details.</p>

<p>With those changes, <a href="https://github.com/ruby/ruby/compare/v3_2_0...v3_3_0#file_bucket">5532 files changed, 326851 insertions(+), 185793 deletions(-)</a>
since Ruby 3.2.0!</p>

<p>Merry Christmas, Happy Holidays, and enjoy programming with Ruby 3.3!</p>

<h2>Download</h2>

<ul>
  <li>
    <p><a href="https://cache.ruby-lang.org/pub/ruby/3.3/ruby-3.3.0.tar.gz">https://cache.ruby-lang.org/pub/ruby/3.3/ruby-3.3.0.tar.gz</a></p>

    <div><pre><code>SIZE: 22065999
SHA1: 1a7e56851bf29bda1183aca99b3b323c58e0187b
SHA256: 96518814d9832bece92a85415a819d4893b307db5921ae1f0f751a9a89a56b7d
SHA512: 26074009b501fc793d71a74e419f34a6033c9353433919ca74ba2d24a3de432dbb11fd92c2bc285f0e4d951a6d6c74bf5b69a2ab36200c8c26e871746d6e0fc6
</code></pre></div>
  </li>
  <li>
    <p><a href="https://cache.ruby-lang.org/pub/ruby/3.3/ruby-3.3.0.tar.xz">https://cache.ruby-lang.org/pub/ruby/3.3/ruby-3.3.0.tar.xz</a></p>

    <div><pre><code>SIZE: 16345456
SHA1: c8f68e1b0a114b90460a0b44165a3b2f540fa5b6
SHA256: 676b65a36e637e90f982b57b059189b3276b9045034dcd186a7e9078847b975b
SHA512: 7959c5753bfa0bfc4d6d74060869aabbe9815c1c97930659da11b917ee0803ddbbd80e869e00c48b8694b4ba48709c3b6493fd045568e36e902616c35ababf01
</code></pre></div>
  </li>
  <li>
    <p><a href="https://cache.ruby-lang.org/pub/ruby/3.3/ruby-3.3.0.zip">https://cache.ruby-lang.org/pub/ruby/3.3/ruby-3.3.0.zip</a></p>

    <div><pre><code>SIZE: 26935108
SHA1: a433eef1d7f96daeaf3b4cb842d0ed2dd82e7dc1
SHA256: 0e6563f679dd3694732eb3addf9de681c67b584602ac574376b60e7a509d2cd8
SHA512: a94a85937a14b217c1f4b90d24185289ed4aee79239c4f3eecf8034d3fd34e65ee8d66869473857ed153067188adc9b70c0471e4ebe842c9f98ef60c34090450
</code></pre></div>
  </li>
</ul>

<h2>What is Ruby</h2>

<p>Ruby was first developed by Matz (Yukihiro Matsumoto) in 1993,
and is now developed as Open Source. It runs on multiple platforms
and is used all over the world especially for web development.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Constellations are younger than continents (268 pts)]]></title>
            <link>https://www.lesswrong.com/posts/YMakfmwZsoLdXAZhb/constellations-are-younger-than-continents</link>
            <guid>38760131</guid>
            <pubDate>Mon, 25 Dec 2023 05:39:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lesswrong.com/posts/YMakfmwZsoLdXAZhb/constellations-are-younger-than-continents">https://www.lesswrong.com/posts/YMakfmwZsoLdXAZhb/constellations-are-younger-than-continents</a>, See on <a href="https://news.ycombinator.com/item?id=38760131">Hacker News</a></p>
Couldn't get https://www.lesswrong.com/posts/YMakfmwZsoLdXAZhb/constellations-are-younger-than-continents: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The C++20 Naughty and Nice List for Game Devs (113 pts)]]></title>
            <link>https://www.jeremyong.com/c++/2023/12/24/cpp20-gamedev-naughty-nice/</link>
            <guid>38760120</guid>
            <pubDate>Mon, 25 Dec 2023 05:35:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jeremyong.com/c++/2023/12/24/cpp20-gamedev-naughty-nice/">https://www.jeremyong.com/c++/2023/12/24/cpp20-gamedev-naughty-nice/</a>, See on <a href="https://news.ycombinator.com/item?id=38760120">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p>The goal here is to compile a list of C++20 features I think game devs should probably
use (possibly with caveats), and features I think game devs will probably want to avoid.
You’re probably curious “why now?” given that it’s 2023 and C++20 was standardized
several years ago. Well, mainly it’s because it took me several years of trying and retrying
various features to get a sense for what I liked and what I didn’t.</p>

<p>I’m going to start with a disclaimer, because whenever feedback regarding C++
matters is concerned, things can get touchy, but please do read the following
before reacting too strongly to anything that follows. The main discalimer is
that I’m assuming that the interested reader is a developer with similar codebase
requirements:</p>

<ul>
  <li>Large codebase (10M+ LOC) that is routinely compiled on your machine</li>
  <li>Heavy DLL usage for plugins and general code structure modularization</li>
  <li>Broad platform compatibility</li>
  <li>Sensitivity to disk usage and binary bloat</li>
  <li>Runtime efficiency is of utmost importance (<code>-O0</code> speed is also important)</li>
</ul>

<p>To the extent that your experience as a developer (or game developer) matches the
requirements above, you may be more inclined to agree with my naughty-and-nice
classification. I think without such constraints, some of the “naughty features” here
are honestly quite nice.</p>

<p>The second disclaimer is that even if your requirements seem to match mine,
you can still come up with diametrically opposite conclusions, and that’s OK also.
Even if codebases “rhyme,” coding culture and practices differ greatly from team
to team, so you’ll need to apply the <em>reasoning</em> used to classify features as “naughty”
or “nice” to your own use cases to determine what applies and to what extent.</p>

<p>The next disclaimer is that even if a feature is on the nice list, it doesn’t mean
the feature can’t be abused, and it doesn’t mean the feature isn’t naughty in some
contexts. Similarly, features in the naughty list may not be naughty in all
circumstances.</p>

<p>The last disclaimer is that this post is not even remotely exhaustive. There is far
too much material to really cover in detail in a single post, so this just covers
some of the broad strokes. If I miss your favorite feature (or most hated feature),
it’s either because there wasn’t room to cover it, or because I don’t have enough
personal experience with the feature to draw a conclusion one way or another.</p>

<p>With that out of the way, let’s start with the nice items, followed immediately
by the naughty items.</p>

<h2 id="nice-default-comparison-and-the-three-way-comparison-operator-aka-the-spaceship-">(Nice) Default comparison and the three-way comparison operator (aka the spaceship: &lt;=&gt;)</h2>

<p>New in C++20 are <a href="https://en.cppreference.com/w/cpp/language/default_comparisons">default comparison</a>
rules for structured types that perform an automatic lexicographic comparison when requested.</p>

<div><pre><code><span>struct</span> <span>Date</span>
<span>{</span>
    <span>int</span> <span>year</span><span>;</span>
    <span>int</span> <span>month</span><span>;</span>
    <span>int</span> <span>day</span><span>;</span>

    <span>auto</span> <span>operator</span><span>&lt;=&gt;</span><span>(</span><span>Date</span> <span>const</span><span>&amp;</span><span>)</span> <span>const</span> <span>=</span> <span>default</span><span>;</span>
    <span>bool</span> <span>operator</span><span>==</span><span>(</span><span>Date</span> <span>const</span><span>&amp;</span><span>)</span> <span>const</span>  <span>=</span> <span>default</span><span>;</span>
<span>};</span>
</code></pre></div>

<p>With the declaration above, instances of <code>Date</code> are comparable with any of the binary comparison
operators, with the behavior you expect (don’t actually define a <code>Date</code> class this way of course).
The <a href="https://en.cppreference.com/w/cpp/language/operator_comparison#Three-way_comparison">three-way comparison operator</a>
there defines a single binary operator which then enables a family of binary comparison operators
on a given object. This operator can of course be overloaded.</p>

<p>These features are a win in my book because combined, they cut down on code duplication,
reducing the surface area for bugs as code changes. Lexicographic comparison is a great
default, because what other behavior would have been a more sensible default?</p>

<p>The main caveat is that I would not use the 3-way comparison operator for custom numeric types
where maximum efficiency is needed, because there may be slight overhead in debug builds,
but chances are, such types are likely small or change infrequently (such that the advantages
of the 3-way comparison operator with respect to maintainability are not felt). As an additional
note to be aware of, in most cases, you probably want to at least implement <code>operator==</code>, which
may be faster than invoking <code>operator&lt;=&gt;</code> to do equality checks.</p>

<h2 id="nice-signed-integers-are-2s-complement-and-arithmetic-shifts">(Nice) Signed integers are 2’s complement and arithmetic shifts</h2>

<p>Signed overflow/underflow remain UB (and it’s understandable that changing this behavior this late
in the game would have dramatic consequences), but it’s nice to know that we can at least expect
sign extension when using <code>operator&gt;&gt;</code> and <code>operator&lt;&lt;</code> on signed operands now.</p>

<h2 id="nice-coroutines-with-heavy-caveats">(Nice) Coroutines (with heavy caveats)</h2>

<p>C++20 <a href="https://en.cppreference.com/w/cpp/language/coroutines">coroutines</a> are one of my favorite
features. It’s been also wildly criticized for its complexity (or because they aren’t stackful, etc.).
However, while I do think the criticisms are understandable, coroutines can work remarkably well
<em>as a user</em>, with similar and often better overhead than what we’d see in a typical task-graph
implementation.</p>

<p>The main downside is that there’s a heavy upfront setup cost (and possibly maintenance cost) to
bootstrap your coroutine-based frontend API for task scheduling.
I recommend checking out <a href="https://github.com/David-Haim/concurrencpp">concurrencpp</a>
if you’re in the market for frameworks that provide a coroutine interface, or if you want to see
the type of constructs that are possible.</p>

<p>Another downside to coroutines are that the dependency graph is implicit as opposed to explicit,
so if you have tooling to visualize the dependency graph and such, this viz is going to have to
operate using runtime data.</p>

<h2 id="nice-constraints-and-concepts">(Nice) Constraints and Concepts</h2>

<p>Sure there is the dreaded <a href="https://stackoverflow.com/questions/54200988/why-do-we-require-requires-requires"><code>requires requires</code></a>
syntactic oddity that shows up, but on the whole, <a href="https://en.cppreference.com/w/cpp/language/constraints">constraints and concepts</a>
should show up pretty much anywhere you have a template (which is hopefully used in your codebase
only where needed already). In exchange for the effort of writing constraints and concepts (all
of I recommend naming as opposed to writing inline concepts), you are rewarded with nicer error
feedback from the compiler <em>forevermore</em> which seems pretty worth if you ask me. In addition, the
template type signatures, when decorated with constraints, now inform the user what types are usable
as valid type parameters. This is a strict win in my book.</p>

<p>The concepts that ship with the compiler are also immediately usable. I wouldn’t recommend writing these yourself,
since you may be missing out on optimizations available through the use of compiler intrinsics.</p>

<h2 id="nice-bit">(Nice) <code>&lt;bit&gt;</code></h2>

<p>The <a href="https://en.cppreference.com/w/cpp/header/bit"><code>&lt;bit&gt;</code> header</a> is nice and standardizes a lot
of operations we arguably should have had years ago (like <code>popcount</code> and bit rotations and such).
The <em>very</em> important addition here is the inclusion of <a href="https://en.cppreference.com/w/cpp/numeric/bit_cast"><code>std::bit_cast</code></a>
which lets us cast unrelated types safely without relying on the <code>memcpy</code> pattern. In MSVC for example,
this is implemented using the MSVC <code>__builtin_bit_cast</code> intrinsic.</p>

<h2 id="nice-numbers">(Nice) <code>&lt;numbers&gt;</code></h2>

<p>You now have <code>pi</code> and other constants available for use in a <a href="https://en.cppreference.com/w/cpp/header/numbers">header</a>.</p>

<h2 id="nice-new-synchronization-primitives">(Nice) New synchronization primitives</h2>

<p>The new <a href="https://en.cppreference.com/w/cpp/header/barrier"><code>&lt;barrier&gt;</code></a>,
<a href="https://en.cppreference.com/w/cpp/header/latch"><code>&lt;latch&gt;</code></a>, and <a href="https://en.cppreference.com/w/cpp/header/semaphore"><code>&lt;semaphore&gt;</code></a>
primitives have been working for me with the caveat that if you already have well-tested cross-platform
implementations of these primitives, I would keep using those. A potential disadvantage is that using
these primitives requires you to buy into the <code>&lt;chrono&gt;</code> way of spelling time points and durations,
which I’ve grown accustomed to but isn’t for everyone.</p>

<h2 id="nice-span">(Nice) <code>&lt;span&gt;</code></h2>

<p>Passing non-owning views is a good idea in general, so it’s nice that the notion of
<a href="https://en.cppreference.com/w/cpp/container/span"><code>std::span</code></a> is now officially codified. This isn’t going
to convince me to use STL containers anytime soon (for other reasons I won’t get into), but the implementation
of <code>std::span</code> as a pointer plus size is unobjectionable enough and easy-to-use (interoperability with functions
that take iterator pairs, range for-loops, etc.).</p>

<h2 id="nice-ish-designated-initializers">(Nice-ish) Designated initializers</h2>

<p><a href="https://en.cppreference.com/w/cpp/language/aggregate_initialization#Designated_initializers">Designated initializers</a> are
a new form of initialization that initializes structured variable members by name.</p>

<div><pre><code><span>struct</span> <span>Point</span>
<span>{</span>
    <span>float</span> <span>x</span><span>;</span>
    <span>float</span> <span>y</span><span>;</span>
    <span>float</span> <span>z</span><span>;</span>
<span>};</span>

<span>Point</span> <span>origin</span><span>{.</span><span>x</span> <span>=</span> <span>0.</span><span>f</span><span>,</span> <span>.</span><span>y</span> <span>=</span> <span>0.</span><span>f</span><span>,</span> <span>.</span><span>z</span> <span>=</span> <span>0.</span><span>f</span><span>};</span>
</code></pre></div>

<p>I consider this feature “nice-ish.” On the one hand, the feature allows us to initialize structured variables in
a self-documenting manner, and I’m always a fan of optimizing for the reader. However, the main caveat regarding
designated initializer usage is that initialized members <em>must</em> appear in declaration order. In other words,
this code won’t compile:</p>

<div><pre><code><span>struct</span> <span>Point</span>
<span>{</span>
    <span>float</span> <span>x</span><span>;</span>
    <span>float</span> <span>y</span><span>;</span>
    <span>float</span> <span>z</span><span>;</span>
<span>};</span>

<span>// Oops, field order is incorrect.</span>
<span>Point</span> <span>origin</span><span>{.</span><span>y</span> <span>=</span> <span>0.</span><span>f</span><span>,</span> <span>.</span><span>z</span> <span>=</span> <span>0.</span><span>f</span><span>,</span> <span>.</span><span>x</span> <span>=</span> <span>0.</span><span>f</span><span>};</span>
</code></pre></div>

<p>This behavior makes sense for structured types with non-trivial layout, but feels unnecessarily restrictive
for POD types. I often work with types that have dozens of fields or more, so honoring the initialization
order to match the original declaration is quite tedious indeed. Furthermore, in game dev, we often move
structure fields around in order to optimize layout (coalescing hot data in cache lines, promoting true
sharing, avoiding false sharing). This type of optimization can’t be done without cascading into compilation
failures throughout the codebase. As a result, designated initializers have the paradoxical effect of making a
codebase <em>less maintainable</em> in a sense.</p>

<p>This one is still <em>barely</em> in the nice category because it does make life better for the reader (who we
all prioritize over the writer), but I do hope that restriction is relaxed for trivial types some day. Flexibility
with ordering was the entire point of the “named parameters” feature in many other languages after all.</p>

<h2 id="naughty-char8_t">(Naughty) char8_t</h2>

<p>MSVC added <code>/Zc:char8_t-</code> to disable this type entirely, and GCC did the same.
The main reason <code>char8_t</code> was introduced was to provide a dedicated
type for unicode data. Unfortunately, as specified, unicode conversions to <code>char*</code> were disallowed,
thereby breaking a lot of compatibility with <code>char*</code> interfaces that expected users to pass <code>u8""</code> strings.
This famously caused a bit of drama by breaking a number of
<a href="https://github.com/ocornut/imgui">Dear ImGui</a> APIs (<a href="https://web.archive.org/web/20220104084024/https://twitter.com/ocornut/status/1377986353498095618">wayback twitter thread</a>).
I will continue to abide by the guidelines summarized
<a href="https://utf8everywhere.org/">here</a> for UTF-8 matters (unless I’m forced to live in a <code>TCHAR</code> world).
That said, the <code>char8_t</code> proposal in general has my sympathy, since it <em>would be nice</em> to have the unicode
story fully straightened out, but c’est la vie.</p>

<h2 id="naughty-ish-no_unique_address">(Naughty-ish) [[no_unique_address]]</h2>

<p>This is naughty <em>specifically</em> because of MSVC, where you continue to need to use <code>[[msvc::no_unique_address]]</code>
for <a href="https://devblogs.microsoft.com/cppblog/msvc-cpp20-and-the-std-cpp20-switch/#c20-no_unique_address">reasons</a>.</p>

<p>Otherwise, you probably want this for things like stateless allocators that are used as data structure
members but shouldn’t occupy actual memory.</p>

<h2 id="naughty-modules">(Naughty) Modules</h2>

<p>C++20 <a href="https://en.cppreference.com/w/cpp/language/modules">modules</a> in its current state are
unfortunately a big disappointment. I do hope they eventually get to a better place, but this may be difficult
for as long as the C++ standard continues to ignore shared linkage and DLLs. Here’s a
<a href="https://stackoverflow.com/questions/52286991/what-is-the-expected-relation-of-c-modules-and-dynamic-linkage/74444920#74444920">StackOverflow answer</a>
I wrote some time ago to describe the problem. Essentially, module and DLL linkages are completely orthogonal
to each other, so if you’re in the business of maintaining a codebase where you’d need both (as most game
devs are), expect there to be a lot of build complexity juggling symbol visibilty and linkage types.
While the problematic <code>jmp</code> indirection mentioned in that StackOverflow answer can be eliminated with full LTO
(and possibly thin LTO), I suspect most game devs find LTO to be a bit too heavy for frequent usage anyways.</p>

<h2 id="naughty-format">(Naughty) <code>&lt;format&gt;</code></h2>

<p>The <a href="https://en.cppreference.com/w/cpp/header/format"><code>&lt;format&gt;</code></a> header is probably great in many contexts,
but I would not personally use it for a game engine. Once you get in the business of making an API that
encourages custom formatter specification to live in a template, IMO, you’ve already lost. Using <code>std::format</code>
and <code>fmtlib</code> which the standard is based on, I saw compile times and binary sizes increase dramatically
in a way that does not scale across a gigantic codebase (to my satisfication). Relying on the linker to
drop duplicate symbols is “an approach” but not one I’m a fan of. It’s <em>incredibly wasteful</em> to ask your
compiler to compile copies of your code and write them to disk for every translation unit that requires
a custom formatter, only to then request the linker to read it all back and drop duplicates (not to mention
PDB sizes). Of course, it’s possible to declare custom formatter templates and implement them in a source file,
but again, this isn’t encouraged by the API, and I don’t believe it’s possible to rely on raw discipline to prevent
that type of code bloat from accruing across a large team.</p>

<p>A preferable interface (I use, but also others AFAIK) is to check the type in a template (no choice there),
and dispatch the formatting routine to somewhere that lives in a single translation unit.</p>

<h2 id="naughty-ranges">(Naughty) <code>&lt;ranges&gt;</code></h2>

<p>I tried <a href="https://en.cppreference.com/w/cpp/header/ranges"><code>&lt;ranges&gt;</code></a> in a medium-ish codebase and benchmarked
the compiler about a year ago. I wasn’t remotely happy with the results and reverted the changes, YMMV.
An incredible amount of work has gone into this, but it sort of reinforces my belief that for some constructs,
templates are a valuable prototyping tool, but not the endgame. Personally, I find code that leverages
ranges <em>harder</em> to read, not easier, because lambdas inlined in functions introduce new scopes that have a
strong non-linearizing effect on the code. This isn’t a criticism of ranges per se, but certainly is a stylistic
preference.</p>

<h2 id="naughty-source_location">(Naughty) <code>&lt;source_location&gt;</code></h2>

<p>The new <a href="https://en.cppreference.com/w/cpp/utility/source_location"><code>&lt;source_location&gt;</code></a> feature lets
you remove a macro which would have historically expanded <code>__FILE__</code> and <code>__LINE__</code> directives and replace
it with a <code>std::source_location</code> which is populated by a default argument (spelled <code>std::source_location::current</code>).
This isn’t overwhelmingly naughty, but I don’t see it as a dramatic improvement either. Chances are,
your log statements need to remain macros since you need a way to strip those statements at build time
depending on the build type anyways. The main drawback of <code>std::source_location</code> is that compared to
<code>__FILE__</code>, where the file length is statically knowable, <code>std::source_location::file_name</code> returns
a <code>const char*</code> string with a file length that <em>isn’t</em> statically knowable.</p>

<p>IMO, the new <code>std::source_location</code> “pattern” makes function signatures a lot uglier, and would be
better served with a separate mechanism for querying PDBs and stack frame data. Luckily,
<a href="https://en.cppreference.com/w/cpp/header/stacktrace">stacktrace</a> is on the horizon, but I doubt
we’ll get any cross-platform interfaces for querying DWARF/PDB files anytime soon (wouldn’t that be
lovely).</p>

<h2 id="conclusion">Conclusion</h2>

<p>On the whole, I view C++20 as an impactful and positive change, albeit with a few hiccups here
and there (understandable given the sheer scale of the standardization effort). It’s also likely
the case that some features I view as misses, might be viewed as absolute godsends by other engineers
with different requirements or coding practices to my own. Finally, as a reminder, there were plenty
of changes in C++20 that weren’t covered here, either because I lack personal experience with the feature,
or because it’s a feature unlikely to be relevant to game devs specifically. With that, I encourage
readers to take this list with a grain of salt, try things out, and draw your own conclusions.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: How do I train a custom LLM/ChatGPT on my own documents in Dec 2023? (661 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38759877</link>
            <guid>38759877</guid>
            <pubDate>Mon, 25 Dec 2023 04:42:46 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38759877">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38760098"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38760098" href="https://news.ycombinator.com/vote?id=38760098&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><p><span>You don't train on documents. There are many startups claiming that but they are deliberately using a misleading term because they know that's what people are searching for.<p>You still do RAG. Llamaindex is still the best option that I know of. Most of the startups that have working products are likely using llamaindex. All of the ones that say they are training on documents are actually using RAG.</p><p>Test it out. If it really and truly doesn't work, search for a script that creates question and answer pairs automatically with gpt-4. Then try using that for qLoRA. I have never heard of anyone successfully using that for a private document knowledgebase though. Only for skills like math, reasoning, Python, etc. I think the issue is that you need a LOT of data and it needs to repeat concepts or any facts you need to learn many, many times in different supporting ways.</p><p>What absolutely does not work is trying to just feed a set of documents into fine tuning. I personally have proven that dozens of times because I had a client who is determined to do it. He has been mislead.</p><p>What it will do is learn the patterns that are in those documents.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38760251"><td></td></tr>
                <tr id="38760512"><td></td></tr>
            <tr id="38760260"><td></td></tr>
                  <tr id="38760189"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38760189" href="https://news.ycombinator.com/vote?id=38760189&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><p><span>To sing the praises of Bedrock again, it does have continuous pre-training as well as RAG “knowledge bases”.  The former is based on JSON fragments and the RAG stuff is PDFs and other document formats.<p>With regards to its efficacy, I haven’t gone to production with it yet but I was reasonably impressed.</p><p>I uploaded 100 legal case documents to Bedrock via Claude and could push it pretty hard asking about the various cases and for situations across the knowledge base.</p><p>It did feel like it broke down and got confused at a certain point of complexity of questioning, but I still think it’s already useful as a “copilot” or search engine and surely it will only improve over time.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38760632"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38760632" href="https://news.ycombinator.com/vote?id=38760632&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><p><span>I forgot about the continuous pre-training thing. How long and how much did they cost on Bedrock?<p>I had tried to suggest continuous pre-training to my client but it seemed expensive and when I mentioned that  he lost interest and just kept wanting me to do fine tuning.</p><p>Also to clarify, did you do the continuous pre-training or RAG? And did you compare the efficacy of one or the other or both?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38760652"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38760652" href="https://news.ycombinator.com/vote?id=38760652&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><p><span>I used the RAG knowledge bases for most of my testing described above.<p>I got a toy demo up and running with continuous pre-training but haven’t evaluated it unfortunately.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38760126"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38760126" href="https://news.ycombinator.com/vote?id=38760126&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><br><div>
                  <p><span>Another question, which one is preferred, LlamaIndex or Langchain, for RAG? Thanks in advance for your insights.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38760430"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38760430" href="https://news.ycombinator.com/vote?id=38760430&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><p><span>You basically don't use langchain for anything besides 30 minute demos that you copied from someone else's github. It has a completely spaghettified API, is not performant, and forces you into excessive mental contortions to reason about otherwise simple tasks.<p>LlamaIndex is pretty good.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38760444"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38760444" href="https://news.ycombinator.com/vote?id=38760444&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><br><div>
                  <p><span>LlamaIndex is mainly focused on RAG. LangChain does a ton of other stuff too. I'd focus on LlamaIndex first.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38760121"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38760121" href="https://news.ycombinator.com/vote?id=38760121&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><br><div>
                  <p><span>Are there public examples of working products using RAG, compared with fine-tuning or training from scratch?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38760393"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38760393" href="https://news.ycombinator.com/vote?id=38760393&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><br><div>
                  <p><span>The OpenAI assistants API is an implementation of a RAG pipeline. It performs both RAG on any documents you upload, and on any conversation you have with it that exceeds the context.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38760282"><td></td></tr>
                  <tr id="38760142"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38760142" href="https://news.ycombinator.com/vote?id=38760142&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><br><div>
                  <p><span>Well said.
The problem is, there are way too many alternatives. Any idea how llamaindex's ingestion engine compares to unstructured.io? ( Which is used in langchain)</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38760081"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38760081" href="https://news.ycombinator.com/vote?id=38760081&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><p><span>AWS Bedrock is fairly easy.  You can do it in 5 or 6 clicks.<p>You have to upload your documents to S3, create a “Knowledge Base” then sync your documents into a vector database like OpenSearch or PineCone.  You are then good to go via their playground or the AWS API.</p><p>I made a video here describing the process, check around 14 minutes in:</p><p><a href="https://ensembleanalytics.io/blog/introducing-bedrock-knowledge-bases" rel="nofollow noreferrer">https://ensembleanalytics.io/blog/introducing-bedrock-knowle...</a></p><p>Bedrock is a decent product I think.  All of the models in one place (apart from the big dogs from OpenAI) and a common API across them.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38760325"><td></td></tr>
                <tr id="38760370"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38760370" href="https://news.ycombinator.com/vote?id=38760370&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><p><span>The documents are encoded as vectors and stored in a database, so I suspect it would be effectively unlimited.  You would just pay for storage and compute.<p>AWS OpenSearch has fairly good integration so you could look up costs for that.  It’s not the cheapest AWS service to run and not exactly serverless as you pay by the hour.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38760351"><td></td></tr>
                <tr id="38760357"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38760357" href="https://news.ycombinator.com/vote?id=38760357&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><br><div>
                  <p><span>I’m sorry, I don’t understand those limits. It uses a lot of unfamiliar terms like “batch inference” and “modality”. I just want a nice UI that I can give my hard-drive to and then ask it questions.</span></p></div></td></tr>
        </tbody></table></td></tr>
                                        <tr id="38760618"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38760618" href="https://news.ycombinator.com/vote?id=38760618&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><p><span>A go-to method is to ingest different chunksizes based on the document hierarchy &amp; then use langchain with a bunch of retrievers depending on the doc type.<p>Then create an index about the metadata of each doc. So that you can ask the RAGbot what all it can answer about.</p><p>Another way to ensure it stays on-domain is to generate synthetic questions &amp; check for similarity against user queries. There's a whole rabbit hole of query decomposition to avoid straying off topic as well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38760083"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38760083" href="https://news.ycombinator.com/vote?id=38760083&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><p><span>I haven't personally tried this for anything serious yet, but to get the thread started:<p>Cheshire Cat [0] looks promising. It's a framework for building AI assistants by providing it with documents that it stores as "memories" that can be retrieved later. I'm not sure how well it works yet, but it has an active community on Discord and seems to be developing rapidly.</p><p>The main perk over the cloud options is that you can point it at any language model, including fully local—my local install pointed at my local Ollama running Mistral.</p><p>[0] <a href="https://github.com/cheshire-cat-ai/core">https://github.com/cheshire-cat-ai/core</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38760116"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38760116" href="https://news.ycombinator.com/vote?id=38760116&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><br><div>
                  <p><span>But that's not training. That's RAG. They seem to be using qdrant which I believe is a vector store.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38760335"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38760335" href="https://news.ycombinator.com/vote?id=38760335&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><br><div>
                  <p><span>They've updated the question to clarify that RAG counts, and as many have noted, properly "training" on a set of documents isn't really a thing.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38760676"><td></td></tr>
            <tr id="38760275"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38760275" href="https://news.ycombinator.com/vote?id=38760275&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><p><span>Slightly off topic but is there recommended advice on how to tune / train not for document retrieval but for consistent JSON output with specific enums?<p>i.e given a text, always return back a certain set of fields. For some keys here is the possible set of enums etc. One shot prompting does work but curious how others approach this if you have training data on hand.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38760434"><td></td></tr>
            <tr id="38760388"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38760388" href="https://news.ycombinator.com/vote?id=38760388&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><br><div>
                  <p><span>You want grammars to restrict the output, search for "gbnf grammar". That and combined with a good prompt with an example, also check out outlines.dev</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38760453"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38760453" href="https://news.ycombinator.com/vote?id=38760453&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><p><span>For OpenAI, use their functions schema mechanism.<p>Aside from that, take a look at llama.cpp grammars.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38760543"><td></td></tr>
            <tr id="38760123"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38760123" href="https://news.ycombinator.com/vote?id=38760123&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><br><div>
                  <p><span>GPT-4 Turbo has a 128K (~300 pages) context window, which probably handles a lot of use cases which might have previously needed extra training/refinement.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38760415"><td></td></tr>
            <tr id="38760377"><td></td></tr>
            <tr id="38760346"><td></td></tr>
            <tr id="38760112"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38760112" href="https://news.ycombinator.com/vote?id=38760112&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><p><span>Train on your own documents or analyze your own documents for answers? Very different things.<p>For the first (fine tuning) follow “AI Jason” on YouTube. He has some great tutorials.</p><p>For the second (RAG or similar), fire up a cloud VM with GPUs or use Ollama locally and read through the LlamaIndex docs on how to build a RAG pipeline.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38760132"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38760132" href="https://news.ycombinator.com/vote?id=38760132&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><br><div>
                  <p><span>Would you kindly elaborate a little bit the difference between training on own documents vs analyzing documents for answers?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38760466"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38760466" href="https://news.ycombinator.com/vote?id=38760466&amp;how=up&amp;goto=item%3Fid%3D38759877"></a></center>    </td><td><p><span>The word "training" implies creating a new model by fine-tuning an existing model on top of new documents.<p>As several other comments in this thread have already indicated: this is almost always the wrong direction. Which is confusing because it's the direction everyone always assumes they should go in at first.</p><p>The approaches that does work is surprisingly simple: take the user's question, search for snippets of your documents that appear to be about that question, then paste all of those snippets into the prompt along with the user's question and see what answer you get.</p><p>This is known as RAG: Retrieval Augmented Generation. It's a very powerful approach.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reforming Unix (149 pts)]]></title>
            <link>https://github.com/Ericson2314/baccumulation/blob/main/reforming-unix.adoc</link>
            <guid>38759875</guid>
            <pubDate>Mon, 25 Dec 2023 04:42:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Ericson2314/baccumulation/blob/main/reforming-unix.adoc">https://github.com/Ericson2314/baccumulation/blob/main/reforming-unix.adoc</a>, See on <a href="https://news.ycombinator.com/item?id=38759875">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:Ericson2314/baccumulation" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="H7nO_qQgVfq--GkIjqbJOZy8lXFGXTAoY-bZEhT-KSXpuqLXEB446eZBaTWyyETQ81SaA3bIp29pbFMFMWVZRQ" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="Ericson2314/baccumulation" data-current-org="" data-current-owner="Ericson2314" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=JIzIh8dk57DHD8KnPgWgEUhKLP7jSvw9pFli%2FUKyWYeWYIUVxY6xkaQmUBpclANsF%2F8bIZpQ9iai0jaKBAgnKUR%2F1csjZna9r02Hru%2FZvyMbMznfsWHo4gPNf5EmKigK1blJS5wx3J%2FM6EWEhjv99vwsAvJTZDS%2BszL6%2F3NO3neoWI8Pphyj4QY7H1HqMRuAFZ8Gb1%2F%2FULchyo3o%2FrhK2yf6Jw8XWttZ1dby1CijDSgdEQmj65cT0VRgMngCVVziHtlhXhnc0aA0onFwa2t1XG3uPNl%2FpYL%2Be08NhsNA0IY%2BRyQNniC2OUaap1QKHYM5M7%2FxAWeM2EWNrWNdl8y3gNk6EFU2VCMS4McM6pZOEbnAYxXs9htPdNv5e9YB1I9ZJPsJQzqUC5lAdwSylx1b%2FYYjDWwAQzT2wyTxn5W1oZHMp%2FgOoYtEzV1RRGw7QbvipSxmccrYvaXxztEjFwdf%2BIWz2SdwJMz3E4ihBmsagpGNpIT7%2Fu29g2xEUdcjC7N4qPlT0GmqL3zihxsC%2B8rN4VD8Q2AmR139gGFDo9EsbVPx9bic9UyH2r4edjQ12rh8gj3rsH9RRp5zMvk2TSAmVX7s--jDD%2F5I4XJtckmREK--uQSYqdoLVrjULkLtkk%2FQpQ%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=Ericson2314%2Fbaccumulation" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/Ericson2314/baccumulation/blob/main/reforming-unix.adoc&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="0116b341db17442baf960210460ce42324080d22f1c6829b7ee70543f9951cb1" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Star – Arthur C. Clarke (1967) [pdf] (307 pts)]]></title>
            <link>https://sites.uni.edu/morgans/astro/course/TheStar.pdf</link>
            <guid>38759297</guid>
            <pubDate>Mon, 25 Dec 2023 03:08:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sites.uni.edu/morgans/astro/course/TheStar.pdf">https://sites.uni.edu/morgans/astro/course/TheStar.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=38759297">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
    </channel>
</rss>