<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 10 Apr 2024 00:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[A MySQL compatible database engine written in pure Go (157 pts)]]></title>
            <link>https://github.com/dolthub/go-mysql-server</link>
            <guid>39983490</guid>
            <pubDate>Tue, 09 Apr 2024 19:50:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dolthub/go-mysql-server">https://github.com/dolthub/go-mysql-server</a>, See on <a href="https://news.ycombinator.com/item?id=39983490">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/dolthub/go-mysql-server/blob/main/mascot.png"><img height="240" src="https://github.com/dolthub/go-mysql-server/raw/main/mascot.png"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">A MySQL compatible database engine written in pure Go</h2><a id="user-content-a-mysql-compatible-database-engine-written-in-pure-go" aria-label="Permalink: A MySQL compatible database engine written in pure Go" href="#a-mysql-compatible-database-engine-written-in-pure-go"></a></p>
<p dir="auto"><strong>go-mysql-server</strong> is a data-source agnostic SQL engine and server
which runs queries on data sources you provide, using the MySQL
dialect and wire protocol. A simple in-memory database implementation
is included, and you can query any data source you want by
implementing your own backend.</p>
<p dir="auto"><a href="https://www.doltdb.com/" rel="nofollow">Dolt</a>, a SQL database with Git-style
versioning, is the main production database implementation of this
package.  <a href="https://docs.dolthub.com/introduction/what-is-dolt" rel="nofollow">Check
out</a> that project
for reference a implementation. Or, hop into the Dolt discord
<a href="https://discord.com/invite/RFwfYpu" rel="nofollow">here</a> if you want to talk to the
<a href="https://www.dolthub.com/team" rel="nofollow">core developers</a> behind
<strong>go-mysql-server</strong> and Dolt.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compatibility</h2><a id="user-content-compatibility" aria-label="Permalink: Compatibility" href="#compatibility"></a></p>
<p dir="auto">With the exception of specific limitations (see below),
<strong>go-mysql-server</strong> is a drop-in replacement for MySQL. Any client
library, tool, query, SQL syntax, SQL function, etc. that works with
MySQL should also work with <strong>go-mysql-server</strong>. If you find a gap in
functionality, please file an issue.</p>
<p dir="auto">For full MySQL compatibility documentation, see the <a href="https://docs.dolthub.com/sql-reference/sql-support" rel="nofollow">Dolt
docs</a> on this
topic.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Scope of this project</h2><a id="user-content-scope-of-this-project" aria-label="Permalink: Scope of this project" href="#scope-of-this-project"></a></p>
<ul dir="auto">
<li>SQL server and engine to query your data sources.</li>
<li>In-memory database backend implementation suitable for use in tests.</li>
<li>Interfaces you can use to implement new backends to query your own
data sources.</li>
<li>With a few caveats and using a full database implementation, a
drop-in MySQL database replacement.</li>
</ul>
<p dir="auto"><strong>go-mysql-server</strong> has two primary uses case:</p>
<ol dir="auto">
<li>
<p dir="auto">Stand-in for MySQL in a golang test environment, using the built-in
<code>memory</code> database implementation.</p>
</li>
<li>
<p dir="auto">Providing access to arbitrary data sources with SQL queries by
implementing a handful of interfaces. The most complete real-world
implementation is <a href="https://github.com/dolthub/dolt">Dolt</a>.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Add <strong>go-mysql-server</strong> as a dependency to your project. In the
directory with the <code>go.mod</code> file, run:</p>
<div data-snippet-clipboard-copy-content="go get github.com/dolthub/go-mysql-server@latest"><pre><code>go get github.com/dolthub/go-mysql-server@latest
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using the in-memory test server</h2><a id="user-content-using-the-in-memory-test-server" aria-label="Permalink: Using the in-memory test server" href="#using-the-in-memory-test-server"></a></p>
<p dir="auto">The in-memory test server can replace a real MySQL server in
tests. Start the server using the code in the <a href="https://github.com/dolthub/go-mysql-server/blob/main/_example/main.go">_example
directory</a>, also reproduced below.</p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
	&quot;context&quot;
	&quot;fmt&quot;
	&quot;time&quot;

	&quot;github.com/dolthub/vitess/go/vt/proto/query&quot;

	sqle &quot;github.com/dolthub/go-mysql-server&quot;
	&quot;github.com/dolthub/go-mysql-server/memory&quot;
	&quot;github.com/dolthub/go-mysql-server/server&quot;
	&quot;github.com/dolthub/go-mysql-server/sql&quot;
	&quot;github.com/dolthub/go-mysql-server/sql/types&quot;
)

// This is an example of how to implement a MySQL server.
// After running the example, you may connect to it using the following:
//
// > mysql --host=localhost --port=3306 --user=root mydb --execute=&quot;SELECT * FROM mytable;&quot;
// +----------+-------------------+-------------------------------+----------------------------+
// | name     | email             | phone_numbers                 | created_at                 |
// +----------+-------------------+-------------------------------+----------------------------+
// | Jane Deo | janedeo@gmail.com | [&quot;556-565-566&quot;,&quot;777-777-777&quot;] | 2022-11-01 12:00:00.000001 |
// | Jane Doe | jane@doe.com      | []                            | 2022-11-01 12:00:00.000001 |
// | John Doe | john@doe.com      | [&quot;555-555-555&quot;]               | 2022-11-01 12:00:00.000001 |
// | John Doe | johnalt@doe.com   | []                            | 2022-11-01 12:00:00.000001 |
// +----------+-------------------+-------------------------------+----------------------------+
//
// The included MySQL client is used in this example, however any MySQL-compatible client will work.

var (
	dbName    = &quot;mydb&quot;
	tableName = &quot;mytable&quot;
	address   = &quot;localhost&quot;
	port      = 3306
)

func main() {
	pro := createTestDatabase()
	engine := sqle.NewDefault(pro)

	session := memory.NewSession(sql.NewBaseSession(), pro)
	ctx := sql.NewContext(context.Background(), sql.WithSession(session))
	ctx.SetCurrentDatabase(&quot;test&quot;)

	// This variable may be found in the &quot;users_example.go&quot; file. Please refer to that file for a walkthrough on how to
	// set up the &quot;mysql&quot; database to allow user creation and user checking when establishing connections. This is set
	// to false for this example, but feel free to play around with it and see how it works.
	if enableUsers {
		if err := enableUserAccounts(ctx, engine); err != nil {
			panic(err)
		}
	}

	config := server.Config{
		Protocol: &quot;tcp&quot;,
		Address:  fmt.Sprintf(&quot;%s:%d&quot;, address, port),
	}
	s, err := server.NewServer(config, engine, memory.NewSessionBuilder(pro), nil)
	if err != nil {
		panic(err)
	}
	if err = s.Start(); err != nil {
		panic(err)
	}
}

func createTestDatabase() *memory.DbProvider {
	db := memory.NewDatabase(dbName)
	db.BaseDatabase.EnablePrimaryKeyIndexes()

	pro := memory.NewDBProvider(db)
	session := memory.NewSession(sql.NewBaseSession(), pro)
	ctx := sql.NewContext(context.Background(), sql.WithSession(session))

	table := memory.NewTable(db, tableName, sql.NewPrimaryKeySchema(sql.Schema{
		{Name: &quot;name&quot;, Type: types.Text, Nullable: false, Source: tableName, PrimaryKey: true},
		{Name: &quot;email&quot;, Type: types.Text, Nullable: false, Source: tableName, PrimaryKey: true},
		{Name: &quot;phone_numbers&quot;, Type: types.JSON, Nullable: false, Source: tableName},
		{Name: &quot;created_at&quot;, Type: types.MustCreateDatetimeType(query.Type_DATETIME, 6), Nullable: false, Source: tableName},
	}), db.GetForeignKeyCollection())
	db.AddTable(tableName, table)

	creationTime := time.Unix(0, 1667304000000001000).UTC()
	_ = table.Insert(ctx, sql.NewRow(&quot;Jane Deo&quot;, &quot;janedeo@gmail.com&quot;, types.MustJSON(`[&quot;556-565-566&quot;, &quot;777-777-777&quot;]`), creationTime))
	_ = table.Insert(ctx, sql.NewRow(&quot;Jane Doe&quot;, &quot;jane@doe.com&quot;, types.MustJSON(`[]`), creationTime))
	_ = table.Insert(ctx, sql.NewRow(&quot;John Doe&quot;, &quot;john@doe.com&quot;, types.MustJSON(`[&quot;555-555-555&quot;]`), creationTime))
	_ = table.Insert(ctx, sql.NewRow(&quot;John Doe&quot;, &quot;johnalt@doe.com&quot;, types.MustJSON(`[]`), creationTime))

	return pro
}"><pre><span>package</span> main

<span>import</span> (
	<span>"context"</span>
	<span>"fmt"</span>
	<span>"time"</span>

	<span>"github.com/dolthub/vitess/go/vt/proto/query"</span>

	sqle <span>"github.com/dolthub/go-mysql-server"</span>
	<span>"github.com/dolthub/go-mysql-server/memory"</span>
	<span>"github.com/dolthub/go-mysql-server/server"</span>
	<span>"github.com/dolthub/go-mysql-server/sql"</span>
	<span>"github.com/dolthub/go-mysql-server/sql/types"</span>
)

<span>// This is an example of how to implement a MySQL server.</span>
<span>// After running the example, you may connect to it using the following:</span>
<span>//</span>
<span>// &gt; mysql --host=localhost --port=3306 --user=root mydb --execute="SELECT * FROM mytable;"</span>
<span>// +----------+-------------------+-------------------------------+----------------------------+</span>
<span>// | name     | email             | phone_numbers                 | created_at                 |</span>
<span>// +----------+-------------------+-------------------------------+----------------------------+</span>
<span>// | Jane Deo | janedeo@gmail.com | ["556-565-566","777-777-777"] | 2022-11-01 12:00:00.000001 |</span>
<span>// | Jane Doe | jane@doe.com      | []                            | 2022-11-01 12:00:00.000001 |</span>
<span>// | John Doe | john@doe.com      | ["555-555-555"]               | 2022-11-01 12:00:00.000001 |</span>
<span>// | John Doe | johnalt@doe.com   | []                            | 2022-11-01 12:00:00.000001 |</span>
<span>// +----------+-------------------+-------------------------------+----------------------------+</span>
<span>//</span>
<span>// The included MySQL client is used in this example, however any MySQL-compatible client will work.</span>

<span>var</span> (
	<span>dbName</span>    <span>=</span> <span>"mydb"</span>
	<span>tableName</span> <span>=</span> <span>"mytable"</span>
	<span>address</span>   <span>=</span> <span>"localhost"</span>
	<span>port</span>      <span>=</span> <span>3306</span>
)

<span>func</span> <span>main</span>() {
	<span>pro</span> <span>:=</span> <span>createTestDatabase</span>()
	<span>engine</span> <span>:=</span> <span>sqle</span>.<span>NewDefault</span>(<span>pro</span>)

	<span>session</span> <span>:=</span> <span>memory</span>.<span>NewSession</span>(<span>sql</span>.<span>NewBaseSession</span>(), <span>pro</span>)
	<span>ctx</span> <span>:=</span> <span>sql</span>.<span>NewContext</span>(<span>context</span>.<span>Background</span>(), <span>sql</span>.<span>WithSession</span>(<span>session</span>))
	<span>ctx</span>.<span>SetCurrentDatabase</span>(<span>"test"</span>)

	<span>// This variable may be found in the "users_example.go" file. Please refer to that file for a walkthrough on how to</span>
	<span>// set up the "mysql" database to allow user creation and user checking when establishing connections. This is set</span>
	<span>// to false for this example, but feel free to play around with it and see how it works.</span>
	<span>if</span> <span>enableUsers</span> {
		<span>if</span> <span>err</span> <span>:=</span> <span>enableUserAccounts</span>(<span>ctx</span>, <span>engine</span>); <span>err</span> <span>!=</span> <span>nil</span> {
			<span>panic</span>(<span>err</span>)
		}
	}

	<span>config</span> <span>:=</span> server.<span>Config</span>{
		<span>Protocol</span>: <span>"tcp"</span>,
		<span>Address</span>:  <span>fmt</span>.<span>Sprintf</span>(<span>"%s:%d"</span>, <span>address</span>, <span>port</span>),
	}
	<span>s</span>, <span>err</span> <span>:=</span> <span>server</span>.<span>NewServer</span>(<span>config</span>, <span>engine</span>, <span>memory</span>.<span>NewSessionBuilder</span>(<span>pro</span>), <span>nil</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>panic</span>(<span>err</span>)
	}
	<span>if</span> <span>err</span> <span>=</span> <span>s</span>.<span>Start</span>(); <span>err</span> <span>!=</span> <span>nil</span> {
		<span>panic</span>(<span>err</span>)
	}
}

<span>func</span> <span>createTestDatabase</span>() <span>*</span>memory.<span>DbProvider</span> {
	<span>db</span> <span>:=</span> <span>memory</span>.<span>NewDatabase</span>(<span>dbName</span>)
	<span>db</span>.<span>BaseDatabase</span>.<span>EnablePrimaryKeyIndexes</span>()

	<span>pro</span> <span>:=</span> <span>memory</span>.<span>NewDBProvider</span>(<span>db</span>)
	<span>session</span> <span>:=</span> <span>memory</span>.<span>NewSession</span>(<span>sql</span>.<span>NewBaseSession</span>(), <span>pro</span>)
	<span>ctx</span> <span>:=</span> <span>sql</span>.<span>NewContext</span>(<span>context</span>.<span>Background</span>(), <span>sql</span>.<span>WithSession</span>(<span>session</span>))

	<span>table</span> <span>:=</span> <span>memory</span>.<span>NewTable</span>(<span>db</span>, <span>tableName</span>, <span>sql</span>.<span>NewPrimaryKeySchema</span>(sql.<span>Schema</span>{
		{<span>Name</span>: <span>"name"</span>, <span>Type</span>: <span>types</span>.<span>Text</span>, <span>Nullable</span>: <span>false</span>, <span>Source</span>: <span>tableName</span>, <span>PrimaryKey</span>: <span>true</span>},
		{<span>Name</span>: <span>"email"</span>, <span>Type</span>: <span>types</span>.<span>Text</span>, <span>Nullable</span>: <span>false</span>, <span>Source</span>: <span>tableName</span>, <span>PrimaryKey</span>: <span>true</span>},
		{<span>Name</span>: <span>"phone_numbers"</span>, <span>Type</span>: <span>types</span>.<span>JSON</span>, <span>Nullable</span>: <span>false</span>, <span>Source</span>: <span>tableName</span>},
		{<span>Name</span>: <span>"created_at"</span>, <span>Type</span>: <span>types</span>.<span>MustCreateDatetimeType</span>(<span>query</span>.<span>Type_DATETIME</span>, <span>6</span>), <span>Nullable</span>: <span>false</span>, <span>Source</span>: <span>tableName</span>},
	}), <span>db</span>.<span>GetForeignKeyCollection</span>())
	<span>db</span>.<span>AddTable</span>(<span>tableName</span>, <span>table</span>)

	<span>creationTime</span> <span>:=</span> <span>time</span>.<span>Unix</span>(<span>0</span>, <span>1667304000000001000</span>).<span>UTC</span>()
	<span>_</span> <span>=</span> <span>table</span>.<span>Insert</span>(<span>ctx</span>, <span>sql</span>.<span>NewRow</span>(<span>"Jane Deo"</span>, <span>"janedeo@gmail.com"</span>, <span>types</span>.<span>MustJSON</span>(<span>`["556-565-566", "777-777-777"]`</span>), <span>creationTime</span>))
	<span>_</span> <span>=</span> <span>table</span>.<span>Insert</span>(<span>ctx</span>, <span>sql</span>.<span>NewRow</span>(<span>"Jane Doe"</span>, <span>"jane@doe.com"</span>, <span>types</span>.<span>MustJSON</span>(<span>`[]`</span>), <span>creationTime</span>))
	<span>_</span> <span>=</span> <span>table</span>.<span>Insert</span>(<span>ctx</span>, <span>sql</span>.<span>NewRow</span>(<span>"John Doe"</span>, <span>"john@doe.com"</span>, <span>types</span>.<span>MustJSON</span>(<span>`["555-555-555"]`</span>), <span>creationTime</span>))
	<span>_</span> <span>=</span> <span>table</span>.<span>Insert</span>(<span>ctx</span>, <span>sql</span>.<span>NewRow</span>(<span>"John Doe"</span>, <span>"johnalt@doe.com"</span>, <span>types</span>.<span>MustJSON</span>(<span>`[]`</span>), <span>creationTime</span>))

	<span>return</span> <span>pro</span>
}</pre></div>
<p dir="auto">This example populates the database by creating <code>memory.Database</code> and
<code>memory.Table</code> objects via golang code, but you can also populate it
by issuing <code>CREATE DATABASE</code>, <code>CREATE TABLE</code>, etc. statements to the
server once it's running.</p>
<p dir="auto">Once the server is running, connect with any MySQL client, including
the golang MySQL connector and the <code>mysql</code> shell.</p>
<div dir="auto" data-snippet-clipboard-copy-content="> mysql --host=localhost --port=3306 --user=root mydb --execute=&quot;SELECT * FROM mytable;&quot;
+----------+-------------------+-------------------------------+----------------------------+
| name     | email             | phone_numbers                 | created_at                 |
+----------+-------------------+-------------------------------+----------------------------+
| Jane Deo | janedeo@gmail.com | [&quot;556-565-566&quot;,&quot;777-777-777&quot;] | 2022-11-01 12:00:00.000001 |
| Jane Doe | jane@doe.com      | []                            | 2022-11-01 12:00:00.000001 |
| John Doe | john@doe.com      | [&quot;555-555-555&quot;]               | 2022-11-01 12:00:00.000001 |
| John Doe | johnalt@doe.com   | []                            | 2022-11-01 12:00:00.000001 |
+----------+-------------------+-------------------------------+----------------------------+"><pre><span>&gt;</span> mysql --host=localhost --port=3306 --user=root mydb --execute=<span><span>"</span>SELECT * FROM mytable;<span>"</span></span>
+----------+-------------------+-------------------------------+----------------------------+
<span>|</span> name     <span>|</span> email             <span>|</span> phone_numbers                 <span>|</span> created_at                 <span>|</span>
+----------+-------------------+-------------------------------+----------------------------+
<span>|</span> Jane Deo <span>|</span> janedeo@gmail.com <span>|</span> [<span><span>"</span>556-565-566<span>"</span></span>,<span><span>"</span>777-777-777<span>"</span></span>] <span>|</span> 2022-11-01 12:00:00.000001 <span>|</span>
<span>|</span> Jane Doe <span>|</span> jane@doe.com      <span>|</span> []                            <span>|</span> 2022-11-01 12:00:00.000001 <span>|</span>
<span>|</span> John Doe <span>|</span> john@doe.com      <span>|</span> [<span><span>"</span>555-555-555<span>"</span></span>]               <span>|</span> 2022-11-01 12:00:00.000001 <span>|</span>
<span>|</span> John Doe <span>|</span> johnalt@doe.com   <span>|</span> []                            <span>|</span> 2022-11-01 12:00:00.000001 <span>|</span>
+----------+-------------------+-------------------------------+----------------------------+</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Limitations of the in-memory database implementation</h2><a id="user-content-limitations-of-the-in-memory-database-implementation" aria-label="Permalink: Limitations of the in-memory database implementation" href="#limitations-of-the-in-memory-database-implementation"></a></p>
<p dir="auto">The in-memory database implementation included with this package is
intended for use in tests. It has specific limitations that we know
of:</p>
<ul dir="auto">
<li><a href="https://github.com/dolthub/go-mysql-server/issues/1306" data-hovercard-type="issue" data-hovercard-url="/dolthub/go-mysql-server/issues/1306/hovercard">Not
threadsafe</a>. To
avoid concurrency issues, limit DDL and DML statements (<code>CREATE TABLE</code>, <code>INSERT</code>, etc.) to a single goroutine.</li>
<li><a href="https://github.com/dolthub/go-mysql-server/issues/1506" data-hovercard-type="issue" data-hovercard-url="/dolthub/go-mysql-server/issues/1506/hovercard">No transaction
support</a>. Statements
like <code>START TRANSACTION</code>, <code>ROLLBACK</code>, and <code>COMMIT</code> are no-ops.</li>
<li><a href="https://github.com/dolthub/go-mysql-server/issues/1347" data-hovercard-type="issue" data-hovercard-url="/dolthub/go-mysql-server/issues/1347/hovercard">Non-performant index
implementation</a>. Indexed
lookups and joins perform full table scans on the underlying tables.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Custom backend implementations</h2><a id="user-content-custom-backend-implementations" aria-label="Permalink: Custom backend implementations" href="#custom-backend-implementations"></a></p>
<p dir="auto">You can create your own backend to query your own data sources by
implementing some interfaces. For detailed instructions, see the
<a href="https://github.com/dolthub/go-mysql-server/blob/main/BACKEND.md">backend guide</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Technical documentation for contributors and backend developers</h2><a id="user-content-technical-documentation-for-contributors-and-backend-developers" aria-label="Permalink: Technical documentation for contributors and backend developers" href="#technical-documentation-for-contributors-and-backend-developers"></a></p>
<ul dir="auto">
<li><a href="https://github.com/dolthub/go-mysql-server/blob/main/ARCHITECTURE.md">Architecture</a> is an overview of the various
packages of the project and how they fit together.</li>
<li><a href="https://github.com/dolthub/go-mysql-server/blob/main/CONTRIBUTING.md">Contribution guide</a> for new contributors,
including instructions for how to get your PR merged.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Powered by go-mysql-server</h2><a id="user-content-powered-by-go-mysql-server" aria-label="Permalink: Powered by go-mysql-server" href="#powered-by-go-mysql-server"></a></p>
<ul dir="auto">
<li><a href="https://github.com/dolthub/dolt">dolt</a></li>
<li><a href="https://github.com/src-d/gitbase">gitbase</a> (defunct)</li>
</ul>
<p dir="auto">Are you building a database backend using <strong>go-mysql-server</strong>? We
would like to hear from you and include you in this list.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security Policy</h2><a id="user-content-security-policy" aria-label="Permalink: Security Policy" href="#security-policy"></a></p>
<p dir="auto"><a href="https://github.com/dolthub/go-mysql-server/blob/main/SECURITY.md">go-mysql-server's security
policy</a> is
maintained in this repository. Please follow the disclosure instructions there.
Please do not initially report security issues in this repository's public
GitHub issues.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto"><strong>go-mysql-server</strong> was originally developed by the <code>{source-d}</code>
organzation, and this repository was originally forked from
<a href="https://github.com/src-d/go-mysql-server">src-d</a>. We want to thank
the entire <code>{source-d}</code> development team for their work on this
project, especially Miguel Molina (@erizocosmico) and Juanjo Álvarez
Martinez (@juanjux).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Apache License 2.0, see <a href="https://github.com/dolthub/go-mysql-server/blob/main/LICENSE">LICENSE</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-4 Turbo with Vision Generally Available (169 pts)]]></title>
            <link>https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4</link>
            <guid>39982818</guid>
            <pubDate>Tue, 09 Apr 2024 18:53:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4">https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4</a>, See on <a href="https://news.ycombinator.com/item?id=39982818">Hacker News</a></p>
Couldn't get https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Cow Magnets (227 pts)]]></title>
            <link>https://www.stanfordmagnets.com/cow-magnets.html</link>
            <guid>39982024</guid>
            <pubDate>Tue, 09 Apr 2024 17:45:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.stanfordmagnets.com/cow-magnets.html">https://www.stanfordmagnets.com/cow-magnets.html</a>, See on <a href="https://news.ycombinator.com/item?id=39982024">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                    <h2><strong>Cow Magnets</strong></h2>
<p><span lang="en">What is a <strong>cow magnet</strong>？Have you ever heard of this <strong><a href="https://www.stanfordmagnets.com/what-are-the-four-types-of-magnets.html">type of magnet</a></strong>? Actually, <strong>c</strong></span><strong>ow magnets</strong> are very popular with farmers, ranchers, and veterinarians since they are a well-known method of&nbsp;preventing hardware disease in cattle. So what’s&nbsp;hardware disease?</p>
<figure id="attachment_35470"><img src="https://www.stanfordmagnets.com/wp-content/uploads/2021/03/Cow_Magnets.jpg" alt="Cow Magnets" width="725" height="453" srcset="https://www.stanfordmagnets.com/wp-content/uploads/2021/03/Cow_Magnets.jpg 725w, https://www.stanfordmagnets.com/wp-content/uploads/2021/03/Cow_Magnets-300x187.jpg 300w, https://www.stanfordmagnets.com/wp-content/uploads/2021/03/Cow_Magnets-600x375.jpg 600w" sizes="(max-width: 725px) 100vw, 725px"><figcaption>Cow Magnets</figcaption></figure>
<h2><strong>About Hardware Disease</strong></h2>
<p>Hardware disease is a common term for bovine traumatic reticulopericarditis. It is usually caused by the ingestion of a sharp, metallic object. These pieces of metal settle in the reticulum and can irritate or penetrate the lining. It is most common in dairy cattle but is occasionally seen in beef cattle. It is very rarely reported in any other ruminants. It can be difficult to conclusively diagnose but can be prevented by the oral administration of a magnet around the time that the animal reaches the age of one year.</p>
<h2><strong>Causes of </strong><strong>Hardware Disease</strong></h2>
<p>Cattle commonly swallow foreign objects, because they do not use their lips to discriminate between materials and they do not completely chew their feed before swallowing.&nbsp;<span lang="en">Sharp metal objects (such as nails or iron wires) are a common cause of hardware diseases.&nbsp;The object travels into the rumen and is then pushed into the reticulum along with the rest of the feed.&nbsp; In some cases, contractions of the reticulum can push the object through part of the reticulum wall into the peritoneal cavity, where it causes severe inflammation.&nbsp;In rare cases, the metal object penetrates the entire wall of the reticulum and can pierce the heart sac, causing pericarditis. Compression by the uterus in late pregnancy, straining during parturition, and mounting during estrus can increase the likelihood of the object penetrating the abdominal wall or the heart sac.</span></p>
<h2><strong>How to prevent the hardware disease?</strong></h2>
<p><span lang="en">A <strong>cow magnet</strong> is a kind of veterinary medical equipment used to treat or prevent hardware diseases of cattle.&nbsp;Traditionally, the cow magnets are strong <strong><a href="https://www.stanfordmagnets.com/alnico-magnets.html">Alnico magnets</a></strong>, in the shape of a smooth rod, about 1 cm by 8 cm (0.4 by 3.1 inches). However, today they are more commonly several ring-shaped <strong><a href="https://www.stanfordmagnets.com/ceramic-ferrite-magnets.html">ferrite magnets</a></strong> attached to a stainless-steel or plastic core, in the same shape as the single-piece original.&nbsp;</span></p>
<p><span lang="en">Newer designs to help increase effectiveness include a cage design, in which the magnet holds metal objects inside a protective plastic framework. Even newer designs include a stronger array of <strong><a href="https://www.stanfordmagnets.com/are-rare-earth-magnets-really-rare.html">rare-earth magnets</a></strong> inside a stainless steel body that resembles the original Alnico design.</span></p>
<p>A rancher or dairy farmer feeds a magnet to each calf at branding time; the magnet settles in the rumen or reticulum and remains there for the life of the animal.&nbsp;The magnet is administered after fasting the cow for 18–24 hours. This is most effective if done to the entire herd before the age of one.</p>
<p>The cow magnet attracts such objects and prevents them from becoming lodged in the animal’s tissue. While the resultant mass of iron remains in the cow’s rumen as a pseudobezoar (an intentionally introduced bezoar), it does not cause the severe problems of hardware disease. Cow magnets cannot be passed through a cow’s 4th bonivial meta-colon.</p>
<p>Cow magnets are widely available from veterinary, feed supply, and scientific supply sources.</p>
<h2><strong>Conclusion&nbsp;</strong></h2>
<p>Thank you for reading our article and we hope it can help you to have a better understanding of the cow magnets. If you want to learn more about magnets, we would like to advise you to visit <strong><a href="https://www.stanfordmagnets.com/">Stanford Magnets</a></strong> for more information.</p>
<p>As a&nbsp;<a href="https://www.stanfordmagnets.com/magnet-manufacturer-and-supplier.html"><strong>leading&nbsp;magnet supplier&nbsp;</strong></a>across the world,&nbsp;<strong>Stanford Magnets</strong>&nbsp;has been involved in R&amp;D, manufacturing, and sales of&nbsp;<span lang="en">magnets</span>&nbsp;since the 1990s. It provides customers with high-quality permanent magnets like&nbsp;<strong><a href="https://www.stanfordmagnets.com/smco-magnets.html">SmCo magnets</a>,</strong>&nbsp;<strong><a href="https://www.samaterials.com/neodymium/1087-neodymium-metal-powder.html">neodymium</a>&nbsp;magnets</strong>,&nbsp;<strong>AlNiCo magnets</strong>, and&nbsp;<strong>ferrite magnets</strong>&nbsp;(ceramic magnets) at a very competitive price.</p>
<p><span></span>
			<span>Post Views: </span>
			<span>35,279</span>
			</p>                                    <p><span>Tags: <a href="https://www.stanfordmagnets.com/tag/alnico-magnets/" rel="tag">Alnico magnets</a>, <a href="https://www.stanfordmagnets.com/4-things-you-should-know-about-ceramic-magnets.html" rel="tag">Ceramic Magnets</a>, <a href="https://www.stanfordmagnets.com/tag/cow-magnet/" rel="tag">Cow Magnet</a>, <a href="https://www.stanfordmagnets.com/where-to-use-neodymium-countersunk-magnets.html-4" rel="tag">ferrite magnets</a>, <a href="https://www.stanfordmagnets.com/tag/hardware-disease/" rel="tag">Hardware Disease</a>, <a href="https://www.stanfordmagnets.com/how-to-choose-a-neodymium-magnet.html-9" rel="tag">leading&nbsp;magnet supplier</a>, <a href="https://www.stanfordmagnets.com/tag/neodymium-magnets/" rel="tag">Neodymium Magnets</a>, <a href="https://www.stanfordmagnets.com/tag/rare-earth-magnets/" rel="tag">rare earth magnets</a>, <a href="https://www.stanfordmagnets.com/everything-you-need-to-know-about-samarium-cobalt-magnets.html" rel="tag">SmCo Magnets</a>, <a href="https://www.stanfordmagnets.com/everything-you-need-to-know-about-rare-earth-magnets.html" rel="tag">Stanford Magnets</a>, <a href="https://www.stanfordmagnets.com/how-to-choose-a-neodymium-magnet.html-5" rel="tag">types of magnet</a></span></p>
                                                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PS1 Programming Course with MIPS Assembly and C (152 pts)]]></title>
            <link>https://pikuma.com/courses/ps1-programming-mips-assembly-language</link>
            <guid>39982011</guid>
            <pubDate>Tue, 09 Apr 2024 17:43:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pikuma.com/courses/ps1-programming-mips-assembly-language">https://pikuma.com/courses/ps1-programming-mips-assembly-language</a>, See on <a href="https://news.ycombinator.com/item?id=39982011">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                <!-- THIS COURSE INCLUDES (MOBILE ONLY) -->
                

                <!-- WHAT YOU'LL LEARN -->
                <div>
                        <h2>What you'll <span>learn</span></h2>
                        <div>
                            <p><img src="https://pikuma.com/images/courses/ps1/psx-controller.png" alt="PSX programming assembly" width="200">
                            </p>
                            <p>This course is a deep dive into the world of <strong>PlayStation</strong> programming! We'll explore the PS1 hardware, understand its sub-components, and learn how to code games using <strong>MIPS assembler</strong> &amp; the <strong>C programming language</strong>. We'll also learn how to use the official Sony <strong>Psy-Q</strong> libraries on a modern development toolchain to be more productive and push faster 3D polygons out of our console.</p>
                        </div>
                        <div>
                            <p><img src="https://pikuma.com/images/courses/ps1/mips-assembler.png" alt="MIPS assembly language" width="220">
                            </p>
                            <p>We are about to enter the 5th generation of 32-bit consoles. This era brings with it many technology milestones, such as the adoption of CPUs based on <strong>RISC architecture</strong> and a preference for coding using a <strong>high-level language</strong> instead of writing games using plain assembly. We will start by learning the basics of MIPS assembly and evolve to use a C compiler with the official Psy-Q library to develop our final project.</p>
                        </div>
                    </div>

                <!-- PROMO VIDEO -->
                <div>
                                <p>
                                    <iframe src="https://www.youtube.com/embed/mPlctVzV4OI" allowfullscreen=""></iframe>
                                </p>
                            </div>

                <!-- TOOLS WE'LL USE -->
                <div>
                        <h2>The <span>tools</span> you'll need</h2>
                        <div>
                            <p>The original development toolchain was designed for Windows/PC, so you can either use the original 32-bit library on a 32-bit operating system (<strong>Windowx XP</strong>), or you can use a modern C compiler with Visual Studio Code on a 64-bit operating system (<strong>Windows 11</strong>). Emulating a Windows system on <strong>macOS</strong> or <strong>Linux</strong> is also possible!</p>
                            <p><img src="https://pikuma.com/images/courses/ps1/os.png" alt="operating system" width="220">
                            </p>
                        </div>
                    </div>

                <!-- IS THIS COURSE FOR YOU -->
                <div>
                        <h2>Is this course for <span>you</span>?</h2>
                        <div>
                            <p><img src="https://pikuma.com/images/courses/ps1/wipeout-final-project-small.gif" alt="psx game development">
                            </p>
                            <div>
                                <p>This is a self-contained course teaching concepts from the ground up. However, it <strong>is expected</strong> from students a basic understanding of coding (if-else, loops, functions).</p>
                                <p>If you like retro programming &amp; want to learn more about the early days of 3D games, then this course is definitely for you!</p>
                            </div>
                        </div>
                    </div>

                <!-- ABOUT THE INSTRUCTOR -->
                <div>
                        <h2>About the <span>instructor</span></h2>
                        <div>
                            <p><img src="https://pikuma.com/images/courses/ps1/instructor.png" alt="gustavo pezzi" width="220">
                            </p>
                            <div>
                                <p><strong>Gustavo Pezzi</strong> is a university lecturer in London, UK. He has won multiple education awards as a teacher and is also the founder of <a href="https://pikuma.com/">pikuma.com</a>.</p>
                                <p>Gustavo teaches fundamentals of computer science and mathematics; his academic path includes institutions such as Pittsburg State University, City University of London, and University of Oxford.</p>
                            </div>
                        </div>
                    </div>

                <!-- MY TEACHING ACCREDITATIONS -->
                

                <!-- COURSE CONTENT -->
                <div>
                        <h2>Course <span>content</span></h2>
                        <div>
                            <p><span>25 hours total length <span>•</span> 32 Chapters <span>•</span> Last updated April 2024</span></p>
                        </div>
                    </div>

                <!-- WHY IS THIS COURSE DIFFERENT -->
                <div>
                        <h2>How is this course <span>different</span>?</h2>
                        <div>
                            <p>Learning how to create games for the original PlayStation is a great excuse to explore really hardcore <strong>computer science</strong> topics. As we learn different aspects of the 32-bit generation of consoles, we'll touch important concepts like algorithms, data structures, data compression, machine architecture, fixed-point math, computer graphics, and much (much!) more.</p>
                        </div>
                        <div>
                            <p><img src="https://pikuma.com/images/courses/ps1/ps1-controller.png" alt="ps1 programming tutorial" width="200">
                            </p>
                        </div>
                        <div>
                            <p>Many new games try to imitate the style and the visuals of old PS1 era using a modern game engine. This is <strong>no imitation</strong>! We'll be flipping bits on the <strong>OG</strong> PlayStation.</p>
                        </div>
                        <div>
                            <p>Many people are surprised that the first part of the course uses <strong>MIPS assembly</strong>. Using an assembler in the early stages of our course allows us to really understand the low-level aspects of the console &amp; really grok how data flow inside the machine.</p>
                        </div>
                        <div>
                            <p><img src="https://pikuma.com/images/courses/ps1/cube.gif" alt="psx programming tutorial" width="200">
                            </p>
                        </div>
                        <div>
                            <p>We'll then move away from assembly and climb one layer of abstraction up. We'll work with a <strong>C compiler</strong> paired with the official Sony Psy-Q library. This is where we'll really glue all the concepts that we learned before to consolidate our knowledge with a final big project.</p>
                        </div>
                        <div>
                            <p><img src="https://pikuma.com/images/courses/ps1/wipeout-ship.gif" alt="psxdev tutorial" width="300">
                            </p>
                        </div>
                        <div>
                            <p>At the end of the course, you'll have all the tools and the skills you need to grow and evolve on your own. You'll have a working project running on the PlayStation console and a deep understanding of the theory that underpins the development of PS1 games.</p>
                        </div>
                    </div>

                <!-- LAUREL AND DISCOUNT MESSAGE -->
                <div>
                        <p><span>73%</span> of our students <strong>come back</strong> for another course</p>
                        <p>
                                <img src="https://pikuma.com/images/about/no-discount.png">
                                We <strong>don't</strong> offer discounts on our courses. Ever.</p>
                    </div>

                <!-- TESTIMONIALS -->
                <div>
                        <h2><strong>What students are <span>saying</span></strong></h2>
                        <div>
                                            <table>
                                                <tbody><tr>
                                                    <td>5 star</td>
                                                    <td></td>
                                                    <td>0.0%</td>
                                                </tr>
                                                <tr>
                                                    <td>4 star</td>
                                                    <td></td>
                                                    <td>0.0%</td>
                                                </tr>
                                                <tr>
                                                    <td>3 star</td>
                                                    <td></td>
                                                    <td>0.0%</td>
                                                </tr>
                                                <tr>
                                                    <td>2 star</td>
                                                    <td></td>
                                                    <td>0.0%</td>
                                                </tr>
                                                <tr>
                                                    <td>1 star</td>
                                                    <td></td>
                                                    <td>0.0%</td>
                                                </tr>
                                            </tbody></table>
                                        </div>
                        
                        
                        
                    </div>

                <!-- SIMILAR COURSES -->
                <div>
                        <h2>Other <span>similar</span> courses</h2>
                        
                    </div>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zed Decoded: Async Rust (164 pts)]]></title>
            <link>https://zed.dev/blog/zed-decoded-async-rust</link>
            <guid>39981945</guid>
            <pubDate>Tue, 09 Apr 2024 17:38:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zed.dev/blog/zed-decoded-async-rust">https://zed.dev/blog/zed-decoded-async-rust</a>, See on <a href="https://news.ycombinator.com/item?id=39981945">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p><h2><span data-br=":R3brrrqbf9la:" data-brr="1">Zed Decoded: Async Rust</span></h2></p><header></header><p>Welcome to the first article in a new series called <strong>Zed Decoded</strong>. In Zed Decoded I'm going to take a close look at Zed — how it's built, which data structures it uses, which technologies and techniques, what features it has, which bugs we ran into. The best part? I won't do this alone, but get to interview and ask my colleagues here at Zed about everything I want to know.</p>
<div><div><p><b>Companion Video</b>: <!-- -->Async Rust</p><p>This post comes with a 1hr companion video, in which Thorsten and Antonio explore how Zed uses async Rust —&nbsp;in Zed. It's a loose conversation that focuses on the code and dives a bit deeper into some topics that didn't fit into the post.</p><p>Watch the video here:<!-- --> <a href="https://youtu.be/gkU4NGSe21I">https://youtu.be/gkU4NGSe21I</a></p></div><p><img src="https://zed.dev/img/post/zed-decoded-async-rust/thumbnail.jpg" width="230" height="150"></p></div>
<p>The first topic that was on my list: async Rust and how it's used in Zed. Over the past few months I've become quite fascinated with async Rust — Zed's the first codebase I've worked in that uses it — so I decided to sit down and ask Antonio, one of Zed's co-founders, about how we use async Rust in Zed.</p>
<p>We won't get into the details of async Rust itself (familiarity with that is to be expected if you want to understand the nitty-gritty of the code we'll see), but instead focus on how Zed uses async Rust to build a high-performance, native application: what async code looks like on the application level, which runtime it uses, why it uses that runtime.</p>
<h2 id="writing-async-rust-with-gpui"><span data-br=":R4nbrrrqbf9la:" data-brr="1">Writing async Rust with GPUI</span></h2>
<p>Let's jump right into the deep end. Here is a snippet of code that's representative of async code in the Zed codebase:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>fn</span><span> show_cursor_names</span><span>(&amp;</span><span>mut</span><span> self</span><span>, </span><span>cx</span><span>: &amp;</span><span>mut</span><span> ViewContext</span><span>&lt;</span><span>Self</span><span>&gt;) {</span></span>
<span data-line=""><span>    self</span><span>.show_cursor_names = </span><span>true</span><span>;</span></span>
<span data-line=""><span>    cx</span><span>.</span><span>notify</span><span>();</span></span>
<span data-line=""><span>    cx</span><span>.</span><span>spawn</span><span>(|</span><span>this</span><span>, </span><span>mut</span><span> cx</span><span>| </span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>        cx</span><span>.</span><span>background_executor</span><span>().</span><span>timer</span><span>(CURSORS_VISIBLE_FOR).</span><span>await</span><span>;</span></span>
<span data-line=""><span>        this</span><span>.</span><span>update</span><span>(&amp;</span><span>mut</span><span> cx</span><span>, |</span><span>this</span><span>, </span><span>cx</span><span>| {</span></span>
<span data-line=""><span>            this</span><span>.show_cursor_names = </span><span>false</span><span>;</span></span>
<span data-line=""><span>            cx</span><span>.</span><span>notify</span><span>()</span></span>
<span data-line=""><span>        })</span></span>
<span data-line=""><span>        .</span><span>ok</span><span>()</span></span>
<span data-line=""><span>    })</span></span>
<span data-line=""><span>    .</span><span>detach</span><span>();</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>It's <a href="https://github.com/zed-industries/zed/blob/98ddefc8884d0957ab766b3aea09265c8423684e/crates/editor/src/editor.rs#L3935-L3947">a function from our <code>Editor</code></a>. When it's called, Zed shows the names of the owners of each cursor: your name or the names of the people you're collaborating with. It's called, for example, when the editor is re-focused, so you can quickly see who's doing what and where.</p>
<p>What <code>show_cursor_names</code> does is the following:</p>
<ul>
<li>Toggle on <code>Editor.show_cursor_names</code> and trigger a re-render of the editor. When <code>Editor.show_cursor_names</code> is true, cursor names will be rendered.</li>
<li>Spawn a task that sleeps for <code>CURSOR_VISIBLE_FOR</code>, turn the cursors off, and trigger another re-render.</li>
</ul>
<p>If you've ever written async Rust before, you can spot some familiar elements in the code: there's a <code>.spawn</code>, there's an <code>async move</code>, there's an <code>await</code>. And if you've ever used the <code>async_task</code> crate before, this might remind you of code <a href="https://docs.rs/async-task/4.7.0/async_task/struct.Task.html#method.detach">like this</a>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>let</span><span> ex</span><span> = </span><span>Executor</span><span>::</span><span>new</span><span>();</span></span>
<span data-line=""><span>ex</span><span>.</span><span>spawn</span><span>(</span><span>async</span><span> {</span></span>
<span data-line=""><span>    loop</span><span> {</span></span>
<span data-line=""><span>        Timer</span><span>::</span><span>after</span><span>(</span><span>Duration</span><span>::</span><span>from_secs</span><span>(</span><span>1</span><span>)).</span><span>await</span><span>;</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>})</span></span>
<span data-line=""><span>.</span><span>detach</span><span>();</span></span></code></pre></div></figure>
<p>That's because Zed uses <code>async_task</code> for its <code>Task</code> type. But in this example there's an <code>Executor</code> — where is that in the Zed code? And what does <code>cx.background_executor()</code> do? Good questions, let's find answers.</p>
<h2 id="macos-as-our-async-runtime"><span data-br=":Rdnbrrrqbf9la:" data-brr="1">macOS as our async runtime</span></h2>
<p>One remarkable thing about async Rust is that it allows you to choose your own runtime. That's different from a lot of other languages (such as JavaScript) in which you can also write asynchronous code. Runtime isn't a term with very sharp definition, but for our purposes here, we can say that a runtime is the thing that runs your asynchronous code and provides you with utilities such as <code>.spawn</code> and something like an <code>Executor</code>.</p>
<p>The most popular of these runtimes is probably <a href="https://github.com/tokio-rs/tokio">tokio</a>. But there's also <a href="https://github.com/smol-rs/smol">smol</a>, <a href="https://github.com/embassy-rs/embassy">embassy</a> and others. Choosing and switching runtimes comes with tradeoffs, they <a href="https://corrode.dev/blog/async/">are only interchangable to a degree</a>, but it is possible.</p>
<p>In Zed for macOS, as it turns out, we don't use any one of these. We also don't use <code>async_task</code>'s <code>Executor</code>. But there has to be something to execute the asynchronous code, right? Otherwise I wouldn't be typing these lines in Zed.</p>
<p>So what then does <code>cx.spawn</code> do and what is the <code>cx.background_executor()</code>? Let's take a look. Here are <a href="https://github.com/zed-industries/zed/blob/dc98b3cfa19d6bd4eae813ce7dfaf9d9e13c232c/crates/gpui/src/app.rs#L818-L836">three relevant methods from GPUI's <code>AppContext</code></a>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/app.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>impl</span><span> AppContext</span><span> {</span></span>
<span data-line=""><span>    pub</span><span> fn</span><span> background_executor</span><span>(&amp;</span><span>self</span><span>) -&gt; &amp;</span><span>BackgroundExecutor</span><span> {</span></span>
<span data-line=""><span>        &amp;</span><span>self</span><span>.background_executor</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    pub</span><span> fn</span><span> foreground_executor</span><span>(&amp;</span><span>self</span><span>) -&gt; &amp;</span><span>ForegroundExecutor</span><span> {</span></span>
<span data-line=""><span>        &amp;</span><span>self</span><span>.foreground_executor</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    /// Spawns the future returned by the given function on the thread pool. The closure will be invoked</span></span>
<span data-line=""><span>    /// with [AsyncAppContext], which allows the application state to be accessed across await points.</span></span>
<span data-line=""><span>    pub</span><span> fn</span><span> spawn</span><span>&lt;</span><span>Fut</span><span>, </span><span>R</span><span>&gt;(&amp;</span><span>self</span><span>, </span><span>f</span><span>: </span><span>impl</span><span> FnOnce</span><span>(</span><span>AsyncAppContext</span><span>) -&gt; </span><span>Fut</span><span>) -&gt; </span><span>Task</span><span>&lt;</span><span>R</span><span>&gt;</span></span>
<span data-line=""><span>    where</span></span>
<span data-line=""><span>        Fut</span><span>: </span><span>Future</span><span>&lt;</span><span>Output</span><span> = </span><span>R</span><span>&gt; + '</span><span>static</span><span>,</span></span>
<span data-line=""><span>        R</span><span>: '</span><span>static</span><span>,</span></span>
<span data-line=""><span>    {</span></span>
<span data-line=""><span>        self</span><span>.foreground_executor.</span><span>spawn</span><span>(</span><span>f</span><span>(</span><span>self</span><span>.</span><span>to_async</span><span>()))</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    // [...]</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>Alright, two executors, <code>foreground_executor</code> and <code>background_executor</code>, and both have <code>.spawn</code> methods. We already saw <code>background_executor</code>'s <code>.spawn</code> above in <code>show_cursor_names</code> and here, in <code>AppContext.spawn</code>, we see the <code>foreground_executor</code> counterpart.</p>
<p>One level deeper, we can see what <code>foreground_executor.spawn</code> does:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/executor.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>impl</span><span> ForegroundExecutor</span><span> {</span></span>
<span data-line=""><span>    /// Enqueues the given Task to run on the main thread at some point in the future.</span></span>
<span data-line=""><span>    pub</span><span> fn</span><span> spawn</span><span>&lt;</span><span>R</span><span>&gt;(&amp;</span><span>self</span><span>, </span><span>future</span><span>: </span><span>impl</span><span> Future</span><span>&lt;</span><span>Output</span><span> = </span><span>R</span><span>&gt; + '</span><span>static</span><span>) -&gt; </span><span>Task</span><span>&lt;</span><span>R</span><span>&gt;</span></span>
<span data-line=""><span>    where</span></span>
<span data-line=""><span>        R</span><span>: '</span><span>static</span><span>,</span></span>
<span data-line=""><span>    {</span></span>
<span data-line=""><span>        let</span><span> dispatcher</span><span> = </span><span>self</span><span>.dispatcher.</span><span>clone</span><span>();</span></span>
<span data-line=""><span>        fn</span><span> inner</span><span>&lt;</span><span>R</span><span>: '</span><span>static</span><span>&gt;(</span></span>
<span data-line=""><span>            dispatcher</span><span>: </span><span>Arc</span><span>&lt;</span><span>dyn</span><span> PlatformDispatcher</span><span>&gt;,</span></span>
<span data-line=""><span>            future</span><span>: </span><span>AnyLocalFuture</span><span>&lt;</span><span>R</span><span>&gt;,</span></span>
<span data-line=""><span>        ) -&gt; </span><span>Task</span><span>&lt;</span><span>R</span><span>&gt; {</span></span>
<span data-line=""><span>            let</span><span> (</span><span>runnable</span><span>, </span><span>task</span><span>) = </span><span>async_task</span><span>::</span><span>spawn_local</span><span>(</span><span>future</span><span>, </span><span>move</span><span> |</span><span>runnable</span><span>| {</span></span>
<span data-line=""><span>                dispatcher</span><span>.</span><span>dispatch_on_main_thread</span><span>(</span><span>runnable</span><span>)</span></span>
<span data-line=""><span>            });</span></span>
<span data-line=""><span>            runnable</span><span>.</span><span>schedule</span><span>();</span></span>
<span data-line=""><span>            Task</span><span>::</span><span>Spawned</span><span>(</span><span>task</span><span>)</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""><span>        inner</span><span>::&lt;</span><span>R</span><span>&gt;(</span><span>dispatcher</span><span>, </span><span>Box</span><span>::</span><span>pin</span><span>(</span><span>future</span><span>))</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    // [...]</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>There's a lot going on here, a lot of syntax, but what happens can be boiled down to this: the <code>.spawn</code> method takes in a <code>future</code>, turns it into a <a href="https://docs.rs/async-task/latest/async_task/struct.Runnable.html"><code>Runnable</code></a> and a <code>Task</code>, and asks the <code>dispatcher</code> to run it on the main thread.</p>
<p>The <code>dispatcher</code> here is a <code>PlatformDispatcher</code>. That's the GPUI equivalent of <code>async_task</code>'s <code>Executor</code> from above. It has <code>Platform</code> in its name because it has different implementations for macOS, Linux, and Windows. But in this post, we're only going to look at macOS, since that's our best-supported platform at the moment and Linux/Windows implementations are still work-in-progress.</p>
<p>So what does <code>dispatch_on_main_thread</code> do? Does <em>this</em> now call an async runtime? No, no runtime <a href="https://github.com/zed-industries/zed/blob/dc98b3cfa19d6bd4eae813ce7dfaf9d9e13c232c/crates/gpui/src/platform/mac/dispatcher.rs#L66-L75">there either</a>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/platform/mac/dispatcher.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>impl</span><span> PlatformDispatcher</span><span> for</span><span> MacDispatcher</span><span> {</span></span>
<span data-line=""><span>    fn</span><span> dispatch_on_main_thread</span><span>(&amp;</span><span>self</span><span>, </span><span>runnable</span><span>: </span><span>Runnable</span><span>) {</span></span>
<span data-line=""><span>        unsafe</span><span> {</span></span>
<span data-line=""><span>            dispatch_async_f</span><span>(</span></span>
<span data-line=""><span>                dispatch_get_main_queue</span><span>(),</span></span>
<span data-line=""><span>                runnable</span><span>.</span><span>into_raw</span><span>().</span><span>as_ptr</span><span>() </span><span>as</span><span> *</span><span>mut</span><span> c_void</span><span>,</span></span>
<span data-line=""><span>                Some</span><span>(</span><span>trampoline</span><span>),</span></span>
<span data-line=""><span>            );</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>    // [...]</span></span>
<span data-line=""><span>}</span></span>
<span data-line=""> </span>
<span data-line=""><span>extern</span><span> "C"</span><span> fn</span><span> trampoline</span><span>(</span><span>runnable</span><span>: *</span><span>mut</span><span> c_void</span><span>) {</span></span>
<span data-line=""><span>    let</span><span> task</span><span> = </span><span>unsafe</span><span> { </span><span>Runnable</span><span>::&lt;()&gt;::</span><span>from_raw</span><span>(</span><span>NonNull</span><span>::</span><span>new_unchecked</span><span>(</span><span>runnable</span><span> as</span><span> *</span><span>mut</span><span> ())) };</span></span>
<span data-line=""><span>    task</span><span>.</span><span>run</span><span>();</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p><code>dispatch_async_f</code> is where the call leaves the Zed codebase, because <code>dispatch_async_f</code> is actually a compile-time generated binding to the <a href="https://developer.apple.com/documentation/dispatch/1452834-dispatch_async_f"><code>dispatch_async_f</code></a> function in <a href="https://developer.apple.com/documentation/DISPATCH">macOS' Grand Central Dispatch's (GCD)</a>. <code>dispatch_get_main_queue()</code>, too, is such a binding.</p>
<p>That's right: Zed, as a macOS application, uses macOS' GCD to schedule and execute work.</p>
<p>What happens in the snippet above is that Zed turns the <code>Runnable</code> — think of it as a handle to a <code>Task</code> — into a raw pointer and passes it to <code>dispatch_async_f</code> along with a <code>trampoline</code>, which puts it on its <code>main_queue</code>.</p>
<p>When GCD then decides it's time to run the next item on the <code>main_queue</code>, it pops it off the queue, and calls <code>trampoline</code>, which takes the raw pointer, turns it back into a <code>Runnable</code> and, to poll the <code>Future</code> behind its <code>Task</code>, calls <code>.run()</code> on it.</p>
<p>And, as I learned to my big surprise: that's it. That's essentially all the code necessary to use GCD as a "runtime" for async Rust. Where other applications use tokio or smol, Zed uses thin wrappers around GCD and crates such as <code>async_task</code>.</p>
<p>Wait, but what about the <code>BackgroundExecutor</code>? It's very, very similar to the <code>ForegroundExecutor</code>, with the main difference being that the <code>BackgroundExecutor</code> calls this method on <code>PlatformDispatcher</code>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>impl</span><span> PlatformDispatcher</span><span> for</span><span> MacDispatcher</span><span> {</span></span>
<span data-line=""><span>    fn</span><span> dispatch</span><span>(&amp;</span><span>self</span><span>, </span><span>runnable</span><span>: </span><span>Runnable</span><span>, </span><span>_</span><span>: </span><span>Option</span><span>&lt;</span><span>TaskLabel</span><span>&gt;) {</span></span>
<span data-line=""><span>        unsafe</span><span> {</span></span>
<span data-line=""><span>            dispatch_async_f</span><span>(</span></span>
<span data-line=""><span>                dispatch_get_global_queue</span><span>(DISPATCH_QUEUE_PRIORITY_HIGH.</span><span>try_into</span><span>().</span><span>unwrap</span><span>(), </span><span>0</span><span>),</span></span>
<span data-line=""><span>                runnable</span><span>.</span><span>into_raw</span><span>().</span><span>as_ptr</span><span>() </span><span>as</span><span> *</span><span>mut</span><span> c_void</span><span>,</span></span>
<span data-line=""><span>                Some</span><span>(</span><span>trampoline</span><span>),</span></span>
<span data-line=""><span>            );</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>The only difference between this <code>dispatch</code> method and <code>dispatch_async_f</code> from above is the queue. The <code>BackgroundExecutor</code> doesn't use the <code>main_queue</code>, but <a href="https://developer.apple.com/documentation/dispatch/1452927-dispatch_get_global_queue?language=objc">a global queue</a>.</p>
<p>Like I did when I first read through this code, you now might wonder: why?</p>
<p>Why use GCD? Why have a <code>ForegroundExecutor</code> and a <code>BackgroundExecutor</code>? What's so special about the <code>main_queue</code>?</p>
<h2 id="never-block-the-main-thread"><span data-br=":R14nbrrrqbf9la:" data-brr="1">Never block the main thread</span></h2>
<p>In a native UI application, the main thread is important. No, the main thread is <em>holy</em>. The main thread is where the rendering happens, where user input is handled, where the operating system communicates with the application. The main thread should never, ever block. On the main thread, the responsiveness of your app lives or dies.</p>
<p>That's true for <a href="https://en.wikipedia.org/wiki/Cocoa_(API)">Cocoa</a> applications on macOS too. Rendering, receiving user input, communication with macOS, and other platform concerns have to happen on the main thread. And since Zed wants perfect cooperation with macOS to ensure high-performance and responsiveness, it does two things.</p>
<p>First, it uses GCD to schedule its work — on and off the main thread — so that macOS can maintain high responsiveness and overall system efficiency.</p>
<p>Second, the importance of the main thread is baked into GPUI, the UI framework, by explicitly making the distinction between the <code>ForegroundExecutor</code> and the <code>BackgroundExecutor</code>, both of which we saw above.</p>
<p>As a writer of application-level Zed code, you should always be mindful of what happens on the main thread and never put too much blocking work on it. If you were to put, say, a blocking <code>sleep(10ms)</code> on the main thread, rendering the UI now has to wait for that <code>sleep()</code> to finish, which means that rendering the next frame would take longer than 8ms — the maximum frame time available if you want to achieve <a href="https://zed.dev/blog/120fps">120 FPS</a>. You'd "drop a frame", as they say.</p>
<p>Knowing that, let's take a look at another small snippet of code. This time it's from the built-in terminal in Zed, a function that <a href="https://github.com/zed-industries/zed/blob/dc98b3cfa19d6bd4eae813ce7dfaf9d9e13c232c/crates/terminal/src/terminal.rs#L1346-L1358">searches through the contents of the terminal buffer</a>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/terminal/src/terminal.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>pub</span><span> struct</span><span> Terminal</span><span> {</span></span>
<span data-line=""><span>    term</span><span>: </span><span>Arc</span><span>&lt;</span><span>Mutex</span><span>&lt;</span><span>alacritty_terminal</span><span>::</span><span>Term</span><span>&lt;</span><span>ZedListener</span><span>&gt;&gt;&gt;,</span></span>
<span data-line=""> </span>
<span data-line=""><span>    // [... other fields ...]</span></span>
<span data-line=""><span>}</span></span>
<span data-line=""> </span>
<span data-line=""><span>pub</span><span> fn</span><span> find_matches</span><span>(</span></span>
<span data-line=""><span>    &amp;</span><span>mut</span><span> self</span><span>,</span></span>
<span data-line=""><span>    mut</span><span> searcher</span><span>: </span><span>RegexSearch</span><span>,</span></span>
<span data-line=""><span>    cx</span><span>: &amp;</span><span>mut</span><span> ModelContext</span><span>&lt;</span><span>Self</span><span>&gt;,</span></span>
<span data-line=""><span>) -&gt; </span><span>Task</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>RangeInclusive</span><span>&lt;</span><span>AlacPoint</span><span>&gt;&gt;&gt; {</span></span>
<span data-line=""><span>    let</span><span> term</span><span> = </span><span>self</span><span>.term.</span><span>clone</span><span>();</span></span>
<span data-line=""><span>    cx</span><span>.</span><span>background_executor</span><span>().</span><span>spawn</span><span>(</span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>        let</span><span> term</span><span> = </span><span>term</span><span>.</span><span>lock</span><span>();</span></span>
<span data-line=""> </span>
<span data-line=""><span>        all_search_matches</span><span>(&amp;</span><span>term</span><span>, &amp;</span><span>mut</span><span> searcher</span><span>).</span><span>collect</span><span>()</span></span>
<span data-line=""><span>    })</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>The first line in <code>find_matches</code>, the <code>self.term.clone()</code>, happens on the main thread and is quick: <code>self.term</code> is an <code>Arc&lt;Mutex&lt;...&gt;&gt;</code>, so cloning only bumps the reference count on the <code>Arc</code>. The call to <code>.lock()</code> then only happens in the background, since <code>.lock()</code> might block. It's unlikely that there will be contention for this lock in this particular code path, but if there was contention, it wouldn't freeze the UI, only a single background thread. That's the pattern: if it's quick, you can do it on the main thread, but if it might take a while or even block, put it on a background thread by using <code>cx.background_executor()</code>.</p>
<p>Here's another example, the project-wide search in Zed (<code>⌘-shift-f</code>). It pushes as much heavy work as possible onto background threads to ensure Zed stays responsive while searching through tens of thousands of files in your project. Here's a simplified and heavily-commented <a href="https://github.com/zed-industries/zed/blob/dc98b3cfa19d6bd4eae813ce7dfaf9d9e13c232c/crates/project/src/project.rs#L6485-L6498">excerpt from <code>Project.search_local</code></a> that shows the main part of the search:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/project/src/project.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>// Spawn a Task on the background executor. The Task finds all files on disk</span></span>
<span data-line=""><span>// that contain &gt;1 matches for the given `query` and sends them back over</span></span>
<span data-line=""><span>// the `matching_paths_tx` channel.</span></span>
<span data-line=""><span>let</span><span> (</span><span>matching_paths_tx</span><span>, </span><span>matching_paths_rx</span><span>) = </span><span>smol</span><span>::</span><span>channel</span><span>::</span><span>bounded</span><span>(</span><span>1024</span><span>);</span></span>
<span data-line=""><span>cx</span><span>.</span><span>background_executor</span><span>()</span></span>
<span data-line=""><span>    .</span><span>spawn</span><span>(</span><span>Self</span><span>::</span><span>background_search</span><span>(</span></span>
<span data-line=""><span>        // [... other arguments ... ]</span></span>
<span data-line=""><span>        query</span><span>.</span><span>clone</span><span>(),</span></span>
<span data-line=""><span>        matching_paths_tx</span><span>,</span></span>
<span data-line=""><span>    ))</span></span>
<span data-line=""><span>    .</span><span>detach</span><span>();</span></span>
<span data-line=""> </span>
<span data-line=""><span>// Setup a channel on which we stream results to the UI.</span></span>
<span data-line=""><span>let</span><span> (</span><span>result_tx</span><span>, </span><span>result_rx</span><span>) = </span><span>smol</span><span>::</span><span>channel</span><span>::</span><span>bounded</span><span>(</span><span>1024</span><span>);</span></span>
<span data-line=""> </span>
<span data-line=""><span>// On the main thread, spawn a Task that first...</span></span>
<span data-line=""><span>cx</span><span>.</span><span>spawn</span><span>(|</span><span>this</span><span>, </span><span>mut</span><span> cx</span><span>| </span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>    // ... waits for the background thread to return the filepaths of</span></span>
<span data-line=""><span>    // the maximum number of files that we want to search...</span></span>
<span data-line=""><span>    let</span><span> mut</span><span> matching_paths</span><span> = </span><span>matching_paths_rx</span></span>
<span data-line=""><span>        .</span><span>take</span><span>(MAX_SEARCH_RESULT_FILES + </span><span>1</span><span>)</span></span>
<span data-line=""><span>        .</span><span>collect</span><span>::&lt;</span><span>Vec</span><span>&lt;</span><span>_</span><span>&gt;&gt;()</span></span>
<span data-line=""><span>        .</span><span>await</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>    // ... then loops over the filepaths in chunks of 64...</span></span>
<span data-line=""><span>    for</span><span> matching_paths_chunk</span><span> in</span><span> matching_paths</span><span>.</span><span>chunks</span><span>(</span><span>64</span><span>) {</span></span>
<span data-line=""><span>        let</span><span> mut</span><span> chunk_results</span><span> = </span><span>Vec</span><span>::</span><span>new</span><span>();</span></span>
<span data-line=""> </span>
<span data-line=""><span>        for</span><span> matching_path</span><span> in</span><span> matching_paths_chunk</span><span> {</span></span>
<span data-line=""><span>            // .... opens each file....</span></span>
<span data-line=""><span>            let</span><span> buffer</span><span> = </span><span>this</span><span>.</span><span>update</span><span>(&amp;</span><span>mut</span><span> cx</span><span>, |</span><span>this</span><span>, </span><span>cx</span><span>| {</span></span>
<span data-line=""><span>                this</span><span>.</span><span>open_buffer</span><span>((*</span><span>worktree_id</span><span>, </span><span>path</span><span>.</span><span>clone</span><span>()), </span><span>cx</span><span>)</span></span>
<span data-line=""><span>            })?;</span></span>
<span data-line=""> </span>
<span data-line=""><span>            // ... and pushes into `chunk_results` a Task that</span></span>
<span data-line=""><span>            // runs on the main thread and ...</span></span>
<span data-line=""><span>            chunk_results</span><span>.</span><span>push</span><span>(</span><span>cx</span><span>.</span><span>spawn</span><span>(|</span><span>cx</span><span>| </span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>                // ... waits for the file to be opened ...</span></span>
<span data-line=""><span>                let</span><span> buffer</span><span> = </span><span>buffer</span><span>.</span><span>await</span><span>?;</span></span>
<span data-line=""><span>                // ... creates a snapshot of its contents ...</span></span>
<span data-line=""><span>                let</span><span> snapshot</span><span> = </span><span>buffer</span><span>.</span><span>read_with</span><span>(&amp;</span><span>cx</span><span>, |</span><span>buffer</span><span>, </span><span>_</span><span>| </span><span>buffer</span><span>.</span><span>snapshot</span><span>())?;</span></span>
<span data-line=""><span>                // ... and again starts a Task on the background executor,</span></span>
<span data-line=""><span>                // which searches through the snapshot for all results.</span></span>
<span data-line=""><span>                let</span><span> ranges</span><span> = </span><span>cx</span></span>
<span data-line=""><span>                    .</span><span>background_executor</span><span>()</span></span>
<span data-line=""><span>                    .</span><span>spawn</span><span>(</span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>                        query</span></span>
<span data-line=""><span>                            .</span><span>search</span><span>(&amp;</span><span>snapshot</span><span>, </span><span>None</span><span>)</span></span>
<span data-line=""><span>                            .</span><span>await</span></span>
<span data-line=""><span>                            .</span><span>iter</span><span>()</span></span>
<span data-line=""><span>                            .</span><span>collect</span><span>::&lt;</span><span>Vec</span><span>&lt;</span><span>_</span><span>&gt;&gt;()</span></span>
<span data-line=""><span>                    })</span></span>
<span data-line=""><span>                    .</span><span>await</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>                Ok</span><span>((</span><span>buffer</span><span>, </span><span>ranges</span><span>))</span></span>
<span data-line=""><span>            }));</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""> </span>
<span data-line=""><span>        // On the main thread, non-blocking, wait for all buffers to be searched...</span></span>
<span data-line=""><span>        let</span><span> chunk_results</span><span> = </span><span>futures</span><span>::</span><span>future</span><span>::</span><span>join_all</span><span>(</span><span>chunk_results</span><span>).</span><span>await</span><span>;</span></span>
<span data-line=""><span>        for</span><span> result</span><span> in</span><span> chunk_results</span><span> {</span></span>
<span data-line=""><span>            if</span><span> let</span><span> Some</span><span>((</span><span>buffer</span><span>, </span><span>ranges</span><span>)) = </span><span>result</span><span>.</span><span>log_err</span><span>() {</span></span>
<span data-line=""><span>                // send the results over the results channel</span></span>
<span data-line=""><span>                result_tx</span></span>
<span data-line=""><span>                    .</span><span>send</span><span>(</span><span>SearchResult</span><span>::</span><span>Buffer</span><span> { </span><span>buffer</span><span>, </span><span>ranges</span><span> })</span></span>
<span data-line=""><span>                    .</span><span>await</span><span>?;</span></span>
<span data-line=""><span>            }</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>})</span></span>
<span data-line=""><span>.</span><span>detach</span><span>();</span></span>
<span data-line=""> </span>
<span data-line=""><span>result_rx</span></span></code></pre></div></figure>
<p>It's a lot of code — sorry! — but there's not a lot more going on than the concepts we already talked about. What's noteworthy here and why I wanted to show it is the ping-pong between the main thread and background threads:</p>
<ul>
<li><strong>main thread</strong>: kicks off the search and hands the <code>query</code> over to background thread</li>
<li><strong>background thread</strong>: finds files in project with &gt;1 occurrences of <code>query</code> in them, sends results back over channel as they come in</li>
<li><strong>main thread</strong>: waits until background thread has found <code>MAX+1</code> results, then drops channel, which causes background thread to exit</li>
<li><strong>main thread</strong>: spawns multiple other main-thread tasks to open each file &amp; create a snapshot.</li>
<li><strong>background threads</strong>: search through buffer snapshot to find all results in a buffer, sends results back over channel</li>
<li><strong>main thread</strong>: waits for background thread to find results in all buffers, then sends them back to the caller of the outer <code>search_local</code> method</li>
</ul>
<p>Even though this method can be optimized and the search made a lot faster (we haven't gotten around to that yet), it can already search thousands of files without blocking the main thread, while still using multiple CPU cores.</p>
<h2 id="async-friendly-data-structures-testing-executors-and-more"><span data-br=":R1inbrrrqbf9la:" data-brr="1">Async-Friendly Data Structures, Testing Executors, and More</span></h2>
<p>I'm pretty sure that the previous code excerpt raised a lot of questions that I haven't answered yet: how exactly is it possible to send a buffer snapshot to a background thread? How efficient is it do that? What if I want to modify such a snapshot on another thread? How do you test all this?</p>
<p>And I'm sorry to say that I couldn't fit all of the answers into this post. But there is a <a href="https://youtu.be/gkU4NGSe21I">companion video</a> in which Antonio and I did dive into a lot of these areas and talked about async-friendly data structures, copy-on-write buffer snapshots, and other things. Antonio also gave <a href="https://www.youtube.com/watch?v=ms8zKpS_dZE">a fantastic talk about how we do property-testing of async Rust code</a> in the Zed code base that I highly recommend. I also promise that in the future there will be a post about the data structures underlying the Zed editor.</p>
<p>Until next time!</p><hr></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ScreenAI: A visual LLM for UI and visually-situated language understanding (135 pts)]]></title>
            <link>https://research.google/blog/screenai-a-visual-language-model-for-ui-and-visually-situated-language-understanding/</link>
            <guid>39981623</guid>
            <pubDate>Tue, 09 Apr 2024 17:15:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.google/blog/screenai-a-visual-language-model-for-ui-and-visually-situated-language-understanding/">https://research.google/blog/screenai-a-visual-language-model-for-ui-and-visually-situated-language-understanding/</a>, See on <a href="https://news.ycombinator.com/item?id=39981623">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                    <section>
                        
                        



<p>We introduce ScreenAI, a vision-language model for user interfaces and infographics that achieves state-of-the-art results on UI and infographics-based tasks. We are also releasing three new datasets: Screen Annotation to evaluate the layout understanding capability of the model, as well as ScreenQA Short and Complex ScreenQA for a more comprehensive evaluation of its QA capability.</p>
                        
                    </section>
                
                
                
                


<div>
        <p data-block-key="df7wk">Screen user interfaces (UIs) and infographics, such as charts, diagrams and tables, play important roles in human communication and human-machine interaction as they facilitate rich and interactive user experiences. UIs and infographics share similar design principles and visual language (e.g., icons and layouts), that offer an opportunity to build a single model that can understand, reason, and interact with these interfaces. However, because of their complexity and varied presentation formats, infographics and UIs present a unique modeling challenge.</p><p data-block-key="9f7at">To that end, we introduce “<a href="https://arxiv.org/abs/2402.04615" target="_blank" rel="noopener noreferrer">ScreenAI: A Vision-Language Model for UI and Infographics Understanding</a>”. ScreenAI improves upon the <a href="https://arxiv.org/abs/2305.18565" target="_blank" rel="noopener noreferrer">PaLI architecture</a> with the flexible patching strategy from <a href="https://arxiv.org/abs/2210.03347" target="_blank" rel="noopener noreferrer">pix2struct</a>. We train ScreenAI on a unique mixture of datasets and tasks, including a novel Screen Annotation task that requires the model to identify UI element information (i.e., type, location and description) on a screen. These text annotations provide large language models (LLMs) with screen descriptions, enabling them to automatically generate question-answering (QA), UI navigation, and summarization training datasets at scale. At only 5B parameters, ScreenAI achieves state-of-the-art results on UI- and infographic-based tasks (<a href="https://x-lance.github.io/WebSRC/" target="_blank" rel="noopener noreferrer">WebSRC</a> and <a href="https://github.com/aburns4/MoTIF" target="_blank" rel="noopener noreferrer">MoTIF</a>), and best-in-class performance on <a href="https://github.com/vis-nlp/ChartQA" target="_blank" rel="noopener noreferrer">Chart QA</a>, <a href="https://rrc.cvc.uab.es/?ch=17&amp;com=evaluation&amp;task=1" target="_blank" rel="noopener noreferrer">DocVQA</a>, and <a href="https://arxiv.org/abs/2104.12756" target="_blank" rel="noopener noreferrer">InfographicVQA</a> compared to models of similar size. We are also releasing three new datasets: <a href="https://github.com/google-research-datasets/screen_qa?tab=readme-ov-file#screen-annotation-dataset-details" target="_blank" rel="noopener noreferrer">Screen Annotation</a> to evaluate the layout understanding capability of the model, as well as <a href="https://github.com/google-research-datasets/screen_qa/tree/main?tab=readme-ov-file#short_answers-directory" target="_blank" rel="noopener noreferrer">ScreenQA Short</a> and <a href="https://github.com/google-research-datasets/screen_qa?tab=readme-ov-file#complexqa" target="_blank" rel="noopener noreferrer">Complex ScreenQA</a> for a more comprehensive evaluation of its QA capability.</p>
    </div>

                
                


<section>
    
    <p>
        <h2 data-block-key="df7wk">ScreenAI</h2>
    </p>


    
</section>

                
                


<div>
        <p data-block-key="df7wk">ScreenAI’s architecture is based on <a href="https://arxiv.org/abs/2209.06794" target="_blank" rel="noopener noreferrer">PaLI</a>, composed of a multimodal encoder block and an autoregressive decoder. The PaLI encoder uses a <a href="https://arxiv.org/abs/2010.11929" target="_blank" rel="noopener noreferrer">vision transformer</a> (ViT) that creates image embeddings and a multimodal encoder that takes the concatenation of the image and text embeddings as input. This flexible architecture allows ScreenAI to solve vision tasks that can be recast as text+image-to-text problems.</p><p data-block-key="fnskt">On top of the PaLI architecture, we employ a flexible patching strategy introduced in pix2struct. Instead of using a fixed-grid pattern, the grid dimensions are selected such that they preserve the native aspect ratio of the input image. This enables ScreenAI to work well across images of various aspect ratios.</p><p data-block-key="bnr6j">The ScreenAI model is trained in two stages: a pre-training stage followed by a fine-tuning stage. First, self-supervised learning is applied to automatically generate data labels, which are then used to train ViT and the language model. ViT is frozen during the fine-tuning stage, where most data used is manually labeled by human raters.</p>
    </div>

                
                
    

<!-- mode: &#x27;&#x27; -->


  
    <div>
      <video playsinline="" muted="true" loop="true" preload="auto">
        <source src="https://storage.googleapis.com/gweb-research2023-media/media/ScreenAI-model.mp4" type="video/mp4">
      </video>
      <div aria-label="Video Play/pause">
        <p><span>play silent looping video</span>
          <span>pause silent looping video</span>
        </p>
        
      </div>
      
      <p data-block-key="f4d4n">ScreenAI model architecture.</p>
      
    </div>
  



                
                


<section>
    
    <p>
        <h2 data-block-key="xjbkq">Data generation</h2>
    </p>


    
</section>

                
                


<section>
    
    <p data-block-key="xjbkq">To create a pre-training dataset for ScreenAI, we first compile an extensive collection of screenshots from various devices, including desktops, mobile, and tablets. This is achieved by using <a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener noreferrer">publicly accessible web pages</a> and following the programmatic exploration approach used for the <a href="https://dl.acm.org/doi/10.1145/3126594.3126651" target="_blank" rel="noopener noreferrer">RICO dataset</a> for mobile apps. We then apply a layout annotator, based on the <a href="https://arxiv.org/abs/2005.12872" target="_blank" rel="noopener noreferrer">DETR</a> model, that identifies and labels a wide range of UI elements (e.g., image, pictogram, button, text) and their spatial relationships. Pictograms undergo further analysis using an <a href="https://arxiv.org/abs/2210.02663" target="_blank" rel="noopener noreferrer">icon classifier</a> capable of distinguishing 77 different icon types. This detailed classification is essential for interpreting the subtle information conveyed through icons. For icons that are not covered by the classifier, and for infographics and images, we use the PaLI image captioning model to generate descriptive captions that provide contextual information. We also apply an <a href="https://cloud.google.com/use-cases/ocr" target="_blank" rel="noopener noreferrer">optical character recognition</a> (OCR) engine to extract and annotate textual content on screen. We combine the OCR text with the previous annotations to create a detailed description of each screen.</p>


    
</section>

                
                
    

<!-- mode: &#x27;&#x27; -->


  
    
    
    <picture>
      
      
      <source media="(min-width: 768px)" srcset="https://storage.googleapis.com/gweb-research2023-media/images/ScreenAI-2.width-800.png" alt="ScreenAI-2">
      
      <img src="https://storage.googleapis.com/gweb-research2023-media/images/ScreenAI-2.width-800.png" alt="ScreenAI-2" loading="lazy">
      
        <p data-block-key="f4d4n">A mobile app screenshot with generated annotations that include UI elements and their descriptions, e.g., TEXT elements also contain the text content from OCR, IMAGE elements contain image captions, LIST_ITEMs contain all their child elements.</p>
      
    </picture>
  



                
                


<section>
    
    <p>
        <h3 data-block-key="xjbkq">LLM-based data generation</h3>
    </p>


    
</section>

                
                


<section>
    
    <p data-block-key="xjbkq">We enhance the pre-training data's diversity using <a href="https://blog.google/technology/ai/google-palm-2-ai-large-language-model/" target="_blank" rel="noopener noreferrer">PaLM 2</a> to generate input-output pairs in a two-step process. First, screen annotations are generated using the technique outlined above, then we craft a prompt around this schema for the LLM to create synthetic data. This process requires prompt engineering and iterative refinement to find an effective prompt. We assess the generated data's quality through human validation against a quality threshold.</p>


    
</section>

                
                <div>
  <p><code data-block-key="5c1oc">You only speak JSON. Do not write text that isn’t JSON.<br>You are given the following mobile screenshot, described in words. Can you generate 5 questions regarding the content of the screenshot as well as the corresponding short answers to them? <p>The answer should be as short as possible, containing only the necessary information. Your answer should be structured as follows:<br>questions: [<br>{{question: the question,<br>    answer: the answer<br>}},<br> ...<br>]</p><p>{THE SCREEN SCHEMA}</p></code></p>
  <p data-block-key="v2dgk">A sample prompt for QA data generation.</p>
</div>
                
                


<div>
        <p data-block-key="xjbkq">By combining the natural language capabilities of LLMs with a structured schema, we simulate a wide range of user interactions and scenarios to generate synthetic, realistic tasks. In particular, we generate three categories of tasks:</p><ul><li data-block-key="dvi3e"><b>Question answering</b>: The model is asked to answer questions regarding the content of the screenshots, e.g., “When does the restaurant open?”</li><li data-block-key="7isdo"><b>Screen navigation</b>: The model is asked to convert a natural language utterance into an executable action on a screen, e.g., “Click the search button.”</li><li data-block-key="a56rn"><b>Screen summarization</b>: The model is asked to summarize the screen content in one or two sentences.</li></ul>
    </div>

                
                
    

<!-- mode: &#x27;&#x27; -->


  
    
    
    <picture>
      
      
      <source media="(min-width: 768px)" srcset="https://storage.googleapis.com/gweb-research2023-media/images/ScreenAI-3.width-800.png" alt="ScreenAI-3">
      
      <img src="https://storage.googleapis.com/gweb-research2023-media/images/ScreenAI-3.width-800.png" alt="ScreenAI-3" loading="lazy">
      
        <p data-block-key="f4d4n">Block diagram of our workflow for generating data for QA, summarization and navigation tasks using existing ScreenAI models and LLMs. Each task uses a custom prompt to emphasize desired aspects, like questions related to counting, involving reasoning, etc.</p>
      
    </picture>
  



                
                
    

<!-- mode: &#x27;&#x27; -->


  
    
    
    <picture>
      
      
      <source media="(min-width: 768px)" srcset="https://storage.googleapis.com/gweb-research2023-media/images/ScreenAI-1.width-800.png" alt="ScreenAI-1">
      
      <img src="https://storage.googleapis.com/gweb-research2023-media/images/ScreenAI-1.width-800.png" alt="ScreenAI-1" loading="lazy">
      
        <p data-block-key="f4d4n">LLM-generated data. Examples for screen QA, navigation and summarization. For navigation, the action bounding box is displayed in red on the screenshot.</p>
      
    </picture>
  



                
                


<section>
    
    <p>
        <h2 data-block-key="xjbkq">Experiments and results</h2>
    </p>


    
</section>

                
                


<div>
        <p data-block-key="xjbkq">As previously mentioned, ScreenAI is trained in two stages: pre-training and fine-tuning. Pre-training data labels are obtained using self-supervised learning and fine-tuning data labels comes from human raters.</p><p data-block-key="ao9ia">We fine-tune ScreenAI using public QA, summarization, and navigation datasets and a variety of tasks related to UIs. For QA, we use well established benchmarks in the multimodal and document understanding field, such as <a href="https://github.com/vis-nlp/ChartQA" target="_blank" rel="noopener noreferrer">ChartQA</a>, <a href="https://rrc.cvc.uab.es/?ch=17&amp;com=evaluation&amp;task=1" target="_blank" rel="noopener noreferrer">DocVQA</a>, <a href="https://rrc.cvc.uab.es/?ch=17&amp;com=tasks" target="_blank" rel="noopener noreferrer">Multi page DocVQA</a>, <a href="https://arxiv.org/abs/2104.12756" target="_blank" rel="noopener noreferrer">InfographicVQA</a>, <a href="https://ocr-vqa.github.io/" target="_blank" rel="noopener noreferrer">OCR VQA</a>, <a href="https://x-lance.github.io/WebSRC/" target="_blank" rel="noopener noreferrer">Web SRC</a> and <a href="https://github.com/google-research-datasets/screen_qa" target="_blank" rel="noopener noreferrer">ScreenQA</a>. For navigation, datasets used include <a href="https://github.com/google-research-datasets/uibert/tree/main" target="_blank" rel="noopener noreferrer">Referring Expressions</a>, <a href="https://github.com/aburns4/MoTIF" target="_blank" rel="noopener noreferrer">MoTIF</a>, <a href="https://arxiv.org/abs/2209.15099" target="_blank" rel="noopener noreferrer">Mug</a>, and <a href="https://github.com/google-research/google-research/tree/master/android_in_the_wild" target="_blank" rel="noopener noreferrer">Android in the Wild</a>. Finally, we use <a href="https://github.com/google-research-datasets/screen2words" target="_blank" rel="noopener noreferrer">Screen2Words</a> for screen summarization. Along with the fine-tuning datasets, we evaluate the fine-tuned ScreenAI model using three novel benchmarks:</p><ol><li data-block-key="3s465">Screen Annotation: Enables the evaluation model layout annotations and spatial understanding capabilities.</li><li data-block-key="d6g8q">ScreenQA Short: A variation of ScreenQA, where its ground truth answers have been shortened to contain only the relevant information that better aligns with other QA tasks.</li><li data-block-key="1oj5v">Complex ScreenQA: Complements ScreenQA Short with more difficult questions (counting, arithmetic, comparison, and non-answerable questions) and contains screens with various aspect ratios.</li></ol><p data-block-key="3m7r7">The fine-tuned ScreenAI model achieves state-of-the-art results on various UI and infographic-based tasks (<a href="https://x-lance.github.io/WebSRC/" target="_blank" rel="noopener noreferrer">WebSRC</a> and <a href="https://github.com/aburns4/MoTIF" target="_blank" rel="noopener noreferrer">MoTIF</a>) and best-in-class performance on <a href="https://github.com/vis-nlp/ChartQA" target="_blank" rel="noopener noreferrer">Chart QA</a>, <a href="https://rrc.cvc.uab.es/?ch=17&amp;com=evaluation&amp;task=1" target="_blank" rel="noopener noreferrer">DocVQA</a>, and <a href="https://arxiv.org/abs/2104.12756" target="_blank" rel="noopener noreferrer">InfographicVQA</a> compared to models of similar size. ScreenAI achieves competitive performance on Screen2Words and OCR-VQA. Additionally, we report results on the new benchmark datasets introduced to serve as a baseline for further research.</p>
    </div>

                
                
    

<!-- mode: &#x27;&#x27; -->


  
    
    
    <picture>
      
      
      <source media="(min-width: 768px)" srcset="https://storage.googleapis.com/gweb-research2023-media/images/ScreenAI-6.width-800.png" alt="ScreenAI-6">
      
      <img src="https://storage.googleapis.com/gweb-research2023-media/images/ScreenAI-6.width-800.png" alt="ScreenAI-6" loading="lazy">
      
        <p data-block-key="f4d4n">Comparing model performance of ScreenAI with state-of-the-art (SOTA) models of similar size.</p>
      
    </picture>
  



                
                


<section>
    
    <p data-block-key="xjbkq">Next, we examine ScreenAI’s scaling capabilities and observe that across all tasks, increasing the model size improves performances and the improvements have not saturated at the largest size.</p>


    
</section>

                
                
    

<!-- mode: &#x27;&#x27; -->


  
    
    
    <picture>
      
      
      <source media="(min-width: 768px)" srcset="https://storage.googleapis.com/gweb-research2023-media/images/ScreenAI-5.width-800.png" alt="ScreenAI-5">
      
      <img src="https://storage.googleapis.com/gweb-research2023-media/images/ScreenAI-5.width-800.png" alt="ScreenAI-5" loading="lazy">
      
        <p data-block-key="f4d4n">Model performance increases with size, and the performance has not saturated even at the largest size of 5B params.</p>
      
    </picture>
  



                
                


<section>
    
    <p>
        <h2 data-block-key="xjbkq">Conclusion</h2>
    </p>


    
</section>

                
                


<section>
    
    <p data-block-key="xjbkq">We introduce the ScreenAI model along with a unified representation that enables us to develop self-supervised learning tasks leveraging data from all these domains. We also illustrate the impact of data generation using LLMs and investigate improving model performance on specific aspects with modifying the training mixture. We apply all of these techniques to build multi-task trained models that perform competitively with state-of-the-art approaches on a number of public benchmarks. However, we also note that our approach still lags behind large models and further research is needed to bridge this gap.</p>


    
</section>

                
                


<section>
    
    <p>
        <h2 data-block-key="xjbkq">Acknowledgements</h2>
    </p>


    
</section>

                
                


<section>
    
    <p data-block-key="xjbkq"><i>This project is the result of joint work with Maria Wang, Fedir Zubach, Hassan Mansoor, Vincent Etter, Victor Carbune, Jason Lin, Jindong Chen and Abhanshu Sharma. We thank Fangyu Liu, Xi Chen, Efi Kokiopoulou, Jesse Berent, Gabriel Barcik, Lukas Zilka, Oriana Riva, Gang Li,Yang Li, Radu Soricut, and Tania Bedrax-Weiss for their insightful feedback and discussions, along with Rahul Aralikatte, Hao Cheng and Daniel Kim for their support in data preparation. We also thank Jay Yagnik, Blaise Aguera y Arcas, Ewa Dominowska, David Petrou, and Matt Sharifi for their leadership, vision and support. We are very grateful toTom Small for helping us create the animation in this post.</i></p>


    
</section>

                

                


<section aria-label="List of footnotes">
  <ol>
    
  </ol>
</section>

                


            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fairbuds: In-ear with replaceable batteries (262 pts)]]></title>
            <link>https://shop.fairphone.com/fairbuds</link>
            <guid>39981550</guid>
            <pubDate>Tue, 09 Apr 2024 17:09:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shop.fairphone.com/fairbuds">https://shop.fairphone.com/fairbuds</a>, See on <a href="https://news.ycombinator.com/item?id=39981550">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrap">
            
            <div data-snippet="s_fp_fairbuds_001" data-name="Fairbuds 001">
                    <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/content/circle_blue.svg" loading="eager">
                    <img src="https://shop.fairphone.com/theme_fairphone/static/src/img/content/square_blue_2.svg" loading="eager"></p><h4>FAIRBUDS</h4>
                    <h2>Premium Sound. Designed to last.</h2>
                    <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/330.webp" loading="lazy" data-bs-original-title="" title="" aria-describedby="tooltip343461">
                    </p>
                    <p>Meet the world's most repairable premium earbuds.</p>
                    <p><span data-fp-product-id="502">0.00</span>
                        <span>plus shipping costs from € 3.95</span>
                    </p>
                    <p><a href="https://shop.fairphone.com/shop/aufear-ww1-fairphone-true-wireless-earbuds-406#attr=119" data-bs-original-title="" title="" aria-describedby="popover696845">buy now</a>
                </p></div>
            <div id="section1" data-snippet="s_fp_fairbuds_002" data-name="Fairbuds 002">
                    <h2>Keep what you love for longer</h2>
                    <div>
                        <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/304.webp" loading="lazy">
                        <i data-fp-youtube-popup="fp_js_youtube_popup_16" data-fp-youtube-id="NkTYn8n_W64"></i></p>
                    </div>
                </div>
            <div data-snippet="s_fp_fairbuds_003" data-name="Fairbuds 003">
                        <p><i></i>
                            <span>Long-lasting with a three-year warranty</span>
                        </p>
                        <p><i></i>
                            <span>14-day trial period with 100% full refund</span>
                        </p>
                        <p><i></i>
                            <span>Replaceable batteries inside buds and charging case</span>
                        </p>
                    </div>
            <div>
                <h2>Iconic design. Available in two colors.</h2>
                
            </div>
            <div id="section2" data-snippet="s_fp_fairbuds_005" data-name="Fairbuds 005">
                    <h2>Premium sound</h2>
                    
                    <div>
                        <h4>FINE-TUNED FOR PERFECTION</h4>
                        <div>
                            <div>
                                    <h5>Active Noise Canceling</h5>
                                    <p>Immerse yourself in your music. Or stay connected to the world around you. It's up to you.</p>
                                </div>
                            <div>
                                    <h5>TITANIUM DRIVERS</h5>
                                    <p>The titanium-coated 11mm premium drivers deliver a one-of-a-kind listening experience, with rich, well-balanced sound profiles.
                                    </p>
                                </div>
                            <div>
                                    <h5>Seamless dual point connectivity</h5>
                                    <p>Stay connected to multiple devices simultaneously and switch between them hassle-free.</p>
                                </div>
                            <div>
                                    <h5>Dedicated app For iOS and Android
                                    </h5>
                                    <p>Pick your favorite presets, customize EQ settings just how you like it, and get all the latest software updates.</p>
                                </div>
                        </div>
                    </div>
                </div>
            <div data-snippet="s_fp_fairbuds_006" data-name="Fairbuds 006">
                        <p>Up to 6 hours of listening in a single charge and 20 additional hours with charging case.</p>
                        </div>
            <div data-snippet="s_fp_fairbuds_007" data-name="Fairbuds 007">
                    <h2>Designed to last.</h2>
                    
                    <div>
                        <h4>Built for living worry-free</h4>
                        <div>
                            <div>
                                    <h5>3 year Warranty</h5>
                                    <p>Your Fairbuds come standard with a two year warranty.We're extending that by another year. Because we've got your
                                        back.
                                    </p>
                                </div>
                            <div>
                                    <h5>Easily Repairable</h5>
                                    <p>It was about time the True Wireless Earbuds category got the signature Fairphone treatment: Built to last and
                                        fully repairable.
                                    </p>
                                </div>
                            <div>
                                    <h5>Replaceable Batteries</h5>
                                    <p>Old batteries should never be the end of your earbuds. That's why we designed the Fairbuds with replaceable
                                        batteries - in the charging case and both buds!
                                    </p>
                                </div>
                            <div>
                                    <h5>IP54 Sweat and Water Resistance</h5>
                                    <p>It always rains in Amsterdam - so of course these had to be weatherproof. That also makes them great for working
                                        out.
                                    </p>
                                </div>
                        </div>
                    </div>
                </div>
            <section data-snippet="s_fp_fairbuds_008" data-name="Fairbuds 008">
                <div>
                    <h2>Small size. Big impact.</h2>
                    <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/326.webp" loading="lazy">
                    </p>
                    <div>
                        <h2>Small size. Big impact.</h2>
                        <div>
                            <ul>
                                <li>Made with fair and recycled materials</li>
                                <li>Made in fair factories</li>
                                <li>Climate conscious and electronic waste neutral</li>
                            </ul>
                            <p><span data-fp-light-box="light_box_16">
                                <i></i>
                                <span>More about our fair approach</span>
                            </span>
                        </p></div>
                    </div>
                </div>
                <div id="light_box_16">
                            <h2>Small size. Big impact.</h2>
                            <div>
                                <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/326.webp" loading="lazy">
                                </p>
                                <h3>Made with fair and recycled materials</h3>
                                <p>We integrate Fairtrade Gold into the Fairbuds’ supply chain and invest in Fairmined Gold Credits, Fairtrade Silver Credits and Cobalt Credits to account for the Fairbuds’ gold, silver and cobalt footprint. They also contain recycled materials such as rare earth elements and post-consumer recycled plastic.
                                </p>
                            </div>
                            <div>
                                <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/112.png" loading="lazy">
                                </p>
                                <h3>Made in fair factories</h3>
                                <p>The people who help to assemble the Fairbuds are paid a living wage bonus that helps to bridge the gap between minimum wage and a decent salary. Plus they get an active voice in improving working conditions with factory management.
                                </p>
                            </div>
                            <div>
                                <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/327.webp" loading="lazy">
                                </p>
                                <h3>Electronic waste neutral</h3>
                                <p>The Fairbuds are electronic waste neutral. What does this mean? The Fairbuds weigh 78 grams with the charging case. So, for every
                                    Fairbuds we put out into the world, we make it a point to responsibly collect and recycle 78 grams of electronic waste.
                                </p>
                            </div>
                            <div>
                                <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/328.webp" loading="lazy">
                                </p>
                                <h3>Climate conscious</h3>
                                <p>Like all our products, the Fairbuds were designed to be climate conscious. The Fairbuds are designed to last really long, thanks to its modular approach. The longer it lasts, the less impact on climate it has. It uses recycled materials in the production process, reducing carbon emissions. For the remaining emissions, we invest in Gold Standard-certified carbon reduction projects.
                                </p>
                            </div>
                        </div>
            </section>
            <div data-snippet="s_fp_fairbuds_009" data-name="Fairbuds 009">
                    <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/content/square_linear_gradient_3.svg" loading="lazy">
                    <img src="https://shop.fairphone.com/theme_fairphone/static/src/img/content/circle_blue.svg" loading="lazy"></p><h2>Your sound. Uninterrupted.</h2>
                    <div>
                        <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/322.webp" loading="lazy">
                            <i></i>
                        </p>
                        <div>
                            <h3>Active Noise Cancelling for the win</h3>
                            <p>For pristine sound in less than perfect conditions, switch on ANC with advanced wind noise reduction.</p>
                        </div>
                    </div>
                    <div>
                        <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/323.webp" loading="lazy">
                            <i></i>
                        </p>
                        <div>
                            <h3>Crystal Clear Calls Always</h3>
                            <p>Say hello to clearer phone calls and voice recordings, thanks to Environmental Noise Canceling (ENC), powered by a six-microphone array
                                that vastly reduces background noise.
                            </p>
                        </div>
                    </div>
                </div>
            <div data-snippet="s_fp_fairbuds_010" data-name="Fairbuds 010">
                    <h2>Easy to use. Easy to control.</h2>
                    
                    <div>
                        <h3>A dedicated mobile app to customise your Fairbuds</h3>
                        <div>
                            <div>
                                    <h5>CUSTOMIZE YOUR EQ SETTINGS</h5>
                                    <p>It’s time to own your sound. Get maximum control over how your Fairbuds sound with the fully customizable eight-band equalizer.
                                        Or take it easy with one of our presets.
                                    </p>
                                </div>
                            <div>
                                    <h5>KEEP YOUR BUDS UPDATED</h5>
                                    <p>You can also use the app to download and install the latest firmware updates for your Fairbuds.</p>
                                </div>
                        </div>
                        
                    </div>
                </div>
            
            <div data-snippet="s_fp_fairbuds_012" data-name="Fairbuds 012">
                    <div>
                        <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/331.webp" loading="lazy">
                        </p>
                        <div>
                            <h3>Get the perfect fit</h3>
                            <p>Because one size shouldn’t fit all. Choose from three different ear tip options and find the one that fits the best.</p>
                        </div>
                    </div>
                    <div>
                        <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/334.webp" loading="lazy">
                        </p>
                        <div>
                            <h3>Connect to more devices</h3>
                            <p>Connect to multiple devices and let the Fairbuds do the work for you. The Fairbuds will know where the music is playing, so you can sit
                                back and enjoy.
                            </p>
                        </div>
                    </div>
                    <div>
                        <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/332.webp" loading="lazy">
                        </p>
                        <div>
                            <h3>Auto play and pause</h3>
                            <p>The Fairbuds know when they're in your ear. Take them out and your song will pause, put them back in and you won't miss a beat.</p>
                        </div>
                    </div>
                    <div>
                        <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/333.webp" loading="lazy">
                        </p>
                        <div>
                            <h3>Dual audio controls</h3>
                            <p>Control your favorite playlist straight from your Fairbuds. Adjusting the volume and playback is right at your fingertips.</p>
                        </div>
                    </div>
                </div>
            
            <div id="section3" data-snippet="s_fp_fairbuds_014" data-name="Fairbuds 014">
                    <h2>The specs at a glance</h2>
                    <p>The Fairbuds are made for all your listening and wireless needs.</p>
                    <div>
                        <section data-name="Item row">
                            <p>
                                <h5>Controls</h5>
                            </p>
                            <div>
                                <ul>
                                    <li>Capacitive Touch Controls (Both Earbuds)</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <div>
                                
                                <h5>Bluetooth &amp; wireless</h5>
                            </div>
                            <div>
                                <ul>
                                    <li>Bluetooth: v5.3 (Profiles A2DP V1.2, AVRCP V1.5, HFP V1.8, HSP V1.2;)</li>
                                    <li>Multipoint Connection (Dual)</li>
                                    <li>Codec: SBC &amp; AAC</li>
                                    <li>Wireless Range: up to 10M (line of sight)</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <p>
                                <h5>Connectors &amp; charging</h5>
                            </p>
                            <div>
                                <ul>
                                    <li>USB Type-C</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <div>
                                
                                <h5>Battery</h5>
                            </div>
                            <div>
                                <ul>
                                    <li>Battery capacity: 45mAh (earbuds) 500mAh (charging case)</li>
                                    <li>Number of cycles: &gt;500 cycles</li>
                                    <li>Charging time: ~2 hours (case + earbuds), 10 min for 1.5h playback</li>
                                    <li>Total playtime (with case): Up to 26 hours</li>
                                    <li>Calling / Music time: Up to 5 hours (ANC on)/ Up to 6 hours (ANC off)</li>
                                    <li>Wireless charging: No</li>
                                    <li>Replaceable battery: Yes (both earbuds and case)</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <div>
                                
                                <h5>SOUND</h5>
                            </div>
                            <div>
                                <ul>
                                    <li>Driver Diameter: 11mm</li>
                                    <li>Driver type: Titanium coated, dynamic driver</li>
                                    <li>Sensitivity: 104±1dB at 1KHZ</li>
                                    <li>Frequency Response Range: 20Hz -20KHz</li>
                                    <li>Driver impedance: 16Ω ±15%</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <div>
                                
                                <h5>Microphone</h5>
                            </div>
                            <div>
                                <ul>
                                    <li>Total of 6 mics: 3 left, 3 right</li>
                                    <li>Smart assistants: Google Assistant, Apple Siri</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <p>
                                <h5>Weather resistant</h5>
                            </p>
                            <div>
                                <ul>
                                    <li>IP54 rating (light rain and sweat)</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <div>
                                
                                <h5>Product dimensions</h5>
                            </div>
                            <div>
                                <ul>
                                    <li>Earbud: 28.7mm*24.6mm*21mm</li>
                                    <li>Case: 65mm*65mm*27mm</li>
                                    <li>Weight: 78g including case; earbuds ~5g</li>
                                </ul>
                            </div>
                        </section>
                        <section data-name="Item row">
                            <div>
                                
                                <h5>Compatibility</h5>
                            </div>
                            <div>
                                <ul>
                                    <li>Compatible with Fairphone 3, 3+, 4 and 5</li>
                                    <li>Compatible with any device with Bluetooth</li>
                                </ul>
                            </div>
                        </section>
                    </div>
                </div>
            <div data-snippet="s_fp_fairbuds_015" data-name="Fairbuds 015">
                    <h2>Included in the box</h2>
                    <p>Everything you need to get started. No more. No less.</p>
                    <div>
                        <div>
                            <p><span>1</span></p><div>
                                <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/335.webp" loading="lazy">
                                </p>
                                <p><span>Fairbuds and charging case</span>
                            </p></div>
                        </div>
                        <div>
                            <p><span>2</span></p><div>
                                <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/336.webp" loading="lazy">
                                </p>
                                <p><span>Three ear tips</span>
                            </p></div>
                        </div>
                        <div>
                            <p><span>3</span></p><div>
                                <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/337.webp" loading="lazy">
                                </p>
                                <p><span>Quick-start guide</span>
                            </p></div>
                        </div>
                    </div>
                </div>
            <div data-snippet="s_fp_fairbuds_016" data-name="Fairbuds 016">
                    <h3>Some things are not in the box, and here’s why:</h3>
                    <p>We do not include a <a data-bs-original-title="" title="" href="https://shop.fairphone.com/shop/usb-c-3-2-long-life-cable-5?category=5#attr=" target="_blank">USB Cable</a> or <a data-bs-original-title="" title="" href="https://shop.fairphone.com/shop/dual-port-30-w-charger-eu-6?category=5#attr=" target="_blank">charger</a> in this box because we believe that it’s better to
                        save the environment through the reduction of plastic waste. Of course, it’s possible to buy one of these products if you need it.
                    </p>
                </div>
            <div data-snippet="s_fp_fairbuds_017" data-name="Fairbuds 017">
                    <h2>Get your Fairbuds today</h2>
                    <div>
                        <div>
                            
                            
                            <p><img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/338.webp" loading="lazy">
                                <img src="https://shop.fairphone.com/theme_fairphone/static/src/img/final_content/339.webp" loading="lazy">
                            </p>
                        </div>
                        <div>
                            <h5>FAIRBUDS</h5>
                            <ul>
                                <li>Titanium coated 11mm drivers</li>
                                <li>Active Noise Cancellation with advanced wind reduction</li>
                                <li>Modular and easy to repair with replaceable buds and batteries</li>
                            </ul>
                            <div>
                                <p><span data-fp-product-id="502">£129.00</span>
                                    <span data-fp-product-id="502">£129.00</span>
                                </p>
                                <p>plus shipping costs from € 3.95</p>
                            </div>
                            <p><a href="https://shop.fairphone.com/shop/aufear-ww1-fairphone-true-wireless-earbuds-406#attr=119" data-bs-original-title="" title="">buy now</a>
                        </p></div>
                    </div>
                </div>
            <div data-snippet="s_fp_fairbuds_003" data-name="Fairbuds 003">
                        <p><i></i>
                            <span>Long-lasting with a three-year warranty</span>
                        </p>
                        <p><i></i>
                            <span>14-day trial period with 100% full refund</span>
                        </p>
                        <p><i></i>
                            <span>Replaceable batteries inside buds and charging case</span>
                        </p>
                    </div>
            <div data-snippet="s_fp_wwwww_024" data-name="wwwww 024">
                    <h2>Frequently asked questions</h2>
                    <div>
                        <section>
                            <h5>Why have you launched the Fairbuds?</h5>
                            <i data-bs-toggle="collapse" aria-expanded="false" data-bs-target="#faq_collapse_tab_1"></i>
                            <p>Our mission at Fairphone is to establish a viable market for sustainable consumer electronics. Many of the problems that we see with smartphones, especially around e-waste and issues in the supply chain, also apply to audio products. In 2021, the Fairphone TWS earbuds were our first step into this new product category. They incorporated longer battery life and Fairtrade gold in the supply chain, but were, otherwise, an off-the-shelf design that was not repairable. Our plan was therefore always to improve on the design later on. The Fairbuds are the result of these efforts.
                                </p>
                        </section>
                        <section>
                            <h5>What warranty do you offer on the Fairbuds?</h5>
                            <i data-bs-toggle="collapse" aria-expanded="false" data-bs-target="#faq_collapse_tab_2"></i>
                            <p>There is a standard 2-year warranty on the earbuds, plus a one-year extended warranty if users register their Fairbuds online. That said, due to the modular design and the repairability, we expect the Fairbuds to last a lot longer than three years.
                                </p>
                        </section>
                        <section>
                            <h5>Which parts of the Fairbuds can be repaired or exchanged by the user?</h5>
                            <i data-bs-toggle="collapse" aria-expanded="false" data-bs-target="#faq_collapse_tab_3"></i>
                            <div id="faq_collapse_tab_3">
                                <p>Earbud (Left and/or Right)</p><p>Earbud Battery and Silicon Ring</p><p>Earbud Tips</p><p>Charging Case Outer Shell</p><p>Charging Case Core</p><p>Charging Case Battery</p></div>
                        </section>
                        <section>
                            <h5>Are the Fairbuds water-resistant/waterproof?</h5>
                            <i data-bs-toggle="collapse" aria-expanded="false" data-bs-target="#faq_collapse_tab_4"></i>
                            <p>The Fairbuds have IP54 certification, meaning they are sweat and weather resistant, but not completely waterproof.
                                </p>
                        </section>
                        <section>
                            <h5>What is the Fairbuds app used for?</h5>
                            <i data-bs-toggle="collapse" aria-expanded="false" data-bs-target="#faq_collapse_tab_5"></i>
                            <p>The Fairbuds app offers users more control over their earbuds, allowing you to change equalizer presets and tune your Fairbuds to your personal preferences. You can use the app to access the latest Fairbuds updates as well, ensuring better longevity of your device, with potentially new features, and the occasional bug-fix.  The app also offers users a quick start guide, tutorials, support articles and a customer service touchpoint. Learn more about the different components that make up your Fairbuds, and order replacement parts through the app if your Fairbuds are in need of repairs.</p>
                        </section>
                        
                        
                        
                        
                        
                    </div>
                </div>
            <div data-snippet="s_fp_home_010" data-name="Home 010">
                        <p>
                            <h2>Best in green electronics</h2>
                            
                        </p>
                        <div>
                            <h5>OUR IMPACT</h5>
                            <p>There are more phones than people. And behind every device is a complex supply chain. With suppliers, local communities and the wider industry, we work for fairer materials and more responsible practices. Showing the electronics industry that we can do better.
                            </p>
                            <p>Together we’re disrupting the industry’s short-term thinking that the world can no longer afford. And changing what it means to be “best.”</p>
                        </div>
                    </div>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Peter Higgs, physicist who discovered Higgs boson, has died (682 pts)]]></title>
            <link>https://www.theguardian.com/science/2024/apr/09/peter-higgs-physicist-who-discovered-higgs-boson-dies-aged-94</link>
            <guid>39981034</guid>
            <pubDate>Tue, 09 Apr 2024 16:21:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/science/2024/apr/09/peter-higgs-physicist-who-discovered-higgs-boson-dies-aged-94">https://www.theguardian.com/science/2024/apr/09/peter-higgs-physicist-who-discovered-higgs-boson-dies-aged-94</a>, See on <a href="https://news.ycombinator.com/item?id=39981034">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Peter Higgs, the Nobel prize-winning physicist who discovered a new particle known as the <a href="https://www.theguardian.com/science/higgs-boson" data-link-name="in body link" data-component="auto-linked-tag">Higgs boson</a>, has died.</p><p>Higgs, 94, who was awarded the Nobel prize for physics in 2013 for his work in 1964 showing how the boson helped bind the universe together by giving particles their mass, died at home in <a href="https://www.theguardian.com/uk/edinburgh" data-link-name="in body link" data-component="auto-linked-tag">Edinburgh</a> on Monday.</p><p>After a series of experiments, which began in earnest in 2008, his theory was proven by physicists working at the Large Hadron Collider at Cern in Switzerland in 2012; the Nobel prize was shared with François Englert, a Belgian theoretical physicist whose work in 1964 also contributed directly to the discovery.</p><figure id="103dd219-b7ee-484e-a783-720a5d0d08b1" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:3,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Peter Higgs interview: ‘I have this kind of underlying incompetence’&quot;,&quot;elementId&quot;:&quot;103dd219-b7ee-484e-a783-720a5d0d08b1&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/science/2013/dec/06/peter-higgs-interview-underlying-incompetence&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>A member of the Royal Society and a Companion of Honour, Higgs spent the bulk of his professional life at Edinburgh University, which set up the Higgs centre for theoretical physics in his honour in 2012.</p><p>Prof Peter Mathieson, the university’s principal, said: “Peter Higgs was a remarkable individual – a truly gifted scientist whose vision and imagination have enriched our knowledge of the world that surrounds us.</p><p>“His pioneering work has motivated thousands of scientists, and his legacy will continue to inspire many more for generations to come.”</p><p>Prof Fabiola Gianotti, the director general at Cern and former leader of the Atlas experiment, which helped discover the Higgs particle in 2012, said: “Besides his outstanding contributions to particle physics, Peter was a very special person, a man of rare modesty, a great teacher and someone who explained physics in a very simple and profound way.</p><p>“An important piece of Cern’s history and accomplishments is linked to him. I am very saddened, and I will miss him sorely.”</p><p>The evening before the discovery of the particle was announced, Peter was invited to a small celebration at the home of John Ellis, the former head of theory at Cern. “A giant of particle physics has left us,” Ellis told the Guardian. “Without his theory, atoms could not exist and radioactivity would be a force as strong as electricity and magnetism.</p><p>“His prediction of the existence of the particle that bears his name was a deep insight, and its discovery at Cern in 2012 was a crowning moment that confirmed his understanding of the way the Universe works.”</p><p>Jon Butterworth, a member of the Atlas collaboration, said Higgs was “a hero to the particle physics community”.</p><p>“Even though he didn’t much enjoy it, he felt a responsibility to use the public profile his achievements brought him for the good of science, and he did so many times. The particle that carries his name is perhaps the single most stunning example of how seemingly abstract mathematical ideas can make predictions which turn out to have huge physical consequences.”</p><p>The Royal Swedish Academy of Sciences, which awards the Nobel, said at the time the standard model of physics which underpins the scientific understanding of the universe “rests on the existence of a special kind of particle: the Higgs particle. This particle originates from an invisible field that fills up all space.</p><p>“Even when the universe seems empty this field is there. Without it, we would not exist, because it is from contact with the field that particles acquire mass. The theory proposed by Englert and Higgs describes this process.”</p><p>An immensely shy man who disliked the fuss, Higgs had left home for a quiet lunch of soup and trout in Leith on the day of the announcement, to be stopped by a former neighbour who gave him the news on his way home.</p><p>Born in Newcastle upon Tyne, Higgs leaves two sons, Chris and Jonny, his daughter-in-law Suzanne and two grandchildren. His wife, Jody, a linguistics lecturer from whom he was separated, died in 2008.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel Gaudi 3 AI Accelerator (287 pts)]]></title>
            <link>https://www.intel.com/content/www/us/en/newsroom/news/vision-2024-gaudi-3-ai-accelerator.html</link>
            <guid>39981032</guid>
            <pubDate>Tue, 09 Apr 2024 16:21:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.intel.com/content/www/us/en/newsroom/news/vision-2024-gaudi-3-ai-accelerator.html">https://www.intel.com/content/www/us/en/newsroom/news/vision-2024-gaudi-3-ai-accelerator.html</a>, See on <a href="https://news.ycombinator.com/item?id=39981032">Hacker News</a></p>
<div id="readability-page-1" class="page">


















    
    
    
        















    
    
        
        
        
        
        
        
        
    




    
    
        
    




    
    
    
    
        
    


    
    
        
    


    
    
        
    


    
        
    
    






























    


    

































    
        <div data-component="global-nav-redesign" data-component-id="1">
            <header role="banner">
                <nav role="navigation" aria-label="main navigation" data-igm="">
                    <!-- Brand and toggle get grouped for better mobile display -->
                    <div>

                        <div>
                            <a href="https://www.intel.com/content/www/us/en/homepage.html" alt="Intel homepage">
                                    
                                <img src="https://www.intel.com/content/dam/logos/intel-header-logo.svg" height="300" width="118" alt="Intel logo - Return to the home page">
                            </a>
                        </div>

                        

                        <!-- START MOBLE TOGGLE buttons -->
                        <div>


                            <!-- START: NON-signed in panel -->
                            <span id="not-logged-in-scenario">

    
        </span>


                            


















































<span id="logged-in-scenario">






</span>

                            
















    




<div id="panel-language-selector" aria-expanded="false" aria-selected="false">
                <h2>
                    
                        
                            Select Your Language
                        
                        
                    
                </h2>
            </div>


                            <!-- END: NON-sign in panel -->
                            

























    

    



    








    











    
    
    
        
    


    
    <div aria-live="off" id="simplify-search" data-component="wa_skip_track" data-igm-search-content="" document-height="true">
                             
                                 
                            
                            <!-- Search Result Typeahead -->
                            <div id="igm-search-result" data-igm-search-results="">
                                    
                                        Sign In to access restricted content
                                </div>
                            <!-- Recent Searches: 1) display default search info if no search terms is available  -->
                            <!-- Recent Searches: 2) display recenter terms when available and hide default search info  -->
                            <div data-igm-search-related="">
                                <div>
                                    <!-- default search info -->
                                    <div>
                                        <h3>Using Intel.com Search</h3>
                                        <p>You can easily search the entire Intel.com site in several ways.</p>
                                        <ul>
                                            <li>
                                                Brand Name:
                                                <strong>
                                                    Core i9
                                                </strong>
                                            </li>
                                            <li>
                                                Document Number:
                                                <strong>
                                                    123456
                                                </strong>
                                            </li>
                                            <li>
                                                Code Name:
                                                <strong>
                                                    Emerald Rapids
                                                </strong>
                                            </li>
                                            <li>
                                                Special Operators:
                                                <strong>
                                                    “Ice Lake”, Ice AND Lake, Ice OR Lake, Ice*
                                                </strong>
                                            </li>
                                        </ul>
                                    </div>
                                    <!-- quick links is always visible on the recents overlay -->
                                    <div>
                                        <h3>Quick Links</h3>
                                        <p>You can also try the quick links below to see results for most popular searches.</p>
                                        <ul>
                                            <!--<li>
                                                <a class="quick-link" rel="noopener noreferrer"
                                                   href=https://ark.intel.com?wapkw=quicklink:product-specifications>
                                                    Product Specifications
                                                </a>
                                            </li>-->
                                            <li>
                                                <a rel="noopener noreferrer" href="https://www.intel.com/content/www/us/en/products/overview.html?wapkw=quicklink:products">
                                                    Product Information
                                                </a>
                                            </li>
                                            <li><a rel="noopener noreferrer" href="https://www.intel.com/content/www/us/en/support.html?wapkw=quicklink:support">
                                                Support
                                            </a>
                                            </li>
                                            <li>
                                                <a rel="noopener noreferrer" href="https://downloadcenter.intel.com/?wapkw=quicklink:download-center">
                                                    Drivers &amp; Software
                                                </a>
                                            </li>
                                        </ul>
                                    </div>
                                    <!-- recent search terms -->
                                    <div data-component="wa_skip_track" data-component-id="1">
                                            <h3>Recent Searches</h3>
                                        </div>
                                </div>
                                <div>
                                    
                                        Sign In to access restricted content
                                </div>
                            </div>
                            
                                 <div data-igm-advanced-search="">
											<div data-component="wa_skip_track" data-component-id="1">
													<h3>Advanced Search</h3>
													<div>
															<h3>Only search in</h3>
															<div aria-label="Only Search In">
																<label for="search_title">
																	
																	Title</label>

																	<label for="search_description">
																	
																Description</label>

																	<label for="search_id">
																	Content ID</label>
															</div>

															
														</div>
												</div>
											<div>
												Sign in to access
												restricted content.
											</div>
										</div>
                                    
                        </div>


                        </div>
                        <!-- END MOBILE TOGGLE buttons -->
                    </div>
                </nav>
            </header>
        </div>

    
    


<div id="alertMsg" data-scroll-track="false">
                        <p>The browser version you are using is not recommended for this site.<br>Please consider upgrading to the latest version of your browser by clicking one of the following links.</p>
                        <div>
                            <ul>
                                
                                    <li><a href="https://support.apple.com/downloads/safari">Safari</a></li>
                                
                                    <li><a href="https://support.google.com/chrome/answer/95346?hl=en">Chrome</a></li>
                                
                                    <li><a href="https://www.microsoft.com/en-us/edge">Edge</a></li>
                                
                                    <li><a href="https://www.mozilla.org/en-US/firefox/new/">Firefox</a></li>
                                
                            </ul>
                        </div>
                    </div>


<main id="primary-content">


























    
        
        
        <main id="primary-content-main">
            

            <div id="articleHero-1" data-component="articleHero" data-component-id="1">
                                                
                                                
                                                    
                                                        <h2>Intel Breaks Down Proprietary Walls to Bring Choice to Enterprise GenAI Market</h2>
                                                    
                                                    
                                                
                                                <div>
                                                    
                                                        <p>Intel Gaudi 3 AI accelerator brings global enterprises choice for generative AI, building on the performance and scalability of its Gaudi 2 predecessor.</p>

                                                    
                                                </div>
                                                
                                            </div>
            <article data-component-id="1" data-component="articletemplate">
                <div>
                            <div>

                                

                                <!-- duplicated from articlehero for vertical layout -->
                                
                                    
                                    
                                        
                                    
                                

                                
                                <!-- BUILT IN - ARTICLE INTRO COMPONENT -->
                                <!-- duplicated from right column for mobile layout -->
                                
                                <!-- END IN - ARTICLE INTRO COMPONENT -->

                                <!-- BUILT IN - ARTICLE TAKEAWAY COMPONENT -->

                                <div data-component="articleTakeaway" id="articleTakeaway-1" data-component-id="1">
                        <h2>News</h2>
                        <ul>
                            
                                
                                    <li><p>April 9, 2024</p>
                                    </li>
                                
                            
                                
                                    <li><p><a href="https://www.intel.com/content/www/us/en/newsroom/contact-public-relations-team.html">Contact Intel PR</a></p>
                                    </li>
                                
                            
                                
                                    <li><h4><strong>Follow Intel Newsroom on social:</strong></h4>

                                    </li>
                                
                            
                        </ul>
                    </div>

                                

                                <!-- only display this for authored pages and not salesforce pages-->
                                <div>
                                        
                                        <img src="" alt="author-image">
                                    </div>

                            </div>

                            <div>


<div id="articleparagraph-2" data-component="articleparagraph" data-component-id="2">
                                
                                
                                    
                                    
                                        <p><strong>What’s New:</strong>&nbsp; At Intel Vision, Intel introduces the Intel® Gaudi® 3 AI accelerator, which delivers 4x AI compute for BF16,&nbsp; 1.5x increase in memory bandwidth, and 2x networking bandwidth for massive system scale out compared to its predecessor – a significant leap in performance and productivity for AI training and inference on popular large language models (LLMs) and multimodal models. Building on the proven performance and efficiency of the Intel® Gaudi® 2 AI accelerator – the <a href="https://www.intel.com/content/www/us/en/newsroom/news/new-gaudi-2-xeon-performance-ai-inference.html" rel="noreferrer noopener" target="_blank">only MLPerf-benchmarked alternative</a> for LLMs on the market – Intel gives customers a choice with open community-based software and industry-standard Ethernet networking to scale their systems more flexibly.&nbsp;</p>

                                    
                                
                            </div>
<div id="articleparagraph-3" data-component="articleparagraph" data-component-id="3">
                                <blockquote>
                                    <p>“In the ever-evolving landscape of the AI market, a significant gap persists in the current offerings. Feedback from our customers and the broader market underscores a desire for increased choice. Enterprises weigh considerations such as availability, scalability, performance, cost, and energy efficiency. Intel Gaudi 3 stands out as the GenAI alternative presenting a compelling combination of price performance, system scalability, and time-to-value advantage.” </p>
                                    
                                    
                                        
                                    
                                </blockquote>
                            </div>
<div id="articleparagraph-4" data-component="articleparagraph" data-component-id="4">
                                
                                
                                    
                                    
                                        <p><strong>Why It Matters: </strong>Today, enterprises across critical sectors such as finance, manufacturing and healthcare are rapidly seeking to broaden accessibility to AI and transitioning generative AI (GenAI) projects from experimental phases to full-scale implementation. To manage this transition, fuel innovation and realize revenue growth goals, businesses require open, cost-effective and more energy-efficient solutions and products that meet return-on-investment (ROI) and operational efficiency needs.&nbsp;</p>

<p>The Intel Gaudi 3 accelerator will meet these requirements and offer versatility through open community-based software and open industry-standard Ethernet, helping businesses flexibly scale their AI systems and applications.&nbsp;&nbsp;</p>

<p><strong>How Custom Architecture Delivers GenAI Performance and Efficiency:</strong>&nbsp;The Intel Gaudi 3 accelerator, architected for efficient large-scale AI compute, is manufactured on a 5 nanometer (nm) process and offers significant advancements over its predecessor.&nbsp; It is designed to allow activation of all engines in parallel — with the Matrix Multiplication Engine (MME), Tensor Processor Cores (TPCs) and Networking Interface Cards (NICs) — enabling the acceleration needed for fast, efficient deep learning computation and scale. Key features include:&nbsp;<br>
&nbsp;</p>

<ul role="list">
	<li aria-setsize="-1" role="listitem">
	<p><strong>AI-Dedicated Compute Engine:</strong> The Intel Gaudi 3 accelerator was purpose-built for high-performance, high-efficiency GenAI compute.&nbsp; Each accelerator uniquely features a heterogenous compute engine comprised of 64 AI-custom and programmable TPCs and eight&nbsp; MMEs. Each Intel Gaudi 3 MME is capable of performing an impressive 64,000 parallel operations, allowing a high degree of computational efficiency, making them adept at handling complex matrix operations, a type of computation that is fundamental to deep learning algorithms. This unique design accelerates speed and efficiency of parallel AI operations and supports multiple data types, including FP8 and BF16.&nbsp;&nbsp;</p>
	</li>
	<li aria-setsize="-1" role="listitem">
	<p><strong>Memory Boost for LLM Capacity Requirements: </strong>128 gigabytes (GB) of HBMe2 memory capacity, 3.7 terabytes (TB) of memory bandwidth and 96 megabytes (MB) of on-board static random access memory (SRAM) provide ample memory for processing large GenAI datasets on fewer Intel Gaudi 3s, particularly useful in serving large language and multimodal models, resulting in increased workload performance and data center cost efficiency.&nbsp;&nbsp;</p>
	</li>
	<li aria-setsize="-1" role="listitem">
	<p><strong>Efficient System Scaling for Enterprise GenAI: </strong>Twenty-four 200 gigabit (Gb) Ethernet ports are integrated into every Intel Gaudi 3 accelerator, providing flexible and open-standard networking. They enable efficient scaling to support large compute clusters and eliminate vendor lock-in from proprietary networking fabrics. The Intel Gaudi 3 accelerator is designed to scale up and scale out efficiently from a single node to thousands to meet the expansive requirements of GenAI models.&nbsp;</p>
	</li>
	<li aria-setsize="-1" role="listitem">
	<p><strong>Open Industry Software for Developer Productivity:</strong> Intel Gaudi software integrates the PyTorch framework and provides optimized Hugging Face community-based models – the most-common AI framework for GenAI developers today. This allows GenAI developers to operate at a high abstraction level for ease of use and productivity and ease of model porting across hardware types.&nbsp;</p>
	</li>
</ul>

<ul role="list">
	<li aria-setsize="-1" role="listitem">
	<p><strong>Gaudi 3 PCIe:</strong> New to the product line is the Gaudi 3 peripheral component interconnect express (PCIe) add-in card. Tailored to bring high efficiency with lower power, this new form factor is ideal for workloads such as fine-tuning, inference and retrieval-augmented generation (RAG). It is equipped as a full-height form factor at 600 watts, with a memory capacity of 128GB and a bandwidth of 3.7TB per second.&nbsp;&nbsp;<br>
	&nbsp;</p>
	</li>
</ul>

<p>Intel Gaudi 3 accelerator will deliver significant performance improvements for training and inference tasks on leading GenAI models. Specifically, the Intel Gaudi 3 accelerator is projected to deliver on average versus Nvidia H100:</p>



<ul>
	<li><strong>50% faster time-to-train</strong><sup>1</sup> across Llama2 7B and 13B parameters, and GPT-3 175B parameter models. &nbsp;</li>
	<li><strong>50% faster inference throughput</strong><sup>2</sup> and <strong>40% greater inference power-efficiency</strong><sup>3</sup> across Llama 7B and 70B parameters, and Falcon 180B parameter models. An even greater inference performance advantage on longer input and output sequences.</li>
	<li><strong>30% faster inferencing</strong><sup>4</sup> on Llama 7B and 70B parameters, and Falcon 180B parameter models against Nvidia H200. &nbsp;</li>
</ul>



<p><strong>About Market Adoption and Availability:</strong>&nbsp;The Intel Gaudi 3 accelerator will be available to original equipment manufacturers (OEMs) in the second quarter of 2024 in industry-standard configurations of Universal Baseboard and open accelerator module (OAM). Among the notable OEM adopters that will bring Gaudi 3 to market are Dell Technologies, HPE, Lenovo and Supermicro. General availability of Intel Gaudi 3 accelerators is anticipated for the third quarter of 2024, and the Intel Gaudi 3 PCIe add-in card is anticipated to be available in the last quarter of 2024.&nbsp;&nbsp;</p>

<p>The Intel Gaudi 3 accelerator will also power several cost-effective cloud LLM infrastructures for training and inference, offering price-performance advantages and choices to organizations that now include NAVER.&nbsp;&nbsp;&nbsp;</p>

<p>Developers can get started today with access to Intel <a href="https://developer.habana.ai/intel-developer-cloud/getting-started-on-the-intel-developer-cloud/?utm_term=&amp;utm_campaign=PMax-+Google&amp;utm_source=adwords&amp;utm_medium=ppc&amp;hsa_acc=1034914560&amp;hsa_cam=21089989807&amp;hsa_grp=&amp;hsa_ad=&amp;hsa_src=x&amp;hsa_tgt=&amp;hsa_kw=&amp;hsa_mt=&amp;hsa_net=adwords&amp;hsa_ver=3&amp;gad_source=1&amp;gclid=Cj0KCQjw2PSvBhDjARIsAKc2cgNPd48lg6eFDhBo6dvmlXhZT20O25FioJwE17vlbrN6C86x51H4vhYaAl2LEALw_wcB" rel="noreferrer noopener" target="_blank">Gaudi 2-based instances</a> on the developer cloud to learn, prototype, test, and run applications and workloads</p>

<p><strong>What’s Next:</strong> Intel Gaudi 3 accelerators' momentum will be foundational for Falcon Shores, Intel’s next-generation graphics processing unit (GPU) for AI and high-performance computing (HPC). Falcon Shores will integrate the Intel Gaudi and Intel® Xe intellectual property (IP) with a single GPU programming interface built on the Intel® oneAPI specification.&nbsp;</p>

<p><strong>More Context:</strong>&nbsp;<a href="https://www.intel.com/content/www/us/en/newsroom/news/vision-2024-enterprise-ai-gaudi-3-open-systems-strategy.html">Intel Unleashes Enterprise AI with Gaudi 3, AI Open Systems Strategy and New Customer Wins</a>&nbsp;(News) | <a href="https://www.intel.com/content/www/us/en/products/details/processors/ai-accelerators/gaudi3.html">Intel Gaudi 3 AI Accelerator</a> (Product Page) | <a href="https://www.intel.com/content/www/us/en/content-details/817486/content-details.html">Intel Gaudi 3 AI Accelerator</a> (White Paper) |&nbsp;&nbsp;<a href="https://www.intel.com/content/www/us/en/newsroom/news/new-gaudi-2-xeon-performance-ai-inference.html">Intel Gaudi 2 Remains Only Benchmarked Alternative to NV H100 for GenAI Performance</a> (News)</p>

                                    
                                
                            </div>
<div id="articleparagraph-5" data-component="articleparagraph" data-component-id="5">
                                
                                
                                    
                                    
                                        <p><sub><strong>The Small Print:&nbsp;</strong></sub></p>

<p><sub>Intel does not control or audit third-party data.  You should consult other sources to evaluate accuracy.&nbsp;</sub></p>

<p><sup>1 </sup><sub>NV H100 comparison based on: <a href="https://developer.nvidia.com/deep-learning-performance-training-inference/training" rel="noreferrer noopener" target="_blank">https://developer.nvidia.com/deep-learning-performance-training-inference/training</a>, Mar 28th 2024  à “Large Language Model” tab Vs Intel® Gaudi® 3&nbsp; projections for LLAMA2-7B, LLAMA2-13B &amp; GPT3-175B as of 3/28/2024. Results may vary&nbsp;</sub></p>

<p><sup>2 </sup><sub>NV H100 comparison based on <a href="https://nvidia.github.io/TensorRT-LLM/performance.html" rel="noreferrer noopener" target="_blank">https://nvidia.github.io/TensorRT-LLM/performance.html#h100-gpus-fp8</a> , Mar 28th, 2024. Reported numbers are per GPU. Vs Intel® Gaudi® 3 projections for LLAMA2-7B, LLAMA2-70B &amp; Falcon 180B projections. Results may vary.&nbsp;</sub></p>

<p><sup>3 </sup><sub>NV comparison based on <a href="https://nvidia.github.io/TensorRT-LLM/performance.html" rel="noreferrer noopener" target="_blank">https://nvidia.github.io/TensorRT-LLM/performance.html#h100-gpus-fp8</a> , Mar 28th, 2024. Reported numbers are per GPU. Vs Intel® Gaudi® 3 projections for LLAMA2-7B, LLAMA2-70B &amp; Falcon 180B Power efficiency for both Nvidia and Gaudi 3 based on internal estimates. Results may vary.&nbsp;&nbsp;</sub></p>

<p><sup>4 </sup><sub>NV H200 comparison based on <a href="https://nvidia.github.io/TensorRT-LLM/performance.html" rel="noreferrer noopener" target="_blank">https://nvidia.github.io/TensorRT-LLM/performance.html#h100-gpus-fp8</a> , Mar 28th, 2024. Reported numbers are per GPU.Vs Intel® Gaudi® 3 projections for LLAMA2-7B, LLAMA2-70B &amp; Falcon 180B projections. Results may vary.&nbsp;</sub></p>

                                    
                                
                            </div>
</div>
                        </div>

                

                
                <div data-component="reference" data-component-id="1" id="reference">
                                
                                
                                    <p><b>About Intel</b></p>
<p>Intel (Nasdaq: INTC) is an industry leader, creating world-changing technology that enables global progress and enriches lives. Inspired by Moore’s Law, we continuously work to advance the design and manufacturing of semiconductors to help address our customers’ greatest challenges. By embedding intelligence in the cloud, network, edge and every kind of computing device, we unleash the potential of data to transform business and society for the better. To learn more about Intel’s innovations, go to <a href="https://newsroom.intel.com/">newsroom.intel.com</a> and <a href="https://www.intel.com/">intel.com</a>.</p>
<p>© Intel Corporation. Intel, the Intel logo and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others.</p>
 
                                
                            </div>
                
                    











                
                

            </article>
        </main>
    
    





    




    


</main>












































    







</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Beeper acquired by Automattic (WordPress) (429 pts)]]></title>
            <link>https://blog.beeper.com/2024/04/09/beeper-is-joining-automattic/</link>
            <guid>39980268</guid>
            <pubDate>Tue, 09 Apr 2024 15:09:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.beeper.com/2024/04/09/beeper-is-joining-automattic/">https://blog.beeper.com/2024/04/09/beeper-is-joining-automattic/</a>, See on <a href="https://news.ycombinator.com/item?id=39980268">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<figure><img data-attachment-id="142603683" data-permalink="https://blog.beeper.com/2024/04/09/beeper-is-joining-automattic/beeper-only/" data-orig-file="https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png" data-orig-size="2608,1471" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="beeper-only" data-image-description="" data-image-caption="" data-medium-file="https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=300" data-large-file="https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=1024" width="1024" height="577" src="https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=1024" alt="" srcset="https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=1024 1024w, https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=2046 2046w, https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=150 150w, https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=300 300w, https://blog.beeper.com/wp-content/uploads/2024/04/beeper-only.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I’m excited to announce that Beeper has been acquired by Automattic. This acquisition marks the beginning of an exciting new chapter as we continue our mission to create the best chat app on earth.</p>







<blockquote>
<p>If you haven’t heard of <a href="https://beeper.com/">Beeper</a> before, welcome! We make a universal chat app – one app to send and receive messages on 14 different chat networks. You might have also heard about Beeper Mini, our briefly available iMessage-on-Android app.</p>
</blockquote>



<p>In many ways, our journey has only just begun. Beeper has just over 115,000 users and was, <a href="https://blog.beeper.com/2024/04/09/beeper-is-now-available/">until today</a>, in beta. Given the state of the messaging landscape today, we believe there is a huge opportunity for us to push boundaries and create new experiences in chat. The majority of other chat apps have stagnated, entrenched in their positions, with <a href="https://twitter.com/ericmigi/status/1761916874227622299">no significant new players</a> emerging since Discord’s launch in 2015. Given the state of the messaging world, we’ve long felt the need for a strong ally with the resources to support us on our quest. Automattic has a long history of putting user control and privacy first with open source, and great bilateral relationships with Meta, Apple, Microsoft, Google, Matrix and others that we hope can usher in a new era of collaboration.</p>



<p>It’s a fantastic match. Automattic is best known for supporting WordPress and WooCommerce – two open source software projects that underpin huge portions of the internet’s publishing and ecommerce infrastructure. Together, we’ll develop software for a third fundamental pillar of the internet: chat.</p>



<p>Matt, Automattic’s CEO, and I have known each other for years. He was an early user, supporter and investor in Beeper. We’re very well aligned on our goal (build the best chat app on earth), approach (open source where possible), and independence (Beeper will operate independently as part of Automattic’s Other Bets division).</p>



<p>This is a big bet. Automattic is doubling down on chat after their acquisition last year of <a href="http://texts.com/">Texts.com</a>, a messaging app with a similar mission. Our teams and products will merge, and I will take on the role leading the team as Head of Messaging. It will take a bit of time for us to integrate and combine forces under the Beeper brand. We’ve got big plans! I’m really excited about the future of chat 📟</p>



<p><strong>Eric Migicovsky</strong></p>



<p>Beeper CEO → Automattic Head of Messaging<br></p>



<hr>



<h3>For Beeper users…</h3>



<ul>
<li>The Beeper app you know and love is only going to get better with the support of Automattic! In fact, today we’re making Beeper available to everyone – no more waitlist. <a href="https://blog.beeper.com/2024/04/09/beeper-is-now-available/">Learn more</a>.</li>



<li>Our privacy policy and terms of service remain the same, though they may change in the future.</li>



<li>As always, Beeper (and now Automattic Inc.) cannot view any of your historical chat history. All messages are encrypted with a key that only you have before being stored. Read more about <a href="https://beeper.com/faq#security-and-privacy">our security and privacy</a> commitments.</li>



<li>Our business model is unchanged. We build a fantastic free chat app, then charge for additional premium features.</li>



<li>If you no longer would like to use Beeper, visit <a href="https://account.beeper.com/">account.beeper.com</a> to delete your account.</li>
</ul>



<h3>For <a href="http://texts.com/">Texts.com</a> users…</h3>



<ul>
<li>Nothing is changing today. Texts is the same product today as it was yesterday.</li>



<li>Beeper and Texts share a common goal of building the best chat app on earth. Texts’ commitment to local data processing will be preserved.</li>



<li>Over time, we will work to integrate the teams and products. More news to come in the future!</li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: We built PriceLevel to find out what companies pay for SaaS (147 pts)]]></title>
            <link>https://www.pricelevel.com/</link>
            <guid>39980222</guid>
            <pubDate>Tue, 09 Apr 2024 15:04:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pricelevel.com/">https://www.pricelevel.com/</a>, See on <a href="https://news.ycombinator.com/item?id=39980222">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <h2>Pricing by Category</h2> <div> <a href="https://www.pricelevel.com/categories/ab-testing"> <div> <p> <h3>A/B Testing</h3> </p> <div> <p><img src="https://logo.clearbit.com/https://amplitude.com/" alt="Amplitude's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://split.io/" alt="Split's logo'" width="56" height="56"><img src="https://www.pricelevel.com/_astro/statsig.B9exqbUs.png" alt="Statsig's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://launchdarkly.com/" alt="LaunchDarkly's logo'" width="56" height="56"> </p> </div> </div> </a><a href="https://www.pricelevel.com/categories/apm"> <div> <p> <h3>Application Performance Monitoring (APM)</h3> </p> <div> <p><img src="https://logo.clearbit.com/https://www.datadog.com/" alt="Datadog's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://newrelic.com/" alt="New Relic's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://grafana.com/" alt="Grafana's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.elastic.co/" alt="Elastic Stack's logo'" width="56" height="56"> </p> </div> </div> </a><a href="https://www.pricelevel.com/categories/ats"> <div> <p> <h3>Applicant Tracking System (ATS)</h3> </p> <div> <p><img src="https://logo.clearbit.com/https://www.greenhouse.com/" alt="Greenhouse's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.lever.co/" alt="Lever's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.ashbyhq.com/" alt="Ashby's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.bamboohr.com/" alt="BambooHR's logo'" width="56" height="56"> </p> </div> </div> </a><a href="https://www.pricelevel.com/categories/business-intelligence"> <div> <p> <h3>Business Intelligence</h3> </p> <div> <p><img src="https://www.pricelevel.com/_astro/looker.D-OYheZS.svg" alt="Looker's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.metabase.com/" alt="Metabase's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.tableau.com/" alt="Tableau's logo'" width="56" height="56"><img src="https://www.pricelevel.com/_astro/power-bi.BbPy9d0V.svg" alt="Power BI's logo'" width="56" height="56"> </p> </div> </div> </a><a href="https://www.pricelevel.com/categories/cross-channel-mktg"> <div> <p> <h3>Cross-Channel Marketing Hub</h3> </p> <div> <p><img src="https://logo.clearbit.com/https://iterable.com/" alt="Iterable's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.hubspot.com/" alt="HubSpot's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://blueshift.com/" alt="Blueshift's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.braze.com/" alt="Braze's logo'" width="56" height="56"> </p> </div> </div> </a><a href="https://www.pricelevel.com/categories/digital-whiteboard"> <div> <p> <h3>Digital Whiteboard</h3> </p> <div> <p><img src="https://logo.clearbit.com/https://miro.com/" alt="Miro's logo'" width="56" height="56"><img src="https://www.pricelevel.com/_astro/lucidchart.CAqfVQd-.png" alt="Lucidchart's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.mural.co/" alt="Mural's logo'" width="56" height="56"><img src="https://www.pricelevel.com/_astro/figma.BIuJBkoC.png" alt="FigJam's logo'" width="56" height="56"> </p> </div> </div> </a><a href="https://www.pricelevel.com/categories/equity-management"> <div> <p> <h3>Equity Management</h3> </p> <div> <p><img src="https://logo.clearbit.com/https://carta.com/" alt="Carta's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://pulley.com/" alt="Pulley's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://ledgy.com/" alt="Ledgy's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.cakeequity.com/" alt="Cake Equity's logo'" width="56" height="56"> </p> </div> </div> </a><a href="https://www.pricelevel.com/categories/hris"> <div> <p> <h3>Human Resources Information System (HRIS)</h3> </p> <div> <p><img src="https://logo.clearbit.com/https://gusto.com/" alt="Gusto's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.ukg.com/" alt="UKG's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.rippling.com/" alt="Rippling's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://namely.com/" alt="Namely's logo'" width="56" height="56"> </p> </div> </div> </a><a href="https://www.pricelevel.com/categories/mdm"> <div> <p> <h3>Mobile Device Management (MDM)</h3> </p> <div> <p><img src="https://logo.clearbit.com/https://www.jamf.com/" alt="Jamf's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.kandji.io/" alt="Kandji's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://addigy.com/" alt="Addigy's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://mosyle.com/" alt="Mosyle's logo'" width="56" height="56"> </p> </div> </div> </a><a href="https://www.pricelevel.com/categories/remote-support-software"> <div> <p> <h3>Remote Support Software</h3> </p> <div> <p><img src="https://logo.clearbit.com/https://www.firstbase.com/" alt="Firstbase's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.hofy.com/" alt="Hofy's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://helloretriever.com/" alt="Retriever's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.allwhere.co/" alt="allwhere's logo'" width="56" height="56"> </p> </div> </div> </a><a href="https://www.pricelevel.com/categories/salesforce-workflow-automation"> <div> <p> <h3>Salesforce Workflow Automation</h3> </p> <div> <p><img src="https://logo.clearbit.com/https://www.formstack.com/" alt="Formstack's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.formassembly.com/" alt="FormAssembly's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://titandxp.com/" alt="Titan Forms's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://productforce.de/" alt="DocXpert's logo'" width="56" height="56"> </p> </div> </div> </a><a href="https://www.pricelevel.com/categories/session-replays"> <div> <p> <h3>Session Replays</h3> </p> <div> <p><img src="https://logo.clearbit.com/https://www.fullstory.com/" alt="FullStory's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://logrocket.com/" alt="LogRocket's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.hotjar.com/" alt="HotJar's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://mouseflow.com/" alt="Mouseflow's logo'" width="56" height="56"> </p> </div> </div> </a><a href="https://www.pricelevel.com/categories/team-messaging"> <div> <p> <h3>Team Messaging</h3> </p> <div> <p><img src="https://logo.clearbit.com/https://slack.com/" alt="Slack's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://discord.com/" alt="Discord's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.chanty.com/" alt="Chanty's logo'" width="56" height="56"><img src="https://www.pricelevel.com/_astro/google-chat.Cv1o0cV3.png" alt="Google Chat's logo'" width="56" height="56"> </p> </div> </div> </a><a href="https://www.pricelevel.com/categories/telephony"> <div> <p> <h3>Telephony</h3> </p> <div> <p><img src="https://logo.clearbit.com/https://www.twilio.com" alt="Twilio Flex's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.talkdesk.com/" alt="Talkdesk's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.vonage.com/" alt="Vonage's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.five9.com/" alt="Five9's logo'" width="56" height="56"> </p> </div> </div> </a><a href="https://www.pricelevel.com/categories/user-research"> <div> <p> <h3>User Research</h3> </p> <div> <p><img src="https://logo.clearbit.com/https://www.usertesting.com/" alt="UserTesting's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://maze.co/" alt="Maze's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.lyssna.com/" alt="Lyssna's logo'" width="56" height="56"><img src="https://logo.clearbit.com/https://www.userlytics.com/" alt="Userlytics's logo'" width="56" height="56"> </p> </div> </div> </a> </div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New Grafana Loki UI: No LogQL Required (189 pts)]]></title>
            <link>https://grafana.com/blog/2024/04/09/find-your-logs-data-with-explore-logs-no-logql-required/</link>
            <guid>39979750</guid>
            <pubDate>Tue, 09 Apr 2024 14:23:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grafana.com/blog/2024/04/09/find-your-logs-data-with-explore-logs-no-logql-required/">https://grafana.com/blog/2024/04/09/find-your-logs-data-with-explore-logs-no-logql-required/</a>, See on <a href="https://news.ycombinator.com/item?id=39979750">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>We are thrilled to announce the preview of Explore Logs, a new way to browse your logs without writing LogQL. In this post, we’ll cover why we built Explore Logs and we’ll dive deeper into some of its features, including at-a-glance breakdowns by label, detected fields, and our new pattern detection. At the end, we’ll tell you how you can try Explore Logs for yourself today.</p><p>But let’s start from the beginning — with good old LogQL.</p><h2 id="we-love-logql">We love LogQL</h2><p>Grafana Loki, Grafana Labs’ <a href="https://github.com/grafana/loki" target="_blank" rel="noopener noreferrer">open source log aggregation project</a>, provides a powerful query language called <a href="https://grafana.com/blog/2022/05/12/10-things-you-didnt-know-about-logql/">LogQL</a>. Site reliability engineers (SREs) and other Loki experts love to use it to filter logs for specific keywords, reduce noise by selecting specific labels, and perform other operations to get answers to understand their systems.</p><p>Metrics can be created from logs, which are put into dashboards to visualize key insights. Alerts can be set up and wired into <a href="https://grafana.com/products/cloud/irm/">Grafana Incident Response &amp; Management</a> (IRM), which includes <a href="https://grafana.com/products/cloud/oncall/">Grafana OnCall</a> and <a href="https://grafana.com/products/cloud/incident/">Grafana Incident,</a> so you can make sure you get early warnings when things go wrong.</p><p>Those same queries can be used to power <a href="https://grafana.com/docs/grafana/latest/panels-visualizations/visualizations/">Grafana dashboard visualizations</a> so you can make sense of your logs. LogQL is really powerful! There’s just one catch …</p><h2 id="but-i-dont-know-logql">‘But I don’t know LogQL!’</h2><p>If you aren’t digging into your logs every day, you might not have had a reason to learn LogQL. Perhaps you dive in now and again, or maybe only during an incident. And even in those moments, having to remember the details of a query language can slow down response times.&nbsp;</p><p>The point is, you come to your logs platform not because you love logs, but because you <em>need</em> logs to do your job. Whether you need them to see a deployment go smoothly, to investigate a latency issue, or to deal with a 4 a.m. page, the last thing you want to do is wrestle with yet another query language.&nbsp;</p><p>If only you could take advantage of all the great benefits Loki + Grafana provides, without needing to learn LogQL. Well, you guessed it: Now you can!</p><h2 id="introducing-explore-logs-a-new-oss-application">Introducing Explore Logs, a new OSS application</h2><p>Explore Logs is our new OSS application that lets you browse your logs as if they were already neatly organized for you in advance. You can find <a href="https://github.com/grafana/explore-logs" target="_blank" rel="noopener noreferrer">the source code on GitHub</a>, but before you head there to try it, allow us to give you a quick tour.</p><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><a href="https://grafana.com/media/blog/explore-logs/explore-logs.gif" itemprop="contentUrl"><img src="https://grafana.com/media/blog/explore-logs/explore-logs.gif" alt="A GIF showing how to use Explore Logs in Grafana"></a></figure><p>When you come into Explore Logs (in the navigation, head over to <strong>Explore</strong> &gt; <strong>Logs</strong>), you are presented with a list of detected services or apps. Engineers no longer have to fight with teams across the organization to standardize on one convention. Instead, we embrace the chaos.</p><p>Services are presented along with their log volumes and a preview of recent log lines, so you can see, at a glance, which services are the most chatty and what kinds of logs they are emitting.</p><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><a href="https://grafana.com/media/blog/explore-logs/recent-log-lines.png" itemprop="contentUrl"><img src="https://grafana.com/media/blog/explore-logs/recent-log-lines.png" alt="Service log volumes and a preview of recent log lines" data-src="/media/blog/explore-logs/recent-log-lines.png"></a></figure><p>Don’t see the service you are looking for? Simply search for it with the search bar (plain text search, not LogQL).</p><p>As if automatic service detection wasn’t enough, things start to get really interesting when you select a service.</p><h2 id="how-to-breakdown-logs-in-a-service">How to breakdown logs in a service&nbsp;</h2><p>Explore Logs provides tools to further visualize and breakdown a service’s logs by labels, detected fields, and patterns, all while making sure the log lines themselves are always just a click away.</p><ul><li><strong>Labels</strong> are key-value pairs that can be attached to log lines, for example: <code>level=error</code>, <code>environment=prod</code>, <code>app=nginx</code>, <code>team=loki</code></li><li><strong>Detected fields</strong> contain structured key-value pairs extracted automatically from a log line at query time.</li><li><strong>Patterns</strong> are templates automatically derived from the log stream, used to match lines of the same type. New innovations here have led to some powerful capabilities described below.</li></ul><p>Let’s explore (get it?) each of these in turn, and see how Explore Logs makes it easier than ever to make use of these features.</p><h3 id="labels">Labels</h3><p>In Loki, <a href="https://grafana.com/docs/loki/latest/get-started/labels/">labels</a> are key-value pairs that are used to organize and identify log streams. Labels are attached to log streams to help users query, filter, and aggregate logs efficiently. They are similar to tags or metadata in other logging systems.</p><p>Explore Logs creates a log volume chart for each label, allowing you to easily see which are the most active.</p><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><a href="https://grafana.com/media/blog/explore-logs/labels.png" itemprop="contentUrl"><img src="https://grafana.com/media/blog/explore-logs/labels.png" alt="Log volume charts for each label in Loki" data-src="/media/blog/explore-logs/labels.png"></a></figure><p>Selecting a label shows you a breakdown of the logs per value. For example, log level is broken down into debug, info, warning, error, and critical.</p><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><a href="https://grafana.com/media/blog/explore-logs/logs-per-value.png" itemprop="contentUrl"><img src="https://grafana.com/media/blog/explore-logs/logs-per-value.png" alt="Logs-per-value panels in Loki" data-src="/media/blog/explore-logs/logs-per-value.png"></a></figure><p>Selecting a value applies the filter (by writing LogQL for you in the background) and immediately jumps to a curated view showing the relevant log lines.</p><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><a href="https://grafana.com/media/blog/explore-logs/curated-view.png" itemprop="contentUrl"><img src="https://grafana.com/media/blog/explore-logs/curated-view.png" alt="A curated view of log lines" data-src="/media/blog/explore-logs/curated-view.png"></a></figure><h3 id="detected-fields">Detected fields</h3><p>Detected fields in Loki refer to fields that are automatically extracted from log messages when they’re ingested. Loki doesn’t index the content of log lines, but it can parse and extract fields from logs at query time. This feature allows users to query logs more efficiently by using these fields without the need to label every possible attribute as labels, which could be costly and inefficient.</p><p>Explore Logs offers a seamless experience when dealing with detected metadata. A selection of the fields is automatically broken out into a grid view, and you can filter the logs down from there.</p><p>To the end user, the mechanics work nearly identically when working with labels and detected fields, reducing the cognitive overhead of having to remember which is which (and the query syntax associated with each one).</p><figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"><a href="https://grafana.com/media/blog/explore-logs/detected-fields.png" itemprop="contentUrl"><img src="https://grafana.com/media/blog/explore-logs/detected-fields.png" alt="Detected field panels in Loki" data-src="/media/blog/explore-logs/detected-fields.png"></a></figure><h3 id="pattern-matching">Pattern matching</h3><p>Loki extracts log patterns, which helps you understand the different types of log lines produced by your services. Pattern extraction occurs after filtering. For best results, we recommend that you first filter by known values (such as labels, detected fields, and time range) to narrow down the search space and make patterns more useful.</p><p>You can use pattern matching to:</p><ol><li>Understand the kinds of log lines produced by your systems</li><li>Hide noisy or irrelevant lines to quickly narrow down on what’s important</li><li>Focus on specific trends or anomalies by filtering for log lines matching one or more of the patterns</li></ol><p>Explore Logs lets you easily add multiple patterns to your filters, which will include log lines matching any of the selected patterns. You can also exclude a pattern to hide that kind of log line.</p><h4 id="example-use-case-for-pattern-matching">Example use case for pattern matching&nbsp;</h4><p>Say you’re looking for errors among a lot of HTTP traffic logs. It can be tough to spot the individual lines you’re looking for. With patterns, you can simply mute the offending lines by excluding lines of that type at the click of a button.</p><p>Consider the example log lines below. You can clearly see two distinct patterns:</p><div><pre data-expanded="false"><code>code=200 method=get path=/page1 trace_id=123
code=500 method=post path=/page2 trace_id=124
err: code=500 msg=”db connection error” trace_id=124
code=201 method=post path=/page2 trace_id=125
code=200 method=get path=/page1 trace_id=126
code=500 method=post path=/page2 trace_id=127
err: code=500 msg=”db connection error” trace_id=127
code=200 method=get path=/page2 trace_id=128
code=200 method=get path=/page2 trace_id=129
code=500 method=post path=/page2 trace_id=130
err: code=500 msg=”db connection error” trace_id=130</code></pre></div><p>The first pattern describes the HTTP requests:</p><div><pre data-expanded="false"><code>code=&lt;_&gt; method=&lt;_&gt; path=/&lt;_&gt; trace_id=&lt;_&gt;</code></pre></div><p>And the second pattern describes the error lines:</p><div><pre data-expanded="false"><code>err: code=&lt;_&gt; msg=”&lt;_&gt;” trace_id=&lt;_&gt;</code></pre></div><p>The values are stripped away, leaving only string constants and LogQL placeholders that make up the template, or pattern.</p><blockquote><p><strong>Did you know?</strong> In <a href="https://github.com/grafana/loki" target="_blank" rel="noopener noreferrer">Loki 3.0</a>, you can use <a href="https://grafana.com/docs/loki/latest/query/#pattern-match-filter-operators">pattern filters</a> in place of RegExp for a faster query time.</p></blockquote><h2 id="what-else-can-you-do-with-explore-logs">What else can you do with Explore Logs?</h2><p>In addition to everything we’ve already covered, there are a few other notable Explore Logs features to call out:</p><h3 id="search">Search</h3><p>Maybe LogQL is hard, but text search is not. Plain text, case-sensitive search of your rendered log lines can come in handy when you’ve narrowed your search far enough.</p><h3 id="copy-url">Copy URL</h3><p>Easily share your current Explore Logs context with a teammate, to help troubleshoot in a team environment.</p><h3 id="open-in-explore">Open in Explore&nbsp;</h3><p>Is there a feature in Explore that you really like that doesn’t exist in Explore Logs yet? Would LogQL be really helpful for you at this point? Easily jump into <a href="https://grafana.com/docs/grafana/latest/explore/">Explore</a> — our UI for data exploration of hundreds of data sources, including Loki — while preserving your current context.</p><h2 id="how-explore-logs-works">How Explore Logs works</h2><p>We can probably agree this looks really cool, and it’s a pretty different experience from Explore. But, how can it actually help developers?&nbsp;</p><p>Well, how does solving observability problems faster sound? Faster to close that P1, faster to know what hotfix to push to prod, faster back to bed. Let’s show you how.</p><p>Suppose you need to identify a misbehaving pod in one of your services. You can certainly get that information using LogQL and Explore — construct a LogQL metrics query that counts errors by service, and see which one pops up. But is it the <em>easiest</em> way?</p><p>Not anymore! Now you can:</p><ul><li>Start by selecting your service</li><li>Select the <code>level</code> label selector, then add <code>level=error</code> to your filter criteria</li><li>Select the <code>pod</code> label selector, then see all impacted pods and their error rates</li><li>With just one more click, see the log lines associated with these pods</li></ul><p>Just a handful of clicks, with visual cues at each step of the way and —&nbsp;once more with feeling — <em>without writing LogQL</em>.</p><h2 id="special-thanks">Special thanks</h2><p>Explore Logs was the result of shared empathy, creativity, and hard work. We’d like to recognize all the contributors to Explore Logs so far:</p><ul><li><a href="https://github.com/cyriltovena" target="_blank" rel="noopener noreferrer">cyriltovena</a></li><li><a href="https://github.com/gtk-grafana" target="_blank" rel="noopener noreferrer">gtk-grafana</a></li><li><a href="https://github.com/ivanahuckova" target="_blank" rel="noopener noreferrer">ivanahuckova</a></li><li><a href="https://github.com/L2D2grafana" target="_blank" rel="noopener noreferrer">L2D2grafana</a></li><li><a href="https://github.com/matryer" target="_blank" rel="noopener noreferrer">matryer</a></li><li><a href="https://github.com/matyax" target="_blank" rel="noopener noreferrer">matyax</a></li><li><a href="https://github.com/sandeepsukhani" target="_blank" rel="noopener noreferrer">sandeepsukhani</a></li><li><a href="https://github.com/shantanualsi" target="_blank" rel="noopener noreferrer">shantanualsi</a></li><li><a href="https://github.com/svennergr" target="_blank" rel="noopener noreferrer">svennergr</a></li><li><a href="https://github.com/trevorwhitney" target="_blank" rel="noopener noreferrer">trevorwhitney</a></li><li><a href="https://github.com/zizzpudding" target="_blank" rel="noopener noreferrer">zizzpudding</a></li></ul><h2 id="try-it-for-yourself">Try it for yourself!</h2><p>Explore Logs is available to preview today. You can learn more in the <a href="https://github.com/grafana/explore-logs" target="_blank" rel="noopener noreferrer">Explore Logs GitHub repository</a>. You can also try it out by installing from the repo and using Explore Logs with <a href="https://grafana.com/blog/2024/04/09/grafana-11-release-all-the-new-features/">Grafana 11</a> and <a href="https://grafana.com/blog/2024/04/09/grafana-loki-3.0-release-all-the-new-features/">Loki 3.0</a>, both of which were <a href="https://grafana.com/blog/2024/04/09/grafanacon-2024-a-guide-to-all-the-announcements-from-grafana-labs/">announced at GrafanaCON 2024</a>.</p><p>Or you can also take Explore Logs for a spin in the <a href="https://play.grafana.org/a/grafana-lokiexplore-app/explore?mode=start&amp;patterns=&amp;var-patterns=&amp;logId=&amp;var-filters=" target="_blank" rel="noopener noreferrer">Grafana Play environment</a>.&nbsp;</p><p>Please let us know what you would like to see improved or added with the <strong>Give Feedback</strong> button in Explore Logs, or you can engage more deeply in the repo itself!</p><p>We are excited to partner with our community and to build the easiest Loki + Grafana experience together!</p><p><em>Learn all about the <a href="https://grafana.com/blog/2024/04/09/grafana-loki-3.0-release-all-the-new-features">latest features in Loki 3.0</a>, our open source log aggregation tool.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[India’s electric rickshaws (121 pts)]]></title>
            <link>https://restofworld.org/2024/e-rickshaw-yc-electric-india/</link>
            <guid>39979375</guid>
            <pubDate>Tue, 09 Apr 2024 13:45:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://restofworld.org/2024/e-rickshaw-yc-electric-india/">https://restofworld.org/2024/e-rickshaw-yc-electric-india/</a>, See on <a href="https://news.ycombinator.com/item?id=39979375">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<!-- Article Start -->
				
<p>At a small factory just north of Delhi, a welder named Ram Baran spends several hours each day training his coworkers in metal cutting, molding, and shaping bodies of three-wheeler electric vehicles.</p>



<p>Baran is not an engineer by education. He started working at the factory in 2017 as a helper — dusting, cleaning, and organizing items. A year later, he got the opportunity to upskill and get trained in welding by Chinese engineers. Nearly 80% of Baran’s 200 co-workers have followed a similar trajectory. “[They] taught us all the work,” Baran told <em>Rest of World. </em>“They taught us welding — how to put the parts and cut them<em>.</em> Over time, I picked up the work and got promoted. Now, our people can also teach these things.”&nbsp;</p>



<p>Each month, this upskilled team at the factory in Sonipat — 40 kilometers from New Delhi — produces bodies and chassis for nearly 5,000 three-wheeler EVs, locally known as e-rickshaws, for the New Delhi-based YC Electric, India’s second-largest manufacturer in the segment. In 2023, YC Electric alone sold over 40,600 e-rickshaws, while <a href="https://www.smev.in/statistics">82,500<strong> </strong>electric cars</a> were sold in the country.</p>



<p>Even as India awaits its first Tesla, these humble e-rickshaws made by workers like Baran are powering an EV revolution in the country. In the last decade, around 1.73 million three-wheeler EVs have <a href="https://cleanmobilityshift.com/ev-dashboard/">been sold</a> in India. Just last month, around 500 manufacturers — most of them homegrown — sold over 44,000 e-rickshaws, compared to less than 6,800 electric cars sold during the month.</p>



<figure></figure>



<p>Unlike the four-wheeler and two-wheeler industries, which are controlled by popular brands like Tata, Ola, and Ather Energy, three of the top five brands in the e-rickshaw segment — YC Electric, Dilli Electric Auto, and Saera Electric —&nbsp;have little to no brand recall.&nbsp;</p>



<p>“Big-name companies won’t set foot in the e-rickshaw industry,” YC Electric’s director, Pawan Kakkar, told <em>Rest of World. </em>“They know it’s not their segment. The buyer is not looking for aesthetics. [The vehicle] should be durable.”</p>



<p>YC Electric was born in 2014 out of a partnership between Kakkar and his partner Sanjeev Pahwa’s cycle-rickshaw company and a traditional <em>tuk-tuk</em> manufacturer. The founders took advantage of the Indian government’s push for local manufacturing around the time, and set up two assembly units in Noida and Kolkata. They started manufacturing in Sonipat by 2016. “I had the network, and, more importantly, I knew what cycle-rickshaw drivers need,” Kakkar said.</p>



<p>A favorable policy environment has been crucial for the three-wheeler EV revolution in India, according to Lizbeth Jibi Godwin, research associate at the Center for Public Policy and Research (CPPR). “The subsidies and exemptions from obtaining permits for EVs have made electric three-wheelers an attractive option,” Godwin told <em>Rest of World</em>. “Additionally, the increasing demand for last-mile connectivity in public transport, such as buses and metro services, has led to a rise in electric three-wheelers.”</p>



<p>Even while government policies have spurred local EV manufacturing, the industry continues to be fueled by Chinese connections for sourcing parts, technical know-how, and even training the workforce.</p>


	<figure>
		<div>
			<ul>
				<li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/05/3E0A5344-copy-40x27.jpeg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/05/3E0A5344-copy-768x432.jpeg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/05/3E0A5344-copy-400x267.jpeg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/05/3E0A5344-copy-600x400.jpeg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/05/3E0A5344-copy-1000x667.jpeg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/05/3E0A5344-copy-1600x1067.jpeg 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/05/3E0A5344-copy-2800x1867.jpeg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="A photograph of an unfinished 3-wheeler in the middle of a warehouse, surrounded by bins and metal components.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li><li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/3E0A5364-copy-40x27.jpeg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/3E0A5364-copy-768x432.jpeg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/3E0A5364-copy-400x267.jpeg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/3E0A5364-copy-600x400.jpeg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/3E0A5364-copy-1000x667.jpeg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/3E0A5364-copy-1600x1067.jpeg 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2024/04/3E0A5364-copy-2800x1867.jpeg 2800w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="A photograph of a man in a tattered and dirty long sleeve shirt and a yellow construction helmet, standing in a warehouse near stacks of a large metal objects.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li>
			</ul>
		</div>
		<figcaption>At the factory in Sonipat, a team of workers produces nearly 5,000 three-wheeler EVs for YC Electric each month.</figcaption>
	</figure>


<p>The Sonipat plant where YC builds its e-rickshaws is a joint venture with the company’s former Chinese import partners Jiang Li and Xue Jian Nan, who hold a 49% stake in the facility. <em>“</em>The link [with the Chinese suppliers] became so good that they also believed in us, invested money with us, and shared technology with us<em>,</em>” Kakkar said. Chinese engineers stayed “for days” to train welders like Baran when the factory first opened, he said.</p>



<p>His company’s ethos, according to Kakkar, is “Make in India, but technology from China.”</p>



<p>This dependence on China is not unique to YC Electric.</p>



<p>Saera Electric, a direct competitor of YC Electric, produces nearly 95% of its vehicles locally, but some parts, like the natural magnet for the motor and critical minerals for the battery, have to come from China because they do not naturally occur in India, Sudip Banerjee, the company’s planning and strategy head, told <em>Rest of World</em>.<em> </em>He said that things could slowly change as <a href="https://www.businesstoday.in/latest/economy/story/jharkhand-emerges-as-the-latest-hub-of-lithium-reserves-in-india-400491-2023-10-03">more lithium reserves</a> are found across the country.</p>



<p>“As far as the information available and from the disclosure cited, there is no Indian EV company completely free of China,” D Dhanuraj, founder and chairman for CPPR, told <em>Rest of World</em>.&nbsp;</p>



<figure><blockquote><p>“Big-name companies won’t set foot in the e-rickshaw industry; they know it’s not their segment."</p></blockquote></figure>



<p>Kakkar said the company’s focus on tech has helped it reach its current scale. In the financial year ending March 2024, YC Electric clocked revenue of over 6.5 billion rupees ($78 million), Kakkar said.</p>



<p>“From the first day, we decided we’ll work on the tech. We will not treat this like a cycle rickshaw. So whatever changes were done [to the vehicle], YC Electric did it first,” Kakkar said. For instance, he said, the company customized the vehicle’s tire size and improved its suspension to meet the requirements of Indian roads. “We got the first-mover advantage. And then we took another step — to collaborate with the Chinese.”</p>



<p>The China connection, though, is often hindered by geopolitical tensions. For instance, YC’s next champion product — a high-speed electric auto like the ones its larger rival Mahindra makes — is stuck after border conflicts soured relations between the two neighbors. The development of the new vehicle — which <em>Rest of World</em> snuck a peek at while it was being tested at the Sonipat factory — has been stunted because “people are not able to come from [China]. Business visas are also not being given,” Kakkar said. India has reportedly put a <a href="https://economictimes.indiatimes.com/industry/cons-products/electronics/visa-delays-for-chinese-professionals-hit-india-businesses/articleshow/100834085.cms?from=mdr">strict visa approval process</a> in place for Chinese professionals, causing delays.</p>



<p>The Indian government has been trying to boost local production<strong> </strong>and reduce dependency on China with policies like a performance-linked incentive for manufacturing and the promotion of advanced chemistry cells for the local production of <a href="https://pib.gov.in/PressReleasePage.aspx?PRID=1946679#:~:text=In%20order%20to%20reduce%20dependency,a%20period%20of%205%20years.">lithium-ion batteries, </a>independent public transport expert Ravi Gadepalli, who works with the World Bank and Asian Development Bank, told <em>Rest of World</em>. But a long-term vision is lacking, Dhanuraj of CPPR said. He believes a lot more clarity and incentives need to be given to research institutions and private companies working on filling gaps in the domestic supply chain.&nbsp;</p>



<p>At YC, meanwhile, there has been a concerted effort to bring in domestic companies to upskill staff and provide material, the Sonipat plant’s general manager, Vidya Sagar Singh, told <em>Rest of World</em>. Tata Steel and JSW Steel, industry leaders in steel manufacturing, have organized training sessions for workers at the plant, with more such workshops planned, he said. Many of the parts at YC’s Noida and Kolkata assembly plants now come from local manufacturers: seats from Jemco, tires from CEAT and MRF, and suspension from HSL Enterprises.</p>
				<!-- Article End -->
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Supreme Commander Graphics Study (2015) (120 pts)]]></title>
            <link>http://www.adriancourreges.com/blog/2015/06/23/supreme-commander-graphics-study/</link>
            <guid>39979140</guid>
            <pubDate>Tue, 09 Apr 2024 13:18:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.adriancourreges.com/blog/2015/06/23/supreme-commander-graphics-study/">http://www.adriancourreges.com/blog/2015/06/23/supreme-commander-graphics-study/</a>, See on <a href="https://news.ycombinator.com/item?id=39979140">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
<img src="http://www.adriancourreges.com/img/blog/2015/supcom/supcom-logo.png">
</p>
<p><a href="https://en.wikipedia.org/wiki/Total_Annihilation">Total&nbsp;Annihilation</a> has a special place in my heart since it was the very first RTS I played;
it was with <a href="https://en.wikipedia.org/wiki/Command_%26_Conquer_%281995_video_game%29">Command&nbsp;&amp;&nbsp;Conquer</a> and <a href="https://en.wikipedia.org/wiki/StarCraft">Starcraft</a> one of the best RTS released in the late 90’s.</p>
<p>10 years later – in 2007 – its successor was released: <a href="https://en.wikipedia.org/wiki/Supreme_Commander_%28video_game%29">Supreme Commander</a>.<br>
With <a href="https://en.wikipedia.org/wiki/Chris_Taylor_%28game_designer%29">Chris&nbsp;Taylor</a> as the designer, <a href="https://mavorsrants.blogspot.com/">Jonathan Mavor</a>
in charge of the engine programming and <a href="https://en.wikipedia.org/wiki/Jeremy_Soule">Jeremy Soule</a> as the music composer (some of the main figures behind the original Total Annihilation), the expectations of the fans were very high.</p>
<p>Supreme Commander turned out to be highly praised by critics and players, with nice features like the “strategic zoom” or physically realistic ballistic.</p>
<p>So let’s see how Moho, the engine powering SupCom, renders a frame of the game! <br>
Since <a href="https://github.com/baldurk/renderdoc">RenderDoc</a> doesn’t support DirectX 9 games, reverse-engineering was done with the good old <a href="https://en.wikipedia.org/wiki/PIX_%28Microsoft%29">PIX</a>.</p>
<h2>Terrain Structure</h2>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-00-map-overview.jpg" width="200/"></p>
<p>Before we dig into the frame rendering, it’s important to first talk about how terrains are built in SupCom and which technique is used.</p>
<p>Here is an overview of “Finn’s Revenge”, a 1 versus 1 map.</p>
<p>On the left is a top-view of the entire map like it appears in-game on the mini-map.<br>
Below is the same map viewed from another angle:</p>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-98.jpg"></p>
<p>First the geometry of the terrain is calculated from an <a href="https://en.wikipedia.org/wiki/Heightmap">heightmap</a>.<br>
The heightmap describes the elevation of the terrain. A white color represents a high altitude and a dark one a low altitude.<br>
For our map, a 513x513 single-channel image is used, it represents a terrain
of 10x10 km in-game. SupCom supports much larger maps, up to 81x81 km.</p>
<table>
<tbody><tr>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-03-heightmap.jpg">
</p>
<p>Heightmap</p>
</div>
</td>
<td>
<img src="http://www.adriancourreges.com/img/arrow-right.png">
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-15-wireframe.jpg">
</p>
<p>Tessellated Terrain</p>
</div>
</td>
</tr>
</tbody></table>

<p>So we have a mesh which represents our terrain.<br>
Then the game applies an albedo texture combined with a normal texture to cover all these polygons.<br>
For each map the sea level is also specified so the game modulates the albedo color of the pixels under the sea surface to give them a blue tint.</p>
<div id="a_map_tessellation">
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-15-wireframe.jpg">
</p>
<p>Wireframe Terrain</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-20-no-water-color.jpg">
</p>
<p>Albedo + Normal Textures</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-30-stratum1-off.jpg">
</p>
<p>Sea Level Color Modulation</p>
</div>
</div>

<p>Okay so having altitude-based texturing is nice, but it gets limiting quite quickly. <br>
How do we add more details and variations to our map?</p>

<p>The technique used is called “<a href="https://en.wikipedia.org/wiki/Texture_splatting">Texture splatting</a>”: the game draws a series of additional albedo+normal textures.
Each step adds what’s called a “stratum” to the terrain.<br>
We already have stratum 0: the terrain with its original albedo+color textures.<br>
To apply the next stratum, we need some extra information: a “splat&nbsp;map”, to tell us where to
draw the new albedo+normal and more importantly where not to draw! Without such a “splat&nbsp;map” also called alpha-map, applying a new stratum would completely cover the previous stratum.
The albedo and normal textures both have their own scaling factor when they are applied to the mesh.</p>
<div id="a_splatmap_frame">
<div>
<table>
<tbody><tr>
<td>
<p>
Base
<br>Stratum #0
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/blank.png">
</p>
<p>No Splatmap</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_albedo_0.jpg">
</p>
<p>Albedo</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_normal_0.jpg">
</p>
<p>Normal</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
</tr>
</tbody></table>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-30-stratum1-off.jpg">
</p>
</div>
</div>
<div>
<table>
<tbody><tr>
<td>
<p>
Applying
<br>Stratum #1
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_splat_1.jpg">
</p>
<p>Splatmap</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_albedo_1.jpg">
</p>
<p>Albedo</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_normal_1.jpg">
</p>
<p>Normal</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
</tr>
</tbody></table>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-40-stratum2-off.jpg">
</p>
</div>
</div>
<div>
<table>
<tbody><tr>
<td>
<p>
Applying
<br>Stratum #2
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_splat_2.jpg">
</p>
<p>Splatmap</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_albedo_2.jpg">
</p>
<p>Albedo</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_normal_2.jpg">
</p>
<p>Normal</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
</tr>
</tbody></table>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-50-stratum3-off.jpg">
</p>
</div>
</div>
<div>
<table>
<tbody><tr>
<td>
<p>
Applying
<br>Stratum #3
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_splat_3.jpg">
</p>
<p>Splatmap</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_albedo_3.jpg">
</p>
<p>Albedo</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_normal_3.jpg">
</p>
<p>Normal</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
</tr>
</tbody></table>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-60-stratum4-off.jpg">
</p>
</div>
</div>
<div>
<table>
<tbody><tr>
<td>
<p>
Applying
<br>Stratum #4
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_splat_4.jpg">
</p>
<p>Splatmap</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_albedo_4.jpg">
</p>
<p>Albedo</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_normal_4.jpg">
</p>
<p>Normal</p>
</div>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png">
</p>
</td>
</tr>
</tbody></table>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-70-no-decals.jpg">
</p>
</div>
</div>
</div>

<p>So we applied strata 1, 2, 3 and 4, each one relying on 3 separate textures.
The albedo and normal textures use 3 channels (RGB) each, but the splat map uses only one channel.<br>
So as an optimization the 4 splat maps are combined into a single RGBA texture.</p>


<p>Okay so we got more texture variations for our terrain. It looks nice from far away, but if
you zoom-in you quickly notice the lack of high-frequency details.</p>
<p>This is when decals are applied: these are like small sprites which modify locally
the albedo color and the normal of a pixel. This terrain has 861 instances of 21 unique decals.</p>
<div id="a_map_decals">
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-70-no-decals.jpg">
</p>
<p>Decals: Before</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-78-no-props.jpg">
</p>
<p>Decals: After</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-79-decals-highlight.jpg">
</p>
<p>Decals Highlight</p>
</div>
</div>

<p>It’s much better but what about some vegetation?<br>
The next step is to add to the terrain what the engine calls “Props”: tree or rock models.
For this map there are 6026 instances of 23 unique models.</p>
<div id="a_map_props">
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-78-no-props.jpg">
</p>
<p>Props: Before</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-95-nosea.jpg">
</p>
<p>Props: After</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-97-props-highlight.jpg">
</p>
<p>Props Highlight</p>
</div>
</div>

<p>Now the final touch: the sea surface. It is a combination of several normal maps with UV scrolling
along different directions, an environment map for reflections and sprites for the waves near the shores.</p>
<div id="a_sea_surface">
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-95-nosea.jpg">
</p>
<p>Sea Surface: Before</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a-98.jpg">
</p>
<p>Sea Surface: After</p>
</div>
</div>

<p>Our terrain is now ready.<br>
Creating good heightmaps and splat maps can be challenging for map designers, but fortunately there
are several tools to help with the task: there is the official “Supcom Map Editor” or <a href="http://www.world-machine.com/">World Machine</a> with even more advanced features.</p>
<p>So now that we know the theory behind the SupCom terrains, let’s move on to an actual frame of the game.</p>
<h2>Frame Breakdown</h2>
<p>This is the game frame we’ll dissect:</p>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_95_final_frame.jpg"></p>
<h3>Frustum Culling</h3>
<p>The game has in RAM the terrain mesh, created from the heightmap, it is tessellated by the CPU and the position of each vertex is known.
When the zoom level changes, the CPU re-calculates the tessellation of the terrain. <br>
Our camera focuses on a scene near the shore. Rendering the whole terrain would be a waste of calculation, so instead the engine extracts a submesh of the whole terrain,
only the portion visible to the player, and feeds this small subset to the GPU for rendering.</p>
<div id="a_frustum_cull">
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_00_frutsumcull_0.jpg">
</p>
<p>Frustum Culling: Before</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_00_frutsumcull_1.jpg">
</p>
<p>Frustum Culling: After</p>
</div>
</div>

<h3>Normal Map</h3>
<p>First, only the normals are calculated.<br>
A first pass computes the normals resulting from the combination of the 5 stratums (5 normal maps and 4 splat maps).<br>
The different normal maps are blended together, all the operations are done in <a href="https://en.wikipedia.org/wiki/Tangent_space">tangent space</a>.</p>
<table>
<tbody><tr>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_01_normal_mesh.png">
</p>
<p>Submesh</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_01_normal_normal5.jpg">
</p>
<p>Normals x5</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_splatmap_combine.jpg">
</p>
<p>Splatmaps</p>
</div>
</td>
<td>
<img src="http://www.adriancourreges.com/img/arrow-right.png">
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_01_terrain_normal.jpg">
</p>
<p>Normal Map</p>
</div>
</td>
</tr>
</tbody></table>

<p>This is done in a single draw call with 6 texture fetches.
You’ll notice the result is quite “yellowish”, it contrasts with the other normal maps which tend to be blue. And indeed: here the Blue channel is not used at all, only the Red and Green.<br>
But wait, a normal is a 3-component vector, how can it be stored only with 2 components? It’s actually a compression technique <a name="supcomNormalSkip"></a>(explained at <a href="#supcomNormalExpl">the end of the post</a>).<br>
For now let’s just assume the Red and Green channels contain all the information we need about the normals.</p>
<p>Stratums are done, now it’s the turn of the decals: terrain decals and building decals are added to modulate the stratum normals.</p>
<div id="b_normal_terrain_decal">
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_01_terrain_normal.jpg">
</p>
<p>Base</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_02_terrain_decal.jpg">
</p>
<p>Base + Terrain Decals</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_03_terrain_build_decal.jpg">
</p>
<p>Base + Terrain Decals + Unit Decals</p>
</div>
</div>

<p>We still haven’t used the Blue and Alpha channels of our render target.<br>
So the game reads from a 512x512 texture representing the whole normals of the terrain (baked from the original heightmap), and calculates for each pixel its normal using a bicubic interpolation.
The results are stored in the Blue and Alpha channels.</p>
<table>
<tbody><tr>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_04_terrain_whole_normal.jpg">
</p>
<p>Normal Map</p>
</div>
</td>
<td>
Bicubic interpolation stored in Blue and Alpha.
<img src="http://www.adriancourreges.com/img/arrow-right.png">
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_04_terrain_normal_reconstruct.jpg">
</p>
<p>Red &amp; Green: Stratum/Decal Normals<br>Blue &amp; Alpha: Base Terrain Normal</p>
</div>
</td>
</tr>
</tbody></table>

<p>Then the game combines these two sets of normals (stratum/decal normals and terrain normals) into the final normals used to calculate the lighting.</p>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_05_terrain_normal_pp.jpg">
</p>
<p>Final Normal Map</p>
</div>
<p>This time there’s no compression: the normals use the 3 RGB channels, one for each component.<br>
It might look very green, but this is because the scene is quite flat, the result is correct: you can take any pixel and calculate its normal vector by doing <code>colorRGB * 2.0 - 1.0</code>, you can also check that the norm of the vector is 1.</p>
<h3>Shadow Map</h3>
<p>The technique used to render the shadows is the <a href="http://www.cg.tuwien.ac.at/research/vr/lispsm/">“Light Space Perspective Shadow Maps”</a> or LiSPSM technique. <br>
Here we just have the sun as a directional light. Each mesh of the scene is rendered, and its distance from the sun is stored into the Red channel of a 1024x1024 texture.
The LiSPSM technique calculates the best projection space to maximize the precision of the shadow map.</p>


<p>If we stop here, we would just be able to draw hard shadows. When the units are rendered, the game actually tries to smooth-out the edges of the shadows
by using some <abbr title="Percentage Closer Filtering">PCF</abbr> sampling.</p>
<p>But even with PCF, there would be no way to obtain the beautiful smooth-shadows we see on the screenshot, especially the smooth silhouettes of the buildings on the ground…
So how was this achieved?</p>
<p>Even during the final parts of the development process of the game, it seems the implementation of shadows was still an on-going effort.
This is what Jonathan Mavor was saying 11 months before the game public release:</p>
<blockquote><p>The shadows in those shots are not finished and we do have a little bit of work to do on them yet. […] <br>We are not finished with the game graphically by any stretch at this point.</p></blockquote>
<p>Just one month after this declaration, a new ground-breaking shadow map technique was emerging: <a href="https://web.archive.org/web/20201124200859/http://www.punkuser.net/vsm/">Variance Shadow Maps</a> or VSM. It was able to render
gorgeous soft shadows very efficiently. <br>
It seems the SupCom team tried to experiment with this new technique: decompiling the D3D bytecode reveals a reference to a <code>DepthToVariancePS()</code> function which computes
a blur version of the shadow map. Before VSM was invented, shadow maps could not and were never blurred. <br>
Here SupCom performs a 5x5 <a href="https://en.wikipedia.org/wiki/Gaussian_blur">Gaussian blur</a> (horizontal and vertical pass) of the shadow map.</p>
<table>
<tbody><tr>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_06_sm_5_100.png">
</p>
<p>LiSPSM</p>
</div>
</td>
<td>
Gaussian Blur
<img src="http://www.adriancourreges.com/img/arrow-right.png">
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_06_sm_9_blur.png">
</p>
<p>Blurred Shadow Map</p>
</div>
</td>
</tr>
</tbody></table>

<p>However in the D3D bytecode, there is no instruction about storing the depth and the squared-depth (information required by the VSM technique).
It seems to be only a partial implementation: maybe there was no time to perfect the technique during the final stages of the development, but anyway the code as-is can
already produce nice results.</p>
<p>Note though that the pseudo-VSM map is used only to produce soft-shadows on the ground.<br>
When a shadow must be drawn onto a unit, it is done through the LiSPSM map with PCF sampling. You can see the difference in the screenshot below (PCF has blocky artifacts at the shadow border):</p>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_06_sm_91_blur_pcflispsm.jpg">
</p>
<p>Different Shadow Map Techniques</p>
</div>
<h3>Shadowed Terrain</h3>
<p>Thanks to the normal map and the shadow map that were generated, it is possible to finally start rendering the terrain: a textured mesh with lighting and shadows.</p>
<table>
<tbody><tr>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_splatmap_combine.jpg">
</p>
<p>SplatMaps</p>
</div>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_water_depth.jpg">
</p>
<p>Water Depth<br>Map</p>
</div>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_07_albedo5.jpg">
</p>
<p>Albedo<br>Textures</p>
</div>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_06_sm_9_blur.png">
</p>
<p>Shadow</p>
</div>
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_05_terrain_normal_pp.jpg">
</p>
<p>Normal</p>
</div>
</td>
</tr>
</tbody></table>
<p><img src="http://www.adriancourreges.com/img/arrow-down.png"></p>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_07_combine.jpg">
</p>
<p>Lighting and Shadow</p>
</div>
<h3>Decals</h3>
<p>The albedo components of the decals are drawn, using the normal information to calculate the lighting equation.</p>
<div id="b_albedo_decals">
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_07_combine.jpg">
</p>
<p>Base</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_08_albedo_decal_terrain.jpg">
</p>
<p>Base + Terrain Decals</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_08_albedo_decal_unit.jpg">
</p>
<p>Base + Terrain Decals + Unit Decals</p>
</div>
</div>

<h3>Water Reflection</h3>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_09_reflection_expl.png"></p>
<p>We have the sea on the right of our scene, so if a robot is sitting in the middle of the water we should be able to see its reflection on the sea surface.</p>
<p>A classic trick exists to render the reflection of a surface: an additional pass is performed, and just before applying the camera transformation, the vertical axis is scaled by -1 so
the entire scene becomes symmetric with regards to the water surface (just like a mirror) which is exactly the transformation needed to render the reflection.
SupCom uses this technique and renders all the mirrored unit meshes into a reflection map.</p>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_09_reflection_map_pp.jpg">
</p>
<p>Reflection Map</p>
</div>
<h3>Mesh Rendering</h3>
<p>All the units are then rendered one by one.
For the vegetation, <a href="https://en.wikipedia.org/wiki/Geometry_instancing">geometry instancing</a> is used to render multiple trees in one draw call.
The sea is rendered using a single quad, with a pixel shader fetching several normal maps, a refraction map (the scene rendered up until now), a
reflection map (just generated above) and a skybox for additional reflection.</p>
<div id="b_all_meshes">
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_08_albedo_decal_unit.jpg">
</p>
<p>Meshes 0%</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_10_1_meshes.jpg">
</p>
<p>Meshes 30%</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_10_2_meshes.jpg">
</p>
<p>Meshes 60%</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_10_9_meshes.jpg">
</p>
<p>Meshes 100%</p>
</div>
</div>

<p>Notice in the last image the small black artifacts of the sea near the screen border: it’s because the sampling of the surface of the water is disrupted to create an illusion of movement.
Sometimes the disruption brings texels from outside the viewport within the viewport: but such information does not exist, hence the black areas.<br>
During the game the UI actually hides these artifacts under a thin border covering the edges of the viewport.</p>
<h3>Mesh Structure</h3>
<p>Each unit in SupCom is rendered in a single draw call. A model is defined by a set of textures:</p>
<ul>
<li>an albedo map</li>
<li>a normal map</li>
<li>a “specular map” which actually contains much more information than the specular. It’s an RGBA texture with:
<ul>
<li>Red: Reflection. How much the environment map is reflected.</li>
<li>Green: Specular. In regards to the sun light.</li>
<li>Blue: Brightness. Used later to control the bloom.</li>
<li>Alpha: Team Color. It modulates the unit albedo depending on the team color.</li>
</ul>
</li>
</ul>


<p><img src="http://www.adriancourreges.com/img/arrow-down.png"></p>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_10_99_final.jpg"></p>
<h3>Particles</h3>
<p>All the particles are then rendered and the health bars of each unit are also added.</p>
<div id="b_11_particles">
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_10_9_meshes.jpg">
</p>
<p>Base Scene</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_11_particles.jpg">
</p>
<p>Base Scene + Particles</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_12_miniui.jpg">
</p>
<p>Base Scene + Particles + Health Bars</p>
</div>
</div>

<h3>Bloom</h3>
<p>Time to make things shine! But how do we get the “brightness information” since we’re working with <abbr title="Low Dynamic Range">LDR</abbr> buffers?<br>
The brightness map is actually contained within the alpha channel, it was being built at the same time the previous meshes were drawn.<br>
A downscaled copy of the frame is created, the alpha channel is used to make only the bright areas stand out and two successive Gaussian blurs are performed.</p>
<table>
<tbody><tr>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_14_bloom_alpha.png">
</p>
<p>Alpha Channel</p>
</div>
</td>
<td>
<img src="http://www.adriancourreges.com/img/arrow-right.png">
</td>
<td>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_14_bloom_blurred.jpg">
</p>
<p>Brightness Blurred</p>
</div>
</td>
</tr>
</tbody></table>

<p>The blurred buffer is then drawn on the top of the original scene with additive blending.</p>
<div id="b_15_bloom">
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_12_miniui.jpg">
</p>
<p>Bloom: Before</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_15_bloom.jpg">
</p>
<p>Bloom: After</p>
</div>
</div>

<h3>User Interface</h3>
<p>We’re done concerning the main scene. The UI is finally rendered, and it is beautifully optimized: a <em>single draw call</em> to render the entire interface.
1158 triangles are pushed at once to the GPU.</p>
<div id="b_96_wireframe">
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_95_final_frame.jpg">
</p>
<p>UI</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/b_96_wireframe.jpg">
</p>
<p>UI (Wireframe Highlight)</p>
</div>
</div>

<p>The pixel shader reads from a single 1024x1024 texture which acts like a <a href="https://en.wikipedia.org/wiki/Texture_atlas">texture atlas</a>. When another unit is selected, the UI is modified,
the texture atlas is regenerated on-the-fly to pack a new set of sprites.</p>
<p>And we’re done for the frame!</p>
<h2>Additional Notes</h2>
<h3>Level of Detail</h3>
<p>Since SupCom supports huge variations in the zoom level, it relies heavily on <a href="https://en.wikipedia.org/wiki/Level_of_detail">level of detail</a> or LOD. <br>
If the player zooms out from the map, the number of visible units quickly increases, to keep up with the increase in GPU load it becomes necessary to render simpler geometry
and smaller textures. Since the units are very far away, the engine can get away with it: models are replaced with <a href="https://en.wikipedia.org/wiki/Low_poly">low-poly</a> versions,
with fewer details but they’re rendered so small on the screen that the
player can hardly see the difference with high-poly models.</p>
<div id="c_lod">
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/c_01_hp_full.jpg">
</p>
<p>LOD High</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/c_01_lp_full.jpg">
</p>
<p>LOD Low</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/c_01_lp_wire.jpg">
</p>
<p>LOD Low - Wireframe</p>
</div>
<div>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/c_01_hp_wire.jpg">
</p>
<p>LOD High - Wireframe</p>
</div>
</div>

<p>LOD does not only concern units: shadows, decals and props stop being rendered beyond a certain distance.</p>
<h3>Fog of War</h3>
<p>Because of the <a href="https://en.wikipedia.org/wiki/Fog_of_war">fog of war</a>, each unit has a line of sight and only the area close to the units is completely visible.
Areas where no units are present are either gray (previously visited) or black (still unexplored).<br>
The game stores the fog information in a 128x128 mono-channel texture which defines the intensity of the fog: 1 means no visibility whereas 0 means full visibility.</p>


<h3><a name="supcomNormalExpl"></a>Normal Compression</h3>
<p><a href="#supcomNormalSkip">As promised</a>, here is a short explanation about the trick used in SupCom to compress normals. <br>
A normal is usually a 3-component vector, however in <a href="https://en.wikipedia.org/wiki/Tangent_space">tangent space</a>, the vector is expressed relatively to the
surface tangent: X and Y are within the tangent plane while the Z component always points away from the surface.<br>
By default the normal is <code>(0, 0, 1)</code> which is why most normal maps appear bluish when the normal is not perturbed.</p>
<p><img src="http://www.adriancourreges.com/img/blog/2015/supcom/shot/a_stratum_normal_0.jpg"></p>
<p>So assuming the normal is a unit-vector, its length is one: <code>X² + Y² + Z² = 1</code>.<br>
If you know the values of X and Y, then Z can only have two possible values: <code>Z = ±√(1 - X² - Y²)</code>.<br>
But since Z always points away from the surface, it has to be positive
and so we have <code>Z = √(1 - X² - Y²)</code>.<br>
That’s why <strong>only storing X and Y in the Red and Green channels is enough</strong>, Z can be derived from them. A more detailed (and better) explanation can be
found in <a href="http://developer.download.nvidia.com/whitepapers/2008/real-time-normal-map-dxt-compression.pdf">this article</a>.</p>
<h3>Normal Blending</h3>
<p>Since we are talking about normals, SupCom performs some kind of <a href="https://en.wikipedia.org/wiki/Linear_interpolation">lerp</a> between normal maps, using the splatmaps as factors.
Actually there are several ways of blending two normal maps, with different results, it is not a straightforward problem like <a href="http://blog.selfshadow.com/publications/blending-in-detail/">this article</a> explains.</p>
<h2>More Links</h2>
<ul>
<li>The <a href="https://mavorsrants.blogspot.com/">blog of Jonathan Mavor</a> has a lot of technical insights and a very nice post about the <a href="https://mavorsrants.blogspot.com/2012/04/total-annihilation-graphics-engine.html">TA Graphics Engine</a>.</li>
<li>The <a href="http://web.archive.org/web/20070807085133/http://www.gamespot.com/features/totalstory/">story behind TA development</a>. Very interesting read from 1998, archived on the Wayback Machine.</li>
<li>Details about <a href="http://supcom.wikia.com/wiki/Height-_/_Texturemaps_with_image_editing_tools">SupCom map editing</a> and modding.</li>
</ul>
<p>More discussion on this very topic: <a href="http://developers.slashdot.org/story/15/06/26/1550227/reverse-engineering-a-frame-of-supreme-commander">Slashdot</a>,
<a href="https://news.ycombinator.com/item?id=9770020">Hacker News</a>,
<a href="https://www.reddit.com/r/programming/comments/3axbnb/supreme_commander_graphics_study_how_it_renders_a/">Reddit</a>.<br>
Also, a print copy of this article <a href="http://www.adriancourreges.com/blog/2015/09/30/print-copy-of-supcom-graphics-study/">has been made available by <em>Hacker Monthly</em></a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Penpot 2.0 Released (114 pts)]]></title>
            <link>https://community.penpot.app/t/penpot-2-0-a-major-milestone-in-our-journey-is-now-yours-to-explore-and-enjoy/4906</link>
            <guid>39978781</guid>
            <pubDate>Tue, 09 Apr 2024 12:40:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://community.penpot.app/t/penpot-2-0-a-major-milestone-in-our-journey-is-now-yours-to-explore-and-enjoy/4906">https://community.penpot.app/t/penpot-2-0-a-major-milestone-in-our-journey-is-now-yours-to-explore-and-enjoy/4906</a>, See on <a href="https://news.ycombinator.com/item?id=39978781">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
              <p>As it’s often the case with major releases, they feel both like the end of a journey and the beginning of a new one.</p>

<p><em>Short clip showing all</em></p>
<p>Let me first cover why <a href="https://penpot.app/penpot-2.0">Penpot 2.0</a> is such an impactful release.</p>
<p>Once again, we delivered on our promise to bring developers and designers closer together. <strong>Our bold movement to build CSS Grid Layout</strong> and enable designers to create responsive interfaces matching coding constructs was unexpected. The design tool space has changed forever.</p>
<p><strong>Component Libraries have been revamped</strong> with a new data structure to help designers and large teams build extensive design systems more modularly. The addition of component swapping as well as more flexible categorisation options provide a significant boost in productivity.</p>
<p>We rebuilt the entire <strong>Penpot’s UI to be sleeker, faster and more beautiful</strong>. This will be obvious to everyone that used Penpot in the past but equally mesmerising to newcomers. Streamlining user experience means allowing for more time spent creating and collaborating at scale, which sits at the core of Penpot’s mission.</p>
<div><a href="https://europe1.discourse-cdn.com/standard20/uploads/penpot/original/2X/f/fd253723f560cacf66fde53bcc0977e47979431b.jpeg" data-download-href="/uploads/short-url/A7qx5hXOxO7zz8v99OaCECgw2Ar.jpeg?dl=1" title="screenshot-interaction"><img src="https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/f/fd253723f560cacf66fde53bcc0977e47979431b_2_690x386.jpeg" alt="screenshot-interaction" data-base62-sha1="A7qx5hXOxO7zz8v99OaCECgw2Ar" width="690" height="386" srcset="https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/f/fd253723f560cacf66fde53bcc0977e47979431b_2_690x386.jpeg, https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/f/fd253723f560cacf66fde53bcc0977e47979431b_2_1035x579.jpeg 1.5x, https://europe1.discourse-cdn.com/standard20/uploads/penpot/original/2X/f/fd253723f560cacf66fde53bcc0977e47979431b.jpeg 2x" data-dominant-color="23252B"></a></div>
<p><em>Penpot 2.0 showing an interactive prototype</em></p>
<p>Each of these features, on its own, would have deserved a major release and yet we have another three major updates.</p>
<ul>
<li>You can now use images as a fill property.</li>
<li>We added HTML generation on top of CSS and SVG.</li>
<li>UI theming is now a reality, starting with Light &amp; Dark.</li>
</ul>
<div><a href="https://europe1.discourse-cdn.com/standard20/uploads/penpot/original/2X/7/7782534368cb5554af51ddfac92d5c2edb5ff362.png" data-download-href="/uploads/short-url/h3e2rZ2gL5R9DkU3OH9NvmLrzdo.png?dl=1" title="workspace-light-dark"><img src="https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/7/7782534368cb5554af51ddfac92d5c2edb5ff362_2_690x456.png" alt="workspace-light-dark" data-base62-sha1="h3e2rZ2gL5R9DkU3OH9NvmLrzdo" width="690" height="456" srcset="https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/7/7782534368cb5554af51ddfac92d5c2edb5ff362_2_690x456.png, https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/7/7782534368cb5554af51ddfac92d5c2edb5ff362_2_1035x684.png 1.5x, https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/7/7782534368cb5554af51ddfac92d5c2edb5ff362_2_1380x912.png 2x" data-dominant-color="8EA3A9"></a></div>
<p><em>Dark or Light themes, we love both!</em></p>
<p>If you want to know all the details of what comes packed with 2.0, including performance improvements and 40+ changes not covered here, head to our <a href="https://penpot.app/dev-diaries">Dev Diaries</a> page.</p>
<p>It took the team 9 months to build and ship this amazing release. We didn’t want to cut corners, we wanted to be proud of our work so you could team up and collaborate around design and code projects with no limitations or compromises.</p>
<p>We are building our own path where concepts such as <a href="https://www.c11n.quest/does-declarative-design-foster-superior-collaboration-with-developers/">declarative design</a>, future-proof ownership of your work and a no-handoff mindset meet long-standing pragmatic design and coding practices.</p>
<p>Our SaaS service at <a href="https://design.penpot.app/">design.penpot.app</a> was the first to roll-out 2.0 a couple of days ago and <a href="https://penpot.app/self-host">self-host images</a> will follow very soon. We will always make sure that, no matter your choice, Penpot delivers the same experience.</p>
<div><a href="https://europe1.discourse-cdn.com/standard20/uploads/penpot/original/2X/f/f33808986c3a8f46b57c5f685543adbd1cf88803.jpeg" data-download-href="/uploads/short-url/yHC4KQ8cxVrBFKaFLBOpF2LH8fF.jpeg?dl=1" title="screenshot-code"><img src="https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/f/f33808986c3a8f46b57c5f685543adbd1cf88803_2_690x386.jpeg" alt="screenshot-code" data-base62-sha1="yHC4KQ8cxVrBFKaFLBOpF2LH8fF" width="690" height="386" srcset="https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/f/f33808986c3a8f46b57c5f685543adbd1cf88803_2_690x386.jpeg, https://europe1.discourse-cdn.com/standard20/uploads/penpot/optimized/2X/f/f33808986c3a8f46b57c5f685543adbd1cf88803_2_1035x579.jpeg 1.5x, https://europe1.discourse-cdn.com/standard20/uploads/penpot/original/2X/f/f33808986c3a8f46b57c5f685543adbd1cf88803.jpeg 2x" data-dominant-color="585858"></a></div>
<p><em>Design-as-code is a reality with Penpot</em></p>
<h2><a name="whats-next-1" href="#whats-next-1"></a>What’s next?</h2>
<p>Delivering Penpot 2.0 required the product team to act almost as a sole entity so interdependencies between new features would not create bottlenecks.</p>
<p>Post 2.0 we are shifting to an “initiatives” approach where smaller autonomous teams can ship upgrades independently. “Design tokens”, “Plugin architecture”, “AI” or “E2E testing framework” are some of them.</p>
<p>Do you want to know everything about Penpot 2.0 and what we’re cooking up next? Do you want to learn from amazing designers and developers that are shaping the industry by driving collaboration forward? Do you want to enjoy our very own PenpotFest in Barcelona, 5-7th June? Make sure to <a href="https://penpotfest.org/">get your early bird tickets</a> while they’re still available!</p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Eclipse via Satellite (167 pts)]]></title>
            <link>https://kieranhealy.org/blog/archives/2024/04/09/the-eclipse-via-satellite/</link>
            <guid>39978723</guid>
            <pubDate>Tue, 09 Apr 2024 12:33:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kieranhealy.org/blog/archives/2024/04/09/the-eclipse-via-satellite/">https://kieranhealy.org/blog/archives/2024/04/09/the-eclipse-via-satellite/</a>, See on <a href="https://news.ycombinator.com/item?id=39978723">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
          <article>
    
    

    
    

    
    <div>
      <p>Yesterday’s eclipse as seen by the <a href="https://www.star.nesdis.noaa.gov/GOES/">GOES-East</a> weather satellite. I just grabbed the full-disk geocolor JPGs with <code>wget</code> and stitched them together with <code>ffmpeg</code>.</p>
<video autoplay="" loop="" muted="" playsinline="" controls="true" width="100%">
    <source src="https://kieranhealy.org/blog/archives/2024/04/09/the-eclipse-via-satellite/eclipse_sm.mp4" type="video/mp4">
    <source src="https://kieranhealy.org/blog/archives/2024/04/09/the-eclipse-via-satellite/eclipse_sm.mov" type="video/mov">
    <source src="https://kieranhealy.org/blog/archives/2024/04/09/the-eclipse-via-satellite/eclipse_sm.webm" type="video/webm">
</video>

    </div>

    

    

    
  </article>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google CodeGemma: Open Code Models Based on Gemma [pdf] (146 pts)]]></title>
            <link>https://storage.googleapis.com/deepmind-media/gemma/codegemma_report.pdf</link>
            <guid>39978717</guid>
            <pubDate>Tue, 09 Apr 2024 12:32:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://storage.googleapis.com/deepmind-media/gemma/codegemma_report.pdf">https://storage.googleapis.com/deepmind-media/gemma/codegemma_report.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=39978717">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Anger is eliminated with the disposal of a paper written because of provocation (135 pts)]]></title>
            <link>https://www.nature.com/articles/s41598-024-57916-z</link>
            <guid>39978653</guid>
            <pubDate>Tue, 09 Apr 2024 12:24:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/s41598-024-57916-z">https://www.nature.com/articles/s41598-024-57916-z</a>, See on <a href="https://news.ycombinator.com/item?id=39978653">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <div id="Sec1-section" data-title="Experiment 1"><h2 id="Sec1">Experiment 1</h2><div id="Sec1-content"><h3 id="Sec2">Introduction</h3><p>The need to control anger has been of importance for a long time in human societies, as inferred by a philosopher in Imperium Romanum who had already explored how to cease being angry<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Seneca, L. A. Seneca Moral Essays, Vol. 1. De ira [Anger] (J. W. Basore, Ed. and Trans.) (Original work published 45) (W. Heinemann, 1928)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR1" id="ref-link-section-d23593774e380">1</a></sup>. However, it can still be challenging to suppress anger effectively. Frequent, unregulated anger often leads to violence towards children<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Rodriguez, C. M. &amp; Green, A. J. Parenting stress and anger expression as predictors of child abuse potential. Child Abuse Negl. 21(4), 367–377. 
                  https://doi.org/10.1016/s0145-2134(96)00177-9
                  
                 (1997)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR2" id="ref-link-section-d23593774e384">2</a></sup>, which has become an increasingly prevalent issue. One study found that the global estimate for children experiencing any form of violence (physical, sexual, emotional, or a combination) in the past year is one billion children aged 2–17&nbsp;years<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Moody, G., Cannings-John, R., Hood, K., Kemp, A. &amp; Robling, M. Establishing the international prevalence of self-reported child maltreatment: A systematic review by maltreatment type and gender. BMC Public Health 18, 1164. 
                  https://doi.org/10.1186/s12889-018-6044-y
                  
                 (2018)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR3" id="ref-link-section-d23593774e388">3</a></sup>. The number of child abuse cases in Japan has reportedly doubled in the past decade<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Child and Family Policy Bureau, Ministry of Health, Labour and Welfare. Trends in the Number of Cases of Child Abuse at Child Guidance Center (accessed 25 January 2023). 
                  https://www.mhlw.go.jp/content/001040752.pdf
                  
                . (in Japanese)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR4" id="ref-link-section-d23593774e392">4</a></sup>. Children learn about appropriate emotional expression and behaviour from their parents<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Denham, S. &amp; Kochanoff, A. T. Parental contributions to preschoolers’ understanding of emotion. Marriage Fam. Rev. 34(3–4), 311–343. 
                  https://doi.org/10.1300/J002v34n03_06
                  
                 (2002)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR5" id="ref-link-section-d23593774e396">5</a></sup>, and children who have been maltreated may lack the opportunity to learn how to regulate anger. Consequently, these maltreated children may have difficulty controlling their own anger<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Heleniak, C., Jenness, J. L., Vander Stoep, A., McCauley, E. &amp; McLaughlin, K. A. Childhood maltreatment exposure and disruptions in emotion regulation: A transdiagnostic pathway to adolescent internalizing and externalizing psychopathology. Cogn. Ther. Res. 40(3), 394–415. 
                  https://doi.org/10.1007/s10608-015-9735-z
                  
                 (2016)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR6" id="ref-link-section-d23593774e401">6</a></sup>, recognising anger in others<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Pollak, S. D., Cicchetti, D., Hornung, K. &amp; Reed, A. Recognizing emotion in faces: Developmental effects of child abuse and neglect. Dev. Psychol. 36(5), 679–688. 
                  https://doi.org/10.1037//0012-1649.36.5.679
                  
                 (2000)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR7" id="ref-link-section-d23593774e405">7</a></sup>, and tend to exhibit externalizing behaviour problems<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Denham, S. A. et al. Prediction of externalizing behavior problems from early to middle childhood: The role of parental socialization and emotion expression. Dev. Psychopathol. 12(1), 23–45. 
                  https://doi.org/10.1017/s0954579400001024
                  
                 (2000)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR8" id="ref-link-section-d23593774e409">8</a></sup>. These studies suggest that parental anger regulation issues negatively affect children’s emotional competence. Therefore, an effective way of reducing anger has been examined throughout the years<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Beames, J. R., O’Dean, S. M., Grisham, J. R., Moulds, M. L. &amp; Denson, T. F. Anger regulation in interpersonal contexts: Anger experience, aggressive behavior, and cardiovascular reactivity. J. Soc. Pers. Relationsh. 36(5), 1441–1458. 
                  https://doi.org/10.1177/0265407518819295
                  
                 (2019)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR9" id="ref-link-section-d23593774e413">9</a></sup>.</p><p>However, simply attempting to suppress anger is usually not effective<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Szasz, P. L., Szentagotai, A. &amp; Hofmann, S. G. The effect of emotion regulation strategies on anger. Behav. Res. Ther. 49(2), 114–119. 
                  https://doi.org/10.1016/j.brat.2010.11.011
                  
                 (2011)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR10" id="ref-link-section-d23593774e420">10</a></sup>. Both cognitive reappraisal and distraction (i.e., thinking about something other than provocative comments) could reduce anger; however, distraction could suppress anger only for a transient period of time<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Fabiansson, E. C. &amp; Denson, T. F. The effects of intrapersonal anger and its regulation in economic bargaining. Plos One 7(12), e51595. 
                  https://doi.org/10.1371/journal.pone.0051595
                  
                 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR11" id="ref-link-section-d23593774e424">11</a></sup>. Cognitive reappraisal refers to the reinterpretation or modification of the meaning of an unpleasant situation. Although reappraisal is considered as an effective way to reduce anger<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Denson, T. F., Moulds, M. L. &amp; Grisham, J. R. The effects of analytical rumination, reappraisal, and distraction on anger experience. Behav. Ther. 43(2), 355–364. 
                  https://doi.org/10.1016/j.beth.2011.08.001
                  
                 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR12" id="ref-link-section-d23593774e428">12</a></sup>, it requires greater cognitive effort<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Kross, E. &amp; Ayduk, O. Self-distancing: Theory, research, and current directions. Adv. Exp. Soc. Psychol. 55(55), 81–136. 
                  https://doi.org/10.1016/bs.aesp.2016.10.002
                  
                 (2017)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR13" id="ref-link-section-d23593774e432">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Orvell, A., Ayduk, O., Moser, J. S., Gelman, S. A. &amp; Kross, E. Linguistic shifts: A relatively effortless route to emotion regulation?. Curr. Dir. Psychol. Sci. 28(6), 567–573. 
                  https://doi.org/10.1177/0963721419861411
                  
                 (2019)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR14" id="ref-link-section-d23593774e435">14</a></sup>. Therefore, reappraisal under stressful situations which require cognitive load was not found to be effective in reducing anger as compared to non-stressful situations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Zhan, J. et al. Regulating anger under stress via cognitive reappraisal and sadness. Front. Psychol. 8, 1372. 
                  https://doi.org/10.3389/fpsyg.2017.01372
                  
                 (2017)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR15" id="ref-link-section-d23593774e439">15</a></sup>. Self-distancing, which may be responsible for the anger-reducing effect of reappraisal<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Denson, T. F., Moulds, M. L. &amp; Grisham, J. R. The effects of analytical rumination, reappraisal, and distraction on anger experience. Behav. Ther. 43(2), 355–364. 
                  https://doi.org/10.1016/j.beth.2011.08.001
                  
                 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR12" id="ref-link-section-d23593774e444">12</a></sup> is also considered as an effective way to reduce anger. Nevertheless, self-distancing or reflection on one’s provocation from a distance is often not feasible, especially in the heat of the moment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Kross, E. &amp; Ayduk, O. Self-distancing: Theory, research, and current directions. Adv. Exp. Soc. Psychol. 55(55), 81–136. 
                  https://doi.org/10.1016/bs.aesp.2016.10.002
                  
                 (2017)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR13" id="ref-link-section-d23593774e448">13</a></sup>.</p><p>Failure to reduce anger can lead an individual to think about a provocative event repeatedly. Such ruminations are often produced in a self-immersed, experiential manner<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Ayduk, O. &amp; Kross, E. From a distance: Implications of spontaneous self-distancing for adaptive self-reflection. J. Pers. Soc. Psychol. 98(5), 809–829. 
                  https://doi.org/10.1037/a0019205
                  
                 (2010)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR16" id="ref-link-section-d23593774e455">16</a></sup>. Self-immersed experiential rumination can lead to reliving past provocative events<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Kross, E., Ayduk, O. &amp; Mischel, W. When asking “why” does not hurt - Distinguishing rumination from reflective processing of negative emotions. Psychol. Sci. 16(9), 709–715. 
                  https://doi.org/10.1111/j.1467-9280.2005.01600.x
                  
                 (2005)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR17" id="ref-link-section-d23593774e459">17</a></sup>, thus maintaining or even increasing subjective anger and vascular responses<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Glynn, L. M., Christenfeld, N. &amp; Gerin, W. Recreating cardiovascular responses with rumination: The effects of a delay between harassment and its recall. Int. J. Psychophysiol. 66(2), 135–140. 
                  https://doi.org/10.1016/j.ijpsycho.2007.03.018
                  
                 (2007)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR18" id="ref-link-section-d23593774e463">18</a></sup>.</p><p>However, among the types of ruminations, writing down a provocation event does not always maintain or increase anger; instead, anger is suppressed depending on the way of writing. For instance, anger was suppressed when participants wrote down the anger-inducing event in a detached, informational, ‘cool’ manner. However, their anger was not suppressed (and was maintained or even increased) when they failed to write down the event in an analytical manner, and wrote it down in a ‘hot’ (emotional) manner<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Denson, T. F., Moulds, M. L. &amp; Grisham, J. R. The effects of analytical rumination, reappraisal, and distraction on anger experience. Behav. Ther. 43(2), 355–364. 
                  https://doi.org/10.1016/j.beth.2011.08.001
                  
                 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR12" id="ref-link-section-d23593774e470">12</a></sup>. Somewhat relevant here is the expressive writing technique<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Pennebaker, J. W. Expressive writing in psychological science. Perspect. Psychol. Sci. 13(2), 226–229. 
                  https://doi.org/10.1177/1745691617707315
                  
                 (2018)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR19" id="ref-link-section-d23593774e474">19</a></sup>, which is frequently used in emotion-focused psychotherapy treatment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Fuentes, A. M. M., Kahn, J. H. &amp; Lannin, D. G. Emotional disclosure and emotion change during an expressive-writing task: Do pronouns matter?. Curr. Psychol. 40, 1672–1679. 
                  https://doi.org/10.1007/s12144-018-0094-2
                  
                 (2021)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR20" id="ref-link-section-d23593774e478">20</a></sup>. It is believed to be effective in suppressing anger in clinical settings. However, only one experimental study using this technique has been conducted, wherein it was found that there was a significant likelihood of reduced anger when sentences about the emotion were written in the past tense<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Pasupathi, M., Wainryb, C., Mansfield, C. D. &amp; Bourne, S. The feeling of the story: Narrating to regulate anger and sadness. Cogn. Emotion 31(3), 444–461. 
                  https://doi.org/10.1080/02699931.2015.1127214
                  
                 (2017)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR21" id="ref-link-section-d23593774e482">21</a></sup>. These studies suggest that anger may be successfully suppressed if individuals are able to separate their internal experience of provocative events from their sense of self<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Bernstein, A. et al. Decentering and related constructs: A critical review and metacognitive processes model. Perspect. Psychol. Sci. 10(5), 599–617. 
                  https://doi.org/10.1177/1745691615594577
                  
                 (2015)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR22" id="ref-link-section-d23593774e486">22</a></sup>. Healy et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Healy, H. A. et al. An experimental test of a cognitive defusion exercise: Coping with negative and positive self-statements. Psychol. Record 58(4), 623–640. 
                  https://doi.org/10.1007/bf03395641
                  
                 (2008)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR23" id="ref-link-section-d23593774e491">23</a></sup> reported that negative self-referential statements (‘my life is pointless’), when presented in a defused format (‘I am having a thought that my life is pointless’), could decrease the emotional discomfort related to that statement.</p><p>These previous studies emphasised the cognitive processes (such as goals or valuations) that occur almost entirely inside individuals’ heads<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Koole, S. L. &amp; Veenstra, L. Does emotion regulation occur only inside people’s heads? Toward a situated cognition analysis of emotion-regulatory dynamics. Psychol. Inq. 26(1), 61–68. 
                  https://doi.org/10.1080/1047840x.2015.964657
                  
                 (2015)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR24" id="ref-link-section-d23593774e499">24</a></sup>. However, if we look at the literature more broadly, studies on emotion regulation (a situated cognitive approach) have demonstrated successful emotion control through dynamic interplay between the person and the situation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Koole, S. L. &amp; Veenstra, L. Does emotion regulation occur only inside people’s heads? Toward a situated cognition analysis of emotion-regulatory dynamics. Psychol. Inq. 26(1), 61–68. 
                  https://doi.org/10.1080/1047840x.2015.964657
                  
                 (2015)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR24" id="ref-link-section-d23593774e503">24</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Gross, J. J. Emotion regulation: Current status and future prospects. Psychol. Inq. 26(1), 1–26. 
                  https://doi.org/10.1080/1047840x.2014.940781
                  
                 (2015)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR25" id="ref-link-section-d23593774e506">25</a></sup>. From this situated cognition perspective, people perceive their environment in terms of the possibilities for the kinds of actions that they would pursue. These functional features of the environment (affordances) do not solely exist inside an individual’s mind but instead have a physical reality that exists in the individual’s relationship with the environment. For instance, people frequently use physical substances to modify their moods. People may take a hot shower when they feel lonely<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Bargh, J. A. &amp; Shalev, I. The substitutability of physical and social warmth in daily life. Emotion 12(1), 154–162. 
                  https://doi.org/10.1037/a0023527
                  
                 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR26" id="ref-link-section-d23593774e510">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Shalev, I. &amp; Bargh, J. On the association between loneliness and physical warmth-seeking through bathing: Reply to Donnellan et al. (2014) and three further replications of Bargh and Shalev (2012) study 1. Emotion 15(1), 120–123. 
                  https://doi.org/10.1037/emo0000014
                  
                 (2015)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR27" id="ref-link-section-d23593774e513">27</a></sup> or hold a teddy bear when they feel afraid<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Koole, S. L., Sin, M. T. A. &amp; Schneider, I. K. Embodied terror management: Interpersonal touch alleviates existential concerns among individuals with low self-esteem. Psychol. Sci. 25(1), 30–37. 
                  https://doi.org/10.1177/0956797613483478
                  
                 (2013)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR28" id="ref-link-section-d23593774e517">28</a></sup>. Such access to physical objects can significantly modify individuals’ ability to manage their emotions.</p><p>In this study, we developed a new anger reduction strategy inspired by the situated cognition approach to emotion regulation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Koole, S. L. &amp; Veenstra, L. Does emotion regulation occur only inside people’s heads? Toward a situated cognition analysis of emotion-regulatory dynamics. Psychol. Inq. 26(1), 61–68. 
                  https://doi.org/10.1080/1047840x.2015.964657
                  
                 (2015)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR24" id="ref-link-section-d23593774e524">24</a></sup>. Relevant to this approach, the notion of a grounded procedure of separation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Lee, S. W. S. &amp; Schwarz, N. Grounded procedures: A proximate mechanism for the psychology of cleansing and other physical actions. Behav. Brain Sci. 44, e1. 
                  https://doi.org/10.1017/s0140525x20000308
                  
                 (2021)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR29" id="ref-link-section-d23593774e528">29</a></sup> also assumes that mental representations and functions are grounded in one’s own experiences and interactions with physical reality. For instance, if people want to take revenge through permanent removal (e.g. hatred for ex), they may destroy a related entity such that it is no longer recognisable (burn, melt, or tear related). In a related study, Briñol et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Brinol, P., Gasco, M., Petty, R. E. &amp; Horcajo, J. Treating thoughts as material objects can increase or decrease their impact on evaluation. Psychol. Sci. 24(1), 41–47. 
                  https://doi.org/10.1177/0956797612449176
                  
                 (2013)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR30" id="ref-link-section-d23593774e532">30</a></sup> reported that writing down negative thoughts about a Mediterranean diet on a piece of paper and disposing of the paper in a trash can result in lower negative (more positive) evaluations of the diet, compared to a group that kept the paper in a booklet. These attitude changes may derive from the cognitive fusion that people often fuse with physical objects, such as jewellery, cars, and family heirlooms<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Hatvany, T., Burkley, E. &amp; Curtis, J. Becoming part of me: Examining when objects, thoughts, goals, and people become fused with the self-concept. Soc. Personal. Psychol. Compass 12(1), e12369. 
                  https://doi.org/10.1111/spc3.12369
                  
                 (2018)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR31" id="ref-link-section-d23593774e536">31</a></sup>. Such fused objects are valued more and are less likely to be abandoned because doing so means losing a part of themselves<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Belk, R. W. Possessions and the extended self. J. Consum. Res. 15(2), 139–168. 
                  https://doi.org/10.1086/209154
                  
                 (1988)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR32" id="ref-link-section-d23593774e540">32</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Reb, J. &amp; Connolly, T. Possession, feelings of ownership and the endowment effect. Judgm. Decis. Mak. J. 2(2), 107–114 (2007)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR33" id="ref-link-section-d23593774e543">33</a></sup>. Specifically, throwing an object associated with negative emotions (anger) may result in losing the negative emotions (anger). However, to the best of our knowledge, no study has tested whether the disposal of anger-written paper can reduce or even eliminate anger.</p><p>Previous studies from a situated cognitive approach to anger management have changed the external environment of the individual in anger. Tool (object) use has received scant attention in these situated cognition approaches to anger management, except for a few studies, such as hitting a punching bag<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Bushman, B. J. Does venting anger feed or extinguish the flame? Catharsis, rumination, distraction, anger, and aggressive responding. Personal. Soc. Psychol. Bull. 28(6), 724–731. 
                  https://doi.org/10.1177/0146167202289002
                  
                 (2002)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR34" id="ref-link-section-d23593774e550">34</a></sup> and playing a video game<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Denzler, M., Hafner, M. &amp; Forster, J. He just wants to play: How goals determine the influence of violent computer games on aggression. Personal. Soc. Psychol. Bull. 37(12), 1644–1654. 
                  https://doi.org/10.1177/0146167211421176
                  
                 (2011)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR35" id="ref-link-section-d23593774e554">35</a></sup>. This study examined a method in which the disposal of a paper (object) on which participants wrote down their descriptions or thoughts about a provocative event could neutralise anger. Participants threw the anger-written paper into a trash box in Experiment 1, and put the paper into a shredder in Experiment 2. If the action of disposal is crucial to modifying emotions, anger would be reduced only in participants in Experiment 1 but not in Experiment 2, as predicted by the grounded separation procedure<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Lee, S. W. S. &amp; Schwarz, N. Grounded procedures: A proximate mechanism for the psychology of cleansing and other physical actions. Behav. Brain Sci. 44, e1. 
                  https://doi.org/10.1017/s0140525x20000308
                  
                 (2021)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR29" id="ref-link-section-d23593774e558">29</a></sup>. Nevertheless, if anger was modified by the meaning of disposal, the subjective ratings of anger would be eliminated in both experiments. The disposal of the paper with the written descriptions would remove the psychological existence of anger for the provoked participants along with the disposal of paper by the dynamic interactions with the object<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Koole, S. L. &amp; Veenstra, L. Does emotion regulation occur only inside people’s heads? Toward a situated cognition analysis of emotion-regulatory dynamics. Psychol. Inq. 26(1), 61–68. 
                  https://doi.org/10.1080/1047840x.2015.964657
                  
                 (2015)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR24" id="ref-link-section-d23593774e562">24</a></sup>. This simple method of eliminating anger could potentially contribute to effective parental anger management toward their children.</p><h3 id="Sec3">Materials and method</h3><h4 id="Sec4">Participants</h4><p>A total of 57 students (women = 21, mean age = 21.11, <i>SD</i> = 1.05) from a local university participated in this experiment. The data from seven participants were excluded from the final analysis because they correctly guessed the purpose of the experiment and they did not express induced anger by insult (subjective ratings of anger were lower or the same compared to those of the baseline), as was the case in a previous study<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Mauss, I. B., Cook, C. L. &amp; Gross, J. J. Automatic emotion regulation during anger provocation. J. Exp. Soc. Psychol. 43(5), 698–711. 
                  https://doi.org/10.1016/j.jesp.2006.07.003
                  
                 (2007)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR36" id="ref-link-section-d23593774e581">36</a></sup>. Our final analysis included 50 participants (women = 16, mean age = 21.10, <i>SD</i> = 1.08). A sample size of 50 participants was determined by G*Power 3.1.9.4<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Faul, F., Erdfelder, E., Lang, A. G. &amp; Buchner, A. G*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences. Behav. Res. Methods 39(2), 175–191. 
                  https://doi.org/10.3758/bf03193146
                  
                 (2007)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR37" id="ref-link-section-d23593774e588">37</a></sup> using the a priori procedure for repeated measures ANOVA, within (periods)—between (disposal and retention) interaction with the parameters of 95% power, an expected effect size of 0.25 (defined as a medium effect by Cohen<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Cohen, J. Statistical Power Analysis for the Behavioral Sciences 2nd edn. (Routledge, 1988). 
                  https://doi.org/10.4324/9780203771587
                  
                ." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR38" id="ref-link-section-d23593774e592">38</a></sup>), alpha level of 0.05, a within-subjects measurement correlation of 0.5, and a nonsphericity correction ε of 1. The calculation suggested a sample size of 22 participants in each group. Based on these analyses, we concluded that the sample size was appropriate for this study.</p><h4 id="Sec5">Materials</h4><p>Angry feelings were assessed with five adjective items: angry, bothered, annoyed, hostile, and irritated. These adjectives were previously used as measures of self-reported anger<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Mischkowski, D., Kross, E. &amp; Bushman, B. J. Flies on the wall are less aggressive: Self-distancing “in the heat of the moment” reduces aggressive thoughts, angry feelings and aggressive behavior. J. Exp. Soc. Psychol. 48(5), 1187–1191. 
                  https://doi.org/10.1016/j.jesp.2012.03.012
                  
                 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR39" id="ref-link-section-d23593774e604">39</a></sup>. In this study, each response scale ranged from 1 (not at all) to 6 (extremely). As was the case in a previous study on anger<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Kubo, K., Okanoya, K. &amp; Kawai, N. Apology isn’t good enough: An apology suppresses an approach motivation but not the physiological and psychological anger. Plos One 7(3), e33006. 
                  https://doi.org/10.1371/journal.pone.0033006
                  
                 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR40" id="ref-link-section-d23593774e608">40</a></sup>, scores on these five adjectives were  averaged to form an anger experience composite, which was the score used in the analysis (Cronbach’s α = 0.90). We also used Positive and Negative Affect Schedule (PANAS) as a subjective scale to assess mainly negative feelings<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Cohen, J. Statistical Power Analysis for the Behavioral Sciences 2nd edn. (Routledge, 1988). 
                  https://doi.org/10.4324/9780203771587
                  
                ." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR38" id="ref-link-section-d23593774e612">38</a></sup>. We used the Japanese version of the 6-point PANAS scale<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Sato, T. &amp; Yasuda, A. Development of the Japanese version of positive and negative affect schedule (PANAS) scales. Japan J. Pers. 9(2), 138–139. 
                  https://doi.org/10.2132/jjpjspp.9.2_138
                  
                 (2001) (in Japanese)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR41" id="ref-link-section-d23593774e616">41</a></sup>.</p><h4 id="Sec6">Procedure</h4><p>In this experiment, participants' subjective emotional states were measured at three time points (baseline, post-provocation, and post-writing). The participants were told to write an essay on social problems (e.g., smoking in public) for which they would receive feedback from a doctoral student assessing the quality of the essay. They had seen the doctoral student before entering the experimental room. After the participants wrote the essay, they completed the PANAS and anger questionnaires for the baseline. The evaluation by the fictitious doctoral student was then provided to the participants. The evaluation included ratings of the essay on six characteristics using a 9-point scale (e.g. for intelligence, 1 = unintelligent, 9 = intelligent). All participants were given the following ratings: intelligence = 3, interest = 3, friendliness = 2, logic = 3, respectability = 4, and rationality = 3. Each essay was also provided with the following comment: ‘I cannot believe an educated person would think like this. I hope this person learns something while at the university’<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Kubo, K., Okanoya, K. &amp; Kawai, N. Apology isn’t good enough: An apology suppresses an approach motivation but not the physiological and psychological anger. Plos One 7(3), e33006. 
                  https://doi.org/10.1371/journal.pone.0033006
                  
                 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR40" id="ref-link-section-d23593774e628">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Harmon-Jones, E. &amp; Sigelman, J. State anger and prefrontal brain activity: Evidence that insult-related relative left-prefrontal activation is associated with experienced anger and aggression. J. Personal. Soc. Psychol. 80(5), 797–803. 
                  https://doi.org/10.1037/0022-3514.80.5.797
                  
                 (2001)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR42" id="ref-link-section-d23593774e631">42</a></sup>. All of these manipulations were successfully used in our previous study<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Kubo, K., Okanoya, K. &amp; Kawai, N. Apology isn’t good enough: An apology suppresses an approach motivation but not the physiological and psychological anger. Plos One 7(3), e33006. 
                  https://doi.org/10.1371/journal.pone.0033006
                  
                 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR40" id="ref-link-section-d23593774e635">40</a></sup>. The participants were required to read the feedback ratings and comments silently for two minutes. Then, they filled out the subjective emotional questionnaires (PANAS and anger adjectives) for the post-provocation period.</p><p>Then, the participants were asked to write every thought of them on receiving the feedback and were given three minutes for this. The instruction was ‘Think about the event from your own perspective. Concentrate especially on the things that originally triggered the emotions and your reactions’. We added guide questions (‘Why were you feeling this way?’, ‘What made you feel this way?’) to induce analytical rumination. To allow the participants to write about their honest feelings, they were informed that the written paper would not be seen by anyone, including the experimenter. After writing, the participants were asked to review the sentences carefully for 30&nbsp;s. For the retention group, the paper was turned over, put in a clear plastic folder, and placed on the right side of the desk. The participants in the disposal group rolled up the paper into a crumpled ball, stood up, threw the paper into the trash can held by the experimenter, and sat back in the chair. Finally, both groups of participants filled out the subjective emotional questionnaires (anger adjectives and PANAS) for the post-writing period. At the end of the experiment, all participants were debriefed and informed of the truth. They were also assured that the evaluations of their essays had been prepared in advance.</p><h3 id="Sec7">Data analyses</h3><p>Angry feelings were analysed using a 2 (group: disposal or retention) × 3 (period: at baseline, post-provocation, and post-writing) ANOVA. All significance levels were set at <i>p</i> &lt; 0.05. We used the Greenhouse–Geisser correction when Mauchly’s test of sphericity was violated. When the interaction was significant, multiple comparisons using the Bonferroni correction method were used to assess the differences.</p><p>We also report Bayes factors (BFs) from the Bayesian repeated measures ANOVA in <i>JASP</i><sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="JASP Team. (2020). JASP (Version 0.7) [Computer software]. 
                  https://jasp-stats.org
                  
                " href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR43" id="ref-link-section-d23593774e659">43</a></sup>. For BFs, BF<sub>10</sub> values reflect the probability of an alternative relative to the null hypothesis. BFs greater than 3 indicate support for the hypotheses. A BF favouring the alternative over the null hypothesis (BF<sub>10</sub>) offers strong evidence for the alternative hypothesis when it is over 10. Values less than 0.33 indicate support for the null hypothesis, and values between 0.33 and 3 indicate data insensitivity. We also reported 95%  confidence intervals.</p><p>We aimed to examine (1) whether angry feelings resumed in the disposal group, and (2) whether angry feelings were different between the groups after the disposal or retention treatments. Our main interest was angry feelings, while we also verified PANAS scores using a 2 (group: disposal or retention) × 3 (period: at baseline, post-provocation, and post-writing) ANOVA.</p><h4 id="Sec8">Ethics statement</h4><p>All participants were paid for their participation and had provided written informed consent in accordance with the procedures before participation. The study was approved by the Ethics Committee of the Department of Cognitive and Psychological Sciences at Nagoya University (201104-C-02–02). All methods were carried out in accordance with the ethical guidelines of the Declaration of Helsinki. All participants provided their written and informed consent prior to starting the study.</p><h3 id="Sec9">Results</h3><h4 id="Sec10">Anger experience</h4><p>The left panel of Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-024-57916-z#Fig1">1</a> shows mean subjective ratings of anger for disposal and retention groups at three time points (baseline, post-provocation, and post-writing). Subjective ratings of anger of both groups increased at the post-provocation (<i>M</i><sub><i>disposal</i></sub> = 3.34, <i>SD</i> = 1.20, 95% CI [2.86, 3.82]; <i>M</i><sub><i>retention</i></sub> = 3.45, <i>SD</i> = 1.11, 95% CI [3.00, 3.89]) from the baseline (<i>M</i><sub><i>disposal</i></sub> = 1.59, <i>SD</i> = 0.50, 95% CI [1.39, 1.79]; <i>M</i><sub><i>retention</i></sub> = 1.78, <i>SD</i> = 0.71, 95% CI [1.50, 2.07]). Subjective ratings at the post-writing decreased from the post-provocation, however those of retention group were still higher than the baseline (<i>M</i><sub><i>retention</i></sub> = 2.64, <i>SD</i> = 0.95, 95% CI [2.26, 3.02]), while those of disposal group eliminated at the same level of the baseline (<i>M</i><sub><i>disposal</i></sub> = 1.87, <i>SD</i> = 0.71, 95% CI [1.59, 2.16]). A 2 (group: disposal or retention) × 3 (period: at baseline, post-provocation, and post-writing) mixed model analysis of variance (ANOVA) revealed a significant main effect of period [<i>F</i> (2, 96) = 73.36, <i>p</i> &lt; 0.001, partial <i>η</i><sup>2</sup> = 0.60, BF<sub>10</sub> &gt; 100], while a main effect of group was&nbsp;not significant [<i>F</i> (1, 48) = 3.21, <i>p</i> &gt; 0.05, partial <i>η</i><sup><i>2</i></sup> = 0.06, BF<sub>10</sub> = 0.66]. The interaction between group and period was significant [<i>F</i> (2, 96) = 3.12, <i>p</i> &lt; 0.05, partial <i>η</i><sup><i>2</i></sup> = 0.06, BF<sub>10</sub> = 1.17]. Multiple comparisons with the Bonferroni method revealed that the subjective anger was significantly higher at the post-provocation than those at the baseline (<i>p</i> &lt; 0.05), indicating that a provocative manipulation was exerted. Subjective ratings of anger post-writing decreased significantly, compared to post-provocation (<i>p</i> &lt; 0.05). Importantly, however, subjective ratings of retention group at the post-writing period were still significantly higher than those of the baseline period (<i>p</i> &lt; 0.05), whereas those of disposal group at the post-writing period eliminated to levels of the baseline period (<i>p</i> &gt; 0.05). Subjective ratings of disposal group at the post-writing period were significantly lower than those of retention group (<i>p</i> &lt; 0.01).</p><div data-test="figure" data-container-section="figure" id="figure-1" data-title="Figure 1"><figure><figcaption><b id="Fig1" data-test="figure-caption-text">Figure 1</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41598-024-57916-z/figures/1" rel="nofollow"><picture><img aria-describedby="Fig1" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-024-57916-z/MediaObjects/41598_2024_57916_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="262"></picture></a></div><p>Self-reported anger during Experiment 1 (left) and Experiment 2 (right). Significant differences emerged at the end of time due to experimental manipulations. Possible values for anger range from 1 to 6. Each vertical line illustrates the 95% confidence intervals for each group.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41598-024-57916-z/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span></a></p></figure></div><h4 id="Sec11">Negative and positive affect</h4><p>The negative affect subscale of the PANAS at post-provocation (<i>M</i><sub><i>disposal</i></sub> = 3.10, <i>SD</i> = 1.00, 95% CI [2.70, 3.49]; <i>M</i><sub><i>retention</i></sub> = 3.06, <i>SD</i> = 1.03, 95% CI [2.64, 3.47]) was higher than at baseline (<i>M</i><sub><i>disposal</i></sub> = 2.45, <i>SD</i> = 0.66, 95% CI [2.18, 2.71]; <i>M</i><sub><i>retention</i></sub> = 2.50, <i>SD</i> = 0.84, 95% CI [2.16, 2.83]) and post-writing (<i>M</i><sub><i>disposal</i></sub> = 2.06, <i>SD</i> = 0.65, 95% CI [1.80, 2.32]; <i>M</i><sub><i>retention</i></sub> = 2.39, <i>SD</i> = 0.88, 95% CI [2.04, 2.73]). The 95% CIs of the disposal group overlapped a little bit between post-provocation [2.70, 3.49] and baseline periods [2.18, 2.71], and those of the retention group overlapped between both the post-provocation [2.64, 3.47] and baseline [2.16, 2.83]. The 95% CIs for the post-writing means partially overlapped between the groups. A 2 (group) × 3 (period) mixed ANOVA revealed a significant main effect of period [<i>F</i> (2, 96) = 28.64, <i>p</i> &lt; 0.001, partial <i>η</i><sup><i>2</i></sup> = 0.37, BF<sub>10</sub> &gt; 100]. However, the main effect of group [<i>F</i> (1, 48) = 0.29, <i>p</i> &gt; 0.05, partial <i>η</i><sup><i>2</i></sup> = 0.01, BF<sub>10</sub> = 0.32] and the interaction between group and period were not significant [<i>F</i> (2, 96) = 1.35, <i>p</i> &gt; 0.05, partial <i>η</i><sup><i>2</i></sup> = 0.03, BF<sub>10</sub> = 0.31]. Multiple comparisons with the Bonferroni method revealed that the subjective negative affect post-provocation was&nbsp;significantly higher than at baseline and post-writing (<i>ps</i> &lt; 0.05).</p><p>The PANAS positive affect subscale showed little variation at three periods (<i>M</i><sub><i>disposal</i></sub> = 2.33, <i>SD</i> = 0.80, 95% CI [2.01, 2.65]; <i>M</i><sub><i>retention</i></sub> = 2.32, <i>SD</i> = 0.75, 95% CI [2.01, 2.62]), post-provocation (<i>M</i><sub><i>disposal</i></sub> = 2.44, <i>SD</i> = 0.76, 95% CI [2.13, 2.75]; <i>M</i><sub><i>retention</i></sub> = 2.42, <i>SD</i> = 0.89, 95% CI [2.06, 2.78]), and post-writing (<i>M</i><sub><i>disposal</i></sub> = 2.38, <i>SD</i> = 0.87, 95% CI [2.03, 2.73]; <i>M</i><sub><i>retention</i></sub> = 2.27, <i>SD</i> = 0.83, 95% CI [1.93, 2.60]). A 2 × 3 mixed ANOVA revealed that neither main effects nor interaction was significant (<i>Fs</i> &lt; 0.90, <i>ps</i> &gt; 0.41, BF<sub>10</sub>s &lt; 0.14).</p><h3 id="Sec12">Discussion</h3><p>This study examined whether writing about the provocative event and disposing of the paper into a trash can would suppress anger. The provocation treatments evoked anger in both the groups similarly. Nevertheless, the retention group still showed significantly higher anger compared to levels at the baseline period, while the disposal group completely eliminated their anger after the disposal of the anger-written paper. These results suggest that the disposal of the paper containing ruminated anger into the trash can neutralise anger. Our interpretation is that the act of throwing the paper with ruminated anger into the trash can produces a feeling similar to the psychological existence (anger) being discarded, leading to anger elimination, since the psychological entity (anger) was disposed along with the physical object (anger-written paper).</p><p>One may argue that it was not the disposal itself but the physical distance played a critical role in reducing anger. Since the paper was distanced from participants in the disposal group, whereas the paper in the retention group was located by them. Nevertheless, Zhang et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Zhang, Y., Risen, J. L. &amp; Hosey, C. Reversing one’s fortune by pushing away bad luck. J. Exp. Psychol. General 143(3), 1171–1184. 
                  https://doi.org/10.1037/a0034023
                  
                 (2014)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR44" id="ref-link-section-d23593774e1018">44</a></sup> showed that engaging in an avoidance action rather than creating physical distance was critical for reversing the perceived effect of negative thoughts. In their study (Experiment 5), participants in avoidance action conditions either threw the ball to the opposite corner of the room (creating physical distance between themselves and the ball), or pretended to throw the ball (creating no distance between themselves and the ball). Participants in the no-avoidance action condition either carried the ball to the opposite corner of the room and left it there (creating physical distance between the self and the ball without involving a throwing action) or held the ball in their non-dominant hand (creating no distance). Participants in both avoidance action conditions reversed the negative thoughts, while participants in both no-avoidance conditions did not. Avoidance actions were crucial in their study. Therefore, the physical distance would not contribute to reduce anger in this study. However, disposal action might be the key to neutralising anger in this study. Nevertheless, we assume that the meaning (i.e. interpretation) of disposal is more important than the action itself. Other studies have also suggested that the meaning of an action is critical for determining its impact, not the action itself<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Brinol, P., Gasco, M., Petty, R. E. &amp; Horcajo, J. Treating thoughts as material objects can increase or decrease their impact on evaluation. Psychol. Sci. 24(1), 41–47. 
                  https://doi.org/10.1177/0956797612449176
                  
                 (2013)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR30" id="ref-link-section-d23593774e1022">30</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Brinol, P., Petty, R. E. &amp; Wagner, B. Body posture effects on self-evaluation: A self-validation approach. Eur. J. Soc. Psychol. 39(6), 1053–1064. 
                  https://doi.org/10.1002/ejsp.607
                  
                 (2009)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR45" id="ref-link-section-d23593774e1025">45</a></sup>. This study could not exclude throwing action's potential contribution to neutralising anger. Thus, we conducted another experiment to exclude the potential contribution of the throwing action as much as possible, confirm the effectiveness of the disposal method, and explore the variation in this method.</p></div></div><div id="Sec13-section" data-title="Experiment 2"><h2 id="Sec13">Experiment 2</h2><div id="Sec13-content"><h3 id="Sec14">Introduction</h3><p>Experiment 1 indicated that the disposal of a piece of paper containing the description of an anger-inducing experience into the trash can neutralise anger. However, it was unclear what aspect of the paper’s disposal neutralised anger. Although we interpreted the meaning of the action as critical to neutralising anger, the physical distance between the participant and the paper or the action itself (i.e. embodied cognition) might have played a critical role. We set up the second experiment: (1) to replicate the results of Experiment 1; (2) to exclude the embodied explanation as much as possible; and (3) to explore another version of the disposal method using a shredder on the desk. In this experiment, we asked participants to put the paper containing anger into the shredder instead of throwing it into the trash can which was kept at some distance from the participants. We also made a small change to the retention group. Participants of retention group put the paper into a clear box on the desk, and the disposal group put the paper into the shredder. Thus, the distance between the participants and the paper and the type of action were matched between the two groups. If the sensorimotor experience of throwing the paper was critical to neutralise anger, we would not be able to replicate the results of Experiment 1. Nevertheless, if the meaning of the disposal of a physical entity plays a critical role in reducing anger, we anticipated obtaining similar results. In line with our prediction, the attitude changed when the paper was transferred to a box labelled ‘trash can’, which indicated mentally discarding it, compared to a box labelled ‘safety box’<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Kim, T. W., Duhachek, A., Briñol, P. &amp; Petty, R. E. Protect or hide your thoughts: The meanings associated with actions matter. In NA-Advances in Consumer Research (eds Cotte, J. &amp; Wood, S.) 96–100 (ACR, 2014)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR46" id="ref-link-section-d23593774e1042">46</a></sup>, suggesting that the perceived meaning of actions, and not the actions per se, influence attitude change. Hence, we designed a new study to confirm whether the perceived meaning of action eliminates anger. We predicted that putting the paper in a shredder would reduce negative emotions (anger), as compared to keeping the paper.</p><h3 id="Sec15">Method</h3><h4 id="Sec16">Participants</h4><p>A total of 48 participants (women = 24, mean age = 26.81, <i>SD</i> = 9.42) were participated through worker dispatching company and a local university. There was no overlap between the participants of the two experiments. This sample size was determined using G*Power 3.1.9.4<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Faul, F., Erdfelder, E., Lang, A. G. &amp; Buchner, A. G*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences. Behav. Res. Methods 39(2), 175–191. 
                  https://doi.org/10.3758/bf03193146
                  
                 (2007)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR37" id="ref-link-section-d23593774e1061">37</a></sup> using the a priori procedure for repeated measures ANOVA, within (periods)–between (disposal and retention) interaction with the parameters of 95% power, an expected effect size of 0.25 (defined as a medium effect by Cohen<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Cohen, J. Statistical Power Analysis for the Behavioral Sciences 2nd edn. (Routledge, 1988). 
                  https://doi.org/10.4324/9780203771587
                  
                ." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR38" id="ref-link-section-d23593774e1065">38</a></sup>), alpha level of 0.05, a within-participants measurement correlation of 0.5, and a nonsphericity correction ε of 1. The calculation suggested a sample size of 22 participants in each group. Based on these analyses, we concluded that the sample size was appropriate for this study. As in Experiment 1, the data of two participants were excluded from the final analysis because they correctly guessed the purpose of the experiment and did not express anger by insult (subjective ratings of anger were lower or the same as those at the baseline). Our final analysis included 46 participants (women = 23, mean age = 26.39, <i>SD</i> = 9.14).</p><h4 id="Sec17">Materials</h4><p>As in Experiment 1, angry feelings were assessed using five adjectives: angry, bothered, annoyed, hostile, and irritated. Responses ranged from 1 (not at all) to 6 (extremely). Scores on these five adjectives will be averaged to form an anger experience composite, which is the score used in the analyses. We also used the Japanese version of the 6-point PANAS scale as a subjective scale to assess mainly negative feelings<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Kubo, K., Okanoya, K. &amp; Kawai, N. Apology isn’t good enough: An apology suppresses an approach motivation but not the physiological and psychological anger. Plos One 7(3), e33006. 
                  https://doi.org/10.1371/journal.pone.0033006
                  
                 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR40" id="ref-link-section-d23593774e1080">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Sato, T. &amp; Yasuda, A. Development of the Japanese version of positive and negative affect schedule (PANAS) scales. Japan J. Pers. 9(2), 138–139. 
                  https://doi.org/10.2132/jjpjspp.9.2_138
                  
                 (2001) (in Japanese)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR41" id="ref-link-section-d23593774e1083">41</a></sup>.</p><p>For the disposal group, a dustbin-type shredder (ACCO Brands Japan Corp, GSHA26MB) was used. This shredder (30&nbsp;cm × 10&nbsp;cm × 28&nbsp;cm) cuts paper into pieces of 2&nbsp;mm × 14&nbsp;mm on putting the paper in from the top. The lower part of the shredder holds a transparent dustbin, so that the pieces of paper can be observed from the outside. For the retention group, a hand-made clear plastic box (23&nbsp;cm × 5&nbsp;cm × 30&nbsp;cm) was used. Paper can be placed from the top, as with the shredder. Furthermore, as with the lower part of the shredder, the box is also transparent so that the paper in the box can be observed from the outside.</p><h4 id="Sec18">Procedure</h4><p>This experiment followed the same method used in Experiment 1 with slight changes. The words “while at university” were removed from the provocative comment (‘I cannot believe an educated person would think like this. I hope this person learns something while at university’<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Kubo, K., Okanoya, K. &amp; Kawai, N. Apology isn’t good enough: An apology suppresses an approach motivation but not the physiological and psychological anger. Plos One 7(3), e33006. 
                  https://doi.org/10.1371/journal.pone.0033006
                  
                 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR40" id="ref-link-section-d23593774e1098">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Harmon-Jones, E. &amp; Sigelman, J. State anger and prefrontal brain activity: Evidence that insult-related relative left-prefrontal activation is associated with experienced anger and aggression. J. Personal. Soc. Psychol. 80(5), 797–803. 
                  https://doi.org/10.1037/0022-3514.80.5.797
                  
                 (2001)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR42" id="ref-link-section-d23593774e1101">42</a></sup>, because non-students participated in this study. The second change was the method of disposing or retaining the paper containing a description of the anger-inducing experience. After participants wrote down provocative events in an analytical manner, a transparent box or a transparent shredder bin was placed on the desk in front of them (Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-024-57916-z#Fig2">2</a>), before they were asked to review the sentences carefully for 30&nbsp;s. Then, participants were required to put the paper into the box, with the frontside of the paper facing them. Participants in the disposal group watched as the paper was cut in the shredder for five seconds. Participants in the retention group were required to enclose the paper in a clear file folder and place it in a transparent box showing their written sentences. Then, they observed the paper carefully for five seconds. Subsequently, the box was turned back to show the blank side of the paper. All participants rated their anger and provided responses to the PANAS after these treatments.</p><div data-test="figure" data-container-section="figure" id="figure-2" data-title="Figure 2"><figure><figcaption><b id="Fig2" data-test="figure-caption-text">Figure 2</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41598-024-57916-z/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-024-57916-z/MediaObjects/41598_2024_57916_Fig2_HTML.jpg?as=webp"><img aria-describedby="Fig2" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41598-024-57916-z/MediaObjects/41598_2024_57916_Fig2_HTML.jpg" alt="figure 2" loading="lazy" width="685" height="457"></picture></a></div><p>Pictures of experimental manipulations in Experiment 2. The disposal group (left) put the paper into the shredder, while the retention group (right) put the paper into the transparent box.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41598-024-57916-z/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span></a></p></figure></div><h3 id="Sec19">Results</h3><h4 id="Sec20">Anger experience</h4><p>The right panel of Fig.&nbsp;<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41598-024-57916-z#Fig1">1</a> shows the mean subjective anger ratings for the disposal and retention groups at the three time points (baseline, post-provocation, and post-writing). This pattern of results is similar to that of Experiment 1. Subjective ratings of anger in both groups increased after provocation (<i>M</i><sub><i>disposal</i></sub> = 3.14, <i>SD</i> = 1.38, 95% CI [2.56, 3.72]; <i>M</i><sub><i>retention</i></sub> = 3.24, <i>SD</i> = 1.04, 95% CI [2.80, 3.67]) from baseline (<i>M</i><sub><i>disposal</i></sub> = 1.57, <i>SD</i> = 0.75, 95% CI [1.25, 1.88]; <i>M</i><sub><i>retention</i></sub> = 1.64, <i>SD</i> = 0.59, 95% CI [1.40, 1.89]). Subjective ratings at post-writing decreased from post-provocation. However, those of the retention group were still higher than those of the baseline (<i>M</i><sub><i>retention</i></sub> = 2.75, <i>SD</i> = 1.05, 95% CI [2.31, 3.19]), while those of the disposal group were eliminated at the same level as the baseline (<i>M</i><sub><i>disposal</i></sub> = 1.98, <i>SD</i> = 0.87, 95% CI [1.62, 2.35]). Only a small overlap (0.04) was observed in the 95% CI for the mean post-writing scores between the groups. A 2 (group: disposal or retention) × 3 (period: at baseline, post-provocation, and post-writing) mixed model ANOVA revealed a significant main effect of period [<i>F</i> (2, 88) = 56.93, <i>p</i> &lt; 0.001, partial <i>η</i><sup><i>2</i></sup> = 0.56, BF<sub>10</sub> &gt; 100], while the main effect of group was&nbsp;not significant [<i>F</i> (1, 44) = 1.68, <i>p</i> &gt; 0.05, partial <i>η</i><sup><i>2</i></sup> = 0.04, BF<sub>10</sub> = 0.46]. The interaction between group and period was significant [<i>F</i> (2, 88) = 3.49, <i>p</i> &lt; 0.05, partial <i>η</i><sup><i>2</i></sup> = 0.07, BF<sub>10</sub> = 1.62]. Multiple comparisons with the Bonferroni method revealed that subjective anger was significantly higher at post-provocation than baseline (<i>p</i> &lt; 0.05), indicating that provocative manipulation was exerted. Subjective ratings of anger at post-writing decreased significantly compared to post-provocation (<i>p</i> &lt; 0.05). However, the subjective ratings of the retention group in the post-writing period were still maintained at the same level of anger as those of the post-provocation period (<i>p</i> &gt; 0.05). Contrastingly, those of the disposal group in the post-writing period were significantly lower than those of the post-provocation period (<i>p</i> &lt; 0.05).</p><p>Additionally, as was the result of Experiment1, the subjective ratings of the retention group in the post-writing period were significantly higher than those of the baseline period (<i>p</i> &lt; 0.05). Those of the disposal group in the post-writing period were eliminated to the baseline period (<i>p</i> &gt; 0.05). The subjective ratings of the disposal group in the post-writing period were significantly lower than those of the retention group (<i>p</i> &lt; 0.05).</p><h4 id="Sec21">Negative and positive affect</h4><p>The negative affect subscale of the PANAS at post-provocation (<i>M</i><sub><i>disposal</i></sub> = 3.34, <i>SD</i> = 1.09, 95% CI [2.88, 3.79]; <i>M</i><sub><i>retention</i></sub> = 3.35, <i>SD</i> = 0.89, 95% CI [2.98, 3.73]) was higher than at baseline (<i>M</i><sub><i>disposal</i></sub> = 2.60, <i>SD</i> = 0.78, 95% CI [2.27, 2.93]; <i>M</i><sub><i>retention</i></sub> = 2.73, <i>SD</i> = 0.92, 95% CI [2.34, 3.11]) and post-writing (<i>M</i><sub><i>disposal</i></sub> = 2.45, <i>SD</i> = 0.96, 95% CI [2.05, 2.85]; <i>M</i><sub><i>retention</i></sub> = 2.57, <i>SD</i> = 0.87, 95% CI [2.20, 2.93]). The 95% CIs of the disposal group overlapped a little bit between post-provocation [2.88, 3.79] and baseline periods [2.27, 2.93], and those of the retention group overlapped between both the post-provocation [2.98, 3.73] and baseline [2.34, 3.11]. A 2 (group) × 3 (period) mixed ANOVA revealed a significant main effect of period [<i>F</i> (2, 88) = 20.19, <i>p</i> &lt; 0.01, partial <i>η</i><sup><i>2</i></sup> = 0.68, BF<sub>10</sub> &gt; 100]. However, the main effect of the group [<i>F</i> (1, 44) = 0.15, <i>p</i> &gt; 0.05, partial <i>η</i><sup><i>2</i></sup> = 0.06, BF<sub>10</sub> = 0.33] and the interaction between group and period were not significant [<i>F</i> (2, 88) = 1.35, <i>p</i> &gt; 0.05, partial <i>η</i><sup><i>2</i></sup> = 0.05, BF<sub>10</sub> = 0.13]. Multiple comparisons with the Bonferroni method revealed that the subjective negative affect post-provocation was&nbsp;significantly higher than at baseline and post-writing (<i>ps</i> &lt; 0.05).</p><p>The positive affect subscale of the PANAS showed little variation at the three-time points (<i>M</i><sub><i>disposal</i></sub> = 2.88, <i>SD</i> = 1.03, 95% CI [2.44, 3.31]; <i>M</i><sub><i>retention</i></sub> = 2.57, <i>SD</i> = 0.89), 95% CI [2.19, 2.94], post-provocation (<i>M</i><sub><i>disposal</i></sub> = 2.49, <i>SD</i> = 0.86, 95% CI [2.13, 2.85]; <i>M</i><sub><i>retention</i></sub> = 2.51, <i>SD</i> = 0.94, 95% CI [2.12, 2.90]), and post-writing (<i>M</i><sub><i>disposal</i></sub> = 2.49, <i>SD</i> = 0.97, 95% CI [2.08, 2.89]; <i>M</i><sub><i>retention</i></sub> = 2.64, <i>SD</i> = 1.02, 95% CI [2.21, 3.06]). A 2 × 3 mixed ANOVA revealed that neither the main effects nor interaction were significant (<i>Fs</i> &lt; 2.28, <i>ps</i> &gt; 0.11, BF<sub>10</sub>s &lt; 0.70).</p><h3 id="Sec22">Discussion</h3><p>The results were essentially the same as those of Experiment 1. The disposal group significantly reduced their anger after disposing of the anger-written paper into the shredder. The retention group showed significantly higher anger than the baseline period and disposal group. These results suggest that the results in Experiment 1 could be attributed neither to the physical distance between the participant and the paper nor to the action itself (i.e. embodied cognition). Specifically, Experiment 2 replicated the results of Experiment 1 and excluded the embodied explanation (the sensorimotor experience of throwing the paper) because the action of the disposal group was quite similar to that of the retention group in Experiment 2. The distance between participant and paper was the same in both groups, as the transparent box and shredder were placed on the desk.</p><h3 id="Sec23">General discussion</h3><p>This study aimed to determine whether the disposal of anger-written papers could eliminate or at least reduce subjective anger. Disposal manipulation eliminated anger, either by throwing the paper into a trash can or placing it into the shredder. We propose that this anger reduction method is quite effective, so the subjective ratings of anger resumed as much as the baseline levels. We believe that this method can be used in daily life and especially for populations characterised by extreme levels of anger and aggression in their home. The use of this method may potentially contribute to emotion socialization, as parents are the primary model for their children.</p><p>These results indicate that the sensorimotor experience of throwing paper plays a small role in reducing subjective anger<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Zhang, Y., Risen, J. L. &amp; Hosey, C. Reversing one’s fortune by pushing away bad luck. J. Exp. Psychol. General 143(3), 1171–1184. 
                  https://doi.org/10.1037/a0034023
                  
                 (2014)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR44" id="ref-link-section-d23593774e1467">44</a></sup>. Instead, the meaning (interpretation) of disposal plays a critical role. These results are consistent with other studies which showed that the meaning of disposal was critical for determining its impact, not the action itself<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Brinol, P., Gasco, M., Petty, R. E. &amp; Horcajo, J. Treating thoughts as material objects can increase or decrease their impact on evaluation. Psychol. Sci. 24(1), 41–47. 
                  https://doi.org/10.1177/0956797612449176
                  
                 (2013)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR30" id="ref-link-section-d23593774e1471">30</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Brinol, P., Petty, R. E. &amp; Wagner, B. Body posture effects on self-evaluation: A self-validation approach. Eur. J. Soc. Psychol. 39(6), 1053–1064. 
                  https://doi.org/10.1002/ejsp.607
                  
                 (2009)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR45" id="ref-link-section-d23593774e1474">45</a></sup>. However, these results are partially inconsistent with those reported by Zhang et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Zhang, Y., Risen, J. L. &amp; Hosey, C. Reversing one’s fortune by pushing away bad luck. J. Exp. Psychol. General 143(3), 1171–1184. 
                  https://doi.org/10.1037/a0034023
                  
                 (2014)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR44" id="ref-link-section-d23593774e1478">44</a></sup>. Their experiment tested whether certain behaviors could lower the perceived likelihood of bad luck, as is often the case with jinxes. Participants who threw a ball believed that a jinxed-negative outcome was less likely than those who held the ball. They demonstrated that engaging in an avoidant action rather than creating physical distance was critical for reversing the perceived effect of the jinx. The results of Experiment 1 in this study are consistent with their results. However, we demonstrated that neither avoidance action nor physical distance was crucial in reducing subjective anger.</p><p>Our results may be related to the phenomenon of ‘backward magical contagion’<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Rozin, P., Nemeroff, C., Wane, M. &amp; Sherrod, A. Operation of the sympathetic magical law of contagion in interpersonal attitudes among americans. Bull. Psychon. Soc. 27(4), 367–370 (1989)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR47" id="ref-link-section-d23593774e1485">47</a></sup>, which is the belief that actions taken on an object (e.g. hair) associated with an individual can affect the individuals themselves. Rozin et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Rozin, P., Dunn, C. &amp; Fedotova, N. Reversing the causal arrow: Incidence and properties of negative backward magical contagion in Americans. Judgm. Decis. Mak. 13(5), 441–450. 
                  https://doi.org/10.1017/S1930297500008718
                  
                 (2018)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR48" id="ref-link-section-d23593774e1489">48</a></sup> discovered that individuals experience strong negative emotions when their personal objects are possessed by negative others (such as rapists or enemies). However, these emotions are reduced when the objects are destroyed, such as throwing them in a septic tank or burning them. The phenomenon of ‘magical contagion’ or ‘celebrity contagion’ refers to the belief that the ‘essence’ of an individual can be transferred to their possessions. This backward magical contagion operates in a reversed process, where manipulating an object associated with a person is thought to impact the individuals themselves. The current study's findings may be explained by the concept of backward magical contagion, which posits that negative emotions can be transferred from others to an individual through their possessions. This study did not involve the direct mediation of other individuals. The neutralization of subjective anger through the disposal of an object may be achieved by recognizing that the physical entity, such as a piece of paper, has been diminished, thus causing the original emotion to also disappear.</p><p>At least, however, some limitations regarding this disposal method should be addressed in future studies. First, the findings of this study are based on the assumption that participants identified their subjective anger with the paper. Thus, subjective anger had gone with the anger-written paper after its disposal. The participants were asked to review the sentences carefully for 30&nbsp;s to enhance this identification between thought and paper. It is not clear whether this review process is necessary for identification.</p><p>Another limitation is that we did not test a digital device, such as a word processor or smartphone, but used only papers. We believe the present disposal method can be generalised to a digital device, whereas empirical data are limited only by physical entities, papers, trash cans, or shredders. Suppose the disposal method is proven to be effective in digital devices. In that case, it will be adopted in various situations, such as business meetings or daily conversations in schools, by writing and disposing of with a smartphone.</p><p>Furthermore, although the disposal method had a more significant effect so that the subjective ratings of anger were eliminated as much as the baseline levels, the effectiveness of this method was not directly compared to other anger reduction methods, such as self-distancing. Other methods may be as effective or even more effective than the present disposal method. Personality traits may modulate the effects of anger suppression, although this has not been examined in the techniques used in this or in other studies. Individuals with high (versus low) levels of trait anger tended to experience lapses in effortful control when exposed to anger-relevant stimuli<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Denny, K. G. &amp; Siemer, M. Trait aggression is related to anger-modulated deficits in response inhibition. J. Res. Person. 46(4), 450–454 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR49" id="ref-link-section-d23593774e1503">49</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Wilkowski, B. M. &amp; Robinson, M. D. Keeping one’s cool: Trait anger, hostile thoughts, and the recruitment of limited capacity control. Person. Soc. Psychol. Bull. 33(9), 1201–1213 (2007)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR50" id="ref-link-section-d23593774e1506">50</a></sup>. As mentioned above, although cognitive reappraisal (the reinterpretation of the meaning of an unpleasant event) is considered an effective way to reduce anger<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Denson, T. F., Moulds, M. L. &amp; Grisham, J. R. The effects of analytical rumination, reappraisal, and distraction on anger experience. Behav. Ther. 43(2), 355–364. 
                  https://doi.org/10.1016/j.beth.2011.08.001
                  
                 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR12" id="ref-link-section-d23593774e1510">12</a></sup>, it requires more significant cognitive effort<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Kross, E. &amp; Ayduk, O. Self-distancing: Theory, research, and current directions. Adv. Exp. Soc. Psychol. 55(55), 81–136. 
                  https://doi.org/10.1016/bs.aesp.2016.10.002
                  
                 (2017)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR13" id="ref-link-section-d23593774e1514">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Orvell, A., Ayduk, O., Moser, J. S., Gelman, S. A. &amp; Kross, E. Linguistic shifts: A relatively effortless route to emotion regulation?. Curr. Dir. Psychol. Sci. 28(6), 567–573. 
                  https://doi.org/10.1177/0963721419861411
                  
                 (2019)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR14" id="ref-link-section-d23593774e1517">14</a></sup>. Self-distancing is not feasible, particularly during the heat of the moment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Kross, E. &amp; Ayduk, O. Self-distancing: Theory, research, and current directions. Adv. Exp. Soc. Psychol. 55(55), 81–136. 
                  https://doi.org/10.1016/bs.aesp.2016.10.002
                  
                 (2017)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR13" id="ref-link-section-d23593774e1521">13</a></sup>. Conversely, the disposal method with low cognitive effort used in this study may be more effective for individuals with lower levels of trait self-control than for those with high trait self-control. Future research should examine whether personality traits moderate the relationship between the disposal method and the expected outcomes.</p><p>Individuals with higher levels of trait anger tended to have prolonged experiences of induced state anger<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Veenstra, L., Bushman, B. J. &amp; Koole, S. L. The facts on the furious: A brief review of the psychology of trait anger. Curr. Opin. Psychol. 
                  https://doi.org/10.1016/j.copsyc.2017.03.014
                  
                 (2018)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR51" id="ref-link-section-d23593774e1528">51</a></sup>. However, experimental research on anger regulation strategies has predominantly emphasized the effectiveness of immediate control<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Szasz, P. L., Szentagotai, A. &amp; Hofmann, S. G. The effect of emotion regulation strategies on anger. Behav. Res. Ther. 49(2), 114–119. 
                  https://doi.org/10.1016/j.brat.2010.11.011
                  
                 (2011)." href="#ref-CR10" id="ref-link-section-d23593774e1532">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Fabiansson, E. C. &amp; Denson, T. F. The effects of intrapersonal anger and its regulation in economic bargaining. Plos One 7(12), e51595. 
                  https://doi.org/10.1371/journal.pone.0051595
                  
                 (2012)." href="#ref-CR11" id="ref-link-section-d23593774e1532_1">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Denson, T. F., Moulds, M. L. &amp; Grisham, J. R. The effects of analytical rumination, reappraisal, and distraction on anger experience. Behav. Ther. 43(2), 355–364. 
                  https://doi.org/10.1016/j.beth.2011.08.001
                  
                 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR12" id="ref-link-section-d23593774e1535">12</a></sup>, neglecting to investigate whether these strategies are equally effective in managing anger that persists over time. However, in everyday life, it is not always feasible to implement anger regulation strategies immediately after anger arises. Therefore, to ascertain its practical utility in real-world settings, it is imperative to examine whether the effectiveness of the disposal method varies with the duration of anger.</p><p>Moreover, it should be tested whether the disposal method can suppress subjective anger even if participants write down a provocation event in an experiential manner rather than in the analytic rumination manner used in this study. Previous studies suggest that anger rumination can maintain<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Peuters, C., Kalokerinos, E. K., Pe, M. L. &amp; Kuppens, P. Sequential effects of reappraisal and rumination on anger during recall of an anger-provoking event. Plos One 14(1), e0209029. 
                  https://doi.org/10.1371/journal.pone.0209029
                  
                 (2019)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR52" id="ref-link-section-d23593774e1542">52</a></sup> or even increase<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Lievaart, M., Huijding, J., van der Veen, F. M., Hovens, J. E. &amp; Franken, I. H. A. The impact of angry rumination on anger-primed cognitive control. J. Behav. Ther. Exp. Psychiatry 54, 135–142. 
                  https://doi.org/10.1016/j.jbtep.2016.07.016
                  
                 (2017)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR53" id="ref-link-section-d23593774e1546">53</a></sup> the original level of anger when participants wrote down a provocation event in an experiential rumination manner. As it may not be easy to write down analytically, especially in the heat of the moment, the disposal method will gain further strength if it is valid by experiential rumination.</p><p>It should be mentioned that although provocation was effective in both the subjective anger score and the PANAS negative score, the revealed emotion regulation strategy in this study seemed specific to anger (as no significant interaction effect for the PANAS negative score was observed). Kubo et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Kubo, K., Okanoya, K. &amp; Kawai, N. Apology isn’t good enough: An apology suppresses an approach motivation but not the physiological and psychological anger. Plos One 7(3), e33006. 
                  https://doi.org/10.1371/journal.pone.0033006
                  
                 (2012)." href="https://www.nature.com/articles/s41598-024-57916-z#ref-CR40" id="ref-link-section-d23593774e1553">40</a></sup> reported that the increase in the state of anger relevant to approach motivation (aggression) by provocation (measured using the STAXI and asymmetry of prefrontal brain activity) was reduced by an apology comment. However, an increase in the subjective scores of negative emotion (assessed using the PANAS) remained unchanged, regardless of the presence or absence of an apology comment. They proposed anger as not a unitary process but one that comprises multiple independent components (subjective anger and negative feelings). If the anger scale used in this study reflects the approach motivation component of anger as well as the STAXI, the disposal method appears to specifically suppress the components of anger’s approach motivation (aggression) and can be used to reduce aggression as a clinical technique.</p><p>Despite these limitations, this is the first study to be designed and used to conveniently eliminate subjective anger by interacting with physical entities. It offers a cost-effective and easy-to-use method to reduce anger by rumination about the provocative event, which otherwise lasts longer. Anyone with a pen and piece of paper can use this method. Suppose one maintains a diary or a personal log. In that case, they can write down a provocative event on the day on the memo pad, and throwing it into the trash can eliminate the provocative event. This action may help neutralize the negative emotions associated with the event, potentially protecting the children’s emotional socialization.</p></div></div><div id="Sec24-section" data-title="Conclusion"><h2 id="Sec24">Conclusion</h2><p>This study presents a new and convenient method for eliminating subjective anger. This method offers a cost-effective way to eliminate anger in various situations, including business meetings, childcare, and clinical applications. The building blocks of this method (e.g. applying it to a digital device or creating a specific application) could be useful in various daily situations as well as behavioural therapies. In particular, for someone who has difficulty suppressing their anger in their homes.</p></div>
                </div><div>
                <div id="data-availability-section" data-title="Data availability"><h2 id="data-availability">Data availability</h2><p>The datasets used and analysed during the current study available from the corresponding author on reasonable request.</p></div><div id="MagazineFulltextArticleBodySuffix" aria-labelledby="Bib1" data-title="References"><h2 id="Bib1">References</h2><div data-container-section="references" id="Bib1-content"><ol data-track-component="outbound reference"><li data-counter="1."><p id="ref-CR1">Seneca, L. A. <i>Seneca Moral Essays</i>, Vol. 1. De ira [Anger] (J. W. Basore, Ed. and Trans.) (Original work published 45) (W. Heinemann, 1928).</p></li><li data-counter="2."><p id="ref-CR2">Rodriguez, C. M. &amp; Green, A. J. Parenting stress and anger expression as predictors of child abuse potential. <i>Child Abuse Negl.</i> <b>21</b>(4), 367–377. <a href="https://doi.org/10.1016/s0145-2134(96)00177-9" data-track="click" data-track-action="external reference" data-track-label="10.1016/s0145-2134(96)00177-9">https://doi.org/10.1016/s0145-2134(96)00177-9</a> (1997).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/s0145-2134(96)00177-9" data-track-action="article reference" href="https://doi.org/10.1016%2Fs0145-2134%2896%2900177-9" aria-label="Article reference 2" data-doi="10.1016/s0145-2134(96)00177-9">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK2s3nvFyqsw%3D%3D" aria-label="CAS reference 2">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9134265" aria-label="PubMed reference 2">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Parenting%20stress%20and%20anger%20expression%20as%20predictors%20of%20child%20abuse%20potential&amp;journal=Child%20Abuse%20Negl.&amp;doi=10.1016%2Fs0145-2134%2896%2900177-9&amp;volume=21&amp;issue=4&amp;pages=367-377&amp;publication_year=1997&amp;author=Rodriguez%2CCM&amp;author=Green%2CAJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="3."><p id="ref-CR3">Moody, G., Cannings-John, R., Hood, K., Kemp, A. &amp; Robling, M. Establishing the international prevalence of self-reported child maltreatment: A systematic review by maltreatment type and gender. <i>BMC Public Health</i> <b>18</b>, 1164. <a href="https://doi.org/10.1186/s12889-018-6044-y" data-track="click" data-track-action="external reference" data-track-label="10.1186/s12889-018-6044-y">https://doi.org/10.1186/s12889-018-6044-y</a> (2018).</p><p><a data-track="click" rel="noopener" data-track-label="10.1186/s12889-018-6044-y" data-track-action="article reference" href="https://link.springer.com/doi/10.1186/s12889-018-6044-y" aria-label="Article reference 3" data-doi="10.1186/s12889-018-6044-y">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30305071" aria-label="PubMed reference 3">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6180456" aria-label="PubMed Central reference 3">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Establishing%20the%20international%20prevalence%20of%20self-reported%20child%20maltreatment%3A%20A%20systematic%20review%20by%20maltreatment%20type%20and%20gender&amp;journal=BMC%20Public%20Health&amp;doi=10.1186%2Fs12889-018-6044-y&amp;volume=18&amp;publication_year=2018&amp;author=Moody%2CG&amp;author=Cannings-John%2CR&amp;author=Hood%2CK&amp;author=Kemp%2CA&amp;author=Robling%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="4."><p id="ref-CR4">Child and Family Policy Bureau, Ministry of Health, Labour and Welfare. <i>Trends in the Number of Cases of Child Abuse at Child Guidance Center</i> (accessed 25 January 2023). <a href="https://www.mhlw.go.jp/content/001040752.pdf" data-track="click" data-track-action="external reference" data-track-label="https://www.mhlw.go.jp/content/001040752.pdf">https://www.mhlw.go.jp/content/001040752.pdf</a>. (<b>in Japanese</b>).</p></li><li data-counter="5."><p id="ref-CR5">Denham, S. &amp; Kochanoff, A. T. Parental contributions to preschoolers’ understanding of emotion. <i>Marriage Fam. Rev.</i> <b>34</b>(3–4), 311–343. <a href="https://doi.org/10.1300/J002v34n03_06" data-track="click" data-track-action="external reference" data-track-label="10.1300/J002v34n03_06">https://doi.org/10.1300/J002v34n03_06</a> (2002).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1300/J002v34n03_06" data-track-action="article reference" href="https://doi.org/10.1300%2FJ002v34n03_06" aria-label="Article reference 5" data-doi="10.1300/J002v34n03_06">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Parental%20contributions%20to%20preschoolers%E2%80%99%20understanding%20of%20emotion&amp;journal=Marriage%20Fam.%20Rev.&amp;doi=10.1300%2FJ002v34n03_06&amp;volume=34&amp;issue=3%E2%80%934&amp;pages=311-343&amp;publication_year=2002&amp;author=Denham%2CS&amp;author=Kochanoff%2CAT">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="6."><p id="ref-CR6">Heleniak, C., Jenness, J. L., Vander Stoep, A., McCauley, E. &amp; McLaughlin, K. A. Childhood maltreatment exposure and disruptions in emotion regulation: A transdiagnostic pathway to adolescent internalizing and externalizing psychopathology. <i>Cogn. Ther. Res.</i> <b>40</b>(3), 394–415. <a href="https://doi.org/10.1007/s10608-015-9735-z" data-track="click" data-track-action="external reference" data-track-label="10.1007/s10608-015-9735-z">https://doi.org/10.1007/s10608-015-9735-z</a> (2016).</p><p><a data-track="click" rel="noopener" data-track-label="10.1007/s10608-015-9735-z" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s10608-015-9735-z" aria-label="Article reference 6" data-doi="10.1007/s10608-015-9735-z">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=Childhood%20maltreatment%20exposure%20and%20disruptions%20in%20emotion%20regulation%3A%20A%20transdiagnostic%20pathway%20to%20adolescent%20internalizing%20and%20externalizing%20psychopathology&amp;journal=Cogn.%20Ther.%20Res.&amp;doi=10.1007%2Fs10608-015-9735-z&amp;volume=40&amp;issue=3&amp;pages=394-415&amp;publication_year=2016&amp;author=Heleniak%2CC&amp;author=Jenness%2CJL&amp;author=Vander%20Stoep%2CA&amp;author=McCauley%2CE&amp;author=McLaughlin%2CKA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="7."><p id="ref-CR7">Pollak, S. D., Cicchetti, D., Hornung, K. &amp; Reed, A. Recognizing emotion in faces: Developmental effects of child abuse and neglect. <i>Dev. Psychol.</i> <b>36</b>(5), 679–688. <a href="https://doi.org/10.1037//0012-1649.36.5.679" data-track="click" data-track-action="external reference" data-track-label="10.1037//0012-1649.36.5.679">https://doi.org/10.1037//0012-1649.36.5.679</a> (2000).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1037//0012-1649.36.5.679" data-track-action="article reference" href="https://doi.org/10.1037%2F%2F0012-1649.36.5.679" aria-label="Article reference 7" data-doi="10.1037//0012-1649.36.5.679">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10976606" aria-label="PubMed reference 7">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Recognizing%20emotion%20in%20faces%3A%20Developmental%20effects%20of%20child%20abuse%20and%20neglect&amp;journal=Dev.%20Psychol.&amp;doi=10.1037%2F%2F0012-1649.36.5.679&amp;volume=36&amp;issue=5&amp;pages=679-688&amp;publication_year=2000&amp;author=Pollak%2CSD&amp;author=Cicchetti%2CD&amp;author=Hornung%2CK&amp;author=Reed%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="8."><p id="ref-CR8">Denham, S. A. <i>et al.</i> Prediction of externalizing behavior problems from early to middle childhood: The role of parental socialization and emotion expression. <i>Dev. Psychopathol.</i> <b>12</b>(1), 23–45. <a href="https://doi.org/10.1017/s0954579400001024" data-track="click" data-track-action="external reference" data-track-label="10.1017/s0954579400001024">https://doi.org/10.1017/s0954579400001024</a> (2000).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1017/s0954579400001024" data-track-action="article reference" href="https://doi.org/10.1017%2Fs0954579400001024" aria-label="Article reference 8" data-doi="10.1017/s0954579400001024">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BD3c3jsVKhtQ%3D%3D" aria-label="CAS reference 8">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10774594" aria-label="PubMed reference 8">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Prediction%20of%20externalizing%20behavior%20problems%20from%20early%20to%20middle%20childhood%3A%20The%20role%20of%20parental%20socialization%20and%20emotion%20expression&amp;journal=Dev.%20Psychopathol.&amp;doi=10.1017%2Fs0954579400001024&amp;volume=12&amp;issue=1&amp;pages=23-45&amp;publication_year=2000&amp;author=Denham%2CSA&amp;author=Workman%2CE&amp;author=Cole%2CPM&amp;author=Weissbrod%2CC&amp;author=Kendziora%2CKT&amp;author=Zahn-Waxler%2CC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="9."><p id="ref-CR9">Beames, J. R., O’Dean, S. M., Grisham, J. R., Moulds, M. L. &amp; Denson, T. F. Anger regulation in interpersonal contexts: Anger experience, aggressive behavior, and cardiovascular reactivity. <i>J. Soc. Pers. Relationsh.</i> <b>36</b>(5), 1441–1458. <a href="https://doi.org/10.1177/0265407518819295" data-track="click" data-track-action="external reference" data-track-label="10.1177/0265407518819295">https://doi.org/10.1177/0265407518819295</a> (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1177/0265407518819295" data-track-action="article reference" href="https://doi.org/10.1177%2F0265407518819295" aria-label="Article reference 9" data-doi="10.1177/0265407518819295">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Anger%20regulation%20in%20interpersonal%20contexts%3A%20Anger%20experience%2C%20aggressive%20behavior%2C%20and%20cardiovascular%20reactivity&amp;journal=J.%20Soc.%20Pers.%20Relationsh.&amp;doi=10.1177%2F0265407518819295&amp;volume=36&amp;issue=5&amp;pages=1441-1458&amp;publication_year=2019&amp;author=Beames%2CJR&amp;author=O%27Dean%2CSM&amp;author=Grisham%2CJR&amp;author=Moulds%2CML&amp;author=Denson%2CTF">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="10."><p id="ref-CR10">Szasz, P. L., Szentagotai, A. &amp; Hofmann, S. G. The effect of emotion regulation strategies on anger. <i>Behav. Res. Ther.</i> <b>49</b>(2), 114–119. <a href="https://doi.org/10.1016/j.brat.2010.11.011" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.brat.2010.11.011">https://doi.org/10.1016/j.brat.2010.11.011</a> (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.brat.2010.11.011" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.brat.2010.11.011" aria-label="Article reference 10" data-doi="10.1016/j.brat.2010.11.011">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21185551" aria-label="PubMed reference 10">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effect%20of%20emotion%20regulation%20strategies%20on%20anger&amp;journal=Behav.%20Res.%20Ther.&amp;doi=10.1016%2Fj.brat.2010.11.011&amp;volume=49&amp;issue=2&amp;pages=114-119&amp;publication_year=2011&amp;author=Szasz%2CPL&amp;author=Szentagotai%2CA&amp;author=Hofmann%2CSG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="11."><p id="ref-CR11">Fabiansson, E. C. &amp; Denson, T. F. The effects of intrapersonal anger and its regulation in economic bargaining. <i>Plos One</i> <b>7</b>(12), e51595. <a href="https://doi.org/10.1371/journal.pone.0051595" data-track="click" data-track-action="external reference" data-track-label="10.1371/journal.pone.0051595">https://doi.org/10.1371/journal.pone.0051595</a> (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0051595" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0051595" aria-label="Article reference 11" data-doi="10.1371/journal.pone.0051595">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2012PLoSO...751595F" aria-label="ADS reference 11">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3sXmtVSruw%3D%3D" aria-label="CAS reference 11">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23300553" aria-label="PubMed reference 11">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3530551" aria-label="PubMed Central reference 11">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effects%20of%20intrapersonal%20anger%20and%20its%20regulation%20in%20economic%20bargaining&amp;journal=Plos%20One&amp;doi=10.1371%2Fjournal.pone.0051595&amp;volume=7&amp;issue=12&amp;publication_year=2012&amp;author=Fabiansson%2CEC&amp;author=Denson%2CTF">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="12."><p id="ref-CR12">Denson, T. F., Moulds, M. L. &amp; Grisham, J. R. The effects of analytical rumination, reappraisal, and distraction on anger experience. <i>Behav. Ther.</i> <b>43</b>(2), 355–364. <a href="https://doi.org/10.1016/j.beth.2011.08.001" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.beth.2011.08.001">https://doi.org/10.1016/j.beth.2011.08.001</a> (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.beth.2011.08.001" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.beth.2011.08.001" aria-label="Article reference 12" data-doi="10.1016/j.beth.2011.08.001">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22440071" aria-label="PubMed reference 12">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20effects%20of%20analytical%20rumination%2C%20reappraisal%2C%20and%20distraction%20on%20anger%20experience&amp;journal=Behav.%20Ther.&amp;doi=10.1016%2Fj.beth.2011.08.001&amp;volume=43&amp;issue=2&amp;pages=355-364&amp;publication_year=2012&amp;author=Denson%2CTF&amp;author=Moulds%2CML&amp;author=Grisham%2CJR">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="13."><p id="ref-CR13">Kross, E. &amp; Ayduk, O. Self-distancing: Theory, research, and current directions. <i>Adv. Exp. Soc. Psychol.</i> <b>55</b>(55), 81–136. <a href="https://doi.org/10.1016/bs.aesp.2016.10.002" data-track="click" data-track-action="external reference" data-track-label="10.1016/bs.aesp.2016.10.002">https://doi.org/10.1016/bs.aesp.2016.10.002</a> (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/bs.aesp.2016.10.002" data-track-action="article reference" href="https://doi.org/10.1016%2Fbs.aesp.2016.10.002" aria-label="Article reference 13" data-doi="10.1016/bs.aesp.2016.10.002">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Self-distancing%3A%20Theory%2C%20research%2C%20and%20current%20directions&amp;journal=Adv.%20Exp.%20Soc.%20Psychol.&amp;doi=10.1016%2Fbs.aesp.2016.10.002&amp;volume=55&amp;issue=55&amp;pages=81-136&amp;publication_year=2017&amp;author=Kross%2CE&amp;author=Ayduk%2CO">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="14."><p id="ref-CR14">Orvell, A., Ayduk, O., Moser, J. S., Gelman, S. A. &amp; Kross, E. Linguistic shifts: A relatively effortless route to emotion regulation?. <i>Curr. Dir. Psychol. Sci.</i> <b>28</b>(6), 567–573. <a href="https://doi.org/10.1177/0963721419861411" data-track="click" data-track-action="external reference" data-track-label="10.1177/0963721419861411">https://doi.org/10.1177/0963721419861411</a> (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1177/0963721419861411" data-track-action="article reference" href="https://doi.org/10.1177%2F0963721419861411" aria-label="Article reference 14" data-doi="10.1177/0963721419861411">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Linguistic%20shifts%3A%20A%20relatively%20effortless%20route%20to%20emotion%20regulation%3F&amp;journal=Curr.%20Dir.%20Psychol.%20Sci.&amp;doi=10.1177%2F0963721419861411&amp;volume=28&amp;issue=6&amp;pages=567-573&amp;publication_year=2019&amp;author=Orvell%2CA&amp;author=Ayduk%2CO&amp;author=Moser%2CJS&amp;author=Gelman%2CSA&amp;author=Kross%2CE">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="15."><p id="ref-CR15">Zhan, J. <i>et al.</i> Regulating anger under stress via cognitive reappraisal and sadness. <i>Front. Psychol.</i> <b>8</b>, 1372. <a href="https://doi.org/10.3389/fpsyg.2017.01372" data-track="click" data-track-action="external reference" data-track-label="10.3389/fpsyg.2017.01372">https://doi.org/10.3389/fpsyg.2017.01372</a> (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fpsyg.2017.01372" data-track-action="article reference" href="https://doi.org/10.3389%2Ffpsyg.2017.01372" aria-label="Article reference 15" data-doi="10.3389/fpsyg.2017.01372">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28855881" aria-label="PubMed reference 15">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5557741" aria-label="PubMed Central reference 15">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Regulating%20anger%20under%20stress%20via%20cognitive%20reappraisal%20and%20sadness&amp;journal=Front.%20Psychol.&amp;doi=10.3389%2Ffpsyg.2017.01372&amp;volume=8&amp;publication_year=2017&amp;author=Zhan%2CJ&amp;author=Wu%2CXF&amp;author=Fan%2CJ&amp;author=Guo%2CJY&amp;author=Zhou%2CJS&amp;author=Ren%2CJ&amp;author=Liu%2CC&amp;author=Luo%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="16."><p id="ref-CR16">Ayduk, O. &amp; Kross, E. From a distance: Implications of spontaneous self-distancing for adaptive self-reflection. <i>J. Pers. Soc. Psychol.</i> <b>98</b>(5), 809–829. <a href="https://doi.org/10.1037/a0019205" data-track="click" data-track-action="external reference" data-track-label="10.1037/a0019205">https://doi.org/10.1037/a0019205</a> (2010).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/a0019205" data-track-action="article reference" href="https://doi.org/10.1037%2Fa0019205" aria-label="Article reference 16" data-doi="10.1037/a0019205">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20438226" aria-label="PubMed reference 16">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881638" aria-label="PubMed Central reference 16">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=From%20a%20distance%3A%20Implications%20of%20spontaneous%20self-distancing%20for%20adaptive%20self-reflection&amp;journal=J.%20Pers.%20Soc.%20Psychol.&amp;doi=10.1037%2Fa0019205&amp;volume=98&amp;issue=5&amp;pages=809-829&amp;publication_year=2010&amp;author=Ayduk%2CO&amp;author=Kross%2CE">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="17."><p id="ref-CR17">Kross, E., Ayduk, O. &amp; Mischel, W. When asking “why” does not hurt - Distinguishing rumination from reflective processing of negative emotions. <i>Psychol. Sci.</i> <b>16</b>(9), 709–715. <a href="https://doi.org/10.1111/j.1467-9280.2005.01600.x" data-track="click" data-track-action="external reference" data-track-label="10.1111/j.1467-9280.2005.01600.x">https://doi.org/10.1111/j.1467-9280.2005.01600.x</a> (2005).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1111/j.1467-9280.2005.01600.x" data-track-action="article reference" href="https://doi.org/10.1111%2Fj.1467-9280.2005.01600.x" aria-label="Article reference 17" data-doi="10.1111/j.1467-9280.2005.01600.x">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16137257" aria-label="PubMed reference 17">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=When%20asking%20%E2%80%9Cwhy%E2%80%9D%20does%20not%20hurt%20-%20Distinguishing%20rumination%20from%20reflective%20processing%20of%20negative%20emotions&amp;journal=Psychol.%20Sci.&amp;doi=10.1111%2Fj.1467-9280.2005.01600.x&amp;volume=16&amp;issue=9&amp;pages=709-715&amp;publication_year=2005&amp;author=Kross%2CE&amp;author=Ayduk%2CO&amp;author=Mischel%2CW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="18."><p id="ref-CR18">Glynn, L. M., Christenfeld, N. &amp; Gerin, W. Recreating cardiovascular responses with rumination: The effects of a delay between harassment and its recall. <i>Int. J. Psychophysiol.</i> <b>66</b>(2), 135–140. <a href="https://doi.org/10.1016/j.ijpsycho.2007.03.018" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.ijpsycho.2007.03.018">https://doi.org/10.1016/j.ijpsycho.2007.03.018</a> (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.ijpsycho.2007.03.018" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.ijpsycho.2007.03.018" aria-label="Article reference 18" data-doi="10.1016/j.ijpsycho.2007.03.018">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17570551" aria-label="PubMed reference 18">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Recreating%20cardiovascular%20responses%20with%20rumination%3A%20The%20effects%20of%20a%20delay%20between%20harassment%20and%20its%20recall&amp;journal=Int.%20J.%20Psychophysiol.&amp;doi=10.1016%2Fj.ijpsycho.2007.03.018&amp;volume=66&amp;issue=2&amp;pages=135-140&amp;publication_year=2007&amp;author=Glynn%2CLM&amp;author=Christenfeld%2CN&amp;author=Gerin%2CW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="19."><p id="ref-CR19">Pennebaker, J. W. Expressive writing in psychological science. <i>Perspect. Psychol. Sci.</i> <b>13</b>(2), 226–229. <a href="https://doi.org/10.1177/1745691617707315" data-track="click" data-track-action="external reference" data-track-label="10.1177/1745691617707315">https://doi.org/10.1177/1745691617707315</a> (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1177/1745691617707315" data-track-action="article reference" href="https://doi.org/10.1177%2F1745691617707315" aria-label="Article reference 19" data-doi="10.1177/1745691617707315">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28992443" aria-label="PubMed reference 19">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=Expressive%20writing%20in%20psychological%20science&amp;journal=Perspect.%20Psychol.%20Sci.&amp;doi=10.1177%2F1745691617707315&amp;volume=13&amp;issue=2&amp;pages=226-229&amp;publication_year=2018&amp;author=Pennebaker%2CJW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="20."><p id="ref-CR20">Fuentes, A. M. M., Kahn, J. H. &amp; Lannin, D. G. Emotional disclosure and emotion change during an expressive-writing task: Do pronouns matter?. <i>Curr. Psychol.</i> <b>40</b>, 1672–1679. <a href="https://doi.org/10.1007/s12144-018-0094-2" data-track="click" data-track-action="external reference" data-track-label="10.1007/s12144-018-0094-2">https://doi.org/10.1007/s12144-018-0094-2</a> (2021).</p><p><a data-track="click" rel="noopener" data-track-label="10.1007/s12144-018-0094-2" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/s12144-018-0094-2" aria-label="Article reference 20" data-doi="10.1007/s12144-018-0094-2">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Emotional%20disclosure%20and%20emotion%20change%20during%20an%20expressive-writing%20task%3A%20Do%20pronouns%20matter%3F&amp;journal=Curr.%20Psychol.&amp;doi=10.1007%2Fs12144-018-0094-2&amp;volume=40&amp;pages=1672-1679&amp;publication_year=2021&amp;author=Fuentes%2CAMM&amp;author=Kahn%2CJH&amp;author=Lannin%2CDG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="21."><p id="ref-CR21">Pasupathi, M., Wainryb, C., Mansfield, C. D. &amp; Bourne, S. The feeling of the story: Narrating to regulate anger and sadness. <i>Cogn. Emotion</i> <b>31</b>(3), 444–461. <a href="https://doi.org/10.1080/02699931.2015.1127214" data-track="click" data-track-action="external reference" data-track-label="10.1080/02699931.2015.1127214">https://doi.org/10.1080/02699931.2015.1127214</a> (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1080/02699931.2015.1127214" data-track-action="article reference" href="https://doi.org/10.1080%2F02699931.2015.1127214" aria-label="Article reference 21" data-doi="10.1080/02699931.2015.1127214">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20feeling%20of%20the%20story%3A%20Narrating%20to%20regulate%20anger%20and%20sadness&amp;journal=Cogn.%20Emotion&amp;doi=10.1080%2F02699931.2015.1127214&amp;volume=31&amp;issue=3&amp;pages=444-461&amp;publication_year=2017&amp;author=Pasupathi%2CM&amp;author=Wainryb%2CC&amp;author=Mansfield%2CCD&amp;author=Bourne%2CS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="22."><p id="ref-CR22">Bernstein, A. <i>et al.</i> Decentering and related constructs: A critical review and metacognitive processes model. <i>Perspect. Psychol. Sci.</i> <b>10</b>(5), 599–617. <a href="https://doi.org/10.1177/1745691615594577" data-track="click" data-track-action="external reference" data-track-label="10.1177/1745691615594577">https://doi.org/10.1177/1745691615594577</a> (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1177/1745691615594577" data-track-action="article reference" href="https://doi.org/10.1177%2F1745691615594577" aria-label="Article reference 22" data-doi="10.1177/1745691615594577">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26385999" aria-label="PubMed reference 22">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5103165" aria-label="PubMed Central reference 22">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Decentering%20and%20related%20constructs%3A%20A%20critical%20review%20and%20metacognitive%20processes%20model&amp;journal=Perspect.%20Psychol.%20Sci.&amp;doi=10.1177%2F1745691615594577&amp;volume=10&amp;issue=5&amp;pages=599-617&amp;publication_year=2015&amp;author=Bernstein%2CA&amp;author=Hadash%2CY&amp;author=Lichtash%2CY&amp;author=Tanay%2CG&amp;author=Shepherd%2CK&amp;author=Fresco%2CDM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="23."><p id="ref-CR23">Healy, H. A. <i>et al.</i> An experimental test of a cognitive defusion exercise: Coping with negative and positive self-statements. <i>Psychol. Record</i> <b>58</b>(4), 623–640. <a href="https://doi.org/10.1007/bf03395641" data-track="click" data-track-action="external reference" data-track-label="10.1007/bf03395641">https://doi.org/10.1007/bf03395641</a> (2008).</p><p><a data-track="click" rel="noopener" data-track-label="10.1007/bf03395641" data-track-action="article reference" href="https://link.springer.com/doi/10.1007/bf03395641" aria-label="Article reference 23" data-doi="10.1007/bf03395641">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20experimental%20test%20of%20a%20cognitive%20defusion%20exercise%3A%20Coping%20with%20negative%20and%20positive%20self-statements&amp;journal=Psychol.%20Record&amp;doi=10.1007%2Fbf03395641&amp;volume=58&amp;issue=4&amp;pages=623-640&amp;publication_year=2008&amp;author=Healy%2CHA&amp;author=Barnes-Holmes%2CY&amp;author=Barnes-Holmes%2CD&amp;author=Keogh%2CC&amp;author=Luciano%2CC&amp;author=Wilson%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="24."><p id="ref-CR24">Koole, S. L. &amp; Veenstra, L. Does emotion regulation occur only inside people’s heads? Toward a situated cognition analysis of emotion-regulatory dynamics. <i>Psychol. Inq.</i> <b>26</b>(1), 61–68. <a href="https://doi.org/10.1080/1047840x.2015.964657" data-track="click" data-track-action="external reference" data-track-label="10.1080/1047840x.2015.964657">https://doi.org/10.1080/1047840x.2015.964657</a> (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1080/1047840x.2015.964657" data-track-action="article reference" href="https://doi.org/10.1080%2F1047840x.2015.964657" aria-label="Article reference 24" data-doi="10.1080/1047840x.2015.964657">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Does%20emotion%20regulation%20occur%20only%20inside%20people%27s%20heads%3F%20Toward%20a%20situated%20cognition%20analysis%20of%20emotion-regulatory%20dynamics&amp;journal=Psychol.%20Inq.&amp;doi=10.1080%2F1047840x.2015.964657&amp;volume=26&amp;issue=1&amp;pages=61-68&amp;publication_year=2015&amp;author=Koole%2CSL&amp;author=Veenstra%2CL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="25."><p id="ref-CR25">Gross, J. J. Emotion regulation: Current status and future prospects. <i>Psychol. Inq.</i> <b>26</b>(1), 1–26. <a href="https://doi.org/10.1080/1047840x.2014.940781" data-track="click" data-track-action="external reference" data-track-label="10.1080/1047840x.2014.940781">https://doi.org/10.1080/1047840x.2014.940781</a> (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1080/1047840x.2014.940781" data-track-action="article reference" href="https://doi.org/10.1080%2F1047840x.2014.940781" aria-label="Article reference 25" data-doi="10.1080/1047840x.2014.940781">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=1129607" aria-label="MathSciNet reference 25">MathSciNet</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=Emotion%20regulation%3A%20Current%20status%20and%20future%20prospects&amp;journal=Psychol.%20Inq.&amp;doi=10.1080%2F1047840x.2014.940781&amp;volume=26&amp;issue=1&amp;pages=1-26&amp;publication_year=2015&amp;author=Gross%2CJJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="26."><p id="ref-CR26">Bargh, J. A. &amp; Shalev, I. The substitutability of physical and social warmth in daily life. <i>Emotion</i> <b>12</b>(1), 154–162. <a href="https://doi.org/10.1037/a0023527" data-track="click" data-track-action="external reference" data-track-label="10.1037/a0023527">https://doi.org/10.1037/a0023527</a> (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/a0023527" data-track-action="article reference" href="https://doi.org/10.1037%2Fa0023527" aria-label="Article reference 26" data-doi="10.1037/a0023527">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21604871" aria-label="PubMed reference 26">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20substitutability%20of%20physical%20and%20social%20warmth%20in%20daily%20life&amp;journal=Emotion&amp;doi=10.1037%2Fa0023527&amp;volume=12&amp;issue=1&amp;pages=154-162&amp;publication_year=2012&amp;author=Bargh%2CJA&amp;author=Shalev%2CI">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="27."><p id="ref-CR27">Shalev, I. &amp; Bargh, J. On the association between loneliness and physical warmth-seeking through bathing: Reply to Donnellan et al. (2014) and three further replications of Bargh and Shalev (2012) study 1. <i>Emotion</i> <b>15</b>(1), 120–123. <a href="https://doi.org/10.1037/emo0000014" data-track="click" data-track-action="external reference" data-track-label="10.1037/emo0000014">https://doi.org/10.1037/emo0000014</a> (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/emo0000014" data-track-action="article reference" href="https://doi.org/10.1037%2Femo0000014" aria-label="Article reference 27" data-doi="10.1037/emo0000014">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25198782" aria-label="PubMed reference 27">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20association%20between%20loneliness%20and%20physical%20warmth-seeking%20through%20bathing%3A%20Reply%20to%20Donnellan%20et%20al.%20%282014%29%20and%20three%20further%20replications%20of%20Bargh%20and%20Shalev%20%282012%29%20study%201&amp;journal=Emotion&amp;doi=10.1037%2Femo0000014&amp;volume=15&amp;issue=1&amp;pages=120-123&amp;publication_year=2015&amp;author=Shalev%2CI&amp;author=Bargh%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="28."><p id="ref-CR28">Koole, S. L., Sin, M. T. A. &amp; Schneider, I. K. Embodied terror management: Interpersonal touch alleviates existential concerns among individuals with low self-esteem. <i>Psychol. Sci.</i> <b>25</b>(1), 30–37. <a href="https://doi.org/10.1177/0956797613483478" data-track="click" data-track-action="external reference" data-track-label="10.1177/0956797613483478">https://doi.org/10.1177/0956797613483478</a> (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1177/0956797613483478" data-track-action="article reference" href="https://doi.org/10.1177%2F0956797613483478" aria-label="Article reference 28" data-doi="10.1177/0956797613483478">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24190907" aria-label="PubMed reference 28">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=Embodied%20terror%20management%3A%20Interpersonal%20touch%20alleviates%20existential%20concerns%20among%20individuals%20with%20low%20self-esteem&amp;journal=Psychol.%20Sci.&amp;doi=10.1177%2F0956797613483478&amp;volume=25&amp;issue=1&amp;pages=30-37&amp;publication_year=2013&amp;author=Koole%2CSL&amp;author=Sin%2CMTA&amp;author=Schneider%2CIK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="29."><p id="ref-CR29">Lee, S. W. S. &amp; Schwarz, N. Grounded procedures: A proximate mechanism for the psychology of cleansing and other physical actions. <i>Behav. Brain Sci.</i> <b>44</b>, e1. <a href="https://doi.org/10.1017/s0140525x20000308" data-track="click" data-track-action="external reference" data-track-label="10.1017/s0140525x20000308">https://doi.org/10.1017/s0140525x20000308</a> (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1017/s0140525x20000308" data-track-action="article reference" href="https://doi.org/10.1017%2Fs0140525x20000308" aria-label="Article reference 29" data-doi="10.1017/s0140525x20000308">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=Grounded%20procedures%3A%20A%20proximate%20mechanism%20for%20the%20psychology%20of%20cleansing%20and%20other%20physical%20actions&amp;journal=Behav.%20Brain%20Sci.&amp;doi=10.1017%2Fs0140525x20000308&amp;volume=44&amp;publication_year=2021&amp;author=Lee%2CSWS&amp;author=Schwarz%2CN">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="30."><p id="ref-CR30">Brinol, P., Gasco, M., Petty, R. E. &amp; Horcajo, J. Treating thoughts as material objects can increase or decrease their impact on evaluation. <i>Psychol. Sci.</i> <b>24</b>(1), 41–47. <a href="https://doi.org/10.1177/0956797612449176" data-track="click" data-track-action="external reference" data-track-label="10.1177/0956797612449176">https://doi.org/10.1177/0956797612449176</a> (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1177/0956797612449176" data-track-action="article reference" href="https://doi.org/10.1177%2F0956797612449176" aria-label="Article reference 30" data-doi="10.1177/0956797612449176">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23184587" aria-label="PubMed reference 30">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Treating%20thoughts%20as%20material%20objects%20can%20increase%20or%20decrease%20their%20impact%20on%20evaluation&amp;journal=Psychol.%20Sci.&amp;doi=10.1177%2F0956797612449176&amp;volume=24&amp;issue=1&amp;pages=41-47&amp;publication_year=2013&amp;author=Brinol%2CP&amp;author=Gasco%2CM&amp;author=Petty%2CRE&amp;author=Horcajo%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="31."><p id="ref-CR31">Hatvany, T., Burkley, E. &amp; Curtis, J. Becoming part of me: Examining when objects, thoughts, goals, and people become fused with the self-concept. <i>Soc. Personal. Psychol. Compass</i> <b>12</b>(1), e12369. <a href="https://doi.org/10.1111/spc3.12369" data-track="click" data-track-action="external reference" data-track-label="10.1111/spc3.12369">https://doi.org/10.1111/spc3.12369</a> (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1111/spc3.12369" data-track-action="article reference" href="https://doi.org/10.1111%2Fspc3.12369" aria-label="Article reference 31" data-doi="10.1111/spc3.12369">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=Becoming%20part%20of%20me%3A%20Examining%20when%20objects%2C%20thoughts%2C%20goals%2C%20and%20people%20become%20fused%20with%20the%20self-concept&amp;journal=Soc.%20Personal.%20Psychol.%20Compass&amp;doi=10.1111%2Fspc3.12369&amp;volume=12&amp;issue=1&amp;publication_year=2018&amp;author=Hatvany%2CT&amp;author=Burkley%2CE&amp;author=Curtis%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="32."><p id="ref-CR32">Belk, R. W. Possessions and the extended self. <i>J. Consum. Res.</i> <b>15</b>(2), 139–168. <a href="https://doi.org/10.1086/209154" data-track="click" data-track-action="external reference" data-track-label="10.1086/209154">https://doi.org/10.1086/209154</a> (1988).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1086/209154" data-track-action="article reference" href="https://doi.org/10.1086%2F209154" aria-label="Article reference 32" data-doi="10.1086/209154">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="mathscinet reference" href="http://www.ams.org/mathscinet-getitem?mr=2295050" aria-label="MathSciNet reference 32">MathSciNet</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Possessions%20and%20the%20extended%20self&amp;journal=J.%20Consum.%20Res.&amp;doi=10.1086%2F209154&amp;volume=15&amp;issue=2&amp;pages=139-168&amp;publication_year=1988&amp;author=Belk%2CRW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="33."><p id="ref-CR33">Reb, J. &amp; Connolly, T. Possession, feelings of ownership and the endowment effect. <i>Judgm. Decis. Mak. J.</i> <b>2</b>(2), 107–114 (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1017/S1930297500000085" data-track-action="article reference" href="https://doi.org/10.1017%2FS1930297500000085" aria-label="Article reference 33" data-doi="10.1017/S1930297500000085">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Possession%2C%20feelings%20of%20ownership%20and%20the%20endowment%20effect&amp;journal=Judgm.%20Decis.%20Mak.%20J.&amp;doi=10.1017%2FS1930297500000085&amp;volume=2&amp;issue=2&amp;pages=107-114&amp;publication_year=2007&amp;author=Reb%2CJ&amp;author=Connolly%2CT">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="34."><p id="ref-CR34">Bushman, B. J. Does venting anger feed or extinguish the flame? Catharsis, rumination, distraction, anger, and aggressive responding. <i>Personal. Soc. Psychol. Bull.</i> <b>28</b>(6), 724–731. <a href="https://doi.org/10.1177/0146167202289002" data-track="click" data-track-action="external reference" data-track-label="10.1177/0146167202289002">https://doi.org/10.1177/0146167202289002</a> (2002).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1177/0146167202289002" data-track-action="article reference" href="https://doi.org/10.1177%2F0146167202289002" aria-label="Article reference 34" data-doi="10.1177/0146167202289002">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=Does%20venting%20anger%20feed%20or%20extinguish%20the%20flame%3F%20Catharsis%2C%20rumination%2C%20distraction%2C%20anger%2C%20and%20aggressive%20responding&amp;journal=Personal.%20Soc.%20Psychol.%20Bull.&amp;doi=10.1177%2F0146167202289002&amp;volume=28&amp;issue=6&amp;pages=724-731&amp;publication_year=2002&amp;author=Bushman%2CBJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="35."><p id="ref-CR35">Denzler, M., Hafner, M. &amp; Forster, J. He just wants to play: How goals determine the influence of violent computer games on aggression. <i>Personal. Soc. Psychol. Bull.</i> <b>37</b>(12), 1644–1654. <a href="https://doi.org/10.1177/0146167211421176" data-track="click" data-track-action="external reference" data-track-label="10.1177/0146167211421176">https://doi.org/10.1177/0146167211421176</a> (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1177/0146167211421176" data-track-action="article reference" href="https://doi.org/10.1177%2F0146167211421176" aria-label="Article reference 35" data-doi="10.1177/0146167211421176">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=He%20just%20wants%20to%20play%3A%20How%20goals%20determine%20the%20influence%20of%20violent%20computer%20games%20on%20aggression&amp;journal=Personal.%20Soc.%20Psychol.%20Bull.&amp;doi=10.1177%2F0146167211421176&amp;volume=37&amp;issue=12&amp;pages=1644-1654&amp;publication_year=2011&amp;author=Denzler%2CM&amp;author=Hafner%2CM&amp;author=Forster%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="36."><p id="ref-CR36">Mauss, I. B., Cook, C. L. &amp; Gross, J. J. Automatic emotion regulation during anger provocation. <i>J. Exp. Soc. Psychol.</i> <b>43</b>(5), 698–711. <a href="https://doi.org/10.1016/j.jesp.2006.07.003" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.jesp.2006.07.003">https://doi.org/10.1016/j.jesp.2006.07.003</a> (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.jesp.2006.07.003" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jesp.2006.07.003" aria-label="Article reference 36" data-doi="10.1016/j.jesp.2006.07.003">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=Automatic%20emotion%20regulation%20during%20anger%20provocation&amp;journal=J.%20Exp.%20Soc.%20Psychol.&amp;doi=10.1016%2Fj.jesp.2006.07.003&amp;volume=43&amp;issue=5&amp;pages=698-711&amp;publication_year=2007&amp;author=Mauss%2CIB&amp;author=Cook%2CCL&amp;author=Gross%2CJJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="37."><p id="ref-CR37">Faul, F., Erdfelder, E., Lang, A. G. &amp; Buchner, A. G*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences. <i>Behav. Res. Methods</i> <b>39</b>(2), 175–191. <a href="https://doi.org/10.3758/bf03193146" data-track="click" data-track-action="external reference" data-track-label="10.3758/bf03193146">https://doi.org/10.3758/bf03193146</a> (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3758/bf03193146" data-track-action="article reference" href="https://doi.org/10.3758%2Fbf03193146" aria-label="Article reference 37" data-doi="10.3758/bf03193146">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17695343" aria-label="PubMed reference 37">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=G%2APower%203%3A%20A%20flexible%20statistical%20power%20analysis%20program%20for%20the%20social%2C%20behavioral%2C%20and%20biomedical%20sciences&amp;journal=Behav.%20Res.%20Methods&amp;doi=10.3758%2Fbf03193146&amp;volume=39&amp;issue=2&amp;pages=175-191&amp;publication_year=2007&amp;author=Faul%2CF&amp;author=Erdfelder%2CE&amp;author=Lang%2CAG&amp;author=Buchner%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="38."><p id="ref-CR38">Cohen, J. <i>Statistical Power Analysis for the Behavioral Sciences</i> 2nd edn. (Routledge, 1988). <a href="https://doi.org/10.4324/9780203771587" data-track="click" data-track-action="external reference" data-track-label="10.4324/9780203771587">https://doi.org/10.4324/9780203771587</a>.</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.4324/9780203771587" data-track-action="book reference" href="https://doi.org/10.4324%2F9780203771587" aria-label="Book reference 38" data-doi="10.4324/9780203771587">Book</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=Statistical%20Power%20Analysis%20for%20the%20Behavioral%20Sciences&amp;doi=10.4324%2F9780203771587&amp;publication_year=1988&amp;author=Cohen%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="39."><p id="ref-CR39">Mischkowski, D., Kross, E. &amp; Bushman, B. J. Flies on the wall are less aggressive: Self-distancing “in the heat of the moment” reduces aggressive thoughts, angry feelings and aggressive behavior. <i>J. Exp. Soc. Psychol.</i> <b>48</b>(5), 1187–1191. <a href="https://doi.org/10.1016/j.jesp.2012.03.012" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.jesp.2012.03.012">https://doi.org/10.1016/j.jesp.2012.03.012</a> (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.jesp.2012.03.012" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jesp.2012.03.012" aria-label="Article reference 39" data-doi="10.1016/j.jesp.2012.03.012">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Flies%20on%20the%20wall%20are%20less%20aggressive%3A%20Self-distancing%20%E2%80%9Cin%20the%20heat%20of%20the%20moment%E2%80%9D%20reduces%20aggressive%20thoughts%2C%20angry%20feelings%20and%20aggressive%20behavior&amp;journal=J.%20Exp.%20Soc.%20Psychol.&amp;doi=10.1016%2Fj.jesp.2012.03.012&amp;volume=48&amp;issue=5&amp;pages=1187-1191&amp;publication_year=2012&amp;author=Mischkowski%2CD&amp;author=Kross%2CE&amp;author=Bushman%2CBJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="40."><p id="ref-CR40">Kubo, K., Okanoya, K. &amp; Kawai, N. Apology isn’t good enough: An apology suppresses an approach motivation but not the physiological and psychological anger. <i>Plos One</i> <b>7</b>(3), e33006. <a href="https://doi.org/10.1371/journal.pone.0033006" data-track="click" data-track-action="external reference" data-track-label="10.1371/journal.pone.0033006">https://doi.org/10.1371/journal.pone.0033006</a> (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0033006" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0033006" aria-label="Article reference 40" data-doi="10.1371/journal.pone.0033006">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="ads reference" href="http://adsabs.harvard.edu/cgi-bin/nph-data_query?link_type=ABSTRACT&amp;bibcode=2012PLoSO...733006K" aria-label="ADS reference 40">ADS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC38XltF2ltbg%3D" aria-label="CAS reference 40">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22457729" aria-label="PubMed reference 40">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3310858" aria-label="PubMed Central reference 40">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Apology%20isn%E2%80%99t%20good%20enough%3A%20An%20apology%20suppresses%20an%20approach%20motivation%20but%20not%20the%20physiological%20and%20psychological%20anger&amp;journal=Plos%20One&amp;doi=10.1371%2Fjournal.pone.0033006&amp;volume=7&amp;issue=3&amp;publication_year=2012&amp;author=Kubo%2CK&amp;author=Okanoya%2CK&amp;author=Kawai%2CN">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="41."><p id="ref-CR41">Sato, T. &amp; Yasuda, A. Development of the Japanese version of positive and negative affect schedule (PANAS) scales. <i>Japan J. Pers.</i> <b>9</b>(2), 138–139. <a href="https://doi.org/10.2132/jjpjspp.9.2_138" data-track="click" data-track-action="external reference" data-track-label="10.2132/jjpjspp.9.2_138">https://doi.org/10.2132/jjpjspp.9.2_138</a> (2001) (<b>in Japanese</b>).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.2132/jjpjspp.9.2_138" data-track-action="article reference" href="https://doi.org/10.2132%2Fjjpjspp.9.2_138" aria-label="Article reference 41" data-doi="10.2132/jjpjspp.9.2_138">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Development%20of%20the%20Japanese%20version%20of%20positive%20and%20negative%20affect%20schedule%20%28PANAS%29%20scales&amp;journal=Japan%20J.%20Pers.&amp;doi=10.2132%2Fjjpjspp.9.2_138&amp;volume=9&amp;issue=2&amp;pages=138-139&amp;publication_year=2001&amp;author=Sato%2CT&amp;author=Yasuda%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="42."><p id="ref-CR42">Harmon-Jones, E. &amp; Sigelman, J. State anger and prefrontal brain activity: Evidence that insult-related relative left-prefrontal activation is associated with experienced anger and aggression. <i>J. Personal. Soc. Psychol.</i> <b>80</b>(5), 797–803. <a href="https://doi.org/10.1037/0022-3514.80.5.797" data-track="click" data-track-action="external reference" data-track-label="10.1037/0022-3514.80.5.797">https://doi.org/10.1037/0022-3514.80.5.797</a> (2001).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/0022-3514.80.5.797" data-track-action="article reference" href="https://doi.org/10.1037%2F0022-3514.80.5.797" aria-label="Article reference 42" data-doi="10.1037/0022-3514.80.5.797">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BD3M3pt1Shsg%3D%3D" aria-label="CAS reference 42">CAS</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=State%20anger%20and%20prefrontal%20brain%20activity%3A%20Evidence%20that%20insult-related%20relative%20left-prefrontal%20activation%20is%20associated%20with%20experienced%20anger%20and%20aggression&amp;journal=J.%20Personal.%20Soc.%20Psychol.&amp;doi=10.1037%2F0022-3514.80.5.797&amp;volume=80&amp;issue=5&amp;pages=797-803&amp;publication_year=2001&amp;author=Harmon-Jones%2CE&amp;author=Sigelman%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="43."><p id="ref-CR43">JASP Team. (2020). JASP (Version 0.7) [Computer software]. <a href="https://jasp-stats.org/" data-track="click" data-track-action="external reference" data-track-label="https://jasp-stats.org">https://jasp-stats.org</a></p></li><li data-counter="44."><p id="ref-CR44">Zhang, Y., Risen, J. L. &amp; Hosey, C. Reversing one’s fortune by pushing away bad luck. <i>J. Exp. Psychol. General</i> <b>143</b>(3), 1171–1184. <a href="https://doi.org/10.1037/a0034023" data-track="click" data-track-action="external reference" data-track-label="10.1037/a0034023">https://doi.org/10.1037/a0034023</a> (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/a0034023" data-track-action="article reference" href="https://doi.org/10.1037%2Fa0034023" aria-label="Article reference 44" data-doi="10.1037/a0034023">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Reversing%20one%E2%80%99s%20fortune%20by%20pushing%20away%20bad%20luck&amp;journal=J.%20Exp.%20Psychol.%20General&amp;doi=10.1037%2Fa0034023&amp;volume=143&amp;issue=3&amp;pages=1171-1184&amp;publication_year=2014&amp;author=Zhang%2CY&amp;author=Risen%2CJL&amp;author=Hosey%2CC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="45."><p id="ref-CR45">Brinol, P., Petty, R. E. &amp; Wagner, B. Body posture effects on self-evaluation: A self-validation approach. <i>Eur. J. Soc. Psychol.</i> <b>39</b>(6), 1053–1064. <a href="https://doi.org/10.1002/ejsp.607" data-track="click" data-track-action="external reference" data-track-label="10.1002/ejsp.607">https://doi.org/10.1002/ejsp.607</a> (2009).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/ejsp.607" data-track-action="article reference" href="https://doi.org/10.1002%2Fejsp.607" aria-label="Article reference 45" data-doi="10.1002/ejsp.607">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=Body%20posture%20effects%20on%20self-evaluation%3A%20A%20self-validation%20approach&amp;journal=Eur.%20J.%20Soc.%20Psychol.&amp;doi=10.1002%2Fejsp.607&amp;volume=39&amp;issue=6&amp;pages=1053-1064&amp;publication_year=2009&amp;author=Brinol%2CP&amp;author=Petty%2CRE&amp;author=Wagner%2CB">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="46."><p id="ref-CR46">Kim, T. W., Duhachek, A., Briñol, P. &amp; Petty, R. E. Protect or hide your thoughts: The meanings associated with actions matter. In <i>NA-Advances in Consumer Research</i> (eds Cotte, J. &amp; Wood, S.) 96–100 (ACR, 2014).</p><p><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Protect%20or%20hide%20your%20thoughts%3A%20The%20meanings%20associated%20with%20actions%20matter&amp;pages=96-100&amp;publication_year=2014&amp;author=Kim%2CTW&amp;author=Duhachek%2CA&amp;author=Bri%C3%B1ol%2CP&amp;author=Petty%2CRE">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="47."><p id="ref-CR47">Rozin, P., Nemeroff, C., Wane, M. &amp; Sherrod, A. Operation of the sympathetic magical law of contagion in interpersonal attitudes among americans. <i>Bull. Psychon. Soc.</i> <b>27</b>(4), 367–370 (1989).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3758/BF03334630" data-track-action="article reference" href="https://doi.org/10.3758%2FBF03334630" aria-label="Article reference 47" data-doi="10.3758/BF03334630">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Operation%20of%20the%20sympathetic%20magical%20law%20of%20contagion%20in%20interpersonal%20attitudes%20among%20americans&amp;journal=Bull.%20Psychon.%20Soc.&amp;doi=10.3758%2FBF03334630&amp;volume=27&amp;issue=4&amp;pages=367-370&amp;publication_year=1989&amp;author=Rozin%2CP&amp;author=Nemeroff%2CC&amp;author=Wane%2CM&amp;author=Sherrod%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="48."><p id="ref-CR48">Rozin, P., Dunn, C. &amp; Fedotova, N. Reversing the causal arrow: Incidence and properties of negative backward magical contagion in Americans. <i>Judgm. Decis. Mak.</i> <b>13</b>(5), 441–450. <a href="https://doi.org/10.1017/S1930297500008718" data-track="click" data-track-action="external reference" data-track-label="10.1017/S1930297500008718">https://doi.org/10.1017/S1930297500008718</a> (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1017/S1930297500008718" data-track-action="article reference" href="https://doi.org/10.1017%2FS1930297500008718" aria-label="Article reference 48" data-doi="10.1017/S1930297500008718">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 48" href="http://scholar.google.com/scholar_lookup?&amp;title=Reversing%20the%20causal%20arrow%3A%20Incidence%20and%20properties%20of%20negative%20backward%20magical%20contagion%20in%20Americans&amp;journal=Judgm.%20Decis.%20Mak.&amp;doi=10.1017%2FS1930297500008718&amp;volume=13&amp;issue=5&amp;pages=441-450&amp;publication_year=2018&amp;author=Rozin%2CP&amp;author=Dunn%2CC&amp;author=Fedotova%2CN">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="49."><p id="ref-CR49">Denny, K. G. &amp; Siemer, M. Trait aggression is related to anger-modulated deficits in response inhibition. <i>J. Res. Person.</i> <b>46</b>(4), 450–454 (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.jrp.2012.04.001" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jrp.2012.04.001" aria-label="Article reference 49" data-doi="10.1016/j.jrp.2012.04.001">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=Trait%20aggression%20is%20related%20to%20anger-modulated%20deficits%20in%20response%20inhibition&amp;journal=J.%20Res.%20Person.&amp;doi=10.1016%2Fj.jrp.2012.04.001&amp;volume=46&amp;issue=4&amp;pages=450-454&amp;publication_year=2012&amp;author=Denny%2CKG&amp;author=Siemer%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="50."><p id="ref-CR50">Wilkowski, B. M. &amp; Robinson, M. D. Keeping one’s cool: Trait anger, hostile thoughts, and the recruitment of limited capacity control. <i>Person. Soc. Psychol. Bull.</i> <b>33</b>(9), 1201–1213 (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1177/0146167207301031" data-track-action="article reference" href="https://doi.org/10.1177%2F0146167207301031" aria-label="Article reference 50" data-doi="10.1177/0146167207301031">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 50" href="http://scholar.google.com/scholar_lookup?&amp;title=Keeping%20one%E2%80%99s%20cool%3A%20Trait%20anger%2C%20hostile%20thoughts%2C%20and%20the%20recruitment%20of%20limited%20capacity%20control&amp;journal=Person.%20Soc.%20Psychol.%20Bull.&amp;doi=10.1177%2F0146167207301031&amp;volume=33&amp;issue=9&amp;pages=1201-1213&amp;publication_year=2007&amp;author=Wilkowski%2CBM&amp;author=Robinson%2CMD">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="51."><p id="ref-CR51">Veenstra, L., Bushman, B. J. &amp; Koole, S. L. The facts on the furious: A brief review of the psychology of trait anger. <i>Curr. Opin. Psychol.</i> <a href="https://doi.org/10.1016/j.copsyc.2017.03.014" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.copsyc.2017.03.014">https://doi.org/10.1016/j.copsyc.2017.03.014</a> (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.copsyc.2017.03.014" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.copsyc.2017.03.014" aria-label="Article reference 51" data-doi="10.1016/j.copsyc.2017.03.014">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29279231" aria-label="PubMed reference 51">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20facts%20on%20the%20furious%3A%20A%20brief%20review%20of%20the%20psychology%20of%20trait%20anger&amp;journal=Curr.%20Opin.%20Psychol.&amp;doi=10.1016%2Fj.copsyc.2017.03.014&amp;publication_year=2018&amp;author=Veenstra%2CL&amp;author=Bushman%2CBJ&amp;author=Koole%2CSL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="52."><p id="ref-CR52">Peuters, C., Kalokerinos, E. K., Pe, M. L. &amp; Kuppens, P. Sequential effects of reappraisal and rumination on anger during recall of an anger-provoking event. <i>Plos One</i> <b>14</b>(1), e0209029. <a href="https://doi.org/10.1371/journal.pone.0209029" data-track="click" data-track-action="external reference" data-track-label="10.1371/journal.pone.0209029">https://doi.org/10.1371/journal.pone.0209029</a> (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0209029" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0209029" aria-label="Article reference 52" data-doi="10.1371/journal.pone.0209029">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1MXmtFems74%3D" aria-label="CAS reference 52">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30601837" aria-label="PubMed reference 52">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6314601" aria-label="PubMed Central reference 52">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 52" href="http://scholar.google.com/scholar_lookup?&amp;title=Sequential%20effects%20of%20reappraisal%20and%20rumination%20on%20anger%20during%20recall%20of%20an%20anger-provoking%20event&amp;journal=Plos%20One&amp;doi=10.1371%2Fjournal.pone.0209029&amp;volume=14&amp;issue=1&amp;publication_year=2019&amp;author=Peuters%2CC&amp;author=Kalokerinos%2CEK&amp;author=Pe%2CML&amp;author=Kuppens%2CP">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="53."><p id="ref-CR53">Lievaart, M., Huijding, J., van der Veen, F. M., Hovens, J. E. &amp; Franken, I. H. A. The impact of angry rumination on anger-primed cognitive control. <i>J. Behav. Ther. Exp. Psychiatry</i> <b>54</b>, 135–142. <a href="https://doi.org/10.1016/j.jbtep.2016.07.016" data-track="click" data-track-action="external reference" data-track-label="10.1016/j.jbtep.2016.07.016">https://doi.org/10.1016/j.jbtep.2016.07.016</a> (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.jbtep.2016.07.016" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.jbtep.2016.07.016" aria-label="Article reference 53" data-doi="10.1016/j.jbtep.2016.07.016">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27494341" aria-label="PubMed reference 53">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 53" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20impact%20of%20angry%20rumination%20on%20anger-primed%20cognitive%20control&amp;journal=J.%20Behav.%20Ther.%20Exp.%20Psychiatry&amp;doi=10.1016%2Fj.jbtep.2016.07.016&amp;volume=54&amp;pages=135-142&amp;publication_year=2017&amp;author=Lievaart%2CM&amp;author=Huijding%2CJ&amp;author=Veen%2CFM&amp;author=Hovens%2CJE&amp;author=Franken%2CIHA">
                    Google Scholar</a>&nbsp;
                </p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41598-024-57916-z?format=refman&amp;flavour=references">Download references</a></p></div></div><div id="Fun-section" data-title="Funding"><h2 id="Fun">Funding</h2><p>This study was supported by JSPS KAKENHI Grant Numbers 21K18552 and 21H04421, by Aoyama Gakuin University grant for ‘Projection Science,’ and by JST SPRING, Grant Number JPMJSP2125.</p></div><div id="author-information-section" aria-labelledby="author-information" data-title="Author information"><h2 id="author-information">Author information</h2><div id="author-information-content"><p><span id="author-notes">Author notes</span></p><ol><li id="nAff1"><p>Nobuyuki Kawai</p><p>Present address: Department of Cognitive and Psychological Sciences, Nagoya University, Nagoya, 464-8601, Japan</p></li></ol><h3 id="affiliations">Authors and Affiliations</h3><ol><li id="Aff1"><p>Department of Cognitive and Psychological Sciences, Nagoya University, Nagoya, 464-8601, Japan</p><p>Yuta Kanaya</p></li><li id="Aff2"><p>Academy of Emerging Science, Chubu University, Kasugai City, 487-8501, Japan</p><p>Nobuyuki Kawai</p></li></ol><div data-test="author-info"><p><span>Authors</span></p><ol><li id="auth-Yuta-Kanaya-Aff1"><span>Yuta Kanaya</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Yuta%20Kanaya" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yuta%20Kanaya%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li><li id="auth-Nobuyuki-Kawai-Aff1-Aff2"><span>Nobuyuki Kawai</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Nobuyuki%20Kawai" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Nobuyuki%20Kawai%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li></ol></div><h3 id="contributions">Contributions</h3><p>N.K.: Conceptualization, Methodology, Writing-Original draft preparation, Writing-Reviewing and Editing, Supervision, Validation. Y.K.: Data collection and curation, Writing-Original draft preparation Visualization, Investigation.</p><h3 id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:kawai@is.nagoya-u.ac.jp">Nobuyuki Kawai</a>.</p></div></div><div id="ethics-section" data-title="Ethics declarations"><h2 id="ethics">Ethics declarations</h2><div id="ethics-content">
              
                <h3 id="FPar1">Competing interests</h3>
                <p>The authors declare no competing interests.</p>
              
            </div></div><div id="additional-information-section" data-title="Additional information"><h2 id="additional-information">Additional information</h2><div id="additional-information-content"><h3>Publisher's note</h3><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div><div id="rightslink-section" data-title="Rights and permissions"><h2 id="rightslink">Rights and permissions</h2><div id="rightslink-content">
                <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
              <p><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Anger%20is%20eliminated%20with%20the%20disposal%20of%20a%20paper%20written%20because%20of%20provocation&amp;author=Yuta%20Kanaya%20et%20al&amp;contentID=10.1038%2Fs41598-024-57916-z&amp;copyright=The%20Author%28s%29&amp;publication=2045-2322&amp;publicationDate=2024-04-09&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and permissions</a></p></div></div><div id="article-info-section" aria-labelledby="article-info" data-title="About this article"><h2 id="article-info">About this article</h2><div id="article-info-content"><p><a data-crossmark="10.1038/s41598-024-57916-z" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41598-024-57916-z" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></p><div><h3 id="citeas">Cite this article</h3><p>Kanaya, Y., Kawai, N. Anger is eliminated with the disposal of a paper written because of provocation.
                    <i>Sci Rep</i> <b>14</b>, 7490 (2024). https://doi.org/10.1038/s41598-024-57916-z</p><p><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41598-024-57916-z?format=refman&amp;flavour=citation">Download citation</a></p><ul data-test="publication-history"><li><p>Received<span>: </span><span><time datetime="2023-02-09">09 February 2023</time></span></p></li><li><p>Accepted<span>: </span><span><time datetime="2024-03-22">22 March 2024</time></span></p></li><li><p>Published<span>: </span><span><time datetime="2024-04-09">09 April 2024</time></span></p></li><li><p><abbr title="Digital Object Identifier">DOI</abbr><span>: </span><span>https://doi.org/10.1038/s41598-024-57916-z</span></p></li></ul><h3>Keywords</h3></div></div></div>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Axion Processors – Arm-based CPUs designed for the data center (204 pts)]]></title>
            <link>https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu/</link>
            <guid>39978577</guid>
            <pubDate>Tue, 09 Apr 2024 12:12:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu/">https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu/</a>, See on <a href="https://news.ycombinator.com/item?id=39978577">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="tx2NYc"><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p><span>At Google, we constantly push the boundaries of computing, exploring what is possible for grand challenges ranging from information retrieval, global video distribution, and of course generative AI. Doing so requires rethinking systems design in deep collaboration with service developers. This rethinking has resulted in our significant investment in custom silicon. Today, we are thrilled to announce the latest incarnation of this work: Google Axion Processors, our first custom Arm®</span><span>-based CPUs designed for the data center. Axion delivers industry-leading performance and energy efficiency and will be available to Google Cloud customers later this year.</span></p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_Ab4940U.max-2000x2000.jpg" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_Ab4940U.max-2000x2000.jpg" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><p><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Run general-purpose workloads on C4A for exceptional performance, energy-efficiency and advanced capabilities.</p></span></p></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p><span>Axion is but the latest in a long line of custom Google silicon. Since 2015 we’ve released five generations of Tensor Processing Units (TPU); in 2018 we released our first Video Coding Unit (VCU), achieving up to </span><a href="https://dl.acm.org/doi/abs/10.1145/3445814.3446723" rel="noopener" target="_blank"><span>33x</span></a><span> more efficiency for video transcoding; </span><span>in 2021, we </span><a href="https://cloud.google.com/blog/topics/systems/the-past-present-and-future-of-custom-compute-at-google?e=48754805"><span>doubled-down</span></a><span> on custom compute by investing in “system on a chip” (SoC) designs, and released the </span><a href="https://blog.google/products/pixel/introducing-google-tensor/" rel="noopener" target="_blank"><span>first of three generations</span></a><span> of Tensor chips for mobile devices.&nbsp;</span></p>
<p><span>While our investments in compute accelerators have transformed our customers’ capabilities, general-purpose compute is and will remain a critical portion of our customers’ workloads. Analytics, information retrieval, and ML training and serving all require a huge amount of compute power. Customers and users who wish to maximize performance, reduce infrastructure costs, and meet sustainability goals have found that the rate of CPU improvements has slowed recently. Amdahl’s Law suggests that as accelerators continue to improve, general purpose compute will dominate the cost and limit the capability of our infrastructure unless we make commensurate investments to keep up.</span></p>
<p><span>Axion processors combine Google’s silicon expertise with Arm’s highest performing CPU cores to deliver instances with up to </span><span>30% better performance than the fastest general-purpose Arm-based instances available in the cloud today, up to 50% better performance and up to 60% better energy-efficiency than comparable current-generation x86-based instances<sup>1</sup>.</span><span> </span><span>That’s why we’ve already started deploying Google services like BigTable, Spanner, BigQuery, Blobstore, Pub/Sub, Google Earth Engine, and the YouTube Ads platform on current generation Arm-based servers and plan to deploy and scale these services and more on Axion soon.</span></p>
<h3><strong>Unrivaled performance and efficiency, underpinned by Titanium</strong></h3>
<p><span>Built using the Arm Neoverse</span><span><span>™</span></span><span> V2 CPU, Axion processors deliver giant leaps in performance </span><span>for general-purpose workloads like web and app servers, containerized microservices, open-source databases, in-memory caches, data analytics engines, media processing, CPU-based AI training and inferencing, and more.&nbsp;</span></p>
<p><span>Axion is underpinned b</span><span>y </span><a href="https://cloud.google.com/titanium?e=48754805"><span>Titanium</span></a><span>, a system of</span><span> purpose-built custom silicon microcontrollers and tiered scale-out offloads</span><span>. Titanium offloads take care of platform operations like networking and security, so Axion processors have more capacity and improved performance for customer workloads. Titanium also offloads storage I/O processing to </span><a href="https://cloud.google.com/compute/docs/disks/hyperdisks"><span>Hyperdisk</span></a><span>, our new block storage service that decouples performance from instance size and that can be dynamically provisioned in real time.&nbsp;</span></p>
<p><em>“Google’s announcement of the new Axion CPU marks a significant milestone in delivering custom silicon that is optimized for Google’s infrastructure, and built on our high-performance Arm Neoverse V2 platform. Decades of ecosystem investment, combined with Google’s ongoing innovation and open-source software contributions ensure the best experience for the workloads that matter most to customers running on Arm everywhere."</em> - Rene Haas, CEO, Arm</p>
<p><span>Beyond performance, customers want to operate more efficiently and meet their sustainability goals. </span><span>Google Cloud data centers are already 1.5X more efficient than the industry average and deliver 3X more computing power with the same amount of electrical power compared with five years ago<sup>2</sup>.</span><span> </span><span>We’ve set ambitious </span><a href="https://sustainability.google/operating-sustainably/" rel="noopener" target="_blank"><span>goals</span></a><span> to </span><span>operate our offices, campuses, and data centers on carbon-free energy, 24/7</span><span>, and offer </span><a href="https://cloud.google.com/carbon-footprint"><span>tools</span></a><span> to help you report on carbon emissions. With Axion processors, customers can optimize for even more energy-efficiency.&nbsp;</span></p>
<h3><strong>Axion - out-of-the-box application compatibility and interoperability</strong></h3>
<p><span>Google also has a rich history of contributions to the Arm ecosystem. We built and open sourced Android, Kubernetes, Tensorflow and the Go language, and worked closely with Arm and industry partners to optimize them for the Arm architecture.&nbsp;</span></p>
<p><span>Axion is built on the standard Armv9 architecture and instruction set. Most recently, we contributed to SystemReady Virtual Environment (VE), Arm’s hardware and firmware interoperability standard that ensures common operating systems and software packages can seamlessly run on Arm-based servers and VMs, making it easier for customers to deploy Arm workloads on Google Cloud with limited-if-any code rewrites. Through this collaboration, we’re accessing an ecosystem of tens of thousands of cloud customers already deploying workloads and leveraging Arm-native software from hundreds of ISVs and open-source projects.&nbsp;</span></p>
<p><span>Customers will be able to use Axion in many Google Cloud services including Google Compute Engine, Google Kubernetes Engine, Dataproc, Dataflow, Cloud Batch, and more.&nbsp; Arm-compatible software and solutions are now available on the </span><a href="https://cloud.google.com/marketplace?hl=en"><span>Google Cloud Marketplace</span></a><span>, and we've recently launched preview support for Arm-based instances migration in the </span><a href="https://cloud.google.com/migrate/virtual-machines"><span>Migrate to Virtual Machines</span></a><span> service.</span></p>
<h3><strong>What our customers and partners are saying</strong></h3>
<p><span>"</span><span>We're thrilled to add application packages built on the new Axion Arm-based CPU for Google Cloud to the Bitnami by VMware Tanzu library. This will deliver significantly improved performance, attractive price-performance, and better sustainability for our users. We're excited to get our hands on the new Google Axion instances and do even more to help our customers streamline deployments and reduce their environmental footprint."</span><span> - Mike Wookey, Senior Director R&amp;D, Tanzu Division, Broadcom</span></p>
<p><span>"Organizations all over the world rely on CrowdStrike and our single platform, single agent architecture to stop cloud breaches. CrowdStrike delivers the industry’s best protection while being the fastest to deploy, so we’re excited about testing Google's new processor to discover power and efficiency gains." </span><span>– Daniel Bernard, Chief Business Officer, CrowdStrike</span></p>
<p><span>“Our customers demand uncompromising cybersecurity protection that our systems provide. We're intrigued by the power and efficiency gains possible with the new Google Cloud's custom Arm-based CPU and plan to validate its capabilities as a way to provide even better threat detection and response capabilities to our customers.” - </span><span>Tzach Segal, VP Business Development, Cybereason</span></p>
<p><span>“Datadog has been a trusted partner for customers adopting Arm-based virtual machines and an early adopter of Arm for our own operations. We’re excited about Google Cloud's announcement of the Axion processor and plan to evaluate it on our workloads as we help customers measure the cost and performance benefits of using Datadog on Google Cloud Arm instances.”</span><span> - </span><span>Yrieix Garnier, VP of Product Management</span><span>, Datadog</span></p>
<p><span>“Elastic is committed to helping customers unlock the potential of all their structured and unstructured data efficiently at any scale. We look forward to testing Google Cloud's new custom Arm-based CPU and expect it to help us provide an even better Elastic customer experience on the Google Cloud Platform.” </span><span>- Steve Kearns, VP of Product, Elastic</span><span>&nbsp;</span></p>
<p><span>“We’ve built a strong partnership with Google Cloud over many years and have seen the benefits of building on GCP Arm-based VMs. We can’t wait to see the remarkable improvements coming with the new generation Arm-based Axion processor.” </span><span>- Joel Meyer, SVP, Engineering, OpenX </span><span>&nbsp;</span></p>
<p><span>"Snap empowers everyone to express themselves, live in the moment, learn about the world, and have fun together. We're constantly optimizing our infrastructure for performance and efficiency. Google's new Axion Arm-based CPU promises major leaps forward in both. The potential to serve our community with these gains while leading on our sustainability goals is incredibly exciting. We look forward to seeing the benefits of Axion-based virtual machines when they become available." - </span><span>Korwin Smith, Sr Director of Engineering, Cloud Infrastructure, Snap</span></p>
<p><span>“WP Engine powers websites for more than 1.5 million customers across 150 countries. They rely on WP Engine to deliver on our core promises of performance, reliability, and security and we take that responsibility to heart. Our commitment to innovation and a customer-inspired mindset means we’re always looking for ways to further enhance our customers’ performance and confidence online. We’re excited to test Google’s new custom Arm-based processor and its anticipated performance and sustainability gains, and explore how they can empower our customers to create even more compelling websites and applications.”</span><span> - Ramadass Prabhakar, SVP and CTO, WP Engine</span></p>
<h3><strong>Learn more</strong></h3>
<p><span>Virtual machines based on Axion processors will be available in preview in the coming months. </span><a href="https://docs.google.com/forms/d/e/1FAIpQLSdmFDDBNffCScti1FLlum71Q2V9kBANNKIy_2fd85iSgMcj9Q/viewform" rel="noopener" target="_blank"><span>Register your interest today</span></a><span>! And if you’re here at Next ‘24, come learn more about Axion and other compute announcements in these related sessions:</span></p>
<ul>
<li>
<p><strong>SPTL205</strong><span> - </span><a href="https://cloud.withgoogle.com/next/session-library?filters=session-type-spotlight&amp;session=SPTL205#all" rel="noopener" target="_blank"><span>Workload-optimized and AI-powered Infrastructure</span></a></p>
</li>
<li>
<p><strong>ARC225 </strong><span>- </span><a href="https://cloud.withgoogle.com/next/session-library?filters=session-type-spotlight&amp;session=ARC225#all" rel="noopener" target="_blank"><span>Transform your cloud operations and design capability with Gemini for Google Cloud</span></a></p>
</li>
<li>
<p><strong>ARC229 </strong><span>- </span><a href="https://cloud.withgoogle.com/next/session-library?filters=session-type-spotlight,track-infrastructure-architects-admins&amp;session=ARC229#all" rel="noopener" target="_blank"><span>Best practices to manage and automate on Compute Engine</span></a></p>
</li>
</ul>
<hr>
<p><sup><em><span><span>1. Google Cloud Internal Data, 31 March 2024<br>2. <a href="https://www.gstatic.com/gumdrop/sustainability/google-2023-environmental-report.pdf" rel="noopener" target="_blank"><span>Google Environmental Report</span></a><span>, 2023, page 10.</span></span></span></em></sup></p></span></section><section><span>Posted in</span><ul><li><a href="https://cloud.google.com/blog/products/compute" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/compute" track-metadata-module="tag list" track-metadata-module_headline="posted in">Compute</a></li><li><a href="https://cloud.google.com/blog/topics/google-cloud-next" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/topics/google-cloud-next" track-metadata-module="tag list" track-metadata-module_headline="posted in">Google Cloud Next</a></li><li><a href="https://cloud.google.com/blog/products/ai-machine-learning" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/ai-machine-learning" track-metadata-module="tag list" track-metadata-module_headline="posted in">AI &amp; Machine Learning</a></li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Total eclipse of the Internet: traffic impacts in Mexico, the US, and Canada (101 pts)]]></title>
            <link>https://blog.cloudflare.com/total-eclipse-internet-traffic-impacts-mexico-us-canada</link>
            <guid>39978396</guid>
            <pubDate>Tue, 09 Apr 2024 11:41:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cloudflare.com/total-eclipse-internet-traffic-impacts-mexico-us-canada">https://blog.cloudflare.com/total-eclipse-internet-traffic-impacts-mexico-us-canada</a>, See on <a href="https://news.ycombinator.com/item?id=39978396">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post"><article><p>04/09/2024</p><section><p>5 min read</p><div><figure><img src="https://blog.cloudflare.com/content/images/2024/04/Image_20240408_140523_866-x.jpeg" alt="" loading="lazy" width="2144" height="1232"><figcaption>A photo of the eclipse taken by Bryton Herdes, a member of Cloudflare's Network team, in Southern Illinois.</figcaption></figure><p>There are events that unite people, like a total solar eclipse, reminding us, humans living on planet Earth, of our shared dependence on the sun. Excitement was obvious in Mexico, several US states, and Canada during the total solar <a href="https://en.wikipedia.org/wiki/Solar_eclipse_of_April_8,_2024">eclipse</a> that occurred on April 8, 2024. Dubbed the Great North American Eclipse, millions gathered outdoors to witness the Moon pass between Earth and the Sun, casting darkness over fortunate states. Amidst the typical gesture of putting the eclipse glasses on and taking them off, depending on if people were looking at the sky during the total eclipse, or before or after, what happened to Internet traffic?</p><p>Cloudflare’s data shows a clear impact on Internet traffic from Mexico to Canada, following the path of totality. The eclipse occurred between 15:42 UTC and 20:52 UTC, moving from south to north, as seen in this <a href="https://science.nasa.gov/eclipses/future-eclipses/eclipse-2024/">NASA image</a> of the path and percentage of darkness of the eclipse.</p><figure><img src="https://blog.cloudflare.com/content/images/2024/04/nasaimage.png" alt="" loading="lazy" width="1600" height="1299"></figure><p>Looking at the <a href="https://radar.cloudflare.com/us">United States</a> in aggregate terms, bytes delivered traffic dropped by 8%, and request traffic by 12% as compared to the previous week at 19:00 UTC (14:00 Eastern, 12:00 Pacific).</p><figure><img src="https://blog.cloudflare.com/content/images/2024/04/cloudflare-radar-traffic-trends-xy-20240408-20240408--1--2.png" alt="" loading="lazy" width="2048" height="1152"><figcaption>Bytes delivered percentage change (-8% at 19:00 UTC)</figcaption></figure><figure><img src="https://blog.cloudflare.com/content/images/2024/04/percchange-eclipse-2024-04-08-at-22.27.27.png" alt="" loading="lazy" width="2106" height="648"><figcaption>HTTP requests percentage change (-12% at 19:00 UTC)</figcaption></figure><p>The state-level perspective in terms of traffic drop at the time of the eclipse, as compared to the previous week, is much more revealing. Here’s a summary of the US states' traffic changes. We can almost trace the path of the eclipse, as shown in the previous NASA image.</p><figure><img src="https://blog.cloudflare.com/content/images/2024/04/Eclipse-US-2024-04-08-at-23.45.02-1.jpg" alt="" loading="lazy" width="2244" height="1546"></figure><p>From our data, Vermont, Arkansas, Indiana, Maine, New Hampshire, and Ohio experienced traffic drops of 40% or more around the time of the eclipse. These states were all in the path of totality, which was not the case for several others.</p><p>In the next table, we provide a detailed breakdown of the same perspective shown on the US map ordered by drop in traffic. In all of these charts, we're using UTC as the time. We include the time of the biggest traffic drop compared to the previous week, at a 5-minute granularity, and also the percentage of drop compared to the previous week. States where it was possible to see at least part of the total eclipse are highlighted in <strong>bold</strong>. At the bottom are those with no clear difference.</p><!--kg-card-begin: html--><table><colgroup><col width="117"><col width="83"><col width="101"><col width="104"></colgroup><tbody><tr><td colspan="4"><p dir="ltr"><span>The US: traffic change at time of the eclipse</span></p></td></tr><tr><td><p dir="ltr"><span>State</span></p></td><td><p dir="ltr"><span>Time of drop (UTC)</span></p></td><td><p dir="ltr"><span>Local time</span></p></td><td><p dir="ltr"><span>% of drop</span></p></td></tr><tr><td><p dir="ltr"><span>Vermont</span></p></td><td><p dir="ltr"><span>19:25</span></p></td><td><p dir="ltr"><span>15:25</span></p></td><td><p dir="ltr"><span>-60%</span></p></td></tr><tr><td><p dir="ltr"><span>Arkansas</span></p></td><td><p dir="ltr"><span>18:50</span></p></td><td><p dir="ltr"><span>13:50</span></p></td><td><p dir="ltr"><span>-54%</span></p></td></tr><tr><td><p dir="ltr"><span>Indiana</span></p></td><td><p dir="ltr"><span>19:05</span></p></td><td><p dir="ltr"><span>15:05</span></p></td><td><p dir="ltr"><span>-50%</span></p></td></tr><tr><td><p dir="ltr"><span>Maine</span></p></td><td><p dir="ltr"><span>19:30</span></p></td><td><p dir="ltr"><span>15:30</span></p></td><td><p dir="ltr"><span>-48%</span></p></td></tr><tr><td><p dir="ltr"><span>New Hampshire</span></p></td><td><p dir="ltr"><span>19:20</span></p></td><td><p dir="ltr"><span>15:20</span></p></td><td><p dir="ltr"><span>-40%</span></p></td></tr><tr><td><p dir="ltr"><span>Ohio</span></p></td><td><p dir="ltr"><span>19:10</span></p></td><td><p dir="ltr"><span>15:10</span></p></td><td><p dir="ltr"><span>-40%</span></p></td></tr><tr><td><p dir="ltr"><span>Kentucky</span></p></td><td><p dir="ltr"><span>19:05</span></p></td><td><p dir="ltr"><span>14:05</span></p></td><td><p dir="ltr"><span>-33%</span></p></td></tr><tr><td><p dir="ltr"><span>Massachusetts</span></p></td><td><p dir="ltr"><span>19:25</span></p></td><td><p dir="ltr"><span>15:25</span></p></td><td><p dir="ltr"><span>-33%</span></p></td></tr><tr><td><p dir="ltr"><span>Michigan</span></p></td><td><p dir="ltr"><span>19:15</span></p></td><td><p dir="ltr"><span>15:15</span></p></td><td><p dir="ltr"><span>-32%</span></p></td></tr><tr><td><p dir="ltr"><span>Kansas</span></p></td><td><p dir="ltr"><span>18:50</span></p></td><td><p dir="ltr"><span>13:50</span></p></td><td><p dir="ltr"><span>-31%</span></p></td></tr><tr><td><p dir="ltr"><span>Missouri</span></p></td><td><p dir="ltr"><span>18:55</span></p></td><td><p dir="ltr"><span>13:55</span></p></td><td><p dir="ltr"><span>-31%</span></p></td></tr><tr><td><p dir="ltr"><span>Connecticut</span></p></td><td><p dir="ltr"><span>19:20</span></p></td><td><p dir="ltr"><span>15:20</span></p></td><td><p dir="ltr"><span>-29%</span></p></td></tr><tr><td><p dir="ltr"><span>Maryland</span></p></td><td><p dir="ltr"><span>19:15</span></p></td><td><p dir="ltr"><span>15:15</span></p></td><td><p dir="ltr"><span>-29%</span></p></td></tr><tr><td><p dir="ltr"><span>New York</span></p></td><td><p dir="ltr"><span>19:25</span></p></td><td><p dir="ltr"><span>15:25</span></p></td><td><p dir="ltr"><span>-29%</span></p></td></tr><tr><td><p dir="ltr"><span>Oklahoma</span></p></td><td><p dir="ltr"><span>18:45</span></p></td><td><p dir="ltr"><span>13:45</span></p></td><td><p dir="ltr"><span>-29%</span></p></td></tr><tr><td><p dir="ltr"><span>Rhode Island</span></p></td><td><p dir="ltr"><span>19:25</span></p></td><td><p dir="ltr"><span>15:25</span></p></td><td><p dir="ltr"><span>-29%</span></p></td></tr><tr><td><p dir="ltr"><span>New Jersey</span></p></td><td><p dir="ltr"><span>19:20</span></p></td><td><p dir="ltr"><span>15:20</span></p></td><td><p dir="ltr"><span>-28%</span></p></td></tr><tr><td><p dir="ltr"><span>Arizona</span></p></td><td><p dir="ltr"><span>18:15</span></p></td><td><p dir="ltr"><span>11:15</span></p></td><td><p dir="ltr"><span>-27%</span></p></td></tr><tr><td><p dir="ltr"><span>Illinois</span></p></td><td><p dir="ltr"><span>19:05</span></p></td><td><p dir="ltr"><span>14:05</span></p></td><td><p dir="ltr"><span>-26%</span></p></td></tr><tr><td><p dir="ltr"><span>Pennsylvania</span></p></td><td><p dir="ltr"><span>19:15</span></p></td><td><p dir="ltr"><span>15:15</span></p></td><td><p dir="ltr"><span>-26%</span></p></td></tr><tr><td><p dir="ltr"><span>West Virginia</span></p></td><td><p dir="ltr"><span>19:15</span></p></td><td><p dir="ltr"><span>15:15</span></p></td><td><p dir="ltr"><span>-24%</span></p></td></tr><tr><td><p dir="ltr"><span>Wisconsin</span></p></td><td><p dir="ltr"><span>19:05</span></p></td><td><p dir="ltr"><span>14:05</span></p></td><td><p dir="ltr"><span>-22%</span></p></td></tr><tr><td><p dir="ltr"><span>Wyoming</span></p></td><td><p dir="ltr"><span>18:20</span></p></td><td><p dir="ltr"><span>12:20</span></p></td><td><p dir="ltr"><span>-19%</span></p></td></tr><tr><td><p dir="ltr"><span>Alaska</span></p></td><td><p dir="ltr"><span>20:15</span></p></td><td><p dir="ltr"><span>12:15</span></p></td><td><p dir="ltr"><span>-18%</span></p></td></tr><tr><td><p dir="ltr"><span>Delaware</span></p></td><td><p dir="ltr"><span>19:20</span></p></td><td><p dir="ltr"><span>15:20</span></p></td><td><p dir="ltr"><span>-18%</span></p></td></tr><tr><td><p dir="ltr"><span>District of Columbia</span></p></td><td><p dir="ltr"><span>19:15</span></p></td><td><p dir="ltr"><span>15:15</span></p></td><td><p dir="ltr"><span>-16%</span></p></td></tr><tr><td><p dir="ltr"><span>New Mexico</span></p></td><td><p dir="ltr"><span>18:25</span></p></td><td><p dir="ltr"><span>12:25</span></p></td><td><p dir="ltr"><span>-16%</span></p></td></tr><tr><td><p dir="ltr"><span>Oregon</span></p></td><td><p dir="ltr"><span>18:15</span></p></td><td><p dir="ltr"><span>11:15</span></p></td><td><p dir="ltr"><span>-16%</span></p></td></tr><tr><td><p dir="ltr"><span>Nebraska</span></p></td><td><p dir="ltr"><span>18:50</span></p></td><td><p dir="ltr"><span>13:50/12:50</span></p></td><td><p dir="ltr"><span>-15%</span></p></td></tr><tr><td><p dir="ltr"><span>Texas</span></p></td><td><p dir="ltr"><span>18:45</span></p></td><td><p dir="ltr"><span>13:45</span></p></td><td><p dir="ltr"><span>-15%</span></p></td></tr><tr><td><p dir="ltr"><span>Colorado</span></p></td><td><p dir="ltr"><span>18:25</span></p></td><td><p dir="ltr"><span>12:25</span></p></td><td><p dir="ltr"><span>-14%</span></p></td></tr><tr><td><p dir="ltr"><span>Virginia</span></p></td><td><p dir="ltr"><span>18:20</span></p></td><td><p dir="ltr"><span>14:20</span></p></td><td><p dir="ltr"><span>-14%</span></p></td></tr><tr><td><p dir="ltr"><span>Alabama</span></p></td><td><p dir="ltr"><span>19:00</span></p></td><td><p dir="ltr"><span>14:00</span></p></td><td><p dir="ltr"><span>-13%</span></p></td></tr><tr><td><p dir="ltr"><span>Tennessee</span></p></td><td><p dir="ltr"><span>19:00</span></p></td><td><p dir="ltr"><span>15:00/14:00</span></p></td><td><p dir="ltr"><span>-13%</span></p></td></tr><tr><td><p dir="ltr"><span>Iowa</span></p></td><td><p dir="ltr"><span>18:15</span></p></td><td><p dir="ltr"><span>13:15</span></p></td><td><p dir="ltr"><span>-12%</span></p></td></tr><tr><td><p dir="ltr"><span>Nevada</span></p></td><td><p dir="ltr"><span>18:10</span></p></td><td><p dir="ltr"><span>11:10</span></p></td><td><p dir="ltr"><span>-12%</span></p></td></tr><tr><td><p dir="ltr"><span>Georgia</span></p></td><td><p dir="ltr"><span>19:05</span></p></td><td><p dir="ltr"><span>15:05</span></p></td><td><p dir="ltr"><span>-11%</span></p></td></tr><tr><td><p dir="ltr"><span>North Carolina</span></p></td><td><p dir="ltr"><span>19:10</span></p></td><td><p dir="ltr"><span>15:10</span></p></td><td><p dir="ltr"><span>-10%</span></p></td></tr><tr><td><p dir="ltr"><span>California</span></p></td><td><p dir="ltr"><span>18:15</span></p></td><td><p dir="ltr"><span>11:15</span></p></td><td><p dir="ltr"><span>-9%</span></p></td></tr><tr><td><p dir="ltr"><span>Florida</span></p></td><td><p dir="ltr"><span>18:15</span></p></td><td><p dir="ltr"><span>14:15</span></p></td><td><p dir="ltr"><span>-7%</span></p></td></tr><tr><td><p dir="ltr"><span>Utah</span></p></td><td><p dir="ltr"><span>18:15</span></p></td><td><p dir="ltr"><span>12:15</span></p></td><td><p dir="ltr"><span>-5%</span></p></td></tr><tr><td><p dir="ltr"><span>Montana</span></p></td><td><p dir="ltr"><span>18:25</span></p></td><td><p dir="ltr"><span>12:25</span></p></td><td><p dir="ltr"><span>-4%</span></p></td></tr><tr><td><p dir="ltr"><span>South Carolina</span></p></td><td><p dir="ltr"><span>19:00</span></p></td><td><p dir="ltr"><span>15:00</span></p></td><td><p dir="ltr"><span>-4%</span></p></td></tr><tr><td><p dir="ltr"><span>Hawaii</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td></tr><tr><td><p dir="ltr"><span>Louisiana</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td></tr><tr><td><p dir="ltr"><span>Minnesota</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td></tr><tr><td><p dir="ltr"><span>Mississippi</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td></tr><tr><td><p dir="ltr"><span>North Dakota</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td></tr><tr><td><p dir="ltr"><span>Idaho</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td></tr><tr><td><p dir="ltr"><span>South Dakota</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td></tr><tr><td><p dir="ltr"><span>Washington</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td><td><p dir="ltr"><span>—</span></p></td></tr></tbody></table><!--kg-card-end: html--><p>Visualized, here's what Vermont’s 60% drop looks like:</p><figure><img src="https://blog.cloudflare.com/content/images/2024/04/vermont.png" alt="" loading="lazy" width="1600" height="483"></figure><p>And here's what the traffic drops in Arkansas, Maine, and Indiana look like:</p><figure><img src="https://blog.cloudflare.com/content/images/2024/04/arkansas.png" alt="" loading="lazy" width="1600" height="480"></figure><figure><img src="https://blog.cloudflare.com/content/images/2024/04/maine.png" alt="" loading="lazy" width="1600" height="509"></figure><figure><img src="https://blog.cloudflare.com/content/images/2024/04/indiana.png" alt="" loading="lazy" width="1600" height="488"></figure><p>In terms of states with larger populations, New York took the lead:</p><figure><img src="https://blog.cloudflare.com/content/images/2024/04/newyork.png" alt="" loading="lazy" width="1600" height="482"></figure><h2 id="mexico-got-the-eclipse-first">Mexico got the eclipse first</h2><p>Before the eclipse became visible in the US, Mexico experienced it first. States within the eclipse zone, such as Coahuila, Durango, and Sinaloa, experienced noticeable drops in traffic. Even Mexico City, located further south, was affected.</p><!--kg-card-begin: html--><table><colgroup><col width="100"><col width="100"><col width="100"><col width="107"></colgroup><tbody><tr><td colspan="4"><p dir="ltr"><span>Mexico: traffic change at time of the eclipse</span></p></td></tr><tr><td><p dir="ltr"><span>State</span></p></td><td><p dir="ltr"><span>Time of drop (UTC)</span></p></td><td><p dir="ltr"><span>Local time</span></p></td><td><p dir="ltr"><span>% of drop</span></p></td></tr><tr><td><p dir="ltr"><span>Durango</span></p></td><td><p dir="ltr"><span>18:15</span></p></td><td><p dir="ltr"><span>12:15</span></p></td><td><p dir="ltr"><span>-57%</span></p></td></tr><tr><td><p dir="ltr"><span>Coahuila</span></p></td><td><p dir="ltr"><span>18:15</span></p></td><td><p dir="ltr"><span>12:15</span></p></td><td><p dir="ltr"><span>-43%</span></p></td></tr><tr><td><p dir="ltr"><span>Sinaloa</span></p></td><td><p dir="ltr"><span>18:10</span></p></td><td><p dir="ltr"><span>11:10</span></p></td><td><p dir="ltr"><span>-34%</span></p></td></tr><tr><td><p dir="ltr"><span>Mexico City</span></p></td><td><p dir="ltr"><span>18:10</span></p></td><td><p dir="ltr"><span>12:10</span></p></td><td><p dir="ltr"><span>-22%</span></p></td></tr></tbody></table><!--kg-card-end: html--><p>Here’s the Durango and Coahuila state perspectives:</p><figure><img src="https://blog.cloudflare.com/content/images/2024/04/durango.png" alt="" loading="lazy" width="1600" height="476"></figure><figure><img src="https://blog.cloudflare.com/content/images/2024/04/cohal.png" alt="" loading="lazy" width="1600" height="480"></figure><h2 id="canada-at-last-an-island-stopped-to-see-the-eclipse">Canada at last: an island stopped to see the eclipse</h2><p>After Mexico and the US, Canada was next in the path of the eclipse. Prince Edward Island experienced the most significant impact in Canada. This region, with a population of less than 200,000, is one of eastern Canada's maritime provinces, situated off New Brunswick and Nova Scotia in the Gulf of St. Lawrence. Next came New Brunswick and Newfoundland and Labrador.</p><!--kg-card-begin: html--><table><colgroup><col width="138"><col width="94"><col width="77"><col width="89"></colgroup><tbody><tr><td colspan="4"><p dir="ltr"><span>Canada: traffic change at time of the eclipse</span></p></td></tr><tr><td><p dir="ltr"><span>State</span></p></td><td><p dir="ltr"><span>Time of drop (UTC)</span></p></td><td><p dir="ltr"><span>Local time</span></p></td><td><p dir="ltr"><span>% of drop</span></p></td></tr><tr><td><p dir="ltr"><span>Prince Edward Island</span></p></td><td><p dir="ltr"><span>19:35</span></p></td><td><p dir="ltr"><span>16:35</span></p></td><td><p dir="ltr"><span>-48%</span></p></td></tr><tr><td><p dir="ltr"><span>New Brunswick</span></p></td><td><p dir="ltr"><span>19:30</span></p></td><td><p dir="ltr"><span>16:30</span></p></td><td><p dir="ltr"><span>-40%</span></p></td></tr><tr><td><p dir="ltr"><span>Newfoundland and Labrador</span></p></td><td><p dir="ltr"><span>19:40</span></p></td><td><p dir="ltr"><span>16:10</span></p></td><td><p dir="ltr"><span>-32%</span></p></td></tr><tr><td><p dir="ltr"><span>Nova Scotia</span></p></td><td><p dir="ltr"><span>19:35</span></p></td><td><p dir="ltr"><span>16:35</span></p></td><td><p dir="ltr"><span>-27%</span></p></td></tr><tr><td><p dir="ltr"><span>Quebec</span></p></td><td><p dir="ltr"><span>19:25</span></p></td><td><p dir="ltr"><span>15:25</span></p></td><td><p dir="ltr"><span>-27%</span></p></td></tr><tr><td><p dir="ltr"><span>Ontario</span></p></td><td><p dir="ltr"><span>19:15</span></p></td><td><p dir="ltr"><span>15:15</span></p></td><td><p dir="ltr"><span>-21%</span></p></td></tr></tbody></table><!--kg-card-end: html--><h2 id="conclusion-internet-is-a-human%E2%80%99s-game">Conclusion: Internet is a human’s game</h2><p>As we've observed during previous occasions, human and nature-related events significantly impact Internet traffic. This includes <a href="https://blog.cloudflare.com/cyber-week-analyzing-internet-traffic-and-e-commerce-trends">Black Friday/Cyber Week</a>, <a href="https://blog.cloudflare.com/easter-passover-ramadan-internet-trends-2023">Easter, Ramadan</a> celebrations, the <a href="https://blog.cloudflare.com/how-the-coronation-of-king-charles-iii-affected-internet-traffic">coronation of King Charles III</a>, the recent <a href="https://blog.cloudflare.com/undersea-cable-failures-cause-internet-disruptions-across-africa-march-14-2024">undersea cable failure in Africa</a>, which affected 13 countries, and now, this total eclipse. </p><p>This was the last total solar eclipse visible in the contiguous United States until August 23, 2044, with the next eclipse of similar breadth projected for August 12, 2045.</p><p>For this and other trends, visit <a href="https://radar.cloudflare.com/">Cloudflare Radar</a> and follow us on social media at <a href="https://twitter.com/CloudflareRadar">@CloudflareRadar</a> (X), <a href="https://cloudflare.social/@radar">cloudflare.social/@radar</a> (Mastodon), and <a href="https://bsky.app/profile/radar.cloudflare.com">radar.cloudflare.com</a> (Bluesky).<br></p></div></section><div><p>We protect <a target="_blank" href="https://www.cloudflare.com/network-services/" rel="noreferrer">entire corporate networks</a>, help customers build <a target="_blank" href="https://workers.cloudflare.com/" rel="noreferrer">Internet-scale applications efficiently</a>, accelerate any <a target="_blank" href="https://www.cloudflare.com/performance/accelerate-internet-applications/" rel="noreferrer">website or Internet application</a>, <a target="_blank" href="https://www.cloudflare.com/ddos/" rel="noreferrer">ward off DDoS attacks</a>, keep <a target="_blank" href="https://www.cloudflare.com/application-security/" rel="noreferrer">hackers at bay</a>, and can help you on <a target="_blank" href="https://www.cloudflare.com/products/zero-trust/" rel="noreferrer">your journey to Zero Trust</a>.</p><p>Visit <a target="_blank" href="https://one.one.one.one/" rel="noreferrer">1.1.1.1</a> from any device to get started with our free app that makes your Internet faster and safer.</p><p>To learn more about our mission to help build a better Internet, <a target="_blank" href="https://www.cloudflare.com/learning/what-is-cloudflare/" rel="noreferrer">start here</a>. If you're looking for a new career direction, check out <a target="_blank" href="https://www.cloudflare.com/careers" rel="noreferrer">our open positions</a>.</p></div><a href="https://blog.cloudflare.com/tag/cloudflare-radar">Cloudflare Radar</a><a href="https://blog.cloudflare.com/tag/trends">Trends</a><a href="https://blog.cloudflare.com/tag/internet-traffic">Internet Traffic</a></article></div><div data-testid="related-posts-section"><p>Related posts</p><article data-testid="related-posts-article"><p data-testid="related-posts-article-date" data-iso-date="2024-03-26T13:00:20.000+00:00">March 26, 2024  1:00 PM</p><a data-testid="related-posts-article-title" href="https://blog.cloudflare.com/top-level-domains-email-phishing-threats"><h2>From .com to .beauty: The evolving threat landscape of unwanted email</h2></a><p data-testid="related-posts-article-excerpt">In this 2023-early 2024 email analysis, we examine how certain generic Top-Level Domains (TLDs) are primarily used for spam and phishing, and their evolution over a year. There are many trends in email threats to examine<!-- -->...</p><ul><span>By<!-- -->&nbsp;</span><li></li></ul></article><article data-testid="related-posts-article"><p data-testid="related-posts-article-date" data-iso-date="2024-03-14T18:03:25.000+00:00">March 14, 2024  6:03 PM</p><a data-testid="related-posts-article-title" href="https://blog.cloudflare.com/undersea-cable-failures-cause-internet-disruptions-across-africa-march-14-2024"><h2>Undersea cable failures cause Internet disruptions for multiple African countries</h2></a><p data-testid="related-posts-article-excerpt">Internet connectivity in several African countries was disrupted on March 14, 2024, beginning at approximately 05:00 UTC. Based on published reports and social media posts from impacted network providers, the disruption is believed to be due to multiple undersea cable failures in the region<!-- -->...</p><ul><span>By<!-- -->&nbsp;</span><li></li><li></li></ul></article><article data-testid="related-posts-article"><p data-testid="related-posts-article-date" data-iso-date="2024-03-08T14:00:58.000+00:00">March 08, 2024  2:00 PM</p><a data-testid="related-posts-article-title" href="https://blog.cloudflare.com/email-security-insights-on-cloudflare-radar"><h2>Launching email security insights on Cloudflare Radar</h2></a><p data-testid="related-posts-article-excerpt">The new Email Security section on Cloudflare Radar provides insights into the latest trends around threats found in malicious email, sources of spam and malicious email, and the adoption of technologies designed to prevent abuse of email<!-- -->...</p><ul><span>By<!-- -->&nbsp;</span><li></li></ul></article><article data-testid="related-posts-article"><p data-testid="related-posts-article-date" data-iso-date="2024-02-12T17:21:46.000+00:00">February 12, 2024  5:21 PM</p><a data-testid="related-posts-article-title" href="https://blog.cloudflare.com/super-bowl-lviii"><h2>A look at Internet traffic trends during Super Bowl LVIII</h2></a><p data-testid="related-posts-article-excerpt">Super Bowl LVIII was a close game, with the Chiefs winning in overtime. In this post, we explore how key moments during the game impacted Internet traffic, as well as looking at the traffic trends driven by advertisements that aired during the game<!-- -->...</p><ul><span>By<!-- -->&nbsp;</span><li></li></ul></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SSSL – Hackless SSL bypass for the Wii U (203 pts)]]></title>
            <link>https://github.com/PretendoNetwork/SSSL</link>
            <guid>39977862</guid>
            <pubDate>Tue, 09 Apr 2024 10:03:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/PretendoNetwork/SSSL">https://github.com/PretendoNetwork/SSSL</a>, See on <a href="https://news.ycombinator.com/item?id=39977862">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">SSSL - Hackless SSL bypass for the Wii U</h2><a id="user-content-sssl---hackless-ssl-bypass-for-the-wii-u" aria-label="Permalink: SSSL - Hackless SSL bypass for the Wii U" href="#sssl---hackless-ssl-bypass-for-the-wii-u"></a></p>
<div dir="auto">
	<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/PretendoNetwork/SSSL/blob/master/shutter.png"><img src="https://github.com/PretendoNetwork/SSSL/raw/master/shutter.png"></a></p></div>
<p dir="auto">On March 1, 2021 Nintendo released Wii U firmware version <a href="https://wiiubrew.org/wiki/5.5.5" rel="nofollow">5.5.5</a>. This update updated the Wii U's SSL verification and recompiled all RPLs (though no code changes were made). The exact purpose for this update is unknown, as nothing of significance was changed, and no other changes were made in this update. With the changes to SSL verification, Nintendo introduced a bug which allows for the forging of SSL certificates. These forged certificates will be seen as "Nintendo Signed" and, due to an existing bug with how the Wii U handles CA common names, will be accepted by all domains.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The bugs</h2><a id="user-content-the-bugs" aria-label="Permalink: The bugs" href="#the-bugs"></a></p>
<p dir="auto">There are 2 bugs at play:</p>
<ol dir="auto">
<li>Normally a CA common name does not accept a single wildcard (*) value. They must contain a hostname, and optionally one or many wildcards for subdomains. The Wii U will accept a single * wildcard in place of a hostname, which allows the CA to be accepted as any domain. This bug has existed since before 5.5.5, but was not useful until now.</li>
<li>As of 5.5.5, CA's crafted in a specific way may take a newly introduced alternate path for verification. This allows for a CA's signature to not be verified correctly. Instead, the Wii U simply checks if the CA matches one already known by the system, but not the signature or contents of the CA. We have no idea why this change was made, as it does not benefit Nintendo at all. It almost feels intentional.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Exploiting</h2><a id="user-content-exploiting" aria-label="Permalink: Exploiting" href="#exploiting"></a></p>
<p dir="auto">Not any CA will work. There are 3 conditions for a CA which still need to be met even for a forged CA to be accepted:</p>
<ol dir="auto">
<li>The CA needs to be one which the Wii U would already accept. The signature is not validated in this case, so modifying an existing CA works.</li>
<li>The Wii U does not allow a Root CA in the cert chain. It will ignore any certs that have a matching subject and authority key.</li>
<li>The title must not roll it's own SSL. WebKit titles such as the eShop, Miiverse, TVii, etc, as well as any game which uses it's own SSL library, will not work with these certificates.</li>
</ol>
<p dir="auto">The easiest way to exploit this bug is to use the Nintendo CA - G3 CA, and is what this script opts to do. This can be dumped from a Wii U's SSL certificates title at <code>/storage_mlc/sys/title/0005001b/10054000/content/scerts/CACERT_NINTENDO_CA_G3.der</code>. Changing the public key to a user-controlled key and changing the authority key identifier to anything else is all that is required. The resulting user-controlled private key and patched CA can be used to bypass SSL verification without any homebrew or CFW at all.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The script</h2><a id="user-content-the-script" aria-label="Permalink: The script" href="#the-script"></a></p>
<p dir="auto">This script takes in a PEM encoded copy of Nintendo CA - G3 and does the above patches and exports the patched CA and private key.</p>
<ul dir="auto">
<li>Install <a href="https://nodejs.org/" rel="nofollow">NodeJS</a></li>
<li><code>git clone https://github.com/PretendoNetwork/SSSL</code></li>
<li><code>cd SSSL</code></li>
<li><code>npm i</code> to install the dependencies</li>
<li><code>node patch</code> to run the patching wizard</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<ul dir="auto">
<li>Shutterbug for actually finding the new verification bug</li>
<li>Jemma and Quarky for decompiling the updated SSL functions</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sqlime: Online SQLite Playground (131 pts)]]></title>
            <link>https://github.com/nalgeon/sqlime</link>
            <guid>39977231</guid>
            <pubDate>Tue, 09 Apr 2024 08:24:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/nalgeon/sqlime">https://github.com/nalgeon/sqlime</a>, See on <a href="https://news.ycombinator.com/item?id=39977231">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Sqlime</h2><a id="user-content-sqlime" aria-label="Permalink: Sqlime" href="#sqlime"></a></p>
<p dir="auto"><strong><a href="http://sqlime.org/" rel="nofollow">Sqlime</a></strong> is an online SQLite playground for debugging and sharing SQL snippets. Kinda like JSFiddle, but for SQL instead of JavaScript.</p>
<p dir="auto">🌟 <strong>New!</strong> Turn static SQL code in your articles into <a href="https://codapi.org/sqlite/" rel="nofollow">interactive examples</a>.</p>
<a href="https://sqlime.org/" rel="nofollow">
    <img src="https://github.com/nalgeon/sqlime/raw/main/img/sqlime.jpg" alt="Sqlime" width="600">
</a>
<p dir="auto">Here are some notable features:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔋 Full-blown database in the browser</h3><a id="user-content--full-blown-database-in-the-browser" aria-label="Permalink: 🔋 Full-blown database in the browser" href="#-full-blown-database-in-the-browser"></a></p>
<p dir="auto">Sqlime is backed by the latest version of SQLite via the <a href="https://github.com/nalgeon/sqlean.js">sqlean.js</a> project. It provides a full-featured SQL implementation, including indexes, triggers, views, transactions, CTEs, window functions and execution plans.</p>
<p dir="auto">It also includes essential SQLite extensions, from math statistics and regular expressions to hash functions and dynamic SQL.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔌 Connect any data source</h3><a id="user-content--connect-any-data-source" aria-label="Permalink: 🔌 Connect any data source" href="#-connect-any-data-source"></a></p>
<p dir="auto">Connect any local or remote SQLite database. Both files and URLs are supported. For example, try loading the <a href="http://sqlime.org/#https://raw.githubusercontent.com/nalgeon/sqliter/main/employees.en.db" rel="nofollow">Employees&nbsp;database</a> from the GitHub repo.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔗 Save and share with others</h3></p>
<p dir="auto">Sqlime saves both the database and the queries to GitHub so that you can revisit them later or share them with a colleague. The database is stored as a plain text SQL dump, so it's easy to read the code or import data into PostgreSQL, MySQL, or other databases.</p>
<p dir="auto">For example, here is the <a href="https://gist.github.com/nalgeon/e012594111ce51f91590c4737e41a046">gist</a> for the Employees database, and here is the <a href="https://sqlime.org/#gist:e012594111ce51f91590c4737e41a046" rel="nofollow">sharing&nbsp;link</a> for it.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🤖 Ask AI</h3><a id="user-content--ask-ai" aria-label="Permalink: 🤖 Ask AI" href="#-ask-ai"></a></p>
<p dir="auto">Connect an OpenAI account to get help with your queries from the state-of-the-art ChatGPT assistant. AI can explain, teach, and troubleshoot your SQL.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nalgeon/sqlime/blob/main/img/sqlime-ai.jpg"><img src="https://github.com/nalgeon/sqlime/raw/main/img/sqlime-ai.jpg" alt="Ask AI" width="600"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">📱 Mobile friendly</h3><a id="user-content--mobile-friendly" aria-label="Permalink: 📱 Mobile friendly" href="#-mobile-friendly"></a></p>
<p dir="auto">Most playgrounds are not meant for small screens. Sqlime was specifically designed and tested on mobile devices. No need to zoom or aim at tiny buttons — everything looks and works just fine.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔒 Secure and private</h3><a id="user-content--secure-and-private" aria-label="Permalink: 🔒 Secure and private" href="#-secure-and-private"></a></p>
<p dir="auto">There is no server. Sqlime works completely in the browser. GitHub and OpenAI credentials are also stored locally. Queries are saved as private GitHub gists within your account. Your data is yours only.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">⌨️ Dead simple</h3><a id="user-content-️-dead-simple" aria-label="Permalink: ⌨️ Dead simple" href="#️-dead-simple"></a></p>
<p dir="auto">Sqlime has zero third-party dependencies other than SQLite. Good old HTML, CSS, and vanilla JS — that's all. No frameworks, no heavy editors, no obsolete and vulnerable libraries. Just some modular open-source code, which is easy to grasp and extend.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Last but not least</h2><a id="user-content-last-but-not-least" aria-label="Permalink: Last but not least" href="#last-but-not-least"></a></p>
<p dir="auto"><strong>⭐️ Star the project</strong> if you like it</p>
<p dir="auto">🚀 <a href="https://antonz.org/subscribe/" rel="nofollow"><strong>Subscribe</strong></a> to stay on top of new features</p>
<p dir="auto">🍋 <a href="https://sqlime.org/" rel="nofollow"><strong>Use Sqlime</strong></a> to debug and share SQL snippets</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The U.S. government may finally mandate safer table saws (170 pts)]]></title>
            <link>https://www.npr.org/2024/04/02/1241148577/table-saw-injuries-safety-sawstop-cpsc</link>
            <guid>39977058</guid>
            <pubDate>Tue, 09 Apr 2024 07:48:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2024/04/02/1241148577/table-saw-injuries-safety-sawstop-cpsc">https://www.npr.org/2024/04/02/1241148577/table-saw-injuries-safety-sawstop-cpsc</a>, See on <a href="https://news.ycombinator.com/item?id=39977058">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storytext">
      <div id="res1241402462">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s400-c85.webp 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s600-c85.webp 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s800-c85.webp 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s900-c85.webp 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1200-c85.webp 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1600-c85.webp 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1800-c85.webp 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s400-c85.jpg 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s600-c85.jpg 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s800-c85.jpg 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s900-c85.jpg 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1200-c85.jpg 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1600-c85.jpg 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1800-c85.jpg 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1100-c50.jpg" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                Tom Noffsinger stands in his garage workshop, where he uses a SawStop table saw for woodworking at his home in Raleigh, North Carolina. About 20 years ago, Noffsinger had a table saw accident and almost lost his thumb.
                <b aria-label="Image credit">
                    
                    Cornell Watson for NPR
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Cornell Watson for NPR
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1200.webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1200.jpg" type="image/jpeg">
            <img data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1200.jpg" alt="" src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-1_custom-cd0af616b9bdba9faea62ef6aaee9a68a8d16daa-s1200.jpg">
        </picture>
    </div>
<div>
        <p>Tom Noffsinger stands in his garage workshop, where he uses a SawStop table saw for woodworking at his home in Raleigh, North Carolina. About 20 years ago, Noffsinger had a table saw accident and almost lost his thumb.</p>
        <p><span aria-label="Image credit">
            
            Cornell Watson for NPR
            
        </span>
    </p></div>
   </div>
   <p>One day about 20 years ago, Tom Noffsinger experienced every woodworker's worst nightmare: One final cut on his table saw before knocking off for the day turned into a trip to the emergency room. It was afternoon, and he'd been in his shop since morning.</p>   <p>"I was a little tired. I should've quit," Noffsinger says. "I ran my hand right into the blade and nearly cut my thumb off."</p>   <p>Table saws are widely considered the <a href="https://www.npr.org/2010/07/05/127780027/sharp-edge-one-mans-quest-to-improve-saw-safety">most dangerous power tool</a>, and approximately <a href="https://www.federalregister.gov/documents/2017/05/12/2017-09098/safety-standard-addressing-blade-contact-injuries-on-table-saws#:~:text=In%202015%2C%20there%20were%20an,contact%20with%20the%20saw%20blade.">30,000</a> blade-contact injuries<strong> </strong>require medical treatment each year in the United States. About 4,000 result in amputations that can be career-ending for some professional carpenters and contractors. The Consumer Product Safety Commission says that when a person is hospitalized, the societal cost per table saw injury exceeds $500,000 when you also factor in loss of income and pain and suffering.</p>   
   
   
<!-- END ID="RES1241667138" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>Noffsinger was lucky by comparison. Although he needed 14 stitches, doctors at a hospital near his home in Raleigh, N.C., were able to save his thumb. Reconstructive surgery followed. Even so, all these years later, he says he still has recurring pain.</p>   <div id="res1241402767">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s400-c85.webp 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s600-c85.webp 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s800-c85.webp 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s900-c85.webp 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1200-c85.webp 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1600-c85.webp 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1800-c85.webp 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s400-c85.jpg 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s600-c85.jpg 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s800-c85.jpg 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s900-c85.jpg 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1200-c85.jpg 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1600-c85.jpg 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1800-c85.jpg 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1100-c50.jpg" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                Noffsinger opens a wooden box that he made using a SawStop table saw, which uses technology to prevent serious injury.
                <b aria-label="Image credit">
                    
                    Cornell Watson for NPR
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Cornell Watson for NPR
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1200.webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1200.jpg" type="image/jpeg">
            <img data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1200.jpg" alt="" src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-17_custom-a62d6068c175c7dfbb9eefd548db008b0d9bf195-s1200.jpg">
        </picture>
    </div>
<div>
        <p>Noffsinger opens a wooden box that he made using a SawStop table saw, which uses technology to prevent serious injury.</p>
        <p><span aria-label="Image credit">
            
            Cornell Watson for NPR
            
        </span>
    </p></div>
   </div>
   <p>Woodworking has been a nearly lifelong passion for Noffsinger, and he was no stranger to power tools. Back before his accident, he'd seen a demonstration of a new and much safer type of table saw at a local woodworking store. Marketed under the name SawStop, it was designed to <a href="https://www.youtube.com/watch?v=SYLAi4jwXcs">stop and retract the spinning blade</a> within a few milliseconds of making contact with flesh — fast enough to turn a potentially life-changing injury into little more than a scratch. Noffsinger's table saw wasn't equipped with the high-tech safety feature because manufacturers aren't required to include it.</p>   
<div id="res1241667654">
    <p>
        <iframe src="https://www.youtube.com/embed/fq3o0VGUh50?rel=0" width="100%" height="100%" frameborder="0" allowfullscreen=""></iframe>
    </p>
        <p><b>
                    
                    <b>YouTube</b>
                </b>
        </p>
</div>   <p>But that may be about to change. The federal Consumer Product Safety Commission (CPSC) appears poised to mandate a SawStop-type safety brake on all new table saws sold in the United States. The move would follow years of failed efforts and false starts by the agency to impose such a standard.</p>   <p>Manufacturers have consistently fought a new rule, saying it would raise the price of table saws for consumers. Safety advocates liken it to air bags in cars and argue that the benefits outweigh the costs.</p>   
   <p>Over the years, Republicans on the commission have sided with the power tool industry in opposing further regulations. But with new Biden administration appointees, proponents on the commission appear to have a majority. In October, the CPSC <a href="https://www.federalregister.gov/documents/2023/12/11/2023-27133/safety-standard-addressing-blade-contact-injuries-on-table-saws-notice-of-extension-of-comment#:~:text=On%20October%2018%2C%202023%2C%20the,closes%20on%20January%202%2C%202024.">voted</a> to move forward on the mandate, which is expected to get approval later this year.</p>   <p>"We've got a [proposed] rule that is designed to prevent tens of thousands of medically treated table saw injuries per year," says CPSC Commissioner Richard Trumka Jr. "That's something that I very much support."</p>   <h3>Proponents say a new standard is long overdue</h3>   <p>Former acting CPSC Chairman Robert Adler says a standard requiring a blade brake "is long, long overdue." An average of more than 10 people per day in the U.S. suffer amputations on these types of saws, and "that is staggering when you think about it," he says. "I'm so thrilled to see it's very likely to occur now."</p>   <p>Adler, who was appointed by President Barack Obama in 2009 and served on the commission for 12 years, is a veteran of the fight for a new table saw safety standard. He calls the failure to require this type of feature on saws "the greatest single frustration I felt" while on the commission. He says that's because table saws are far and away the most dangerous tool that most Americans ever buy.</p>   <p>SawStop's competitors are represented by the <a href="https://www.powertoolinstitute.com/">Power Tool Institute</a>, the trade group that includes big power-tool makers such as Bosch, DeWalt and Milwaukee, as well as lesser-known brands. The group maintains that the new safety rule would be an overreach.</p>   <p>"Small manufacturers may go out of business," Susan Orenga, the Power Tool Institute's executive manager, said at a public hearing on the new rule in February. Requiring the safety brake would raise the cost of table saws too much, she said. "Sales of table saws will decrease, resulting in unemployment, and the government could be creating a monopoly."</p>   
   <p>The industry has long maintained that since SawStop owns patents surrounding the safety technology, the company would unduly benefit from such a government-imposed standard. But at the same hearing where Orenga spoke, SawStop pledged to allow manufacturers to produce safer saws regardless of those patents.</p>   <h3>Table saw safety comes at a price</h3>   <p>Exactly how much the safety brake would add to the price of a saw is unclear. An entry-level SawStop retails for $899. A comparable saw without the safety technology goes for several hundred dollars less.</p>   <p>But with the economies of scale enjoyed by larger competitors, the price difference could be narrower down the road.</p>   <div id="res1241403640">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s400-c85.webp 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s600-c85.webp 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s800-c85.webp 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s900-c85.webp 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1200-c85.webp 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1600-c85.webp 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1800-c85.webp 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s400-c85.jpg 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s600-c85.jpg 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s800-c85.jpg 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s900-c85.jpg 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1200-c85.jpg 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1600-c85.jpg 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1800-c85.jpg 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1100-c50.jpg" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                SawStops retail for hundreds of dollars more than the competition, depending on the manufacturer and the type of table saw. Unlike less expensive brands sold in big-box stores, SawStops are at the premium end of the market.
                <b aria-label="Image credit">
                    
                    Cornell Watson for NPR
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Cornell Watson for NPR
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1200.webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1200.jpg" type="image/jpeg">
            <img data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1200.jpg" alt="" src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-25_custom-7a2ece725d97d260cbe59018a8c1f00ea18ce0cc-s1200.jpg">
        </picture>
    </div>
<div>
        <p>SawStops retail for hundreds of dollars more than the competition, depending on the manufacturer and the type of table saw. Unlike less expensive brands sold in big-box stores, SawStops are at the premium end of the market.</p>
        <p><span aria-label="Image credit">
            
            Cornell Watson for NPR
            
        </span>
    </p></div>
   </div>
   <p>Since <a href="https://www.sawstop.com/company/#:~:text=The%20technology%20was%20invented%20by,SawStop%20Table%20Saw%20was%20sold.">SawStop came onto the market in 2004</a>, tens of thousands of the company's table saws have been sold in the U.S., and the company estimates that this has saved tens of thousands of professional and hobbyist woodworkers from injury.</p>   <p>The key to the SawStop is its <a href="https://www.sawstop.com/service-tips/active-injury-mitigation-aim-system-and-brake-cartridge-replacement-for-the-compact-table-saw-cts/">active injury mitigation</a> (AIM) system, which sends a small electrical charge through the saw blade, and because skin is conductive, the system senses whether the blade is touched. Basically, wood doesn't conduct electricity, but people do. When a hand comes in contact with the blade on a SawStop, this triggers a brake to stop the blade from spinning. This occurs so quickly that there's not enough time for a serious injury.</p>   <p>Sally Greenberg, executive director of the National Consumers League, has been interested in table saw safety since first hearing about the SawStop technology on <a href="https://www.npr.org/2004/12/07/4182602/table-saw-technology-aims-to-save-fingers">NPR</a> in 2004. Like Adler, she has been frustrated by the slow progress on a new safety standard.</p>   <p>"This is a category of product that could be made in this case 100% safe, but because of industry foot-dragging and resistance and lobbying power in Congress and with agencies, you have a situation of two steps forward, one step back," she says.</p>   
   <p>Until recently, SawStop competitors were largely prevented from developing AIM-type technology by a web of patents now owned by German-based TTS Tooltechnic Systems, which bought SawStop in 2017. But 20 years after the first SawStop was sold, most of those patents have now expired.</p>   <h3>SawStop vows to free up a key patent for rivals</h3>   <p>However, one key patent — the "840" patent — is not set to expire until 2033. To stave off potential competitors, it describes the AIM technology very broadly. In a surprise move at February's CPSC hearing, TTS Tooltechnic Systems North America CEO Matt Howard announced that the company would "dedicate the 840 patent to the public" if a new safety standard were adopted. Howard says that this would free up rivals to pursue their own safety devices or simply copy SawStop's. At the hearing, he challenged them "to get in the game."</p>   
   
<!-- END ID="RES1242019064" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>Howard's concession follows years of bad blood between SawStop and the larger power tool companies. Before starting SawStop, the inventor of its technology, <a href="https://www.npr.org/2011/05/25/136617222/advocates-urge-lawmakers-to-make-table-saws-safer">Steve Gass</a> — himself a patent attorney — tried to interest manufacturers in licensing his idea. He got no takers. And years later, when Bosch Power Tools began selling a saw with its own version of an injury-mitigation system, SawStop <a href="https://www.sawstop.com/news/sawstop-sues-bosch-to-protect-inventions/">won a patent-infringement suit </a>against the company. TTS subsequently agreed to let Bosch sell the saw, but Bosch never reintroduced it to the U.S. market.</p>   <p>That lawsuit, however, has been cited by the industry to buttress its claim that any move to develop similar safety features would be aggressively met by SawStop and TTS.</p>   <p>There are other industry objections as well. Orenga notes that manufacturers already comply with a voluntary standard requiring blade guards and anti-kickback features designed to prevent a blade from catching a piece of wood and throwing it violently back at the operator.</p>   <h3>"Flimsy, poorly functioning guards" don't help</h3>   <p>But according to the CPSC, it's common for table saw users to "<a href="https://www.federalregister.gov/documents/2023/11/01/2023-23898/safety-standard-addressing-blade-contact-injuries-on-table-saws">remove modular blade guards</a>," often for reasons of "improved visibility" — in other words, because they can't easily see the cut they are trying to make.</p>   
   <p>As a result, the CPSC says, it has seen no discernible change in the number of blade-contact injuries since the industry adopted a voluntary requirement for improved blade guards and other safety features in 2010. In short, the voluntary standard "doesn't adequately reduce the risk of injury," Trumka says, which is why the commission is pursuing a mandatory standard.</p>   <p>Jim Hamilton, who hosts a popular <a href="https://www.youtube.com/@StumpyNubs">woodworking channel on YouTube</a>, says most table saw injuries could be prevented if woodworkers consistently used a blade guard. "Sadly, a culture has developed around many power tools, including table saws, that suggests safety devices are unnecessary or obstructive," he says, noting that even "veteran workers, including those who have worked at the highest levels of their trade, are seriously injured every day."</p>   <p>The situation is made worse, Hamilton says, by manufacturers including "flimsy, poorly functioning guards" that actually encourage users to remove them.</p>   <h3>Table saws cause a "vaporizing" type of injury</h3>   <p>Richard Bodor, a San Diego-based plastic surgeon, is all too familiar with the kind of catastrophic hand injuries that saw blades can cause.</p>   <p>The one he remembers most vividly occurred about 25 years ago, before SawStops were on the market. While he was operating one night to replant an amputated finger, the emergency room called about another "four-finger replant" being referred from Bodor's colleague — a senior surgeon and mentor. At first, Bodor thought his colleague was simply inquiring about another patient. He soon realized it was the surgeon himself who was injured.</p>   <p>That surgeon had been operating a table saw when his glove caught the saw blade and pulled in his hand. Bodor says the injured surgeon was surprisingly calm during pre-op, as the two discussed the complicated procedure to reconstruct the man's mangled hand.</p>   
   
<!-- END ID="RES1242011842" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>Referring to each of his shredded fingers, the injured surgeon applied his own expertise to the reconstruction. "'I think this finger is going to make it. Now, I'm a little worried about this guy. However, I think this small one might be toast,'" Bodor said, recalling their conversation.</p>   <p>After a long recovery, Bodor said, the man eventually was able to resume surgeries. But these types of saw injuries are especially challenging and difficult to repair, he says. Unlike a clean amputation from a sharp cooking knife, he explains, a table saw blade actually obliterates the tissue. "It's a vaporizing type of injury," he says, adding that replantation typically requires hours of meticulous microsurgery.</p>   
   <p>But not everyone is convinced that a new safety standard alone will prevent such devastating injuries. Dale Juntunen owns a contracting firm in Deer River, Minn., that has been building homes for more than 40 years. "In all the years I've been in business, we've never had anybody get hurt" on a table saw, he says.</p>   <p>"If it's mandated, you're going to have people hanging on to their old saws forever," Juntunen says. "And, you know, that's when I'd say there will be more injuries on an old saw."</p>   <div id="res1241403994">
            <div data-crop-type="">
        <picture>
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s400-c85.webp 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s600-c85.webp 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s800-c85.webp 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s900-c85.webp 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1200-c85.webp 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1600-c85.webp 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1800-c85.webp 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/webp">
            <source srcset="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s400-c85.jpg 400w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s600-c85.jpg 600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s800-c85.jpg 800w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s900-c85.jpg 900w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1200-c85.jpg 1200w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1600-c85.jpg 1600w,
https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1800-c85.jpg 1800w" sizes="(min-width: 1300px) 763px, (min-width: 1025px) calc(100vw - 496px), (min-width: 768px) calc(100vw - 171px), calc(100vw - 30px)" type="image/jpeg">
            <img src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1100-c50.jpg" alt="" loading="lazy">
        </picture>
        
</div>
<div>
    <div>
        <p>
                Noffsinger purchased a SawStop when he returned from the hospital after his table saw injury, and he has been using it ever since.
                <b aria-label="Image credit">
                    
                    Cornell Watson for NPR
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Cornell Watson for NPR
        
    </span>
</p></div>
<div>
        <picture>
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1200.webp" type="image/webp">
            <source data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1200.jpg" type="image/jpeg">
            <img data-original="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1200.jpg" alt="" src="https://media.npr.org/assets/img/2024/03/28/sawstop-npr-cw-19_custom-266565243d181afe6139d6b3551d73581898a5ad-s1200.jpg">
        </picture>
    </div>
<div>
        <p>Noffsinger purchased a SawStop when he returned from the hospital after his table saw injury, and he has been using it ever since.</p>
        <p><span aria-label="Image credit">
            
            Cornell Watson for NPR
            
        </span>
    </p></div>
   </div>
   <p>Noffsinger, the North Carolina hobbyist woodworker, says even though he was injured, he's not sure mandating new safety technology on all saws is the best idea.</p>   <p>Still, when he returned home from the emergency room after nearly severing his thumb on a saw blade, he was met by his wife, "hands on her hips," he says. "She said, 'You will buy that SawStop thing.' So that's what I did."</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Interview with Yanis Varoufakis on Technofeudalism (165 pts)]]></title>
            <link>https://www.wired.com/story/yanis-varoufakis-technofeudalism-interview/</link>
            <guid>39977002</guid>
            <pubDate>Tue, 09 Apr 2024 07:38:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/yanis-varoufakis-technofeudalism-interview/">https://www.wired.com/story/yanis-varoufakis-technofeudalism-interview/</a>, See on <a href="https://news.ycombinator.com/item?id=39977002">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The tech giants have overthrown capitalism. That’s the argument of former Greek finance minister Yanis Varoufakis, who became famous trying to defend debt-laden Greece from its German creditors. Varoufakis has never quite regained the notoriety of 2015. But he has remained a prominent left-wing voice. After a failed campaign for a seat in the European Parliament in 2019, he plans to run again this June. This time, his adversary isn’t Berlin or the banks. It’s the tech companies he accuses of warping the economy while turning people against one other.</p><div data-testid="GenericCallout"><figure><p><span>Courtesy of Penguin Random House</span></p></figure></div><p>Varoufakis is also a prolific author; his 17th book, written as a letter to his techno-curious father, chronicles the evolution of capitalism from the 1960s advertising boom, through Wall Street in the 1980s, to the 2008 financial crisis and the pandemic. In its most compelling stretches, <a data-offer-url="https://www.amazon.com/Technofeudalism-Killed-Capitalism-Yanis-Varoufakis/dp/1685891241" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.amazon.com/Technofeudalism-Killed-Capitalism-Yanis-Varoufakis/dp/1685891241&quot;}" href="https://www.amazon.com/Technofeudalism-Killed-Capitalism-Yanis-Varoufakis/dp/1685891241" rel="noopener" target="_blank"><em>Technofeudalism</em></a> argues that Apple, Facebook, and Amazon have changed the economy so much that it now resembles Europe’s medieval feudal system. The tech giants are the lords, while everyone else is a peasant, working their land for not much in return.</p><p>To Varoufakis, every time you post on X, formerly Twitter, you’re essentially toiling Elon Musk’s estate like a medieval serf. Musk doesn't pay you. But your free labor pays him, in a sense, by increasing the value of his company. On X, the more active users there are, the more people can be shown advertising or sold subscriptions. On Google Maps, he argues, users improve the product—alerting the system to traffic jams on their route.</p><p>The feudal comparison isn’t novel. But <em>Technofeudalism</em> attempts to introduce the idea to a wider audience. Its US release, launched the month before regulators in the <a href="https://www.wired.com/story/doj-sues-apple-antitrust/">US</a> and <a href="https://www.wired.com/story/apple-meta-alphabet-eu-digital-markets-act/">European Union</a> simultaneously initiated antitrust actions against Apple, also had impeccable timing.</p><p>Over Zoom, I spoke to Varoufakis, from his home near Athens, about how the tech giants have changed the economy—and why we should care about it.</p><p><em>This interview has been edited for length and clarity.</em></p><p><strong>WIRED: That word, <em>technofeudalism</em>, what does it mean? How is the feudal system relevant here?</strong></p><p><strong>Yanis Varoufakis:</strong> Profit drives capitalism, rent drove feudalism. Now we have moved [from one system to the other] because of this new form of super-duper, all-singing, all-dancing capital: cloud capital, algorithmic capital. If I'm right, that is creating new digital fiefdoms like Amazon.com, like Airbnb, where the main mode of wealth extraction comes in the form not of profit but of rent.</p><p>Take the Apple Store. You are producing an app, Apple can withhold 30 percent of your profits [through a commission fee]. That's a rent. That's like a ground rent. It's a bit like the Apple Store is a fiefdom. It's a cloud fiefdom, and Apple extracts a rent exactly as in feudalism. So my argument is not that we went back from capitalism to feudalism. My argument is that we have progressed forward to a new system, which has many of the characteristics of feudalism, but it is one step ahead of capitalism. To signal that, I added the word <em>techno</em>.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><strong>When you're talking about these digital fiefdoms, the idea is easier to understand in terms of platforms that take a cut of the sales, like the Apple App Store or Amazon. But can you also accuse other platforms of operating these digital fiefs, like Facebook?</strong></p><p>Facebook is a classic cloud fief. It creates cloud capital which is attractive to you, to me, to other people who want to communicate with each other—to find friends, or post their views, or news about their dog or their cat. So you're drawn into this fiefdom, and then the next step for Zuckerberg was to draw into the same fiefdom publishers and advertisers in order to sell them the attention of users. And then immediately after that, as Cory Doctorow so beautifully describes through his concept of <a href="https://www.wired.com/story/tiktok-platforms-cory-doctorow/">enshittification</a>, you're a publisher, you feel great because your sales go up through Facebook, and then suddenly, you find that you've been downgraded. And then you have to pay a higher cloud rent in order to be re-upgraded [paying for ads, for example, for customers to find your product]. That’s typical cloud capitalism, producing technofeudalism.</p><p><strong>I understand technofeudalism as affecting three groups of people. Can we boil down who is affected into these groups?</strong></p><p>Yes, and I've given them names. The company that produces the electric bicycles sold on Alibaba or Amazon.com, this is a vassal capitalist. Most of the profit margin for that company is skimmed off by Jeff Bezos [Amazon’s founder and executive chairman] in the form of cloud rent.</p><p>Second is cloud proles, or cloud proletarians. Look at the workers in Amazon warehouses who are monitored by algorithms.</p><p>And the third one is you and me. I call us cloud serfs. Because the parallel with the serfs is that we <em>volunteer</em> free labor. It doesn't matter whether we're enjoying it or not. Every time you upload a video on Tiktok, on Facebook, on Instagram, you're adding to the capital stock of these companies. We are adding to it directly through our labor or our movement or our existence. In that way we're serfs, but we are more than serfs, we’re cloud serfs producing capital. And that has never happened in the history of the world.</p><p><strong>A company like Apple might argue that instead of being a fiefdom, maybe the Apple App Store is more like a mall where companies have to rent their stores from whomever owns the building. How is technofeudalism different from the mall dynamic?</strong></p><p>Well, hugely. Say you and I were going into partnership together with a fashion brand. We go to the shopping mall and we hire a shop, the rent is fixed. It is not proportional to our sales. The more money we make, the higher our price-to-rent margin. With the Apple Store, they get 30 percent of all sales. That’s not at all the same thing. That is the equivalent of the ground rent that the feudal lord used to extract from vassal capitalists.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><strong>What makes cloud capitalism a worse economic system than capitalism?</strong></p><p>The first thing is from a macroeconomic perspective. When you have such a large sum of money extracted in the form of cloud rent, that money disappears from a circular flow of income. According to my calculations, between 35 and 40 percent of GDP is being siphoned off the circular flow of income by cloud rent, and that means there is less money in the economy. Investment is low, and that means less good, quality jobs in the rest of the economy.</p><p>The second reason is that this cloud capital is designed to reproduce itself through our attention and through our free labor. And platforms discovered that we spend more time doing this, producing free cloud capital for the owners of cloud capital, if we're angry. So algorithms are primed to poison our conversations. That is highly detrimental to our democracies because consensus is really bad for cloud capital. It doesn't want it. It wants you and me to be angry and shouting at each other.</p><p>Now, as a professor, I have noticed the effect on kids in universities in Britain, in Australia, here in Greece, in America. I find that students today are too scared of having a face-to-face conversation. They want a safe space. They do not want any challenging ideas to be presented to them in class. They protest, they will have you thrown out of university if you say something that upsets them, about anything. But give them a phone and they become toxic and ballistic. Now, that is no way of running a democracy or a civilized society for that matter.</p><p><strong>People have already expressed dissatisfaction with capitalism in various protest movements across Europe. Why should they care that there's been a shift to a slightly different system that's dominated by a slightly different kind of company?</strong></p><p>Ordinary people need to know the reasons behind the discontent. The discontented always ask: Why is this happening? Giving them an answer, in a way that makes sense to them, is hugely empowering. This is the foundation of any possibility of democracy. Because to have democracy, it's not enough to be able to vote every four or five years. You need people who understand what is going on, who are informed about the causes of their discontent. Because if they don't understand the causes of their discontent, then it's easy for them to fall prey to xenophobia, to misogyny, to racism. Then they can say, it’s the Jew. It's the Muslim. It's the foreigner. It's the Brit. It's the German, whatever. Then people latch on to simple solutions, which is the beginning of fascism.</p><p><strong>Are we at the beginning of fascism? And if so, is that really technofeudalism’s fault?</strong></p><p>I think that fascism is already on the rise. In France almost <a href="https://www.france24.com/en/france/20220425-victory-in-defeat-le-pen-raises-far-right-s-glass-ceiling-fails-to-crack-it">45 percent</a> of the population are supporting a neofascist [Marine Le Pen]. In Italy, we have a neofascist prime minister, Giorgia Meloni. That was not the doing of technofeudalism, because technofeudalism came later. What happened is, the rise of cloud capital and the siphoning off of money from the circular flow of income increases the discontent within people. At the same time you have the algorithms which make money and accumulate cloud capital to the extent that we hate one another. Hate is the fuel of facism. So if you blend discontent, the fact that most people can’t make ends meet, and you throw in there the hatred that is reinforced by the algorithms, that's fascism.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><strong>So if we have this new system that is fueling a new fascism, then what should we do about it?</strong></p><p>Well, many things. But to begin with, let's understand where we are, so we don't blame the foreigners. We don't blame women. We don't blame trans people. A little bit of knowledge goes a long way towards recreating the circumstances for a decent conversation between us.</p><p>In economic terms, we need to introduce a cloud tax immediately. Tax Amazon 5 percent for every transaction that takes place on its platform. Then, introduce a capacity for you and me to own a digital identity so we don't need Google or Facebook to vouch for who we are on the internet. Having a state-issued digital identity will go a long way towards restoring or handing you property rights over your data, because at the moment you do not own your data.</p><p>You can introduce interoperability. I am on X. I can't go to Bluesky. Let's say that Elon Musk decides to block me because I said something he didn't like. He has blocked me before for a couple of weeks. Now, I have more than a million followers on X. I cannot leave without losing them. If I go to Bluesky, I have 10 followers. Interoperability would mean that if I go to another platform, to Bluesky, when I post something on Bluesky, then my 1 million followers on X can hear it.</p><p><strong>It’s interesting you mention interoperability, because that’s one of the proposals in the EU's Digital Markets Act, which feels like it’s at least trying to get at some of the problems you've outlined. Do you think it goes far enough?</strong></p><p>No, it certainly doesn't go far enough. There are some interesting ideas in there, like interoperability. But nobody in government is actually working on this. This is my problem. Not that it is a hard task, but there is nobody working on it, because they don't care. They are all in the pockets of the big technofeudal lords, as I call them.</p><p><strong>So if you believe no one in government is doing anything, how do you move forward from that?</strong></p><p>That's a very good question. I have no idea. But this is why—against my spirit, against my preferences and my desires—I'm still in politics, because there is no alternative to politics.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I made a discrete logic network card (334 pts)]]></title>
            <link>https://qdiv.dev/posts/eth2/</link>
            <guid>39976640</guid>
            <pubDate>Tue, 09 Apr 2024 06:24:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qdiv.dev/posts/eth2/">https://qdiv.dev/posts/eth2/</a>, See on <a href="https://news.ycombinator.com/item?id=39976640">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><h5>April 9, 2024</h5><p>This post is a continuation of my journey to build a complete computer system using discrete logic components. At this point I have made a computer capable of running network applications like an HTTP server or a LAN game.</p><p>Last year I built <a href="https://qdiv.dev/posts/eth-to-spi">a physical level adapter</a> which converts a 10BASE-T Ethernet signal to SPI and back. Back then I used an STM32 microcontroller to test its operation, now I’m implementing a MAC layer module to connect it to my <a href="https://qdiv.dev/posts/ccpu">homebrew computer</a>.</p><p>Both adapters are full-duplex and have independent transmitter and receiver parts.</p><p><img src="https://qdiv.dev/eth2/overview-eth.jpg" alt="Discrete logic computer">
<em>Complete computer. The new module is bottom-right.</em></p><p><img src="https://qdiv.dev/eth2/eth.jpg" alt="ETH MAC adapter">
<em>The new module with PHY shield removed. Bodge wires fix swapped SCK and MOSI.</em></p><h2 id="receiver">Receiver
<a href="#receiver">#</a></h2><p>Summary of receiver operation:</p><ul><li>SPI serial data is converted to bytewise parallel data, byte clock is extracted;</li><li>First 6 bytes are checked against destination MAC address criteria, unmatched frames are rejected;</li><li>Bytes are written into a static RAM buffer;</li><li>When a frame ends, receiver is disabled and further frames are rejected until user re-arms the receiver. Byte counter is stopped, its value is made accessible to the user.</li></ul><p><a href="https://en.wikipedia.org/wiki/Frame_check_sequence">FCS</a> is not checked in hardware.</p><h3 id="data-collection">Data collection
<a href="#data-collection">#</a></h3><p>Firstly, serial SPI data needs to be converted into a stream of bytes.</p><p><img src="https://qdiv.dev/eth2/receiver.png" alt="Receiver"></p><p>Serial data is shifted into a shift register (<code>U32</code>). <code>U30</code> and <code>U31</code> count bits and bytes respectively. Static RAM write signal <code>recv_buf_we</code> is formed using a D flip-flop <code>U29B</code>. This signal briefly becomes low after each 8 bits of input data:</p><p><img src="https://qdiv.dev/eth2/recv_buf_we.svg" alt="recv_buf_we"></p><p>Received bytes are written into a 2 kB static RAM buffer 6116 (<code>U20</code>).</p><p><img src="https://qdiv.dev/eth2/recv-buffer.png" alt="receiver buffer"></p><p><code>U13</code>, <code>U16</code> and <code>U18</code> form an address multiplexer: it chooses either byte counter or system address bus as an address input for the SRAM (<code>U20</code>). A tri-state buffer <code>U21</code> forwards the received byte into the RAM.</p><p>To access the received data and its length, RAM and byte counter are connected to the system data bus with tri-state buffers:</p><p><img src="https://qdiv.dev/eth2/recv-output.png" alt="receiver output"></p><p><code>U25</code> connects the receiver RAM with the system data bus. After a frame is complete, the byte counter is not reset and its value is kept on the <code>recv_byte_cnt</code> bus. This bus is connected with the system data bus using <code>U26</code> and <code>U27</code>. They are activated when CPU makes a read request to specific addresses. The other half of <code>U27</code> makes a two-bit read-only status register which is used to query receiver and transmitter status.</p><h3 id="mac-address-filtering">MAC address filtering
<a href="#mac-address-filtering">#</a></h3><p>When analyzing the Ethernet traffic I noticed that frames usually come in small groups (3-4 frames together separated by a short delay). Frames in one group usually have different destination MAC addresses. This made me think that my computer won’t be able to filter received frames by MAC and re-arm the receiver fast enough to catch the frames meant for itself. I needed a hardware MAC address filtering.</p><p>Storing a custom MAC address somewhere and then comparing first 6 received bytes against it is a no-go: too complex. I could also make it a repetition of a single byte (e.g. FE:FE:FE:FE:FE:FE), but that’s boring. To bring some variation to my MAC, I made it a function of the byte index:</p><ul><li>Bit 0 is fixed to 0;</li><li>Bit 1 is fixed to 1;</li><li>Bits 2-4 are an inversion of the byte index;</li><li>Bits 5-7 are fixed to 1.</li></ul><p>Using this rule, the MAC address comes out to be <code>FE:FA:F6:F2:EE:EA</code>. We also need to accept the broadcast MAC <code>FF:FF:FF:FF:FF:FF</code> to work with ARP.</p><p><img src="https://qdiv.dev/eth2/mac-filter.png" alt="MAC filter"></p><p>On this schematics, bus <code>a[0..3]</code> is the lower 4 bits of the byte counter. Bus <code>d[0..7]</code> is the received byte. <code>U33</code> compares data bits 0 and 2-4 with their desired values, the output of <code>U34A</code> will be high when those bits match. <code>U35A</code> implements the broadcast MAC check: its output will be high when bits 0 and 2-4 are all ones. Those two signals are combined with a logical OR (implemented with diodes <code>D7</code> and resistor <code>R6</code>). The remaining bits are checked for being all ones with <code>U35B</code>.</p><p>This block only checks the validity of a single byte. To check all six of them, the result is accumulated in <code>U10A</code>. When no frame is being received, <code>ss</code> (the incoming SPI slave select signal) is low and <code>U10A</code> is set to 1. During frame reception this value is updated for each received byte. If destination MAC address matches the criteria, the value of <code>U10A</code> stays high. When byte address reaches 5, the final value is latched into <code>U36B</code>. Its output is used to inhibit frame reception if destination address is unmatched.</p><h2 id="transmitter">Transmitter
<a href="#transmitter">#</a></h2><p>Similarly to the receiver, the transmitter doesn’t implement FCS generation, it is done in software. To simplify the transmitter even further, I decided to only support frames of a fixed length. This way no complex digital comparator is necessary, the frame transmission logic only depends on a single bit of the byte counter. I selected the frame length to be 1024 bytes, this is close to the usual MTU of 1500 bytes. The frame preamble (the sequence of several 0x55 ending with a 0xD5 required by 10BASE-T) is also included in those 1024 bytes and needs to be loaded there in software.</p><p>Fixing the frame length doesn’t have any effect on higher-level protocols because they encode the packet size in their headers and do not rely on the actual Ethernet frame length.</p><p>Summary of transmitter operation:</p><ul><li>Data is stored in a static RAM;</li><li>20 MHz clock is fed to a 4-bit counter, its overflow output is used as a byte clock;</li><li>To transmit a frame, user writes to a specific write-only memory location which enables the counter;</li><li>Parallel byte data is serialized using a shift register.</li></ul><h3 id="counters">Counters
<a href="#counters">#</a></h3><p><img src="https://qdiv.dev/eth2/tx-counters.png" alt="tx counters"></p><p>Same as in the receiver, two counters are used to count bits (<code>U12</code>) and bytes (<code>U14</code>). First counter is fed by a 20 MHz clock from an integrated oscillator. 20 MHz is not used directly, but only divided at least by 2. This way the duty cycle of the oscillator doesn’t affect the output signal.</p><h3 id="data-flow">Data flow
<a href="#data-flow">#</a></h3><p><img src="https://qdiv.dev/eth2/tx-dataflow.png" alt="tx data flow"></p><p>Same as in the receiver three 74HC157 multiplexors (not shown here) are used to select address input for the RAM (<code>U22</code>). <code>U23</code> is used to load data into the RAM. <code>U24</code> acts as an intermediate storage for the byte currently being transmitted. The idea here is similar to my <a href="https://qdiv.dev/posts/vga/#image-generation">VGA pipeline</a>: byte counter 74HC4040 is a ripple counter and is slow to stabilize, <code>U24</code> provides a stable output while RAM output is still invalid. This data is fed to the shift register <code>U28</code> and shifted bit-by-bit.</p><p><em>After I’d built the thing I noticed that I’d messed up the order of bits coming from the RAM to the shift register. I had to shuffle bits in software to workaround this hardware bug. This was something I couldn’t test in Verilog beforehand.</em></p><p>To form a nice 10BASE-T signal (see <a href="https://qdiv.dev/posts/eth-to-spi/#transmitter">my previous post</a>) <code>MOSI</code> and <code>SCK</code> should be precisely synchronized. <code>U11A</code> and <code>U8B</code> achieve that. <code>tx_cnt0</code> (bit 0 of the bit counter, 20 MHz divided by 2) is used as a clock. <code>U11A</code> changes its output in sync with this signal. <code>U8B</code> delays the clock to match the delay introduced by <code>U11A</code>. Because a D-latch is more complex than a simple AND gate and has a slightly larger (by 5 ns) delay, a faster 74LV74A is used here. Its propagation delay is the same as of 74HC08. This is the only chip of a “fast” family on this board.</p><h2 id="cpu-interface">CPU interface
<a href="#cpu-interface">#</a></h2><p>From the programmer’s point of view, my Ethernet adapter has following interface:</p><ul><li>Both frame buffers are mapped at <code>0xF000</code>.</li><li>There are two read-only registers:<ul><li>8-bit status register at <code>0xFB00</code> has two flags:<ul><li><code>RX_FULL</code> - a frame is received,</li><li><code>TX_BUSY</code> - a frame is being transmitted;</li></ul></li><li>16-bit received data length register at <code>0xFB02</code>.</li></ul></li><li>Writing any value at <code>0xFB00</code> re-arms the receiver.</li><li>Writing any value at <code>0xFB01</code> starts a transmission.</li></ul><p>There are no interrupts since my CPU doesn’t support them.</p><p><img src="https://qdiv.dev/eth2/addr-select.png" alt="address selector"></p><p>Any relevant address starts with an <code>F</code> (upper 4 bits are all ones). This condition is checked by <code>U2A</code>.</p><p>Bit 11 should be 0 for a buffer address. <code>U1D</code>, <code>D2</code>, <code>R2</code> and <code>U1E</code> check that. Then the buffer select signal is combined with either write- or output-enable signals to select writing to the TX buffer or reading from the RX buffer.</p><p>Second hex digit being <code>B</code> (1011) for registers is checked by <code>U1B</code> and <code>U2B</code>. Then another diode logic block (<code>D1</code>, <code>R1</code>, <code>U1C</code>) combines it with the first digit check. Decoders <code>U4A</code> and <code>U4B</code> are used to select the individual function.</p><p>Two LEDs indicate buffer or register access.</p><h2 id="programming">Programming
<a href="#programming">#</a></h2><p>I wanted a network support for my computer, but didn’t want to implement a TCP/IP stack myself. Also I wanted a decent C compiler because my first compiler sucked and programming in assembly is annoying. So I made a <a href="https://github.com/imihajlow/ccpu-cc">C compiler</a>. It is mature enough to compile uIP 1.0 (a tiny TCP/IP library). Despite my CPU having awfully low code density, uIP is small enough to fit into RAM and have some place left for an actual application.</p><p>Network performance is very low, but I’m still very happy with it considering that no commercial CPUs or special chips are involved here:</p><ul><li>Ping round trip average 85 ms;</li><li>HTTP server download speed 2.6 kB/s (serving static files from the SD card).</li></ul><h2 id="project-repository">Project repository
<a href="#project-repository">#</a></h2><p>Models, schematic files and PCB drawings are located <a href="https://github.com/imihajlow/ccpu">on github</a>.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I Tripped Over the Debian Weak Keys Vulnerability (301 pts)]]></title>
            <link>https://www.hezmatt.org/~mpalmer/blog/2024/04/09/how-i-tripped-over-the-debian-weak-keys-vuln.html</link>
            <guid>39976225</guid>
            <pubDate>Tue, 09 Apr 2024 04:36:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hezmatt.org/~mpalmer/blog/2024/04/09/how-i-tripped-over-the-debian-weak-keys-vuln.html">https://www.hezmatt.org/~mpalmer/blog/2024/04/09/how-i-tripped-over-the-debian-weak-keys-vuln.html</a>, See on <a href="https://news.ycombinator.com/item?id=39976225">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">

				
				<p>
					Posted: Tue,  9 April 2024
					| <a href="https://www.hezmatt.org/~mpalmer/blog/2024/04/09/how-i-tripped-over-the-debian-weak-keys-vuln.html">permalink</a>
					| <a href="https://www.hezmatt.org/~mpalmer/blog/2024/04/09/how-i-tripped-over-the-debian-weak-keys-vuln.html#comments">
						
							No comments
						
					</a>
				</p>
<p><em>Those of you who haven’t been in IT for far, far too long might not know that next month will be the 16th(!) anniversary of the <a href="https://security-tracker.debian.org/tracker/DSA-1571-1">disclosure</a> of what was, at the time, a fairly earth-shattering revelation: that for about 18 months, the Debian OpenSSL package was <a href="https://security-tracker.debian.org/tracker/CVE-2008-0166">generating entirely predictable private keys</a>.</em></p>

<p>The recent <a href="https://en.wikipedia.org/wiki/XZ_Utils_backdoor">xz-stential threat</a> (thanks to <a href="https://infosec.exchange/@nixCraft@mastodon.social">@nixCraft</a> for <a href="https://mastodon.social/@nixCraft/112219225728684695">making me aware of that one</a>), has got me thinking about my own serendipitous interaction with a major vulnerability.
Given that the statute of limitations has (probably) run out, I thought I’d share it as a tale of how “huh, that’s weird” can be a powerful threat-hunting tool – but only if you’ve got the time to keep pulling at the thread.</p>

<h2 id="prelude-to-an-adventure">Prelude to an Adventure</h2>

<p>Our story begins back in March 2008.
I was working at Engine Yard (EY), a now largely-forgotten Rails-focused hosting company, which pioneered several advances in Rails application deployment.
Probably EY’s greatest claim to lasting fame is that they helped launch a little code hosting platform you might have heard of, by providing them free infrastructure when they were little more than a glimmer in the Internet’s eye.</p>

<p>I am, of course, talking about everyone’s favourite Microsoft product: GitHub.</p>

<p>Since GitHub was in the right place, at the right time, with a compelling product offering, they quickly started to gain traction, and grow their userbase.
With growth comes challenges, amongst them the one we’re focusing on today: SSH login times.
Then, as now, GitHub provided SSH access to the git repos they hosted, by SSHing to <code>git@github.com</code> with publickey authentication.
They were using the standard way that everyone manages SSH keys: the <code>~/.ssh/authorized_keys</code> file, and that became a problem as the number of keys started to grow.</p>

<p>The way that SSH uses this file is that, when a user connects and asks for publickey authentication, SSH opens the <code>~/.ssh/authorized_keys</code> file and scans all of the keys listed in it, looking for a key which matches the key that the user presented.
This linear search is normally not a huge problem, because nobody in their right mind puts more than a few keys in their <code>~/.ssh/authorized_keys</code>, right?</p>

<figure>
<img src="https://www.hezmatt.org/~mpalmer/blog/images/2008_github_auth_keys_sideeye.jpg" alt="2008-era GitHub giving monkey puppet side-eye to the idea that nobody stores many keys in an authorized_keys file">
</figure>

<p>Of course, as a popular, rapidly-growing service, GitHub was gaining users at a fair clip, to the point that the one big file that stored all the SSH keys was starting to visibly impact SSH login times.
This problem was also not going to get any better by itself.
Something Had To Be Done.</p>

<p>EY management was keen on making sure GitHub ran well, and so despite it not <em>really</em> being a hosting problem, they were willing to help fix this problem.
For some reason, the late, great, Ezra Zygmuntowitz pointed GitHub in my direction, and let me take the time to <em>really</em> get into the problem with the GitHub team.
After examining a variety of different possible solutions, we came to the conclusion that the least-worst option was to patch OpenSSH to lookup keys in a MySQL database, indexed on the key fingerprint.</p>

<p>We didn’t take this decision on a whim – it wasn’t a case of “yeah, sure, let’s just hack around with OpenSSH, what could possibly go wrong?”.
We knew it was potentially catastrophic if things went sideways, so you can imagine how much worse the other options available were.
Ensuring that this wouldn’t compromise security was a lot of the effort that went into the change.
In the end, though, we rolled it out in early April, and lo! SSH logins were fast, and we were pretty sure we wouldn’t have to worry about this problem for a long time to come.</p>

<p>Normally, you’d think “patching OpenSSH to make mass SSH logins super fast” would be a good story on its own.
But no, this is just the opening scene.</p>

<h2 id="chekovs-gun-makes-its-appearance">Chekov’s Gun Makes its Appearance</h2>

<p>Fast forward a little under a month, to the first few days of May 2008.
I get a message from one of the GitHub team, saying that <em>somehow</em> users were able to access other users’ repos over SSH.
Naturally, as we’d recently rolled out the OpenSSH patch, which touched <em>this very thing</em>, the code I’d written was suspect number one, so I was called in to help.</p>

<figure>
<img src="https://www.hezmatt.org/~mpalmer/blog/images/the_usual_suspects.png" alt="The lineup scene from the movie The Usual Suspects">
<figcaption>
  They're called The Usual Suspects for a reason, but sometimes, it really <b>is</b> Keyser Söze
</figcaption>
</figure>

<p>Eventually, after more than a little debugging, we discovered that, somehow, there were two users with keys that had the same key fingerprint.
This <em>absolutely</em> shouldn’t happen – it’s a bit like winning the lottery twice in a row<sup id="fnref:1"><a href="https://www.hezmatt.org/~mpalmer/blog/#fn:1">1</a></sup> – unless the users had somehow shared their keys with each other, of course.
Still, it was worth investigating, just in case it was a web application bug, so the GitHub team reached out to the users impacted, to try and figure out what was going on.</p>

<p>The users professed no knowledge of each other, neither admitted to publicising their key, and couldn’t offer any explanation as to how the other person could possibly have gotten their key.</p>

<p>Then things went from “weird” to “what the…?”.
Because <em>another</em> pair of users showed up, sharing a key fingerprint – but it was a <em>different</em> shared key fingerprint.
The odds now have gone from “winning the lottery multiple times in a row” to as close to “this literally cannot happen” as makes no difference.</p>

<figure>
<img src="https://www.hezmatt.org/~mpalmer/blog/images/were_through_the_looking_glass.jpg" alt="Milhouse from The Simpsons says that We're Through The Looking Glass Here, People">
</figure>

<p>Once we were really, <em>really</em> confident that the OpenSSH patch wasn’t the cause of the problem, my involvement in the problem basically ended.
I wasn’t a GitHub employee, and EY had plenty of other customers who needed my help, so I wasn’t able to stay deeply involved in the on-going investigation of The Mystery of the Duplicate Keys.</p>

<p>However, the GitHub team did keep talking to the users involved, and managed to determine the only apparent common factor was that all the users claimed to be using Debian or Ubuntu systems, which was where their SSH keys would have been generated.</p>

<p>That was as far as the investigation had really goten, when along came May 13, 2008.</p>

<h2 id="chekovs-gun-goes-off">Chekov’s Gun Goes Off</h2>

<p>With the publication of <a href="https://security-tracker.debian.org/tracker/DSA-1571-1">DSA-1571-1</a>, everything suddenly became clear.
Through a well-meaning but ultimately disasterous cleanup of OpenSSL’s randomness generation code, the Debian maintainer had inadvertently reduced the number of possible keys that could be generated by a given user from “bazillions” to a little over 32,000.
With so many people signing up to GitHub – some of them no doubt following best practice and freshly generating a separate key – it’s unsurprising that some collisions occurred.</p>

<p>You can imagine the sense of “oooooooh, so <em>that’s</em> what’s going on!” that rippled out once the issue was understood.
I was mostly glad that we had conclusive evidence that my OpenSSH patch wasn’t at fault, little knowing how much more contact I was to have with Debian weak keys in the future, running <a href="https://pwnedkeys.com/">a huge store of known-compromised keys</a> and using them to find <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1620772">misbehaving Certificate Authorities</a>, amongst other things.</p>

<h2 id="lessons-learned">Lessons Learned</h2>

<p>While I’ve not found a description of exactly when and how Luciano Bello discovered the vulnerability that became CVE-2008-0166, I presume he first came across it some time before it was disclosed – likely before GitHub tripped over it.
The stable Debian release that included the vulnerable code had been released a year earlier, so there was plenty of time for Luciano to have discovered key collisions and go “hmm, I wonder what’s going on here?”, then keep digging until the solution presented itself.</p>

<p>The thought “hmm, that’s odd”, followed by intense investigation, leading to the discovery of a major flaw is also what ultimately brought down the recent XZ backdoor.
The critical part of that sequence is the ability to <em>do</em> that intense investigation, though.</p>

<p>When I reflect on my brush with the Debian weak keys vulnerability, what sticks out to me is the fact that I <em>didn’t</em> do the deep investigation.
I wonder if Luciano hadn’t found it, how long it might have been before it was found.
The GitHub team would have continued investigating, presumably, and perhaps they (or I) would have eventually dug deep enough to find it.
But we were all super busy – myself, working support tickets at EY, and GitHub feverishly building features and fighting the fires in their rapidly-growing service.</p>

<p>As it was, Luciano <em>was</em> able to take the time to dig in and find out what was happening, but just like the XZ backdoor, I feel like we, as an industry, got a bit lucky that someone with the skills, time, and energy was on hand at the right time to make a huge difference.</p>

<p>It’s a luxury to be able to take the time to really dig into a problem, and it’s a luxury that most of us rarely have.
Perhaps an understated takeaway is that somehow we all need to wrestle back some time to follow our hunches and really dig into the things that make us go “hmm…”.</p>

<h2 id="support-my-hunches">Support My Hunches</h2>

<p>If you’d like to help me be able to do intense investigations of mysterious software phenomena, you can <a href="https://ko-fi.com/tobermorytech">shout me a refreshing beverage on ko-fi</a>.</p>



<hr>
			
			

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MapSCII – A Braille and ASCII world map renderer for the console (133 pts)]]></title>
            <link>https://github.com/rastapasta/mapscii</link>
            <guid>39975887</guid>
            <pubDate>Tue, 09 Apr 2024 02:58:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rastapasta/mapscii">https://github.com/rastapasta/mapscii</a>, See on <a href="https://news.ycombinator.com/item?id=39975887">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto">MapSCII - The Whole World In Your Console. <a href="https://travis-ci.com/rastapasta/mapscii" rel="nofollow"><img src="https://camo.githubusercontent.com/d7d076fbc026aa6986f301975e2539fc1b94b7dfb9b50e4143af6a3c035c2879/68747470733a2f2f7472617669732d63692e636f6d2f726173746170617374612f6d6170736369692e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/rastapasta/mapscii.svg?branch=master"></a></h2><a id="user-content-mapscii---the-whole-world-in-your-console-" aria-label="Permalink: MapSCII - The Whole World In Your Console. " href="#mapscii---the-whole-world-in-your-console-"></a></div>
<p dir="auto">A node.js based <a href="http://wiki.openstreetmap.org/wiki/Vector_tiles" rel="nofollow">Vector Tile</a> to <a href="http://www.fileformat.info/info/unicode/block/braille_patterns/utf8test.htm" rel="nofollow">Braille</a> and <a href="https://de.wikipedia.org/wiki/American_Standard_Code_for_Information_Interchange" rel="nofollow">ASCII</a> renderer for <a href="https://en.wikipedia.org/wiki/Xterm" rel="nofollow">xterm</a>-compatible terminals.</p>
<p dir="auto"><a href="https://asciinema.org/a/117813?autoplay=1" rel="nofollow"><img src="https://cloud.githubusercontent.com/assets/1259904/25480718/497a64e2-2b4a-11e7-9cf0-ed52ee0b89c0.png" alt="asciicast"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Try it out!</h2><a id="user-content-try-it-out" aria-label="Permalink: Try it out!" href="#try-it-out"></a></p>

<p dir="auto">If you're on Windows, use the open source telnet client <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html" rel="nofollow">PuTTY</a> to connect.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Use your mouse to drag and zoom in and out!</li>
<li>Discover Point-of-Interests around any given location</li>
<li>Highly customizable layer styling with <a href="https://www.mapbox.com/mapbox-gl-style-spec/" rel="nofollow">Mapbox Styles</a> support</li>
<li>Connect to any public or private vector tile server</li>
<li>Or just use the supplied and optimized <a href="https://github.com/osm2vectortiles">OSM2VectorTiles</a> based one</li>
<li>Work offline and discover local <a href="https://github.com/mapbox/vector-tile-spec">VectorTile</a>/<a href="https://github.com/mapbox/mbtiles-spec">MBTiles</a></li>
<li>Compatible with most Linux and OSX terminals</li>
<li>Highly optimized algorithms for a smooth experience</li>
<li>100% pure JavaScript! 😎</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to run it locally</h2><a id="user-content-how-to-run-it-locally" aria-label="Permalink: How to run it locally" href="#how-to-run-it-locally"></a></p>
<p dir="auto">With a modern node installation available, just start it with</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">How to install it locally</h2><a id="user-content-how-to-install-it-locally" aria-label="Permalink: How to install it locally" href="#how-to-install-it-locally"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">With npm</h3><a id="user-content-with-npm" aria-label="Permalink: With npm" href="#with-npm"></a></p>
<p dir="auto">If you haven't already got Node.js &gt;= version 10, then <a href="http://nodejs.org/" rel="nofollow">go get it</a>.</p>

<p dir="auto">If you're on OSX, or get an error about file permissions, you may need to do <code>sudo npm install -g mapscii</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">With snap</h3><a id="user-content-with-snap" aria-label="Permalink: With snap" href="#with-snap"></a></p>
<p dir="auto">In any of the <a href="https://snapcraft.io/docs/core/install" rel="nofollow">supported Linux distros</a>:</p>
<div data-snippet-clipboard-copy-content="sudo snap install mapscii"><pre><code>sudo snap install mapscii
</code></pre></div>
<p dir="auto">(This snap is maintained by <a href="https://github.com/nathanhaines/">@nathanhaines</a>)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Running</h2><a id="user-content-running" aria-label="Permalink: Running" href="#running"></a></p>
<p dir="auto">This is pretty simple too.</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Keyboard shortcuts</h2><a id="user-content-keyboard-shortcuts" aria-label="Permalink: Keyboard shortcuts" href="#keyboard-shortcuts"></a></p>
<ul dir="auto">
<li>Arrows <strong>up</strong>, <strong>down</strong>, <strong>left</strong>, <strong>right</strong> to scroll around</li>
<li>Press <strong>a</strong> or <strong>z</strong> to zoom in and out</li>
<li>Press <strong>c</strong> to switch to block character mode</li>
<li>Press <strong>q</strong> to quit</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Mouse control</h2><a id="user-content-mouse-control" aria-label="Permalink: Mouse control" href="#mouse-control"></a></p>
<p dir="auto">If your terminal supports mouse events you can drag the map and use your scroll wheel to zoom in and out.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Behind the scenes</h2><a id="user-content-behind-the-scenes" aria-label="Permalink: Behind the scenes" href="#behind-the-scenes"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Libraries</h3><a id="user-content-libraries" aria-label="Permalink: Libraries" href="#libraries"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Mastering the console</h4><a id="user-content-mastering-the-console" aria-label="Permalink: Mastering the console" href="#mastering-the-console"></a></p>
<ul dir="auto">
<li><a href="https://github.com/substack/node-x256"><code>x256</code></a> for converting RGB values to closest xterm-256 <a href="https://en.wikipedia.org/wiki/File:Xterm_256color_chart.svg" rel="nofollow">color code</a></li>
<li><a href="https://github.com/CoderPuppy/term-mouse"><code>term-mouse</code></a> for mouse handling</li>
<li><a href="https://github.com/TooTallNate/keypress"><code>keypress</code></a> for input handling</li>
<li><a href="https://github.com/sindresorhus/string-width"><code>string-width</code></a> to determine visual string lengths</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Discovering the map data</h4><a id="user-content-discovering-the-map-data" aria-label="Permalink: Discovering the map data" href="#discovering-the-map-data"></a></p>
<ul dir="auto">
<li><a href="https://github.com/mapbox/vector-tile-js"><code>vector-tile</code></a> for <a href="https://github.com/mapbox/vector-tile-spec/tree/master/2.1">VectorTile</a> parsing</li>
<li><a href="https://github.com/mapbox/pbf"><code>pbf</code></a> for <a href="https://developers.google.com/protocol-buffers/" rel="nofollow">Protobuf</a> decoding</li>
<li><a href="https://github.com/mapbox/node-mbtiles"><code>mbtiles</code></a> for <a href="https://github.com/mapbox/mbtiles-spec/blob/master/1.2/spec.md">MBTiles</a> parsing</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Juggling the vectors and numbers</h4><a id="user-content-juggling-the-vectors-and-numbers" aria-label="Permalink: Juggling the vectors and numbers" href="#juggling-the-vectors-and-numbers"></a></p>
<ul dir="auto">
<li><a href="https://github.com/mapbox/earcut"><code>earcut</code></a> for polygon triangulation</li>
<li><a href="https://github.com/mourner/rbush"><code>rbush</code></a> for 2D spatial indexing of geo and label data</li>
<li><a href="https://github.com/madbence/node-bresenham"><code>bresenham</code></a> for line point calculations</li>
<li><a href="https://github.com/mourner/simplify-js"><code>simplify-js</code></a> for polyline simplifications</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Handling the flow</h4><a id="user-content-handling-the-flow" aria-label="Permalink: Handling the flow" href="#handling-the-flow"></a></p>
<ul dir="auto">
<li><a href="https://github.com/bitinn/node-fetch"><code>node-fetch</code></a> for HTTP requests</li>
<li><a href="https://github.com/sindresorhus/env-paths"><code>env-paths</code></a> to determine where to persist downloaded tiles</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">TODOs</h3><a id="user-content-todos" aria-label="Permalink: TODOs" href="#todos"></a></p>
<ul dir="auto">
<li>
<p dir="auto">MapSCII</p>
<ul>
<li>
<p dir="auto"> GeoJSON support via <a href="https://github.com/mapbox/geojson-vt">geojson-vt</a></p>
</li>
<li>
<p dir="auto"> CLI support</p>
<ul dir="auto">
<li>[-] startup parameters
<ul>
<li> TileSource</li>
<li> Style</li>
<li> center position</li>
<li> zoom</li>
<li> demo mode?</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto"> mouse control</p>
<ul>
<li> hover POIs/labels</li>
<li> hover maybe even polygons/-lines?</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto">Styler</p>
<ul>
<li> respect zoom based style ranges</li>
</ul>
</li>
<li>
<p dir="auto">Renderer</p>
<ul>
<li> download and process tiles in a different thread (<a href="https://github.com/rastapasta/mapscii/issues/3" data-hovercard-type="issue" data-hovercard-url="/rastapasta/mapscii/issues/3/hovercard">#3</a>)</li>
<li> optimize renderer for large areas (<a href="https://github.com/rastapasta/mapscii/issues/6" data-hovercard-type="issue" data-hovercard-url="/rastapasta/mapscii/issues/6/hovercard">#6</a>)</li>
<li> label drawing
<ul>
<li> multi line label?</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto">TileSource</p>
<ul>
<li> implement single vector-tile handling</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Special thanks</h2><a id="user-content-special-thanks" aria-label="Permalink: Special thanks" href="#special-thanks"></a></p>
<ul dir="auto">
<li><a href="https://github.com/lukasmartinelli">lukasmartinelli</a> &amp; <a href="https://github.com/manuelroth">manuelroth</a> for all their work on <a href="https://github.com/osm2vectortiles">OSM2VectorTiles</a> (global vector tiles from <a href="https://wiki.openstreetmap.org/wiki/Planet.osm" rel="nofollow">OSM Planet</a>)</li>
<li><a href="https://github.com/mourner">mourner</a> for all his work on mindblowing GIS algorithms (like the used <a href="https://github.com/mapbox/earcut">earcut</a>, <a href="https://github.com/mourner/rbush">rbush</a>, <a href="https://github.com/mourner/simplify-js">simplify-js</a>, ..)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Licenses</h2><a id="user-content-licenses" aria-label="Permalink: Licenses" href="#licenses"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Map data</h3><a id="user-content-map-data" aria-label="Permalink: Map data" href="#map-data"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">The Open Data Commons Open Database License (oDbl)</h4><a id="user-content-the-open-data-commons-open-database-license-odbl" aria-label="Permalink: The Open Data Commons Open Database License (oDbl)" href="#the-open-data-commons-open-database-license-odbl"></a></p>
<p dir="auto"><a href="https://www.openstreetmap.org/" rel="nofollow">OpenStreetMap</a> is open data, licensed under the <a href="http://opendatacommons.org/licenses/odbl/" rel="nofollow">Open Data Commons Open Database License</a> (ODbL) by the <a href="http://osmfoundation.org/" rel="nofollow">OpenStreetMap Foundation</a> (OSMF).</p>
<p dir="auto">You are free to copy, distribute, transmit and adapt our data, as long as you credit OpenStreetMap and its contributors. If you alter or build upon our data, you may distribute the result only under the same licence. The full <a href="http://opendatacommons.org/licenses/odbl/1.0/" rel="nofollow">legal code</a> explains your rights and responsibilities.</p>
<p dir="auto">The cartography in our map tiles, and our documentation, are licenced under the <a href="http://creativecommons.org/licenses/by-sa/2.0/" rel="nofollow">Creative Commons Attribution-ShareAlike 2.0</a> licence (CC BY-SA).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">MapSCII</h3><a id="user-content-mapscii" aria-label="Permalink: MapSCII" href="#mapscii"></a></p>
<ul dir="auto">
<li><a href="https://github.com/rastapasta/mapscii/blob/master/LICENSE">License</a></li>
<li><a href="https://github.com/rastapasta/mapscii/blob/master/AUTHORS">Authors</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[BART to offer final rides on original equipment on April 20 (122 pts)]]></title>
            <link>https://www.trains.com/trn/news-reviews/news-wire/bart-to-offer-final-rides-on-original-equipment-on-april-20/</link>
            <guid>39975865</guid>
            <pubDate>Tue, 09 Apr 2024 02:52:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.trains.com/trn/news-reviews/news-wire/bart-to-offer-final-rides-on-original-equipment-on-april-20/">https://www.trains.com/trn/news-reviews/news-wire/bart-to-offer-final-rides-on-original-equipment-on-april-20/</a>, See on <a href="https://news.ycombinator.com/item?id=39975865">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><strong>'Riding into History' event will operate on original 24-mile segment to Fremont, Calif.</strong></p><div><figure id="attachment_170302" aria-describedby="caption-attachment-170302"><img fetchpriority="high" decoding="async" src="https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day.jpg" alt="Black and white photo of rapid-transit equipment in underground station" width="1000" height="761" srcset="https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day.jpg 1000w, https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day-300x228.jpg 300w, https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day-768x584.jpg 768w, https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day-600x457.jpg 600w, https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day-400x304.jpg 400w, https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day-200x152.jpg 200w, https://www.trains.com/wp-content/uploads/2023/08/TRN_BART_first_day-350x266.jpg 350w" sizes="(max-width: 1000px) 100vw, 1000px"><figcaption id="caption-attachment-170302">A Bay Area Rapid Transit prototype train poses at the Lake Merritt station in Oakland prior to the start of service, in late 1971 or early 1972. While BART removed the last of the original equipment from service last September, it will hold a farewell event on April 20. BART</figcaption></figure>
<hr>
<p>OAKLAND, Calif. — Bay Area Rapid Transit, the 131-mile electrified rail network in the San Francisco Bay Area, is offering the public a last chance to ride the 1970s-era futuristic railcars that made up its original fleet.</p>
<p>On Saturday, April 20, at 1 p.m. at the MacArthur station in Oakland, BART will commemorate the cars with a ceremony and then run two 10-car trains using original cars for the last time. Anyone can ride for the usual fare.</p>
<p>“We understand that BART cars are iconic, especially the sloped-front A cars,” said BART spokesperson Jim Allison. “We just wanted to give them a proper sendoff so that people had a chance to say goodbye to the cars that have been serving the Bay Area for more than 50 years.”</p>
<p>The special trains will run about 24 miles from MacArthur to Fremont, the first segment of BART to open 52 years ago. The trains will make the usual stops and run more loops between the two stations if needed to accommodate everyone who wants to ride, he said.</p>
<p>The “Riding into History: Final Run of the First Fleet” event will include speeches, a raffle for a couple of railcar plates, and probably some merchandise for sale, Allison said. Some details were still being decided early this month.</p>
<p>April 20 is coincidentally the same day when the electric trains of the Key System, a BART predecessor, ran their final miles in 1958.</p>
<p>The legacy fleet ended regular service in September 2023; when that date was set, BART had indicated it would eventually hold a special farewell event [see <a href="https://www.trains.com/trn/news-reviews/news-wire/bart-to-retire-last-original-cars-on-sept-11/" target="_blank" rel="noopener">“BART to retire last original cars …,”</a> Trains News Wire, Aug. 25, 2023]. Most of the legacy equipment has already been recycled, but BART is donating three cars — one each of the A, B and C versions — to the Western Railway Museum at Rio Vista Junction, which is run by the Bay Area Electric Railroad Association. Five other cars were awarded in 2022 for reuse ranging from an arcade area at an Oakland bar and grill to use in firefighter training [see “<a href="https://www.trains.com/trn/news-reviews/news-wire/bart-to-award-eight-retired-cars-for-reuse/" target="_blank" rel="noopener">BART to award eight retired cars ..,”</a> News Wire, March 16, 2022].</p>
<p>When it opened on Sept. 11, 1972, BART was the first entirely new rail transit system built in the United States in decades, built to an atypical 5-foot, 6-inch gauge for reasons <a href="https://www.bart.gov/news/articles/2022/news20220708-2" target="_blank" rel="noopener">the agency explains here</a>. Its technology, advanced for the time, included central computer control, on-board electronic propulsion and “the lightest weight car per passenger ever built,” the museum says. The intended effect was space age, not subway.</p>
<p>Museum volunteers will ride the last trains, staff a table, and speak for a few minutes at the farewell, said Andy Payne, a museum archivist and author of “Legacy Fleet,” an upcoming book about the cars.</p>
<p>The museum will receive the cars in June and intends to place them in its Loring C. Jensen Memorial Car House 3. “We are planning exhibits near the cars showcasing the history of the BART system and the legacy fleet,” he said. “In the future, if funding allows, we would love to build the <a href="https://www.wrm.org/fundraising-campaigns/rapid-transit-history-center" target="_blank" rel="noopener">Rapid Transit History Center</a>” that would feature the cars and other aspects of Bay Area electric rail history.</p>
<p>The museum runs historic equipment from several electric railroads on about 6 miles of ex-Sacramento Northern track with overhead wire, but can’t operate the BART cars, because of their gauge and need for third-rail power.</p>
<p>According to BART, the 669 cars in the legacy fleet used 1,000-volt DC electricity for propulsion, with one 150 hp motor per axle and four motors per car. The fleet had:</p>
<ul>
<li>59 A2 cars and 380 B2 cars, built by aerospace company Rohr Industries. They began service in 1972, and were rehabilitated in 1997 and 2002.</li>
<li>150 C1 cars from Alstom. They entered service in 1988, and were never rehabilitated.</li>
<li>80 C2 cars from Morrison-Knudsen. They began service in 1994, and were never rehabilitated.</li>
</ul>
<p>Each car was 70 feet long, except for the A model, 75 feet with a cab.</p>
<p>BART’s new <a href="https://www.bart.gov/about/projects/cars" target="_blank" rel="noopener">Fleet of the Future</a> consists of 775 cars from Bombardier, later bought by Alstom. Also 70 feet long, each car uses 1,000-volt DC electricity, gets power from a third rail, and has two trucks with one 194-hp motor per axle, and two axles per truck.</p>
<p><em>— Updated at 1:30 p.m. CT to correct caption information.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Distributed SQLite: Paradigm shift or hype? (233 pts)]]></title>
            <link>https://kerkour.com/distributed-sqlite</link>
            <guid>39975596</guid>
            <pubDate>Tue, 09 Apr 2024 01:51:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kerkour.com/distributed-sqlite">https://kerkour.com/distributed-sqlite</a>, See on <a href="https://news.ycombinator.com/item?id=39975596">Hacker News</a></p>
Couldn't get https://kerkour.com/distributed-sqlite: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[TSAC: Low Bitrate Audio Compression (206 pts)]]></title>
            <link>https://bellard.org/tsac/</link>
            <guid>39975331</guid>
            <pubDate>Tue, 09 Apr 2024 01:00:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bellard.org/tsac/">https://bellard.org/tsac/</a>, See on <a href="https://news.ycombinator.com/item?id=39975331">Hacker News</a></p>
<div id="readability-page-1" class="page">


<p>
TSAC is an audio compression utility reaching very low bitrates such
as 5.5 kb/s for mono or 7.5 kb/s for stereo at 44.1 kHz with a good
perceptual quality. Hence TSAC compresses a 3.5 minute stereo song to
a file of 192 KiB.
</p>
<p>
An Nvidia GPU is necessary for fast operation. CPU only is also
supported but slower.
</p>

<h2>Compression Results</h2>

<p>The audio extracts are
from <a href="https://listening-test.coresv.net/results.htm">here</a>.
</p>
  
<p>
  Waiting (Pops):
</p>
<table>
  <tbody><tr>
    <td>original<br>
      <audio controls=""><source src="https://bellard.org/tsac/Waiting.wav" type="audio/wav"></audio>
    </td><td>stereo 7.26 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Waiting_stereo.wav" type="audio/wav"></audio>
    </td><td>mono 5.61 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Waiting_mono.wav" type="audio/wav"></audio>
    </td><td>stereo 2.99 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Waiting_stereo_q5.wav" type="audio/wav"></audio>
  </td></tr>
</tbody></table>

<p>
  Greatest_Love_of_All_2min57 (Pops):
</p>
<table>
  <tbody><tr> 
   <td>original<br>
      <audio controls=""><source src="https://bellard.org/tsac/Greatest_Love_of_All_2min57.wav" type="audio/wav"></audio>
   </td><td>stereo 6.79 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Greatest_Love_stereo.wav" type="audio/wav"></audio>
   </td><td>mono 5.02 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Greatest_Love_stereo.wav" type="audio/wav"></audio>
   </td><td>stereo 2.84 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Greatest_Love_stereo_q5.wav" type="audio/wav"></audio>
  </td></tr>
</tbody></table>

<p>
  9-Have-big-expensive-car.441 (Pops):
</p>
<table>
<tbody><tr> 
   <td>original<br>
     <audio controls=""><source src="https://bellard.org/tsac/9-Have-big-expensive-car.441.wav" type="audio/wav"></audio>
   </td><td>stereo 7.81 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Have-big-expensive-car_stereo.wav" type="audio/wav"></audio>
   </td><td>mono 5.91 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/Have-big-expensive-car_mono.wav" type="audio/wav"></audio>
   </td><td>stereo 3.25 kb/s<br>
     <audio controls=""><source src="https://bellard.org/tsac/Have-big-expensive-car_stereo_q5.wav" type="audio/wav"></audio>
</td></tr>
</tbody></table>

<p>
  21-classic.441 (Classic):
</p>
<table>
<tbody><tr> 
   <td>original<br>
     <audio controls=""><source src="https://bellard.org/tsac/21-classic.441.wav" type="audio/wav"></audio>
   </td><td>stereo 6.21 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/classic_stereo.wav" type="audio/wav"></audio>
   </td><td>mono 4.71 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/classic_mono.wav" type="audio/wav"></audio>
   </td><td>stereo 2.57 kb/s<br>
     <audio controls=""><source src="https://bellard.org/tsac/classic_stereo_q5.wav" type="audio/wav"></audio>
</td></tr>
</tbody></table>

<p>
  4-Sound-English-male.441 (Voice):
</p>
<table>
  <tbody><tr>
    <td>original<br>
      <audio controls=""><source src="https://bellard.org/tsac/4-Sound-English-male.441.wav" type="audio/wav"></audio>
    </td><td>mono 6.79 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/4-Sound-English-male.441_mono.wav" type="audio/wav"></audio>
    </td><td>mono 3.74 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/4-Sound-English-male.441_mono_q5.wav" type="audio/wav"></audio>
    </td><td>mono 2.18 kb/s<br>
      <audio controls=""><source src="https://bellard.org/tsac/4-Sound-English-male.441_mono_q3.wav" type="audio/wav"></audio>
  </td></tr>
</tbody></table>

<h2>Download</h2>

<ul>
  <li>Linux version: <a href="https://bellard.org/tsac/tsac-2024-04-08.tar.gz">tsac-2024-04-08.tar.gz</a>. (<a href="https://bellard.org/tsac/readme.txt">readme.txt</a>)</li>
  <li>Windows version (experimental): <a href="https://bellard.org/tsac/tsac-2024-04-08-win64.zip">tsac-2024-04-08-win64.zip</a>.</li>
</ul>

<h2>Technical information</h2>
<ul>
  <li><code>tsac</code> is based on a modified version of
    the <a href="https://github.com/descriptinc/descript-audio-codec">Descript
      Audio Codec</a> extended for stereo and a Transformer model to further
    increase the compression ratio. Both models are quantized to 8 bits
    per parameter.</li>
  <li>The Transformer model is evaluated in a deterministic and
    reproducible way. Hence the result does not depend on the exact
    GPU or CPU model nor on the number of configured threads. This key
    point ensures that a compressed file can be decompressed using a
    different hardware or software configuration.</li>
</ul>

<hr>
Fabrice Bellard - <a href="https://bellard.org/">https://bellard.org/</a>


</div>]]></description>
        </item>
    </channel>
</rss>