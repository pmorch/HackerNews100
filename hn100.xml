<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 01 Feb 2025 23:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The government information crisis is bigger than you think it is (220 pts)]]></title>
            <link>https://freegovinfo.info/node/14747/</link>
            <guid>42895331</guid>
            <pubDate>Sat, 01 Feb 2025 03:21:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://freegovinfo.info/node/14747/">https://freegovinfo.info/node/14747/</a>, See on <a href="https://news.ycombinator.com/item?id=42895331">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>[This post is adapted from our forthcoming book, <em>Preserving Government Information: Past, Present, and Future</em>.]</p>
<p>Today we want to clarify something important about preserving government information. There is a difference between the government changing a policy and the government erasing information, but the line between those two has blurred in the digital age.</p>
<p>When a new president is inaugurated, one expects new policies. The number of changes and the speed of change may vary for different administrations, but we expect that every administration will be different in some ways from its predecessor. After all, that is part of the reason we have elections. Also, information that the government publishes is updated all the time, not just when administrations change. Laws and regulations are added and amended and rescinded, new economic and environmental and census data are collected and published, government recommendations to the public (like the Department of Agriculture’s “food pyramid” guidance) are revised. </p>
<p>Changes in government information are normal in a democracy.</p>
<p>Because change is normal, it is essential to preserve government information – even “non-current” and “out of date” information – in order to document those changes. This is not a new idea, but a long-accepted principle of democracy. Citizens need a record of what a government’s stated values were and when they changed, what actions it took and when it took them, what data it collected and generated at specific points in time, and so forth. It is important to preserve even information that later proves to be inaccurate in order to document what the government knew and when it knew it. </p>
<p>Because published government information is the evidence for a democracy, its preservation is essential.</p>
<p>In the era in which government information was published in paper formats, preservation of that information relied on libraries. The information was distributed to FDLP libraries based on the needs of the communities that those libraries served. Beginning in 1962, Regional FDLs received and retained all the paper publications in the FDLP system. When new information superseded or replaced old information, the old information was not erased or discarded; it was preserved in Regional FDLs and in every FDL whose community valued that older information. In the print era, it was taken for granted that, once government information was released to the public, it would not be withdrawn or altered or lost.<sup><a id="return1" href="#fn1">1</a></sup> </p>
<p>In the digital age, government publishing has shifted from the distribution of unalterable printed books to digital posts on government websites. Such digital publications can be moved, altered, and withdrawn at the flick of a switch. Publishing agencies are not required to preserve their own information, nor to provide free access to it. </p>
<p>Some digital government information is actively preserved by GPO, NARA, and the Library of Congress. Some government-collected data are preserved by law or by tradition. But the laws that allow this are weak and government preservation of government information suffers from large gaps. Non-government projects (notably the <a href="https://archive.org/">Internet Archive</a> and the <a href="https://eotarchive.org/">End-of-Term Archive</a>) use web harvesting to attempt to acquire and store government information, but these projects are, by their nature, incomplete and their long-term guarantees of access are fragile. As a result of all this, the public can no longer assume that any given piece of government information will not be withdrawn or altered or lost. </p>
<p>The early actions of the incoming Trump administration (as well as the actions of the first Trump administration) have brought the vulnerability of digital information to the public’s attention (see our previous post “<a href="https://freegovinfo.info/node/14744/">Federal information scrubbing has begun</a>”) and the public is rightfully worried. That vulnerability is, however, not limited to this administration. Digital government information was being lost before President Trump. </p>
<p>The current crisis of imminent loss of information exists not only because government information is being changed, but because it is being erased. The erasure is possible because of the gaps in the current preservation infrastructure. </p>
<p>The scale of loss and alteration of information under Trump may prove to be unprecedented and certainly requires immediate short-term action. But librarians and archivists and citizens should use this current crisis to demand more than short-term solutions. A new distributed digital preservation infrastructure is needed for digital government information.</p>
<p>
James A. Jacobs<br>
James R. Jacobs</p>
<ol>
<li id="fn1">Even when information <em>was</em> withdrawn for some reason, there was a record of the withdrawals. (See this <a href="https://docs.google.com/spreadsheets/d/1HIAT3KhOwX3hQobrIv66ZHOOeBtrVVZRPnhSX99V3Oo/edit?gid=0#gid=0">spreadsheet</a> listing withdrawn documents 1981 – 2018, collated from GPO’s no-longer published “<a href="https://www.govinfo.gov/app/search/%7B%22query%22%3A%22%5C%22administrative%20notes%5C%22%22%2C%22offset%22%3A0%2C%22facetToExpand%22%3A%22governmentauthornav%22%2C%22facets%22%3A%7B%22governmentauthornav%22%3A%5B%22Superintendent%20of%20Documents%22%5D%7D%2C%22filterOrder%22%3A%5B%22governmentauthornav%22%5D%2C%22pageSize%22%3A100%7D">Administrative Notes</a><a>” newsletter.) </a><a href="#return1">↵</a>
</li>

</ol>


<!-- BEGIN License added by Creative-Commons-Configurator plugin for WordPress -->
<p prefix="dct: http://purl.org/dc/terms/ cc: http://creativecommons.org/ns#"><a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img data-recalc-dims="1" alt="CC BY-NC-SA 4.0" src="https://i0.wp.com/freegovinfo.info/wp-content/plugins/creative-commons-configurator-1/media/cc/by-nc-sa/4.0/88x31.png?resize=88%2C31&amp;ssl=1" width="88" height="31"></a>
This work is licensed under a <a rel="license" target="_blank" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>
<!-- END License added by Creative-Commons-Configurator plugin for WordPress -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Decision to dump water from Tulare County lakes altered after confusing locals (151 pts)]]></title>
            <link>https://sjvwater.org/decision-to-dump-water-from-tulare-county-lakes-altered-after-sending-locals-in-mad-scramble/</link>
            <guid>42894708</guid>
            <pubDate>Sat, 01 Feb 2025 01:30:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sjvwater.org/decision-to-dump-water-from-tulare-county-lakes-altered-after-sending-locals-in-mad-scramble/">https://sjvwater.org/decision-to-dump-water-from-tulare-county-lakes-altered-after-sending-locals-in-mad-scramble/</a>, See on <a href="https://news.ycombinator.com/item?id=42894708">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
<p>Water managers were relieved Thursday evening after the Army Corps of Engineers agreed to back off of a sudden decision earlier in the day to dump massive amounts of water from Kaweah and Success lakes.</p>



<p>Water managers said they got about an hour’s warning from the Army Corp’s Sacramento office to expect the Tule and Kaweah rivers to be at “channel capacity” by Thursday night.&nbsp;</p>



<p>Channel capacity means the maximum amount of water a river can handle. For the Kaweah, that’s 5,500 cubic feet per second and for the Tule, it’s 3,500 cfs.</p>



<p>Those levels were last seen, and surpassed, during the 2023 floods, which destroyed dozens of homes and businesses and caused significant damage to infrastructure.</p>



<p>“We were able to get them to back off that,” said Eric Limas, General Manager of the Lower Tule River and Pixley irrigation districts, of the Army Corps. “They’ll still be releasing water sometime tonight, but it will be a smaller amount, which will increase tomorrow.”</p>



<p>Limas and Tulare Irrigation District General Manager Aaron Fukuda were unsure how high releases would ultimately go and for how long but Kaweah has about 27,000 acre feet and Success about 5,000 acre fee that are above levels allowed by the Army Corps during winter.</p>



<p>Water managers will continue working with the Army Corps to limit the amount of water released from the lakes, Fukuda said.</p>



<p>“We’re still trying to wrap our minds around the numbers that made this happen,” Fukuda said. “We haven’t received much information from the Army Corps, just very vague answers.”</p>



<p>Rick Brown, chief public affairs officer for the Sacramento office of the Army Corps, would only say that levels in both lakes were “currently in the flood control space.”&nbsp;</p>



<p>He directed further questions to the Army Corps’ headquarters, which did not return an email Thursday asking: Who made the decision to release the water? Why? Why so suddenly? And why weren’t safety personnel notified?</p>



<p>Some people interviewed for this story speculated that the move was political on the part of the new administration, a kind of water “flex,” but declined to elaborate.</p>



<p>Tulare County Sheriff Mike Boudreaux said one of his officers had heard about the pending releases through the grapevine late Thursday afternoon and they were getting conflicting information through the evening.&nbsp;</p>



<p>The Tule River goes through the heart of Porterville and there are a number of <a href="https://sjvwater.org/planning-and-coordination-kept-porterville-dry-during-floods-but-the-rest-of-the-san-joaquin-valley-remains-fragmented/">agreements</a> about how releases should be made, including notifications to first responders, which is why Porterville didn’t flood in 2023.</p>



<p>Army Corps reservoirs are required to be drawn down every fall to make room for winter storms and later runoff.&nbsp;</p>



<p>But the Army Corps typically works with downstream agricultural users to allow them to keep a bit more water in the lakes to hedge against dry years, such this one is shaping up to be.</p>



<p>Kaweah River Water Master Victor Hernandez said Lake Kaweah’s winter capacity is 12,000 acre feet, but had been allowed to go up to 39,000 acre feet after an aerial snow survey showed the watershed currently only has another 45,000 acre feet in snow cover.</p>



<p>“Even if everything came down at once, it would only be enough to fill the reservoir halfway,” he said. “We were on track with the Corps working with the models and forecasts and doing our planning and then I get a call at 2:15 p.m. telling me they were going to channel capacity.”</p>



<p>Hernandez was floored.</p>



<p>“In 25 years, I’ve never seen anything like this,” he said. “I was given no explanation at all.”</p>



<p>Before they got word of the Army Corp’s decision to release less water, Hernandez, Fukuda and Limas were planning for the worst.</p>



<p>Hernandez had already notified managers on the old Tulare Lake Bed to expect possible flood water. And Limas and Fukuda had crews ready to work through the night stripping out weirs and channel guides, which were only recently rebuilt after the 2023 floods, to keep the water moving.</p>



<p>“Normally, these kinds of flood releases are done with a lot of notification and coordination,” Fukuda said. “I’ve been doing this 18 years and have never seen something like this.”</p>



<p>The Army Corps also operates Isabella and Pine Flat lakes on the Kern and Kings rivers, respectively.</p>



<p>Kern River Watermaster Art Chianello and Kings River Watermaster Steve Haugen both said they had not received notice of flood releases from Isabella and Pine Flat.</p>



<p>But neither of those lake levels are above their winter allowance, Haugen said.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Notes on OpenAI O3-Mini (117 pts)]]></title>
            <link>https://simonwillison.net/2025/Jan/31/o3-mini/</link>
            <guid>42894215</guid>
            <pubDate>Sat, 01 Feb 2025 00:24:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2025/Jan/31/o3-mini/">https://simonwillison.net/2025/Jan/31/o3-mini/</a>, See on <a href="https://news.ycombinator.com/item?id=42894215">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-permalink-context="/2025/Jan/31/o3-mini/">

<p>31st January 2025</p>



<p>OpenAI’s <a href="https://openai.com/index/openai-o3-mini/">o3-mini is out today</a>. As with other o-series models it’s a slightly difficult one to evaluate—we now need to decide if a prompt is best run using GPT-4o, o1, o3-mini or (if we have access) o1 Pro.</p>
<p>Confusing matters further, the benchmarks in <a href="https://openai.com/index/o3-mini-system-card/">the o3-mini system card</a> (PDF) aren’t a universal win for o3-mini across all categories. It generally benchmarks higher than GPT-4o and o1 but not across everything.</p>
<p>The biggest win for o3-mini is on the Codeforces ELO competitive programming benchmark, which I think is <a href="https://arxiv.org/abs/2501.01257">described by this 2nd January 2025 paper</a>, with the following scores:</p>
<ul>
<li>o3-mini (high) 2130</li>
<li>o3-mini (medium) 2036</li>
<li>o1 1891</li>
<li>o3-mini (low) 1831</li>
<li>o1-mini 1650</li>
<li>o1-preview 1258</li>
<li>GPT-4o 900</li>
</ul>
<p>Weirdly, that GPT-4o score was in an older copy of the System Card PDF which has been replaced by an updated document that doesn’t mention Codeforces ELO scores at all.</p>
<p>One note from the System Card that stood out for me concerning intended applications of o3-mini for OpenAI themselves:</p>
<blockquote>
<p>We also plan to allow users to use o3-mini to search the internet and summarize the results in ChatGPT. We expect o3-mini to be a useful and safe model for doing this, especially given its performance on the jailbreak and instruction hierarchy evals detailed in Section 4 below.</p>
</blockquote>
<p>This is notable because the existing o1 models on ChatGPT have not yet had access to their web search tool—despite the mixture of search and “reasoning” models having very clear benefits.</p>
<p>o3-mini does not and <a href="https://twitter.com/nikunjhanda/status/1885415728624656481">will not</a> support vision. We will have to wait for future OpenAI reasoning models for that.</p>
<p>I released <a href="https://llm.datasette.io/en/stable/changelog.html#v0-21">LLM 0.21</a> with support for the new model, plus its <code>-o reasoning_effort high</code> (or <code>medium</code> or <code>low</code>) option for tweaking the reasoning effort—details <a href="https://github.com/simonw/llm/issues/728">in this issue</a>.</p>
<p>Note that the new model is currently only available for <a href="https://platform.openai.com/docs/guides/rate-limits/usage-tiers#tier-3-rate-limits">Tier 3</a> and higher users, which requires you to have spent at least $100 on the API.</p>
<p>o3-mini <a href="https://openai.com/api/pricing/">is priced</a> at $1.10/million input tokens, $4.40/million output tokens—less than half the price of GPT-4o (currently $2.50/$10) and massively cheaper than o1 ($15/60).</p>
<p>I tried using it to summarize <a href="https://news.ycombinator.com/item?id=42890627">this conversation about o3-mini on Hacker News</a>, using <a href="https://til.simonwillison.net/llms/claude-hacker-news-themes#user-content-adding-a--m-model-option">my hn-summary.sh script</a>.</p>

<div><pre>hn-summary.sh 42890627 -o o3-mini</pre></div>

<p>Here’s <a href="https://gist.github.com/simonw/09e5922be0cbb85894cf05e6d75ae050">the result</a>—it used 18,936 input tokens and 2,905 output tokens for a total cost of 3.3612 cents.</p>

<p>Another characteristic worth noting is o3-mini’s token output limit—the measure of how much text it can output in one go.  That’s 100,000 tokens, compared to 16,000 for GPT-4o and just 8,000 for both DeepSeek R1 and Claude 3.5.</p>

<p>Invisible “reasoning tokens” come out of the same budget, so it’s likely not possible to have it output the full 100,000.</p>

<p>The model accepts up to 200,000 tokens of input, an improvement on GPT-4o’s 128,000.</p>

<p>An application where output limits really matter is translation between human languages, where the output can realistically be expected to have a similar length to the input. It will be interesting seeing how well o3-mini works for that, especially given its low price.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Earthstar – A database for private, distributed, offline-first applications (110 pts)]]></title>
            <link>https://earthstar-project.org/</link>
            <guid>42894200</guid>
            <pubDate>Sat, 01 Feb 2025 00:22:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://earthstar-project.org/">https://earthstar-project.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42894200">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>A database for private, distributed, offline-first applications.</p><p>Earthstar is a specification and JavaScript library for building connected applications owned and run by their users.</p><p><img src="https://earthstar-project.org/splash.png"></p></div><ul><li>Works offline.</li><li>Store music, photos, video.</li><li>Actually delete stuff.</li><li>Temporary documents.</li><li>Live syncing.</li><li>Use one or many identities.</li><li>Sneakernets.</li><li>Always self-hosted.</li><li>Servers optional.</li><li>No blockchain.</li><li>No tokens.</li><li>Free forever, in every sense.</li></ul><ul><li>Verification with ed25519.</li><li>Works in the browser.</li><li>Grant read-only access.</li><li>Efficient sync.</li><li>Streaming sync.</li><li>One identity across many devices.</li><li>Multiwriter.</li><li>Storage drivers.</li><li>Document write permissions.</li><li>Deno.</li><li>Node.</li></ul><hr><div><p><a href="https://nlnet.nl/"><img src="https://earthstar-project.org/nlnet.svg"></a></p><p>This project was funded through the<!-- --> <a href="https://nlnet.nl/assure">NGI Assure Fund</a>, a fund established by<!-- --> <a href="https://nlnet.nl/">NLnet</a> <!-- -->with financial support from the European Commission's<!-- --> <a href="https://ngi.eu/">Next Generation Internet</a> <!-- -->programme, under the aegis of DG Communications Networks, Content and Technology under grant agreement No 957073.</p></div></div></div>]]></description>
        </item>
    </channel>
</rss>