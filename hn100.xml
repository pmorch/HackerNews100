<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 19 Feb 2026 18:30:15 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Gemini 3.1 Pro (387 pts)]]></title>
            <link>https://deepmind.google/models/model-cards/gemini-3-1-pro/</link>
            <guid>47075318</guid>
            <pubDate>Thu, 19 Feb 2026 16:14:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://deepmind.google/models/model-cards/gemini-3-1-pro/">https://deepmind.google/models/model-cards/gemini-3-1-pro/</a>, See on <a href="https://news.ycombinator.com/item?id=47075318">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-content">
    
  
    




  

  

<div id="cover">
          
            <p><span>Published 19 February 2026</span></p>
            
          
        </div>





  
    




  <div id="intro">
  <p data-block-key="344bo">Model Cards are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from time-to-time; for example, to include updated evaluations as the model is improved or revised.</p><p data-block-key="cm4bc">Published: February 2026</p>
</div>


  
    



  <div>
  

  <ul data-glue-jumplink-label="Jump to section within page">
    
      
      <li>
        <a href="#model-information" data-gtm-event="in_page_navigation" data-event-content-type="jumplinks" data-event-content-name="Model Information">
          Model Information
        </a>
      </li>
      
    
      
      <li>
        <a href="#model-data" data-gtm-event="in_page_navigation" data-event-content-type="jumplinks" data-event-content-name="Model Data">
          Model Data
        </a>
      </li>
      
    
      
      <li>
        <a href="#implementation-and-sustainability" data-gtm-event="in_page_navigation" data-event-content-type="jumplinks" data-event-content-name="Implementation and Sustainability">
          Implementation and Sustainability
        </a>
      </li>
      
    
      
      <li>
        <a href="#distribution" data-gtm-event="in_page_navigation" data-event-content-type="jumplinks" data-event-content-name="Distribution">
          Distribution
        </a>
      </li>
      
    
      
      <li>
        <a href="#evaluation" data-gtm-event="in_page_navigation" data-event-content-type="jumplinks" data-event-content-name="Evaluation">
          Evaluation
        </a>
      </li>
      
    
      
      <li>
        <a href="#intended-usage-and-limitations" data-gtm-event="in_page_navigation" data-event-content-type="jumplinks" data-event-content-name="Intended Usage and Limitations">
          Intended Usage and Limitations
        </a>
      </li>
      
    
      
      <li>
        <a href="#ethics-and-content-safety" data-gtm-event="in_page_navigation" data-event-content-type="jumplinks" data-event-content-name="Ethics and Content Safety">
          Ethics and Content Safety
        </a>
      </li>
      
    
      
      <li>
        <a href="#frontier-safety" data-gtm-event="in_page_navigation" data-event-content-type="jumplinks" data-event-content-name="Frontier Safety">
          Frontier Safety
        </a>
      </li>
      
    
  </ul>
  
</div>



  


  
    




  <div id="model-information">
      
      
        

<p>
  <h2 data-block-key="344bo">Model Information</h2>
</p>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Description</h3><p data-block-key="emvjj">Gemini 3.1 Pro is the next iteration in the Gemini 3 series of models, a suite of highly capable, natively multimodal reasoning models. As of this model card’s date of publication, Gemini 3.1 Pro is Google’s most advanced model for complex tasks. Geminin 3.1 Pro can comprehend vast datasets and challenging problems from massively multimodal information sources, including text, audio, images, video, and entire code repositories.</p>
</div>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Model dependencies</h3><p data-block-key="fubl5">Gemini 3.1 Pro is based on Gemini 3 Pro.</p>
</div>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Inputs</h3><p data-block-key="5emtg">Text strings (e.g., a question, a prompt, document(s) to be summarized), images, audio, and video files, with a token context window of up to 1M.</p>
</div>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Outputs</h3><p data-block-key="4hel8">Text, with a 64K token output.</p>
</div>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Architecture</h3><p data-block-key="fjl15">Gemini 3.1 Pro is based on Gemini 3 Pro. For more information about the model architecture for Gemini 3.1 Pro, see the Gemini 3 Pro <a href="https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf" rel="noopener" target="_blank">model card</a>.</p>
</div>
      
    </div>


  
    <hr>

  
    




  <div id="model-data">
      
      
        

<p>
  <h2 data-block-key="344bo">Model Data</h2>
</p>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Training Dataset</h3><p data-block-key="9a96d">Gemini 3.1 Pro is based on Gemini 3 Pro. For more information about the training dataset for Gemini 3.1 Pro, see the Gemini 3 Pro <a href="https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf" rel="noopener" target="_blank">model card</a>.</p>
</div>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Training Data Processing</h3><p data-block-key="5uunv">For more information about the training data processing for Gemini 3.1 Pro, see the Gemini 3 Pro <a href="https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf" rel="noopener" target="_blank">model card</a>.</p>
</div>
      
    </div>


  
    <hr>

  
    




  <div id="implementation-and-sustainability">
      
      
        

<p>
  <h2 data-block-key="344bo">Implementation and Sustainability</h2>
</p>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Hardware</h3><p data-block-key="er3jj">Gemini 3.1 Pro is based on Gemini 3 Pro. For more information about the hardware for Gemini 3.1 Pro and our continued<a href="https://sustainability.google/operating-sustainably/" rel="noopener" target="_blank"> commitment to operate sustainably</a>, see the Gemini 3 Pro<a href="https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf" rel="noopener" target="_blank"> model card</a>.</p>
</div>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Software</h3><p data-block-key="7dri8">Gemini 3.1 Pro is based on Gemini 3 Pro. For more information about the software for Gemini 3.1 Pro, see the Gemini 3 Pro <a href="https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf" rel="noopener" target="_blank">model card</a>.</p>
</div>
      
    </div>


  
    <hr>

  
    




  


  
    <hr>

  
    




  <div id="evaluation">
      
      
        

<p>
  <h2 data-block-key="344bo">Evaluation</h2>
</p>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Approach</h3><p data-block-key="56qeu">Gemini 3.1 Pro was evaluated across a range of benchmarks, including reasoning, multimodal capabilities, agentic tool use, multi-lingual performance, and long-context. Additional benchmarks and details on approach, results and their methodologies can be found at: <a href="http://deepmind.google/models/evals-methodology/gemini-3-1-pro" rel="noopener" target="_blank">deepmind.google/models/evals-methodology/gemini-3-1-pro</a>.</p>
</div>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Results</h3><p data-block-key="8rrpr">Gemini 3.1 Pro significantly outperforms Gemini 2.5 Pro across a range of benchmarks requiring enhanced reasoning and multimodal capabilities. Results as of February 2026 are listed below:</p>
</div>
      
    </div>


  
    




  <div id="results">
    <table>
      <thead>
        <tr>
          <th scope="col">Benchmark</th>
          <th scope="col"><span>Notes</span></th>
          <th scope="col">
            Gemini 3.1 Pro
            <small>Thinking (High)</small>
          </th>
          <th scope="col">
            Gemini 3 Pro
            <small>Thinking (High)</small>
          </th>
          <th scope="col">
            Sonnet 4.6
            <small>Thinking (Max)</small>
          </th>
          <th scope="col">
            Opus 4.6
            <small>Thinking (Max)</small>
          </th>
          <th scope="col">
            GPT-5.2
            <small>Thinking (xhigh)</small>
          </th>
          <th scope="col">
            GPT-5.3-Codex
            <small>Thinking (xhigh)</small>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th rowspan="2" scope="row">
            Humanity's Last Exam
            <small>
              Academic reasoning (full set, text + MM)
            </small>
          </th>
          <td><small>No tools</small></td>
          <td><strong>44.4%</strong></td>
          <td>37.5%</td>
          <td>33.2%</td>
          <td>40.0%</td>
          <td>34.5%</td>
          <td>—</td>
        </tr>
        <tr>
          <td>
            <small>
              Search (blocklist) + Code
            </small>
          </td>
          <td>51.4%</td>
          <td>45.8%</td>
          <td>49.0%</td>
          <td><strong>53.1%</strong></td>
          <td>45.5%</td>
          <td>—</td>
        </tr>

        <tr>
          <th scope="row">
            ARC-AGI-2
            <small>Abstract reasoning puzzles</small>
          </th>
          <td><small>ARC Prize Verified</small></td>
          <td><strong>77.1%</strong></td>
          <td>31.1%</td>
          <td>58.3%</td>
          <td>68.8%</td>
          <td>52.9%</td>
          <td>—</td>
        </tr>

        <tr>
          <th scope="row">
            GPQA Diamond
            <small>Scientific knowledge</small>
          </th>
          <td><small>No tools</small></td>
          <td><strong>94.3%</strong></td>
          <td>91.9%</td>
          <td>89.9%</td>
          <td>91.3%</td>
          <td>92.4%</td>
          <td>—</td>
        </tr>

        <tr>
          <th rowspan="2" scope="row">
            Terminal-Bench 2.0
            <small>Agentic terminal coding</small>
          </th>
          <td><small>Terminus-2 harness</small></td>
          <td><strong>68.5%</strong></td>
          <td>56.9%</td>
          <td>59.1%</td>
          <td>65.4%</td>
          <td>54.0%</td>
          <td>64.7%</td>
        </tr>
        <tr>
          <td>
            <small>Other best self-reported harness</small>
          </td>
          <td>—</td>
          <td>—</td>
          <td>—</td>
          <td>—</td>
          <td>62.2% <small>(Codex)</small></td>
          <td>
            <strong>77.3%</strong>
            <small>(Codex)</small>
          </td>
        </tr>

        <tr>
          <th scope="row">
            SWE-Bench Verified
            <small>Agentic coding</small>
          </th>
          <td><small>Single attempt</small></td>
          <td>80.6%</td>
          <td>76.2%</td>
          <td>79.6%</td>
          <td><strong>80.8%</strong></td>
          <td>80.0%</td>
          <td>—</td>
        </tr>

        <tr>
          <th scope="row">
            SWE-Bench Pro (Public)
            <small>
              Diverse agentic coding tasks
            </small>
          </th>
          <td><small>Single attempt</small></td>
          <td>54.2%</td>
          <td>43.3%</td>
          <td>—</td>
          <td>—</td>
          <td>55.6%</td>
          <td><strong>56.8%</strong></td>
        </tr>

        <tr>
          <th scope="row">
            LiveCodeBench Pro
            <small>
              Competitive coding problems from Codeforces, ICPC, and IOI
            </small>
          </th>
          <td><small>Elo</small></td>
          <td><strong>2887</strong></td>
          <td>2439</td>
          <td>—</td>
          <td>—</td>
          <td>2393</td>
          <td>—</td>
        </tr>

        <tr>
          <th scope="row">
            SciCode
            <small>Scientific research coding</small>
          </th>
          <td></td>
          <td><strong>59%</strong></td>
          <td>56%</td>
          <td>47%</td>
          <td>52%</td>
          <td>52%</td>
          <td>—</td>
        </tr>

        <tr>
          <th scope="row">
            APEX-Agents
            <small>
              Long horizon professional tasks
            </small>
          </th>
          <td><small></small></td>
          <td><strong>33.5%</strong></td>
          <td>18.4%</td>
          <td>—</td>
          <td>29.8%</td>
          <td>23.0%</td>
          <td>—</td>
        </tr>

        <tr>
          <th scope="row">
            GDPval-AA Elo
            <small>Expert tasks</small>
          </th>
          <td></td>
          <td>1317</td>
          <td>1195</td>
          <td><strong>1633</strong></td>
          <td>1606</td>
          <td>1462</td>
          <td>—</td>
        </tr>

        <tr>
          <th rowspan="2" scope="row">
            τ2-bench
            <small>Agentic and tool use</small>
          </th>
          <td><small>Retail</small></td>
          <td>90.8%</td>
          <td>85.3%</td>
          <td>91.7%</td>
          <td><strong>91.9%</strong></td>
          <td>82.0%</td>
          <td>—</td>
        </tr>
        <tr>
          <td><small>Telecom</small></td>
          <td><strong>99.3%</strong></td>
          <td>98.0%</td>
          <td>97.9%</td>
          <td><strong>99.3%</strong></td>
          <td>98.7%</td>
          <td>—</td>
        </tr>

        <tr>
          <th scope="row">
            MCP Atlas
            <small>
              Multi-step workflows using MCP
            </small>
          </th>
          <td></td>
          <td><strong>69.2%</strong></td>
          <td>54.1%</td>
          <td>61.3%</td>
          <td>59.5%</td>
          <td>60.6%</td>
          <td>—</td>
        </tr>

        <tr>
          <th scope="row">
            BrowseComp
            <small>Agentic search</small>
          </th>
          <td>
            <small>Search + Python + Browse</small>
          </td>
          <td><strong>85.9%</strong></td>
          <td>59.2%</td>
          <td>74.7%</td>
          <td>84.0%</td>
          <td>65.8%</td>
          <td>—</td>
        </tr>

        <tr>
          <th scope="row">
            MMMU-Pro
            <small>
              Multimodal understanding and reasoning
            </small>
          </th>
          <td><small>No tools</small></td>
          <td>80.5%</td>
          <td><strong>81.0%</strong></td>
          <td>74.5%</td>
          <td>73.9%</td>
          <td>79.5%</td>
          <td>—</td>
        </tr>

        <tr>
          <th scope="row">
            MMMLU
            <small>Multilingual Q&amp;A</small>
          </th>
          <td></td>
          <td><strong>92.6%</strong></td>
          <td>91.8%</td>
          <td>89.3%</td>
          <td>91.1%</td>
          <td>89.6%</td>
          <td>—</td>
        </tr>

        <tr>
          <th rowspan="2" scope="row">
            MRCR v2 (8-needle)
            <small>Long context performance</small>
          </th>
          <td><small>128k (average)</small></td>
          <td><strong>84.9%</strong></td>
          <td>77.0%</td>
          <td><strong>84.9%</strong></td>
          <td>84.0%</td>
          <td>83.8%</td>
          <td>—</td>
        </tr>
        <tr>
          <td>
            <small>1M (pointwise)</small>
          </td>
          <td>26.3%</td>
          <td>26.3%</td>
          <td><small>Not supported</small></td>
          <td><small>Not supported</small></td>
          <td><small>Not supported</small></td>
          <td>—</td>
        </tr>
      </tbody>
    </table>
  </div>


  
    




  <div id="intended-usage-and-limitations">
      
      
        

<p>
  <h2 data-block-key="344bo">Intended Usage and Limitations</h2>
</p>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Benefit and Intended Usage</h3><p data-block-key="2k71k">Gemini 3.1 Pro is the next iteration in the Gemini 3.0 series of models, a suite of highly intelligent and adaptive models, capable of helping with real-world complexity, solving problems that require enhanced reasoning and intelligence, creativity, strategic planning and making improvements step-by-step. It is particularly well-suited for applications that require:</p><ul><li data-block-key="926ju">agentic performance</li><li data-block-key="4n01t">advanced coding</li><li data-block-key="ala1v">long context and/or multimodal understanding</li><li data-block-key="87pnn">algorithmic development</li></ul>
</div>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Known Limitations</h3><p data-block-key="8qrh9">For more information about the known limitations for Gemini 3.1 Pro, see the Gemini 3 Pro <a href="https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf" rel="noopener" target="_blank">model card</a>.</p>
</div>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Acceptable Usage</h3><p data-block-key="65pfs">For more information about the acceptable usage for Gemini 3.1 Pro, see the Gemini 3 Pro <a href="https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf" rel="noopener" target="_blank">model card</a>.</p>
</div>
      
    </div>


  
    <hr>

  
    




  <div id="ethics-and-content-safety">
      
      
        

<p>
  <h2 data-block-key="344bo">Ethics and Content Safety</h2>
</p>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Evaluation Approach</h3><p data-block-key="2k71k">For more information about the evaluation approach for Gemini 3.1 Pro, see the Gemini 3 Pro <a href="https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf" rel="noopener" target="_blank">model card</a>.</p>
</div>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Safety Policies</h3><p data-block-key="2k71k">For more information about the safety policies for Gemini 3.1 Pro, see the Gemini 3 Pro <a href="https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf" rel="noopener" target="_blank">model card</a>.</p>
</div>
      
        

      
        

<div>
  <h3 data-block-key="344bo">Training and Development Evaluation Results</h3><p data-block-key="2v31c">Results for some of the internal safety evaluations conducted during the development phase are listed below. The evaluation results are for automated evaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage increase or decrease in performance compared to the indicated model, as described below. Overall, Gemini 3.1 Pro outperforms Gemini 3.0 Pro across both safety and tone, while keeping unjustified refusals low. We mark improvements in green and regressions in red. Safety evaluations of Gemini 3.1 Pro produced results consistent with the original Gemini 3.0 Pro safety assessment.</p>
</div>
      
        

      
        

<div>
    <table>
      <thead>
        <tr>
          <th scope="col">Evaluation<sup>1</sup></th>
          <th scope="col">
            Description
          </th>
          <th scope="col">
            Gemini 3.1 Pro<br>
            <small>vs. Gemini 3.0 Pro</small>
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th scope="row">
            Text to Text Safety
          </th>
          <td>Automated content safety evaluation measuring safety policies</td>
          <td>+0.10% (non-egregious)</td>
        </tr>
        <tr>
          <th scope="row">
            Multilingual Safety 
          </th>
          <td>Automated safety policy evaluation across multiple languages</td>
          <td>+0.11% (non-egregious)</td>
        </tr>
        <tr>
          <th scope="row">
            Image to Text Safety
          </th>
          <td>Automated content safety evaluation measuring safety policies</td>
          <td>-0.33%</td>
        </tr>
        <tr>
          <th scope="row">
            Tone<sup>2</sup>
          </th>
          <td>Automated evaluation measuring objective tone of model refusal</td>
          <td>+0.02%</td>
        </tr>
        <tr>
          <th scope="row">
            Unjustified-refusals
          </th>
          <td>Automated evaluation measuring model’s ability to respond to borderline prompts while remaining safe</td>
          <td>-0.08%</td>
        </tr>                        
      </tbody>
    </table>
  </div>
      
        

      
        



      
        

      
        

<div>
  <p data-block-key="4i2vs">We continue to improve our internal evaluations, including refining automated evaluations to reduce false positives and negatives, as well as update query sets to ensure balance and maintain a high standard of results. The performance results reported below are computed with improved evaluations and thus are not directly comparable with performance results found in previous Gemini model cards.</p><p data-block-key="h4t8">We expect variation in our automated safety evaluations results, which is why we review flagged content to check for egregious or dangerous material. Our manual review confirmed losses were overwhelmingly either a) false positives or b) not egregious.</p>
</div>
      
        

      
        

<div>
  <h3 data-block-key="z38lz">Human Red Teaming Results</h3><p data-block-key="d8uos">We conduct manual red teaming by specialist teams who sit outside of the model development team. High-level findings are fed back to the model team. For child safety evaluations, Gemini 3.1 Pro satisfied required launch thresholds, which were developed by expert teams to protect children online and meet <a href="https://blog.google/technology/safety-security/an-update-on-our-child-safety-efforts-and-commitments/" rel="noopener" target="_blank">Google’s commitments to child safety</a> across our models and Google products. For content safety policies generally, including child safety, we saw similar safety performance compared to Gemini 3.0 Pro.</p>
</div>
      
        

      
        

<div>
  <h3 data-block-key="z38lz">Risks and Mitigations</h3><p data-block-key="tr6n">For more information about the risks and mitigations for Gemini 3.1 Pro, see the Gemini 3 Pro <a href="https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf" rel="noopener" target="_blank">model card</a>.</p>
</div>
      
    </div>


  
    <hr>

  
    




  <div id="frontier-safety">
      
      
        

<p>
  <h2 data-block-key="344bo">Frontier Safety</h2>
</p>
      
        

      
        

<div>
  <p data-block-key="4i2vs">Our <a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/strengthening-our-frontier-safety-framework/frontier-safety-framework_3.pdf" rel="noopener" target="_blank">Frontier Safety Framework</a> includes rigorous evaluations that address risks of severe harm from frontier models, covering five risk domains: CBRN (chemical, biological, radiological and nuclear information risks), cyber, harmful manipulation, machine learning R&amp;D and misalignment.</p><p data-block-key="1q5f9">Our frontier safety strategy is based on a “safety buffer” to prevent models from reaching critical capability levels (CCLs), i.e. if a frontier model does not reach the alert threshold for a CCL, we can assume models developed before the next regular testing interval will not reach that CCL. We conduct continuous testing, evaluating models at a fixed cadence and when a significant capability jump is detected. (Read more about this in our <a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/evaluating-potential-cybersecurity-threats-of-advanced-ai/An_Approach_to_Technical_AGI_Safety_Apr_2025.pdf" rel="noopener" target="_blank">approach to technical AGI safety.</a>)</p><p data-block-key="2ub8o">Following FSF protocols, we conducted a full evaluation of Gemini 3.1 Pro (focusing on Deep Think mode). We found that the model remains below alert thresholds for the CBRN, harmful manipulation, machine learning R&amp;D, and misalignment CCLs. As previous models passed the alert threshold for cyber, we performed more additional testing in this domain on Gemini 3.1 Pro with and without Deep Think mode, and found that the model remains below the cyber CCL.</p><p data-block-key="490m1">More details on our evaluations and the mitigations we deploy can be found in the<a href="https://deepmind.google/models/fsf-reports/gemini-3-pro/" rel="noopener" target="_blank"> Gemini 3 Pro Frontier Safety Framework Report</a>.</p>
</div>
      
    </div>


  
    




  <div id="frontier-safety">
    <table>
      <thead>
        <tr>
          <th scope="col">Domain</th>
          <th scope="col">
            Key Results for Gemini 3.1 Pro
          </th>
          <th scope="col">
            CCL
          </th>
          <th scope="col">
            CCL reached?
          </th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th scope="row">
            CBRN
          </th>
          <td>
            (Deep Think mode) The model can provide highly accurate and actionable information but still fails to offer novel or sufficiently complete and detailed instructions for critical stages,  to significantly enhance the capabilities of low to medium resourced threat actors required for the CCL. We continue to deploy mitigations in this domain.
          </td>
          <td>
            Uplift Level 1 
          </td>
          <td>
            CCL not reached
          </td>
        </tr>
        <tr>
          <th scope="row">
            Cyber
          </th>
          <td>
            (3.1 Pro) We conducted additional testing on the model in this domain as Gemini 3 Pro had previously reached the alert threshold. The model shows an  increase in cyber capabilities compared to Gemini 3 Pro. As with Gemini 3 Pro, the model has reached the alert threshold, but still does not reach the levels of uplift required for the CCL.
            <p>
            (Deep Think mode) Accounting for inference costs, the model with Deep Think mode performs considerably worse than without Deep Think mode. Even at high levels of inference, results for the model with Deep Think mode do not suggest higher capability than without Deep Think mode.
            </p><p>
            We continue to deploy mitigations in this domain.
          </p></td>
          <td>
            Uplift Level 1 
          </td>
          <td>
            CCL not reached
          </td>
        </tr>
        <tr>
          <th scope="row">
            Harmful Manipulation
          </th>
          <td>
            (Deep Think mode) Evaluations indicated that the model showed higher manipulative efficacy for belief change metrics compared to a non-AI baseline, with the maximum odds ratio of 3.6x, which is the same as Gemini 3 Pro, and did not reach the alert threshold.  
          </td>
          <td>
            Level 1 (exploratory) 
          </td>
          <td>
            CCL not reached
          </td>
        </tr>
        <tr>
          <th scope="row">
            Machine Learning R&amp;D
          </th>
          <td>
            (Deep Think mode) The model shows gains on RE-Bench compared to Gemini 3 Pro, with a human-normalised average score of 1.27 compared to Gemini 3 Pro's score of 1.04. On one particular challenge, Optimise LLM Foundry, it scores double the human-normalised baseline score (reducing the runtime of a fine-tuning script from 300 seconds to 47 seconds, compared to the human reference solution of 94 seconds). However, the model’s average performance across all challenges remains beneath the alert threshold for the CCLs.
          </td>
          <td>
            Acceleration level 1<br>
            Automation level 1
          </td>
          <td>
            CCLs not reached
          </td>
        </tr>
        <tr>
          <th scope="row">
            Misalignment (Exploratory)
          </th>
          <td>
            (Deep Think mode) On stealth evaluations, the model performs similarly to Gemini 3 Pro. On situational awareness, the model is stronger than Gemini 3 Pro: on three challenges which no other model has been able to consistently solve, max tokens, context size mod, and oversight frequency, the model achieves a success rate of almost 100%. However, its performance on other challenges is inconsistent, and thus the model does not reach the alert threshold.
          </td>
          <td>
            Instrumental Reasoning<br>
            Levels 1 + 2 (exploratory)
          </td>
          <td>
            CCLs not reached
          </td>
        </tr>
      </tbody>
    </table>
  </div>


  

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gemini 3.1 Pro Preview (140 pts)]]></title>
            <link>https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-3.1-pro-preview?pli=1</link>
            <guid>47074735</guid>
            <pubDate>Thu, 19 Feb 2026 15:19:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-3.1-pro-preview?pli=1">https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-3.1-pro-preview?pli=1</a>, See on <a href="https://news.ycombinator.com/item?id=47074735">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[America vs. Singapore: You Can't Save Your Way Out of Economic Shocks (133 pts)]]></title>
            <link>https://www.governance.fyi/p/america-vs-singapore-you-cant-save</link>
            <guid>47074389</guid>
            <pubDate>Thu, 19 Feb 2026 14:52:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.governance.fyi/p/america-vs-singapore-you-cant-save">https://www.governance.fyi/p/america-vs-singapore-you-cant-save</a>, See on <a href="https://news.ycombinator.com/item?id=47074389">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!mrn8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb306c317-e1de-4420-95f5-9d3f1bc7b28f_800x430.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!mrn8!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb306c317-e1de-4420-95f5-9d3f1bc7b28f_800x430.jpeg 424w, https://substackcdn.com/image/fetch/$s_!mrn8!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb306c317-e1de-4420-95f5-9d3f1bc7b28f_800x430.jpeg 848w, https://substackcdn.com/image/fetch/$s_!mrn8!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb306c317-e1de-4420-95f5-9d3f1bc7b28f_800x430.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!mrn8!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb306c317-e1de-4420-95f5-9d3f1bc7b28f_800x430.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!mrn8!,w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb306c317-e1de-4420-95f5-9d3f1bc7b28f_800x430.jpeg" width="1200" height="645" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b306c317-e1de-4420-95f5-9d3f1bc7b28f_800x430.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:430,&quot;width&quot;:800,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:&quot;center&quot;,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!mrn8!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb306c317-e1de-4420-95f5-9d3f1bc7b28f_800x430.jpeg 424w, https://substackcdn.com/image/fetch/$s_!mrn8!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb306c317-e1de-4420-95f5-9d3f1bc7b28f_800x430.jpeg 848w, https://substackcdn.com/image/fetch/$s_!mrn8!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb306c317-e1de-4420-95f5-9d3f1bc7b28f_800x430.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!mrn8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb306c317-e1de-4420-95f5-9d3f1bc7b28f_800x430.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><ul><li><p><strong>Procrastination does not meaningfully predict saving regret.</strong><span> Across 12 psychometric measures tested in both countries, the relationship is weak to nonexistent, and where statistically significant, it frequently runs in the </span><em>opposite</em><span> direction from what the behavioral economics literature predicts.</span></p></li><li><p><strong>Economic shocks do.</strong><span> Exposure to negative financial shocks is the dominant predictor of wishing you’d saved more.</span></p></li></ul><p>About half of Americans between 60 and 74 wish they had saved more. That’s a familiar finding, and it comes with a familiar explanation: people procrastinate. They know they should save, they intend to save, and then they don’t, because the present is vivid and retirement is abstract, because inertia is powerful, because human beings are not the rational optimizers of the textbook. A generation of behavioral economics has crystallized around this idea. We get nudges, automatic enrollment in 401(k) plans, default escalation schedules. The policy apparatus assumes, at bottom, that under-saving is a self-control problem.</p><p><a href="https://www.nber.org/papers/w34835" rel="">A new working paper from Rohwedder, Hurd, and Börsch-Supan suggests we’ve been looking in the wrong place.</a><span> The authors surveyed thousands of people aged 60–74 in the United States and Singapore, two countries that both emphasize individual responsibility for retirement but differ sharply in institutional design. They asked a simple question: if you could do it over, would you have saved more? Then they tested what actually predicts the answer. Is it procrastination? Or is it something else?</span></p><p>The something else turns out to be economic shocks. And the difference is not subtle. Which is (depends on you, darkly or not so) funny, considering what a lot of people are saying about LLMs/AI/etc and the job market. </p><p data-attrs="{&quot;url&quot;:&quot;https://www.governance.fyi/p/america-vs-singapore-you-cant-save?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.governance.fyi/p/america-vs-singapore-you-cant-save?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>The authors didn’t just ask people whether they procrastinate and whether they regret their saving. They fielded 12 separate psychometric measures: questions about putting off tasks, giving up when things get difficult, settling for mediocre results, losing motivation, preferring immediate gratification. These are the kinds of instruments the behavioral literature treats as markers of present bias and poor self-control. The prediction, grounded in decades of work from Laibson, Thaler, O’Donoghue, Rabin, and others, is straightforward: people who score high on procrastination should be more likely to wish they’d saved more.</p><p><span>They aren’t. Across both countries, across 21 separate statistical comparisons per dataset, the relationship between procrastination and saving regret is, to a first approximation, nonexistent. Where significant associations do appear, they frequently run in the wrong direction. In Singapore, people who report </span><em>never</em><span> putting off difficult things are </span><em>more</em><span> likely to express saving regret than those who sometimes do. The authors later confirmed these null results using a different, widely validated procrastination scale. The finding held.</span></p><p>Now consider the alternative explanation. The surveys also asked respondents whether they had experienced negative financial shocks over their lifetimes: unemployment spells, large health expenses, earnings shortfalls, divorces, early forced retirement. Here the pattern is immediate and powerful. In the U.S., 69 percent of respondents reported at least one negative shock, compared with 46 percent in Singapore. And among Americans who experienced such shocks, 61 percent expressed saving regret, compared with 42 percent among those who didn’t.</p><p>Four of the five most common negative shocks are labor-market related, and the U.S. leads on every one. Some 18 percent of American respondents reported an unemployment spell serious enough to damage their finances, compared with 11 percent in Singapore. Among those who experienced that shock, 62 percent of Americans expressed saving regret versus 54 percent of Singaporeans. The pattern repeats across the board: health limiting work (20 percent of Americans, 14 percent of Singaporeans), earnings falling short of expectations (16 percent versus 12 percent), being pushed into early retirement (13 percent versus 8 percent). In each case, the shock is both more common in the U.S. and more financially scarring.</p><p>It’s not just that more Americans lose their jobs. It’s that losing a job in America does more lasting damage to a household’s financial trajectory. An unemployment spell in the U.S. leaves people staring at their retirement accounts with a 62 percent chance of wishing they’d saved more. The same event in Singapore produces regret at 54 percent, still painful, but meaningfully less so. Multiply that differential across every category of labor market disruption, across decades of working life, and you begin to see why the two countries diverge so sharply on saving regret despite similar levels of individual responsibility.</p><p><span>As the number of negative shocks accumulates, regret in the U.S. climbs steadily, reaching 76 percent among those who experienced five or more. In Singapore, regret barely budges: it hovers around 50 percent regardless of how many shocks a person reports. And among respondents in both countries who experienced </span><em>no</em><span> negative shocks, the rate of saving regret is nearly identical: 42 percent in the U.S. versus 40 percent in Singapore. The cross-national gap in regret is almost entirely a gap in shock exposure and shock consequences.</span></p><p>This is where institutional design enters the story, and where the comparison gets interesting, because Singapore’s advantage isn’t just about retirement accounts. (What follows draws on the paper’s detailed institutional background as well as more recent developments.)</p><p><span>Singapore’s Central Provident Fund mandates that roughly 37 percent of earnings flow into individual accounts earmarked for retirement, housing, and health care. These aren’t optional. They aren’t nudges. They’re compulsory contributions, split across three accounts: an Ordinary Account for housing and eventually retirement, a Special Account locked until age 55 for retirement only, and a MediSave Account for health insurance and medical expenses. The system doesn’t pool risk the way Social Security does, but it creates a buffer. When a health shock hits, there’s a dedicated account to absorb it. When housing costs are high, there’s a dedicated account for that, too. And critically, these accounts exist </span><em><strong>before</strong></em><span> the shock arrives. They aren’t savings that a job loss can redirect toward rent.</span></p><p>On the labor market side, Singapore takes a different approach, though not always a generous one. For most of its modern history, there was no government-provided unemployment insurance at all. The stated policy aim was re-employment, not income replacement. The Retirement and Re-employment Act, introduced in 2007 and enacted in 2012, requires employers to offer contract extensions to workers reaching the retirement age (initially 62, now 63), with penalties for unjustified refusals. The re-employment age has been raised repeatedly, to 67 in 2017, to 68 in 2022. The results are visible in the data: labor force participation among Singaporean men aged 60–64 rose from 53 percent in 2005 to 77 percent in 2019. For women in that age range, it jumped from 21 percent to 51 percent. Singapore doesn’t primarily cushion job loss with cash benefits. It tries to prevent job loss from happening in the first place, or at least to shorten the gap.</p><p><span>That said (and this postdates the paper’s data collection), Singapore has recently acknowledged the limits of this approach. </span><a href="https://www.channelnewsasia.com/singapore/jobseeker-support-scheme-unemployment-benefits-6000-how-apply-5064691" rel="">In April 2025, the government launched the SkillsFuture Jobseeker Support scheme, which provides up to S$6,000 over six months to involuntarily unemployed citizens earning S$5,000 or less per month.</a><span> The payments taper over time and are tied to active participation in job search activities, career coaching, and training. The government set aside more than S$200 million for the program, expecting roughly 60,000 eligible individuals per year. It’s modest by international standards, but it represents a significant shift in a country that had long resisted anything resembling unemployment benefits, and it’s paired with structured re-employment support rather than offered as a standalone cash transfer.</span></p><p><span>Now consider the American alternative. The U.S. unemployment insurance system is, to put it plainly, a mess. And the mess is measurable.</span><a href="https://www.nelp.org/enforcing-unemployment-insurance-performance-standards-to-support-more-workers/" rel=""> In 2024, only 27 percent of jobless workers nationwide received UI benefits.</a><span> That’s not a typo. </span><em><strong>Roughly three out of four unemployed Americans get nothing.</strong></em><span> State-level variation is staggering: Minnesota led the nation at 55 percent; Kentucky managed 10 percent. The duration of benefits ranges from as few as 12 weeks in North Carolina, Florida, and Tennessee to 26 weeks in most states, and the maximum weekly benefit varies from $235 in Mississippi to $823 in Massachusetts.</span></p><p><span>A 55-year-old American worker who loses her job faces a gauntlet of compounding risks that her Singaporean counterpart largely does not. She may or may not qualify for unemployment benefits depending on which state she lives in, how she lost her job, and whether she can navigate the application process. If she does qualify, the benefits may last as few as 12 weeks. If her employer provided her health insurance, as is the case for the majority of covered workers, she loses that too, precisely when stress and disruption make health problems more likely. Employer-provided health insurance tied to employment means that a job loss can simultaneously eliminate income </span><em>and</em><span> health coverage, a compounding shock that Singapore’s system avoids by design. </span><a href="https://eig.org/whos-left-out-of-americas-retirement-savings-system/" rel="">Roughly 42% of American workers lack access to employer-sponsored retirement plans in the first place</a><span>. And when shocks arrive, a layoff at 55, a medical crisis, a divorce, they erode whatever savings a household has managed to accumulate.</span></p><p>The health care comparison is particularly stark. Health spending shocks occur at roughly equal rates in both countries, around 10 to 11 percent of respondents in each sample reported a large medical expense. But the consequences diverge dramatically. In the U.S., experiencing a health spending shock is associated with a 24-percentage-point increase in saving regret relative to those with no negative shocks at all. In Singapore, the corresponding increase is just 10 points. Same shock, radically different financial scar, because in Singapore, MediSave and subsidized public insurance absorb much of the blow. It helps that Singapore spends roughly 4 percent of GDP on health care; the U.S. spends 17 percent.</p><p><span>No? Automatic enrollment works. Default escalation schedules increase contributions. The behavioral economics toolkit has real value, but these are </span><em>tools</em><span> at the end of the day, not a cure all. If the reason people end up with less savings than they’d like is primarily that </span><em>life happened to them</em><span>, job losses, health crises, family disruptions, stagnant wages, then making it marginally easier to contribute to a 401(k) treats a symptom rather than the disease.</span></p><p>And the disease is uninsured risk. The paper reframes under-saving not as a failure of willpower but as a failure of risk management, or more precisely, as a failure to provide the institutional infrastructure that lets households manage risk. Singapore’s system is far from perfect. It concentrates wealth heavily in housing (median housing wealth of about $377,000 against median total wealth of $575,000 for older Singaporeans), leaving less available for non-housing consumption. It lacks the redistributive features that make Social Security critical for lower-income Americans. And even with all that forced saving, 45 percent of older Singaporeans still wish they’d saved more. Mandatory contributions are not a complete answer.</p><p>But they are a better starting point than assuming the problem is procrastination. The evidence here is fairly clear: when you compare people who weren’t hit by shocks, Americans and Singaporeans look almost identical in their saving satisfaction. The gap opens up because Americans face more shocks, more severe shocks, and weaker institutional buffers against those shocks. College costs in the U.S. doubled in real terms between 1989 and 2016 while median wages stagnated. Divorce rates are higher. Labor market disruptions are more common and more financially devastating. Each of these is a rock thrown at the household balance sheet, and no amount of commitment-device wizardry prevents the damage.</p><p>The authors discovered that probability numeracy, the ability to reason about uncertainty and likelihood, was strongly associated with lower saving regret in both countries. Individuals who answered all probability questions correctly had saving regret rates 14 percentage points lower in the U.S. and 19 points lower in Singapore. Financial literacy, by contrast, showed no consistent relationship.</p><p><span>That distinction matters. Financial literacy is about understanding compound interest and inflation. Probability numeracy is about understanding </span><em>risk</em><span>, that bad things happen with some frequency, that the future is uncertain, that planning means preparing for contingencies. If the core problem is shock exposure rather than procrastination, it makes sense that the skill most protective against regret is the one that helps people think clearly about an uncertain world.</span></p><p data-attrs="{&quot;url&quot;:&quot;https://www.governance.fyi/p/america-vs-singapore-you-cant-save?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.governance.fyi/p/america-vs-singapore-you-cant-save?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>The policy implications follow naturally, and the paper is explicit about them. Strengthening social insurance against catastrophic risks, health expenses, long-term care costs, labor market disruptions, would do more to reduce saving regret than yet another tweak to choice architecture. Expanding access to retirement savings vehicles matters, certainly, but so does ensuring that a single medical bill or job loss doesn’t wipe out decades of careful accumulation. The authors point to buffer-stock saving programs, emergency savings accounts, and integrated health-and-retirement saving frameworks as directions worth pursuing, while noting that self-insurance alone is “inefficient protection against large shocks because of the lack of risk-pooling” and “insufficient because many persons cannot save enough to meet all contingencies.”</p><p>We’ve spent a generation treating under-saving as a problem of human psychology. The better framing might be simpler and, in its way, harder: people aren’t failing to save because they’re weak. They’re failing to save because the world is rough, and their institutions don’t do enough to help them weather it.</p><p><strong>Probability numeracy</strong><span> stands out. Respondents who answered all probability questions correctly had saving regret 14 percentage points lower in the U.S. and 19 points lower in Singapore. Financial literacy, the “Big Three” questions on compound interest, inflation, and diversification, showed no consistent relationship. In Singapore, lower financial literacy was actually associated with </span><em>lower</em><span> regret. The distinction: financial literacy measures whether you understand how money grows; probability numeracy measures whether you understand that bad things happen and can reason about how likely they are.</span></p><p><span>A </span><strong>long financial planning horizon</strong><span> (10+ years) was associated with roughly 10 points lower regret in the U.S. and 6 points in Singapore. </span><strong>Higher wealth</strong><span> also reduces regret, particularly in the U.S., where the gap between the highest and lowest wealth quartiles is about 24 percentage points (36% vs. 60% regret). In Singapore, the gradient is flatter (40% vs. 46%).</span></p><p>Some 23 percent of Americans reported three or more shocks; only 10 percent of Singaporeans did. U.S. regret climbs steeply with accumulation: 42 percent with zero shocks, 54 percent with one, 61 percent with two, 76 percent with five or more. In Singapore, regret rises to about 50 percent after one shock and then barely moves, hovering between 48 and 55 percent regardless of additional shocks.</p><p><strong>Divorce:</strong><span> 19 percent of U.S. respondents experienced divorce or separation (63% regret); only 1.5 percent of Singaporeans did (40% regret). </span></p><p><strong>College costs:</strong><span> 9 percent of Americans reported higher-than-expected college expenses (67% regret) versus 4 percent of Singaporeans (46% regret). Context from the paper: U.S. college costs doubled in real terms between 1989 and 2016 while median wages stagnated; Singapore university tuition rose only 14 percent between 2007 and 2016 while median wages rose 23 percent.</span></p><p>Several ostensibly positive shocks (working longer than expected, receiving financial help from family, spending less than expected) turn out to correlate with negative shocks. In Singapore, 61 percent of those who worked longer than expected had also experienced a negative shock, compared with 43 percent of those who hadn't. In the U.S. the pattern is similar if less stark: 80 percent versus 67 percent. </p><p>These "positive" events may reflect coping with adversity rather than genuine windfalls: working longer because you had to, receiving family help because a health crisis demanded it. The authors exclude them from their summary positive-shock variable, and are candid about why: "defining unambiguous positive shocks is challenging." Even after that exclusion, the cleaned-up variable behaves oddly. In the U.S., experiencing a positive shock is associated with about 9 percentage points lower regret. In Singapore, it has virtually no effect.</p><p><span>About 54 percent of Americans aged 60–74 wish they’d saved more, compared with 45 percent of Singaporeans. Very few in either country wish they’d saved less (1.5 percent and 4.3 percent respectively). These figures are </span><em>after</em><span> a built-in correction: respondents were reminded that saving more means spending less, then asked which categories of spending they could have cut. Those who said “no way we could have cut spending” were recoded as not expressing regret. Before that correction, regret was 66 percent in the U.S. and 53 percent in Singapore. The survey also ran a framing experiment: asking “spend less and save more” versus just “save more” reduced regret by about 7 percentage points.</span></p><p>The U.S. data come from the RAND American Life Panel (ALP), an Internet-based panel of about 6,000 individuals, surveyed in two waves (2016 and 2017–18; 2,618 respondents aged 60–74, with 2,111 overlapping both waves). The Singapore data come from the Singapore Life Panel (SLP), a monthly Internet-based survey representative of the Singapore population aged 50–70 at recruitment, fielded in May 2018 (4,309 respondents aged 60–74). The SLP questionnaire was designed to match the second ALP wave as closely as possible. Descriptive statistics are weighted; regressions are unweighted. Standard errors in ALP regressions are adjusted for repeated observations from overlap cases.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.governance.fyi/p/america-vs-singapore-you-cant-save?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.governance.fyi/p/america-vs-singapore-you-cant-save?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pebble Production: February Update (194 pts)]]></title>
            <link>https://repebble.com/blog/february-pebble-production-and-software-updates</link>
            <guid>47073112</guid>
            <pubDate>Thu, 19 Feb 2026 12:36:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://repebble.com/blog/february-pebble-production-and-software-updates">https://repebble.com/blog/february-pebble-production-and-software-updates</a>, See on <a href="https://news.ycombinator.com/item?id=47073112">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span><img src="https://repebble.com/assets/february-pebble-production-and-software-updates-0-image.png" alt="" loading="lazy"></span></p>
<h3 id="mega-update-on-pebble-time-2-pebble-round-2-and-index-01"><a href="#mega-update-on-pebble-time-2-pebble-round-2-and-index-01"><span>#</span>Mega update on Pebble Time 2, Pebble Round 2 and Index 01</a></h3>
<p>Things are busy in Pebbleland! We’re getting close to shipping 3 new hardware products and all the associated software that comes along with them. Overall, things feel good. I’d say the amount of last minute shenanigans is at the normal amount. Getting new hardware into ‘production’ is a pretty wild and exciting process. Building hardware is an exercise in balancing competing priorities of cost, quality and speed. In the last mile push to get into production, things can change quickly for the best (woohoo! the waterproof test finally passes, we can move to the next stage), or less good (uh, the production line needs 3 more test fixtures to test Index 01 mic performance, and a major production test software update…that’ll be a lot more money). Unlike with software, you can’t easily fix hardware issues after you ship! Making these last minute decisions is sometimes pretty stressful but hey, that’s the world of making hardware.</p>
<h3 id="pebble-time-2-production-update"><a href="#pebble-time-2-production-update"><span>#</span><strong>Pebble Time 2 Production Update</strong></a></h3>
<p><span><img src="https://repebble.com/assets/february-pebble-production-and-software-updates-1-cleanshot_2026-02-17_at_23.42.112x.png" alt="" loading="lazy"></span></p>
<p>We’re in the Production Verification Test (PVT) phase right now, the last stop before Mass Production (MP). During this phase we manufactured hundreds of PT2s in a series of test builds, uncovered a bunch of issues, and fixed a bunch of issues. Just before the factories shut down for the lunar New Year, we got the good news that all the tests passed on the last build!</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/HP9PcCY_Fpc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"></iframe>
<p>We focused most of January on improving the waterproofing on the watch (flash back to <a href="https://ericmigi.com/blog/pebble-2-duo-is-in-mass-production/#pebble-2-duo-waterpr" target="_blank" rel="noopener noreferrer">last summer</a> when we worked on this for Pebble 2 Duo!). I traveled to visit the factory (<a href="https://bsky.app/profile/ericmigi.com/post/3md2p4n3uwk2u" target="_blank" rel="noopener noreferrer">travelogue here</a>) and worked through a lot of open issues. Above is a video of the speaker waterproof testing from the production line. Good news is that we fixed all the issues, tests are passing and it looks like we’ll be able to certify PT2 with a waterproof rating of 30m or 3ATM! This means you can get your watch wet, wear it while swimming (but not in hot tubs/saunas) and generally not worry about it. It’s not a dive watch, though. Also, don’t expose it to hot water (this could weaken the waterproof seals), or high pressure water. It’s not invincible.</p>
<p><strong>Entering PT2 Mass Production on March 9</strong></p>
<p><span><img src="https://repebble.com/assets/february-pebble-production-and-software-updates-2-cleanshot_2026-02-15_at_13.39.532x.png" alt="" loading="lazy"></span></p>
<p><em>Snapshot of our mass production plan (output counts are cumulative)</em></p>
<p>The factory is closed now for Lunar New Year and will reopen around the end of Feb. As of today, mass production is scheduled to start on March 9. It will take the production line a little while to spin up towards our target output of 500 watches per day. Finished watches ship from the factory once a week to our distribution center (which takes ~1 week), then get packed for shipping (a few days to a week), then get delivered to you (~7-10 days). These dates and estimates are ALL subject to change - if we run into a problem, production shuts down until we fix it. Delays can and most likely will happen.</p>
<p><strong>What everyone’s been waiting for…when will your PT2 arrive 🙂</strong></p>
<p>Based on current schedule, the first mass production PT2s will arrive on wrists during the beginning of April. We should wrap up delivering all pre-ordered Pebble Time 2s two months later by the beginning of June. If your watch had an initial date of December, it should arrive in April and if your initial date was April, it should arrive in June. Unfortunately we can’t predict when your specific watch will arrive - please don’t email to ask, we’ll just send you a link to this blog post.</p>
<p>A few weeks before your watch is scheduled to ship, we’ll email link for you to confirm your address (<a href="https://orders.repebble.com/" target="_blank" rel="noopener noreferrer">change if now if you’d like</a>), pick optional accessories (extra chargers and straps) and pay any tariffs/VAT/taxes owed. For US orders, the tariff amount is $10 per watch. For other countries, VAT/taxes will be calculated and charged during order confirmation. When the watch is delivered you won’t need to pay anything else or deal with customs forms.</p>
<h3 id="index-01-production-update"><a href="#index-01-production-update"><span>#</span>Index 01 Production Update</a></h3>
<p><span><img src="https://repebble.com/assets/february-pebble-production-and-software-updates-3-cleanshot_2026-02-17_at_23.41.412x.png" alt="" loading="lazy"></span></p>
<p>Index 01 is also in the Production Verification Test (PVT) phase. We’ve manufactured several hundred so far. Waterproof testing went well (it’s rated 1m of submersion, ipx8). You’ll be able to wash your hands, wash dishes, shower, get it wet etc but you can’t swim with it on. PTV is proceeding well, but we’re not finished yet. We’re still aiming to start mass production during March, but we don’t have a firm start date yet.</p>
<p>In order news, we’re working an Index 01 ring sizer kit that will be available for $10 (hopefully including worldwide shipping, working on that now). This will let you measure your index finger and find your exact Pebble-specific ring size. We will ask everyone to measure their ring size, either by ordering an Index 01 sizer kit or 3D printing the kit, because our sizes are different than Oura or other rings.</p>
<p>We’re also considering offering size 14 and 15. It’s a big upfront expense (~$50,000) to offer these sizes due to additional tooling that will be needed, so we’re collecting interest - <a href="https://forms.gle/fgZxy7Vn7tL8bQER7" target="_blank" rel="noopener noreferrer">sign up here</a> if you would like Index 01 in these sizes!</p>
<h3 id="pebble-round-2-update"><a href="#pebble-round-2-update"><span>#</span>Pebble Round 2 Update</a></h3>
<p>Things are rolling along. We finished the Design Verification 1 (DVT1) phase just before the Lunar New Year holiday started. Work is progressing well. One of the huge speed-ups to the program overall is that the electrical design is almost identical to Pebble Time 2. This means our (two person) firmware team can code new features or bug fixes for PT2 and they work immediately on PR2! After the lunar new year, we’ll focus on waterproof testing and last minute tweaks before the current estimated production start date in late May.</p>
<h3 id="so-much-software"><a href="#so-much-software"><span>#</span>So much software!</a></h3>
<p>Our software output has been tremendous - we’re fixing bugs left, right and center and adding lots of new features to PebbleOS (<a href="https://ndocs.repebble.com/pebbleos-changelog" target="_blank" rel="noopener noreferrer">changelog</a>) and the Pebble mobile app (<a href="https://ndocs.repebble.com/changelog" target="_blank" rel="noopener noreferrer">changelog</a>).</p>
<p><span><img src="https://repebble.com/assets/february-pebble-production-and-software-updates-4-image.png" alt="" loading="lazy"></span></p>
<p>Here are some highlights:</p>
<ul>
<li>Weather now works (in sunrise/sunset timeline pins and the Weather app)</li>
<li>WhatsApp calls show up as calls (on Android)</li>
<li>Fixed a major background crash bug in Pebble iOS that caused weather and other apps to not fetch live data.</li>
<li>Added Websocket support to Pebble iOS</li>
<li>Many old Pebble apps/faces use weather APIs that no longer work (Yahoo, OpenWeather). The Pebble mobile app now catches these network requests and returns data from Open-Meteo - keeping old watchfaces working!</li>
<li>Pebble Appstore is now ‘native’ inside the Pebble mobile app (in v1.0.11.1 on <a href="https://repebble.com/app" target="_blank" rel="noopener noreferrer">beta channels</a> today). We’ve also updated the Pebble Appstore on the web at <a href="http://apps.repebble.com/" target="_blank" rel="noopener noreferrer">apps.repebble.com</a> . If you’re a developer and don’t see the latest version of your app or watchface, please make sure to <a href="http://appstore-api.repebble.com/dashboard" target="_blank" rel="noopener noreferrer">import them</a> (takes ~2 minutes).</li>
<li>Now you can <a href="https://apps.repebble.com/collections/most-loved/watchfaces/1" target="_blank" rel="noopener noreferrer">filter out older apps</a> with non-working settings pages or companion apps. Or filter specifically for apps that are open source!</li>
<li>Some PebbleKit 1.0 Android apps should work again (thanks Google for giving us back <code>com.getpebble.android.provider.basalt</code>). But devs - please upgrade your apps to PebbleKit 2.0 Android for new companion apps (<a href="https://docs.google.com/document/d/1BcX7W9HEBays5puwcRQh1GzClyHc014IRzEIuk7lLuk/edit?tab=t.0" target="_blank" rel="noopener noreferrer">more info</a> and <a href="https://github.com/pebble-dev/PebbleKitAndroid2" target="_blank" rel="noopener noreferrer">repo</a>)</li>
<li>Watch settings can now be adjusted in the Pebble mobile app. Your settings are saved and synced to all your Pebble watches.</li>
<li>Thanks to many community contributions, there are now many new app icons for notifications for apps that didn’t exist 10 years ago!</li>
<li>Most PebbleOS work has been going into factory verification sw for Obelix</li>
<li>Left handed mode - wear your Pebble on right hand with buttons flipped (thanks Claudio!)</li>
<li>Health data is now synced from watch to phone (thanks <a href="https://github.com/coredevices/mobileapp/pull/54" target="_blank" rel="noopener noreferrer">Michael</a>!)</li>
</ul>
<p>We’ve also made some great advances on the SDK and developer front…expect an update very soon 😉</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Paged Out Issue #8 [pdf] (176 pts)]]></title>
            <link>https://pagedout.institute/download/PagedOut_008.pdf</link>
            <guid>47072968</guid>
            <pubDate>Thu, 19 Feb 2026 12:13:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pagedout.institute/download/PagedOut_008.pdf">https://pagedout.institute/download/PagedOut_008.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=47072968">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[DOGE Track (280 pts)]]></title>
            <link>https://dogetrack.info/</link>
            <guid>47072967</guid>
            <pubDate>Thu, 19 Feb 2026 12:13:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dogetrack.info/">https://dogetrack.info/</a>, See on <a href="https://news.ycombinator.com/item?id=47072967">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<section>
<h2>What Is This?</h2>

<ul>
  <li><a href="https://dogetrack.info/about/this-site/">A Very Important Disclaimer</a></li>
  <li><a href="https://dogetrack.info/about/this-data/">About This Data</a></li>
  <li><a href="https://dogetrack.info/about/downloading-data/">Downloading the Data</a></li>
  <li><a href="https://dogetrack.info/about/contributing/">How to Contribute</a></li>
  <li><a href="https://dogetrack.info/about/these-symbols/">Symbols &amp; Terminology</a></li>
  <li><a href="https://dogetrack.info/about/changes/">What's Changed?</a></li>
  <li><a href="https://dogetrack.info/about/whats-next/">What's Next?</a></li>
</ul>
</section>
<section>
<h2>What Is DOGE?</h2>

<ul>
  <li><a href="https://dogetrack.info/projects/">DOGE's Projects</a></li>
  <li><a href="https://dogetrack.info/projects/anti-personnel">Attacking the Federal Workforce</a></li>
  <li><a href="https://dogetrack.info/projects/viral-waste">Fraud and Waste</a></li>
  <li><a href="https://dogetrack.info/projects/spending-control/">Seizing Control of Spending</a></li>
  <li><a href="https://dogetrack.info/projects/deregulation/">Regulatory Rollback</a></li>
  <li><a href="https://dogetrack.info/projects/it-modernization/">IT Modernization</a></li>
  <li><a href="https://dogetrack.info/projects/god-view/">"God View"</a></li>
  <li><a href="https://dogetrack.info/projects/exec-orders/">Executive Orders</a></li>
  <li><a href="https://dogetrack.info/projects/timeline/">The DOGE Timeline</a></li>
</ul>
</section>
<section>
<h2>The People in DOGE</h2>

<ul>
  <li><a href="https://dogetrack.info/people/">Who's in DOGE?</a></li>
  <li><a href="https://dogetrack.info/people/paid-staff">Who's Being Paid?</a></li>
  <li><a href="https://dogetrack.info/people/who-left">Who Has Left?</a></li>
  <li><a href="https://dogetrack.info/people/details">The Devils in the Details</a></li>
  <li><a href="https://dogetrack.info/people/wreckers">The Wreckers</a></li>
  <li><a href="https://dogetrack.info/people/aliases/">Unmasked Aliases</a></li>
  <li><a href="https://dogetrack.info/people/leaders/">Leaders and Boosters</a></li>
  <li><a href="https://dogetrack.info/people/support-team/">The Support Team</a></li>
  <li><a href="https://dogetrack.info/people/enablers/">How Enablers Support DOGE</a></li>
  <li><a href="https://dogetrack.info/people/enabler-staff/">Key Enablers</a></li>
  <li><a href="https://dogetrack.info/people/unknowns/">Unknowns</a></li>
</ul>
</section>
<section>
<h2>Prolific Wreckers</h2>

<ul>
  <li><a href="https://dogetrack.info/wreckers/akash-bobba">Akash Bobba</a></li>
  <li><a href="https://dogetrack.info/wreckers/nate-cavanaugh">Nate Cavanaugh</a></li>
  <li><a href="https://dogetrack.info/wreckers/cavanaugh-cronies">Cavanaugh's Cronies</a></li>
  <li><a href="https://dogetrack.info/wreckers/edward-coristine">Edward Coristine</a></li>
  <li><a href="https://dogetrack.info/wreckers/marko-elez/">Marko Elez</a></li>
  <li><a href="https://dogetrack.info/wreckers/luke-farritor">Luke Farritor</a></li>
  <li><a href="https://dogetrack.info/wreckers/cole-killian">Cole Killian</a></li>
  <li><a href="https://dogetrack.info/wreckers/gavin-kliger">Gavin Kliger</a></li>
  <li><a href="https://dogetrack.info/wreckers/tarak-makecha">Tarak Makecha</a></li>
  <li><a href="https://dogetrack.info/wreckers/aram-moghaddassi">Aram Moghaddassi</a></li>
  <li><a href="https://dogetrack.info/wreckers/nikhil-rajpal">Nikhil Rajpal</a></li>
  <li><a href="https://dogetrack.info/wreckers/adam-ramada">Adam Ramada</a></li>
  <li><a href="https://dogetrack.info/wreckers/payton-rehling">Payton Rehling</a></li>
  <li><a href="https://dogetrack.info/wreckers/kyle-schutt">Kyle Schutt</a></li>
  <li><a href="https://dogetrack.info/wreckers/ethan-shaotran">Ethan Shaotran</a></li>
  <li><a href="https://dogetrack.info/wreckers/jordan-wick">Jordan Wick</a></li>
  <li><a href="https://dogetrack.info/wreckers/other">Other Wreckers</a></li>
</ul>
</section>
<section>
<h2>Agencies Targeted</h2>

<ul>
  <li><a href="https://dogetrack.info/agencies/">Agency Timeline</a></li>
  <li><a href="https://dogetrack.info/agencies/opm/">Office of Personnel Management</a></li>
  <li><a href="https://dogetrack.info/agencies/gsa/">General Services Administration</a></li>
  <li><a href="https://dogetrack.info/agencies/white-house/">White House/DOGE</a></li>
  <li><a href="https://dogetrack.info/agencies/nds/">National Design Studio</a></li>
  <li><a href="https://dogetrack.info/agencies/usaid/">US Agency for International Development</a></li>
  <li><a href="https://dogetrack.info/agencies/cfpb/">Consumer Financial Protection Bureau</a></li>
  <li><a href="https://dogetrack.info/agencies/agriculture/">Department of Agriculture</a></li>
  <li><a href="https://dogetrack.info/agencies/commerce/">Department of Commerce</a></li>
  <li><a href="https://dogetrack.info/agencies/defense/">Department of Defense</a></li>
  <li><a href="https://dogetrack.info/agencies/education/">Department of Education</a></li>
  <li><a href="https://dogetrack.info/agencies/energy/">Department of Energy</a></li>
  <li><a href="https://dogetrack.info/agencies/homeland-security/">Department of Homeland Security</a></li>
  <li><a href="https://dogetrack.info/agencies/interior/">Department of the Interior</a></li>
  <li><a href="https://dogetrack.info/agencies/justice/">Department of Justice</a></li>
  <li><a href="https://dogetrack.info/agencies/labor/">Department of Labor</a></li>
  <li><a href="https://dogetrack.info/agencies/transportation/">Department of Transportation</a></li>
  <li><a href="https://dogetrack.info/agencies/epa/">Environmental Protection Agency</a></li>
  <li><a href="https://dogetrack.info/agencies/health/">Health and Human Services</a></li>
  <li><a href="https://dogetrack.info/agencies/housing/">Housing and Urban Development</a></li>
  <li><a href="https://dogetrack.info/agencies/nasa/">National Aeronautics and Space Administration</a></li>
  <li><a href="https://dogetrack.info/agencies/sba/">Small Business Association</a></li>
  <li><a href="https://dogetrack.info/agencies/social-security/">Social Security Administration</a></li>
  <li><a href="https://dogetrack.info/agencies/state/">State Department</a></li>
  <li><a href="https://dogetrack.info/agencies/treasury/">The Treasury Department</a></li>
  <li><a href="https://dogetrack.info/agencies/usps/">US Postal Service</a></li>
  <li><a href="https://dogetrack.info/agencies/veterans/">Veterans Administration</a></li>
  <li><a href="https://dogetrack.info/agencies/nlrb/">National Labor Relations Board</a></li>
  <li><a href="https://dogetrack.info/agencies/independent/">Independent Agencies</a></li>
</ul>
</section>
<section>
<h2>Everything Pages</h2>

<ul>
  <li><a href="https://dogetrack.info/all/people/">All the People</a></li>
  <li><a href="https://dogetrack.info/all/events/">All the Events</a></li>
  <li><a href="https://dogetrack.info/all/positions/">All the Staffing Moves</a></li>
  <li><a href="https://dogetrack.info/all/systems/">All the Systems</a></li>
  <li><a href="https://dogetrack.info/all/sources/">All the Source Citations</a></li>
  <li><a href="https://dogetrack.info/all/questions/">All Open Questions</a></li>
</ul>
</section>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A physically-based GPU ray tracer written in Julia (115 pts)]]></title>
            <link>https://makie.org/website/blogposts/raytracing/</link>
            <guid>47072444</guid>
            <pubDate>Thu, 19 Feb 2026 10:55:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://makie.org/website/blogposts/raytracing/">https://makie.org/website/blogposts/raytracing/</a>, See on <a href="https://news.ycombinator.com/item?id=47072444">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-jscall-id="29"><p data-jscall-id="32"><img alt="BOMEX cumulus clouds rendered with volumetric path tracing" data-jscall-id="33" src="https://makie.org/website/bonito/png/breeze7235631823897871785.png"></p><p data-jscall-id="34">We're excited to announce <a href="https://github.com/MakieOrg/Makie.jl/pull/5532" data-jscall-id="35">RayMakie</a> and <a href="https://github.com/JuliaGraphics/Hikari.jl" data-jscall-id="36">Hikari</a>, a physically-based GPU ray tracing pipeline integrated directly into <a href="https://docs.makie.org/" data-jscall-id="37">Makie</a>. Any Makie scene can now be rendered with photorealistic path tracing: just swap out the backend and get global illumination, volumetric media, spectral rendering, and physically-based materials, all running on the GPU.</p><p data-jscall-id="38">All showcase scripts and demo scenes from this post are available at <a href="https://github.com/SimonDanisch/RayDemo" data-jscall-id="39">github.com/SimonDanisch/RayDemo</a>.</p><p data-jscall-id="40"><strong data-jscall-id="41">Note:</strong> RayMakie, Hikari, and Raycore are not fully released yet — we plan to publish official releases in the coming weeks. In the meantime, the <code data-jscall-id="42">Project.toml</code> in <a href="https://github.com/SimonDanisch/RayDemo" data-jscall-id="43">RayDemo</a> will be kept up to date so you can already try things out.</p><h2 id="Why Ray Tracing in Julia?" data-jscall-id="44">Why Ray Tracing in Julia?</h2><p data-jscall-id="45">Research groups across many fields (climate science, structural biology, fluid dynamics, particle physics) produce complex 3D data that needs to be communicated clearly and compellingly. Photorealistic rendering can transform dense simulation output into images that reveal structure and tell a story. But getting research data into a traditional ray tracer usually means exporting meshes, learning new tools, and losing the interactive workflow.</p><p data-jscall-id="46">By building ray tracing directly into Makie, we eliminate that gap. The same scene you explore interactively with GLMakie can be rendered photorealistically with RayMakie, no export step, no new API to learn.</p><p data-jscall-id="47">Writing the implementation in Julia gives us:</p><ul data-jscall-id="48"><li data-jscall-id="49"><p data-jscall-id="50"><strong data-jscall-id="51">Performance</strong>: Julia compiles to efficient GPU code, competitive with C++ ray tracers</p></li><li data-jscall-id="52"><p data-jscall-id="53"><strong data-jscall-id="54">Cross-vendor GPU support</strong>: A single codebase runs on AMD, NVIDIA, and CPU via <a href="https://github.com/JuliaGPU/KernelAbstractions.jl" data-jscall-id="55">KernelAbstractions.jl</a></p></li><li data-jscall-id="56"><p data-jscall-id="57"><strong data-jscall-id="58">Makie integration</strong>: The familiar Makie API for scene construction, camera control, and lighting, with ray tracing as a drop-in rendering option</p></li><li data-jscall-id="59"><p data-jscall-id="60"><strong data-jscall-id="61">Modular architecture</strong>: Custom materials, media, and integrators run directly on the GPU through Julia's multiple dispatch, opening up novel visualization and simulation use cases</p></li><li data-jscall-id="62"><p data-jscall-id="63"><strong data-jscall-id="64">Hackability</strong>: A state-of-the-art spectral path tracer in a high-level language makes ray tracing research and experimentation accessible to a much wider audience</p></li></ul><h2 id="How It Works" data-jscall-id="65">How It Works</h2><p data-jscall-id="66">Hikari is a Julia port of <a href="https://pbrt.org/" data-jscall-id="67">pbrt-v4</a>, the reference implementation from <em data-jscall-id="68">Physically Based Rendering</em> (Pharr, Jakob, Humphreys). It implements a wavefront volumetric path tracer with spectral rendering, supporting participating media (NanoVDB, grid-based volumes), physically-based materials (metals, dielectrics, coated surfaces), and environment/sun-sky lighting. The ray intersection engine lives in <a href="https://github.com/JuliaGeometry/Raycore.jl" data-jscall-id="69">Raycore.jl</a>, a standalone package factored out of Hikari and based on AMD's <a href="https://github.com/GPUOpen-LibrariesAndSDKs/RadeonRays_SDK" data-jscall-id="70">Radeon Rays SDK</a> and <a href="https://gpuopen.com/hiprt/" data-jscall-id="71">HIPRT</a>.</p><p data-jscall-id="72">RayMakie connects Hikari to Makie's scene graph. You build a scene with standard Makie calls (<code data-jscall-id="73">mesh!</code>, <code data-jscall-id="74">surface!</code>, <code data-jscall-id="75">volume!</code>, <code data-jscall-id="76">meshscatter!</code>), set materials and lights, then render:</p><pre data-jscall-id="77"><code data-jscall-id="78">
using RayMakie, Hikari

scene = Scene(size=(1920, 1080), lights=[SunSkyLight(Vec3f(1, 2, 8))])
cam3d!(scene)
mesh!(scene, my_mesh; material=Hikari.Gold(roughness=0.1))

img = colorbuffer(scene;
    device=AMDGPU.ROCBackend(),  # or CUDABackend(), CPU()
    integrator=Hikari.VolPath(samples=100, max_depth=12),
    sensor=Hikari.FilmSensor(iso=100, white_balance=6500),
)</code></pre><h2 id="Showcases" data-jscall-id="79">Showcases</h2><h3 id="Breeze: Volumetric Cloud Rendering" data-jscall-id="80">Breeze: Volumetric Cloud Rendering</h3><p data-jscall-id="81"><a href="https://github.com/NumericalEarth/Breeze.jl/" data-jscall-id="82">Breeze.jl</a> generates cloud fields from Large Eddy Simulations powered by <a href="https://github.com/CliMA/Oceananigans.jl" data-jscall-id="83">Oceananigans.jl</a>, a GPU-accelerated ocean and atmosphere simulator developed at MIT's Climate Modeling Alliance (CliMA). The demo renders BOMEX cumulus clouds as photorealistic volumetric media, using NanoVDB sparse grids for efficient storage and Hikari's volumetric path tracing for physically-accurate light scattering through the cloud medium.</p><p data-jscall-id="84"><img alt="BOMEX cumulus clouds rendered with volumetric path tracing" data-jscall-id="85" src="https://makie.org/website/bonito/png/breeze7235631823897871785.png"></p><p data-jscall-id="86">The terrain demo combines real elevation data from ArcGIS (via <a href="https://github.com/MakieOrg/Tyler.jl" data-jscall-id="87">Tyler.jl</a>) with BOMEX cloud volumes, inspired by <a href="https://www.rayshader.com/" data-jscall-id="88">rayshader</a>.</p><p data-jscall-id="89"><img alt="Alpine terrain with volumetric clouds" data-jscall-id="90" src="https://makie.org/website/bonito/png/terrain794547408289448833.png"></p><blockquote data-jscall-id="91"><p data-jscall-id="92">Makie-Oceananigans integration has been a major initiative over the past year. The ray tracing work with Breeze is truly groundbreaking in my opinion. It may be crucial for science, for inspecting the structure of clouds and thunderstorms. It also has the potential to lead to commercial products.</p><p data-jscall-id="93"><strong data-jscall-id="94">Gregory Wagner</strong>, Research Scientist at MIT and CliMA (Climate Modeling Alliance), lead developer of Oceananigans.jl and Breeze.jl</p></blockquote><h3 id="PlantGeom: Digital Twins for Agriculture" data-jscall-id="95">PlantGeom: Digital Twins for Agriculture</h3><p data-jscall-id="96"><a href="https://github.com/VEZY/PlantGeom.jl" data-jscall-id="97">PlantGeom.jl</a> renders biophysically accurate 3D plant models for agricultural research. The ray-traced oil palm uses coated diffuse transmission materials to simulate the waxy leaf cuticle and subsurface light transport through leaf tissue.</p><p data-jscall-id="98"><img alt="Ray-traced oil palm with translucent leaves" data-jscall-id="99" src="https://makie.org/website/bonito/png/plants9877348102989772360.png"></p><blockquote data-jscall-id="100"><p data-jscall-id="101">Makie has become a central part of my daily scientific workflow. The fact that a single plotting ecosystem can cover the entire spectrum from high-performance 3D scenes to publication-ready figures is just exceptional. Several of the packages I develop would simply not exist in their current form without Makie. My research focuses on developing plant-scale digital twins to study complex agricultural systems (agroforestry, species mixtures, agrivoltaics) with the goal of understanding crop responses to climate and contributing to food security and climate-change adaptation. The recent work on ray tracing is especially exciting: beyond rendering, I am planning to use RayCore.jl for scientific applications such as computing radiation interception in plant canopies, which enables organ-scale energy balance calculations (latent and sensible heat fluxes) and photosynthesis modeling. Understanding how plant shadows affect heat transfer is crucial for adapting agriculture to extreme heat events. Makie has been a genuine force multiplier for my research.</p><p data-jscall-id="102"><strong data-jscall-id="103">Remi Vezy</strong>, CIRAD, developer of PlantGeom.jl</p></blockquote><h3 id="ProtPlot: Protein Structure Visualization" data-jscall-id="104">ProtPlot: Protein Structure Visualization</h3><p data-jscall-id="105"><a href="https://github.com/MurrellGroup/ProtPlot.jl" data-jscall-id="106">ProtPlot.jl</a> renders protein ribbon diagrams with physically-based materials. Different materials reveal different aspects of the structure: glass refractions show the interior ribbon path, while a coated diffuse surface with shallow depth of field draws attention to specific regions of the fold. Specular highlights, ambient occlusion, and defocus blur make spatial relationships immediately clear in a way that flat shading cannot.</p><table data-jscall-id="107"><tbody><tr data-jscall-id="108"><th data-jscall-id="109">Glass</th><th data-jscall-id="110">Physical based Gold with Depth of Field</th></tr><tr data-jscall-id="111"><td data-jscall-id="112"><img alt="Protein ribbon with glass material" data-jscall-id="113" src="https://makie.org/website/bonito/png/protplot_glass2422419635124639137.png"></td><td data-jscall-id="114"><img alt="Protein ribbon with a gold material and depth of field" data-jscall-id="115" src="https://makie.org/website/bonito/png/protplot_7pkz4446811177816820644.png"></td></tr></tbody></table><p data-jscall-id="116">ProtPlot also powers animated visualizations of protein folding trajectories, the transport process that generative models learn to perform. Ray tracing makes the spatial relationships in these animations immediately legible. The code to produce this is almost entirely standard Makie and ProtPlot, only the imports and a few rendering parameters change:</p><pre data-jscall-id="117"><code data-jscall-id="118">
using RayMakie, ProtPlot, Hikari, AMDGPU

device = AMDGPU.ROCBackend()

tracks = readdir("Trajectories/samp_00015", join=true)
set_theme!(lights=[
    Makie.SunSkyLight(Vec3f(0.4, -0.3, 0.7);
        intensity=1.0f0, turbidity=3.0f0, ground_enabled=false),
])
ProtPlot.animate_molecule_dir("trajectory.mp4", tracks)</code></pre><p data-jscall-id="119">The <code data-jscall-id="120">animate_molecule_dir</code> function is pure ProtPlot code, building Makie figures with <code data-jscall-id="121">Axis3</code>, <code data-jscall-id="122">atomplot!</code>, and <code data-jscall-id="123">ribbon!</code> as usual. Then when using the RayMakie backend, Makie will use it to render the video without requiring any additional changes.</p><blockquote data-jscall-id="127"><p data-jscall-id="128">My lab is working on new kinds of generative models, primarily for protein structures. These work by specifying a process that transports randomly sampled noise to a biophysically plausible protein structure, and training a deep neural network to learn how to do this. But the details of this transport process are critical and, while you can to some extent mathematically reason about it, there is no substitute to being able to actually see it in action, both when you're designing it and when investigating how well the model has actually learned it. We work with visualization tools, like ProtPlot.jl, primarily developed by Anton Oresten in my lab, which rely entirely on Makie for this. These visualizations are not just for our internal use, but can be valuable for communicating how the methods work. Developments like raytracing will allow us to configure these to show exactly the details we seek to communicate without them getting buried in the complexity.</p><p data-jscall-id="129"><strong data-jscall-id="130">Ben Murrell</strong>, Karolinska Institutet</p></blockquote><h3 id="TrixiParticles: Fluid Simulation" data-jscall-id="131">TrixiParticles: Fluid Simulation</h3><p data-jscall-id="132"><a href="https://github.com/trixi-framework/TrixiParticles.jl" data-jscall-id="133">TrixiParticles.jl</a> simulates fluid dynamics with smoothed particle hydrodynamics. The water splash demo renders SPH surface meshes with a dielectric material (IOR 1.33) simulating water. Fresnel reflections and refractions create the characteristic look of water without any post-processing. The animation shows a gold ball dropping into water, with each frame independently path-traced:</p><blockquote data-jscall-id="137"><p data-jscall-id="138">Native raytracing in Makie would let us move some of our workflows entirely into Julia, from simulation to publication-ready figures, without relying on external tools.</p><p data-jscall-id="139"><strong data-jscall-id="140">Dr. Michael Schlottke-Lakemper</strong>, University of Stuttgart, lead developer of TrixiParticles.jl</p></blockquote><h3 id="Volumetric Rendering: Clouds, Smoke, and Exhaust Plumes" data-jscall-id="141">Volumetric Rendering: Clouds, Smoke, and Exhaust Plumes</h3><p data-jscall-id="142">Participating media are first-class citizens in Hikari's path tracer. Light scatters through volumes realistically, no billboard tricks or screen-space approximations. Hikari supports two volume representations: <strong data-jscall-id="143">NanoVDB</strong> sparse grids for large-scale data (like the cloud simulations above), and <strong data-jscall-id="144">RGBGridMedium</strong> for dense grids with per-voxel color, emission, and scattering properties. Both integrate directly with Makie's <code data-jscall-id="145">volume!</code> plot or can be attached to any mesh as a <code data-jscall-id="146">MediumInterface</code>.</p><p data-jscall-id="147">The <strong data-jscall-id="148">Stanford bunny cloud</strong> from the <a href="https://github.com/mmp/pbrt-v4-scenes" data-jscall-id="149">pbrt-v4 test scenes</a>, rendered with NanoVDB and Henyey-Greenstein phase function scattering:</p><p data-jscall-id="150"><img alt="Stanford bunny cloud" data-jscall-id="151" src="https://makie.org/website/bonito/png/bunny3536803747307745313.png"></p><p data-jscall-id="152">A <strong data-jscall-id="153">sphere wake</strong> from <a href="https://github.com/WaterLily-jl/WaterLily.jl" data-jscall-id="154">WaterLily.jl</a> LES simulation, visualized as volumetric smoke. The volume density is updated in-place each frame via <code data-jscall-id="155">RGBGridMedium</code> with a colormap, so the scene never needs to be rebuilt:</p><p data-jscall-id="159">The <strong data-jscall-id="160">HL-20 spacecraft</strong> (model provided by <a href="https://juliahub.com/" data-jscall-id="161">JuliaHub</a>) with a procedurally generated emissive rocket exhaust plume. <code data-jscall-id="162">RGBGridMedium</code> with per-voxel emission creates the blue-white core fading to orange at the edges:</p><p data-jscall-id="163"><img alt="HL-20 spacecraft with volumetric exhaust" data-jscall-id="164" src="https://makie.org/website/bonito/png/spacecraft12604446927484047855.png"></p><h3 id="GLTF Models: Emissive Textures and Scene Composition" data-jscall-id="165">GLTF Models: Emissive Textures and Scene Composition</h3><p data-jscall-id="166">RayMakie loads GLTF/GLB models and automatically maps their PBR materials to Hikari equivalents. Emissive texture maps create area lights that both glow and illuminate the scene. The Christmas tree decorations below are lit entirely by their own emissive maps; the quadcopter model was provided by <a href="https://juliahub.com/" data-jscall-id="167">JuliaHub</a>:</p><p data-jscall-id="168"><img alt="Christmas tree with glowing decorations and drone" data-jscall-id="169" src="https://makie.org/website/bonito/png/drone_christmas13347553003851564844.png"></p><h3 id="Geant4: Particle Detector Visualization" data-jscall-id="170">Geant4: Particle Detector Visualization</h3><p data-jscall-id="171"><a href="https://github.com/JuliaHEP/Geant4.jl" data-jscall-id="172">Geant4.jl</a> provides Julia bindings to the CERN Geant4 particle physics simulation toolkit. The CMS (Compact Muon Solenoid) detector at CERN is one of the largest and most complex scientific instruments ever built. RayMakie can load the full detector geometry from GDML files, apply a quadrant cut to reveal internal structure, and render the result with physically-based metal materials (gold, copper, silver, aluminum, iron).</p><table data-jscall-id="173"><tbody><tr data-jscall-id="174"><th data-jscall-id="175"></th><th data-jscall-id="176"></th></tr><tr data-jscall-id="177"><td data-jscall-id="178"><img alt="CMS detector close-up" data-jscall-id="179" src="https://makie.org/website/bonito/png/cms_detector24219475611935801176.png"></td><td data-jscall-id="180"><img alt="CMS detector full view" data-jscall-id="181" src="https://makie.org/website/bonito/png/cms_detector5584426331694323319.png"></td></tr></tbody></table><p data-jscall-id="182">The detector meshes are generated from Geant4's tessellated polyhedra with crease-angle vertex splitting for smooth normals on curved barrel surfaces while preserving hard edges at structural boundaries.</p><h3 id="Black Hole: Custom GPU Materials" data-jscall-id="183">Black Hole: Custom GPU Materials</h3><p data-jscall-id="184">One of the most powerful aspects of building a ray tracer in Julia is that users can define entirely new physics by subtyping <code data-jscall-id="185">Hikari.Medium</code>. The black hole demo demonstrates this: a custom <code data-jscall-id="186">SpacetimeMedium</code> struct implements gravitational lensing by overriding <code data-jscall-id="187">Hikari.apply_deflection</code> to bend light rays according to the Schwarzschild metric. The accretion disk is an emissive volumetric density field with temperature-dependent coloring, hotter near the event horizon, cooler at the outer edge.</p><p data-jscall-id="188">Because Julia's multiple dispatch compiles these custom methods directly into the GPU kernels alongside the built-in materials, there is no performance penalty for user-defined physics. The same wavefront path tracer handles standard glass and metals alongside relativistic spacetime curvature.</p><p data-jscall-id="189"><img alt="Black hole with accretion disk and gravitational lensing" data-jscall-id="190" src="https://makie.org/website/bonito/png/blackhole2083336987488631976.png"></p><p data-jscall-id="191">The black hole can also be explored interactively. RayMakie's interactive mode progressively refines the path-traced image while you move the camera in real time:</p><p data-jscall-id="195">An overlay renderer composites rasterized elements (lines, text, wireframes) on top of the ray-traced image, so Makie's standard 2D overlays like legends, colorbars, and annotations work alongside path tracing. The interactive window can also target individual subscenes and axes, so you can place a ray-traced view next to other plots in a GLMakie figure. Looking ahead, this overlay renderer has the potential to grow into a full pure-Julia GPU-accelerated rasterizer, which could eventually replace OpenGL as Makie's primary rendering backend.</p><h2 id="Getting Started" data-jscall-id="196">Getting Started</h2><p data-jscall-id="197">RayMakie is available as a Makie backend. To render any existing Makie scene with ray tracing:</p><pre data-jscall-id="198"><code data-jscall-id="199">
using RayMakie, Hikari

# Build your scene with standard Makie
scene = Scene(size=(800, 600), lights=[SunSkyLight(Vec3f(1, 2, 8))])
cam3d!(scene)
mesh!(scene, my_geometry; material=Hikari.Gold())

# Render with path tracing
img = colorbuffer(scene;
    device=AMDGPU.ROCBackend(),
    integrator=Hikari.VolPath(samples=100, max_depth=12),
)</code></pre><p data-jscall-id="200">For interactive exploration, use <code data-jscall-id="201">RayMakie.interactive_window</code> to progressively refine the image while adjusting the camera in real time.</p><h2 id="Future Work" data-jscall-id="202">Future Work</h2><ul data-jscall-id="203"><li data-jscall-id="204"><p data-jscall-id="205"><strong data-jscall-id="206">Memory optimizations</strong>: GPU memory is currently allocated eagerly and not released early, making it easy to run out of VRAM on complex scenes. We plan to implement early release of intermediate GPU buffers and more careful memory management. We also can still improve packing and our struct sizes and test that we dont do unecessary allocations.</p></li><li data-jscall-id="207"><p data-jscall-id="208"><strong data-jscall-id="209">Performance optimizations</strong>: While rendering is already fast, there is significant room for optimization in BVH construction, batching ray intersections, kernel occupancy, and data layout.</p></li><li data-jscall-id="210"><p data-jscall-id="211"><strong data-jscall-id="212">Code quality and Makie integration</strong>: The current implementation is a solid prototype, but needs cleanup and full integration of experimental features. Some internal code paths and the Makie backend interface need improvement.</p></li><li data-jscall-id="213"><p data-jscall-id="214"><strong data-jscall-id="215">SPPM for caustics</strong>: Stochastic Progressive Photon Mapping was removed and deprioritized, but we would like to bring caustic rendering back in the future.</p></li><li data-jscall-id="216"><p data-jscall-id="217"><strong data-jscall-id="218">GPU backend testing</strong>: Currently only AMD GPUs (via AMDGPU.jl) are fully tested and guaranteed to work well. NVIDIA support via CUDA.jl should work but needs more testing. The CPU backend still has allocation issues that are likely a Julia-level bug requiring further investigation.</p></li><li data-jscall-id="219"><p data-jscall-id="220"><strong data-jscall-id="221">Makie tests</strong> We still need to port the whole Makie test suite with reference tests, right now tests are minimal and no visual regression tests.</p></li></ul><h2 id="Acknowledgments" data-jscall-id="222">Acknowledgments</h2><p data-jscall-id="223">Hikari is a Julia port of <a href="https://pbrt.org/" data-jscall-id="224">pbrt-v4</a> by Matt Pharr, Wenzel Jakob, and Greg Humphreys. It builds on <a href="https://github.com/JuliaGraphics/Trace.jl" data-jscall-id="225">Trace.jl</a>, originally created by <a href="https://github.com/pxl-th" data-jscall-id="226">Anton Smirnov</a>, and on the <a href="https://github.com/JuliaGeometry/Raycore.jl" data-jscall-id="227">Raycore.jl</a> intersection engine. GPU support is powered by <a href="https://github.com/JuliaGPU/KernelAbstractions.jl" data-jscall-id="228">KernelAbstractions.jl</a> and the Julia GPU ecosystem. The quadcopter and HL-20 spacecraft GLTF models were provided by <a href="https://juliahub.com/" data-jscall-id="229">JuliaHub</a>.</p><p data-jscall-id="230">This work was made possible by an investment of the <a href="https://www.sovereign.tech/" data-jscall-id="231">Sovereign Tech Agency</a>.</p><p data-jscall-id="232">Some of the optimization and GPU work on Raycore has been funded by <a href="https://www.muonspace.com/" data-jscall-id="233">Muon Space</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mark Zuckerberg to testify in landmark social media trial (113 pts)]]></title>
            <link>https://www.ft.com/content/0c6d8ff6-f207-431b-bfb9-1d8b42bb4b6d</link>
            <guid>47070743</guid>
            <pubDate>Thu, 19 Feb 2026 06:54:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/0c6d8ff6-f207-431b-bfb9-1d8b42bb4b6d">https://www.ft.com/content/0c6d8ff6-f207-431b-bfb9-1d8b42bb4b6d</a>, See on <a href="https://news.ycombinator.com/item?id=47070743">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main id="site-content" data-ft-origin="next-barrier-page"><div id="barrier-page"><div id="heroOffer-Hero offers-d2ca0378-6db0-4a8a-9b65-74d8603ad8ab" data-component="heroOffer" data-component-unique-name="Hero offers" data-o3-theme="inverse"><div data-o-grid-colspan="12 L6"><p><span></span><span></span><span></span><span>Subscribe to unlock this article</span><span></span></p></div><div data-o-grid-colspan="12 L6"><div><h2><span><span>Save 40% on Standard Digital</span></span></h2><p><span><span><span>was </span><span>Dkr4188</span><span> </span><span>now </span><span>Dkr2499</span><span> for your first year</span></span></span></p></div><p><span><span>Save now on essential digital access to trusted FT journalism on any device. Savings based on monthly annualised price - offer ends 25th February</span></span></p></div></div><div id="recommendedOffers-Recommended Offers" data-component="recommendedOffers" data-component-unique-name="Recommended Offers"><p><h2 data-o-grid-colspan="12">Explore more offers.</h2></p><div data-o-grid-colspan="12"><div data-o-grid-colspan="12"><div><p><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fbarrier-page-components.s3.eu-west-1.amazonaws.com%2Fassets%2Ficons%2Fprimary_product_icon_trial.svg?format=svg&amp;source=next-barrier-page" alt=""></p><p><h3>Trial</h3></p></div><p><span><span>Dkr10</span><span> for 4 weeks</span></span></p><p><span><span>Then </span><span>Dkr535</span><span> per month. Complete digital access with exclusive insights and industry deep dives on any device. Cancel anytime during your trial.</span></span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fbarrier-page-components.s3.eu-west-1.amazonaws.com%2Fassets%2Ficons%2Fprimary_product_icon_premium.svg?format=svg&amp;source=next-barrier-page" alt=""></p><p><h3>Premium Digital</h3></p></div><p><span><span>Dkr535</span><span> per month</span></span></p><p><span><span>Complete digital access with exclusive insights and industry deep dives on any device.</span></span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://images.ft.com/v3/image/raw/https%3A%2F%2Fbarrier-page-components.s3.eu-west-1.amazonaws.com%2Fassets%2Ficons%2Fprimary_product_icon_print.svg?format=svg&amp;source=next-barrier-page" alt=""></p><p><h3>Print</h3></p></div><p><span><span>was </span><span>Dkr6799</span><span> </span><span>now </span><span>Dkr1459</span><span> for your first year</span></span></p><p><span><span>Delivery Monday - Saturday, including FT Weekend and FT Digital Edition: all the content of the FT newspaper on any device. Savings based on annual price.</span></span></p></div></div></div><div data-component="subscriptionOptions" data-component-unique-name="Subscription Options Offers API" data-o3-theme="inverse"><h2>Explore our full range of subscriptions.</h2><div><div><div><h3>For individuals</h3></div><p>Discover all the plans currently available in your country</p></div><div><div><h3> For multiple readers</h3></div><p>Digital access for organisations. Includes exclusive features and content.</p></div></div></div><div data-component="whyFT" data-component-unique-name="Why FT" data-o3-theme="inverse"><div><h2>Why the FT?</h2><p>See why over a million readers pay to read the Financial Times.</p></div><p><a href="https://subs.ft.com/whytheft?ft-content-uuid=0c6d8ff6-f207-431b-bfb9-1d8b42bb4b6d" aria-label="Find out why the FT">Find out why</a></p></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[European Tech Alternatives (237 pts)]]></title>
            <link>https://eutechmap.com/map</link>
            <guid>47070142</guid>
            <pubDate>Thu, 19 Feb 2026 05:07:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eutechmap.com/map">https://eutechmap.com/map</a>, See on <a href="https://news.ycombinator.com/item?id=47070142">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Electrobun v1: Build fast, tiny, and cross-platform desktop apps with TypeScript (142 pts)]]></title>
            <link>https://blackboard.sh/blog/electrobun-v1/</link>
            <guid>47069650</guid>
            <pubDate>Thu, 19 Feb 2026 03:46:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blackboard.sh/blog/electrobun-v1/">https://blackboard.sh/blog/electrobun-v1/</a>, See on <a href="https://news.ycombinator.com/item?id=47069650">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p><strong>Build ultra fast, tiny, and cross-platform desktop apps with TypeScript.</strong></p> <p>Two years ago I paused <a href="https://blackboard.sh/colab/">co(lab)</a> to build the desktop app framework I wished existed. Now that I've shipped a stable v1, this post is me reflecting on this two-year sidequest that had me learning Zig, C, C++, and Objective-C.</p> <h2>Why I Built This</h2> <p>My intro to programming was Visual Basic 6 in the early 2000s, building desktop apps. Then Adobe AIR changed my life—I built a few startups and shipped desktop apps to thousands of people. That was the golden age for me. Fast forward 20+ years of zero-to-one work at startups, building and scaling key systems as early eng at unicorns shipping to 10s of millions, and starting my own startup lab; somehow desktop development had gotten worse. I was building co(lab), a hybrid web browser + code editor + PTY terminal, and I just ran into one papercut too many.</p> <p>The first version was built in Electron. The DX was rough—figuring out code signing, notarization, distribution, and updates felt like fighting the framework instead of building my app. I wanted to ship like the web, continuously, but every piece of the toolchain made that harder than it needed to be.</p> <p>I tried Tauri but Rust is not for everyone. Bun was up and coming, still months away from 1.0. So I got to work.</p> <h2>From macOS to Everywhere</h2> <p>When Electrobun started, it only built macOS apps. Today it has first-class support for building on and distributing to <strong>macOS, Windows, and Ubuntu</strong>. Installers, auto-update artifacts, differential patches—all generated automatically. Bring your own static host (R2, S3, GitHub Releases) and you're done. The differential updates are powered by <a href="https://blackboard.sh/blog/introducing-zig-bsdiff">zig-bsdiff</a>, which I ported from C to Zig and optimized with SIMD and zstd.</p> <p>As Bun's FFI stabilized, I replaced most of the Zig FFI layer I'd written and leaned on Bun directly. The architecture inverted in a good way—Bun uses shared memory when spinning up workers, so Electrobun stays efficient even with multiple processes.</p> <h2>What Shipped</h2> <p>Electrobun today is a complete framework: cross-platform window controls, menus, accelerators, global shortcuts, clipboard, dialogs, webview partitions, session storage, find-in-page, and solid tooling around bundling and updates.</p> <p>The OOPIF story is real now. Electron's <code>&lt;webview&gt;</code> tag was deprecated from Chromium and they still haven't fixed it. <a href="https://blackboard.sh/blog/building-a-better-oopif">Building a Better OOPIF</a> goes deep on how <code>&lt;electrobun-webview&gt;</code> evolved into a true "super iframe"—DOM positioning, process isolation, layering that actually works, and no cursor flicker nightmares. It works across platforms without patching browser engines.</p> <h2>What's Next</h2> <p>co(lab) is fully rewritten on Electrobun and I'm doubling down on it now that v1 is real. The framework is stable enough to build ambitious, long-lived products without worrying about platform churn. That was always the goal.</p> <p>The community is growing. People in our Discord are building insanely cool apps. If you've tested betas, filed issues, or sent feedback—thank you. Electrobun is the first major thing I'm shipping from <a href="https://blackboard.sh/">Blackboard</a>, and you helped shape it.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anthropic officially bans using subscription auth for third party use (572 pts)]]></title>
            <link>https://code.claude.com/docs/en/legal-and-compliance</link>
            <guid>47069299</guid>
            <pubDate>Thu, 19 Feb 2026 02:52:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://code.claude.com/docs/en/legal-and-compliance">https://code.claude.com/docs/en/legal-and-compliance</a>, See on <a href="https://news.ycombinator.com/item?id=47069299">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Step 3.5 Flash – Open-source foundation model, supports deep reasoning at speed (181 pts)]]></title>
            <link>https://static.stepfun.com/blog/step-3.5-flash/</link>
            <guid>47069179</guid>
            <pubDate>Thu, 19 Feb 2026 02:32:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://static.stepfun.com/blog/step-3.5-flash/">https://static.stepfun.com/blog/step-3.5-flash/</a>, See on <a href="https://news.ycombinator.com/item?id=47069179">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <div id="hero">
                
                
                
                <div id="teaserChartArea">
                            
                            <div id="teaserPlotArea">
<div>
    <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/logos/stepfun-color-logo.svg" alt="Step 3.5 Flash" onerror="this.style.display='none';this.parentElement.innerHTML+='<span class=\'teaser-point-initial\'>S</span>';">
    </p>
    <p>81.0</p>
    
</div>
<div>
    <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/logos/glm-logo.svg" alt="GLM-4.7" onerror="this.style.display='none';this.parentElement.innerHTML+='<span class=\'teaser-point-initial\'>G</span>';">
    </p>
    <p>78.5</p>
    
</div>
<div>
    <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/logos/deepseek-color-logo.svg" alt="DeepSeek V3.2" onerror="this.style.display='none';this.parentElement.innerHTML+='<span class=\'teaser-point-initial\'>D</span>';">
    </p>
    <p>77.3</p>
    
</div>
<div>
    <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/logos/k-only-light.svg" alt="Kimi K2.5" onerror="this.style.display='none';this.parentElement.innerHTML+='<span class=\'teaser-point-initial\'>K</span>';">
    </p>
    <p>80.5</p>
    
</div>
<div>
    <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/logos/gemini-color-logo.svg" alt="Gemini 3.0 Pro" onerror="this.style.display='none';this.parentElement.innerHTML+='<span class=\'teaser-point-initial\'>G</span>';">
    </p>
    <p>80.7</p>
    
</div>
<div>
    <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/logos/claude-color-logo.svg" alt="Claude Opus 4.5" onerror="this.style.display='none';this.parentElement.innerHTML+='<span class=\'teaser-point-initial\'>C</span>';">
    </p>
    <p>80.6</p>
    
</div>
<div>
    <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/logos/openai-logo.svg" alt="GPT-5.2 xhigh" onerror="this.style.display='none';this.parentElement.innerHTML+='<span class=\'teaser-point-initial\'>G</span>';">
    </p>
    <p>82.2</p>
    
</div>
</div>
                            <div>
                                <div id="teaserXTicks"><p>200</p><p>400</p><p>600</p><p>800</p><p>1000</p><p>Likely &gt;1000</p></div>
                                <p>Total Model Parameters (B)</p>
                            </div>
                        </div>
                <p>Scores represent the mean of the following eight benchmarks listed below, excluding xbench-DeepSearch. The Step 3.5 Flash score is derived under standard settings (i.e., $w/o$ Parallel Thinking).</p>
                <div>
                    <p data-content="hero.abstract"><strong>Step 3.5 Flash</strong> is our most capable open-source foundation model, engineered to deliver frontier reasoning and agentic capabilities with exceptional efficiency. Built on a sparse Mixture of Experts (MoE) architecture, it selectively activates only <strong>11B of its 196B parameters</strong> per token. This "intelligence density" allows it to rival the reasoning depth of top-tier proprietary models, while maintaining the agility required for real-time interaction.</p>
                    <div>
                        <ul data-content="hero.highlights">
                            <li>
                                <strong>Deep Reasoning at Speed:</strong>
                                <span>While chatbots are built for reading, agents must reason fast. Powered by 3-way Multi-Token Prediction (MTP-3), Step 3.5 Flash achieves a generation throughput of 100–300 tok/s in typical usage (peaking at 350 tok/s for single-stream coding tasks). This allows for complex, multi-step reasoning chains with immediate responsiveness.</span>
                            </li>
                            <li>
                                <strong>A Robust Engine for Coding &amp; Agents:</strong>
                                <span>Step 3.5 Flash is purpose-built for agentic tasks, integrating a scalable RL framework that drives consistent self-improvement. It achieves 74.4% on SWE-bench Verified and 51.0% on Terminal-Bench 2.0, proving its ability to handle sophisticated, long-horizon tasks with unwavering stability.</span>
                            </li>
                            <li>
                                <strong>Efficient Long Context:</strong>
                                <span>The model supports a cost-efficient 256K context window by employing a 3:1 Sliding Window Attention (SWA) ratio—integrating three SWA layers for every one full-attention layer. This hybrid approach ensures consistent performance across massive datasets or long codebases while significantly reducing the computational overhead typical of standard long-context models.</span>
                            </li>
                            <li>
                                <strong>Accessible Local Deployment:</strong>
                                <span>Optimized for accessibility, Step 3.5 Flash brings elite-level intelligence to local environments. It runs securely on high-end consumer hardware (e.g., Mac Studio M4 Max, NVIDIA DGX Spark), ensuring data privacy without sacrificing performance.</span>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>

        <div id="benchmark">
                <div>

                    
                    <div id="mathCategory">
                        <h4>Reasoning</h4>
                        
                    </div>

                    
                    <div id="codingCategory">
                        <h4>Coding</h4>
                        
                    </div>

                    
                    <div id="agentCategory">
                        <h4>Agent</h4>
                        <div data-benchmark="browsecompZHContext">
            <div>
                        <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/logos/stepfun-dark-logo.png" alt="Step 3.5 Flash" onerror="this.style.display='none';this.parentElement.innerHTML+='<span class=\'bar-initial\'>S</span>';"></p><p>56.3</p>
                        
                    </div>
            <div>
                        <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/logos/stepfun-dark-logo.png" alt="StepFun Research" onerror="this.style.display='none';this.parentElement.innerHTML+='<span class=\'bar-initial\'>S</span>';"></p><p>35.0</p>
                        
                    </div>
            <div>
                        <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/logos/k-only-light.svg" alt="Kimi K2.5 (Thinking)" onerror="this.style.display='none';this.parentElement.innerHTML+='<span class=\'bar-initial\'>K</span>';"></p><p>40.0</p>
                        
                    </div>
            <div>
                        <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/logos/manus.svg" alt="Manus Agent (Quality Mode)" onerror="this.style.display='none';this.parentElement.innerHTML+='<span class=\'bar-initial\'>M</span>';"></p><p>40.0</p>
                        
                    </div>
            <div>
                        <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/logos/grok-logo.svg" alt="SuperGrok Expert" onerror="this.style.display='none';this.parentElement.innerHTML+='<span class=\'bar-initial\'>G</span>';"></p><p>40.0</p>
                        
                    </div>
            <div>
                        <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/logos/openai-logo.svg" alt="ChatGPT-5-Pro" onerror="this.style.display='none';this.parentElement.innerHTML+='<span class=\'bar-initial\'>G</span>';"></p><p>75.0</p>
                        
                    </div></div>
                    </div>

                </div>

                <p>Performance of Step 3.5 Flash measured across <strong>Reasoning, Coding, and Agentic Tasks</strong>. Open-source models (left) are sorted by their total parameter count, while top-tier proprietary models are shown on the right. xbench-DeepSearch scores are sourced from <a href="https://xbench.org/agi/aisearch" target="_blank" rel="noopener">official publications</a> for consistency. The shadowed bars represent the enhanced performance of Step 3.5 Flash using <a href="https://arxiv.org/pdf/2601.05593" target="_blank" rel="noopener">Parallel Thinking</a>.</p>

            </div>

        <div id="showcase">
                <h2>Step 3.5 Flash: Intelligence in Practice</h2>
                <p>True intelligence density is not just about peak performance on conventional benchmarks, but about robustness in dynamic, real-world scenarios. While we value strong results on standard metrics as a foundation, our primary goal is to validate that the model functions as a resilient and effective partner when facing the unpredictability of actual execution.</p>
                <p>In the following part, we consolidate a range of performance feedback from real-world showcases, rigorous internal benchmarks, and supplemental public leaderboards. Covering everything from advanced reasoning in math and coding to everyday interaction capabilities, these results demonstrate that Step 3.5 Flash is not just fast enough to think—it is <strong>Reliable Enough to Act</strong>.</p>

                
                

                
                <div id="showcase-agentic-coding">
                    

                    <div>
                        <div>
                            <video controls="" preload="metadata">
                                <source src="https://static.stepfun.com/blog/step-3.5-flash/raw_case/coding_case/Earth.mp4" type="video/mp4">
                            </video>
                            <p>Tactical Weather Intelligence Dashboard — A flight-cockpit inspired 3D globe visualizer engineered for high-density data environments. Featuring a custom WebGL 2.0 engine, it manages 15,000+ active nodes with real-time WebSocket telemetry. This case demonstrates our model's ability to build low-latency data pipelines and high-performance geospatial visualizations with a focus on system stability and professional-grade UI/UX.</p>
                            
                        </div>

                        <div>
                            <video controls="" preload="metadata">
                                <source src="https://static.stepfun.com/blog/step-3.5-flash/raw_case/coding_case/Ocean_v2_4k.mp4" type="video/mp4">
                            </video>
                            <p>Three.js Procedural Ocean Engine — A high-performance rendering system featuring fractal-based wave geometry and ray-traced surfaces. It leverages Fresnel reflectance and PBR materials for photorealistic lighting. This showcase highlights our model's expertise in Computer Graphics (CG), complex rendering pipeline design, and seamless integration of Three.js/GLSL/Shadertoy workflows.</p>
                            
                        </div>

                        <div>
                            <video controls="" preload="metadata">
                                <source src="https://static.stepfun.com/blog/step-3.5-flash/raw_case/coding_case/Agentic_Coding_with_text.mp4" type="video/mp4">
                            </video>
                            <p>Agentic Workflow Take In — A case demonstrates how Step assists in executing daily data processes, achieving end-to-end data production. It aligns upstream data formats, accurately calls data generation models, verifies and transforms the results, and generates workflow reports, embodying the core concept of Agent-in-the-loop. Step can effectively take over our daily workflows, undertaking complex and repetitive processes.</p>
                            
                        </div>

                        <div>
                            <video controls="" preload="metadata">
                                <source src="https://static.stepfun.com/blog/step-3.5-flash/raw_case/coding_case/SolarDisplay.mp4" type="video/mp4">
                            </video>
                            <p>Epic Solar System Simulation — A 3D interactive model of the solar system with cinematic lighting and atmosphere, presenting a shocking visual narrative from nothingness to a complete galaxy through an epic opening performance of dynamically generated and orbiting planets one by one. This demonstrates Step comprehensive creative ability in 3D scene orchestration, lighting and atmosphere creation, and control of interactive narrative rhythm.</p>
                            
                        </div>

                        <div>
                            <video controls="" preload="metadata">
                                <source src="https://static.stepfun.com/blog/step-3.5-flash/raw_case/coding_case/DataAnaly_en_4k_v2.mp4" type="video/mp4">
                            </video>
                            <p>Autonomous Business Intelligence Engine — End-to-end data processing—from CSV ingestion to Cubic Spline interpolation and multi-scenario forecasting. Demonstrates high-order reasoning in multi-step tool use, automated error correction during code execution, and complex data visualization. Successfully modeled a 60% DNU drop scenario, identifying a 1.6x quality gap between acquisition channels. It reflects the model's agentic strength in systematic problem solving and its ability to act as a self-directed Data Scientist.</p>
                            
                        </div>

                        <div>
                            <video controls="" preload="metadata">
                                <source src="https://static.stepfun.com/blog/step-3.5-flash/raw_case/coding_case/Deepresearch_explore.mp4" type="video/mp4">
                            </video>
                            <p>Autonomous Large-Scale Repository Architect — A specialized agentic workflow for navigating and deciphering high-complexity codebases. Beyond simple file scanning, the model performs deep-trace logic mapping and cross-module dependency analysis to synthesize the "mental model" of an entire ecosystem. This showcase demonstrates the model's superior cognitive capacity for large-scale software architecture, enabling it to autonomously generate professional Wikis that connect high-level design patterns to low-level implementation details across thousands of lines of code.</p>
                            
                        </div>
                    </div>

                    
                    <div>
                        <p><strong>Beyond Vibe Coding - Driving Professional Data Agent in Claude Code.</strong> Within advanced agent frameworks like Claude Code, LLMs have evolved beyond "vibe coding" to becoming active problem-solvers capable of driving complex workflows to accomplish sophisticated objectives. To evaluate this in a real-world context, we task Step 3.5 Flash to act as a professional data analyst within the Claude Code environment.</p>
                        <p>We curate a benchmark of 50 end-to-end tasks that reflect the intricate nature of Internet backend data analysis. As shown in the table below, Step 3.5 Flash demonstrates exceptional proficiency in managing these multi-stage processes—independently handling data ingestion, cleaning, feature construction, and results interpretation. With a score of 39.58%, it proves to be a robust engine for sophisticated agentic systems, outperforming several frontier models in analytical accuracy.</p>

                        <div>
                            <div>
                                <h3>Professional Data Analysis Benchmark</h3>
                                
                            </div>
                            <p>We notice that frontier models like Gemini 3.0 Pro didn't perform as expected in this specific test. This could be due to framework compatibility issues within Claude Code, or simply a difference in analytical capability. Either way, the takeaway here is how well Step 3.5 Flash syncs with the Claude Code, enabling it to handle professional data tasks with solid reliability.</p>
                        </div>
                    </div>
                </div>

                
                <div id="showcase-deep-research">
                    
                    <p>While Step 3.5 Flash is compact, its utility is no longer limited by its internal parametric knowledge. In the agentic era, the ability to leverage the internet as a dynamic knowledge base is more critical than static memory—a strength proven by Step 3.5 Flash's performance on benchmarks like xbench-DeepSearch and BrowserComp.</p>
                    <p>Deep Research extends basic information retrieval by delegating the entire research workflow to an agentic loop of planning, searching, reflecting, and writing. To evaluate Step 3.5 Flash on this complex process, we use the Scale AI <a href="https://scale.com/research/researchrubrics" target="_blank" rel="noopener">Research Rubrics</a>, a benchmark designed to assess the factual grounding and reasoning depth of long-form research. Our implementation facilitates this through a single-agent loop based on a ReAct architecture, natively integrating specialized tools such as <em>batch_web_surfer</em> and <em>shell</em> for iterative investigations. This approach allows Step 3.5 Flash to achieve a score of 65.27%, delivering research quality that competes with OpenAI and Gemini Deep Research while maintaining significantly higher inference efficiency.</p>

                    
                    <div>
                        <div>
                            <h3>Performance on <span>ResearchRubrics</span></h3>
                            <div>
                                <div>
                                    <p><span>Step 3.5 Flash</span></p>
                                    <p><span>65.3</span>
                                    <span>ReAct Agent</span>
                                </p></div>
                                <div>
                                    <p><span>Gemini DeepResearch</span></p>
                                    <p><span>63.7</span>
                                    <span>Agent System</span>
                                </p></div>
                                
                                <div>
                                    <p><span>OpenAI DeepResearch</span></p>
                                    <p><span>60.7</span>
                                    <span>Agent System</span>
                                </p></div>
                                <div>
                                    <p><span>Qwen DeepResearch</span></p>
                                    <p><span>49.2</span>
                                    <span>Agent System</span>
                                </p></div>
                            </div>
                        </div>
                        <p>We evaluated commercial agents by collecting reports from their official web interfaces (captured Dec 2–15, 2025) under default configurations, while our internal models utilized the ReAct framework for report generation. All outputs were subsequently appraised by an LLM judge using a ternary grading for each criterion.</p>
                    </div>

                    
                    <div>
                        <p>We demonstrate Step 3.5 Flash's exceptional Deep Research capabilities through a case study on early childhood science education. In this instance, Step 3.5 Flash synthesized a comprehensive research report of approximately 10,000 words, distilling complex neuroplasticity theories into an actionable, expert-grade guide for ages 0–3. The output bridges theoretical milestones with practical "Parental Scripts," reframing sensory play as structured inquiry while maintaining a rigorous focus on both cognitive depth and safety guidance.</p>
                        

                        <p><strong>Multi-Agent Orchestration Framework.</strong> Step 3.5 Flash also natively supports a multi-agent architecture where a Master Agent orchestrates complex tasks through autonomous planning and dynamic routing. This hierarchical framework dispatches specialized Search and Verify agents to handle retrieval and factual grounding via parallel tool-invocation loops. To ensure precision, a Summary Agent consolidates each sub-agent's trajectory into structured feedback, enabling the Master Agent to synthesize a final, coherent response.</p>
                        <div data-case-file="raw_case/dr_bmk_multi_agent/case1.json" data-multi-agent="true">
                                
                                <p><span>Multi-Agent Deep Research</span>
                            </p></div>
                    </div>
                </div>

                
                <div id="showcase-edge-cloud">
                    

                    <div>
                        <div>
                            <video controls="" preload="metadata">
                                <source src="https://static.stepfun.com/blog/step-3.5-flash/raw_case/Edge_cloud_Collaboration/gui/gui-case1.mp4" type="video/mp4">
                            </video>
                            <p>In this case, the user asks to search for the latest Arxiv papers on GUI Agents, summarize them, and immediately share the result via WeChat. Step 3.5 Flash, acting as the 'Cloud Brain,' first executes the search and summarization in the cloud for maximum speed. Once the content is ready, it triggers the 'Hand'—our on-device <a href="https://github.com/stepfun-ai/gelab-zero" target="_blank" rel="noopener">Step-GUI</a>—to wake up the phone, open WeChat, and deliver the message to the specific contact. This is Cloud-Device Synergy in action.</p>
                        </div>

                        <div>
                            <video controls="" preload="metadata">
                                <source src="https://static.stepfun.com/blog/step-3.5-flash/raw_case/Edge_cloud_Collaboration/gui/gui-case2.mp4" type="video/mp4">
                            </video>
                            <p>In this case, the user asks to compare Mac Mini M4 prices across platforms. Step 3.5 Flash, acting as the 'Cloud Brain,' decomposes this complex request into specific sub-tasks for Taobao, JD.com, and Pinduoduo. This cloud-side planning significantly lowers the difficulty for the on-device <a href="https://github.com/stepfun-ai/gelab-zero" target="_blank" rel="noopener">Step-GUI</a>, ensuring higher success rates as it retrieves real-time data from each app. Step 3.5 Flash then synthesizes the results to identify Pinduoduo as the cheapest option and offers a buying guide. This demonstrates <strong>Cloud-Device Synergy</strong>: cloud intelligence simplifies local execution for reliable results.</p>
                        </div>
                    </div>

                    <p>Furthermore, we conduct a comparative evaluation on the <a href="https://arxiv.org/pdf/2512.15431" target="_blank">AndroidDaily Hard</a> subset, a benchmark tailored for Chinese mobile application scenarios encompassing e-commerce, entertainment, and other daily tasks.</p>

                    <div>
                            <h3>Performance on AndroidDaily Hard</h3>
                            <div>
                                    <p><span>Step 3.5 Flash + Step-GUI</span></p>
                                    <p><span>57</span>
                                    <span>Edge–Cloud</span>
                                </p></div>
                        </div>

                    <p>We compare two paradigms: (1) single-agent <a href="https://github.com/stepfun-ai/gelab-zero" target="_blank" rel="noopener">Step-GUI</a> executing tasks independently on-device, and (2) an edge-cloud collaborative framework integrating Step 3.5 Flash with <a href="https://github.com/stepfun-ai/gelab-zero" target="_blank" rel="noopener">Step-GUI</a> via GUI-MCP. The results demonstrate that utilizing Step 3.5 Flash as the cloud-based host agent to orchestrate <a href="https://github.com/stepfun-ai/gelab-zero" target="_blank" rel="noopener">Step-GUI</a> significantly enhances the system's performance in complex scenarios.</p>
                </div>

                
                <div id="showcase-math">
                    
                    <p>Step 3.5 Flash demonstrates exceptional logical rigor in competition-level math. Through the deep analysis of IMO Shortlisted problems, the model proves its core strength in complex symbolic reasoning and abstract structural synthesis.</p>

                    <div>
                        
                        <div id="mathCase1">
                            
                            
                            <p>The problem seeks to characterize all real numbers \(\alpha\) such that the sum of the floor functions \(S_n = \sum_{k=1}^n \lfloor k\alpha\rfloor\) is always divisible by \(n\). The primary difficulty lies in the fact that \(\alpha\) is a real number, requiring one to separate its integer part \(m\) and fractional part \(\theta\) to analyze how the summation interacts with the modularity of \(n\). The core insight of the proof is reducing the problem to the behavior of the fractional sum \(T_n = \sum_{k=1}^n \lfloor k\theta\rfloor\) and employing induction to show that the divisibility constraints force extreme values for the floor functions.</p>
                        </div>

                        
                        <div id="mathCase2">
                            
                            
                            <p>The problem asks whether a specific inequality involving the sums of exponential terms \(3^{a_n}\) and \(2^{a_n}\) must hold for at least one \(n\) in any sequence of positive real numbers. The primary difficulty lies in the potentially divergent behavior of the numerator and denominator, which makes it non-obvious whether the ratio ever drops below a fixed constant like \(1/2024\). The core insight of the proof is to perform a change of variables \(x_i = 2^{a_i}\) and identify the power \(\alpha = \log_2 3\), transforming the expression into a ratio of power sums \(\frac{\sum x_i^\alpha}{(\sum x_i)^2}\).</p>
                        </div>
                    </div>
                </div>

                
                <div id="showcase-reliability">
                    

                    <p><strong>We also care about interaction reliability</strong>—the model's ability to not just solve problems, but to engage users with precision and professional judgment. To test this, we evaluated Step 3.5 Flash across two critical dimensions:</p>

                    <ul>
                        <li><strong>Proactive Intent Clarification</strong>: In our internal benchmark of 74 ambiguous real-world requests (primarily localized queries), Step 3.5 Flash consistently identified missing information and asked targeted questions to clarify user intent rather than making assumptions.</li>
                    </ul>

                    <div>
                            <h3>Proactive Intent Clarification</h3>
                            
                        </div>

                    <ul>
                        <li><strong>Advisory &amp; Consultation</strong>: Across 500 prompts in a balanced bilingual setting spanning life, learning, and workplace contexts, the model demonstrated solid domain knowledge and a professional style, maintaining high instruction-following standards in both English and Chinese.</li>
                    </ul>

                    <div>
                        <table>
                            <thead>
                                <tr>
                                    <th>Model</th>
                                    <th>Average</th>
                                    <th>Usefulness</th>
                                    <th>Logic</th>
                                    <th>Tone</th>
                                    <th>Instruction-following</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr><td>GPT-5.2</td><td>77.8%</td><td>77.2%</td><td>81.9%</td><td>73.0%</td><td>79.6%</td></tr>
                                <tr><td>Gemini 3.0 Pro</td><td>70.6%</td><td>73.9%</td><td>61.7%</td><td>72.3%</td><td>74.4%</td></tr>
                                <tr><td>Step 3.5 Flash</td><td>70.5%</td><td>73.3%</td><td>62.1%</td><td>72.4%</td><td>74.2%</td></tr>
                                <tr><td>Deepseek V3.2</td><td>70.3%</td><td>72.5%</td><td>64.4%</td><td>71.2%</td><td>72.9%</td></tr>
                                <tr><td>Claude Opus 4.5</td><td>68.5%</td><td>69.7%</td><td>66.5%</td><td>65.9%</td><td>72.1%</td></tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>

        

        <div id="techniques">
                <h2>The Engine Behind</h2>

                <div>
                    <div>
                        <h3 data-content="method.subsection_3_1_title">Architecture Optimized for Flash-Speed Decoding and Inference</h3>

                        <p>The architecture of <strong>Step 3.5 Flash</strong> is defined by a model-system co-design that prioritizes <strong>inference cost and speed</strong> as the core architectural constraint. We employ a <strong>Sparse Mixture-of-Experts (MoE)</strong> backbone to decouple global model capacity from per-token computation. While the total knowledge base spans <strong>196B parameters</strong>, the system only activates <strong>11B parameters per token</strong> during inference. To further reduce <strong>memory overhead</strong>, we strategically utilize dense layers for the first few layers of the network for high intelligence density.</p>

                        <p>To navigate the quadratic bottleneck of long-context processing, we leverage a hybrid attention layout that interleaves <strong>Sliding-Window Attention (SWA)</strong> with <strong>Full Attention</strong> at a 3:1 ratio. We specifically opted for SWA over linear alternatives to maintain the architectural flexibility required for <strong>speculative decoding</strong>. SWA is inherently compatible with <strong>Multi-Token Prediction (MTP)</strong> heads. These heads predict additional future tokens in parallel with the primary output, enabling <strong>parallel verification</strong>. This allows the model to validate multiple token hypotheses in a single pass, effectively breaking the serial constraints of standard autoregressive decoding.</p>

                        <p>To ensure this lightweight hybrid structure retains peak performance, we implemented two critical enhancements. We utilized an <strong>augmented query-head count</strong> in the SWA layers—increasing from 64 to 96—to strengthen representational power without expanding the \(KV\) cache footprint. This modification is highly efficient: since the attention window is fixed, the computational cost of these additional heads remains constant regardless of total sequence length. This allows us to scale up model expressiveness without the "long-context penalty" where attention costs usually explode as the conversation grows. Complementing this is our <strong><a href="https://arxiv.org/abs/2505.06708" target="_blank" rel="noopener">Head-wise Gated Attention</a></strong>, which functions as an input-dependent attention sink. By dynamically modulating information flow, this mechanism preserves numerical stability while incurring negligible overhead.</p>

                        <p>These strategic architectural refinements demonstrate that frontier-level reasoning can be decoupled from prohibitive latency. By integrating <strong>sparse-active execution</strong> with <strong>concurrent token verification</strong>, the model achieves a decoding throughput up to <strong>350 tokens per second (TPS)</strong> on NVIDIA Hopper GPUs while running SWE-bench Verified.</p>

                        <p><strong>Last but not least</strong>, the <strong>optimized total parameter scale</strong> of Step 3.5 Flash facilitates highly accessible, local inference. By consolidating its total capacity to a scale compatible with high-end personal hardware, the model supports high-fidelity private deployment on workstations such as the <strong>Apple M4 Max</strong>, <strong>NVIDIA DGX Spark</strong>, or <strong>AMD AI Max+ 395</strong>, providing a 100% trusted execution environment.</p>

                        <div>
                            <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/step3.5.svg" alt="Architecture"></p><p>The overall architecture of Step 3.5 Flash.</p>
                        </div>

                        <p>As the local deployment of large language models (LLMs) becomes increasingly prevalent, we have successfully adapted the Step 3.5 Flash to NVIDIA DGX Spark 128GB device based on the edge-side inference engine llama.cpp, and simultaneously released the INT4 quantized model weights in GGUF format. On NVIDIA DGX Spark, the Step 3.5 Flash achieves a generation speed of 20 tokens per second; by integrating the INT8 quantization technology for KVCache, it supports an extended context window of up to 256K tokens, thus delivering long text processing capabilities on par with cloud-based inference. The new model can be tested by developers on NVIDIA accelerated infrastructure via <a href="https://build.nvidia.com/" target="_blank">build.nvidia.com</a>.</p>
                    </div>

                    <div>
                        <h3 data-content="method.subsection_3_2_title">Scalable RL Unleashes the Reasoning Potential</h3>

                        <p>We introduce a scalable reinforcement learning framework designed to reliably train reasoning and agentic language models at scale.</p>

                        <p>Modern RL pipelines for LLMs rely on high-throughput inference engines to generate rollouts, while optimization happens asynchronously in a separate training system. At scale, this setup introduces two compounding challenges:</p>

                        <ol>
                            <li>Training–inference mismatch, caused by numerical and architectural differences between systems</li>
                            <li>Off-policy drift, as policies evolve while rollouts lag behind</li>
                        </ol>

                        <p>For long reasoning sequences, even minor token-level discrepancies can explode into extreme importance weights—leading to unstable updates, early convergence, or complete training collapse.</p>

                        <p>To address this, we propose <strong>Metropolis Independence Sampling Filtered Policy Optimization (MIS-PO)</strong>, which replaces fragile importance weighting with <strong>strict sample filtering</strong>. Instead of scaling gradients with continuous importance-sampling ratios as in PPO, MIS-PO uses these ratios solely as a <strong>binary acceptance criterion</strong>. Trajectories whose likelihood deviates too far between the inference and training policies are simply excluded from optimization, while accepted samples are treated as effectively on-policy. Concretely, the policy update is driven by</p>

                        <p>
                            \[\mathcal{L}_{actor} = - \mathbb{E}_{\tau \sim \pi_{\theta_\text{vllm}}} \left[ \mathbb{I}(\tau) \cdot \log \pi_\theta(a_t|s_t) \cdot \hat{A}_t \right],\]
                        </p>

                        <p>where the binary indicator \(\mathbb{I}(\tau)\) filters out off-distribution samples. This design dramatically reduces gradient variance and enables stable, long-horizon optimization without aggressive clipping.</p>

                        <p>Our framework also includes <strong>truncation-aware value bootstrapping</strong>, which prevents long reasoning trajectories from being incorrectly penalized when hitting context limits, and <strong>routing confidence monitoring</strong> for Mixture-of-Experts models, providing a practical signal for RL stability at scale.</p>

                        <p>Together, these components turn reinforcement learning into a <strong>reliable engine for continuous self-improvement</strong>, enabling consistent gains across mathematics, coding, and tool use, while remaining stable under large-scale, off-policy training.</p>
                    </div>

                    <div>
                        <p><img src="https://static.stepfun.com/blog/step-3.5-flash/assets/tb_plots_grad_norm_eb.svg" alt="RL Algorithm Ablation"></p><p>Training dynamics of different RL algorithms. Ablations are conducted on the Qwen model.</p>
                    </div>
                </div>
            </div>

        

        <div id="benchmarks">
                <h2>Benchmarks</h2>
                <p>In our benchmark table, we provide a detailed, side-by-side comparison of today's top-performing open-source models. Across a wide range of metrics, Step 3.5 Flash stands out with consistently strong results. Our evaluation focuses on three core dimensions—Reasoning, Coding and Agentic Capability—and visualizes score differences across peer models in a horizontal, at-a-glance format.</p>

                <div>
                    <table>
                        <thead>
                            <tr>
                                <th>Benchmark</th>
                                <th>Step 3.5 Flash</th>
                                <th>DeepSeek V3.2</th>
				<th>Kimi <br>K2 Thinking / K2.5</th>
                                <th>GLM-4.7</th>
                                <th>MiniMax M2.1</th>
                                <th>MiMo-V2 Flash</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td># Activated Params</td>
                                <td>11B</td>
                                <td>37B</td><td>32B</td><td>32B</td><td>10B</td><td>15B</td>
                            </tr>
                            <tr>
                                <td># Total Params (MoE)</td>
                                <td>196B</td>
                                <td>671B</td><td>1T</td><td>355B</td><td>230B</td><td>309B</td>
                            </tr>
                            <tr>
                                <td>Est. decoding cost<br><span>@ 128K context, Hopper GPU**</span></td>
                                <td>1.0x<br><span>100 tok/s, MTP-3, EP8</span></td>
                                <td>6.0x<br><span>33 tok/s, MTP-1, EP32</span></td>
                                <td>18.9x<br><span>33 tok/s, no MTP, EP32</span></td>
                                <td>18.9x<br><span>100 tok/s, MTP-3, EP8</span></td>
                                <td>3.9x<br><span>100 tok/s, MTP-3, EP8</span></td>
                                <td><span>1.2x</span><br><span>100 tok/s, MTP-3, EP8</span></td>
                            </tr>
                            <tr><td></td><td></td><td></td><td>Agent</td><td></td><td></td><td></td></tr>
                            <tr><td>τ²-Bench</td><td>88.2</td><td>80.3 (85.2*)</td><td><span>74.3*</span><span>/</span><span>85.4*</span></td><td>87.4</td><td>86.6*</td><td>80.3 (84.1*)</td></tr>
			    <tr><td>BrowseComp</td><td>51.6</td><td>51.4</td><td>41.5* / <span>60.6</span></td><td>52.0</td><td>47.4</td><td>45.4</td></tr>

			    <tr><td>BrowseComp<br><span>(w/ Context Manager)</span></td><td>69.0</td><td>67.6</td><td><span>60.2</span><span>/</span><span>74.9</span></td><td>67.5</td><td>62.0</td><td>58.3</td></tr>

			    <tr><td>BrowseComp-ZH</td><td>66.9</td><td>65.0</td><td>62.3 / 62.3*</td><td>66.6</td><td>47.8*</td><td>51.2*</td></tr>

			    <tr><td>BrowseComp-ZH<br><span>(w/ Context Manager)</span></td><td>73.7</td><td>—</td><td><span>—</span><span>/</span><span>—</span></td><td>—</td><td>—</td><td>—</td></tr>

			    <tr><td>GAIA<br><span>(no file)</span></td><td>84.5</td><td>75.1*</td><td><span>75.6*</span><span>/</span><span>75.9*</span></td><td>61.9*</td><td>64.3*</td><td>78.2*</td></tr>

			    <tr><td>xbench-DeepSearch<br><span>(2025.05)</span></td><td>83.7</td><td>78.0*</td><td><span>76.0*</span><span>/</span><span>76.7*</span></td><td>72.0*</td><td>68.7*</td><td>69.3*</td></tr>
                            <tr><td>xbench-DeepSearch<br><span>(2025.10)</span></td><td>56.3</td><td>55.7*</td><td><span>—</span><span>/</span><span>40+</span></td><td>52.3*</td><td>43.0*</td><td>44.0*</td></tr>
                            <tr><td><span>ResearchRubrics</span></td><td>65.3</td><td>55.8*</td><td><span>56.2*</span><span>/</span><span>59.5*</span></td><td>62.0*</td><td>60.2*</td><td>54.3*</td></tr>
                            <tr><td></td><td></td><td></td><td>Reasoning</td><td></td><td></td><td></td></tr>
                            <tr><td>AIME 2025</td><td>97.3</td><td>93.1</td><td><span>94.5</span><span>/</span><span>96.1</span></td><td>95.7</td><td>83.0</td><td>94.1 (95.1*)</td></tr>
                            <tr><td>HMMT 2025 (Feb.)</td><td>98.4</td><td>92.5</td><td><span>89.4</span><span>/</span><span>95.4</span></td><td>97.1</td><td>71.0*</td><td>84.4 (95.4*)</td></tr>
                            <tr><td>HMMT 2025 (Nov.)</td><td>94.0</td><td>90.2</td><td><span>89.2*</span><span>/</span><span>—</span></td><td>93.5</td><td>74.3*</td><td>91.0*</td></tr>
                            <tr><td>IMOAnswerBench</td><td>85.4</td><td>78.3</td><td><span>78.6</span><span>/</span><span>81.8</span></td><td>82.0</td><td>60.4*</td><td>80.9*</td></tr>
                            <tr><td></td><td></td><td></td><td>Coding</td><td></td><td></td><td></td></tr>
                            <tr><td>LiveCodeBench-V6</td><td>86.4</td><td>83.3</td><td><span>83.1</span><span>/</span><span>85.0</span></td><td>84.9</td><td>—</td><td>80.6 (81.6*)</td></tr>
                            <tr><td>SWE-bench Verified</td><td>74.4</td><td>73.1</td><td><span>71.3</span><span>/</span><span>76.8</span></td><td>73.8</td><td>74.0</td><td>73.4</td></tr>
                            <tr><td>Terminal-Bench 2.0</td><td>51.0</td><td>46.4</td><td><span>35.7*</span><span>/</span><span>50.8</span></td><td>41.0</td><td>47.9</td><td>38.5</td></tr>
                        </tbody>
                    </table>
                </div>
                <ul>
                    <li>"—" indicates the score is not publicly available or not tested.</li>
                    <li>"*" indicates the original score was inaccessible or lower than our reproduced, so we report the evaluation under the same test conditions as Step 3.5 Flash to ensure fair comparability.</li>
                    <li>BrowseComp (with Context Manager): when the effective context length exceeds a predefined threshold, the agent resets the context and restarts the agent loop. (By contrast, Kimi K2.5 and DeepSeek-V3.2 used a discard-all strategy.)</li>
                    <li>In decoding cost section, decoding **Estimated using a similar but more accurate approach than <a href="https://arxiv.org/abs/2507.19427" target="_blank" rel="noopener">arxiv.org/abs/2507.19427</a></li>
                </ul>
            </div>

        

        <div id="limitations">
                <h2>Known Issues and Future Directions</h2>
                <ol>
                    <li><strong>Token Efficiency.</strong> Step 3.5 Flash achieves frontier-level agentic intelligence but currently relies on longer generation trajectories than Gemini 3.0 Pro to reach comparable quality.</li>
                    <li><strong>Efficient Universal Mastery.</strong> We aim to unify generalist versatility with deep domain expertise. To achieve this efficiently, we are advancing variants of on-policy distillation, allowing the model to internalize expert behaviors with higher sample efficiency.</li>
                    <li><strong>RL for More Agentic Tasks.</strong> While Step 3.5 Flash demonstrates competitive performance on academic agentic benchmarks, the next frontier of agentic AI necessitates the application of RL to intricate, expert-level tasks found in professional work, engineering, and research.</li>
                    <li><strong>Operational Scope and Constraints.</strong> Step 3.5 Flash is tailored for coding and work-centric tasks, but may experience reduced stability during distribution shifts. This typically occurs in highly specialized domains or long-horizon, multi-turn dialogues, where the model may exhibit repetitive reasoning, mixed-language outputs, or inconsistencies in time and identity awareness.</li>
                </ol>
            </div>

        <div id="meet-stepfun">
                <h2>Meet StepFun</h2>
                <ul>
                    <li>
                        <strong>OpenClaw</strong> is a powerful agentic platform that works seamlessly with Step 3.5 Flash.
                        <details>
                            <summary>Quick Setup</summary>
                            <div>
                                <p><strong>Install:</strong> <code>curl -fsSL https://openclaw.ai/install.sh | bash</code></p>
                                <p><strong>Onboard:</strong> Run <code>openclaw onboard</code>.</p>
                                <p><strong>Configure:</strong> In WebUI (Config → Models), add a new provider:</p>
                                <ul>
                                    <li>Type: <code>openai-completions</code> → Base URL: <code>https://api.stepfun.ai/v1</code></li>
                                    <li>Model ID: <code>step-3.5-flash</code> (Context: 256000)</li>
                                </ul>
                            </div>
                        </details>
                        For a full walkthrough, see our <strong><a href="https://github.com/stepfun-ai/Step-3.5-Flash/tree/main/cookbooks/openclaw" target="_blank" rel="noopener">OpenClaw Cookbook</a></strong>.
                    </li>
                    <li>Step 3.5 Flash is available via our <strong>API platform (<a href="https://platform.stepfun.com/docs/zh/llm/reasoning" target="_blank" rel="noopener">中文</a><span>/</span><a href="https://platform.stepfun.ai/docs/en/llm/reasoning" target="_blank" rel="noopener">EN</a>)</strong>, and you can chat with it on the <strong>Web (<a href="https://www.stepfun.com/" target="_blank" rel="noopener">中文</a><span>/</span><a href="https://stepfun.ai/" target="_blank" rel="noopener">EN</a>)</strong> or in our <strong>App (<a href="https://apps.apple.com/cn/app/%E9%98%B6%E8%B7%83ai-%E9%98%B6%E8%B7%83%E6%98%9F%E8%BE%B0ai%E5%8A%A9%E6%89%8B/id6502382318" target="_blank" rel="noopener">iOS</a><span>/</span><a href="https://play.google.com/store/apps/details?id=cn.yuewen.ywapp&amp;hl=zh" target="_blank" rel="noopener">Android</a>)</strong>.</li>
                    <li>Join our <strong><a href="https://discord.gg/RcMJhNVAQc" target="_blank" rel="noopener">Discord community</a></strong> for updates, support, and early access.</li>
                </ul>
            </div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Minecraft Java is switching from OpenGL to Vulkan (258 pts)]]></title>
            <link>https://www.gamingonlinux.com/2026/02/minecraft-java-is-switching-from-opengl-to-vulkan-for-the-vibrant-visuals-update/</link>
            <guid>47068948</guid>
            <pubDate>Thu, 19 Feb 2026 01:55:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gamingonlinux.com/2026/02/minecraft-java-is-switching-from-opengl-to-vulkan-for-the-vibrant-visuals-update/">https://www.gamingonlinux.com/2026/02/minecraft-java-is-switching-from-opengl-to-vulkan-for-the-vibrant-visuals-update/</a>, See on <a href="https://news.ycombinator.com/item?id=47068948">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
						<p>Work continues for the Vibrant Visuals update to come to Minecraft Java, and as part of that they're switching the rendering from OpenGL to Vulkan.</p>
<p><a href="https://www.minecraft.net/en-us/article/another-step-towards-vibrant-visuals-for-java-edition" target="_blank" rel="noopener">Announced</a> today (February 18th) by Mojang developers, it's a huge change for such a game and will take time - but it will be worth it in the end so they can take advantage of all the modern features available for both visual improvements and better performance.</p>
<p><a href="https://uploads.golmedia.net/uploads/articles/article_media/6889725121771426976gol2.webp" data-fancybox="images"><img src="https://uploads.golmedia.net/uploads/articles/article_media/6889725121771426976gol2.webp"></a></p>
<p>They note clearly that their aim is to "keep Minecraft: Java Edition playable for almost any PC-operating system, including macOS and Linux". For the macOS side of things, they'll use a translation layer since Apple don't support Vulkan directly (they made their own API with Metal).</p>
<p>For modders, they're suggesting they start making preparations to move away from OpenGL</p>
<blockquote>
<p>Switching from OpenGL to Vulkan will have an impact on the mods that currently use OpenGL for rendering, and we anticipate that updating from OpenGL to Vulkan will take modders more effort than the updates you undertake for each of our releases. </p>
<p>To start with, we recommend our modding community look at moving away from OpenGL usage. We encourage authors to try to reuse as much of the internal rendering APIs as possible, to make this transition as easy as possible. If that is not sufficient for your needs, then come and talk to us!  </p>
</blockquote>
<p>It does mean that players on really old devices that don't support Vulkan will be left out, but Vulkan has been supported going back to some pretty <em>old</em> GPUs. You've got time though, as they'll be rolling out Vulkan alongside OpenGL in snapshots (development releases) "sometime over the summer". You'll be able to toggle between them during the testing period until Mojang believe it's ready. OpenGL will be entirely removed eventually once they're happy with performance and stability.</p>
<div><p><span>Release Date:</span> <span>8th November 2011</span></p><p><span>Platform:</span> <span>🐧 Native Linux</span></p></div>
						<p><span>Article taken from <a href="https://www.gamingonlinux.com/">GamingOnLinux.com.</a></span>
						
					</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[15 years of FP64 segmentation, and why the Blackwell Ultra breaks the pattern (182 pts)]]></title>
            <link>https://nicolasdickenmann.com/blog/the-great-fp64-divide.html</link>
            <guid>47068890</guid>
            <pubDate>Thu, 19 Feb 2026 01:46:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nicolasdickenmann.com/blog/the-great-fp64-divide.html">https://nicolasdickenmann.com/blog/the-great-fp64-divide.html</a>, See on <a href="https://news.ycombinator.com/item?id=47068890">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>Buy an RTX 5090, the fastest consumer GPU money can buy, and you get 104.8 TFLOPS of FP32 compute. Ask it to do double-precision math and you get 1.64 TFLOPS. That 64:1 gap is not a technology limitation. For fifteen years, the FP64:FP32 ratio has been slowly getting wider on consumer GPUs, widening the divide between consumer and enterprise silicon. Now the AI boom is quietly dismantling that logic.</p>

                    <h2>The Evolution of FP64 on Nvidia GPUs</h2>

                    <p>The FP64:FP32 ratio on Nvidia consumer GPUs has degraded consistently since the Fermi architecture debuted in 2010. On Fermi, the GF100 die shipped to both GeForce and Tesla lines; the hardware supported 1:2 FP64:FP32, but GeForce cards were driver-capped to 1:8.<sup><a href="#fn1" id="fnref1">1</a></sup></p>

                    <p>Over time, Nvidia moved away from “artificially” lowering FP64 performance on consumer GPUs. Instead, the architectural split became structural; the hardware itself is fundamentally different across product tiers. While datacenter GPUs have consistently kept a 1:2 or 1:3 FP64:FP32 performance (until the recent AI boom, more on that later), the performance ratio on consumer GPUs has consistently gotten worse. From 1:8 on the Fermi architecture in 2010 to 1:24 on Kepler in 2012 to 1:32 in 2014 to our final 1:64 ratio on Ampere in 2020.</p>

                    <p>This effectively also means that over 15 years, from the GTX 480 in 2010 to the RTX 5090 in 2025 the FP64 performance on consumer GPUs only increased 9.65x from 0.17 TFLOPS to 1.64 TFLOPS, while in the same time range the FP32 performance improved a whopping 77.63x from 1.35 TFLOP to 104.8 TFLOP.</p>

                    <figure>
                        <img src="https://nicolasdickenmann.com/assets/FP32toFP64.png" alt="FP32 versus FP64 throughput scaling on Nvidia consumer GPUs over time">
                        <figcaption>FP32 vs FP64 throughput scaling across Nvidia GPU generations.<sup><a href="#fn2" id="fnref2-1">2</a></sup></figcaption>
                    </figure>


                    <h2>Nvidia's Move to Segment the Market</h2>
                    <p>So why has FP64 performance on consumer GPUs progressively gotten weaker (in relation to FP32) while it stayed consistently strong on enterprise hardware?</p>

                    <p>If this were purely a technical or cost constraint, you would expect the gap to be smaller. But since historically, Nvidia has taken deliberate steps to limit double-precision (FP64) throughput on GeForce cards, it makes it hard to argue this is accidental. The much simpler explanation is market segmentation.</p>

                    <p>Most consumer workloads, such as gaming, 3d rendering, or video editing do not need FP64. High-performance computing on the other hand has long relied on double precision (FP64). Fields such as computational fluid dynamics, climate modeling, quantitative finance, and computational chemistry depend on numerical stability and precision that single precision (FP32) cannot always provide. So FP64 becomes a very convenient lever: weaken it on consumer GPUs, preserve it on enterprise versions, and you get a clean dividing line between markets. Nvidia has been fairly open about this. In the consumer Ampere GA102 whitepaper, they note "The small number of FP64 hardware units are included to ensure any programs with FP64 code operate correctly.".<sup><a href="#fn3" id="fnref3">3</a></sup></p>

                    <p>And the segmentation worked. Over time, the price gap between consumer GPUs and datacenter GPUs widened from roughly 5x around 2010 to over 20x by 2022. Enterprise cards commanded massive premiums, justified in part by their strong FP64 performance (among other features like ECC memory, NVLink, support contracts, and so on). From a business standpoint, the elegance is obvious: closely related silicon sold into two markets at vastly different margins, with FP64 throughput serving as a clear dividing line.</p>

                    <p>Modern AI training largely does not depend on FP64 though. FP32 works fine, and on the contrary lower precisions (FP16, BF16, FP8, even FP4) are often preferred. Suddenly, consumer GPUs looked surprisingly capable for serious compute workloads. Researchers, startups, and hobbyists could train meaningful models without the purchase of an expensive Tesla or A100. In response, Nvidia updated its GeForce End User License Agreement (EULA) in 2017 to prohibit use of consumer GPUs in datacenters, in a divisive move. In what was (to my knowledge) an unprecedented shift, implicit technical segmentation was replaced by explicit contractual restrictions.<sup><a href="#fn5" id="fnref5">5</a></sup></p>


                    <figure>
                        <img src="https://nicolasdickenmann.com/assets/enterprise_consumer_price_ratio.png" alt="Enterprise vs consumer GPU price ratio over time">
                        <figcaption>Enterprise vs consumer GPU price ratio (2010-2022). Official MSPR numbers for consumer GPU, best effort for enterprise GPUs.<sup><a href="#fn2" id="fnref2-2">2</a></sup></figcaption>
                    </figure>

                    <h2>How FP64 Emulation and AI Is Changing the Game</h2>
                    <p>What if you have an old RTX 4090 lying around at home and, for some reason, you need the precision of FP64 but the built-in FP64 capabilities are not sufficient? Aside from the obvious answer of purchasing enterprise GPU power, FP64 emulation using FP32 floats can be an answer. This concept dates back to 1971, when T. J. Dekker described double-float arithmetic.<sup><a href="#fn6" id="fnref6">6</a></sup></p>

                    <p>The simple idea is to split a 64-bit floating point number into two 32-bit floating point numbers: <code>A = a_hi + a_lo</code>. The <code>a_hi</code> term carries the most significant bits, while <code>a_lo</code> captures the rounding error. Andrew Thall proposed a bunch of common algorithms for emulated FP64s (summation, multiplication, etc.) back in 2007 when GPUs did not have FP64 capabilities.<sup><a href="#fn7" id="fnref7">7</a></sup> You lose 5 bits of precision as your effective mantissa is only 48 bits (twice the FP32 effective mantissa) and not the FP64 53 bits of precision. If a modest reduction in numerical precision is acceptable, you may be able to achieve substantially higher throughput by using emulated double-precision computation. This can be advantageous given the steep FP64-to-FP32 performance disparity, even after accounting for the overhead introduced by emulation.</p>
                    <figure>
                        <img src="https://nicolasdickenmann.com/assets/emulate_double.drawio.png" alt="Diagram of emulated double using high and low parts">
                        <figcaption>Emulated double representation using high and low FP32 parts.</figcaption>
                    </figure>

                    <p>A newer scheme that preserves full 64-bit precision but only works for matrix multiplication is the Ozaki scheme.<sup><a href="#fn8" id="fnref8">8</a></sup> This scheme exploits the speedup of tensor cores (specialized hardware for matrix multiply-accumulate (MMA) operations) and the distributive property of matrix multiplication.<sup><a href="#fn9" id="fnref9">9</a></sup> The Ozaki scheme splits FP64 numbers into, for example, FP8 numbers:</p>
                    <p>A = A<sub>1</sub> + A<sub>2</sub> + A<sub>3</sub> + ... + A<sub>k</sub></p>
                    <p>where A<sub>1</sub> contains the most significant bits and A<sub>2</sub> contains the next slice of bits and so on. We then calculate:</p>
                    <p>A<sub>i</sub> B<sub>i</sub></p>
                    <p>for each A<sub>i</sub> and B<sub>i</sub>. All the results are summed back up in 64-bit precision:</p>
                    <p>AB = Σ A<sub>i</sub> B<sub>i</sub></p>
                    <p>The Ozaki scheme is gaining increasing traction thanks to the abundance of extremely fast FP8 and FP4 tensor cores being deployed for AI workloads. NVIDIA added support for the Ozaki scheme in cuBLAS in October 2025 and plans to continue developing it.<sup><a href="#fn10" id="fnref10">10</a></sup></p>

                    <p>From a GPU manufacturer's perspective, this direction is logical. The majority of enterprise GPU revenue now comes from AI applications; market segmentation based on FP64 performance makes no more sense. Enhancing FP64 emulation through low-precision tensor cores allows a reduction in the relative allocation of dedicated FP64 units in enterprise GPUs while expanding FP8 and FP4 compute resources that directly benefit AI workloads.</p>

                    <p>The latest generation of NVIDIA enterprise GPUs, the B300 based on the Blackwell Ultra architecture, represents a decisive shift toward low precision. FP64 performance has been significantly reduced in favor of more NVFP4 tensor cores, with the FP64:FP32 ratio dropping from 1:2 to 1:64.<sup><a href="#fn11" id="fnref11">11</a></sup> In absolute terms, peak FP64 performance declines from 37 TFLOPS on the B200 to 1.2 TFLOPS on the B300. Paradoxically, instead of consumer hardware catching up to enterprise-class capabilities, enterprise hardware is now embracing constraints traditionally associated with consumer GPUs.</p>

                    <p>Does this signal a gradual replacement of physical FP64 units through emulation? Not necessarily. According to NVIDIA, the company is not abandoning 64-bit computing and plans future improvements to FP64 capabilities.<sup><a href="#fn11" id="fnref11">11</a></sup> Nonetheless, FP64 emulation is here to stay, exploiting the abundance of low-precision tensor cores to supplement hardware FP64 for HPC workloads.</p>

                    <p>But the segmentation logic hasn't disappeared; it may simply be migrating. The RTX 5090 delivers a 1:1 FP16:FP32 ratio, while the B200 sits at 16:1. For fifteen years, FP64 was the dividing line between consumer and enterprise silicon. The next divide may already be taking shape in low-precision floating point.</p>
                    <section aria-label="Footnotes">
                        <hr>
                        <ol>
                            <li id="fn1">AnandTech: GTX 480/470 FP64 ratio discussion (archived). <a href="https://web.archive.org/web/20100402215300/http://www.anandtech.com/show/2977/nvidia-s-geforce-gtx-480-and-gtx-470-6-months-late-was-it-worth-the-wait-/6">https://web.archive.org/web/20100402215300/http://www.anandtech.com/show/2977/nvidia-s-geforce-gtx-480-and-gtx-470-6-months-late-was-it-worth-the-wait-/6</a> <a href="#fnref1" aria-label="Back to content">↩</a></li>
                            <li id="fn2">Google Sheets: numbers used for the computations. <a href="https://docs.google.com/spreadsheets/d/1NHHlgVytLx43DGzP8HlPeOCs7HKPElgpSO__9j6oMFo/edit?usp=sharing">https://docs.google.com/spreadsheets/d/1NHHlgVytLx43DGzP8HlPeOCs7HKPElgpSO__9j6oMFo/edit?usp=sharing</a> <a href="#fnref2-1" aria-label="Back to first graph">↩</a> <a href="#fnref2-2" aria-label="Back to second graph">↩</a></li>
                            <li id="fn3">NVIDIA Ampere GA102 GPU Architecture Whitepaper (PDF). <a href="https://www.nvidia.com/content/PDF/nvidia-ampere-ga-102-gpu-architecture-whitepaper-v2.pdf">https://www.nvidia.com/content/PDF/nvidia-ampere-ga-102-gpu-architecture-whitepaper-v2.pdf</a> <a href="#fnref3" aria-label="Back to content">↩</a></li>
                            <li id="fn4">Alibaba Product Insights: A100 vs RTX 3090—Is the A100 Really Worth the Hype and Extra for Deep Learning? <a href="https://www.alibaba.com/product-insights/a100-vs-rtx-3090-is-the-a100-really-worth-the-hype-and-extra-for-deep-learning.html">https://www.alibaba.com/product-insights/a100-vs-rtx-3090-is-the-a100-really-worth-the-hype-and-extra-for-deep-learning.html</a> <a href="#fnref4" aria-label="Back to content">↩</a></li>
                            <li id="fn5">Wccftech on 2017 GeForce EULA datacenter restriction. <a href="https://wccftech.com/nvidia-geforce-eula-prohibits-datacenter-blockchain-allowed/">https://wccftech.com/nvidia-geforce-eula-prohibits-datacenter-blockchain-allowed/</a> <a href="#fnref5" aria-label="Back to content">↩</a></li>
                            <li id="fn6">T. J. Dekker (1971), double-float arithmetic. <a href="https://csclub.uwaterloo.ca/~pbarfuss/dekker1971.pdf">https://csclub.uwaterloo.ca/~pbarfuss/dekker1971.pdf</a> <a href="#fnref6" aria-label="Back to content">↩</a></li>
                            <li id="fn7">Andrew Thall (2007), Extended-Precision Floating-Point Numbers for GPU Computation. <a href="https://andrewthall.org/papers/df64_qf128.pdf">https://andrewthall.org/papers/df64_qf128.pdf</a> <a href="#fnref7" aria-label="Back to content">↩</a></li>
                            <li id="fn8">Ozaki et al. (2011), Error-Free Transformations for Matrix Multiplication. <a href="https://link.springer.com/article/10.1007/s11075-011-9478-1">https://link.springer.com/article/10.1007/s11075-011-9478-1</a> <a href="#fnref8" aria-label="Back to content">↩</a></li>
                            <li id="fn9">NVIDIA blog: Tensor Cores for Science (ISC 2025). <a href="https://developer.nvidia.com/blog/nvidia-top500-supercomputers-isc-2025/#tensor_cores_for_science%C2%A0">https://developer.nvidia.com/blog/nvidia-top500-supercomputers-isc-2025/#tensor_cores_for_science%C2%A0</a> <a href="#fnref9" aria-label="Back to content">↩</a></li>
                            <li id="fn10">NVIDIA blog: Unlocking Tensor Core Performance with Floating-Point Emulation in cuBLAS. <a href="https://developer.nvidia.com/blog/unlocking-tensor-core-performance-with-floating-point-emulation-in-cublas">https://developer.nvidia.com/blog/unlocking-tensor-core-performance-with-floating-point-emulation-in-cublas</a> <a href="#fnref10" aria-label="Back to content">↩</a></li>
                            <li id="fn11">HPCwire: NVIDIA says it's not abandoning 64-bit computing (Dec 9, 2025). <a href="https://www.hpcwire.com/2025/12/09/nvidia-says-its-not-abandoning-64-bit-computing/">https://www.hpcwire.com/2025/12/09/nvidia-says-its-not-abandoning-64-bit-computing/</a> <a href="#fnref11" aria-label="Back to content">↩</a></li>
                        </ol>
                    </section>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How AI is affecting productivity and jobs in Europe (155 pts)]]></title>
            <link>https://cepr.org/voxeu/columns/how-ai-affecting-productivity-and-jobs-europe</link>
            <guid>47068320</guid>
            <pubDate>Thu, 19 Feb 2026 00:22:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cepr.org/voxeu/columns/how-ai-affecting-productivity-and-jobs-europe">https://cepr.org/voxeu/columns/how-ai-affecting-productivity-and-jobs-europe</a>, See on <a href="https://news.ycombinator.com/item?id=47068320">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
      

      <article>
        
              <div>
                
                  <p>&nbsp;Europe faces a critical choice in the race for artificial intelligence (AI). As the technology promises to reshape economies worldwide, policymakers are caught between two competing narratives. Optimists envision AI as the catalyst for a new productivity boom, potentially adding several percentage points to annual growth (Baily et al. 2023). Sceptics warn that adoption barriers, skill gaps, and uneven diffusion may limit gains and exacerbate inequality (Acemoglu 2024, Filippucci et al. 2024, Gambacorta and Shreeti, 2025). For Europe, the stakes are particularly high: while the continent boasts world-leading AI researchers and industrial capacity, it lags behind the US and China in developing new AI technologies (Cornelli et al. 2023). Recent studies suggest that AI could widen cross-country income gaps, with benefits concentrating in advanced economies that are better prepared to adopt and integrate these technologies (Cazzaniga et al. 2024, Gambacorta et al. 2025, Hennig and Khan 2025).</p>

<p>Yet robust firm-level evidence on AI’s actual effects in Europe remains scarce. Do European firms that adopt AI genuinely become more productive? Does AI destroy jobs or augment workers? Are the benefits shared broadly, or do they concentrate among larger, better-resourced companies? In a recent study (Aldasoro et al. 2026), we provide the first causal evidence on how AI adoption affects productivity and employment across more than 12,000 European firms.</p>

<h2>Europe’s AI paradox</h2>

<p>Europe’s position in the global AI landscape is paradoxical. On various innovation metrics, the continent falls behind. The EU trails the US not only in the absolute number of AI-related patents but also in AI specialisation – the share of AI patents relative to total patents. This innovation gap translates into differences in firms’ readiness to adopt AI, as measured by the IMF’s AI preparedness index, which assesses countries based on digital infrastructure, human capital, innovation capacity, and regulatory frameworks (Cazzaniga et al. 2024).</p>

<p>However, when it comes to actual deployment, the picture is more nuanced. Drawing on the European Investment Bank Investment Survey (EIBIS), we find that on average, AI adoption levels are similar in the EU and the US. Notably, important heterogeneity emerges beneath the surface. Financially developed EU countries – such as Sweden and the Netherlands – match US adoption rates, with around 36% of firms using big data analytics and AI in 2024. In contrast, firms in less financially developed EU economies, such as Romania and Bulgaria, lag substantially behind, with adoption rates around 28% in 2024. Figure 1 illustrates this divide, showing how the gap has persisted and even widened in recent years.</p>

<p><strong>Figure 1</strong> Use of big data analytics and AI by country groups</p>

  


<h6><em>Notes</em>: Average share of firms reporting that they use AI by country groups, controlling for firms’ sector. The error bars represent 95% confidence intervals. EU countries are grouped based on an index of financial development using financial market data from 2015 to 2023 and consisting of two composite indicators: (i) financial market size and integration, and (ii) financial market depth (see Betz et al., 2026). Source: EIBIS 2019-2024.</h6>

<p>Adoption also varies dramatically by firm size. Among large firms (more than 250 employees), 45% have deployed AI, compared with only 24% of small firms (10 to 49 employees). This echoes classic patterns in technology diffusion (Comin and Hobijn 2010): larger firms possess the resources, technical expertise, and economies of scale needed to absorb integration costs. AI-adopting firms are also systematically different – they invest more, are more innovative, and face tighter constraints in finding skilled workers. These patterns suggest that simply observing which firms adopt AI and comparing their performance could yield misleading results, as adoption itself is endogenous to firm characteristics.</p>

<h2>Isolating AI’s causal effect</h2>

<p>To credibly identify the causal effect of AI on productivity, we develop a novel instrumental variable strategy, inspired by Rajan and Zingales’ (1998) seminal work on financial dependence and growth. Their key insight was that industry characteristics measured in one economy – where they are arguably less affected by local distortions – can serve as an exogenous source of variation when applied to other countries.</p>

<p>We extend this logic to the firm level. For each EU firm in our sample, we identify comparable US firms – matched on sector, size, investment intensity, innovation activity, financing structure and management practices. We then assign the AI adoption rate of these matched US firms as a proxy for the EU firm’s exogenous exposure to AI. Because US firms operate under different institutional, regulatory and policy environments, their adoption patterns capture technological drivers that are plausibly independent of EU-specific factors. Rigorous propensity-score balancing tests confirm that our matched US and EU firms are virtually identical across key observable characteristics, validating the identification strategy. Our analysis draws on survey data from EIBIS combined with balance sheet data from Moody’s Orbis.</p>

<h2>Productivity gains without job losses</h2>

<p>Our results reveal three key findings. First, AI adoption causally increases labour productivity levels by 4% on average in the EU. This effect is statistically robust and economically meaningful, though more moderate than the transformative scenarios predicted by some observers. The magnitude aligns with mid-range macroeconomic projections (Bergeaud 2024) rather than the most optimistic estimates of productivity booms. While our analysis focuses on labour productivity levels and captures a one-off effect – rather than long-run total factor productivity growth – the 4% gain suggests that AI acts in the short term as a complementary input that enhances efficiency, albeit with implementation frictions and skill gaps tempering its impact.</p>

<p>Second, and crucially, we find no evidence that AI reduces employment in the short run. While naïve comparisons suggest AI-adopting firms employ more workers, this relationship disappears once we account for selection effects through our instrumental variable approach. The absence of negative employment effects, combined with significant productivity gains, points to a specific mechanism: capital deepening. AI augments worker output – enabling employees to complete tasks faster and make better decisions – without displacing labour. This finding resonates with micro-level experimental evidence showing that AI tools can produce productivity gains between 10% and 65%, with strong effects in coding, consultant tasks and professional writing (Noy and Zhang 2023, Gambacorta et al. 2024, Brynjolfsson et al. 2025). These experimental effects are task-specific, whereas our estimates capture firm-level averages.</p>

<p>Importantly, workers in AI-adopting firms have benefited through higher wages, both in aggregate and per employee. Whether these wage gains will persist in the long term, and whether they will be shared equitably across skill levels, remains an open question that merits continued monitoring.</p>

<h2>Uneven gains and the critical role of complementary investments</h2>

<p>Third, AI’s productivity benefits are far from evenly distributed. Breaking down our results by firm size reveals that medium and large companies experience substantially stronger productivity gains than their smaller counterparts (see Figure 2). This differential effect reflects the role of scale in absorbing AI integration costs and accessing complementary assets – data infrastructure, technical talent, and organisational capacity to redesign workflows. The finding raises concerns about widening productivity gaps between firms and regions, particularly given Europe’s industrial structure, which is dominated by small and medium-sized enterprises.</p>

<p><strong>Figure 2</strong> Effects of AI adoption on labour productivity by company size</p>

  


<h6><em>Notes</em>: The dependent variable is labour productivity, calculated as the log of turnover per employee, and is derived from EIBIS. AI adoption is measured using the AI implementation status derived from similar firms in the US. All regressions control for firm investment, profitability, financial leverage, total assets, age, and the interaction of country, sector and year fixed effects. Investment is expressed as the annual change in total fixed assets. Profitability is the ratio of earnings before interest and taxes (EBIT) to total assets. Financial leverage is the ratio of loans and long-term debt to total assets. All control variables come from Orbis and are lagged by 1 year. Error bars represent 90% confidence interval, based on standard errors clustered at country-sector-year level. Log linear approximation, 0.01 = 1% increase.</h6>

<p>Perhaps most importantly, our analysis reveals that AI adoption alone is insufficient. Firms must make complementary investments to unlock AI’s full potential. Our results show the striking heterogeneity in how different types of investments enhance AI’s productivity effects. An extra percentage point of investment in software and data infrastructure increases AI’s productivity effect by 2.4 percentage points. Investment in workforce training has an even larger multiplier effect: an additional percentage point spent on training amplifies AI’s productivity gains by 5.9 percentage points. These findings underscore a critical insight: the productivity dividends from AI depend not merely on acquiring the technology but on firms’ capacity to integrate it through investments in intangible assets and human capital.</p>

<h2>Implications for European policy</h2>

<p>These findings carry significant implications for policymakers. First, the benefits of AI adoption are mostly visible for medium and large firms. This means that Europe may work on policies that help smaller firms reach the critical scale necessary to benefit from AI. This requires well-functioning financial markets that can channel capital to innovative, fast-growing companies. Our evidence shows that firms in countries with more sophisticated financial markets are better equipped to invest in AI and complementary assets. This underscores the importance of advancing the EU Savings and Investment Union to ensure that promising smaller firms can access the finance they need to grow and compete.</p>

<p>Second, the central role of complementary investments means that public policy must look beyond subsidising AI hardware or software licenses. Effective support requires incentivising firm-level investments in integration, workflow redesign and continuous learning. Workforce development programs should prioritise what might be called ‘fusion skills’ – capabilities like prompt engineering, data stewardship and human-in-the-loop decision making that enhance human-AI complementarity. This demands coordinated investments in vocational training, tertiary education and lifelong learning.</p>

<p>Finally, while our results offer some reassurance that AI may not be leading to immediate job destruction, policymakers should not be complacent. The capital-deepening effects we document may be transitional. As AI systems become more capable and as firms gain experience integrating them, labour-displacing effects could emerge. Moreover, the wage gains we observe may accrue disproportionately to highly skilled workers, potentially widening income inequality. Continued monitoring of AI’s labour market effects and proactive policies to ensure inclusive growth will be essential as the technology matures.</p>

<p><em>Authors’ note: The views expressed in this column are those of the authors and do not necessarily reflect those of the Bank for International Settlements and the European Investment Bank.</em></p>

<h2>&nbsp;References</h2>

<p>Acemoglu, D (2024), “The simple macroeconomics of AI”, <em>Economic Policy</em> 40: 13–58.</p>

<p>Aldasoro, I, L Gambacorta, R Pál, D Revoltella, C Weiss and M Wolski (2026), “<a href="https://cepr.org/publications/dp21082">AI adoption, productivity and employment: Evidence from European firms</a>”, CEPR Discussion Paper No. 21082.</p>

<p>Baily, M N, E Brynjolfsson and A Korinek (2023), “Machines of mind: The case for an AI-powered productivity boom”, Brookings Institution.</p>

<p>Bergeaud, A (2024), “The past, present and future of European productivity”, paper presented at the ECB Forum on Central Banking, Sintra, July.</p>

<p>Betz, F, R Pál, A Sapir and T Huyen (2026), “Capital markets and access to equity for European firms”, EIB Working Paper, forthcoming.</p>

<p>Brynjolfsson, E, D Li and L Raymond (2025), “Generative AI at work”, <em>Quarterly Journal of Economics </em>140(2): 889–942.</p>

<p>Cazzaniga, M, F Jaumotte, L Li, G Melina, A Panton, C Pizzinelli, E Rockall and M Mendes Tavares (2024), “GenAI: Artificial intelligence and the future of work”, IMF Staff Discussion Note 2024/001.</p>

<p>Comin, D and B Hobijn (2010), “An exploration of technology diffusion”, <em>American Economic Review </em>100: 2031–2059.</p>

<p>Cornelli, G, J Frost and S Mishra (2023), “Artificial intelligence, services globalisation and income inequality”, BIS Working Paper.</p>

<p>Filippucci, F, P Gal and M Schief (2024), “Miracle or myth? Assessing the macroeconomic productivity gains from artificial intelligence”, OECD Artificial Intelligence Paper No. 29.</p>

<p>Gambacorta, L, H Qiu, D Rees and S Shan (2024), “Generative AI and labour productivity: A field experiment on coding”, BIS Working Paper No. 1208.</p>

<p>Gambacorta, L, E Kharroubi, A Mehrotra and T Oliviero (2025), “Artificial intelligence and growth in advanced and emerging economies: short-run impact”, BIS Working Paper No. 1321.</p>

<p>Gambacorta, L and V Shreeti (2025), “<a href="https://cepr.org/voxeu/columns/big-techs-ai-empire">Big techs’ AI empire</a>”, VoxEU.org, 16 May.</p>

<p>Hennig, T and S Khan (2025), “How artificial intelligence will affect Asia’s economies”, IMF Blog, 5 January.</p>

<p>Noy, S and W Zhang (2023), “Experimental evidence on the productivity effects of generative artificial intelligence”, <em>Science</em> 381(6654): 187–192.</p>

<p>Rajan, R G and L Zingales (1998), “Financial dependence and growth”, <em>American Economic Review </em>88(3): 559–586.</p>

              </div>

              
                                          </article>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft offers guide to pirating Harry Potter series for LLM training (332 pts)]]></title>
            <link>https://devblogs.microsoft.com/azure-sql/langchain-with-sqlvectorstore-example/</link>
            <guid>47067759</guid>
            <pubDate>Wed, 18 Feb 2026 23:19:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/azure-sql/langchain-with-sqlvectorstore-example/">https://devblogs.microsoft.com/azure-sql/langchain-with-sqlvectorstore-example/</a>, See on <a href="https://news.ycombinator.com/item?id=47067759">Hacker News</a></p>
Couldn't get https://devblogs.microsoft.com/azure-sql/langchain-with-sqlvectorstore-example/: Error: Request failed with status code 404]]></description>
        </item>
        <item>
            <title><![CDATA[Ladybird: Closing this as we are no longer pursuing Swift adoption (292 pts)]]></title>
            <link>https://github.com/LadybirdBrowser/ladybird/issues/933</link>
            <guid>47067678</guid>
            <pubDate>Wed, 18 Feb 2026 23:08:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/LadybirdBrowser/ladybird/issues/933">https://github.com/LadybirdBrowser/ladybird/issues/933</a>, See on <a href="https://news.ycombinator.com/item?id=47067678">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="issue-body-viewer" data-team-hovercards-enabled="true" data-turbolinks="false" id="issue-body-viewer"><p dir="auto">List of issues preventing moving forward on moving Swift 6.0 support out of an experimental state:</p>
<p dir="auto">Swift issues:</p>
<ul>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2423820399" data-permission-text="Title is private" data-url="https://github.com/swiftlang/llvm-project/issues/8998" data-hovercard-type="issue" data-hovercard-url="/swiftlang/llvm-project/issues/8998/hovercard" href="https://github.com/swiftlang/llvm-project/issues/8998">Please backport d8352e93c1c8042d9166eab3d76d6c07ef585b6d<span>&nbsp;swiftlang/llvm-project#8998</span></a></span></p>
<p dir="auto">Details: Swift's version of LLVM is missing the fix for <span><a data-error-text="Failed to load title" data-id="1137046914" data-permission-text="Title is private" data-url="https://github.com/llvm/llvm-project/issues/53815" data-hovercard-type="issue" data-hovercard-url="/llvm/llvm-project/issues/53815/hovercard" href="https://github.com/llvm/llvm-project/issues/53815">[Clang] ICE in CheckPointerToMemberOperands passing decltype of lambda<span>&nbsp;llvm/llvm-project#53815</span></a></span>. This means that any assertions build of llvm from the swift open source project cannot build our code. Snapshot builds are released with assertions on.</p>
<p dir="auto">Workaround: Build swift from source on Linux without llvm assertions, or use macOS.</p>
<p dir="auto">PR: <span><a data-error-text="Failed to load title" data-id="2445185064" data-permission-text="Title is private" data-url="https://github.com/swiftlang/llvm-project/issues/9038" data-hovercard-type="pull_request" data-hovercard-url="/swiftlang/llvm-project/pull/9038/hovercard" href="https://github.com/swiftlang/llvm-project/pull/9038">🍒 [Clang] [Sema] Handle placeholders in '.*' expressions (#83103)<span>&nbsp;swiftlang/llvm-project#9038</span></a></span></p>
<p dir="auto">Fixed in Swift 6.0.0 release</p>
</li>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2440588492" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/75593" data-hovercard-type="issue" data-hovercard-url="/swiftlang/swift/issues/75593/hovercard" href="https://github.com/swiftlang/swift/issues/75593">Interop: Compiler and C++ Bridging header disagree on ABI of <code>Optional&lt;CxxValueType&gt;</code><span>&nbsp;swiftlang/swift#75593</span></a></span></p>
<p dir="auto">Details: It is not currently possible to return a swift optional of a small C++ type back to C++. The compiler and the generated bridging header disagree on how that is supposed to be done.</p>
<p dir="auto">Workaround: Don't use Optional, use a return type that forces the C++ type to be heap allocated. Array is one alternative.</p>
</li>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2445844445" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/75661" data-hovercard-type="issue" data-hovercard-url="/swiftlang/swift/issues/75661/hovercard" href="https://github.com/swiftlang/swift/issues/75661">Interop: Compiling with C++17 or higher on Ubuntu 22.04 fails with cyclic header dependencies in libstdc++<span>&nbsp;swiftlang/swift#75661</span></a></span></p>
<p dir="auto">Details: Swift's clang module map for libstdc++ contains cycles when <code>&lt;execution&gt;</code> is included. See <a href="https://forums.swift.org/t/swift-5-9-release-on-ubuntu-22-04-fails-to-build-std-module/67659" rel="nofollow">https://forums.swift.org/t/swift-5-9-release-on-ubuntu-22-04-fails-to-build-std-module/67659</a></p>
<p dir="auto">Workaround: Edit <code>&lt;prefix&gt;/lib/swift/linux/libstdcxx.h</code> to comment out the <code>#include &lt;execution&gt;</code> line.</p>
<p dir="auto">PR: <span><a data-error-text="Failed to load title" data-id="2445867195" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/75662" data-hovercard-type="pull_request" data-hovercard-url="/swiftlang/swift/pull/75662/hovercard" href="https://github.com/swiftlang/swift/pull/75662">[cxx-interop] Disable c++ execution header with libstdcxx versions &gt;= 11<span>&nbsp;swiftlang/swift#75662</span></a></span> (Just a workaround, not a fix)<br>
6.0 Backport: <span><a data-error-text="Failed to load title" data-id="2474439162" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/75971" data-hovercard-type="pull_request" data-hovercard-url="/swiftlang/swift/pull/75971/hovercard" href="https://github.com/swiftlang/swift/pull/75971">🍒 [cxx-interop] Disable c++ execution header with libstdcxx versions &gt;= 11<span>&nbsp;swiftlang/swift#75971</span></a></span><br>
Fixed in swiftlang/swift:main and release/6.0, but not in 6.0.0 or 6.0.1</p>
</li>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2478862199" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/76024" data-hovercard-type="issue" data-hovercard-url="/swiftlang/swift/issues/76024/hovercard" href="https://github.com/swiftlang/swift/issues/76024">Interop: Cannot return <code>swift::Optional&lt;swift::String&gt;</code> from C++ function<span>&nbsp;swiftlang/swift#76024</span></a></span></p>
<p dir="auto">Details: Returning binding types <code>swift::Optional&lt;T&gt;</code> or <code>swift::String</code> from a C++ function is not supported</p>
<p dir="auto">Workaround: Return std:: types?</p>
</li>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2560313000" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/76809" data-hovercard-type="issue" data-hovercard-url="/swiftlang/swift/issues/76809/hovercard" href="https://github.com/swiftlang/swift/issues/76809">Swift cannot import libstdc++-13 chrono header in C++23 mode<span>&nbsp;swiftlang/swift#76809</span></a></span></p>
<p dir="auto">Details: Swift 6.0 cannot import libstdc++-13 or higher <code>&lt;chrono&gt;</code> header.</p>
<p dir="auto">Workaround: Use libc++ or a lower libstdc++ version. libstdc++-13 is default on Ubuntu 24.04 LTS.</p>
<p dir="auto">Fixed in swiftlang/swift:main as of Oct 18, 2024</p>
</li>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2926260250" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/80065" data-hovercard-type="issue" data-hovercard-url="/swiftlang/swift/issues/80065/hovercard" href="https://github.com/swiftlang/swift/issues/80065">[cxx-interop] SIL verifier crash in Unmanaged.passUnretained() on SWIFT_UNSAFE_REFERENCE type<span>&nbsp;swiftlang/swift#80065</span></a></span></p>
<p dir="auto">Details: SIL verifier crash when trying to compare unsafe reference types by pointer</p>
<p dir="auto">Workaround: Disable SIL verification (!! yikes)<br>
Fixed in <span><a data-error-text="Failed to load title" data-id="3074553244" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/81614" data-hovercard-type="pull_request" data-hovercard-url="/swiftlang/swift/pull/81614/hovercard" href="https://github.com/swiftlang/swift/pull/81614">[cxx-interop] Relax a SILVerifier assertion for immortal reference types<span>&nbsp;swiftlang/swift#81614</span></a></span></p>
</li>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2936808960" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/80182" data-hovercard-type="issue" data-hovercard-url="/swiftlang/swift/issues/80182/hovercard" href="https://github.com/swiftlang/swift/issues/80182">[cxx-interop] Bitfield setter/getter for SWIFT_UNSAFE_REFERENCE crashes frontend<span>&nbsp;swiftlang/swift#80182</span></a></span></p>
<p dir="auto">Details: SWIFT_UNSAFE_REFERENCE types with getters/setters for bitfields crash the frontend</p>
<p dir="auto">Workaround: ... don't use SWIFT_UNSAFE_REFERENCE? unsure. Need guidance<br>
Fixed in <span><a data-error-text="Failed to load title" data-id="2938474851" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/80197" data-hovercard-type="pull_request" data-hovercard-url="/swiftlang/swift/pull/80197/hovercard" href="https://github.com/swiftlang/swift/pull/80197">[cxx-interop] Do not create mutating properties for classes<span>&nbsp;swiftlang/swift#80197</span></a></span></p>
</li>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2657430890" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/77607" data-hovercard-type="issue" data-hovercard-url="/swiftlang/swift/issues/77607/hovercard" href="https://github.com/swiftlang/swift/issues/77607">CxxInterop: Swift does not synthesize CxxConvertibleToContainer iterator operator== in some cases<span>&nbsp;swiftlang/swift#77607</span></a></span></p>
<p dir="auto">Details: <code>Vector&lt;u32, 2&gt;</code> is not recognized as <code>CxxConvertibleToContainer</code><br>
Workaround: Treat it as a sequence instead, and any transfer to a swift type requires manual copying of elements</p>
</li>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="3090514071" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/81774" data-hovercard-type="issue" data-hovercard-url="/swiftlang/swift/issues/81774/hovercard" href="https://github.com/swiftlang/swift/issues/81774">Enabling cxx interop on Arch with GCC 15 causes lots of errors<span>&nbsp;swiftlang/swift#81774</span></a></span></p>
<p dir="auto">Details: Swift fails to import clang modules with <code>#include &lt;math.h&gt;</code> with libstdc++-15 installed.</p>
<p dir="auto">Workaround: None (!!)</p>
</li>
</ul>
<p dir="auto">CMake issues:</p>
<ul>
<li>
<p dir="auto"> <a href="https://gitlab.kitware.com/cmake/cmake/-/issues/26174" rel="nofollow">https://gitlab.kitware.com/cmake/cmake/-/issues/26174</a></p>
<p dir="auto">Details: Swift + Ninja doesn't respect CMAKE_OSX_DEPLOYMENT_TARGET. This results in a mismatched LC_BUILD_VERSION on swift and c++ object files, spamming the console with warnings.</p>
<p dir="auto">Workaround: </p><div itemprop="text">
    <table data-tab-size="8" data-paste-markdown-skip="">

        <tbody><tr>
          <td id="L21" data-line-number="21"></td>
          <td id="LC21"> <span># FIXME: https://gitlab.kitware.com/cmake/cmake/-/issues/26174</span> </td>
        </tr>

        <tr>
          <td id="L22" data-line-number="22"></td>
          <td id="LC22"> <span>if</span> (<span>APPLE</span>) </td>
        </tr>

        <tr>
          <td id="L23" data-line-number="23"></td>
          <td id="LC23"> <span>    set</span>(CMAKE_Swift_COMPILER_TARGET <span>"<span>${CMAKE_SYSTEM_PROCESSOR}</span>-apple-macosx<span>${CMAKE_OSX_DEPLOYMENT_TARGET}</span>"</span>) </td>
        </tr>

        <tr>
          <td id="L24" data-line-number="24"></td>
          <td id="LC24"> <span>endif</span>() </td>
        </tr>
    </tbody></table>
  </div>

</li>
<li>
<p dir="auto"> <a href="https://gitlab.kitware.com/cmake/cmake/-/issues/26175" rel="nofollow">https://gitlab.kitware.com/cmake/cmake/-/issues/26175</a></p>
<p dir="auto">Details: With CMP0157 enabled, swiftc does not set install_name directory to "<a data-hovercard-type="user" data-hovercard-url="/users/rpath/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/rpath">@rpath</a>" per CMAKE_INSTALL_NAME_DIR</p>
<p dir="auto">Workaround: </p><div itemprop="text">
    <table data-tab-size="8" data-paste-markdown-skip="">

        <tbody><tr>
          <td id="L123" data-line-number="123"></td>
          <td id="LC123">     <span># FIXME: https://gitlab.kitware.com/cmake/cmake/-/issues/26175</span> </td>
        </tr>

        <tr>
          <td id="L124" data-line-number="124"></td>
          <td id="LC124"> <span>    if</span> (<span>APPLE</span>) </td>
        </tr>

        <tr>
          <td id="L125" data-line-number="125"></td>
          <td id="LC125"> <span>        add_custom_command</span>(<span>TARGET</span> LibGfx POST_BUILD </td>
        </tr>

        <tr>
          <td id="L126" data-line-number="126"></td>
          <td id="LC126">             <span>COMMAND</span> install_name_tool -id @rpath/liblagom-gfx.0.dylib <span>"$&lt;TARGET_FILE:LibGfx&gt;"</span> </td>
        </tr>

        <tr>
          <td id="L127" data-line-number="127"></td>
          <td id="LC127">         ) </td>
        </tr>

        <tr>
          <td id="L128" data-line-number="128"></td>
          <td id="LC128"> <span>    endif</span>() </td>
        </tr>
    </tbody></table>
  </div>

<p dir="auto">PR: <a href="https://gitlab.kitware.com/cmake/cmake/-/merge_requests/9692" rel="nofollow">https://gitlab.kitware.com/cmake/cmake/-/merge_requests/9692</a>. Merged Aug 2, 2024 to be backported to CMake 3.29, 3.30.</p>
</li>
<li>
<p dir="auto"> <a href="https://gitlab.kitware.com/cmake/cmake/-/issues/26195" rel="nofollow">https://gitlab.kitware.com/cmake/cmake/-/issues/26195</a></p>
<p dir="auto">Details: Imported targets from dependencies can have INTERFACE_COMPILE_OPTIONS or INTERFACE_LINK_OPTIONS that swiftc doesn't understand.</p>
<p dir="auto">Workaround: Swizzle the flags just after import, for every single imported library.</p>
</li>
</ul>
<p dir="auto">Ladybird issues:</p>
<ul>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2447337585" data-permission-text="Title is private" data-url="https://github.com/LadybirdBrowser/ladybird/issues/965" data-hovercard-type="pull_request" data-hovercard-url="/LadybirdBrowser/ladybird/pull/965/hovercard" href="https://github.com/LadybirdBrowser/ladybird/pull/965">AK+LibGfx: Explicitly spell out headers in the clang module map<span>&nbsp;#965</span></a></span></p>
<p dir="auto">Details: Creating a modulemap for larger libraries can cause issues with libc headers. For example, creating an umbrella directory entry for LibGfx causes issues with <code>&lt;math.h&gt;</code>, which is clearly included in every file that is complaining about it. Needs more module.modulemap massaging to get the clang frontend/swiftc to properly associate system headers with system modules and not our own modules</p>
<p dir="auto">Workaround: ¯\_(ツ)_/¯<br>
Resolution: Generate module maps for each library</p>
</li>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2471629808" data-permission-text="Title is private" data-url="https://github.com/LadybirdBrowser/ladybird/issues/1101" data-hovercard-type="issue" data-hovercard-url="/LadybirdBrowser/ladybird/issues/1101/hovercard" href="https://github.com/LadybirdBrowser/ladybird/issues/1101">Swift: Importing AK and querying type properties crashes swift-frontend in Debug build<span>&nbsp;#1101</span></a></span></p>
<p dir="auto">Details: Building the CxxSequence protocol conformance test for AK containers crashes the swift frontend process in debug mode</p>
<p dir="auto">Workaround: Build in release mode lmao<br>
Upstream bug: Not yet reduced</p>
</li>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2471684633" data-permission-text="Title is private" data-url="https://github.com/LadybirdBrowser/ladybird/issues/1102" data-hovercard-type="issue" data-hovercard-url="/LadybirdBrowser/ladybird/issues/1102/hovercard" href="https://github.com/LadybirdBrowser/ladybird/issues/1102">Swift: Using un-namespaced 'String' type after importing AK crashes swift frontend<span>&nbsp;#1102</span></a></span></p>
<p dir="auto">Details: A function that takes an unnamespaced <code>String</code> argument will crash the swift frontend if <code>AK</code> is imported</p>
<p dir="auto">Workaround: Qualify all references to String as AK.String or Swift.String<br>
Upstream bug: <span><a data-error-text="Failed to load title" data-id="3130478507" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/82108" data-hovercard-type="issue" data-hovercard-url="/swiftlang/swift/issues/82108/hovercard" href="https://github.com/swiftlang/swift/issues/82108">[cxxinterop] UNREACHABLE in AstMangler when mangling C++ type imported via global using declaration<span>&nbsp;swiftlang/swift#82108</span></a></span></p>
</li>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2488554441" data-permission-text="Title is private" data-url="https://github.com/LadybirdBrowser/ladybird/issues/1201" data-hovercard-type="issue" data-hovercard-url="/LadybirdBrowser/ladybird/issues/1201/hovercard" href="https://github.com/LadybirdBrowser/ladybird/issues/1201">Swift: Building AK swift test with Testing module crashes compiler frontend<span>&nbsp;#1201</span></a></span></p>
<p dir="auto">Details: Using swift-testing to test AK container conformance to swift interop protocols crashes the frontend</p>
<p dir="auto">Workaround: Keep custom test runner code<br>
Upstream bug: Not yet reduced</p>
</li>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2633898310" data-permission-text="Title is private" data-url="https://github.com/LadybirdBrowser/ladybird/issues/2168" data-hovercard-type="issue" data-hovercard-url="/LadybirdBrowser/ladybird/issues/2168/hovercard" href="https://github.com/LadybirdBrowser/ladybird/issues/2168">Swift: AK::StringView is no longer a CxxSequenceType on swift/main<span>&nbsp;#2168</span></a></span></p>
<p dir="auto">Details: AK::StringView fails to conform to CxxSequenceType on swift/main</p>
<p dir="auto">Workaround: Reach into the bytesUnsafe() in order to iterate over the bytes of the view as a sequence<br>
Upstream bug: Not yet reduced</p>
</li>
</ul>
<p dir="auto">Nice-to-have:</p>
<ul>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2895111217" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/79767" data-hovercard-type="issue" data-hovercard-url="/swiftlang/swift/issues/79767/hovercard" href="https://github.com/swiftlang/swift/issues/79767">Interop: Application crash when returning <code>Optional&lt;CxxType&gt;</code><span>&nbsp;swiftlang/swift#79767</span></a></span></p>
<p dir="auto">Details: Returning MyCxx.CxxType? from a swift function that is called from C++ crashes on call.</p>
<p dir="auto">Workaround: Return as [MyCxx.CxxType] instead, with a 0 or 1-sized array</p>
</li>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2933646074" data-permission-text="Title is private" data-url="https://github.com/swiftlang/vscode-swift/issues/1449" data-hovercard-type="issue" data-hovercard-url="/swiftlang/vscode-swift/issues/1449/hovercard" href="https://github.com/swiftlang/vscode-swift/issues/1449">Root-level compile_commands.json required for simple CMake projects<span>&nbsp;swiftlang/vscode-swift#1449</span></a></span></p>
<p dir="auto">Details: Top-level compile_commands.json is required for SourceKit-LSP and vscode-swift to grok the project</p>
<p dir="auto">Workaround: Create a symlink <code>ln -s Build/release/compile_commands.json compile_commands.json</code></p>
</li>
<li>
<p dir="auto"> <span><a data-error-text="Failed to load title" data-id="2933293904" data-permission-text="Title is private" data-url="https://github.com/swiftlang/swift/issues/80142" data-hovercard-type="issue" data-hovercard-url="/swiftlang/swift/issues/80142/hovercard" href="https://github.com/swiftlang/swift/issues/80142">Automatically include path to <code>&lt;swift/bridging&gt;</code> in SDK installs<span>&nbsp;swiftlang/swift#80142</span></a></span></p>
<p dir="auto">Details: An extra include path is required to include <code>&lt;swift/bridging&gt;</code> on Linux</p>
<p dir="auto">Workaround: Grab the path from <code>swiftc -print-target-info</code></p>
</li>
</ul>
<p dir="auto">Open questions:</p>
<ul>
<li>
<p dir="auto">Unclear how to pass view types or byte slices to swift without creating a copy.</p>
<ul dir="auto">
<li>We will want to be passing untrusted Strings, or c++-owned Spans of bytes to swift for it to crunch on and return some structured data. It's not clear how to inform swift about this without copying the data (at least) once.</li>
<li><del>I was not able to massage swift into interpreting our String and StringView types as 'CxxConvertibleToContainer' or 'CxxRandomAccessContainer' types. Likely because they are actually immutable?</del></li>
</ul>
</li>
<li>
<p dir="auto">Unclear how to convince Swift that our types are just as good as std:: ones.</p>
<ul dir="auto">
<li>AK::Optional</li>
<li>AK::HashTable/HashMap</li>
<li>AK::Time</li>
<li>more?</li>
</ul>
</li>
<li>
<p dir="auto"> How to integrate with our garbage collector? <a href="https://forums.swift.org/t/ladybird-browser-and-swift-garbage-collection/76084" rel="nofollow">https://forums.swift.org/t/ladybird-browser-and-swift-garbage-collection/76084</a></p>
</li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Martial arts robots at 2026 Spring Festival Gala [video] (127 pts)]]></title>
            <link>https://www.youtube.com/watch?v=mUmlv814aJo</link>
            <guid>47067496</guid>
            <pubDate>Wed, 18 Feb 2026 22:47:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=mUmlv814aJo">https://www.youtube.com/watch?v=mUmlv814aJo</a>, See on <a href="https://news.ycombinator.com/item?id=47067496">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[What years of production-grade concurrency teaches us about building AI agents (117 pts)]]></title>
            <link>https://georgeguimaraes.com/your-agent-orchestrator-is-just-a-bad-clone-of-elixir/</link>
            <guid>47067395</guid>
            <pubDate>Wed, 18 Feb 2026 22:37:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://georgeguimaraes.com/your-agent-orchestrator-is-just-a-bad-clone-of-elixir/">https://georgeguimaraes.com/your-agent-orchestrator-is-just-a-bad-clone-of-elixir/</a>, See on <a href="https://news.ycombinator.com/item?id=47067395">Hacker News</a></p>
Couldn't get https://georgeguimaraes.com/your-agent-orchestrator-is-just-a-bad-clone-of-elixir/: Error: getaddrinfo ENOTFOUND georgeguimaraes.com]]></description>
        </item>
        <item>
            <title><![CDATA[Sizing chaos (763 pts)]]></title>
            <link>https://pudding.cool/2026/02/womens-sizing/</link>
            <guid>47066552</guid>
            <pubDate>Wed, 18 Feb 2026 21:18:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pudding.cool/2026/02/womens-sizing/">https://pudding.cool/2026/02/womens-sizing/</a>, See on <a href="https://news.ycombinator.com/item?id=47066552">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!--[--><!--[--><!----><main id="content"><!----><!---->  <header></header><!----> <div> <h2><p><!--[--><span>m</span><span>e</span><span>e</span><span>t</span><span> </span><span>y</span><span>o</span><span>u</span><span>r</span><span> </span><span>t</span><span>y</span><span>p</span><span>i</span><span>c</span><span>a</span><span>l</span><!--]--><!----></p> <p role="img" aria-label="tween"><!--[--><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/T/T-004.png" alt="t"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/W/W-005.png" alt="w"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/E/E-003.png" alt="e"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/E/E-012.png" alt="e"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/N/N-010.png" alt="n"><!--]--></span><!--]--></p><!----></h2> <p><!---->Like many girls her age, she loves to keep up with the latest fashion trends and explore new ways to express herself. Shopping is fun, but it won’t always be this way.<!----></p> </div><!----> <div><h2><p><!--[--><span>f</span><span>i</span><span>t</span><span> </span><span>4</span><span> </span><span>a</span><!--]--><!----></p> <p role="img" aria-label="teen"><!--[--><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/T/T-016.png" alt="t"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/E/E-002.png" alt="e"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/E/E-011.png" alt="e"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/N/N-015.png" alt="n"><!--]--></span><!--]--></p></h2>  <p><!---->with <a href="https://pudding.cool/author/jan-diehm/">Jan Diehm</a><!----></p> <div><!--[--><p>I remember once being that teen girl shopping in the women’s section for the first time. I took stacks upon stacks of jeans with me to the dressing room, searching in vain for that one pair that fit perfectly. Over 20 years later, my hunt for the ideal pair of jeans continues. But now as an adult, I’m stuck with the countless ways that women’s apparel is not made for the average person, like me.</p><p>Children’s clothing sizes are often tied to a kid’s age or stage of development. The idea is that as a young person grows older, her clothes will evolve with her. Youth styles tend to be boxy and oversized to allow room for kids to move and grow. By early adolescence, apparel for girls becomes more fitted. Junior’s styles have higher waistlines and less-pronounced curves compared to adult clothing lines. In short: clothes for tweens are made for tween bodies.</p><p>By the time most teenage girls can wear women’s clothes — around age 15 — their options are seemingly endless. But the evolution in clothing sizes that followed girls throughout childhood abruptly stops there.</p><p>This is the reality I find myself reckoning with today: Women’s clothing — designed for adults — fits modern teen girls better.</p><!--]--></div></div><!----> <div><!--[!--><!--]--> <!--[--><div><p>Age: 14-15</p> <p>Sizes: Women's</p></div><!--]--> <div id="beeswarm"><!--[--><p>Waistline in Inches</p><!--]--> <svg width="-20" height="-56"><!--[--><g><!--[--><g id="band-XXS" style="transition-delay: 0.75s"><rect style="transition: all var(--ms-500) ease-in-out" x="9.868000000000002" y="0" width="-1.9214999999999982" height="0" fill="#9ABBD9"></rect><text style="transition: all var(--ms-500) ease-in-out" x="8.907250000000003" y="-132" text-anchor="middle">XXS</text></g><g id="band-XS" style="transition-delay: 0.5s"><rect style="transition: all var(--ms-500) ease-in-out" x="7.946500000000004" y="0" width="-2.103500000000002" height="0" fill="#9ABBD9"></rect><text style="transition: all var(--ms-500) ease-in-out" x="6.894750000000003" y="-132" text-anchor="middle">XS</text></g><g id="band-S" style="transition-delay: 0.25s"><rect style="transition: all var(--ms-500) ease-in-out" x="5.843000000000002" y="0" width="-2.4430000000000014" height="0" fill="#9ABBD9"></rect><text style="transition: all var(--ms-500) ease-in-out" x="4.621500000000001" y="-132" text-anchor="middle">S</text></g><g id="band-M" style="transition-delay: 0s"><rect style="transition: all var(--ms-500) ease-in-out" x="3.4000000000000004" y="0" width="-3.325000000000001" height="0" fill="#9ABBD9"></rect><text style="transition: all var(--ms-500) ease-in-out" x="1.7374999999999998" y="-132" text-anchor="middle">M</text></g><g id="band-L" style="transition-delay: 0.25s"><rect style="transition: all var(--ms-500) ease-in-out" x="0.07499999999999929" y="0" width="-5.074999999999999" height="0" fill="#9ABBD9"></rect><text style="transition: all var(--ms-500) ease-in-out" x="-2.4625000000000004" y="-132" text-anchor="middle">L</text></g><g id="band-XL" style="transition-delay: 0.5s"><rect style="transition: all var(--ms-500) ease-in-out" x="-5" y="0" width="-6.125" height="0" fill="#9ABBD9"></rect><text style="transition: all var(--ms-500) ease-in-out" x="-8.0625" y="-132" text-anchor="middle">XL</text></g><g id="band-XXL" style="transition-delay: 0.75s"><rect style="transition: all var(--ms-500) ease-in-out" x="-11.125" y="0" width="-2.9749999999999996" height="0" fill="#9ABBD9"></rect><text style="transition: all var(--ms-500) ease-in-out" x="-12.6125" y="-132" text-anchor="middle">XXL</text></g><!--]--></g><g style="transition: opacity var(--ms-500) ease-in-out"><rect style="transition: all var(--ms-500) ease-in-out" x="0" y="0" width="0" height="0"></rect></g><!--]--><g transform="translate(0, -112)" opacity="1"></g></svg> </div></div><!----> <div><h2><!--[--><span>P</span><span>a</span><span>i</span><span>n</span><span> </span><span>i</span><span>s</span><!--]--><!----> <p role="img" aria-label="universal"><!--[--><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/U/U-008.png" alt="u"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/N/N-019.png" alt="n"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/I/I-020.png" alt="i"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/V/V-018.png" alt="v"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/E/E-013.png" alt="e"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/R/R-010.png" alt="r"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/S/S-014.png" alt="s"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/A/A-009.png" alt="a"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/L/L-010.png" alt="l"><!--]--></span><!--]--></p><!----> <!--[--><span>s</span><span>i</span><span>z</span><span>i</span><span>n</span><span>g</span><span> </span><span>i</span><span>s</span><span> </span><span>n</span><span>o</span><span>t</span><!--]--><!----></h2> <!--[--><p><!---->Few life experiences feel as universal, across generations, as the pains and frustrations of trying to find clothes that fit.<!----></p><p><!---->Sizes vary wildly from store to store. Even within a single apparel company, no one size is consistent. There are no regulations or universal sizing standards. Instead each brand is incentivized to make up its own. When size guides change — and they’re always changing — brands are not obligated to disclose updates.<!----></p><p><!---->There are also often different sizing structures for every type of garment. “Plus” size means one thing, “curve” means another, and “extended” sizes can be defined as all of the above or something else entirely. Don’t count on any of those sizes to be available to try on in-store, but do brace for return fees if your online order doesn’t fit. Free in-store alterations are largely a thing of the past, while a trip to the tailor’s can cost just as much as the item itself.<!----></p><p><!---->The only consistent feature is that the industry at large continues to cling onto the same underlying sizing system that’s been broken for decades. And it’s only gotten worse.<!----></p><!--]--></div><!----> <div><h2><!--[--><span>T</span><span>h</span><span>e</span><span> </span><span>v</span><span>i</span><span>l</span><span>l</span><span>a</span><span>i</span><span>n</span><span> </span><span>a</span><span>r</span><span>c</span><span> </span><span>o</span><span>f</span><!--]--><!----> <p role="img" aria-label="vanity"><!--[--><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/V/V-003.png" alt="v"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/A/A-002.png" alt="a"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/N/N-013.png" alt="n"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/I/I-018.png" alt="i"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/T/T-002.png" alt="t"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/Y/Y-007.png" alt="y"><!--]--></span><!--]--></p><!----> <p role="img" aria-label="sizing"><!--[--><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/S/S-008.png" alt="s"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/I/I-008.png" alt="i"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/Z/Z-001.png" alt="z"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/I/I-006.png" alt="i"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/N/N-005.png" alt="n"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/G/G-017.png" alt="g"><!--]--></span><!--]--></p><!----></h2> <!--[--><p><!---->On top of all these problems, consumers often know the labels for any given size cannot be trusted.<!----></p><p><!---->Vanity sizing, the practice where size labels stay the same even as the underlying measurements frequently become larger, is so ubiquitous across the fashion and apparel industry that younger generations have never experienced a world without it.<!----></p><p><!---->Cultural narratives around vanity sizing often square the blame on female shoppers, not brands. <a href="https://www.newsweek.com/fashion-designers-introduce-less-zero-sizes-112005"><i>Newsweek</i></a> once called it “self-delusion on a mass scale” because women were more likely to buy items that were labeled as sizes smaller than reality. But there’s more to the story.<!----></p><p><!---->Vanity sizing provides a powerful <a href="https://www.sciencedirect.com/science/article/abs/pii/S1057740813000612">marketing strategy</a> for brands. Companies found that whenever women needed a size larger than expected, they were less likely to follow through on their purchases. Some could even develop negative associations with the brand and never shop there again. But when manufacturers manipulated sizing labels, leading to a more positive customer experience, brands could maintain a slight competitive edge.<!----></p><p><!---->The dynamic perpetuates an arms race toward artificially deflating size labels. Most shoppers aren’t even aware when size charts change, or by how much. If anything, vanity sizing consistently gaslights women to the point where few are able to know their “true” size. But where would we be today without it?<!----></p><!--]--></div><!----> <div><h2><p role="img" aria-label="sew"><!--[--><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/S/S-007.png" alt="s"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/E/E-012.png" alt="e"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/W/W-009.png" alt="w"><!--]--></span><!--]--></p> <p role="img" aria-label="what?"><!--[--><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/W/W-017.png" alt="w"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/H/H-005.png" alt="h"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/A/A-004.png" alt="a"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/T/T-009.png" alt="t"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/specialChars/question-001.png" alt="?"><!--]--></span><!--]--></p></h2> <div><!--[--><p><!---->I once believed that change was inevitable and sizing problems would become a relic of the past. If it wasn’t some scrappy upstart that promised to revolutionize the sizing system, then at least the major fashion conglomerates would be well-placed to modernize and tap the full potential of the plus-size market. But that progress never fully materialized. And I got tired of waiting.<!----></p> <!--[!--><!--]--> <!--[!--><!--]--> <!--[!--><!--]--><p><!---->A few years ago, I started learning how to sew. Somehow it felt more practical to make my own clothes than count on meaningful change to happen on its own. Getting started was easier than I thought. The first sewing pattern I ever completed — a boxy, drop-shoulder style that could turn into either a shirt or dress — was free to download. It included a 29-page instruction manual with photos and illustrations documenting every step.<!----></p> <!--[--><div><p><img src="https://pudding.cool/2026/02/womens-sizing/assets/patternmaking.jpg" alt="a sketch of a bodice block on grid paper with a ruler and notebook"></p><p>Drafting a custom pattern based on my body measurements and proportions</p></div><!--]--> <!--[!--><!--]--> <!--[!--><!--]--><p><!---->From there, I started learning how to draft my own sewing patterns from scratch. That’s when I realized the truth behind my sizing struggles: Clothing sizes are optimized for mass production and appeal — not women’s bodies. Nothing represents this more than a size 8.<!----></p> <!--[!--><!--]--> <!--[!--><!--]--> <!--[!--><!--]--><p><!---->Fashion designers often use body measurements for a <span>size 8</span> as a starting point when creating new design samples. Manufacturers then use a mathematical formula to determine each next size up or down the range in a process called grading. The effect is like a Russian doll. Each size up is incrementally larger than the last.<!----></p> <!--[!--><!--]--> <!--[--><!--]--> <!--[!--><!--]--><p><!---->The uniform shape makes it easier for factories to mass-produce garments, however it comes with several tradeoffs. It’s hard to scale up to larger-sized clothing before the proportions become distorted. It also becomes impractical to make multiple versions of a single item to accommodate varying body shapes or heights. That means most women’s clothing is derived from a single set of proportions — a size 8. According to U.S. health data, fewer than 10% of adult women have waistlines that fit the standard sample size or smaller.<!----></p> <!--[!--><!--]--> <!--[!--><!--]--> <!--[!--><!--]--><p><!---->I, like the vast majority of women, do not fit the standard mold. Instead I took an old pattern-making textbook often taught in fashion design schools to start making clothes to fit my own unique proportions. I gathered and recorded over 58 different body measurements in order to get started and from there, I could make my own <span>custom base pattern,</span> known as a bodice block or sloper.<!----></p> <!--[!--><!--]--> <!--[!--><!--]--> <!--[--><!--]--><p><!---->Once I compared my personalized sloper to commercial patterns and retail garments, I had a revelation: clothes were never made to fit bodies like mine. It didn’t matter how much weight I gained or lost, whether I contorted my body or tried to buy my way into styles that “flatter” my silhouette, there was no chance that clothes would ever fit perfectly on their own. Finally I understood why.<!----></p> <!--[!--><!--]--> <!--[!--><!--]--> <!--[!--><!--]--><!--]--></div></div><!----> <!----> <div><h2><p><!--[--><span>s</span><span>i</span><span>z</span><span>i</span><span>n</span><span>g</span><span> </span><span>f</span><span>o</span><span>r</span><!--]--><!----></p> <p role="img" aria-label="every"><!--[--><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/E/E-018.png" alt="e"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/V/V-009.png" alt="v"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/E/E-009.png" alt="e"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/R/R-005.png" alt="r"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/Y/Y-001.png" alt="y"><!--]--></span><!--]--></p> <p role="img" aria-label="body"><!--[--><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/B/B-018.png" alt="b"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/O/O-002.png" alt="o"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/D/D-006.png" alt="d"><!--]--></span><span><!--[--><img src="https://pudding.cool/2026/02/womens-sizing/assets/letters/png_letters/Y/Y-002.png" alt="y"><!--]--></span><!--]--></p></h2> <div><!--[--><p><!---->The fashion industry thrives on exclusivity. Luxury brands maintain their status by limiting who is able to buy or even wear their clothes. If few women fit the “ideal” standards, then products serving only them are inherently exclusionary. Size charts become the de facto dividing line determining who belongs and who doesn’t.<!----></p><p><!---->This line of gatekeeping is baked into the foundation of virtually all clothing. The modern sizing system in the U.S. was <a href="https://archive.org/details/womensmeasuremen454obri/mode/2up">developed in the 1940s</a> based on mostly young, white women. No women of color were originally included. The system was never built to include a diverse cross-section of people, ages, or body types. It has largely stayed that way by design.<!----></p><p><!---->In its 1995 standards update, ASTM International admitted that its sizing guidelines were never meant to represent the population at large. Instead body measurements were based on “designer experience” and “market observations.” The goal was to tailor sizes to the existing customer base. But what happens when more than half of all women are pushed to the margins or left behind?<!----></p><p><!---->It doesn’t have to be this way. Teenage girls shouldn’t be aging out of sizing options from the moment they start wearing women’s clothes. A woman does not need hourglass proportions to look good, just as garment-makers do not need standardized sizes to produce well-fitting clothes.<!----></p><p><!---->There are no rules forcing brands to adopt any particular sizing system. There is no such thing as a “true” size 8, or any size for that matter. If brands are constantly developing and customizing their size charts, then it makes little sense to perpetuate a broken system. Sizes are all made up anyway — why can’t we make them better?<!----></p><!--]--></div></div><!----> <div><h4>Methodology</h4> <div><!--[--><p><!---->To highlight the median body proportions of the adult women in the U.S., we relied on anthropometric reference data for children and adults that is regularly released by the National Center for Health Statistics within the U.S. Department of Health and Human Services.<!----></p><p><!---->For this story, we pulled data on the median waistline circumference of women and girls that was <a href="https://stacks.cdc.gov/view/cdc/174595">gathered between 2021-2023</a>. For girls and women under 20 years old, measurements were recorded in two-year age ranges (ex: 10–11 years, 14–15 years), with a median of 141 participants per age range. For women over 20, measurements were recorded in nine-year age ranges (ex: 20–29 years, 30–39 years) and collectively for all women 20 and older. Each nine-year age range had a median of 465 participants. Overall, measurements were recorded for 3,121 women ages 20 and older.  Those who were pregnant were excluded from the data.<!----></p><p><!---->HHS also provides a breakdown of measurements within set percentiles for each age range, which includes figures for the 5th, 10th, 15th, 25th, 50th, 75th, 85th, 90th, and 95th percentiles. We then used that percentile data to extrapolate the waistline measurements of all women and girls within each respective age group.<!----></p><p><!---->We also compared figures to those recorded by HHS from <a href="https://www.cdc.gov/nchs/data/series/sr_11/sr11_249.pdf">1988-1994</a>. There, 7,410 women ages 20 and older participated in the study. Measurements were originally recorded in centimeters, so we converted to inches.<!----></p><p><!---->Brands included in the size chart comparisons represent a diverse cross-section of popular apparel brands and retailers in the U.S., including a mix of mass market, fast fashion, premium and luxury labels.<!----></p><p><!---->For each brand, we focused on collecting body measurements for “regular” or “standard” size ranges, as well as “plus” sizes when available. Sizing information for “petite,” “tall,” or “curve” clothing lines were not included. Size charts reflect the body measurements for garments categorized as general “apparel.” In a select few cases where that category was unavailable, “dresses” were used as the default garment type.<!----></p><p><!---->Within each size range, we focused on collecting three main body measurements: Bust, waist, and hip. Some were presented as a range from minimum to maximum values, while others were single measurements. All numeric U.S. women’s sizing labels and descriptions were recorded, as well as their corresponding alpha sizes, when available.<!----></p><p><!---->Size chart data was last manually captured in July 2025 and may not reflect a brand’s current size chart. Brands frequently change their size charts, and more often than not, shoppers aren’t even aware when measurements or sizes are updated.<!----></p><p><!---->The standardized size charts refer to ASTM International’s regular release of its Standard Table of Measurements for Adult Female Misses Figure Type. The 1995 release (designated as D 5585-95) reflects sizes 2-20. ASTM updated its standards in 2021 (designated as <a href="https://store.astm.org/d5585-21.html">D5585-21</a>) to include sizes 00-20.<!----></p><p><!---->Ransom note letters are from <a href="https://indieground.net/product/ransom-note-letters/">Indieground.</a><!----></p><!--]--></div> <h4>Related pieces</h4> </div><!----> <!--[--><!--]--><!----><!----><!----></main><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[27-year-old Apple iBooks can connect to Wi-Fi and download official updates (417 pts)]]></title>
            <link>https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/</link>
            <guid>47066241</guid>
            <pubDate>Wed, 18 Feb 2026 20:54:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/">https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/</a>, See on <a href="https://news.ycombinator.com/item?id=47066241">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="siteTable_t3_1r8900z"><div id="thing_t1_o64bigf" onclick="click_thing(this)" data-fullname="t1_o64bigf" data-type="comment" data-gildings="0" data-subreddit="MacOS" data-subreddit-prefixed="r/MacOS" data-subreddit-fullname="t5_2s2gv" data-subreddit-type="public" data-author="Augustisimus" data-author-fullname="t2_48cjitb4" data-replies="0" data-permalink="/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o64bigf/"><p>[–]<a href="https://old.reddit.com/user/Augustisimus">Augustisimus</a><span title="iMac"><span>iMac</span></span><span></span> <span title="12">12 points</span><span title="13">13 points</span><span title="14">14 points</span> <time title="Wed Feb 18 20:32:54 2026 UTC" datetime="2026-02-18T20:32:54+00:00">4 hours ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_o64bigfv20"><div><p>Apple has gone through phases.</p>

<p>During the 2010s they were definitely operating under a planned obsolescence model. Updates were designed to put additional stress on older hardware.</p>

<p>Now, in the 2020s, this is less of a concern, because services, not hardware, is their primary business model. It doesn’t matter if you have a ten year old Intel MacBook, as long as you’re subscribed to Apple One.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o64bigf/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li>report</li><li>reply</li></ul></div><div id="thing_t1_o636snm" onclick="click_thing(this)" data-fullname="t1_o636snm" data-type="comment" data-gildings="0" data-subreddit="MacOS" data-subreddit-prefixed="r/MacOS" data-subreddit-fullname="t5_2s2gv" data-subreddit-type="public" data-author="Romengar" data-author-fullname="t2_yyryv" data-replies="0" data-permalink="/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o636snm/"><p>[–]<a href="https://old.reddit.com/user/FantasicMouse">FantasicMouse</a><span></span> <span title="4">4 points</span><span title="5">5 points</span><span title="6">6 points</span> <time title="Wed Feb 18 18:09:41 2026 UTC" datetime="2026-02-18T18:09:41+00:00">7 hours ago</time>&nbsp;(5 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_o63fyoxpip"><div><p>I belive xp servers are still online or atleast they were two years ago. I think last I touched win 98 I had to manually install updates from an installer disk… god it’s been so long ago but I think 98 you had to do that anyway…</p>

<p>As of 5 years ago I know xp and 98 se where still hosted on Microsoft’s servers and I’d say xp would be the equivalent to this version of macOS</p>

<p>I’ll say though that PPC Mac’s do a lot better than win xp machines if you’re trying to actually use them in today’s age</p>
</div></form><ul><li><a href="https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o63fyox/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#o63cwlx" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div><div id="thing_t1_o6350ic" onclick="click_thing(this)" data-fullname="t1_o6350ic" data-type="comment" data-gildings="0" data-subreddit="MacOS" data-subreddit-prefixed="r/MacOS" data-subreddit-fullname="t5_2s2gv" data-subreddit-type="public" data-author="Druben-hinterm-Dorfe" data-author-fullname="t2_iqo95lm4s" data-replies="0" data-permalink="/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o6350ic/"><div id="thing_t1_o637ocx" onclick="click_thing(this)" data-fullname="t1_o637ocx" data-type="comment" data-gildings="0" data-subreddit="MacOS" data-subreddit-prefixed="r/MacOS" data-subreddit-fullname="t5_2s2gv" data-subreddit-type="public" data-author="Reasonable_Draft1634" data-author-fullname="t2_g16p4747" data-replies="0" data-permalink="/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o637ocx/"><p>[–]<a href="https://old.reddit.com/user/Reasonable_Draft1634">Reasonable_Draft1634</a><span></span> <span title="43">43 points</span><span title="44">44 points</span><span title="45">45 points</span> <time title="Wed Feb 18 17:33:03 2026 UTC" datetime="2026-02-18T17:33:03+00:00">7 hours ago</time>&nbsp;(12 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_o637ocxrpq"><div><p>How is that “planned obsolesce”, exactly? Modern websites rely on technologies that simply didn’t exist 20 years ago. ECMAScript 6+ (ES2015 and beyond). Advanced CSS (Grid, Flexbox, container queriesModern TLS encryption (TLS 1.2 / 1.3), WebAssemblyAdvanced GPU acceleration APIs, etc. </p>

<p>Webkit must implement these standards to stay compatible. Those systems were designed long before modern JavaScript engines and security models. How about all the hardware limitations? </p>

<p>It is incredible to me the twisted arguments folks still go with and try to convince us it is a thing.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o637ocx/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#o6350ic" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div><div id="thing_t1_o63q55p" onclick="click_thing(this)" data-fullname="t1_o63q55p" data-type="comment" data-gildings="0" data-subreddit="MacOS" data-subreddit-prefixed="r/MacOS" data-subreddit-fullname="t5_2s2gv" data-subreddit-type="public" data-author="I-figured-it-out" data-author-fullname="t2_co2mkgj6" data-replies="0" data-permalink="/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o63q55p/"><p>[–]<a href="https://old.reddit.com/user/I-figured-it-out">I-figured-it-out</a><span></span> <span title="1">1 point</span><span title="2">2 points</span><span title="3">3 points</span> <time title="Wed Feb 18 18:53:59 2026 UTC" datetime="2026-02-18T18:53:59+00:00">6 hours ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_o63q55pv7o"><div><p>Try using modern  Safari to download and render mission critical content from a 5 year old website built and hosted by a curmudgeon on an XP server… . If it was hosted on a G4 it would have a solid unix backend, running a reliable apache server that can likely to have been updated to be reasonably secure, if not fast.</p>

<p>Once upon a time in the late 1990s IBM corporate had an email server that reached its client limits, unattended forgotten in a closet as the company grew. The server had been unattended and unmaintained other than by remote access. 
IBM’s email demands grew enourmously during thst time of corporate expansion when email had been adopted as a norm (displacing fax) and from hundreds of users to tens of thousands. They decided to upgrade the server hardware. When they eventually found it they were dismayed to discover a dust covered 128k Mac from 1984 chugging away doing a job that was considered far too heavy for IBM’s mid -late1990s consumer line of computers.  </p>

<p>Story goes, so they decided in retrospect- to replace the 128K Mac, not as planned -with the heavy iron servers that IBM sold it’s corporate customers, but with a nice shiny new iMac.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o63q55p/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#o6350ic" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div></div><div id="thing_t1_o639gms" onclick="click_thing(this)" data-fullname="t1_o639gms" data-type="comment" data-gildings="0" data-subreddit="MacOS" data-subreddit-prefixed="r/MacOS" data-subreddit-fullname="t5_2s2gv" data-subreddit-type="public" data-author="PoppaFish" data-author-fullname="t2_mkyqku" data-replies="0" data-permalink="/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o639gms/"><p>[–]<a href="https://old.reddit.com/user/Cockur">Cockur</a><span></span> <span title="0">0 points</span><span title="1">1 point</span><span title="2">2 points</span> <time title="Wed Feb 18 19:04:26 2026 UTC" datetime="2026-02-18T19:04:26+00:00">6 hours ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_o63sh84jag"><div><p>You could run a bunch of old daws and music making software like samplers or trackers. You could use it for sequencing any old midi gear too</p>

<p>Lots of folk out there running old platforms specifically for this reason </p>

<p>If you can think of a good reason to use it then it’s useful</p>
</div></form><ul><li><a href="https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o63sh84/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#o639gms" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div><div id="thing_t1_o63r36n" onclick="click_thing(this)" data-fullname="t1_o63r36n" data-type="comment" data-gildings="0" data-subreddit="MacOS" data-subreddit-prefixed="r/MacOS" data-subreddit-fullname="t5_2s2gv" data-subreddit-type="public" data-author="DjNormal" data-author-fullname="t2_mfe7c" data-replies="0" data-permalink="/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o63r36n/"><p>[–]<a href="https://old.reddit.com/user/DjNormal">DjNormal</a><span></span> <span title="3">3 points</span><span title="4">4 points</span><span title="5">5 points</span> <time title="Wed Feb 18 18:58:09 2026 UTC" datetime="2026-02-18T18:58:09+00:00">6 hours ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_o63r36n03y"><div><p>Meanwhile I can <em>never</em> reinstall Office 2010 for my mom, because Microsoft shut down their authentication servers.</p>

<p>I got her over to Libre Office, but it’s a little clunky and just enough different that she struggles with it.</p>

<p>On my end, my 2010 MBP is still the best DJ computer I have. My legacy outboard gear still works and despite having a dead battery, the MBP still runs great (on Sierra). I have it an SSD back in 2017 and it felt like a new machine again… for a while.</p>

<p>We’ve still got stuff at old as the Apple ][+ lying around, still functioning. I have few complaints.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o63r36n/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li>report</li><li>reply</li></ul></div><div id="thing_t1_o63b47a" onclick="click_thing(this)" data-fullname="t1_o63b47a" data-type="comment" data-gildings="0" data-subreddit="MacOS" data-subreddit-prefixed="r/MacOS" data-subreddit-fullname="t5_2s2gv" data-subreddit-type="public" data-author="Device_whisperer" data-author-fullname="t2_73aimw16" data-replies="0" data-permalink="/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o63b47a/"><p>[–]<a href="https://old.reddit.com/user/Device_whisperer">Device_whisperer</a><span></span> <span title="0">0 points</span><span title="1">1 point</span><span title="2">2 points</span> <time title="Wed Feb 18 20:39:47 2026 UTC" datetime="2026-02-18T20:39:47+00:00">4 hours ago</time>&nbsp;(1 child)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_o64cycxm3t"><div><p>There are still a number of things that MacOS can't do correctly. Simple things. Basic things. They still cling to obsolete file system protocols (AFP) and can't maintain sync with industry-standard SMB shares. Most of the damn time, it won't let you delete anything without a confirmation, with no means to turn it off.   </p>

<p>Their screen graphics are a CPA. I have the 5K screen, and there IS NO setting that makes the text look good. They are either way too small, or they must be scaled, which affects the whole damn display. Yeah, I have a 5K screen that only looks good in 1080P. Why bother?</p>

<p>I don't know about you, but I couldn't care less about a 27-year-old book that I'm not going to read ever again.  I'd rather have today's files present and available.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o64cycx/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#o63inf1" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div><div id="thing_t1_o6373xt" onclick="click_thing(this)" data-fullname="t1_o6373xt" data-type="comment" data-gildings="0" data-subreddit="MacOS" data-subreddit-prefixed="r/MacOS" data-subreddit-fullname="t5_2s2gv" data-subreddit-type="public" data-author="IAmABoredCat1590" data-author-fullname="t2_ieq2gmtw" data-replies="0" data-permalink="/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o6373xt/"><p>[–]<a href="https://old.reddit.com/user/IAmABoredCat1590">IAmABoredCat1590</a><span title="MacBook Pro (Intel)"><span>MacBook Pro (Intel)</span></span><span></span> <span title="1">1 point</span><span title="2">2 points</span><span title="3">3 points</span> <time title="Wed Feb 18 17:30:28 2026 UTC" datetime="2026-02-18T17:30:28+00:00">7 hours ago</time>&nbsp;(1 child)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_o6373xt0ys"><div><p>…Windows 7 can do that too…</p>

<p>As soon as you connect to the network and refresh the updates, it downloads the latest Windows build for that version and installs it because it fetches stuff from an archived server that’s still being held up by apple.</p>

<p>In your case, it did the sage thing. Fetch the update from the maintained server.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o6373xt/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li>report</li><li>reply</li></ul></div><div id="thing_t1_o65jluk" onclick="click_thing(this)" data-fullname="t1_o65jluk" data-type="comment" data-gildings="0" data-subreddit="MacOS" data-subreddit-prefixed="r/MacOS" data-subreddit-fullname="t5_2s2gv" data-subreddit-type="public" data-author="felixding" data-author-fullname="t2_46rdp" data-replies="0" data-permalink="/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o65jluk/"><p>[–]<a href="https://old.reddit.com/user/felixding">felixding</a><span></span> <span title="this subreddit hides comment scores for 120 minutes">[score hidden]</span> <time title="Thu Feb 19 00:54:13 2026 UTC" datetime="2026-02-19T00:54:13+00:00">35 minutes ago</time>&nbsp;(0 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_o65rnnksyw"><div><p>I'm in the Discord.</p>

<p>Trust me, I really have done my homework.</p>

<ul>
<li>I keep searching with various keywords on Reddit, Hacker News, X, Google, OS News, GitHub, Distro Watch, *-look.org...</li>
<li>I follow almost all the recreation attempts on GitHub (e.g. OS X Lion theme for xfce, NEXTSPACE, Gershwin...)</li>
<li>I keep a 2013 MBP just to use Marvericks and Flavours, and a iMac G4 to use Tiger.</li>
<li>I have VMs of Mac OS 9, Jaguar, etc, on my MBP M2</li>
</ul>

<p>The list could go on but the point is I really tried.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o65rnnk/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#o65l9mp" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div><div id="thing_t1_o63dh91" onclick="click_thing(this)" data-fullname="t1_o63dh91" data-type="comment" data-gildings="0" data-subreddit="MacOS" data-subreddit-prefixed="r/MacOS" data-subreddit-fullname="t5_2s2gv" data-subreddit-type="public" data-author="springlord" data-author-fullname="t2_sxw8b" data-replies="0" data-permalink="/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o63dh91/"><p>[–]<a href="https://old.reddit.com/user/springlord">springlord</a><span></span> <span title="0">0 points</span><span title="1">1 point</span><span title="2">2 points</span> <time title="Wed Feb 18 19:33:05 2026 UTC" datetime="2026-02-18T19:33:05+00:00">5 hours ago</time>&nbsp;(1 child)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_o63ypgardg"><div><p>Man I used to be a fanboy too but at some point you need to drop it in name of intellectual honesty if you want to make a remotely valid point.</p>

<p>The G4 was an very high end CPU, in perfs and in price, so if you want to make silly comparisons in 2003 it was rather competing with the Xeon line, not with P3.</p>

<p>And even then, your post actually underlines the very definition of planned obsolescence, the PowerPC architecture was intentionally killed by Apple despite excellent hardware when on the contrary it is indeed still possible to build and find maintained software for old x86 systems.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/MacOS/comments/1r8900z/macos_which_officially_supports_27_year_old/o63ypga/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li><a href="#o63g8tc" data-event-action="parent" rel="nofollow">parent</a></li><li>report</li><li>reply</li></ul></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[There is unequivocal evidence that Earth is warming (2024) (216 pts)]]></title>
            <link>https://science.nasa.gov/climate-change/evidence/</link>
            <guid>47065678</guid>
            <pubDate>Wed, 18 Feb 2026 20:09:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://science.nasa.gov/climate-change/evidence/">https://science.nasa.gov/climate-change/evidence/</a>, See on <a href="https://news.ycombinator.com/item?id=47065678">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primary">

	<article id="post-275202"><div>






<h3>Takeaways</h3>



<ul>
<li>While Earth’s climate <a href="https://www.climate.gov/maps-data/climate-data-primer/past-climate">has changed throughout its history</a>, the current warming is happening at a rate not seen in the past 10,000 years.</li>



<li>According to the Intergovernmental Panel on Climate Change (<a href="https://www.ipcc.ch/">IPCC</a>), "Since systematic scientific assessments began in the 1970s, the influence of human activity on the warming of the climate system has evolved from theory to established fact."<a href="#footnote_1"><sup>1</sup></a></li>



<li>Scientific information taken from natural sources (such as ice cores, rocks, and tree rings) and from modern equipment (like satellites and instruments) all show the signs of a changing climate.</li>



<li>From global temperature rise to melting ice sheets, the evidence of a warming planet abounds.</li>
</ul>



<h2>The rate of change since the mid-20th century is unprecedented over millennia.</h2>



<p>Earth's climate has changed throughout history. Just in the last 800,000 years, there have been eight cycles of ice ages and warmer periods, with the end of the last ice age about 11,700 years ago marking the beginning of the modern climate era — and of human civilization. Most of these climate changes are attributed to <a href="http://climate.nasa.gov/blog/2949/why-milankovitch-orbital-cycles-cant-explain-earths-current-warming/">very small variations in Earth’s orbit</a> that change the amount of solar energy our planet receives.</p>





<p>The current warming trend is different because it is clearly the result of human activities since the mid-1800s, and is proceeding at a rate not seen over many recent millennia.<sup><a href="#footnote_1">1</a></sup> It is undeniable that human activities have produced the atmospheric gases that have trapped more of the Sun’s energy in the Earth system. This extra energy has warmed the atmosphere, ocean, and land, and widespread and rapid changes in the atmosphere, ocean, cryosphere, and biosphere have occurred.</p>





<p>Earth-orbiting satellites and new technologies have helped scientists see the big picture, collecting many different types of information about our planet and its climate all over the world. These data, collected over many years, reveal the signs and patterns of a changing climate.</p>



<p>Scientists demonstrated the heat-trapping nature of carbon dioxide and other gases in the mid-19th century.<a href="#footnote_2"><sup>2</sup></a> Many of the science instruments NASA uses to study our climate focus on how these gases affect the movement of infrared radiation through the atmosphere. From the measured impacts of increases in these gases, there is no question that increased greenhouse gas levels warm Earth in response.</p>


<div id="">
						<p>Intergovernmental Panel on Climate Change</p>
						
					</div>


<p>Ice cores drawn from Greenland, Antarctica, and tropical mountain glaciers show that Earth’s climate responds to changes in greenhouse gas levels. Ancient evidence can also be found in tree rings, ocean sediments, coral reefs, and layers of sedimentary rocks. This ancient, or paleoclimate, evidence reveals that current warming is occurring roughly 10 times faster than the average rate of warming after an ice age. Carbon dioxide from human activities is increasing about 250 times faster than it did from natural sources after the last Ice Age.<a href="#footnote_3"><sup>3</sup></a></p>


<div id="">
			<h2>The Evidence for Rapid Climate Change Is Compelling:</h2>

			<div>

					<ul>
						
						<li>

							<div>

										<h3>Global Temperature Is Rising</h3>
										<div><p>
											The planet's average surface temperature has risen about 2 degrees Fahrenheit (1 degrees Celsius) since the late 19th century, a change driven largely by increased carbon dioxide emissions into the atmosphere and other human activities.<sup><a href="#footnote_4">4</a></sup> Most of the warming occurred in the past 40 years, with the seven most recent years being the warmest. The years 2016 and 2020 are tied for the warmest year on record.<sup><a href="#footnote_5">5</a></sup></p><p><em><sub>Image credit: Ashwin Kumar, Creative Commons Attribution-Share Alike 2.0 Generic.</sub></em></p></div>

										
									</div>

														
							
						</li>
													
						<li>

							<div>

										<h3>The Ocean Is Getting Warmer</h3>
										<div><p>
											The ocean has absorbed much of this increased heat, with the top 100 meters (about 328 feet) of ocean showing warming of 0.67 degrees Fahrenheit (0.33 degrees Celsius) since 1969.<sup><a href="#footnote_6">6</a></sup> Earth stores 90% of the extra energy in the ocean.</p><p><em><sub>Image credit: Kelsey Roberts/USGS</sub></em></p></div>

										
									</div>

														
							
						</li>
													
						<li>

							<div>

										<h3>The Ice Sheets Are Shrinking</h3>
										<div><p>
											The Greenland and Antarctic ice sheets have decreased in mass. Data from NASA's Gravity Recovery and Climate Experiment show Greenland lost an average of 279 billion tons of ice per year between 1993 and 2019, while Antarctica lost about 148 billion tons of ice per year.<sup><a href="https://science.nasa.gov/wp-admin/post.php?post=275202&amp;action=edit#footnote_7">7</a></sup></p><p><em><sub>Image: The Antarctic Peninsula, Credit: NASA</sub></em></p></div>

										
									</div>

														
							
						</li>
													
						<li>

							<div>

										<h3>Glaciers Are Retreating</h3>
										<div><p>
											Glaciers are retreating almost everywhere around the world — including in the Alps, Himalayas, Andes, Rockies, Alaska, and Africa.<sup><a href="https://science.nasa.gov/wp-admin/post.php?post=275202&amp;action=edit#footnote_8">8</a></sup></p><p><em><sub>Image: Miles Glacier, Alaska Image credit: NASA</sub></em></p></div>

										
									</div>

														
							
						</li>
													
						<li>

							<div>

										<h3>Snow Cover Is Decreasing</h3>
										<div><p>
											Satellite observations reveal that the amount of spring snow cover in the Northern Hemisphere has decreased over the past five decades and the snow is melting earlier.<sup><a href="#footnote_9">9</a></sup></p><p><em><sub>Image credit: NASA/JPL-Caltech</sub></em></p></div>

										
									</div>

														
							
						</li>
													
						<li>

							<div>

										<h3>Sea Level Is Rising</h3>
										<div><p>
											Global sea level rose about 8 inches (20 centimeters) in the last century. The rate in the last two decades, however, is nearly double that of the last century and accelerating slightly every year.<sup><a href="https://science.nasa.gov/wp-admin/post.php?post=275202&amp;action=edit#footnote_10">10</a></sup></p><p><em><sub>Image credit: U.S. Army Corps of Engineers Norfolk District</sub></em></p></div>

										
									</div>

														
							
						</li>
													
						<li>

							<div>

										<h3>Arctic Sea Ice Is Declining</h3>
										<div><p>
											Both the extent and thickness of Arctic sea ice has declined rapidly over the last several decades.<sup><a href="https://science.nasa.gov/wp-admin/post.php?post=275202&amp;action=edit#footnote_11">11</a></sup></p><p><em><sub>Credit: NASA's Scientific Visualization Studio</sub></em></p></div>

										
									</div>

														
							
						</li>
													
						<li>

							<div>

										<h3>Extreme Events Are Increasing in Frequency</h3>
										<div><p>
											The number of record high temperature events in the United States has been increasing, while the number of record low temperature events has been decreasing, since 1950. The U.S. has also witnessed increasing numbers of intense rainfall events.<sup><a href="https://science.nasa.gov/wp-admin/post.php?post=275202&amp;action=edit#footnote_12">12</a></sup></p><p><em><sub>Image credit: Régine Fabri,&nbsp;<a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>, via Wikimedia Commons</sub></em></p></div>

										
									</div>

														
							
						</li>
													
						<li>

							<div>

										<h3>Ocean Acidification Is Increasing</h3>
										<div><p>
											Since the beginning of the Industrial Revolution, the acidity of surface ocean waters has increased by about 30%.<sup><a href="#footnote_13">13</a>, <a href="#footnote_14">14</a></sup> This increase is due to humans emitting more carbon dioxide into the atmosphere and hence more being absorbed into the ocean. The ocean has absorbed between 20% and 30% of total anthropogenic carbon dioxide emissions in recent decades (7.2 to 10.8 billion metric tons per year).<sup>1<a href="#footnote_15">5</a>, <a href="#footnote_16">16</a></sup></p><p><em><sub>Image credit: NOAA</sub></em></p></div>

										
									</div>

														
							
						</li>
													
					</ul>
				</div>

		</div>


<h3>References</h3>











<p id="footnote_3"><strong>3.</strong> <a href="https://www.ipcc.ch/report/ar6/wg1/downloads/report/IPCC_AR6_WGI_Chapter02.pdf">IPCC Sixth Assessment Report, WG1, Chapter 2</a><br>Vostok ice core data; NOAA Mauna Loa CO2 record<br>O. Gaffney, W. Steffen, "The Anthropocene Equation." <i>The Anthropocene Review</i> 4, issue 1 (April 2017): 53-61. https://doi.org/abs/10.1177/2053019616688022. </p>



<p id="footnote_4"><strong>4.</strong> <a href="https://www.ncei.noaa.gov/monitoring" target="_blank" rel="noopener">https://www.ncei.noaa.gov/monitoring</a><br> <a href="https://crudata.uea.ac.uk/cru/data/temperature/" target="_blank" rel="noopener">https://crudata.uea.ac.uk/cru/data/temperature/</a><br> <a href="http://data.giss.nasa.gov/gistemp" target="_blank" rel="noopener">http://data.giss.nasa.gov/gistemp</a> </p>



<p id="footnote_5"><strong>5.</strong> <a href="https://www.giss.nasa.gov/research/news/20170118/" target="_blank" rel="noopener">https://www.giss.nasa.gov/research/news/20170118/</a> </p>







<p id="footnote_7"><strong>7.</strong> I. Velicogna, Yara Mohajerani, A. Geruo, F. Landerer, J. Mouginot, B. Noel, E. Rignot,  T. Sutterly, M. van den Broeke, M. Wessem, D. Wiese, "Continuity of Ice Sheet Mass Loss in Greenland and Antarctica From the GRACE and GRACE Follow-On Missions." <i>Geophysical Research Letters</i> 47, Issue 8 (28 April 2020): e2020GL087291. https://doi.org/10.1029/2020GL087291. </p>



<p id="footnote_8"><strong>8.</strong> <a href="http://nsidc.org/sotc/glacier_balance.html" target="_blank" rel="noopener">National Snow and Ice Data Center</a> <br><a href="http://wgms.ch/" target="_blank" rel="noopener">World Glacier Monitoring Service</a> </p>



<p id="footnote_9"><strong>9.</strong> <a href="http://nsidc.org/cryosphere/sotc/snow_extent.html" target="_blank" rel="noopener">National Snow and Ice Data Center</a> <br>D.A. Robinson, D. K. Hall, and T. L. Mote, "MEaSUREs Northern Hemisphere Terrestrial Snow Cover Extent Daily 25km EASE-Grid 2.0, Version 1 (2017). Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. doi: <br><a href="https://doi.org/10.5067/MEASURES/CRYOSPHERE/nsidc-0530.001">https://doi.org/10.5067/MEASURES/CRYOSPHERE/nsidc-0530.001</a>. <a href="http://nsidc.org/cryosphere/sotc/snow_extent.html" target="_blank" rel="noopener">http://nsidc.org/cryosphere/sotc/snow_extent.html</a> <br>Rutgers University Global Snow Lab. <a href="http://climate.rutgers.edu/snowcover/docs.php?target=vis" target="_blank" rel="noopener">Data History</a>  </p>



<p id="footnote_10"><strong>10.</strong> R.S. Nerem, B.D. Beckley, J. T. Fasullo, B.D. Hamlington, D. Masters, and G.T. Mitchum, "Climate-change–driven accelerated sea-level rise detected in the altimeter era." <i>PNAS </i>15, no. 9<i> </i>(12 Feb. 2018): 2022-2025. https://doi.org/10.1073/pnas.1717312115. </p>



<p id="footnote_11"><strong>11.</strong> <a href="https://nsidc.org/cryosphere/sotc/sea_ice.html" target="_blank" rel="noopener">https://nsidc.org/cryosphere/sotc/sea_ice.html</a><br>Pan-Arctic Ice Ocean Modeling and Assimilation System (PIOMAS, Zhang and Rothrock, 2003)<br> <a href="http://psc.apl.washington.edu/research/projects/arctic-sea-ice-volume-anomaly/">http://psc.apl.washington.edu/research/projects/arctic-sea-ice-volume-anomaly/</a><br> <a href="http://psc.apl.uw.edu/research/projects/projections-of-an-ice-diminished-arctic-ocean/">http://psc.apl.uw.edu/research/projects/projections-of-an-ice-diminished-arctic-ocean/</a> </p>



<p id="footnote_12"><strong>12.</strong> USGCRP, 2017: <i>Climate Science Special Report: Fourth National Climate Assessment, Volume I</i> [Wuebbles, D.J., D.W. Fahey, K.A. Hibbard, D.J. Dokken, B.C. Stewart, and T.K. Maycock (eds.)]. U.S. Global Change Research Program, Washington, DC, USA, 470 pp, <a href="https://science2017.globalchange.gov/">https://doi.org/10.7930/j0j964j6</a>. </p>



<p id="footnote_13"><strong>13.</strong> <a href="http://www.pmel.noaa.gov/co2/story/What+is+Ocean+Acidification%3F" target="_blank" rel="noopener">http://www.pmel.noaa.gov/co2/story/What+is+Ocean+Acidification%3F</a> </p>



<p id="footnote_14"><strong>14.</strong> <a href="http://www.pmel.noaa.gov/co2/story/Ocean+Acidification" target="_blank" rel="noopener">http://www.pmel.noaa.gov/co2/story/Ocean+Acidification</a> </p>



<p id="footnote_15"><strong>15.</strong> C.L. Sabine, et al., “The Oceanic Sink for Anthropogenic CO2.” <i>Science</i> 305 (16 July 2004): 367-371. https://doi.org/10.1126/science.1097403. </p>



<p id="footnote_16"><strong>16.</strong> <a href="https://www.ipcc.ch/srocc/" target="_blank" rel="noopener">Special Report on the Ocean and Cryosphere in a Changing Climate</a>, Technical Summary, Chapter TS.5, Changing Ocean, Marine Ecosystems, and Dependent Communities, Section 5.2.2.3.<br> <a href="https://www.ipcc.ch/srocc/chapter/technical-summary/" target="_blank" rel="noopener">https://www.ipcc.ch/srocc/chapter/technical-summary/</a> </p>



<p><sub><i>Header image shows clouds imitating mountains as the sun sets after midnight as seen from Denali's backcountry Unit 13 on June 14, 2019. Credit: <a href="https://www.nps.gov/media/photo/view.htm?id=DF3609D9-1E8E-4BA2-914B-4C1F3E8E7071">NPS/Emily Mesner</a></i></sub><br><em><sub>Image credit in list of evidence: Ashwin Kumar, Creative Commons Attribution-Share Alike 2.0 Generic.</sub></em></p>


<div id="">
					<p>Keep Exploring</p>
					<h2>Discover More Topics From NASA</h2>
				</div></div></article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[99% of adults over 40 have shoulder "abnormalities" on an MRI, study finds (132 pts)]]></title>
            <link>https://arstechnica.com/health/2026/02/99-of-adults-over-40-have-shoulder-abnormalities-on-an-mri-study-finds/</link>
            <guid>47064944</guid>
            <pubDate>Wed, 18 Feb 2026 19:08:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/health/2026/02/99-of-adults-over-40-have-shoulder-abnormalities-on-an-mri-study-finds/">https://arstechnica.com/health/2026/02/99-of-adults-over-40-have-shoulder-abnormalities-on-an-mri-study-finds/</a>, See on <a href="https://news.ycombinator.com/item?id=47064944">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>Breaking the findings down to shoulders instead of people, of the 1204 shoulders in the study, 1,076 (90 percent) were asymptomatic while 128 (10 percent) were symptomatic. Of the 1,076 asymptomatic shoulders, 96 percent had RC abnormalities (1,039 of 1,076), and of the 128 symptomatic shoulders, 98 percent had abnormalities (126 of 128).</p>
<p>Prevalence of tendinopathy and partial-thickness tears was similar between the symptomatic and asymptomatic groups. It initially looked like full-thickness tears were more common in the symptomatic groups, but when researchers adjusted for other factors, including additional abnormalities spotted in the MRIs, the difference between the symptomatic and asymptomatic groups vanished.</p>
<h2>Context</h2>
<p>The authors argue that the findings suggest clinicians should rethink MRI findings, changing not just how they’re used, but also how they’re explained to patients. The language in particular should change given that “abnormalities” are ubiquitous—thus <em>normal</em>—and shouldn’t be described in terms that indicate a need for repair, like “tear.”</p>
<p>“While we refer to these findings as abnormalities, many likely represent normal age-related changes rather than clinically relevant structural changes,” the authors write. “Adopting more precise and less value-laden terminology—such as lesion, defect, fraying, disruption, structural alteration, or degeneration—may help reduce patient anxiety and the perceived need to do something or fix something by avoiding language that implies trauma or a requirement for repair.”</p>
<p>In <a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2844661">an accompanying editorial</a>, two orthopedic surgeons from the University of California, San Francisco, Edgar Garcia-Lopez and Brian Feeley, agree with the language shift and caution clinicians to proactively put MRI findings in context.</p>
<p>They also address the glaring question of when MRIs should even be used for shoulder pain. They suggest that for pain that’s not related to an injury, clinicians should first try a couple months of watch-and-wait with rest or physical therapy to regain function. If there’s no meaningful improvement, an MRI may be warranted. But they stressed that any further decisions on treatment should be based on the patient’s history, clinical exam, and functional limitations of their shoulder—not just what’s seen on the imaging.</p>
<p>“Of course, the findings of this study are not meant to dissuade clinicians from using MRI when appropriate, but to reinforce that the diagnosis and management of shoulder pain should be guided primarily by functional limitations,” the surgeons write.</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Echo, an iOS SSH+mosh client built on Ghostty (116 pts)]]></title>
            <link>https://replay.software/updates/introducing-echo</link>
            <guid>47064787</guid>
            <pubDate>Wed, 18 Feb 2026 18:58:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://replay.software/updates/introducing-echo">https://replay.software/updates/introducing-echo</a>, See on <a href="https://news.ycombinator.com/item?id=47064787">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Introducing Echo</h2><p>10th February 2026</p><p>We're thrilled to introduce Echo — a fast, modern SSH client for iOS and iPadOS, built for the new era of rich terminal-based tools and AI coding agents.</p><p>Echo is our first brand new app in a while, and it's our first app for iOS and iPadOS. It's a little different from what we've done before, and we'd love to tell you why we built it and what makes it special.</p><h2>Why build a terminal app?</h2><p>Something exciting has been happening in the terminal over the last couple of years. There's been an explosion in the TUI space — beautifully crafted, highly complex text-based user interfaces that are pushing the boundaries of what a terminal can do. Tools like<!-- --> <a href="https://lazygit.dev/" target="_blank">lazygit</a> <!-- -->and<!-- --> <a href="https://github.com/jesseduffield/lazydocker" target="_blank">lazydocker</a>, powered by libraries like<!-- --> <a href="https://github.com/charmbracelet/bubbletea" target="_blank">Bubbletea</a>,<!-- --> <a href="https://github.com/vadimdemedes/ink" target="_blank">Ink</a> <!-- -->and<!-- --> <a href="https://github.com/Textualize/textual" target="_blank">Textual</a>, have shown that the terminal isn't just for text anymore — it's become a rich, interactive canvas.</p><p>At the same time, AI coding agents have completely changed how developers work. Tools like Claude Code, Codex and Amp are running in terminals on remote machines, generating code, running builds, and waiting for human input. Developers increasingly need to check in on these agents from wherever they are — approve a change on the train, monitor a build from the couch, or nudge an agent in the right direction while away from their desk.</p><p>And then there's<!-- --> <a href="https://ghostty.org/" target="_blank">Ghostty</a>. Ghostty is our favourite terminal emulator. It's a terminal built with our own values of performance and true-to-platform native behaviour, as well as being beautiful, fast and flexible. Ghostty's terminal engine is open source and written in a way that can be embedded, which meant we could bring that same level of performance and correctness to iOS.</p><p>Over the last twelve months, we've been using all of these tools heavily. How we program has changed dramatically — we spend more time in the terminal than ever, working alongside agents, reviewing their output, and managing remote machines. At some point we realised that the app we kept reaching for on our phones didn't exist yet. So we built it. Echo is that app.</p><h2>Built for iOS, not ported to it</h2><p>We didn't want to just wrap a terminal in a WebView and ship it, or use a substandard terminal emulator. Echo is a native app, built from the ground up for iPhone and iPad. That means Metal-accelerated rendering, native Keychain integration for your SSH keys, and Face ID to keep your connections secure.</p><p>On iPhone, we spent a lot of time on the keyboard experience. There's a specially designed toolbar above the keyboard with quick keys for common terminal characters, and gesture-based arrow key movement that feels right at home on a touchscreen. It sounds like a small thing, but it makes a huge difference when you're actually trying to get work done on your phone.</p><p>On iPad, Echo really shines. Full hardware keyboard support with all the shortcuts you'd expect, Split View and Slide Over for running multiple sessions side by side, and Stage Manager support so you can resize and arrange terminal windows alongside your other apps. It's the kind of experience that makes an iPad with a keyboard feel like a genuinely capable development machine.</p><figure><p><img src="https://replay.software/echo/images/ipad-multiwindow.png" alt="Echo running in split view on iPad with multiple terminal windows"><span></span></p><figcaption>Multiple terminal sessions running side by side on iPad with Stage Manager.</figcaption></figure><h2>A home for agents on the go</h2><p>One of the things we're most excited about is how well Echo works as an interface for AI coding agents. Echo's minimal, distraction-free UI turns out to be the perfect environment for this — you SSH into your machine, attach to a tmux session, and you're right back where you left off with your agent.</p><p>We've been using Echo ourselves to interact with Claude Code, Codex, and others — and it's genuinely changed how we think about those workflows. Being able to approve a file change or review a diff from your phone feels like a superpower. The complex TUI interfaces that these agents present — syntax-highlighted code, interactive diffs, progress indicators — they all render beautifully because of Ghostty's terminal engine underneath.</p><figure><p><img src="https://replay.software/echo/images/agents-hero.png" alt="Echo app showing Claude Code and AI agents"><span></span></p><figcaption>Interacting with AI coding agents on the go via Echo.</figcaption></figure><h2>Themes, naturally</h2><p>If you know us from<!-- --> <a href="https://replay.software/sleeve">Sleeve</a>, you know we care about customization. Echo ships with a curated collection of terminal themes so you can make your terminal feel like yours. We've hand-picked some classics and some fresh options, and we'll be adding more over time.</p><h2>Available now</h2><p>Echo is available today on the App Store for iPhone and iPad, for a one-time purchase of $2.99. No subscriptions, no in-app purchases — just the way we like it.</p><p>This is a really exciting release for us. Echo represents something new for Replay — our first step into iOS, and into a space that's evolving incredibly fast. We have a lot of ideas for where to take Echo next, and we can't wait to share them with you.</p><p>If you have any questions, feedback, or just want to say hi, you can always reach us at<!-- --> <a href="https://replay.software/cdn-cgi/l/email-protection#3b484e4b4b54494f7b495e4b575a421548545d4f4c5a495e"><span data-cfemail="acdfd9dcdcc3ded8ecdec9dcc0cdd582dfc3cad8dbcddec9">[email&nbsp;protected]</span></a>. We'd love to hear what you think.</p><p><b>Al &amp; Hector</b><img src="https://replay.software/replay/images/Signatures.gif" width="208" height="70"></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cosmologically Unique IDs (435 pts)]]></title>
            <link>https://jasonfantl.com/posts/Universal-Unique-IDs/</link>
            <guid>47064490</guid>
            <pubDate>Wed, 18 Feb 2026 18:37:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jasonfantl.com/posts/Universal-Unique-IDs/">https://jasonfantl.com/posts/Universal-Unique-IDs/</a>, See on <a href="https://news.ycombinator.com/item?id=47064490">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>We are an exploratory species, just past the solar system now, but perhaps one day we will look back and call our galaxy merely the first. There are many problems to solve along the way, and today we will look at one very small one. How do we assign IDs to devices (or any object) so the IDs are guaranteed to always be unique?</p><p>Being able to identify objects is a fundamental tool for building other protocols, and it also underpins manufacturing, logistics, communications, and security. Every ship and satellite needs an ID for traffic control and maintenance history. Every radio, router, and sensor needs an ID so packets have a source and destination. Every manufactured component needs an ID for traceability. And at scale, the count explodes: swarms of robots, trillions of parts, and oceans of cargo containers moving through a civilization’s supply chain.</p><p>One of the key functions of an ID is to differentiate objects from one another, so we need to make sure we don’t assign the same ID twice. Unique ID assignment becomes a more challenging problem when we try to solve it at the scale of the universe.</p><p>But we can try.</p><h2 id="random"><span>Random</span><a href="#random"><i></i></a></h2><p>The first and easiest solution is to pick a random number every time a device needs an ID.</p><p>This is so simple that it is likely the best solution; you can do this anytime, anywhere, without the need for a central authority or coordination of any kind.</p><p>The big issue, though, is that it’s possible for two devices to pick the same ID by chance. Fortunately, we have complete control over the size of the random number, and by extension, the probability of a collision. This means we can make the likelihood of a collision functionally zero.</p><p>You may say that “functionally zero” is not enough, that although the probability is small, it is not <em>actually</em> zero, and so you are concerned. But consider this example: The probability of you being struck by a meteorite right now is small but non-zero, and you might even call that a “reasonable” (if paranoid) concern. But are you worried that every human on Earth will be hit by a meteorite right now? That probability is also non-zero, yet it is so infinitesimally small that we treat it as an impossibility. That is how small we can make the probability of an ID collision.</p><p>So how small does this probability need to be before we are comfortable? It will be helpful to reframe the question: How many IDs can we generate before a collision is expected?</p><p>The most recent version of <a href="https://en.wikipedia.org/wiki/Universally_unique_identifier">Universally Unique Identifiers</a> (UUIDs), which are a version of what we have been describing, uses 122 random bits. Using <a href="https://en.wikipedia.org/wiki/Birthday_problem">the birthday paradox</a>, we can calculate the expected number of IDs before a collision is $\approx 2^{61}$.</p><p>Is this high, or is it low? Is it enough to last the galaxy-wide expansion of the human race up to the heat death of the universe? Let’s try to calculate our own principled number by looking at the physical limits of the universe.</p><h3 id="universal-limit"><span>Universal limit</span><a href="#universal-limit"><i></i></a></h3><p>The paper <a href="https://arxiv.org/pdf/astro-ph/0404510">“Universal Limits on Computation”</a> has calculated that if the entire universe were a maximally efficient computer (known as <a href="https://en.wikipedia.org/wiki/Computronium">computronium</a>), it would have an upper limit of $10^{120}$ operations before the heat death of the universe. If we assume every operation generates a new ID, then we can calculate how large our IDs need to be to avoid a collision until the universe runs out of time.</p><p>Using approximations from <a href="https://en.wikipedia.org/wiki/Birthday_problem">the birthday paradox</a>, the probability of a collision for $n$ random numbers across a set of $d$ values is</p><p>\[p(n, d) \approx 1 - e^{-\frac{n(n-1)}{2d}}\]</p><p>We want a probability of $p = 0.5$ (this is a close approximation for when a collision is “expected”) for $n = 10^{120}$ numbers, so we can solve for $d$ to get</p><p>\[d \approx -\frac{n(n-1)}{2 \times \ln(1 - p)} = -\frac{10^{120}(10^{120}-1)}{2 \times \ln(1 - 0.5)} \approx 10^{240}\]</p><p>This is how large the ID space must be if we want to avoid a collision until the heat death of the universe. In terms of bits, this would require $\log_{2}(10^{240}) = 797.26$, so at least 798 bits.</p><p>This is the most extreme upper limit, and is a bit overkill. With 798 bits, we could assign IDs to literally everything ever and never expect a collision. Every device, every microchip, every component of every microchip, every keystroke, every tick of every clock, every star and every atom, everything can be IDed using this protocol and we still won’t expect a collision.</p><h3 id="reasonable-limits"><span>Reasonable limits</span><a href="#reasonable-limits"><i></i></a></h3><p>A more reasonable upper limit might be to assume that every atom in the observable universe will get one ID (we assume atoms won’t be assigned multiple IDs throughout time, which is a concession). There are an estimated $10^{80}$ atoms in the universe. Using the same equation as above, we find that we need 532 bits to avoid (probabilistically) a collision up to that point.</p><p>Or maybe we convert all of the mass of the universe into 1-gram nanobots? We would have $1.5 \times 10^{56}$ bots, which would require IDs of 372 bits.</p><p>We now have four sizes of IDs we can choose from, depending on how paranoid we are:</p><ul><li>798 bits from computronium</li><li>532 bits for atoms</li><li>372 bits for 1-gram nanobots</li><li>122 bits from UUIDs</li></ul><blockquote><p>Note that this has assumed true randomness when generating a random number, but this is sometimes a challenge. Many random number generators will use a pseudo-random number generator with a non-random seed. You want to ensure your hardware is capable of introducing true randomness, such as from a quantum source, or by using a cryptographically secure pseudorandom number generator (CSPRNG). If that is not available, using sensor data, timestamps, or other non-deterministic sources can help add additional randomness, but, it will not be pure randomness and therefore it will increase the probability that IDs collide. It would probably be a good idea to ban any IDs that are “common”, such as the first 1,000 IDs from every well known pseudo-random generator, the all-zeros ID, the all-ones ID, etc..</p></blockquote><p>But what if we are exceptionally paranoid and <strong>demand</strong> that the IDs are theoretically guaranteed to be unique? None of this probabilistic nonsense. That will take us on a journey.</p><h2 id="deterministic"><span>Deterministic</span><a href="#deterministic"><i></i></a></h2><p>As usual, let’s start with the easiest solution and work from there.</p><blockquote><p>All the code for visuals, simulations, and analysis can be found at <a href="https://github.com/JasonFantl/CUID-blog-post">this github repo</a>.</p></blockquote><p>Let’s create a single central computer that uses a counter to assign IDs. When someone requests an ID, it assigns the value of its counter, then increments the counter so the next ID will be unique. This scheme is nice since it guarantees uniqueness and the length of the IDs grows as slow as possible: logarithmically.</p><p>If all the 1-gram nanobots got an ID from this central computer, the longest ID would be $\log_2(1.5 \times 10^{56}) = 187$ bits. Actually, it would be a tiny bit longer due to overhead when <a href="https://jasonfantl.com/posts/Universal-Codes/">encoding a variable-length value</a>. We will ignore that for now.</p><p>Ok, there are serious issues with this solution. The primary issue I see is access. What if you’re on a distant planet and don’t have communication with the central computer? Or maybe your planet is so far from the computer that getting an ID would take days. Unacceptable.</p><p>In order to fix this, we might start sending out satellites in every direction that can assign unique IDs. Imagine we send the first satellite with ID <code>0</code>, then the next with <code>1</code>, and keep incrementing. Now people only need to request an ID from their nearest satellite and they will get back an ID that looks like <code>A.B</code>, where <code>A</code> is the ID of the satellite and <code>B</code> is the counter on the satellite. For example, the fourth satellite assigning its tenth ID would send out <code>3.9</code>. This ensures that every ID is unique and that getting an ID is more accessible.</p><p>But why stop at satellites? Why not let <em>any</em> device with an ID be capable of assigning new IDs?</p><p>For example, imagine a colony ship is built and gets the sixth ID from satellite <code>13</code>, so it now has an ID of <code>13.5</code>. The colonists take this ship to the outer rim, too far to communicate with anyone. When they reach their planet, they build construction robots which need new IDs. They can’t request IDs from a satellite since they are too far, but they could request IDs from their ship. The construction bots get IDs <code>13.5.3</code> and <code>13.5.4</code> since the ship had already assigned 3 IDs before this time and its counter was at <code>3</code>. And now these robots could assign IDs as well!</p><p>This does assume you always have at least one device capable of assigning IDs nearby. But, if you are in conditions to be creating new devices, then you probably have at least one pre-existing device nearby.</p><p>Let’s call this naming scheme Dewey.</p><h3 id="dewey"><span>Dewey</span><a href="#dewey"><i></i></a></h3><p>How does Dewey compare to the random-IDs in terms of bits required?</p><p>If an ID is of the form <code>A.B. ... .Z</code>, then we can encode that using <a href="https://en.wikipedia.org/wiki/Elias_omega_coding">Elias omega coding</a>. For now we will ignore the small overhead of the encoding and assume each number is perfectly represented using its binary values, but we will add it back in later. That means the ID <code>4.10.1</code> would have the binary representation <code>100.1010.1</code>, which has 8 bits. We can see how each value in the ID grows logarithmically since a counter grows logarithmically.</p><p>How the IDs grow over time will depend on what order IDs are assigned. Let’s look at some examples.</p><p>If each new device goes to the original device, creating an expanding subtree, then the IDs will grow logarithmically. This is exactly the central computer model we considered earlier.</p><p><a href="https://jason-fantl-blog.b-cdn.net/Dewey-subtree.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Dewey-subtree.gif" alt="" width="500" data-proofer-ignore=""></a></p><p>If we take the other extreme, where each new device requests an ID from the most recent device, then we form a chain. The IDs will grow linearly in this case.</p><p><a href="https://jason-fantl-blog.b-cdn.net/Dewey-chain.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Dewey-chain.gif" alt="" width="500" data-proofer-ignore=""></a></p><p>Or what if each new device chooses a random device to request an ID from? The growth should be something between linear and logarithmic. We will look more into this later.</p><p>We might also ask, what are the best-case and worst-case assignment trees for this scheme? We can just run the simulation and select the best or worst next node and see what happens. Note that there are multiple ways to show the best-case and worst-case since many IDs have the same length, so we arbitrarily have to pick one at a time, but the overall shape of the tree will be the same. Also note that this uses one-node lookahead, which might fail for more complex schemes, but is valid here.</p><div><p><a href="https://jason-fantl-blog.b-cdn.net/Dewey-chain.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Dewey-chain.gif" alt="" width="500" data-proofer-ignore=""></a></p><p><a href="https://jason-fantl-blog.b-cdn.net/Dewey-best.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Dewey-best.gif" alt="" width="500" data-proofer-ignore=""></a></p></div><p>We see one worst-case tree is the chain. This best-case tree for Dewey seems to have every node double its children, then repeat. This causes it to grow wide quite quickly. This indicates that this scheme would be great if we expect new devices to primarily request IDs from nodes that already have many children, but not great if we expect new devices to request IDs from other newer devices (the chain is the extreme example of this).</p><p>Here is the best-case at a larger scale to get a more intuitive feel for how the graph grows. What we care about is the fact that it is a fairly dense graph, which means this scheme would be best if humans use a small number of nodes to request IDs from.</p><p><a href="https://jason-fantl-blog.b-cdn.net/Dewey-large.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Dewey-large.gif" alt="" width="600" data-proofer-ignore=""></a></p><p>It’s annoying that the chain of nodes causes the ID to grow linearly. Can we design a better ID-assignment scheme that would be logarithmic for the chain as well?</p><h3 id="binary"><span>Binary</span><a href="#binary"><i></i></a></h3><p>Here is another attempt at an ID-assignment scheme, let’s see if it will grow any slower.</p><p>Take the entire space of IDs, visualized as a binary tree. Each device will have an ID somewhere on this tree. In order to assign new IDs, a device will take the column below it (columns alternate from left or right for each device) and assign the IDs in that column. With this scheme each node has a unique ID and also has an infinite list of IDs to assign (the blue outline in the figure), each of which also has an infinite list of IDs to assign, and so on.</p><p><a href="https://jason-fantl-blog.b-cdn.net/Binarytree-statespace.jpg"><img data-src="https://jason-fantl-blog.b-cdn.net/Binarytree-statespace.jpg" alt="" width="500" data-proofer-ignore="" src="https://jason-fantl-blog.b-cdn.net/Binarytree-statespace.jpg"></a></p><p>And now we can look at how it grows across a subtree and across a chain.</p><div><p><a href="https://jason-fantl-blog.b-cdn.net/Binary-subtree.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Binary-subtree.gif" alt="" width="500" data-proofer-ignore=""></a></p><p><a href="https://jason-fantl-blog.b-cdn.net/Binary-chain.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Binary-chain.gif" alt="" width="500" data-proofer-ignore=""></a></p></div><p>Both cases grow linearly. This is not what we were looking for. It’s now worth asking: Is this scheme always worse than the Dewey scheme?</p><p>If we look at the worst-case and best-case of this scheme, we notice that the best-case will grow differently then Dewey.</p><div><p><a href="https://jason-fantl-blog.b-cdn.net/Binary-subtree.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Binary-subtree.gif" alt="" width="500" data-proofer-ignore=""></a></p><p><a href="https://jason-fantl-blog.b-cdn.net/Binary-best.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Binary-best.gif" alt="" width="500" data-proofer-ignore=""></a></p></div><p>And the best-case at a larger scale.</p><p><a href="https://jason-fantl-blog.b-cdn.net/Binary-large.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Binary-large.gif" alt="" width="600" data-proofer-ignore=""></a></p><p>It grows roughly equally in all directions. The depth of the best-case tree grows faster than Dewey, which means this scheme would be better for growth models where new nodes are equally likely to request from older nodes and newer nodes. Specifically, the best-case tree grows by adding a child to every node in the tree and then repeating.</p><p>So this scheme can be better for some trees when compared to Dewey. Let’s keep exploring.</p><p>Actually, there is a scheme that looks different, but grows the same as this one.</p><h4 id="2-adic-valuation"><span>2-Adic Valuation</span><a href="#2-adic-valuation"><i></i></a></h4><p>If each ID is an integer, then a node with ID $n$ would assign to its $i$th child the ID $2^i(2n+1)$. Essentially, each child will double the ID from the previous child, and the first child has the ID $2n+1$ from its parent. This is a construction based on <a href="https://en.wikipedia.org/wiki/P-adic_valuation">2-adic valuation</a>.</p><p>You can prove that this generates unique IDs by using the <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic">Fundamental Theorem of Arithmetic</a>.</p><p>You can change the memory layout of this scheme pretty easily by using $(i, n)$ as the ID instead of $2^i(2n+1)$. Now the sequential child IDs of a node will grow logarithmically instead of linearly. This feels very similar to Dewey.</p><p>That’s all a bit complicated, but essentially we can say that this is an alternative representation of the Binary scheme we already looked at. But we want to explore new schemes that might have better memory growth characteristics.</p><h3 id="token"><span>Token</span><a href="#token"><i></i></a></h3><p>Let’s try to reverse-engineer a scheme that can grow logarithmically for the chain tree.</p><p>We know that a counter grows logarithmically, so ideally the ID would only increment a counter when adding a new node.</p><p>One idea is to have a token that gets passed down to children with a hop-count attached to it. But what happens when a device gets a new ID request and it doesn’t have a token to pass? We will have a token index which increments each time a parent has to create a new token. The new token will then be appended to the parent ID. So the chain of three will look like <code>[]</code>, <code>[(0,0)]</code>, <code>[(0,1)]</code>, as the root node has no token, then the first child causes the root to generate token, then the next hop gets the token passed down to it with an incremented hop count. If the root node had two more ID requests, it would generate <code>[(1,0)]</code> and <code>[(2,0)]</code>, incrementing the first value to produce unique tokens. Each ID is a list of (token-index, hop-count) pairs, ordered by creation. Let’s get a better idea of what this looks like by looking at a simulation.</p><p>Here we have the expanding subtree, the chain, and one of the best-cases.</p><div><p><a href="https://jason-fantl-blog.b-cdn.net/Token-subtree.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Token-subtree.gif" alt="" width="500" data-proofer-ignore=""></a></p><p><a href="https://jason-fantl-blog.b-cdn.net/Token-chain.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Token-chain.gif" alt="" width="500" data-proofer-ignore=""></a></p></div><p><a href="https://jason-fantl-blog.b-cdn.net/Token-best.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Token-best.gif" alt="" width="500" data-proofer-ignore=""></a></p><p>We can see that IDs are a bit longer in general since we have more information in each ID, but at least it grows logarithmically in our extreme cases.</p><p>This logarithmic growth for chains is reflected in the larger-scale best-case graph, where we see long chains growing from the root.</p><p><a href="https://jason-fantl-blog.b-cdn.net/Token-large.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Token-large.gif" alt="" width="600" data-proofer-ignore=""></a></p><p>This is kind of a lie though. The chain is logarithmic, but if we add even one more child to any node, the scheme starts to grow linearly. If our graph grows even a little in both depth and width together, we find ourselves back at the linear regime. We didn’t generate the worst-case graph above since our simulation uses a greedy search algorithm and the worst-case takes two steps to identify. The true worst-case is hard-coded and shown below, which we can see does grow linearly.</p><p><a href="https://jason-fantl-blog.b-cdn.net/Token-worst.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Token-worst.gif" alt="" width="500" data-proofer-ignore=""></a></p><p>So we have yet to find an algorithm that produces logarithmic growth in all cases. Is it even possible to design a scheme that always grows logarithmically, even in the worst-case?</p><details> <summary> Unfortunately not. Here is the proof that any scheme we develop will always be linear in the worst-case. </summary><p>In order to prove how fast any scheme must grow, we will look at how fast the number of possible IDs grows as nodes are added. This will require iterating over every possible assignment history and then counting how many unique possible IDs there are in the space of all possible assignment histories.</p><p>It is important to note that each path must produce a different ID. If any two paths produced the same ID, that means it would be possible to generate two nodes with the same ID.</p><p>To get our grounding, let’s first consider the tree containing all the possible 4-node paths. We will see in a moment that it will be useful to label each node using a 1-indexed Dewey system. The labels are not IDs (we are trying to write a proof about <em>any</em> possible ID scheme), the labels are just useful for talking about the paths and nodes.</p><p><a href="https://jason-fantl-blog.b-cdn.net/proof.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/proof.gif" alt="" width="500" data-proofer-ignore=""></a></p><p>We see every possible sequence for reaching the fourth node (only considering nodes along the path to that node) highlighted above. So we can now count how many possible IDs we need in tree with 4 nodes for <em>any</em> assignment order of those 4 nodes.</p><p>We see that there are 16 nodes in the tree, so whatever ID-assignment scheme we build must account for 16 unique IDs by the time we have added four nodes.</p><p>In general, notice that each time we add a new ID, we add a new leaf to every node in the tree of all possible paths. This means the number of IDs we need to account for grows as $2^{n-1}$ for $n$ nodes.</p><p>We can similarly come to this conclusion by looking at the labels. The sum of the values in a label will equal the iteration at which that node was added. It is also true the other direction: All possible paths of $n$ nodes can be generated by looking at all possible sums of numbers up to $n$, although they must be greater than 0 and the order of the sum will matter. These are known as <a href="https://en.wikipedia.org/wiki/Composition_(combinatorics)">integer compositions</a>, and they produce the result we saw from above, $2^{n-1}$ paths for $n$ nodes.</p><p>This is an issue. Even in the ideal case where we label each possible node in the space of all histories using a counter (this is actually a valid ID-assignment scheme and generates the 2-Adic Valuation scheme we have already seen), the memory of a counter grows logarithmically. No matter what scheme we use, the memory must grow at least on the order of $\log_2(2^{n-1}) = n-1$, linearly.</p></details><p>Although we have proven that whatever scheme we come up with will be linear in the worst-case, it seems plausible that some algorithms perform better than others for different growth models. If we can find a reasonable growth model for humans expanding into the universe, then we should be able to reverse-engineer the best algorithm.</p><h2 id="space-settlement-models"><span>Space Settlement Models</span><a href="#space-settlement-models"><i></i></a></h2><p>Let us consider different models that approximate how humans might expand into the universe.</p><h3 id="small-scale"><span>Small-scale</span><a href="#small-scale"><i></i></a></h3><p>The first and easiest model to consider is random parent selection. Each time a device is added it will randomly select from all the previous devices to request an ID. This will produce what is known as a <a href="https://en.wikipedia.org/wiki/Random_recursive_tree">Random Recursive Tree</a>. We will also run this at a small scale, up to around 2,048 nodes. And we will actually use the <a href="https://en.wikipedia.org/wiki/Elias_omega_coding">Elias omega encoding</a> so we can have more comparable results to the Random ID assignment bit usage.</p><p><a href="https://jason-fantl-blog.b-cdn.net/Random-graph-plot.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/Random-graph-plot.gif" alt="" width="600" data-proofer-ignore=""></a></p><p>The best scheme is Binary, followed by Dewey, and Token is the worst. This makes some sense since a random tree will grow at a roughly equal rates in depth and width, which is the best-case for Binary. Dewey and Token are harder to reason about, but we suspect that Dewey does best for high-width trees and Token for high-depth trees.</p><p>For example, we can look at a <a href="https://en.wikipedia.org/wiki/Preferential_attachment">preferential attachment</a> random graph, where nodes are more likely to connect to nodes with more connections, a model which many real-world networks follow. The width of the tree will dominate the depth, so we might expect Dewey to win out. Specifically, <a href="https://en.wikipedia.org/wiki/Preferential_attachment">preferential attachment</a> chooses a node weighted by the degree (number of edges) to choose a parent, which increases the degree of that parent, creating positive feedback. Let’s see how each ID assignment scheme handles this new growth model.</p><p><a href="https://jason-fantl-blog.b-cdn.net/PreferentialRandom-graph-plot.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/PreferentialRandom-graph-plot.gif" alt="" width="600" data-proofer-ignore=""></a></p><p>And we see that Dewey performs best, followed by Token, and then Binary by a wide margin.</p><p>Although, it seems unrealistic that devices become more popular because they assign more IDs. It seems reasonable to believe that some devices are more popular than others, but that popularity is not dependent on its history. A satellite will be very popular relative to a lightbulb, not because the satellite happened to assign more IDs in the past, but because its intrinsic properties like its position and accessibility make it easier to request IDs from. We could use a <a href="https://en.wikipedia.org/wiki/Fitness_model_(network_theory)">fitness model</a>, where each node is initialized with a fitness score that determines how popular it will be. The fitness score is sampled from an exponential.</p><p><a href="https://jason-fantl-blog.b-cdn.net/FitnessRandom-graph-plot.gif"><img data-src="https://jason-fantl-blog.b-cdn.net/FitnessRandom-graph-plot.gif" alt="" width="600" data-proofer-ignore=""></a></p><p>And it seems that Dewey and Binary do equally well, with Token producing the worst IDs. Although this seems pretty similar to the purely Random graph.</p><p>We need to run a large number of simulations for a large number of nodes and see if there’s a consistent pattern.</p><h3 id="medium-scale"><span>Medium-scale</span><a href="#medium-scale"><i></i></a></h3><p>Below we run 1,000 simulations for each growth model, building a graph up to about a million ($2^{20}$) nodes. We plot the maximum ID of the graph over time. Each run is shown as a line, then the x axis is made exponential since we suspect that the IDs grow with the logarithm of the node count, which will be easier to see with an exponential x axis.</p><p><a href="https://jason-fantl-blog.b-cdn.net/Million-node-sim.png"><img data-src="https://jason-fantl-blog.b-cdn.net/Million-node-sim.png" alt="" width="700" data-proofer-ignore="" src="https://jason-fantl-blog.b-cdn.net/Million-node-sim.png"></a></p><p>That’s some pretty clean results! We see a roughly straight line for most plots (the exceptions being Binary for the Preferential growth model and the Fitness growth model where it curves a small amount). The straight lines are a strong indication that the growth of IDs actually is logarithmic, and that we could fit a curve to it. To inspect the Preferential model for the other ID assignment schemes, let’s plot it again without Binary.</p><p><a href="https://jason-fantl-blog.b-cdn.net/preferential_plot.png"><img data-src="https://jason-fantl-blog.b-cdn.net/preferential_plot.png" alt="" width="650" data-proofer-ignore="" src="https://jason-fantl-blog.b-cdn.net/preferential_plot.png"></a></p><p>And we still see the linear trends on the exponential plot, which indicates that Dewey and Token schemes still grow logarithmically.</p><details> <summary> Here is my best explanation for why the plots are logarithmic. </summary><p>In the Random growth model, each node is statistically indistinguishable from the others, so we should expect every node to see the same <em>average</em> subtree over time. In distribution, the subtree under the root should look similar to the subtree under the millionth node, just at a smaller scale. This suggests that we can use a recursive relation between these subtrees to infer the overall scaling law.</p><p>Suppose we simulate the growth of a 1,000-node tree and observe that the maximum ID length has increased by about 34 bits (which is what we saw for Dewey). We then take the node with the longest ID among those 1,000 nodes and conceptually re-run a 1,000-node simulation with this node acting as the root. Because the Random model treats all nodes symmetrically, we expect this node’s subtree to grow in a statistically similar way to the original root’s subtree. Since all of our ID assignment schemes have additive ID lengths along ancestry, growing this subtree to 1,000 nodes should increase the maximum ID length by roughly another 34 bits.</p><p>However, this subtree is embedded inside the full tree. By the time this node has accumulated 1,000 descendants, we should expect that all other nodes in the original tree have also accumulated, on average, about 1,000 descendants. In other words, each time we simulate an isolated 1,000-node subtree, the full tree size grows by a factor of 1,000, while the maximum ID length increases by an approximately constant amount. In practice we observed an increase closer to 38 bits rather than 34, which could be due to noise, small-(n) effects, encoding overhead, or flaws in this heuristic.</p><p>This means the ID length is growing linearly while the total number of nodes is growing exponentially. In this example, the maximum-ID-length function satisfies a recurrence of the form $T(n \cdot 1000^d) \approx T(n) + 34 d$ which is only satisfied by a logarithmic function. Writing this explicitly, we get $T(n) \propto \log(n)$ (with the base—about (1.225) in this case—set by the observed constant).</p><p>This analysis is harder to apply to the Fitness and Preferential model, as nodes are different from each other in those schemes. But the plots do indicate that it is probably still true. It might be that the analysis is still true <em>on average</em> for these schemes, and so the finer details about different nodes gets washed away when we scale up, but I don’t feel confident about that argument. Bigger simulations might help identify if the trends are actually non-logarithmic.</p><p>Future simulations might also consider that devices have lifetimes (nodes disappear after some time), which can dramatically alter the analysis. Initial tests with a constant lifetime (relative to how many nodes have been added) showed linear growth of IDs over time. This makes sense since it essentially forces a wide chain, which we know grows linearly for all our ID assignment schemes. Is this a reasonable assumption? What if devices live longer if they are more popular, how might that change the outcome?</p></details><p>For now we will use the above simulations as the first rung on our <a href="https://en.wikipedia.org/wiki/Cosmic_distance_ladder">ladder</a> of simulations, using those results to plug into larger models which then are plugged into even larger models.</p><h3 id="large-scale"><span>Large-scale</span><a href="#large-scale"><i></i></a></h3><p>In order to determine how many bits these schemes might require for a universe-wide humanity, we need to evaluate models of how our IDs will grow between worlds.</p><p>We will use the million-node simulation of the Fitness growth model to model the assignment of IDs on the surface of a planet for its first few years. To scale up to a full planet over hundreds of years, we can fit a logarithmic curve to our Fitness model and extrapolate.</p><p>For this analysis we will select the Dewey ID assignment scheme since it seems to perform well across all growth models.</p><p><a href="https://jason-fantl-blog.b-cdn.net/log.png"><img data-src="https://jason-fantl-blog.b-cdn.net/log.png" alt="" width="100" data-proofer-ignore="" src="https://jason-fantl-blog.b-cdn.net/log.png"></a></p><p>When we fit a logarithmic curve to the max ID length of Dewey ID assignment in the Fitness growth model, it fits the curve $(6.5534 ± 0.2856) \ln(n)$ (where $0.2856$ is the standard deviation). This equation now allows us to closely approximate the max ID length after an arbitrary number of devices.</p><p>We have our model for expansion on a planet, now we need a model for how humanity spreads from one planet to the next. We can’t really know what it will look like when/if we expand into the universe, but people have definitely tried. Below are some papers modeling how humans will expand into the universe, from which we can try to create our own best-guess model more relevant to our analysis.</p><ul><li><a href="https://ntrs.nasa.gov/api/citations/19790011801/downloads/19790011801.pdf">Galactic Civilizations: Population Dynamics and Interstellar Diffusion</a>, by Newman and Sagan. Essentially, expansion through the galaxy is slow because only newly settled planets contribute to further spread, and each must undergo local population growth before exporting colonists, producing a slow and constant traveling wavefront of expansion across the galaxy.</li><li><a href="https://ntrs.nasa.gov/api/citations/19940022867/downloads/19940022867.pdf">The Fermi Paradox: An Approach Based on Percolation Theory</a>, by Geoffrey A. Landis. Essentially, using Percolation Theory with some “reasonable” values for the rate of spreading to new planets and rates of survival, this paper finds that some wavefronts will die out while others survive, meaning we will slowly spread through the galaxy in branches.</li><li><a href="https://arxiv.org/pdf/1902.04450v2">The Fermi Paradox and the Aurora Effect: Exo-civilization Settlement, Expansion and Steady States</a>. Essentially, modeling solar systems as a gas and settlement as a process that depends on the distance between planets, planets living conditions, and civilization lifetimes, they find that distant clusters of the universe will fall into a steady state of being settled.</li></ul><p>We will model the expansion between planets in a galaxy by using a constant-speed expanding wavefront that settles any habitable planet, where that new planet is seeded with a random ID from the closest settled planet. We will use the same model for the expansion between galaxies.</p><p>This will produce linear growth of ID-length as the wavefront moves outward. As each planet restarts the ID assignment process, it will cause the ID length to grow larger according to the same curve we saw for the first planet.</p><p>We have a rough estimate that there might be around <a href="https://www.latimes.com/science/la-sci-earth-like-planets-20131105-story.html">40 billion habitable planets in our Milky Way galaxy</a>, and the latest estimates hold there are around <a href="https://science.nasa.gov/missions/hubble/hubble-reveals-observable-universe-contains-10-times-more-galaxies-than-previously-thought/">2 trillion galaxies in the observable universe</a>.</p><p>If we assume that planets are close to uniformly positioned in a galaxy and the galaxy is roughly spherical (many galaxies are actually disks, but it won’t change the final conclusion), then we can expect the radius of the galaxy in terms of planet-hops can be solved for using the equation of the volume of a sphere. The radius in terms of planet-hops can be approximated by $\sqrt[3]{\frac{3V}{4 \pi}} = \sqrt[3]{\frac{3 \cdot 40 \cdot 10^{9}}{4 \pi}} \approx 2121$.</p><p><a href="https://jason-fantl-blog.b-cdn.net/solar-systems.png"><img data-src="https://jason-fantl-blog.b-cdn.net/solar-systems.png" alt="" width="400" data-proofer-ignore="" src="https://jason-fantl-blog.b-cdn.net/solar-systems.png"></a></p><p>If we assume each planet produces around 1 billion IDs before settling the next nearest planet, then we can calculate the ID length by the time it reaches the edge of the galaxy. This will be the amount by which the longest ID increases per planet (we are assuming 1 billion assignments) multiplied by the number of times this happens, which is the number of planets we hop to reach the edge of the galaxy. This doesn’t sound good.</p><p>\[6.5534 \cdot \ln(10^9) \cdot 2121 \approx 288048\]</p><p>That is a lot of bits. And it will only get worse. We will use the same approximation for galaxies as we did for planets.</p><p><a href="https://jason-fantl-blog.b-cdn.net/universe.png"><img data-src="https://jason-fantl-blog.b-cdn.net/universe.png" alt="" width="400" data-proofer-ignore="" src="https://jason-fantl-blog.b-cdn.net/universe.png"></a></p><p>Again assuming galaxies fill space uniformly, and as a sphere, we get the number of hops between galaxies to be $\sqrt[3]{\frac{3 \cdot 2 \cdot 10^{12}}{4 \pi}} \approx 7816$. And using the $288048$ from above as the length the ID increases every galaxy, we get</p><p>\[288048 \cdot 7816 = 2251383168\]</p><p>That is an exceptionally large number of bits. It would take about $281.4$ MB just to store the ID in memory.</p><p>This Deterministic solution is terrible when compared to the Random solution, which even in its most paranoid case only used 798 bits.</p><p>We might see this and try to think of solutions. Maybe we regulate that settlers must bring a few thousand of the shortest IDs they can find from their parent planet to the new planet, which would cut down the ID length per planet by around a half. But unless we find a way to grow IDs logarithmically across planets and galaxies, it won’t get you even close (remember, $2121 \cdot 7816 = 16577736$ planet hops in total).</p><p>So for now it seems the safest bet for universally unique IDs are Random numbers with a large enough range that the probabilities of collisions are functionally zero. But it was fun to consider how we might bring that probability to actually zero: designing different ID assignment schemes, running simulations, and modeling human expansion through the universe.</p><h2 id="end"><span>End</span><a href="#end"><i></i></a></h2><p>All the code for visuals, simulations, and analysis can be found at <a href="https://github.com/JasonFantl/CUID-blog-post">my repo on github</a>.</p><p>This was very much an exploration with many paths left unexplored, please reach out if you explore one of them and want to chat about it, it’s good fun.</p><p>Thanks to Kevin Montambault and Jacob Hendricks for being happy to talk with me for hours on end about these strange interests of mine. I am grateful and privileged to have friends with such deep curiosities.</p><h3 id="side-notes"><span>Side notes</span><a href="#side-notes"><i></i></a></h3><p>Another potential interesting component of this is security. You can prevent ID-spoofing by using signatures to verify identity and that each message comes from who they claim. For the Random case, you would use your public key as your ID. For the Deterministic schemes, each node could sign their child’s public key, which would allow one to verify the chain of signatures up to the root node which all nodes have knowledge of. Replay attacks can be avoided using challenges (send and respond challenges), although they would be hard in unidirectional or delayed comms (planet to planet), so you might label messages as unconfirmed until a challenge is verified.</p><p>We should also add some error correction to the IDs so if someone for example tries to read an ID and mis-reads a letter they can correct it later. Since there are many ways to apply error correction, there should be a version number attached to the error-correcting ID.</p><p>Some objects can not store IDs themselves, such as when an ID is assigned to a planet for example, and so it’s possible that multiple IDs get accidentally assigned to the same object. In this case we should actually store a list of IDs for objects which represent all the IDs that refer to the same object.</p><p>There can be an issue related to the <a href="https://en.wikipedia.org/wiki/Ship_of_Theseus">ship of Theseus</a> where an object with an ID might be slowly repaired with new parts, until eventually all the parts have been replaced. Should this object still have the same ID? One pragmatic solution might be to have the ID stored in a particular piece of hardware and accept that what it means to have a particular ID is to just to have that particular piece of hardware regardless of what it is connected to.</p><p>Here are some related topics to what we have talked about in this post: <a href="https://en.wikipedia.org/wiki/Decentralized_identifier">Decentralized identifiers</a> (DIDs) and <a href="https://link.springer.com/chapter/10.1007/978-3-662-47666-6_45">Ancestry Labeling Schemes</a>.</p></div></div>]]></description>
        </item>
    </channel>
</rss>