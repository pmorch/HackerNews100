<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 03 Feb 2025 00:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Waydroid – Android in a Linux container (176 pts)]]></title>
            <link>https://waydro.id/</link>
            <guid>42911042</guid>
            <pubDate>Sun, 02 Feb 2025 19:29:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://waydro.id/">https://waydro.id/</a>, See on <a href="https://news.ycombinator.com/item?id=42911042">Hacker News</a></p>
<div id="readability-page-1" class="page">
  <!-- ====== Header Start ====== -->
  
  <!-- ====== Header End ====== -->
  <!-- ====== Hero Start ====== -->
  <div id="home">
          <div data-wow-delay=".2s">
            <p><img src="https://waydro.id/assets/images/hero/waydroid_white_tb.png"></p><p> A container-based approach to boot a full Android system on regular GNU/Linux systems running Wayland based desktop environments. </p>
            <ul>
              <li>
                <a href="#docs" rel="nofollow noopener"> Documentation</a>
              </li>
              <li>
                <a href="#about" rel="nofollow noopener"> Learn More <i></i>
                </a>
              </li>
            </ul>
          </div>
          <div data-wow-delay=".25s">
            <div id="carouselExampleCaptions" data-bs-ride="carousel">
                <div>
                  <p><img src="https://waydro.id/assets/images/hero/main_landing.jpeg"></p><div>
                    <h5>Full Integration Of Android on Linux</h5>
                    <p>Using Waydroid's Multi-Window Mode</p>
                  </div>
                </div>
                <div>
                  <p><img src="https://waydro.id/assets/images/hero/Group%201.png"></p><div>
                    <h5>Mobile Linux Integrations</h5>
                    <p>Brought To Life With Waydroid</p>
                  </div>
                </div>
                <div>
                  <p><img src="https://waydro.id/assets/images/hero/clean_desktop.jpeg"></p><div>
                    <h5>Bring Your Desktop To Life</h5>
                    <p>With Waydroids Fullscreen Mode For Desktops &amp; Kiosks</p>
                  </div>
                </div>
              </div>
            <p><img src="https://waydro.id/assets/images/hero/dotted-shape.svg" alt="shape">
            <img src="https://waydro.id/assets/images/hero/dotted-shape.svg" alt="shape">
          </p></div>
        </div>
  <!-- ====== Hero End ====== -->
  <!-- ====== Features Start ====== -->
  <div id="features">
      <div>
            <p><span>Features</span></p><h2>Main Features of Waydroid</h2>
            <p> Waydroid uses Linux namespaces (user, pid, uts, net, mount, ipc) to run a full Android system in a container and provide Android applications on any GNU/Linux-based platform (arm, arm64, x86, x86_64). The Android system inside the container has direct access to needed hardware through LXC and the binder interface. </p>
          </div>
      <div>
        <!-- Feature Start -->
        <div data-wow-delay=".1s">
              <h3>Free and Open-Source</h3>
              <p> The Project is completely free and open-source, currently our repo is hosted on <a target="BLANK" href="https://github.com/waydroid">Github.</a> </p>
            </div>
        <!-- Feature Start -->
        <div data-wow-delay=".15s">
              <h3>Full app integration</h3>
              <p> Waydroid integrated with Linux adding the Android apps to your linux applications folder. </p>
            </div>
        <!-- Feature Start -->
        <div data-wow-delay=".2s">
              <h3>Multi-window mode</h3>
              <p> Waydroid expands on Android freeform window definition, adding a number of features. </p>
            </div>
        <!-- Feature Start -->
        <div data-wow-delay=".25s">
              <h3>Full UI Mode</h3>
              <p> For gaming and full screen entertainment, Waydroid can also be run to show the full Android UI. </p>
            </div>
        <!-- Feature Start -->
        <div data-wow-delay=".1s">
              <h3>Near native performance</h3>
              <p> Get the best performance possible using wayland and AOSP mesa, taking things to the next level </p>
            </div>
        <!-- Feature Start -->
        <div data-wow-delay=".1s">
              <h3>Active community</h3>
              <p> Find out what all the buzz is about and explore all the possibilities Waydroid could bring </p>
            </div>
      </div>
    </div>
  <!-- ====== Features End ====== -->
  <!-- ====== About Start ====== -->
  <div data-wow-delay=".2s" id="about">
        <div>
            <p><span>About Us</span></p><h2>Get your favourite Android Apps on Linux.</h2>
            <p> Waydroid brings all the apps you love, right to your desktop, working side by side your Linux applications.<br> The Android inside the container has direct access to needed hardwares.<br> The Android runtime environment ships with a minimal customized Android system image based on <a href="https://lineageos.org/" target="blank">LineageOS</a>. The used image is currently based on Android 11 </p>
            <p><a href="#install"> Install Instructions <i></i>
            </a>
          </p></div>
        <p><img src="https://waydro.id/assets/images/hero/photo1628875295.jpeg" alt="about-image">
        </p>
      </div>
  <!-- ====== About End ====== -->
  <!-- ====== Docs Start ====== -->
  <div id="docs">
            <p><span>Docs</span></p><h2>Our Documentation</h2>
            <p> Our documentation site can be found at <a target="BLANK" href="https://docs.waydro.id/"> docs.waydro.id</a>
            </p>
            <h2>Bugs &amp; Reports</h2>
            <p> Bug Reports can be filed on our repo <a target="BLANK" href="https://github.com/waydroid/waydroid/issues"> Github Repo</a>
            </p>
            <h2>Project Development</h2>
            <p> Our development repositories are hosted on <a target="BLANK" href="https://github.com/waydroid/"> Github</a>
            </p>
            <h2>How to Install ?</h2>
            <p> Please refer to our <a target="BLANK" href="https://docs.waydro.id/usage/install-on-desktops"> installation docs</a> for complete installation guide. </p>
            <h2>Manual Image Download</h2>
            <p>You can also manually download our images from</p>
            <p><a target="BLANK" href="https://sourceforge.net/projects/waydroid">
              <img src="https://waydro.id/assets/images/logo/sf.png" alt="sourceforge logo"> SourceForge <i></i>
            </a>
          </p></div>
  <!-- ====== Docs End ====== -->
  <!-- ====== FAQ Start ====== -->
  <section id="install">
    <p><img src="https://waydro.id/assets/images/faq/shape.svg" alt="shape">
    </p>
    <div>
      <div>
            <p><span>Instructions</span></p><h2>Quick install reference</h2>
            <p>For systemd distributions</p>
          </div>
      <div>
        
        <form>
          <p>Waydroid supports most common architectures (ARM, ARM64, x86 &amp; x86_64 CPUs)</p>
          <p>Waydroid uses Android's mesa integration for passthrough, and that enables support to most ARM/ARM64 SOCs on the mobile side, and Intel/AMD GPUs for the PC side. For Nvidia GPUs (except tegra) and VMs, we recommend using <a href="https://docs.waydro.id/faq/get-waydroid-to-work-through-a-vm">software-rendering</a> </p>
        </form>
      </div>
      <div>
        <p>Follow the install instructions for your linux distribution. You can find a list in our <a href="https://docs.waydro.id/usage/install-on-desktops">docs</a>.
        </p>
      </div>
      <div>
        <p>After installing you should start the waydroid-container service, if it was not started automatically:</p>
        <div>
          <figure>
            <pre><code data-lang="">sudo systemctl enable --now waydroid-container
</code></pre>
          </figure>
        </div>
      </div>
      <div>
        <p>Then launch Waydroid from the applications menu and follow the first-launch wizard.</p>
      </div>
      <div>
        <p>If prompted, use the following links for System OTA and Vendor OTA:</p>
        <div>
          <pre><code data-lang=""><p>https://ota.waydro.id/system</p></code></pre>
        </div>
        <div>
          <pre><code data-lang=""><p>https://ota.waydro.id/vendor</p></code></pre>
        </div>
      </div>
      <div>
        <p>For further instructions, please visit the docs site <a target="BLANK" href="https://docs.waydro.id/">here</a>
          </p>
      </div>
    </div>
  </section>
  <!-- ====== FAQ End ====== -->
  <div id="wdlinux">
              <p><img src="https://waydro.id/assets/images/hero/Computer_wd.png">
              </p>
              <div>
                
                <h3><span>Latest Beta </span><span> 01.30.2023</span></h3>
                <p> We have started creating a few fully-integrated distros in order to demonstrate some of the possibilities that Waydroid can help achieve. <br> Each of the distros we produce will also showcase some of the work from our growing community of contributors. <br> Our initial alpha releases of this integration started with Ubuntu 20.04 (focal) and is now on Ubuntu 22.04 (jammy) as well as Debian 12 (bookworm), and includes many added tools and scripts to help open up what is possible. </p>
                <div>
                  
                  <form>
                    <p>Waydroid-Linux currently only supports x86_64 CPUs (Intel/AMD)</p>
                    <p>Waydroid-Linux uses Android's mesa integration for passthrough, and that restricts support to Intel and AMD GPUs<br> For Nvidia GPUs and VMs, we recommend using <a href="https://docs.waydro.id/faq/get-waydroid-to-work-through-a-vm">software-rendering</a> </p>
                    <div id="sources">
                      <p>We have been working with a number of devs on Waydroid-Linux, and have been creating or contributing to a number of projects for it. <br> Here are just a few of the projects we've been using:</p>
                      <ol>
                        <li>
                          <div>
                            <p>Waydroid-Linux Tools</p><p> A few scripts, configs, and themes for the Waydroid-Linux builds </p>
                          </div>
                        </li>
                        <li>
                          <div>
                            <p>Waydroid-Settings</p><p> A GTK app written in Python to control Waydroid settings and expand with scripts (shell/py) </p>
                          </div>
                        </li>
                        <li>
                          <div>
                            <p>Penguins-Eggs</p><p> A tool used for packaging and installation of various Linux distros </p>
                            
                          </div>
                        </li>
                        <li>
                          
                        </li>
                      </ol>
                    </div>
                  </form>
                </div>
                <!---------->
                <details>
                  <summary>Live Mode Info</summary><br> Due to how Waydroid uses LXC and kernel modules for the binder, it will not work while running in live mode and must be installed before working properly.&nbsp; <br>Make sure to check the readme for the .iso, as it contains the specifics needed for each build.&nbsp;
                </details>
                <br>
                <!-- Button trigger modal -->
                <!-- Modal -->
                
                <!---------->
              </div>
            </div>
  <!-- ====== Team Start ====== -->
  <div id="team">
      <div>
            <p><span>Our Team</span></p><h2>Meet The Team</h2>
            <p>Here are the members of our team</p>
          </div>
      <div>
        <div data-wow-delay=".1s">
            
            <p>
              <h5>Erfan Abdi</h5>
              <p4>@erfanoabdi</p4>
              <h6 contenteditable="true">Lead Developer</h6>
            </p>
            
          </div>
        <div data-wow-delay=".15s">
            
            <p>
              <h5>Alessandro Astone</h5>
              <p4>@aleasto</p4>
              <h6>Developer</h6>
            </p>
            
          </div>
        <div data-wow-delay=".15s">
            
            <p>
              <h5>Jon West</h5>
              <p4>@electrikjesus</p4>
              <h6>Developer</h6>
            </p>
            
          </div>
        <div data-wow-delay=".2s">
            
            <p>
              <h5>Radek Błędowski</h5>
              <p4>@RKBDI</p4>
              <h6>Designer</h6>
            </p>
            
          </div>
      </div>
    </div>
  <div id="donate">
          <h2>Help Us Grow</h2>
          <br>
          <h4> Waydroid is now on Open-Collective </h4>
          <h4> We are now accepting donations and sponsorships through Open-Collective. </h4>
          <div>
            <p><a href="https://opencollective.com/waydroid/donate" target="_blank">
                <img src="https://opencollective.com/webpack/donate/button@2x.png?color=blue">
              </a>
            </p>
            <!-- /.animated scroll -->
          </div>
          <!-- /.banner-child -->
          <!-- /.banner-child -->
        </div>
  <!-- ====== Team End ====== -->
  <!-- ====== Contact Start ====== -->
  <!-- ====== Contact End ====== -->
  <!-- ====== Footer Start ====== -->
  
  <!-- ====== Footer End ====== -->
  <!-- ====== Back To Top Start ====== -->
  <span>
    <i> </i>
  </span>
  <!-- ====== Back To Top End ====== -->
  <!-- ====== All Javascript Files ====== -->
  
  
  
  
  



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Everyone knows your location: tracking myself down through in-app ads (835 pts)]]></title>
            <link>https://timsh.org/tracking-myself-down-through-in-app-ads/</link>
            <guid>42909921</guid>
            <pubDate>Sun, 02 Feb 2025 17:07:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://timsh.org/tracking-myself-down-through-in-app-ads/">https://timsh.org/tracking-myself-down-through-in-app-ads/</a>, See on <a href="https://news.ycombinator.com/item?id=42909921">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
            <p>Recently I read about a <a href="https://www.404media.co/hackers-claim-massive-breach-of-location-data-giant-threaten-to-leak-data/?ref=timsh.org" rel="noreferrer">massive geolocation data leak from Gravy Analytics</a>, which exposed more than 2000 apps, both in AppStore and Google Play, that secretly collect geolocation data without user consent. Oftentimes, even without developers` knowledge. </p><p>I looked into the list (<a href="https://docs.google.com/spreadsheets/d/1Ukgd0gIWd9gpV6bOx2pcSHsVO6yIUqbjnlM4ewjO6Cs/edit?gid=1257088277&amp;ref=timsh.org#gid=1257088277" rel="noreferrer">link here</a>) and found at least 3 apps I have installed on my iPhone. Take a look for yourself! <br>This made me come up with an idea to track myself down externally, e.g. to buy my geolocation data leaked by some application. </p><h3 id="tldr">TL;DR</h3><p>After more than couple dozen hours of trying, here are the main takeaways: </p><ol><li>I found a couple requests sent by my phone with <strong>my precise location </strong>+ 5 requests that leak <strong>my IP address</strong>, which can be turned into geolocation using reverse DNS. </li><li>Learned a lot about the RTB (real-time bidding) auctions and OpenRTB protocol and was shocked by the amount and types of data sent with the bids to ad exchanges. </li><li>Gave up on the idea to buy my location data from a data broker or a tracking service, because I don't have a big enough company to take a trial or $10-50k to buy a huge database with the data of millions of people + me. <br>Well maybe I do, but such expense seems a bit irrational. <br>Turns out that EU-based peoples` data is almost the most expensive. </li></ol><p>But still, I know my location data was collected and I know where to buy it! </p><hr><h2 id="starting-point">Starting point</h2><p>My setup for this research included:</p><ul><li>My old iPhone 11 restored to factory defaults + new apple id. <br>Felt too uncomfortable to do all this on my current phone. </li><li>Charles Proxy to record all traffic coming in and out. <br>I set up the SSL certificate on the iPhone to decrypt all https traffic.</li><li>A simple game called Stack by KetchApp - I remember playing it at school 10-12 years ago. Choosing it as a lab rat felt nostalgic. <br>To my surprise, there were a lot of KetchApp games on the list. </li></ul><figure><img src="https://timsh.org/content/images/2025/01/image-1.png" alt="" loading="lazy" width="320" height="180"></figure><h3 id="huge-amount-of-requests">Huge amount of requests</h3><p>Ok, here we go: only 1 app installed without the default Apple ones, Charles on, launching Stack in 3, 2, 1.... </p><figure data-kg-thumbnail="https://timsh.org/content/media/2025/01/Screen-Recording-2025-01-19-at-00.02.51_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://timsh.org/content/media/2025/01/Screen-Recording-2025-01-19-at-00.02.51.mp4" poster="https://img.spacergif.org/v1/2410x2152/0a/spacer.png" width="2410" height="2152" loop="" autoplay="" muted="" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:11</span>
                        </p>
                        </div>
            </div>
            
        <img src="https://timsh.org/content/media/2025/01/Screen-Recording-2025-01-19-at-00.02.51_thumb.jpg"></figure><p>These are the requests that the app sends in the first minute after launch. <br>Take a look at the timing of the requests - almost every split second. </p><p>Let's take a look at the contents of the requests. <br>I actually checked every single one of them - but I'll leave out only the interesting ones here. </p><h3 id="unity-ads">Unity [ads]</h3><p>Let's start with the juiciest request sent to <code>https://o.isx.unity3d.com</code> - the first one that included my geo, while I <strong>disabled Location Services</strong> on iPhone for all apps! <br>If you are as naive as I was before this, you might be surprised - what does Unity, the 3D engine, have to do with the in-app advertisement or location tracking? <br>Perhaps that's just some monitoring data to help improve the engine? </p><p>Turns out that Unity's main revenue stream (they made $2 bln+ in 2023) is Unity Ads - "Mobile Game Ad Network". Sounds quite interesting.</p><p>Below is the request body in json format sent to Unity Ads. I will only leave the  fields worth mentioning - the actual size is 200+ keys. </p><pre><code>{
  "ts": "2025-01-18T23:27:39Z", // Timestamp
  "c": "ES", // Country code,
  "d": "sports.bwin.es", // Domain; the app or website where the ad will be displayed.
  "bn": "molocoads-eu-banner", // WTF is moloco ads? We'll see!
  "cip": "181.41.[redacted]", // my IP !!
  "dm": "iPhone12,1", 
  "ct": "2", // Connection type; e.g., Wi-Fi
  "car": "Yoigo", // mobile network operator
  "ifv": "6B00D8E5-E37B-4EA0-BB58-[redacted]", // ID for Vendor. We'll get back to it!
  "lon": "2.[redacted]", // Longitude ... 
  "lat": "41.[redacted]", // Latitude ... 
  "sip": "34.227.224.225", // Server IP (Amazon AWS in US) 
  "uc": "1", // User consent for tracking = True; OK what ?!
}</code></pre><p>Ok, so my IP + location + timestamp + some <code>ifv</code> id are shared with Unity → Moloco Ads → Bwin, and then I see the actual Bwin ad in the game. <br>Wonderful! </p><div><p>As a quick note - location shared was not very precise (but still in the same postal index), I guess due to the fact that iPhone was connected to WiFi and had no SIM installed. <br>If it was LTE, I bet the lat/lon would be much more precise. </p></div><h3 id="hello-facebook-what-are-you-doing-here">Hello Facebook... What are you doing here?</h3><p>Next interesting request that leaks my IP + timestamp (= geo-datapoint) is Facebook.<br>What?!</p><ul><li>I don't have any Meta [Facebook] app installed on this iPhone</li><li>I didn't link the app nor my Apple ID to any Facebook account</li><li>I didn't consent to Facebook getting my IP address!</li></ul><p>And yet here we are:</p><pre><code>{ 
	"bundles": {
		"bidder_token_info": {
			"data": {
				"bt_extras": {
                  "ip":"181.41.[redacted], // nice Extras, bro
                  "ts":1737244649
			},
			"fingerprint": null
		},
        {
          "a lot of data: yes a loooooooot"
         }</code></pre><p>We'll talk more about this one in the next section. </p><h3 id="why-do-you-need-my-screen-brightness-level">Why do you need my screen brightness level? </h3><p>Last request I found interesting was sent to... Unity again: <br><a href="https://configv2.unityads.unity3d.com/webview/4.12.1/release/config.json?ref=timsh.org"><code>https://configv2.unityads.unity3d.com</code></a>. <br>Let's see what's in that config Unity needs so much: </p><pre><code>{
  "osVersion":"16.7.1",
  "connectionType":"wifi",
  "eventTimeStamp":1737244651,
  "vendorIdentifier":"6B00D8E5-E37B-[redacted]", // ifv once again 
  "wiredHeadset":false, // excuse me? 
  "volume":0.5,
  "cpuCount":6,
  "systemBootTime":1737215978,
  "batteryStatus":3,
  "screenBrightness":0.34999999403953552,
  "freeMemory":507888,
  "totalMemory":3550640, // is this RAM?
  "timeZone":"+0100",
  "deviceFreeSpace":112945148
  "networkOperator":"6553565535"
  "advertisingTrackingId":"00000000-0000....", // interesting ...
  }</code></pre><p>There's no "personal information" here, but honestly this amount of data shared with an arbitrary list of 3rd parties is scary. <br>Why do they need to know my screen brightness, memory amount, current volume and if I'm wearing headphones? </p><p>I know the "right" answer - to help companies target their audience better! <br>For example, if you're promoting a mobile app that is 1 GB of size, and the user only has 500 MB of space left - don't show him the ad, right?</p><p>But I also heard lots of controversies on this topic. <br>Like Uber dynamically adjusting taxi price based on your battery level - because you're not waiting for a cheaper option with 4% left while standing in the street. </p><p>I can't know if that or another one is true. <br>But the fact that this data is available and accessible by advertisers suggests that they should at least think of using it. <br>I would. </p><p>Ok, enough with the requests. <br>We can already see the examples of different ip and geolocation leaks. <br>One more "provider" that <strong>also got my IP</strong> + timestamp was adjust.com - but the request body was too boring to include. </p><hr><h2 id="lets-talk-ids">Let's talk IDs</h2><p>You might've already noticed <code>ifv</code> and <code>advertisingTrackingId</code> == <code>IDFA</code> in the requests above - what are those? </p><p>IFV, or IDFV, is "ID for Vendor". <br>This is my id unique for each vendor, a.k.a developer - in this case, KetchApp. <br>This checks out: I installed another KetchApp game to quickly record the requests, and the <code>ifv</code> value was the same for it. </p><p>Advertising Tracking ID, on the other hand, is the cross-vendor value, the one that is shared with an app if you choose "Allow app to track your activity across ...". <br>As you can see above, it was actually set to <code>000000-0000...</code> because I "Asked app not to track". </p><p>I checked this by manually disabling and enabling tracking option for the Stack app and comparing requests in both cases. </p><h3 id="and-thats-the-only-difference-between-allowing-and-disallowing-tracking"><strong>And that's the only difference between allowing and disallowing tracking</strong></h3><p><br>I understand there might be nothing shocking to you in it - this is not really kept secret, you can go and check the docs for Apple developers, for example. </p><p>But I believe this is <strong>not</strong> communicated correctly to the end users, you and me, in any adequate way, shape or form: the free apps you install and use <strong>collect your precise location</strong> with timestamp and send it to some 3rd-party companies. </p><p>The only thing that stops anyone with access to bid data (yet another ad buying agent, or ad exchange, or a dataset bought or rented from data broker, as you'll see later) from tracking you down with all trips you make daily is this <code>IDFA</code> that is not shared when you disallow apps to "track you across apps" to "enhance and personalise your ads experience". </p><p>By the way: if you're using 10 apps from the same vendor (Playrix, KetchApp or another 1000-app company) and allow <strong>a single app</strong> to track you – it would mean that the data collected in all 10 apps will be enriched with your IDFA which can later be exchanged to your personal data. </p><p>At the same time, there is so much data in the requests that I'd expect ad exchanges to find some loophole ID that would allow cross-app tracking without the need for IDFA. <br>I found at least 20 ids like <code>tid</code> and <code>sid</code>, <code>device_id</code> and <code>uid</code> (these 2 are shared with Facebook), and so on. </p><p>By the way, the fact that Facebook collected my IP + timestamp without any adequate consent / app connection from my end is crazy. <br>I think Facebook is more than capable of connecting the dots and my Meta Account to this hit as soon as I login to Instagram or Facebook app on the same IP address. </p><hr><h2 id="how-does-the-data-flow">How does the data flow?</h2><p>Let's get back to the request that leaked my location for a second and look at its trace. We'll focus on the parties in the middle:</p><p>stack<strong> →  o.isx.unity3d.com → molocoads →</strong> bwin (advertiser)</p><p>Unity [ads] is an SSP (supply-side platform) that acts as a collector of data from the app via SDK. <br>As an app developer, you don't need to worry about gathering the right data, registering as a publisher on an ad exchange or whatever - just install the SDK and receive the money. </p><p>All right, what about <a href="https://www.moloco.com/?ref=timsh.org" rel="noreferrer">Molocoads</a>? </p><figure><img src="https://timsh.org/content/images/2025/01/Screenshot-2025-01-29-at-23.06.38.png" alt="" loading="lazy" width="2000" height="786" srcset="https://timsh.org/content/images/size/w600/2025/01/Screenshot-2025-01-29-at-23.06.38.png 600w, https://timsh.org/content/images/size/w1000/2025/01/Screenshot-2025-01-29-at-23.06.38.png 1000w, https://timsh.org/content/images/size/w1600/2025/01/Screenshot-2025-01-29-at-23.06.38.png 1600w, https://timsh.org/content/images/2025/01/Screenshot-2025-01-29-at-23.06.38.png 2286w" sizes="(min-width: 720px) 720px"><figcaption><span>screenshot from Molocoads landing page</span></figcaption></figure><p>Moloco ads is a DSP network that resells data from multiple SSPs (like Unity, Applovin, Chartboost). Basically, from almost every one of the requested hosts I've seen pop up in Charles Proxy.<br>It then applies some "smart optimisation" and connects a vacant banner space on your phone screen with the advertiser.</p><p>Sounds like moloco aggregates a lot of data and basically anyone (<em>to be clear</em> <em>- any company that becomes an ad partner</em>) can access the data by bidding lower than others. <br>Or imagine a real ad exchange that bids normally and collects all of the data along the way "as a side gig". <br>Basically, this is how intelligence companies and data brokers get their data. </p><p>At this point I was looking for any mentions of Moloco on Telegram and Reddit, and I ran into this post that answered a lot of my questions:</p><figure><blockquote>
<a href="https://www.reddit.com/r/adops/comments/rqlr36/eli5_what_is_the_controversy_behind_bidstream/?ref=timsh.org">ELI5: What is the controversy behind “bidstream data”? Are there really no restraints on who gets this data and what they do with it?</a><br> by
<a href="https://www.reddit.com/user/Pubh12/?ref=timsh.org">u/Pubh12</a> in
<a href="https://www.reddit.com/r/adops/?ref=timsh.org">adops</a>
</blockquote>
</figure><p>Especially, <a href="https://www.reddit.com/r/adops/comments/rqlr36/comment/hqbwmbr/?ref=timsh.org" rel="noreferrer">this comment</a>. To quote a part of it:</p><blockquote>They access it if they integrate with the provider of bidstream, which would be the SSP. It's on the SSP to verify the vendor to whom they give access to bids. Usually, the requirement would be that you actually... bid. <br>SSPs want you to spend money, that's how their business makes revenue. They might open up only part of the traffic to specific vendors (i.e.. if you don't bid worldwide, you won't get the bidstream worldwide, only in the regions in which you operate).</blockquote><p>Just wonderful. </p><h3 id="data-brokers">Data Brokers</h3><p>Let's move further. When I found out how the data gets out, I started looking for any place where it's being sold. It was a quick search.</p><p>I found a data marketplace called <a href="https://datarade.ai/data-categories/device-graph-data?ref=timsh.org" rel="noreferrer">Datarade</a> which is a panel with all sorts of data. When I searched for MAID-specific data, hundreds of options showed up, like these two: </p><figure><img src="https://timsh.org/content/images/2025/01/Screenshot-2025-01-29-at-23.24.10.png" alt="" loading="lazy" width="1680" height="740" srcset="https://timsh.org/content/images/size/w600/2025/01/Screenshot-2025-01-29-at-23.24.10.png 600w, https://timsh.org/content/images/size/w1000/2025/01/Screenshot-2025-01-29-at-23.24.10.png 1000w, https://timsh.org/content/images/size/w1600/2025/01/Screenshot-2025-01-29-at-23.24.10.png 1600w, https://timsh.org/content/images/2025/01/Screenshot-2025-01-29-at-23.24.10.png 1680w" sizes="(min-width: 720px) 720px"></figure><p>The price of the Redmob dataset surprised me, - $120k a year... for what?<br>Let's now take a look at their promo:</p><figure><img src="https://timsh.org/content/images/2025/01/Screenshot-2025-01-29-at-23.26.05.png" alt="" loading="lazy" width="1626" height="838" srcset="https://timsh.org/content/images/size/w600/2025/01/Screenshot-2025-01-29-at-23.26.05.png 600w, https://timsh.org/content/images/size/w1000/2025/01/Screenshot-2025-01-29-at-23.26.05.png 1000w, https://timsh.org/content/images/size/w1600/2025/01/Screenshot-2025-01-29-at-23.26.05.png 1600w, https://timsh.org/content/images/2025/01/Screenshot-2025-01-29-at-23.26.05.png 1626w" sizes="(min-width: 720px) 720px"></figure><div><p>Check out the list of features on the right - do any of them look familiar? </p><p><strong>Quick note</strong>: "low latency" means they know your location from the last time any of the apps shared it. It can be as little as 5 seconds ago. <br>What's even better is that Redmob provides a <strong>free sample</strong> of the data. </p></div><p>I tried to request it from their website, but the sample never landed in my mailbox (surprise-surprise, timsh.org doesn't seem like a customer with high potential). <br>Thankfully, this sample is public on <a href="https://marketplace.databricks.com/details/caa4c07a-b27e-4876-9c9c-3f3c2bbbc11f/Redmob_SAMPLE-Redmob-MAID-Data-for-Identity-Graph-I-Global-I-15B-Users-RealTime?ref=timsh.org" rel="noreferrer">Databricks Marketplace</a> with this annotation:</p><blockquote>Enhance your products and services using our global location data covering over 1.5 billion devices. Using our extensive location dataset, you can unearth concealed patterns, conduct rapid analyses, and obtain profound knowledge.<p>We can also provide region-specific data (MENA, Africa, APAC, etc.) based on your specific requirements. Our pricing model includes an annual licensing option, and we provide free sample data so that you can evaluate the quality of our dataset for yourself. </p></blockquote><figure><img src="https://timsh.org/content/images/2025/01/Screenshot-2025-01-31-at-01.12.16.png" alt="" loading="lazy" width="2000" height="562" srcset="https://timsh.org/content/images/size/w600/2025/01/Screenshot-2025-01-31-at-01.12.16.png 600w, https://timsh.org/content/images/size/w1000/2025/01/Screenshot-2025-01-31-at-01.12.16.png 1000w, https://timsh.org/content/images/size/w1600/2025/01/Screenshot-2025-01-31-at-01.12.16.png 1600w, https://timsh.org/content/images/size/w2400/2025/01/Screenshot-2025-01-31-at-01.12.16.png 2400w" sizes="(min-width: 1200px) 1200px"><figcaption><span>Some sample data for better understanding</span></figcaption></figure><p>To me, the most absurd part is the <code>app</code> column - the source of the data can't be more obvious. I'm also quite interested in the <code>yod</code> column - if it's the birthyear, where did they get it from? Never mind, who cares about your birthyear.</p><h3 id="show-me-the-pii">Show me the PII!</h3><p>All right, imagine I bought the access to a huge stream of Redmob data. <br>But my goal is to track and stalk people like myself or anyone else, so I need some way to exchange MAIDs (<em>=</em><code>ifa</code>) for the actual personal info: name, address, phone number... </p><p>No problem! This kind of dataset is surprisingly also present on Datarade. <br>Take a look at a sample table with <code>MAID &lt;&gt; PII</code> type that is provided by "<a href="https://www.agrmarketingsolutions.com/data-nuggets/?ref=timsh.org" rel="noreferrer">AGR Marketing Solutions</a>":</p><figure><a href="https://docs.google.com/spreadsheets/d/1gbom_3YO-oFB6Yrg_MAhrJKGkYtNHR2S/edit?gid=2029445799&amp;ref=timsh.org#gid=2029445799"><div><p>AGR_Mobile_Intent_PII20240903.xlsx</p><p><img src="https://timsh.org/content/images/icon/spreadsheets_2023q4.ico" alt=""><span>Google Docs</span></p></div><p><img src="https://timsh.org/content/images/thumbnail/AHkbwyL0Y-RadP94i-3ntHlOyBNz5QtZLseHmdD1MAKSAFQi7l2fIzkQjGmDmSQRI2yTN7B1h5cNCpCeVlmlA0dsdek_xQhi6nazcP6xeg-w1200-h630-p" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>Inside - all personal info (full name, email, phone number, physical address, property ownership... and IDFAs. </p><p>Congrats, you have just reached the bottom of this rabbit hole. <br>Let's wrap it up and make a couple of bold statements.</p><hr><h2 id="how-to-track-yourself-down">How to track yourself down?</h2><p>Easy! Just follow this simple step-by-step guide:</p><ol><li>Use some free apps for a bit. <br>Move around and commute - this makes the geo data more valuable. </li><li>"Allow" or "ask not to track" - a combo of IP + location + User-agent + geolocation will still be leaked to hundreds of "3rd parties" regardless of your choice.</li><li>Wait for a few seconds until fake DSPs and data brokers receive your data.</li><li>Exchange your full name or phone number for an IDFA (if present), IP address and user-agent through the <code>MAID &lt;&gt; PII</code> data purchased somewhere.</li><li>Now, access the "Mobility data" consisting of geolocation history, and filter it using the values from the previous step. </li></ol><p>Congratulations! You found yourself. </p><p>I <a href="https://excalidraw.com/?ref=timsh.org#json=Ip5AaR-FPppPmtL3AcrBg,-woEvDuI7vER5B7skpT3zA" rel="noreferrer">created a flowchart</a> that includes almost all actors and data mentioned above - now you can see how it's all connected. </p><figure><img src="https://timsh.org/content/images/2025/02/dataflow_upd-1.png" alt="" loading="lazy" width="2000" height="747" srcset="https://timsh.org/content/images/size/w600/2025/02/dataflow_upd-1.png 600w, https://timsh.org/content/images/size/w1000/2025/02/dataflow_upd-1.png 1000w, https://timsh.org/content/images/size/w1600/2025/02/dataflow_upd-1.png 1600w, https://timsh.org/content/images/size/w2400/2025/02/dataflow_upd-1.png 2400w"></figure><p>This is the worst thing about these data trades that happen constantly around the world - each small part of it is (or seems) legit. It's the bigger picture that makes them look ugly. </p><hr><h2 id="afterwords">Afterwords</h2><p>Thanks for reading this story until the end!<br>My research was heavily influenced by these posts and investigations: </p><figure><a href="https://krebsonsecurity.com/2024/10/the-global-surveillance-free-for-all-in-mobile-ad-data/?ref=timsh.org"><div><p>The Global Surveillance Free-for-All in Mobile Ad Data</p><p>Not long ago, the ability to remotely track someone’s daily movements just by knowing their home address, employer, or place of worship was considered a powerful surveillance tool that should only be in the purview of nation states. But a…</p><p><img src="https://timsh.org/content/images/icon/favicon.ico" alt=""><span>Krebs on Security</span><span>Skip to content</span></p></div><p><img src="https://timsh.org/content/images/thumbnail/peoplephone.png" alt="" onerror="this.style.display = 'none'"></p></a></figure><figure><a href="https://www.404media.co/candy-crush-tinder-myfitnesspal-see-the-thousands-of-apps-hijacked-to-spy-on-your-location/?ref=timsh.org"><div><p>Candy Crush, Tinder, MyFitnessPal: See the Thousands of Apps Hijacked to Spy on Your Location</p><p>A hack of location data company Gravy Analytics has revealed which apps are—knowingly or not—being used to collect your information behind the scenes.</p><p><img src="https://timsh.org/content/images/icon/favicon-3.svg" alt=""><span>404 Media</span><span>Joseph Cox</span></p></div><p><img src="https://timsh.org/content/images/thumbnail/andrew-guan-lTUyP3RaLpw-unsplash.jpg" alt="" onerror="this.style.display = 'none'"></p></a></figure><figure><a href="https://interaktiv.br.de/ausspioniert-mit-standortdaten/en/index.html?ref=timsh.org"><div><p>Under Surveillance</p><p>How Location Data Jeopardizes German Security</p><p><img src="https://timsh.org/content/images/icon/apple-touch-icon.png" alt=""><span>BR</span><span>BR Data</span></p></div><p><img src="https://timsh.org/content/images/thumbnail/teaser.png" alt="" onerror="this.style.display = 'none'"></p></a></figure>
        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sniffnet – monitor your Internet traffic (174 pts)]]></title>
            <link>https://github.com/GyulyVGC/sniffnet</link>
            <guid>42909530</guid>
            <pubDate>Sun, 02 Feb 2025 16:14:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/GyulyVGC/sniffnet">https://github.com/GyulyVGC/sniffnet</a>, See on <a href="https://news.ycombinator.com/item?id=42909530">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
<themed-picture data-catalyst-inline="true"><picture>
<img alt="" title="Sniffnet" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/header_repository.png" width="95%">
</picture></themed-picture>
<p dir="auto"><a href="#download"><img alt="" title="Download" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/download.svg"></a>
<a href="https://github.com/GyulyVGC/sniffnet/blob/main/ROADMAP.md"><img alt="" title="Roadmap" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/roadmap.svg"></a>
<a href="https://sniffnet.net/" rel="nofollow"><img alt="" title="Website" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/website.svg"></a>
<a href="https://github.com/GyulyVGC/sniffnet/wiki"><img alt="" title="Wiki" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/wiki.svg"></a></p>
<p dir="auto">Application to comfortably monitor your Internet traffic <br>
Cross-platform, Intuitive, Reliable</p>
<p dir="auto">Translated in:<br>
🇨🇳 🇩🇪 🇫🇷 🇷🇺 🇵🇹 🇪🇦 🇮🇹 🇵🇱 <a href="https://github.com/GyulyVGC/sniffnet/issues/60" data-hovercard-type="issue" data-hovercard-url="/GyulyVGC/sniffnet/issues/60/hovercard">+&nbsp;12&nbsp;more&nbsp;languages</a></p>
</div>
<p dir="auto">
<themed-picture data-catalyst-inline="true"><picture>
<img alt="" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/hr.png" width="100%">
</picture></themed-picture>
</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/overview.png"><img alt="" title="Overview page" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/overview.png" width="95%"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/inspect.png"><img alt="" title="Inspect page" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/inspect.png" width="47%"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/notifications.png"><img alt="" title="Notifications page" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/notifications.png" width="47%"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/catppuccin.png"><img alt="" title="Custom theme" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/catppuccin.png" width="47%"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/thumbnail.png"><img alt="" title="Thumbnail mode" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/thumbnail.png" width="47%"></a>
</p>
<p dir="auto">
<themed-picture data-catalyst-inline="true"><picture>
<img alt="" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/hr.png" width="100%">
</picture></themed-picture>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><em>Support Sniffnet's development</em> 💖</h2><a id="user-content-support-sniffnets-development-" aria-label="Permalink: Support Sniffnet's development 💖" href="#support-sniffnets-development-"></a></p>
<p dir="auto"><i>Sniffnet is completely free, open-source software which needs lots of effort and time to develop and maintain.</i></p>
<p dir="auto"><i>If you appreciate Sniffnet, <a href="https://github.com/sponsors/GyulyVGC">consider sponsoring</a>:
your support will allow me to dedicate more time to this project,
constantly expanding it including <a href="https://github.com/GyulyVGC/sniffnet/blob/main/ROADMAP.md">new features and functionalities</a>.</i></p>
<p dir="auto"><i>A special mention goes to these awesome organizations and folks who are sponsoring Sniffnet:</i></p>
<p dir="auto">
<a href="https://github.com/github" title="GitHub"><img src="https://avatars.githubusercontent.com/github?v=4" width="60px" alt="GitHub"></a>&nbsp;&nbsp;
<a href="https://nlnet.nl/" title="NLnet" rel="nofollow"><img src="https://camo.githubusercontent.com/9e7f127e3732d4322576aa2462ce899725954f576fa5c36543b38f684f53a6cd/68747470733a2f2f6e6c6e65742e6e6c2f6c6f676f2f6c6f676f2e737667" width="60px" alt="NLnet" data-canonical-src="https://nlnet.nl/logo/logo.svg"></a>&nbsp;&nbsp;
<a href="https://ipinfo.io/" title="IPinfo" rel="nofollow"><img src="https://avatars.githubusercontent.com/ipinfo?v=4" width="60px" alt="IPinfo"></a>&nbsp;&nbsp;
<a href="https://github.com/Cthulu201" title="Cthulu201"><img src="https://avatars.githubusercontent.com/Cthulu201?v=4" width="60px" alt="Cthulu201"></a>&nbsp;&nbsp;
<a href="https://github.com/0x0177b11f" title="Tiansheng Li"><img src="https://avatars.githubusercontent.com/0x0177b11f?v=4" width="60px" alt="Tiansheng Li"></a>&nbsp;&nbsp;
<a href="https://github.com/ZEROF" title="ZEROF"><img src="https://avatars.githubusercontent.com/ZEROF?v=4" width="60px" alt="ZEROF"></a>&nbsp;&nbsp;
<a href="https://www.janwalter.org/" title="Jan Walter" rel="nofollow"><img src="https://avatars.githubusercontent.com/wahn?v=4" width="60px" alt="Jan Walter"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Download</h2><a id="user-content-download" aria-label="Permalink: Download" href="#download"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th><a href="#download"><img alt="Windows" title="Windows" height="35px" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/windows.svg"></a></th>
<th><a href="#download"><img alt="macOS" title="macOS" height="35px" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/macos.svg"></a></th>
<th><a href="#download"><img alt="Linux (.deb)" title="Linux (.deb)" height="35px" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/linux_deb.svg"></a></th>
<th><a href="#download"><img alt="Linux (.rpm)" title="Linux (.rpm)" height="35px" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/linux_rpm.svg"></a></th>
</tr>
</thead>
<tbody>
<tr>
<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_Windows_64-bit.msi">64‑bit</a>&nbsp;|&nbsp;<a href="https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_Windows_32-bit.msi">32‑bit</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
<td><a href="https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_macOS_Intel.dmg">Intel</a>&nbsp;|&nbsp;<a href="https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_macOS_AppleSilicon.dmg">Apple&nbsp;silicon</a></td>
<td><a href="https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxDEB_amd64.deb">amd64</a>&nbsp;|&nbsp;<a href="https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxDEB_arm64.deb">arm64</a>&nbsp;|&nbsp;<a href="https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxDEB_i386.deb">i386</a>&nbsp;|&nbsp;<a href="https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxDEB_armhf.deb">armhf</a></td>
<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxRPM_x86_64.rpm">x86_64</a>&nbsp;|&nbsp;<a href="https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxRPM_aarch64.rpm">aarch64</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Links in the table above will download the latest version of Sniffnet directly from <a href="https://github.com/GyulyVGC/sniffnet/releases">GitHub releases</a>. <br></p>

<p dir="auto"><strong>Alternative installation methods</strong> are reported in the following:</p>
<details>
  <summary>from Crates.io</summary>
<p dir="auto">Follow this method only if you have <a href="https://www.rust-lang.org/tools/install" rel="nofollow">Rust installed</a> on your machine. <br>
In this case, the application binary can be built and installed with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo install sniffnet --locked"><pre>cargo install sniffnet --locked</pre></div>
</details>
<details>
  <summary>from Homebrew</summary>
<p dir="auto">You can install <a href="https://github.com/Homebrew/homebrew-core/pkgs/container/core%2Fsniffnet">Sniffnet Homebrew package</a> with:</p>

</details>
<details>
  <summary>from Nixpkgs</summary>
<p dir="auto">You can install <a href="https://search.nixos.org/packages?channel=23.05&amp;show=sniffnet&amp;from=0&amp;size=50&amp;sort=relevance&amp;type=packages&amp;query=sniffnet" rel="nofollow">Sniffnet Nix package</a> adding the following Nix code to your NixOS Configuration, usually located in <code>/etc/nixos/configuration.nix</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="environment.systemPackages = [
  pkgs.sniffnet
];"><pre><span>environment</span><span>.</span><span><span>systemPackages</span></span> <span>=</span> <span>[</span>
  <span>pkgs</span><span>.</span><span><span>sniffnet</span></span>
<span>]</span><span>;</span></pre></div>
<p dir="auto">Alternatively, you can install it in your home using <a href="https://github.com/nix-community/home-manager">Home Manager</a> with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="home.packages = [
  pkgs.sniffnet
];"><pre><span>home</span><span>.</span><span><span>packages</span></span> <span>=</span> <span>[</span>
  <span>pkgs</span><span>.</span><span><span>sniffnet</span></span>
<span>]</span><span>;</span></pre></div>
<p dir="auto">Alternatively, you can try it in a shell with:</p>

</details>
<details>
  <summary>on Arch Linux</summary>
<p dir="auto">You can install Sniffnet community package via <a href="https://wiki.archlinux.org/title/Pacman" rel="nofollow">pacman</a>:</p>

</details>
<details>
  <summary>on FreeBSD</summary>
<p dir="auto">You can install Sniffnet port with:</p>

</details>
<details>
  <summary>on NetBSD</summary>
<p dir="auto">You can install Sniffnet from the official repositories via <a href="https://pkgin.net/" rel="nofollow">pkgin</a>:</p>

</details>
<details>
  <summary>on Tiny Core Linux</summary>
<p dir="auto">You can install Sniffnet from the official repository with:</p>

</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>💻 choose a <strong>network adapter</strong> of your PC to inspect</li>
<li>🏷️ select a set of <strong>filters</strong> to apply to the observed traffic</li>
<li>📖 view overall <strong>statistics</strong> about your Internet traffic</li>
<li>📈 view <strong>real-time charts</strong> about traffic intensity</li>
<li>📌 keep an eye on your network even when the application is <strong>minimized</strong></li>
<li>📁 <strong>export</strong> comprehensive capture reports as <strong>PCAP files</strong></li>
<li>🔎 identify <strong>6000+ upper layer services</strong>, protocols, trojans, and worms</li>
<li>🌐 find out <strong>domain name</strong> and <strong>ASN</strong> of the hosts you are exchanging traffic with</li>
<li>🏠 identify connections in your <strong>local network</strong></li>
<li>🌍 get information about the country of remote hosts (<strong>IP geolocation</strong>)</li>
<li>⭐ save your <strong>favorite</strong> network hosts</li>
<li>🕵️‍♂️ search and <strong>inspect</strong> each of your network connections in real time</li>
<li>🔉 set <strong>custom notifications</strong> to inform you when defined network events occur</li>
<li>🎨 choose the <strong>style</strong> that fits you the most, including custom themes support</li>
<li>...and more!</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">User manual</h2><a id="user-content-user-manual" aria-label="Permalink: User manual" href="#user-manual"></a></p>
<p dir="auto">Do you want to <strong>learn more</strong>? <br>
Check out the <a href="https://github.com/GyulyVGC/sniffnet/wiki"><strong>Sniffnet Wiki</strong></a>, a comprehensive manual to help you
thoroughly master the application from a basic setup to the most advanced functionalities. <br>
The Wiki includes step-by-step guides, tips, examples of usage, and answers to frequent questions.</p>
<p dir="auto">
<a href="https://github.com/GyulyVGC/sniffnet/wiki">
<img alt="" title="Sniffnet Wiki" src="https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/logos/wiki/wikilogo.svg" width="300px">
</a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Troubleshooting</h2><a id="user-content-troubleshooting" aria-label="Permalink: Troubleshooting" href="#troubleshooting"></a></p>
<details>
  <summary>See details</summary>
<p dir="auto"><h3 tabindex="-1" dir="auto">Missing dependencies</h3><a id="user-content-missing-dependencies" aria-label="Permalink: Missing dependencies" href="#missing-dependencies"></a></p>
<p dir="auto">Most of the errors that may arise are likely due to your system missing dependencies
required to correctly analyze a network adapter. <br>
Check the <a href="https://github.com/GyulyVGC/sniffnet/wiki/Required-dependencies">required dependencies page</a>
for instructions on how to proceed depending on your operating system.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Rendering problems</h3><a id="user-content-rendering-problems" aria-label="Permalink: Rendering problems" href="#rendering-problems"></a></p>
<p dir="auto">In some circumstances, especially if you are running on an old architecture or your graphical drivers are not updated,
the <code>wgpu</code> default renderer used by <a href="https://github.com/iced-rs/iced">iced</a>
may manifest bugs (the interface glitches, color gradients are unsupported, or some icons are completely black). <br>
In these cases you can set an environment variable to switch to the <code>tiny-skia</code> renderer,
a CPU-only software renderer that should work properly on every environment:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto"><em><strong>In any case, don't hesitate to <a href="https://github.com/GyulyVGC/sniffnet/issues/new/choose">open an issue</a>, and I will do my best to help you!</strong></em></h3><a id="user-content-in-any-case-dont-hesitate-to-open-an-issue-and-i-will-do-my-best-to-help-you" aria-label="Permalink: In any case, don't hesitate to open an issue, and I will do my best to help you!" href="#in-any-case-dont-hesitate-to-open-an-issue-and-i-will-do-my-best-to-help-you"></a></p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<ul dir="auto">
<li>A big shout-out to <a href="https://github.com/GyulyVGC/sniffnet/blob/main/CONTRIBUTORS.md">all the contributors</a> of Sniffnet!</li>
<li>The graphical user interface has been realized with <a href="https://github.com/iced-rs/iced">iced</a>, a cross-platform GUI library for Rust focused on simplicity and type-safety</li>
<li>IP geolocation and ASN data are provided by <a href="https://www.maxmind.com/" rel="nofollow">MaxMind</a></li>
<li>Last but not least, thanks to <a href="https://github.com/GyulyVGC/sniffnet/stargazers">every single stargazer</a>: all forms of support made it possible to keep improving Sniffnet!</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What is interviewing like now with everyone using AI? (149 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42909166</link>
            <guid>42909166</guid>
            <pubDate>Sun, 02 Feb 2025 15:19:32 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42909166">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="42911944"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911944" href="https://news.ycombinator.com/vote?id=42911944&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I've let people use GPT in coding interviews, provided that they show me how they use it. At the end I'm interested in knowing how a person solves a problem, and thinks about it. Do they just accept whatever crap the gpt gives them, can they take a critical approach to it, etc.</p><p>So far, everyone that elected to use GPT did much worse. They did not know what to ask, how to ask, and did not "collaborate" with the AI. So far my opinion is if you have a good interview process, you can clearly see who are the good candidates with or without ai.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912237"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912237" href="https://news.ycombinator.com/vote?id=42912237&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>We do the same thing. It's perfectly fine for candidates to use AI-assistive tooling provided that they can edit/maintain the code and not just sit in a prompt the whole time. The heavier a candidate relies on LLMs, the worse they often do. It really comes down to discipline.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912619"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912619" href="https://news.ycombinator.com/vote?id=42912619&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>same thing here. Interview is basically a representative thing of what we do, but also depends on the level of seniority. I ask people just to share the screen with me and use whatever you want / fell comfortable with. Google, ChatGPT, call your mom, I don't care as long as you walk me through how you're approaching the thing at hand. We've all googled tar xvcxfgzxfzcsadc, what's that permission for .pem is it 400, etc.. no shame in anything and we all use all of the things through day. Let's simulate a small task at hand and see where we end up at. Similarly, there is a bias where people leaning more on LLMs doing worse than those just googling or, gasp, opening documentation.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912579"><td></td></tr>
                  <tr id="42912049"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912049" href="https://news.ycombinator.com/vote?id=42912049&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>My company, a very very large company, is transitioning back to only in-person interviews due to the rampant amount of cheating happening during interviews.</p><p>As an interviewer, it's wild to me how many candidates think they can get away with it, when you can very obviously hear them typing, then watching their eyes move as they read an answer from another screen. And the majority of the time the answer is incorrect anyway. I'm happy that we won't have to waste our time on those candidates anymore.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912304"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912304" href="https://news.ycombinator.com/vote?id=42912304&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>So depressing to hear that “because of rampant cheating”</p><p>As a person looking for a job, I’m really not sure what to do.  If people are lying on their resumes and cheating in interviews, it feels like there’s nothing I can do except do the same.  Otherwise I’ll remain jobless.</p><p>But to this day I haven’t done either.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912988"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912988" href="https://news.ycombinator.com/vote?id=42912988&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>&gt; it feels like there’s nothing I can do except do the same.</p><p>Why does it feel like that when you’re replying to someone who already points out that it doesn’t work? Cheating can prevent you from getting a job, and it can get you fired from the job too. It can also impede your ability to learn and level up your own skills. I’m glad you haven’t done it yet, just know that you can be a better candidate and increase your chances by not cheating.</p><p>Using an LLM isn’t cheating if the interviewer allows it. Whether they allow it or not, there’s still no substitute for putting in the work. Interviews are a skill that can (and should) be practiced. Candidates are rarely hired for technical skill alone. Attitude, communication, curiosity, and lots of other soft skills are severely underestimated by so many job seekers, especially those coming right out of school. A small amount of strengthening your non-code abilities can improve your odds much faster than leetcode ever will. And if you have time, why not do both?</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912752"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912752" href="https://news.ycombinator.com/vote?id=42912752&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Here's the thing: 95% of cheaters still suck, even when cheating. Its hard to imagine how people can perform so badly while cheating, yet they consistently do. All you need to do to stand out is not be utterly awful. Worrying about what other people are doing is more detrimental to your performance than anything else is. Just focus on yourself: being broadly competent, knowing your niche well, and being good at communicating how you learn when you hit the edges of your knowledge. Those are the skills that always stand out.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912987"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42912987" href="https://news.ycombinator.com/vote?id=42912987&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Yeah, we found this when we started doing take-home exams: it turns out that a junior dev who spends twice as much time on the problem than what we asked them to doesn’t put out senior-level code - we could read the skill level in the code almost instantly. Same thing with cheating like that - it turns out knowing the answer isn’t the same thing as having experience, and it’s pretty obvious pretty quickly which one you’re dealing with.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42912503"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912503" href="https://news.ycombinator.com/vote?id=42912503&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I don't know, I kind of feel like leetcode interviews are a situation where the employer is cheating. I mean, you're admittedly filtering out a great number of acceptable candidates knowing that if you just find 1 in a 1000, that'll be good enough. It is patently unfair to the individuals that are smart enough to do your work, but poor at some farcical representation of the work. That is cheating.</p><p>In my opinion, if a prospective employee is able to successfully use AI to trick me into hiring them, then that is a hell of a lot closer to the actual work they'll be hired to do (compared to leetcode).</p><p>I say, if you can cheat at an interview with AI, do it.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912641"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42912641" href="https://news.ycombinator.com/vote?id=42912641&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>The employer sets the terms of the interview. If you don’t like them, don’t apply.</p><p>What you’re suggesting here isn’t any different than submitting a fraudulent resume because you disagree with the required qualifications.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912678"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42912678" href="https://news.ycombinator.com/vote?id=42912678&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Yea, exactly.</p><p>If a candidate were up front with me and asked if they could use AI, or said they learned an answer from AI and then wanted to discuss it with me, I'd be happy with that. But attempting to hide it and pretend they aren't using it when our interview rules specifically ask you not to do it is just being dishonest, which isn't a characteristic of someone I want to hire.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912662"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42912662" href="https://news.ycombinator.com/vote?id=42912662&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>On principle, what you’re saying has merit. In practice, the market is currently rife with employers submitting job postings with inflated qualifications, for positions that may or may not exist. So there’s bad actors all around and it’s difficult to tell who actually is behaving with integrity.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912863"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42912863" href="https://news.ycombinator.com/vote?id=42912863&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I would like to be paid though. What do I care about the terms of the interview as long as they hire me?</p><p>What is being suggested here is not participating in the mind numbing process that is called ‘applying for a job’.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912953"><td></td></tr>
                        <tr id="42912771"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42912771" href="https://news.ycombinator.com/vote?id=42912771&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I dunno why there is always the assumption in these threads that leetcode is being used. My company has never used leetcode-style questions, and likely never will.</p><p>I work in security, and our questions are pretty basic stuff. "What is cross-site scripting, and how would you protect against it?", "You're tasked with parsing a log file to return the IP addresses that appear at least 10 times, how would you approach this?" Stuff like that. And then a follow-up or two customized to the candidate's response.</p><p>I really don't know how we could possibly make it easier for candidates to pass these interviews. We aren't trying to trick people, or weed people out. We're trying to find people that have the foundational experience required to do the job they're being hired for. Even when people do answer them incorrectly, we try to help them out and give them guidance, because it's really about trying to evaluate how a person thinks rather than making sure they get the right answer.</p><p>I mean hell, it's not like I'm spending hours interviewing people because I get my rocks off by asking people lame questions or rejecting people; I <i>want</i> to hire people! I will go out of my way to advocate for hiring someone that's honest and upfront about being incorrect or not knowing an answer, but wants to think through it with me.</p><p>But cheating? That's a show stopper. If you've been asked to not use ChatGPT, but you use it anyway, you're not getting the benefit of the doubt. You're getting rejected and blacklisted.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42912415"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912415" href="https://news.ycombinator.com/vote?id=42912415&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Note also "And the majority of the time the answer is incorrect anyway."</p><p>I haven't looked for development-related jobs this millennium, but it's unclear to me how effective a crutch AI is for interviews--at least for well-designed and run interviews. Maybe in some narrow domains for junior people.</p><p>As a few of us have written elsewhere, I consider not having in-person  interviews past an initial screen sheer laziness and companies generally deserve whoever they end up with.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42912102"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912102" href="https://news.ycombinator.com/vote?id=42912102&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>When I was interviewing entry level programmers at my last job, we gave them an assignment that should only take a few hours, but we basically didn't care about the code at all.</p><p>Instead, we were looking to see if they followed instructions, and if they left anything out.</p><p>I never had a chance to test it out, since we hadn't hired anyone new in so long, but ChatGPT/etc would almost always fail this exam because of how bad it is at making sure everything was included.</p><p>And bad programmers also failed it.  It always left us with a few candidates that paid attention, and from there we figure if they can do that, they can learn the rest.  It seemed to work quite well.</p><p>I was recently laid off from that company, and now I'm realizing that I really want to see what current-day candidates would turn in.  Oh well.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912362"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912362" href="https://news.ycombinator.com/vote?id=42912362&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>For those tests I never follow the rules, I just make something quick and dirty because I refuse to spend unpaid hours. In the interview the first question is why I didnt follow the instructions, and they think my reason is fair.</p><p>Companies seem to think that we program just for fun and ask to make a full blown app... also underestimating the time candidates actually spend making it.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912830"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42912830" href="https://news.ycombinator.com/vote?id=42912830&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>If you’re spending the time applying and submitting <i>something</i> then you might as well spend the extra 30 minutes or so to do it right, no?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912885"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42912885" href="https://news.ycombinator.com/vote?id=42912885&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Any time someone says ‘should only take a few hours’ they’re far underestimating the time it actually takes.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912939"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42912939" href="https://news.ycombinator.com/vote?id=42912939&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Not if you’re applying to hundreds, or thousands of jobs. Unless you know someone, it’s a quantity game.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                              <tr id="42912207"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912207" href="https://news.ycombinator.com/vote?id=42912207&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>The industry (all industries really) might want to reconsider online applications, or at least privilege in-person resume drop-offs because the escalating ai application/evaluation war that's happening doesn't seem to be helping anyone.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912916"><td></td></tr>
                  <tr id="42912810"><td></td></tr>
                <tr id="42912907"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912907" href="https://news.ycombinator.com/vote?id=42912907&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>For the goal of the interview - showing your knowledge and skills - you are failing miserably. People know what LLMs can do, the interview is about you.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912842"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912842" href="https://news.ycombinator.com/vote?id=42912842&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I guess its more of a question if you can solve the problem without AI.</p><p>In most interview tasks you are not solving the task “with” ai.</p><p>Its AI who solves the task while you watch it do it.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42911155"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911155" href="https://news.ycombinator.com/vote?id=42911155&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>My startup got acquired last year so I haven't interviewed anyone in a while, but my technical interview has always been:</p><p>- share your screen</p><p>- download/open the coding challenge</p><p>- you can use any website, Stack Overflow, whatever, to answer my questions as long as it's on the screenshare</p><p>My goal is to determine if the candidate can be technically productive, so I allow any programming language, IDE, autocompleter, etc, that they want.  I would have no problem with them using GPT/Copilot in addition to all that, as long as it's clear how they're solving it.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912005"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912005" href="https://news.ycombinator.com/vote?id=42912005&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I recently interviewed for my team and tried this same approach. I thought it made sense because I want to see how people can actually work and problem solve given all the tools at their disposal, just like on the job.</p><p>It proved to be awkward and clumsy very quickly. Some candidates resisted it since they clearly thought it would make them judged harsher. Some candidates were on the other extreme and basically tried asking ChatGPT the problem straight up, even though I clarified up front "You can even use ChatGPT as long as you're not just directly asking for the solution to the whole problem and just copy/pasting, obviously."</p><p>After just the initial batch of candidates it became clear it was muddying things too much, so I simply forbade using it for the rest of the candidates, and those interviews went much smoother.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912901"><td></td></tr>
                <tr id="42912925"><td></td></tr>
                  <tr id="42912631"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912631" href="https://news.ycombinator.com/vote?id=42912631&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Did you tell them that you “want to see how people can actually work and problem solve given all the tools at their disposal, just like on the job”? Just curious.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42912263"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912263" href="https://news.ycombinator.com/vote?id=42912263&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>If you really don't penalize them for this, you should clearly state it. Some people may still think they'll be penalized as that is the norm.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912103"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912103" href="https://news.ycombinator.com/vote?id=42912103&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>I did this while hiring last year and the number of candidates who got stuff wrong because they were too proud to just look up the answer was shocking.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912228"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912228" href="https://news.ycombinator.com/vote?id=42912228&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Is it pride or is it hard to shake the (reasonable, I'd say) fear the reviewer will judge regardless of their claims?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912527"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42912527" href="https://news.ycombinator.com/vote?id=42912527&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Exactly. You never know. Some interviewers will penalize you for not having something memorized and having to look it up, some will penalize you for guessing, some will penalize you for simply not knowing and asking for help. Some interviewers will penalize you for coming up with something quick and dirty and then refining it, some will penalize you for jumping right to the final product. There's no consistency.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42911656"><td></td></tr>
            <tr id="42912070"><td></td></tr>
            <tr id="42911761"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42911761" href="https://news.ycombinator.com/vote?id=42911761&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>I'd be fine with the GPT side of things, as long as I could somehow inject poor answers, and see if the interviewee notices and corrects.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911804"><td></td></tr>
            <tr id="42912058"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912058" href="https://news.ycombinator.com/vote?id=42912058&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>the trick is to phrase the problem in a way that GPT4 will always give the incorrect answer (due to vagueness of your problem) and that multiple rounds of guiding/correcting are needed to solve.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912144"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42912144" href="https://news.ycombinator.com/vote?id=42912144&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>That's pretty good because it can exhaust the context window quickly and then it starts spiraling out of control, which would require the candidate to act.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912469"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42912469" href="https://news.ycombinator.com/vote?id=42912469&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>If you only use ChatGPT to code, you are only able to copy paste the llm emitted code, then you ask for changes to the code (to reflect for example the evolution of the product)</p>
              </div></td></tr>
        </tbody></table></td></tr>
                              <tr id="42911909"><td></td></tr>
                <tr id="42912021"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912021" href="https://news.ycombinator.com/vote?id=42912021&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>It's pretty obvious when someone's input focus changes to nothing or when their mouse leaves the screen entirely, or you could just ask to see the display settings to begin. Doesn't solve for multiple computers but it's pretty obvious in real time when someone's actual attention drifts or they suddenly have abilities they didn't have before.</p><p>Either way, screen sharing beats whiteboards. Even if we throw our hands up and give up, we'll be firing frauds before the probationary period ends.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912603"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42912603" href="https://news.ycombinator.com/vote?id=42912603&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>There is nothing fraudulent about using LLMs. If people can use them on the job, it's okay to use them on the interview. They're the calculators of tomorrow if not of today.</p><p>Interviewing just needs to adapt such as by assessing one's open source  projects and contributions. Not much more is needed. And if the candidate completely misrepresents their open source profile, this can be handled by an initial contract-to-hire period.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912848"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42912848" href="https://news.ycombinator.com/vote?id=42912848&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>I agree that there's nothing fraudulent with using a tool you would use on the job when you are interviewing. But in no way are LLMs equivalent to calculators. Calculators actually <i>give the correct answer</i> reliably, unlike LLMs. A sporadically reliable tool is worse than no tool at all.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912656"><td></td></tr>
                                    <tr id="42912517"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912517" href="https://news.ycombinator.com/vote?id=42912517&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I've always just tried to hold a conversation with the candidate, what they think their strengths are weaknesses are and a little probing.</p><p>This works especially well if <i>I</i> don't know the area they're strongest in, because then they get to explain it to me. If I don't understand it then it's a pretty clear signal that they either don't understand it well enough or are a poor communicator. Both are dealbreakers.</p><p>Otherwise, for me, the most important thing is gauging: Aptitude, Motivation and Trustworthiness. If you have these three attributes then I could not possibly give a shit that you don't know how kubernetes operators work, or if you can't invert a binary tree.</p><p>You'll learn when you need it; it's not like the knowledge is somehow esoteric or hidden.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42910568"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42910568" href="https://news.ycombinator.com/vote?id=42910568&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Part of my resume review process is trying to decide if I can trust the person. If their resume seems too AI-generated, I feel less like I can trust that candidate and typically reject the candidate.</p><p>Once you get to the interview process, it's very clear if someone thinks they can use AI to help with the interview process. I'm not going to sit here while you type my question into OpenAI and try to BS a meaningful response to my question 30 seconds later.</p><p>AI-proof interviewing is easy if you know what you're talking about. Look at the candidates resume and ask them to describe some of their past projects. If they can have a meaningful conversation without delays, you can probably trust their resume. It's easy to spot BS whether AI is behind it or not.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42910796"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42910796" href="https://news.ycombinator.com/vote?id=42910796&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>This, and tbh this has always been the best way. Someone who has projects, whether personal or professional, and has the capability to discuss those projects in depth and with passion will usually be a better employee than a leet code specialist.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911672"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42911672" href="https://news.ycombinator.com/vote?id=42911672&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Doesn't even have to be a project per se, if they can discuss some sort of technical topic in depth (i.e. the sort of discussion you might have when discussing potential solutions to a problem) then that's a great sign imo.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42911754"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42911754" href="https://news.ycombinator.com/vote?id=42911754&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Good interviews are a conversation, a dialog to uncover how the person thinks, how they listen, how they approach problems and discuss. Also a bit detail knowledge, but that's only a minor component in the end. Any interview where AI in its current form helps is not good anyway. Keep in mind that in our industry, the interview goes both ways. If the candidate thinks your process is bad then they are less inclined to join your company because they know that their coworkers will have been chosen by a subpar process.</p><p>That said, I'm waiting for an "interview assistant" product. It listens in to the conversation and silently provides concise extra information about the mentioned subjects that can be quickly glanced at without having to enter anything. Or does this already exist?</p><p>Such a product could be useful for coding to. Like watching me over the shoulder and seeing aha, you are working with so-and-so library, let me show you some key parts of the API in this window, or you are trying to do this-and-that, let me give you some hints. Not as intrusive as current assistants that try to write code for you, just some proactive lookup without having to actively seek out information. Anybody knows a product for that?</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912560"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912560" href="https://news.ycombinator.com/vote?id=42912560&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I'm pretty sure I've been in an interview with an 'interview assistant' and that it was another person.</p><p>This was 2-3 years ago in a remote interview. The candidate would hear the question, BS us a bit and then sometimes provide a good answer.</p><p>But then if we asked follow up questions they would blow those.</p><p>They also had odd 'AV issues' which were suspicious.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912178"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912178" href="https://news.ycombinator.com/vote?id=42912178&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>That might be good for newbie developers but for the rest of us it'll end up being the Clippy of AI assistants. If I want to know more about an API I'm using, I'll Google (or ask ChatGPT) for details; I don't need an assistant trying to be helpful and either treating me like a child, or giving me info that maybe right but which I don't need at the moment.</p><p>The only way I can see that working is if it spends hundreds of hours watching you to understand what you know and don't know, and even then it'll be a bit of a crap shoot.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42911301"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42911301" href="https://news.ycombinator.com/vote?id=42911301&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Agreed. This is why - while I won't ding an applicant for not having a public Github, I'm always happy when they do because usually they'll have some passion projects on there that we can discuss.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911949"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42911949" href="https://news.ycombinator.com/vote?id=42911949&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I have 23 years of experience and I am almost invisible on GitHub, and for all those years I've been fired from 4 contracts due to various disconnects (one culture mis-fit and two under-performances due to illness I wasn't aware of at the time, and one because the company literally restructured over the weekend and fired 80% of all engineers), and I have been contracting a lot in the last 10 years (we're talking 17-19 gigs).</p><p>If you look solely at my GitHub you'd likely reject me right away.</p><p>I wish I had the time and energy for passion projects in programming. I so wish it was so. But commercial work has all but destroyed my passion for programming, though I know it can be rekindled if I can ever afford to take a properly long sabbatical (at least 2 years).</p><p>I'll more agree with your parent / sibling comments: take a look at the resume and look for bad signs like too vanilla / AI language, too grandiose claims (though when you are experienced you might come across as such so 50/50), or almost no details, general tone etc.</p><p>And the best indicator is a video call conversation, I found as a candidate. I am confident in what I can do (and have done), I am energetic and love to go for the throat of the problems on my first day (provided the onboarding process allows for it) and it shows -- people have told me that and liked it.</p><p>If we're talking passion, I am more passionate about taking a walk with my wife and discussing the current book we're reading, or getting to know new people, or going to the sauna, or wondering what's the next meetup we should be going to, stuff like that. But passion + work, I stand apart by being casual and not afraid of any tech problems, and by prioritizing being a good teammate first and foremost (several GitHub-centric items come to mind: meaningful PR comments and no minutiae, good commit messages, proper textual comment updates in the PR when f.ex. requirements change a bit, editing and re-editing a list of tasks in the PR description).</p><p>I already do too much programming. Don't hold it against me if I don't live on the computer and thus have no good GitHub open projects. Talk to me. You'll get much better info.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912205"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912205" href="https://news.ycombinator.com/vote?id=42912205&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>To add to this, lots of senior people in the consultanting world are brought in under escalations.  They often have to hide the fact they are an external resource.</p><p>Also if you have a novel or disclosure sensitive passion project, GitHub may be avoided even as a very conservative bright line.</p><p>As stated above I think it can be good to find common points to enhance the interview process, but make sure to not use it as a filter.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42911799"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42911799" href="https://news.ycombinator.com/vote?id=42911799&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Also because most people are busy with actual work and don't have the time to have passion projects. Some people do, and that's great, but most people are simply not passionate about labor, regardless of what kind of labor it is.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42910842"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42910842" href="https://news.ycombinator.com/vote?id=42910842&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>There are much more sophisticated methods than that now with AI, like speech to text to LLM. It's getting increasingly harder to detect interviewees cheating.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911031"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42911031" href="https://news.ycombinator.com/vote?id=42911031&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I think GP's point is that this says as much about the interview design and interviewer skill as it does about the candidate's tools.</p><p>If you do a rote interview that's easy to game with AI, it will certainly be harder to detect them cheating.</p><p>If you have an effective and well designed open ended interview that's more collaborative, you get a lot more signal to filter the wheat from the chaff.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911570"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42911570" href="https://news.ycombinator.com/vote?id=42911570&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>&gt; <i>If you have an effective and well designed open ended interview that's more collaborative, you get a lot more signal to filter the wheat from the chaff.</i></p><p>I understood their point but my point is a direct opposition to theirs, that at some point with AI advances this will essentially become impossible. You can make it as open ended as you want but if AI continues to improve, the human interviewee can simply act as a ventriloquist dummy for the AI and get the job. Stated another way, what kind of "effective and well designed open ended interview" can you make that would not succumb to this problem?</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911872"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42911872" href="https://news.ycombinator.com/vote?id=42911872&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>&gt; at some point with AI advances this will essentially become impossible.</p><p>In-person interviews, second round comes with a plane ticket.  This used to be the norm.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42911739"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42911739" href="https://news.ycombinator.com/vote?id=42911739&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>This is called fraud, and it is a crime.</p><p>People don't really call the police, nor sue over this.  But they can, and have in the past.</p><p>If it gets bad, look for people starting to seek legal recourse.</p><p>People aren't developers with 5 years experience, if all they can do is copy and paste.  Anyone fraudulently claiming so is a scam artist, a liar, and deserves jail time.</p><p>So you create an interview process that can only be passed by a skilled dev, including them signing a doc saying the code is entirely their work, only referencing a language manual/manpages.</p><p>And if they show up to work incapable of doing the same, it's time to call the cops.</p><p>That's probably the only way to deal with scam artists and scum, going forward.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911871"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_42911871" href="https://news.ycombinator.com/vote?id=42911871&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Can you cite case law around where some one misrepresented their capabilities in a job interview and were criminally prosecuted? Like what criminal statute specifically was charged? You won’t find it, because at worst this would fall under a contract dispute and hence civil law. Screeching “fraud is a crime” hysterically serves no one.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912395"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_42912395" href="https://news.ycombinator.com/vote?id=42912395&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Fraud can be described as deceit to profit in some way.  You may note the rigidity of the process above, where I indicated a defined set of conditions.</p><p>It costs employers money to on board someone, not just in pay, but in other employees training that person.  Obviously the case must be clear cut, but I've personally hired someone who clearly cheated during the remote phone interview, and literally couldn't even code a function in any language in person.</p><p>There are people with absolutely no background as a coder, applying to jobs with 5 years experience, then fraudulently misrepresenting the work of others at their own, to get the job.</p><p>That's fraud.</p><p>As I said, it's not being prosecuted as such now.  But if this keeps up?</p><p>You can bet it will be.</p><p>Because it is fraud.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912972"><td></td></tr>
                        <tr id="42912073"><td></td></tr>
                                          <tr id="42912709"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912709" href="https://news.ycombinator.com/vote?id=42912709&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>With AI making traditional coding problems trivial, tech interviews are shifting toward practical, real-world challenges, system design, and debugging exercises rather than pure algorithm puzzles. Some companies are revisiting in-person whiteboarding to assess thought processes, while others embrace AI, evaluating how candidates integrate it into their workflow. There's also a greater focus on explaining decisions, trade-offs, and collaboration. Instead of banning AI, many employers now test how effectively candidates use it while ensuring they have foundational skills. The trend favors assessing problem-solving in real work scenarios rather than just coding ability under artificial constraints.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42911831"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911831" href="https://news.ycombinator.com/vote?id=42911831&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>The traditional tech interview was always designed to optimize for reliably finding someone who was willing to do what they were told even if it feels like busywork. As a rule someone who has the time and the motivation to brush up on an essentially useless skill in order to pass your job interview will likely fit nicely as a cog in your machine.</p><p>AI doesn't just change the interviewing game by making it easy to cheat on these interviews, <i>it should be changing your hiring strategy altogether</i>. If you're still thinking in terms of optimizing for cogs, you're missing the boat—unless you're hiring for a very short term gig what you need now is someone with high creative potential and great teamwork skills.</p><p>And as far as I know there is no reliable template interview for recognizing someone who's good at thinking outside the box and who understands people. You just have to talk to them: talk about their past projects, their past teams, how they learn, how they collaborate. And then you have to get good at understanding what kinds of answers you need for the specific role you're trying to fill, which will likely be different from role to role.</p><p>The days of the interchangeable cog are over, and with them easy answers for interviewing.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911932"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42911932" href="https://news.ycombinator.com/vote?id=42911932&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Have you spent a lot of time trying to hire people? I guarantee you there is no shadow council trying to figure out how to hire "busywork" worker bees. This perspective smells completely like "If I were in charge, things would be so much better." Guess what? If you were to take your idea and try to lead this change across a 100 people engineering org, there would be "out of the box thinkers" who would go against your ideas and cause dissent. At that point, guess what? You're going to figure out how to hire compliant people who will execute on your strategy.</p><p>"talk about their past projects, their past teams, how they learn, how they collaborate"</p><p>You have now excluded amazing engineers who suck at talking about themselves in interviews. They may be great collaborators and communicators, but freeze up selling themselves in an interview.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912575"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912575" href="https://news.ycombinator.com/vote?id=42912575&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>&gt; You have now excluded amazing engineers who suck at talking about themselves in interviews. They may be great collaborators and communicators, but freeze up selling themselves in an interview.</p><p>This was the norm until perhaps for about the last 10-15 years of Software Engineering.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912089"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912089" href="https://news.ycombinator.com/vote?id=42912089&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>My take is:</p><p>- “big” tech companies like Google, Amazon, Microsoft came up with these types of tech interviews. And there it seems pretty clear that for most of their positions they are looking for cogs</p><p>- The vast majority of tech companies have just copied what “big” tech is doing, including tech interviews. These companies may not be looking for cogs, but they are using an interview process that’s not suitable for them</p><p>- Very few companies have their own interview process suitable for them. These are usually small companies and therefore  the number of engineers in such companies is negligible to be taken into account (most likely, less than 1% of the audience here work at such companies)</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912409"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912409" href="https://news.ycombinator.com/vote?id=42912409&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>&gt; I guarantee you there is no shadow council trying to figure out how to hire "busywork" worker bees.</p><p>The council itself is made of "busywork" worker bees. Slave hiring slaves - the vast majority of IT interviewers and candidates are idiot savants - they know very little outside of IT, or even realize  that there is more to life than IT.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42910806"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42910806" href="https://news.ycombinator.com/vote?id=42910806&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>The key is having interviewers that know what they are talking about so in-depth meandering discussions can be had regarding personal and work projects which usually makes it clear whether the applicant knows what they are talking about. Leetcode was only ever a temporary interview technique, and this 'AI' prominence in the public domain has simply sped up it's demise.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911989"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42911989" href="https://news.ycombinator.com/vote?id=42911989&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>This completely..</p><p>You ask a rote question and you'll get a rote answer while the interviewee is busy looking at a fixed point on the screen.</p><p>You then ask a pointed question about something they know or care about, and suddenly their face lights up, they're animated, and they are looking around.</p><p>It's a huge tell.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912589"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912589" href="https://news.ycombinator.com/vote?id=42912589&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>You know, this makes me wonder if a viable remote interview technique, at least until real-time deepfaking gets better, would be to have people close their eyes while talking to them. For somebody who knows their stuff it'll have zero impact; for someone relying entirely on GPT, it will completely derail them.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42910923"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42910923" href="https://news.ycombinator.com/vote?id=42910923&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>This is the way. We do an intro call, an engineering chat (exactly as you describe), a coding challenge and 2 team chat sessions in person. At the end of that, we usually have a good feeling about how sharp the candidate is, of they like to learn and discover new things, what their work ethic is. It's not bullet proof, but it removes a lot of noise from the signal.</p><p>The coding challenge is supposed to be solved with AI. We can no longer afford not to use LLMs for engineering, as it's that much of a productivity boost when used right, so candidates should show how they use LLMs. They need to be able to explain the code of course, and answer questions about it, but for us it's a negative mark of a candidate proclaims that they don't use LLMs.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911061"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42911061" href="https://news.ycombinator.com/vote?id=42911061&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>&gt; <i>The coding challenge is supposed to be solved with AI. We can no longer afford not to use LLMs for engineering, as it's that much of a productivity boost when used right, so candidates should show how they use LLMs. They need to be able to explain the code of course, and answer questions about it, but for us it's a negative mark of a candidate proclaims that they don't use LLMs.</i></p><p>Do you state this upfront or is it some hidden requirement? Generally I'd expect an interview coding exercise to not be done with AI, but if it's a hidden requirement that the interviewer does not disclose, it is unfair to be penalized for not reading their minds.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911225"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42911225" href="https://news.ycombinator.com/vote?id=42911225&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I would say as long as it is stated you can complete the coding exercise using any tool available it is fine. I do agree, no task should be a trick.</p><p>I am personally of the view you should be able to use search engines, AI, anything you want, as the task should be representative of doing the task in person. The key focus has to be the programmer's knowledge and why they did what they did.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911622"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42911622" href="https://news.ycombinator.com/vote?id=42911622&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>One client of mine has a couple repositories for non-mission critical things like their fork of an open source project, decommissioned microservices, a SVG generator for their web front-end, etc.</p><p>They also take this approach of "whatever tool works," but their coding test is "here's some symptoms of the SVG generator misbehaving, figure out what happened and fix it," which requires digging into the commit history, issues, actually looking at the SVG output, etc.</p><p>Once you've figured out how the system architecture works, and the most likely component to be causing the problem, you have to convert part of the code to use a newer, undocumented API exposed by a RPC server that speaks a serialization format that no LLM has ever seen before.  Doing this is actually way faster and accurate using an AI, if you know how to centaur with it and make sure the output is tested to be correct.</p><p>This is a much more representative test of how someone's going to handle doing actual work knocking issues out.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42911707"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42911707" href="https://news.ycombinator.com/vote?id=42911707&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Reminds me of the old joke/story where the Caltech student asks, "Can we use Feynman in this open-book exam?"</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42911995"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42911995" href="https://news.ycombinator.com/vote?id=42911995&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Well, the challenge involves using a python LLM framework to build a simple RAG system for recipes.</p><p>It's not a hidden requirement per se to use LLM assistance, but the candidate should have a good answer ready why they didn't use an LLM to solve the challenge.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912221"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42912221" href="https://news.ycombinator.com/vote?id=42912221&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Why is it a negative that the candidate can solve the challenge without using an LLM? I don’t really understand this.</p><p>Also, what is a good answer for not using one? Will you provide access to one during the course of the interview? Or I am just expected to be paying for one?</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912665"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_42912665" href="https://news.ycombinator.com/vote?id=42912665&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>It's not negative that the candidate can solve it without an LLM, but it is positive if the candidate can use the LLM to speed up the solution. The code challenge is timeboxed.</p><p>We are providing an API key for LLM inference, as implementing the challenge requires this as well.</p><p>And I haven't heard a good answer yet for not using one, ideally the candidate knows how to mitigate the drawbacks of LLMs while benefiting from their utility regardless.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912695"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_42912695" href="https://news.ycombinator.com/vote?id=42912695&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>&gt;I haven’t heard a good answer for not using one</p><p>Again, what would be a good answer? Or are you just saying there isn’t one?</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42912075"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42912075" href="https://news.ycombinator.com/vote?id=42912075&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Ah so you expect mind readers who can divine something from your brain that goes against 99.99% of interviewers' practices and would get them instantly disqualified from an overwhelming majority of interviews. Nice work good luck finding candidates.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42912651"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912651" href="https://news.ycombinator.com/vote?id=42912651&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>&gt; as it's that much of a productivity boost when used right</p><p>Frankly, if an interviewer told me this, I would genuinely wonder why what they're building is such a simple toy product that an LLM can understand it well enough to be productive.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42912328"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912328" href="https://news.ycombinator.com/vote?id=42912328&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>On our side we've transitioned to only in person interviews.</p><p>The biggest thing I've noticed is take home challenges have lost all value. Since GPT can plausibly solve almost anything you throw at it, and it doesn't give you any indication of how the candidate thinks.</p><p>And to be fair, I want a candidate that uses GPT / Cursor / whatever tools get the job done. But reading the same AI solution to a coding challenge doesn't tell me anything about how they think or approach problems.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912498"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912498" href="https://news.ycombinator.com/vote?id=42912498&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I'm not a fan of take-home challenges anyway (for the most part). Anything non-trivial is a big time suck and you <i>know</i> some people will spend all weekend on you two hour assignment.</p><p>Sometimes you have to. In my previous analyst stint a writing sample was pretty non-negotiable unless they could oint to publicly-published material--which was much preferred. ChatGPT isn't much use there except to save some time. It's very formulaic and wouldn't pass though, honestly, some people are worse on their own.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42911710"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911710" href="https://news.ycombinator.com/vote?id=42911710&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I don’t know the answer, but I’d like to share that I asked a simple question about scheduling a phone interview to learn more about a candidate.</p><p>The candidate’s first response? “Memory updated”. That led to some laughs internally and then a clear rejection email.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911725"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42911725" href="https://news.ycombinator.com/vote?id=42911725&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>My first read of this was they made a joke (not wise when scheduling for interviews sure but maybe funny) by intentionally responding that way.</p><p>This is because my brain couldn't fathom what is likely the reality here -- that someone was just pumping your email thru AI and pumping the response back unedited and unsanitized, and so the first thing you got back was just the first "part" of the AI response.</p><p>...Christ.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911928"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42911928" href="https://news.ycombinator.com/vote?id=42911928&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>I'm with you. Looking at the way people respond online to things now since LLMs and GenAI went mainstream is baffling. So many comments along the lines of "this is AI" when there are more ordinary explanations.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42911896"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42911896" href="https://news.ycombinator.com/vote?id=42911896&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Yeah I don't know about this specific situation, but as someone who is on the job market, is a good developer, but can come off as a little odd sometimes, I often wonder how often I roll a natural 1 on my Cha check and get perceived as an AI imposter.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912215"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42912215" href="https://news.ycombinator.com/vote?id=42912215&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>If anything, coming across as “a little odd” can be a sign I’m actually talking to a human.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912524"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42912524" href="https://news.ycombinator.com/vote?id=42912524&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>That's a good point. The major LLMs are all tilted so much towards a weird blend of corpo-speak with third-world underpaid English speaker influence (e.g. "delve", from common Nigerian usage) that having any quirks at all outside that is a good sign.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42912183"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912183" href="https://news.ycombinator.com/vote?id=42912183&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Your perception of the reality is spot on. For this round I was hiring for entry level technical support and we had limited time to properly vet candidates.</p><p>Unfortunately what we end up doing is have to make some assumptions. If something seems remotely fishy, like that “Memory updated” or typeface change (ChatGPT doesn’t follow your text formatting when pasting into your email compose window), it raises a lot of eyebrows and very quickly leads to a rejection. There’s other cases where your written English is flawless but your phone interview indicates you don’t understand the English language compared to when we correspond over email/Indeed/etc.</p><p>Mind you, this is all before we even get to the technical knowledge part of any interview.</p><p>On a related hire, I am also in the unfortunate position where we may have to let a new CS grad go because it seemed like every code change and task we gave him was fully copy/pasted through ChatGPT. When presented with a simple code performance and optimization bug, he was completely lost on general debugging practices which led our team to question his previous work while onboarding. Using AI isn’t against company policy (see: small team with limited resources), but personally I see over reliance on ChatGPT as much, much worse than blindly following Stack Overflow.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912326"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42912326" href="https://news.ycombinator.com/vote?id=42912326&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>&gt; typeface change</p><p>Long live plain text email.</p><pre><code>    ()  ascii ribbon campaign - against HTML e-mail 
    /\  www.asciiribbon.org   - against proprietary attachments</code></pre></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912401"><td></td></tr>
                        <tr id="42912841"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912841" href="https://news.ycombinator.com/vote?id=42912841&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>A friend of mine works with industrial machines, and once was tasked with translating machine's user's manual, even though he doesn't speak English. I do, and I had some free time, so I helped him. As an example, I was given user manual for a different, but similar machine.</p><p>1. The manual was mostly a bunch of phrases that were grammatically correct, but didn't really convey much meaning</p><p>2. The second half of the manual talked about a different machine than the first half</p><p>3. It was full of exceptionally bad mistranslations, and to this day "trained signaturee of the employee" is our inside joke</p><p>Imagine asking ChatGPT to write a manual except ChatGPT has down syndrome and a heart attack so it gives you five pages of complete bullshit. That was real manual that got shipped a 100 000€ or so machine. And nobody bothered to proofread it even once.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912938"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42912938" href="https://news.ycombinator.com/vote?id=42912938&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>I once worked in the US for a Japanese company that had their manuals "translated" into English and then sent on for polishing. Like the parent, it would be mostly "<i>a bunch of phrases that were grammatically correct, but didn't really convey much meaning</i>" .  I couldn't spend more than an hour a day on that kind of thing; more than that and it would start to make sense.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                              <tr id="42912647"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912647" href="https://news.ycombinator.com/vote?id=42912647&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>We haven't seen major issues with AI with candidates on camera. The couple that have tried to cheat have done so rather obviously, and the problem we use is more about problem-solving than it is about reverse-a-linked-list.</p><p>This is borne out by results downstream with clients. No client we've sent more than a couple of people has ever had concerns about quality, so we're fairly confident that we are in fact detecting the cheating that is happening with reasonable consistency.</p><p>I actually just looked at our data a few days ago to see how candidates who listed LLMs or related terms on their resume did on our interview. On average, they did much worse (about half the pass rate, and double the hard-fail rate). I suspect this is a general "corporate BS factor" and not anything about LLMs specifically, but it's certainly relevant.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42910524"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42910524" href="https://news.ycombinator.com/vote?id=42910524&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>As someone currently job searching it hasn’t changed much, besides companies adding DO NOT USE AI warnings before every section. Even Anthropic forces you to write a little “why do you want to work here DO NOT USE AI” paragraph. The irony.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911230"><td></td></tr>
                <tr id="42911728"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42911728" href="https://news.ycombinator.com/vote?id=42911728&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Applying at Anthropic was a bad experience for me. I was invited to do a timed set of leetcode exercises on some website. I didn't feel like doing that, and focused on my other applications.</p><p>Then they emailed me a month later after my "invitation" expired. It looked like it was written by a human: "Hey, we're really interested in your profile, here's a new invite link, please complete this automated pre-screen thingie".</p><p>So I swallowed my pride and went through with that humiliating exercise. Ended up spending two hours doing algorithmic leetcode problems. This was for a product security position. Maybe we could have talked about vulnerabilities that I have found instead.</p><p>I was too slow to solve them and received some canned response.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912150"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42912150" href="https://news.ycombinator.com/vote?id=42912150&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>fyi, that's because (from experience) the last job req I publicly posted generated almost 450 responses, and (quite generously) over a third were simply not relevant.  It was for a full-stack rails eng.  Here, I'm not even including people whose experience was django or even React; I mean people with no web experience at all, or were not in the time zone requested.  Another 20% or so were nowhere near the experience level (senior) requested either.</p><p>The price of people bulk applying with no thought is I have to bulk filter.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912198"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42912198" href="https://news.ycombinator.com/vote?id=42912198&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>So you allow yourself to use AI in order to save time, but we have to put up with the shit[1] companies make up? That's good, it's for the best if I don't work for a company that thinks so lowly of its potential candidates.</p><p>[1]: Including but not limited to: having to manually fill a web form because the system couldn't correctly parse a CV; take-home coding challenges; studying for LeetCode interviews; sending a perfectly worded, boot-licking cover letter.</p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="42910879"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42910879" href="https://news.ycombinator.com/vote?id=42910879&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Changed enormously. Both resumes and interviews are effectively useless now. If our AI agents can't find a portfolio of original work nearly exactly what we want to hire you for then you aren't ever going to hear from us. If you are one of the 1 in 4000 applications who gets an interview then you're already 70% likely to get an offer and the interview is mostly a formality.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912000"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912000" href="https://news.ycombinator.com/vote?id=42912000&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>What worked for me is just ignoring the job listing websites, and calling recruiters directly on the phone. Don’t bother hitting “easy apply” just scroll to the bottom and call the number.</p><p>I’ve also been asked for the first time in ages to come to the companies office to do interviews.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42911194"><td></td></tr>
            <tr id="42910904"><td></td></tr>
                <tr id="42911247"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42911247" href="https://news.ycombinator.com/vote?id=42911247&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I thought that meant what you typically write in the "Experience" section. GP, am I wrong?</p><p>Is everyone writing a "Projects" section by rewording what they wrote in "Experience"?! For me, "Projects" should strictly be personal projects. If not, maybe that's what I'm missing.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42911864"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42911864" href="https://news.ycombinator.com/vote?id=42911864&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Projects are personal projects, or at least projects in which you did a distinguishable effort.</p><p>They don't have to be public to the whole world, you can have links that are only in your resume.</p><p>But if they're on GitHub, they have to be public, since there aren't unlisted repositories.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42912608"><td></td></tr>
                  <tr id="42910984"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42910984" href="https://news.ycombinator.com/vote?id=42910984&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I recently reviewed a medium-complexity assignment—just questions, no coding—and out of six candidates, I only approved one. The others were disqualified because their answers were filled with easily identifiable ChatGPT-generated fluff.</p><p>And I had made it clear that they should use their own words.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912725"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912725" href="https://news.ycombinator.com/vote?id=42912725&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>My company actually encourages the use of AI. My interview process was one relatively complex take home, an explanation of my solutions and thinking, then a live "onsite" (via zoom) where I had to code in front of a senior engineer while thinking aloud.</p><p>If I was incompetent, I could've shoved the problem into o1 on ChatGPT and probably solved the problems, but I wouldn't have been able to provide insight into why I made the design choices I made and how I optimized my solutions, and that would've ultimately gotten me thrown out of the candidate pool.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42909842"><td></td></tr>
                <tr id="42911641"><td></td></tr>
                <tr id="42911803"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42911803" href="https://news.ycombinator.com/vote?id=42911803&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>&gt; hiring market tightened up... that doesn't mean there isn't one</p><p>tightened market is one thing, the absolute insanity of the recruitment process in last couple years with now AI thrown into the mix is really something to behold, test these waters at your own peril</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42911854"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911854" href="https://news.ycombinator.com/vote?id=42911854&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I don't understand why an interviewer would ban the use of AI if they are allowed to use AI in the role.</p><p>The interview is a chance to see how a candidate performs in a work like environment. Let them use the tools they will use on the job and see how well they can perform.</p><p>Even for verbal interviews, if they are using ChatGPT on the side and can manage the conversation satisfactorily then more power to them.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912422"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912422" href="https://news.ycombinator.com/vote?id=42912422&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Run competitions. If you're hiring fresh grads, this is probably the best way to filter by skill. If you can use AI to beat all the other candidates that's a skill by itself. In practice, those that use AI rarely ever make it into the top 10. Add a presentation/demo as part of the criteria to filter out those with bad communication skills.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912195"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912195" href="https://news.ycombinator.com/vote?id=42912195&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Shouldn't a portfolio of personal projects be enough ? In the past couple years I:</p><p>- adapted Java's Regex engine to work on streams of characters</p><p>- wrote a basic parametric geometry engine</p><p>- wrote a debugger for an async framework</p><p>- did innovative work with respect to whole-codebase transformation using macros</p><p>Among other things.</p><p>As for ChatGPT in the context of an interview, I'd only use it if I were asked to do changes on a codebase I don't know in limited time.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912273"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912273" href="https://news.ycombinator.com/vote?id=42912273&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I think the arguments is there is no way to validate it was you that did the work. There's been too many instances of groups that do interviews for others or the work for take homes to help get people placed. There was a big deal about some H1Bs a while back where the people that showed up didn't look anything like the people that interviewed. So I understand both sides.</p><p>It's frustrating though when you've done a lot of work, as you've listed. I think in a good interview maybe going over that code and getting the chance to explain things you did, why you did, or issues you had, could also go a long way.</p><p>Interviewing is tough, more so at scale.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912305"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912305" href="https://news.ycombinator.com/vote?id=42912305&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Bit annoying is that when companies ask for a portfolio, they often mean GitHub.  Lot of non-technical hiring people I discussed this with were confused by the fact that there are other ways to contribute, like mailing lists.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42912344"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912344" href="https://news.ycombinator.com/vote?id=42912344&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>For the time being, I’ve banned LLMs in my interviews.</p><p>I want to see how the candidate reasons about code. So I try to ask practical questions and treat them like pairing sessions.</p><p>- Given a broke piece of code, can you find the bug and get it working?</p><p>- Implement a basic password generator, similar to 1Password (with optional characters and symbols)</p><p>If you can reason about code without an LLM, then you’ll do even better with an LLM. At least, that’s my theory.</p><p>I never ask trick questions. I never pull from Leetcode. I hardly care about time complexity. Just show me you can reason about code. And if you make some mistakes, I won’t judge you.</p><p>I’m trying to be as fair as possible.</p><p>I do understand that LLMs are part of our lives now. So I’m trying to explore ways to integrate them into the interview. But I need more time to ponder.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912478"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912478" href="https://news.ycombinator.com/vote?id=42912478&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Thinking out loud, here’s one idea for an LLM-assisted interview:</p><p>- Spin up a Digital Ocean droplet</p><p>- Add the candidate’s SSH key</p><p>- Have them implement a basic API. It must be publicly accessible.</p><p>- Connect the API to a database. Add more features.</p><p>- Set up a basic deployment pipeline. Could be as simple  as script that copies the code from your local machine to the server.</p><p>Anything would be fair game. The goal would be to see how the candidate converses with the LLM, how they handle unexpected changes, and how they make decisions.</p><p>Just a thought.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42911599"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911599" href="https://news.ycombinator.com/vote?id=42911599&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>I've been on both sides recently, and it hasn't really changed significantly. If you're heming and hawing you're not getting the job.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42911360"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911360" href="https://news.ycombinator.com/vote?id=42911360&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>I have a colleague that uses AI to comment on RFCs. It is so clearly machine generated, that I wonder if I am the only one to see it. 
He is a good colleague though, but as he is a bit junior, it is still not clear to me if AI is helping him to improve faster or if it is hindering his deep learning of stuff.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912443"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912443" href="https://news.ycombinator.com/vote?id=42912443&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>I listened in to someone interviewing people since many people used AI. It's the same with googling the answer it is very obvious that someone is taking too long to get to the answer and or you can't see a separate screen. Mitigation is literally looking at the text window and seeing if they are not typing / taking too long to even make a bad implementation. There is now a problem if you allow for google since google will autogen a gemini query to solve it.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912551"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912551" href="https://news.ycombinator.com/vote?id=42912551&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>I expect in person interviews are going to be the norm soon, assuming they’re not already.  For now, the challenge I give candidates causes ChatGPT to produce convoluted code that a human never would. I then ask the person to explain the code line-by-line and they’re almost never able to give a satisfactory answer</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912251"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912251" href="https://news.ycombinator.com/vote?id=42912251&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>If your interview process is susceptible to AI then you don't need to hire for the job. Just use an AI and prompt it.</p><p>The job you are therefore hiring for is now trivial. If it weren't, no amount of AI could pass your interview process.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912666"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912666" href="https://news.ycombinator.com/vote?id=42912666&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I belive this line of thinking mistakes the result with the process, similar to assuming that the reason companies ask people to reverse a linked list is because there's an unmet market demand for list-reversal algorithms.</p><p>An interview has to be hard enough to filter those that are unqualified but also easy enough that the right person can pass with some minor preparation. If an interviewer asked me for the equivalent of production-ready code to add support for custom hardware in the Linux kernel I'd either reply with my freelance hourly rate or I'd end the interview.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42911743"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911743" href="https://news.ycombinator.com/vote?id=42911743&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>In my most recent cycle, I didn’t ask to use AI and I was only warned once about using AI when I had the official language plugin for an IDE annotate some struct fields with json tags. I explained the plugin functionality and we moved on.</p><p>When I was part of interviews on the other side for my former employer, I encountered multiple candidates who appeared to be using AI assistance without notifying the interviewers ahead of time or at all.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42911615"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911615" href="https://news.ycombinator.com/vote?id=42911615&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I've been very curious about this and about how we should modify our hiring. Its obvious that an individual should be able to use AI companions to build better, faster, higher quality things... But the skillsets are sooo uneven now that its unfair to those who are with and without.</p><p>I think it ultimately comes back to impact (like always) which has remained largely unchanged.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42911683"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911683" href="https://news.ycombinator.com/vote?id=42911683&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I haven't done any hiring in a while, but my feelings on the matter:</p><p>If they can talk through the technology and code fluently, honestly, I don't care how they do the work. Honestly I feel like the ability to communicate is a far more important skill than the precise technology.</p><p>This is of course presumes you have a clue about the technology you're hiring for.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42911905"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911905" href="https://news.ycombinator.com/vote?id=42911905&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Buddy of mine recently got a position with the help of custom built model that was listening on the call and printed answers on another screen. The arms race is here and frankly, given that a lot of people are already using it at work, there is no way to stop it short of minute upon minute supervision and even biggest micromanagers won't be able to deal with it.</p><p>Honestly, if I could trust that companies won't try to evaluate my conversation through 20 different ridiculous filters, I would probably argue that my buddy is out of line.. As it stands, however, he is merely leveling out the playing field. But, just life with WFH, management class does not like that imposition one bit.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42912256"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912256" href="https://news.ycombinator.com/vote?id=42912256&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>People are sending us emails that are not just written with chatgpt, but I think they've automated the process as well, as parts of the prompt slip in.</p><p>You can see things in the emails like:</p><p>"I provided a concise, polite response from a candidate to a job rejection, expressing gratitude, a desire for feedback, and interest in future opportunities."</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912851"><td></td></tr>
                  <tr id="42911523"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911523" href="https://news.ycombinator.com/vote?id=42911523&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Panel interviews seem to be more common.  Curious if others have seen the same?  I personally feel very uncomfortable coding in front of a group.  First one of these I tried had like 5 people watching and I lost my nerve and bailed. :|</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912281"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912281" href="https://news.ycombinator.com/vote?id=42912281&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Panels and live programming assignments are such an awful idea. Is that what the workplace is like? Doo they want people who can work under those conditions? I've been a working professional for 18 years who gives public talks regularly and I can still see myself clamming up in that situation. Everyone knows it's hard to think and type when you are being watched.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42912676"><td></td></tr>
            <tr id="42911525"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911525" href="https://news.ycombinator.com/vote?id=42911525&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>It's still remote. I don't get how you could pass an interview using ChatGPT unless it's purely leetcode.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42911737"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911737" href="https://news.ycombinator.com/vote?id=42911737&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I can't speak for job interviewing, but having recently completed 3rd-semester trade-school oral exams in Java programming:</p><p>It is really important to watch people code.</p><p>Anyone can fake an abstract overview.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42911801"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911801" href="https://news.ycombinator.com/vote?id=42911801&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>It can be weird. Seen some decent resumes for people that in the actual interview the candidate obviously has zero demonstrable knowledge of.</p><p>Ask even the shallowest question and they are lost and just start regurgitating what feels like very bad prompt based responses.</p><p>At that point it's just about closing down the interview without being unprofessional.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42910395"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42910395" href="https://news.ycombinator.com/vote?id=42910395&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Not sure why interviews would change.</p><p>Even if you're using ChatGPT heavily it's your job to ensure it's right. And you need to know what to ask it. So you still need all the same skills and conceptual understanding as before.</p><p>I mean, I didn't observe interviews change after powerful IDE's replaced basic text editors.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42910678"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42910678" href="https://news.ycombinator.com/vote?id=42910678&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Because interviews were always an attempt to discern a signal few hours interview into an accurate prediction of performance from months to years. AIs generate a lot of nosie to mask that. Interviewees can just pass the question to the AI, who will generate a reasonable sounding response.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42910571"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42910571" href="https://news.ycombinator.com/vote?id=42910571&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>Because there's a format of interview that's basically a brainteaser that takes 45 minutes to think through and whiteboard some code for, but which is trivially solvable by copy and pasting a screenshot of the prompt into ChatGPT. This amounts to candidates being given the answer and then pretending to struggle with understanding your question and then figuring out a solution to it when really they're just stalling for time and then just copying the answer from one browser tab to the next.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42912126"><td></td></tr>
            <tr id="42912698"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912698" href="https://news.ycombinator.com/vote?id=42912698&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>This conversation feels bizarrely tone deaf. The skill of being able to recall specific knowledge on demand is going away.</p><p>How LLMs will evaluate a skill they are making obsolete is a question I am not sure I understand.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912736"><td></td></tr>
                  <tr id="42910403"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42910403" href="https://news.ycombinator.com/vote?id=42910403&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I mentioned this in a different related post but there seems to be a pretty sad lack of basic integrity in the tech world where it's become a point of pride to develop and use apps which allow an applicant to blatantly cheat during interviews using LLMs.</p><p>As a result, several of my friends who assist in hiring at their companies have already returned to "on-site" interviews. The funny thing about this is that these are 100% remote jobs - but the interviews are being conducted at shared workspaces. This is what happens when the level of trust goes down to zero due to bad actors.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912077"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42912077" href="https://news.ycombinator.com/vote?id=42912077&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>Largely past COVID it seems like sheer laziness or cheapness not to conduct in-person interviews for a professional job other than a short-term project after essentially an initial screen for all sorts of reasons that have little to do with cheating. I don’t care if the job is largely remote.</p><p>As someone else noted, this used to be utterly standard. And frankly I’d probably just pass on someone who balked. Plenty of fish in the sea.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42911837"><td></td></tr>
            <tr id="42910634"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42910634" href="https://news.ycombinator.com/vote?id=42910634&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div>
                  <p>There are some tools that read your screen and can provide hints and solutions for coding type questions. I honestly don't trust myself to not mess it up, plus the whole ethics side of it, but I'm sure that will always be a problem for online assessments</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42911686"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42911686" href="https://news.ycombinator.com/vote?id=42911686&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>I tell everyone to share their entire screen, have their video on, and start coding. It's not that different. Even as an interviewer, I experimented with the usual cheating techniques so I know what to look out for. The best are the AI teleprompters. If you can do the work with your own AI then I see no need to care as the business will not care either.</p><p>The story is completely different for airgapped dark room jobs, but if you know you know.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42912555"><td></td></tr>
                  <tr id="42912661"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42912661" href="https://news.ycombinator.com/vote?id=42912661&amp;how=up&amp;goto=item%3Fid%3D42909166"></a></center>    </td><td><br><div><p>If a problem can be “trivially” solved by GPT. The problem is with your interview process, not the tool. It’s wild to me that interviewers still ask candidates for senior positions leetcode type questions. Yet the actual job is for some front end or devops position.</p><p>The gap between interview and actual on job duties is very wide at many — delusional - companies.</p></div></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Lume – OS lightweight CLI for MacOS & Linux VMs on Apple Silicon. (228 pts)]]></title>
            <link>https://github.com/trycua/lume</link>
            <guid>42908061</guid>
            <pubDate>Sun, 02 Feb 2025 11:46:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/trycua/lume">https://github.com/trycua/lume</a>, See on <a href="https://news.ycombinator.com/item?id=42908061">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><strong>lume</strong> is a lightweight Command Line Interface and local API server to create, run and manage macOS and Linux virtual machines (VMs) with near-native performance on Apple Silicon, using Apple's <code>Virtualization.Framework</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Run prebuilt macOS images in just 1 step</h3><a id="user-content-run-prebuilt-macos-images-in-just-1-step" aria-label="Permalink: Run prebuilt macOS images in just 1 step" href="#run-prebuilt-macos-images-in-just-1-step"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/trycua/lume/blob/main/img/cli.png"><img src="https://github.com/trycua/lume/raw/main/img/cli.png" alt="lume cli"></a>
</p>
<div dir="auto" data-snippet-clipboard-copy-content="lume run macos-sequoia-vanilla:latest"><pre>lume run macos-sequoia-vanilla:latest</pre></div>
<p dir="auto">For a python interface, check out <a href="https://github.com/trycua/pylume">pylume</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="lume <command>

Commands:
  lume create <name>            Create a new macOS or Linux VM
  lume run <name>               Run a VM
  lume ls                       List all VMs
  lume get <name>               Get detailed information about a VM
  lume set <name>               Modify VM configuration
  lume stop <name>              Stop a running VM
  lume delete <name>            Delete a VM
  lume pull <image>             Pull a macOS image from container registry
  lume clone <name> <new-name>  Clone an existing VM
  lume images                   List available macOS images in local cache
  lume ipsw                     Get the latest macOS restore image URL
  lume prune                    Remove cached images
  lume serve                    Start the API server

Options:
  --help     Show help [boolean]
  --version  Show version number [boolean]

Command Options:
  create:
    --os <os>            Operating system to install (macOS or linux, default: macOS)
    --cpu <cores>        Number of CPU cores (default: 4)
    --memory <size>      Memory size, e.g., 8GB (default: 4GB)
    --disk-size <size>   Disk size, e.g., 50GB (default: 40GB)
    --display <res>      Display resolution (default: 1024x768)
    --ipsw <path>        Path to IPSW file or 'latest' for macOS VMs

  run:
    --no-display         Do not start the VNC client app
    --shared-dir <dir>   Share directory with VM (format: path[:ro|rw])
    --mount <path>       For Linux VMs only, attach a read-only disk image

  set:
    --cpu <cores>        New number of CPU cores
    --memory <size>      New memory size
    --disk-size <size>   New disk size

  delete:
    --force              Force deletion without confirmation

  pull:
    --registry <url>     Container registry URL (default: ghcr.io)
    --organization <org> Organization to pull from (default: trycua)

  serve:
    --port <port>        Port to listen on (default: 3000)"><pre>lume <span>&lt;</span>command<span>&gt;</span>

Commands:
  lume create <span>&lt;</span>name<span>&gt;</span>            Create a new macOS or Linux VM
  lume run <span>&lt;</span>name<span>&gt;</span>               Run a VM
  lume ls                       List all VMs
  lume get <span>&lt;</span>name<span>&gt;</span>               Get detailed information about a VM
  lume <span>set</span> <span>&lt;</span>name<span>&gt;</span>               Modify VM configuration
  lume stop <span>&lt;</span>name<span>&gt;</span>              Stop a running VM
  lume delete <span>&lt;</span>name<span>&gt;</span>            Delete a VM
  lume pull <span>&lt;</span>image<span>&gt;</span>             Pull a macOS image from container registry
  lume clone <span>&lt;</span>name<span>&gt;</span> <span>&lt;</span>new-name<span>&gt;</span>  Clone an existing VM
  lume images                   List available macOS images <span>in</span> <span>local</span> cache
  lume ipsw                     Get the latest macOS restore image URL
  lume prune                    Remove cached images
  lume serve                    Start the API server

Options:
  --help     Show <span>help</span> [boolean]
  --version  Show version number [boolean]

Command Options:
  create:
    --os <span>&lt;</span>os<span>&gt;</span>            Operating system to install (macOS or linux, default: macOS)
    --cpu <span>&lt;</span>cores<span>&gt;</span>        Number of CPU cores (default: 4)
    --memory <span>&lt;</span>size<span>&gt;</span>      Memory size, e.g., 8GB (default: 4GB)
    --disk-size <span>&lt;</span>size<span>&gt;</span>   Disk size, e.g., 50GB (default: 40GB)
    --display <span>&lt;</span>res<span>&gt;</span>      Display resolution (default: 1024x768)
    --ipsw <span>&lt;</span>path<span>&gt;</span>        Path to IPSW file or <span><span>'</span>latest<span>'</span></span> <span>for</span> macOS VMs

  run:
    --no-display         Do not start the VNC client app
    --shared-dir <span>&lt;</span>dir<span>&gt;</span>   Share directory with VM (format: path[:ro<span>|</span>rw])
    --mount <span>&lt;</span>path<span>&gt;</span>       For Linux VMs only, attach a read-only disk image

  set:
    --cpu <span>&lt;</span>cores<span>&gt;</span>        New number of CPU cores
    --memory <span>&lt;</span>size<span>&gt;</span>      New memory size
    --disk-size <span>&lt;</span>size<span>&gt;</span>   New disk size

  delete:
    --force              Force deletion without confirmation

  pull:
    --registry <span>&lt;</span>url<span>&gt;</span>     Container registry URL (default: ghcr.io)
    --organization <span>&lt;</span>org<span>&gt;</span> Organization to pull from (default: trycua)

  serve:
    --port <span>&lt;</span>port<span>&gt;</span>        Port to listen on (default: 3000)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="brew tap trycua/lume
brew install lume"><pre>brew tap trycua/lume
brew install lume</pre></div>
<p dir="auto">You can also download the <code>lume.pkg.tar.gz</code> archive from the <a href="https://github.com/trycua/lume/releases">latest release</a>, extract it, and install the package manually.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Prebuilt Images</h2><a id="user-content-prebuilt-images" aria-label="Permalink: Prebuilt Images" href="#prebuilt-images"></a></p>
<p dir="auto">Pre-built images are available on <a href="https://github.com/orgs/trycua/packages">ghcr.io/trycua</a>.
These images come with an SSH server pre-configured and auto-login enabled.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Image</th>
<th>Tag</th>
<th>Description</th>
<th>Size</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>macos-sequoia-vanilla</code></td>
<td><code>latest</code>, <code>15.2</code></td>
<td>macOS Sonoma 15.2</td>
<td>40GB</td>
</tr>
<tr>
<td><code>macos-sequoia-xcode</code></td>
<td><code>latest</code>, <code>15.2</code></td>
<td>macOS Sonoma 15.2 with Xcode command line tools</td>
<td>50GB</td>
</tr>
<tr>
<td><code>ubuntu-noble-vanilla</code></td>
<td><code>latest</code>, <code>24.04.1</code></td>
<td><a href="https://ubuntu.com/download/server/arm" rel="nofollow">Ubuntu Server for ARM 24.04.1 LTS</a> with Ubuntu Desktop</td>
<td>20GB</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">For additional disk space, resize the VM disk after pulling the image using the <code>lume set &lt;name&gt; --disk-size &lt;size&gt;</code> command.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Local API Server</h2><a id="user-content-local-api-server" aria-label="Permalink: Local API Server" href="#local-api-server"></a></p>
<p dir="auto"><code>lume</code> exposes a local HTTP API server that listens on <code>http://localhost:3000/lume</code>, enabling automated management of VMs.</p>

<p dir="auto">For detailed API documentation, please refer to <a href="https://github.com/trycua/lume/blob/main/docs/API-Reference.md">API Reference</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docs</h2><a id="user-content-docs" aria-label="Permalink: Docs" href="#docs"></a></p>
<ul dir="auto">
<li><a href="https://github.com/trycua/lume/blob/main/docs/API-Reference.md">API Reference</a></li>
<li><a href="https://github.com/trycua/lume/blob/main/docs/Development.md">Development</a></li>
<li><a href="https://github.com/trycua/lume/blob/main/docs/FAQ.md">FAQ</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome and greatly appreciate contributions to lume! Whether you're improving documentation, adding new features, fixing bugs, or adding new VM images, your efforts help make lume better for everyone. For detailed instructions on how to contribute, please refer to our <a href="https://github.com/trycua/lume/blob/main/CONTRIBUTING.md">Contributing Guidelines</a>.</p>
<p dir="auto">Join our <a href="https://discord.gg/8p56E2KJ" rel="nofollow">Discord community</a> to discuss ideas or get assistance.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">lume is open-sourced under the MIT License - see the <a href="https://github.com/trycua/lume/blob/main/LICENSE">LICENSE</a> file for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Trademarks</h2><a id="user-content-trademarks" aria-label="Permalink: Trademarks" href="#trademarks"></a></p>
<p dir="auto">Apple, macOS, and Apple Silicon are trademarks of Apple Inc. Ubuntu and Canonical are registered trademarks of Canonical Ltd. This project is not affiliated with, endorsed by, or sponsored by Apple Inc. or Canonical Ltd.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Stargazers over time</h2><a id="user-content-stargazers-over-time" aria-label="Permalink: Stargazers over time" href="#stargazers-over-time"></a></p>
<p dir="auto"><a href="https://starchart.cc/trycua/lume" rel="nofollow"><img src="https://camo.githubusercontent.com/561442573e1c2212a9bfb1ba7e7bb847cfbf6f205c18769dbb73f4ea9cd1dd24/68747470733a2f2f7374617263686172742e63632f7472796375612f6c756d652e7376673f76617269616e743d6164617074697665" alt="Stargazers over time" data-canonical-src="https://starchart.cc/trycua/lume.svg?variant=adaptive"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spaced repetition can allow for infinite recall (2022) (132 pts)]]></title>
            <link>https://www.efavdb.com/memory%20recall</link>
            <guid>42908041</guid>
            <pubDate>Sun, 02 Feb 2025 11:42:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.efavdb.com/memory%20recall">https://www.efavdb.com/memory%20recall</a>, See on <a href="https://news.ycombinator.com/item?id=42908041">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
            <p>
         <img src="https://www.efavdb.com/images/jeopardy.jpg">
</p>

<p>My friend Andrew is an advocate of the “spaced repetition” technique for
memorization of a great many facts [1].  The ideas behind this are&nbsp;two-fold:</p>
<ul>
<li>
<p>When one first “learns” a new fact, it needs to be reviewed frequently in
  order to not forget it.  However, with each additional review, the fact can
be retained longer before a refresher is needed to maintain it in&nbsp;recall.</p>
</li>
<li>
<p>Because of this, one can maintain a large, growing body of facts in recall
  through daily review:  Each day, one need only review for ten minutes or so,
covering a small number of facts. The facts included should be sampled from the
full library in a way that prefers newer entries, but that also sprinkles in
older facts often enough so that none are ever forgotten.  Apps have been
written to intelligently take care of the sampling process for&nbsp;us.</p>
</li>
</ul>
<p>Taking this framework as correct motivates questioning exactly how far it can
be pushed:  <em>Would an infinitely-long-lived, but forgetful person be able to
recall an infinite number of facts using this method? </em>  <span>\(\ldots\)</span> Below, we
show that the answer is: <em><span>YES</span>!</em></p>
<h5>Proof:</h5>
<p>We first posit that the number of days <span>\(T\)</span> that a fact can be retained before
it needs to be reviewed grows as a power-law in <span>\(s\)</span>, the number of times it’s
been reviewed so&nbsp;far,</p>
<p>\begin{eqnarray} \tag{1}\label{1}
T(s) \sim s^{\gamma},
\end{eqnarray}</p>
<p>
with <span>\(\gamma &gt; 0\)</span>. With this assumption, if <span>\(N(t)\)</span> facts are to be recalled
from <span>\(t\)</span> days ago, one can show that the amount of work needed today to retain
these will go like (see appendix for a proof of this&nbsp;line)</p>
<p>\begin{eqnarray}\tag{2}\label{2}
w(t) \sim \frac{N(t)}{t^{\gamma / (\gamma + 1)}}.
\end{eqnarray}</p>
<p>
The total work needed today is then the sum of work needed for each past day’s&nbsp;facts,</p>
<p>\begin{eqnarray} \tag{3} \label{3}
W(total) = \int_1^{\infty} \frac{N(t)}{t^{\gamma / (\gamma + 1)}} dt.
\end{eqnarray}</p>
<p>
Now, each day we only have a finite amount of time to study.  However, the
above total work integral will diverge at large <span>\(t\)</span> unless it decays faster
than <span>\(1/t\)</span>.  To ensure this, we can limit the number of facts retained from
from <span>\(t\)</span> days ago to go&nbsp;as</p>
<p>\begin{eqnarray} \tag{4} \label{4}
N(t) \sim \frac{1}{t^{\epsilon}} \times \frac{1}{t^{1 / (\gamma + 1)}},
\end{eqnarray}</p>
<p>
where <span>\(\epsilon\)</span> is some small, positive constant.  Plugging (\ref{4}) into
(\ref{3}) shows that we are guaranteed a finite required study time each day.
However, after <span>\(t\)</span> days of study, the total number of facts retained scales&nbsp;as</p>
<p>\begin{eqnarray}
N_{total}(t) &amp;\sim &amp; \int_1^{t} N(t) dt \\
&amp;\sim &amp; \int_0^{t} \frac{1}{t^{1 / (\gamma + 1)}} \\
&amp;\sim &amp; t^{ \gamma / (\gamma + 1)}. \tag{5} \label{5}
\end{eqnarray}</p>
<p>
Because we assume that <span>\(\gamma &gt; 0\)</span>, this grows without bound over time,
eventually allowing for an infinitely large&nbsp;library.</p>
<p>We conclude that — though we can’t remember a fixed number of facts from each
day in the past using spaced repetition — we can ultimately recall an infinite
number of facts using this method.  To do this only requires that we gradually
curate our previously-introduced facts so that the scaling (\ref{4}) holds at
all&nbsp;times.</p>
<h3>Appendix: Proof of&nbsp;(2)</h3>
<p>Recall that we assume <span>\(N(s)\)</span> facts have been reviewed exactly <span>\(s\)</span> times.  On a
given day, the number of these that need to be reviewed then goes&nbsp;like</p>
<p>\begin{eqnarray} \tag{A1}\label{A1}
W(s) \sim \frac{N(s)}{T(s)}.
\end{eqnarray}</p>
<p>
where <span>\(T(s)\)</span> is given in (\ref{1}).  This holds because each of the <span>\(N(s)\)</span>
facts that have been studied <span>\(s\)</span> times so far must be reviewed within <span>\(T(s)\)</span>
days, or one will be forgotten.  During these <span>\(T(s)\)</span> days, each will move to
having been reviewed <span>\(s+1\)</span> times.&nbsp;Therefore,</p>
<p>\begin{eqnarray} \tag{A2} \label{A2}
\frac{ds}{dt} &amp;\sim &amp; \frac{1}{T(s)}
\end{eqnarray}</p>
<p>
Integrating this gives <span>\(s\)</span> as a function of <span>\(t\)</span>,</p>
<p>\begin{eqnarray} \tag{A3} \label{A3}
s \sim t^{1 / (\gamma + 1)}
\end{eqnarray}</p>
<p>Plugging this last line and (1) into (A1), we get&nbsp;(2).</p>
<h2>References</h2>
<p>[1] See Andrew’s blog post on spaced repetition <a href="https://andrewjudson.com/spaced-repitition/2022/06/03/spaced-repitition.html">
here</a>.</p>



             
 
                

                <hr>
    <p><a href="" target="_blank" rel="nofollow noopener noreferrer">
            <img src="https://www.efavdb.com/wp-content/uploads/2014/12/JonathanLinkedIn.jpg" alt="Jonathan Landy Avatar" title="Jonathan Landy">
            
        </a>
        Jonathan grew up in the midwest and then went to school at Caltech and&nbsp;UCLA. Following this, he did two postdocs, one at UCSB and one at UC Berkeley. &nbsp;His academic research focused primarily on applications of statistical mechanics, but his professional passion has always been in the mastering, development, and practical application of slick&nbsp;math methods/tools. He currently works as a data-scientist at Stitch Fix.
    </p>

            






            <hr>
            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reverse-engineering and analysis of SanDisk High Endurance microSDXC card (2020) (223 pts)]]></title>
            <link>https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/</link>
            <guid>42907766</guid>
            <pubDate>Sun, 02 Feb 2025 10:32:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/">https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/</a>, See on <a href="https://news.ycombinator.com/item?id=42907766">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><strong>TL;DR – The SanDisk High Endurance cards use SanDisk/Toshiba <a href="https://www.tomshardware.com/news/wd-sandisk-bics3-64-layer-3d-nand,32328.html" target="_blank" rel="noopener">3D TLC Flash</a>. It took way, way more work than it should have to figure this out (thanks for nothing, SanDisk!).<br>
In contrast, the SanDisk MAX Endurance uses the same 3D TLC in pMLC (pseudo-multi-level cell) mode.</strong></p><p>In a <a href="https://ripitapart.com/2019/08/17/unboxing-and-review-of-sandisk-64gb-microsdxc-high-endurance-card/" target="_blank" rel="noopener">previous blog post</a>, I took a look at SanDisk’s microSD cards that were aimed for use in write-intensive applications like dash cameras. In that post I took a look at its performance metrics, and speculated about what sort of NAND Flash memory is used inside. SanDisk doesn’t publish any detailed specifications about the cards’ internal workings, so that means I have no choice but to reverse-engineer the <del>can of worms</del> card myself.</p><p>In the hopes of uncovering more information, I sent an email to SanDisk’s support team asking about what type of NAND Flash they are using in their High Endurance lineup of cards, alongside endurance metrics like P/E (Program/Erase) cycle counts and total terabytes written (TBW). Unfortunately, the SanDisk support rep couldn’t provide a satisfactory answer to my questions, as they’re not able to provide any information that’s not listed in their public spec sheets. They said that all of their cards use MLC Flash, which I guess is correct if you call TLC Flash 3-bit MLC (which Samsung does).</p><div>
<blockquote><p>Dear Jason,</p>
<p>Thank you for contacting SanDisk® Global customer care. We really appreciate you being a part of our SanDisk® family.</p>
<p>I understand that you wish to know more about the SanDisk® High Endurance video monitoring card, as such please allow me to inform you that all our SanDisk® memory cards uses Multi level cell technology (MLC) flash. However, the read/write cycles for the flash memory is not published nor documented only the read and write speed in published as such they are 100 MB/S &amp; 40 MB/s. The 64 GB card can record Full HD video up to 10,000 hours. To know more about the card you may refer to the link below:</p>
<p><a title="Click to follow link: https://www.sandisk.com/home/memory-cards/microsd-cards/high-endurance-microsd" href="https://www.sandisk.com/home/memory-cards/microsd-cards/high-endurance-microsd" target="_blank" rel="noopener">SANDISK HIGH ENDURANCE VIDEO MONITORING microSD CARD</a></p>
<p>Best regards,<br>
Allan B.<br>
SanDisk® Global Customer Care</p></blockquote>
<p>I’ll give them a silver star that says “You Tried” at least.</p>
<h2>Anatomy of an SD Card</h2>
<p>While (micro)SD cards feel like a solid monolithic piece of technology, they’re made up of multiple different chips, each performing a different role. A basic SD card will have a controller that manages the NAND Flash chips and communicates with the host (PC, camera, etc.), and the NAND Flash itself (made up of 1 or more Flash dies). Bunnie Huang’s blog, Bunnie Studios, has an excellent article on the internals of SD cards, including counterfeits and how they’re made – check it out <a href="https://www.bunniestudios.com/blog/?p=3554" target="_blank" rel="noopener">here</a>.</p>
<div data-shortcode="caption" id="attachment_2132"><p><a href="https://ripitapart.com/wp-content/uploads/2019/10/sd-card-anatomy-2.png"><img aria-describedby="caption-attachment-2132" data-attachment-id="2132" data-permalink="https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/sd-card-anatomy/" data-orig-file="https://ripitapart.com/wp-content/uploads/2019/10/sd-card-anatomy-2.png" data-orig-size="268,476" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SD Card Anatomy" data-image-description="<p>Block diagram of a typical SD card.</p>
" data-image-caption="<p>Block diagram of a typical SD card.</p>
" data-medium-file="https://ripitapart.com/wp-content/uploads/2019/10/sd-card-anatomy-2.png?w=169" data-large-file="https://ripitapart.com/wp-content/uploads/2019/10/sd-card-anatomy-2.png?w=268" src="https://ripitapart.com/wp-content/uploads/2019/10/sd-card-anatomy-2.png?w=584" alt="SD Card Anatomy" srcset="https://ripitapart.com/wp-content/uploads/2019/10/sd-card-anatomy-2.png 268w, https://ripitapart.com/wp-content/uploads/2019/10/sd-card-anatomy-2.png?w=84&amp;h=150 84w" sizes="(max-width: 268px) 100vw, 268px"></a></p><p id="caption-attachment-2132">Block diagram of a typical SD card.</p></div>
<p>MicroSD cards often (but not always!) include test pads, used to program/test the NAND Flash during manufacture. These can be exploited in the case of <a href="https://blog.acelaboratory.com/pc-3000-flash-monolith-pinout-research.html" target="_blank" rel="noopener">data recovery</a>, or to reuse microSD cards that have a defective controller or firmware by turning the card into a piece of raw NAND Flash – check out Gough Lui’s adventures <a href="https://goughlui.com/2015/04/05/teardown-optimization-comsol-8gb-usb-flash-stick-au6989sn-gt-sdtnrcama-008g/" target="_blank" rel="noopener">here</a>. Note that there is no set standard for these test pads (even for the same manufacturer!), but there are common patterns for some manufacturers like SanDisk that make reverse-engineering easier.</p>
<h2>Crouching Controller, Hidden Test Pads</h2>
<p>microSD cards fall into a category of “monolithic” Flash devices, as they combine a controller and raw NAND Flash memory into a single, inseparable package. Many manufacturers break out the Flash’s data bus onto hidden (and nearly completely undocumented) test pads, which some other memory card and USB drive manufacturers take advantage of to make cheap storage products using failed parts; the controller can simply be electrically disabled and the Flash is then used as if it were a regular chip.</p>
<p>In the case of SanDisk cards, there is very limited information on their cards’ test pad pinouts. Each generation has slight differences, but the layout is mostly the same. <del>These differences can be fatal, as the power and ground connections are sometimes reversed (this spells instant death for a chip if its power polarity is mixed up!).</del></p>
<p><strong>CORRECTION (July 22, 2020):</strong> <em>Upon further review, I might have accidentally created a discrepancy between the leaked pinouts online, versus my own documentation in terms of power polarity; see the “Test Pad Pinout” section.</em></p>
<p>My card (and many of their higher-end cards – that is, not their Ultra lineup) features test pads that aren’t covered by solder mask, but are instead covered by some sort of screen-printed epoxy with a laser-etched serial number on top. With a bit of heat and some scraping, I was able to remove the (very brittle) coating on top of the test pads; this also removed the serial number which I believe is an anti-tamper measure by SanDisk.</p>

		
		

<p>After cleaning off any last traces of the epoxy coating, I was greeted with the familiar SanDisk test pad layout, plus a few extra on the bottom.</p>
<h2>Building the Breakout Board</h2>
<p>The breakout board is relatively simple in concept: for each test pad, bring out a wire that goes to a bigger test point for easier access, and wire up the normal SD bus to an SD connector to let the controller do its work with twiddling the NAND Flash bus. Given how small each test pad is (and how many), things get a bit… messy.</p>

		
		

<p>I started by using double-side foam adhesive tape to secure the SD card to a piece of perfboard. I then tinned all of the pads and soldered a small 1uF ceramic capacitor across the card’s power (Vcc) and ground (GND) test pads. Using 40-gauge (0.1 mm, or 4-thousandths of an inch!) magnet wire, I mapped each test pad to its corresponding machine-pin socket on the perfboard. Including the extra test pads, that’s a total of 28 tiny wires!</p>
<p>For the SD connector side of things, I used a flex cable for the <a href="http://xtc2clip.org/how-it-works" target="_blank" rel="noopener">XTC 2 Clip</a> (a tool used to service HTC Android devices), as it acted as a flexible “remote SD card” and broke out the signals to a small ribbon cable. I encased the flex cable with copper tape to act as a shield against electrical noise and to provide physical reinforcement, and soldered the tape to the outer pads on the perfboard for reinforcement. The ribbon cable end was then tinned and each SD card’s pin was wired up with magnet wire. The power lines were then broken out to an LED and resistor to indicate when the card was receiving power.</p>
<h2>Bus Analysis</h2>
<p>With all of the test pads broken out to an array of test pins, it was time to make sense of what pins are responsible for accessing the NAND Flash inside the card.</p>
<h2>Test Pad Pinout</h2>
<div data-shortcode="caption" id="attachment_2165"><p><a href="https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png"><img aria-describedby="caption-attachment-2165" data-attachment-id="2165" data-permalink="https://ripitapart.com/sandisk-high-endurance-microsd-test-pad-pinout/" data-orig-file="https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png" data-orig-size="1666,935" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SanDisk High Endurance microSD Test Pad Pinout" data-image-description="<p>Diagram of the test pads on SanDisk’s High Endurance microSD card.</p>
" data-image-caption="<p>Diagram of the test pads on SanDisk’s High Endurance microSD card.</p>
" data-medium-file="https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=300" data-large-file="https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=584" src="https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=584&amp;h=328" alt="Diagram of the test pads on SanDisk's High Endurance microSD card." width="584" height="328" srcset="https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=584 584w, https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=1168 1168w, https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=150 150w, https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=300 300w, https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=768 768w, https://ripitapart.com/wp-content/uploads/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=1024 1024w" sizes="(max-width: 584px) 100vw, 584px"></a></p><p id="caption-attachment-2165">Diagram of the test pads on SanDisk’s High Endurance microSD card. (click to enlarge)</p></div>
<p>The overall test pad pinout was the same for other microSD cards from SanDisk<del>, but there were some differences, primarily regarding the layout of the power pads; notably, <strong>the </strong><strong>main power pins are backwards</strong>! This can destroy the card if you’re not careful when applying power.</del></p>
<p><strong>CORRECTION (July 22, 2020):</strong> <em>I might actually have just gotten my own documentation mixed up in terms of the power and ground test pads. Regardless, one should always be careful to ensure the correct power polarity is sent to a device.</em></p>
<p>I used my <a href="https://www.dreamsourcelab.com/shop/logic-analyzer/dslogic-plus/" target="_blank" rel="noopener">DSLogic Plus</a> logic analyzer to analyze the signals on all of the pins. Since the data pinout was previously discovered, the hard part of figuring out what each line represented (data bus, control, address, command, write-protect, ready/busy status) was already done for me. However, not all of the lines were immediately evident as the pinouts I found online only included the bare minimum of lines to make the NAND Flash accessible, with one exception being a control line that places the controller into a reset state and releases its control of the data lines (this will be important later on).</p>
<p>By sniffing the data bus at the DSLogic’s maximum speed (and using its 32 MB onboard buffer RAM), I was able to get a clear snapshot of the commands being sent to the NAND Flash from the controller during initialization.</p>
<h2>Bus Sniffing &amp; NAND I/O 101 (writing commands, address, reading data)</h2>
<p>In particular, I was looking for two commands: RESET (0xFF), and READ ID (0x90). When looking for a command sequence, it’s important to know how and when the data and control lines change. I will try to explain it step-by-step, but if you’re interested there is an <a href="https://user.eng.umd.edu/~blj/CS-590.26/micron-tn2919.pdf" target="_blank" rel="noopener">introductory white paper</a> by Micron that explains all of the fundamentals of NAND Flash with much more information about how NAND Flash works.</p>

		
		

<p>When a RESET command is sent to the NAND Flash, first the /CE (Chip Select, Active Low) line is pulled low. Then the CLE (Command Latch Enable) line is pulled high; the data bus is set to its intended value of 0xFF (all binary ones); then the /WE (Write Enable, Active Low) line is pulsed from high to low, then back to high again (the data bus’ contents are committed to the chip when the /WE line goes from low to high, known as a “rising edge”); the CLE line is pulled back low to return to its normal state. The Flash chip will then pull its R/B (Ready/Busy Status) line low to indicate it is busy resetting itself, then releases the line back to its high state when it’s finished.</p>
<p>The READ ID command works similarly, except after writing the command with 0x90 (binary 1001 0000) on the data bus, it then pulls the ALE (Address Latch Enable) line high instead of CLE, and writes 0x00 (all binary zeroes) by pulsing the /WE line low. The chip transfers its internally programmed NAND Flash ID into its internal read register, and the data is read out from the device on each rising edge of the /RE (Read Enable, Active Low) line; for most devices this is 4 to 8 bytes of data.</p>
<h2>NAND Flash ID</h2>
<p>For each NAND Flash device, it has a (mostly) unique ID that identifies the manufacturer, and other functional data that is defined by that manufacturer; in other words, only the manufacturer ID, assigned by the <a href="https://en.wikipedia.org/wiki/JEDEC" target="_blank" rel="noopener">JEDEC Technology Association</a>, is well-defined.</p>
<p>The first byte represents the Flash manufacturer, and the rest (2 to 6 bytes) define the device’s characteristics, as set out by the manufacturer themselves. Most NAND vendors are very tight-lipped when it comes to datasheets, and SanDisk (and by extension, Toshiba/Kioxia) maintain very strict control, save for some slightly outdated leaked Toshiba datasheets. Because the two aforementioned companies share their NAND fabrication facilities, we can reasonably presume the data structures in the vendor-defined bytes can be referenced against each other.</p>
<p>In the case of the SanDisk High Endurance 128GB card, it has a NAND Flash ID of 0x45 48 9A B3 7E 72 0D 0E. Some of these values can be compared against a <a href="http://www.datasheet.hk/view_download.php?id=2027929&amp;file=0515%5Ctc58teg5dcjtai0_7779332.pdf" target="_blank" rel="noopener">Toshiba datasheet</a>:</p>
<table>
<thead>
<tr>
<th>Byte Value (Hex)</th>
<th>Description/Interpretation</th>
</tr>
</thead>
<tbody>
<tr>
<td>45</td>
<td>
<ul>
<li>Manufacturer: SanDisk</li>
</ul>
</td>
</tr>
<tr>
<td>48</td>
<td>
<ul>
<li>I/O voltage: Presumed 1.8 volts (measured with multimeter)</li>
<li>Device capacity: Presumed 128 GB&nbsp;(unable to confirm against datasheet)</li>
</ul>
</td>
</tr>
<tr>
<td>9A</td>
<td>
<ul>
<li>NAND type: TLC (Triple-Level Cell / 3 bits per cell)</li>
<li>Flash dies per /CE: 4 (card uses four 32GB Flash chips internally)</li>
</ul>
</td>
</tr>
<tr>
<td>B3</td>
<td>
<ul>
<li>Block size: 12 MiB (768 pages per block) excluding spare area (determined outside datasheet)</li>
<li>Page size: 16,384 bytes / 16 kiB excluding spare area</li>
</ul>
</td>
</tr>
<tr>
<td>7E</td>
<td>
<ul>
<li>Planes per /CE: 8 (2 planes per die)</li>
</ul>
</td>
</tr>
<tr>
<td>72</td>
<td>
<ul>
<li>Interface type: Asynchronous</li>
<li>Process geometry: BiCS3 3D NAND (determined outside datasheet)</li>
</ul>
</td>
</tr>
<tr>
<td>0D</td>
<td>
<ul>
<li>Unknown (no information listed in datasheet)</li>
</ul>
</td>
</tr>
<tr>
<td>0E</td>
<td>
<ul>
<li>Unknown (no information listed in datasheet)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Although not all byte values could be conclusively determined, I was able to determine that the <strong>SanDisk High Endurance cards use <a href="https://www.tomshardware.com/news/wd-sandisk-bics3-64-layer-3d-nand,32328.html" target="_blank" rel="noopener">BiCS3 3D TLC NAND Flash</a></strong>, but at least it is <strong>3D NAND</strong> which improves endurance dramatically compared to traditional/planar NAND. Unfortunately, from this information alone, I cannot determine whether the card’s controller takes advantage of any SLC caching mechanisms for write operations.</p>
<p>The chip’s process geometry was determined by looking up the first four bytes of the Flash ID, and cross-referencing it to a line from a configuration file in Silicon Motion’s <a href="https://www.usbdev.ru/files/smi/" target="_blank" rel="noopener">mass production tools</a> for their <a href="http://www.siliconmotion.com/download.php?t=U0wyRnpjMlYwY3k4eU1ERTVMekV3THpBNUwzQnliMlIxWTNReE16Z3lNamd4TWpVMkxuQmtaajA5UFZOTk16STNNU0J3Y205a2RXTjBJR0p5YVdWbUM%3D" target="_blank" rel="noopener">SM3271</a> USB Flash drive controller, and their <a href="http://en.siliconmotion.com/download/product-brief/SM2258XT_Product_Brief_ENG_Q1109.pdf" target="_blank" rel="noopener">SM2258XT</a> DRAM-less SSD controller. These tools revealed supposed part numbers of SDTNAIAMA-256G and SDUNBIEMM-32G respectively, but I don’t think this is accurate for the specific Flash configuration in this card.</p>
<h2>External Control</h2>
<p>I wanted to make sure that I was getting the correct ID from the NAND Flash, so I rigged up a Texas Instruments <a href="https://www.ti.com/tool/MSP-EXP430FR2433" target="_blank" rel="noopener">MSP430FR2433 development board</a> and wrote some (very) rudimentary code to send the required RESET and READ ID commands, and attempt to extract any extra data from the chip’s hidden JEDEC Parameter Page along the way.</p>
<p>My first roadblock was that the MSP430 would reset every time it attempted to send the RESET command, suggesting that too much current was being drawn from the MSP430 board’s limited power supply. This can occur during <a href="https://en.wikipedia.org/wiki/Bus_contention" target="_blank" rel="noopener">bus contention</a>, where two devices “fight” each other when trying to set a certain digital line both high and low at the same time. I was unsure what was going on, since publicly-available information didn’t mention how to disable the card’s built-in controller (doing so would cause it to <a href="https://en.wikipedia.org/wiki/Three-state_logic#Tri-state_Buffer" target="_blank" rel="noopener">tri-state</a> the lines, effectively “letting go” of the NAND bus and allowing another device to take control).</p>
<p>I figured out that the A1 test pad (see diagram) was the controller’s reset line (pulsing this line low while the card was running forced my card reader to power-cycle it), and by holding the line low, the controller would release its control of the NAND Flash bus entirely. After this, my microcontroller code was able to read the Flash ID correctly and consistently.</p>
<div data-shortcode="caption" id="attachment_2122"><p><a href="https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png"><img aria-describedby="caption-attachment-2122" data-attachment-id="2122" data-permalink="https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/sandisk-he-128gb-nand-flash-id/" data-orig-file="https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png" data-orig-size="877,375" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SanDisk High Endurance SD Card NAND Flash ID" data-image-description="" data-image-caption="<p>Reading out the card’s Flash ID with my own microcontroller code.</p>
" data-medium-file="https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png?w=300" data-large-file="https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png?w=584" src="https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png?w=584" alt="Reading out the card's Flash ID with my own microcontroller code." srcset="https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png 877w, https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png?w=150&amp;h=64 150w, https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png?w=300&amp;h=128 300w, https://ripitapart.com/wp-content/uploads/2019/10/sandisk-he-128gb-nand-flash-id-1.png?w=768&amp;h=328 768w" sizes="(max-width: 877px) 100vw, 877px"></a></p><p id="caption-attachment-2122">Reading out the card’s Flash ID with my own microcontroller code.</p></div>
<h2>JEDEC Parameter Page… or at least what SanDisk made of it!</h2>
<p>The JEDEC Parameter Page, if present, contains detailed information on a Flash chip’s characteristics with far greater detail than the NAND Flash ID – and it’s well-standardized so parsing it would be far easier. However, it turns out that SanDisk decided to ignore the standard format, and decided to use their own proprietary Parameter Page format! Normally the page starts with the ASCII string “JEDEC”, but I got a repeating string of “SNDK” (corresponding with their <a href="https://www.marketbeat.com/stocks/NASDAQ/SNDK/" target="_blank" rel="noopener">stock symbol</a>) with other data that didn’t correspond to anything like the JEDEC specification! Oh well, it was worth a try.</p>
<p>I collected the data with the same Arduino sketch as shown above, and pulled 1,536 bytes’ worth of data; I wrote a quick <a href="https://ideone.com/eLclhy#stdin" target="_blank" rel="noopener">program on Ideone</a> to provide a nicely-formatted hex dump of the first 512 bytes of the Parameter Page data:</p>
<pre>Offset 00:01:02:03:04:05:06:07:08:09:0A:0B:0C:0D:0E:0F 0123456789ABCDEF
------ --+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-- ----------------
0x0000 53 4E 44 4B 53 4E 44 4B 53 4E 44 4B 53 4E 44 4B SNDKSNDKSNDKSNDK
0x0010 53 4E 44 4B 53 4E 44 4B 53 4E 44 4B 53 4E 44 4B SNDKSNDKSNDKSNDK
0x0020 08 08 00 08 06 20 00 02 01 48 9A B3 00 05 08 41 ..... ...H.....A
0x0030 48 63 6A 08 08 00 08 06 20 00 02 01 48 9A B3 00 Hcj..... ...H...
0x0040 05 08 41 48 63 6A 08 08 00 08 06 20 00 02 01 48 ..AHcj..... ...H
0x0050 9A B3 00 05 08 41 48 63 6A 08 08 00 08 06 20 00 .....AHcj..... .
0x0060 02 01 48 9A B3 00 05 08 41 48 63 6A 08 08 00 08 ..H.....AHcj....
0x0070 06 20 00 02 01 48 9A B3 00 05 08 41 48 63 6A 08 . ...H.....AHcj.
0x0080 08 00 08 06 20 00 02 01 48 9A B3 00 05 08 41 48 .... ...H.....AH
0x0090 63 6A 08 08 00 08 06 20 00 02 01 48 9A B3 00 05 cj..... ...H....
0x00A0 08 41 48 63 6A 08 08 00 08 06 20 00 02 01 48 9A .AHcj..... ...H.
0x00B0 B3 00 05 08 41 48 63 6A 08 08 00 08 06 20 00 02 ....AHcj..... ..
0x00C0 01 48 9A B3 00 05 08 41 48 63 6A 08 08 00 08 06 .H.....AHcj.....
0x00D0 20 00 02 01 48 9A B3 00 05 08 41 48 63 6A 08 08  ...H.....AHcj..
0x00E0 00 08 06 20 00 02 01 48 9A B3 00 05 08 41 48 63 ... ...H.....AHc
0x00F0 6A 08 08 00 08 06 20 00 02 01 48 9A B3 00 05 08 j..... ...H.....
0x0100 41 48 63 6A 08 08 00 08 06 20 00 02 01 48 9A B3 AHcj..... ...H..
0x0110 00 05 08 41 48 63 6A 08 08 00 08 06 20 00 02 01 ...AHcj..... ...
0x0120 48 9A B3 00 05 08 41 48 63 6A 08 08 00 08 06 20 H.....AHcj..... 
0x0130 00 02 01 48 9A B3 00 05 08 41 48 63 6A 08 08 00 ...H.....AHcj...
0x0140 08 06 20 00 02 01 48 9A B3 00 05 08 41 48 63 6A .. ...H.....AHcj
0x0150 08 08 00 08 06 20 00 02 01 48 9A B3 00 05 08 41 ..... ...H.....A
0x0160 48 63 6A 08 08 00 08 06 20 00 02 01 48 9A B3 00 Hcj..... ...H...
0x0170 05 08 41 48 63 6A 08 08 00 08 06 20 00 02 01 48 ..AHcj..... ...H
0x0180 9A B3 00 05 08 41 48 63 6A 08 08 00 08 06 20 00 .....AHcj..... .
0x0190 02 01 48 9A B3 00 05 08 41 48 63 6A 08 08 00 08 ..H.....AHcj....
0x01A0 06 20 00 02 01 48 9A B3 00 05 08 41 48 63 6A 08 . ...H.....AHcj.
0x01B0 08 00 08 06 20 00 02 01 48 9A B3 00 05 08 41 48 .... ...H.....AH
0x01C0 63 6A 08 08 00 08 06 20 00 02 01 48 9A B3 00 05 cj..... ...H....
0x01D0 08 41 48 63 6A 08 08 00 08 06 20 00 02 01 48 9A .AHcj..... ...H.
0x01E0 B3 00 05 08 41 48 63 6A 08 08 00 08 06 20 00 02 ....AHcj..... ..
0x01F0 01 48 9A B3 00 05 08 41 48 63 6A 08 08 00 08 06 .H.....AHcj.....</pre>
<p>Further analysis with my DSLogic showed that the controller itself requests a total of 4,128 bytes (4 kiB + 32 bytes) of Parameter Page data, which is filled with the same repeating data as shown above.</p>
<h3>Reset Quirks</h3>
<p>When looking at the logic analyzer data, I noticed that the controller sends the READ ID command twice, but the first time it does so without resetting the Flash (which should normally be done as soon as the chip is powered up!). The data that the Flash returned was… strange to say the least.</p>
<table>
<thead>
<tr>
<th>Byte Value (Hex)</th>
<th>Interpreted Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>98</td>
<td>
<ul>
<li>Manufacturer: Toshiba</li>
</ul>
</td>
</tr>
<tr>
<td>00</td>
<td>
<ul>
<li>I/O voltage: Unknown (no data)</li>
<li>Device capacity: Unknown (no data)</li>
</ul>
</td>
</tr>
<tr>
<td>90</td>
<td>
<ul>
<li>NAND type: SLC (Single-Level Cell / 1 bit per cell)</li>
<li>Flash dies per /CE: 1</li>
</ul>
</td>
</tr>
<tr>
<td>93</td>
<td>
<ul>
<li>Block size: 4 MB excluding spare area</li>
<li>Page size: 16,384 bytes / 16 kiB excluding spare area</li>
</ul>
</td>
</tr>
<tr>
<td>76</td>
<td>
<ul>
<li>Planes per /CE: 2</li>
</ul>
</td>
</tr>
<tr>
<td>72</td>
<td>
<ul>
<li>Interface type: Asynchronous</li>
<li>Process geometry: 70 nm planar</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>This confused me initially when I was trying to find the ID from the logic capture alone; after talking to a contact who has experience in NAND Flash data recovery, they said this is expected for SanDisk devices, which make liberal use of vendor-proprietary commands and data structures. If the fourth byte is to be believed, it says the block size is 4 megabytes, which I think is plausible for a modern Flash device. The rest of the information doesn’t really make any sense to me apart from the first byte indicating the chip is made by Toshiba.</p>
<h2>Conclusion</h2>
<p>I shouldn’t have to go this far in hardware reverse-engineering to just ask a simple question of what Flash SanDisk used in their high-endurance card. You’d think they would be proud to say they use 3D NAND for higher endurance and reliability, but I guess not!</p>
<h2>Downloads</h2>
<p>For those that are interested, I’ve included the logic captures of the card’s activity shortly after power-up. I’ve also included the (very crude) Arduino sketch that I used to read the NAND ID and Parameter Page data manually:</p>
<ul>
<li><a href="https://www.dropbox.com/s/8yolkc756q37mnh/sandisk%20he%20128%20power%20on.dsl?dl=0" target="_blank" rel="noopener">Logic capture #1</a></li>
<li><a href="https://www.dropbox.com/s/hhkl3c0jyk366c3/sandisk%20he%20128%20power%20on%202.dsl?dl=0" target="_blank" rel="noopener">Logic capture #2</a></li>
<li><a href="https://github.com/ginbot86/2433_nandflashtest" target="_blank" rel="noopener">NAND I/O Arduino sketch</a></li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Analyzing the codebase of Caffeine: a high performance caching library (191 pts)]]></title>
            <link>https://adriacabeza.github.io/2024/07/12/caffeine-cache.html</link>
            <guid>42907488</guid>
            <pubDate>Sun, 02 Feb 2025 09:37:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://adriacabeza.github.io/2024/07/12/caffeine-cache.html">https://adriacabeza.github.io/2024/07/12/caffeine-cache.html</a>, See on <a href="https://news.ycombinator.com/item?id=42907488">Hacker News</a></p>
Couldn't get https://adriacabeza.github.io/2024/07/12/caffeine-cache.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Life Is More Than an Engineering Problem – Interview with Ted Chiang (308 pts)]]></title>
            <link>https://lareviewofbooks.org/article/life-is-more-than-an-engineering-problem/</link>
            <guid>42907268</guid>
            <pubDate>Sun, 02 Feb 2025 08:53:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lareviewofbooks.org/article/life-is-more-than-an-engineering-problem/">https://lareviewofbooks.org/article/life-is-more-than-an-engineering-problem/</a>, See on <a href="https://news.ycombinator.com/item?id=42907268">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><div><h2>Julien Crockett speaks with Ted Chiang about the search for a perfect language, the state of AI, and the future direction of technology.</h2><div><p><img loading="lazy" decoding="async" data-nimg="fill" sizes="
          (max-width: 768px) 100vw, 
          (max-width: 960px) 750px, 
          750px
        " srcset="https://cdn.lareviewofbooks.org/unsafe/640x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 640w, https://cdn.lareviewofbooks.org/unsafe/750x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 750w, https://cdn.lareviewofbooks.org/unsafe/828x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 828w, https://cdn.lareviewofbooks.org/unsafe/1080x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 1080w, https://cdn.lareviewofbooks.org/unsafe/1200x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 1200w, https://cdn.lareviewofbooks.org/unsafe/1920x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 1920w, https://cdn.lareviewofbooks.org/unsafe/2048x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 2048w, https://cdn.lareviewofbooks.org/unsafe/3840x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg 3840w" src="https://cdn.lareviewofbooks.org/unsafe/3840x0/filters:format(jpeg):quality(75)/https%3A%2F%2Fassets.lareviewofbooks.org%2Fuploads%2Flifecycle-softwareobjects-web__85640.jpg"></p></div></div><p><em>This interview is part of </em><a rel="" target="_self" href="https://lareviewofbooks.org/feature/the-rules-we-live-by/"><em>The Rules We Live By,</em></a><em> a series devoted to asking what it means to be a human living by an ever-evolving set of rules. The series is made up of conversations with those who dictate, think deeply about, and seek to bend or break the rules we live by.</em></p><p>¤</p><p><em>“ONCE IN A WHILE,” Ted Chiang tells me, “an idea keeps coming back over a period of months or even years. […] I start asking, is there an interesting philosophical question that might be illuminated by this idea?” To read Chiang is to experience a master world-builder critically exploring philosophical questions in new ways—from how we should care for an artificial being to what would be the consequence of having a perfect record of the past.</em></p><p><em>Lately, Chiang has trained his eye on artificial intelligence. And Chiang’s takes haven’t gone unnoticed. In a </em><a rel="" target="_self" href="https://lareviewofbooks.org/article/how-to-raise-your-artificial-intelligence-a-conversation-with-alison-gopnik-and-melanie-mitchell/"><em>conversation</em></a><em> I had earlier this year with computer scientist Melanie Mitchell and psychologist Alison Gopnik, they each referenced Chiang when searching for the right framework to discuss AI.</em></p><p><em>Chiang has a knack for descriptively illustrating his points. For example, when discussing whether LLMs might one day develop subjective experience, he explains: “It’s like imagining that a printer could actually feel pain because it can print bumper stickers with the words ‘Baby don’t hurt me’ on them. It doesn’t matter if the next version of the printer can print out those stickers faster, or if it can format the text in bold red capital letters instead of small black ones. Those are indicators that you have a more capable printer but not indicators that it is any closer to actually feeling anything.”</em></p><p><em>For me, the essence of Chiang’s work, however, isn’t his critical take on technology. It’s his humanism—the way he brings to the fore the mundane reality behind existential questions and moments of societal change. It is perhaps for this reason that his work resonates with so many.</em></p><p><em>In our conversation, we discuss how Chiang picks his subjects, the historical search for a perfect language, the state of AI, and what it would take for Chiang to become hopeful about the direction of technology.</em></p><p>¤</p><p><strong>JULIEN CROCKETT: The idea for this interview came from a conversation I had with computer scientist Melanie Mitchell and psychologist Alison Gopnik, in which they referenced your work when describing the state of artificial intelligence and its possible futures. Why do you think scientists and engineers look to your work to explain their own?</strong></p><p><strong>TED CHIANG:</strong> I was actually surprised that my name popped up. I think it was mostly just a coincidence that you interviewed two people who have found that my work resonates with their own. They might be outliers, compared to scientists as a whole.</p><p><strong>What about the other way around—has scientific progress had an effect on the direction of your work?</strong></p><p>I don’t think there has been a clear impact of recent scientific research on my fiction. My stories are mostly motivated by philosophical questions, many of which are not particularly new. Sometimes the way I investigate a philosophical question is inflected by recent developments in science or technology, but the recent developments probably aren’t the motivating impulse.</p><p><strong>Your stories cover a wide range of topics, but I see a through line in your focus on how humans react to societal change—whether it’s a discovery that mathematics is actually inconsistent, as in your 1991 story “Division by Zero,” or a world where we raise robots as children, as in your 2010 novella </strong><em><strong>The Lifecyle of Software Objects</strong></em><strong>. What draws you to a topic?</strong></p><p>Most of the time, when ideas come to me, they leave my attention very quickly. But once in a while, an idea keeps coming back over a period of months or even years. I take that as a signal that I should pay attention and think about the idea in a more intentional way. What that usually means is that I start asking, “Is there an interesting philosophical question that might be illuminated by this idea?” If I can identify that philosophical question, then I can start thinking about different ways a story might help me dramatize it.</p><p><strong>Why is science fiction the best vehicle for you to explore ideas?</strong></p><p>The ideas that most interest me just lean in a science-fictional direction. I certainly think that contemporary mimetic fiction is capable of investigating philosophical questions, but the philosophical questions that I find myself drawn to require more speculative scenarios. In fact, when philosophers pose thought experiments, the scenarios they describe often have a science-fictional feel; they need a significant departure from reality to highlight the issue they’re getting at. When a philosophical thought experiment is supposed to be set in the actual world, the situation often has a contrived quality. For example, the famous “trolley problem” is supposedly set in the actual world, but it describes a situation that is extremely artificial; in the real world, we have safeguards precisely to avoid situations like that.</p><p><strong>What role does science play in your stories? Or, asked another way, what are the different roles played by science and magic in fiction?</strong></p><p>Some people think of science as a body of facts, and the facts that science has collected are important to our modern way of life. But you can also think about science as a process, as a way of understanding the universe. You can write fiction that is consistent with the specific body of facts we have, or you can write fiction that reflects the scientific worldview, even if it is not consistent with that body of facts. For example, take a story where there is faster-than-light travel. Faster-than-light travel is impossible, but the story can otherwise reflect the general worldview of science: the idea that the universe is an extremely complicated machine, and through careful observation, we can deduce the principles by which this machine works and then apply what we’ve learned to develop technology based on those principles. Such a story is faithful to the scientific worldview, so I would argue that it’s a science fiction story even if it is not consistent with the body of facts we currently have.</p><p>By contrast, magic implies a different understanding of how the universe works. Magic is hard to define. A lot of people would say magic definitionally cannot have rules, and that’s one popular way of looking at it. But I have a different take—I would say that magic is evidence that the universe knows you’re a person. It’s not that magic cannot have rules; it’s that the rules are more like the patterns of human psychology or of interactions between people. Magic means that the universe is behaving not as a giant machine but as something that is aware of you as a person who is different from other people, and that people are different from things. At some level, the universe responds to your intentions in a way that the laws of physics as we understand them don’t.</p><p>These are two very different ways of understanding how the universe works, and fiction can engage in either one. Science needs to adhere to the scientific worldview, but fiction is not an engineering project. The author can choose whichever one is better suited to their goals.</p><p><strong>Your work often explores the way tools mediate our relationship with reality. One such tool is language. You write about language perhaps most popularly in “Story of Your Life” (1998), the basis for the film </strong><em><strong>Arrival</strong></em><strong> (2016), but also in “Understand” (1991), exploring what would happen if we had a medical treatment for increasing intelligence. Receiving the treatment after an accident, the main character grows frustrated by the limits of conventional language:</strong></p><br><blockquote><strong>I’m designing a new language. I’ve reached the limits of conventional languages, and now they frustrate my attempts to progress further. They lack the power to express concepts that I need, and even in their own domain, they’re imprecise and unwieldy. They’re hardly fit for speech, let alone thought. […]</strong></blockquote><blockquote><strong>&nbsp;</strong></blockquote><blockquote><strong>I’ll reevaluate basic logic to determine the suitable atomic components for my language. This language will support a dialect coexpressive with all of mathematics, so that any equation I write will have a linguistic equivalent.</strong></blockquote><p><strong>Do you think there could be a “better” language? Or is it just mathematics?</strong></p><p>Umberto Eco wrote a book called <em>The Search for the Perfect Language</em> (1994), which is a history of the idea that there exists a perfect language. At one point in history, scholars believed the perfect language was the language that Adam and Eve spoke in the Garden of Eden or the language angels speak. Later on, scholars shifted to the idea that it was possible to construct an artificial language that was perfect, in the sense that it would be completely unambiguous and bear a direct relationship to reality.</p><p>Modern linguistics holds that this idea is nonsensical. It’s foundational to our modern conception of language that the relationship between any given word and the concept it is assigned to is arbitrary. But I think that many of us can relate to the desire for a language that expresses exactly what we mean unambiguously. We’ve all tried to convey something and wished there were a word for it, but that’s not a problem of English or French or German—that’s a problem of language itself. And even though I know a perfect language is impossible, the idea continues to fascinate me.</p><p>As for the question of whether mathematics could be a better language, the reason that mathematics is useful is precisely what makes it unsuitable as a general language. Mathematics is extremely precise, but it’s limited to a specific domain. Scientists who speak different languages can use the same mathematics, but they still have to rely on their native languages when they publish a paper; they can’t say everything they need to say with equations alone. Language has to support every type of communication that humans engage in, from debates between politicians to pillow talk between lovers. That’s not what mathematics is for. We could be holding this conversation in any human language that we both understand, but we couldn’t hold it in mathematical equations. As soon as you try and modify mathematics so that it can do those things, it ceases to be mathematics.</p><p><strong>I grew up in a French household, and I often feel that there are French words and expressions that better capture what I want to express than any English word or expression could.</strong></p><p>Eco writes that when European scholars were arguing about what language Adam and Eve spoke, each one typically argued in favor of the language he himself spoke. So Flemish scholars said that Adam and Eve obviously must have spoken Flemish, because Flemish is the most perfect expression of human thought.</p><p><strong>Funny. Another tool increasingly mediating our relationship with society and reality is artificial intelligence. You’ve written skeptically about how modern AI systems are being implemented, and one metaphor you use to describe large language models (LLMs) is as </strong><a rel="" target="_self" href="https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web"><strong>“a blurry JPEG of the web.”</strong></a><strong> What do you mean?</strong></p><p>When we use a search engine, we get verbatim quotes from text on the internet and also a link to the original web page. A search engine gives us information directly from the horse’s mouth. LLMs are like a search engine that rephrases information instead of giving it verbatim or pointing you to the original source. In some respects, that is really cool, but they’re not rephrasing it reliably. It’s like asking a question and getting an answer back from someone who read the answer but didn’t really understand it and is trying to rephrase it to the best of their ability. I call LLMs a blurry JPEG because they give a low-resolution version of the internet. If you are using the internet to find information, which is what most of us use the internet for, it doesn’t really make sense to go with the low-resolution version when we have conventional search engines that point you to the actual information itself.</p><p>It’s entertaining to be able to ask a question and get an answer back in a conversational form, but LLMs are not being marketed as entertainment devices. They’re being marketed as products that will answer your questions accurately, and that’s not what LLMs are doing.</p><p><strong>Do you think that LLMs will become useful tools that can reliably answer questions?</strong></p><p>I don’t want to say LLMs are only good for entertainment; there are many respects in which LLMs are genuinely amazing. The fact that they can rephrase something in any style of prose is fascinating; no one would have predicted that statistical models of all the text on the internet would be capable of that. But predicting the most likely next word is different from having correct information about the world, which is why LLMs are not a reliable way to get the answers to questions, and I don’t think there is good evidence to suggest that they will become reliable. Over the past couple of years, there have been some papers published suggesting that training LLMs on more data and throwing more processing power at the problem provides diminishing returns in terms of performance. They can get better at reproducing patterns found online, but they don’t become capable of actual reasoning; it seems that the problem is fundamental to their architecture. And you can bolt tools onto the side of an LLM, like giving it a calculator it can use when you ask it a math problem, or giving it access to a search engine when you want up-to-date information, but putting reliable tools under the control of an unreliable program is not enough to make the controlling program reliable. I think we will need a different approach if we want a truly reliable question answerer.</p><p><strong>Modern AI systems are one tool in a long line of tools that help us approximate reality. We seem to easily ascribe attributes of ourselves, such as thought and reasoning, to these tools. For example, we regularly describe the brain as a computer and vice versa. Why do you think we see ourselves in our tools?</strong></p><p>There was a time when people compared the brain to a telephone switchboard. The brain is the most complex thing we have ever encountered, and when the telephone switchboard was the most complicated machine we had ever built, we naturally used it as a metaphor when trying to understand what the brain is. But that doesn’t actually tell us anything about how the brain works. The fact that we can now build computers doesn’t mean that the brain is more like a computer than a telephone switchboard. There are many ways in which it is obvious that the brain is not like a computer, but because the computer metaphor is so prevalent, we overlook those differences. Computers consist of software running on hardware, but there is no distinction between software and hardware in biological systems. If you were to apply that metaphor to any other organ in the body, it would seem absurd. For example, “My liver was running this old program, but all I needed to do was update the software and now my liver is functioning much better, even though the hardware is the same.” No one says that. It’s not a useful way of thinking about the liver, and it is not a useful way of thinking about the brain either.</p><p>By the same token, because we imagine that computers are like brains, we are tempted to think of computers as intelligent and engaged in thinking. When we do that, we’re taking this metaphor way too literally. What telephone switchboards did was not so readily mappable to something people do, and that probably deterred people from imagining that a telephone switchboard was engaged in reasoning. But LLMs can generate plausible text, which totally throws us for a loop. LLMs are not engaged in reasoning any more than a telephone switchboard was, but their ability to simulate conversation makes it far easier to imagine that they are.</p><p><strong>You wrote an article called </strong><a rel="" target="_self" href="https://www.newyorker.com/culture/the-weekend-essay/why-ai-isnt-going-to-make-art"><strong>“Why A.I. Isn’t Going to Make Art”</strong></a><strong> where you argue that generative artificial intelligence reduces the amount of intention in the world because, by using AI tools, we lose the opportunity to make the choices necessary for creating art. What impact are AI tools having on artists and their artwork?</strong></p><p>I should note that I didn’t pick the title of the essay; if I had, I might have called it something like “Why AI Won’t Make Art Easy to Make.” Many people would have you believe that the process of making art and the end result can be easily separated, but I don’t believe they can be. I was talking with someone who is very excited about AI-generated imagery, and she said, “Let’s imagine, for the sake of argument, that AI can make better art than humans. In that scenario, do you think that we should reject AI art simply to protect the livelihood of human artists?” I responded, “I’m not going to grant you that premise, because that is the question under debate. You are framing the hypothetical in a way that assumes the conclusion.” I don’t believe it’s meaningful to say that something is better art absent any context of how it was created. Art is all about context. It’s not an activity like tightening bolts, where I don’t really care whether someone used a conventional wrench or a pneumatic wrench, as long as the bolts are tight.</p><p>As for the impact on artists, I’d say the primary effect of AI tools is that they encourage the idea that art is no different from tightening bolts. Artists have always had to deal with commercial considerations, but it’s probably a more pressing issue now than ever before. The impulse to view everything in terms of efficiency, of reducing costs and maximizing output, is radically overapplied in the modern world. There are certain situations in which that is an appropriate framing, but art cannot be understood that way. Arguably the most important parts of our lives should not be approached with this attitude. Some of this attitude comes from the fact that the people making AI tools are engineers viewing everything from an engineering perspective, but it’s also that, as a culture, we have adopted this way of thinking as the default.</p><p><strong>In French, we would call engineers viewing everything as an engineering problem a “professional deformity.” But an issue perhaps tangentially related to viewing everything as a wrench is “the alignment problem.” Your novella </strong><em><strong>The Lifecycle of Software Objects</strong></em><strong> has been referenced in this context. For example, Alison Gopnik talks about how one way to “align” artificial intelligence with our goals and values could be the same way we align each new generation of humans, through caregiving.</strong></p><p>I don’t like the phrase “the alignment problem.” It’s not clear to me that it refers to something meaningful—or at least that the phrase refers to something that is new and meaningfully different from the broader problems of how to be a good person and how to build a good society. For example, when corporations behave badly, should we consider that an alignment problem? Most of the conversation around the alignment problem suggests that it’s a technical problem, something that can be addressed by implementing a better algorithm or by solving the right equations. But why, for example, do large corporations behave so much worse than most of the people who work for them? I think most of the people who work for large corporations are, to varying degrees, unhappy with the effect those corporations have on the world. Why is that? And could that be fixed by solving a math problem? I don’t think so.</p><p>People who talk about aligning AI with human values imagine that if we could somehow solve this programming problem, then everything would be okay. I don’t see how that follows at all. Imagine you have some hypothetical AI that is better at accomplishing tasks than humans and that does exactly what you tell it to do. Do you want ExxonMobil to have such an AI at its disposal? That doesn’t sound good. Conversely, imagine a hypothetical AI that does what is best for the world as a whole, even if human beings are asking it to do something else. Who would buy such an AI? Certainly not ExxonMobil. I can’t see any corporation buying software that ignores the instructions of humans and does what is best for the world. If that were something that corporations were interested in, do you think they’d be behaving the way they are now?</p><p><strong>But there is something intuitively appealing about the idea of taking what we know about raising children and applying it to an intelligent system, like an AI system, that seems to learn—even if it might not learn in the same way we do.</strong></p><p>The question of whether we can teach AI our values the way parents teach children their values is a very interesting one to me, philosophically. An extremely common ethical guideline is that you should treat others the way you would like to be treated, and this is something that parents try to impress upon their children. When parents do that, they are asking children to put themselves in another person’s place and imagine what their emotional reaction would be, and children often can’t or don’t want to do this, which is why it can take a while for children to learn to play well with others. What would it mean for a machine to do that? We have no idea how to build a machine capable of that. And even if you successfully teach a child to play well with others, that is no guarantee that the child will become an adult who contributes to a good society. The executives of ExxonMobil were almost certainly taught this ethical guideline at some point, and look how well that turned out.</p><p><strong>Could there be value, though, in treating an AI system as more of a partner—something or someone with whom we develop a relationship—rather than merely as a tool?</strong></p><p>It all depends on what you mean by “relationship.” If you’re a woodworker, you might develop emotional associations with a set of chisels you’ve used for years, and in some sense that’s a “relationship,” but it’s entirely different from the relationship you have with people. You might make sure you keep your chisels sharp and rust-free, and say that you’re treating them with respect, but that’s entirely different from the respect you owe to your colleagues. One way to clarify this is to remember that people have their own preferences, while things do not. To respect your colleagues means to pay attention to their preferences and interests and balance them against your own; when they do this to you in return, you have a good relationship. By contrast, your chisel has no preferences; it doesn’t want to be sharp. When you keep it sharp, you are doing so because it will help you do good work or because it gives you a feeling of satisfaction to know that it’s sharp. Either way, you are only serving your own interests, and that’s fine because a chisel is just a tool. If you don’t keep it sharp, you are only harming yourself. By contrast, if you don’t respect your colleagues, there is a problem beyond the fact that it might make your job harder; you do them harm because you are ignoring their preferences. That’s why we consider it wrong to treat a person like a tool; by acting as if they don’t have preferences, you are dehumanizing them.</p><p>AI systems lack preferences; that is true of the systems we have now, and it will be true of any system we build in the foreseeable future. The companies that sell AI systems might benefit if you develop an emotional relationship with their product, so they might create the illusion that AI systems have preferences. But any attempt to encourage people to treat AI systems with respect should be understood as an attempt to make people defer to corporate interests. It might have value to corporations, but there is no value for you.</p><p><strong>In </strong><em><strong>The Lifecycle of Software Objects</strong></em><strong>, the humans develop deep emotional relationships with their digital agents. What characteristics do those digital agents have that make such relationships possible?</strong></p><p>The digital entities in that story have genuine interests and preferences. The premise of the story is that, even though they’re digital, they are in a certain sense alive and have subjective experience. If you’re a responsible pet owner, you will inconvenience yourself to fulfill your pet’s needs, both their physical needs and their psychological ones. The human characters in the story recognize that they have a similar responsibility to their digital pets. They even come to realize that they can’t escape those responsibilities by simply suspending their digital pets the way you might put your laptop in hibernate mode. As an analogy, imagine that you could put your dog or cat into hibernate mode whenever you left on a trip. Your dog or cat might not notice, but even if they did, they might not mind. Now imagine that you could put your child into hibernate mode whenever you were too busy to spend time with them. Your child would absolutely notice, and even if you told them it was for their own good, they would make certain inferences about how much you valued them. That’s the situation the human characters in the story find themselves in.</p><p><strong>Could AI systems one day have those characteristics?</strong></p><p>I believe it’s theoretically possible for us to build digital entities that have subjective experience, inasmuch as I don’t think there’s a physical law that prevents it. We don’t currently have a good idea of how to build such entities. I don’t think we’re going to create them accidentally, because the AI systems we’re building right now are not even heading in the right direction. LLMs are not going to develop subjective experience no matter how big they get. It’s like imagining that a printer could actually feel pain because it can print bumper stickers with the words “Baby don’t hurt me” on them. It doesn’t matter if the next version of the printer can print out those stickers faster, or if it can format the text in bold red capital letters instead of small black ones. Those are indicators that you have a more capable printer but not indicators that it is any closer to actually feeling anything.</p><p><strong>The technology we use also impacts our relationships with one another. In your 2013 story “The Truth of Fact, the Truth of Feeling,” you investigate the unintended consequences that Remem—a product that creates a perfect record of the past—has on human relationships. It seems like the takeaway from your story is that some things are more important than truth</strong>.</p><p>I wouldn’t say that some things are more important than truth. What I was hoping to convey with that story is that there is value in knowing what actually happened, but that is not the end of the discussion. Ideally, we should be able to acknowledge what actually happened without that being the last word on the subject.</p><p><strong>How does that work at a societal level?</strong></p><p>Take the Truth and Reconciliation Commission in South Africa after the fall of apartheid. The truth is essential; it is the only basis from which you can move forward productively. You cannot deny what happened and expect a healthy society to result from that. But once everyone has admitted what they did, there is the opportunity for forgiveness. Society can decide whether punishment is called for and what form it should take; in certain situations, maybe admitting one’s guilt is enough. Once you’ve achieved some kind of reconciliation, it becomes possible to move forward.</p><p><strong>I want to end by asking whether you are optimistic about the future. When I’ve asked this question in previous interviews, some have responded that they are optimistic because it’s a moral duty; it’s what we must be if we want to create a better future. Do you view optimism or hope in this way?</strong></p><p>As usual, we need to be specific about what we mean by “optimism” and “pessimism.” Some people believe that everything will work out fine and we don’t need to devote energy to considering bad outcomes. I think this attitude is extremely common in the tech industry. That’s a kind of optimism, and I definitely don’t fall into that camp. By contrast, some people believe that bad outcomes are inevitable and there’s nothing we can do prevent them. Some might call that pessimism, but I’d say that’s closer to fatalism.</p><p>I think we need to think about the possible bad outcomes and work to mitigate them; if we do that, we have a chance of preventing them from coming to pass. I don’t know if that’s optimism, unless everything except fatalism is optimism. I suppose it might be a moral duty to not be fatalistic. We have to believe that our actions have the potential to make a difference because if we don’t believe that, we won’t take any action at all.</p><p>You can also consider this question within the narrower context of technological development, and ask whether one thinks that the risk of bad outcomes is serious enough that we should slow down our pursuit of new technologies. In this framing, optimists are the ones who say no, the risks aren’t that serious, while pessimists are the ones who say yes, the risks are very serious. My stance on this has probably shifted in a negative direction over time, primarily because of my growing awareness of how often technology is used for wealth accumulation. I don’t think capitalism will solve the problems that capitalism creates, so I’d be much more optimistic about technological development if we could prevent it from making a few people extremely rich.</p><p>¤</p><p><em>Ted Chiang’s fiction has won four Hugo, four Nebula, and four Locus Awards, and has been featured in&nbsp;The Best American Short Stories. His debut collection,&nbsp;</em>Stories of Your Life and Others<em> (2002), has been translated into 21 languages. He was born in Port Jefferson, New York, and currently lives near Seattle.</em></p><p>¤</p><p><em>Featured image: Cover of </em>The Lifecycle of Software Objects<em>, illustration by Christian Pearce.</em></p><div><p>LARB Contributor</p><p>Julien Crockett is an intellectual property attorney and the science and law editor at the <em>Los Angeles Review of Books</em>. He runs the <em>LARB</em> column <a rel="" target="_self" href="https://lareviewofbooks.org/feature/the-rules-we-live-by/">The Rules We Live By,</a> exploring what it means to be a human living by an ever-evolving set of rules.</p></div><section><h3>LARB Staff Recommendations</h3><ul><li><article><h2><a href="https://lareviewofbooks.org/article/the-technologies-that-remake-us-on-ted-chiangs-exhalation-stories/">The Technologies That Remake Us: On Ted Chiang’s “Exhalation: Stories”</a></h2><p>“Exhalation: Stories” is a stunning achievement in speculative fiction, from an author whose star will only continue to rise.</p></article></li><li><article><h2><a href="https://lareviewofbooks.org/article/how-to-raise-your-artificial-intelligence-a-conversation-with-alison-gopnik-and-melanie-mitchell/">How to Raise Your Artificial Intelligence: A Conversation with Alison Gopnik and Melanie Mitchell</a></h2><p>Julien Crockett interviews Alison Gopnik and Melanie Mitchell about complexity and learning in AI systems, and our roles as caregivers.</p><p><span><a href="https://lareviewofbooks.org/contributor/julien-crockett/">Julien Crockett</a></span><span>May 31, 2024</span></p></article></li></ul></section><div><h4><a href="https://lareviewofbooks.org/donate/">Did you enjoy this article?</a></h4><hr><p>LARB depends on the support of readers to publish daily without a paywall. Please support the continued work of our writers and staff by making a tax-deductible donation today!</p></div></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CDC orders mass retraction of research across all science and medicine journals (807 pts)]]></title>
            <link>https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction</link>
            <guid>42905937</guid>
            <pubDate>Sun, 02 Feb 2025 04:52:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction">https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction</a>, See on <a href="https://news.ycombinator.com/item?id=42905937">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em>I believe we are breaking news some news here. To help sustain independent journalism and analysis, please support Inside Medicine. Thanks for reading…</em></p><p><span>The CDC has instructed its scientists to retract or pause the publication of any research manuscript being considered by </span><em>any medical or scientific journal</em><span>, not merely its own internal periodicals, </span><em>Inside Medicine </em><span>has learned. The move aims to ensure that no “forbidden terms” appear in the work. The policy includes manuscripts that are in the revision stages at journal (but not officially accepted) and those already accepted for publication but not yet live. </span></p><p>In the order, CDC researchers were instructed to remove references to or mentions of a list of forbidden terms: “Gender, transgender, pregnant person, pregnant people, LGBT, transsexual, non-binary, nonbinary, assigned male at birth, assigned female at birth, biologically male, biologically female,” according to an email sent to CDC employees (see below).”</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png" width="215" height="296.3633241758242" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:2007,&quot;width&quot;:1456,&quot;resizeWidth&quot;:215,&quot;bytes&quot;:6395981,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F286d049f-4bbf-4a2a-a779-7d8e0af7b1c6_1796x2476.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><span>A screenshot of a CDC email shared with </span><em>Inside Medicine</em><span> of a list of terms that must be removed from any CDC-authored manuscript being seriously considered or “in press” (but not yet online or in print) at any medical or scientific journal.</span></figcaption></figure></div><p><span>The policy goes beyond the previously </span><a href="https://insidemedicine.substack.com/p/uganda-confirms-a-new-ebola-outbreak" rel="">reported</a><span> pause of the CDC’s own publications, including </span><em>Morbidity and Mortality Weekly Report </em><span>(MMWR), which has seen two issues go unreleased since January 16, marking the first publication gap of any kind in approximately 60 years. </span><em>Emerging infectious Diseases</em><span> and </span><em>Preventing Chronic Disease</em><span>, the CDC’s other major publications, also remain under lock and key, but have not yet been affected because they are monthly releases and both were released as scheduled in January, prior to President Trump’s inauguration. The policy also goes beyond the general communications gag order that already prevents any CDC scientist from submitting any new scientific findings to the public. </span></p><p><span>The edict applies to both any previously submitted manuscript under consideration and those accepted but not yet published. For example, if CDC scientists previously submitted a manuscript to </span><em>The New England Journal of Medicine, The Journal of the American Medical Association, </em><span>or any other publication, the article must be stopped and reviewed. (These are hypothetical, but are examples of major journals where CDC officials often publish.)</span></p><p><span>How many manuscripts are affected is unclear, but it could be many. Most manuscripts include simple demographic information about the populations or patients studied, which typically includes gender (and which is frequently used interchangeably with sex). That means just about any major study would fall under the censorship regime of the new policy, including studies on Covid-19, cancer, heart disease, </span><em>or anything else,</em><span> let alone anything that the administration considers to be “woke ideology.” </span></p><p>Meanwhile, chaos and fear are already guiding decisions. While the policy is only meant to apply to work that might be seen as conflicting with President Trump’s executive orders, CDC experts don’t know how to interpret that. Do papers that describe disparities in health outcomes fall into “woke ideology” or not? Nobody knows, and everyone is scared that they’ll be fired. This is leading to what Germans call “vorauseilender Gehorsam,” or “preemptive obedience,” as one non-CDC scientist commented. </p><p>“I’ve got colleagues pulling papers over Table 1 concerns,” an official told me. (Table 1 refers to basic demographic information about the study populations included in research papers, rather than actual results.) Indeed, many studies include demographic information about sexual orientation. For example, a study describing mpox outcomes would likely include basic statistics in tables summarizing the percentage of patients who were vaccinated and were lesbian, gay, transgender, or otherwise. This information can be highly impactful during an outbreak, as it helps clinicians develop policies on who to vaccinate (given limited doses, as is the case with mpox), and even to whom scarce and limited supplies of tests and treatments should be offered to maximize benefits. </p><p>It is not necessarily the case that researchers who have submitted articles but who have not yet received an official decision from a journal need to actively recall them, however. But if a journal sends an article back for revisions, the authors would at that point have to cleanse the document of any “problematic language.” Of course, at that point, the gag order already in place would halt any resubmission. </p><p data-attrs="{&quot;url&quot;:&quot;https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>What can and cannot go forward appears to require approval by a Trump political appointee, an explicit requirement for any public health communications under the Trump Administration’s gag order. That’s slowing many things down. At present, there is only one political appointee in the entire CDC, acting Director Susan Monarez (plus her personal assistant, who is not a scientist). It’s unclear if some decisions may be devolved to lower officials. For example, if a paper is pulled because it simply mentions gender, it is unknown if anyone other than Monarez possesses the authority to approve its resubmission. </p><p>“How can one person vet all of this?” another official asked, “especially one who, [like Monarez], came from an agency of, what, 130 people?”</p><p>And yet, that seems to be the theme of the new administration: a few privileged individuals have been handed enormous authority, creating a backlog of decisions that may end up being fairly arbitrarily determined.</p><p data-attrs="{&quot;url&quot;:&quot;https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://insidemedicine.substack.com/p/breaking-news-cdc-orders-mass-retraction?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Recent results show that LLMs struggle with compositional tasks (313 pts)]]></title>
            <link>https://www.quantamagazine.org/chatbot-software-begins-to-face-fundamental-limitations-20250131/</link>
            <guid>42905453</guid>
            <pubDate>Sun, 02 Feb 2025 03:21:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/chatbot-software-begins-to-face-fundamental-limitations-20250131/">https://www.quantamagazine.org/chatbot-software-begins-to-face-fundamental-limitations-20250131/</a>, See on <a href="https://news.ycombinator.com/item?id=42905453">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-role="selectable">
    <p>On December 17, 1962,&nbsp; <em>Life International</em> published <a href="https://www.researchgate.net/publication/341189675_Is_Einstein's_Puzzle_Over-Specified">a logic puzzle</a> consisting of 15 sentences describing five houses on a street. Each sentence was a clue, such as “The Englishman lives in the red house” or “Milk is drunk in the middle house.” Each house was a different color, with inhabitants of different nationalities, who owned different pets, and so on. The story’s headline asked: “Who Owns the Zebra?” Problems like this one have proved to be a measure of the abilities — limitations, actually — of today’s machine learning models.</p>
<p>Also known as Einstein’s puzzle or riddle (likely an apocryphal attribution), the problem tests a certain kind of multistep reasoning. <a href="https://nouhadziri.github.io/">Nouha Dziri</a>, a research scientist at the Allen Institute for AI, and her colleagues recently set transformer-based large language models (LLMs), such as ChatGPT, to work on such tasks — and largely found them wanting. “They might not be able to reason beyond what they have seen during the training data for hard tasks,” Dziri said. “Or at least they do an approximation, and that approximation can be wrong.”</p>
<p>Einstein’s riddle requires composing a larger solution from solutions to subproblems, which researchers call a compositional task. Dziri’s team showed that LLMs that have only been trained to predict the next word in a sequence — which is most of them — are <a href="https://arxiv.org/abs/2305.18654">fundamentally limited</a> in their ability to solve compositional reasoning tasks. Other researchers have shown that transformers, the neural network architecture used by most LLMs, have hard mathematical bounds when it comes to solving such problems. Scientists have had some successes pushing transformers past these limits, but those increasingly look like short-term fixes. If so, it means there are fundamental computational caps on the abilities of these forms of artificial intelligence — which may mean it’s time to consider other approaches.</p>
<p>“The work is really motivated to help the community make this decision about whether transformers are really the architecture we want to embrace for universal learning,” said <a href="https://cims.nyu.edu/~andrewgw/">Andrew Wilson</a>, a machine learning expert at New York University who was not involved with this study.</p>
<h2><strong>Success Begets Scrutiny</strong></h2>

<p>Ironically, LLMs have only themselves to blame for this discovery of one of their limits. “The reason why we all got curious about whether they do real reasoning is because of their amazing capabilities,” Dziri said. They dazzled on tasks involving natural language, despite the seeming simplicity of their training. During the training phase, an LLM is shown a fragment of a sentence with the last word obscured (though technically it isn’t always a single word). The model predicts the missing information and then “learns” from its mistakes.</p>
<p>The largest LLMs — OpenAI’s o1 and GPT-4, Google’s Gemini, Anthropic’s Claude — train on almost all the available data on the internet. As a result, the LLMs end up learning the syntax of, and much of the semantic knowledge in, written language. Such “pre-trained” models can be further trained, or fine-tuned, to complete sophisticated tasks <a href="https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-models-20230316/">far beyond</a> simple sentence completion, such as summarizing a complex document or generating code to play a computer game. The results were so powerful that the models seemed, at times, <a href="https://www.quantamagazine.org/new-theory-suggests-chatbots-can-understand-text-20240122/">capable of reasoning</a>. Yet they also failed in ways both obvious and surprising.</p>
<p>“On certain tasks, they perform amazingly well,” Dziri said. “On others, they’re shockingly stupid.”</p>
<figure>
    <p><img width="1834" height="2560" src="https://www.quantamagazine.org/wp-content/uploads/2025/01/NouhaDziri_crAllenInstituteforAI-1-scaled.jpg" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/01/NouhaDziri_crAllenInstituteforAI-1-scaled.jpg 1834w, https://www.quantamagazine.org/wp-content/uploads/2025/01/NouhaDziri_crAllenInstituteforAI-1-1232x1720.jpg 1232w, https://www.quantamagazine.org/wp-content/uploads/2025/01/NouhaDziri_crAllenInstituteforAI-1-373x520.jpg 373w, https://www.quantamagazine.org/wp-content/uploads/2025/01/NouhaDziri_crAllenInstituteforAI-1-768x1072.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2025/01/NouhaDziri_crAllenInstituteforAI-1-1100x1536.jpg 1100w, https://www.quantamagazine.org/wp-content/uploads/2025/01/NouhaDziri_crAllenInstituteforAI-1-1467x2048.jpg 1467w" sizes="(max-width: 1834px) 100vw, 1834px">    </p>
            <figcaption>
                            <p>Nouha Dziri and her team helped show the difficulty current AI systems have with certain kinds of reasoning tasks.</p>
            <p>Allen Institute for AI</p>
        </figcaption>
    </figure>

<p>Take basic multiplication. Standard LLMs, such as ChatGPT and GPT-4, fail badly at it. In early 2023 when Dziri’s team asked GPT-4 to multiply two three-digit numbers, it initially succeeded only 59% of the time. When it multiplied two four-digit numbers, accuracy fell to just 4%.</p>
<p>The team also tested the LLMs on tasks like Einstein’s riddle, where it also had limited success. GPT-4 always got the right answer when the puzzle involved two houses with two attributes per house. But the accuracy fell to 10% when the complexity of the puzzle increased to four houses with four attributes per house. For the original version in <em>Life International</em> — five houses, each with five attributes — the success rate was 0%.</p>
<p>Dziri’s team thought that maybe the LLMs simply hadn’t seen enough examples in their training data, so they fine-tuned GPT-3 on 1.8 million examples of multiplying two numbers. Then, when they showed it new problems, the LLM aced them — but only if they were sufficiently similar to what it had seen during training. For example, the training data included the multiplication of two three-digit numbers, and of a two-digit number with a four-digit number, but when the model was asked to multiply a four-digit number with a three-digit number, it succeeded only 2% of the time. “If they are truly reasoning and understanding certain tasks, they should get the implicit algorithm,” Dziri said. That’s not what her team saw. “That raises a lot of questions about how LLMs perform tasks and whether they’re doing true reasoning.”</p>
<p>The team observed the same pattern when it came to solving Einstein’s riddle: GPT-3 failed when asked to answer bigger versions of the puzzle compared to the ones it was fine-tuned on. “It’s mimicking something that it has seen, but it doesn’t have full understanding of it,” Dziri said.</p>
<h2><strong>Hard Limits</strong></h2>

<p>As Dziri and her co-authors were finalizing their results, a different team was taking another approach to understanding why LLMs struggled with compositional tasks. <a href="https://www.cs.columbia.edu/~binghuip/">Binghui Peng</a>, at the time a doctoral student at Columbia University, was working with one of his advisers, Christos Papadimitriou, and colleagues to understand why LLMs “hallucinate,” or generate factually incorrect information. Peng, now a postdoctoral researcher at Stanford University, suspected it was because transformers seem to lack the “capability of composition.”</p>
<p>To understand why, imagine we feed an LLM two pieces of information: The father of Frédéric Chopin was Nicolas Chopin, and Nicolas Chopin was born on April 15, 1771. If we then ask it, “What is the birth date of Frédéric Chopin’s father?” the LLM would have to answer by composing, or putting together, the different facts. In effect, it would need to answer the following nested question: “What is the birth date of (Who is the father of (Frédéric Chopin)?)?” If the LLM predicts the wrong words as an answer, it’s said to have hallucinated — in this case, possibly as a result of failing to solve the compositional task.</p>
<p>Peng wanted to test this hunch. His team started by studying the properties of a simple transformer, one with only a single layer, which learns to “pay attention” to the ordering and position of a sentence’s words when trying to predict the next word. (Modern LLMs have scores of such layers.) The team <a href="https://arxiv.org/abs/2402.08164">established a link</a> between the complexity of the transformer layer and the “domain size,” or the number of bits required to represent the questions. By focusing on this simple model, they proved a mathematical bound. “If the total number of parameters in this one-layer transformer is less than the size of a domain, then transformers provably cannot solve the compositional task,” Peng said. In other words, an LLM with only one transformer layer was clearly and mathematically limited.</p>
<p>While this was a strong theoretical result, its practical implications weren’t clear, because modern LLMs are so much more complex. “It’s not easy to extend our proof,” Peng said. So his team used a different approach to study the abilities of more complicated transformers: They turned to computational complexity theory, which studies problems in terms of the resources, such as time and memory, needed to solve them.</p>
<figure>
    <p><img width="2560" height="2133" src="https://www.quantamagazine.org/wp-content/uploads/2025/01/BinghuiPeng_coBinghuiPeng-1-scaled.jpg" alt="" decoding="async" srcset="https://www.quantamagazine.org/wp-content/uploads/2025/01/BinghuiPeng_coBinghuiPeng-1-scaled.jpg 2560w, https://www.quantamagazine.org/wp-content/uploads/2025/01/BinghuiPeng_coBinghuiPeng-1-1720x1433.jpg 1720w, https://www.quantamagazine.org/wp-content/uploads/2025/01/BinghuiPeng_coBinghuiPeng-1-520x433.jpg 520w, https://www.quantamagazine.org/wp-content/uploads/2025/01/BinghuiPeng_coBinghuiPeng-1-768x640.jpg 768w, https://www.quantamagazine.org/wp-content/uploads/2025/01/BinghuiPeng_coBinghuiPeng-1-1536x1280.jpg 1536w, https://www.quantamagazine.org/wp-content/uploads/2025/01/BinghuiPeng_coBinghuiPeng-1-2048x1707.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px">    </p>
            <figcaption>
                            <p>Binghui Peng is part of a team that showed transformers, which underlie most large language models, have inherent mathematical limits to their abilities.</p>
            <p>Courtesy of Binghui Peng</p>
        </figcaption>
    </figure>

<p>They ended up using a well-known conjecture to show that the computational power of even multilayer transformers is limited when it comes to solving complicated compositional problems. Then, in December 2024, Peng and colleagues at the University of California, Berkeley <a href="https://arxiv.org/abs/2412.02975">posted a proof</a> — without relying on computational complexity conjectures — showing that multilayer transformers indeed cannot solve certain complicated compositional tasks. Basically, some compositional problems will always be beyond the ability of transformer-based LLMs.</p>
<p>“If your model gets larger, you can solve much harder problems,” Peng said. “But if, at the same time, you also scale up your problems, it again becomes harder for larger models.” This suggests that the transformer architecture has inherent limitations.</p>
<h2><strong>Pushing the Boundaries</strong></h2>

<p>To be clear, this is not the end of LLMs. Wilson of NYU points out that despite such limitations, researchers are beginning to augment transformers to help them better deal with, among other problems, arithmetic. For example, <a href="https://www.cs.umd.edu/~tomg/">Tom Goldstein</a>, a computer scientist at the University of Maryland, and his colleagues <a href="https://arxiv.org/abs/2405.17399">added a twist</a> to how they presented numbers to a transformer that was being trained to add, by embedding extra “positional” information in each digit. As a result, the model could be trained on 20-digit numbers and still reliably (with 98% accuracy) add 100-digit numbers, whereas a model trained without the extra positional embedding was only about 3% accurate. “This suggests that maybe there are some basic interventions that you could do,” Wilson said. “That could really make a lot of progress on these problems without needing to rethink the whole architecture.”</p>
<p>Another way to overcome an LLM’s limitations, beyond just increasing the size of the model, is to provide a step-by-step solution of a problem within the prompt, a technique known as <a href="https://www.quantamagazine.org/how-chain-of-thought-reasoning-helps-neural-networks-compute-20240321/">chain-of-thought</a> prompting. Empirical studies have shown that this approach can give an LLM such as GPT-4 a newfound ability to solve more varieties of related tasks. It’s not exactly clear why, which has led many researchers to study the phenomenon. “We were curious about why it’s so powerful and why you can do so many things,” said <a href="https://haotianye.com/">Haotian Ye</a>, &nbsp;a doctoral student at Stanford University.</p>
<p>When Ye was still an undergraduate at Peking University, he and his colleagues <a href="https://arxiv.org/abs/2305.15408">modeled the behavior of transformers</a> with and without chain-of-thought prompting. Their proof, using another branch of computer science called circuit complexity theory, established how chain-of-thought prompting essentially turns a large problem into a sequence of smaller problems, making it possible for transformers to tackle more complex compositional tasks. “That means … it can solve some problems that lie in a wider or more difficult computational class,” Ye said.</p>
        
        
<p>But, Ye cautions, their result does not imply that real-world models will actually solve such difficult problems, even with chain-of-thought. The work focused on what a model is theoretically capable of; the specifics of how models are trained dictate how they can come to achieve this upper bound.</p>
<p>Ultimately, as impressive as these results are, they don’t contradict the findings from Dziri’s and Peng’s teams. LLMs are fundamentally matching the patterns they’ve seen, and their abilities are constrained by mathematical boundaries. Embedding tricks and chain-of-thought prompting simply extends their ability to do more sophisticated pattern matching. The mathematical results imply that you can always find compositional tasks whose complexity lies beyond a given system’s abilities. Even some newer “state-space models,” which have been touted as more powerful alternatives to transformers, <a href="https://arxiv.org/abs/2405.16674">show similar limitations</a>.</p>
<p>On the one hand, these results don’t change anything for most people using these tools. “The general public doesn’t care whether it’s doing reasoning or not,” Dziri said. But for the people who build these models and try to understand their capabilities, it matters. “We have to really understand what’s going on under the hood,” she said. “If we crack how they perform a task and how they reason, we can probably fix them. But if we don’t know, that’s where it’s really hard to do anything.”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tools for 2025 (117 pts)]]></title>
            <link>http://yosemitesam.ch/3-tools-for-2025/</link>
            <guid>42904966</guid>
            <pubDate>Sun, 02 Feb 2025 02:12:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://yosemitesam.ch/3-tools-for-2025/">http://yosemitesam.ch/3-tools-for-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=42904966">Hacker News</a></p>
Couldn't get http://yosemitesam.ch/3-tools-for-2025/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Proposed bill to make it a crime to download DeepSeek in the US (104 pts)]]></title>
            <link>https://www.congress.gov/bill/119th-congress/senate-bill/321/all-actions?s=3&amp;r=1</link>
            <guid>42904838</guid>
            <pubDate>Sun, 02 Feb 2025 01:54:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.congress.gov/bill/119th-congress/senate-bill/321/all-actions?s=3&#x26;r=1">https://www.congress.gov/bill/119th-congress/senate-bill/321/all-actions?s=3&#x26;r=1</a>, See on <a href="https://news.ycombinator.com/item?id=42904838">Hacker News</a></p>
Couldn't get https://www.congress.gov/bill/119th-congress/senate-bill/321/all-actions?s=3&r=1: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA['Obelisks', a new class of life living inside humans (103 pts)]]></title>
            <link>https://bgr.com/science/researchers-just-discovered-an-entirely-new-class-of-life-living-inside-humans/</link>
            <guid>42904578</guid>
            <pubDate>Sun, 02 Feb 2025 01:20:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bgr.com/science/researchers-just-discovered-an-entirely-new-class-of-life-living-inside-humans/">https://bgr.com/science/researchers-just-discovered-an-entirely-new-class-of-life-living-inside-humans/</a>, See on <a href="https://news.ycombinator.com/item?id=42904578">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
								
<p>The human body is an amazing, curious, and disgusting thing. At any given moment, millions of tiny lifeforms are making their way across your body—both inside and out. And now, researchers say they’ve discovered an entirely new class of life within the human body, the digestive system, to be exact. These new life forms are called Obelisks, and researchers say that they first believed they might be viruses.</p><p>However, after studying them a bit more in-depth, the researchers believe that while they appear similar to viruses in some ways, they do not have any detectable sequences or even structural similarities to other known biological agents that we have encountered. So, if they are <a target="_blank" rel="noreferrer noopener" href="https://bgr.com/science/your-toothbrush-is-covered-with-hundreds-of-viruses-unlike-anything-seen-before/">viruses</a>, they’re something entirely new.

</p><p><span>However, the chances of this new class of life within the&nbsp;<a href="https://bgr.com/science/new-human-organ-interstitium-skin-tissue/" target="_blank" rel="noopener">human body</a>&nbsp;being a vi</span>rus are slim, especially since the researchers say they have so far identified at least 30,000 different Obelisks. Further, they appeared in roughly 10 percent of the human microbiomes that the team examined while working on a preprint paper. This, the researchers say, supports the idea that Obelisks might include colonists of these different microbiomes.</p><figure><img loading="lazy" decoding="async" width="6016" height="4016" src="https://bgr.com/wp-content/uploads/2022/02/AdobeStock_313579308.jpeg?quality=82&amp;strip=all" alt="scientists working in lab" srcset="https://bgr.com/wp-content/uploads/2022/02/AdobeStock_313579308.jpeg?quality=82 6016w, https://bgr.com/wp-content/uploads/2022/02/AdobeStock_313579308.jpeg?resize=150%2C100&amp;quality=82 150w, https://bgr.com/wp-content/uploads/2022/02/AdobeStock_313579308.jpeg?resize=300%2C200&amp;quality=82 300w, https://bgr.com/wp-content/uploads/2022/02/AdobeStock_313579308.jpeg?resize=768%2C513&amp;quality=82 768w, https://bgr.com/wp-content/uploads/2022/02/AdobeStock_313579308.jpeg?resize=1024%2C684&amp;quality=82 1024w, https://bgr.com/wp-content/uploads/2022/02/AdobeStock_313579308.jpeg?resize=1536%2C1025&amp;quality=82 1536w, https://bgr.com/wp-content/uploads/2022/02/AdobeStock_313579308.jpeg?resize=2048%2C1367&amp;quality=82 2048w, https://bgr.com/wp-content/uploads/2022/02/AdobeStock_313579308.jpeg?resize=63%2C42&amp;quality=82 63w" sizes="(max-width: 6016px) 100vw, 6016px"><span><span>Image source: chokniti / Adobe</span></span></figure><p>Exactly where these Obelisks come from, though, is still very unclear. Researchers are still unsure exactly what might play “host” to these different pieces of genetic material. However, they all seem to include codes for a new protein class that the researchers have begun to call Oblins.</p><div>	<h4>Tech. Entertainment. Science. Your inbox.</h4>	<p>Sign up for the most interesting tech &amp; entertainment news out there.</p>		<p>By signing up, I agree to the <a rel="noopener" href="https://pmc.com/terms-of-use/" target="_blank">Terms of Use</a> and have reviewed the <a rel="noopener" href="https://pmc.com/privacy-policy/" target="_blank">Privacy Notice.</a></p>	</div><p>Instructions for building these proteins appear to take up at least half of the genetic material found in this new class of life. Additionally, the researchers say that the ability to code for proteins makes the Obelisks much different from other known RNA loops, like viroids.</p>
<p>However, they also don’t seem to have the genetic makeup to create the protein shells that RNA viruses are known for—including COVID-19—which allows the viruses to live when they are outside of their cells. The researchers’ paper is available on the preprint server <a href="https://www.biorxiv.org/content/10.1101/2024.01.20.576352v1" target="_blank" rel="noreferrer noopener"><em>bioRxiv</em></a>, and further peer review is needed to determine the true value of these findings.</p>
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Smoot–Hawley Tariff Act (102 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Smoot%E2%80%93Hawley_Tariff_Act</link>
            <guid>42904351</guid>
            <pubDate>Sun, 02 Feb 2025 00:55:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Smoot%E2%80%93Hawley_Tariff_Act">https://en.wikipedia.org/wiki/Smoot%E2%80%93Hawley_Tariff_Act</a>, See on <a href="https://news.ycombinator.com/item?id=42904351">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div lang="en" dir="ltr" id="mw-content-text">

<table><caption>Tariff Act of 1930</caption><tbody><tr><td colspan="2"><span typeof="mw:File"><a href="https://en.wikipedia.org/wiki/File:Great_Seal_of_the_United_States_(obverse).svg"><img alt="Great Seal of the United States" src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/5c/Great_Seal_of_the_United_States_%28obverse%29.svg/140px-Great_Seal_of_the_United_States_%28obverse%29.svg.png" decoding="async" width="140" height="140" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/5/5c/Great_Seal_of_the_United_States_%28obverse%29.svg/210px-Great_Seal_of_the_United_States_%28obverse%29.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/5/5c/Great_Seal_of_the_United_States_%28obverse%29.svg/280px-Great_Seal_of_the_United_States_%28obverse%29.svg.png 2x" data-file-width="600" data-file-height="600"></a></span></td></tr><tr><th scope="row">Long title</th><td>An Act To provide revenue, to regulate commerce with foreign countries, to encourage the industries of the United States, to protect American labor, and for other purposes.</td></tr><tr><th scope="row">Nicknames</th><td>Hawley–Smoot Tariff, Smoot–Hawley Tariff</td></tr><tr><th scope="row">Enacted&nbsp;by</th><td>the <a href="https://en.wikipedia.org/wiki/71st_United_States_Congress" title="71st United States Congress">71st United States Congress</a></td></tr><tr><th scope="row">Effective</th><td>March 13, 1930</td></tr><tr><th colspan="2">Citations</th></tr><tr><th scope="row">Public law</th><td><a href="https://en.wikipedia.org/wiki/Act_of_Congress#Public_law,_private_law,_designation" title="Act of Congress"><abbr title="Public Law">Pub. L.</abbr></a>&nbsp;<a rel="nofollow" href="https://uslaw.link/citation/us-law/public/71/361">71–361</a></td></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/United_States_Statutes_at_Large" title="United States Statutes at Large"><span>Statutes at Large</span></a></th><td>ch. 497, 46&nbsp;<a href="https://en.wikipedia.org/wiki/United_States_Statutes_at_Large" title="United States Statutes at Large">Stat.</a>&nbsp;<a rel="nofollow" href="https://legislink.org/us/stat-46-590">590</a></td></tr><tr><th colspan="2">Codification</th></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/United_States_Code" title="United States Code">U.S.C.</a> sections created</th><td>589</td></tr><tr><th colspan="2">Legislative history</th></tr><tr><td colspan="2"><div><ul><li><b>Introduced</b> in the House of Representatives as H.R. 2667 by <a href="https://en.wikipedia.org/wiki/Willis_C._Hawley" title="Willis C. Hawley">Willis C. Hawley</a> (<a href="https://en.wikipedia.org/wiki/Republican_Party_(United_States)" title="Republican Party (United States)">R</a>-<a href="https://en.wikipedia.org/wiki/Oregon" title="Oregon">OR</a>) on April or May 1929</li><li><b>Committee consideration</b> by <a href="https://en.wikipedia.org/wiki/United_States_House_Committee_on_Ways_and_Means" title="United States House Committee on Ways and Means">House Ways and Means</a>, <a href="https://en.wikipedia.org/wiki/United_States_Senate_Committee_on_Finance" title="United States Senate Committee on Finance">Senate Finance</a></li><li><b>Passed the House</b> on May 28, 1929&nbsp;(<a rel="nofollow" href="https://www.govtrack.us/congress/votes/71-1/h7">264–147</a>)</li><li><b>Passed the Senate</b>  on March 24, 1930&nbsp;(<a rel="nofollow" href="https://www.govtrack.us/congress/votes/71-2/s295">53–31</a>)</li><li><b>Reported by the joint conference committee</b> on June 9, 1930; <b>agreed to by the Senate</b> on June 13, 1930&nbsp;(without <a href="https://en.wikipedia.org/wiki/Division_of_the_assembly" title="Division of the assembly">division</a>, after motion to <a href="https://en.wikipedia.org/wiki/Commit_(motion)" title="Commit (motion)">recommit</a> failed <a rel="nofollow" href="https://www.govtrack.us/congress/votes/71-2/s345">42–44</a>) and by the <b>House</b> on June 14, 1930&nbsp;(<a rel="nofollow" href="https://www.govtrack.us/congress/votes/71-2/h60">222–153</a>)</li><li><b>Signed into law</b> by President <a href="https://en.wikipedia.org/wiki/Herbert_Hoover" title="Herbert Hoover">Herbert Hoover</a> on June 17, 1930</li></ul></div></td></tr><tr><th colspan="2">Major amendments</th></tr><tr><td colspan="2">Moving Americans Privacy Protection Act</td></tr></tbody></table>
<p>The <b>Tariff Act of 1930</b> (codified at <a href="https://en.wikipedia.org/wiki/Title_19_of_the_United_States_Code" title="Title 19 of the United States Code">19 U.S.C.</a> <a rel="nofollow" href="https://www.law.cornell.edu/uscode/text/19/chapter-4">ch. 4</a>), commonly known as the <b>Smoot–Hawley Tariff</b> or <b>Hawley–Smoot Tariff</b>,<sup id="cite_ref-1"><a href="#cite_note-1"><span>[</span>1<span>]</span></a></sup> was a law that implemented <a href="https://en.wikipedia.org/wiki/Protectionism" title="Protectionism">protectionist</a> trade policies in the United States. Sponsored by Senator <a href="https://en.wikipedia.org/wiki/Reed_Smoot" title="Reed Smoot">Reed Smoot</a> and Representative <a href="https://en.wikipedia.org/wiki/Willis_C._Hawley" title="Willis C. Hawley">Willis C. Hawley</a>, it was signed by President <a href="https://en.wikipedia.org/wiki/Herbert_Hoover" title="Herbert Hoover">Herbert Hoover</a> on June 17, 1930. The act raised US <a href="https://en.wikipedia.org/wiki/Tariff" title="Tariff">tariffs</a> on over 20,000 imported goods.<sup id="cite_ref-FOOTNOTETaussig1931_2-0"><a href="#cite_note-FOOTNOTETaussig1931-2"><span>[</span>2<span>]</span></a></sup>
</p><p>The tariffs under the act, excluding duty-free imports, were the second highest in United States history, exceeded by only the <a href="https://en.wikipedia.org/wiki/Tariff_of_1828" title="Tariff of 1828">Tariff of 1828</a>.<sup id="cite_ref-3"><a href="#cite_note-3"><span>[</span>3<span>]</span></a></sup> The Act prompted retaliatory tariffs by many other countries.<sup id="cite_ref-:2_4-0"><a href="#cite_note-:2-4"><span>[</span>4<span>]</span></a></sup> The Act and tariffs imposed by America's trading partners in retaliation were major factors of the reduction of American exports and imports by 67% during the <a href="https://en.wikipedia.org/wiki/Great_Depression" title="Great Depression">Great Depression</a>.<sup id="cite_ref-Eckes_1995_5-0"><a href="#cite_note-Eckes_1995-5"><span>[</span>5<span>]</span></a></sup> Economists and economic historians have agreed that the passage of the Smoot–Hawley Tariff worsened the effects of the Great Depression.<sup id="cite_ref-6"><a href="#cite_note-6"><span>[</span>6<span>]</span></a></sup>
</p>
<meta property="mw:PageProp/toc">
<div><h2 id="Sponsors_and_legislative_history">Sponsors and legislative history</h2><p><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Smoot%E2%80%93Hawley_Tariff_Act&amp;action=edit&amp;section=1" title="Edit section: Sponsors and legislative history"><span>edit</span></a><span>]</span></span></p></div>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Smoot_and_Hawley_standing_together,_April_11,_1929.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/Smoot_and_Hawley_standing_together%2C_April_11%2C_1929.jpg/220px-Smoot_and_Hawley_standing_together%2C_April_11%2C_1929.jpg" decoding="async" width="220" height="227" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/Smoot_and_Hawley_standing_together%2C_April_11%2C_1929.jpg/330px-Smoot_and_Hawley_standing_together%2C_April_11%2C_1929.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/Smoot_and_Hawley_standing_together%2C_April_11%2C_1929.jpg/440px-Smoot_and_Hawley_standing_together%2C_April_11%2C_1929.jpg 2x" data-file-width="3546" data-file-height="3662"></a><figcaption><a href="https://en.wikipedia.org/wiki/Willis_C._Hawley" title="Willis C. Hawley">Willis C. Hawley</a> (left) and <a href="https://en.wikipedia.org/wiki/Reed_Smoot" title="Reed Smoot">Reed Smoot</a> in April 1929, shortly before the Smoot–Hawley Tariff Act passed the House of Representatives</figcaption></figure>
<p>The <a href="https://en.wikipedia.org/wiki/League_of_Nations" title="League of Nations">League of Nations</a>' <a href="https://en.wikipedia.org/wiki/Geneva_World_Economic_Conference_(1927)" title="Geneva World Economic Conference (1927)">World Economic Conference</a> met at Geneva in 1927, concluding in its final report that "the time has come to put an end to <a href="https://en.wikipedia.org/wiki/Tariff" title="Tariff">tariffs</a>, and to move in the opposite direction". Vast debts and reparations could be repaid only through gold, services, or goods, but the only items available on that scale were goods; however, many of the delegates' governments did the opposite; in 1928, France was the first by passing a new tariff law and quota system.<sup id="cite_ref-Peel_7-0"><a href="#cite_note-Peel-7"><span>[</span>7<span>]</span></a></sup>
</p><p>By the late 1920s, the US economy had made exceptional gains in productivity because of <a href="https://en.wikipedia.org/wiki/Electrification" title="Electrification">electrification</a>, which was a critical factor in <a href="https://en.wikipedia.org/wiki/Mass_production" title="Mass production">mass production</a>. Another contributing factor to economic growth was motorcars, trucks, and tractors replacing horses and mules. One sixth to one quarter of farmland, which had been devoted to feeding horses and mules, was freed up, contributing to a surplus in farm produce. Although nominal and real wages had increased, they did not keep up with the <a href="https://en.wikipedia.org/wiki/Productivity" title="Productivity">productivity</a> gains.
</p><p>Senator Smoot contended that raising the tariff on imports would alleviate the overproduction problem, but the United States had actually been running a <a href="https://en.wikipedia.org/wiki/Balance_of_trade" title="Balance of trade">trade account surplus</a>, and although manufactured goods imports were rising, manufactured exports were rising even faster. Food exports had been falling and were in trade account deficit, but the value of food imports were a little over half of the value of manufactured imports.<sup id="cite_ref-Beaudreau_1996_8-0"><a href="#cite_note-Beaudreau_1996-8"><span>[</span>8<span>]</span></a></sup>
</p>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Smoot_Hawley_Senate_Vote.svg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Smoot_Hawley_Senate_Vote.svg/220px-Smoot_Hawley_Senate_Vote.svg.png" decoding="async" width="220" height="136" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Smoot_Hawley_Senate_Vote.svg/330px-Smoot_Hawley_Senate_Vote.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Smoot_Hawley_Senate_Vote.svg/440px-Smoot_Hawley_Senate_Vote.svg.png 2x" data-file-width="959" data-file-height="593"></a><figcaption>Senate vote by state <p><span>&nbsp;</span>&nbsp;Two <i>yeas</i></p> <p><span>&nbsp;</span>&nbsp;Two <i>nays</i></p> <p><span>&nbsp;</span>&nbsp;One <i>yea</i> and one <i>nay</i></p> <p><span>&nbsp;</span>&nbsp;One <i>yea</i> and one <i>abstention</i></p> <p><span>&nbsp;</span>&nbsp;One nay and one <i>abstention</i></p> <p><span>&nbsp;</span>&nbsp;Two <i>abstentions</i></p> </figcaption></figure>
<p>As the global economy entered the first stages of the <a href="https://en.wikipedia.org/wiki/Great_Depression" title="Great Depression">Great Depression</a> in late 1929, the main goal of the US was to protect its jobs and farmers from foreign competition. Smoot championed another tariff increase within the United States in 1929, which became the Smoot–Hawley Tariff Bill. In his memoirs, Smoot made it abundantly clear: "The world is paying for its ruthless destruction of life and property in the <a href="https://en.wikipedia.org/wiki/World_War_I" title="World War I">World War</a> and for its failure to adjust purchasing power to productive capacity during the <a href="https://en.wikipedia.org/wiki/Industrial_revolution" title="Industrial revolution">industrial revolution</a> of the <a href="https://en.wikipedia.org/wiki/Roaring_Twenties" title="Roaring Twenties">decade following the war</a>."<sup id="cite_ref-Meril1990_9-0"><a href="#cite_note-Meril1990-9"><span>[</span>9<span>]</span></a></sup>
</p><p>Smoot was a <a href="https://en.wikipedia.org/wiki/History_of_the_United_States_Republican_Party" title="History of the United States Republican Party">Republican</a> from <a href="https://en.wikipedia.org/wiki/Utah" title="Utah">Utah</a> and chairman of the <a href="https://en.wikipedia.org/wiki/Senate_Finance_Committee" title="Senate Finance Committee">Senate Finance Committee</a>. <a href="https://en.wikipedia.org/wiki/Willis_C._Hawley" title="Willis C. Hawley">Willis C. Hawley</a>, a Republican from <a href="https://en.wikipedia.org/wiki/Oregon" title="Oregon">Oregon</a>, was chairman of the <a href="https://en.wikipedia.org/wiki/House_Committee_on_Ways_and_Means" title="House Committee on Ways and Means">House Committee on Ways and Means</a>. During the <a href="https://en.wikipedia.org/wiki/1928_United_States_presidential_election" title="1928 United States presidential election">1928 United States presidential election</a>, one of <a href="https://en.wikipedia.org/wiki/Herbert_Hoover" title="Herbert Hoover">Herbert Hoover</a>'s promises was to help beleaguered farmers by increasing tariffs on agricultural products. Hoover won, and Republicans maintained comfortable majorities <a href="https://en.wikipedia.org/wiki/1928_United_States_House_of_Representatives_elections" title="1928 United States House of Representatives elections">in the House</a> and <a href="https://en.wikipedia.org/wiki/1928_United_States_Senate_elections" title="1928 United States Senate elections">the Senate</a> during 1928. The House passed a version of the act in May 1929, increasing tariffs on agricultural and industrial goods alike. The House bill passed on a vote of 264 to 147, with 244 Republicans and 20 Democrats voting in favor of the bill.<sup id="cite_ref-Irwin_1996_10-0"><a href="#cite_note-Irwin_1996-10"><span>[</span>10<span>]</span></a></sup> The Senate debated its bill until March 1930, with many members trading votes based on their states' industries. The Senate bill passed on a vote of 44 to 42, with 39 Republicans and 5 Democrats voting in favor of the bill.<sup id="cite_ref-Irwin_1996_10-1"><a href="#cite_note-Irwin_1996-10"><span>[</span>10<span>]</span></a></sup> The <a href="https://en.wikipedia.org/wiki/United_States_congressional_conference_committee" title="United States congressional conference committee">conference committee</a> then unified the two versions, largely by raising tariffs to the higher levels passed by the House.<sup id="cite_ref-economist_11-0"><a href="#cite_note-economist-11"><span>[</span>11<span>]</span></a></sup> The House passed the conference bill on a vote of 222 to 153, with the support of 208 Republicans and 14 Democrats.<sup id="cite_ref-Irwin_1996_10-2"><a href="#cite_note-Irwin_1996-10"><span>[</span>10<span>]</span></a></sup>
</p>

<p>In May 1930, a petition was signed by 1,028 economists in the United States asking President Hoover to veto the legislation, organized by <a href="https://en.wikipedia.org/wiki/Paul_Douglas_(Illinois_politician)" title="Paul Douglas (Illinois politician)">Paul Douglas</a>, <a href="https://en.wikipedia.org/wiki/Irving_Fisher" title="Irving Fisher">Irving Fisher</a>, James T. F. G. Wood, <a href="https://en.wikipedia.org/wiki/Frank_Dunstone_Graham" title="Frank Dunstone Graham">Frank Graham</a>, Ernest Patterson, <a href="https://en.wikipedia.org/wiki/Henry_Seager" title="Henry Seager">Henry Seager</a>, <a href="https://en.wikipedia.org/wiki/Frank_Taussig" title="Frank Taussig">Frank Taussig</a>, and <a href="https://en.wikipedia.org/wiki/Clair_Wilcox" title="Clair Wilcox">Clair Wilcox</a>.<sup id="cite_ref-12"><a href="#cite_note-12"><span>[</span>12<span>]</span></a></sup><sup id="cite_ref-13"><a href="#cite_note-13"><span>[</span>13<span>]</span></a></sup> Automobile executive <a href="https://en.wikipedia.org/wiki/Henry_Ford" title="Henry Ford">Henry Ford</a> also spent an evening at the <a href="https://en.wikipedia.org/wiki/White_House" title="White House">White House</a> trying to convince Hoover to veto the bill, calling it "an economic stupidity",<sup id="cite_ref-14"><a href="#cite_note-14"><span>[</span>14<span>]</span></a></sup> while <a href="https://en.wikipedia.org/wiki/J._P._Morgan" title="J. P. Morgan">J. P. Morgan</a>'s Chief Executive <a href="https://en.wikipedia.org/wiki/Thomas_W._Lamont" title="Thomas W. Lamont">Thomas W. Lamont</a> said he "almost went down on [his] knees to beg Herbert Hoover to veto the asinine Hawley–Smoot tariff".<sup id="cite_ref-15"><a href="#cite_note-15"><span>[</span>15<span>]</span></a></sup>
</p><p>While Hoover joined the economists in opposing the bill, calling it "vicious, extortionate, and obnoxious" because he felt it would undermine the commitment he had pledged to international cooperation, he eventually signed the bill after he yielded to influence from his own party, his Cabinet (who had threatened to resign), and business leaders.<sup id="cite_ref-Sobel_1972_16-0"><a href="#cite_note-Sobel_1972-16"><span>[</span>16<span>]</span></a></sup> In retaliation, Canada and other countries raised their own tariffs on American goods after the bill had become law.<sup id="cite_ref-17"><a href="#cite_note-17"><span>[</span>17<span>]</span></a></sup> <a href="https://en.wikipedia.org/wiki/Franklin_D._Roosevelt" title="Franklin D. Roosevelt">Franklin D. Roosevelt</a> spoke against the act during his campaign for President in 1932.<sup id="cite_ref-economist_11-1"><a href="#cite_note-economist-11"><span>[</span>11<span>]</span></a></sup>
</p>

<p>Most of the decline in trade was due to a plunge in GDP in the US and worldwide. However, beyond that was additional decline. Some countries protested and others also retaliated with trade restrictions and tariffs. American exports to the protesters fell 18% and exports to those who retaliated fell 31%.<sup id="cite_ref-18"><a href="#cite_note-18"><span>[</span>18<span>]</span></a></sup> Threats of retaliation by other countries began long before the bill was enacted into law in June 1930. As the House of Representatives passed it in May 1929, boycotts broke out, and foreign governments moved to increase rates against American products, although rates could be increased or decreased by the Senate or by the conference committee. By September 1929, Hoover's administration had received protest notes from 23 trading partners, but the threats of retaliatory actions were ignored.<sup id="cite_ref-economist_11-2"><a href="#cite_note-economist-11"><span>[</span>11<span>]</span></a></sup>
</p><p>In May 1930, Canada, the country's most loyal trading partner, retaliated by imposing new tariffs on 16 products that accounted altogether for around 30% of US exports to Canada.<sup id="cite_ref-19"><a href="#cite_note-19"><span>[</span>19<span>]</span></a></sup> Canada later also forged closer economic links with the <a href="https://en.wikipedia.org/wiki/British_Empire" title="British Empire">British Empire</a> via the <a href="https://en.wikipedia.org/wiki/British_Empire_Economic_Conference" title="British Empire Economic Conference">British Empire Economic Conference</a> of 1932, while France and Britain protested and developed new trade partners, and Germany developed a system of trade via clearing. The depression worsened for workers and farmers despite Smoot and Hawley's promises of prosperity from high tariffs; consequently, Hawley lost re-nomination, while Smoot was one of 12 Republican Senators who lost their seats in <a href="https://en.wikipedia.org/wiki/1932_United_States_Senate_elections" title="1932 United States Senate elections">the 1932 elections</a>, with the swing being the largest in Senate history (being equaled in <a href="https://en.wikipedia.org/wiki/1958_United_States_Senate_elections" title="1958 United States Senate elections">1958</a> and <a href="https://en.wikipedia.org/wiki/1980_United_States_Senate_elections" title="1980 United States Senate elections">1980</a>).<sup id="cite_ref-20"><a href="#cite_note-20"><span>[</span>20<span>]</span></a></sup> Nations other than Canada that enacted retaliatory tariffs included: Cuba, Mexico, France, Italy, Spain, Argentina, Australia, New Zealand, and Switzerland.<sup id="cite_ref-:2_4-1"><a href="#cite_note-:2-4"><span>[</span>4<span>]</span></a></sup>
</p>

<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Average_Tariff_Rates_in_USA_(1821-2016).png"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Average_Tariff_Rates_in_USA_%281821-2016%29.png/450px-Average_Tariff_Rates_in_USA_%281821-2016%29.png" decoding="async" width="450" height="228" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Average_Tariff_Rates_in_USA_%281821-2016%29.png/675px-Average_Tariff_Rates_in_USA_%281821-2016%29.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Average_Tariff_Rates_in_USA_%281821-2016%29.png/900px-Average_Tariff_Rates_in_USA_%281821-2016%29.png 2x" data-file-width="1291" data-file-height="653"></a><figcaption>Average tariff rates in the United States, 1821–2016</figcaption></figure>
<p>In the two-volume series published by the US Bureau of the Census, "The Historical Statistics of the United States, Colonial Times to 1970, Bicentennial Edition", tariff rates have been represented in two forms. The dutiable tariff rate peak of 1932 was 59.1%, second only to the 61.7% rate of 1830.<sup id="cite_ref-21"><a href="#cite_note-21"><span>[</span>21<span>]</span></a></sup>
</p><p>However, 63% of all imports in 1933 were not taxed, which the dutiable tariff rate does not reflect. The free and dutiable rate in 1929 was 13.5% and peaked under Smoot–Hawley in 1933 at 19.8%, one-third below the average 29.7% "free and dutiable rate" in the United States from 1821 to 1900.<sup id="cite_ref-22"><a href="#cite_note-22"><span>[</span>22<span>]</span></a></sup> The average tariff rate, which was applied on dutiable imports,<sup id="cite_ref-:0_23-0"><a href="#cite_note-:0-23"><span>[</span>23<span>]</span></a></sup><sup id="cite_ref-:1_24-0"><a href="#cite_note-:1-24"><span>[</span>24<span>]</span></a></sup> increased from 40.1% in 1929 to 59.1% in 1932 (+19%).<sup id="cite_ref-:0_23-1"><a href="#cite_note-:0-23"><span>[</span>23<span>]</span></a></sup><sup id="cite_ref-:1_24-1"><a href="#cite_note-:1-24"><span>[</span>24<span>]</span></a></sup>
</p>

<p>At first, the tariff seemed to be a success. According to historian <a href="https://en.wikipedia.org/wiki/Robert_Sobel" title="Robert Sobel">Robert Sobel</a>, "Factory payrolls, construction contracts, and industrial production all increased sharply." However, larger economic problems loomed in the guise of weak banks. When the <a href="https://en.wikipedia.org/wiki/Creditanstalt" title="Creditanstalt">Creditanstalt</a> of <a href="https://en.wikipedia.org/wiki/Austria" title="Austria">Austria</a> failed in 1931, the global deficiencies of the Smoot–Hawley Tariff became apparent.<sup id="cite_ref-Sobel_1972_16-1"><a href="#cite_note-Sobel_1972-16"><span>[</span>16<span>]</span></a></sup> US imports decreased 66% from $4.4 billion (1929) to $1.5 billion (1933), and exports decreased 61% from $5.4 billion to $2.1 billion. GNP fell from $103.1 billion in 1929 to $75.8 billion in 1931 and bottomed out at $55.6 billion in 1933.<sup id="cite_ref-25"><a href="#cite_note-25"><span>[</span>25<span>]</span></a></sup> Imports from Europe decreased from a 1929 high of $1.3 billion to just $390 million during 1932, and US exports to Europe decreased from $2.3 billion in 1929 to $784 million in 1932. Overall, world trade decreased by some 66% between 1929 and 1934.<sup id="cite_ref-26"><a href="#cite_note-26"><span>[</span>26<span>]</span></a></sup>
</p><p>Unemployment was 8% in 1930 when the Smoot–Hawley Act was passed but the new law failed to lower it. The rate jumped to 16% in 1931 and 25% in 1932–1933.<sup id="cite_ref-27"><a href="#cite_note-27"><span>[</span>27<span>]</span></a></sup> There is some contention about whether this can necessarily be attributed to the tariff.<sup id="cite_ref-FOOTNOTEEckes1995113_28-0"><a href="#cite_note-FOOTNOTEEckes1995113-28"><span>[</span>28<span>]</span></a></sup><sup id="cite_ref-FOOTNOTEIrwin1998332–333_29-0"><a href="#cite_note-FOOTNOTEIrwin1998332–333-29"><span>[</span>29<span>]</span></a></sup> It was only during <a href="https://en.wikipedia.org/wiki/World_War_II" title="World War II">World War II</a>, when "the American economy expanded at an unprecedented rate",<sup id="cite_ref-30"><a href="#cite_note-30"><span>[</span>30<span>]</span></a></sup> that unemployment fell below 1930s levels.<sup id="cite_ref-31"><a href="#cite_note-31"><span>[</span>31<span>]</span></a></sup> Imports during 1929 were only 4.2% of the US GNP, and exports were only 5.0%. <a href="https://en.wikipedia.org/wiki/Monetarists" title="Monetarists">Monetarists</a>, such as <a href="https://en.wikipedia.org/wiki/Milton_Friedman" title="Milton Friedman">Milton Friedman</a>, who emphasized the central role of the money supply in causing the depression, considered the Smoot–Hawley Act to be only a minor cause for the <a href="https://en.wikipedia.org/wiki/Great_Depression_in_the_United_States" title="Great Depression in the United States">Great Depression in the United States</a>.<sup id="cite_ref-32"><a href="#cite_note-32"><span>[</span>32<span>]</span></a></sup>
</p>

<p>The 1932 <a href="https://en.wikipedia.org/wiki/Democratic_Party_(United_States)" title="Democratic Party (United States)">Democratic</a> campaign platform pledged to lower tariffs. After winning the election, President <a href="https://en.wikipedia.org/wiki/Franklin_D._Roosevelt" title="Franklin D. Roosevelt">Franklin D. Roosevelt</a> and the now-Democratic Congress passed <a href="https://en.wikipedia.org/wiki/Reciprocal_Trade_Agreements_Act" title="Reciprocal Trade Agreements Act">Reciprocal Trade Agreements Act</a> of 1934. This act allowed the President to negotiate tariff reductions on a bilateral basis and treated such a tariff agreement as regular legislation, requiring a majority, rather than as a treaty requiring a two-thirds vote. This was one of the core components of the trade negotiating framework that developed after World War II. After World War II, that understanding supported a push towards multilateral trading agreements that would prevent similar situations in the future. While the <a href="https://en.wikipedia.org/wiki/Bretton_Woods_system" title="Bretton Woods system">Bretton Woods Agreement</a> of 1944 focused on foreign exchange and did not directly address tariffs, those involved wanted a similar framework for <a href="https://en.wikipedia.org/wiki/International_trade" title="International trade">international trade</a>. President <a href="https://en.wikipedia.org/wiki/Harry_S._Truman" title="Harry S. Truman">Harry S. Truman</a> launched this process in November 1945 with negotiations for the creation of a proposed <a href="https://en.wikipedia.org/wiki/International_Trade_Organization" title="International Trade Organization">International Trade Organization</a> (ITO).<sup id="cite_ref-33"><a href="#cite_note-33"><span>[</span>33<span>]</span></a></sup>
</p><p>As it happened, separate negotiations on the <a href="https://en.wikipedia.org/wiki/General_Agreement_on_Tariffs_and_Trade" title="General Agreement on Tariffs and Trade">General Agreement on Tariffs and Trade</a> (GATT) moved more quickly, with an agreement signed in October 1947; in the end, the United States never signed the ITO agreement. Adding a multilateral "most-favored-nation" component to that of reciprocity, the GATT served as a framework for the gradual reduction of tariffs over the subsequent half century.<sup id="cite_ref-34"><a href="#cite_note-34"><span>[</span>34<span>]</span></a></sup> Postwar changes to the Smoot–Hawley tariffs reflected a general tendency of the United States to reduce its tariff levels unilaterally while its trading partners retained their high levels. The American Tariff League Study of 1951 compared the free and dutiable tariff rates of 43 countries. It found that only seven nations had a lower tariff level than the United States (5.1%), and eleven nations had free and dutiable tariff rates higher than the Smoot–Hawley peak of 19.8% including the United Kingdom (25.6%). The 43-country average was 14.4%, which was 0.9% higher than the U.S. level of 1929, demonstrating that few nations were reciprocating in reducing their levels as the United States reduced its own.<sup id="cite_ref-35"><a href="#cite_note-35"><span>[</span>35<span>]</span></a></sup>
</p>
<div><h2 id="In_modern_political_dialogue">In modern political dialogue</h2><p><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Smoot%E2%80%93Hawley_Tariff_Act&amp;action=edit&amp;section=7" title="Edit section: In modern political dialogue"><span>edit</span></a><span>]</span></span></p></div>
<p>In the discussion leading up to the passage of the <a href="https://en.wikipedia.org/wiki/North_American_Free_Trade_Agreement" title="North American Free Trade Agreement">North American Free Trade Agreement</a> (NAFTA), then-Vice President <a href="https://en.wikipedia.org/wiki/Al_Gore" title="Al Gore">Al Gore</a> mentioned the Smoot–Hawley Tariff as a response to NAFTA objections voiced by <a href="https://en.wikipedia.org/wiki/H._Ross_Perot" title="H. Ross Perot">Ross Perot</a> during a <a href="https://en.wikipedia.org/wiki/H._Ross_Perot#Reform_Party_and_1996_presidential_campaign" title="H. Ross Perot">debate in 1993</a> they had on <i><a href="https://en.wikipedia.org/wiki/The_Larry_King_Show" title="The Larry King Show">The Larry King Show</a></i>. He gave Perot a framed picture of Smoot and Hawley shaking hands after its passage.<sup id="cite_ref-economist_11-3"><a href="#cite_note-economist-11"><span>[</span>11<span>]</span></a></sup> In April 2009, then-Representative <a href="https://en.wikipedia.org/wiki/Michele_Bachmann" title="Michele Bachmann">Michele Bachmann</a> made news when, during a speech, she referred to the Smoot–Hawley Tariff as "the Hoot–Smalley Act", misattributed its signing to <a href="https://en.wikipedia.org/wiki/Franklin_D._Roosevelt" title="Franklin D. Roosevelt">Franklin D. Roosevelt</a>, and blamed it for the <a href="https://en.wikipedia.org/wiki/Great_Depression" title="Great Depression">Great Depression</a>.<sup id="cite_ref-36"><a href="#cite_note-36"><span>[</span>36<span>]</span></a></sup><sup id="cite_ref-37"><a href="#cite_note-37"><span>[</span>37<span>]</span></a></sup><sup id="cite_ref-Yglesias_2009_38-0"><a href="#cite_note-Yglesias_2009-38"><span>[</span>38<span>]</span></a></sup> The act has been compared to the 2010 <a href="https://en.wikipedia.org/wiki/Foreign_Account_Tax_Compliance_Act" title="Foreign Account Tax Compliance Act">Foreign Account Tax Compliance Act</a> (FATCA), with Andrew Quinlan from the <a href="https://en.wikipedia.org/wiki/Center_for_Freedom_and_Prosperity" title="Center for Freedom and Prosperity">Center for Freedom and Prosperity</a> calling FATCA "the worst economic idea to come out of Congress since Smoot–Hawley".<sup id="cite_ref-39"><a href="#cite_note-39"><span>[</span>39<span>]</span></a></sup> The act received attention as <a href="https://en.wikipedia.org/wiki/Donald_Trump" title="Donald Trump">Donald Trump</a> pledged tariffs during his <a href="https://en.wikipedia.org/wiki/Donald_Trump_2024_presidential_campaign" title="Donald Trump 2024 presidential campaign">2024 campaign</a>.<sup id="cite_ref-40"><a href="#cite_note-40"><span>[</span>40<span>]</span></a></sup>
</p>

<p>Prior to 2016, the Tariff Act provided that "[a]ll goods, wares, articles, and merchandise mined, produced, or manufactured wholly or in part in any foreign country by <a href="https://en.wikipedia.org/wiki/Convict_labor" title="Convict labor">convict labor</a> or/and <a href="https://en.wikipedia.org/wiki/Forced_labor" title="Forced labor">forced labor</a> or/and indentured labor under penal sanctions shall not be entitled to entry at any of the ports of the United States" with a specific exception known as the "consumptive demand exception", which allowed forced labor-based imports of goods where United States domestic production was not sufficient to meet consumer demand.<sup id="cite_ref-41"><a href="#cite_note-41"><span>[</span>41<span>]</span></a></sup> The exception was removed under <a href="https://en.wikipedia.org/wiki/Wisconsin" title="Wisconsin">Wisconsin</a> Representative <a href="https://en.wikipedia.org/wiki/Ron_Kind" title="Ron Kind">Ron Kind</a>'s amendment bill, which was incorporated into the Trade Facilitation and Trade Enforcement Act of 2015, signed by President <a href="https://en.wikipedia.org/wiki/Barack_Obama" title="Barack Obama">Barack Obama</a> on February 24, 2016.<sup id="cite_ref-42"><a href="#cite_note-42"><span>[</span>42<span>]</span></a></sup>
</p>

<p>In the 1986 film, <i><a href="https://en.wikipedia.org/wiki/Ferris_Bueller%27s_Day_Off" title="Ferris Bueller's Day Off">Ferris Bueller's Day Off</a></i>, <a href="https://en.wikipedia.org/wiki/Ben_Stein" title="Ben Stein">Ben Stein</a>, playing a high school economics teacher, references the tariff in a lecture to his students.<sup id="cite_ref-43"><a href="#cite_note-43"><span>[</span>43<span>]</span></a></sup><sup id="cite_ref-44"><a href="#cite_note-44"><span>[</span>44<span>]</span></a></sup><sup id="cite_ref-45"><a href="#cite_note-45"><span>[</span>45<span>]</span></a></sup> It is also heavily featured in the 1989 book <i>Dave Barry Slept Here: A Sort of History of the United States</i> by <a href="https://en.wikipedia.org/wiki/Dave_Barry" title="Dave Barry">Dave Barry</a>.<sup id="cite_ref-46"><a href="#cite_note-46"><span>[</span>46<span>]</span></a></sup>
</p>

<ul><li><a href="https://en.wikipedia.org/wiki/Country-of-origin_labeling" title="Country-of-origin labeling">Country-of-origin labeling</a></li>
<li><a href="https://en.wikipedia.org/wiki/List_of_tariffs_in_the_United_States" title="List of tariffs in the United States">List of tariffs in the United States</a></li>
<li><a href="https://en.wikipedia.org/wiki/Plant_Patent_Act_of_1930" title="Plant Patent Act of 1930">Plant Patent Act of 1930</a> (originally enacted as Title III of the Smoot–Hawley Tariff Act)</li>
<li><a href="https://en.wikipedia.org/wiki/Protectionism_in_the_United_States" title="Protectionism in the United States">Protectionism in the United States</a></li>
<li><a href="https://en.wikipedia.org/wiki/Tariffs_in_United_States_history" title="Tariffs in United States history">Tariffs in United States history</a></li></ul>

<div><ol>
<li id="cite_note-1"><span><b><a href="#cite_ref-1">^</a></b></span> <span>ch. 497, 46&nbsp;<a href="https://en.wikipedia.org/wiki/United_States_Statutes_at_Large" title="United States Statutes at Large">Stat.</a>&nbsp;<a rel="nofollow" href="https://legislink.org/us/stat-46-590">590</a>, June 17, 1930, <i>see</i> <a href="https://en.wikipedia.org/wiki/Title_19_of_the_United_States_Code" title="Title 19 of the United States Code">19&nbsp;U.S.C.</a>&nbsp;<a rel="nofollow" href="https://www.law.cornell.edu/uscode/text/19/1654">§&nbsp;1654</a></span>
</li>
<li id="cite_note-FOOTNOTETaussig1931-2"><span><b><a href="#cite_ref-FOOTNOTETaussig1931_2-0">^</a></b></span> <span><a href="#CITEREFTaussig1931">Taussig 1931</a>.</span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><a rel="nofollow" href="https://krugman.blogs.nytimes.com/2010/02/16/wws-543-class-notes-21710/">WWS 543: Class notes, 2/17/10</a>, <a href="https://en.wikipedia.org/wiki/Paul_Krugman" title="Paul Krugman">Paul Krugman</a>, February 16, 2010, <a rel="nofollow" href="http://www.princeton.edu/~pkrugman/Nineteenth_century_policy.pdf">Presentation</a>, slide 4</span>
</li>
<li id="cite_note-:2-4"><span>^ <a href="#cite_ref-:2_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:2_4-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFMitchenerO'RourkeWandschneider2022">Mitchener, Kris James; O'Rourke, Kevin Hjortshøj; Wandschneider, Kirsten (2022). <a rel="nofollow" href="https://doi.org/10.1093%2Fej%2Fueac006">"The Smoot–Hawley Trade War"</a>. <i>Economic Journal</i>. <b>132</b> (647): <span>2500–</span>2533. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span title="Freely accessible"><a rel="nofollow" href="https://doi.org/10.1093%2Fej%2Fueac006">10.1093/ej/ueac006</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Economic+Journal&amp;rft.atitle=The+Smoot%E2%80%93Hawley+Trade+War&amp;rft.volume=132&amp;rft.issue=647&amp;rft.pages=%3Cspan+class%3D%22nowrap%22%3E2500-%3C%2Fspan%3E2533&amp;rft.date=2022&amp;rft_id=info%3Adoi%2F10.1093%2Fej%2Fueac006&amp;rft.aulast=Mitchener&amp;rft.aufirst=Kris+James&amp;rft.au=O%27Rourke%2C+Kevin+Hjortsh%C3%B8j&amp;rft.au=Wandschneider%2C+Kirsten&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1093%252Fej%252Fueac006&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-Eckes_1995-5"><span><b><a href="#cite_ref-Eckes_1995_5-0">^</a></b></span> <span><cite id="CITEREFEckesMarket1995">Eckes, Alfred E. Jr.; Market, O.A. (1995). <a rel="nofollow" href="https://books.google.com/books?id=Sl2FAAAAIAAJ"><i>Opening America's Market: U.S. Foreign Trade Policy Since 1776</i></a>. Business, society &amp; the state. University of North Carolina Press. pp.&nbsp;<span>100–</span>103. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-8078-2213-5" title="Special:BookSources/978-0-8078-2213-5"><bdi>978-0-8078-2213-5</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Opening+America%27s+Market%3A+U.S.+Foreign+Trade+Policy+Since+1776&amp;rft.series=Business%2C+society+%26+the+state&amp;rft.pages=%3Cspan+class%3D%22nowrap%22%3E100-%3C%2Fspan%3E103&amp;rft.pub=University+of+North+Carolina+Press&amp;rft.date=1995&amp;rft.isbn=978-0-8078-2213-5&amp;rft.aulast=Eckes&amp;rft.aufirst=Alfred+E.+Jr.&amp;rft.au=Market%2C+O.A.&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DSl2FAAAAIAAJ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-6"><span><b><a href="#cite_ref-6">^</a></b></span> <span><cite id="CITEREFWhaples1995"><a href="https://en.wikipedia.org/wiki/Robert_Whaples" title="Robert Whaples">Whaples, Robert</a> (March 1995). <a rel="nofollow" href="http://www.employees.csbsju.edu/jolson/econ315/whaples2123771.pdf">"Where Is There Consensus Among American Economic Historians? The Results of a Survey on Forty Propositions"</a> <span>(PDF)</span>. <i><a href="https://en.wikipedia.org/wiki/The_Journal_of_Economic_History" title="The Journal of Economic History">The Journal of Economic History</a></i>. <b>55</b> (1). <a href="https://en.wikipedia.org/wiki/Cambridge_University_Press" title="Cambridge University Press">Cambridge University Press</a>: 144. <a href="https://en.wikipedia.org/wiki/CiteSeerX_(identifier)" title="CiteSeerX (identifier)">CiteSeerX</a>&nbsp;<span title="Freely accessible"><a rel="nofollow" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.482.4975">10.1.1.482.4975</a></span>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1017%2FS0022050700040602">10.1017/S0022050700040602</a>. <a href="https://en.wikipedia.org/wiki/JSTOR_(identifier)" title="JSTOR (identifier)">JSTOR</a>&nbsp;<a rel="nofollow" href="https://www.jstor.org/stable/2123771">2123771</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:145691938">145691938</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Journal+of+Economic+History&amp;rft.atitle=Where+Is+There+Consensus+Among+American+Economic+Historians%3F+The+Results+of+a+Survey+on+Forty+Propositions&amp;rft.volume=55&amp;rft.issue=1&amp;rft.pages=144&amp;rft.date=1995-03&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.482.4975%23id-name%3DCiteSeerX&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A145691938%23id-name%3DS2CID&amp;rft_id=https%3A%2F%2Fwww.jstor.org%2Fstable%2F2123771%23id-name%3DJSTOR&amp;rft_id=info%3Adoi%2F10.1017%2FS0022050700040602&amp;rft.aulast=Whaples&amp;rft.aufirst=Robert&amp;rft_id=http%3A%2F%2Fwww.employees.csbsju.edu%2Fjolson%2Fecon315%2Fwhaples2123771.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-Peel-7"><span><b><a href="#cite_ref-Peel_7-0">^</a></b></span> <span><cite id="CITEREFPeel1941"><a href="https://en.wikipedia.org/wiki/Arthur_George_Villiers_Peel" title="Arthur George Villiers Peel">Peel, George</a> (1941). <i>The War: the root and remedy</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+War%3A+the+root+and+remedy&amp;rft.date=1941&amp;rft.aulast=Peel&amp;rft.aufirst=George&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-Beaudreau_1996-8"><span><b><a href="#cite_ref-Beaudreau_1996_8-0">^</a></b></span> <span><cite id="CITEREFBeaudreau1996">Beaudreau, Bernard C. (1996). <i>Mass Production, the Stock Market Crash and the Great Depression</i>. New York, Lincoln, Shanghi: Authors Choice Press.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Mass+Production%2C+the+Stock+Market+Crash+and+the+Great+Depression&amp;rft.place=New+York%2C+Lincoln%2C+Shanghi&amp;rft.pub=Authors+Choice+Press&amp;rft.date=1996&amp;rft.aulast=Beaudreau&amp;rft.aufirst=Bernard+C.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-Meril1990-9"><span><b><a href="#cite_ref-Meril1990_9-0">^</a></b></span> <span><cite id="CITEREFMerill1990">Merill, Milton (1990). <i>Reed Smoot: Apostle in Politics</i>. Logan, UT: Utah State Press. p.&nbsp;340. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-87421-127-1" title="Special:BookSources/0-87421-127-1"><bdi>0-87421-127-1</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Reed+Smoot%3A+Apostle+in+Politics&amp;rft.place=Logan%2C+UT&amp;rft.pages=340&amp;rft.pub=Utah+State+Press&amp;rft.date=1990&amp;rft.isbn=0-87421-127-1&amp;rft.aulast=Merill&amp;rft.aufirst=Milton&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-Irwin_1996-10"><span>^ <a href="#cite_ref-Irwin_1996_10-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Irwin_1996_10-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Irwin_1996_10-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFIrwinRandall_S._Kroszner1996">Irwin, Douglas A.; Randall S. Kroszner (December 1996). <a rel="nofollow" href="https://web.archive.org/web/20110718215424/http://research.chicagobooth.edu/economy/research/articles/124.pdf">"Log-Rolling and Economic Interests in the Passage of the Smoot–Hawley Tariff"</a> <span>(PDF)</span>. <i>Carnegie-Rochester Conference Series on Public Policy</i>. <b>45</b>: 6. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1016%2Fs0167-2231%2896%2900023-1">10.1016/s0167-2231(96)00023-1</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:154857884">154857884</a>. Archived from <a rel="nofollow" href="http://research.chicagobooth.edu/economy/research/articles/124.pdf">the original</a> <span>(PDF)</span> on July 18, 2011<span>. Retrieved <span>January 17,</span> 2011</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Carnegie-Rochester+Conference+Series+on+Public+Policy&amp;rft.atitle=Log-Rolling+and+Economic+Interests+in+the+Passage+of+the+Smoot%E2%80%93Hawley+Tariff&amp;rft.volume=45&amp;rft.pages=6&amp;rft.date=1996-12&amp;rft_id=info%3Adoi%2F10.1016%2Fs0167-2231%2896%2900023-1&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A154857884%23id-name%3DS2CID&amp;rft.aulast=Irwin&amp;rft.aufirst=Douglas+A.&amp;rft.au=Randall+S.+Kroszner&amp;rft_id=http%3A%2F%2Fresearch.chicagobooth.edu%2Feconomy%2Fresearch%2Farticles%2F124.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-economist-11"><span>^ <a href="#cite_ref-economist_11-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-economist_11-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-economist_11-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-economist_11-3"><sup><i><b>d</b></i></sup></a></span> <span><cite><a rel="nofollow" href="http://www.economist.com/finance/displaystory.cfm?story_id=12798595">"The Battle of Smoot–Hawley"</a>. <i><a href="https://en.wikipedia.org/wiki/The_Economist" title="The Economist">The Economist</a></i>. December 18, 2008.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Economist&amp;rft.atitle=The+Battle+of+Smoot%E2%80%93Hawley&amp;rft.date=2008-12-18&amp;rft_id=http%3A%2F%2Fwww.economist.com%2Ffinance%2Fdisplaystory.cfm%3Fstory_id%3D12798595&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-12"><span><b><a href="#cite_ref-12">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20080227204101/http://www.clubforgrowth.org/media/uploads/smooth%20hawley%20ny%20times%2005%2005%2030.pdf">"1,028 Economists Ask Hoover To Veto Pending Tariff Bill: Professors in 179 Colleges and Other Leaders Assail Rise in Rates as Harmful to Country and Sure to Bring Reprisals"</a> <span>(PDF)</span>. <i><a href="https://en.wikipedia.org/wiki/The_New_York_Times" title="The New York Times">The New York Times</a></i>. May 5, 1930. Archived from <a rel="nofollow" href="http://www.clubforgrowth.org/media/uploads/smooth%20hawley%20ny%20times%2005%2005%2030.pdf">the original</a> <span>(PDF)</span> on February 27, 2008.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=1%2C028+Economists+Ask+Hoover+To+Veto+Pending+Tariff+Bill%3A+Professors+in+179+Colleges+and+Other+Leaders+Assail+Rise+in+Rates+as+Harmful+to+Country+and+Sure+to+Bring+Reprisals&amp;rft.date=1930-05-05&amp;rft_id=http%3A%2F%2Fwww.clubforgrowth.org%2Fmedia%2Fuploads%2Fsmooth%2520hawley%2520ny%2520times%252005%252005%252030.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span>.</span>
</li>
<li id="cite_note-13"><span><b><a href="#cite_ref-13">^</a></b></span> <span><cite><a rel="nofollow" href="http://econjwatch.org/issues/volume-4-issue-3-september-2007">"Economists Against Smoot–Hawley"</a>. <i>Econ Journal Watch</i>. September 2007.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Econ+Journal+Watch&amp;rft.atitle=Economists+Against+Smoot%E2%80%93Hawley&amp;rft.date=2007-09&amp;rft_id=http%3A%2F%2Feconjwatch.org%2Fissues%2Fvolume-4-issue-3-september-2007&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-14"><span><b><a href="#cite_ref-14">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20101029201229/http://www.time.com/time/magazine/article/0,9171,960038,00.html">"Shades of Smoot–Hawley"</a>. <i><a href="https://en.wikipedia.org/wiki/Time_(magazine)" title="Time (magazine)">Time</a></i>. October 7, 1985. Archived from <a rel="nofollow" href="http://www.time.com/time/magazine/article/0,9171,960038,00.html">the original</a> on October 29, 2010.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Time&amp;rft.atitle=Shades+of+Smoot%E2%80%93Hawley&amp;rft.date=1985-10-07&amp;rft_id=http%3A%2F%2Fwww.time.com%2Ftime%2Fmagazine%2Farticle%2F0%2C9171%2C960038%2C00.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-15"><span><b><a href="#cite_ref-15">^</a></b></span> <span><cite id="CITEREFChernow1990">Chernow, Ron (1990), <a rel="nofollow" href="https://archive.org/details/houseofmorganame00cher_0/page/323"><i>The House of Morgan: An American Banking Dynasty and the Rise of Modern Finance</i></a>, New York: Atlantic Monthly Press, p.&nbsp;<a rel="nofollow" href="https://archive.org/details/houseofmorganame00cher_0/page/323">323</a>, <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-87113-338-5" title="Special:BookSources/0-87113-338-5"><bdi>0-87113-338-5</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+House+of+Morgan%3A+An+American+Banking+Dynasty+and+the+Rise+of+Modern+Finance&amp;rft.place=New+York&amp;rft.pages=323&amp;rft.pub=Atlantic+Monthly+Press&amp;rft.date=1990&amp;rft.isbn=0-87113-338-5&amp;rft.aulast=Chernow&amp;rft.aufirst=Ron&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fhouseofmorganame00cher_0%2Fpage%2F323&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span>.</span>
</li>
<li id="cite_note-Sobel_1972-16"><span>^ <a href="#cite_ref-Sobel_1972_16-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Sobel_1972_16-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFSobel1972">Sobel, Robert (1972). <a rel="nofollow" href="https://archive.org/details/ageofgiantcorpor0000sobe/page/87"><i>The Age of Giant Corporations: A Microeconomic History of American Business, 1914–1970</i></a>. Westport: Greenwood Press. pp.&nbsp;<a rel="nofollow" href="https://archive.org/details/ageofgiantcorpor0000sobe/page/87">87–88</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-8371-6404-4" title="Special:BookSources/0-8371-6404-4"><bdi>0-8371-6404-4</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Age+of+Giant+Corporations%3A+A+Microeconomic+History+of+American+Business%2C+1914%E2%80%931970&amp;rft.place=Westport&amp;rft.pages=87-88&amp;rft.pub=Greenwood+Press&amp;rft.date=1972&amp;rft.isbn=0-8371-6404-4&amp;rft.aulast=Sobel&amp;rft.aufirst=Robert&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fageofgiantcorpor0000sobe%2Fpage%2F87&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-17"><span><b><a href="#cite_ref-17">^</a></b></span> <span><cite id="CITEREFSteward2018">Steward, James B. (March 8, 2018). <a rel="nofollow" href="https://www.nytimes.com/2018/03/08/business/tariff-trump-trade-wars.html">"What History Has to Say about the 'Winners' in Trade Wars"</a>. <i>The New York Times</i>. No.&nbsp;International edition. New York<span>. Retrieved <span>November 7,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=What+History+Has+to+Say+about+the+%27Winners%27+in+Trade+Wars&amp;rft.issue=International+edition&amp;rft.date=2018-03-08&amp;rft.aulast=Steward&amp;rft.aufirst=James+B.&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2018%2F03%2F08%2Fbusiness%2Ftariff-trump-trade-wars.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-18"><span><b><a href="#cite_ref-18">^</a></b></span> <span><cite id="CITEREFMitchenerWandschneiderO'Rourke2021">Mitchener, Kris James; Wandschneider, Kirsten; O'Rourke, Kevin Hjortshøj (2021), <a rel="nofollow" href="https://www.nber.org/system/files/working_papers/w28616/w28616.pdf"><i>The Smoot–Hawley Trade War</i></a> <span>(PDF)</span>, National Bureau of Economic Research, No. w28616</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Smoot%E2%80%93Hawley+Trade+War&amp;rft.pub=National+Bureau+of+Economic+Research&amp;rft.date=2021&amp;rft.aulast=Mitchener&amp;rft.aufirst=Kris+James&amp;rft.au=Wandschneider%2C+Kirsten&amp;rft.au=O%27Rourke%2C+Kevin+Hjortsh%C3%B8j&amp;rft_id=https%3A%2F%2Fwww.nber.org%2Fsystem%2Ffiles%2Fworking_papers%2Fw28616%2Fw28616.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-19"><span><b><a href="#cite_ref-19">^</a></b></span> <span><cite id="CITEREFBrownHogendorn2000">Brown, Wilson B.; Hogendorn, Jan S. (2000). <i>International Economics: In the Age of Globalization</i>. Toronto: University of Toronto Press. p.&nbsp;246. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/1-55111-261-2" title="Special:BookSources/1-55111-261-2"><bdi>1-55111-261-2</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=International+Economics%3A+In+the+Age+of+Globalization&amp;rft.place=Toronto&amp;rft.pages=246&amp;rft.pub=University+of+Toronto+Press&amp;rft.date=2000&amp;rft.isbn=1-55111-261-2&amp;rft.aulast=Brown&amp;rft.aufirst=Wilson+B.&amp;rft.au=Hogendorn%2C+Jan+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span>.</span>
</li>
<li id="cite_note-20"><span><b><a href="#cite_ref-20">^</a></b></span> <span><cite id="CITEREFJeffreys-Jones1997">Jeffreys-Jones, Rhodri (1997). <i>Changing Differences: Women and the Shaping of American Foreign Policy, 1917–1994</i>. Rutgers University Press. p.&nbsp;48.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Changing+Differences%3A+Women+and+the+Shaping+of+American+Foreign+Policy%2C+1917%E2%80%931994&amp;rft.pages=48&amp;rft.pub=Rutgers+University+Press&amp;rft.date=1997&amp;rft.aulast=Jeffreys-Jones&amp;rft.aufirst=Rhodri&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-21"><span><b><a href="#cite_ref-21">^</a></b></span> <span><cite id="CITEREFDeSilver2018">DeSilver, Drew (March 22, 2018). <a rel="nofollow" href="https://www.pewresearch.org/fact-tank/2018/03/22/u-s-tariffs-are-among-the-lowest-in-the-world-and-in-the-nations-history/">"U.S. Tariffs are among the lowest in the world – and in the nation's history"</a>. Pew Research Center.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=U.S.+Tariffs+are+among+the+lowest+in+the+world+%E2%80%93+and+in+the+nation%27s+history&amp;rft.pub=Pew+Research+Center&amp;rft.date=2018-03-22&amp;rft.aulast=DeSilver&amp;rft.aufirst=Drew&amp;rft_id=https%3A%2F%2Fwww.pewresearch.org%2Ffact-tank%2F2018%2F03%2F22%2Fu-s-tariffs-are-among-the-lowest-in-the-world-and-in-the-nations-history%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-22"><span><b><a href="#cite_ref-22">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.census.gov/prod/www/statistical_abstract.html"><i>The Historical Statistics of the United States, Colonial Times to 1970, Bicentennial Edition</i></a>. Vol.&nbsp;Part 2. U.S. Census Bureau. p.&nbsp;888.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Historical+Statistics+of+the+United+States%2C+Colonial+Times+to+1970%2C+Bicentennial+Edition&amp;rft.pages=888&amp;rft.pub=U.S.+Census+Bureau&amp;rft_id=https%3A%2F%2Fwww.census.gov%2Fprod%2Fwww%2Fstatistical_abstract.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span> Table: Series U207-212 (Part 2 ZIP file: file named CT1970p2-08.pdf).</span>
</li>
<li id="cite_note-:0-23"><span>^ <a href="#cite_ref-:0_23-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:0_23-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFOffice_of_Analysis_and_Research_Services2017">Office of Analysis and Research Services (March 2017), <a rel="nofollow" href="https://www.usitc.gov/documents/dataweb/ave_table_1891_2016.pdf"><i>U.S. imports for consumption, duties collected, and ratio of duties to value, 1891–2016. U.S. imports for consumption under tariff preference programs, 1976–2016</i></a> <span>(PDF)</span>, U.S. International Trade Commission</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=U.S.+imports+for+consumption%2C+duties+collected%2C+and+ratio+of+duties+to+value%2C+1891%E2%80%932016.+U.S.+imports+for+consumption+under+tariff+preference+programs%2C+1976%E2%80%932016&amp;rft.pub=U.S.+International+Trade+Commission&amp;rft.date=2017-03&amp;rft.au=Office+of+Analysis+and+Research+Services&amp;rft_id=https%3A%2F%2Fwww.usitc.gov%2Fdocuments%2Fdataweb%2Fave_table_1891_2016.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-:1-24"><span>^ <a href="#cite_ref-:1_24-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:1_24-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://fraser.stlouisfed.org/title/1208"><i>Historical Statistics of the United States: Colonial Times to 1957</i></a>, 1960</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Historical+Statistics+of+the+United+States%3A+Colonial+Times+to+1957&amp;rft.date=1960&amp;rft_id=https%3A%2F%2Ffraser.stlouisfed.org%2Ftitle%2F1208&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-25"><span><b><a href="#cite_ref-25">^</a></b></span> <span>Bureau of the Census, <i>Historical Statistics</i> series F-1</span>
</li>
<li id="cite_note-26"><span><b><a href="#cite_ref-26">^</a></b></span> <span><cite id="CITEREFJones2003">Jones, Joseph Marion (2003). <a rel="nofollow" href="https://web.archive.org/web/20090312055958/http://future.state.gov/when/timeline/1921_timeline/smoot_tariff.html"><i>Smoot–Hawley Tariff</i></a>. U.S. Department of State. Garland Pub. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-8240-5367-2" title="Special:BookSources/0-8240-5367-2"><bdi>0-8240-5367-2</bdi></a>. Archived from <a rel="nofollow" href="https://future.state.gov/when/timeline/1921_timeline/smoot_tariff.html">the original</a> on March 12, 2009.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Smoot%E2%80%93Hawley+Tariff&amp;rft.series=U.S.+Department+of+State&amp;rft.pub=Garland+Pub.&amp;rft.date=2003&amp;rft.isbn=0-8240-5367-2&amp;rft.aulast=Jones&amp;rft.aufirst=Joseph+Marion&amp;rft_id=http%3A%2F%2Ffuture.state.gov%2Fwhen%2Ftimeline%2F1921_timeline%2Fsmoot_tariff.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-27"><span><b><a href="#cite_ref-27">^</a></b></span> <span><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Historical+Statistics+of+the+United+States%2C+Colonial+Times+to+1957&amp;rft.place=Washington%2C+DC&amp;rft.pages=70&amp;rft.pub=Govt.+Print.+Office&amp;rft.date=1960&amp;rft.au=U.S.+Bureau+of+the+Census&amp;rft.au=Social+Science+Research+Council&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span>.</span>
</li>
<li id="cite_note-FOOTNOTEEckes1995113-28"><span><b><a href="#cite_ref-FOOTNOTEEckes1995113_28-0">^</a></b></span> <span><a href="#CITEREFEckes1995">Eckes 1995</a>, p.&nbsp;113.</span>
</li>
<li id="cite_note-FOOTNOTEIrwin1998332–333-29"><span><b><a href="#cite_ref-FOOTNOTEIrwin1998332–333_29-0">^</a></b></span> <span><a href="#CITEREFIrwin1998">Irwin 1998</a>, pp.&nbsp;332–333.</span>
</li>
<li id="cite_note-30"><span><b><a href="#cite_ref-30">^</a></b></span> <span><cite id="CITEREFTassava2008">Tassava, Christopher (February 10, 2008). <a rel="nofollow" href="http://eh.net/encyclopedia/the-american-economy-during-world-war-ii/">"The American Economy during World War II"</a>. In Whaples, Robert (ed.). <i>EH.Net Encyclopedia</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=The+American+Economy+during+World+War+II&amp;rft.btitle=EH.Net+Encyclopedia&amp;rft.date=2008-02-10&amp;rft.aulast=Tassava&amp;rft.aufirst=Christopher&amp;rft_id=http%3A%2F%2Feh.net%2Fencyclopedia%2Fthe-american-economy-during-world-war-ii%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-31"><span><b><a href="#cite_ref-31">^</a></b></span> <span><a href="https://en.wikipedia.org/wiki/Bureau_of_Labor_Statistics" title="Bureau of Labor Statistics">Bureau of Labor Statistics</a>, <a rel="nofollow" href="http://herb.ashp.cuny.edu/items/show/1510">"Graph of U.S. Unemployment Rate, 1930–1945"</a>, <i>HERB: Resources for Teachers</i>, retrieved April 24, 2015.</span>
</li>
<li id="cite_note-32"><span><b><a href="#cite_ref-32">^</a></b></span> <span><cite id="CITEREFFriedmanSchwartz1963">Friedman, Milton; Schwartz, Anna Jacobson (1963). <i>A monetary history of the United States, 1867–1960</i>. p.&nbsp;342.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=A+monetary+history+of+the+United+States%2C+1867%E2%80%931960&amp;rft.pages=342&amp;rft.date=1963&amp;rft.aulast=Friedman&amp;rft.aufirst=Milton&amp;rft.au=Schwartz%2C+Anna+Jacobson&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-33"><span><b><a href="#cite_ref-33">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.trumanlibrary.gov/library/public-papers/248/statement-president-forthcoming-international-conference-tariffs-and">"Statement by the President on the Forthcoming International Conference on Tariffs and Trade"</a>. <i><a href="https://en.wikipedia.org/wiki/Harry_S._Truman_Library_%26_Museum" title="Harry S. Truman Library &amp; Museum">Harry S. Truman Library &amp; Museum</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Harry+S.+Truman+Library+%26+Museum&amp;rft.atitle=Statement+by+the+President+on+the+Forthcoming+International+Conference+on+Tariffs+and+Trade&amp;rft_id=https%3A%2F%2Fwww.trumanlibrary.gov%2Flibrary%2Fpublic-papers%2F248%2Fstatement-president-forthcoming-international-conference-tariffs-and&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-34"><span><b><a href="#cite_ref-34">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.wto.org/English/thewto_e/whatis_e/tif_e/fact4_e.htm">"Understand the WTO: The GATT years: from Havana to Marrakesh"</a>, <i><a href="https://en.wikipedia.org/wiki/World_Trade_Organization" title="World Trade Organization">World Trade Organization</a></i></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=World+Trade+Organization&amp;rft.atitle=Understand+the+WTO%3A+The+GATT+years%3A+from+Havana+to+Marrakesh&amp;rft_id=http%3A%2F%2Fwww.wto.org%2FEnglish%2Fthewto_e%2Fwhatis_e%2Ftif_e%2Ffact4_e.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span>.</span>
</li>
<li id="cite_note-35"><span><b><a href="#cite_ref-35">^</a></b></span> <span>Lloyd, Lewis E. <i>Tariffs: The Case for Protection</i>. The Devin-Adair Co., 1955, Appendix, Table VI, pp. 188–189</span>
</li>
<li id="cite_note-36"><span><b><a href="#cite_ref-36">^</a></b></span> <span><cite id="CITEREFBenen2009"><a href="https://en.wikipedia.org/wiki/Steve_Benen" title="Steve Benen">Benen, Steve</a> (April 30, 2009). <a rel="nofollow" href="https://washingtonmonthly.com/2009/04/30/hoot-smalley/">"<span></span>'Hoot–Smalley'<span></span>"</a>. <i><a href="https://en.wikipedia.org/wiki/Washington_Monthly" title="Washington Monthly">Washington Monthly</a></i><span>. Retrieved <span>December 10,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Washington+Monthly&amp;rft.atitle=%27Hoot%E2%80%93Smalley%27&amp;rft.date=2009-04-30&amp;rft.aulast=Benen&amp;rft.aufirst=Steve&amp;rft_id=https%3A%2F%2Fwashingtonmonthly.com%2F2009%2F04%2F30%2Fhoot-smalley%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-37"><span><b><a href="#cite_ref-37">^</a></b></span> <span><cite id="CITEREFKleefeld2009">Kleefeld, Eric (April 29, 2009). <a rel="nofollow" href="https://talkingpointsmemo.com/dc/historian-michele-bachmann-blames-fdr-s-hoot-smalley-tariffs-for-great-depression">"Historian Michele Bachmann Blames FDR's 'Hoot–Smalley' Tariffs For Great Depression"</a>. <i><a href="https://en.wikipedia.org/wiki/Talking_Points_Memo" title="Talking Points Memo">Talking Points Memo</a></i><span>. Retrieved <span>December 10,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Talking+Points+Memo&amp;rft.atitle=Historian+Michele+Bachmann+Blames+FDR%27s+%27Hoot%E2%80%93Smalley%27+Tariffs+For+Great+Depression&amp;rft.date=2009-04-29&amp;rft.aulast=Kleefeld&amp;rft.aufirst=Eric&amp;rft_id=https%3A%2F%2Ftalkingpointsmemo.com%2Fdc%2Fhistorian-michele-bachmann-blames-fdr-s-hoot-smalley-tariffs-for-great-depression&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-Yglesias_2009-38"><span><b><a href="#cite_ref-Yglesias_2009_38-0">^</a></b></span> <span><cite id="CITEREFYglesias2009"><a href="https://en.wikipedia.org/wiki/Matthew_Yglesias" title="Matthew Yglesias">Yglesias, Matthew</a> (April 29, 2009). <a rel="nofollow" href="https://web.archive.org/web/20090502184835/http://yglesias.thinkprogress.org/archives/2009/04/michelle-bachmann-embraces-ignorance-reverse-causation.php">"Michelle Bachmann Embraces Ignorance, Reverse Causation"</a>. <i><a href="https://en.wikipedia.org/wiki/ThinkProgress" title="ThinkProgress">ThinkProgress</a></i>. Archived from <a rel="nofollow" href="http://yglesias.thinkprogress.org/archives/2009/04/michelle-bachmann-embraces-ignorance-reverse-causation.php">the original</a> on May 2, 2009.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ThinkProgress&amp;rft.atitle=Michelle+Bachmann+Embraces+Ignorance%2C+Reverse+Causation&amp;rft.date=2009-04-29&amp;rft.aulast=Yglesias&amp;rft.aufirst=Matthew&amp;rft_id=http%3A%2F%2Fyglesias.thinkprogress.org%2Farchives%2F2009%2F04%2Fmichelle-bachmann-embraces-ignorance-reverse-causation.php&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-39"><span><b><a href="#cite_ref-39">^</a></b></span> <span><cite id="CITEREFJatras2013">Jatras, James George (April 23, 2013). <a rel="nofollow" href="https://web.archive.org/web/20160808053036/http://repealfatca.com/index.asp?idmenu=4&amp;idsubmenu=124&amp;title=lets-get-republican-presidential-candidates-uon-the-recordu-for-fatca-repeal">"Senator Rand Paul Introduces Bill to Repeal FATCA!"</a>. Archived from <a rel="nofollow" href="http://repealfatca.com/index.asp?idmenu=4&amp;idsubmenu=124&amp;title=lets-get-republican-presidential-candidates-uon-the-recordu-for-fatca-repeal">the original</a> on August 8, 2016.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Senator+Rand+Paul+Introduces+Bill+to+Repeal+FATCA%21&amp;rft.date=2013-04-23&amp;rft.aulast=Jatras&amp;rft.aufirst=James+George&amp;rft_id=http%3A%2F%2Frepealfatca.com%2Findex.asp%3Fidmenu%3D4%26idsubmenu%3D124%26title%3Dlets-get-republican-presidential-candidates-uon-the-recordu-for-fatca-repeal&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-40"><span><b><a href="#cite_ref-40">^</a></b></span> <span><cite><a rel="nofollow" href="https://slate.com/news-and-politics/2024/11/trump-tariffs-china-how-would-they-work-what-does-it-mean.html">"How Trump Could Make His Tariff Promises Happen—and the Potential Fallout That Awaits"</a>. <i>Slate</i>. November 26, 2024.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Slate&amp;rft.atitle=How+Trump+Could+Make+His+Tariff+Promises+Happen%E2%80%94and+the+Potential+Fallout+That+Awaits&amp;rft.date=2024-11-26&amp;rft_id=https%3A%2F%2Fslate.com%2Fnews-and-politics%2F2024%2F11%2Ftrump-tariffs-china-how-would-they-work-what-does-it-mean.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-41"><span><b><a href="#cite_ref-41">^</a></b></span> <span>Section 307 of the Tariff Act of 1930, quoted in Altschuller, S., <a rel="nofollow" href="https://www.globalbusinessandhumanrights.com/2016/02/16/u-s-congress-finally-eliminates-the-consumptive-demand-exception/">U.S. Congress Finally Eliminates the Consumptive Demand Exception</a>, <i>Global Business and Human Rights</i>, published by <a href="https://en.wikipedia.org/wiki/Foley_Hoag_LLP" title="Foley Hoag LLP">Foley Hoag LLP</a>, 16 February 2016, accessed 22 November 2020</span>
</li>
<li id="cite_note-42"><span><b><a href="#cite_ref-42">^</a></b></span> <span><a href="https://en.wikipedia.org/wiki/GovTrack.us" title="GovTrack.us">GovTrack.us</a>, <a rel="nofollow" href="https://www.govtrack.us/congress/bills/114/hr190">H.R. 1903 (114th): To amend the Tariff Act of 1930 to eliminate the consumptive demand exception to prohibition on importation of goods made with convict labor, forced labor, or indentured labor, and for other purposes</a>, accessed 22 November 2020</span>
</li>
<li id="cite_note-43"><span><b><a href="#cite_ref-43">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.imdb.com/title/tt0091042/characters/nm0825401">"Ferris Bueller's Day Off (1986)"</a>, <i>IMDb</i><span>, retrieved <span>December 3,</span> 2023</span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IMDb&amp;rft.atitle=Ferris+Bueller%27s+Day+Off+%281986%29&amp;rft_id=http%3A%2F%2Fwww.imdb.com%2Ftitle%2Ftt0091042%2Fcharacters%2Fnm0825401&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-44"><span><b><a href="#cite_ref-44">^</a></b></span> <span><cite id="CITEREFSnow2018">Snow, Kirstin (March 11, 2018). <a rel="nofollow" href="https://www.pennlive.com/opinion/2018/03/how_ferris_buellers_day_off_pr.html">"How 'Ferris Bueller's Day Off' prepared us for Trump's tariffs"</a>. <i>pennlive</i><span>. Retrieved <span>December 3,</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=pennlive&amp;rft.atitle=How+%27Ferris+Bueller%27s+Day+Off%27+prepared+us+for+Trump%27s+tariffs&amp;rft.date=2018-03-11&amp;rft.aulast=Snow&amp;rft.aufirst=Kirstin&amp;rft_id=https%3A%2F%2Fwww.pennlive.com%2Fopinion%2F2018%2F03%2Fhow_ferris_buellers_day_off_pr.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-45"><span><b><a href="#cite_ref-45">^</a></b></span> <span><cite id="CITEREFGabriel">Gabriel, Jon. <a rel="nofollow" href="https://www.azcentral.com/story/opinion/op-ed/2018/03/08/ferris-bueller-can-teach-trump-thing-2-economics/403608002/">"Gabriel: Ferris Bueller could teach Trump a thing or two about tariffs"</a>. <i>The Arizona Republic</i><span>. Retrieved <span>December 3,</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Arizona+Republic&amp;rft.atitle=Gabriel%3A+Ferris+Bueller+could+teach+Trump+a+thing+or+two+about+tariffs&amp;rft.aulast=Gabriel&amp;rft.aufirst=Jon&amp;rft_id=https%3A%2F%2Fwww.azcentral.com%2Fstory%2Fopinion%2Fop-ed%2F2018%2F03%2F08%2Fferris-bueller-can-teach-trump-thing-2-economics%2F403608002%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
<li id="cite_note-46"><span><b><a href="#cite_ref-46">^</a></b></span> <span><cite id="CITEREFBarry1989">Barry, Dave (1989). <i>Dave Barry Slept Here</i>. New York: Random House Publishing Group. pp.&nbsp;<span>112–</span>113, 123, 157. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-449-90462-8" title="Special:BookSources/0-449-90462-8"><bdi>0-449-90462-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Dave+Barry+Slept+Here&amp;rft.place=New+York&amp;rft.pages=%3Cspan+class%3D%22nowrap%22%3E112-%3C%2Fspan%3E113%2C+123%2C+157&amp;rft.pub=Random+House+Publishing+Group&amp;rft.date=1989&amp;rft.isbn=0-449-90462-8&amp;rft.aulast=Barry&amp;rft.aufirst=Dave&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></span>
</li>
</ol></div>

<div>
<ul><li><cite id="CITEREFArchibaldFeldman1998">Archibald, Robert B.; Feldman, David H. (1998), "Investment During the Great Depression: Uncertainty and the Role of the Smoot–Hawley Tariff", <i>Southern Economic Journal</i>, <b>64</b> (4): <span>857–</span>879, <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.2307%2F1061208">10.2307/1061208</a>, <a href="https://en.wikipedia.org/wiki/JSTOR_(identifier)" title="JSTOR (identifier)">JSTOR</a>&nbsp;<a rel="nofollow" href="https://www.jstor.org/stable/1061208">1061208</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Southern+Economic+Journal&amp;rft.atitle=Investment+During+the+Great+Depression%3A+Uncertainty+and+the+Role+of+the+Smoot%E2%80%93Hawley+Tariff&amp;rft.volume=64&amp;rft.issue=4&amp;rft.pages=%3Cspan+class%3D%22nowrap%22%3E857-%3C%2Fspan%3E879&amp;rft.date=1998&amp;rft_id=info%3Adoi%2F10.2307%2F1061208&amp;rft_id=https%3A%2F%2Fwww.jstor.org%2Fstable%2F1061208%23id-name%3DJSTOR&amp;rft.aulast=Archibald&amp;rft.aufirst=Robert+B.&amp;rft.au=Feldman%2C+David+H.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFCrucini1994">Crucini, Mario J. (1994), "Sources of variation in real tariff rates: The United States 1900 to 1940", <i>American Economic Review</i>, <b>84</b> (3): <span>346–</span>353, <a href="https://en.wikipedia.org/wiki/JSTOR_(identifier)" title="JSTOR (identifier)">JSTOR</a>&nbsp;<a rel="nofollow" href="https://www.jstor.org/stable/2118081">2118081</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=American+Economic+Review&amp;rft.atitle=Sources+of+variation+in+real+tariff+rates%3A+The+United+States+1900+to+1940&amp;rft.volume=84&amp;rft.issue=3&amp;rft.pages=%3Cspan+class%3D%22nowrap%22%3E346-%3C%2Fspan%3E353&amp;rft.date=1994&amp;rft_id=https%3A%2F%2Fwww.jstor.org%2Fstable%2F2118081%23id-name%3DJSTOR&amp;rft.aulast=Crucini&amp;rft.aufirst=Mario+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFCruciniKahn1996">Crucini, Mario J.; Kahn, James (1996), "Tariffs and Aggregate Economic Activity: Lessons from the Great Depression", <i>Journal of Monetary Economics</i>, <b>38</b> (3): <span>427–</span>467, <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span title="Freely accessible"><a rel="nofollow" href="https://doi.org/10.1016%2FS0304-3932%2896%2901298-6">10.1016/S0304-3932(96)01298-6</a></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Monetary+Economics&amp;rft.atitle=Tariffs+and+Aggregate+Economic+Activity%3A+Lessons+from+the+Great+Depression&amp;rft.volume=38&amp;rft.issue=3&amp;rft.pages=%3Cspan+class%3D%22nowrap%22%3E427-%3C%2Fspan%3E467&amp;rft.date=1996&amp;rft_id=info%3Adoi%2F10.1016%2FS0304-3932%2896%2901298-6&amp;rft.aulast=Crucini&amp;rft.aufirst=Mario+J.&amp;rft.au=Kahn%2C+James&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFEckes1995">Eckes, Alfred (1995), <i>Opening America's Market: U.S. Foreign Trade Policy since 1776</i>, Chapel Hill: University of North Carolina Press, <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-585-02905-9" title="Special:BookSources/0-585-02905-9"><bdi>0-585-02905-9</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Opening+America%27s+Market%3A+U.S.+Foreign+Trade+Policy+since+1776&amp;rft.place=Chapel+Hill&amp;rft.pub=University+of+North+Carolina+Press&amp;rft.date=1995&amp;rft.isbn=0-585-02905-9&amp;rft.aulast=Eckes&amp;rft.aufirst=Alfred&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFEichengreen1989"><a href="https://en.wikipedia.org/wiki/Barry_Eichengreen" title="Barry Eichengreen">Eichengreen, Barry</a> (1989), "The Political Economy of the Smoot–Hawley Tariff", <i>Research in Economic History</i>, <b>12</b>: <span>1–</span>43</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Research+in+Economic+History&amp;rft.atitle=The+Political+Economy+of+the+Smoot%E2%80%93Hawley+Tariff&amp;rft.volume=12&amp;rft.pages=%3Cspan+class%3D%22nowrap%22%3E1-%3C%2Fspan%3E43&amp;rft.date=1989&amp;rft.aulast=Eichengreen&amp;rft.aufirst=Barry&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFIrwin1998">Irwin, Douglas A. (May 1998). <a rel="nofollow" href="http://papers.nber.org/papers/w5509.pdf">"The Smoot–Hawley Tariff: A Quantitative Assessment"</a> <span>(PDF)</span>. <i>The Review of Economics and Statistics</i>. <b>80</b> (2). The MIT Press: <span>326–</span>334. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1162%2F003465398557410">10.1162/003465398557410</a>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://search.worldcat.org/issn/0034-6535">0034-6535</a>. <a href="https://en.wikipedia.org/wiki/JSTOR_(identifier)" title="JSTOR (identifier)">JSTOR</a>&nbsp;<a rel="nofollow" href="https://www.jstor.org/stable/2646642">2646642</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:57562207">57562207</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Review+of+Economics+and+Statistics&amp;rft.atitle=The+Smoot%E2%80%93Hawley+Tariff%3A+A+Quantitative+Assessment&amp;rft.volume=80&amp;rft.issue=2&amp;rft.pages=%3Cspan+class%3D%22nowrap%22%3E326-%3C%2Fspan%3E334&amp;rft.date=1998-05&amp;rft.issn=0034-6535&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A57562207%23id-name%3DS2CID&amp;rft_id=https%3A%2F%2Fwww.jstor.org%2Fstable%2F2646642%23id-name%3DJSTOR&amp;rft_id=info%3Adoi%2F10.1162%2F003465398557410&amp;rft.aulast=Irwin&amp;rft.aufirst=Douglas+A.&amp;rft_id=http%3A%2F%2Fpapers.nber.org%2Fpapers%2Fw5509.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span> Previously published as <cite id="CITEREFIrwin1996"><a rel="nofollow" href="http://www.nber.org/papers/w5509.pdf">"The Smoot–Hawley Tariff: A Quantitative Assessment"</a> <span>(PDF)</span>, <i>NBER Working Paper Series</i>, National Bureau of Economic Research, March 1996</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=NBER+Working+Paper+Series&amp;rft.atitle=The+Smoot%E2%80%93Hawley+Tariff%3A+A+Quantitative+Assessment&amp;rft.date=1996-03&amp;rft.aulast=Irwin&amp;rft.aufirst=Douglas+A.&amp;rft_id=http%3A%2F%2Fwww.nber.org%2Fpapers%2Fw5509.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFIrwin2011">Irwin, Douglas (2011), <i>Peddling Protectionism: Smoot–Hawley and the Great Depression</i>, Princeton University Press, <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-691-15032-1" title="Special:BookSources/978-0-691-15032-1"><bdi>978-0-691-15032-1</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Peddling+Protectionism%3A+Smoot%E2%80%93Hawley+and+the+Great+Depression&amp;rft.pub=Princeton+University+Press&amp;rft.date=2011&amp;rft.isbn=978-0-691-15032-1&amp;rft.aulast=Irwin&amp;rft.aufirst=Douglas&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span>; <a rel="nofollow" href="https://ciaotest.cc.columbia.edu/journals/cato/v31i3/f_0023218_19007.pdf">online book review</a></li>
<li><cite id="CITEREFKaplan1996">Kaplan, Edward S. (1996), <i>American Trade Policy: 1923–1995</i>, London: Greenwood Press, <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-313-29480-1" title="Special:BookSources/0-313-29480-1"><bdi>0-313-29480-1</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=American+Trade+Policy%3A+1923%E2%80%931995&amp;rft.place=London&amp;rft.pub=Greenwood+Press&amp;rft.date=1996&amp;rft.isbn=0-313-29480-1&amp;rft.aulast=Kaplan&amp;rft.aufirst=Edward+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFKottman1975">Kottman, Richard N. (1975), "Herbert Hoover and the Smoot–Hawley Tariff: Canada, A Case Study", <i>Journal of American History</i>, <b>62</b> (3): <span>609–</span>635, <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.2307%2F2936217">10.2307/2936217</a>, <a href="https://en.wikipedia.org/wiki/JSTOR_(identifier)" title="JSTOR (identifier)">JSTOR</a>&nbsp;<a rel="nofollow" href="https://www.jstor.org/stable/2936217">2936217</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+American+History&amp;rft.atitle=Herbert+Hoover+and+the+Smoot%E2%80%93Hawley+Tariff%3A+Canada%2C+A+Case+Study&amp;rft.volume=62&amp;rft.issue=3&amp;rft.pages=%3Cspan+class%3D%22nowrap%22%3E609-%3C%2Fspan%3E635&amp;rft.date=1975&amp;rft_id=info%3Adoi%2F10.2307%2F2936217&amp;rft_id=https%3A%2F%2Fwww.jstor.org%2Fstable%2F2936217%23id-name%3DJSTOR&amp;rft.aulast=Kottman&amp;rft.aufirst=Richard+N.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFKoyama2009">Koyama, Kumiko (2009), "The Passage of the Smoot–Hawley Tariff Act: Why Did the President Sign the Bill?", <i>Journal of Policy History</i>, <b>21</b> (2): <span>163–</span>186, <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1017%2FS0898030609090071">10.1017/S0898030609090071</a>, <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:154415038">154415038</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Policy+History&amp;rft.atitle=The+Passage+of+the+Smoot%E2%80%93Hawley+Tariff+Act%3A+Why+Did+the+President+Sign+the+Bill%3F&amp;rft.volume=21&amp;rft.issue=2&amp;rft.pages=%3Cspan+class%3D%22nowrap%22%3E163-%3C%2Fspan%3E186&amp;rft.date=2009&amp;rft_id=info%3Adoi%2F10.1017%2FS0898030609090071&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A154415038%23id-name%3DS2CID&amp;rft.aulast=Koyama&amp;rft.aufirst=Kumiko&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFMcDonaldO'BrienCallahan1997">McDonald, Judith; O'Brien, Anthony Patrick; Callahan, Colleen (1997), "Trade Wars: Canada's Reaction to the Smoot–Hawley Tariff", <i>Journal of Economic History</i>, <b>57</b> (4): <span>802–</span>826, <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1017%2FS0022050700019549">10.1017/S0022050700019549</a>, <a href="https://en.wikipedia.org/wiki/JSTOR_(identifier)" title="JSTOR (identifier)">JSTOR</a>&nbsp;<a rel="nofollow" href="https://www.jstor.org/stable/2951161">2951161</a>, <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:154380335">154380335</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Economic+History&amp;rft.atitle=Trade+Wars%3A+Canada%27s+Reaction+to+the+Smoot%E2%80%93Hawley+Tariff&amp;rft.volume=57&amp;rft.issue=4&amp;rft.pages=%3Cspan+class%3D%22nowrap%22%3E802-%3C%2Fspan%3E826&amp;rft.date=1997&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A154380335%23id-name%3DS2CID&amp;rft_id=https%3A%2F%2Fwww.jstor.org%2Fstable%2F2951161%23id-name%3DJSTOR&amp;rft_id=info%3Adoi%2F10.1017%2FS0022050700019549&amp;rft.aulast=McDonald&amp;rft.aufirst=Judith&amp;rft.au=O%27Brien%2C+Anthony+Patrick&amp;rft.au=Callahan%2C+Colleen&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFMadsen2001">Madsen, Jakob B. (2001), "Trade Barriers and the Collapse of World Trade during the Great Depression", <i>Southern Economic Journal</i>, <b>67</b> (4): <span>848–</span>868, <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.2307%2F1061574">10.2307/1061574</a>, <a href="https://en.wikipedia.org/wiki/JSTOR_(identifier)" title="JSTOR (identifier)">JSTOR</a>&nbsp;<a rel="nofollow" href="https://www.jstor.org/stable/1061574">1061574</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Southern+Economic+Journal&amp;rft.atitle=Trade+Barriers+and+the+Collapse+of+World+Trade+during+the+Great+Depression&amp;rft.volume=67&amp;rft.issue=4&amp;rft.pages=%3Cspan+class%3D%22nowrap%22%3E848-%3C%2Fspan%3E868&amp;rft.date=2001&amp;rft_id=info%3Adoi%2F10.2307%2F1061574&amp;rft_id=https%3A%2F%2Fwww.jstor.org%2Fstable%2F1061574%23id-name%3DJSTOR&amp;rft.aulast=Madsen&amp;rft.aufirst=Jakob+B.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFMerill1990">Merill, Milton (1990), <i>Reed Smoot: Apostle in Politics</i>, Logan, UT: Utah State Press, <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-87421-127-1" title="Special:BookSources/0-87421-127-1"><bdi>0-87421-127-1</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Reed+Smoot%3A+Apostle+in+Politics&amp;rft.place=Logan%2C+UT&amp;rft.pub=Utah+State+Press&amp;rft.date=1990&amp;rft.isbn=0-87421-127-1&amp;rft.aulast=Merill&amp;rft.aufirst=Milton&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li>Mitchener, Kris James, Kirsten Wandschneider, and Kevin Hjortshøj O'Rourke. "The Smoot–Hawley Trade War" (No. w28616. National Bureau of Economic Research, 2021) <a rel="nofollow" href="https://www.nber.org/system/files/working_papers/w28616/w28616.pdf">online</a>.</li>
<li><cite id="CITEREFO'Brien">O'Brien, Anthony, <a rel="nofollow" href="http://arquivo.pt/wayback/20091002093955/http://eh.net/encyclopedia/article/obrien.hawley-smoot.tariff">"Smoot–Hawley Tariff"</a>, <i>EH Encyclopedia</i>, archived from <a rel="nofollow" href="http://www.eh.net/encyclopedia/article/obrien.hawley-smoot.tariff">the original</a> on October 2, 2009</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Smoot%E2%80%93Hawley+Tariff&amp;rft.btitle=EH+Encyclopedia&amp;rft.aulast=O%27Brien&amp;rft.aufirst=Anthony&amp;rft_id=http%3A%2F%2Fwww.eh.net%2Fencyclopedia%2Farticle%2Fobrien.hawley-smoot.tariff&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFPastor1980">Pastor, Robert (1980), <a rel="nofollow" href="https://archive.org/details/congresspolitics0000past"><i>Congress and the Politics of U.S. Foreign Economic Policy, 1929–1976</i></a>, Berkeley: University of California Press, <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-520-03904-1" title="Special:BookSources/0-520-03904-1"><bdi>0-520-03904-1</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Congress+and+the+Politics+of+U.S.+Foreign+Economic+Policy%2C+1929%E2%80%931976&amp;rft.place=Berkeley&amp;rft.pub=University+of+California+Press&amp;rft.date=1980&amp;rft.isbn=0-520-03904-1&amp;rft.aulast=Pastor&amp;rft.aufirst=Robert&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fcongresspolitics0000past&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFSchattschneider1935"><a href="https://en.wikipedia.org/wiki/Elmer_Eric_Schattschneider" title="Elmer Eric Schattschneider">Schattschneider, E. E.</a> (1935), <i>Politics, Pressures and the Tariff</i>, New York: Prentice-Hall</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Politics%2C+Pressures+and+the+Tariff&amp;rft.place=New+York&amp;rft.pub=Prentice-Hall&amp;rft.date=1935&amp;rft.aulast=Schattschneider&amp;rft.aufirst=E.+E.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span> – Classic study of passage of Hawley–Smoot Tariff</li>
<li><cite id="CITEREFTaussig1931"><a href="https://en.wikipedia.org/wiki/Frank_William_Taussig" title="Frank William Taussig">Taussig, F. W.</a> (1931), <a rel="nofollow" href="https://www.mises.org/etexts/taussig.pdf"><i>The Tariff History of the United States</i></a> <span>(PDF)</span> (8th&nbsp;ed.), New York: G. P. Putnam's Sons</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Tariff+History+of+the+United+States&amp;rft.place=New+York&amp;rft.edition=8th&amp;rft.pub=G.+P.+Putnam%27s+Sons&amp;rft.date=1931&amp;rft.aulast=Taussig&amp;rft.aufirst=F.+W.&amp;rft_id=https%3A%2F%2Fwww.mises.org%2Fetexts%2Ftaussig.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFTemin1989">Temin, Peter (1989), <span title="Free registration required"><a rel="nofollow" href="https://archive.org/details/lessonsfromgreat0000temi"><i>Lessons from the Great Depression</i></a></span>, Cambridge, MA: MIT Press, <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-262-20073-2" title="Special:BookSources/0-262-20073-2"><bdi>0-262-20073-2</bdi></a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Lessons+from+the+Great+Depression&amp;rft.place=Cambridge%2C+MA&amp;rft.pub=MIT+Press&amp;rft.date=1989&amp;rft.isbn=0-262-20073-2&amp;rft.aulast=Temin&amp;rft.aufirst=Peter&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Flessonsfromgreat0000temi&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li>
<li><cite id="CITEREFTurneyNorthrup2003">Turney, Elaine C. Prange; Northrup, Cynthia Clark (2003), <i>Tariffs and Trade in U.S. History: An Encyclopedia</i></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Tariffs+and+Trade+in+U.S.+History%3A+An+Encyclopedia&amp;rft.date=2003&amp;rft.aulast=Turney&amp;rft.aufirst=Elaine+C.+Prange&amp;rft.au=Northrup%2C+Cynthia+Clark&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASmoot%E2%80%93Hawley+Tariff+Act"></span></li></ul>
</div>

<ul><li><a rel="nofollow" href="https://www.govinfo.gov/content/pkg/COMPS-8183/uslm/COMPS-8183.xml">Tariff Act of 1930</a> as amended (<a rel="nofollow" href="https://www.govinfo.gov/content/pkg/COMPS-8183/pdf/COMPS-8183.pdf">PDF</a>/<a rel="nofollow" href="https://www.govinfo.gov/app/details/COMPS-8183">details</a>) in the <a href="https://en.wikipedia.org/wiki/United_States_Government_Publishing_Office" title="United States Government Publishing Office">GPO</a> <a rel="nofollow" href="https://www.govinfo.gov/help/comps">Statute Compilations collection</a></li></ul>




<!-- 
NewPP limit report
Parsed by mw‐api‐ext.eqiad.main‐86f489c55d‐jc77s
Cached time: 20250202060409
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.631 seconds
Real time usage: 0.786 seconds
Preprocessor visited node count: 4123/1000000
Post‐expand include size: 176205/2097152 bytes
Template argument size: 4027/2097152 bytes
Highest expansion depth: 15/100
Expensive parser function count: 2/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 211637/5000000 bytes
Lua time usage: 0.390/10.000 seconds
Lua memory usage: 7516063/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  664.831      1 -total
 35.92%  238.823      1 Template:Reflist
 14.78%   98.287     26 Template:Citation
 12.03%   79.967      4 Template:Cite_journal
 11.86%   78.859      3 Template:Navbox
 11.66%   77.552      1 Template:Herbert_Hoover
  8.93%   59.346      1 Template:Short_description
  7.80%   51.876      1 Template:Infobox_U.S._legislation
  7.36%   48.951      3 Template:Sfn
  7.22%   48.016      1 Template:Infobox
-->

<!-- Saved in parser cache with key enwiki:pcache:55546:|#|:idhash:canonical and timestamp 20250202060409 and revision id 1273424176. Rendering was triggered because: api-parse
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Musk aides gain access to sensitive Treasury payment system (111 pts)]]></title>
            <link>https://www.washingtonpost.com/business/2025/02/01/elon-musk-treasury-payments-system/</link>
            <guid>42904200</guid>
            <pubDate>Sun, 02 Feb 2025 00:38:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/business/2025/02/01/elon-musk-treasury-payments-system/">https://www.washingtonpost.com/business/2025/02/01/elon-musk-treasury-payments-system/</a>, See on <a href="https://news.ycombinator.com/item?id=42904200">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/business/2025/02/01/elon-musk-treasury-payments-system/: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>