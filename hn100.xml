<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 16 May 2024 05:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Utah Locals Are Getting Cheap 10 Gbps Fiber Thanks to Local Governments (136 pts)]]></title>
            <link>https://www.techdirt.com/2024/05/15/utah-locals-are-getting-cheap-10-gbps-fiber-thanks-to-local-governments/</link>
            <guid>40373931</guid>
            <pubDate>Thu, 16 May 2024 00:22:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2024/05/15/utah-locals-are-getting-cheap-10-gbps-fiber-thanks-to-local-governments/">https://www.techdirt.com/2024/05/15/utah-locals-are-getting-cheap-10-gbps-fiber-thanks-to-local-governments/</a>, See on <a href="https://news.ycombinator.com/item?id=40373931">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-438359">


<h3>from the <i>just-build-it-yourself</i> dept</h3>

<p>Tired of being underserved and overbilled by shitty regional broadband monopolies, back in 2002 a coalition of local Utah governments formed <a href="https://www.utopiafiber.com/faqs/">UTOPIA</a> — (the Utah Telecommunication Open Infrastructure Agency). The inter-local agency collaborative venture then set about building an “open access” fiber network that allows any ISP to then come and compete on the shared network. </p>
<p>As we’ve noted over the years, regional monopolies like Qwest (now Centurylink or Lumen) didn’t much like that. They desperately tried to <a href="https://www.deseret.com/2005/7/22/19903471/utopia-responds-to-qwest-lawsuit/">sue and harass the network out of existence</a> in the early aughts, claiming the concept violated numerous local laws (it didn’t). These efforts failed, in part, because of widespread support among a public extremely tired of being ripped off by shitty monopolies. </p>
<p>Two decades later and the coalition <a href="https://www.utopiafiber.com/2024/05/08/utopia-fiber-adds-three-new-residential-internet-service-providers-to-its-open-access-network/">just announced</a> that 18 different ISPs now compete for Utah resident attention over a network that now covers 21 different Utah cities. In many instances, ISPs on the network are offering symmetrical (uncapped) gigabit fiber for as little as $45 a month (plus $30 network connection fee, so $75). Some ISPs are even offering symmetrical <strong>10 Gbps fiber for around $150 a month</strong>:</p>
<blockquote>
<p><em>“Sumo Fiber, a veteran member of the UTOPIA Open Access Marketplace, is now offering 10 Gbps symmetrical for $119, plus a $30 UTOPIA Fiber infrastructure fee, bringing the total cost to $149 per month.”</em></p>
</blockquote>
<p>It’s a collaborative hybrid that blurs the line between private companies and government, and it works. And the prices being offered here are significantly less than locals often pay in highly developed tech-centric urban hubs like New York, San Francisco, or Seattle. </p>
<p>Yet giant local ISPs like Comcast and Qwest spent decades trying to either sue this network into oblivion, or using their proxy policy orgs (like the “<a href="https://mail.communitynets.org/content/utopia-confronts-critics-continues-new-strategy">Utah Taxpayer Association</a>“) to falsely claim this effort would end in chaos and inevitable taxpayer tears. Yet miraculously UTOPIA is profitable, and for the last 15 years, every UTOPIA project has been paid for completely through subscriber revenues.</p>
<p>As other Utah cities have considered following suit, those same local monopolies have created dark money campaigns and even <a href="https://www.techdirt.com/2022/07/12/charters-running-a-fake-consumer-group-in-maine-thats-killing-community-broadband-with-the-help-of-a-democratic-advisor/">fake consumer groups</a> to <a href="https://www.techdirt.com/2024/01/18/telecom-monopolies-are-once-again-funding-covert-sleazy-local-attacks-on-community-broadband-networks/">lie to locals that such efforts are still inevitable government boondoggles</a>. Such sleazy lobbying campaigns are cheaper than actually competing or building the kind of networks these locals have spent several decades clamoring for. </p>
<p>For years, real world experience and <a href="https://www.techdirt.com/2020/12/04/benton-study-again-shows-how-open-access-broadband-networks-can-drive-competition-improve-service/">several</a> different <a href="https://transition.fcc.gov/stage/pdf/Berkman_Center_Broadband_Study_13Oct09.pdf">studies</a> and reports (including see our <a href="https://copia.is/library/just-a-click-away/">Copia study on this concept</a>) have made it clear that open access networks and policies result in faster, better, more affordable broadband access. UTOPIA is proving it at scale, but numerous other municipalities have been following suit with the help of COVID relief and infrastructure bill funding. </p>
<p>Sometimes such networks are owned by local governments. Sometimes they’re community-owned cooperatives. Sometimes they’re the extension of the local city-owned utility. Sometimes they’re built on the back of public/private partnerships.</p>
<p>According to a&nbsp;<a href="https://communitynets.org/content/community-network-map">database</a>&nbsp;of such networks tracked by the Institute For Local Self Reliance (which I have done research and writing work for), there are now 450 municipal broadband networks in the U.S. Since January 1, 2021, at least 47 new networks have come online, with dozens in the planning or pre-construction phases. And this may be an undercount given the FCC’s failure to track them all.</p>
<p>But because big monopolies (and a bunch of Libertarian think tankers with covert financial ties to those same monopolies) didn’t like the idea for ideological or financial reasons, federal and state policymakers have vacillated between demonizing the idea of municipal broadband, or banned it entirely (17 states <a href="https://broadbandnow.com/report/municipal-broadband-roadblocks#:~:text=17%20states%20currently%20have%20laws,operating%20municipal%20networks%20more%20difficult.">currently prohibit such networks</a>, and House Republicans attempted <a href="https://www.techdirt.com/2021/02/19/new-bill-tries-to-ban-community-broadband-during-pandemic/">a federal ban during COVID</a>). </p>
<p>Again, this could have all been prevented if big ISPs like AT&amp;T, Comcast, Verizon, CenturyLink and others had actually delivered the affordable, ultra-fast access Americans have demanded for decades. It could have been avoided if they’d embraced competition. It could have been avoided if they’d <a href="https://mountainstatespotlight.org/2020/12/09/frontier-has-sucked-up-millions-before-without-giving-w-va-good-broadband-theyre-about-to-get-another-chance/">properly used</a> the <a href="https://www.techdirt.com/2020/06/22/att-has-now-eliminated-41000-jobs-since-42-billion-trump-tax-cut/">untold billions</a> in taxpayer subsidies they’ve received over the last thirty years to expand access. </p>
<p>Community and municipal broadband sees widespread bipartisan support. It’s an organic, highly local, response to decades of corruption and market failure these companies enabled at every step of the way. Any impact it has on regional telecom monopolies was entirely earned on the back of decades of hubris and greed.</p>
<p>
Filed Under: <a href="https://www.techdirt.com/tag/broadband/" rel="tag">broadband</a>, <a href="https://www.techdirt.com/tag/community-broadband/" rel="tag">community broadband</a>, <a href="https://www.techdirt.com/tag/fiber/" rel="tag">fiber</a>, <a href="https://www.techdirt.com/tag/high-speed-internet/" rel="tag">high speed internet</a>, <a href="https://www.techdirt.com/tag/municipal-broadband/" rel="tag">municipal broadband</a>, <a href="https://www.techdirt.com/tag/open-access/" rel="tag">open access</a>, <a href="https://www.techdirt.com/tag/telecom/" rel="tag">telecom</a>, <a href="https://www.techdirt.com/tag/utah/" rel="tag">utah</a>, <a href="https://www.techdirt.com/tag/utopia/" rel="tag">utopia</a>
<br>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making a Postgres query 1k times faster (143 pts)]]></title>
            <link>https://mattermost.com/blog/making-a-postgres-query-1000-times-faster/</link>
            <guid>40372296</guid>
            <pubDate>Wed, 15 May 2024 21:00:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mattermost.com/blog/making-a-postgres-query-1000-times-faster/">https://mattermost.com/blog/making-a-postgres-query-1000-times-faster/</a>, See on <a href="https://news.ycombinator.com/item?id=40372296">Hacker News</a></p>
Couldn't get https://mattermost.com/blog/making-a-postgres-query-1000-times-faster/: Error: Parse Error: Header overflow]]></description>
        </item>
        <item>
            <title><![CDATA[A 'plague' comes before the fall: lessons from Roman history (104 pts)]]></title>
            <link>https://thebulletin.org/2024/05/a-plague-comes-before-the-fall-lessons-from-roman-history/</link>
            <guid>40371785</guid>
            <pubDate>Wed, 15 May 2024 20:11:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thebulletin.org/2024/05/a-plague-comes-before-the-fall-lessons-from-roman-history/">https://thebulletin.org/2024/05/a-plague-comes-before-the-fall-lessons-from-roman-history/</a>, See on <a href="https://news.ycombinator.com/item?id=40371785">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span><img width="1024" height="720" src="https://thebulletin.org/wp-content/uploads/2024/05/roman-ruins-1024x720.png" alt="Colosseum." title="roman ruins" decoding="async" loading="lazy" srcset="https://thebulletin.org/wp-content/uploads/2024/05/roman-ruins-1024x720.png 1024w, https://thebulletin.org/wp-content/uploads/2024/05/roman-ruins-300x211.png 300w, https://thebulletin.org/wp-content/uploads/2024/05/roman-ruins-768x540.png 768w, https://thebulletin.org/wp-content/uploads/2024/05/roman-ruins-1536x1080.png 1536w, https://thebulletin.org/wp-content/uploads/2024/05/roman-ruins-526x370.png 526w, https://thebulletin.org/wp-content/uploads/2024/05/roman-ruins.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px">The ruins of the Colosseum in Rome. Credit: Livioandronico2013. CC BY-SA 4.0.</span></p><div><p>The <em>Pax Romana—</em>the 200-year “<a href="https://open.spotify.com/show/2v1yIKNR3jiV94tGi0g5ot">golden age</a>” of the Roman Empire—was a marvel of diversity, connectivity, and unchallenged hegemony. By the middle of the second century AD, imperial Rome ruled territory across three different continents. Roughly one-quarter of the Earth’s population, some 60 million people, lived under Rome’s vast aegis, and the emperors of the age—most notably Marcus Aurelius—enjoyed the consent of those they governed. The Empire’s elites—witnessing the disciplined legions, widespread religiosity, cultural efflorescence, and dominant economy—likely expected their world order to endure forever.</p>
<p>In the year 166 AD, however, seemingly eternal Rome was caught completely off-guard as a deadly novel disease swept across the Eurasian landmass. It ransacked Rome’s cities for at least a decade and preceded centuries of decline. This major biological event—now known as the Antonine plague—appears to have been <a href="https://www.amazon.com/Pox-Romana-Turning-Ancient-History/dp/069121915X">the world’s first pandemic</a>.</p>
<p>Historians hotly debate its death toll—with estimates ranging from 2 percent to 35 percent mortality—and its broader social and economic effects. The disease itself remains undiagnosed. The great Greek physician Galen described its main symptoms as fever, throat ulcers, and a pustular rash. Some have suspected it was measles or smallpox, but <a href="https://www.cambridge.org/core/journals/journal-of-roman-archaeology/article/smallpoxs-antiquity-in-doubt/B15B505D959E90824B6B9DCFAB1FA124">modern analysis</a> provides reasons to doubt these as the possible culprits. Human remains from the Antonine plague period, meanwhile, have thus far failed to yield genetic evidence sufficient to identify the pathogen.</p>
<p>Although the plague did not on its own cut short Rome’s dominance, it struck an empire that was confronting multiple challenges beneath a veneer of prosperity and growth—factors that modern-day infectious disease experts might recognize as creating the ideal conditions for pandemics. Much remains unknown about the Antonine plague; in some ways, modern scholars are just as in the dark about this first pandemic as its contemporary victims. But interdisciplinary researchers, trying to understand how the plague could have helped push such a powerful empire to the breaking point, have recently been unravelling some of its mysteries.</p><div id="thebu-623384653"><p><a data-no-instant="1" href="https://thebulletin.org/magazine/2024-05/?utm_source=Website&amp;utm_medium=MobileMediumRectangle&amp;utm_campaign=Website_MayMagazine_05072024&amp;utm_content=ClimateChange_MayMagazine_05072024" rel="noopener" target="_blank" aria-label="2024 May Magazine – Mobile Medium Rectangle"><img loading="lazy" decoding="async" src="https://thebulletin.org/wp-content/uploads/2024/05/2024-May-Magazine-%E2%80%93-Mobile-Medium-Rectangle.png" alt="" srcset="https://thebulletin.org/wp-content/uploads/2024/05/2024-May-Magazine-%E2%80%93-Mobile-Medium-Rectangle.png 1250w, https://thebulletin.org/wp-content/uploads/2024/05/2024-May-Magazine-%E2%80%93-Mobile-Medium-Rectangle-300x250.png 300w, https://thebulletin.org/wp-content/uploads/2024/05/2024-May-Magazine-%E2%80%93-Mobile-Medium-Rectangle-1024x854.png 1024w, https://thebulletin.org/wp-content/uploads/2024/05/2024-May-Magazine-%E2%80%93-Mobile-Medium-Rectangle-768x640.png 768w, https://thebulletin.org/wp-content/uploads/2024/05/2024-May-Magazine-%E2%80%93-Mobile-Medium-Rectangle-444x370.png 444w" sizes="(max-width: 1250px) 100vw, 1250px" width="300" height="250"></a></p></div>
<p><strong>Probing the plague</strong>. Historians, archaeologists, and scientists have been sharing data and expertise, working together to develop histories of past pandemics—including the Antonine plague—that are surprisingly comprehensive and nuanced. Paleogenetic and paleoclimatological evidence reveal the crucial role of environmental and demographic factors in the pandemic. Insights from modern economics and sociology have improved historians’ understanding of how the institutions of the Roman Empire were affected by disease mortality. Even before the pandemic arrived, the pre-existing ecological, economic, and demographic context of mid-second century Eurasia prepared the way for the disease that would accelerate the end of Rome’s era of efflorescence.</p>
<p>Research assessing the severity of modern anthropogenic climate change, for example, has compiled a vast array of climatological data dating back to the Roman period, and well before. Such research offers historians an increasingly detailed and <a href="https://link.springer.com/chapter/10.1007/978-3-030-81103-7_13">comprehensive view</a> of the ecosystems of ancient Eurasia and Africa. The ancient Mediterranean was (and still is) polka-dotted with microclimates; meanwhile, <a href="https://www.pnas.org/doi/10.1073/pnas.1721818115">ice cores</a> from Greenland, <a href="https://www.nature.com/articles/s41561-021-00698-0">ancient tree rings</a> from northern Europe, and <a href="https://www.sciencenews.org/article/roman-empire-cold-climate-plague-archaeology">sediment cores</a> from Egypt and Italy suggest that some regions in and around Roman territory endured cooler temperatures and droughts about a decade ahead of the Antonine plague pandemic. These climatological shifts were hardly severe, nor did they affect the entire Mediterranean Basin. Many of the affected regions, however, happened to play outsized roles in supplying Roman cities with grain.</p>
<p>The annual Nile flood in Egypt, for instance, reliably nourished well-irrigated grainfields with nutrient-rich water from the Ethiopian highlands. The resulting harvests, often abundant, were stored and then shipped in massive vessels across the Mediterranean to Rome for distribution to the city’s masses. But from the 150s onward, a series of droughts near the Nile headwaters in equatorial east Africa disrupted the flood, reducing the productivity of Rome’s main breadbasket. Meanwhile, at the same time, increased storm activity in the western Mediterranean—as confirmed by sediment cores extracted from the coast of southern France—made shipping already scarce grain far riskier than in previous centuries. As a result, denizens of Rome and several other major cities, and possibly also some of Rome’s soldiers, endured greater food insecurity and malnutrition—weakening their bodies ahead of the pandemic’s arrival in the 160s.</p>
<p><strong>An interconnected, vulnerable ancient world.</strong> Historians still don’t know exactly where and when the pandemic entered Roman territory. But, again, historical circumstances conspired in favor of the novel disease.</p>
<p>An outbreak today can <a href="https://www.cell.com/trends/parasitology/fulltext/S1471-4922(18)30142-9#%20">jump continents</a> as quickly as an airplane can fly. Travel and transportation can facilitate the spread of infectious diseases. It may not be coincidental, therefore, that by the time of the Antonine plague, the Eurasian landmass was better-connected than ever before. In 166 AD, for the first time in recorded history, the imperial Han court in Luoyang, China, received visitors from the Roman Empire. Merchants from India, sub-Saharan Africa, Arabia, and Egypt rode the trade winds to ports all around the Indian Ocean. Roman soldiers, seeking to police and tax such abundant trade, ventured well outside Roman borders—as Latin inscriptions in the Farasan Islands of southern Arabia attest. In short, there were plenty of opportunities for novel diseases to cross political and geographic barriers into new populations, transforming what might have otherwise been a regional epidemic into a pandemic that spread across three different continents.</p>
<p>In the Roman Empire, an impressive transportation infrastructure—once a source of economic and military power—became a sudden liability once the pandemic breached its borders. Roman roads and ships weren’t themselves responsible, but larger movements and migrations transported the disease from city to city.</p>
<p>Because of the shifts in local climates, and resulting food insecurity, desperate and hungry rural peasants had already flooded into cities in Asia Minor (present day Turkey) and Italy. Beyond Roman borders, nomadic peoples on the Eurasian Steppe in search of food pushed against the Germanic tribes along the Danube River, sending hordes of migrants and invaders into Roman frontier provinces. Contemporary sources from the Han Empire reference a series of epidemics in several Chinese cities, as well as the army. Concerns over ever-present sickness were partly responsible for the famed <a href="https://www.britannica.com/topic/Yellow-Turbans#ref268958">Yellow Turban Rebellion</a>—a peasant rebellion that unleashed decades of civil war and instability in much of eastern China.</p>
<p>At the exact same time, tens of thousands of Roman soldiers were uprooted from their military bases and sent thousands of miles—first to fight a war on the Empire’s eastern frontier in Persia (Iran), then back into Europe to resist the surging tide of Germanic migrants. At multiple points along these journeys, soldiers could have collected the Antonine plague pathogen.</p>
<p><strong>The plague and the capital.</strong> Rome’s large legions might have sustained disease transmission for weeks, if not months, as armies passed back-and-forth through the same densely populated cities of Asia Minor and Italy that were taking on underfed refugees from the budding crisis.</p>
<p>None of these cities, however, were as packed as Rome—a cosmopolis of over one million people. In October of 166 AD, just as the pandemic reached Italy, the city held a massive triumphal parade for the legions, fresh off their victory in Persia. Perhaps 100,000 or more citizens crammed into the city center to celebrate, creating what may have been the world’s first super-spreader event.</p>
<p>Shortly following the triumph, the streets of Rome must have resembled a war zone. Bodies were so strewn about the city that Marcus Aurelius and his co-emperor imposed strict regulations on burials and tombs. They funded corpse removal. They sought out the gods for aid. At some point, perhaps after the first wave abated, the emperors commissioned statues to memorialize elite victims, while the masses were commemorated in remembrance events.</p>
<p>The ancient Romans had limited means to treat the Antonine plague, although they developed many remedies of unknown or suspect effectiveness. Elites, including the emperor Marcus Aurelius, used a concoction called “theriac”—an aged blend of exotic spices and expensive substances, mixed with a dose of opium. Others tried various smell therapies—including smelling laurel leaves. Galen claimed that fresh urine applied directly to the skin could help—the younger the urinator, the better.</p>
<p>The Antonine plague would continue to rage in the cities and military camps of the Roman Empire for at least another decade. A second wave of an undiagnosed epidemic disease hit Rome in 190 AD; if this too was part of the Antonine plague, then the pandemic lasted at least a quarter-century. However long it endured, the plague was an unprecedented test the resilience of Roman systems; Galen named it “the everlasting pestilence.”</p>
<p>Marcus may have rallied Rome during the first wave. But when the plague struck northern Italy a few years later, he abandoned his friends and soldiers to a dark winter of sickness. Officials responded to drought and high grain prices with price controls, most likely disincentivizing production and making shortages even worse. In response to plague and war deaths in the legions, Marcus recruited criminals and slaves into the military. This proved fateful when, a few years later, many of them deserted and, now well-equipped and trained, turned on the cities of the Empire, pillaging and murdering in a crime wave that stretched from Asia Minor to western Europe.</p>
<p>While it might seem like the pandemic single-handedly caused the decline and fall of the Roman Empire, it was clearly more complicated than that. The western Roman Empire would muddle along for over 200 years, but its heyday ended with the Antonine plague. The plague exposed and exacerbated pre-existing fragilities. Many Roman achievements may have been grand, but the Empire was a product of its pre-industrial context, in which weather, famine, and other factors could be destabilizing. The agricultural economy was subject to the vagaries of its ecosystem and the limitations of fledgling markets. Roman cities, for all the attention paid to aqueducts and baths, were contaminated by poor sanitation and grappled with persistent malnutrition. They may have been temporarily well-connected enough to enjoy the commodities of distant regions, but these same populations were simultaneously “immunologically naive” to pathogens from outside their immediate area. While it is no coincidence that the pandemic and the end of the <em>Pax Romana</em> occurred at the same time, exploring the connections between them underscores the interconnectedness and even interdependence of past human societies and their environmental contexts.</p>
<p>Present societies now easily mitigate much of what ailed Rome during the Antonine plague. The wonders of modern medicine—treatments, vaccines, and proven sanitation measures—render once-deadly scourges innocuous or even eradicated. A globalized society is one which collaborates and coordinates—orienting markets, scientific research, and communication channels towards responding to threats and, even better, predicting and preventing them before they occur. And yet, like the Roman Empire, the strengths of the modern world order have inbuilt weaknesses. Travel and transportation are so cheap and easy that pandemic diseases seem virtually impossible to contain.</p>
<p>The collaborative process that permeates most democratic societies nevertheless requires seemingly slow and cumbersome debate and consensus building. Yet all told, the modern world’s capacity to understand and adapt to our natural context—clumsy as it is at times—so far continues to outpace the rapidly evolving diseases that surround us. A vital part of our strategy must be to <a href="https://thebulletin.org/2023/01/deadliest-pandemics/">learn from</a> the pandemics of the past.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What’s the difference between an -ectomy, an -ostomy, and an -otomy? (1986) (132 pts)]]></title>
            <link>https://www.straightdope.com/21341781/in-medicine-what-s-the-difference-between-an-ectomy-an-ostomy-and-an-otomy</link>
            <guid>40371650</guid>
            <pubDate>Wed, 15 May 2024 20:01:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.straightdope.com/21341781/in-medicine-what-s-the-difference-between-an-ectomy-an-ostomy-and-an-otomy">https://www.straightdope.com/21341781/in-medicine-what-s-the-difference-between-an-ectomy-an-ostomy-and-an-otomy</a>, See on <a href="https://news.ycombinator.com/item?id=40371650">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <main data-module="" data-padding="none" data-width="full-constrained">

                

                
                    
                

                <div>
                                    <div data-align-center="">
            <blockquote><p>Dear Cecil: In medicine, what’s the difference between an "-ectomy,” an "-ostomy,” and an "-otomy”? My wife believes they mean “hack it off,” “bite it off,” and “pinch it till it drops off.” J.W., Chicago</p></blockquote>

            
        </div>
<div data-crop="large-2x1-notfixed" data-align-floatright="">
            
            
                
                    
                        
                            <figure><a id="image-variant-700001" name="image-variant-700001" data-cms-ai="0"></a>
        <picture data-crop="large-2x1-notfixed">
    
            
                

            
        

        
        
            
    
            <source type="image/webp" width="840" height="608" data-srcset="https://cst.brightspotcdn.com/dims4/default/c57efe7/2147483647/strip/true/crop/300x217+0+0/resize/840x608!/format/webp/quality/90/?url=https%3A%2F%2Fcdn.vox-cdn.com%2Fthumbor%2FZpDQgpBq6XDFmAHVG9pdp1X1W1U%3D%2F0x0%3A300x217%2F300x217%2Ffilters%3Afocal%28150x108%3A151x109%29%3Ano_upscale%28%29%2Fcdn.vox-cdn.com%2Fuploads%2Fchorus_asset%2Ffile%2F20535578%2F861219.gif 1x,https://cst.brightspotcdn.com/dims4/default/55bb77a/2147483647/strip/true/crop/300x217+0+0/resize/1680x1216!/format/webp/quality/90/?url=https%3A%2F%2Fcdn.vox-cdn.com%2Fthumbor%2FZpDQgpBq6XDFmAHVG9pdp1X1W1U%3D%2F0x0%3A300x217%2F300x217%2Ffilters%3Afocal%28150x108%3A151x109%29%3Ano_upscale%28%29%2Fcdn.vox-cdn.com%2Fuploads%2Fchorus_asset%2Ffile%2F20535578%2F861219.gif 2x" data-lazy-load="true" srcset="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSI2MDhweCIgd2lkdGg9Ijg0MHB4Ij48L3N2Zz4=">

    

    
        <source width="840" height="608" data-srcset="https://cst.brightspotcdn.com/dims4/default/9490ecf/2147483647/strip/true/crop/300x217+0+0/resize/840x608!/quality/90/?url=https%3A%2F%2Fcdn.vox-cdn.com%2Fthumbor%2FZpDQgpBq6XDFmAHVG9pdp1X1W1U%3D%2F0x0%3A300x217%2F300x217%2Ffilters%3Afocal%28150x108%3A151x109%29%3Ano_upscale%28%29%2Fcdn.vox-cdn.com%2Fuploads%2Fchorus_asset%2Ffile%2F20535578%2F861219.gif" data-lazy-load="true" srcset="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSI2MDhweCIgd2lkdGg9Ijg0MHB4Ij48L3N2Zz4=">

    


        
        
    <img alt="861219.gif" srcset="https://cst.brightspotcdn.com/dims4/default/9490ecf/2147483647/strip/true/crop/300x217+0+0/resize/840x608!/quality/90/?url=https%3A%2F%2Fcdn.vox-cdn.com%2Fthumbor%2FZpDQgpBq6XDFmAHVG9pdp1X1W1U%3D%2F0x0%3A300x217%2F300x217%2Ffilters%3Afocal%28150x108%3A151x109%29%3Ano_upscale%28%29%2Fcdn.vox-cdn.com%2Fuploads%2Fchorus_asset%2Ffile%2F20535578%2F861219.gif 1x,https://cst.brightspotcdn.com/dims4/default/b0693d6/2147483647/strip/true/crop/300x217+0+0/resize/1680x1216!/quality/90/?url=https%3A%2F%2Fcdn.vox-cdn.com%2Fthumbor%2FZpDQgpBq6XDFmAHVG9pdp1X1W1U%3D%2F0x0%3A300x217%2F300x217%2Ffilters%3Afocal%28150x108%3A151x109%29%3Ano_upscale%28%29%2Fcdn.vox-cdn.com%2Fuploads%2Fchorus_asset%2Ffile%2F20535578%2F861219.gif 2x" width="840" height="608" data-src="https://cst.brightspotcdn.com/dims4/default/9490ecf/2147483647/strip/true/crop/300x217+0+0/resize/840x608!/quality/90/?url=https%3A%2F%2Fcdn.vox-cdn.com%2Fthumbor%2FZpDQgpBq6XDFmAHVG9pdp1X1W1U%3D%2F0x0%3A300x217%2F300x217%2Ffilters%3Afocal%28150x108%3A151x109%29%3Ano_upscale%28%29%2Fcdn.vox-cdn.com%2Fuploads%2Fchorus_asset%2Ffile%2F20535578%2F861219.gif" data-lazy-load="true" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIgaGVpZ2h0PSI2MDhweCIgd2lkdGg9Ijg0MHB4Ij48L3N2Zz4=">

</picture>

    

    
        <div><p>Illustration by Slug Signorino</p></div>
    
</figure>

                        
                    
                
            
        </div><p>Cecil replies:</p><p>Very funny, J.W., and actually not all that far off the mark. Turning to <i>Taber’s Cyclopedic Medical Dictionary,</i> which for an old deve like me is a constant garden of delight, we learn the following:</p><ul><li>An “-ectomy” is the cutting out of something, as in “tonsillectomy.” In other words, hacking it off. This may account for lingering male squeamishness about another well-known operation, the vasectomy. (In reality, of course, only a tiny portion of the vas deferens is removed.)</li><li>An “-ostomy” (actually, “-stomy”) involves cutting a hole in something, or more precisely, furnishing it with a mouth or outlet, as in “colostomy,” in which an opening is cut into the colon to create an artificial anus. (Seems like a waste, considering how many real ones there are already.)</li><li>Finally, there’s “-otomy,” (or “-tomy”), which means to slice it up, i.e., an operation in which cutting is involved. Thus we can distinguish a lobectomy, in which a lobe, typically of the brain, is removed, from a lobotomy, in which they merely jab an ice pick in there and chop things up.</li></ul><p>I’m not kidding, either. You might want to read an engrossing volume entitled <i>Great and Desperate Cures: The Rise and Decline of Psychosurgery and Other Radical Treatments for Mental Illness,</i> by Elliott Valenstein (1986). Valenstein quotes a letter written in the mid-1940s by one prominent lobotomist, Walter Freeman:</p><div data-align-center="">
            <blockquote><p>I have also been trying out a sort of half-way stage between electroshock and prefrontal lobotomy [to treat mental patients]. … This consists of knocking them out with a shock and while they are under the ‘anesthetic’ thrusting an ice pick up between the eyeball and the eyelid through the roof of the orbit [the bony cavity that contains the eye] actually into the frontal lobe of the brain and making the lateral cut by swinging the thing from side to side. I have done two patients on both sides and another on one side without running into any complications, except a very black eye in one case. There may be trouble later on but it seemed fairly easy, although definitely a disagreeable thing to watch. It remains to be seen how these cases hold up, but so far they have shown considerable relief of their symptoms, and only some of the minor behavior difficulties that follow lobotomy. [That is, prefrontal lobotomy, which typically involved boring holes through the front of the skull. The ice pick operation is called a transorbital lobotomy.] They can even get up and go home within an hour or so. If this works out it will be a great advance for people who are too bad for shock but not bad enough for surgery.</p></blockquote>

            
        </div>
<p>Freeman went around the country in the late 1940s demonstrating this technique in mental hospitals. These exhibitions reportedly went well for the most part, except on those occasions when the patient bled too much or the ice pick broke off within the orbit or inside the skull. To remedy this problem, the ice pick was later replaced with a sturdier instrument and an ordinary carpenter’s hammer was used to drive it into the brain.</p><p>The first lobotomy in the United States took place on September 14, 1936. By August 15, 1949, the procedure had been performed 10,706 times. In the mid-1950s the popularity of the operation waned due to the availability of psychotropic drugs, which offered similar benefits without the trauma. One hopes today the practice is extinct, but you never know.</p><p>My point in telling this story is that you’re right to regard -otomies, -ectomies and so on with some skepticism. The majority of medical professionals performing such techniques help their patients, but a few are just mopes with icepicks. The challenge is telling the two apart.</p><p>Cecil Adams</p><p>Send questions to Cecil via <a href="mailto:cecil@straightdope.com" target="_blank" data-cms-ai="0">cecil@straightdope.com.</a><br></p></div>

                

                
                    
                

                
            </main>

        
            
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New exponent functions that make SiLU and SoftMax 2x faster, at full accuracy (256 pts)]]></title>
            <link>https://github.com/ggerganov/llama.cpp/pull/7154</link>
            <guid>40371612</guid>
            <pubDate>Wed, 15 May 2024 19:57:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ggerganov/llama.cpp/pull/7154">https://github.com/ggerganov/llama.cpp/pull/7154</a>, See on <a href="https://news.ycombinator.com/item?id=40371612">Hacker News</a></p>
<div id="readability-page-1" class="page"><div disabled="" sortable="">
          
<p dir="auto">📈 <strong>llama.cpp server</strong> for <em>bench-server-baseline</em> on <em>Standard_NC4as_T4_v3</em> for <code>phi-2</code>-<code>q4_0</code>: <strong>543 iterations</strong> 🚀</p>

<details>
<summary>Expand details for performance related PR only</summary>
<ul dir="auto">
<li>Concurrent users: 8, duration: 10m</li>
<li>HTTP request          : avg=8626.19ms        p(95)=21696.44ms fails=, finish reason: stop=474 truncated=69</li>
<li>Prompt processing (pp): avg=94.59tk/s p(95)=412.43tk/s</li>
<li>Token generation  (tg): avg=33.43tk/s p(95)=48.33tk/s</li>
<li>ggml-org/models/phi-2/ggml-model-q4_0.gguf parallel=8 ctx-size=16384 ngl=33 batch-size=2048 ubatch-size=256 pp=1024 pp+tg=2048 branch=expf commit=d7359a389c236193edac1c8761e6ac98844654f3</li>
</ul>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/db33b06dd0cfe99d55bf162b4fee930601203d12bb1550d983bb5cb1ebb5c54c/68747470733a2f2f692e696d6775722e636f6d2f51317462364a662e6a706567"><img width="100%" height="100%" src="https://camo.githubusercontent.com/db33b06dd0cfe99d55bf162b4fee930601203d12bb1550d983bb5cb1ebb5c54c/68747470733a2f2f692e696d6775722e636f6d2f51317462364a662e6a706567" alt="prompt_tokens_seconds" data-canonical-src="https://i.imgur.com/Q1tb6Jf.jpeg"></a>
</p><details>
<summary>More</summary>
<section data-identity="5ec07373-0b36-431e-8ec5-bb63a70b2153" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;---\nconfig:\n    xyChart:\n        titleFontSize: 12\n        width: 900\n        height: 600\n    themeVariables:\n        xyChart:\n            titleColor: \&quot;#000000\&quot;\n---\nxychart-beta\n    title \&quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3\n duration=10m 543 iterations\&quot;\n    y-axis \&quot;llamacpp:prompt_tokens_seconds\&quot;\n    x-axis \&quot;llamacpp:prompt_tokens_seconds\&quot; 1715376005 --&amp;gt; 1715376631\n    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 676.15, 676.15, 676.15, 676.15, 676.15, 693.38, 693.38, 693.38, 693.38, 693.38, 686.03, 686.03, 686.03, 686.03, 686.03, 716.71, 716.71, 716.71, 716.71, 716.71, 787.67, 787.67, 787.67, 787.67, 787.67, 798.67, 798.67, 798.67, 798.67, 798.67, 798.41, 798.41, 798.41, 798.41, 798.41, 816.18, 816.18, 816.18, 816.18, 816.18, 816.66, 816.66, 816.66, 816.66, 816.66, 826.24, 826.24, 826.24, 826.24, 826.24, 827.91, 827.91, 827.91, 827.91, 827.91, 839.83, 839.83, 839.83, 839.83, 839.83, 845.37, 845.37, 845.37, 845.37, 845.37, 891.54, 891.54, 891.54, 891.54, 891.54, 896.52, 896.52, 896.52, 896.52, 896.52, 898.39, 898.39, 898.39, 898.39, 898.39, 896.16, 896.16, 896.16, 896.16, 896.16, 909.86, 909.86, 909.86, 909.86, 909.86, 901.74, 901.74, 901.74, 901.74, 901.74, 898.93, 898.93, 898.93, 898.93, 898.93, 900.17, 900.17, 900.17, 900.17, 900.17, 901.19, 901.19, 901.19, 901.19, 901.19, 901.37, 901.37, 901.37, 901.37, 901.37, 914.57, 914.57, 914.57, 914.57, 914.57, 913.27, 913.27, 913.27, 913.27, 913.27, 914.12, 914.12, 914.12, 914.12, 914.12, 884.7, 884.7, 884.7, 884.7, 884.7, 880.58, 880.58, 880.58, 880.58, 880.58, 874.62, 874.62, 874.62, 874.62, 874.62, 874.44, 874.44, 874.44, 874.44, 874.44, 878.93, 878.93, 878.93, 878.93, 878.93, 876.59, 876.59, 876.59, 876.59, 876.59, 879.89, 879.89, 879.89, 879.89, 879.89, 889.29, 889.29, 889.29, 889.29, 889.29, 896.06, 896.06, 896.06, 896.06, 896.06, 895.27, 895.27, 895.27, 895.27, 895.27, 898.07, 898.07, 898.07, 898.07, 898.07, 895.61, 895.61, 895.61, 895.61, 895.61, 898.03, 898.03, 898.03, 898.03, 898.03, 900.02, 900.02, 900.02, 900.02, 900.02, 903.55, 903.55, 903.55, 903.55, 903.55, 912.38, 912.38, 912.38, 912.38, 912.38, 913.02, 913.02, 913.02, 913.02, 913.02, 909.18, 909.18, 909.18, 909.18, 909.18, 908.34, 908.34, 908.34, 908.34, 908.34, 904.61, 904.61, 904.61, 904.61, 904.61, 904.91, 904.91, 904.91, 904.91, 904.91, 909.01, 909.01, 909.01, 909.01, 909.01, 908.42, 908.42, 908.42, 908.42, 908.42, 913.16, 913.16, 913.16, 913.16, 913.16, 912.15, 912.15, 912.15, 912.15, 912.15, 914.4, 914.4, 914.4, 914.4, 914.4, 917.57, 917.57, 917.57, 917.57, 917.57, 915.58, 915.58, 915.58, 915.58, 915.58, 920.75, 920.75, 920.75, 920.75, 920.75, 919.24, 919.24, 919.24, 919.24, 919.24, 920.07, 920.07, 920.07, 920.07, 920.07, 918.79, 918.79, 918.79, 918.79, 918.79, 917.24, 917.24, 917.24, 917.24, 917.24, 918.44, 918.44, 918.44, 918.44, 918.44, 918.61, 918.61, 918.61, 918.61]\n                    \n&quot;}" data-plain="---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: &quot;#000000&quot;
---
xychart-beta
    title &quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations&quot;
    y-axis &quot;llamacpp:prompt_tokens_seconds&quot;
    x-axis &quot;llamacpp:prompt_tokens_seconds&quot; 1715376005 --> 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 676.15, 676.15, 676.15, 676.15, 676.15, 693.38, 693.38, 693.38, 693.38, 693.38, 686.03, 686.03, 686.03, 686.03, 686.03, 716.71, 716.71, 716.71, 716.71, 716.71, 787.67, 787.67, 787.67, 787.67, 787.67, 798.67, 798.67, 798.67, 798.67, 798.67, 798.41, 798.41, 798.41, 798.41, 798.41, 816.18, 816.18, 816.18, 816.18, 816.18, 816.66, 816.66, 816.66, 816.66, 816.66, 826.24, 826.24, 826.24, 826.24, 826.24, 827.91, 827.91, 827.91, 827.91, 827.91, 839.83, 839.83, 839.83, 839.83, 839.83, 845.37, 845.37, 845.37, 845.37, 845.37, 891.54, 891.54, 891.54, 891.54, 891.54, 896.52, 896.52, 896.52, 896.52, 896.52, 898.39, 898.39, 898.39, 898.39, 898.39, 896.16, 896.16, 896.16, 896.16, 896.16, 909.86, 909.86, 909.86, 909.86, 909.86, 901.74, 901.74, 901.74, 901.74, 901.74, 898.93, 898.93, 898.93, 898.93, 898.93, 900.17, 900.17, 900.17, 900.17, 900.17, 901.19, 901.19, 901.19, 901.19, 901.19, 901.37, 901.37, 901.37, 901.37, 901.37, 914.57, 914.57, 914.57, 914.57, 914.57, 913.27, 913.27, 913.27, 913.27, 913.27, 914.12, 914.12, 914.12, 914.12, 914.12, 884.7, 884.7, 884.7, 884.7, 884.7, 880.58, 880.58, 880.58, 880.58, 880.58, 874.62, 874.62, 874.62, 874.62, 874.62, 874.44, 874.44, 874.44, 874.44, 874.44, 878.93, 878.93, 878.93, 878.93, 878.93, 876.59, 876.59, 876.59, 876.59, 876.59, 879.89, 879.89, 879.89, 879.89, 879.89, 889.29, 889.29, 889.29, 889.29, 889.29, 896.06, 896.06, 896.06, 896.06, 896.06, 895.27, 895.27, 895.27, 895.27, 895.27, 898.07, 898.07, 898.07, 898.07, 898.07, 895.61, 895.61, 895.61, 895.61, 895.61, 898.03, 898.03, 898.03, 898.03, 898.03, 900.02, 900.02, 900.02, 900.02, 900.02, 903.55, 903.55, 903.55, 903.55, 903.55, 912.38, 912.38, 912.38, 912.38, 912.38, 913.02, 913.02, 913.02, 913.02, 913.02, 909.18, 909.18, 909.18, 909.18, 909.18, 908.34, 908.34, 908.34, 908.34, 908.34, 904.61, 904.61, 904.61, 904.61, 904.61, 904.91, 904.91, 904.91, 904.91, 904.91, 909.01, 909.01, 909.01, 909.01, 909.01, 908.42, 908.42, 908.42, 908.42, 908.42, 913.16, 913.16, 913.16, 913.16, 913.16, 912.15, 912.15, 912.15, 912.15, 912.15, 914.4, 914.4, 914.4, 914.4, 914.4, 917.57, 917.57, 917.57, 917.57, 917.57, 915.58, 915.58, 915.58, 915.58, 915.58, 920.75, 920.75, 920.75, 920.75, 920.75, 919.24, 919.24, 919.24, 919.24, 919.24, 920.07, 920.07, 920.07, 920.07, 920.07, 918.79, 918.79, 918.79, 918.79, 918.79, 917.24, 917.24, 917.24, 917.24, 917.24, 918.44, 918.44, 918.44, 918.44, 918.44, 918.61, 918.61, 918.61, 918.61]
                    
">
      <pre lang="mermaid" aria-label="Raw mermaid code">---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: "#000000"
---
xychart-beta
    title "llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations"
    y-axis "llamacpp:prompt_tokens_seconds"
    x-axis "llamacpp:prompt_tokens_seconds" 1715376005 --&gt; 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 676.15, 676.15, 676.15, 676.15, 676.15, 693.38, 693.38, 693.38, 693.38, 693.38, 686.03, 686.03, 686.03, 686.03, 686.03, 716.71, 716.71, 716.71, 716.71, 716.71, 787.67, 787.67, 787.67, 787.67, 787.67, 798.67, 798.67, 798.67, 798.67, 798.67, 798.41, 798.41, 798.41, 798.41, 798.41, 816.18, 816.18, 816.18, 816.18, 816.18, 816.66, 816.66, 816.66, 816.66, 816.66, 826.24, 826.24, 826.24, 826.24, 826.24, 827.91, 827.91, 827.91, 827.91, 827.91, 839.83, 839.83, 839.83, 839.83, 839.83, 845.37, 845.37, 845.37, 845.37, 845.37, 891.54, 891.54, 891.54, 891.54, 891.54, 896.52, 896.52, 896.52, 896.52, 896.52, 898.39, 898.39, 898.39, 898.39, 898.39, 896.16, 896.16, 896.16, 896.16, 896.16, 909.86, 909.86, 909.86, 909.86, 909.86, 901.74, 901.74, 901.74, 901.74, 901.74, 898.93, 898.93, 898.93, 898.93, 898.93, 900.17, 900.17, 900.17, 900.17, 900.17, 901.19, 901.19, 901.19, 901.19, 901.19, 901.37, 901.37, 901.37, 901.37, 901.37, 914.57, 914.57, 914.57, 914.57, 914.57, 913.27, 913.27, 913.27, 913.27, 913.27, 914.12, 914.12, 914.12, 914.12, 914.12, 884.7, 884.7, 884.7, 884.7, 884.7, 880.58, 880.58, 880.58, 880.58, 880.58, 874.62, 874.62, 874.62, 874.62, 874.62, 874.44, 874.44, 874.44, 874.44, 874.44, 878.93, 878.93, 878.93, 878.93, 878.93, 876.59, 876.59, 876.59, 876.59, 876.59, 879.89, 879.89, 879.89, 879.89, 879.89, 889.29, 889.29, 889.29, 889.29, 889.29, 896.06, 896.06, 896.06, 896.06, 896.06, 895.27, 895.27, 895.27, 895.27, 895.27, 898.07, 898.07, 898.07, 898.07, 898.07, 895.61, 895.61, 895.61, 895.61, 895.61, 898.03, 898.03, 898.03, 898.03, 898.03, 900.02, 900.02, 900.02, 900.02, 900.02, 903.55, 903.55, 903.55, 903.55, 903.55, 912.38, 912.38, 912.38, 912.38, 912.38, 913.02, 913.02, 913.02, 913.02, 913.02, 909.18, 909.18, 909.18, 909.18, 909.18, 908.34, 908.34, 908.34, 908.34, 908.34, 904.61, 904.61, 904.61, 904.61, 904.61, 904.91, 904.91, 904.91, 904.91, 904.91, 909.01, 909.01, 909.01, 909.01, 909.01, 908.42, 908.42, 908.42, 908.42, 908.42, 913.16, 913.16, 913.16, 913.16, 913.16, 912.15, 912.15, 912.15, 912.15, 912.15, 914.4, 914.4, 914.4, 914.4, 914.4, 917.57, 917.57, 917.57, 917.57, 917.57, 915.58, 915.58, 915.58, 915.58, 915.58, 920.75, 920.75, 920.75, 920.75, 920.75, 919.24, 919.24, 919.24, 919.24, 919.24, 920.07, 920.07, 920.07, 920.07, 920.07, 918.79, 918.79, 918.79, 918.79, 918.79, 917.24, 917.24, 917.24, 917.24, 917.24, 918.44, 918.44, 918.44, 918.44, 918.44, 918.61, 918.61, 918.61, 918.61]
                    
</pre>
    </div>
  <span role="presentation">
    <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="16" height="16" viewBox="0 0 16 16" fill="none" data-view-component="true">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>
  </span>
</section>

</details>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/52c5e5809cf979690fcb6f4cd9dd7a4ee43655b91e2bf1d56d07c2091ec26711/68747470733a2f2f692e696d6775722e636f6d2f6a355857356f6c2e6a706567"><img width="100%" height="100%" src="https://camo.githubusercontent.com/52c5e5809cf979690fcb6f4cd9dd7a4ee43655b91e2bf1d56d07c2091ec26711/68747470733a2f2f692e696d6775722e636f6d2f6a355857356f6c2e6a706567" alt="predicted_tokens_seconds" data-canonical-src="https://i.imgur.com/j5XW5ol.jpeg"></a>
<details>
    <summary>More</summary>
<section data-identity="95c07a72-b7e4-4a9e-9a0d-e0cea47fd8ec" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;---\nconfig:\n    xyChart:\n        titleFontSize: 12\n        width: 900\n        height: 600\n    themeVariables:\n        xyChart:\n            titleColor: \&quot;#000000\&quot;\n---\nxychart-beta\n    title \&quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3\n duration=10m 543 iterations\&quot;\n    y-axis \&quot;llamacpp:predicted_tokens_seconds\&quot;\n    x-axis \&quot;llamacpp:predicted_tokens_seconds\&quot; 1715376005 --&amp;gt; 1715376631\n    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.33, 41.33, 41.33, 41.33, 41.33, 35.68, 35.68, 35.68, 35.68, 35.68, 29.47, 29.47, 29.47, 29.47, 29.47, 28.84, 28.84, 28.84, 28.84, 28.84, 30.64, 30.64, 30.64, 30.64, 30.64, 31.13, 31.13, 31.13, 31.13, 31.13, 32.39, 32.39, 32.39, 32.39, 32.39, 33.65, 33.65, 33.65, 33.65, 33.65, 33.61, 33.61, 33.61, 33.61, 33.61, 33.73, 33.73, 33.73, 33.73, 33.73, 33.4, 33.4, 33.4, 33.4, 33.4, 33.78, 33.78, 33.78, 33.78, 33.78, 33.62, 33.62, 33.62, 33.62, 33.62, 32.91, 32.91, 32.91, 32.91, 32.91, 32.27, 32.27, 32.27, 32.27, 32.27, 32.39, 32.39, 32.39, 32.39, 32.39, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.07, 32.07, 32.07, 32.07, 32.07, 31.93, 31.93, 31.93, 31.93, 31.93, 31.67, 31.67, 31.67, 31.67, 31.67, 31.58, 31.58, 31.58, 31.58, 31.58, 31.79, 31.79, 31.79, 31.79, 31.79, 31.57, 31.57, 31.57, 31.57, 31.57, 31.78, 31.78, 31.78, 31.78, 31.78, 32.01, 32.01, 32.01, 32.01, 32.01, 32.02, 32.02, 32.02, 32.02, 32.02, 31.52, 31.52, 31.52, 31.52, 31.52, 31.35, 31.35, 31.35, 31.35, 31.35, 31.45, 31.45, 31.45, 31.45, 31.45, 31.65, 31.65, 31.65, 31.65, 31.65, 31.8, 31.8, 31.8, 31.8, 31.8, 32.01, 32.01, 32.01, 32.01, 32.01, 32.12, 32.12, 32.12, 32.12, 32.12, 32.05, 32.05, 32.05, 32.05, 32.05, 31.82, 31.82, 31.82, 31.82, 31.82, 31.67, 31.67, 31.67, 31.67, 31.67, 31.73, 31.73, 31.73, 31.73, 31.73, 31.87, 31.87, 31.87, 31.87, 31.87, 31.99, 31.99, 31.99, 31.99, 31.99, 32.1, 32.1, 32.1, 32.1, 32.1, 32.02, 32.02, 32.02, 32.02, 32.02, 31.97, 31.97, 31.97, 31.97, 31.97, 31.31, 31.31, 31.31, 31.31, 31.31, 30.76, 30.76, 30.76, 30.76, 30.76, 30.0, 30.0, 30.0, 30.0, 30.0, 29.71, 29.71, 29.71, 29.71, 29.71, 29.65, 29.65, 29.65, 29.65, 29.65, 29.82, 29.82, 29.82, 29.82, 29.82, 29.85, 29.85, 29.85, 29.85, 29.85, 29.95, 29.95, 29.95, 29.95, 29.95, 29.98, 29.98, 29.98, 29.98, 29.98, 30.01, 30.01, 30.01, 30.01, 30.01, 29.85, 29.85, 29.85, 29.85, 29.85, 29.78, 29.78, 29.78, 29.78, 29.78, 29.74, 29.74, 29.74, 29.74, 29.74, 29.88, 29.88, 29.88, 29.88, 29.88, 30.01, 30.01, 30.01, 30.01, 30.01, 30.1, 30.1, 30.1, 30.1, 30.1, 30.18, 30.18, 30.18, 30.18, 30.18, 30.28, 30.28, 30.28, 30.28]\n                    \n&quot;}" data-plain="---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: &quot;#000000&quot;
---
xychart-beta
    title &quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations&quot;
    y-axis &quot;llamacpp:predicted_tokens_seconds&quot;
    x-axis &quot;llamacpp:predicted_tokens_seconds&quot; 1715376005 --> 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.33, 41.33, 41.33, 41.33, 41.33, 35.68, 35.68, 35.68, 35.68, 35.68, 29.47, 29.47, 29.47, 29.47, 29.47, 28.84, 28.84, 28.84, 28.84, 28.84, 30.64, 30.64, 30.64, 30.64, 30.64, 31.13, 31.13, 31.13, 31.13, 31.13, 32.39, 32.39, 32.39, 32.39, 32.39, 33.65, 33.65, 33.65, 33.65, 33.65, 33.61, 33.61, 33.61, 33.61, 33.61, 33.73, 33.73, 33.73, 33.73, 33.73, 33.4, 33.4, 33.4, 33.4, 33.4, 33.78, 33.78, 33.78, 33.78, 33.78, 33.62, 33.62, 33.62, 33.62, 33.62, 32.91, 32.91, 32.91, 32.91, 32.91, 32.27, 32.27, 32.27, 32.27, 32.27, 32.39, 32.39, 32.39, 32.39, 32.39, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.07, 32.07, 32.07, 32.07, 32.07, 31.93, 31.93, 31.93, 31.93, 31.93, 31.67, 31.67, 31.67, 31.67, 31.67, 31.58, 31.58, 31.58, 31.58, 31.58, 31.79, 31.79, 31.79, 31.79, 31.79, 31.57, 31.57, 31.57, 31.57, 31.57, 31.78, 31.78, 31.78, 31.78, 31.78, 32.01, 32.01, 32.01, 32.01, 32.01, 32.02, 32.02, 32.02, 32.02, 32.02, 31.52, 31.52, 31.52, 31.52, 31.52, 31.35, 31.35, 31.35, 31.35, 31.35, 31.45, 31.45, 31.45, 31.45, 31.45, 31.65, 31.65, 31.65, 31.65, 31.65, 31.8, 31.8, 31.8, 31.8, 31.8, 32.01, 32.01, 32.01, 32.01, 32.01, 32.12, 32.12, 32.12, 32.12, 32.12, 32.05, 32.05, 32.05, 32.05, 32.05, 31.82, 31.82, 31.82, 31.82, 31.82, 31.67, 31.67, 31.67, 31.67, 31.67, 31.73, 31.73, 31.73, 31.73, 31.73, 31.87, 31.87, 31.87, 31.87, 31.87, 31.99, 31.99, 31.99, 31.99, 31.99, 32.1, 32.1, 32.1, 32.1, 32.1, 32.02, 32.02, 32.02, 32.02, 32.02, 31.97, 31.97, 31.97, 31.97, 31.97, 31.31, 31.31, 31.31, 31.31, 31.31, 30.76, 30.76, 30.76, 30.76, 30.76, 30.0, 30.0, 30.0, 30.0, 30.0, 29.71, 29.71, 29.71, 29.71, 29.71, 29.65, 29.65, 29.65, 29.65, 29.65, 29.82, 29.82, 29.82, 29.82, 29.82, 29.85, 29.85, 29.85, 29.85, 29.85, 29.95, 29.95, 29.95, 29.95, 29.95, 29.98, 29.98, 29.98, 29.98, 29.98, 30.01, 30.01, 30.01, 30.01, 30.01, 29.85, 29.85, 29.85, 29.85, 29.85, 29.78, 29.78, 29.78, 29.78, 29.78, 29.74, 29.74, 29.74, 29.74, 29.74, 29.88, 29.88, 29.88, 29.88, 29.88, 30.01, 30.01, 30.01, 30.01, 30.01, 30.1, 30.1, 30.1, 30.1, 30.1, 30.18, 30.18, 30.18, 30.18, 30.18, 30.28, 30.28, 30.28, 30.28]
                    
">
      <pre lang="mermaid" aria-label="Raw mermaid code">---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: "#000000"
---
xychart-beta
    title "llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations"
    y-axis "llamacpp:predicted_tokens_seconds"
    x-axis "llamacpp:predicted_tokens_seconds" 1715376005 --&gt; 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 41.33, 41.33, 41.33, 41.33, 41.33, 35.68, 35.68, 35.68, 35.68, 35.68, 29.47, 29.47, 29.47, 29.47, 29.47, 28.84, 28.84, 28.84, 28.84, 28.84, 30.64, 30.64, 30.64, 30.64, 30.64, 31.13, 31.13, 31.13, 31.13, 31.13, 32.39, 32.39, 32.39, 32.39, 32.39, 33.65, 33.65, 33.65, 33.65, 33.65, 33.61, 33.61, 33.61, 33.61, 33.61, 33.73, 33.73, 33.73, 33.73, 33.73, 33.4, 33.4, 33.4, 33.4, 33.4, 33.78, 33.78, 33.78, 33.78, 33.78, 33.62, 33.62, 33.62, 33.62, 33.62, 32.91, 32.91, 32.91, 32.91, 32.91, 32.27, 32.27, 32.27, 32.27, 32.27, 32.39, 32.39, 32.39, 32.39, 32.39, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.5, 32.07, 32.07, 32.07, 32.07, 32.07, 31.93, 31.93, 31.93, 31.93, 31.93, 31.67, 31.67, 31.67, 31.67, 31.67, 31.58, 31.58, 31.58, 31.58, 31.58, 31.79, 31.79, 31.79, 31.79, 31.79, 31.57, 31.57, 31.57, 31.57, 31.57, 31.78, 31.78, 31.78, 31.78, 31.78, 32.01, 32.01, 32.01, 32.01, 32.01, 32.02, 32.02, 32.02, 32.02, 32.02, 31.52, 31.52, 31.52, 31.52, 31.52, 31.35, 31.35, 31.35, 31.35, 31.35, 31.45, 31.45, 31.45, 31.45, 31.45, 31.65, 31.65, 31.65, 31.65, 31.65, 31.8, 31.8, 31.8, 31.8, 31.8, 32.01, 32.01, 32.01, 32.01, 32.01, 32.12, 32.12, 32.12, 32.12, 32.12, 32.05, 32.05, 32.05, 32.05, 32.05, 31.82, 31.82, 31.82, 31.82, 31.82, 31.67, 31.67, 31.67, 31.67, 31.67, 31.73, 31.73, 31.73, 31.73, 31.73, 31.87, 31.87, 31.87, 31.87, 31.87, 31.99, 31.99, 31.99, 31.99, 31.99, 32.1, 32.1, 32.1, 32.1, 32.1, 32.02, 32.02, 32.02, 32.02, 32.02, 31.97, 31.97, 31.97, 31.97, 31.97, 31.31, 31.31, 31.31, 31.31, 31.31, 30.76, 30.76, 30.76, 30.76, 30.76, 30.0, 30.0, 30.0, 30.0, 30.0, 29.71, 29.71, 29.71, 29.71, 29.71, 29.65, 29.65, 29.65, 29.65, 29.65, 29.82, 29.82, 29.82, 29.82, 29.82, 29.85, 29.85, 29.85, 29.85, 29.85, 29.95, 29.95, 29.95, 29.95, 29.95, 29.98, 29.98, 29.98, 29.98, 29.98, 30.01, 30.01, 30.01, 30.01, 30.01, 29.85, 29.85, 29.85, 29.85, 29.85, 29.78, 29.78, 29.78, 29.78, 29.78, 29.74, 29.74, 29.74, 29.74, 29.74, 29.88, 29.88, 29.88, 29.88, 29.88, 30.01, 30.01, 30.01, 30.01, 30.01, 30.1, 30.1, 30.1, 30.1, 30.1, 30.18, 30.18, 30.18, 30.18, 30.18, 30.28, 30.28, 30.28, 30.28]
                    
</pre>
    </div>
  <span role="presentation">
    <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="16" height="16" viewBox="0 0 16 16" fill="none" data-view-component="true">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>
  </span>
</section>

</details>

<details>
<summary>Details</summary>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/c9c7c8cc87ce6595e66b8f760299af0e170c7718acc0145d5efd7eb8654bd031/68747470733a2f2f692e696d6775722e636f6d2f7a396c315a72522e6a706567"><img width="100%" height="100%" src="https://camo.githubusercontent.com/c9c7c8cc87ce6595e66b8f760299af0e170c7718acc0145d5efd7eb8654bd031/68747470733a2f2f692e696d6775722e636f6d2f7a396c315a72522e6a706567" alt="kv_cache_usage_ratio" data-canonical-src="https://i.imgur.com/z9l1ZrR.jpeg"></a>
</p><details>
    <summary>More</summary>
<section data-identity="0f6a0084-7712-4327-848a-d3aa4e03e368" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;---\nconfig:\n    xyChart:\n        titleFontSize: 12\n        width: 900\n        height: 600\n    themeVariables:\n        xyChart:\n            titleColor: \&quot;#000000\&quot;\n---\nxychart-beta\n    title \&quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3\n duration=10m 543 iterations\&quot;\n    y-axis \&quot;llamacpp:kv_cache_usage_ratio\&quot;\n    x-axis \&quot;llamacpp:kv_cache_usage_ratio\&quot; 1715376005 --&amp;gt; 1715376631\n    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24, 0.24, 0.24, 0.24, 0.24, 0.38, 0.38, 0.38, 0.38, 0.38, 0.23, 0.23, 0.23, 0.23, 0.23, 0.12, 0.12, 0.12, 0.12, 0.12, 0.21, 0.21, 0.21, 0.21, 0.21, 0.11, 0.11, 0.11, 0.11, 0.11, 0.13, 0.13, 0.13, 0.13, 0.13, 0.15, 0.15, 0.15, 0.15, 0.15, 0.18, 0.18, 0.18, 0.18, 0.18, 0.22, 0.22, 0.22, 0.22, 0.22, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.26, 0.26, 0.26, 0.26, 0.26, 0.32, 0.32, 0.32, 0.32, 0.32, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.18, 0.18, 0.18, 0.18, 0.18, 0.3, 0.3, 0.3, 0.3, 0.3, 0.28, 0.28, 0.28, 0.28, 0.28, 0.32, 0.32, 0.32, 0.32, 0.32, 0.21, 0.21, 0.21, 0.21, 0.21, 0.17, 0.17, 0.17, 0.17, 0.17, 0.15, 0.15, 0.15, 0.15, 0.15, 0.14, 0.14, 0.14, 0.14, 0.14, 0.12, 0.12, 0.12, 0.12, 0.12, 0.2, 0.2, 0.2, 0.2, 0.2, 0.31, 0.31, 0.31, 0.31, 0.31, 0.23, 0.23, 0.23, 0.23, 0.23, 0.16, 0.16, 0.16, 0.16, 0.16, 0.15, 0.15, 0.15, 0.15, 0.15, 0.11, 0.11, 0.11, 0.11, 0.11, 0.13, 0.13, 0.13, 0.13, 0.13, 0.17, 0.17, 0.17, 0.17, 0.17, 0.23, 0.23, 0.23, 0.23, 0.23, 0.21, 0.21, 0.21, 0.21, 0.21, 0.19, 0.19, 0.19, 0.19, 0.19, 0.16, 0.16, 0.16, 0.16, 0.16, 0.15, 0.15, 0.15, 0.15, 0.15, 0.14, 0.14, 0.14, 0.14, 0.14, 0.09, 0.09, 0.09, 0.09, 0.09, 0.25, 0.25, 0.25, 0.25, 0.25, 0.44, 0.44, 0.44, 0.44, 0.44, 0.54, 0.54, 0.54, 0.54, 0.54, 0.62, 0.62, 0.62, 0.62, 0.62, 0.6, 0.6, 0.6, 0.6, 0.6, 0.29, 0.29, 0.29, 0.29, 0.29, 0.14, 0.14, 0.14, 0.14, 0.14, 0.15, 0.15, 0.15, 0.15, 0.15, 0.12, 0.12, 0.12, 0.12, 0.12, 0.17, 0.17, 0.17, 0.17, 0.17, 0.11, 0.11, 0.11, 0.11, 0.11, 0.17, 0.17, 0.17, 0.17, 0.17, 0.31, 0.31, 0.31, 0.31, 0.31, 0.23, 0.23, 0.23, 0.23, 0.23, 0.25, 0.25, 0.25, 0.25, 0.25, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.14, 0.14, 0.14, 0.14, 0.14, 0.11, 0.11, 0.11, 0.11, 0.11, 0.17, 0.17, 0.17, 0.17]\n                    \n&quot;}" data-plain="---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: &quot;#000000&quot;
---
xychart-beta
    title &quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations&quot;
    y-axis &quot;llamacpp:kv_cache_usage_ratio&quot;
    x-axis &quot;llamacpp:kv_cache_usage_ratio&quot; 1715376005 --> 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24, 0.24, 0.24, 0.24, 0.24, 0.38, 0.38, 0.38, 0.38, 0.38, 0.23, 0.23, 0.23, 0.23, 0.23, 0.12, 0.12, 0.12, 0.12, 0.12, 0.21, 0.21, 0.21, 0.21, 0.21, 0.11, 0.11, 0.11, 0.11, 0.11, 0.13, 0.13, 0.13, 0.13, 0.13, 0.15, 0.15, 0.15, 0.15, 0.15, 0.18, 0.18, 0.18, 0.18, 0.18, 0.22, 0.22, 0.22, 0.22, 0.22, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.26, 0.26, 0.26, 0.26, 0.26, 0.32, 0.32, 0.32, 0.32, 0.32, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.18, 0.18, 0.18, 0.18, 0.18, 0.3, 0.3, 0.3, 0.3, 0.3, 0.28, 0.28, 0.28, 0.28, 0.28, 0.32, 0.32, 0.32, 0.32, 0.32, 0.21, 0.21, 0.21, 0.21, 0.21, 0.17, 0.17, 0.17, 0.17, 0.17, 0.15, 0.15, 0.15, 0.15, 0.15, 0.14, 0.14, 0.14, 0.14, 0.14, 0.12, 0.12, 0.12, 0.12, 0.12, 0.2, 0.2, 0.2, 0.2, 0.2, 0.31, 0.31, 0.31, 0.31, 0.31, 0.23, 0.23, 0.23, 0.23, 0.23, 0.16, 0.16, 0.16, 0.16, 0.16, 0.15, 0.15, 0.15, 0.15, 0.15, 0.11, 0.11, 0.11, 0.11, 0.11, 0.13, 0.13, 0.13, 0.13, 0.13, 0.17, 0.17, 0.17, 0.17, 0.17, 0.23, 0.23, 0.23, 0.23, 0.23, 0.21, 0.21, 0.21, 0.21, 0.21, 0.19, 0.19, 0.19, 0.19, 0.19, 0.16, 0.16, 0.16, 0.16, 0.16, 0.15, 0.15, 0.15, 0.15, 0.15, 0.14, 0.14, 0.14, 0.14, 0.14, 0.09, 0.09, 0.09, 0.09, 0.09, 0.25, 0.25, 0.25, 0.25, 0.25, 0.44, 0.44, 0.44, 0.44, 0.44, 0.54, 0.54, 0.54, 0.54, 0.54, 0.62, 0.62, 0.62, 0.62, 0.62, 0.6, 0.6, 0.6, 0.6, 0.6, 0.29, 0.29, 0.29, 0.29, 0.29, 0.14, 0.14, 0.14, 0.14, 0.14, 0.15, 0.15, 0.15, 0.15, 0.15, 0.12, 0.12, 0.12, 0.12, 0.12, 0.17, 0.17, 0.17, 0.17, 0.17, 0.11, 0.11, 0.11, 0.11, 0.11, 0.17, 0.17, 0.17, 0.17, 0.17, 0.31, 0.31, 0.31, 0.31, 0.31, 0.23, 0.23, 0.23, 0.23, 0.23, 0.25, 0.25, 0.25, 0.25, 0.25, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.14, 0.14, 0.14, 0.14, 0.14, 0.11, 0.11, 0.11, 0.11, 0.11, 0.17, 0.17, 0.17, 0.17]
                    
">
      <pre lang="mermaid" aria-label="Raw mermaid code">---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: "#000000"
---
xychart-beta
    title "llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations"
    y-axis "llamacpp:kv_cache_usage_ratio"
    x-axis "llamacpp:kv_cache_usage_ratio" 1715376005 --&gt; 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.24, 0.24, 0.24, 0.24, 0.24, 0.38, 0.38, 0.38, 0.38, 0.38, 0.23, 0.23, 0.23, 0.23, 0.23, 0.12, 0.12, 0.12, 0.12, 0.12, 0.21, 0.21, 0.21, 0.21, 0.21, 0.11, 0.11, 0.11, 0.11, 0.11, 0.13, 0.13, 0.13, 0.13, 0.13, 0.15, 0.15, 0.15, 0.15, 0.15, 0.18, 0.18, 0.18, 0.18, 0.18, 0.22, 0.22, 0.22, 0.22, 0.22, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.26, 0.26, 0.26, 0.26, 0.26, 0.32, 0.32, 0.32, 0.32, 0.32, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.18, 0.18, 0.18, 0.18, 0.18, 0.3, 0.3, 0.3, 0.3, 0.3, 0.28, 0.28, 0.28, 0.28, 0.28, 0.32, 0.32, 0.32, 0.32, 0.32, 0.21, 0.21, 0.21, 0.21, 0.21, 0.17, 0.17, 0.17, 0.17, 0.17, 0.15, 0.15, 0.15, 0.15, 0.15, 0.14, 0.14, 0.14, 0.14, 0.14, 0.12, 0.12, 0.12, 0.12, 0.12, 0.2, 0.2, 0.2, 0.2, 0.2, 0.31, 0.31, 0.31, 0.31, 0.31, 0.23, 0.23, 0.23, 0.23, 0.23, 0.16, 0.16, 0.16, 0.16, 0.16, 0.15, 0.15, 0.15, 0.15, 0.15, 0.11, 0.11, 0.11, 0.11, 0.11, 0.13, 0.13, 0.13, 0.13, 0.13, 0.17, 0.17, 0.17, 0.17, 0.17, 0.23, 0.23, 0.23, 0.23, 0.23, 0.21, 0.21, 0.21, 0.21, 0.21, 0.19, 0.19, 0.19, 0.19, 0.19, 0.16, 0.16, 0.16, 0.16, 0.16, 0.15, 0.15, 0.15, 0.15, 0.15, 0.14, 0.14, 0.14, 0.14, 0.14, 0.09, 0.09, 0.09, 0.09, 0.09, 0.25, 0.25, 0.25, 0.25, 0.25, 0.44, 0.44, 0.44, 0.44, 0.44, 0.54, 0.54, 0.54, 0.54, 0.54, 0.62, 0.62, 0.62, 0.62, 0.62, 0.6, 0.6, 0.6, 0.6, 0.6, 0.29, 0.29, 0.29, 0.29, 0.29, 0.14, 0.14, 0.14, 0.14, 0.14, 0.15, 0.15, 0.15, 0.15, 0.15, 0.12, 0.12, 0.12, 0.12, 0.12, 0.17, 0.17, 0.17, 0.17, 0.17, 0.11, 0.11, 0.11, 0.11, 0.11, 0.17, 0.17, 0.17, 0.17, 0.17, 0.31, 0.31, 0.31, 0.31, 0.31, 0.23, 0.23, 0.23, 0.23, 0.23, 0.25, 0.25, 0.25, 0.25, 0.25, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.12, 0.14, 0.14, 0.14, 0.14, 0.14, 0.11, 0.11, 0.11, 0.11, 0.11, 0.17, 0.17, 0.17, 0.17]
                    
</pre>
    </div>
  <span role="presentation">
    <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="16" height="16" viewBox="0 0 16 16" fill="none" data-view-component="true">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>
  </span>
</section>

</details>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/3942f2339f91c1f1f38e2fc6e9b2dd0e52c45e7aa773079744af1ded0d55bc98/68747470733a2f2f692e696d6775722e636f6d2f7a6b396d316b422e6a706567"><img width="100%" height="100%" src="https://camo.githubusercontent.com/3942f2339f91c1f1f38e2fc6e9b2dd0e52c45e7aa773079744af1ded0d55bc98/68747470733a2f2f692e696d6775722e636f6d2f7a6b396d316b422e6a706567" alt="requests_processing" data-canonical-src="https://i.imgur.com/zk9m1kB.jpeg"></a>
<details>
    <summary>More</summary>
<section data-identity="1dc42fc3-a67b-42cc-9e43-8195101d631a" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;---\nconfig:\n    xyChart:\n        titleFontSize: 12\n        width: 900\n        height: 600\n    themeVariables:\n        xyChart:\n            titleColor: \&quot;#000000\&quot;\n---\nxychart-beta\n    title \&quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3\n duration=10m 543 iterations\&quot;\n    y-axis \&quot;llamacpp:requests_processing\&quot;\n    x-axis \&quot;llamacpp:requests_processing\&quot; 1715376005 --&amp;gt; 1715376631\n    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 7.0, 7.0, 7.0, 7.0, 4.0, 4.0, 4.0, 4.0, 4.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 3.0, 8.0, 8.0, 8.0, 8.0, 8.0, 2.0, 2.0, 2.0, 2.0, 2.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 5.0, 5.0, 5.0, 5.0, 5.0, 8.0, 8.0, 8.0, 8.0, 8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0]\n                    \n&quot;}" data-plain="---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: &quot;#000000&quot;
---
xychart-beta
    title &quot;llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations&quot;
    y-axis &quot;llamacpp:requests_processing&quot;
    x-axis &quot;llamacpp:requests_processing&quot; 1715376005 --> 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 7.0, 7.0, 7.0, 7.0, 4.0, 4.0, 4.0, 4.0, 4.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 3.0, 8.0, 8.0, 8.0, 8.0, 8.0, 2.0, 2.0, 2.0, 2.0, 2.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 5.0, 5.0, 5.0, 5.0, 5.0, 8.0, 8.0, 8.0, 8.0, 8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0]
                    
">
      <pre lang="mermaid" aria-label="Raw mermaid code">---
config:
    xyChart:
        titleFontSize: 12
        width: 900
        height: 600
    themeVariables:
        xyChart:
            titleColor: "#000000"
---
xychart-beta
    title "llama.cpp bench-server-baseline on Standard_NC4as_T4_v3
 duration=10m 543 iterations"
    y-axis "llamacpp:requests_processing"
    x-axis "llamacpp:requests_processing" 1715376005 --&gt; 1715376631
    line [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 7.0, 7.0, 7.0, 7.0, 4.0, 4.0, 4.0, 4.0, 4.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 3.0, 8.0, 8.0, 8.0, 8.0, 8.0, 2.0, 2.0, 2.0, 2.0, 2.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 4.0, 4.0, 4.0, 4.0, 4.0, 8.0, 8.0, 8.0, 8.0, 8.0, 5.0, 5.0, 5.0, 5.0, 5.0, 8.0, 8.0, 8.0, 8.0, 8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 8.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0]
                    
</pre>
    </div>
  <span role="presentation">
    <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="16" height="16" viewBox="0 0 16 16" fill="none" data-view-component="true">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>
  </span>
</section>

</details>

</details>
</details>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Project Gameface launches on Android (130 pts)]]></title>
            <link>https://developers.googleblog.com/en/project-gameface-launches-on-android/</link>
            <guid>40371401</guid>
            <pubDate>Wed, 15 May 2024 19:39:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developers.googleblog.com/en/project-gameface-launches-on-android/">https://developers.googleblog.com/en/project-gameface-launches-on-android/</a>, See on <a href="https://news.ycombinator.com/item?id=40371401">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    
      
    

    

    

    <section>
      
        
          <p><a href="https://developers.googleblog.com/en/search/?author=Avneet+Singh">Avneet Singh</a>
            
              <span>Product Manager</span>
            
            
              <span>Google Partner Innovation</span>
            
          </p>
        
          
        

      
      </section>

    
    <div>
          

<div>
    <p data-block-key="yqqoj">At I/O 2023, we launched <a href="https://blog.google/technology/ai/google-project-gameface/">Project Gameface</a>, an open-source, hands-free gaming ‘mouse’ enabling people to control a computer’s cursor using their head movement and facial gestures. People can raise their eyebrows to click and drag, or open their mouth to move the cursor, making gaming more accessible.</p><p data-block-key="c8bt5">The project was inspired by the story of quadriplegic video game streamer Lance Carr, who lives with muscular dystrophy, a progressive disease that weakens muscles. And we collaborated with Lance to bring Project Gameface to life. The full story behind the product is available on the <a href="https://blog.google/technology/ai/google-project-gameface/">Google Keyword blog</a>.</p><p data-block-key="7k1tq">We’ve been delighted to see companies like <a href="https://www.playability.gg/">playAbility</a> utilize Project Gameface building blocks, like <a href="https://storage.googleapis.com/mediapipe-assets/Model%20Card%20Blendshape%20V2.pdf">MediaPipe Blendshapes</a>, in their inclusive software. Now, we’re open sourcing more code for Project Gameface to help developers build Android applications to make every Android device more accessible. Through the device's camera, it seamlessly tracks facial expressions and head movements, translating them into intuitive and personalized control. Developers can now build applications where their users can configure their experience by customizing facial expressions, gesture sizes, cursor speed, and more.</p><p data-block-key="ca2du">For this release, we collaborated with <a href="https://incluzza.org/">Incluzza</a>, a social enterprise in India that supports people with disability, to learn how Project Gameface can be expanded to educational, work and other settings, like being able to type messages to family or searching for new jobs.</p>
</div>    <div>
    <p data-block-key="yqqoj">While building Project Gameface for Android, we based our product design and development on three core principles:</p><ol><li data-block-key="9t5u7">Give people with disabilities a new additional means to operate Android devices.</li></ol><p data-block-key="drc1o">2. Build a cost-effective solution that’s generally available to enable scalable usage.</p><p data-block-key="64b54">3. Leverage the learnings and guiding principles from the first Gameface launch to make the product user-friendly and customizable.</p><h3 data-block-key="8dm8n"><b><br>Building out a cursor in an Android device</b></h3><p data-block-key="d9s6v">We are launching a novel way to start operating an Android device. Based on the positive feedback on Project Gameface, we realized that developers and users appreciated the idea of moving a cursor with head movement and taking actions through facial expressions.</p><p data-block-key="13v61">We have replicated the same idea to bring a new virtual cursor on an Android device. We are using the Android accessibility service to create a new cursor and are leveraging <a href="https://youtu.be/3NePkYhFkiw?si=dIk4396bp-kVXLQW">MediaPipe’s Face Landmarks Detection API</a> to program the cursor in a way so it moves according to a user’s head movement.</p><p data-block-key="1t503">Within the API, there are 52 face blendshape values which represent the expressiveness of 52 facial gestures such as raising left eyebrow or mouth opening. We use some of these 52 values to effectively map and control a wide range of functions, offering users expanded possibilities for customization and manipulation. We are also leveraging blendshapes coefficients which gives developers an ability to set different thresholds on each specific expression and this helps them customize the experience.</p>
</div>   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Project_Gameface_1_1_Nh0Y7zK.original.png" alt="Project Gameface visuals">
        
    </p>
</div>
  <div>
    <h3 data-block-key="yqqoj"><b>Bringing the best of Android Accessibility Service to Project Gameface</b></h3><h4 data-block-key="4dvo5"><i>Mobile actions</i></h4><p data-block-key="a18bh">In the Windows version for Project Gameface, we enabled users to replicate common click actions. However, in Android, there is a wider array of capabilities that users need to perform. There are touch events that are inputted into the OS and there are other global action events like “Go Back”, “Switch to Multitasking”, “Home”. We used the <a href="https://developer.android.com/reference/android/accessibilityservice/AccessibilityService">Android Accessibility API supported mobile actions</a> to determine which actions could be provided to the user. Currently, Project Gameface for Android supports GLOBAL_ACTION_HOME, GLOBAL_ACTION_BACK, GLOBAL_ACTION_NOTIFICATIONS, GLOBAL_ACTION_ACCESSIBILITY_ALL_APPS</p><h4 data-block-key="cl7e2"><i><br>Camera Feed</i></h4><p data-block-key="9ug6s">The camera feed significantly enhances the user experience, facilitating accurate threshold settings and a deeper comprehension of gestures. It also sends a clear signal to the user that their camera is being actively used to understand their head movements and gestures.</p><p data-block-key="a6p3">Just creating an overlay of camera feed would have prevented developers from accessing some important sections of their Android device like the Android settings. We use Android accessibility service with Project Gameface to enable the camera to continue floating even in Android settings and any other important sections of a user’s Android device.</p>
</div>   

<div>
    <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/Project_Gameface_1.original.png" alt="Project Gameface camera feed">
        
    </p>
</div>
  <div>
    <h3 data-block-key="yqqoj"><b>Enabling users to perform the ‘drag function’</b></h3><p data-block-key="2tps8">The Android accessibility service currently lacks a straightforward method for users to perform real-time interactive screen dragging. However, our product has been upgraded to include drag functionality, allowing users to define both starting and ending points. Consequently, the drag action will be executed seamlessly along the specified path.</p>
</div>   

<div>
    
        <video autoplay="" loop="" muted="" playsinline="" poster="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-fux_2cpn_thumb.jpg">
<source src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/Project_Gameface_1_1.mp4" type="video/mp4">
<p>Sorry, your browser doesn't support playback for this video</p>

</video>
    
    
</div>  <div>
    <p data-block-key="yqqoj">We’re excited to see the potential of Project Gameface and can’t wait for developers and enterprises to leverage it to build new experiences. The code for Gameface is now <a href="https://github.com/google/project-gameface">open sourced on Github</a>.<b><br></b></p><hr><h3 data-block-key="fdlso"><b>Acknowledgements</b></h3><p data-block-key="fp8gp"><i><sub>We would like to acknowledge the invaluable contributions of the following people to Project GameFace for Android: Edwina Priest, Sisi Jin, KC Chung, Boon Panichprecha, Dome Seelapun, Kim Nomrak, Guide Pumithanon, Lance Carr, Communique Team (Meher Dabral,Samudra Sengupta), EnAble/Incluzza India (Shristi G, Vinaya C, Debashree Bhattacharya, Manju Sharma, Jeeja Ghosh, Sultana Banu, Sunetra Gupta, Ajay Balachandran , Karthik Chandrasekar</sub></i></p>
</div> 
      </div>
    

    

    
    
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PaliGemma: Open-Source Multimodal Model by Google (117 pts)]]></title>
            <link>https://blog.roboflow.com/paligemma-multimodal-vision/</link>
            <guid>40371237</guid>
            <pubDate>Wed, 15 May 2024 19:24:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.roboflow.com/paligemma-multimodal-vision/">https://blog.roboflow.com/paligemma-multimodal-vision/</a>, See on <a href="https://news.ycombinator.com/item?id=40371237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://ai.google.dev/gemma/docs/paligemma?ref=blog.roboflow.com"><u>PaliGemma</u></a> is a vision language model (VLM) developed and released by Google that has <a href="https://blog.roboflow.com/multimodal-models/"><u>multimodal</u></a> capabilities.&nbsp;</p><p>Unlike other VLMs, such as <a href="https://blog.roboflow.com/gpt-4o-vision-use-cases/"><u>OpenAI’s GPT-4o</u></a>, <a href="https://blog.roboflow.com/gemini-what-we-know/"><u>Google Gemini</u></a>, and <a href="https://blog.roboflow.com/claude-3-opus-multimodal/"><u>Anthropic’s Claude 3</u></a> which have struggled with object detection and segmentation, PaliGemma has a wide range of abilities, paired with the ability to fine-tune for better performance on specific tasks. </p><p>Google’s decision to open source a highly capable multimodal model with the ability to fine-tune on custom data is a major breakthrough for open-source AI. PaliGemma gives you the opportunity to create custom multimodal models which you can self-host in the cloud and potentially on larger edge devices like NVIDIA Jetsons.</p><h2 id="what-is-paligemma">What is PaliGemma?</h2><p>PaliGemma, <a href="https://developers.googleblog.com/en/gemma-family-and-toolkit-expansion-io-2024/?ref=blog.roboflow.com"><u>released alongside other products</u></a> at the <a href="https://io.google/2024/?ref=blog.roboflow.com"><u>2024 Google I/O event</u></a>, is a combined multimodal model based on two other models from Google research: SigLIP, a vision model, and Gemma, a large language model, which means the model is a composition of a Transformer decoder and a Vision Transformer image encoder. It takes both image and text as input and generates text as output, supporting multiple languages. </p><p>Important aspects of PaliGemma:</p><ul><li>Relatively small 3 billion combined parameter model</li><li><a href="https://ai.google.dev/gemma/terms?ref=blog.roboflow.com"><u>Permissible commercial use terms</u></a></li><li><a href="https://ai.google.dev/gemma/docs/paligemma/fine-tuning-paligemma?ref=blog.roboflow.com"><u>Ability to fine-tune</u></a> for image and short video caption, visual question answering, text reading, object detection, and object segmentation</li></ul><p>While PaliGemma is useful without fine-tuning, Google says it is “not designed to be used directly, but to be transferred (by fine-tuning) to specific tasks using a similar prompt structure” which means whatever baseline we can observe with the model weights is only the tip of the iceberg for how useful the model may be in a given context. <a href="https://ai.google.dev/gemma/docs/paligemma/model-card?ref=blog.roboflow.com#pre-train_datasets"><u>PaliGemma is pre-trained</u></a> on WebLI, CC3M-35L, VQ²A-CC3M-35L/VQG-CC3M-35L, OpenImages, and WIT.</p><h3 id="links-to-paligemma-resources">Links to PaliGemma Resources</h3><p>Google supplied ample resources to start prototyping with PaliGemma and we’ve curated the highest quality information for those of you who want to jump into using PaliGemma immediately. We suggest getting started with the following resources:</p><ul><li><a href="https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/README.md?ref=blog.roboflow.com"><u>PaliGemma Github README</u></a></li><li><a href="https://ai.google.dev/gemma/docs/paligemma?ref=blog.roboflow.com"><u>PaliGemma documentation</u></a></li><li><a href="https://ai.google.dev/gemma/docs/paligemma/fine-tuning-paligemma?ref=blog.roboflow.com"><u>PaliGemma fine-tuning documentation</u></a></li><li><a href="https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/paligemma/finetune_paligemma.ipynb?ref=blog.roboflow.com"><u>Fine-tune PaliGemma in Google Colab</u></a></li><li><a href="https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/363?project=roboflow-marketing&amp;ref=blog.roboflow.com"><u>Access PaliGemma in Google Vertex</u></a></li></ul><p>In this post we will explore what PaliGemma can do, compare PaliGemma benchmarks to other LMMs, understand PaliGemma’s limitations, and see how it performs in real world use cases. We’ve put together learnings that can save you time while testing PaliGemma.</p><p>Let’s get started!</p><h2 id="what-can-paligemma-do">What can PaliGemma do?</h2><p>PaliGemma is a single-turn vision language model and it works best when fine-tuning to a specific use case. This means you can input an image and text string, such as a prompt to caption the image, or a question and PaliGemma will output text in response to the input, such as a caption of the image, an answer to a question, or a list of object bounding box coordinates.</p><p>Tasks PaliGemma is suited to perform relate to the <a href="https://ai.google.dev/gemma/docs/paligemma/model-card?ref=blog.roboflow.com#benchmark-results"><u>benchmarking results Google</u></a> released across the following tasks:</p><ul><li>Fine-tuning on single tasks</li><li>Image question answering and captioning</li><li>Video question answering and captioning</li><li>Segmentation</li></ul><p>This means PaliGemma is useful for straightforward and specific questions related to visual data.</p><p>We’ve created a table to show PaliGemma results relative to other models based on reported results on common benchmarks.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-6.png" alt="" loading="lazy" width="896" height="146" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-6.png 600w, https://blog.roboflow.com/content/images/2024/05/image-6.png 896w" sizes="(min-width: 720px) 720px"></figure><p>While benchmarks are helpful data points, they do not tell the entire story. PaliGemma is <strong>built to be fine-tuned</strong> and the other models are closed-source. For the purposes of showing which options are available, we compare against other, often much larger, models that are unable to be fine-tuned.</p><p>It is worth experimenting to see if fine-tuning with custom data will lead to better performance for your specific use case than out-of-the-box performance with other models.</p><p>Later in this post, we will compare PaliGemma to other <a href="https://blog.roboflow.com/gpt-4-vision-alternatives/"><u>open-source VLMs and LMMs</u></a> using a standard set of tests. Continue reading to see how it performs.</p><h2 id="how-to-fine-tune-paligemma">How to Fine-tune PaliGemma</h2><p>One of the exciting aspects of PaliGemma is its ability to finetune on custom use-case data. <a href="https://ai.google.dev/gemma/docs/paligemma/fine-tuning-paligemma?ref=blog.roboflow.com"><u>A notebook</u></a> published by Google’s PaliGemma team showcases how to fine-tune on a small dataset.</p><p>It’s important to note that in this example, only the attention layers are fine-tuned and therefore the performance improvements may be limited.</p><h2 id="how-to-deploy-and-use-paligemma">How to Deploy and Use PaliGemma</h2><p>You can deploy PaliGemma using an open-source <a href="https://inference.roboflow.com/?ref=blog.roboflow.com"><u>Inference package</u></a>. First, we will need to install Inference, as well as some other packages needed to run PaliGemma.</p><div><p>📓</p><div><p>See the PaliGemma inference notebook, which contains the code below </p><a href="https://colab.research.google.com/drive/1_q09OjR2Ldl1FZnvfqwckvxrW_FIYclC?usp=sharing&amp;ref=blog.roboflow.com"><u>here</u></a><p>.</p></div></div><pre><code>!git clone https://github.com/roboflow/inference.git
%cd inference
!pip install -e .</code></pre><pre><code>!pip install git+https://github.com/huggingface/transformers.git accelerate -q</code></pre><p>Next, we will set up PaliGemma by importing the module from Inference and putting in our <a href="https://docs.roboflow.com/api-reference/authentication?ref=blog.roboflow.com"><u>Roboflow API key</u></a>.</p><pre><code>import inference
from inference.models.paligemma.paligemma import PaliGemma

pg = PaliGemma(api_key="YOUR ROBOFLOW API KEY")</code></pre><p>Last, we can input a test image as a Pillow image, pair it with a prompt, and wait for the result.</p><pre><code>from PIL import Image

image = Image.open("/content/dog.webp") # Change to your image
prompt = "How many dogs are in this image?"

result = pg.predict(image,prompt)</code></pre><p>When prompted with this image, we get the accurate answer of&nbsp; `1`.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/dog.webp" alt="" loading="lazy" width="960" height="1280" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/dog.webp 600w, https://blog.roboflow.com/content/images/2024/05/dog.webp 960w" sizes="(min-width: 720px) 720px"></figure><h2 id="paligemma-evaluation-for-computer-vision">PaliGemma Evaluation&nbsp;for Computer Vision</h2><p>Next, we will evaluate how PaliGemma does on various computer vision tasks that we’ve tested using <a href="https://blog.roboflow.com/gpt-4o-vision-use-cases/"><u>GPT-4o</u></a>, <a href="https://blog.roboflow.com/claude-3-opus-multimodal/"><u>Claude 3</u></a>, <a href="https://blog.roboflow.com/first-impressions-with-google-gemini/"><u>Gemini</u></a>, and other models.</p><p>Here, we will test several different use cases including optical character recognition (OCR), document OCR, document understanding, <a href="https://blog.roboflow.com/what-is-vqa/"><u>visual question answering</u></a> (VQA), and <a href="https://blog.roboflow.com/object-detection/"><u>object detection</u></a>.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-18.png" alt="" loading="lazy" width="909" height="168" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-18.png 600w, https://blog.roboflow.com/content/images/2024/05/image-18.png 909w" sizes="(min-width: 720px) 720px"></figure><h3 id="paligemma-for-optical-character-recognition-ocr">PaliGemma for Optical Character Recognition (OCR)</h3><p><a href="https://blog.roboflow.com/what-is-optical-character-recognition-ocr/"><u>Optical character recognition</u></a> is a computer vision task to return the visible text from an image in machine-readable text format. While its a simple task in concept, it can be a difficult task to accomplish in production applications.</p><p>Below we try OCR with both the prompts that we’ve seen work with other LMMs, asking it to “Read the serial number. Return the number with no additional text.” With this prompt, it failed, claiming that it did not have the training or capability to answer that question.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-7.png" alt="" loading="lazy" width="683" height="347" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-7.png 600w, https://blog.roboflow.com/content/images/2024/05/image-7.png 683w"></figure><p>However, we know from the model documentation that it should be capable of OCR. We tried with the example prompt provided in the documentation, `ocr`, where we got a successful, correct result. </p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-8.png" alt="" loading="lazy" width="686" height="341" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-8.png 600w, https://blog.roboflow.com/content/images/2024/05/image-8.png 686w"></figure><p>Trying with a different image with the first prompt also yielded correct results, bringing up a potential limitation of prompt sensitivity.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-9.png" alt="" loading="lazy" width="685" height="424" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-9.png 600w, https://blog.roboflow.com/content/images/2024/05/image-9.png 685w"></figure><p>Next, testing on an <a href="https://blog.roboflow.com/best-ocr-models-text-recognition/"><u>OCR benchmark</u></a> that we have used previously to test other OCR models like Tesseract, Gemini, Claude, GPT-4o and others, we saw very impressive results.&nbsp;</p><p>In average accuracy, we saw 85.84%, beating all other OCR models except for Anthropic’s Claude 3 Opus. </p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-10.png" alt="Average accuracy of all tested models, all except PaliGemma are cached results." loading="lazy" width="504" height="421"><figcaption><span>Average accuracy of all tested models, where all except PaliGemma are cached results. The graph labels on the right side are overlapped. They are Gemini 1.5, GPT-4o and PaliGemma in that order.</span></figcaption></figure><p>PaliGemma also achieved relatively fast speeds. Combined with the cheaper local nature of the model, PaliGemma seems to be the top OCR model in terms of speed efficiency and cost efficiency.</p><div><p>🗒️</p><p>Speed efficiency and cost efficiency, metrics introduced in the OCR benchmarking post, refer to a metric of accuracy given (divided by) time elapsed and cost incurred.</p></div><p>In median speed efficiency, it beats the previous leader, GPT-4o, set a day earlier when it was released, by a healthy margin. In terms of cost efficiency, PaliGemma outperformed the previous leader, EasyOCR, by almost three times, running more accurately and cheaper.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-11.png" alt="Median speed and cost efficiency of all tested models" loading="lazy" width="696" height="296" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-11.png 600w, https://blog.roboflow.com/content/images/2024/05/image-11.png 696w"><figcaption><span>Median speed and cost efficiency of all tested models, where all except PaliGemma are cached results. The graph labels on the right side are overlapped. They are Gemini 1.5, GPT-4o and PaliGemma in that order.</span></figcaption></figure><p>We consider these results to make PaliGemma a top OCR model given the local and more lightweight nature of PaliGemma compared to the models it beat, including the recently released GPT-4o, Gemini, and other OCR packages.</p><h3 id="document-understanding">Document Understanding</h3><p>Document understanding refers to the ability to extract relevant key information from an image, usually with other irrelevant text.</p><p>On an image with a receipt, we ask it to extract the tax paid according to the receipt. Here, PaliGemma gives a close but incorrect result consistently across several attempts.&nbsp;</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-12.png" alt="" loading="lazy" width="691" height="486" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-12.png 600w, https://blog.roboflow.com/content/images/2024/05/image-12.png 691w"></figure><p>However, on an image with a pizza menu, when asked to provide the cost of a specific pizza, it returned a correct value. </p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-13.png" alt="" loading="lazy" width="690" height="510" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-13.png 600w, https://blog.roboflow.com/content/images/2024/05/image-13.png 690w"></figure><p>This performs similar or equivalent to the experience we had with GPT-4 with Vision, where it failed tax extraction but answered the pizza menu question correctly. Gemini, Claude 3 and the new GPT-4o did answer both questions correctly, as well as <a href="https://roboflow.com/compare/qwenvl-vs-gpt-4-vision?ref=blog.roboflow.com"><u>Qwen-VL-Plus</u></a>, an open-source VLM.</p><h3 id="visual-question-answering-vqa">Visual Question Answering (VQA)</h3><p>Visual Question Answering involves posing a model with an image and a question requiring some form of recognition, identification, or reasoning.</p><p>When posed with a question on how much money was present in a picture with 4 coins, it answered with 4 coins. A technically correct answer, but the question asked for the amount of money in the image.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-14.png" alt="" loading="lazy" width="686" height="485" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-14.png 600w, https://blog.roboflow.com/content/images/2024/05/image-14.png 686w"></figure><p>When tasked with identifying a scene featuring Kevin Mcallister from the movie Home Alone, it responded with “christmas”. We consider this to be an incorrect answer.&nbsp;</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-15.png" alt="" loading="lazy" width="690" height="339" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-15.png 600w, https://blog.roboflow.com/content/images/2024/05/image-15.png 690w"></figure><h3 id="object-detection">Object Detection</h3><p>As we mentioned earlier, VLMs have traditionally struggled with object detection, much less instance segmentation. However, PaliGemma is reported to have object detection and instance segmentation abilities.</p><p>First, we test with the same prompt we have given other models in the past. Here, it returns an incorrect, likely hallucinated result.&nbsp;</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-16.png" alt="" loading="lazy" width="691" height="479" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-16.png 600w, https://blog.roboflow.com/content/images/2024/05/image-16.png 691w"></figure><p>However, when prompting with the keyword `detect`, followed by the object `dog` (so `detect dog`) as detailed in the model documentation, it correctly and accurately identifies the dog in the image. Using the keyword `segment dog` also resulted in a correct segmentation.</p><figure><img src="https://blog.roboflow.com/content/images/2024/05/image-17.png" alt="" loading="lazy" width="632" height="419" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/image-17.png 600w, https://blog.roboflow.com/content/images/2024/05/image-17.png 632w"></figure><p>Although it is very impressive that a VLM is able to provide object detection and recognition capabilities, it is worth noting that only basic examples, such as those possible with a traditional object detection model, succeeded. When prompted to find cars, (there is a car present visible through the door of the building in the back) it returned no results.</p><h2 id="use-cases-for-paligemma">Use Cases for PaliGemma</h2><p>Whether using PaliGemma zero-shot or fine-tuned on custom data, there are specific use cases tailored to PaliGemma’s strengths that will open the door to new AI use cases. Let’s take a look at a two of them.</p><h3 id="custom-applications">Custom Applications</h3><p>Models like Claude 3, Gemini 1.5 Pro, and GPT-4o are used out-of-the-box and applied to problems they are suited to solve. PaliGemmi brings multimodal abilities to use cases that are still unsolved by closed-source models because you can fine-tune PaliGemma with proprietary data related to your problem. This is useful in industries like manufacturing, CPG, healthcare, and security. If you have a unique problem that closed-models have not seen, and will never see due to their proprietary nature, then PaliGemma is a great entry point into building custom AI solutions.&nbsp;</p><h3 id="ocr">OCR</h3><p>As shown earlier in this article, PaliGemma is a strong OCR model without any additional fine-tuning. When building OCR applications to scale to billions of predictions, latency, cost, and accuracy can be difficult to balance. Before PaliGemma, closed-source models were the best-in-class option for performance but their cost and lack of model ownership made them difficult to justify in production. This model can provide immediate performance and be improved over time by fine-tuning on your specific data.</p><h2 id="limitations-of-paligemma">Limitations of PaliGemma</h2><p>PaliGemma, and all VLMs, are best suited for tasks with clear instructions and are not the best tool for open-ended, complex, nuanced, or reason based problems. This is where VLMs are distinct from LMMs and you will find the best results if you use the models where they are most likely to perform well.</p><p>In terms of context, PaliGemma has information based on the pre-training datasets and any data supplied during fine-tuning. PaliGemma will not know information outside of this and, barring any weights updates with new data from Google or the open source community, you should not rely on PaliGemma as a knowledge base.</p><p>To get the most out of PaliGemma, and have a reason to use the model over other open source models, you’ll want to train the model on custom data. Its zero-shot performance is not state-of-the-art across most benchmarks. Setting up a custom training pipeline will be necessary to warrant using PaliGemma for most use cases.</p><p>Finally, during various tests, we saw drastic differences in results with slight changes to prompts. This is similar behavior to other LMMs, like <a href="https://blog.roboflow.com/yolo-world-prompting-tips/"><u>YOLO-World</u></a>, and takes time to understand how to best prompt the model. Changes in a prompt, like removing an ‘s’ to make a word singular rather than plural, can be the difference between a perfect detection and an unusable output.</p><figure><div><p><img src="https://blog.roboflow.com/content/images/2024/05/Screenshot-2024-05-14-at-8.44.07-PM.png" width="1610" height="1054" loading="lazy" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/Screenshot-2024-05-14-at-8.44.07-PM.png 600w, https://blog.roboflow.com/content/images/size/w1000/2024/05/Screenshot-2024-05-14-at-8.44.07-PM.png 1000w, https://blog.roboflow.com/content/images/size/w1600/2024/05/Screenshot-2024-05-14-at-8.44.07-PM.png 1600w, https://blog.roboflow.com/content/images/2024/05/Screenshot-2024-05-14-at-8.44.07-PM.png 1610w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.roboflow.com/content/images/2024/05/Screenshot-2024-05-14-at-8.43.35-PM.png" width="1688" height="946" loading="lazy" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/Screenshot-2024-05-14-at-8.43.35-PM.png 600w, https://blog.roboflow.com/content/images/size/w1000/2024/05/Screenshot-2024-05-14-at-8.43.35-PM.png 1000w, https://blog.roboflow.com/content/images/size/w1600/2024/05/Screenshot-2024-05-14-at-8.43.35-PM.png 1600w, https://blog.roboflow.com/content/images/2024/05/Screenshot-2024-05-14-at-8.43.35-PM.png 1688w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.roboflow.com/content/images/2024/05/Screenshot-2024-05-14-at-8.45.12-PM.png" width="1804" height="1138" loading="lazy" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2024/05/Screenshot-2024-05-14-at-8.45.12-PM.png 600w, https://blog.roboflow.com/content/images/size/w1000/2024/05/Screenshot-2024-05-14-at-8.45.12-PM.png 1000w, https://blog.roboflow.com/content/images/size/w1600/2024/05/Screenshot-2024-05-14-at-8.45.12-PM.png 1600w, https://blog.roboflow.com/content/images/2024/05/Screenshot-2024-05-14-at-8.45.12-PM.png 1804w" sizes="(min-width: 720px) 720px"></p></div><figcaption><p><span>Notice the different results based on plural vs singular nouns</span></p></figcaption></figure><h2 id="conclusion">Conclusion</h2><p>Google’s release of PaliGemma is incredibly useful for the advancement of multimodal AI. The lightweight open source model built for fine-tuning means anyone can custom train their own large vision-language model and deploy it for any commercial purpose on their own hardware or cloud. </p><p>Previous LMMs have been extremely expensive to fine-tune and often require large amounts of compute to run, making them prohibitive for broad adoption. PaliGemma breaks the mold and offers people building custom AI applications a breakthrough model to create sophisticated applications.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LDAPjs decomissioned by maintainer over hateful email (102 pts)]]></title>
            <link>https://github.com/ldapjs/node-ldapjs</link>
            <guid>40370190</guid>
            <pubDate>Wed, 15 May 2024 17:53:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ldapjs/node-ldapjs">https://github.com/ldapjs/node-ldapjs</a>, See on <a href="https://news.ycombinator.com/item?id=40370190">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Project Decomissioned</h2><a id="user-content-project-decomissioned" aria-label="Permalink: Project Decomissioned" href="#project-decomissioned"></a></p>
<p dir="auto">This project has been decomissioned. I, James Sumners, took it on when it was
languishing without any maintenance as it filled a need in the ecosystem and
I had built things at a prior organization that depended upon this project.
I spent a lot of time triaging issues and reworking things toward a path
that could be more easily maintained by a community of volunteers. But I have
not had the time to dedicate to this project in quite a while. There are
outstanding issues that would take me at least a week of dedicated development
time to solve, and I cannot afford to take time off of work to do that.
Particularly considering that the aforementioned organization was two
jobs ago, and it is extremely unlikely that I will transition to a role again
that will need this project.</p>
<p dir="auto">So, why am I just now deciding to decomission this project? Because today,
2024-05-14, I received the following email:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ldapjs/node-ldapjs/blob/master/dt.png"><img src="https://github.com/ldapjs/node-ldapjs/raw/master/dt.png" alt="Abusive email"></a></p>
<p dir="auto">I will not tolerate abuse, and I especially will not tolerate tacit death
threats, over a hobby. You can thank the author of that email for the
decomissioning on this project.</p>
<p dir="auto">My recommendation to you in regard to LDAP operations: write a gateway in a
language that is more suited to these types of operations. I'd suggest
<a href="https://go.dev/" rel="nofollow">Go</a>.</p>
<p dir="auto">👋</p>
<p dir="auto">P.S.: if I ever do need this project again, I might revive it. But I'd fight
hard for my suggestion above. Also, I will consider turning it over to an
interested party, but I will require at least one recommendation from a
Node.js core contributor that I can vet with the people that I know on that
team.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Blog: Android's theft protection features keep your device and data safe (151 pts)]]></title>
            <link>https://blog.google/products/android/android-theft-protection/</link>
            <guid>40369668</guid>
            <pubDate>Wed, 15 May 2024 17:12:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/products/android/android-theft-protection/">https://blog.google/products/android/android-theft-protection/</a>, See on <a href="https://news.ycombinator.com/item?id=40369668">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>
        <video autoplay="" muted="" loop="" playsinline="" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/blog_header_2.mp4" title="In an animation, a person steals someone’s unlocked phone. As the thief carries the phone away, it locks itself and a notification pops up: “Your device was auto-locked; a possible theft motion was detected.”" poster="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Theft_blog_hero_image_thumbnail.png">
          Sorry, your browser doesn't support embedded videos, but don't worry, you can
            <a href="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/blog_header_2.mp4">download it</a>
            and watch it with your favorite video player!
        </video>
      </p>
      
    </div><div data-reading-time="true" data-component="uni-drop-cap|uni-tombstone">

            
              


<google-read-aloud-player data-analytics-module="{
        &quot;event&quot;: &quot;module_impression&quot;,
        &quot;module_name&quot;: &quot;ai_audio&quot;,
        &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
    }" data-date-modified="2024-05-15T17:10:55.384138+00:00" data-progress-bar-style="half-wave" data-api-key="AIzaSyBLT6VkYe-x7sWLZI2Ep26-fNkBKgND-Ac" data-article-style="style9" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-layout-style="style1" data-highlight-mode="word-over-paragraph" data-highlight-text-color="#000000" data-highlight-word-background="#8AB4F8" data-highlight-paragraph-background="#D2E3FC" data-background="linear-gradient(180deg, #F1F3F4 0%, #F8F9FA 100%)" data-foreground-color="#202124" data-font="600 16px Google Sans, sans-serif" data-box-shadow="0px 1px 3px 1px rgba(60, 64, 67, 0.15)">
</google-read-aloud-player>




            

            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
         }"><p data-block-key="el7di">Smartphones help us with everyday tasks like online banking, storing sensitive information, taking photos of our friends and families and quickly paying for stuff. While our phones make our lives easier, they also contain a lot of valuable information which makes these devices a target for people who might want to get their hands on our data.</p><p data-block-key="3r7mt">To help keep your device and your data safe before, during and after a theft attempt, we’re introducing a new suite of advanced theft protection features. These features will be rolling out through Google Play services updates later this year to the billions of devices running Android 10+, with some features available in Android 15.</p></div>
  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
         }"><h2 data-block-key="kv45b">1. Improved device and data protection to deter theft before it happens</h2><p data-block-key="2icmd">We're working to strengthen your device's security against theft with new and improved protection features that will make thieves think twice about trying.</p><p data-block-key="93f7b"><b>Factory reset upgrade prevents a reset by a thief.</b> For some criminals, the goal is to quickly reset your stolen device and resell it. We’re making it more difficult to do that with an upgrade to Android’s factory reset protection. With this upgrade, if a thief forces a reset of the stolen device, they’re not able to set it up again without knowing your device or Google account credentials. This renders a stolen device unsellable, reducing incentives for phone theft.</p><p data-block-key="48h9d"><b>Private space hides your sensitive apps.</b> Some thieves just want the device, but many aim to extract valuable data and transfer funds from your phone that can be worth much more than your hardware. Private space is a new feature that lets you create a separate area in your phone that you can hide and lock with a separate PIN, giving you additional security for apps that might contain sensitive data, like health or financial information.</p><p data-block-key="dnako"><b>More steps for changing sensitive device settings to protect your data.</b> Disabling Find My Device or extending screen timeout now requires your PIN, password or biometric authentication, adding an extra layer of security preventing criminals who got a hold of your device from keeping it unlocked or untrackable online.</p><p data-block-key="asfvs"><b>Increased authentication to protect you in case your PIN is known by a thief.</b> When enabled, our new enhanced authentication will require biometrics for accessing and changing critical Google account and device settings, like changing your PIN, disabling theft protection or accessing Passkeys, from an untrusted location.</p><p data-block-key="1ejes">Factory reset protection updates and private space will be released as part of Android 15. Enhanced authentication protections will be released to select devices later this year.</p></div>
  

  
    







  
      <div data-analytics-module="{
          &quot;module_name&quot;: &quot;Inline Images&quot;,
          &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
        }">
  

  <p>

      
      
        
          <video tabindex="0" autoplay="" loop="" muted="" playsinline="" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Protect_sensitive_settings_30fps.mp4" type="video/mp4" title="Animation showing a biometric screen when a user tries to turn off Find My Device.  Caption: Android will protect access to sensitive settings by requiring users to enter their  PIN or biometrics." alt="Protect sensitive settings">
            Video format not supported
          </video>
        
      
    
    </p>
    
      <figcaption><p data-block-key="shdvm">Android will protect access to sensitive settings by requiring users to enter their PIN or biometrics.</p></figcaption>
    
  
    </div>
  



  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
         }"><h2 data-block-key="kv45b">2. Automatic protection the moment your phone is stolen</h2><p data-block-key="an4h1">Having a device stolen is unexpected and stressful and it can be hard to react quickly at the moment it happens. That’s why we created features that can automatically recognize suspicious signals and proactively protect your data on the device.</p><p data-block-key="3jaj2"><b>Automatic AI-powered screen lock for when your phone is snatched.</b> Theft Detection Lock is a powerful new feature that uses Google AI to sense if someone snatches your phone from your hand and tries to run, bike or drive away. If a common motion associated with theft is detected, your phone screen quickly locks – which helps keep thieves from easily accessing your data.</p><p data-block-key="7qjv1"><b>Added protection when a thief has your device.</b> If a thief tries to disconnect your phone for prolonged periods of time, Offline Device Lock automatically locks your screen to help protect your data even when your device is off the grid. Android can also recognize other signs that your device may be in the wrong hands. For example, it will lock your device screen when excessive failed authentication attempts are made.</p><p data-block-key="2p9na">Theft Detection Lock and Offline Device Lock will be available to Android 10+ devices through a Google Play services update later this year.</p></div>
  

  
    







  
      <div data-analytics-module="{
          &quot;module_name&quot;: &quot;Inline Images&quot;,
          &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
        }">
  

  <p>

      
      
        
          <video tabindex="0" autoplay="" loop="" muted="" playsinline="" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Theft_Detection_Lock_-_30fps_2.mp4" type="video/mp4" title="Animation showing how Theft Detection Lock works to protect user data Caption: Android uses AI to lock the device if the phone detects motion that could indicate theft." alt="Theft Detection Lock">
            Video format not supported
          </video>
        
      
    
    </p>
    
      <figcaption><p data-block-key="shdvm">Android uses AI to lock the device if the phone detects motion that could indicate theft.</p></figcaption>
    
  
    </div>
  



  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
         }"><h2 data-block-key="kv45b">3. Lock your device and act quickly after your phone is stolen</h2><p data-block-key="vnhl"><a href="https://support.google.com/android/answer/6160491?hl=en" rt-link-type="external">Find My Device</a> already lets you remotely lock or wipe a lost or stolen phone and you can now <a href="https://blog.google/products/android/android-find-my-device/" rt-link-type="external">mark it as lost</a> for easier tracking. But many users are shocked and stressed after a phone goes missing and can’t recall their Google account password to access Find My Device.</p><p data-block-key="fr2qg"><b>Remote Lock feature throws you a lifeline if your phone is already gone.</b> You'll be able to lock the screen of your phone with just your phone number and a quick security challenge using any device. This buys you time to recover your account details and access additional helpful options in Find My Device, including sending a full factory reset command to completely wipe the device.</p><p data-block-key="57j0p">Remote Lock will be available to Android 10+ devices through a Google Play services update later this year. Find My Device is available on Android 5+ devices.</p></div>
  

  
    







  
      <div data-analytics-module="{
          &quot;module_name&quot;: &quot;Inline Images&quot;,
          &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
        }">
  

  <p>

      
      
        
          <video tabindex="0" autoplay="" loop="" muted="" playsinline="" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Remote-lock-updated-final-30fps_2.mp4" type="video/mp4" title="Animation showing a user turning on Remote Lock." alt="Remote Lock">
            Video format not supported
          </video>
        
      
    
    </p>
    
      <figcaption><p data-block-key="shdvm">Remote Lock lets you remotely lock your device screen quickly</p></figcaption>
    
  
    </div>
  



  

  
    <div data-component="uni-article-paragraph" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android’s theft protection features keep your device and data safe&quot;
         }"><p data-block-key="kv45b">We're committed to keeping your device and data secure on Android. We’re constantly developing new protections to help our users around the world. Look out for more security and privacy features and updates from Android.<br></p><p data-block-key="5r4jt"><a href="https://security.googleblog.com/2024/05/io-2024-whats-new-in-android-security.html" rt-link-type="external">Learn more</a> about how we’re also protecting users from financial fraud and scams with new features.</p></div>
  

  
    



<section data-analytics-module="{
  &quot;module_name&quot;: &quot;Related Content Tout&quot;,
  &quot;section_header&quot;: &quot;10 updates coming to the Android ecosystem&quot;
}">
  <a href="https://blog.google/products/android/android-15-google-io-2024/" data-ga4-analytics-cta-click="{
  &quot;event&quot;: &quot;cta_click&quot;,
  &quot;link_text&quot;: &quot;See more&quot;
}" data-ga4-analytics-lead-click="{
  &quot;event&quot;: &quot;article_lead_click&quot;,
  &quot;link_text&quot;: &quot;10 updates coming to the Android ecosystem&quot;,
  &quot;link_type&quot;: &quot;internal&quot;,
  &quot;article_name&quot;: &quot;10 updates coming to the Android ecosystem&quot;,
  &quot;author_name&quot; : &quot;Menaka Shroff&quot;,
  &quot;page_name&quot;: &quot;android-15-google-io-2024&quot;,
  &quot;position&quot;: &quot;1 of 1&quot;,
  &quot;click_location&quot;: &quot;undefined&quot;,
  &quot;primary_tag&quot;: &quot;Products - Android&quot;,
  &quot;secondary_tags&quot;: &quot;undefined&quot;,
  &quot;publish_date&quot;: &quot;2024-05-15|17:00&quot;,
  &quot;hero_media&quot;: &quot;image&quot;,
  &quot;days_since_published&quot;: &quot;0&quot;,
  &quot;content_category&quot;: &quot;Announcement&quot;,
  &quot;word_count&quot;: &quot;1032&quot;,
  &quot;has_audio&quot;: &quot;no&quot;,
  &quot;has_video&quot;: &quot;yes&quot;,
  &quot;has_image&quot;: &quot;yes&quot;,
  &quot;has_carousel&quot;: &quot;no&quot;
}">
    <p>Related Article</p>
    <div>
      
        <figure>
          <img alt="An image showcasing Android 15 logo in the middle surrounded by a smartwatch, a TV interface, a car display interface in a circular web." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/0._Blog_header_Oe8lecY.width-165.format-webp.webp" data-loading="{
              &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/0._Blog_header_Oe8lecY.width-165.format-webp.webp&quot;,
              &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/0._Blog_header_Oe8lecY.width-300.format-webp.webp&quot;
            }">
          </figure>
      
      <div>
        <p>Related Article</p>
        <p>10 updates coming to the Android ecosystem</p>
        <p>From Theft Detection Lock to casting on Rivian to Wear OS 5 updates, here’s what’s coming to Android 15 and its device ecosystem.</p>
        
      </div>
    </div>
  </a>
</section>

  

  
    



<section data-analytics-module="{
  &quot;module_name&quot;: &quot;Related Content Tout&quot;,
  &quot;section_header&quot;: &quot;I/O 2024&quot;
}">
  <a href="https://blog.google/technology/developers/google-io-2024-collection/" data-ga4-analytics-cta-click="{
  &quot;event&quot;: &quot;cta_click&quot;,
  &quot;link_text&quot;: &quot;See more&quot;
}" data-ga4-analytics-landing-lead="{
  &quot;event&quot;: &quot;landing_page_lead&quot;,
  &quot;link_text&quot;: &quot;See more&quot;
}">
    
    <div>
      
        <figure>
          <img alt="A grid with curved lines and rectangles filled with a gradient of rainbow colors." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO24_Collections_SocialShare_5whx.width-165.format-webp.webp" data-loading="{
              &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO24_Collections_SocialShare_5whx.width-165.format-webp.webp&quot;,
              &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/IO24_Collections_SocialShare_5whx.width-300.format-webp.webp&quot;
            }">
          </figure>
      
      <div>
        
        <p>I/O 2024</p>
        <p>Here’s a look at everything we announced at Google I/O 2024.</p>
        
      </div>
    </div>
  </a>
</section>

  

  
    

  
    






<div role="form" aria-label="Sign up to receive weekly news and stories from Google." data-component="uni-subscribe" data-analytics-module="{
    &quot;module_name&quot;: &quot;Newsletter&quot;,
    &quot;section_header&quot;: &quot;Get more stories from Google in your inbox.&quot;
  }">
        
        
        <p>You are already subscribed to our newsletter.</p>
      </div>

  

  


            
            

            
              




            
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jepsen: Datomic Pro 1.0.7075 (223 pts)]]></title>
            <link>https://jepsen.io/analyses/datomic-pro-1.0.7075</link>
            <guid>40369467</guid>
            <pubDate>Wed, 15 May 2024 16:57:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jepsen.io/analyses/datomic-pro-1.0.7075">https://jepsen.io/analyses/datomic-pro-1.0.7075</a>, See on <a href="https://news.ycombinator.com/item?id=40369467">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><a href="https://datomic.com/">Datomic</a> is a temporal Entity-Attribute-Value OLTP database which supports non-interactive transactions on top of pluggable storage engines. It offers a variety of query mechanisms across thick and thin clients, including Datalog, graph traversal, and an ODM-style API. We evaluated Datomic Pro 1.0.7075 and found its inter-transaction safety properties appear stronger than claimed. Not only was every history Serializable, but sessions bound to a single peer appear Strong Session Serializable, and histories restricted to write transactions and reads using <code>d/sync</code> appear Strong Serializable. However, inside of a transaction Datomic behaves as if operations were evaluated concurrently. Depending on how one interprets those operations, this might violate three of the most widely accepted formalizations of Serializability, each of which specify serial intra-transaction semantics. It also creates the potential for invariant violations when composing transaction functions. Datomic has published a <a href="https://blog.datomic.com/2024/05/Jepsen-tests-Datomic.html">companion blog post</a> alongside this report. This work was funded by <a href="https://nubank.com.br/en/">Nubank</a> (Nu Pagamentos S.A), and conducted in accordance with the <a href="https://jepsen.io/ethics">Jepsen ethics policy</a>.</p><article>
  <div>
<h2 data-number="1" id="background"> Background</h2>
<p><a href="https://datomic.com/">Datomic</a> is a general-purpose database intended for systems of record. In many ways, Datomic is unusual. At any instant in time, the state of the database is represented by a set of <code>[entity, attribute, value]</code> (<a href="https://en.wikipedia.org/wiki/Entity%E2%80%93attribute%E2%80%93value_model">EAV</a>) triples, known as <em>datoms</em>. Each datom declares that some <em>entity</em> (like a person) has a particular <em>attribute</em> (like a name) with a specific <em>value</em> (like “Vidrun”). The types and cardinality of attributes are controlled by a <a href="https://docs.datomic.com/pro/schema/schema.html">schema</a>.</p>
<p>Datomic is also a <a href="https://en.wikipedia.org/wiki/Temporal_database">temporal database</a>: it models time explicitly. Every transaction is identified by a <a href="https://docs.datomic.com/pro/glossary.html#t">strictly monotonic logical timestamp</a> <code>t</code>, as well as a wall-clock time <code>txInstant</code>. Transactions can <a href="https://docs.datomic.com/pro/glossary.html#assertion"><em>assert</em></a> a datom, adding it to the database, or they can <a href="https://docs.datomic.com/pro/glossary.html#retraction"><em>retract</em></a> a datom, removing it from the database. Every datom also retains a reference to the transaction that asserted or retracted it. A full datom is therefore a five-tuple of <code>[entity, attribute, value, transaction, asserted-or-retracted?]</code>. The database is an ever-growing set of these tuples.<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>Users can request a snapshot state of the database <a href="https://docs.datomic.com/pro/tutorial/history.html#asof-query">at any logical or wall-clock time</a>—right now or years in the past. They can also obtain a full <a href="https://docs.datomic.com/pro/tutorial/history.html#history-query">view of the database’s history</a>, allowing users to ask questions like “was there ever a time when Janelle Monáe and Cindi Mayweather were recorded in the same room together?”</p>
<p>Given a state of the database, users may query it via a <a href="https://docs.datomic.com/pro/query/query.html">Datalog-style API</a>, a <a href="https://docs.datomic.com/pro/query/pull.html">declarative graph traversal API</a>, or an <a href="https://docs.datomic.com/pro/overview/entities.html">ODM-style <code>Entity</code> datatype</a> which allows lazy access to an entity’s associated values, including other entities.</p>
<p>Datomic comes in two flavors. In this report we discuss <a href="https://www.datomic.com/index.html">Datomic Pro</a>, which anyone can run on their own computers. <a href="https://www.datomic.com/details.html">Datomic Cloud</a> runs in AWS and uses a <a href="https://docs.datomic.com/cloud/whatis/architecture.html">somewhat different architecture</a>.</p>
<h2 data-number="1.1" id="architecture"> Architecture</h2>
<p>Datomic Pro comprises several <a href="https://docs.datomic.com/pro/overview/architecture.html">co-operating services</a>. <em>Transactors</em> execute write transactions, maintain indices, and write data to storage. <em>Peers</em> are thick clients: they embed a JVM library which submits transactions to transactors, executes read queries against storage, and caches results. For applications written in other languages, Datomic also has a traditional client-server model. <em>Clients</em> are thin clients which forward transactions and queries to a <em>peer server</em>: a peer which runs a small network API.</p>
<p>Internally, Datomic <a href="https://docs.datomic.com/pro/transactions/acid.html#how-it-works">appends each transaction</a> to the <a href="https://docs.datomic.com/pro/query/indexes.html#log"><em>log</em></a>: a time-ordered set of transactions. From the log Datomic maintains <a href="https://docs.datomic.com/pro/query/indexes.html">four indices</a> sorted by different permutations of entity, attribute, value, and time. These indices allow efficient queries like “which entities were modified yesterday,” or “who run the world?”<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>Both log and indices are stored as persistent, immutable trees in a data store like <a href="https://docs.datomic.com/pro/overview/storage.html">Cassandra or DynamoDB</a>. Because tree nodes are immutable, their backing storage only needs to guarantee eventual consistency. A small pointer to the roots of these trees provides a consistent, immutable snapshot of the database’s state. To commit a transaction, a transactor saves new immutable tree nodes to storage, then executes a compare-and-set (CaS) operation to advance the root pointer. This CaS operation must execute under <a href="https://jepsen.io/consistency/models/sequential">Sequential</a> consistency.</p>
<p>Using a Sequential CaS operation ensures a global order of transactions, and limits Datomic’s write throughput to the speed of a single transactor. To reduce contention, Datomic tries to have a <a href="https://docs.datomic.com/pro/operation/ha.html">single active transactor</a> at all times. Operators typically deploy multiple transactors for fault tolerance.</p>
<p>Peers connect directly to storage, and also to transactors. Transactions are forwarded to an active transactor, which executes them. Each peer also maintains a local, monotonically-advancing copy of the root pointer, which allows the peer to read tree nodes from storage. Since tree nodes are immutable, they can be trivially cached. There may be any number of peers, allowing near-linear read scalability.</p>
<h2 data-number="1.2" id="transaction-model"> Transaction Model</h2>
<p>Datomic has an unusual transaction model. Most OLTP databases offer interactive transactions: one begins a transaction, submits an operation, receives results from that operation, submits another, and so on before finally committing. Some databases, like <a href="https://docs.voltdb.com/UsingVoltDB/DesignProcAnatomy.php">VoltDB</a>, use stored procedures: an operator writes a small program which is installed in the database. Clients invoke that program by name, which mutates database state and returns values to the client. Other databases like <a href="https://fauna.com/fql">FaunaDB</a> allow clients to directly submit miniature programs as text or an abstract syntax tree. Like stored procedures, these programs perform arbitrary reads and writes, mutate state, and return data to the user.</p>
<p>Datomic does something rather different. It enforces a strict separation between read and write paths. There are no interactive transactions. It has stored procedures, but they cannot return values to the caller.</p>
<p>A read obtains an immutable state of the entire database. For instance, the <a href="https://docs.datomic.com/pro/clojure/index.html#datomic.api/db"><code>db</code></a> function returns the most recent database state<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> the peer is aware of. To obtain the most recent state across all peers, or a state later than a given time, one calls <a href="https://docs.datomic.com/pro/clojure/index.html#datomic.api/sync"><code>d/sync</code></a>. To obtain a state from a past time (seconds or years ago), one calls <a href="https://docs.datomic.com/pro/tutorial/history.html#asof-query">d/as-of</a>. These states are cheap, highly cacheable, and never block other writers or readers.</p>
<p>Given a database state, one can run any number of queries using (e.g.) <a href="https://docs.datomic.com/pro/clojure/index.html#datomic.api/q"><code>q</code></a> or <a href="https://docs.datomic.com/pro/clojure/index.html#datomic.api/pull"><code>pull</code></a>. Queries lazily fetch datoms from cache or storage. Since database states are immutable, any number of queries run against the same state occur at the exact same logical time. In this sense, all queries run on the same state take place in a single atomic transaction—even two queries executed on different machines, months apart.</p>
<p>Write transactions<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a> are represented as an ordered list of <a href="https://web.archive.org/web/20240129122139/https://docs.datomic.com/pro/transactions/transactions.html#transaction-structure">operations</a>.<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<blockquote>
<p>A transaction is simply a list of lists and/or maps, each of which is a statement in the transaction.</p>
</blockquote>
<p>For example, here is a transaction of three operations, all involving entity <code>123</code>:</p>
<div id="cb1"><pre><code><span id="cb1-1">[[<span>:db/add</span> <span>123</span> <span>:person/name</span> <span>"N. K. Jemisin"</span>]</span>
<span id="cb1-2"> [<span>:db/cas</span> <span>123</span> <span>:author/hugo-count</span> <span>2</span> <span>3</span>]]</span>
<span id="cb1-3"> [<span>:author/add-book</span> <span>123</span> <span>"The Stone Sky"</span>]]</span></code></pre></div>
<p>Those operations may be simple assertions (<code>:db/add</code>) or retractions <code>(:db/retract)</code> of datoms, or they may be calls to <a href="https://docs.datomic.com/pro/transactions/transaction-functions.html">transaction functions</a>: either built-in or user-defined. In this example, the built-in <a href="https://docs.datomic.com/pro/transactions/transaction-functions.html#dbfn-cas"><code>db/cas</code></a> function performs a CaS operation, asserting the number of Hugo awards for this author is 3 if and only if that number is currently 2. One can also <a href="https://docs.datomic.com/pro/reference/database-functions.html#using-transaction-functions">store a function</a> (represented as a Clojure AST or <a href="https://docs.datomic.com/pro/clojure/index.html#datomic.api/function">Java string</a>) in the database just like any other value. Alternatively, one may write a function in any JVM language, and provide it in a <code>jar</code> file on the transactor’s <a href="https://docs.oracle.com/javase/8/docs/technotes/tools/windows/classpath.html">classpath</a>. Once a function has been installed, any transaction may invoke it by providing the function’s name and arguments. Here, the <code>author/add-book</code> function receives the state of the database as of the start of the transaction, as well as any arguments from the transaction. It can perform arbitrary (pure) computation, including running queries against the database state. It then returns a new set of operations for the transaction—for instance, assertions, retractions, or calls to other functions. Function calls are recursively expanded until only assertions and retractions remain.</p>
<p>While transaction functions can make decisions based on the results of reads they perform internally, there is no channel to return those reads (or other information) to the caller of <code>transact</code>. Transactions <em>only</em> return effects. This means there is no direct analogue for an arbitrary read-write transaction in Datomic! For example, you can write a function which performs a conditional write,<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a> but you can’t inform the caller whether the write took place or not. This constraint nudges Datomic users towards pulling reads out of the write transaction path—a key factor in obtaining good performance from a system which can logically execute only one write transaction at a time.</p>
<p>Instead of offering arbitrary return values from transactions, every call to <code>transact</code> returns the database state just before the transaction, the database state the transaction produced, and the set of datoms the transaction expanded to. This allows callers to execute read-write transactions by splitting them in twain: they submit a transaction which performs some writes, then use the pre-state of the database to determine what data that transaction would have read. Peers can also examine the post-state and set of datoms produced by the transaction to (e.g.) determine whether a conditional write took place.</p>
<p>From the perspective of traditional database systems, this sounds absurd. Mixed read-write transactions are a staple of OLTP workloads—how could you get anything done without them? Datomic offers a view of an alternate universe: one where database snapshots are cheap, efficient, and can be passed from node to node with just a timestamp. From this point of view, other databases feel impoverished. What do you mean, Postgres can’t give you the state of the entire database a transaction observed? The lack of a return channel for transaction functions may be annoying, but Datomic’s other strengths generally allow it to solve the same kinds of problems as a traditional, interactive transaction system. For example, NuBank (Datomic’s current developers) offers financial services to nearly 94 million users, processing an average of 2.3 billion user transactions per day. Almost all of their products use Datomic as a system of record.</p>
<h2 data-number="1.3" id="consistency"> Consistency</h2>
<p>Datomic advertises <a href="https://docs.datomic.com/pro/transactions/transactions.html">ACID transactions</a> and means it: their <a href="https://docs.datomic.com/pro/transactions/acid.html">ACID documentation</a> makes detailed, specific promises with respect to consistency models and durability guarantees. Transactions are “written to storage in a single atomic write,” which precludes intermediate read anomalies. Every peer “sees completed transactions as of a particular point in time,” and observes <em>all</em> transactions, totally ordered, up to that time. Transactions are always flushed to durable storage before client acknowledgement.</p>
<p>When our analysis began in early January 2024, Datomic’s documentation <a href="https://web.archive.org/web/20231208204951/docs.datomic.com/pro/transactions/acid.html#isolation">informally claimed</a> write transactions were <a href="https://jepsen.io/consistency/models/serializable">Serializable</a>:</p>
<blockquote>
<p>The Isolation property ensures that concurrent transactions result in the same system state that would result if the transactions were executed serially.</p>
</blockquote>
<p>Since write transactions are Serializable and execute atomically, and since read-only queries execute against committed snapshots, it seems plausible that histories of both read and write transactions should also be Serializable.<a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<p>Serializability does not impose <a href="https://jepsen.io/consistency/models/strict-serializable">real-time</a> or <a href="https://cs.uwaterloo.ca/~kmsalem/pubs/DaudjeeICDE04.pdf">session</a> ordering constraints: in a Serializable system, it is legal for a client to execute a transaction which inserts object <span><em>x</em></span>, then execute a second transaction which fails to observe <span><em>x</em></span>. While Datomic’s documentation does not make this claim, it seems plausible that Datomic’s transactor design might provide <a href="https://jepsen.io/consistency/models/strict-serializable">Strong Serializability</a> over write transactions, preventing real-time anomalies.</p>
<p>Since <code>d/db</code> returns an asynchronously updated <a href="https://docs.datomic.com/pro/transactions/client-synchronization.html">copy of the database</a>, we expect peers to observe stale reads. Indeed, Datomic is explicit that peer reads may not observe some recently committed transactions. However, it would be straightforward for peers to ensure that their time basis advances monotonically; if we say that every session is bound to a single peer node, we would expect to observe <a href="https://dbmsmusings.blogspot.com/2019/06/correctness-anomalies-under.html">Strong Session Serializable</a> histories.</p>
<p>In addition to these possible realtime and session constraints, Datomic has multiple synchronization mechanisms. Clients can <a href="https://docs.datomic.com/pro/transactions/client-synchronization.html">block until they observe</a> a value of the database at or later than some time <code>t</code>. This enables clients to ensure consistency when threading state through side channels. Calling <a href="https://docs.datomic.com/pro/clojure/index.html#datomic.api/sync"><code>d/sync</code></a> forces the client to synchronize with the transactor, preventing stale reads. We expect histories which always use <code>d/sync</code> to be Strict Serializable as well.</p>
<p>Datomic’s documentation also described it as a “<a href="https://web.archive.org/web/20231208204951/https://docs.datomic.com/pro/transactions/acid.html#isolation">single-writer</a>” system:</p>
<blockquote>
<p>A single thread in a single process is responsible for writing transactions. The Isolation property follows automatically from this, because there are no concurrent transactions. Transactions are always executed serially.</p>
</blockquote>
<p>This is wrong in two senses. First, Datomic is fault-tolerant: one can and should run several transactor nodes on different computers. Typically one transactor is active and the others are in standby. When a transactor’s <a href="https://docs.datomic.com/pro/operation/ha.html#enabling">failure detector</a> believes there is no active transactor, it will attempt to promote itself to active. However, <a href="https://www.cs.utexas.edu/~lorenzo/corsi/cs380d/papers/p225-chandra.pdf">perfect failure detectors are impossible</a> in asynchronous networks. There may be times when a standby transactor believes it should take over, but another active transactor is still running. This means transactions may actually execute concurrently. During this window Datomic is not a single-writer system, but a multi-writer one!</p>
<p>Second, even if there were a perfect failure detector which ensured a single Datomic transactor at a time, its messages to storage could be arbitrarily delayed by the network and arrive interleaved with messages from other transactors. Thankfully this doesn’t matter: Datomic’s safety property follows directly from the Sequential consistency of the storage system’s <a href="https://docs.datomic.com/pro/transactions/acid.html#implications">CaS operation</a>. Any number of concurrent transactors ought to be safe.</p>
<h2 data-number="2" id="test-design"> Test Design</h2>
<p>We designed a <a href="https://github.com/jepsen-io/datomic/tree/7997e678a1925d2c3a576a728a63bc29a1b1812c">test suite for Datomic</a> using the <a href="https://github.com/jepsen-io/jepsen">Jepsen testing library</a>. Our test <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/db.clj#L54-L69">installed Datomic Pro</a> 1.0.7075 on a cluster of Debian Bookworm nodes. For storage, it provisioned a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/db/storage.clj#L40-L43">DynamoDB table</a> in AWS. Two of the test nodes ran transactors, and the remaining nodes ran peers.</p>
<p>Our peers were <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer.clj">small Clojure programs</a> which used the <a href="https://docs.datomic.com/pro/peer/peer-introduction.html">Datomic peer library</a>. They connected to storage and transactors and exposed a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer.clj#L96-L114">small HTTP API</a> for performing test suite operations. For each operation the test <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/client.clj#L44-L66">used an HTTP client</a> to submit that operation to some peer. The peer executed that operation using the peer library, and returned a result to the client. We ran our workloads both using <code>d/db</code>, which may yield stale reads, and also with <code>d/sync</code>, which blocks but guarantees recency.</p>
<p>Our test harness <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/nemesis.clj">injected faults</a> into both transactors and peers, including process pauses, crashes, and clock errors. We created network partitions between nodes (including both transactors and peers) and between nodes and the storage system. We also requested Datomic perform garbage collection.</p>
<p>Datomic transactors kill themselves when they cannot maintain a stable connection to storage. When we ran transactors with the default 5-second timeout settings on nodes outside AWS, transactors routinely killed themselves every few minutes due to normal network fluctuations. With a 1-second timeout, even transactors running in our EC2 test environment would kill themselves roughly every 10–20 minutes. To work around this, Datomic advises that operators run their own supervisor daemons to restart transactors. We used a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/resources/transactor.service">systemd service</a> with <code>Restart=on-failure</code>.</p>
<p>Our test suite included four workloads.</p>
<h2 data-number="2.1" id="list-append"> List Append</h2>
<p>We designed an <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/workload/append.clj#L31-L42">append workload</a> for use with the <a href="https://github.com/jepsen-io/elle">Elle transaction checker</a>. Logically, this workload operates over lists of integer elements, with each list identified by an integer primary key. Clients perform transactions comprising random operations. Each operation may read the current value of a list, or append a unique element to the end of a list. Elle then performs a broad array of checks on the history of transactions. It looks for aborted and intermediate reads, violations of internal consistency, and inconsistent orders of elements across different reads of a list. From the element orders, it infers write-write, write-read, and read-write dependencies between transactions. From the order of transactions on each logical process, and the global order of transactions, it infers per-process and real-time orders, respectively. Elle then searches for cycles in the resulting dependency graphs. Various cycles correspond to violations of different consistency models, like Strict Serializability.</p>
<p>We encoded our lists in Datomic <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L9-L18">as follows</a>. Each list was represented by a single entity with two attributes. One, <code>append/key</code>, served as the primary key. The other, <code>append/elements</code>, was a many-valued attribute which stored all the integer elements in a given list.</p>
<p>Performing the writes in a transaction was straightforward: given a write, we emitted <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L85-L88">a single operation</a> for the transaction stating that the given key now had that element: <code>{:append/key k, :append/elements element}</code>. To perform a read of <code>k</code>, we <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L85-L88">read a local cache of <code>k</code>’s elements</a>. We populated that cache with an <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L68-L72">initial series of read queries</a>, then used a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L77-L90">small state machine</a> to simulate internal reads.</p>
<p>Note that multi-valued attributes represent an unordered <em>set</em>, not an ordered list. Elle’s inference uses the order of list elements to infer the serialization order of transactions. To obtain this order, we took advantage of the fact that Datomic is a temporal database: every datom includes a reference to the transaction which wrote it. When we read the elements for a given key, we also <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L24-L31">included their corresponding transactions</a>. We then <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L37">sorted the elements</a> by transaction times, which provides exactly the order Elle needs.</p>
<p>Elle’s list-append workload is designed for databases which offer mixed read-write transactions, but Datomic doesn’t have this concept. As previously mentioned, any read-write transaction can be expressed in Datomic by running the writes in a transaction function, then using the returned database state to determine what the transaction’s reads would have been. We used this technique in our workload: a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L40">single function</a> executes the transaction, simulates internal reads, and produces side effects (for the write transaction) and completed reads (to be returned to the client). We execute this function twice: <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L139">once using a stored procedure via <code>transact</code></a>, then a second time on the peer to <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append.clj#L144">fill in reads</a>, using the pre-state of the database <code>transact</code> returned.</p>
<h2 data-number="2.2" id="list-append-with-cas"> List Append with CaS</h2>
<p>Many Datomic users use the built-in compare-and-set function <a href="https://docs.datomic.com/pro/transactions/transaction-functions.html#dbfn-cas"><code>db/cas</code></a> to control concurrent updates to an attribute of an entity outside a transaction. For example, they might read the current DB state using <code>d/db</code>, read the value of a counter as <code>4</code>, then increment the counter’s value using <code>[:db/cas 123 :counter/value 4 5]</code>. The CaS function asserts the new value 5 if and only if the current value is 4.</p>
<p>Datomic guarantees transactions are always Serializable, but a user might want to express a logical “user transaction” consisting of a read followed by a separate write transaction. Since Datomic database states are always complete snapshots, and transactions are Serializable, using <code>db/cas</code> for every write<a href="#fn8" id="fnref8" role="doc-noteref"><sup>8</sup></a> allows users to build an ad hoc <a href="https://jepsen.io/consistency/models/snapshot-isolation">Snapshot Isolation</a> over these user transactions.</p>
<p>Our <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/workload/append_cas.clj">append-cas</a> workload provides the same logical API as the list-append workload, but uses this CaS pattern to ensure Snapshot Isolation. Instead of multi-valued elements, we encoded each list <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append_cas.clj#L12-L21">as a single-valued, comma-separated string</a>. We <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append_cas.clj#L142-L143">performed a read</a> at the start of each transaction, <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append_cas.clj#L102-L122">applied reads and writes locally</a>, maintaining a buffer of written values, then <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/append_cas.clj#L81-L95">constructed a transaction</a> of CaS operations which ensured that any values we wrote had not been modified since they were read.</p>
<h2 data-number="2.3" id="internal"> Internal</h2>
<p>Our two list-append workloads measured safety between transactions, but because they simulated the results of internal reads, they did not measure Datomics intra-transaction semantics. We designed an <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/workload/internal.clj">internal</a> workload which measures internal consistency with a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/workload/internal.clj#L129-L270">suite of hand-crafted transactions</a>. For instance, we assert that the value for some attribute of an entity is 1, then 2. We assert and retract a fact in the same transaction. We assert a value, then try to CaS it to something else. We perform multiple CaS operations—trying to change 1 to 2, then 2 to 3. We create an entity, then modify it using a <a href="https://docs.datomic.com/pro/schema/identity.html#lookup-refs">lookup ref</a>. Using a transaction function, we attempt to increment a value twice, and so on.</p>
<h2 data-number="2.4" id="grant"> Grant</h2>
<p>To ensure that transaction functions preserved function invariants, we designed a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/workload/grant.clj#">grant</a> workload which simulates a simple state machine using transaction functions. Grants are first created, then can either be approved or denied. We <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/grant.clj#L11-L23">encode a grant</a> as a single entity with three attributes: <code>created-at</code>, <code>approved-at</code>, and <code>denied-at</code>.</p>
<p>No grant should be <em>both</em> approved and denied. We ensure this invariant by writing a <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/grant.clj#L89-L99">pair of transaction functions</a> <code>approve</code> and <code>deny</code>. Each first checks that the grant under consideration has not been approved or denied already, aborting the transaction if necessary. If the grant hasn’t been approved or denied yet, <code>approve</code> adds the grant’s <code>approved-at</code> date. Our <code>deny</code> function works the same way.</p>
<p>Our grant workload creates a new grant in one transaction. In subsequent transactions it tries to approve and/or deny the grant. We repeat this process, exploring <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/workload/grant.clj#L109-L112">different combinations</a> of functions and transaction boundaries. We check to make sure that no grant is <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/src/jepsen/datomic/workload/grant.clj#L84-L104">both approved and denied</a>.</p>
<h2 data-number="3" id="results"> Results</h2>
<p>We found no behavior which violated Datomic’s core safety claims. Transactions appeared to execute as if they had been applied in a total order, and that order was consistent with the local order of operations on each peer. Histories restricted to just those transactions performing writes, and histories in which reads used <code>(d/sync conn)</code> to obtain a current copy of the database, were consistent with real-time order.</p>
<p>However, we did observe unusual behavior within transactions. This intra-transaction behavior is generally consistent with Datomic’s documentation, but it represents a significant departure both from typical database behavior and the major formalisms used to model transactional isolation. We discuss those divergences here.</p>
<h2 data-number="3.1" id="internal-consistency"> Internal Consistency</h2>
<p>Virtually all databases and formalisms Jepsen is familiar with provide serial execution semantics within a transaction. For example, a transaction like <code>set x = 1; read x;</code> would print <code>1</code>, rather than the value of <code>x</code> when the transaction started.</p>
<p>Although Datomic transactions are <a href="https://docs.datomic.com/pro/transactions/transactions.html#transaction-structure">ordered lists of operations</a>, Datomic does not preserve this order in execution. Instead, all operations within a transaction (adds, retracts, and transaction functions) are executed as if they were concurrent with one another. Transaction functions always observe the state of the database at the beginning of the transaction. They do not observe prior assertions, retractions, or transaction functions. For example, consider <a href="https://s3.amazonaws.com/jepsen.io/analyses/datomic-pro-1.0.7075/internal.zip">these results</a> from our internal workload. Imagine entity <code>123</code> currently has an <code>:internal/value</code> of <code>0</code>, and we execute the following transaction:</p>
<div id="cb2"><pre><code><span id="cb2-1">[[<span>:db/cas</span> <span>123</span> <span>:internal/value</span> <span>0</span> <span>1</span>]</span>
<span id="cb2-2"> [<span>:db/cas</span> <span>123</span> <span>:internal/value</span> <span>0</span> <span>1</span>]]</span></code></pre></div>
<p>In a serial execution model, this transaction would fail: the first CaS would alter the value of key <code>123</code> from <code>0</code> to <code>1</code>, and the second CaS would fail, since the current value was <code>1</code> and not <code>0</code>. In Datomic, both CaS operations observe the initial state <code>0</code>, and both succeed. They produce a pair of redundant assertions <code>[:db/add 123 :interval/value 1]</code>, and the value of entity <code>123</code> becomes <code>1</code>.</p>
<p>This means that state transitions may not compose as one expects. For instance, here is a transaction function that <a href="https://github.com/jepsen-io/datomic/blob/7997e678a1925d2c3a576a728a63bc29a1b1812c/peer/src/jepsen/datomic/peer/internal.clj#L33-L37">increments the value</a> of the entity with key <code>k</code>:</p>
<div id="cb3"><pre><code><span id="cb3-1">(<span>defn</span><span> increment</span></span>
<span id="cb3-2">  [db k]</span>
<span id="cb3-3">  (<span>let</span> [{<span>:keys</span> [id value]} (<span>read</span> db k)]</span>
<span id="cb3-4">    [[<span>:db/add</span> id <span>:internal/value</span> (<span>inc</span> value)]]))</span></code></pre></div>
<p>What value does the following transaction produce, given an entity with key <code>"x"</code> and value <code>0</code>?</p>
<div id="cb4"><pre><code><span id="cb4-1">[[<span>'internal/increment</span> <span>"x"</span>]</span>
<span id="cb4-2"> [<span>'internal/increment</span> <span>"x"</span>]]</span></code></pre></div>
<p>In a serial model, the result of two increments would be <code>2</code>. In Datomic, it’s <code>1</code>: both <code>increment</code> functions receive the database state from the start of the transaction. Similarly, transaction functions do not observe lexically prior assertions or retractions.</p>
<div id="cb5"><pre><code><span id="cb5-1">[[<span>:db/add</span> id-of-x <span>:internal/value</span> <span>1</span>]</span>
<span id="cb5-2"> [<span>'internal/increment</span> <span>"x"</span>]]</span></code></pre></div>
<p>This produces a final value of <code>1</code>, not <code>2</code>.</p>
<p>Likewise, <a href="https://docs.datomic.com/pro/schema/identity.html#lookup-refs">lookup refs</a> use the state of the database as of the start of the transaction. This means a transaction which adds an entity cannot use a lookup ref to refer to it later in that same transaction. The following transaction aborts with an <code>Unable to resolve entity</code> message:</p>
<div id="cb6"><pre><code><span id="cb6-1">[<span>; Create an entity with key "x"</span></span>
<span id="cb6-2"> [<span>:db/add</span> <span>"x"</span> <span>:internal/key</span> <span>"x"</span>]</span>
<span id="cb6-3"> <span>; And set the value of the entity with key x</span></span>
<span id="cb6-4"> <span>; to 0:</span></span>
<span id="cb6-5"> [<span>:db/add</span> [<span>:internal/key</span> <span>"x"</span>] <span>:internal/value</span> <span>0</span>]]</span></code></pre></div>
<p>Many of the above transactions included multiple assertion requests with the same entity, attribute, and value. What happens if the values conflict? Imagine this transaction executes on a state where <code>x</code>’s value is <code>0</code>.</p>
<div id="cb7"><pre><code><span id="cb7-1">[[<span>:db/add</span> id-of-x <span>:internal/value</span> <span>2</span>]</span>
<span id="cb7-2"> [<span>'internal/increment</span> <span>"x"</span>]]</span></code></pre></div>
<p>In a database with serial intra-transaction semantics, this would produce the value <code>3</code>. In Datomic, the increment observes the start-of-transaction value <code>0</code>. It completes successfully, and the transaction expands to the following:</p>
<div id="cb8"><pre><code><span id="cb8-1">[[<span>:db/add</span> id-of-x <span>:internal/value</span> <span>2</span>]</span>
<span id="cb8-2"> [<span>:db/add</span> id-of-x <span>:internal/value</span> <span>1</span>]]</span></code></pre></div>
<p>If this were executed by a serial database, it would produce the value <code>1</code>. But Datomic’s order-free semantics have another rule we have not yet discussed. If two assertions in the same transaction have different values for the same single-cardinality attribute of the same entity, the transaction aborts with <code>:db.error/datoms-conflict</code>. This transaction aborts!</p>
<p>This in-transaction conflict detection mechanism likely rules out many cases where the use of transaction functions would produce surprising results. A pair of increments will silently produce a single increment, but this is only possible because they all expand to compatible <code>[entity, attribute, value]</code> triples. Since there are an infinite number of incompatible values, and a single compatible choice for any <code>[entity, attribute]</code> pair, it seems likely that users who accidentally compose transaction functions incorrectly will find their transactions fail due to conflicts, and recognize their mistake.</p>
<p>This behavior may be surprising, but it is generally consistent with Datomic’s documentation. Nubank does not intend to alter this behavior, and we do not consider it a bug.</p>
<h2 data-number="3.2" id="pseudo-write-skew"> Pseudo Write Skew</h2>
<p>The fact that transactions appear to execute in serial, but the operations <em>within</em> a transaction appear to execute concurrently, creates an apparent paradox. A set of transaction functions might be correct when executed in separate transactions, but <em>incorrect</em> when executed in the same transaction! While Datomic’s in-transaction conflict checker prevents conflicts on a (single-cardinality) <code>[entity, attribute]</code> pair, it does nothing to control concurrency of functions which produce disjoint <code>[entity, attribute]</code> pairs.</p>
<p>We designed the grant workload to illustrate this scenario. Following the <a href="https://web.archive.org/web/20231208204951/https://docs.datomic.com/pro/reference/database-functions.html#uses-for-transaction-functions">documentation’s advice</a> that transaction functions “can atomically analyze and transform database values,” and can be used to “ensure atomic read-modify-update processing, and integrity constraints,” we wrote a pair of transaction functions <code>approve</code> and <code>deny</code>. These functions encode the two legal state transitions for a single grant.</p>
<div id="cb9"><pre><code><span id="cb9-1">(<span>defn</span><span> approved?</span></span>
<span id="cb9-2">  <span>"Has a grant been approved?"</span></span>
<span id="cb9-3">  [db id]</span>
<span id="cb9-4">  (<span>-&gt;</span> '{<span>:find</span>  [?t]</span>
<span id="cb9-5">        <span>:in</span>    [$ ?id]</span>
<span id="cb9-6">        <span>:where</span> [[?id <span>:grant/approved-at</span> ?t]]}</span>
<span id="cb9-7">      (d/q db id)</span>
<span id="cb9-8">      <span>count</span></span>
<span id="cb9-9">      <span>pos?</span>))</span>
<span id="cb9-10"></span>
<span id="cb9-11">(<span>defn</span><span> ensure-fresh</span></span>
<span id="cb9-12">  <span>"Throws if the given grant ID</span></span>
<span id="cb9-13"><span>  is approved or denied."</span></span>
<span id="cb9-14">  [db id]</span>
<span id="cb9-15">  (<span>when</span> (approved? db id)</span>
<span id="cb9-16">    (throw+ {<span>:type</span> <span>:already-approved</span>}))</span>
<span id="cb9-17">  (<span>when</span> (denied? db id)</span>
<span id="cb9-18">    (throw+ {<span>:type</span> <span>:already-denied</span>})))</span>
<span id="cb9-19"></span>
<span id="cb9-20">(<span>defn</span><span> approve</span></span>
<span id="cb9-21">  <span>"Approves a grant by ID. Ensures the</span></span>
<span id="cb9-22"><span>  grant has not been approved or denied."</span></span>
<span id="cb9-23">  [db id]</span>
<span id="cb9-24">  (ensure-fresh db id)</span>
<span id="cb9-25">  [[<span>:db/add</span> id <span>:grant/approved-at</span> (Date.)]])</span></code></pre></div>
<p>The <code>denied?</code> and <code>deny</code> functions are identical to <code>approved?</code> and <code>approve</code>, except they use the <code>denied-at</code> attribute; we omit them for brevity.</p>
<p>By ensuring that the given grant ID is fresh (i.e.&nbsp;neither approved nor denied), these functions ensure an important invariant: no sequence of <code>approve</code> and/or <code>deny</code> calls can produce a grant which is both approved and denied. And indeed, Datomic’s Serializable transactions guarantee this invariant holds—so long as calls to <code>approve</code> and <code>deny</code> only ever take place in <em>different</em> transactions.</p>
<p>However, if a single transaction happens to call both <code>approve</code> and <code>deny</code>, <a href="https://s3.amazonaws.com/jepsen.io/analyses/datomic-pro-1.0.7075/grant.zip">something very interesting occurs</a>:</p>
<div id="cb10"><pre><code><span id="cb10-1">[[<span>'grant/approve</span> id]</span>
<span id="cb10-2"> [<span>'grant/deny</span> id]]</span></code></pre></div>
<p>This transaction produces a grant with the following state:</p>
<div id="cb11"><pre><code><span id="cb11-1">{<span>:db/id</span>             <span>17592186045426</span>,</span>
<span id="cb11-2"> <span>:grant/created-at</span>  #inst <span>"2024-02-01..."</span>,</span>
<span id="cb11-3"> <span>:grant/denied-at</span>   #inst <span>"2024-02-01..."</span>,</span>
<span id="cb11-4"> <span>:grant/approved-at</span> #inst <span>"2024-02-01..."</span>}</span></code></pre></div>
<p>This grant is both approved and denied at the same time. Our invariant has been violated! Datomic’s in-transaction conflict checker did not prevent this behavior because the <code>approve</code> and <code>deny</code> functions returned assertion requests for disjoint <code>[entity, attribute]</code> pairs.</p>

<p>If we were to draw a data dependency graph between these two functions using the language of <a href="https://pmg.csail.mit.edu/papers/adya-phd.pdf">Adya’s formalism</a>, we’d see something like the following:</p>

<p>The <code>approve</code> function wrote a new version of the grant’s <code>approved-at</code> attribute, but when <code>deny</code> read that attribute, it observed the previous (unborn) version from the start-of-transaction database state. This is analogous to a read-write (<code>rw</code>) anti-dependency edge in Adya’s Direct Serialization Graph. Symmetrically, <code>deny</code> wrote a new version of the grant’s <code>denied-at</code> attribute, but <code>approve</code> saw the previous unborn version of <code>denied-at</code>. This gives rise to a dependency cycle: each transaction function failed to observe the other’s effects.</p>
<p>If these <code>approve</code> and <code>deny</code> boxes were transactions, we’d call this cycle G2-item: an isolation anomaly proscribed by <a href="https://jepsen.io/consistency/models/repeatable-read">Repeatable Read</a> and Serializability. Indeed, this phenomenon is analogous to a concurrency anomaly <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-95-51.pdf">Berenson et al called</a> called Write Skew:</p>
<blockquote>
<p>Suppose <code>T1</code> reads x and y, which are consistent with C(), and then a <code>T2</code> reads x and y, writes x, and commits. Then <code>T1</code> writes y. If there were a constraint between x and y, it might be violated.</p>
</blockquote>
<p>There are some similarities between the inter-transaction concurrency control of Berenson et al’s Snapshot Isolation and the intra-transaction concurrency control of Datomic’s end-of-transaction conflict checker. When the write sets (assertion requests) of two transactions (transaction functions) intersect on some object (an entity and cardinality-one attribute), the first-committer-wins principle (conflict checker) prevents concurrent execution by forcing an abort. When their write sets are disjoint, invariants preserved by two transaction functions individually may be violated by the transaction as a whole.</p>
<p>Like the internal consistency findings above, this behavior may be surprising, but it is broadly consistent with Datomic’s documentation. Nubank intends to preserve Datomic’s concurrent intra-transaction semantics. We consider this expected behavior for Datomic, rather than a bug.</p>
<h2 data-number="3.3" id="entity-predicates"> Entity Predicates</h2>
<p>From Datomic’s point of view, the grant workload’s invariant violation is a matter of user error. Transaction functions do not execute atomically in sequence. Checking that a precondition holds in a transaction function is unsafe when some other operation in the transaction could invalidate that precondition!</p>
<p>However, Datomic offers a <a href="https://docs.datomic.com/pro/transactions/transaction-functions.html#when-to-use">suite</a> of constraints for enforcing database invariants, including type, uniqueness, and arbitrary predicates on specific attributes. One of the most general constraints is an <a href="https://docs.datomic.com/pro/schema/schema.html#entity-predicates">entity predicate</a>.</p>
<p>Entity predicates are functions which receive a candidate state of the database with all transaction effects applied, the ID of an entity, and return <code>true</code> if the transaction should be allowed to commit that state. “Entity” is something of a misnomer: these predicates have access to the <em>entire</em> state of the database, and can therefore enforce arbitrary global constraints, not just those scoped to a particular entity.</p>
<p>We can use entity predicates to ensure grants are never approved and denied. To start, we write an entity predicate function <code>valid-grant?</code>.</p>
<div id="cb12"><pre><code><span id="cb12-1">(<span>defn</span><span> valid-grant?</span></span>
<span id="cb12-2">  [db eid]</span>
<span id="cb12-3">  (<span>let</span> [{<span>:grant/keys</span> [approved-at denied-at]}</span>
<span id="cb12-4">        (d/pull db '[<span>:grant/approved-at</span></span>
<span id="cb12-5">                     <span>:grant/denied-at</span>]</span>
<span id="cb12-6">                   eid)]</span>
<span id="cb12-7">   (<span>not</span> (<span>and</span> approved-at denied-at))))</span></code></pre></div>
<p>Then we add an <a href="https://docs.datomic.com/pro/schema/schema.html#entity-specs">entity spec</a> to the schema which references that function.</p>
<div id="cb13"><pre><code><span id="cb13-1">(<span>def</span><span> schema</span></span>
<span id="cb13-2"> [...</span>
<span id="cb13-3">  {<span>:db/ident</span>        <span>:grant/valid</span>?</span>
<span id="cb13-4">   <span>:db.entity/preds</span> [<span>'grant/valid-grant?</span>]</span>
<span id="cb13-5">   <span>:db/doc</span>          <span>"Ensures the given grant</span></span>
<span id="cb13-6"><span>                     is not approved *and*</span></span>
<span id="cb13-7"><span>                     denied"</span>}])</span></code></pre></div>
<p>Unlike other schema constraints, which are enforced for every transaction, entity specs (and their associated entity predicates) are only enforced when transactions explicitly ask for them. Datomic believes that whether or not to enforce an entity spec is a domain decision, and that this approach is more flexible than making entity specs mandatory. Therefore our transition functions assert the grant’s <code>approved-at</code> or <code>denied-at</code> attribute, then <a href="https://github.com/jepsen-io/datomic/blob/0af5c0d5a2e9fdb5baee54378f64c1cc0f496ac0/peer/src/jepsen/datomic/peer/grant.clj#L99-L115">request the entity spec be enforced</a> by adding a special request for a <em>virtual datom</em>, binding the attribute <code>:db/ensure</code> to our entity spec.</p>
<div id="cb14"><pre><code><span id="cb14-1">(<span>defn</span><span> approve</span></span>
<span id="cb14-2">  [db id]</span>
<span id="cb14-3">  [[<span>:db/add</span> id <span>:grant/approved-at</span> (Date.)]</span>
<span id="cb14-4">   [<span>:db/add</span> id <span>:db/ensure</span> <span>:grant/valid</span>?]])</span>
<span id="cb14-5"></span>
<span id="cb14-6">(<span>defn</span><span> deny</span></span>
<span id="cb14-7">  [db id]</span>
<span id="cb14-8">  [[<span>:db/add</span> id <span>:grant/denied-at</span> (Date.)]</span>
<span id="cb14-9">   [<span>:db/add</span> id <span>:db/ensure</span> <span>:grant/valid</span>?]])</span></code></pre></div>
<p>Using this entity spec, attempts to approve and deny a grant within the same transaction <a href="https://s3.amazonaws.com/jepsen.io/analyses/datomic-pro-1.0.7075/grant-entity-pred.zip">throw an error</a>, preserving our intended invariant.</p>
<div id="cb15"><pre><code><span id="cb15-1">{<span>:cognitect.anomalies/category</span></span>
<span id="cb15-2"> <span>:cognitect.anomalies/incorrect</span>,</span>
<span id="cb15-3"> <span>:cognitect.anomalies/message</span></span>
<span id="cb15-4"> <span>"Entity 17592186045427 failed pred</span></span>
<span id="cb15-5"><span>  #'jepsen.datomic.peer.grant/valid-grant?</span></span>
<span id="cb15-6"><span>  of spec :grant/valid?"</span>,</span>
<span id="cb15-7">  <span>:db.error/pred-return</span> <span>false</span>,</span>
<span id="cb15-8">  <span>:db/error</span> <span>:db.error/entity-pred</span>}</span></code></pre></div>
<h2 data-number="4" id="discussion"> Discussion</h2>
<p>In our testing, Datomic’s inter-transaction semantics were consistent with Strong Session Serializability. Intra-transaction semantics appeared strictly concurrent: the operations within a transaction seemed to be executed simultaneously, and the resulting effects merged via set union. This combination satisfies a common high-level definition of Serializability: “equivalence to a serial execution of transactions.” However, it does seem to violate the definitions of Serializability in the most broadly-adopted academic formalisms for transactional isolation. Datomic argues—and Jepsen is willing to entertain—that these formalisms should not be applied to Datomic; they are fundamentally different kinds of databases.</p>
<p>While some details of the documentation were inaccurate or misleading, Datomic’s inter- and intra-transaction behavior appeared consistent with its core safety claims. Indeed, we believe Datomic’s inter-transaction safety properties are stronger than promised.</p>
<p>As always, we caution that Jepsen takes an experimental approach to safety verification: we can prove the presence of bugs, but not their absence. We also note that correctness errors in the storage system underlying Datomic could cause violations of Datomic’s guarantees; Datomic atop DynamoDB is only as safe as DynamoDB’s compare-and-set operation.</p>
<h2 data-number="4.1" id="inter-transaction-semantics"> Inter-Transaction Semantics</h2>
<p>If one considers a session as being bound to a single peer, Datomic appears to guarantee Strong Session Serializability. Histories of transactions appear indistinguishable from one in which those transactions had executed in some total order, and that order is consistent with the order observed on each peer.</p>
<p>Histories restricted to write transactions (i.e.&nbsp;calls to <code>d/transact</code>) appear Strict Serializable. So too do histories where readers use <code>d/sync</code> to obtain an up-to-date state of the database rather than <code>d/db</code>, which could be stale.</p>
<h2 data-number="4.2" id="intra-transaction-semantics"> Intra-Transaction Semantics</h2>
<p>Most transactional systems provide serial semantics within a single transaction.<a href="#fn9" id="fnref9" role="doc-noteref"><sup>9</sup></a> Each operation—writes, reads, procedure calls, etc.—within a transaction appears to take place after the previous operation in that same transaction. This property is explicitly encoded in the major formalisms for transactional isolation. <a href="https://pmg.csail.mit.edu/papers/icde00.pdf">Adya, Liskov, and O’Neil</a> begin their database model by defining transactions as ordered, and explicitly specify later operations observe earlier ones:</p>
<blockquote>
<p>Each transaction reads and writes objects and indicates a total order in which these operations occur….</p>
<p>If an event <span><em>w</em><sub><em>i</em></sub>(<em>x</em><sub><em>i</em>.<em>m</em></sub>)</span> is followed by <span><em>r</em><sub><em>i</em></sub>(<em>x</em><sub><em>j</em></sub>)</span> without an intervening event <span><em>w</em><sub><em>i</em></sub>(<em>x</em><sub><em>i</em>.<em>n</em></sub>)</span> in <span><em>E</em></span>, <span><em>x</em><sub><em>j</em></sub></span> must be <span><em>x</em><sub><em>i</em>.<em>m</em></sub></span>. This condition ensures that if a transaction modiﬁes object <span><em>x</em></span> and later reads <span><em>x</em></span>, it will observe its last update to <span><em>x</em></span>.</p>
</blockquote>
<p>Similarly, the <a href="https://software.imdea.org/~andrea.cerone/works/Framework.pdf">abstract execution formalism</a> of Cerone, Bernardi, and Gotsman defines an <em>internal consistency axiom</em> preserved by all consistency models from Read Atomic through Serializable:</p>
<blockquote>
<p>The internal consistency axiom  ensures that, within a transaction, the database provides sequential semantics: a read from an object returns the same value as the last write to or read from this object in the transaction. In particular,  guarantees that, if a transaction writes to an object and then reads the object, then it will observe its last write.</p>
</blockquote>
<p>Crooks, Alvisi, Pu, and Clement’s <a href="https://www.cs.cornell.edu/lorenzo/papers/Crooks17Seeing.pdf">client-centric formalism</a> similarly specifies transactions include a total order, and uses that order to ensure reads observe the most recent write to that object within the current transaction:</p>
<blockquote>
<p>Further, once an operation in <span><em>T</em></span> writes <span><em>v</em></span> to <span><em>k</em></span>, we require all subsequent operations in <span><em>T</em></span> that read <span><em>k</em></span> to return <span><em>v</em></span>.</p>
</blockquote>
<p>Even as far back as 1979, <a href="https://www.eecs.harvard.edu/~htk/publication/1979-sigmod-kung-papadimitriou.pdf">Kung and Papadimitriou</a> defined transactions as a finite sequence of <em>transaction steps</em>. “Thus, our transactions are straight-line programs,” they explain.</p>
<p>In all of these models, a Serializable system behaves equivalently to one which begins with an initial database state <span><em>d</em><em>b</em><sub>0</sub></span>, picks some transaction <span><em>T</em></span>, applies the first operation in <span><em>T</em></span> producing an intermediate database state <span><em>d</em><em>b</em><sub>0</sub>′</span>, applies the second operation in <span><em>T</em></span> to <span><em>d</em><em>b</em><sub>0</sub>′</span> producing <span><em>d</em><em>b</em><sub>0</sub>″</span>, and so on until the transaction has completed, producing a committed database state <span><em>d</em><em>b</em><sub>1</sub></span>. Then it moves to a second transaction, and the process continues.</p>
<p>Datomic’s semantics are quite different. As previously discussed, the operations within a transaction (assertions, retractions, transaction functions, etc.) are evaluated logically concurrent with one another. Every transaction function in a transaction <span><em>T</em></span> observes the state of the database when <span><em>T</em></span> began, and produces a new set of operations. They do not observe the other assertions, retractions, or functions in <span><em>T</em></span>. These operations are recursively evaluated until only assertions and retractions remain. Those assertions and retractions are merged with set union, checked for conflicts (e.g.&nbsp;contradictory assertions about the value of a single-cardinality attribute on some entity), and then applied to the database state to produce a new, committed version of the database.</p>

<p>This behavior may be surprising to users familiar with other databases, but it is (to some extent) documented. The <a href="https://docs.datomic.com/pro/schema/identity.html#lookup-refs">lookup ref documentation</a> explains that refs use the before-transaction database state. The <a href="https://docs.datomic.com/pro/reference/database-functions.html#processing-transaction-functions">database functions documentation</a> says the transaction processor calls transactions “in turn”, which hints at ordered execution, but explicitly notes that functions are passed “the value of the db (currently, as of the beginning of the transaction).” On the other hand, that same documentation goes on to say that “[t]ransaction functions are serialized by design,” which is true <em>between</em> transactions, but not <em>within</em> them.</p>
<p>Datomic’s concurrent semantics yield advantages and drawbacks. For one, a common axiom of database systems is that committed database state is always <em>consistent</em>, in the business-rules sense. <a href="https://jepsen.io/consistency/models/read-committed">Read Committed</a> and above proscribe phenomenon G1b (<em>intermediate read</em>) in which one transaction sees intermediate state from another transaction. Datomic goes one step further: it is impossible to observe your <em>own</em> transaction’s intermediate state. One can never<a href="#fn10" id="fnref10" role="doc-noteref"><sup>10</sup></a> produce or observe an inconsistent view of the system—full stop! In some sense, the concept of intermediate state is inherently confusing; Datomic does away with it altogether. This choice also simplifies Datomic’s model of time: everything in a transaction happens “at once”, and every datom is <em>always</em> associated with a single, totally-ordered time.</p>
<p>On the other hand, Datomic’s model reintroduces one of the problems Serializability has long been used to prevent. As Papadimitriou’s 1979 paper <a href="https://www.cs.purdue.edu/homes/bb/cs542-06Spr-bb/SCDU-Papa-79.pdf">The Serializability of Concurrent Database Updates</a><a href="#fn11" id="fnref11" role="doc-noteref"><sup>11</sup></a> concisely argues:</p>
<blockquote>
<p>Another way of viewing serializability is as a tool for ensuring system correctness. If each user transaction is correct—i.e., when run by itself, it is guaranteed to map consistent states of the database to consistent states—and transactions are guaranteed to be intermingled in a serializable way, then the overall system is also correct.</p>
</blockquote>
<p>It seems plausible that users would want to write transaction functions that transform data while preserving some kind of correctness invariant. Datomic’s <a href="https://web.archive.org/web/20231208204951/https://docs.datomic.com/pro/reference/database-functions.html#uses-for-transaction-functions">transaction functions documentation</a> originally suggested as much:</p>
<blockquote>
<p>Transaction functions run on the transactor inside of transactions, and thus can atomically analyze and transform database values. You can use them to ensure atomic read-modify-update processing, and integrity constraints… A transaction function can issue queries on the db value it is passed, and can perform arbitrary logic in the programming language.</p>
</blockquote>
<p>If one writes a set of transaction functions which independently preserve some invariant—say, that a grant must never be both approved and also denied, or that the circuits in a home never exceed the capacity of the main panel—one would like to say (analogous to Serializable transactions) that any composition of these functions also preserves that invariant. But as we’ve demonstrated, within a single Datomic transaction this is not true! A transaction which calls multiple transaction functions might produce an outcome incompatible with the atomic application of those functions. It might violate integrity constraints. Paradoxically, combining two transactions into one can actually make the system <em>less</em> safe.</p>
<p>It seems likely that Datomic’s behavior violates the major modern transaction formalisms: Cerone et al’s internal consistency axiom, Adya’s program order, Crooks et al’s in-transaction order, etc. It may be possible to contort Datomic’s model into alignment with these formalisms: say, by defining Datomic as containing only one object (the entire database), or through a non-local translation of Datomic operations to the formalism’s sequence of reads and writes, in which reads are reordered to the beginning of the transaction, and writes to the end. However, these approaches strain intuition. Datomic databases obviously contain independently addressable entities and attributes. Datomic transactions are clearly made up of individual parts, those parts are written in order, and this looks very much like how other databases would express a transaction with serial semantics. Convincing users to ignore that intuition seems a challenging lift.</p>
<p>An easier path might be to abandon these formalisms altogether: they are clearly not designed to apply to Datomic’s concurrent intra-transaction semantics. Instead, we could follow the classic informal definition of Serializability. The internal structure of transactions is completely opaque; all that matters is that the history of transactions is equivalent to one which executed in a serial order. Under this interpretation, Datomic does ensure Serializability, Strong Session Serializability, and so on—just with different intra-transaction rules. To avoid confusion, we carefully distinguish between inter- and intra-transaction consistency throughout this report.</p>
<h2 data-number="4.3" id="recommendations"> Recommendations</h2>
<p>We found no evidence of safety bugs in Datomic, or serious divergence between documentation and system behavior. Datomic’s concurrency architecture is refreshingly straightforward, and its transactional correctness easy to argue. Jepsen believes users can rely on Datomic’s inter-transaction Serializability.</p>
<p>However, Datomic users should be aware of the concurrent execution semantics within transactions. These are specified in the documentation, but remain an unusual choice which creates the potential for subtle invariant violations. Users should be careful when calling multiple transaction functions in the same transaction. In particular, watch out for intersecting read sets and disjoint write sets. Also be aware of the possibility that multiple updates (e.g. increments) to a single value might quietly collapse to a single update.</p>
<p>In practice, we believe several factors protect Datomic users against encountering anomalies. First, users often try to create a schema and use it in the same transaction, or try to use a lookup ref to refer to an entity created in the same transaction. Both of these scenarios fail, which guides users towards re-reading the documentation and internalizing Datomic’s model. Second, the in-transaction conflict checker likely prevents many of the anomalies that could arise from logically-concurrent transaction functions: if two transaction functions produce different values for a single-cardinality attribute of an entity, the transaction aborts.</p>
<p>In addition, users can use <a href="https://docs.datomic.com/pro/schema/schema.html#attribute-predicates">attribute predicates</a> to constrain individual values, and <a href="https://docs.datomic.com/pro/schema/schema.html#entity-specs">entity specs</a> (which must be requested on each transaction) to constrain all attributes of a single entity, or even an entire database. However, users must take care to explicitly request the appropriate entity specs within every transaction that might require them.</p>
<p>Another potential surprise: Datomic goes to great pains to ensure every database state is business-rules consistent: there are no intermediate states, every state is the product of a committed transaction, and so on. However, not all schema constraints apply to extant data. In particular, attribute predicates are only enforced on newly-added datoms, not on existing datoms.</p>
<p>A small operational note: Datomic transactors kill themselves after a few minutes of not being able to talk to storage. We recommended Datomic add a retry loop to make transactors robust to network fluctuations.</p>
<h2 data-number="4.4" id="documentation-changes"> Documentation Changes</h2>
<p>Following our collaboration, Datomic has made extensive revisions to their documentation.</p>
<p>First, we worked together to rewrite Datomic’s <a href="https://docs.datomic.com/pro/transactions/acid.html">transaction safety documentation</a>. It now reflects the stronger safety properties we believe Datomic actually offers: Serializability globally, monotonicity on each peer, and Strict Serializability when restricted to writes, or reads which use <code>sync</code>. Datomic also removed the “single-writer” argument from their safety documentation.</p>
<p>Datomic’s docs now include a <a href="https://docs.datomic.com/pro/transactions/transactions.html">comprehensive explanation</a> of transaction syntax and semantics. It covers the structure of transaction requests, the rules for expanding map forms and transaction functions, and the process of applying a transaction. Expanded documentation for <a href="https://docs.datomic.com/pro/transactions/transaction-functions.html">transaction functions</a> explains Datomic’s various mechanisms for ensuring consistency, how to create and invoke functions, and the behavior of built-in functions. The transaction function documentation no longer says they can be used to “atomically analyze and transform database values”, nor does it claim transaction functions can “ensure atomic read-modify-write processing”.</p>
<p>Datomic <a href="https://web.archive.org/web/20240129122139/https://docs.datomic.com/pro/transactions/transactions.html#transaction-structure">used to refer</a> to the data structure passed to <code>d/transact</code> as a “transaction”, and to its elements as “statements” or “operations”. Going forward, Datomic intends to refer to this structure as a “transaction request”, and to its elements as “data”. The <code>[:db/add ...]</code> and <code>[:db/retract ...]</code> forms are “assertion requests” and “retraction requests,” respectively. This helps distinguish between assertion <em>datoms</em>, which are <code>[entity, attribute, value, transaction, added-or-removed?]</code> tuples, and the incomplete <code>[entity, attribute, value]</code> assertion <em>request</em> in a transaction request.</p>
<p>Datomic has also added documentation <a href="https://docs.datomic.com/pro/tech-notes/comparison-with-updating-transactions.html">arguing for a difference</a> between Datomic transactions and SQL-style “updating transactions.” There is also a new <a href="https://docs.datomic.com/pro/tech-notes/composing-transactions-by-example.html">tech note</a> which discusses the differences between transaction functions and entity predicates when composing transactions.</p>
<h2 data-number="4.5" id="future-work"> Future Work</h2>
<p>Our tests did not evaluate excision or historical queries. Nor did we investigate the Datomic client library—though we believe its behavior is likely similar to the peers we designed in this test. We also limited ourselves to a single storage engine: DynamoDB. Datomic runs atop a variety of storage systems; testing others might be of interest. Finally, we have not evaluated Datomic Cloud, which uses a slightly different architecture.</p>
<p>Jepsen is aware of few systems or formalisms which provide inter-transaction Serializability but intra-transaction concurrent semantics. Datomic’s behavior suggests fascinating research questions.</p>
<p>First, what <em>are</em> Datomic transactions? Is there a sense in which they are a <em>dual</em> to typical database transactions? Rather than happening entirely in series, everything happens all at once. What are the advantages and drawbacks of such a “co-transaction” model? Can the drawbacks be mitigated through static analysis, runtime checks, or API extensions? And does this actually matter in practice, or are users unlikely to write transactions which could violate invariants?</p>
<p>Second, are there other databases with concurrent intra-transaction semantics? Conversely, what about other temporal databases with serial intra-transaction semantics? How does Datomic’s model fit into this landscape?</p>
<p><a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-173.pdf">Alvaro’s Dedalus</a>, a research project exploring temporal Datalog, comes to mind. Like Datomic, its transactions happen “all at once.” As in Datomic, this creates the apparent paradox that breaking up operations into multiple transactions can actually make them safer. Consider also <a href="https://docs.fauna.com/fauna/current/cookbook/basics/update_document">Fauna</a>, a temporal database supporting up to Strong Serializability. Like Datomic, Fauna transactions are small programs that the database evaluates, rather than an interactive session driven by a client. Unlike Datomic, Fauna’s transactions provide (what appears to be) serial execution with incremental side effects within each transaction. Are Fauna’s in-transaction temporal semantics sound? How do their models compare?</p>
<p>The similarity between Datomic’s end-of-transaction conflict checker and Snapshot Isolation’s first-committer-wins rule suggests new research opportunities. How close is the relationship between Snapshot Isolation and Datomic’s in-transaction semantics, and what parts of the existing literature on Snapshot Isolation could we apply to Datomic? Can we show that within a Datomic transaction, cycles between transaction functions must always involve a pair of adjacent read-write anti-dependency edges. Clearly Datomic does not prevent the intra-transaction analogue of lost update, since it collapses multiple increments. What about Fractured Read? Does it allow something like the read-only transaction anomaly described by <a href="https://www.cs.umb.edu/~poneil/ROAnom.pdf">Fekete, O’Neil, and O’Neil</a>? Or <a href="https://www.news.cs.nyu.edu/~jinyang/pub/walter-sosp11.pdf">Long Fork</a>? Are there analogues to other G2-item and G2 cycles, perhaps involving predicates?</p>
<p>Finally, one wonders whether there might be a connection to <a href="https://arxiv.org/pdf/1901.01930.pdf">Hellerstein &amp; Alvaro’s CALM theorem</a>. Could we show, for instance, that transaction functions which are logically monotonic are safe to combine in a single Datomic transaction? Datalog programs without negation are logically monotonic. Can we show that those programs are also safe under this execution model? Jepsen encourages future research.</p>
<p><em>Jepsen wishes to thank the entire Datomic team at Nubank, and in particular Dan De Aguiar, Guilherme Baptista, Adrian Cockcroft, Stuart Halloway, Keith Harper, and Chris Redinger. Peter Alvaro offered key insights into concurrent semantics. <a href="https://www.irenekannyo.com/">Irene Kannyo</a> provided invaluable editorial support. This work was funded by <a href="https://nubank.com.br/en/">Nubank</a> (Nu Pagamentos S.A), and conducted in accordance with the <a href="https://jepsen.io/ethics">Jepsen ethics policy</a>.</em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>Datomic also provides an <a href="https://docs.datomic.com/pro/reference/excision.html">excision</a> mechanism which rewrites history to permanently delete datoms. This is useful for regulatory compliance or removing unwanted PII.<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Girls!<a href="#fnref2" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Datomic refers to an immutable version of the database as a “value”. To avoid confusion with other kinds of values in this report, we call this a “database state”.<a href="#fnref3" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>Most systems use “transaction” to refer to a group of operations, including reads or writes, executed as a unit. Datomic uses “transaction” to refer specifically to a write transaction—i.e.&nbsp;a call to <a href="https://docs.datomic.com/pro/clojure/index.html#datomic.api/transact"><code>d/transact</code></a>. However, Datomic’s reads are trivially transactional as well. We refer to both reads and writes as transactions in this work—it significantly simplifies our discussion of consistency models.<a href="#fnref4" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>At the start of our collaboration, Datomic used “statement”, “operation”, and “data” to refer to elements of a transaction. We use “operation” in this report for consistency with the database literature, and to avoid confusion with other kinds of data. Datomic intends to refer to transaction elements solely as “data” going forward.<a href="#fnref5" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>Datomic wishes to note that transaction functions (for instance, <code>db/cas</code>) do not actually perform writes. They produce data structures which represent <em>requests</em> for writes. Those writes are performed during the final stages of transaction execution. Delayed evaluation of transaction effects is a common database technique; we use the term “write” loosely with this understanding.<a href="#fnref6" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>As Fekete, O’Neil, and O’Neil point out, adding read-only transactions to a history which is otherwise Serializable can <a href="https://www.cs.umb.edu/~poneil/ROAnom.pdf">actually yield non-Serializable histories</a>! However, this paper applies specifically to Snapshot Isolation, where two transactions may read the same state and write new values concurrently. Datomic’s design ensures transactions are atomic, in the sense that no two transactions overlap in the window between their read and write timestamps.<a href="#fnref7" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>We say “every” write for safety and clarity. In practice, users often arrange for all transactions requiring concurrency control to conflict on a single attribute of an entity. A single CaS operation on, say, a customer’s <code>version</code> attribute could ensure that any number of updates to that customer occur sequentially.<a href="#fnref8" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>Of course, typical Serializable databases may not <em>actually</em> execute operations in serial order. However, they (ought to) behave indistinguishably from a system which had. Similarly, Datomic may not execute transaction functions in parallel—but it guarantees concurrent semantics. For concision, we say “serial semantics” instead of “behavior which is indistinguishable from a serial execution,” and so on.<a href="#fnref9" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>Unless one produces new, transient database states using <code>d/with</code>.<a href="#fnref10" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>Intriguingly, Papadimitriou’s paper begins with transactions which perform a set of reads, then a set of writes; this formalism might be more readily applicable to Datomic transactions. Later in the paper he addresses “multistep transactions,” which are analogous to the serial formalisms discussed in this section.<a href="#fnref11" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
  </div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Tarsier – Vision utilities for web interaction agents (151 pts)]]></title>
            <link>https://github.com/reworkd/tarsier</link>
            <guid>40369319</guid>
            <pubDate>Wed, 15 May 2024 16:46:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/reworkd/tarsier">https://github.com/reworkd/tarsier</a>, See on <a href="https://news.ycombinator.com/item?id=40369319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/reworkd/Tarsier/main/.github/assets/tarsier.png"><img src="https://raw.githubusercontent.com/reworkd/Tarsier/main/.github/assets/tarsier.png" height="300" alt="Tarsier Monkey"></a>
</p>
<p dir="auto">
  <em>🙈 Vision utilities for web interaction agents 🙈</em>
</p>
<p dir="auto">
    <a href="https://pypi.org/project/tarsier/" rel="nofollow">
        <img alt="Python" src="https://camo.githubusercontent.com/0562f16a4ae7e35dae6087bf8b7805fb7e664a9e7e20ae6d163d94e56b94f32d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d3336373041303f7374796c653d666f722d7468652d6261646765266c6f676f3d707974686f6e266c6f676f436f6c6f723d666664643534" data-canonical-src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&amp;logo=python&amp;logoColor=ffdd54">
        <img alt="Version" src="https://camo.githubusercontent.com/e3c0bb6224b756f0057970306b1daf2b9d4f063ce276f67a892cbbdac4c82ccb/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f746172736965723f7374796c653d666f722d7468652d626164676526636f6c6f723d333637304130" data-canonical-src="https://img.shields.io/pypi/v/tarsier?style=for-the-badge&amp;color=3670A0">
    </a>
</p>
<p dir="auto">
<a href="https://reworkd.ai/" rel="nofollow">🔗 Main site</a>
<span>&nbsp;&nbsp;•&nbsp;&nbsp;</span>
<a href="https://twitter.com/khoomeik/status/1723432848739483976" rel="nofollow">🐦 Twitter</a>
<span>&nbsp;&nbsp;•&nbsp;&nbsp;</span>
<a href="https://discord.gg/gcmNyAAFfV" rel="nofollow">📢 Discord</a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tarsier</h2><a id="user-content-tarsier" aria-label="Permalink: Tarsier" href="#tarsier"></a></p>
<p dir="auto">If you've tried using an LLM to automate web interactions, you've probably run into questions like:</p>
<ul dir="auto">
<li>How should you feed the webpage to an LLM? (e.g. HTML, Accessibility Tree, Screenshot)</li>
<li>How do you map LLM responses back to web elements?</li>
<li>How can you inform a text-only LLM about the page's visual structure?</li>
</ul>
<p dir="auto">At Reworkd, we iterated on all these problems across tens of thousands of real web tasks to build a powerful perception system for web agents... Tarsier!
In the video below, we use Tarsier to provide webpage perception for a minimalistic GPT-4 LangChain web agent.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description tarsier.mp4">tarsier.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/50181239/282260008-af12beda-89b5-4add-b888-d780b353304b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTU4MDcxMDQsIm5iZiI6MTcxNTgwNjgwNCwicGF0aCI6Ii81MDE4MTIzOS8yODIyNjAwMDgtYWYxMmJlZGEtODliNS00YWRkLWI4ODgtZDc4MGIzNTMzMDRiLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MTUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTE1VDIxMDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTBkMTM0M2YwNTkzYzkzYjc0NjU3ZDU4MmFiMjMxNjI0MGYyNDc4MTNiNWM2MTk5OTlkYTVjMTEzZDZiZDE1Y2YmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.VKHJqRjEIxRLBSfqvLGG3AWyAX4CPBHTLOFIIRMxnlw" data-canonical-src="https://private-user-images.githubusercontent.com/50181239/282260008-af12beda-89b5-4add-b888-d780b353304b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTU4MDcxMDQsIm5iZiI6MTcxNTgwNjgwNCwicGF0aCI6Ii81MDE4MTIzOS8yODIyNjAwMDgtYWYxMmJlZGEtODliNS00YWRkLWI4ODgtZDc4MGIzNTMzMDRiLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MTUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTE1VDIxMDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTBkMTM0M2YwNTkzYzkzYjc0NjU3ZDU4MmFiMjMxNjI0MGYyNDc4MTNiNWM2MTk5OTlkYTVjMTEzZDZiZDE1Y2YmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.VKHJqRjEIxRLBSfqvLGG3AWyAX4CPBHTLOFIIRMxnlw" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">How does it work?</h2><a id="user-content-how-does-it-work" aria-label="Permalink: How does it work?" href="#how-does-it-work"></a></p>
<p dir="auto">Tarsier visually tags interactable elements on a page via brackets + an ID e.g. <code>[23]</code>.
In doing this, we provide a mapping between elements and IDs for an LLM to take actions upon (e.g. <code>CLICK [23]</code>).
We define interactable elements as buttons, links, or input fields that are visible on the page; Tarsier can also tag all textual elements if you pass <code>tag_text_elements=True</code>.</p>
<p dir="auto">Furthermore, we've developed an OCR algorithm to convert a page screenshot into a whitespace-structured string (almost like ASCII art) that an LLM <em>even without vision</em> can understand.
Since current vision-language models still lack fine-grained representations needed for web interaction tasks, this is critical.
On our internal benchmarks, unimodal GPT-4 + Tarsier-Text beats GPT-4V + Tarsier-Screenshot by 10-20%!</p>
<table>
<thead>
<tr>
<th>Tagged Screenshot</th>
<th>Tagged Text Representation</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/reworkd/tarsier/blob/main/.github/assets/tagged.png"><img src="https://github.com/reworkd/tarsier/raw/main/.github/assets/tagged.png" alt="tagged"></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/reworkd/tarsier/blob/main/.github/assets/tagged_text.png"><img src="https://github.com/reworkd/tarsier/raw/main/.github/assets/tagged_text.png" alt="tagged"></a></td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Visit our <a href="https://github.com/reworkd/Tarsier/tree/main/cookbook">cookbook</a> for agent examples using Tarsier:</p>
<ul dir="auto">
<li><a href="https://github.com/reworkd/tarsier/blob/main/cookbook/langchain-web-agent.ipynb">An autonomous LangChain web agent</a> 🦜⛓️</li>
<li><a href="https://github.com/reworkd/tarsier/blob/main/cookbook/llama-index-web-agent.ipynb">An autonomous LlamaIndex web agent</a> 🦙</li>
</ul>
<p dir="auto">Otherwise, basic Tarsier usage might look like the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import asyncio

from playwright.async_api import async_playwright
from tarsier import Tarsier, GoogleVisionOCRService
import json

def load_google_cloud_credentials(json_file_path):
    with open(json_file_path) as f:
        credentials = json.load(f)
    return credentials

async def main():
    # To create the service account key, follow the instructions on this SO answer https://stackoverflow.com/a/46290808/1780891
    google_cloud_credentials = load_google_cloud_credentials('./google_service_acc_key.json')

    ocr_service = GoogleVisionOCRService(google_cloud_credentials)
    tarsier = Tarsier(ocr_service)

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()
        await page.goto(&quot;https://news.ycombinator.com&quot;)

        page_text, tag_to_xpath = await tarsier.page_to_text(page)

        print(tag_to_xpath)  # Mapping of tags to x_paths
        print(page_text)  # My Text representation of the page


if __name__ == '__main__':
    asyncio.run(main())"><pre><span>import</span> <span>asyncio</span>

<span>from</span> <span>playwright</span>.<span>async_api</span> <span>import</span> <span>async_playwright</span>
<span>from</span> <span>tarsier</span> <span>import</span> <span>Tarsier</span>, <span>GoogleVisionOCRService</span>
<span>import</span> <span>json</span>

<span>def</span> <span>load_google_cloud_credentials</span>(<span>json_file_path</span>):
    <span>with</span> <span>open</span>(<span>json_file_path</span>) <span>as</span> <span>f</span>:
        <span>credentials</span> <span>=</span> <span>json</span>.<span>load</span>(<span>f</span>)
    <span>return</span> <span>credentials</span>

<span>async</span> <span>def</span> <span>main</span>():
    <span># To create the service account key, follow the instructions on this SO answer https://stackoverflow.com/a/46290808/1780891</span>
    <span>google_cloud_credentials</span> <span>=</span> <span>load_google_cloud_credentials</span>(<span>'./google_service_acc_key.json'</span>)

    <span>ocr_service</span> <span>=</span> <span>GoogleVisionOCRService</span>(<span>google_cloud_credentials</span>)
    <span>tarsier</span> <span>=</span> <span>Tarsier</span>(<span>ocr_service</span>)

    <span>async</span> <span>with</span> <span>async_playwright</span>() <span>as</span> <span>p</span>:
        <span>browser</span> <span>=</span> <span>await</span> <span>p</span>.<span>chromium</span>.<span>launch</span>(<span>headless</span><span>=</span><span>False</span>)
        <span>page</span> <span>=</span> <span>await</span> <span>browser</span>.<span>new_page</span>()
        <span>await</span> <span>page</span>.<span>goto</span>(<span>"https://news.ycombinator.com"</span>)

        <span>page_text</span>, <span>tag_to_xpath</span> <span>=</span> <span>await</span> <span>tarsier</span>.<span>page_to_text</span>(<span>page</span>)

        <span>print</span>(<span>tag_to_xpath</span>)  <span># Mapping of tags to x_paths</span>
        <span>print</span>(<span>page_text</span>)  <span># My Text representation of the page</span>


<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span>:
    <span>asyncio</span>.<span>run</span>(<span>main</span>())</pre></div>
<p dir="auto">Keep in mind that Tarsier tags different types of elements differently to help your LLM identify what actions are performable on each element. Specifically:</p>
<ul dir="auto">
<li><code>[#ID]</code>: text-insertable fields (e.g. <code>textarea</code>, <code>input</code> with textual type)</li>
<li><code>[@ID]</code>: hyperlinks (<code>&lt;a&gt;</code> tags)</li>
<li><code>[$ID]</code>: other interactable elements (e.g. <code>button</code>, <code>select</code>)</li>
<li><code>[ID]</code>: plain text (if you pass <code>tag_text_elements=True</code>)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Local Development</h2><a id="user-content-local-development" aria-label="Permalink: Local Development" href="#local-development"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Setup</h3><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<p dir="auto">We have provided a handy setup script to get you up and running with Tarsier development.</p>

<p dir="auto">If you modify any TypeScript files used by Tarsier, you'll need to execute the following command.
This compiles the TypeScript into JavaScript, which can then be utilized in the Python package.</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Testing</h3><a id="user-content-testing" aria-label="Permalink: Testing" href="#testing"></a></p>
<p dir="auto">We use <a href="https://docs.pytest.org/" rel="nofollow">pytest</a> for testing. To run the tests, simply run:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Linting</h3><a id="user-content-linting" aria-label="Permalink: Linting" href="#linting"></a></p>
<p dir="auto">Prior to submitting a potential PR, please run the following to format your code:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Supported OCR Services</h2><a id="user-content-supported-ocr-services" aria-label="Permalink: Supported OCR Services" href="#supported-ocr-services"></a></p>
<ul>
<li> <a href="https://cloud.google.com/vision" rel="nofollow">Google Cloud Vision</a></li>
<li> <a href="https://aws.amazon.com/textract/" rel="nofollow">Amazon Textract</a> (Coming Soon)</li>
<li> <a href="https://azure.microsoft.com/en-us/services/cognitive-services/computer-vision/" rel="nofollow">Microsoft Azure Computer Vision</a> (Coming Soon)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<ul>
<li> Add documentation and examples</li>
<li> Clean up interfaces and add unit tests</li>
<li> Launch</li>
<li> Improve OCR text performance</li>
<li> Add options to customize tagging styling</li>
<li> Add support for other browsers drivers as necessary</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citations</h2><a id="user-content-citations" aria-label="Permalink: Citations" href="#citations"></a></p>
<div data-snippet-clipboard-copy-content="bibtex
@misc{reworkd2023tarsier,
  title        = {Tarsier},
  author       = {Rohan Pandey and Adam Watkins and Asim Shrestha and Srijan Subedi},
  year         = {2023},
  howpublished = {GitHub},
  url          = {https://github.com/reworkd/tarsier}
}"><pre><code>bibtex
@misc{reworkd2023tarsier,
  title        = {Tarsier},
  author       = {Rohan Pandey and Adam Watkins and Asim Shrestha and Srijan Subedi},
  year         = {2023},
  howpublished = {GitHub},
  url          = {https://github.com/reworkd/tarsier}
}
</code></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Three of the oldest stars in the universe found circling the Milky Way (107 pts)]]></title>
            <link>https://news.mit.edu/2024/mit-researchers-discover-universes-oldest-stars-in-galactic-backyard-0514</link>
            <guid>40369226</guid>
            <pubDate>Wed, 15 May 2024 16:40:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.mit.edu/2024/mit-researchers-discover-universes-oldest-stars-in-galactic-backyard-0514">https://news.mit.edu/2024/mit-researchers-discover-universes-oldest-stars-in-galactic-backyard-0514</a>, See on <a href="https://news.ycombinator.com/item?id=40369226">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
          

            <p>MIT researchers, including several undergraduate students, have discovered three of the oldest stars in the universe, and they happen to live in our own galactic neighborhood.</p><p>The team spotted the stars in the Milky Way’s “halo” — the cloud of stars that&nbsp;envelopes the entire&nbsp;main galactic disk. Based on the team’s analysis, the three stars formed between 12 and 13 billion years ago, the time when the very first galaxies were taking shape.</p><p>The researchers have coined the stars “SASS,” for Small Accreted Stellar System stars, as they believe each star once belonged to its own small, primitive galaxy that was later absorbed by&nbsp;the&nbsp;larger&nbsp;but still growing&nbsp;Milky Way. Today, the three stars are all that are left of their respective galaxies. They circle the outskirts of the Milky Way, where the team suspects there may be more such ancient stellar survivors.</p><p>“These oldest stars should definitely be there, given what we know of galaxy formation,” says MIT professor of physics Anna Frebel. “They are part of our cosmic family tree. And we now have a new way to find them.”</p><p>As they uncover similar SASS stars, the researchers hope to use them as analogs of ultrafaint dwarf galaxies, which are thought to be some of the universe’s&nbsp;surviving&nbsp;first galaxies. Such galaxies are still intact today but are too distant and faint for astronomers to study in depth. As SASS stars may have once belonged to similarly primitive dwarf galaxies but are&nbsp;in the Milky Way and as such&nbsp;much closer, they could be an accessible key to understanding the evolution of ultrafaint dwarf galaxies.</p><p>“Now we can look for more analogs in the Milky Way, that are much brighter, and study their chemical evolution without having to chase these extremely faint stars,” Frebel says.</p><p>She and her colleagues have <a href="https://doi.org/10.1093/mnras/stae670" target="_blank">published their findings today</a> in the <em>Monthly Notices of the Royal Astronomical Society (MNRAS)</em>. The study’s co-authors are Mohammad Mardini, at&nbsp;Zarqa University, in Jordan; Hillary Andales ’23; and current MIT undergraduates Ananda Santos and Casey Fienberg.</p><p><strong>Stellar frontier</strong></p><p>The team’s discoveries grew out of a classroom&nbsp;concept. During the 2022 fall semester, Frebel launched a new course, 8.S30<em>&nbsp;</em>(Observational Stellar Archaeology), in which students learned techniques for analyzing ancient stars and then applied those tools to stars that had never been studied before, to determine their origins.</p><p>“While most of our classes are taught from the ground up, this class immediately put us at the frontier of research in astrophysics,” Andales says.</p><p>The students worked from star data collected by Frebel over the years from&nbsp;the 6.5-meter Magellan-Clay telescope&nbsp;at the Las Campanas Observatory. She keeps hard copies of the data in a large binder in her office, which the students combed through to look for stars of interest.</p><p>In particular, they were searching ancient stars that formed&nbsp;soon after the Big Bang, which occurred&nbsp;13.8 billion years ago. At this time, the universe was made mostly of hydrogen and helium and very low abundances of other chemical elements, such as strontium and barium. So, the students looked through Frebel’s binder for stars with spectra, or measurements of starlight, that indicated low abundances of strontium and barium.</p><p>Their search narrowed in on three stars that were originally observed by the Magellan&nbsp;telescope&nbsp;between 2013 and 2014. Astronomers never followed up on these particular stars to interpret their spectra and deduce their origins. They were, then, perfect candidates for the students in Frebel’s class.</p><p>The students&nbsp;learned how to characterize a star in order to prepare for the analysis of&nbsp;the spectra for each of the three stars. They&nbsp;were able to determine the chemical composition of each one with&nbsp;various&nbsp;stellar&nbsp;models.&nbsp;The intensity of a particular&nbsp;feature in the stellar spectrum, corresponding to a specific&nbsp;wavelength of light, corresponds to a particular abundance of a specific element.</p><p>After&nbsp;finalizing their analysis, the students were able to confidently conclude that the three stars did hold very low abundances of strontium, barium, and other&nbsp;elements such as iron, compared to their&nbsp;reference&nbsp;star — our own sun. In fact, one star contained less than 1/10,000 the amount of iron to helium compared to the sun today.</p><p>“It took a lot of hours staring at a computer, and a lot of debugging, frantically texting and emailing each other to figure this out,” Santos recalls. “It was a big learning curve, and a special experience.”</p><p><strong>“On the run”</strong></p><p>The stars’ low chemical abundance did hint that they originally formed 12 to 13 billion years ago. In fact, their low chemical signatures were similar to what astronomers had previously measured for some ancient, ultrafaint dwarf galaxies. Did the team’s stars originate in similar galaxies? And how did they come to be in the Milky Way?</p><p>On a hunch, the scientists checked out the stars’ orbital patterns and how they move across the sky. The three stars are in different locations throughout the Milky Way’s halo and are estimated to be about 30,000 light years from Earth. (For reference, the disk of the Milky Way spans 100,000 light years across.)</p><p>As they retraced each star’s motion&nbsp;about the galactic center using observations from the Gaia astrometric satellite, the team noticed a curious thing: Relative to most of the stars in the main disk, which move like cars on a racetrack, all three stars seemed to be going the wrong way. In astronomy, this is known as “retrograde motion” and is a tipoff that an object was once “accreted,” or drawn in from elsewhere.</p><p>“The only way you can have stars going the wrong way from the rest of the gang is if you threw them in the wrong way,” Frebel says.</p><p>The fact that these three stars were orbiting in completely different ways from the rest of the galactic disk and even the halo, combined with the fact that they held low chemical abundances, made a strong case that the stars were indeed ancient and once belonged to older, smaller dwarf galaxies that fell into the Milky Way at random angles and continued their stubborn trajectories billions of years later.</p><p>Frebel, curious as to whether retrograde motion was a feature of other ancient stars in the halo that astronomers previously analyzed, looked through the scientific literature and found 65 other stars, also with low strontium and barium abundances, that appeared to also be going against the galactic flow.</p><p>“Interestingly they’re all quite fast — hundreds of kilometers per second, going the wrong way,” Frebel says. “They’re on the run! We don’t know why that’s the case, but&nbsp;it was the piece to the puzzle that we needed, and that I didn’t quite anticipate when we started.”</p><p>The team is eager to search out other ancient SASS stars, and they now have a relatively simple recipe to do so: First, look for stars with low chemical abundances, and then track their orbital patterns for signs of retrograde motion. Of the more than 400 billion stars in the Milky Way, they anticipate that the method will turn up a small but significant number of the universe’s oldest stars.</p><p>Frebel plans to relaunch the class&nbsp;this&nbsp;fall, and looks back at that first course, and the three students who took their results through to publication, with admiration and gratitude.</p><p>“It’s been awesome to work with three women undergrads. That’s a first for me,” she says. “It’s really an example of the MIT way. We do. And whoever says, ‘I want to participate,’ they can do that, and good things happen.”</p><p>This research was supported, in part, by the National Science Foundation.</p>        

      </div><div>
  
  
  

      <header>
      <h2>Press Mentions</h2>
    </header>
  
  
  

  <div><h3>Gizmodo</h3><p>Isaac Schultz of <em>Gizmodo</em> reports on recent research by Prof. Anna Frebel and colleagues identifying some of the oldest&nbsp;stars in our universe, which grew from Frebel’s new course, 8.S30 (Observational Stellar Archaeology). “Studying the ancient stars won’t only help explain the timeline of stellar evolution, but how our galaxy actually formed,” Schultz explains.&nbsp;</p></div>


    

  
  

  
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Starting emails with "BEGIN PGP MESSAGE" will fool the filter (146 pts)]]></title>
            <link>https://nondeterministic.computer/@martin/112444389342113780</link>
            <guid>40369119</guid>
            <pubDate>Wed, 15 May 2024 16:32:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nondeterministic.computer/@martin/112444389342113780">https://nondeterministic.computer/@martin/112444389342113780</a>, See on <a href="https://news.ycombinator.com/item?id=40369119">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Reasons not to take Lumina's anticavity probiotic (180 pts)]]></title>
            <link>https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity</link>
            <guid>40369084</guid>
            <pubDate>Wed, 15 May 2024 16:29:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity">https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity</a>, See on <a href="https://news.ycombinator.com/item?id=40369084">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>I like to think of the Bay Area intellectual culture as the equivalent of the Vogons’ in </span><em>Hitchhiker’s Guide to the Galaxy</em><span>. The Vogons, if you don’t remember, are an alien species who demolish Earth to build an interstellar highway. Similarly, Bay Area intellectuals tend to see some goal in the future that they want to get to and they make a straight line for it, tunneling through anything in their way.&nbsp;</span></p><p>Sometimes this Bay Area tunneling produces great results and benefits a lot of people. Sometimes it produces terrible results and harms a lot of people. But, regardless of the quality of the results, it always leaves behind a hole.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg" width="512" height="288.0450070323488" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:1422,&quot;resizeWidth&quot;:512,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Vogon poetry is the third worst in the Universe. The second worst is that  of the Azgoths...\&quot; - The Hitchhiker's Guide to the Galaxy quote&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="Vogon poetry is the third worst in the Universe. The second worst is that  of the Azgoths...&quot; - The Hitchhiker's Guide to the Galaxy quote" title="Vogon poetry is the third worst in the Universe. The second worst is that  of the Azgoths...&quot; - The Hitchhiker's Guide to the Galaxy quote" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c1625be-3458-4d30-b76a-9954b252fd1a_1422x800.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><span>“You see, your response of ‘You should probably do at least a little bit of research before confidently stating your opinion on a technical topic’ was a clear example of an </span><em>ad hominem</em><span> fallacy, which is explained here on page 495 of the Sequences. Allow me to read this whole chapter to you…”</span></figcaption></figure></div><p>Speaking of holes, in my weird, nerdy corner of the Internet, there’s recently been a hubbub around an anticavity probiotic, Lumina Probiotic, coming straight from the Bay Area. In the literal sense, this probiotic is meant to prevent holes (in teeth). In the more metaphorical sense, though, it fits in well with previous Bay Area fads, tunneling not only through the dentistry industry but also through the FDA approval process. You see, despite this being clearly a drug and thus under FDA/CDER purview, the founder of Lumina, Aaron Silverbook, has decided to sell this directly to the public as a cosmetic product without doing the requisite safety and efficacy tests.</p><p>In case you can’t tell by the title of the post, I think this is a terrible idea, as well as probably illegal. Unlike most people in the Bay Area, I think formalized safety and efficacy trials are a must for health products. In fact, I told Aaron Silverbook this when he asked me for my advice about his product last fall. No, the FDA is not a perfect institution, and yes, it can be improved in many, many ways. But the history of health product regulation is written in blood. There’s a reason why we need some sort of regulation, even if that form of regulation can be improved.</p><p><span>I’ve been annoyed for some months now to see Lumina sell their product directly to the public without FDA approval or even human trials. I’ve also been disappointed for some months to see how many people I respect (and some I don’t respect) have been using it/promoting it. Taking unapproved drugs is a bad idea, no matter what rationalist bloggers with MDs, porn star/escort/sex researchers, Twitter guys, or </span><a href="https://manifold.markets/Reddit/will-richard-hanania-find-out-his-r" rel="">conservative firebrands who get sick immediately after taking the unapproved drug</a><span> tell you.</span></p><p>Despite my annoyance, I had resigned myself to just grumbling about Lumina to my friends. That is, until last week, when I randomly started looking more deeply into some of Lumina’s claims as part of an unrelated project. As I looked more deeply, I became convinced that many of Lumina’s claims are unfounded, and it is, in fact, simultaneously a more dangerous and less effective drug than Lumina or its boosters have been publicly saying that it is. So, I thought it’d be best to write a blog post and share my criticisms to stop people from getting sick from a bad drug.</p><p><span>Also, before I start, I did only think it fair to ask Aaron Silverbook for his comments on this blog post before publishing. So far, I haven’t heard back</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-1-144660269" target="_self" rel="">1</a></span><span>, but I will update this post if I do. With that in mind, let’s begin.</span></p><p><span>Your mouth has a bunch of bacteria in it all the time. In a healthy mouth, these bacteria are useful insofar as they prevent other, worse bacteria from taking up residence in your mouth. However, these bacteria, like the bacteria in your </span><a href="https://trevorklee.substack.com/p/ground-squirrel-microbiomes-are-neat/comments" rel="">gut</a><span> or </span><a href="https://trevorklee.substack.com/p/bacterial-vaginosis-we-contain-multitudes?r=3ege4" rel="">vagina</a><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-2-144660269" target="_self" rel="">2</a></span><span> (assuming you have one) are only “good” insofar as your body can keep them in check, mostly through flushing the bacteria from your mouth to your stomach via swallowing, at which point they get destroyed by stomach acid.</span></p><p>Sometimes your body can’t keep these bacteria in check, like when defense mechanisms fail (e.g. persistent lack of saliva) or the mouth becomes more hospitable for the bacteria (e.g. excess of sugar). The bacteria start to overgrow. And when you give bacteria an inch, they take a mile, fortifying their position. The most important way they do that in the mouth is by forming biofilms on the teeth (dental plaque), which are “bacterial cities”. These biofilms are mutual aid pacts, in which bacteria share defenses, nutrients, and swap useful genes.</p><p><span>In the mouth, the biofilms also help the bacteria produce a more hospitable habitat for themselves. These bacteria, specifically </span><em>Streptococcus mutans, Streptococcus sobrinus, </em><span>and lactobacilli produce lactic acid through their metabolism. This not only changes the local environment to be a more preferable pH, but it also lets them create pits in teeth by demineralizing the teeth to live in. These pits, if they don’t get remineralized by the saliva, become cavities.</span></p><p>This is all pretty settled science. Brushing your teeth with a fluoride-enhanced toothpaste, like you’ve probably done your entire life, is meant to disrupt these biofilms and promote remineralization of these pits. The newer, less settled science mostly revolves around ways to combat these cavity-causing bacteria directly. There have been various attempts to create vaccines or antibiotics for these bacteria, none of which have been amazingly successful.</p><p>One inventor who’s tried repeatedly to address this issue is a guy named Jeffrey Hillman, who’s technically a dentist by training. Starting in the 80s and continuing through the 2000s, he tried to make an idea work where he would genetically engineer safe bacteria to outcompete the bacteria in the mouth that cause cavities and then permanently reside in the mouth. The result would be a mouth permanently full of safe bacteria that couldn’t possibly cause cavities and would beat up any dangerous bacteria that would.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg" width="634" height="356" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:356,&quot;width&quot;:634,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Wonka's Origins Charlie And The Chocolate Factory, 40% OFF&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Wonka's Origins Charlie And The Chocolate Factory, 40% OFF" title="Wonka's Origins Charlie And The Chocolate Factory, 40% OFF" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd15edb2e-1a05-4af8-b8ab-72683260b31c_634x356.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>Pictured: Jeffrey Hillman’s origin story. Any resemblance to Tim Burton’s 2005 remake of </span><em>Willy Wonka</em><span> is purely coincidental. Ignore the Warner Bros. copyright in the corner. </span></figcaption></figure></div><p><span>His ideas around this went through several iterations, a lot of money (definitely tens of millions and possibly more), and several companies, most notably Oragenics. After a number of rat trials (which </span><a href="https://twitter.com/natalia__coelho/status/1778537436446117985?utm_source=substack&amp;utm_medium=email" rel="">weren’t entirely successful</a><span>), one or two aborted human trials</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-3-144660269" target="_self" rel="">3</a></span><span>, and two bouts of self-experimentation, the idea died on the vine in the 2000s. Then, it was reborn in a less exciting way as </span><a href="https://probiorahealth.com/patented-formula/" rel="">ProBiora</a><span>, a formulation of specially picked, non-genetically engineered bacteria that would also outcompete dangerous oral bacteria. This product </span><a href="https://pubmed.ncbi.nlm.nih.gov/26427036/" rel="">then failed its one-and-only human trial</a><span>, an outcome Hillman apparently ignored. You can now buy ProBiora today at all participating retailers.</span></p><p><span>Fast-forward to last year, when rationalist Aaron Silverbook came across Hillman’s original work with the genetically modified bacteria. Aaron, based on his previous work as </span><a href="https://manifund.org/projects/recreate-the-cavity-preventing-gmo-bacteria-bcs3-l1-from-precursor-" rel="">guy at a rationalist nonprofit, videogame producer, and porn producer</a><span>, decided to recreate Hillman’s work</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-4-144660269" target="_self" rel="">4</a></span><span>. First, he applied for funding from FTX. He got it, but then FTX collapsed. Then, he applied for funding from alternative rationalist funding source Manifund, got that, and failed to recreate Hillman’s work. However, </span><a href="https://manifold.markets/Austin/if-funded-will-lantern-bioworks-suc" rel="">Aaron declared mission success anyways</a><span> in that he negotiated with Oragenics to acquire a sample of BCS3L-1, one of Hillman’s later strains</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-5-144660269" target="_self" rel="">5</a></span><span>, in exchange for $50k and promise of royalties, although </span><a href="https://www.oragenics.com/news-media/press-releases/detail/163/oragenics-enters-into-agreement-with-lantern-bioworks-for" rel="">he didn’t get any intellectual property rights</a><span> .</span></p><p>Aaron then went on an intellectual journey where he tried to figure out what exactly to do with this genetically modified bacteria. After all, he was faced with basically the same daunting FDA journey as Hillman, but without Hillman’s scientific background or financial resources. After talking to a bunch of people, including me, he eventually decided on a very rationalist, very Bay Area, very strange approach:</p><p>1. Sell the genetically modified bacteria as-is for a one time payment of $20,000 in a libertarian charter city in Honduras</p><p>2. Give a bunch of rationalist-adjacent celebrities free samples of the GMO bacteria as-is in exchange for positive press, including Scott Alexander, Aella (the porn star/escort/sex researcher who he’s the business manager for), Richard Hanania, Cremieux, and Bryan Caplan</p><p>3. Take preorders for $200 a piece from the general public</p><p>It’s worth noting that, regardless of what I think of this plan (i.e. it’s bad and maybe unethical), I’m pretty sure this plan is also illegal. While Lantern claims to be marketing this probiotic as a cosmetic, it is meant to prevent and cure tooth decay. According to the WHO, tooth decay is a disease. A product meant to cure and prevent a disease is a drug, and legally needs to go through the drug approval process. But, you know, whatever.</p><p>Anyhow, enough about Lumina as a company. Let’s talk about Lumina’s science.</p><div><p><span>It’s a little hard to say. Jeffrey Hillman created a bunch of different versions of his genetically modified bacteria with a confusing naming structure. But, as far as I can tell, BCS3L-1 was/is a genetically modified </span><em>S. mutans</em><span> bacteria with </span><a href="https://sci-hub.gupiaoq.com/10.1023/a:1020695902160" rel="">four main features</a><span>:</span></p><p><span>1. It produced mutacin-1140, a naturally occurring antibiotic in the bacteriocin family.</span></p></div><p>2. It was resistant itself to mutacin-1140.</p><p>3. It produced alcohol instead of lactic acid.</p><p><span>4. It has a deleted </span><em>comE</em><span> gene, which was intended to prevent genetic transformation by wildtype, existing </span><em>S. mutans</em><span>.</span></p><p><span>The first 2 features are natural and occur with some frequency in </span><em>S. mutans</em><span> population. Specifically, </span><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC205644/" rel="">there are at least 3 </a><em><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC205644/" rel="">S. mutans</a></em><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC205644/" rel=""> groups which both secrete and are resistant to mutacin</a><span> including the group that BCS3L-1 comes from.</span></p><p><span>The second 2 features are engineered. BCS3L-1 has its </span><em>ldh</em><span> gene replaced by an alcoholic dehydrogenase gene, and has, as mentioned, a deleted </span><em>comE </em><span>gene.</span></p><p><span>The lack of an </span><em>ldh</em><span> gene means that BCS3L-1 does not produce lactic acid. The alcoholic dehydrogenase gene means that it produces ethanol instead. I don’t think this is the safest way to replace lactic acid, although I don’t think this is the biggest problem with BCS3L-1</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-6-144660269" target="_self" rel="">6</a></span><span>.</span></p><p><span>The lack of a </span><em>comE </em><span>gene is hard for me to evaluate. As of the early 2000s, when Hillman was creating BCS3L-1,</span><em> </em><span>deleting </span><em>comE </em><span>seemed like a definitive way to prevent BCS3L-1 from forming effective biofilms or taking up helpful genes (like, say, regaining the </span><em>ldh</em><span> gene). </span><a href="https://www.mdpi.com/2073-4425/8/1/15" rel="">As of 2017</a><span>, this picture is much more complicated. </span><em>comE</em><span> is involved in many different things, and some of its functions are redundant.</span></p><p><span>So, deletion of </span><em>comE</em><span> would definitely make it more difficult for BCS3L-1 to be transformed, but it would likely not make it impossible. It would definitely make it harder for BCS3L-1 to survive in the mouth and compete against wildtype </span><em>S. mutans</em><span> who are resistant to mutacin-1140. And it definitely would not make it impossible for BCS3L-1 to transform other </span><em>S. mutans</em><span>, like by autolysis, which is basically bacterial self-detonation. This releases bacterial DNA in the biofilm, so it could result in wildtype </span><em>S. mutans</em><span> getting some of the genes of BCS3L-1 (like resistance to mutacin 1140).</span></p><p><span>Putting this all together, putting BCS3L-1 in your mouth results in your teeth being colonized by whatever bacteria are resistant to mutacin-1140. Ideally, this would be some mixture of BCS3L-1 and harmless bacteria. However, if any other bacteria are in the mouth that are resistant to mutacin-1140 and can live on your teeth (e.g. naturally occurring mutacin-resitant </span><em>S. mutans</em><span>), they will become the dominant species in your mouth, as BCS3L-1 has several fitness-decreasing mutations. Or, it’s entirely possible that BCS3L-1 will start off by being the dominant species in your mouth, then, at some point, will just transform the existing </span><em>S. mutans</em><span> into mutacin-1140 resistant </span><em>S. mutans</em><span>, at which point these wildtype </span><em>S. mutans </em><span>will, again, become the dominant species in your mouth.</span></p><p>But let’s say BCS3L-1 becomes the dominant species in your mouth. What then? Are there any health risks? I’m glad you asked.</p><p>When I talk about the health risks of BCS3L-1, there are really two categories of health risks to discuss: the health risks if BCS3L-1 works as intended, and the health risks if it doesn’t. You see, one of the main functions of the FDA is to not only outline the health risks of products working as intended, but to minimize the health risks of products not working as intended. Like, say, the health risks involved with the product being contaminated.</p><p><span>BCS3L-1 is a probiotic, which is a bacteria that you ingest. This puts it in the same category as kombucha or yogurt. And, like </span><a href="https://www.reddit.com/r/Kombucha/comments/a3pxz7/my_homemade_kombucha_which_i_swore_by_was_making/" rel="">kombucha</a><span> or </span><a href="https://japantoday.com/category/national/students-hospitalized-after-eating-teacher%E2%80%99s-homemade-yogurt-in-nagoya" rel="">yogurt</a><span>, improper manufacturing of BCS3L-1 could introduce any number of contaminants into the product, including foreign bacteria or fungi (like mold). These can make you incredibly sick or even kill you.</span></p><p><span>The FDA has strict manufacturing standards when it comes to probiotics, known as </span><a href="https://internationalprobiotics.org/wp-content/uploads/IPA-Probiotic-Manufacturing-Guidelines-2019.pdf" rel="">GMP standards</a><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-7-144660269" target="_self" rel="">7</a></span><span>. These include making sure your factory is clean and free from contaminants, your protocol reliably produces safe probiotics and is followed closely by your employees, and your end product is regularly tested. These standards aren’t just paper standards, either. The FDA regularly goes and inspects factories to make sure they follow GMP standards. Because these standards are so strict, most smaller drug developers, like my companies, find it cost-prohibitive to manufacture drugs ourselves, and rely on contract factories to do so.</span></p><p>If you are a Bay Area type, you might think that it’s unfair that the FDA regulates who can manufacture drugs. You’d probably be tempted to manufacture the drug by yourself. In fact, that’s what I suspect Lumina has done, because I really doubt a contract factory would be ok making an unapproved drug for them to sell to the public, as that would get the contract factory in trouble.</p><p>But, again, these standards are written in blood. As the links above suggest, even “safe” probiotics like yogurt or kombucha can make you incredibly sick or kill you if improperly manufactured. BCS3L-1 definitely could make someone sick or kill them if improperly manufactured. If Lumina is not following GMP standards, as I suspect they’re not, they are at risk of seriously injuring or killing their customers through contamination.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg" width="682" height="408" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:408,&quot;width&quot;:682,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Food Poisoning: Symptoms and Treatment | Allina Health&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Food Poisoning: Symptoms and Treatment | Allina Health" title="Food Poisoning: Symptoms and Treatment | Allina Health" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe23618a8-3f1c-48ae-acfd-facf88a326da_682x408.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Pictured: you after ingesting contaminated, improperly manufactured probiotics. You know, in some sense, a probiotic that makes you unable to leave the toilet is also an anti-cavity probiotic, in that you will not want to eat anything afterwards.</figcaption></figure></div><p><span>Similarly, I don’t think Lumina is regularly sequencing the bacteria that they are sending out to people. They certainly aren’t following </span><a href="https://www.chpa.org/public-policy-regulatory/voluntary-codes-guidelines/best-practices-voluntary-guidelines-probiotics" rel="">the Best Practices Guidelines for Probiotics</a><span>, which require you to state how much of each strain in CFUs is in each batch that you send out on your packaging. So, when Lumina claims that you are receiving BCS3L-1, which has the modifications above, they actually have no idea what you’re receiving.&nbsp;</span></p><p>You could be receiving:</p><p>1) Just BCS3L-1</p><p>2) Random contaminants</p><p>3) Mutated BCS3L-1 (like one that regained the ability to produce lactic acid)</p><p>4) Dangerous bacteria or fungi that have taken over your batch</p><p>5) Some combination of 1 through 4</p><p><span>So, that’s what I mean when I say the first category of health risks when taking BCS3L-1 are the unknown health risks. </span><strong>Neither you, nor Lumina, have any idea what you’re infecting your mouth with.</strong></p><p>Onto the next category: the known health risks.</p><p>BCS3L-1, if you remember, produces two main byproducts by design: alcohol and mutacin-1140. Now the alcohol that BCS3L-1 produces can definitely be a health risk (see footnote 6), but I want to discuss mutacin-1140.</p><p><span>Mutacin-1140 is an antibiotic in the lantibiotic class. Oragenics has spent the past 20 years or so trying to develop it and related antibiotics commercially, </span><a href="https://pubmed.ncbi.nlm.nih.gov/30479173/" rel="">most notably for </a><em><a href="https://pubmed.ncbi.nlm.nih.gov/30479173/" rel="">C. difficile</a></em><span>, an infection of the digestive tract. They’ve struggled in part because, although mutacin-1140 can be effective against </span><em>C. difficile</em><span>, it’s </span><a href="https://www.frontiersin.org/journals/microbiology/articles/10.3389/fmicb.2018.00415/full" rel="">somewhat cytotoxic</a><span> (i.e. is somewhat dangerous to the body) and</span><a href="https://sci-hub.gupiaoq.com/10.1517/17425255.2011.573478" rel=""> caused a hypersensitivity reaction in a rat when given through IV at a high dose</a><span>. It also has difficult pharmacokinetics, because </span><a href="https://sci-hub.gupiaoq.com/10.1517/17425255.2011.573478" rel="">it binds strongly to blood and plasma</a><span>, meaning that it tends to go everywhere that blood goes, making it hard to target specific infections.&nbsp;</span></p><p><span>On the plus side, it is very effective at surviving the digestive tract, in that </span><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5864910/" rel="">it survives for greater than 240 minutes in simulated gastric fluid and for 72 minutes in simulated intestinal fluid</a><span>. This stability in the stomach is probably why Oragenics keeps trying to develop it for infections of the digestive tract.</span></p><p>Now, given that information, think about the wisdom of infecting your mouth with a bacteria that is designed to continually produce mutacin-1140. You are continually producing an antibiotic in your mouth that:</p><p>1) Can be dangerous</p><p>2) Goes everywhere that blood goes</p><p>3) Is not inactivated by stomach acid</p><p>4) Kills other bacteria very effectively</p><p>At the very least, this is a great way to give yourself the digestive equivalent of continually taking antibiotics (i.e. diarrhea and indigestion). This also might be a good way to give yourself a hypersensitivity reaction like that poor rat. It’s hard to say, because making a safety equivalence between taking an IV antibiotic one time at a high dose and taking an antibiotic orally at a low dose for potentially decades is really difficult. This is why the FDA requires safety studies.</p><p><span>What I can say for sure is that this would be exceptionally dangerous for infants and immunocompromised people. </span><a href="https://www.fda.gov/news-events/press-announcements/fda-raises-concerns-about-probiotic-products-sold-use-hospitalized-preterm-infants#:~:text=The%20FDA%20is%20aware%20that,the%20United%20States%20since%202018." rel="">Infants have died from hospital-grade probiotics before</a><span>, and </span><a href="https://www.sciencedirect.com/science/article/pii/S2405844024039392#:~:text=Yet%2C%20probiotics%20themselves%20may%20also,localized%20and%20opportunistic%20infections%20(Fig." rel="">immunocompromised people have gotten seriously sick</a><span>. That’s from normal, “healthy” probiotics. How do you think your infant (who does not yet have a fully colonized microbiome) will respond if you infect them with a bacterium that nukes all other bacteria in their system? Better hope you don’t kiss your baby or share food or drinks with them!</span></p><p><span>I hope I’ve conclusively proven, at this point, that Lumina has messed up big time. They have put a lot of people at risk, including everyone who they’ve non-consensually infected by introducing a genetically modified bacteria into the wild. They messed with things they didn’t understand, put profit and “acceleration” before safety, and, in one of the worst sins that a rationalist can do, tunneled a hole through the Chesterton fence of the FDA</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-8-144660269" target="_self" rel="">8</a></span><span>.</span></p><p><span>If Lumina had the good sense of Hillman (who, to be clear, I don’t think is a scientific saint either), they at least would have sold the version of the GMO bacteria that had a self-destruct button, </span><a href="https://sci-hub.gupiaoq.com/10.1111/j.1365-2672.2007.03316.x" rel="">AJ2M</a><span>, which I think was the last strain Hillman created. That one was designed to be vulnerable to chlorhexidine and to require an exogenous amino acid, d-alanine, to function. If the d-alanine stopped being provided, the bacteria died, assuming it didn’t acquire any mutations in the meantime that let it keep surviving.</span></p><p>But Lumina didn’t do that, even though I and, I assume others, told them to do that. They sold the earlier version of the probiotic without a kill-switch, which means that the cat is out of the bag and is probably giving overly credulous rationalists diarrhea as we speak. So, at the very least, Lumina needs to:</p><p>1) Stop selling the probiotic and refund everyone who’s bought it so far</p><p>2) Do research into which antibiotics and what course of antibiotics will completely remove BCS3L-1</p><p>3) Message everyone who’s bought BCS3L-1 with information on how to test if they still have it and how to rid them themselves of it if they do</p><p>4) Fund people’s doctors’ visits to rid themselves of BCS3L-1</p><p><span>Or, you know, they could also do the typical Bay Area thing and keep tunneling along regardless of what damage they leave in their wake. After all, as every dentist knows, one person’s hole is another person’s business opportunity</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-9-144660269" href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity#footnote-9-144660269" target="_self" rel="">9</a></span><span>.</span></p><div data-attrs="{&quot;url&quot;:&quot;https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><p>Like this post? Share it!</p><p data-attrs="{&quot;url&quot;:&quot;https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a href="https://trevorklee.substack.com/p/please-dont-take-luminas-anticavity?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dragonfly: An optical telescope built from an array of off-the-shelf Canon lens (171 pts)]]></title>
            <link>https://www.dunlap.utoronto.ca/instrumentation/dragonfly/</link>
            <guid>40369021</guid>
            <pubDate>Wed, 15 May 2024 16:24:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dunlap.utoronto.ca/instrumentation/dragonfly/">https://www.dunlap.utoronto.ca/instrumentation/dragonfly/</a>, See on <a href="https://news.ycombinator.com/item?id=40369021">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper">
 




  

<div id="attachment_18521"><p><a href="http://www.dunlap.utoronto.ca/wp-content/uploads/2023/04/PXL_20221118_165758669-1.jpg"><img src="http://www.dunlap.utoronto.ca/wp-content/uploads/2023/04/PXL_20221118_165758669-1-226x300.jpg" alt="" width="248" height="329" data-id="18521" srcset="https://www.dunlap.utoronto.ca/wp-content/uploads/2023/04/PXL_20221118_165758669-1-226x300.jpg 226w, https://www.dunlap.utoronto.ca/wp-content/uploads/2023/04/PXL_20221118_165758669-1-768x1020.jpg 768w, https://www.dunlap.utoronto.ca/wp-content/uploads/2023/04/PXL_20221118_165758669-1-771x1024.jpg 771w" sizes="(max-width: 248px) 100vw, 248px"></a></p><p>Grad student Seery Chen connects cables to a power supply on the Dragonfly telescope in New Mexico, in November of 2022. Credit: Seery Chen.</p></div>
<p>
Dragonfly is an innovative, multi-lens array designed for ultra-low surface brightness astronomy at visible wavelengths. Commissioned in 2013 with only three lenses, the array is growing in size and proving capable of detecting extremely faint, complex structure around galaxies.</p>
<p>In 2022, the Dragonfly team completed 70 per cent of its ultrawide survey, which will map out the full footprint of sloan digital sky Survey when complete.</p>
<p>An expansion of an additional 120 lenses is currently underway in 2023.</p>
<p>According to Cold Dark Matter (CDM) cosmology, structure in the Universe grows from the “bottom up”, with small galaxies merging to form larger ones. Evidence of such mergers can be seen in faint streams and filaments visible around the Milky Way Galaxy and the nearby M31 galaxy.</p>
<p>But the CDM model predicts that we should see more of this structure than is currently observed. However, images obtained using even the largest, most advanced telescopes today contain scattered light that may be hiding this faint structure. Dragonfly is designed to reveal the faint structure by greatly reducing scattered light and internal reflections within its optics. It achieves this using commercially-available Canon 400mm lenses, with unprecedented nano-fabricated coatings with sub-wavelength structure on optical glasses.</p>
<p>Also, Dragonfly images a galaxy through multiple lenses simultaneously—akin to a dragonfly’s compound eye—enabling further removal of unwanted light. The result is an image in which extremely faint galaxy structure is visible.</p>
<p><span>The&nbsp; co-principal-investigators for Dragonfly are U of T’s&nbsp;<a title="DAA Prof. Roberto Abraham" href="http://www.astro.utoronto.ca/~abraham/Web/Welcome.html" target="_blank" rel="noopener">Professor Roberto Abraham</a>&nbsp;and Yale University’s Professor Pieter van Dokkum.&nbsp;</span></p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Viking 7B: open LLM for the Nordic languages trained on AMD GPUs (102 pts)]]></title>
            <link>https://www.silo.ai//blog/viking-7b-the-first-open-llm-for-the-nordic-languages</link>
            <guid>40368760</guid>
            <pubDate>Wed, 15 May 2024 16:05:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.silo.ai//blog/viking-7b-the-first-open-llm-for-the-nordic-languages">https://www.silo.ai//blog/viking-7b-the-first-open-llm-for-the-nordic-languages</a>, See on <a href="https://news.ycombinator.com/item?id=40368760">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>Together with University of Turku’s research group TurkuNLP and HPLT, Europe’s largest private AI lab Silo AI is releasing the first multilingual large language model (LLM) for all Nordic languages. Viking 7B is a best-in-class open source model that is sensitive to local values and cultures and further evidence of the team’s novel approach to training capable LLMs for low-resource languages. It is a significant milestone on the journey towards a state-of-the-art LLM family for all European languages.</strong></p><p>Following the completion of the language model <a href="https://www.silo.ai/blog/europes-open-language-model-poro-a-milestone-for-european-ai-and-low-resource-languages">Poro</a>, and the first checkpoint release of <a href="https://www.silo.ai/blog/viking-7b-13b-33b-sailing-the-nordic-seas-of-multilinguality">Viking</a>, Silo AI and TurkuNLP of University of Turku are now releasing the full 7B parameter version of Viking. At the same time, we are also releasing further checkpoints for the Viking 13B and Viking 33B models. In addition to the Nordic languages, Viking also covers English and programming languages. Evaluations indicate best-in-class performance in all Nordic languages, without compromising performance in English.&nbsp;</p><p>Viking relies on the same training approach as Poro, focusing on low-resource languages without compromising English, but extends to include Danish, Finnish, Norwegian, Icelandic, Swedish and programming languages. And the model family comes with an updated architecture and in a variety of model sizes. </p><p>Building on Silo AI's strategy to promote democratic access to LLMs and promote linguistic diversity across Europe, the collaboration with TurkuNLP utilizes the latest advancements in multilingual LLMs. Unlike most other LLMs, we're prioritizing low-resource language performance, rather than relegating them to an afterthought. The team has worked on determining optimal training approaches and architectures to support this. This covers optimal model architecture for pre-training, as well as other approaches to training and data sampling like data reuse frequencies for low-resource languages during training and incorporating translated paired texts between high- and low-resource languages. Several of these strategies rely on a cross-lingual signal to enhance the model's understanding of the connections between languages, proving crucial in achieving superior performance for low-resource languages, without compromising performance in English.</p><p>Silo AI and TurkuNLP are dedicated to developing models that not only excel in linguistic performance and inclusivity but are also attuned to local values and cultures. Such sensitivity ensures that these technological advancements serve as connectors, rather than dividers, in digital communication. It enhances Europe’s digital infrastructure, thereby accelerating the adoption of LLM-driven products and applications. This, in turn, fosters innovation across sectors and use cases throughout Europe, bolstering the continent's technological ecosystem.</p><p>Further emphasizing digital sovereignty, Viking is trained on the EuroHPC supercomputer LUMI, utilizing up to 4096 AMD MI-250X GPUs. LUMI is not only Europe’s most powerful supercomputer and the 5th most powerful in the world, but also the 3rd greenest supercomputer among the top 500 supercomputers. LUMI’s energy consumption is covered with power produced 100% with hydroelectricity, and the waste heat of LUMI will account for about 20 percent of the district heating in the surrounding city of Kajaani.&nbsp;</p><p>With a purpose-built software layer to train models on AMD, Silo AI and TurkuNLP possess unmatched experience with training on AMD at scale, having <a href="https://lumi-supercomputer.eu/scaling-the-pre-training-of-large-language-models-of-100b-parameters-to-thousands-of-amd-mi250x-gpus-on-lumi/">shown that their</a> theoretical predictions for throughput scaling materialize in weak and strong scaling experiments. As one of the seminal initiatives on AMD GPUs, this shows how it’s possible to achieve good throughput on the AMD-based LUMI, training the models with their open source training framework and utilizing up to 4096 MI-250X GPUs simultaneously.</p><h2>Viking 7B completed and checkpoint performance</h2><p>Today, the Viking models stand at 100% of training on Viking 7B, 85% on 13B and 65% on 33B. With common benchmarks, we can observe evidence of outperformance with respect to other open models (e.g. Falcon, GPT-SW3, Llama, Mistral, MPT, etc). Results indicate best-in-class performance in low-resource languages vis-à-vis other open models, without compromising performance in English and programming languages. In our latest evaluations, Viking is benchmarked on a large number of relevant measures, including translated tests, MMLU, Arc-C, HellaSwag etc. While translated tests are commonly used (e.g. to prove multilinguality of Mistral Large) and provide indicative evidence, they don't fully capture the multilingual reasoning capabilities of language models. Another measure, perplexity, further corroborates Viking’s performance. Overall, Viking not only showcases its adeptness at understanding and generating Nordic languages but also highlights its efficiency in processing and predicting linguistic sequences. This dual advantage indicates the viability of the approach to train multilingual models, and Viking's technological edge in navigating the complexities of multilinguality.</p><h2>Viking 7B/13B/33B: A modern architecture with more languages</h2><p>Below is a summary of key features of the Viking model family covering English, Finnish, Swedish, Norwegian, Danish, Icelandic and code:</p><p>‍</p><ul role="list"><li><strong>Research Checkpoints: </strong>Silo AI and TurkuNLP are committed to publishing checkpoints throughout the training process, providing transparency on the model training process.</li><li><strong>Model architecture:</strong> Viking uses an architecture similar to Llama 2, with flash attention, rotary embeddings, grouped query attention and supports a 4k sequence length</li><li><strong>Model sizes: </strong>7B, 13B and 33B parameters</li><li><strong>Multilingual capabilities: </strong>The models are designed to process English and Nordic languages, and have proficiency with a variety of programming languages. Additionally, they can perform basic translation between English and Nordic languages.</li><li><strong>Dataset:</strong> The model family is trained with a dataset of 2 trillion tokens, including Danish, English, Finnish, Icelandic, Norwegian, Swedish and a variety of programming languages.</li><li><strong>Open source: </strong>The model family is freely available under the Apache 2.0 License, implying applicability for both commercial and research use.</li><li><strong>Training hardware: </strong>Our models are trained using the LUMI supercomputer in Finland, covering up to 4096 AMD MI250X GPUs.</li></ul><h3>Considerations for Use</h3><p>The intended audience for Poro Research Checkpoints is academic and industry research. These checkpoints are not suitable for deployment in a production use case without further training, fine-tuning and testing. For more on Silo AI's SaaS-based custom LLMs we invite you to familiarize yourself with the <a href="https://www.silo.ai/silogen">SiloGen platform</a>.</p><h3>Acknowledgments</h3><p>We wish to thank the operators of the <a href="https://www.lumi-supercomputer.eu/">LUMI/EuroHPC</a> supercomputer for computational resources and technical support, including AMD, HPE and CSC – the IT Center for Science, Finland. TurkuNLP researchers have received funding from the European Union’s Horizon Europe research and innovation programme High Performance Language Technologies (HPLT) under grant agreement No 101070350.</p><p>‍</p></div><div><h2>About</h2><div role="list"><div role="listitem"><h3>Silo AI</h3><p>Silo AI is Europe’s largest private AI lab on a mission to ensure Europe has a flagship AI company. We’re a trusted AI partner that brings competitive advantage to product R&amp;D. We build AI-driven solutions and products to enable smart devices, autonomous vehicles, industry 4.0, and smart cities. Silo AI provides its customers unique access to world-class AI models and expertise, as well as the Silo OS infrastructure to speed up AI development and deployment. With SiloGen, Silo AI is currently building market leading open source LLMs, with the intent to ensure European digital sovereignty and democratize access to LLMs.</p><p><a href="https://www.silo.ai/" target="_blank">www.silo.ai</a></p></div><div role="listitem"><h3>TurkuNLP</h3><p>The TurkuNLP Group is a group of researchers at the University of Turku, with a research focus on various aspects of natural language processing, language technology and digital linguistics. TurkuNLP has contributed to a large number of open source NLP resources, such as FinBERT, WikiBERT, FinGPT, Turku Dependency Treebank, Universal Dependencies, Turku Neural Parsing Pipeline, Large internet corpora, Turku Paraphrase Corpus, Turku Sentiment Corpus, Wikidata normalization, TurkuONE etc. The University of Turku is an international academic community of 25,000 students and staff and was ranked among the 301–400 best universities in the 2023 Shanghai Ranking. </p></div></div></div><div><h2>Want to discuss how Silo AI could help your organization?</h2><p>Get in touch with our AI&nbsp;experts.</p><div><p><img loading="lazy" alt="" src="https://assets-global.website-files.com/63beb9b135d26ec169729fa2/63f603ac4a61da58b147991a_peter-sarlin.jpg"></p><div><p>Peter Sarlin, PhD</p><p>CEO &amp; Co-Founder</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Adobe Photoshop Source Code (2013) (473 pts)]]></title>
            <link>https://computerhistory.org/blog/adobe-photoshop-source-code/</link>
            <guid>40368016</guid>
            <pubDate>Wed, 15 May 2024 15:12:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://computerhistory.org/blog/adobe-photoshop-source-code/">https://computerhistory.org/blog/adobe-photoshop-source-code/</a>, See on <a href="https://news.ycombinator.com/item?id=40368016">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<h3><em>Software Gems: The Computer History Museum Historical Source Code Series</em></h3>
<div><h3> pho·to·shop, transitive verb, often capitalized ˈfō-(ˌ)tō-ˌshäp to alter (a digital image) with Photoshop software or other image-editing software especially in a way that distorts reality (as for deliberately deceptive purposes) </h3><h4>— Merriam-Webster online dictionary, 2012</h4></div>
<p>When brothers Thomas and John Knoll began designing and writing an image editing program in the late 1980s, they could not have imagined that they would be adding a word to the dictionary.</p>



<div id="attachment_9140"><p><img aria-describedby="caption-attachment-9140" src="https://computerhistory.org/wp-content/uploads/2019/08/photoshop-source-code-thomas-knoll.jpg" alt="" width="310" height="300"></p><p id="caption-attachment-9140">Thomas Knoll</p></div> <div id="attachment_9133"><p><img aria-describedby="caption-attachment-9133" src="https://computerhistory.org/wp-content/uploads/2019/08/photoshop-source-code-john-knoll.jpg" alt="" width="310" height="300"></p><p id="caption-attachment-9133">John Knoll</p></div>




<p>Thomas Knoll, a PhD student in computer vision at the University of Michigan, had written a program in 1987 to display and modify digital images. His brother John, working at the movie visual effects company Industrial Light &amp; Magic, found it useful for editing photos, but it wasn’t intended to be a product. Thomas said, “We developed it originally for our own personal use…it was a lot a fun to do.”</p>
<p>Gradually the program, called “Display”, became more sophisticated. In the summer of 1988 they realized that it indeed could be a credible commercial product. They renamed it “Photoshop” and began to search for a company to distribute it. About 200 copies of version 0.87 were bundled by slide scanner manufacturer Barneyscan as “Barneyscan XP”.</p>
<p>The fate of Photoshop was sealed when Adobe, encouraged by its art director Russell Brown, decided to buy a license to distribute an enhanced version of Photoshop. The deal was finalized in April 1989, and version 1.0 started shipping early in 1990.</p>
<p>Over the next ten years, more than 3 million copies of Photoshop were sold.</p>



<div id="attachment_9132"><p><img aria-describedby="caption-attachment-9132" src="https://computerhistory.org/wp-content/uploads/2019/08/photoshop-source-code-box-and-disk.jpg" alt="" width="789" height="369"></p><p id="caption-attachment-9132">The box and disk for the original version of Photoshop on Mac.</p></div>




<p>That first version of Photoshop was written primarily in Pascal for the Apple Macintosh, with some machine language for the underlying Motorola 68000 microprocessor where execution efficiency was important. It wasn’t the effort of a huge team. Thomas said, “For version 1, I was the only engineer, and for version 2, we had two engineers.” While Thomas worked on the base application program, John wrote many of the image-processing plug-ins.</p>



<div id="attachment_9139"><p><img aria-describedby="caption-attachment-9139" src="https://computerhistory.org/wp-content/uploads/2019/08/photoshop-source-code-splashscreen.jpg" alt="" width="500" height="276"></p><p id="caption-attachment-9139">The splash screen of Photoshop 1.0.7.</p></div>




<p>With the permission of Adobe Systems Inc., the Computer History Museum is pleased to make available, for non-commercial use, the source code to the 1990 version 1.0.1 of Photoshop. All the code is here with the exception of the MacApp applications library that was licensed from Apple. There are 179 files in the zipped folder, comprising about 128,000 lines of mostly uncommented but well-structured code. By line count, about 75% of the code is in Pascal, about 15% is in 68000 assembler language, and the rest is data of various sorts.</p>
<p>To download the code you must agree to the terms of the license, which permits only non-commercial use and does not give you the right to license it to third parties by posting copies elsewhere on the web.</p>
<p>Download <a title="Download Photoshop version 1.0.1 Source Code" href="https://computerhistory.org/blog/photoshop-software-license-agreement/">Photoshop version 1.0.1 Source Code</a></p>
<ul>
	<li><a href="https://www.computerhistory.org/collections/catalog/102640940">1990 version of Adobe Photoshop User Guide</a></li>
	<li><a href="https://www.computerhistory.org/collections/catalog/102640945">1990 version of Adobe Photoshop tutorial</a></li>
</ul>
<h2>Commentary on the source code</h2>
<p>Software architect Grady Booch is the Chief Scientist for Software Engineering at IBM Research Almaden and a trustee of the Computer History Museum. He offers the following observations about the Photoshop source code:</p>
<ul>
	<li>“Opening the files that constituted the source code for Photoshop 1.0, I felt a bit like Howard Carter as he first breached the tomb of King Tutankhamen. What wonders awaited me?</li>
	<li>I was not disappointed by what I found. Indeed, it was a marvelous journey to open up the cunning machinery of an application I’d first used over 20 years ago.</li>
	<li>Architecturally, this is a very well-structured system. There’s a consistent separation of interface and abstraction, and the design decisions made to componentize those abstractions – with generally one major type for each combination of interface and implementation – were easy to follow.</li>
	<li>The abstractions are quite mature. The consistent naming, the granularity of methods, the almost breathtaking simplicity of the implementations because each type was so well abstracted, all combine to make it easy to discern the texture of the system.</li>
	<li>Having the opportunity to examine Photoshop’s current architecture, I believe I see fundamental structures that have persisted, though certainly in more evolved forms, in the modern implementation. Tiles, filters, abstractions for virtual memory (to attend to images far larger than display buffers or main memory could normally handle) are all there in the first version. Yet it had just over 100,000 lines of code, compared to well over 10 million in the current version! Then and now, much of the code is related to input/output and the myriad of file formats that Photoshop has to attend to.</li>
	<li>There are only a few comments in the version 1.0 source code, most of which are associated with assembly language snippets. That said, the lack of comments is simply not an issue. This code is so literate, so easy to read, that comments might even have gotten in the way.</li>
	<li>It is delightful to find historical vestiges of the time: code to attend to Andy Herzfield’s software for the Thunderscan scanner, support of early TARGA raster graphics file types, and even a few passing references to Barneyscan lie scattered about in the code. These are very small elements of the overall code base, but their appearance reminds me that no code is an island.</li>
	<li>This is the kind of code I aspire to write.”</li>
</ul>
<p>And this is the kind of code we all can learn from. Software source code is the literature of computer scientists, and it deserves to be studied and appreciated. Enjoy a view of Photoshop from the inside.</p>
<h2>Early Photoshop screenshots*</h2>



<div id="attachment_9137"><p><img aria-describedby="caption-attachment-9137" src="https://computerhistory.org/wp-content/uploads/2019/08/photoshop-source-code-screen-main.jpg" alt="" width="460" height="341"></p><p id="caption-attachment-9137">The home screen, showing the available tools.</p></div> <div id="attachment_9134"><p><img aria-describedby="caption-attachment-9134" src="https://computerhistory.org/wp-content/uploads/2019/08/photoshop-source-code-screen-brushes.jpg" alt="" width="460" height="280"></p><p id="caption-attachment-9134">Photoshop allowed you to select brush color as well as size and texture. (The first color Mac was the Macintosh II in 1987.)</p></div> <div id="attachment_9136"><p><img aria-describedby="caption-attachment-9136" src="https://computerhistory.org/wp-content/uploads/2019/08/photoshop-source-code-screen-image_filters.jpg" alt="" width="418" height="263"></p><p id="caption-attachment-9136">There were some sophisticated selection tools, and a good assortment of image filters. One important missing feature, which came with version 3 in 1994, was the ability to divide an image into multiple layers.</p></div> <div id="attachment_9138"><p><img aria-describedby="caption-attachment-9138" src="https://computerhistory.org/wp-content/uploads/2019/08/photoshop-source-code-screen-preferences.jpg" alt="" width="460" height="277"></p><p id="caption-attachment-9138">The preferences page allowed for some customization of the features.</p></div> <div id="attachment_9135"><p><img aria-describedby="caption-attachment-9135" src="https://computerhistory.org/wp-content/uploads/2019/08/photoshop-source-code-screen-fonts.jpg" alt="" width="434" height="322"></p><p id="caption-attachment-9135">There was a limited choice of fonts, font sizes, and font styles. The text was entered into this dialog box, then moved into the image.</p></div>



<ul>
	<li><em>Screen shots courtesy of creativebits, <a href="http://www.creativebits.com.sg/">www.creativebits.org</a>.</em></li>
</ul>
<h3>Historical Source Code Releases</h3>
<ul>
	<li><a href="https://computerhistory.org/blog/macpaint-and-quickdraw-source-code">MacPaint and QuickDraw Source Code</a>, July 18, 2010</li>
	<li><a href="https://computerhistory.org/blog/the-apl-programming-language-source-code/">APL Programming Language Source Code</a>, October 10, 2012</li>
	<li><a href="https://computerhistory.org/blog/adobe-photoshop-source-code/">Adobe Photoshop Source Code</a>, February 13, 2013</li>
	<li><a href="https://computerhistory.org/blog/apple-ii-dos-source-code/">Apple II DOS Source Code</a>, November 12, 2013</li>
	<li><a href="https://computerhistory.org/blog/microsoft-ms-dos-early-source-code/">Microsoft MS-DOS Early Source Code</a>, March 25, 2014</li>
	<li><a href="https://computerhistory.org/blog/microsoft-word-for-windows-1-1a-source-code/">Microsoft Word for Windows Version 1.1a Source Code</a>, March 25, 2014</li>
	<li><a href="https://computerhistory.org/blog/early-digital-research-cpm-source-code/">Early Digital Research CP/M Source Code</a>, October 1, 2014</li>
	<li><a href="https://computerhistory.org/blog/xerox-alto-source-code/">Xerox Alto Source Code</a>, October 21, 2014</li>
	<li><a href="https://computerhistory.org/blog/electronic-arts-deluxepaint-early-source-code/">Electronic Arts DeluxePaint Early Source Code</a>, July 22, 2015</li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple announces new accessibility features, including Eye Tracking (350 pts)]]></title>
            <link>https://www.apple.com/newsroom/2024/05/apple-announces-new-accessibility-features-including-eye-tracking/</link>
            <guid>40367331</guid>
            <pubDate>Wed, 15 May 2024 14:22:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2024/05/apple-announces-new-accessibility-features-including-eye-tracking/">https://www.apple.com/newsroom/2024/05/apple-announces-new-accessibility-features-including-eye-tracking/</a>, See on <a href="https://news.ycombinator.com/item?id=40367331">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    

</nav>



<main id="main" role="main"> 



<span id="opens-in-new-window">opens in new window</span>
<section>
<article data-analytics-activitymap-region-id="article">









    
    
    









    





    <div>
        

        <div>
                    
                    
                        <span>PRESS RELEASE</span>
                    
                    
                        <span>May 15, 2024</span>
                    
                    
                </div>

        <div>
                
                
                
                    <h2>
                        
    
        Apple announces new accessibility features, including Eye Tracking, Music Haptics, and Vocal Shortcuts
    

                    </h2>
                
            </div>

        

        
            
    
    
    
    
    

        

    </div>







    
    
    


    
    <div data-component-list="ScrollAnimationDefault VideoPlayer">
                <video data-auto-ac-video="" src="https://www.apple.com/newsroom/videos/apple-accessibility-ipad-eye-tracking/Apple_AccessibilityiPadEyeTracking/us/apple-accessibility-features-eye-tracking_16X9.m3u8" poster="https://www.apple.com/newsroom/videos/apple-accessibility-ipad-eye-tracking/Apple_AccessibilityiPadEyeTracking/us/posters/Apple-accessibility-features-iPad-Eye-Tracking_571x321.jpg.large.jpg" preload="auto" data-optimize-url="" data-text-tracks="{&quot;mode&quot;:&quot;hidden&quot;,&quot;src&quot;:&quot;&quot;,&quot;srclang&quot;:&quot;en&quot;}" data-ac-video-options="{&quot;responsive&quot;:&quot;true&quot;,&quot;sharing&quot;:{&quot;allowEmbed&quot;:true,&quot;description&quot;:&quot;Coming later this year, Apple\u2019s new accessibility features include Eye Tracking, a way for users to navigate iPad and iPhone with just their eyes.&quot;,&quot;videoid&quot;:&quot;65be019eb2028f57ef2ec0bf2ff7eb8d&quot;,&quot;originatorUrl&quot;:&quot;https://www.apple.com/newsroom/2024/05/apple-announces-new-accessibility-features-including-eye-tracking/?videoid=65be019eb2028f57ef2ec0bf2ff7eb8d&quot;,&quot;hideExtension&quot;:true,&quot;title&quot;:&quot;Eye Tracking on iPad&quot;,&quot;hideFacebookShare&quot;:false,&quot;url&quot;:&quot;/newsroom/videos/apple-accessibility-ipad-eye-tracking/Apple_AccessibilityiPadEyeTracking/us/apple-accessibility-features-eye-tracking_16X9.m3u8&quot;,&quot;embedpath&quot;:&quot;https://share.newsroom.apple/newsroom/embed/videos/?embedvideoid=&quot;,&quot;duration&quot;:&quot;00:26&quot;,&quot;analytics&quot;:{&quot;pageName&quot;:&quot;Apple announces new accessibility features, including Eye Tracking&quot;},&quot;hideTwitterShare&quot;:false,&quot;poster&quot;:&quot;/newsroom/videos/apple-accessibility-ipad-eye-tracking/Apple_AccessibilityiPadEyeTracking/us/posters/Apple-accessibility-features-iPad-Eye-Tracking_571x321.jpg.large.jpg&quot;}}">
                </video>
                
                <div>Coming later this year, Apple’s new accessibility features include Eye Tracking, a way for users to navigate iPad and iPhone with just their eyes.</div>
            </div>






    
    
    


     
     
    
    
        <div>
             
                 <div><span>CUPERTINO, CALIFORNIA</span>&nbsp;Apple&nbsp;today announced new accessibility features coming later this year, including Eye Tracking, a way for users with physical disabilities to control iPad or iPhone with their eyes. Additionally, Music Haptics will offer a new way for users who are deaf or hard of hearing to experience music using the Taptic Engine in iPhone; Vocal Shortcuts will allow users to perform tasks by making a custom sound; Vehicle Motion Cues can help reduce motion sickness when using iPhone or iPad in a moving vehicle; and more accessibility features will come to visionOS. These features combine the power of Apple hardware and software, harnessing Apple silicon, artificial intelligence, and machine learning to further Apple’s decades-long commitment to designing products for everyone.
</div>
                 
             
                 <div>“We believe deeply in the transformative power of innovation to enrich lives,” said Tim Cook, Apple’s CEO. “That’s why for nearly 40 years, Apple has championed inclusive design by embedding accessibility at the core of our hardware and software. We’re continuously pushing the boundaries of technology, and these new features reflect our long-standing commitment to delivering the best possible experience to all of our users.”
</div>
                 
             
                 <div>“Each year, we break new ground when it comes to accessibility,” said Sarah Herrlinger, Apple’s senior director of Global Accessibility Policy and Initiatives. “These new features will make an impact in the lives of a wide range of users, providing new ways to communicate, control their devices, and move through the world.”
</div>
                 
             
                 <h2><strong>Eye Tracking Comes to iPad and iPhone</strong>
</h2>
                 
             
                 <div>Powered by artificial intelligence, Eye Tracking gives users a built-in option for navigating iPad and iPhone with just their eyes. Designed for users with physical disabilities, Eye Tracking uses the front-facing camera to set up and calibrate in seconds, and with on-device machine learning, all data used to set up and control this feature is kept securely on device, and isn’t shared with Apple.
</div>
                 
             
                 <div>Eye Tracking works across iPadOS and iOS apps, and doesn’t require additional hardware or accessories. With Eye Tracking, users can navigate through the elements of an app and use Dwell Control to activate each element, accessing additional functions such as physical buttons, swipes, and other gestures solely with their eyes.
</div>
                 
             
                 <h2><strong>Music Haptics Makes Songs More Accessible</strong>
</h2>
                 
             
                 <div>Music Haptics is a new way for users who are deaf or hard of hearing to experience music on iPhone. With this accessibility feature turned on, the Taptic Engine in iPhone plays taps, textures, and refined vibrations to the audio of the music. Music Haptics works across millions of songs in the Apple Music catalog, and will be available as an API for developers to make music more accessible in their apps.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>Music Haptics is a new way for users who are deaf or hard of hearing to experience music on iPhone.</div>
        
            <a aria-label="Download video: Music Haptics on iPhone 15 Pro" data-analytics-title="Download video - Music Haptics on iPhone 15 Pro" download="" href="https://www.apple.com/newsroom/videos/apple-accessibility-music-haptics/downloads/Apple-accessibility-features-Music-Haptics.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>New Features for a Wide Range of Speech</strong>
</h2>
                 
             
                 <div>With Vocal Shortcuts, iPhone and iPad users can assign custom utterances that Siri can understand to launch shortcuts and complete complex tasks. Listen for Atypical Speech, another new feature, gives users an option for enhancing speech recognition for a wider range of speech. Listen for Atypical Speech uses on-device machine learning to recognize user speech patterns. Designed for users with acquired or progressive conditions that affect speech, such as cerebral palsy, amyotrophic lateral sclerosis (ALS), or stroke, these features provide a new level of customization and control, building on features introduced in iOS 17 for users who are nonspeaking or at risk of losing their ability to speak.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="vocal-shortcuts">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-fa08d516d87ca1556ebab64e3b08969e" href="#gallery-fa08d516d87ca1556ebab64e3b08969e" data-ac-gallery-trigger="gallery-fa08d516d87ca1556ebab64e3b08969e"><span>On iPhone 15 Pro, a screen reads “Set Up Vocal Shortcuts” and prompts the user to choose an action and record a phrase to teach their iPhone how to recognize their voice.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-d5b3c3363de1da36b28d5a8ccfa9fe7d" href="#gallery-d5b3c3363de1da36b28d5a8ccfa9fe7d" data-ac-gallery-trigger="gallery-d5b3c3363de1da36b28d5a8ccfa9fe7d"><span>On iPhone 15 Pro, a screen reads “Say ‘Rings’ One Last Time,” and prompts the user to teach iPhone to recognize the phrase by saying it three times.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-4b12605871a1b6c371e682d284c0ec84" href="#gallery-4b12605871a1b6c371e682d284c0ec84" data-ac-gallery-trigger="gallery-4b12605871a1b6c371e682d284c0ec84"><span>On iPhone 15 Pro, a user gets an alert from Vocal Shortcuts that says “Open Activity Rings.” </span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-fa08d516d87ca1556ebab64e3b08969e" aria-labelledby="gallery-dotnav-fa08d516d87ca1556ebab64e3b08969e" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:set-up-screen">
                                
                                <div>
                                    <div>With Vocal Shortcuts, iPhone and iPad users can assign custom utterances that Siri can understand to launch shortcuts and complete complex tasks.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/05/apple-announces-new-accessibility-features-including-eye-tracking/article/Apple-accessibility-features-Vocal-Shortcuts-settings.zip" download="" data-analytics-title="download image - Apple-accessibility-features-Vocal-Shortcuts-settings_inline" aria-label="Download media, On iPhone 15 Pro, a screen reads “Set Up Vocal Shortcuts” and prompts the user to choose an action and record a phrase to teach their iPhone how to recognize their voice."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-d5b3c3363de1da36b28d5a8ccfa9fe7d" aria-labelledby="gallery-dotnav-d5b3c3363de1da36b28d5a8ccfa9fe7d" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:phrase-prompt">
                                
                                <div>
                                    <div>With Vocal Shortcuts, iPhone and iPad users can assign custom utterances that Siri can understand to launch shortcuts and complete complex tasks.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/05/apple-announces-new-accessibility-features-including-eye-tracking/article/Apple-accessibility-features-Vocal-Shortcuts-prompt.zip" download="" data-analytics-title="download image - Apple-accessibility-features-Vocal-Shortcuts-prompt_inline" aria-label="Download media, On iPhone 15 Pro, a screen reads “Say ‘Rings’ One Last Time,” and prompts the user to teach iPhone to recognize the phrase by saying it three times."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-4b12605871a1b6c371e682d284c0ec84" aria-labelledby="gallery-dotnav-4b12605871a1b6c371e682d284c0ec84" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:alert">
                                
                                <div>
                                    <div>With Vocal Shortcuts, iPhone and iPad users can assign custom utterances that Siri can understand to launch shortcuts and complete complex tasks.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/05/apple-announces-new-accessibility-features-including-eye-tracking/article/Apple-accessibility-features-Vocal-Shortcuts-alert.zip" download="" data-analytics-title="download image - Apple-accessibility-features-Vocal-Shortcuts-alert_inline" aria-label="Download media, On iPhone 15 Pro, a user gets an alert from Vocal Shortcuts that says “Open Activity Rings.” "></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <div>“Artificial intelligence has the potential to improve speech recognition for millions of people with atypical speech, so we are thrilled that Apple is bringing these new accessibility features to consumers,”&nbsp;said Mark Hasegawa-Johnson, the Speech Accessibility Project at the Beckman Institute for Advanced Science and Technology at the University of Illinois Urbana-Champaign’s principal investigator.&nbsp;“The Speech Accessibility Project was designed as a broad-based, community-supported effort to help companies and universities make speech recognition more robust and effective, and Apple is among the accessibility advocates who made the Speech Accessibility Project possible.”
</div>
                 
             
                 <h2><strong>Vehicle Motion Cues Can Help Reduce Motion Sickness</strong>
</h2>
                 
             
                 <div>Vehicle Motion Cues is a new experience for iPhone and iPad that can help reduce motion sickness for passengers in moving vehicles. Research shows that motion sickness is commonly caused by a sensory conflict between what a person sees and what they feel, which can prevent some users from comfortably using iPhone or iPad while riding in a moving vehicle. With Vehicle Motion Cues, animated dots on the edges of the screen represent changes in vehicle motion to help reduce sensory conflict without interfering with the main content. Using sensors built into iPhone and iPad, Vehicle Motion Cues recognizes when a user is in a moving vehicle and responds accordingly. The feature can be set to show automatically on iPhone, or can be turned on and off in Control Center.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>Vehicle Motion Cues is a new experience for iPhone and iPad that can help reduce motion sickness for passengers in moving vehicles.</div>
        
            <a aria-label="Download video: Vehicle Motion Cues on iPhone 15 Pro" data-analytics-title="Download video - Vehicle Motion Cues on iPhone 15 Pro" download="" href="https://www.apple.com/newsroom/videos/apple-accessibility-vehicle-motion-cues/downloads/Apple-accessibility-features-Vehicle-Motion-Cues.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>CarPlay Gets Voice Control, More Accessibility Updates</strong>
</h2>
                 
             
                 <div>Accessibility features coming to CarPlay include Voice Control, Color Filters, and Sound Recognition. With Voice Control, users can navigate CarPlay and control apps with just their voice. With Sound Recognition, drivers or passengers who are deaf or hard of hearing can turn on alerts to be notified of car horns and sirens. For users who are colorblind, Color Filters make the CarPlay interface visually easier to use, with additional visual accessibility features including Bold Text and Large Text.
</div>
                 
             
         </div>
 

    
    
    


    
        
        
        
        
            <figure aria-label="Media, The new Sound Recognition feature in CarPlay alerts a user of a potential siren sound.">
                <div>
                         
                            
                            <div>
                                Updates to CarPlay include Sound Recognition, which allows drivers or passengers who are deaf or hard of hearing to turn on alerts to be notified of car horns and sirens.
                            </div>
                        
                        
                        
                        
                        <a href="https://www.apple.com/newsroom/images/2024/05/apple-announces-new-accessibility-features-including-eye-tracking/article/Apple-accessibility-features-Vehicle-Motion-Cues.zip" download="" data-analytics-title="download image - Apple-accessibility-features-Vehicle-Motion-Cues_big" aria-label="Download media, The new Sound Recognition feature in CarPlay alerts a user of a potential siren sound."></a>
                    </div>
            </figure>
        
    










    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Accessibility Features Coming to visionOS</strong>
</h2>
                 
             
                 <div>This year, accessibility features coming to visionOS will include systemwide Live Captions to help everyone — including users who are deaf or hard of hearing — follow along with spoken dialogue in live conversations and in audio from apps. With Live Captions for FaceTime in visionOS, more users can easily enjoy the unique experience of connecting and collaborating using their Persona. Apple Vision Pro will add the capability to move captions using the window bar during Apple Immersive Video, as well as support for additional Made for iPhone hearing devices and cochlear hearing processors. Updates for vision accessibility will include the addition of Reduce Transparency, Smart Invert, and Dim Flashing Lights for users who have low vision, or those who want to avoid bright lights and frequent flashing.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, The Live Captions experience in visionOS is shown from an Apple Vision Pro user’s point of view.">
        <div>
             
              
              <div>
                visionOS will offer Live Captions, so users who are deaf or hard of hearing can follow along with spoken dialogue in live conversations and in audio from apps.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2024/05/apple-announces-new-accessibility-features-including-eye-tracking/article/Apple-accessibility-features-Apple-Vision-Pro-Live-Captions.zip" download="" data-analytics-title="download image - Apple-accessibility-features-Apple-Vision-Pro-Live-Captions_big" aria-label="Download media, The Live Captions experience in visionOS is shown from an Apple Vision Pro user’s point of view."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <div>These features join the dozens of accessibility features already available in Apple Vision Pro, which offers a flexible input system and an intuitive interface designed with a wide range of users in mind. Features such as VoiceOver, Zoom, and Color Filters can also provide users who are blind or have low vision access to spatial computing, while features such as Guided Access can support users with cognitive disabilities. Users can control Vision Pro with any combination of their eyes, hands, or voice, with accessibility features including Switch Control, Sound Actions, and Dwell Control that can also help those with physical disabilities.
</div>
                 
             
                 <div>“Apple Vision Pro is without a doubt the most accessible technology I’ve ever used,” said Ryan Hudson-Peralta, a Detroit-based product designer, accessibility consultant, and cofounder of Equal Accessibility LLC. “As someone born without hands and unable to walk, I know the world was not designed with me in mind, so it’s been incredible to see that visionOS just works. It’s a testament to the power and importance of accessible and inclusive design.”
</div>
                 
             
                 <h2><strong>Additional Updates</strong>
</h2>
                 
             
                 <div><ul>
<li>For users who are blind or have low vision, <strong>VoiceOver</strong> will include new voices, a flexible Voice Rotor, custom volume control, and the ability to customize VoiceOver keyboard shortcuts on Mac.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li><strong>Magnifier</strong> will offer a new Reader Mode and the option to easily launch Detection Mode with the Action button.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Braille users will get a new way to start and stay in <strong>Braille Screen Input</strong> for faster control and text editing; Japanese language availability for Braille Screen Input; support for multi-line braille with <strong>Dot Pad</strong>; and the option to choose different input and output tables.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>For users with low vision, <strong>Hover Typing</strong> shows larger text when typing in a text field, and in a user’s preferred font and color.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>For users at risk of losing their ability to speak, <strong>Personal Voice</strong> will be available in Mandarin Chinese. Users who have difficulty pronouncing or reading full sentences will be able to create a Personal Voice using shortened phrases.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>For users who are nonspeaking, <strong>Live Speech</strong> will include categories and simultaneous compatibility with <strong>Live Captions</strong>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>For users with physical disabilities, <strong>Virtual Trackpad</strong> for AssistiveTouch allows users to control their device using a small region of the screen as a resizable trackpad.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li><strong>Switch Control </strong>will include the option to use the cameras in iPhone and iPad to recognize finger-tap gestures as switches.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li><strong>Voice Control</strong> will offer support for custom vocabularies and complex words.</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="additional-accessibility-updates">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-fdea3498ac2a21e1b4faad11ec7721f4" href="#gallery-fdea3498ac2a21e1b4faad11ec7721f4" data-ac-gallery-trigger="gallery-fdea3498ac2a21e1b4faad11ec7721f4"><span>The new Reader Mode in Magnifier is shown on iPhone 15 Pro.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-7ba994d8fdada592fe798af2d946682c" href="#gallery-7ba994d8fdada592fe798af2d946682c" data-ac-gallery-trigger="gallery-7ba994d8fdada592fe798af2d946682c"><span>The Hover Typing experience is shown on iPhone 15 Pro.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-9deb1a63c2b363d38cc89c40fd39c6ec" href="#gallery-9deb1a63c2b363d38cc89c40fd39c6ec" data-ac-gallery-trigger="gallery-9deb1a63c2b363d38cc89c40fd39c6ec"><span>The Personal Voice experience is shown in Mandarin Chinese on Mac.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-fdea3498ac2a21e1b4faad11ec7721f4" aria-labelledby="gallery-dotnav-fdea3498ac2a21e1b4faad11ec7721f4" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:magnifier-reader-mode">
                                
                                <div>
                                    <div>Additional accessibility updates include a new Reader Mode in Magnifier.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/05/apple-announces-new-accessibility-features-including-eye-tracking/article/Apple-accessibility-features-Magnifier-Reader-Mode.zip" download="" data-analytics-title="download image - Apple-accessibility-features-Magnifier-Reader-Mode_big" aria-label="Download media, The new Reader Mode in Magnifier is shown on iPhone 15 Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-7ba994d8fdada592fe798af2d946682c" aria-labelledby="gallery-dotnav-7ba994d8fdada592fe798af2d946682c" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:hover-typing">
                                
                                <div>
                                    <div>Hover Typing shows larger text when typing in a text field, and in a user’s preferred font and color.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/05/apple-announces-new-accessibility-features-including-eye-tracking/article/Apple-accessibility-features-Hover-Typing.zip" download="" data-analytics-title="download image - Apple-accessibility-features-Hover-Typing_big" aria-label="Download media, The Hover Typing experience is shown on iPhone 15 Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-9deb1a63c2b363d38cc89c40fd39c6ec" aria-labelledby="gallery-dotnav-9deb1a63c2b363d38cc89c40fd39c6ec" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:personal-voice-for-mandarin">
                                
                                <div>
                                    <div>Personal Voice will be available in Mandarin Chinese for users at risk of losing their ability to speak.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/05/apple-announces-new-accessibility-features-including-eye-tracking/article/Apple-accessibility-features-Personal-Voice-in-Mandarin.zip" download="" data-analytics-title="download image - Apple-accessibility-features-Personal-Voice-in-Mandarin_big" aria-label="Download media, The Personal Voice experience is shown in Mandarin Chinese on Mac."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Celebrate Global Accessibility Awareness Day with Apple</strong>
</h2>
                 
             
                 <div>This week, Apple is introducing new features, curated collections, and more in celebration of Global Accessibility Awareness Day:
</div>
                 
             
                 <div><ul>
<li>Throughout the month of May, select <strong>Apple Store locations</strong> will host free sessions to help customers explore and discover accessibility features built into the products they love. Apple Piazza Liberty in Milan will feature the talent behind <a href="https://www.apple.com/it/today/event/talk-coordown-051624/7192194773665875456/?sn=R667" target="_blank">“Assume that I can,”</a> the viral campaign for World Down Syndrome Day. And available year-round at Apple Store locations globally, Today at Apple group reservations are a place where friends, families, schools, and community groups can learn about accessibility features together.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li><strong>Shortcuts</strong> adds <a href="https://www.icloud.com/shortcuts/fb786d920177410dba03ee31b171b9a5" target="_blank" rel="nofollow" data-analytics-exit-link="">Calming Sounds</a>, which plays ambient soundscapes to minimize distractions, helping users focus or rest.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Visit the <strong>App Store</strong> to discover <a href="https://apps.apple.com/story/id1744227708" target="_blank" rel="nofollow" data-analytics-exit-link="">incredible apps and games</a> that promote access and inclusion for all, including the accessible App Store Award-winning game Unpacking, apps as tools for augmentative and alternative communication (AAC), and more.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>The <strong>Apple TV app</strong> will honor trailblazing creators, performers, and activists who passionately share the experiences of people with disabilities. This year’s theme is <a href="https://tv.apple.com/room/edt.item.607f3a2b-fab0-45fb-a92a-e636f1131ca8" target="_blank" rel="nofollow" data-analytics-exit-link="">Remaking the World</a>, and each story invites viewers to envision a reality where everyone is empowered to add their voice to the greater human story.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li><strong>Apple Books</strong> will spotlight lived experiences of disability through curated collections of first-person narratives by disabled writers in ebook and audiobook formats.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li><strong>Apple Fitness+</strong> workouts, meditations, and trainer tips welcome users who are deaf or hard of hearing with American Sign Language, and Time to Walk now includes transcripts in the <strong>Apple Podcasts</strong> app. Fitness+ workouts always include Audio Hints to support users who are blind or have low vision, as well as modifiers so that users of all levels can participate.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Users can visit <strong>Apple Support </strong>to learn how their Apple devices can be customized using built-in accessibility features. From adapting the gestures to customizing how information is presented on a device’s screen, the <a href="https://apple.co/4adMekr" target="_blank" rel="nofollow" data-analytics-exit-link="">Apple Accessibility playlist</a> will help users learn how to personalize Apple Vision Pro, iPhone, iPad, Apple Watch, and Mac to work best for them.</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    






    
















	
	
	
		















	
	

</article>



</section>
</main>


	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jan Leike Resigns from OpenAI (208 pts)]]></title>
            <link>https://twitter.com/janleike/status/1790603862132596961</link>
            <guid>40367160</guid>
            <pubDate>Wed, 15 May 2024 14:08:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/janleike/status/1790603862132596961">https://twitter.com/janleike/status/1790603862132596961</a>, See on <a href="https://news.ycombinator.com/item?id=40367160">Hacker News</a></p>
Couldn't get https://twitter.com/janleike/status/1790603862132596961: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Open-source BI and analytics for engineers (202 pts)]]></title>
            <link>https://github.com/quarylabs/quary</link>
            <guid>40367090</guid>
            <pubDate>Wed, 15 May 2024 14:02:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/quarylabs/quary">https://github.com/quarylabs/quary</a>, See on <a href="https://news.ycombinator.com/item?id=40367090">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://quary.dev/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/fd38077185109c43513e5ef1ddef73853fa68649e5b9855e52edb7896351a166/68747470733a2f2f73746f726167652e676f6f676c65617069732e636f6d2f7075626c69635f686f737465645f6d6174657269616c732f71756172792e737667" height="128" data-canonical-src="https://storage.googleapis.com/public_hosted_materials/quary.svg">
    </a></p><p dir="auto"><h2 tabindex="-1" dir="auto">Quary</h2><a id="user-content-quary" aria-label="Permalink: Quary" href="#quary"></a></p>
    <p dir="auto"><h3 tabindex="-1" dir="auto">Business Intelligence for Engineers 🅀</h3><a id="user-content-business-intelligence-for-engineers-🅀" aria-label="Permalink: Business Intelligence for Engineers 🅀" href="#business-intelligence-for-engineers-🅀"></a></p>
  

<p dir="auto"><a href="https://www.quary.dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/0db84e4fbdb51e2ec8f3ee3325a4fdf464dc7fa68c5afd39e1f3c0b41953217f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d414445253230425925323051756172792d3030303030302e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d5175617279266c6162656c436f6c6f723d303030" alt="Made by Quary" data-canonical-src="https://img.shields.io/badge/MADE%20BY%20Quary-000000.svg?style=for-the-badge&amp;logo=Quary&amp;labelColor=000"></a>
<a href="https://join.slack.com/t/quarylabs/shared_invite/zt-2dlbfnztw-dMLXJVL38NcbhqRuM5gUcw" rel="nofollow"><img src="https://camo.githubusercontent.com/306ec3bfc44f9ea0852a63201ec124177fff81549e40087c5edf22f10a91a468/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f736c61636b2d407175617279636f6d6d756e6974792d3030303030302e7376673f7374796c653d666f722d7468652d6261646765266c6f676f3d736c61636b266c6162656c436f6c6f723d303030" alt="Slack Community" data-canonical-src="https://img.shields.io/badge/slack-@quarycommunity-000000.svg?style=for-the-badge&amp;logo=slack&amp;labelColor=000"></a>
<a href="https://www.ycombinator.com/companies/quary" rel="nofollow"><img src="https://camo.githubusercontent.com/687f45af50a437f0c74bedcbc4aa1ef462f3fbc644467128cd99ad1b5bf0ab25/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f59253230436f6d62696e61746f722d5732342d6f72616e67653f7374796c653d666f722d7468652d6261646765266c6f676f3d5175617279266c6162656c436f6c6f723d303030" alt="YC" data-canonical-src="https://img.shields.io/badge/Y%20Combinator-W24-orange?style=for-the-badge&amp;logo=Quary&amp;labelColor=000"></a>
<a href="https://github.com/quarylabs/quary"><img src="https://camo.githubusercontent.com/f542855cd17cb31f2ed91fc487a4d670955d6fe5316bf7c085aafcaafc5d3477/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f71756172796c6162732f71756172793f7374796c653d666f722d7468652d6261646765266c6f676f3d5175617279266c6162656c436f6c6f723d303030" alt="GitHub Repo stars" data-canonical-src="https://img.shields.io/github/stars/quarylabs/quary?style=for-the-badge&amp;logo=Quary&amp;labelColor=000"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">With Quary, engineers can:</h2><a id="user-content-with-quary-engineers-can" aria-label="Permalink: With Quary, engineers can:" href="#with-quary-engineers-can"></a></p>
<ul dir="auto">
<li>🔌 Connect to their Database</li>
<li>📖 Write SQL queries to transform, organize, and document tables in a database</li>
<li>📊 Create charts, dashboards and reports (in development)</li>
<li>🧪 Test, collaborate &amp; refactor iteratively through version control</li>
<li>🚀 Deploy the organised, documented model back up to the database</li>
</ul>
<p dir="auto">View the <a href="https://www.quary.dev/docs" rel="nofollow">documentation</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🗃️ Supported Databases</h2><a id="user-content-️-supported-databases" aria-label="Permalink: 🗃️ Supported Databases" href="#️-supported-databases"></a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/39325e2e61660cf8576a687cedca9ffcebd05fc65708b25778e14e93a0c2f9df/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f416d617a6f6e25323052656473686966742d3532374646463f7374796c653d666f722d7468652d6261646765266c6f676f3d416d617a6f6e2532305265647368696674266c6f676f436f6c6f723d7768697465"><img src="https://camo.githubusercontent.com/39325e2e61660cf8576a687cedca9ffcebd05fc65708b25778e14e93a0c2f9df/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f416d617a6f6e25323052656473686966742d3532374646463f7374796c653d666f722d7468652d6261646765266c6f676f3d416d617a6f6e2532305265647368696674266c6f676f436f6c6f723d7768697465" alt="Amazon Redshift" data-canonical-src="https://img.shields.io/badge/Amazon%20Redshift-527FFF?style=for-the-badge&amp;logo=Amazon%20Redshift&amp;logoColor=white"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/24e51ed66c655e60ee1c38c95790e8f4ebcc1cddfaabf9922d696acf2bdc45d9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f476f6f676c6525323042696751756572792d3432383546343f7374796c653d666f722d7468652d6261646765266c6f676f3d476f6f676c65253230436c6f7564266c6f676f436f6c6f723d7768697465"><img src="https://camo.githubusercontent.com/24e51ed66c655e60ee1c38c95790e8f4ebcc1cddfaabf9922d696acf2bdc45d9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f476f6f676c6525323042696751756572792d3432383546343f7374796c653d666f722d7468652d6261646765266c6f676f3d476f6f676c65253230436c6f7564266c6f676f436f6c6f723d7768697465" alt="Google BigQuery" data-canonical-src="https://img.shields.io/badge/Google%20BigQuery-4285F4?style=for-the-badge&amp;logo=Google%20Cloud&amp;logoColor=white"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/38f0c319f4d14f5f01953e495dd4932c800383b024ac991b46ffed3a99254ee8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f506f737467726553514c2d3333363739313f7374796c653d666f722d7468652d6261646765266c6f676f3d706f737467726573716c266c6f676f436f6c6f723d7768697465"><img src="https://camo.githubusercontent.com/38f0c319f4d14f5f01953e495dd4932c800383b024ac991b46ffed3a99254ee8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f506f737467726553514c2d3333363739313f7374796c653d666f722d7468652d6261646765266c6f676f3d706f737467726573716c266c6f676f436f6c6f723d7768697465" alt="PostgreSQL" data-canonical-src="https://img.shields.io/badge/PostgreSQL-336791?style=for-the-badge&amp;logo=postgresql&amp;logoColor=white"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/dc35a1d40a4c61e5b08851b29a05998c1150fa48e739484e1087bdd6ac9ac6b1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f536e6f77666c616b652d3239423545383f7374796c653d666f722d7468652d6261646765266c6f676f3d736e6f77666c616b65266c6f676f436f6c6f723d7768697465"><img src="https://camo.githubusercontent.com/dc35a1d40a4c61e5b08851b29a05998c1150fa48e739484e1087bdd6ac9ac6b1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f536e6f77666c616b652d3239423545383f7374796c653d666f722d7468652d6261646765266c6f676f3d736e6f77666c616b65266c6f676f436f6c6f723d7768697465" alt="Snowflake" data-canonical-src="https://img.shields.io/badge/Snowflake-29B5E8?style=for-the-badge&amp;logo=snowflake&amp;logoColor=white"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/e4ef8fd29c64e2f3043a67b93d0a78d353dd8be6aabd2da6fe933eb572831371/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f53757061626173652d3345434638453f7374796c653d666f722d7468652d6261646765266c6f676f3d7375706162617365266c6f676f436f6c6f723d7768697465"><img src="https://camo.githubusercontent.com/e4ef8fd29c64e2f3043a67b93d0a78d353dd8be6aabd2da6fe933eb572831371/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f53757061626173652d3345434638453f7374796c653d666f722d7468652d6261646765266c6f676f3d7375706162617365266c6f676f436f6c6f723d7768697465" alt="Supabase" data-canonical-src="https://img.shields.io/badge/Supabase-3ECF8E?style=for-the-badge&amp;logo=supabase&amp;logoColor=white"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/57689e4e589ad19e7470ed6281e71c5114ad988f72e280c7d56658bad2e72cca/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4475636b44422d4646463f7374796c653d666f722d7468652d6261646765266c6f676f3d6475636b6462266c6f676f436f6c6f723d626c61636b"><img src="https://camo.githubusercontent.com/57689e4e589ad19e7470ed6281e71c5114ad988f72e280c7d56658bad2e72cca/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4475636b44422d4646463f7374796c653d666f722d7468652d6261646765266c6f676f3d6475636b6462266c6f676f436f6c6f723d626c61636b" alt="DuckDB" data-canonical-src="https://img.shields.io/badge/DuckDB-FFF?style=for-the-badge&amp;logo=duckdb&amp;logoColor=black"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/da64cab451e08b0784e2872d8c2f7fdc3ba0dafb253e2bf975ac3ec06fb9751b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f53514c6974652d3030334235373f7374796c653d666f722d7468652d6261646765266c6f676f3d73716c697465266c6f676f436f6c6f723d7768697465"><img src="https://camo.githubusercontent.com/da64cab451e08b0784e2872d8c2f7fdc3ba0dafb253e2bf975ac3ec06fb9751b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f53514c6974652d3030334235373f7374796c653d666f722d7468652d6261646765266c6f676f3d73716c697465266c6f676f436f6c6f723d7768697465" alt="SQLite" data-canonical-src="https://img.shields.io/badge/SQLite-003B57?style=for-the-badge&amp;logo=sqlite&amp;logoColor=white"></a>
</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/quarylabs/quary/blob/main/assets/readme_demo.gif"><img src="https://github.com/quarylabs/quary/raw/main/assets/readme_demo.gif" alt="quary_core_image" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🏗️ Asset Types in Quary</h2><a id="user-content-️-asset-types-in-quary" aria-label="Permalink: 🏗️ Asset Types in Quary" href="#️-asset-types-in-quary"></a></p>
<p dir="auto">Define and manage the following asset types as code:</p>
<ul dir="auto">
<li><strong>Sources:</strong> Define the external data sources that feed into Quary, such as database tables, flat files, or APIs (with DuckDB).</li>
<li><strong>Models:</strong> Transform raw data from sources into analysis-ready datasets using SQL, this lets engineers split complex queries into atomic components.</li>
<li><strong>Charts:</strong> Create visual representations of your data using SQL.</li>
<li><strong>🚧 Dashboards (WIP):</strong> Combine multiple charts into a single view, allowing engineers to monitor and analyze data in one place.</li>
<li><strong>🚧 Reports (WIP):</strong> Create detailed reports to share insights and findings with your team or stakeholders.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Getting Started</h2><a id="user-content--getting-started" aria-label="Permalink: 🚀 Getting Started" href="#-getting-started"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Quary is a VSCode Extension (Interface) &amp; Rust-based CLI (Core)</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Extension</h4><a id="user-content-extension" aria-label="Permalink: Extension" href="#extension"></a></p>
<p dir="auto">The VSCode extension can be installed <a href="https://marketplace.visualstudio.com/items?itemName=Quary.quary-extension" rel="nofollow">here</a>. Note that it depends on the CLI being installed.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">CLI</h4><a id="user-content-cli" aria-label="Permalink: CLI" href="#cli"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Homebrew installation</h4><a id="user-content-homebrew-installation" aria-label="Permalink: Homebrew installation" href="#homebrew-installation"></a></p>
<div data-snippet-clipboard-copy-content="brew install quarylabs/quary/quary"><pre><code>brew install quarylabs/quary/quary
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Linux/Mac through curl</h4><a id="user-content-linuxmac-through-curl" aria-label="Permalink: Linux/Mac through curl" href="#linuxmac-through-curl"></a></p>
<p dir="auto">Quary can be installed using curl on Linux/Mac using the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -fsSL https://raw.githubusercontent.com/quarylabs/quary/main/install.sh | bash"><pre>curl -fsSL https://raw.githubusercontent.com/quarylabs/quary/main/install.sh <span>|</span> bash</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Other installations</h4><a id="user-content-other-installations" aria-label="Permalink: Other installations" href="#other-installations"></a></p>
<p dir="auto">Other builds are available in the <a href="https://github.com/quarylabs/quary/releases/latest">releases page</a> to download.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Once installed, a sample project can be created and run as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="mkdir example # create an empty project folder
cd example
quary init    # initialize DuckDB demo project with sample data
quary compile # validate the project structure and model references without database
quary build   # build and execute the model views/seeds against target database
quary test -s   # run defined tests against target database"><pre>mkdir example <span><span>#</span> create an empty project folder</span>
<span>cd</span> example
quary init    <span><span>#</span> initialize DuckDB demo project with sample data</span>
quary compile <span><span>#</span> validate the project structure and model references without database</span>
quary build   <span><span>#</span> build and execute the model views/seeds against target database</span>
quary <span>test</span> -s   <span><span>#</span> run defined tests against target database</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🅀 Community</h2><a id="user-content-🅀-community" aria-label="Permalink: 🅀 Community" href="#🅀-community"></a></p>
<p dir="auto"><a href="https://join.slack.com/t/quarylabs/shared_invite/zt-2dlbfnztw-dMLXJVL38NcbhqRuM5gUcw" rel="nofollow">Join our Slack channel</a>, for help, ideas, and discussions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Support</h2><a id="user-content-support" aria-label="Permalink: Support" href="#support"></a></p>
<p dir="auto">If you run into any problems using Quary, please let us know. We want Quary to be easy-to-use, so if you are getting
confused, it is our fault, not yours. <a href="https://github.com/quarylabs/quary/issues">Create an issue</a> and we'll be happy to
help you out.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Check out our other projects</h3><a id="user-content-check-out-our-other-projects" aria-label="Permalink: Check out our other projects" href="#check-out-our-other-projects"></a></p>
<p dir="auto"><a href="https://github.com/quarylabs/sqruff">SQRUFF</a>, a compact, high-speed SQL linter, engineered with Rust efficiency.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Worst Website in the Entire World (352 pts)]]></title>
            <link>https://matduggan.com/the-worst-website-in-the-entire-world/</link>
            <guid>40366962</guid>
            <pubDate>Wed, 15 May 2024 13:52:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matduggan.com/the-worst-website-in-the-entire-world/">https://matduggan.com/the-worst-website-in-the-entire-world/</a>, See on <a href="https://news.ycombinator.com/item?id=40366962">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
<p>What if you set out to make the worst website you possibly could? So poorly designed and full of frustrating patterns that users would not only hate the experience of using this website, but would also come to hate your company. Could we make a web experience so terrible that it would express how much our company hated our users? </p><p>As a long-time Internet addict, I've encountered my fair share of terrible websites. Instagram where now half my feed is advertisements for stupid t-shirts and the other half is empty black space. </p><figure><img src="https://matduggan.com/content/images/2024/05/image.png" alt="" loading="lazy" width="604" height="758" srcset="https://matduggan.com/content/images/size/w600/2024/05/image.png 600w, https://matduggan.com/content/images/2024/05/image.png 604w"><figcaption><span>Who in the fuck would ever wear this</span></figcaption></figure><p>Or ARNGREN.net which is like if a newspaper ad threw up on my screen. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-1.png" alt="" loading="lazy" width="816" height="684" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-1.png 600w, https://matduggan.com/content/images/2024/05/image-1.png 816w" sizes="(min-width: 720px) 720px"></figure><p>But Instagram still occasionally shows me pictures of people I follow and ultimately the stuff on ARNGREN is so cool I still want to buy it regardless of the layout. </p><p>No, I believe it is the crack team at Broadcom that have nailed it for the worst website in existence. </p><h3 id="lured-in-with-free-vmware">Lured in with free VMware </h3><p>So through social media I discovered this blog post from VMware announcing that their popular virtualization software is free for personal use now. <a href="https://blogs.vmware.com/cloud-foundation/2024/05/14/vmware-desktop-hypervisor-pro-apps-now-available-for-personal-use/" rel="noreferrer">You can read that here. </a> Great, I used VMware Fusion before and it was ok and maybe it will let me run Windows on an ARM Mac. Probably not but let's try it out and see. </p><blockquote>This means that everyday users who want a virtual lab on their Mac, Windows or Linux computer can do so <strong><em>for free</em></strong> simply by registering and downloading the latest build from the new download portal located at <a href="http://support.broadcom.com/">support.broadcom.com</a>. With the new commercial model, we have reduced our product group offerings down to a single SKU (VCF-DH-PRO) for users who require commercial use licensing. This simplification eliminates 40+ other SKUs and makes quoting and purchasing VMware Desktop Hypervisor apps, Fusion Pro and Workstation Pro, easier than ever. The new Desktop Hypervisor app subscription can be purchased from any Broadcom Advantage partner.</blockquote><p>I don't want to register at support.broadcom.com but it looks like I don't have a choice as this is the screen on the VMware site. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-2.png" alt="" loading="lazy" width="1118" height="453" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-2.png 600w, https://matduggan.com/content/images/size/w1000/2024/05/image-2.png 1000w, https://matduggan.com/content/images/2024/05/image-2.png 1118w" sizes="(min-width: 720px) 720px"></figure><p>Now this is where alarm bells start going crazy in my head. Nothing about this notice makes sense. "The store will be moving to a new domain". So it's...not...down for maintenance but actually is just gone? Or is it actually coming back? Because then you say "store will be shutdown" (just a quick note, you want "the store" and "will be shutting down on April 30th 2024"). Also why don't you just redirect to the new domain? What is happening here?</p><h3 id="broadcom">Broadcom</h3><p>So then I go to support.broadcom.com which is where I was told to register and make an account. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-3.png" alt="" loading="lazy" width="1552" height="1039" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-3.png 600w, https://matduggan.com/content/images/size/w1000/2024/05/image-3.png 1000w, https://matduggan.com/content/images/2024/05/image-3.png 1552w" sizes="(min-width: 720px) 720px"></figure><p>Never a <em>great sign</em> when there's a link to an 11 page PDF of how to navigate your website. That's the "Learn how to navigate Broadcom Support" link. You can download that killer doc here: <a href="https://support.broadcom.com/documents/d/ecx/broadcom-support-portal-getting-started-guide">https://support.broadcom.com/documents/d/ecx/broadcom-support-portal-getting-started-guide</a></p><p> Alright let's register. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-4.png" alt="" loading="lazy" width="1373" height="746" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-4.png 600w, https://matduggan.com/content/images/size/w1000/2024/05/image-4.png 1000w, https://matduggan.com/content/images/2024/05/image-4.png 1373w" sizes="(min-width: 720px) 720px"></figure><p>First the sentence "Enhance your skills through multiple self-service avenues by creating your Broadcom Account" leaps off the page as just pure corporate nonsense. I've also never seen a less useful CAPTCHA, it looks like it is from 1998 and any modern text recognition software would defeat it. In fact the Mac text recognition in Preview defeats 3 of the 4 characters with no additional work:</p><figure><img src="https://matduggan.com/content/images/2024/05/image-5.png" alt="" loading="lazy" width="412" height="173"></figure><p>So completely pointless and user hostile. Scoring lots of points for the worst website ever. I'm also going to give some additional points for "Ask our chatbot for assistance", an idea so revolting normally I'd just give up on the entire idea. But of course I'm curious, so I click on the link for the "Ask our chatbot" and.....</p><p><strong>It takes me back to the main page. </strong></p><figure><img src="https://matduggan.com/content/images/2024/05/image-6.png" alt="" loading="lazy" width="1471" height="1026" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-6.png 600w, https://matduggan.com/content/images/size/w1000/2024/05/image-6.png 1000w, https://matduggan.com/content/images/2024/05/image-6.png 1471w" sizes="(min-width: 720px) 720px"></figure><p>Slow clap Broadcom. Imagine being a customer that is so frustrated with your support portal that you actually click "Ask a chatbot" and the web developers at Broadcom come by and karate chop you right in the throat. Bravo. Now in Broadcom's defense in the corner IS a chatbot icon so I kinda see what happened here. Let's ask it a question. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-7.png" alt="" loading="lazy" width="349" height="595"></figure><p>I didn't say hello. I don't know why it decided I said hello to it. But in response to VMware it gives me this: </p><figure><img src="https://matduggan.com/content/images/2024/05/image-8.png" alt="" loading="lazy" width="325" height="545"></figure><p>Did the chatbot just tell me to go fuck myself? Why did you make a chatbot if all you do is select a word from a list and it returns the link to the support doc? Would I like to "Type a Query"?? WHAT IS A CHATBOT IF NOT TYPING QUERIES? </p><figure><img src="https://f4.bcbits.com/img/a1708837337_65" alt="Radio | Thanks! I Hate It" loading="lazy" width="700" height="700"></figure><h3 id="next-steps">Next Steps</h3><p>I fill in the AI-proof CAPTCHA and hit next, only to be greeted with the following screen for 30 seconds. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-9.png" alt="" loading="lazy" width="639" height="607" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-9.png 600w, https://matduggan.com/content/images/2024/05/image-9.png 639w"></figure><p>Finally I'm allowed to make my user account. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-10.png" alt="" loading="lazy" width="674" height="359" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-10.png 600w, https://matduggan.com/content/images/2024/05/image-10.png 674w"></figure><p>Um....alright....seems like overkill Broadcom but you know what this is your show. I have 1Password so this won't be a problem. It's not letting me copy/paste from 1Password into this field but if I do Command + \ it seems to let me insert. Then I get this. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-11.png" alt="" loading="lazy" width="673" height="385" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-11.png 600w, https://matduggan.com/content/images/2024/05/image-11.png 673w"></figure><p>What are you doing to me Broadcom. Did I....wrong you in some way? I don't understand what is happening. Ok well I refresh the page, try again and it works this time. Except I can't copy/paste into the Confirm Password field. </p><p>I mean they can't expect me to type out the impossibly complicated password they just had me generate right? Except they have and they've added a check to ensure that I don't disable Javascript and treat it like a normal HTML form. </p><p>Hey front-end folks, just a quick note. Never ever ever ever ever mess with my browser. It's not yours, it's mine. I'm letting you use it for free to render your bloated sites. Don't do this to me. I get to copy paste whatever I want whenever I want. When you get your own browser you can do whatever you want but while you are living in my house under my rules I get to copy/paste whenever I goddamn feel like it. </p><h3 id="quickly-losing-enthusiasm-for-the-idea-of-vmware">Quickly losing enthusiasm for the idea of VMware</h3><p>So after pulling up the password and typing it in, I'm treated to this absolutely baffling screen. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-12.png" alt="" loading="lazy" width="459" height="982"></figure><p>Do I need those? I feel like I might need those. eStore at least sounds like something I might want. I don't really want Public Semiconductors Case Management but I guess that one comes in the box. 44 seconds of this icon later </p><figure><img src="https://matduggan.com/content/images/2024/05/image-14.png" alt="" loading="lazy" width="353" height="270"></figure><p>I'm treated to the following. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-15.png" alt="" loading="lazy" width="585" height="749"></figure><p>Broadcom, you clever bastards. Just when I thought I was out, they pulled me back in. Tricking users into thinking a link is going to help them and then telling them to get fucked by advising them to contact your sales rep? Genius. </p><p>So then I hit cancel and get bounced back to......you guessed it!</p><figure><img src="https://matduggan.com/content/images/2024/05/image-16.png" alt="" loading="lazy" width="1269" height="950" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-16.png 600w, https://matduggan.com/content/images/size/w1000/2024/05/image-16.png 1000w, https://matduggan.com/content/images/2024/05/image-16.png 1269w" sizes="(min-width: 720px) 720px"></figure><p>Except I'm not even logged into my newly created account. So then I go to login with my new credentials and I <em>finally</em> make it to my customer portal. Well no first they need to redirect me <strong>back </strong>to the Broadcom Support main page again with new icons.</p><figure><img src="https://matduggan.com/content/images/2024/05/image-17.png" alt="" loading="lazy" width="556" height="142"></figure><p>Apparently my name was too long to show and instead of fixing that or only showing first name Broadcom wanted to ensure the disrespect continued and sorta trail off. Whatever, I'm finally in the Matrix. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-18.png" alt="" loading="lazy" width="2000" height="1042" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-18.png 600w, https://matduggan.com/content/images/size/w1000/2024/05/image-18.png 1000w, https://matduggan.com/content/images/size/w1600/2024/05/image-18.png 1600w, https://matduggan.com/content/images/2024/05/image-18.png 2157w" sizes="(min-width: 720px) 720px"></figure><p>Now where might I go to...actually download some VMware software. There's a search bar that says "Search the entire site", let's start there!</p><figure><img src="https://matduggan.com/content/images/2024/05/image-19.png" alt="" loading="lazy" width="1913" height="1107" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-19.png 600w, https://matduggan.com/content/images/size/w1000/2024/05/image-19.png 1000w, https://matduggan.com/content/images/size/w1600/2024/05/image-19.png 1600w, https://matduggan.com/content/images/2024/05/image-19.png 1913w" sizes="(min-width: 720px) 720px"></figure><p>Nothing found except for a CVE. Broadcom you are GOOD! For a second I thought you were gonna help me and like Lucy with the football you made me eat shit again. </p><figure><img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS57-zFKu0g-ZID6cNw0ZyMZlELK7wodVkSkKL_GA1GCg&amp;s" alt="Lucy and the football - John Quiggin's Blogstack" loading="lazy" width="275" height="183"></figure><p><strong>My Downloads</strong> was also unhelpful. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-20.png" alt="" loading="lazy" width="1916" height="520" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-20.png 600w, https://matduggan.com/content/images/size/w1000/2024/05/image-20.png 1000w, https://matduggan.com/content/images/size/w1600/2024/05/image-20.png 1600w, https://matduggan.com/content/images/2024/05/image-20.png 1916w" sizes="(min-width: 720px) 720px"></figure><p>But maybe I can add the entitlement to the account? Let's try All Products. </p><figure><iframe src="https://player.vimeo.com/video/946568812?app_id=122963" width="426" height="240" frameborder="0" allow="autoplay; fullscreen; picture-in-picture; clipboard-write" title="Screen Recording 2024-05-15 at 14.26.33"></iframe></figure><p>Of course the link doesn't work. What was I even thinking trying that? That one is really on me. However "All Products" on the left-hand side works and finally I find it. My white whale. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-21.png" alt="" loading="lazy" width="905" height="218" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-21.png 600w, https://matduggan.com/content/images/2024/05/image-21.png 905w" sizes="(min-width: 720px) 720px"></figure><p>Except when I click on product details I'm brought back to....</p><figure><img src="https://matduggan.com/content/images/2024/05/image-22.png" alt="" loading="lazy" width="935" height="947" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-22.png 600w, https://matduggan.com/content/images/2024/05/image-22.png 935w" sizes="(min-width: 720px) 720px"></figure><p>The blank page with no information! Out of frustration I click on "My Downloads" again which is now magically full of links! Then I see it!</p><figure><img src="https://matduggan.com/content/images/2024/05/image-23.png" alt="" loading="lazy" width="934" height="572" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-23.png 600w, https://matduggan.com/content/images/2024/05/image-23.png 934w" sizes="(min-width: 720px) 720px"></figure><p>YES. Clicking on it I get my old buddy the Broadcom logo for a solid <em>2 minutes 14 seconds</em>.</p><figure><img src="https://matduggan.com/content/images/2024/05/image-24.png" alt="" loading="lazy" width="932" height="658" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-24.png 600w, https://matduggan.com/content/images/2024/05/image-24.png 932w" sizes="(min-width: 720px) 720px"></figure><p>Now I have fiber internet with 1000 down, so this has nothing to do with me. Finally I click the download button and I get.....the Broadcom logo again. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-25.png" alt="" loading="lazy" width="940" height="608" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-25.png 600w, https://matduggan.com/content/images/2024/05/image-25.png 940w" sizes="(min-width: 720px) 720px"></figure><p>30 seconds pass. 1 minute passes. 2 minutes pass. I'm not sure what to do. </p><figure><img src="https://matduggan.com/content/images/2024/05/image-26.png" alt="" loading="lazy" width="393" height="120"></figure><p>No. No you piece of shit website. I've come <em>too far</em> and sacrificed too much of my human dignity. I am getting a fucking copy of VMware Fusion. Try 2 is the same thing. 3, 4, 5 all fail. Then finally.</p><figure><img src="https://matduggan.com/content/images/2024/05/image-27.png" alt="" loading="lazy" width="478" height="72"></figure><p>I install it and like a good horror movie, I think it's all over. I've killed Jason. Except when I'm installing Windows I see this little link:</p><figure><img src="https://matduggan.com/content/images/2024/05/image-28.png" alt="" loading="lazy" width="638" height="507" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-28.png 600w, https://matduggan.com/content/images/2024/05/image-28.png 638w"></figure><p>And think "wow I would like to know what the limitations are for Windows 11 for Arm!". Click on it and I'm redirected to...</p><figure><img src="https://matduggan.com/content/images/2024/05/image-29.png" alt="" loading="lazy" width="1187" height="918" srcset="https://matduggan.com/content/images/size/w600/2024/05/image-29.png 600w, https://matduggan.com/content/images/size/w1000/2024/05/image-29.png 1000w, https://matduggan.com/content/images/2024/05/image-29.png 1187w" sizes="(min-width: 720px) 720px"></figure><p>Just one final fuck you from the team at Broadcom. </p><h3 id="conclusion">Conclusion</h3><p>I've used lots of bad websites in my life. Hell, I've made a lot of bad websites in my life. But never before have I seen a website that so completely expresses just the pure hatred of users like this one. Everything was as poorly designed as possible, with user hostile design at every corner.</p><p>Honestly Broadcom, I don't even know why you bothered buying VMware. It's impossible for anyone to ever get this product from you. Instead of migrating from the VMware store to this disaster, maybe just shut this down entirely. Destroy the backups of this dumpster fire and start fresh. Maybe just consider a Shopify site because at least then an average user might have a snowballs chance in hell of ever finding something to download from you. </p><p>Do you know of a worse website? I want to see it. <a href="https://c.im/@matdevdug">https://c.im/@matdevdug</a></p><figure><img src="http://i1.kym-cdn.com/photos/images/newsfeed/000/614/639/9df.gif" alt="" loading="lazy" width="480" height="360"></figure>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What went wrong with UniSuper and Google Cloud? (107 pts)]]></title>
            <link>https://danielcompton.net/google-cloud-unisuper</link>
            <guid>40366867</guid>
            <pubDate>Wed, 15 May 2024 13:43:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danielcompton.net/google-cloud-unisuper">https://danielcompton.net/google-cloud-unisuper</a>, See on <a href="https://news.ycombinator.com/item?id=40366867">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<article>
    <header>
        
            
        
    </header>

<p>Over the past two weeks, UniSuper, an Australian superannuation fund, faced every cloud user’s nightmare: their cloud provider deleted their data. From May 2nd to 13th, UniSuper experienced a major outage and in several updates <a href="https://www.unisuper.com.au/contact-us/outage-update">blamed Google Cloud</a> for the incident.</p>
<blockquote>
<p>The disruption of UniSuper services was caused by a combination of rare issues at Google Cloud that resulted in an inadvertent misconfiguration during the provisioning of UniSuper’s Private Cloud, which triggered a previously unknown software bug that impacted UniSuper’s systems. This was an unprecedented occurrence, and measures have been taken to ensure this issue does not happen again.</p>
</blockquote>
<p>This culminated in a <a href="https://www.unisuper.com.au/about-us/media-centre/2024/a-joint-statement-from-unisuper-and-google-cloud">press release</a>, jointly signed by Google Cloud CEO Thomas Kurian. They make it sound like an exotic, one-of-a-kind bug in Google Cloud, though after some research, I’m not entirely convinced.</p>
<blockquote>
<p>Google Cloud CEO, Thomas Kurian has confirmed that the disruption arose from an unprecedented sequence of events whereby an inadvertent misconfiguration during provisioning of UniSuper’s Private Cloud services ultimately resulted in the deletion of UniSuper’s Private Cloud subscription.</p>
<p>This is an isolated, ‘one-of-a-kind occurrence’ that has never before occurred with any of Google Cloud’s clients globally. This should not have happened. Google Cloud has identified the events that led to this disruption and taken measures to ensure this does not happen again.</p>
<p>UniSuper had duplication in two geographies as a protection against outages and loss. However, when the deletion of UniSuper’s Private Cloud subscription occurred, it caused deletion across both of these geographies.</p>
<p>Restoring UniSuper’s Private Cloud instance has called for an incredible amount of focus, effort, and partnership between our teams to enable an extensive recovery of all the core systems. The dedication and collaboration between UniSuper and Google Cloud has led to an extensive recovery of our Private Cloud which includes hundreds of virtual machines, databases and applications.</p>
</blockquote>
<p>The press release uses vague language, obscuring the technical details of what happened. Given the lack of precision, I assumed this was written solely by UniSuper. Gergely Orosz <a href="https://x.com/GergelyOrosz/status/1788531368701346100">checked</a> with Google Cloud, and they confirmed that this was an official joint statement.</p>
<p>Given the few details provided, I did more research to try to understand what exactly happened.</p>
<h2 id="what-was-deleted">What was deleted?</h2>
<p>Google Cloud doesn’t have a resource called a “Subscription”; the closest concept would probably be a “Billing Account.” While Google has a Virtual Private Cloud (VPC), you wouldn’t describe it as an instance, and deleting a VPC doesn’t seem like it would have the drastic effects described.</p>
<p>However, if you research UniSuper’s Google Cloud migration, you will see that they use <a href="https://cloud.google.com/vmware-engine?hl=en">Google Cloud VMWare Engine</a> (GCVE). From <a href="https://www.itnews.com.au/news/unisuper-60-percent-complete-in-cloud-shift-596583">June 2023</a>:</p>
<blockquote>
<p>The superannuation fund has shifted almost all non-production workloads out of its data centres and into Google Cloud so far.</p>
<p><strong>UniSuper used the Google VMware Engine (GCVE) managed service</strong> and engaged partner Kasna to assist with the migration.</p>
</blockquote>
<p>GCVE has a resource called a <a href="https://cloud.google.com/vmware-engine/docs/concepts-private-cloud">private cloud</a>. A private cloud contains the hosts, management server, storage, and networking for a <a href="https://docs.vmware.com/en/VMware-Cloud-Provider-Stack/index.html">VMware stack</a>.</p>
<p>Let’s look at the <a href="https://cloud.google.com/vmware-engine/docs/reference/rest/v1/projects.locations.privateClouds/delete">API method</a> for <a href="https://cloud.google.com/vmware-engine/docs/private-clouds/howto-delete-private-cloud#delete_a_private_cloud">deleting a private cloud</a>:</p>
<blockquote>
<p>A PrivateCloud resource scheduled for deletion has PrivateCloud.state set to DELETED and expireTime set to the time when deletion is final and can no longer be reversed. The delete operation is marked as done as soon as the PrivateCloud is successfully scheduled for deletion (this also applies when delayHours is set to zero), and the operation is not kept in pending state until PrivateCloud is purged. PrivateCloud can be restored using privateClouds.undelete method before the expireTime elapses. <strong>When expireTime is reached, deletion is final and all private cloud resources are irreversibly removed and billing stops.</strong></p>
</blockquote>
<p>All private cloud resources being irreversibly removed sounds a lot like the outage that UniSuper had. Some people have said that Google deleted their entire Google Cloud account. This seems less likely to me because Google has a number of safeguards and delays when <a href="https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects">deleting projects</a>:</p>
<blockquote>
<p>Warning: You can recover most resources if you restore a project within the 30-day period. Some services have delays in restoring and you might need to wait some time for services to be restored. Some resources, such as Cloud Storage or Pub/Sub resources, are deleted much sooner. These resources might not be fully recoverable even if you restore the project within the 30-day period.</p>
</blockquote>
<h2 id="how-did-everything-get-deleted">How did everything get deleted?</h2>
<p>UniSuper’s press release says:</p>
<blockquote>
<p>UniSuper had duplication in two geographies as a protection against outages and loss. However, when the deletion of UniSuper’s Private Cloud subscription occurred, it caused deletion across both of these geographies.</p>
</blockquote>
<p>Again, the language here is frustratingly vague and passive but implies that Google Cloud deleted multiple independent private clouds in separate regions. Google Cloud doesn’t have a “geography”; it has <a href="https://cloud.google.com/about/locations">zones and regions</a>. At first read, it sounds like they are describing a multi-region setup. Google Cloud has two Australian regions, Sydney and Melbourne, which would make sense.</p>
<p>Looking closer at the docs, though, GCVE offers two kinds of private clouds: a standard private cloud hosted in a single zone or a “<a href="https://cloud.google.com/vmware-engine/docs/private-clouds/howto-create-stretched-private-cloud">stretched private cloud</a>”. A stretched private cloud runs in a single region across two zones, with a third zone as a witness zone for failover. A close reading of the press release doesn’t rule out UniSuper having a single stretched private cloud running in a single region.</p>
<p>So we either have a single stretched private cloud being deleted or two separate private clouds being deleted. A single stretched private cloud seems more likely to me, but I can’t be definitive.</p>
<h2 id="how-was-it-deleted">How was it deleted?</h2>
<p>So we come to the big question: How were the private cloud(s) deleted? The press release makes heroic use of the passive voice to obscure the actors: “an unprecedented sequence of events whereby an inadvertent misconfiguration during provisioning of UniSuper’s Private Cloud services ultimately resulted in the deletion of UniSuper’s Private Cloud subscription.”</p>
<p>Based on my experiences with Google Cloud’s professional services team, they, and presumably their partners, recommend Terraform for defining infrastructure as code. This leads to several possible interpretations of this sentence:</p>
<ol>
<li>UniSuper ran a <code>terraform apply</code> with Terraform code that was “misconfigured”. This triggered a bug in Google Cloud, and Google Cloud accidentally deleted the private cloud.</li>
</ol>
<p>This is what UniSuper has implied or stated throughout the outage.</p>
<ol start="2">
<li>UniSuper ran a <code>terraform apply</code> with a bad configuration or perhaps a <code>terraform destroy</code> with the prod <a href="https://developer.hashicorp.com/terraform/language/values/variables#variable-definitions-tfvars-files">tfvar file</a>. The Terraform plan showed “delete private cloud,” and the operator approved it.</li>
</ol>
<p>Automation errors like this happen every day, although they aren’t usually this catastrophic. This seems more plausible to me than a rare one-in-a-million bug that only affected UniSuper.</p>
<ol start="3">
<li>UniSuper ran an automation script provided by Google Cloud’s professional services team with a bug. A misconfiguration caused the script to go off the rails. The operator was asked whether to delete the production private cloud, and they said yes.</li>
</ol>
<p>I find this less plausible, but it is one way to interpret Google Cloud as being at fault for what sounds like a customer error in automation.</p>
<h2 id="maybe-it-was-a-google-cloud-bug">Maybe it was a Google Cloud bug?</h2>
<p>There are a few holes in my theory that this was primarily UniSuper’s fault:</p>
<ol>
<li>On <a href="https://www.unisuper.com.au/contact-us/outage-update">Tuesday, 7 May</a>, UniSuper attributed a statement to Google Cloud in which Google Cloud admitted fault for the outage:</li>
</ol>
<blockquote>
<p>The disruption of UniSuper services was caused by a combination of rare issues at Google Cloud that resulted in an inadvertent misconfiguration during the provisioning of UniSuper’s Private Cloud, which triggered a previously unknown software bug that impacted UniSuper’s systems. This was an unprecedented occurrence, and measures have been taken to ensure this issue does not happen again.</p>
</blockquote>
<ol start="2">
<li>
<p>Thomas Kurian (apparently) signed off on a joint statement with UniSuper. This statement is less accusatory than UniSuper’s other statements but doesn’t clarify which party was at fault.</p>
</li>
<li>
<p>Google Cloud hasn’t released any pushback to the story, either directly or through proxies in the media.</p>
</li>
</ol>
<p>Why would Google Cloud not respond to this story if it was UniSuper’s fault? It’s hard to say, but putting out a competing statement blaming or contradicting your customer is a bad look with that customer and <a href="https://x.com/patio11/status/1789061633865597309">with all future customers</a>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Given how little detail was communicated, it is difficult to make a conclusive statement about what happened, though I personally suspect UniSuper operator error was a large factor. Hopefully, <a href="https://www.apra.gov.au/">APRA</a>, Australia’s superannuation regulator, will investigate further and release a public report with more details.</p>



</article>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Proteins in blood could provide early cancer warning 'by more than seven years' (294 pts)]]></title>
            <link>https://www.theguardian.com/society/article/2024/may/15/proteins-blood-cancer-warning-seven-years-study</link>
            <guid>40366443</guid>
            <pubDate>Wed, 15 May 2024 13:11:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/society/article/2024/may/15/proteins-blood-cancer-warning-seven-years-study">https://www.theguardian.com/society/article/2024/may/15/proteins-blood-cancer-warning-seven-years-study</a>, See on <a href="https://news.ycombinator.com/item?id=40366443">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Proteins in the blood could warn people of cancer more than seven years before it is diagnosed, according to <a href="https://www.nature.com/articles/s41467-024-48017-6" data-link-name="in body link">research</a>.</p><p>Scientists at the <a href="https://www.theguardian.com/education/oxforduniversity" data-link-name="in body link" data-component="auto-linked-tag">University of Oxford</a> studied blood samples from more than 44,000 people in the UK Biobank, including over 4,900 people who subsequently had a cancer diagnosis.</p><p>They compared the proteins of people who did and did not go on to be diagnosed with cancer and identified 618 proteins linked to 19 types of cancer, including colon, lung, non-Hodgkin lymphoma and liver.</p><p>The study, funded by <a href="https://www.theguardian.com/society/cancer" data-link-name="in body link" data-component="auto-linked-tag">Cancer</a> Research UK and published in Nature Communications, also found 107 proteins associated with cancers diagnosed more than seven years after the patient’s blood sample was collected and 182 proteins that were strongly associated with a cancer diagnosis within three years.</p><p>​The authors concluded that some of these proteins could be used to detect cancer much earlier and potentially provide new treatment options, though further research was needed.​</p><p>Dr Keren Papier, a senior nutritional epidemiologist at <a href="https://www.ndph.ox.ac.uk/" data-link-name="in body link">Oxford Population Health</a> at the University of Oxford and joint first author of the study, said: “To save more lives from cancer, we need to better understand what happens at the earliest stages of the disease … [and] how the proteins in our blood can affect our risk of cancer. Now we need to study these proteins in depth to see which ones could be reliably used for prevention.”</p><p>A second linked study looking at genetic data from more than 300,000 cancer cases <a href="https://www.nature.com/articles/s41467-024-46834-3." data-link-name="in body link">found 40 proteins in the blood</a> that influenced someone’s risk of getting nine types of cancer. While altering these proteins may increase or decrease the chances of someone developing cancer, in some cases this could lead to unintended side-effects, the authors found.</p><p>Mark Lawler, the chair in translational cancer genomics and professor of digital health at Queen’s University Belfast, said: “The data are impressive – finding evidence of cancer before it has manifested itself clinically provides a critical window of opportunity to treat with a greater chance for success, or even more importantly to achieve the holy grail of preventing cancer before it can even occur. More work to be done, but an important step forward in a disease that affects one in two of UK citizens during their lives.”</p><p>​Lawrence Young, a professor of molecular oncology at the University of Warwick, said the findings were another step towards identifying markers of increased cancer risk as well as those aiding early cancer diagnosis.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-9">skip past newsletter promotion</a><p id="EmailSignup-skip-link-9" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>“Determining protein changes that precede the development of cancer is not only important in identifying high-risk individuals but could also provide insights into factors responsible for causing cancer.”​</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I coded something dumb and I'm proud of it (145 pts)]]></title>
            <link>https://plbrault.com/blog-posts/i-coded-something-dumb-and-im-proud-of-it-en/</link>
            <guid>40366323</guid>
            <pubDate>Wed, 15 May 2024 12:58:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://plbrault.com/blog-posts/i-coded-something-dumb-and-im-proud-of-it-en/">https://plbrault.com/blog-posts/i-coded-something-dumb-and-im-proud-of-it-en/</a>, See on <a href="https://news.ycombinator.com/item?id=40366323">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I recently got back into the development of an open source game I released last summer, <em><a href="https://plbrault.com/blog-posts/i-created-the-nerdierst-game-ever-en/">You're the OS!</a></em>. It is a browser game, written in Python and compiled to WebAssembly, in which, as the title indicates, you are the operating system of a computer. As such, you have to manage processes, memory and I/O events.</p>
<p>In case you haven't played the game, here is a very short summary of its core mechanics: you have some CPU cores, and you have a list of processes with varying levels of starvation, and you have to make them take turns on CPU cores and make sure none of them starves.</p>
<p>
    <img alt="A glimpse of the game" src="https://plbrault.com/blog-images/youre-the-os.png">
</p>
<p>Recently, I added a power-up to the game: after 6 minutes of playing, you get a <code>Sort</code> button that, when clicked, sorts idle processes in decreasing order of starvation. I decided that the game would show the sorting algorithm being executed, by moving around processes as it happens. The sorting algorithm I wanted to use is <a href="https://en.wikipedia.org/wiki/Quicksort">Quicksort</a>. In order for it to work like I wanted, there was 2 problems to overcome:</p>
<p>1 - This is a game, with a main loop that completely redraws everything on the screen 60 times per second. Therefore, it was not just a matter of writing a Quicksort function that performs an animation between each recursion. I needed to somehow create a function that performs a single step of the algorithm, then gives back control to the main loop (which ironically sounds just like an OS' preemptive scheduling) for the duration of the animation frames, before being executed again from where it was interrupted.</p>
<p>2 - Just to make it more complicated, the list can change <em>while</em> it is being sorted, as processes can be killed, assigned to a CPU core, or removed from a CPU core.</p>
<p>Now, I want to share a comment from my code, detailing the solution that I came up with. I am quite proud of my solution, but not because it is particularly clever — on the contrary, <strong>I like it precisely because it is dumb</strong>:</p>
<blockquote>
<p><em>This method creates the visual illusion that the next recursion of the quicksort algorithm is performed on the idle processes. In reality, the algorithm is always performed from the beginning, and stops as soon as a recursion that actually changes the array has happened. This way, the intended in-game result is achieved while avoiding the need to keep track of the algorithm's state, and a correct end result is ensured even when the idle process list changes between recursions.</em></p>
</blockquote>
<p>To try and better explain what the comment means, here is the code of my Quicksort function that stops as soon as an actual change to the array is detected:</p>

<pre><code><span>def</span> <span>simulate_next_sort_step</span>(<span>arr</span>: [<span>Process</span>]):
    <span># Standard Quicksort operations</span>
    <span>if</span> <span>len</span>(<span>arr</span>) <span>&lt;=</span> <span>1</span>:
        <span>return</span> <span>arr</span>
    <span>pivot</span> = <span>arr</span>[<span>len</span>(<span>arr</span>) <span>//</span> <span>2</span>]
    <span>left</span> = [<span>process</span> <span>for</span> <span>process</span> <span>in</span> <span>arr</span> <span>if</span> <span>process</span>.<span>sort_key</span> <span>&lt;</span> <span>pivot</span>.<span>sort_key</span>]
    <span>middle</span> = [<span>process</span> <span>for</span> <span>process</span> <span>in</span> <span>arr</span> <span>if</span> <span>process</span>.<span>sort_key</span> <span>==</span> <span>pivot</span>.<span>sort_key</span>]
    <span>right</span> = [<span>process</span> <span>for</span> <span>process</span> <span>in</span> <span>arr</span> <span>if</span> <span>process</span>.<span>sort_key</span> <span>&gt;</span> <span>pivot</span>.<span>sort_key</span>]

    <span>""" The magic happens here: we proceed to the next recursion only if
        the current one didn't actually change anything. """</span>
    <span>if</span> (<span>left</span> <span>+</span> <span>middle</span> <span>+</span> <span>right</span>) <span>==</span> <span>arr</span>:
        <span>return</span> <span>simulate_next_sort_step</span>(<span>left</span>) <span>+</span> <span>middle</span> <span>+</span> <span>simulate_next_sort_step</span>(<span>right</span>)
    <span>return</span> <span>left</span> <span>+</span> <span>middle</span> <span>+</span> <span>right</span>
</code></pre>
<p>You see, I realized along the way that the premise of my first problem described above was mistaken: my need was not, in fact, to implement a function that only executes the next recursion in the quicksort algorithm. My need was to implement an animation that <em>pretends</em> to only execute the next recursion in the quicksort algorithm. My solution does exactly that, in a stateless manner. It is a stupid, inefficient solution — but it is a solution that works, and completely avoids the corner case stated in my second problem: if the content of the array changes along the way, it will naturally cause the illusion of backtracking in the algorithm.</p>
<p>Of course, I could have gone through the trouble of actually figuring out a version of Quicksort that resumes from the previous function call and only executes one recursion. This would have been way more efficient, algorithmically speaking. But it would have also been way more complex, would have produced code that was harder to understand, and would have required addressing corner cases.</p>
<p>The thing is: I did not need the efficiency. This is a terrible implementation of Quicksort, but that terribleness does not really make a dent in the game's performance, knowing that the number of processes that need to be sorted at all times will never exceed 42 — which is a lot for the players of my game, but is nothing for an actual computer.</p>
<p>This solution that I came up with is a testament to the KISS principle (<em>"Keep It Simple, Stupid"</em>). It is also a good reminder that part of finding a good solution to a problem is to make sure that the problem is correctly identified.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nearly all Nintendo 64 games can now be recompiled into native PC ports (313 pts)]]></title>
            <link>https://www.tomshardware.com/video-games/nearly-all-nintendo-64-games-can-now-be-recompiled-into-native-pc-ports-to-add-proper-ray-tracing-ultrawide-high-fps-and-more</link>
            <guid>40366204</guid>
            <pubDate>Wed, 15 May 2024 12:48:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/video-games/nearly-all-nintendo-64-games-can-now-be-recompiled-into-native-pc-ports-to-add-proper-ray-tracing-ultrawide-high-fps-and-more">https://www.tomshardware.com/video-games/nearly-all-nintendo-64-games-can-now-be-recompiled-into-native-pc-ports-to-add-proper-ray-tracing-ultrawide-high-fps-and-more</a>, See on <a href="https://news.ycombinator.com/item?id=40366204">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-320-80.png.webp 320w, https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-1200-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-1920-80.png.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-320-80.png" alt="Demonstration of Zelda: Majora's Mask running in Ultrawide through current Emulation techniques vs through native PC Recompilation." srcset="https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-320-80.png 320w, https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-1200-80.png 1200w, https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV-1920-80.png 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV.png"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/NDrJv9Xqj4S4KhrRs3bYUV.png">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span>Demonstration of Zelda: Majora's Mask running in Ultrawide through current Emulation techniques vs through native PC Recompilation.</span>
<span itemprop="copyrightHolder">(Image credit: Nerrel on YouTube)</span>
</figcaption>
</div>

<div id="article-body">
<p>Despite its 1996 release, the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/Nintendo-64-Console-HTPC-Intel-Atom-Nvidia-Ion,11445.html" data-before-rewrite-localise="https://www.tomshardware.com/news/Nintendo-64-Console-HTPC-Intel-Atom-Nvidia-Ion,11445.html">Nintendo 64</a>'s original hardware and games have both remained relatively hot-button in enthusiast circles here into 2024. Now, the next frontier of high-end N64 gameplay may be through recompiled PC ports instead of emulation, courtesy of Mr-Wiseguy on GitHub. Wiseguy is responsible for the release of both <a data-analytics-id="inline-link" href="https://github.com/Mr-Wiseguy/N64Recomp" data-url="https://github.com/Mr-Wiseguy/N64Recomp" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">N64Recomp</a> and <a data-analytics-id="inline-link" href="https://github.com/Mr-Wiseguy/Zelda64Recomp" data-url="https://github.com/Mr-Wiseguy/Zelda64Recomp" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Zelda64Recomp</a>, a project that ports <em>The Legend of Zelda: Majora's Mask</em> to PC with N64Recomp's graphical and QoL improvements, as screenshotted above and highlighted by YouTuber Nerrel below.</p><div data-nosnippet=""><p><iframe data-lazy-priority="low" data-lazy-src="https://www.youtube.com/embed/ywWwUuWRgsM" allowfullscreen=""></iframe></p></div><p>So, what makes crazy graphical improvements like real ray-tracing, uncapped FPS, and proper ultrawide support possible for N64 games? If you've been in the Nintendo 64 enthusiast scene for a long time, you may recall the waves made when a completely decompiled <em>Super Mario 64 </em>PC Port dropped in 2020 and allowed for features like <a data-analytics-id="inline-link" href="https://www.youtube.com/watch?v=ChqP2ecA8qE" data-url="https://www.youtube.com/watch?v=ChqP2ecA8qE" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">real ray-tracing</a>, full model replacements, and so on. It still gets mods to this day.</p><p>Recompiled ports aren't quite the same as decompiled ports like the SM64 PC port in this context, but both will run natively on PC and thus be able to <em>truly</em> maximize performance and effect accuracy to the original hardware while still providing the PC-expected enhancements that come with emulation. &nbsp;N64Recomp is basically the best of both worlds, and since manually decompiling N64 games takes years of labor from one or more people, a tool to more efficiently recompile them into a quickly playable-on-PC state is a godsend for preservationists everywhere.</p><p>A tool like this also ensures that old classics that aren't currently receiving the attention of big mainstream hits remain playable well into the future in an ideal state. A Twitter post by Dario, who makes the RT64 plugin leveraged by N64Recomp and some N64 emulators, highlights this.</p><div><blockquote data-lang="en"><p lang="en" dir="ltr">My friend Wiseguy's been working in secret for a year on a tool to make PC ports of N64 games without complete decompilations. The result doesn't include assets and only requires a ROM to play.He's managed to run games like Banjo-Kazooie, Rocket Robot and even Superman 64. pic.twitter.com/sKGuViEsJZ<a href="https://twitter.com/dariosamo/status/1789049134709678500" data-url="https://twitter.com/dariosamo/status/1789049134709678500" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">May 10, 2024</a></p></blockquote></div><p>Even as we speak, advancements like this aren't the only huge boons we're seeing for fans of the Nintendo 64's library or even original hardware. The open-source <a data-analytics-id="inline-link" href="https://www.tomshardware.com/video-games/nintendo/summercart64-open-source-n64-flash-cart-revealed-turns-a-regular-console-into-a-nintendo-64dd" data-before-rewrite-localise="https://www.tomshardware.com/video-games/nintendo/summercart64-open-source-n64-flash-cart-revealed-turns-a-regular-console-into-a-nintendo-64dd">SummerCart64</a> recently dropped and is basically the definitive flash cart for the old console since it also implements full 64DD support. Several real hardware-compatible <a data-analytics-id="inline-link" href="https://www.tomshardware.com/video-games/the-n64-is-still-being-pushed-past-its-limits-28-years-later-homebrew-devs-wont-give-up-on-the-nintendo-64-compare-2024-mario-to-his-1996-ancestor" data-before-rewrite-localise="https://www.tomshardware.com/video-games/the-n64-is-still-being-pushed-past-its-limits-28-years-later-homebrew-devs-wont-give-up-on-the-nintendo-64-compare-2024-mario-to-his-1996-ancestor">homebrew N64 games and ROM hacks</a> also keep releasing, including highlights like the 30-fighter <em>Smash Remix</em> and Mario 64 engine rewrite, <em>Peach's Fury</em>.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-BfzC7N9ZJhKmewdbMcf9EF"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div>
</div>




<!-- Drop in a standard article here maybe? -->



</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to get 7th graders to smoke (199 pts)]]></title>
            <link>https://www.experimental-history.com/p/how-to-get-7th-graders-to-smoke</link>
            <guid>40366137</guid>
            <pubDate>Wed, 15 May 2024 12:41:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.experimental-history.com/p/how-to-get-7th-graders-to-smoke">https://www.experimental-history.com/p/how-to-get-7th-graders-to-smoke</a>, See on <a href="https://news.ycombinator.com/item?id=40366137">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77290f1b-b91c-4d40-82eb-a15d7f5c9b7c_1151x1634.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77290f1b-b91c-4d40-82eb-a15d7f5c9b7c_1151x1634.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77290f1b-b91c-4d40-82eb-a15d7f5c9b7c_1151x1634.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77290f1b-b91c-4d40-82eb-a15d7f5c9b7c_1151x1634.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77290f1b-b91c-4d40-82eb-a15d7f5c9b7c_1151x1634.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77290f1b-b91c-4d40-82eb-a15d7f5c9b7c_1151x1634.jpeg" width="514" height="729.6924413553431" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/77290f1b-b91c-4d40-82eb-a15d7f5c9b7c_1151x1634.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1634,&quot;width&quot;:1151,&quot;resizeWidth&quot;:514,&quot;bytes&quot;:306733,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77290f1b-b91c-4d40-82eb-a15d7f5c9b7c_1151x1634.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77290f1b-b91c-4d40-82eb-a15d7f5c9b7c_1151x1634.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77290f1b-b91c-4d40-82eb-a15d7f5c9b7c_1151x1634.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F77290f1b-b91c-4d40-82eb-a15d7f5c9b7c_1151x1634.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>photo cred: my dad</figcaption></figure></div><div><p><span>Years ago, I wrote a master’s thesis that was so bad I immediately </span><a href="https://www.experimental-history.com/i/50779923/funders-undermine-the-people-they-fund-by-telling-them-what-to-do" rel="">threw it in the trash</a><span>. But along the way I learned something important, which is how to get seventh-graders to smoke.</span></p><p><span>My lesson came from </span><a href="https://www.researchgate.net/profile/Brian-Flay/publication/19894528_Affective_and_social_influences_approaches_to_the_prevention_of_multiple_substance_abuse_among_seventh_grade_students_Results_for_Project_SMART/links/59e0f2f1aca2724cbfd92530/Affective-and-social-influences-approaches-to-the-prevention-of-multiple-substance-abuse-among-seventh-grade-students-Results-for-Project-SMART.pdf" rel="">Hansen et al., 1989</a><span>. They randomly assigned students at eight junior high schools in Los Angeles to complete one of two anti-drug programs:</span></p></div><div><p><span>A) A “Social” program that was all about resisting negative influences and fostering good friendships</span><br><span>B) An “Emotion” program that was all about managing bad feelings</span><br><span>or</span><br><span>C) No program at all</span></p><p><span>The researchers surveyed the 2,863 participating students three times: just before the programs started, and 12 and 24 months after the programs ended. (They also took saliva samples to keep students honest.) The programs themselves lasted for 12 weeks.</span></p><p><span>In the Emotion program, students did things like:</span></p></div><ul><li><p>Compliment each other to improve their self-esteem</p></li><li><p>Set goals for themselves and think about how drugs interfere with those goals</p></li><li><p>Learn strategies for emotion regulation like deep breathing and muscle relaxation</p></li><li><p>Practice being assertive and saying no to drugs in role-plays</p></li><li><p>Make a videotaped commitment to stay drug-free</p></li></ul><div><p><span>Some of this stuff seems a bit dated now, sure, and the video thing sounds a little creepy. But mostly it looks reasonable—couldn’t hurt, right?</span></p><p><span>Except it </span><em>did </em><span>hurt. Students who did the Emotion program ended up smoking </span><em>more </em><span>cigarettes and </span><em>more </em><span>weed and drinking </span><em>more </em><span>alcohol than students who received no program at all. Which is to say: researchers came into schools in Los Angeles and ran a drug prevention program that caused a bunch of seventh-graders to </span><em>do more drugs</em></p><p><span>(Best of all, the name of this program was Project SMART.)</span></p><p><span>What about the kids in the Social program? Basically bupkis. The effects were way stronger in the Emotion program, and in the wrong direction.</span></p><p><span>(You should always be skeptical of any individual study, and especially one this old. But I’m at least willing to assume that these results weren’t </span><a href="https://en.wikipedia.org/wiki/Data_dredging" rel="">p-hacked</a><span>. If you were gonna cook your books, you would probably try to hide the fact that you got 12-year-olds to toke up.)</span></p><p><span>This story makes me go “GULP”. You can have a PhD and good intentions. You can have money and buy-in. You can do a bunch of reasonable things to prevent a problem that everyone agrees is bad. You can spend a lot of time and effort running your project and collecting your data. And after all that you can, according to your own best calculations, make people </span><em>worse off</em><span>. </span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-144595148" href="https://www.experimental-history.com/p/how-to-get-7th-graders-to-smoke#footnote-1-144595148" target="_self" rel="">1</a></span></p><p><span>That’s just one random paper from the 80s, but the literature is littered with similar well-meaning interventions that failed or backfired:</span></p></div><ul><li><p><span>“Scared Straight” programs, where at-risk youth go to prisons and get yelled at by prisoners, famously </span><a href="https://onlinelibrary.wiley.com/doi/pdf/10.4073/csr.2013.5" rel="">do not work and maybe make students more likely to commit crimes</a><span>.</span></p></li><li><p><span>The Drug Abuse Resistance Education (D.A.R.E) program I had to do in elementary school, where a cop came to class and told us about all the drugs we weren’t supposed to take, </span><a href="https://www.mdpi.com/1660-4601/6/1/267" rel="">also doesn’t do anything</a><span>.</span></p></li><li><p><span>A big trial of mindfulness training in UK schools </span><a href="https://pubmed.ncbi.nlm.nih.gov/35820993/" rel="">maybe made kids a bit more depressed</a><span>, and two attempts to teach psychotherapy principles to students in Australia </span><a href="https://osf.io/preprints/psyarxiv/ytdsj" rel="">both</a><span> </span><a href="https://www.sciencedirect.com/science/article/pii/S0005796723001560" rel="">failed</a><span>.</span></p></li></ul><p><br><span>Those programs all harmed kids or failed to help them, but don’t worry, we also harm adults sometimes, or fail to help them:</span></p><ul><li><p><span>Social scientists have invented lots of programs that try to make people less prejudiced.&nbsp;Every review of these programs concludes that they either </span><a href="https://scholar.harvard.edu/files/dobbin/files/an2018.pdf" rel="">don’t work</a><span> or </span><a href="https://ecommons.cornell.edu/server/api/core/bitstreams/650a7406-20df-49e2-95f1-d000e3fa6959/content" rel="">they don’t work in the ways we want</a><span> or </span><a href="https://www.annualreviews.org/content/journals/10.1146/annurev.psych.60.110707.163607" rel="">we don’t know if they work</a><span>.</span></p></li><li><p><span>Researchers came up with their best attempts at getting Democrats and Republicans to like each other more, and all of their ideas got outperformed by a </span><a href="https://www.experimental-history.com/i/142599282/the-best-psychologists-in-the-world-work-for-heineken" rel="">Heineken commercial</a></p></li><li><p><span>You know those signs on the highway that say things like, “Drive safely! Over 20 people have died on this highway so far this year!”? They </span><a href="https://www.science.org/doi/10.1126/science.abm3427" rel="">maybe cause more people to crash and die</a><span>.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-144595148" href="https://www.experimental-history.com/p/how-to-get-7th-graders-to-smoke#footnote-2-144595148" target="_self" rel="">2</a></span></p></li></ul><div><p><span>So yes, </span><a href="https://www.vitalcitynyc.org/articles/its-hard-to-change-people?utm_source=pocket_reader" rel="">it’s hard to change people</a><span>. But that’s okay—making iPhones is also hard, and we seem to have nailed that one.</span></p><p><span>What really screws us is that it’s </span><em>surprisingly </em><span>hard to change people. We cook up schemes that seem like they should definitely work, then they don’t work, and this doesn’t chasten us or dim our enthusiasm for future schemes. Hansen et al., after accidentally causing seventh-graders to smoke, don’t end their paper with a long reverie on their hubris. They write a few self-exculpatory paragraphs and move on to the next project.</span></p><p><span>The problem is that our </span><a href="https://www.experimental-history.com/p/on-the-importance-of-staring-directly" rel="">illusion of explanatory depth</a><span> is so deep when it comes to human behavior that we never realize how little we understand, which prevents us from ever learning more. Nobody thinks they can whip up an iPhone in their garage over the weekend, but most people think they know how to save the children, fix the schools, reform the prisons, overhaul healthcare, repair politics, restore civility, and bring about world peace. Perhaps that’s why we have iPhones and we don’t have any of those other things.</span></p></div><div><p><span>This myth of the easily-malleable human is so widespread and so deeply believed that it borders on delusion. Once you see it, though, it can make sense of some things that otherwise seem psychotic.</span></p><p><span>For example, in the US, anybody who does academic research on humans or animals has to undergo ethics training first. That sounds reasonable, until you realize the “training” is just PowerPoint slides that you click through as fast as you can, and then you get asked questions like:</span></p><p><strong><span>Which of these represents responsible treatment of research subjects?</span><br></strong><span>A) Poking them in the eye</span><br><span>B) Using the internet to discover their weaknesses</span><br><span>C) Running them over with a forklift</span><br><span>D) Treating them with respect</span></p><p><span>And then there are a few questions like:</span></p><p><strong><span>Subsection 41b.46 of the 1972 Research Reform Act stipulates which of the following?</span><br></strong><span>A) Paragraph 17 of the 1971 Research Reform Act is null and void</span><br><span>B) Principal Investigators are not allowed to be listed as Co-Principal Investigators</span><br><span>C) Conflicts of interest must be reported on Form 99-F</span><br><span>D) Any research expenditures greater than $100 must be done via certified check</span></p><p><span>If you fail the exam, you just retake it until you pass. So this “ethics” test is actually a test of whether you can read at a sixth-grade level.</span></p><p><span>Most workplace trainings look like this. Here are some questions from an actual sexual harassment training you can purchase for your organization at </span><a href="http://sexualharassmenttraining.com/" rel="">SexualHarassmentTraining.com</a><span>:</span></p></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed30e21-df86-4e23-9743-c67bbdb3b729_812x493.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed30e21-df86-4e23-9743-c67bbdb3b729_812x493.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed30e21-df86-4e23-9743-c67bbdb3b729_812x493.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed30e21-df86-4e23-9743-c67bbdb3b729_812x493.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed30e21-df86-4e23-9743-c67bbdb3b729_812x493.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed30e21-df86-4e23-9743-c67bbdb3b729_812x493.png" width="812" height="493" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/eed30e21-df86-4e23-9743-c67bbdb3b729_812x493.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:493,&quot;width&quot;:812,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:43806,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed30e21-df86-4e23-9743-c67bbdb3b729_812x493.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed30e21-df86-4e23-9743-c67bbdb3b729_812x493.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed30e21-df86-4e23-9743-c67bbdb3b729_812x493.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feed30e21-df86-4e23-9743-c67bbdb3b729_812x493.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90cc8cd6-13a8-44b8-be76-482c0955b4a3_812x493.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90cc8cd6-13a8-44b8-be76-482c0955b4a3_812x493.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90cc8cd6-13a8-44b8-be76-482c0955b4a3_812x493.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90cc8cd6-13a8-44b8-be76-482c0955b4a3_812x493.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90cc8cd6-13a8-44b8-be76-482c0955b4a3_812x493.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90cc8cd6-13a8-44b8-be76-482c0955b4a3_812x493.png" width="812" height="493" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/90cc8cd6-13a8-44b8-be76-482c0955b4a3_812x493.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:493,&quot;width&quot;:812,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:34553,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90cc8cd6-13a8-44b8-be76-482c0955b4a3_812x493.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90cc8cd6-13a8-44b8-be76-482c0955b4a3_812x493.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90cc8cd6-13a8-44b8-be76-482c0955b4a3_812x493.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90cc8cd6-13a8-44b8-be76-482c0955b4a3_812x493.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><p><span>Some hypocrisy is so profound that it distorts the space-time continuum. Like when a conservative Christian senator sponsors a bill that’s like “Let’s Make It Illegal to Be Horny” and then gets caught at a brothel wearing a diaper and nipple clamps. That’s the level of hypocrisy we’re dealing with here. If you claim to care about preventing sexual harassment and then you’re out here asking whether the Civil Rights Act of 1964 is a “county” law, you </span><em>do not </em><span>care about preventing sexual harassment.</span></p><p><span>I understand these trainings exist solely for the purposes of ass-covering. If you get sued because one of your employees, say, </span><a href="https://www.thecrimson.com/article/2005/1/7/professor-accused-of-rules-violation-professor/" rel="">sticks a research participant with a dirty needle</a><span>, you can go, “Hey, don’t blame us! We made them do an ethics training!”</span></p><p><span>But why does this ass-covering work? I don’t mean legally; I don’t care if this is all because of Subsection 31a of the Let’s Make Things Worse Act of 1986, or because of the Supreme Court decision in </span><em>Buttmunch v. Fartmeister </em><span>or whatever. I mean </span><em>why do we allow it</em><span>? Anybody who has to suffer through these trainings knows that they’re stupid and useless. But when those same people are sitting in the jury box, they nod and say, “Well, you can’t blame the company, they made their employees do an ethics training.” </span><em>This </em><span>is the hypocrisy that really makes no sense—it’s hypocrisy on top of hypocrisy, a nipple-clamp on a nipple-clamp.</span></p><p><span>I think we accept this ass-covering because we believe that it’s </span><em>possible</em><span>, and even </span><em>easy</em><span>, to mass-produce the improvement of humans. We think we can turn sex pests into good citizens via PowerPoint presentation. When we see those PowerPoints up close, of course, we go, “Oh no, not </span><em>these </em><span>PowerPoints. Some other PowerPoints, the ones that actually work.”</span></p><p><span>But are no PowerPoints that work. You cannot plonk someone in front of a computer screen for an hour and expect them to become a better person. Well-meaning researchers have tried way, way harder than that and gotten way, way less.</span></p></div><p>There are lots of reasons why we are continually surprised by how hard it is to change people, but there are three particularly nefarious ones that deserve closer inspection.</p><div><p><span>We perceive ourselves in full 4000K HD with Dolby Atmos Surround Sound, but when we perceive each other, it’s like we’re watching a VHS tape that someone made by using a Motorola Razr phone c. 2007 to record the screen on the back of an airplane seat.</span></p><p><span>Psychologists call this “</span><a href="https://en.wikipedia.org/wiki/Psychological_distance" rel="">psychological distance</a><span>”: the further something is from me, the less detail it has in my imagination. So we are profoundly aware of how hard it would be to change ourselves, but only dimly aware of everything it would take to change someone else. You’re already kinda fuzzy anyway, so can’t you just be kinda fuzzy in a different way instead?</span></p><p><span>Here’s an example. I’m a weakling, a real beta boy with limited upper body strength. Let’s say I want to get ripped, jacked, shredded, swoll, etc. If you made a workout plan for me, it might look something like this:</span></p></div><ol><li><p>Go to gym</p></li><li><p>Work out</p></li><li><p>Get jacked</p></li></ol><p><span>But if </span><em>I </em><span>made a workout plan for me, it would look more like this:</span></p><ol><li><p>Decide which of my very important tasks to ignore so I can go to the gym instead.</p></li><li><p>Find workout clothes.</p></li><li><p>Workout clothes are all old and ratty.</p></li><li><p>Look for new workout clothes online.</p></li><li><p>Spend the rest of the day figuring out whether I’m more of a nylon poplin guy or a jacquard knit guy.</p></li><li><p>Wait for clothes to come in.</p></li><li><p>Go to gym.</p></li><li><p>Figure out which podcast I want to listen to while I work out.</p></li><li><p>Okay now I’m ready to work out.</p></li><li><p>Wait I’ve heard this episode before, this the one where Malcolm Gladwell proves that Toyotas are safe by driving one off the George Washington Bridge.</p></li><li><p><span>Okay </span><em>now</em><span> I’m ready to work out.</span></p></li><li><p>Oh no there’s someone on the machine I want to use.</p></li><li><p>Mill around a bit, get on another machine and pretend it’s the one I wanted to use in the first place.</p></li><li><p>Okay he’s gone. Get on the other machine.</p></li><li><p>Oh no I don’t know how to use this machine.</p></li><li><p>Watch a YouTube video where a frighteningly large man tells me how to use the machine.</p></li><li><p>Oh no the frighteningly large man is now telling me January 6th was a false flag operation.</p></li><li><p>Use machine.</p></li><li><p>It kinda hurts, but I can’t tell if it’s a “You’re getting stronger” kind of hurt, or a “If you keep doing this you won’t be able to walk when you’re 57” kind of hurt.</p></li><li><p>Repeat for another 45 minutes.</p></li><li><p>Go home.</p></li><li><p>Wait I have to do this every day until I die??</p></li></ol><p>I’m going to talk about implicit bias for a second, so if you’re the kind of person who gets upset about that, please deactivate your Pedantry Module and just play along for the sake of the example.</p><p><span>Psychologists would very much like to reduce people’s implicit biases, especially their anti-Black biases. So far, they have </span><a href="https://web.p.ebscohost.com/ehost/pdfviewer/pdfviewer?vid=0&amp;sid=acc5cec4-865f-434f-916e-99f043d57352%40redis" rel="">failed</a><span> to do that. And they’ve tried lots of stuff:</span></p><ul><li><p>Helping people set a goal to not be biased</p></li><li><p>Lecturing them about how great multiculturalism is</p></li><li><p>Telling them a story that counters their stereotypes (“Imagine a White guy attacks you and throws you in his trunk, and then a Black guy shows up and saves the day!”)</p></li><li><p>Making people play a virtual dodgeball game where all of their teammates are courteous Black players and all of their opponents are mean nasty White players</p></li><li><p>Showing them a bunch of pictures of Black faces with the word “GOOD” written next to them</p></li></ul><p>Some of these interventions changed people’s biases in the moment, but none of the effects lasted beyond 24 hours. And of course they didn’t! As soon as participants leave the lab, they go right back into the world that massaged those biases into the folds of their brains in the first place. You can’t permanently change implicit biases with 15 minutes of screentime, just like you can’t spray someone with a hose and expect them to stay wet forever.</p><p><span>This is part of why changing people is so surprisingly hard—no matter how much you focus on the person in front of you, you’ll never appreciate the million tiny influences that made them who they are and that keep them that way. If you really want to make someone different, you might have to change the TV they watch, the music they listen to, the things they learn in school, the friends they hang out with, the role models they look up to, etc., and if you do all that, congratulations, you’ve started what we call a </span><em>cult</em><span>. Which, unlike social scientists, do have a pretty good track record of changing people.</span></p><p>Most people’s theories of human behavior are just never gonna be tested, and so their hypotheses can be both wrong and immortal. For example, if you think the solution to political polarization is to drug Congress with magic mushrooms, then a) nobody’s ever going to prove you wrong, and b) I think I know which anti-drug program you got in high school.</p><p>On top of this, we’re all running our own tiny-N, p-hacked studies and then slathering the results in confirmation bias:</p><ul><li><p><span>“My kid does better when we feed him raw beef and read him </span><em>Ulysses</em><span>, so that’s what all schools should do, and the fact that this also happens to fit my personal and political aesthetics is merely a coincidence.”</span></p></li><li><p>“I gave my religion’s holy book to a person who was struggling and now they’re doing better, which is proof my religion is true.”</p></li><li><p>“Some famous CEOs were mean to their employees and got good results, so I should do that too, which is convenient because I am a jerk.”</p></li></ul><p>These itsy-bitsy confounded little pseudo-studies are more convincing to us than any “official” experiments precisely because they unfold before our own eyes. On the one hand, that’s fair—“official” experiments are so poor on average that you should consider them guilty until proven innocent. But doing low-quality uncontrolled social science in your own backyard is a good way to increase your convictions without increasing your evidence.</p><p><span>Even when there is reasonably good data, our hypotheses about how humans work are often so vague that they can withstand any attempts at falsification. Okay, so </span><em>this </em><span>emotions-based anti-drug intervention didn’t succeed, but maybe that’s because the instructors weren’t motivated enough, or it didn’t go on long enough, or they used the wrong kind of deep breathing technique, or they should have targeted fifth-graders instead of seventh-graders, etc., on and on, forever. If you can only think of all these critiques and exceptions after the fact, however, you at least have to admit you didn’t really know what you were talking about in the first place.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-144595148" href="https://www.experimental-history.com/p/how-to-get-7th-graders-to-smoke#footnote-3-144595148" target="_self" rel="">3</a></span></p><p><span>The philosopher Michael Strevens </span><a href="https://www.strevens.org/scientia/" rel="">argues</a><span> that science requires humans to adopt an “alien mindset”—you have to ignore common sense, the wisdom of the ancients, the literal word of God, etc. Why would anyone toss out everything they know and instead try to learn things by </span><a href="https://en.wikipedia.org/wiki/Francesco_Redi" rel="">putting rotten meat in a jar</a><span>? Science took so long to develop, Strevens says, because it seemed </span><em>stupid</em><span>.</span></p><p>I say: we must become even stupider. If all of our intuitions, theories, and knowledge cause us to run programs that make tweens do more drugs—well, then, we oughta ditch our intuitions, theories, and knowledge!</p><div><p><span>Sufficiently stupid people would look at </span><a href="http://sexualharassmenttraining.com/" rel="">SexualHarassmentTraining.com</a><span> and ask, “Wait, how does this work? You show people walls of text and then ask them multiple choice questions and then they don’t sexually harass each other anymore?” They would wonder whether an imaginary dodgeball game could really make people less racist. They might question whether a couple deep-breathing exercises are enough to stop seventh graders from doing shots at a party.</span></p><p><span>It’s important to cultivate that kind ignorance, because every single person on Earth is at least a part-time people-changer. We want to raise our kids to be kind. We want to earn our boss’s respect. We would like our spouse to stop playing the “road trip playlist” that’s just a 10-hour loop of “Dreams” by The Cranberries and “Dreams” by Fleetwood Mac. We’ll never have large-N, preregistered, multi-site RCTs that can tell us how to do these things. We have to make our best guesses, but we also have to treat those guesses with enough skepticism that we notice when we guess wrong, so we can guess differently next time.</span></p><p><span>Some people are supposed to be </span><em>professional</em><span> people-changers, and so they carry a greater burden of proof and a sacred set of responsibilities. When you have the power to compel people to do things, you should be able to prove that your compulsions make people better off. It’s not enough to say, “Hey, I’m just doing stuff that everybody would agree is intuitive and reasonable,” because, as we’ve seen, intuitive and reasonable stuff often </span><em>hurts people</em><span>.</span></p><p><span>We can’t expect every well-meaning program to work. We know so little about how to help people that sometimes we’re going to screw it up, in which case our responsibility is to figure out what we did wrong. What we cannot do is accidentally turn tweens into binge-drinkers and then keep right on going as if nothing happened.</span></p><p><span>This is a thorny problem, but I know exactly how to solve it. I’m just waiting for the IRB to approve my application to run people over with a forklift.</span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Raspberry Pi Ltd is considering an IPO (347 pts)]]></title>
            <link>https://www.londonstockexchange.com/news-article/market-news/expected-intention-to-float/16470316</link>
            <guid>40366062</guid>
            <pubDate>Wed, 15 May 2024 12:32:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.londonstockexchange.com/news-article/market-news/expected-intention-to-float/16470316">https://www.londonstockexchange.com/news-article/market-news/expected-intention-to-float/16470316</a>, See on <a href="https://news.ycombinator.com/item?id=40366062">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Fastest rate of natural carbon dioxide rise over the last 50k years (244 pts)]]></title>
            <link>https://today.oregonstate.edu/news/researchers-identify-fastest-rate-natural-carbon-dioxide-rise-over-last-50000-years</link>
            <guid>40365882</guid>
            <pubDate>Wed, 15 May 2024 12:13:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://today.oregonstate.edu/news/researchers-identify-fastest-rate-natural-carbon-dioxide-rise-over-last-50000-years">https://today.oregonstate.edu/news/researchers-identify-fastest-rate-natural-carbon-dioxide-rise-over-last-50000-years</a>, See on <a href="https://news.ycombinator.com/item?id=40365882">Hacker News</a></p>
<div id="readability-page-1" class="page"><div property="content:encoded"><p>
	CORVALLIS, Ore. – Today’s rate of atmospheric carbon dioxide increase is 10 times faster than at any other point in the past 50,000 years, researchers have found through a detailed chemical analysis of ancient Antarctic ice.</p>
<p>
	The findings, just published in the Proceedings of the National Academy of Sciences, provide important new understanding of abrupt climate change periods in Earth’s past and offer new insight into the potential impacts of climate change today.</p>
<p>
	“Studying the past teaches us how today is different. The rate of CO2 change today really is unprecedented,” said Kathleen Wendt, an assistant professor in Oregon State University’s College of Earth, Ocean, and Atmospheric Sciences and the study’s lead author.</p>
<p>
	“Our research identified the fastest rates of past natural CO2 rise ever observed, and the rate occurring today, largely driven by human emissions, is 10 times higher.”</p>
<p>
	Carbon dioxide, or CO2, is a greenhouse gas that occurs naturally in the atmosphere. When carbon dioxide enters the atmosphere, it contributes to warming of the climate due to the greenhouse effect. In the past, the levels have fluctuated due to ice age cycles and other natural causes, but today they are rising because of human emissions.</p>
<p>
	Ice that built up in Antarctic over hundreds of thousands of years includes ancient atmospheric gasses trapped in air bubbles. Scientists use samples of that ice, collected by drilling cores up to 2 miles (3.2 kilometers) deep, to analyze the trace chemicals and build records of past climate. The U.S. National Science Foundation supported the ice core drilling and the chemical analysis used in the study.</p>
<p>
	Previous research showed that during the last ice age, which ended about 10,000 years ago, there were several periods where carbon dioxide levels appeared to jump much higher than the average. But those measurements were not detailed enough to reveal the full nature of the rapid changes, limiting scientists’ ability to understand what was occurring, Wendt said.</p>
<p>
	“You probably wouldn’t expect to see that in the dead of the last ice age,” she said. “But our interest was piqued, and we wanted to go back to those periods and conduct measurements at greater detail to find out what was happening.”</p>
<p>
	Using samples from the West Antarctic Ice Sheet Divide ice core, Wendt and colleagues investigated what was occurring during those periods. They identified a pattern that showed that these jumps in carbon dioxide occurred alongside North Atlantic cold intervals known as Heinrich Events that are associated with abrupt climate shifts around the world.</p>
<p>
	“These Heinrich Events are truly remarkable,” said <a href="https://ceoas.oregonstate.edu/people/christo-buizert">Christo Buizert</a>, an associate professor in the College of Earth, Ocean, and Atmospheric Sciences and co-author of the study. “We think they are caused by a dramatic collapse of the North American ice sheet. This sets into motion a chain reaction that involves changes to the tropical monsoons, the Southern hemisphere westerly winds and these large burps of CO2 coming out of the oceans.”</p>
<p>
	During the largest of the natural rises, carbon dioxide increased by about 14 parts per million in 55 years. And the jumps occurred about once every 7,000 years or so. At today’s rates, that magnitude of increase takes only 5 to 6 years.</p>
<p>
	Evidence suggests that during past periods of natural carbon dioxide rise, the westerly winds that play an important role in the circulation of the deep ocean were also strengthening, leading to a rapid release of CO2 from the Southern Ocean.</p>
<p>
	Other research has suggested that these westerlies will strengthen over the next century due to climate change. The new findings suggest that if that occurs, it will reduce the Southern Ocean’s capacity to absorb human-generated carbon dioxide, the researchers noted.</p>
<p>
	“We rely on the Southern Ocean to take up part of the carbon dioxide we emit, but rapidly increasing southerly winds weaken its ability to do so,” Wendt said.</p>
<p>
	Additional coauthors include Ed Brook, Kyle Niezgoda and Michael Kalk of Oregon State; Christoph Nehrbass-Ahles of the University of Bern in Switzerland and the National Physical Laboratory in the United Kingdom; Thomas Stocker, Jochen Schmitt, Hubertus Fischer and Thomas Stocker of the University of Bern; Laurie Menviel of the University of New South Wales in Australia; James Rae of the University of St. Andrews in the United Kingdom; Juan Muglia of Argentina; David Ferreira of the University of Reading in the United Kingdom and Shaun Marcott of University of Wisconsin-Madison.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oracle goes vegan: Dumps Terraform for OpenTofu (235 pts)]]></title>
            <link>https://www.thestack.technology/oracle-dumps-terraform-for-opentofu/</link>
            <guid>40365198</guid>
            <pubDate>Wed, 15 May 2024 10:50:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thestack.technology/oracle-dumps-terraform-for-opentofu/">https://www.thestack.technology/oracle-dumps-terraform-for-opentofu/</a>, See on <a href="https://news.ycombinator.com/item?id=40365198">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    <div>
      <p>Oracle has swapped Terraform for the open-source fork OpenTofu under the hood of its Oracle E-Business Suite (EBS) Cloud Manager.</p><p>It is now telling customers they “must” make the shift to its new OpenTofu-based version of the migration/provisioning tool by June 30, 2024.</p><p>Oracle EBS is a suite of business applications including CRM, procurement and supply chain software. “Cloud Manager” is what it describes as the “primary tool” for EBS customers looking to adopt Oracle Cloud.&nbsp;</p><p>It can be used for migrating Linux-based environments, provisioning new environments, and performing lifecycle management activities. </p><p>(Unless The Stack is sorely mistaken, "Cloud Manager" is a lick of Oracle paint on an underlying open source Terraform engine; or was... )</p><h2 id="oracle%E2%80%99s-opentofu-shift"><strong>Oracle’s OpenTofu shift</strong></h2><p>In a short <a href="https://blogs.oracle.com/ebsandoraclecloud/post/ebs-cloud-manager-24111-now-available?ref=thestack.technology"><u>blog</u></a>, an EBS product director at Oracle said that its “latest Oracle E-Business Suite (EBS) Cloud Manager update, 24.1.1.1, is now available,” urging customers to update “at your earliest convenience.”</p><p>“In this release, we have switched from Terraform to OpenTofu due to forthcoming Terraform licensing changes,” wrote <a href="https://blogs.oracle.com/authors/terri-noyes?ref=thestack.technology"><u>Terri Noyes</u></a>.</p><p>“ You must therefore upgrade your Cloud Manager to 24.1.1.1 by June 30, 2024 at the latest,” she said, adding that the release updated further components to “maintain security standards and improve supportability.”</p><p>The move comes after Hashicorp’s 2023 decision to adopt a more restrictive BSL 1.1. Licence for Terraform and other products, instead of the <a href="https://www.mozilla.org/en-US/MPL/2.0/?ref=thestack.technology"><u>MPL 2.0</u></a> that it previously used. That move triggered a swift fork, OpenTofu, adopted by the Linux Foundation. (Version 1.7 <a href="https://www.thestack.technology/opentofu-1-7-business-value/"><u>landed in March</u></a> 2024 and was widely considered to be the first enterprise-ready version.)</p><p>Oracle’s move seems like a straightforward decision to ensure it is using the most permissive underlying IaC tool without having to worry about downstream licence complications, no more and no less. OpenTofu is essentially a pretty familiar drop-in replacement for Terraform; using it here is ultimately a minor implementation detail for those looking to move complex EBS environments to the cloud, but it does signal that serious enterprises feel the fork is already robust enough to use.&nbsp;</p><p>In late April IBM agreed to buy Hashicorp for $6.7 billion.&nbsp;</p><h2 id="see-also-red-hash-ibm-vows-to-run-the-red-hat-playbook-after-64-billion-hashicorp-buyout">See also: <a href="https://www.thestack.technology/ibm-hashicorp-buyout-benefits/"><strong><u>"Red Hash"? IBM vows to run the Red Hat playbook after $6.4 billion HashiCorp buyout</u></strong></a></h2>
    </div>


      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Translation of the Rust's core and alloc crates to Coq for formal verification (328 pts)]]></title>
            <link>https://formal.land/blog/2024/04/26/translation-core-alloc-crates</link>
            <guid>40363744</guid>
            <pubDate>Wed, 15 May 2024 06:32:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://formal.land/blog/2024/04/26/translation-core-alloc-crates">https://formal.land/blog/2024/04/26/translation-core-alloc-crates</a>, See on <a href="https://news.ycombinator.com/item?id=40363744">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container" itemprop="articleBody"><p>We continue our work on formal verification of <a href="https://www.rust-lang.org/" target="_blank" rel="noopener noreferrer">Rust</a> programs with our tool <a href="https://github.com/formal-land/coq-of-rust" target="_blank" rel="noopener noreferrer">coq-of-rust</a>, to translate Rust code to the formal proof system <a href="https://coq.inria.fr/" target="_blank" rel="noopener noreferrer">Coq</a>. One of the limitation we had was the handling of primitive constructs from the standard library of Rust, like <a href="https://doc.rust-lang.org/core/option/enum.Option.html#method.unwrap_or_default" target="_blank" rel="noopener noreferrer">Option::unwrap_or_default</a> or all other primitive functions. For each of these functions, we had to make a Coq definition to represent its behavior. This is both tedious and error prone.</p>
<p>To solve this issue, we worked on the translation of the <a href="https://doc.rust-lang.org/core/" target="_blank" rel="noopener noreferrer">core</a> and <a href="https://doc.rust-lang.org/alloc/" target="_blank" rel="noopener noreferrer">alloc</a> crates of Rust using <code>coq-of-rust</code>. These are very large code bases, with a lot of unsafe or advanced Rust code. We present what we did to have a "best effort" translation of these crates. The resulting translation is in the following folders:</p>
<ul>
<li><a href="https://github.com/formal-land/coq-of-rust/blob/main/CoqOfRust/alloc" target="_blank" rel="noopener noreferrer">CoqOfRust/alloc</a></li>
<li><a href="https://github.com/formal-land/coq-of-rust/blob/main/CoqOfRust/core" target="_blank" rel="noopener noreferrer">CoqOfRust/core</a></li>
</ul>

<figure><p><img decoding="async" loading="lazy" alt="Crab with a pen" src="https://formal.land/assets/images/crab-in-library-33b99a73bc3cfc9a6c36bcb893f870a1.webp" width="1024" height="1024">
</p><figcaption>A crab in a library</figcaption></figure>
<h2 id="initial-run-">Initial run 🐥<a href="#initial-run-" aria-label="Direct link to Initial run 🐥" title="Direct link to Initial run 🐥">​</a></h2>
<p>An initial run of <code>coq-of-rust</code> on the <code>alloc</code> and <code>core</code> crates of Rust generated us two files of a few hundred thousands lines of Coq corresponding to the whole translation of these crates. This is a first good news, as it means the tool runs of these large code bases. However the generated Coq code does not compile, even if the errors are very rare (one every few thousands lines).</p>
<p>To get an idea, here is the size of the input Rust code as given by the <code>cloc</code> command:</p>
<ul>
<li><code>alloc</code>: 26,299 lines of Rust code</li>
<li><code>core</code>: 54,192 lines of Rust code</li>
</ul>
<p>Given that this code uses macros that we expand in our translation, the actual size that we have to translate is even bigger.</p>
<h2 id="splitting-the-generated-code-">Splitting the generated code 🪓<a href="#splitting-the-generated-code-" aria-label="Direct link to Splitting the generated code 🪓" title="Direct link to Splitting the generated code 🪓">​</a></h2>
<p>The main change we made was to split the output generated by <code>coq-of-rust</code> with one file for each input Rust file. This is possible because our translation is insensitive to the order of definitions and context-free. So, even if there are typically cyclic dependencies between the files in Rust, something that is forbidden in Coq, we can still split them.</p>
<p>We get the following sizes as output:</p>
<ul>
<li><code>alloc</code>: 54 Coq files, 171,783 lines of Coq code</li>
<li><code>core</code>: 190 Coq files, 592,065 lines of Coq code</li>
</ul>
<p>The advantages of having the code split are:</p>
<ul>
<li>it is easier to read and navigate in the generated code</li>
<li>it is easier to compile as we can parallelize the compilation</li>
<li>it is easier to debug as we can focus on one file at a time</li>
<li>it is easier to ignore files that do not compile</li>
<li>it will be easier to maintain, as it is easier to follow the diff of a single file</li>
</ul>
<h2 id="fixing-some-bugs-">Fixing some bugs 🐞<a href="#fixing-some-bugs-" aria-label="Direct link to Fixing some bugs 🐞" title="Direct link to Fixing some bugs 🐞">​</a></h2>
<p>We had some bugs related to the collisions between module names. These can occur when we choose a name for the module for an <code>impl</code> block. We fixed these by adding more information in the module names to make them more unique, like the <code>where</code> clauses that were missing. For example, for the implementation of the <code>Default</code> trait for the <code>Mapping</code> type:</p>
<div><pre tabindex="0"><code><span><span>#[derive(Default)]</span><span></span><br></span><span><span></span><span>struct</span><span> </span><span>Mapping</span><span>&lt;</span><span>K</span><span>,</span><span> </span><span>V</span><span>&gt;</span><span> </span><span>{</span><span></span><br></span><span><span>    </span><span>// ...</span><span></span><br></span><span><span></span><span>}</span><br></span></code></pre></div>
<p>we were generating the following Coq code:</p>
<div><pre tabindex="0"><code><span><span>Module</span><span> Impl_core_default_Default_for_dns_Mapping_K_V</span><span>.</span><span></span><br></span><span><span>  </span><span>(* ...trait implementation ... *)</span><span></span><br></span><span><span></span><span>End</span><span> Impl_core_default_Default_for_dns_Mapping_K_V</span><span>.</span><br></span></code></pre></div>
<p>We now generate:</p>
<div><pre tabindex="0"><code><span><span>Module</span><span> Impl_core_default_Default_where_core_default_Default_K_where_core_default_Default_V_for_dns_Mapping_K_V</span><span>.</span><span></span><br></span><span><span>  </span><span>(* ... *)</span><br></span></code></pre></div>
<p>with a module name that includes the <code>where</code> clauses of the <code>impl</code> block, stating that both <code>K</code> and <code>V</code> should implement the <code>Default</code> trait.</p>
<p>Here is the list of files that do not compile in Coq, as of today:</p>
<ul>
<li><code>alloc/boxed.v</code></li>
<li><code>core/any.v</code></li>
<li><code>core/array/mod.v</code></li>
<li><code>core/cmp/bytewise.v</code></li>
<li><code>core/error.v</code></li>
<li><code>core/escape.v</code></li>
<li><code>core/iter/adapters/flatten.v</code></li>
<li><code>core/net/ip_addr.v</code></li>
</ul>
<p>This represents 4% of the files. Note that in the files that compile there are some unhandled Rust constructs that are axiomatized, so this does not give the whole picture of what we do not support.</p>
<h2 id="example-">Example 🔎<a href="#example-" aria-label="Direct link to Example 🔎" title="Direct link to Example 🔎">​</a></h2>
<p>Here is the source code of the <code>unwrap_or_default</code> method for the <code>Option</code> type:</p>
<div><pre tabindex="0"><code><span><span>pub</span><span> </span><span>fn</span><span> </span><span>unwrap_or_default</span><span>(</span><span>self</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>T</span><span></span><br></span><span><span></span><span>where</span><span></span><br></span><span><span>    </span><span>T</span><span>:</span><span> </span><span>Default</span><span>,</span><span></span><br></span><span><span></span><span>{</span><span></span><br></span><span><span>    </span><span>match</span><span> </span><span>self</span><span> </span><span>{</span><span></span><br></span><span><span>        </span><span>Some</span><span>(</span><span>x</span><span>)</span><span> </span><span>=&gt;</span><span> x</span><span>,</span><span></span><br></span><span><span>        </span><span>None</span><span> </span><span>=&gt;</span><span> </span><span>T</span><span>::</span><span>default</span><span>(</span><span>)</span><span>,</span><span></span><br></span><span><span>    </span><span>}</span><span></span><br></span><span><span></span><span>}</span><br></span></code></pre></div>
<p>We translate it to:</p>
<div><pre tabindex="0"><code><span><span>Definition</span><span> unwrap_or_default </span><span>(</span><span>T </span><span>:</span><span> Ty</span><span>.</span><span>t</span><span>)</span><span> </span><span>(</span><span>τ </span><span>:</span><span> list Ty</span><span>.</span><span>t</span><span>)</span><span> </span><span>(</span><span>α </span><span>:</span><span> list Value</span><span>.</span><span>t</span><span>)</span><span> </span><span>:</span><span> M </span><span>:=</span><span></span><br></span><span><span>  </span><span>let</span><span> Self </span><span>:</span><span> Ty</span><span>.</span><span>t </span><span>:=</span><span> Self T </span><span>in</span><span></span><br></span><span><span>  </span><span>match</span><span> τ</span><span>,</span><span> α </span><span>with</span><span></span><br></span><span><span>  </span><span>|</span><span> </span><span>[</span><span>]</span><span>,</span><span> </span><span>[</span><span> self </span><span>]</span><span> </span><span>=&gt;</span><span></span><br></span><span><span>    ltac</span><span>:</span><span>(</span><span>M</span><span>.</span><span>monadic</span><br></span><span><span>      </span><span>(</span><span>let</span><span> self </span><span>:=</span><span> M</span><span>.</span><span>alloc </span><span>(</span><span>|</span><span> self </span><span>|</span><span>)</span><span> </span><span>in</span><span></span><br></span><span><span>      M</span><span>.</span><span>read </span><span>(</span><span>|</span><span></span><br></span><span><span>        M</span><span>.</span><span>match_operator </span><span>(</span><span>|</span><span></span><br></span><span><span>          self</span><span>,</span><span></span><br></span><span><span>          </span><span>[</span><span></span><br></span><span><span>            </span><span>fun</span><span> γ </span><span>=&gt;</span><span></span><br></span><span><span>              ltac</span><span>:</span><span>(</span><span>M</span><span>.</span><span>monadic</span><br></span><span><span>                </span><span>(</span><span>let</span><span> γ</span><span>0_0</span><span> </span><span>:=</span><span></span><br></span><span><span>                  M</span><span>.</span><span>get_struct_tuple_field_or_break_match </span><span>(</span><span>|</span><span></span><br></span><span><span>                    γ</span><span>,</span><span></span><br></span><span><span>                    </span><span>"core::option::Option::Some"</span><span>,</span><span></span><br></span><span><span>                    </span><span>0</span><span></span><br></span><span><span>                  </span><span>|</span><span>)</span><span> </span><span>in</span><span></span><br></span><span><span>                </span><span>let</span><span> x </span><span>:=</span><span> M</span><span>.</span><span>copy </span><span>(</span><span>|</span><span> γ</span><span>0_0</span><span> </span><span>|</span><span>)</span><span> </span><span>in</span><span></span><br></span><span><span>                x</span><span>)</span><span>)</span><span>;</span><span></span><br></span><span><span>            </span><span>fun</span><span> γ </span><span>=&gt;</span><span></span><br></span><span><span>              ltac</span><span>:</span><span>(</span><span>M</span><span>.</span><span>monadic</span><br></span><span><span>                </span><span>(</span><span>M</span><span>.</span><span>alloc </span><span>(</span><span>|</span><span></span><br></span><span><span>                  M</span><span>.</span><span>call_closure </span><span>(</span><span>|</span><span></span><br></span><span><span>                    M</span><span>.</span><span>get_trait_method </span><span>(</span><span>|</span><span> </span><span>"core::default::Default"</span><span>,</span><span> T</span><span>,</span><span> </span><span>[</span><span>]</span><span>,</span><span> </span><span>"default"</span><span>,</span><span> </span><span>[</span><span>]</span><span> </span><span>|</span><span>)</span><span>,</span><span></span><br></span><span><span>                    </span><span>[</span><span>]</span><span></span><br></span><span><span>                  </span><span>|</span><span>)</span><span></span><br></span><span><span>                </span><span>|</span><span>)</span><span>)</span><span>)</span><span></span><br></span><span><span>          </span><span>]</span><span></span><br></span><span><span>        </span><span>|</span><span>)</span><span></span><br></span><span><span>      </span><span>|</span><span>)</span><span>)</span><span>)</span><span></span><br></span><span><span>  </span><span>|</span><span> </span><span>_</span><span>,</span><span> </span><span>_</span><span> </span><span>=&gt;</span><span> M</span><span>.</span><span>impossible</span><br></span><span><span>  </span><span>end</span><span>.</span><br></span></code></pre></div>
<p>We prove that it is equivalent to the simpler functional code:</p>
<div><pre tabindex="0"><code><span><span>Definition</span><span> unwrap_or_default </span><span>{</span><span>T </span><span>:</span><span> </span><span>Set</span><span>}</span><span></span><br></span><span><span>    </span><span>{</span><span>_</span><span> </span><span>:</span><span> core</span><span>.</span><span>simulations</span><span>.</span><span>default</span><span>.</span><span>Default</span><span>.</span><span>Trait T</span><span>}</span><span></span><br></span><span><span>    </span><span>(</span><span>self </span><span>:</span><span> Self T</span><span>)</span><span> </span><span>:</span><span></span><br></span><span><span>    T </span><span>:=</span><span></span><br></span><span><span>  </span><span>match</span><span> self </span><span>with</span><span></span><br></span><span><span>  </span><span>|</span><span> None </span><span>=&gt;</span><span> core</span><span>.</span><span>simulations</span><span>.</span><span>default</span><span>.</span><span>Default</span><span>.</span><span>default </span><span>(</span><span>Self </span><span>:=</span><span> T</span><span>)</span><span></span><br></span><span><span>  </span><span>|</span><span> Some x </span><span>=&gt;</span><span> x</span><br></span><span><span>  </span><span>end</span><span>.</span><br></span></code></pre></div>
<p>This simpler definition is what we use when verifying code. The proof of equivalence is in <a href="https://github.com/formal-land/coq-of-rust/blob/main/CoqOfRust/core/proofs/option.v" target="_blank" rel="noopener noreferrer">CoqOfRust/core/proofs/option.v</a>. In case the original source code changes, we are sure to capture these changes thanks to our proof. Because the translation of the <code>core</code> library was done automatically, we trust the generated definitions more than definitions that would be done by hand. However, there can still be mistakes or incompleteness in <code>coq-of-rust</code>, so we still need to check at proof time that the code makes sense.</p>
<h2 id="conclusion">Conclusion<a href="#conclusion" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>We can now work on the verification of Rust programs with more trust in our formalization of the standard library. Our next target is to simplify our proof process, which is still tedious. In particular, showing that simulations are equivalent to the original Rust code requires doing the name resolution, introduction of high-level types, and removal of the side-effects. We would like to split these steps.</p>
<p>If you are interested in formally verifying your Rust projects, do not hesitate to get in touch with us at&nbsp;<a href="mailto:contact@formal.land" target="_blank" rel="noopener noreferrer">contact@formal.land</a>&nbsp;💌! Formal verification provides the highest level of safety for critical applications, with a mathematical guarantee of the absence of bugs for a given specification.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A low budget consumer hardware espionage implant: a GSM device hidden in (314 pts)]]></title>
            <link>https://ha.cking.ch/s8_data_line_locator/</link>
            <guid>40363704</guid>
            <pubDate>Wed, 15 May 2024 06:24:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ha.cking.ch/s8_data_line_locator/">https://ha.cking.ch/s8_data_line_locator/</a>, See on <a href="https://news.ycombinator.com/item?id=40363704">Hacker News</a></p>
<div id="readability-page-1" class="page">

<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a><ul>
<li><a href="#s8-data-line-locator-capabilities">S8 data line locator capabilities</a><ul>
<li><a href="#listen-in">Listen in</a></li>
<li><a href="#call-back">Call back</a></li>
<li><a href="#query-location">Query location</a></li>
</ul></li>
</ul></li>
<li><a href="#hardware">Hardware</a><ul>
<li><a href="#chips">Chips</a></li>
<li><a href="#connections">Connections</a><ul>
<li><a href="#usb-passthrough">USB (passthrough)</a></li>
<li><a href="#uart">UART</a></li>
<li><a href="#usb-mtk">USB (MTK)</a></li>
</ul></li>
</ul></li>
<li><a href="#dumping-firmware">Dumping firmware</a><ul>
<li><a href="#obtaining-and-building-fernlys-mt6261-branch">Obtaining and building fernly’s MT6261 branch</a></li>
<li><a href="#dumping-rom">Dumping ROM</a></li>
<li><a href="#dumping-flash">Dumping flash</a></li>
<li><a href="#writing-flash-attempt">Writing flash attempt</a></li>
</ul></li>
<li><a href="#analysis">Analysis</a><ul>
<li><a href="#sim-sniffing-via-simtrace">SIM sniffing (via SIMtrace)</a></li>
<li><a href="#gprs-sniffing-attempt-via-openbts">GPRS sniffing attempt (via OpenBTS)</a></li>
<li><a href="#flash-contents">Flash contents</a><ul>
<li><a href="#os">OS</a></li>
<li><a href="#fat12-filesystems">FAT12 filesystems (?)</a></li>
<li><a href="#configuration-data">Configuration data</a></li>
<li><a href="#hidden-commands">Hidden commands</a></li>
</ul></li>
<li><a href="#provider-call-logs-and-itemized-bill">Provider call logs and itemized bill</a><ul>
<li><a href="#dw-or-loc-commands-and-during-idle"><code>dw</code> or <code>loc</code> commands and during idle</a></li>
</ul></li>
<li><a href="#gpsui.net">gpsui.net</a><ul>
<li><a href="#interface">Interface</a></li>
<li><a href="#settings">Settings</a></li>
<li><a href="#alarms">Alarms</a></li>
<li><a href="#real-time-location-tracking">Real time location tracking</a></li>
<li><a href="#history">History</a></li>
<li><a href="#fence">Fence</a></li>
<li><a href="#push-commands">Push commands</a></li>
<li><a href="#management">Management</a></li>
<li><a href="#vulnerabilities">Vulnerabilities</a></li>
</ul></li>
<li><a href="#detection">Detection</a></li>
</ul></li>
<li><a href="#future-work">Future work</a><ul>
<li><a href="#issues">Issues</a></li>
<li><a href="#ideas">Ideas</a></li>
<li><a href="#other-people-working-on-this">Other people working on this</a></li>
</ul></li>
<li><a href="#appendix-fuck-up">Appendix: Fuck up</a></li>
<li><a href="#appendix-video">Appendix: Video</a></li>
</ul>
</div>
<p>(Published: 2017-11-11, Last update: 2018-01-07)</p>
<p><strong>The following analysis was performed on a S8 data line locator which replied to the hidden SMS command for version query (<code>*3646655*</code>) with:</strong></p>
<pre><code>Ver=MTK6261M.T16.17.01.10
build=2017/01/10 17:33</code></pre>
<h2 id="introduction">Introduction</h2>
<p>A while back Joe Fitz tweeted about the <em>S8 data line locator</em><a href="#fn1" id="fnref1"><sup>1</sup></a>. He referred to it as “Trickle down espionage” due to its reminiscence of NSA spying equipment.</p>
<p>The <em>S8 data line locator</em> is a GSM listening and location device hidden inside the plug of a standard USB data/charging cable. It supports the 850, 900, 1800 and 1900 MHz GSM frequencies.</p>
<p>Its core idea is very similar to the COTTONMOUTH product line by the NSA/CSS <span>[1]</span> in which an RF device is hidden inside a USB plug. Those hidden devices are referred to as implants.</p>
<p>The device itself is marketed as a location tracker usable in cars, where a thief would not be able to identify the USB cable as a location tracking device. Its malicious use-cases can, however, not be denied. Especially since it features no GPS making its location reporting very coarse (1.57 km deviation in my tests). It can, e.g., be called to listen to a live audio feed from a small microphone within the device, as well as programmed to call back if the sound level surpasses a 45 dB threshold. The fact that the device can be repackaged in its sliding case, after configuring it, i.e.&nbsp;inserting a SIM, without any noticeable marks to the packaging suggests its use-case: covert espionage.</p>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/00_packaging.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/00_packaging.jpg" alt="S8 data line locator sliding case packaging."></a></p>
<h2 id="s8-data-line-locator-capabilities">S8 data line locator capabilities</h2>
<p>The S8 data line locator has several eavesdropping, espionage and spying capabilities. A SMS message log could look like this:</p>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/10_00_cmds.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/10_00_cmds.jpg" alt="S8 data line locator hidden commands."></a></p>
<h3 id="listen-in">Listen in</h3>
<p>Calling the S8 data line locator for 10 seconds establishes a call and allows you to listen to the microphone feed from the device.</p>
<h3 id="call-back">Call back</h3>
<p>Sending <code>1111</code> via SMS to the device enables voice activated call back. It is acknowledged via the following SMS reply:</p>
<pre><code>DT: Set voice monitoring, voice callback and sound sensitivity:400</code></pre>
<p>Once the audio level goes above 40 dB the device calls back the number that send the <code>1111</code> command.</p>
<p>Sending <code>0000</code> disables the audio triggered call back. It is replied by:</p>
<pre><code>DT: Voice monitoring cancelled successfully.</code></pre>
<h3 id="query-location">Query location</h3>
<p>Accoding to the manual sending ‘dw’ via SMS to the device yields a reply SMS with the location. This reply is in the form:</p>
<pre><code>Loc:Street, ZIP City, Country
http://gpsui.net/u/xxxx Battery: 100%</code></pre>
<p>The ‘xxxx’ are replaced with characters ‘0-9,A-Z,a-z’ and the <code>Street, ZIP City, Country</code> line with the appropriate street, ZIP, city and country. The link to http://gpsui.net can be accessed without authorization. It forwards to Google maps.</p>
<p>The location was never more accurate than 1.57 km off.</p>
<p><strong>During the query the device will use a mobile data connection to an unknown endpoint (presumably gpsui.net). This is confirmed by a “MMS/Internet” charge by my provider. My provider does not discern MMS and Internet, but it is save to assume there is an Internet connection established during location query.</strong></p>
<p><strong>This issue was the stepping stone for this analysis. Because the device sends unknown data to an unknown third party it can not - at least with a clear conscious - be used in, e.g., a penetration test. You simply can not use a potentially pre-owned tool.</strong></p>
<p>I therefore tried to analyze and eliminate this phone-home “feature”.</p>

<p>To gain access to the devices innards we first tear of the metal shield of the USB connector: <a href="https://ha.cking.ch/s8_data_line_locator/images/04_00_teardown.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/04_00_teardown.jpg" alt="S8 data line locator removing USB connector shield."></a></p>
<p>Next, we remove the plastic cover: <a href="https://ha.cking.ch/s8_data_line_locator/images/04_03_teardown.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/04_03_teardown.jpg" alt="S8 data line locator removing USB connector shield."></a></p>
<h2 id="chips">Chips</h2>
<p>After opening the device we can identify the chips:</p>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/06_02_chipid.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/06_02_chipid.jpg" alt="S8 data line locator board with MT6261MA and RDA 6625e chips."></a></p>
<p>It features:</p>
<ul>
<li>MediaTek MT6261MA: Low budget chip often used in cheap Chinese smartwatches. No official documentation nor information about the chip is available from MediaTek.</li>
<li>RDA 6626e: “a high-power, high-efficiency quad-band front-end Module […] designed for GSM850, EGSM900, DCS1800, PCS1900 handheld digital cellular equipment.”</li>
</ul>
<h2 id="connections">Connections</h2>
<p>So far I could identify 3 different avenues to connect to the device:</p>
<h3 id="usb-passthrough">USB (passthrough)</h3>
<p>The USB A-connector and the Micro-B cable are not connected to the MT6261MA. They merely pass the signal from one to the other:</p>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/07_00_meter.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/07_00_meter.jpg" alt="S8 data line locator USB passthrough."></a></p>
<h3 id="uart">UART</h3>
<p>The next connection is a UART:</p>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/07_02_meter.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/07_02_meter.jpg" alt="S8 data line locator UART."></a></p>
<p>Interfacing with it yields, approximately 3 seconds after booting the device:</p>
<pre><code>screen /dev/ttyUSB0 115200 # 8N1

F1: 0000 0000
V0: 0000 0000 [0001]
00: 1029 0001
01: 0000 0000
U0: 0000 0001 [0000]
G0: 0002 0000 [0000]
T0: 0000 0C73
Jump to BL




~~~ Welcome to MTK Bootloader V005 (since 2005) ~~~
**===================================================**


Bye bye bootloader, jump to=0x1000a5b0
</code></pre>
<p>However, the output stops there. Input to the device is ignored.</p>
<p>It is likely there exist a different firmware version that accepts AT modem commands<a href="#fn2" id="fnref2"><sup>2</sup></a>. The boot banner of that alternate firmware references “ZhiPu”<a href="#fn3" id="fnref3"><sup>3</sup></a> (some file names of the FAT12 in the firmware flash of my device contain this string as well, so the device firmware is likely related to that other firmware).</p>
<h4 id="alternative-cable">Alternative cable</h4>
<pre><code>
F1: 0000 0000
V0: 0000 0000 [0001]
00: 1029 0002       
01: 0000 0000
U0: 0000 0001 [0000]
G0: 0002 0000 [0000]
T0: 0000 0C73       
Jump to BL   
          



~~~ Welcome to MTK Bootloader V005 (since 2005) ~~~
**===================================================**
                                                       
                                                       
Bye bye bootloader, jump to=0x1000a5b0
                                      
LOG: RegisterSn: 
LOG: ZhiPu_sock_buf_init malloc= 217780, 217180, 216940
LOG: ZhiPu_mmi_get_imsi_request
LOG: ZhiPu_system_init VERSION= MTK6261M.T16.17.01.10 , build date is 2017/01/10 17:33, curtime 2004-01-01 00:00
LOG: g_zhipu_imei= \
LOG: ----- 0 -----  ----- -268081676 -----  ----- 2 -----
LOG: ZhiPu_sms_ready_sync
LOG: ZhiPu System Language: English
LOG: service_availability= 0,ChargerConnected= 1,poweron_mode= 0
LOG: sim invalid, 4 minutes later reboot
LOG: ----- 0 -----  ----- 83 -----  ----- 2 -----
LOG: idle_screen_network_name:Same IMEI</code></pre>
<h3 id="usb-mtk">USB (MTK)</h3>
<p>The DP and DM pads on the USB connector are not connected to the D+ and D- lines of the USB connector. However, the V and GND pads are. The DP and DM pads are instead routed to the MT6261MA processor as illustrated here:</p>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/07_01_meter.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/07_01_meter.jpg" alt="S8 data line locator MTK USB."></a></p>
<p>Next, a USB cable must be soldered to these connectors as follows:</p>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/09_usb.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/09_usb.jpg" alt="S8 data line locator MTK USB soldered."></a></p>
<p>The device will then be recognized as an MediaTek phone USB endpoint with the following data:</p>
<p><code>ID 0e8d:0003 MediaTek Inc. MT6227 phone</code></p>
<p>This is often called the “MTK boot repair”, “MTK DM DP flash”, etc. It will allow us to interface with the device and dump the firmware ROM and flash.</p>
<h2 id="dumping-firmware">Dumping firmware</h2>
<p>To dump the firmware I use the open source Fernvale research OS <span>[2]</span>. It was initially targeted for the MT6260 processor. It has, however, been ported to the MT6261 and also works on the MT6261MA.</p>
<h2 id="obtaining-and-building-fernlys-mt6261-branch">Obtaining and building fernly’s MT6261 branch</h2>
<p>A suitable fork of fernly by Urja “urjaman” Rannikko can be obtained and build as follows:</p>
<pre><code>git clone https://github.com/urjaman/fernly
git clone https://github.com/robertfoss/setup_codesourcery.git
sudo setup_codesourcery/setup.sh
/usr/local/bin/codesourcery-arm-2014.05.sh
cd fernly
git checkout fernly6261
make CROSS_COMPILE=arm-none-eabi-
exit
cp 95-fernvale-simple.rules /etc/udev/rules.d/.</code></pre>
<h2 id="dumping-rom">Dumping ROM</h2>
<p>To dump the flash we run:</p>
<pre><code>echo "data = [" &gt; rom.py
fernly/build/fernly-usb-loader /dev/fernvale fernly/build/dump-rom-usb.bin &gt;&gt; rom.py
echo "
]
f = open('rom.bin','wb')
for s in data:
  f.write(chr(int(s,16)))
f.close()
" &gt;&gt; rom.py
python rom.py</code></pre>
<p>The file <code>rom.bin</code> will now (at least according to the fernly repository documentation) contain the devices ROM.</p>
<h2 id="dumping-flash">Dumping flash</h2>
<p>To dump the flash of the device we need to patch flashrom as follows:</p>
<pre><code>git clone https://github.com/flashrom/flashrom
cd flashrom/
git checkout c8305e1dee66cd69bd8fca38bff2c8bf32924306
patch -p0 &lt; ../fernly/flashrom-fernvale.patch
# manually fix Makefile.rej to complete patching</code></pre>
<p>The patch does not cleanly apply so you need to fix the rejected <code>Makefile</code> (<code>Makefile.rej</code>) manually yourself.</p>
<p>Once this was done we can first load the fernly firmware into the devices RAM via:</p>
<pre><code>fernly/build/fernly-usb-loader -w /dev/fernvale fernly/build/stage1.bin fernly/build/firmware.bin</code></pre>
<p>Next, we can use the <code>fernvale_spi</code> programmer we patched into flashrom.</p>
<p>We first let it recognize the flash via:</p>
<pre><code>flashrom/flashrom --programmer fernvale_spi:dev=/dev/fernvale</code></pre>
<p>And then read the flash via:</p>
<pre><code>flashrom/flashrom --programmer fernvale_spi:dev=/dev/fernvale -c "MX25L3205(A)" --read flash.dat</code></pre>
<p><code>flash.dat</code> will now contain the devices flash memory.</p>
<h2 id="writing-flash-attempt">Writing flash attempt</h2>
<p>Writing the flash can be performed via:</p>
<pre><code>flashrom/flashrom --programmer fernvale_spi:dev=/dev/fernvale -c "MX25L3205(A)" --write flash.dat</code></pre>
<p>However, the flash seems to be block protected and the block protect bits can not be disabled by flashrom. I have not (yet) found a way to disable the block protect.</p>
<h4 id="alternative-device">Alternative device</h4>
<pre><code>$ flashrom/flashrom --programmer fernvale_spi:dev=/dev/fernvale
flashrom v0.9.9-86-ge1a960e-dirty on Linux 4.13.2-1.el7.elrepo.x86_64 (x86_64)
flashrom is free software, get the source code at https://flashrom.org

Using clock_gettime for delay loops (clk_id: 1, resolution: 1ns).
Found GigaDevice flash chip "GD25LQ32" (4096 kB, SPI) on fernvale_spi.
No operations were specified.</code></pre>
<h2 id="analysis">Analysis</h2>
<p>Mostly for my personal education I did some more analysis then the obligatory firmware dump.</p>
<h2 id="sim-sniffing-via-simtrace">SIM sniffing (via SIMtrace)</h2>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/02_simtrace.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/02_simtrace.jpg" alt="SIM sniffing against S8 data line locator via SIMtrace."></a></p>
<p>First, I sniffed the communication between the device and the SIM. Interestingly, it accessed all records of the telephone book and SMS storage. More specifically it accesses the following files, which are not needed to provide the services rendered by the device itself:</p>
<ul>
<li>ADF
<ul>
<li>EF(ECC)</li>
<li>EF(EXT2)</li>
<li>EF(SMS)</li>
</ul></li>
<li>DF(TELECOM)
<ul>
<li>DF(PHONEBOOK)
<ul>
<li>EF(ADN)</li>
<li>EF(ANRA1)</li>
<li>EF(SMS)</li>
</ul></li>
</ul></li>
</ul>
<p>Other SIM accesses seems to be normal.</p>
<p>This is probably not an elaborate scheme to harvest phone numbers and send them to China, but rather the way the default manufactured SIM code was implemented and it was never trimmed down to the needs of this device. Nevertheless, I found it interesting seeing how the device is accessing virtually everything on the SIM.</p>
<h2 id="gprs-sniffing-attempt-via-openbts">GPRS sniffing attempt (via OpenBTS)</h2>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/03_000_openbts.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/03_000_openbts.jpg" alt="S8 data line locator connected to OpenBTS."></a></p>
<p>Next, I tried to sniff the Internet traffic to figure out what is send to whom via the mobile data connection. To this end, I used a Ettus B100 with OpenBTS.</p>
<p>Unfortunately, the S8 data line locator did not connect to the GPRS. This caused the following alternative response to the <code>dw</code> location command:</p>
<pre><code>Loc:Please link:http://gpsui.net/smap.php?lac=1000&amp;cellid=10&amp;c=901&amp;n=70&amp;v=7100 Battery:67%</code></pre>
<h2 id="flash-contents">Flash contents</h2>
<p>The most interesting things could be found in the dumped flash.</p>
<h3 id="os">OS</h3>
<p>Strings in the <code>flash.dat</code> suggest the device is probably running Nucleus RTOS:</p>
<pre><code>$ strings -a flash.dat
Copyright (c) 1993-2000 ATI - Nucleus PLUS - Version ARM 7/9  1.11.19</code></pre>
<p>Other strings that may help identify the OS are:</p>
<pre><code>$ strings -a flash.dat | grep "\.c"
psss\components\src\bl_Secure_v5.c
psss\components\src\SSS_secure_shared_v5.c
hal\system\bootloader\src\bl_Main.c
hal\system\bootloader\src\bl_Main.c
hal\system\bootloader\src\bl_FTL.c
hal\system\bootloader\src\bl_FTL.c
hal\system\bootloader\src\bl_FTL.c
hal\storage\flash\mtd\src\flash_disk.c
hal\system\bootloader\src\bl_Main.c
hal\peripheral\src\dcl_pmu6261.c
hal\system\cache\src\cache.c
hal\peripheral\src\dcl_rtc.c
hal\peripheral\src\dcl_pmu6261.c
hal\system\bootloader\src\bl_FTL.c
hal\system\bootloader\src\bl_FTL.c
hal\peripheral\src\rtc.c
hal\peripheral\src\rtc.c
hal\peripheral\src\rtc.c
hal\peripheral\src\rtc.c
hal\peripheral\src\rtc.c
hal\peripheral\src\rtc.c
hal\storage\flash\mtd\src\flash_mtd_sf_dal.c
hal\peripheral\src\dcl_pmu_common.c
hal\peripheral\src\dcl_f32k_clk.c
hal\peripheral\src\dcl_f32k_clk.c
hal\peripheral\src\dcl_gpio.c
hal\peripheral\src\dcl_pmu_common.c
hal\system\cache\src\cache.c
hal\peripheral\src\dcl_f32k_clk.c
hal\peripheral\src\dcl_gpio.c
hal\peripheral\src\gpio.c
hal\system\bootloader\src\bl_FTL.c
hal\peripheral\src\rtc.c
hal\peripheral\src\bmt_hw.c
hal\peripheral\src\dcl_pmu6261.c
hal\storage\flash\mtd\src\flash_mtd.c
hal\peripheral\src\gpio.c
custom\common\hal\combo_flash_nor.c
hal\peripheral\src\dcl_rtc.c
hal\peripheral\src\dcl_rtc.c
hal\storage\flash\mtd\src\flash_disk.c
custom\common\hal\combo_flash_nor.c
hal\storage\flash\mtd\src\flash_mtd_sf_dal.c
hal\system\emi\src\emi.c
sss\components\src\SSS_secure_shared_common.c
alice.c
ddload.c
plutommi\Framework\GDI\gdisrc\gdi.c
C.cKi
hal\audio\src\v1\audio_service.c
ddload.c
ddload.c
plutommi\Framework\GDI\gdisrc\gdi_image_hwjpg_v2.c
plutommi\Framework\GDI\gdisrc\gdi_image_hwjpg_v2.c
plutommi\Framework\GDI\gdisrc\gdi_util.c
plutommi\Framework\GDI\gdisrc\gdi_util.c
hal\audio\src\v1\audio_service.c
ddload.c</code></pre>
<h3 id="fat12-filesystems">FAT12 filesystems (?)</h3>
<p><strong>Update:</strong> In my original write up I missed the flash translation layer, hence the FAT12 filesystem was corrupted. Thanks to Bjoern Kerler (<a href="https://twitter.com/viperbjk">@viperbjk</a>) for pointing this out to me. I will work on descrambling the flash and update once I have it working.</p>
<p>For the time being here is my original try at extracting the files from the file system:</p>
<p>Searching the <code>flash.dat</code> for the FAT12 file systems that are supposedly present in on MediaTek phones, we get:</p>
<pre><code>$ hexdump -C flash.dat
002c1e20  00 00 00 00 00 00 00 00  00 ef cd 4e 4f 20 4e 41  |...........NO NA|
002c1e30  4d 45 20 20 20 20 46 41  54 31 32 20 20 20 00 00  |ME    FAT12   ..|
002c1e40  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
002c1e50  00 00 00 00 00 00 00 00  00 00 4d 4d 4d 4d 4d 4d  |..........MMMMMM|
002c1e60  4d 4d 4d 4d 4d 4d 4d 4d  4d 4d 4d 4d 4d 4d 4d 4d  |MMMMMMMMMMMMMMMM|
*
002c1ff0  4d 4d 4d 4d 4d 4d 4d 4d  4d 4d 4d 4d 4d 4d 55 aa  |MMMMMMMMMMMMMMU.|
[...]
002d8400  eb 58 90 46 69 6c 65 53  79 73 20 00 02 01 01 00  |.X.FileSys .....|
002d8410  01 80 00 9b 01 f8 02 00  01 00 01 00 01 00 00 00  |................|
002d8420  9b 01 00 00 80 00 29 00  00 21 30 4e 4f 20 4e 41  |......)..!0NO NA|
002d8430  4d 45 20 20 20 20 46 41  54 31 32 20 20 20 00 00  |ME    FAT12   ..|
002d8440  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
002d8450  00 00 00 00 00 00 00 00  00 00 4d 4d 4d 4d 4d 4d  |..........MMMMMM|
002d8460  4d 4d 4d 4d 4d 4d 4d 4d  4d 4d 4d 4d 4d 4d 4d 4d  |MMMMMMMMMMMMMMMM|
*
002d85f0  4d 4d 4d 4d 4d 4d 4d 4d  4d 4d 4d 4d 4d 4d 55 aa  |MMMMMMMMMMMMMMU.|
[...]
002dbc00  ff ff ff ff ff de 9e 68  00 00 00 00 00 50 ba ff  |.......h.....P..|
002dbc10  55 93 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |U...............|
002dbc20  00 00 00 00 00 00 00 00  00 ef cd 4e 4f 20 4e 41  |...........NO NA|
002dbc30  4d 45 20 20 20 20 46 41  54 31 32 20 20 20 00 00  |ME    FAT12   ..|
002dbc40  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
002dbc50  00 00 00 00 00 00 00 00  00 00 4d 4d 4d 4d 4d 4d  |..........MMMMMM|
002dbc60  4d 4d 4d 4d 4d 4d 4d 4d  4d 4d 4d 4d 4d 4d 4d 4d  |MMMMMMMMMMMMMMMM|
*
002dbdf0  4d 4d 4d 4d 4d 4d 4d 4d  4d 4d 4d 4d 4d 4d 55 aa  |MMMMMMMMMMMMMMU.|</code></pre>
<p>However, two of the partitions do not appear to be valid FAT12 file systems:</p>
<pre><code>$ fls -o 5646 flash.dat -f fat12
Invalid magic value (Not a FATFS file system (magic))
$ fls -o 5826 flash.dat -f fat12
v/v 6531:   $MBR
v/v 6532:   $FAT1
v/v 6533:   $FAT2
d/d 6534:   $OrphanFiles
$ fls -o 5853 flash.dat -f fat12
Invalid magic value (Not a FATFS file system (magic))</code></pre>
<p>And the middle FAT12 block seems to be corrupted as well, i.e.&nbsp;only orphan files:</p>
<pre><code>$ fls -o 5826 flash.dat -rp -f fat12
v/v 6531:   $MBR
v/v 6532:   $FAT1
v/v 6533:   $FAT2
d/d 6534:   $OrphanFiles
-/r * 469:  $OrphanFiles/MP0B_001
-/r * 470:  $OrphanFiles/ST33A004
-/r * 471:  $OrphanFiles/ST33B004
[...]</code></pre>
<p>An attempt was made to extract the files:</p>
<pre><code>fls -o 5826 flash.dat -Frp -f fat12 | while read line; do
    path=$(echo "$line" | awk -F':' '{print $2}')
    mkdir -p $(dirname $path);
    icat -o 5826 flash.dat $(echo "$line" | grep -oE "[0-9]+" | head -n1) &gt; $path
done</code></pre>
<p>But most files are empty. The results are also very inconsistent, i.e., when changing SIM cards there are significant changes to the files listed by The Sleuthkit. This indicates that those are either not FAT12 partitions or a modified FAT12 variant.</p>
<p>Again as stated at the start of this section I’m missing the flash translation layer (FTL). There are proprietary tools which can do the FTL descrambling for you.</p>
<p>But to keep this whole writeup open source, further analysis was done using hexdump.</p>
<h3 id="configuration-data">Configuration data</h3>
<p>The flash also contained some configuration data. First, the IMSI of the inserted SIM and the number that is used to remote control the device could be found in the flash:</p>
<pre><code>$ hexdump -C flash.dat
002e2ad0  00 00 00 00 32 xx xx xx  xx xx xx xx xx xx xx xx  |....2xxxxxxxxxxx|
002e2ae0  xx xx 37 00 00 01 00 01  00 00 00 00 00 00 00 00  |xx7.............|
002e2af0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*
002e2b10  00 00 00 00 00 00 00 00  00 00 00 2b 34 39 31 xx  |...........+491x|
002e2b20  xx xx xx xx xx xx xx xx  00 00 00 00 00 00 00 00  |xxxxxxxx........|
002e2b30  00 00 00 00 00 00 00 00  00 00 00 00 00 67 70 73  |.............gps|
002e2b40  75 69 2e 6e 65 74 00 00  00 00 00 00 00 00 00 00  |ui.net..........|
002e2b50  00 00 00 00 00 00 00 00  00 00 00 00 00 67 70 73  |.............gps|
002e2b60  75 69 2e 6e 65 74 00 00  00 00 00 00 00 00 00 00  |ui.net..........|
002e2b70  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
*</code></pre>
<p>In the above flash segment you can also see a reference to <code>gpsui.net</code>. This is presumably the remote server which is contacted to turn the MCC, MNC, LAI and CID codes into street, city and country information as well as the link to gpsui.net which forwards to Google maps. However, because writing to the flash could not be achieved this hypothesis could not be confirmed.</p>
<h3 id="hidden-commands">Hidden commands</h3>
<p>Eventually, there was a small find potentially making this effort worthwhile. Searching the <code>flash.dat</code> for the <code>dw</code>,<code>1111</code> and <code>0000</code> commands reveals more hidden commands:</p>
<pre><code>$ hexdump -C flash.dat
00069530  8c ae 00 00 8d ae 8e ae  72 65 73 74 6f 72 65 00  |........restore.|
00069540  00 00 00 00 00 00 00 00  01 00 00 00 68 68 68 00  |............hhh.|
00069550  00 00 00 00 00 00 00 00  00 00 00 00 02 00 00 00  |................|
00069560  69 6d 73 69 00 00 00 00  00 00 00 00 00 00 00 00  |imsi............|
00069570  03 00 00 00 74 69 6d 65  7a 6f 6e 65 00 00 00 00  |....timezone....|
00069580  00 00 00 00 04 00 00 00  74 69 6d 65 00 00 00 00  |........time....|
00069590  00 00 00 00 00 00 00 00  05 00 00 00 61 71 65 00  |............aqe.|
000695a0  00 00 00 00 00 00 00 00  00 00 00 00 06 00 00 00  |................|
000695b0  61 71 63 00 00 00 00 00  00 00 00 00 00 00 00 00  |aqc.............|
000695c0  07 00 00 00 73 65 72 76  65 72 00 00 00 00 00 00  |....server......|
000695d0  00 00 00 00 08 00 00 00  64 64 64 00 00 00 00 00  |........ddd.....|
000695e0  00 00 00 00 00 00 00 00  09 00 00 00 72 65 67 00  |............reg.|
000695f0  00 00 00 00 00 00 00 00  00 00 00 00 0a 00 00 00  |................|
00069600  61 71 62 00 00 00 00 00  00 00 00 00 00 00 00 00  |aqb.............|
00069610  0b 00 00 00 71 71 71 00  00 00 00 00 00 00 00 00  |....qqq.........|
00069620  00 00 00 00 0c 00 00 00  64 77 00 00 00 00 00 00  |........dw......|
00069630  00 00 00 00 00 00 00 00  0d 00 00 00 6c 6f 63 00  |............loc.|
00069640  00 00 00 00 00 00 00 00  00 00 00 00 0e 00 00 00  |................|
00069650  66 61 61 00 00 00 00 00  00 00 00 00 00 00 00 00  |faa.............|
00069660  0f 00 00 00 66 66 66 00  00 00 00 00 00 00 00 00  |....fff.........|
00069670  00 00 00 00 10 00 00 00  31 31 31 31 00 00 00 00  |........1111....|
00069680  00 00 00 00 00 00 00 00  11 00 00 00 30 30 30 30  |............0000|
00069690  00 00 00 00 00 00 00 00  00 00 00 00 12 00 00 00  |................|
000696a0  72 70 74 00 00 00 00 00  00 00 00 00 00 00 00 00  |rpt.............|
000696b0  13 00 00 00 67 62 72 70  74 00 00 00 00 00 00 00  |....gbrpt.......|
000696c0  00 00 00 00 14 00 00 00  74 72 61 63 6b 00 00 00  |........track...|
000696d0  00 00 00 00 00 00 00 00  15 00 00 00 6d 6f 6e 69  |............moni|
000696e0  74 6f 72 00 00 00 00 00  00 00 00 00 16 00 00 00  |tor.............|
000696f0  73 6f 73 6f 6e 00 00 00  00 00 00 00 00 00 00 00  |soson...........|
00069700  17 00 00 00 73 6f 73 6f  66 66 00 00 00 00 00 00  |....sosoff......|
00069710  00 00 00 00 18 00 00 00  73 6f 73 00 00 00 00 00  |........sos.....|
00069720  00 00 00 00 00 00 00 00  19 00 00 00 71 63 73 6f  |............qcso|
00069730  73 00 00 00 00 00 00 00  00 00 00 00 1a 00 00 00  |s...............|
00069740  6c 65 64 6f 6e 00 00 00  00 00 00 00 00 00 00 00  |ledon...........|
00069750  1b 00 00 00 6c 65 64 6f  66 66 00 00 00 00 00 00  |....ledoff......|
00069760  00 00 00 00 1c 00 00 00  66 6c 69 67 68 74 6f 6e  |........flighton|
00069770  00 00 00 00 00 00 00 00  1d 00 00 00 66 6c 69 67  |............flig|
00069780  68 74 6f 66 66 00 00 00  00 00 00 00 1e 00 00 00  |htoff...........|
00069790  65 73 69 6f 6e 6f 77 00  00 00 00 00 00 00 00 00  |esionow.........|
000697a0  1f 00 00 00 65 73 69 6f  61 64 64 72 00 00 00 00  |....esioaddr....|
000697b0  00 00 00 00 20 00 00 00  68 62 74 6f 6e 00 00 00  |.... ...hbton...|
000697c0  00 00 00 00 00 00 00 00  21 00 00 00 68 62 74 6f  |........!...hbto|
000697d0  66 66 00 00 00 00 00 00  00 00 00 00 22 00 00 00  |ff.........."...|
000697e0  65 73 69 6f 6c 6f 63 61  74 65 74 79 70 65 00 00  |esiolocatetype..|
000697f0  23 00 00 00 65 65 65 00  00 00 00 00 00 00 00 00  |#...eee.........|
00069800  00 00 00 00 24 00 00 00  73 6e 64 73 74 6f 70 00  |....$...sndstop.|
00069810  00 00 00 00 00 00 00 00  25 00 00 00 64 64 65 00  |........%...dde.|
00069820  00 00 00 00 00 00 00 00  00 00 00 00 26 00 00 00  |............&amp;...|
00069830  66 6f 72 6d 61 74 74 66  00 00 00 00 00 00 00 00  |formattf........|
00069840  27 00 00 00 68 65 6c 70  00 00 00 00 00 00 00 00  |'...help........|
00069850  00 00 00 00 28 00 00 00  2a 65 38 31 2a 00 00 00  |....(...*e81*...|
00069860  00 00 00 00 00 00 00 00  29 00 00 00 2a 65 38 30  |........)...*e80|
00069870  2a 00 00 00 00 00 00 00  00 00 00 00 2a 00 00 00  |*...........*...|
00069880  2a 72 65 62 6f 6f 74 2a  00 00 00 00 00 00 00 00  |*reboot*........|
00069890  2b 00 00 00 2a 33 36 34  36 36 35 35 2a 00 00 00  |+...*3646655*...|
000698a0  00 00 00 00 2c 00 00 00  69 6d 65 69 73 65 74 00  |....,...imeiset.|</code></pre>
<p>However, most of those commands do not function correctly. It seems the devices firmware is shared among several such location tracking and listening devices, e.g., there are commands referring to LEDs and a TF card, both of which this device do no feature, however, other devices available online do.</p>
<p>An incomplete list of the found commands and there replies is:</p>
<ul>
<li><code>help</code>: replies with the following commands:
<ul>
<li><code>dw</code>: Locate</li>
<li><code>qqq</code>: Device binding</li>
<li><code>1111</code>: Sound Alarm Monitor on</li>
<li><code>0000</code>: Sound Alarm Monitor off</li>
<li><code>ddd</code>: Reset all tasks</li>
<li><code>aqb</code>: Get Username Password</li>
<li><code>eee</code>: Recording saved</li>
<li><code>dde</code>: Cleanup TF card</li>
<li><code>hhh</code>: Device status</li>
</ul></li>
<li><code>loc</code>: same as <code>dw</code></li>
<li><code>imsi</code>: Query IMEI and IMSI</li>
<li><code>faa</code>: “DTMG: Set voice monitoring, SMS reply and sound sensitivity successfully:40”, “DTMG: Unusual sound detected”</li>
<li><code>fff</code>: “DT: Set voice monitoring, voice callback and sound sensitivity successfully:40”</li>
<li><code>1111</code>: “DT: Set voice monitoring, voice callback and sound sensitivity successfully:400”</li>
<li><code>0000</code>: “DT: Voice monitoring cancelled successfully.”</li>
<li><code>gbrpt</code>: “Report:Location the continuous escalation has been closed.”</li>
<li><code>track</code>: “Track:Caller answer mode the device is set to reply location.”</li>
<li><code>hbton</code>: “Hbt:Device is turned on real-time online”</li>
<li><code>hbtoff</code>: “Hbt: Device online has been closed”</li>
<li><code>esionow</code>: “…” ?</li>
<li><code>esioaddr</code>: “Setting esio addr and port fail!”</li>
<li><code>esiolocatetype</code>: “Esio:Reporting location type has been updated to 0.”</li>
<li><code>server</code>: “Setting server addr and port fail!”</li>
<li><code>reg</code>: “…” ?</li>
<li><code>monitor</code>: “Monitor:Caller answer mode the device is set to automatically answer.”</li>
<li><code>eee</code>: “Tf-Card check fails of is insufficient free space!”</li>
<li><code>sndstop</code>: “Cam:No task is running, cancel failed!”</li>
<li><code>*e81*</code>: “…” ?</li>
<li><code>*e80*</code>: “…” ?</li>
<li><code>soson</code>, <code>sosoff</code>, <code>sos</code>, <code>qcsos</code>: ?</li>
<li><code>ledon</code>, <code>ledoff</code>: ?</li>
<li><code>flighton</code>, <code>flightoff</code>: ?</li>
<li><code>aqe</code>: “Setting apn fail!”</li>
<li><code>imeiset</code>: “…” does not seem to set the IMEI</li>
<li><code>restore</code>: “Restore ok!”</li>
<li><code>formattf</code>: ?</li>
<li><code>time</code>: “…” ?</li>
<li><code>timezone</code>: “Setting time zone ok. Current time zone 0”</li>
<li><code>age</code>: “…” ?</li>
<li><code>*3646655*</code>: queries for version information</li>
<li><code>*reboot*</code>: reboots the device</li>
</ul>
<p>Interestingly the reply strings could not be found in the flash in plaintext. This suggests that some of the data is compressed.</p>
<p>The message log of me trying some of the found hidden commands to populate the above list is as follows:</p>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/10_01_cmds.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/10_01_cmds.jpg" alt="S8 data line locator hidden commands."></a></p>
<p>It seems that we can use <code>esioaddr</code> to change the address used to lock up the location information. However, no connection to a given domain nor IP is actually made. The device will simply report <code>the addr invalid</code> in the location report.</p>
<p>The <code>server</code> command sets a different server. Changing it does not result in <code>the addr invalid</code> responses, as can be seen from this second message log:</p>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/10_14_cmds.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/10_14_cmds.jpg" alt="S8 data line locator hidden commands."></a></p>
<h2 id="provider-call-logs-and-itemized-bill">Provider call logs and itemized bill</h2>
<p>Because the GPRS sniffing failed I resort to the billing of my provider to further analyze the communication habits of the S8 data line locator.</p>
<p>Obviously reply SMS are billed. More interesting is the Internet access patterns.</p>
<h3 id="dw-or-loc-commands-and-during-idle"><code>dw</code> or <code>loc</code> commands and during idle</h3>
<p>During location queries the device will use “MMS/Internet” service. The following is a segment in which first repeated location queries were performed, then the devices was left idle:</p>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/11_00_provider_logs.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/11_00_provider_logs.jpg" alt="Provider call logs and itemized bill during location queries."></a></p>
<p>Even during idle the device sometimes uses the “MMS/Internet” service.</p>
<p>Even though I deactivated all tracking features that I may have activated during my previous testing, I can not be 100 % sure that this is not something that I activated, maybe while stumbling through the gpsui.net website. However, I regardless of whether I activated this “feature” or not, I do not want it and would like to know what data is actually send and how to deactivate it.</p>
<h2 id="gpsui.net">gpsui.net</h2>
<p>Going deeper into the gpsui.net website would probably result in a new writeup in itself. It is a very big surveillance hub, just replace the xxxx in http://gpsui.net/u/xxxx with some letters and numbers and you can see random people’s locations.</p>
<p>The website also makes a reference to ZhiPu:</p>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/12_gpsui.net.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/12_gpsui.net.jpg" alt="gpsui.net"></a></p>
<p>It seems this is the company that makes these trackers.</p>
<p>You can get your credentials for login by texting <code>aqb</code> to your S8 data line monitor. The username as well as the password are 6 digit numbers. They are also located in the flash right before the IMSI.</p>
<p>The web interface allows access to several features, which may or may not work as I’m not interested in them and hence not tested all of them:</p>
<h3 id="interface">Interface</h3>
<p>The plain interface after login looks like this: <a href="https://ha.cking.ch/s8_data_line_locator/images/13_00_interface.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/13_00_interface.jpg" alt="gpsui.net: Interface"></a></p>
<p>I panned the map into the ocean to hide my location. The location is pinpointed on the map by a little car and a pop up containing the GPS data and date of the last location update.</p>
<h3 id="settings">Settings</h3>
<p>You can change various settings: <a href="https://ha.cking.ch/s8_data_line_locator/images/13_01_setting.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/13_01_setting.jpg" alt="gpsui.net: settings"></a></p>
<h3 id="alarms">Alarms</h3>
<p>You can setup alarms: <a href="https://ha.cking.ch/s8_data_line_locator/images/13_02_alarm.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/13_02_alarm.jpg" alt="gpsui.net: alarms"></a></p>
<h3 id="real-time-location-tracking">Real time location tracking</h3>
<p>You can enable real time location tracking: <a href="https://ha.cking.ch/s8_data_line_locator/images/13_03_rtloc.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/13_03_rtloc.jpg" alt="gpsui.net: real time location"></a></p>
<h3 id="history">History</h3>
<p>Interestingly, the web interface allows to playback past location queries, as can be seen here: <a href="https://ha.cking.ch/s8_data_line_locator/images/13_04_history.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/13_04_history.jpg" alt="gpsui.net: history"></a></p>
<p>I find this particularity disturbing because in the original manual of the S8 data line locator there is no mention of the login credentials nor a way to get them. Also I did not expect a location query history to be stored somewhere.</p>
<h3 id="fence">Fence</h3>
<p>It also allows to set a geo fence: <a href="https://ha.cking.ch/s8_data_line_locator/images/13_05_fence.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/13_05_fence.jpg" alt="gpsui.net: fence"></a></p>
<h3 id="push-commands">Push commands</h3>
<p>Next, it allows you to push command to the device: <a href="https://ha.cking.ch/s8_data_line_locator/images/13_06_push_cmd.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/13_06_push_cmd.jpg" alt="gpsui.net: push commands"></a></p>
<p>This means anyone with access to your gpsui.net login credentials can control your device. A device which original packaging nor manual make any reference to said website.</p>
<h3 id="management">Management</h3>
<p>You can also add your fleet of devices into one account for simplified management: <a href="https://ha.cking.ch/s8_data_line_locator/images/13_07_mgnmt.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/13_07_mgnmt.jpg" alt="gpsui.net: management"></a></p>
<h3 id="vulnerabilities">Vulnerabilities</h3>
<p>After publishing this write up, Vangelis Stykas (<a href="https://twitter.com/evstykas">@evstykas</a>) found a bunch of Insecure Direct Object References with Authorization bypass through user-controlled key vulnerabilities leading to Horizontal escalation of privilege (one user can view/modify information of all other 615,817 accounts) in gpsui.net.</p>
<p>So my initial suspicions about gpsui.net were correct: you do not want your data to be send there.</p>
<p>We then also looked at some other (GPS) location tracking web services. What we found was mildly concerning and you can read about it here: <a href="https://0x0.li/trackmageddon/">https://0x0.li/trackmageddon/</a></p>
<p>I just want to point out here that a normal user is (at least as far as I know) never informed about the login credentials to the above website.</p>
<p>Neither is the user informed that the location queries are logged and stored there. Nor that the device can be remote controlled from there.</p>
<h2 id="detection">Detection</h2>
<p>When sending data the S8 data line locator can be detected with a CC308+ (a cheap Chinese RF detector):</p>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/01_cc308+.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/01_cc308+.jpg" alt="CC308+ detecting the S8 data line locator."></a></p>
<p>The S8 data line locator seems to be badly shielded. A location request via the <code>dw</code> command causes noticeable electronic noise by the device. It seems in general to cause all sorts of RF interference.</p>
<h2 id="future-work">Future work</h2>
<p>While I did not (yet) succeed with my original goal to disable the mobile data phone home “feature’, it was nevertheless a fun exercise and hopefully someone finds this useful or at least educational.</p>
<p>Future work needs to be done on several things:</p>
<h2 id="issues">Issues</h2>
<p>I was not able yet to write new firmware via flashrom because I was not able to disable block protection on the flash, yet. Maybe a different avenue for flashing new firmware could be the SPFlash tool<a href="#fn4" id="fnref4"><sup>4</sup></a> and/or the Flash tool. However, that would not be open source. <strong>If you are able to flash your S8 data line locator please contact me with details!</strong></p>
<p>Further, I tried to capture the GPRS data connection of the device, but was unable to do so. It would not use GPRS when connected to my network. Currently, I do not know how the APN is configured. The SIM trace does not indicate that the EF(ACL) is ever accessed. However, as I found the correct APN configuration stored in the devices flash, this suggests the device acquires this information via a setup SMS by the service provider.</p>
<h2 id="ideas">Ideas</h2>
<p>Dremel the board smaller, e.g., you don’t need the USB connector. This way the S8 data line locator could be turned into a “modular” bug that could be placed where ever there is a 5 V 1 A power source.</p>
<h2 id="other-people-working-on-this">Other people working on this</h2>
<p><a href="https://twitter.com/dmxinajeansuit">@dmxinajeansuit</a>: <a href="http://n0.lol/em/s8">http://n0.lol/em/s8</a></p>
<h2 id="appendix-fuck-up">Appendix: Fuck up</h2>
<p>No writeup would be complete without at least one fuck up. So here it is:</p>
<p>While using the S8 data line locator with OpenBTS I provisioned imaginary numbers. When switching SIM cards I forgot to turn of the voice activated callback.</p>
<p>So long story short, some guy with the number 3333333 listend in on me for 2 minutes:</p>
<p><a href="https://ha.cking.ch/s8_data_line_locator/images/11_01_provider_logs.jpg"><img src="https://ha.cking.ch/s8_data_line_locator/images/11_01_provider_logs.jpg" alt="Provider call log fail."></a></p>
<p>The number appears to be some sort of “service” number, hence it was an expensive call. But more importantly I did not notice this until I reviewed the logs!</p>
<p>So my resume on these little hardware espionage implants: <strong>They are stealthy and dangerous as fuck!</strong></p>
<h2 id="appendix-video">Appendix: Video</h2>
<p>An accompanying video is available at <a href="https://www.youtube.com/watch?v=hVOyoIfHA4E">https://www.youtube.com/watch?v=hVOyoIfHA4E</a></p>




</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a math website the internet loved, I'm back with more features (270 pts)]]></title>
            <link>https://teachyourselfmath.app/?page=1</link>
            <guid>40363517</guid>
            <pubDate>Wed, 15 May 2024 05:50:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://teachyourselfmath.app/?page=1">https://teachyourselfmath.app/?page=1</a>, See on <a href="https://news.ycombinator.com/item?id=40363517">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>