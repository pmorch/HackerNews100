<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 10 Feb 2024 19:00:09 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Tenets (110 pts)]]></title>
            <link>https://github.com/sveltejs/svelte/discussions/10085</link>
            <guid>39327113</guid>
            <pubDate>Sat, 10 Feb 2024 15:57:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/sveltejs/svelte/discussions/10085">https://github.com/sveltejs/svelte/discussions/10085</a>, See on <a href="https://news.ycombinator.com/item?id=39327113">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="presentation" data-paste-markdown-skip="">
    <tbody data-target-translation-id="6029409" data-target-translation-type="discussion">
        <tr>
    <td>
        <p dir="auto">This is an attempt to articulate the Svelte <em>philosophy</em> — our bedrock principles, that guide our design decisions.</p>
<p dir="auto"><em>Edit: for visitors from Hacker News, and anyone else who is curious, <a href="https://www.youtube.com/watch?v=eswNQiq4T2w&amp;t=5211s" rel="nofollow">here is the video</a> that this list came out of</em></p>
<h2 dir="auto">The web matters</h2>
<p dir="auto">We work on Svelte because we believe that the web is a critically important technology, and that its continued survival is not guaranteed.</p>
<h2 dir="auto">Optimise for vibes</h2>
<p dir="auto">People use Svelte because they <em>like</em> Svelte. They like it because it aligns with their aesthetic sensibilities.</p>
<p dir="auto">Instead of striving to be the fastest or smallest or whateverest, we explicitly aim to be the framework with the best vibes.</p>
<h2 dir="auto">Don't optimise for adoption</h2>
<p dir="auto">We're not trying to be the most popular framework, we're trying to be the best framework. Sometimes that means making choices that we believe in but that go against the grain of web development trends.</p>
<h2 dir="auto">HTML, The Mother Language</h2>
<p dir="auto">HTML is a really good language for describing UI. Svelte augments HTML in a way that makes it a really good language for describing <em>interactive</em> UI.</p>
<p dir="auto">Most frameworks are JS-centric, because JS is the most powerful language. But then they find themselves jumping through hoops to make it feel like you're writing HTML. We think both options are valid, but the HTML-first approach ends up feeling more natural.</p>
<h2 dir="auto">Embrace progress</h2>
<p dir="auto">There is a tendency in the web developer community towards a harmful form of pessimistic nostalgia — the idea that things were better in the prelapsarian age before bundlers, TypeScript, client-side routing and other trappings of modernity.</p>
<p dir="auto">This is nonsense. As a community our default position is one of optimism about technology — the platform is getting better, our tools are getting better, our devices are getting better, and if we embrace that fact we can make better stuff.</p>
<p dir="auto">And when other frameworks introduce new ideas like signals or server components, we look at them with interest and jealousy, and try to work out how we can incorporate good ideas, instead of resting on our laurels. There is always room for improvement.</p>
<h2 dir="auto">Numbers lie</h2>
<p dir="auto">Lighthouse has broken the brains of a generation of web developers. We have replaced good judgment with subservience to metrics that were only ever intended to be used as a diagnostic tool.</p>
<p dir="auto">Goodhart's Law states that</p>
<blockquote>
<p dir="auto">When a measure becomes a target, it ceases to be a good measure</p>
</blockquote>
<p dir="auto">and this is very true in web development. Numerical rigour is good, and we pay attention to the various numbers, but when designing Svelte we think qualitatively, not quantitatively.</p>
<h2 dir="auto">Magical, not magic</h2>
<p dir="auto">There's a subtle line between something feeling <em>magical</em>, and something feeling like <em>magic</em>. We want Svelte to feel magical — we want you to feel like a wizard when you're writing Svelte code. Historically I think Svelte went too far into magic territory, where it's not 100% clear why things work a certain way, and that's something that we're rectifying with Svelte 5.</p>
<h2 dir="auto">Dream big</h2>
<p dir="auto">'Choose the right tool for the job' is sensible but boring advice.</p>
<p dir="auto">It makes us small in our ambitions. I want us to dream bigger. I don't want to feel like my tools can't handle evolving requirements, or that if I want to dabble in a new field I need to learn an entirely new way of working first.</p>
<p dir="auto">Even if it turns out to be unachievable, I find it valuable to ask the question 'what would it take for SvelteKit to be the best framework for <em>any</em> app?', whether it's purely static content, or a realtime multiplayer app, or an offline-first productivity app, or even something built for an augmented reality headset.</p>
<h2 dir="auto">No-one cares</h2>
<p dir="auto">Most people do not care about frameworks. They just want to build something cool, and Svelte is for those people too.</p>
<p dir="auto">So when we design things we need to think about the people who haven't read the docs in a while, if at all, and don't care about things like fine-grained rendering or configuring their build tool. This means that things need to be intuitive, that we shouldn't need to worry about manual optimisations like memoisation, that we should have as few APIs as possible, and that things need to be discoverable — for example you should be able to hover over a rune and get a link to comprehensive documentation.</p>
<p dir="auto">This also informs our approach to documentation and tutorials — it should be possible to build what you want by just learning the concepts that you need, and worrying about the other stuff for another day.</p>
<h2 dir="auto">Design by consensus</h2>
<p dir="auto">Svelte is a community-driven and consensus-led project. It's important that the community — that's you — has a stake in the project's future. Many of Svelte's best ideas originated outside the core team.</p>
<p dir="auto">When we introduce new plans, we want to communicate them openly and provide everyone with good opportunities to offer their feedback.</p>
<p dir="auto">Those of us who work on the project every day have a vision for what kind of thing we want it to be, but we don't want to foist that vision on people against their will. And so while we can't get unanimous agreement on every change, we can at least say that dissenting voices have been heard and considered.</p>
    </td>
  </tr>

    </tbody>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A rent-stabilized 1 bedroom apartment for $1,100 In NYC? broker's fee is $15K (139 pts)]]></title>
            <link>https://gothamist.com/news/a-rent-stabilized-1-bedroom-apartment-for-1100-in-nyc-the-brokers-fee-is-15k</link>
            <guid>39326675</guid>
            <pubDate>Sat, 10 Feb 2024 15:12:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gothamist.com/news/a-rent-stabilized-1-bedroom-apartment-for-1100-in-nyc-the-brokers-fee-is-15k">https://gothamist.com/news/a-rent-stabilized-1-bedroom-apartment-for-1100-in-nyc-the-brokers-fee-is-15k</a>, See on <a href="https://news.ycombinator.com/item?id=39326675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>How much would you pay a broker for a $1,100-a-month apartment if you knew the rent wouldn’t be jacked up year after year?</p><p>A broker in Queens was offering apartment hunters the deal of a lifetime: a one-bedroom, rent-stabilized unit in Flushing, well below market rate for the area. The only catch was a $15,000 broker fee to secure the unit. Under rent stabilization, modest annual increases are <a href="https://gothamist.com/news/nyc-board-votes-to-increase-rents-on-1-million-rent-stabilized-units-by-3" rel="noopener" target="_blank">set by a city panel</a>, shielding tenants from dramatic hikes.</p><p>That was the predicament facing 27-year-old Christian Garbutt while he was searching for an apartment last month, he told Gothamist. The apartment seemed great, but he couldn’t afford the fee — nor did he want to pay it.</p><p>But the $15,000 broker fee levied by Miguel Silva, a broker with the New York City branch of the real estate company Keller Williams, was too high for even his employers. In response to questions from Gothamist, they said they are returning some of the money to the tenant who landed the apartment.</p><p>Broker fees are standard procedure in the city’s highly competitive real estate market, even when tenants find the units online and do most of the work themselves. Typical rates range from a month’s rent to a higher percentage of the yearly total.</p><p>But as affordable housing dwindles, broker’s fees are rising along with rents, making moves more difficult and dependent on upfront cash, in a sector where laws and regulations remain cloudy.</p><p>Last month, Gov. Kathy Hochul criticized “<a href="https://gothamist.com/news/nyc-brokers-charging-exorbitant-fees-forced-to-pay-260k-in-penalties" rel="noopener" target="_blank">excessive</a>” fees when she announced a $260,000 penalty against a brokerage firm found to be demanding $20,000 from prospective tenants trying to secure a rent-stabilized apartment, a rare rebuke of the practice.</p><p>The New York Department of State, which licenses brokers, said in an email that it determines that fees are too high when they exceed “industry norms and standards” and do not relate to actual services.</p><p>The rules are murky, and no laws explicitly cap broker’s fees or define the difference between reasonable costs and extortion — similar to a once-common arrangement known as “<a href="https://www.brickunderground.com/blog/2015/11/what_is_key_money" rel="noopener" target="_blank">key money</a>.”</p><h4><b>‘That’s insane’</b></h4><p>Garbutt said he was looking for an apartment in Queens when he came across a place in Flushing priced at $1,450 a month and advertised as a “newly renovated rent-stabilized” one-bedroom on the listings website StreetEasy. He said he toured the unit and “fell in love with it,” but soon found out there was a catch: The broker was asking for an $8,000 fee.</p><p>Garbutt said he decided to pass on the place because the upfront cost would have wiped out his savings. He said he found another one-bedroom in the same building — this one listed online at $1,100 a month — and again texted the broker.</p><p>According to text messages reviewed by Gothamist, the broker warned “the fee is also high. It’s much higher than the other one.” He wanted $15,000.</p><p>Garbutt said he was “shocked” by the figure and could not afford it. He said he stopped responding, even after the broker offered to negotiate the fee and updated the listing to $1,800 a month.</p><p>“That’s insane," Garbutt said of the fee. "That’s totally not fair. Normal New Yorkers, a lot of people, don't have that type of money saved up.”</p><p>He said he’s still looking for a place.</p><p>Silva, the broker, did not respond to requests for comment.</p><p>Keller Williams said it would return any money over 15% of the annual rent to the tenant who got the apartment.</p><p>"Although there are no standard or typical or legal caps on broker fees, Keller Williams NYC adheres to real property law and its guidance in the commission fees that are charged to reasonably relate to legitimate services provided to renters by our agents and firm,” said Richard Amato, an operating principal at the firm.</p><p>Here’s what you need to know about broker’s fees and what to do if you think you’re being overcharged.</p><h4><b>What are the upfront costs for renting an apartment?</b></h4><p>Renting an apartment in New York City is hard. The broker’s fee, a uniquely New York inconvenience that has <a href="https://www.northjersey.com/story/news/state/2022/09/09/broker-fees-nyc-nj-renters/65474656007/" rel="noopener" target="_blank">spread</a> to a <a href="https://therealdeal.com/new-york/2020/02/07/broker-fees-for-nyc-rentals-mystified-outsiders-heres-how-other-us-cities-do-it/" rel="noopener" target="_blank">few other places</a>, can make it even harder.</p><p>Along with the first month’s rent, security deposit and moving expenses, apartment hunters in the five boroughs typically have to fork over even more money to a middleman — a broker — usually hired by a landlord to list and show apartments.</p><p>Brokers typically charge a one-time fee of around 8% to 15% of the annual rent, or roughly $5,400 on a $3,000-a-month apartment.</p><p>In most cases, there is no way of getting around it, said Allia Mohamed, CEO of listings and landlord review website openigloo.</p><p>“It’s not really fair, but if you want to get that specific apartment you have to be prepared to pay up,” Mohamed said.</p><h4><b>What is a broker anyway?</b></h4><p>A real estate broker is a person who facilitates the sale or rental of a property, typically for a fee.</p><p>Real estate brokers in the Empire State <a href="https://dos.ny.gov/real-estate-broker" rel="noopener" target="_blank">are regulated by the New York Department of State</a>, which grants them a license if they meet the requirements and pass an exam.</p><p>Normally, people hire brokers to survey the market and find prospective options to buy or rent a place.</p><p>But in New York City, it's more common for landlords to hire the brokers to list the apartments on StreetEasy, Trulia and other platforms that charge a fee, and arrange visits with applicants. It’s then left to tenants to pay their commission.</p><h4><b>How much is too much?</b></h4><p>There’s a limit to what’s considered reasonable, according to industry regulators and lawmakers. Even many brokers agree that some fees are truly exorbitant. But where brokers cross the line isn’t clearly spelled out.</p><p>Regulators from the Department of State didn’t respond to a question about what they consider the industry standard for New York City broker fees. Industry groups generally agree that 15% of the annual rent is the norm.</p><p>Yet brokers know that someone with disposable income may be willing to pony up for a rent-stabilized apartment, since they could save money down the road. That’s the argument Garbutt said his broker made.</p><p>“He said it’s a lot of money, but you’re going to see it in the long run,” Garbutt recalled.</p><p>Still, that arrangement locks out the vast majority of New Yorkers who can only dream of paying that kind of fee.</p><p>The median household income in New York City is around $76,600, <a href="https://www.census.gov/quickfacts/fact/table/newyorkcitynewyork" rel="noopener" target="_blank">according to the U.S. Census Bureau</a>. Median rents are about $4,100 in Manhattan and $2,500 in Queens, according to the latest <a href="https://streeteasy.com/blog/data-dashboard/[object%20Object]?agg=Median&amp;metric=Asking%20Rent&amp;type=Rentals&amp;bedrooms=One%20Bedroom&amp;property=Any%20Property%20Type&amp;minDate=2010-01-01&amp;maxDate=2024-01-01&amp;area=Flatiron,Brooklyn%20Heights" rel="noopener" target="_blank">StreetEasy review of listings</a>. And most New Yorkers are considered rent-burdened, as they pay more than 30% of their income on rent, <a href="https://gothamist.com/news/1-in-3-nyc-tenants-spend-half-their-income-on-rent-as-affordability-crisis-deepens" rel="noopener" target="_blank">city housing data</a> shows.</p><p>For a $3,000-a-month apartment, that means you would need $11,400 upfront to cover the security deposit, first month of rent and 15% broker’s fee.</p><p>If you suspect you’re being overcharged, you can file a complaint <a href="https://dos.ny.gov/preliminary-statement-complaint-0" rel="noopener" target="_blank">with the Department of State.</a></p><h4><b>So is anyone doing anything about these fees?</b></h4><p>Past efforts to limit the fees have all failed.</p><p>The Real Estate Board of New York, or REBNY, successfully sued to <a href="https://gothamist.com/news/those-hefty-brokers-fees-are-returning-following-state-judges-ruling" rel="noopener" target="_blank">end a brief cap on broker’s fees for tenants</a>, based on an interpretation of <a href="https://gothamist.com/news/nyc-real-estate-brokers-are-already-exploiting-a-perceived-loophole-in-new-rent-laws" rel="noopener" target="_blank">state rent laws</a> enacted in 2019.</p><p>A City Council <a href="https://gothamist.com/news/city-council-proposals-would-slash-obscene-brokers-fees-and-limit-security-deposits" rel="noopener" target="_blank">bill limiting broker’s fees</a> to one month’s rent also died in 2019 amid <a href="https://ny.curbed.com/2019/6/28/18761629/nyc-broker-fee-reform-bill-city-council-real-estate" rel="noopener" target="_blank">opposition from the real estate industry</a>.</p><p>The latest attempt? A <a href="https://gothamist.com/news/nyc-broker-fees-are-skyrocketing-the-city-council-is-trying-to-put-the-fees-on-landlords" rel="noopener" target="_blank">City Council bill</a> that would require whoever hired the broker — such as the landlord, property manager or tenant — to cover the cost.</p><p>“I don't think anyone should be forced to pay a fee to someone who they never hired,” said Councilmember Chi Ossé of Brooklyn, who introduced the measure. “It's kind of replicating how we do transactions in every other industry within the city.”</p><p>REBNY and other critics of the bill say it will lead to higher rents on non-rent-stabilized apartments because landlords will spread the cost across the monthly rent payments for as long as the tenant lives there, instead of a one-time fee. Owners of rent-stabilized units would have to eat the cost.</p><p>“This bill would make the process of renting an apartment more costly and challenging for New Yorkers while negatively impacting the livelihood of hardworking agents,” said REBNY spokesperson Christopher Santarelli.</p><p>Veteran broker <a href="https://sammoritz.medium.com/thoughts-on-broker-fees-in-nyc-from-a-new-york-city-real-estate-agent-c7ef0802a68" rel="noopener" target="_blank">Sam Moritz</a> agreed.</p><p>“The tenant paying the broker fee is what it is,” he said. “If you eliminate the tenant-paid broker fee for apartments, rents are going to increase.”</p><p>Nikki Thomas, a broker and real estate agent for the Corcoran Group, declined to take a position on the legislation but said nixing the fee could be good business for property owners.</p><p>Thomas said she often encourages landlords to pay her commission and then add the price to the rent, since people get alienated by “junk fees.”</p><p>“I usually tell them to adjust the rent to factor that in, because I know people psychologically don’t like additional upfront costs,” she said. “You’re starting off with a happier tenant.”</p><h4><b>So what are you paying for exactly?</b></h4><p>Convenience — usually for the landlord — said Mohamed, the openigloo executive.</p><p>The brokers advertise the apartments, arrange showings and put together applications for the property owner, she said.</p><p>“When the landlord is hiring the broker, they’re the ones benefiting from the headache the broker is taking off their shoulders,” Mohamed said. “They definitely put in a ton of work in helping the landlord sift through applicants and prepare that space.”</p><p>Moritz, the longtime broker, said the services are especially important when the landlord lives outside the city or has a busy schedule that prevents them from continuously showing the apartment.</p><p>“They want to hire a professional, someone who does this full time and closes deals efficiently and professionally,” he said.</p><p>The brokers also have to cover some costs. Posting the apartment on StreetEasy costs $7 a day, or more than $200 a month, for example.</p><p>Moritz said he charges tenants the equivalent of one month’s rent so that he can get apartments leased up as quickly as possible. He said he figures he needs to earn about $6,500 a month to cover his own rent and expenses in Bushwick, which equates to at least three or four broker fees a month, he said.</p><p>He criticized brokers who charge exorbitant fees and said they are taking advantage of tenants and owners.</p><p>“I think that is a little greedy because this is the landlord’s asset,” Moritz said. “I personally think that if a landlord gives me a listing, then I am working for the landlord.”</p><p>Plenty of tenants also end up hiring brokers to help them find an apartment, especially if they have disposable income, a busy schedule or are moving to New York City from somewhere else.</p><p>“A broker can accomplish in a few days what might take someone several weeks,” Thomas of the Corcoran Group said. “Like so many things, you can do it on your own, but is it actually worth it?”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Was Illegally Fired by Amazon for Speaking Out About a Coworker's Death (2023) (467 pts)]]></title>
            <link>https://jacobin.com/2023/11/i-was-illegally-fired-by-amazon-for-speaking-out-about-a-coworkers-death/</link>
            <guid>39326559</guid>
            <pubDate>Sat, 10 Feb 2024 14:56:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jacobin.com/2023/11/i-was-illegally-fired-by-amazon-for-speaking-out-about-a-coworkers-death/">https://jacobin.com/2023/11/i-was-illegally-fired-by-amazon-for-speaking-out-about-a-coworkers-death/</a>, See on <a href="https://news.ycombinator.com/item?id=39326559">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content">

                <!-- Antescript -->

                
                  
                

                <!-- Intro -->
                
                  
                    
    <dl>
      <dt>Interview by</dt>
      
        <dd>
          <a href="https://jacobin.com/author/caspar-shaller">Caspar Shaller</a>
        </dd>
      
    </dl>
  
                  
                

                
                  
                    <section id="ch-0">
                      <p>Two years ago, union organizer Magda Malinowska was fired from her job at an Amazon warehouse near Poznań, in western Poland. Her sacking came as retaliation for her efforts to speak out against poor working conditions — a conflict catalyzed by the September 2021 death of forty-nine-year-old Dariusz Dziamski, a colleague of hers who died on the shop floor. Fast forward to October 2023, and a Polish court has ruled that Amazon fired Malinowska illegally.</p>
<p>The ruling provides a small step toward justice for Malinowska, albeit only after a two-year delay, and a period in which many aspects of Amazon workers’ rights have worsened. In an interview, Malinowska spoke to <i>Jacobin</i>’s Caspar Shaller about Amazon’s inhumane treatment of staff, its violation of basic union rights, and workers’ efforts to stand up against corporate tyranny.</p>

                    </section>
                  
                

                <!-- Main Content -->

                
    
      
        <section id="ch-1">
          
            
            <hr>
          
          
            <div>
                <p><span>
                  
                    
                      Caspar Shaller
                </span></p><p>A court has decided that Amazon fired you illegally and reinstated your job …</p>

              </div>
            <div>
                <p><span>
                  
                    
                      Magda Malinowska
                </span></p><p>… but they still have three weeks to appeal. I assume they will.</p>

              </div>
          
            <div>
                <p><span>
                  
                    
                      Caspar Shaller
                </span></p><p>What was the judge’s reasoning?</p>

              </div>
            <div>
                <p><span>
                  
                    
                      Magda Malinowska
                </span></p><p>That was the most interesting part: it was actually pretty clear that Amazon violated union rights. So, from a formal, legal perspective it was clear that I should win the case.</p>
<p>In Poland, however, it is possible to win the case, but without reinstatement. Some judges believe that if there is a major conflict between the trade unionists and the company it will be better this way. I was afraid that I would win the case but would not be reinstated — all the more so because the judge called more witnesses and delved deeply into the case and the relationship between the union and Amazon. The HR employees who fired me were questioned twice. Finally, the judge stated that my dismissal could have been caused by my activity. What I was accused of in terminating the contract was not proven during the case. Amazon didn’t manage to provide any evidence to support their position.</p>

              </div>
          
            <div>
                <p><span>
                  
                    
                      Caspar Shaller
                </span></p><p>What was the reason Amazon gave for firing you?</p>

              </div>
            <div>
                <p><span>
                  
                    
                      Magda Malinowska
                </span></p><p>They fired me for allegedly taking pictures or videos — but they didn’t know, because no one saw it — when the body of Dariusz, a colleague of mine who had died during his shift, was moved to the hearse, which they considered inconsistent with their values and social standards.</p>

              </div>
          
            <div>
                <p><span>
                  
                    
                      Caspar Shaller
                </span></p><p>How did Dariusz die?</p>

              </div>
            <div>
                <p><span>
                  
                    
                      Magda Malinowska
                </span></p><p>Dariusz had all the signs of experiencing a heart attack, but apparently that was not the medical reason. His wife told me his heart was broken. That’s why this was such an important case for us. Dariusz worked so hard. His job used to be done by a few people during a shift, but then they made him do all that work alone, pushing around trolleys with heavy boxes.</p>
<p>Dariusz had been complaining that his job was too exhausting for him and he wanted a different task. But they wouldn’t give him another position. They did the exact opposite: they reduced the number of people working the same job, so his work got even more exhausting.</p>
<p>Before Dariusz died, we’d long been trying to get Amazon to carefully examine energy expenditure and how hard the work we do is, including Dariusz’s. The company is required to do so by law. However, Amazon only roughly estimates how much energy workers put in, and doesn’t use an appropriate method to calculate it. A few years ago, we managed to persuade the Labor Inspectorate and CIOP (Central Institute for Labor Protection) to investigate the cases of several employees; some of them were putting in up to twice as much as the allowed levels.</p>
<p>We have court judgments that say that Amazon does not examine this properly. But this is dangerous, especially as each of us has some health issues, and some of us have been doing hard physical work for years. After Dariusz’s death, I told the media that [this past dispute] was probably the real reason for my dismissal.</p>
<p>On the Sunday before Dariusz died, he asked the supervisor to transfer him to another department because he was fed up with working too hard. Despite the requests, he continued to work alone at his post for about five hours. The next morning Dariusz collapsed and died on the floor of the warehouse. They didn’t really help him, despite his symptoms. He was told to go through the warehouse — the size of a dozen or so soccer fields — on his own, to go down the stairs to the medical room. When he got there, he died.</p>

              </div>
          
            <div>
                <p><span>
                  
                    
                      Caspar Shaller
                </span></p><p>Does this kind of thing happen a lot? Are there a lot of people who die in Amazon warehouses?</p>

              </div>
            <div>
                <p><span>
                  
                    
                      Magda Malinowska
                </span></p><p>It’s not like a construction site or a mine, where workers die all the time or have severe accidents. Amazon management actually gets pretty angry when there’s an accident. The work is dangerous in another way: the repetition and the strain get to you. That does affect your body and your health. That’s why we want to be able to do a labor inspection, to see if someone’s health is being affected by their work. And we want to change the definition of a workplace accident. Because if you do a super heavy job for some time and then you get a heart attack, formally it’s not connected to the job.</p>

              </div>
          
            <div>
                <p><span>
                  
                    
                      Caspar Shaller
                </span></p><p>Amazon is known for spearheading new types of labor surveillance. How is that connected to this case?</p>

              </div>
            <div>
                <p><span>
                  
                    
                      Magda Malinowska
                </span></p><p>One reason for the surveillance is that Amazon is trying to optimize all steps of the work process. They are not the only ones to try out new forms of labor management, but they are very quick at implementing changes. They are constantly implementing new ways of controlling workers’ bodies and movements. You can’t even leave your workstation for more than three minutes. You have scanners and cameras everywhere checking on your every movement.</p>
<p>So, surveillance is really the big issue at Amazon. Through all this, they force you to do very simple movements in a very repetitive way. Because they broke down the labor process into these simple movements, they can easily exchange workers, they don’t need experienced workers, they can just train new ones to do these simple movements. But having to do the same movements over and over and faster and faster is totally destroying our bodies.</p>

              </div>
          
            <div>
                <p><span>
                  
                    
                      Caspar Shaller
                </span></p><p>What are you going to do, now that you can go back to the warehouse?</p>

              </div>
            <div>
                <p><span>
                  
                    
                      Magda Malinowska
                </span></p><p>Well, for me, this is a completely new situation. I’ve never been fired and then reinstated. It’s going to be interesting what Amazon will do now. And I’m wondering if, after this ruling and the explanation that the judge gave us, they will be willing to change their relationship with us on the union side. That is actually what the judge said: that there is a conflict between labor and employer, but the conflict cannot be an argument to dismiss union members.</p>
<p>Firing all union members would mean there’s no union in the workplace anymore, but Polish law guarantees the right to a union. The juge even said she can see that Amazon’s attitude toward unions is very negative. It’s a global problem with Amazon: they don’t want to recognize unions anywhere. So, I think it was very important that this judge confirms what we’ve been saying, someone who’s not like us — some militant activist, who’s always up for a fight — but a representative of the state.</p>

              </div>
          
            <div>
                <p><span>
                  
                    
                      Caspar Shaller
                </span></p><p>Do you think this ruling will change anything in the immediate future?</p>

              </div>
            <div>
                <p><span>
                  
                    
                      Magda Malinowska
                </span></p><p>Unfortunately, I’m afraid they will not change their policy. They behave like they’re not scared of anything and try to break as many rules and regulations as possible. They’re just smashing everything on their way to making more and more profit. They’re always checking how far they can go, until finally there will be nothing left that can stop them. So this small victory is a step toward stoping them.</p>
<p>Amazon has used Poland as a base from which to attack German unions right next door, either by importing Polish workers as strikebreakers when German warehouses were being picketed or then by simply building warehouses along the German-Polish border to serve the German market and get around German labor laws and unions.</p>

              </div>
          
            <div>
                <p><span>
                  
                    
                      Caspar Shaller
                </span></p><p>How can workers cooperate over national lines and stop multinationals from playing workers off each other?</p>

              </div>
            <div>
                <p><span>
                  
                    
                      Magda Malinowska
                </span></p><p>The current situation is amazing for Amazon. There are so many different legal systems, even within Germany for example, different regions have different regulations. So they try to use it against us and to make bigger profits, pay less taxes, and so on. They move orders from one warehouse to another warehouse, if there is slack in one location – or when we’re organizing a blockade, for example for our campaign “Make Amazon Pay.”</p>
<p>When the Polish warehouses were opened, German workers were on strike, and the Amazon moved orders from German warehouses to Polish warehouses, forcing people Polish to work longer shifts. When Polish workers heard about the reason why they had to work longer shifts, they said, hey we don’t want to be scabs, and organized a go-slow. That was the beginning of our cooperation with German workers.</p>

              </div>
          
            <div>
                <p><span>
                  
                    
                      Caspar Shaller
                </span></p><p>How has organizing workers made progress over the recent years?</p>

              </div>
            <div>
                <p><span>
                  
                    
                      Magda Malinowska
                </span></p><p>Unfortunately, it’s become more difficult to organize. I think people are more scared. After previous actions, some people got fired. And there’s been a shift in company policy. When Amazon started out in Poland, they hired people on permanent contracts. That gave people a feeling of stability and legal protection, which allowed them to fight back.</p>
<p>But now, there are a lot of people who are employed by agencies. The split among the workers is pretty bad. I’ve seen discussions online about how only certain types of workers are allowed to do overtime. Pay is so low that everyone wants to pick up more shifts, so weirdly being allowed to work even more becomes a matter of prestige. So, working overtime isn’t a penalty, it’s a prize. That situation is totally sick.</p>

              </div>
          
            <div>
                <p><span>
                  
                    
                      Caspar Shaller
                </span></p><p>What are you doing to change that?</p>

              </div>
            <div>
                <p><span>
                  
                    
                      Magda Malinowska
                </span></p><p>Last year, we started a campaign about the firing of shop stewards and union representatives. Indeed, I wasn’t the only one who was sacked, there were others, too. And together with other unions, we organized a huge campaign to change the law. And it was successful: the government changed the law. Since the law came into effect in September it’s basically pointless to fire union officials. It’s still happening illegally, of course, but maybe it changes workers’ mentality a bit to know they have more legal rights. Maybe unions will get a little bit stronger. Or at least there won’t be a repetition of 2021 when so many people were sacked out of the blue.</p>
<p>Recently there was an election and the far-right government <a href="https://jacobin.com/2023/10/poland-lewica-left-wing-alliance-opposition-donald-tusk-law-and-justice">lost</a>. So maybe there might be some change in how the state handles these cases. But we are not focused only on the law, we’re also trying to figure out how to strengthen our position in warehouses. And we will continue to educate workers and exchange ideas and experiences among people from my union and others. One important focus will be on inspecting labor standards and how workers can do that themselves. We will try to use health and safety as tool to make working conditions better.</p>

              </div>
          
        </section>
      
    
  

              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[In 2023 operations for the .GOV TLD transitioned from Verisign to Cloudflare (105 pts)]]></title>
            <link>https://indico.dns-oarc.net/event/48/contributions/1038/</link>
            <guid>39326092</guid>
            <pubDate>Sat, 10 Feb 2024 13:46:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://indico.dns-oarc.net/event/48/contributions/1038/">https://indico.dns-oarc.net/event/48/contributions/1038/</a>, See on <a href="https://news.ycombinator.com/item?id=39326092">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
    <section>
        
        <p><span>
    <span>Christian Elmerot</span>
        <span>
            <span>(<span>Cloudflare</span>)</span></span></span>
        </p>
    </section>


    
        <div>
                <p>In 2023 operations for the .GOV TLD transitioned from Verisign to Cloudflare. One interesting aspect of this transition was the different approaches to DNSSEC signing by Verisign and Cloudflare. Whereas Verisign uses offline signing with RSA (algorithm 8) and NSEC3, Cloudflare generally uses online signing with ECDSA (algorithm 13) and NSEC.</p>
<p>Although the parties agreed to transition using only RSA, we wanted to test the statement in RFC 8901 ("Multi-Signer DNSSEC Models") that says "NSEC and NSEC3 can be used by different providers to serve the same zone." After extensive testing by both parties, we found no reasons why it shouldn't work, and this approach was used for the transition. To the best of our knowledge, this is likely to be the first time that a signed zone of such significance was operated using NSEC and NSEC3 at the same time.</p>
            </div>
    

    
        
        
    
        
        
    

    

    
        <section>
            
            
    <p><span itemprop="performers" itemscope="" itemtype="http://schema.org/Person">
                
                
                    <span>Christian Elmerot</span>
                
                <span>
                        <span>(<span>Cloudflare</span>)</span>
                    </span>
            </span>
        
    </p>

        </section>
    

    

    
    


    

    
    
        
    
    
    
    
    
    
    
    
    

    

    
    
        
    
    
    
    

    

        
        
    
    
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Memray – A Memory Profiler for Python (114 pts)]]></title>
            <link>https://github.com/bloomberg/memray</link>
            <guid>39325983</guid>
            <pubDate>Sat, 10 Feb 2024 13:28:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bloomberg/memray">https://github.com/bloomberg/memray</a>, See on <a href="https://news.ycombinator.com/item?id=39325983">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:bloomberg/memray" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="iVNVeL11Ne4eZZduspHHZq__lLvIN97ZtqkCG4kasqHqYAwDRNNovc-G_YMSb13WxbNm41z3nMBkhcmHJUGBkQ" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="bloomberg/memray" data-current-org="bloomberg" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=hJMDbBKF%2FZk%2Fu7%2FzhksoRR0nkCJ81U1FbCPyUMprfnWcmK%2FOBfgTDBt6MIpxPVyLnm7k46l8sBphd5ByPUuykwepgGzg45IbJOWuSUzSYfIiss6tfftTzfCEijP7rXOt07Futo7bDM3x%2BKdGf7ApqGXkkBCl6o5thPCk%2B4MKCjpwwrE2GFnEyq6LYl2Y%2FcVjWmSbE%2FbDoMsd7MfNkfK%2BN8SyNQcMeNA%2FE4aSHvaPzVu7ByLD1FoOcqIx6fRvyXhNqjnjx%2BlWmaUKoaa9wRSAHB96y5%2BHrR7uOlW6rUpdR4X%2B%2BmfOP54p2i%2FTlVst%2BZLx3dWikpm0usGPdRj26yWMlFal7IJIWfbRMN14rN9VPPMGOrdio7JydNrSLHasm1R2hC26aA12dwrNUnOBaDU4w1AcFceZyU9AhWX21%2FAvArgkKlV5zAUZj5sXfFHjZfE%2FPFkymoieonyxJQfV0DcNdG4aiU4TPalvOZ%2BOWgdpCKl%2B2Hpi1k3o9nNslpy4EfoFslCgCXSbT2LJOga5un0%3D--%2B96EEylELqg9NdPp--X73HRzcrjaMHYUaLwdsorQ%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=bloomberg%2Fmemray" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/bloomberg/memray&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="92d30e7bde27f0903164d388b5d768aa9f5f52f3f0a26850c59693e1e2bc2baa" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OPML Is Underrated (137 pts)]]></title>
            <link>https://kmaasrud.com/blog/opml-is-underrated.html</link>
            <guid>39324847</guid>
            <pubDate>Sat, 10 Feb 2024 09:31:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kmaasrud.com/blog/opml-is-underrated.html">https://kmaasrud.com/blog/opml-is-underrated.html</a>, See on <a href="https://news.ycombinator.com/item?id=39324847">Hacker News</a></p>
<div id="readability-page-1" class="page"><h2 id="opml-is-underrated">OPML is underrated</h2>
<!-- atom-id: a23474ca-0fc0-4444-93ad-21d1d08cded9 -->

<p>As a response to the general <a href="https://doctorow.medium.com/social-quitting-1ce85b67b456">enshittification</a>
of major platforms, I would say we are seeing a resurgence of the old
web’s ethos, with personal blogs gaining traction and the concept of the
<a href="https://neustadt.fr/essays/the-small-web/">small web</a> on the
rise. That might be colored by the digital communities I hang around in
(which are mostly dominated by programmers) but it does at least
empirically feel like a trend<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>. That brings along with
it a new interest in open web standards. Among them is RSS<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a>,
which both I, and I think a lot others, have increasingly integrated
into our digital routines to keep track of posts from people and sources
we’re following. RSS aligns perfectly with the movement towards more
personalized and controlled content consumption. Unlike the
algorithm-driven feeds of <q>other platforms</q> — which often
prioritize engagement over relevance or quality — RSS allows me to
curate my own information stream. This feels important to me, as it
gives me a level of autonomy over the content that shapes my views and
knowledge, as opposed to handing that power over to advertisers.</p>
<p>There is an issue, though. RSS feeds can be a bit clunky to manage
and keep track of. Their decentralized nature also makes discoverability
an issue. Enter <a href="http://opml.org/spec2.opml">OPML</a>, which is
an outliner format that is most commonly used to store <a href="http://opml.org/spec2.opml#subscriptionLists">a list of feed
subscriptions</a>. I promise you; having a single file that stores all
the feeds you’re interested in is a gamechanger, as it makes it
significantly easier to organize, migrate, and share those feeds across
different platforms and devices. Here’s an example:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>&lt;?xml</span><span> version=</span><span>"1.0"</span><span> encoding=</span><span>"utf-8"</span><span>?&gt;</span></span>
<span id="cb1-2">&lt;<span>opml</span><span> version=</span><span>"2.0"</span>&gt;</span>
<span id="cb1-3">  &lt;<span>head</span>&gt;</span>
<span id="cb1-4">    &lt;<span>title</span>&gt;A list of feeds I follow&lt;/<span>title</span>&gt;</span>
<span id="cb1-5">  &lt;/<span>head</span>&gt;</span>
<span id="cb1-6">  &lt;<span>body</span>&gt;</span>
<span id="cb1-7">    &lt;<span>outline</span><span> text=</span><span>"My favorite blog"</span><span> xmlUrl=</span><span>"https://a-cool-blog.tld/blog/feed.xml"</span><span> type=</span><span>"rss"</span></span>
<span id="cb1-8"><span>      htmlUrl=</span><span>"https://a-cool-blog.tld/blog"</span><span> description=</span><span>"You can also add a description"</span> /&gt;</span>
<span id="cb1-9">    <span>&lt;!-- more outline elements with feeds... --&gt;</span></span>
<span id="cb1-10">  &lt;/<span>body</span>&gt;</span>
<span id="cb1-11">&lt;/<span>opml</span>&gt;</span></code></pre></div>
<p>Each outline item must have the type <code>rss</code> (that goes for
both RSS and Atom feeds) and must include the <code>xmlUrl</code>
attribute. Optionally, you can specify some more attributes, like adding
a title with <code>text</code>, a description with
<code>description</code> and a link to the blog front page with
<code>htmlUrl</code> — that added metadata can be very useful. Yes, it
is XML-based, which I admit isn’t exactly the easiest format to work
with, but it has a few advantages, which we’ll get back to.</p>
<p>With OPML, you don’t need separate applications or services to
categorize feeds. Categorization can be achieved within a single OPML
file through its outlining capabilities or by managing multiple OPML
files, each dedicated to a different category or use-case. It is a very
viable workflow to have one OPML file for your YouTube subscriptions,
another for your favorite Twitter/X and Mastodon users, one more for
news sites, and yet another for personal blogs — the world’s your
oyster. However, there aren’t many application that support nested OPML
outlines or categorizing based on different files, sadly, but there
should be! This is a call to action, developers: Perfect
side-project!</p>
<p>Beyond personal convenience, OPML has the potential to better the
<em>ecosystem</em> of the <q>small web.</q> By not only sharing an RSS
feed on your personal website, but also your list of subscribed feeds,
we’re effectively creating a recommendation system that is based on
concious curation, not statistical metrics. Your OPML file is now called
a <em><a href="https://blogroll.org/what-are-blogrolls/">blogroll</a></em>, and
you officially get to call yourself a <strong>90s web
developer</strong>. Jokes aside, I believe the simple fact that there is
a known person behind each recommendation is advantageous. Yes, this
might promote smaller digital social circles, but I personally think the
transparency of a known source is the best way to combat <a href="https://en.wikipedia.org/wiki/Filter_bubble">filter bubbles</a>.
That part is a whole sociological discussion in itself, so if you would
like to discuss it further, I would love chatting about it on <a href="https://lists.sr.ht/~kmaasrud/inbox">my mailing list</a>.</p>
<p>Now, getting back to the fact that OPML is XML-based; I’d like to
highlight an often-overlooked feature of this: The ability to use an XSL
stylesheet to display the OPML file rendered through a HTML template
when loaded in a browser. With this, you can add a short introduction
and guide to the format, making the blogroll more accessible to those
unfamiliar with it. It also opens the possibility to showcase each feed
with added context or descriptions.</p>
<details>
<summary>
Here is an example XSL stylesheet you can use:
</summary>
<div id="cb2"><pre><code><span id="cb2-1"><span>&lt;?</span><span>xml</span><span> version=</span><span>"1.0"</span><span> encoding=</span><span>"UTF-8"</span><span>?&gt;</span></span>
<span id="cb2-2"><span>&lt;</span><span>xsl:stylesheet</span><span> version=</span><span>"1.0"</span><span> xmlns:xsl=</span><span>"http://www.w3.org/1999/XSL/Transform"</span><span>&gt;</span></span>
<span id="cb2-3">  <span>&lt;</span><span>xsl:template</span><span> match=</span><span>"/opml"</span><span>&gt;</span></span>
<span id="cb2-4">    <span>&lt;html</span><span> xmlns=</span><span>"http://www.w3.org/1999/xhtml"</span><span> xml:lang=</span><span>"en"</span><span> lang=</span><span>"en"</span><span>&gt;</span></span>
<span id="cb2-5">      <span>&lt;head&gt;</span></span>
<span id="cb2-6">        <span>&lt;title&gt;</span></span>
<span id="cb2-7">          <span>&lt;</span><span>xsl:value-of</span><span> select=</span><span>"head/title"</span><span>/&gt;</span></span>
<span id="cb2-8">        <span>&lt;/title&gt;</span></span>
<span id="cb2-9">        <span>&lt;meta</span><span> name=</span><span>"viewport"</span><span> content=</span><span>"width=device-width, initial-scale=1"</span><span>/&gt;</span></span>
<span id="cb2-10">        <span>&lt;style&gt;</span> /* Insert CSS here */ <span>&lt;/style&gt;</span></span>
<span id="cb2-11">      <span>&lt;/head&gt;</span></span>
<span id="cb2-12">      <span>&lt;body&gt;</span></span>
<span id="cb2-13">        <span>&lt;p&gt;</span></span>
<span id="cb2-14">          This is a list of blogs and news sources I follow. The page</span>
<span id="cb2-15">          is itself an <span>&lt;a</span><span> href=</span><span>"http://opml.org/"</span><span>&gt;</span>OPML<span>&lt;/a&gt;</span> file, which</span>
<span id="cb2-16">          means you can copy the link into your RSS reader to</span>
<span id="cb2-17">          subscribe to all the feeds listed below.</span>
<span id="cb2-18">        <span>&lt;/p&gt;</span></span>
<span id="cb2-19">        <span>&lt;ul&gt;</span></span>
<span id="cb2-20">          <span>&lt;</span><span>xsl:apply-templates</span><span> select=</span><span>"body/outline"</span><span>/&gt;</span></span>
<span id="cb2-21">        <span>&lt;/ul&gt;</span></span>
<span id="cb2-22">      <span>&lt;/body&gt;</span></span>
<span id="cb2-23">    <span>&lt;/html&gt;</span></span>
<span id="cb2-24">  <span>&lt;/</span><span>xsl:template</span><span>&gt;</span></span>
<span id="cb2-25">  <span>&lt;</span><span>xsl:template</span><span> match=</span><span>"outline"</span><span> xmlns=</span><span>"http://www.w3.org/1999/xhtml"</span><span>&gt;</span></span>
<span id="cb2-26">    <span>&lt;</span><span>xsl:choose</span><span>&gt;</span></span>
<span id="cb2-27">      <span>&lt;</span><span>xsl:when</span><span> test=</span><span>"@type"</span><span>&gt;</span></span>
<span id="cb2-28">        <span>&lt;</span><span>xsl:choose</span><span>&gt;</span></span>
<span id="cb2-29">          <span>&lt;</span><span>xsl:when</span><span> test=</span><span>"@xmlUrl"</span><span>&gt;</span></span>
<span id="cb2-30">            <span>&lt;li&gt;</span></span>
<span id="cb2-31">              <span>&lt;strong&gt;</span></span>
<span id="cb2-32">                <span>&lt;a</span><span> href=</span><span>"</span><span>{@htmlUrl}</span><span>"</span><span>&gt;&lt;</span><span>xsl:value-of</span><span> select=</span><span>"@text"</span><span>/&gt;&lt;/a&gt;</span></span>
<span id="cb2-33">                (<span>&lt;a</span><span> class=</span><span>"feed"</span><span> href=</span><span>"</span><span>{@xmlUrl}</span><span>"</span><span>&gt;</span>feed<span>&lt;/a&gt;</span>)</span>
<span id="cb2-34">              <span>&lt;/strong&gt;</span></span>
<span id="cb2-35">              <span>&lt;</span><span>xsl:choose</span><span>&gt;</span></span>
<span id="cb2-36">                <span>&lt;</span><span>xsl:when</span><span> test=</span><span>"@description != </span><span>''</span><span>"</span><span>&gt;</span></span>
<span id="cb2-37">                  <span>&lt;br/&gt;&lt;</span><span>xsl:value-of</span><span> select=</span><span>"@description"</span><span>/&gt;</span></span>
<span id="cb2-38">                <span>&lt;/</span><span>xsl:when</span><span>&gt;</span></span>
<span id="cb2-39">              <span>&lt;/</span><span>xsl:choose</span><span>&gt;</span></span>
<span id="cb2-40">            <span>&lt;/li&gt;</span></span>
<span id="cb2-41">          <span>&lt;/</span><span>xsl:when</span><span>&gt;</span></span>
<span id="cb2-42">        <span>&lt;/</span><span>xsl:choose</span><span>&gt;</span></span>
<span id="cb2-43">      <span>&lt;/</span><span>xsl:when</span><span>&gt;</span></span>
<span id="cb2-44">    <span>&lt;/</span><span>xsl:choose</span><span>&gt;</span></span>
<span id="cb2-45">  <span>&lt;/</span><span>xsl:template</span><span>&gt;</span></span>
<span id="cb2-46"><span>&lt;/</span><span>xsl:stylesheet</span><span>&gt;</span></span></code></pre></div>
</details>
<p>You can link to the stylesheet in your OPML file by adding
<code>&lt;?xml-stylesheet type="text/xsl" href="path/to/stylesheet.xsl"?&gt;</code>
at the top. I actually do this on <a href="https://kmaasrud.com/blogroll.xml">my own blogroll</a>, so check
that out if you want some inspiration.</p>
<p>While we’re all getting a bit fed up with the big platforms, OPML is
like a breath of fresh air from the old web days. It’s all about making
life easier when managing feeds, sharing cool finds, and stumbling upon
new stuff. So I encourage you to create your own blogroll, slap it on
your website, and share what you’re into. It’s a simple move, but it
could spark some real connections and bring back a bit of that community
vibe we miss.</p>


<section>
<h3>Here are some posts from sites I follow</h3>
<section>

<div>
<h4 dir="auto">
<a href="https://blog.rust-lang.org/2024/02/06/crates-io-status-codes.html" target="_blank" rel="noopener">crates.io: API status code changes</a>
</h4>
<p dir="auto">Cargo and crates.io were developed in the rush leading up to the Rust 1.0 release to fill the needs for a tool to manage dependencies and a registry that people could use to share code. This rapid work resulted in these tools being connected with an API t…</p>
<p>via <a href="https://blog.rust-lang.org/">Rust Blog</a>
February 6, 2024</p>
</div>

<div>
<h4 dir="auto">
<a href="https://sourcehut.org/blog/2024-01-19-outage-post-mortem/" target="_blank" rel="noopener">SourceHut network outage post-mortem</a>
</h4>
<p dir="auto">It’s been a busy couple of weeks here at SourceHut. At the time of writing, we
have restored SourceHut to full service following an unprecedented 170 hour
outage, and while we still have numerous kinks to sort out following an
unscheduled emergency migration…</p>
<p>via <a href="https://sourcehut.org/blog/">Blogs on Sourcehut</a>
January 19, 2024</p>
</div>

<div>
<h4 dir="auto">
<a href="https://nutcroft.mataroa.blog/blog/when-hope-and-gloom-unite/" target="_blank" rel="noopener">When hope and gloom unite</a>
</h4>
<p dir="auto">This is the Matrix and I am Neo. Not because I am the One — I'm not. The reason I am Neo is because I really can fly, I really can stop bullets, I really can download knowledge to my brain.
The reader might expect that I justify the above but instead I…</p>
<p>via <a href="https://nutcroft.com/">nutcroft</a>
January 16, 2024</p>
</div>

</section>
</section>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building the DirectX shader compiler better than Microsoft? (219 pts)]]></title>
            <link>https://devlog.hexops.com/2024/building-the-directx-shader-compiler-better-than-microsoft/</link>
            <guid>39324800</guid>
            <pubDate>Sat, 10 Feb 2024 09:22:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devlog.hexops.com/2024/building-the-directx-shader-compiler-better-than-microsoft/">https://devlog.hexops.com/2024/building-the-directx-shader-compiler-better-than-microsoft/</a>, See on <a href="https://news.ycombinator.com/item?id=39324800">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><main aria-role="main"><div><p>This is a <del>story</del> nightmare about the messy state of Microsoft’s DirectX shader compiler, and trying to wrangle it into a nicer experience for game developers. In some respects, we now build the DXC compiler better than how Microsoft does.</p><h2 id="setting-the-stage">Setting the stage</h2><p>For <a href="https://machengine.org/">Mach engine</a> we’ve been building an <a href="https://devlog.hexops.com/2024/mach-v0.3-released/#sysgpu">experimental graphics API called sysgpu</a> using Zig, aiming to be a <em>successor</em> and <em>descendant</em> of WebGPU for native graphics. It will support Metal, Vulkan, Direct3D, and OpenGL backends. As part of this, we need to compile shader programs into something that Direct3D 12 can consume. But what does it consume?</p><h2 id="a-brief-history-lesson">A brief history lesson</h2><p>The DirectX graphics API uses HLSL as its shading language of choice. In the past, with Direct3D 11 and earlier, this compiler was called ‘FXC’ (the ‘effects compiler’)</p><h3 id="fxc-is-deprecated-dxc-enters-the-scene-with-direct3d-12">FXC is deprecated, DXC enters the scene with Direct3D 12</h3><p>Unfortunately, FXC as a compiler is rather notoriously slow among game developers, with suboptimal code generation - meaning shaders often both compile and execute fairly suboptimally.</p><p>With the release of Direct3D 12 and Shader Model 6.0 (SM6), Microsoft officially deprecated the FXC compiler distributed as part of the Windows OS in favor of a new compiler called ‘DXC’ (‘directx compiler’), which exists as a public Microsoft-official fork of LLVM/Clang v3.7 <a href="https://github.com/microsoft/DirectXShaderCompiler">Microsoft/DirectXShaderCompiler</a> and prebuilt binaries you can download.</p><p>In this Microsoft fork of LLVM, changes are meticulously annotated via <code>// HLSL Change Start</code> and <code>// HLSL Change End</code> comments making it clear who owns what code:</p><p><a href="https://devlog.hexops.com/img/2024/hlsl-change-start"><img src="https://devlog.hexops.com/img/2024/hlsl-change-start.png"></a></p><h3 id="what-a-directx-driver-eats-for-breakfast-dxbc-or-dxil">What a DirectX driver eats for breakfast: DXBC or DXIL</h3><p>Although HLSL is the language of choice for Direct3D programming, at the end of the day GPUs under the hood all have different compute architectures and requirements: the compiled binary form of a shader program that an Intel GPU needs is going to be different from what an NVIDIA GPU needs, same goes for AMD.</p><p>Microsoft’s role is to provide the nice game developer frontend APIs (like Direct3D, and the HLSL shanding language), while working with independent hardware vendors (IHV’s) like Intel/AMD/NVIDIA who write the drivers - bridging those nice frontend APIs to whatever is hopefully closest to hardware manufacturer’s instruction set architecture (ISA) under the hood. You can think of it like web browsers making sure JavaScript can run on both a Windows PC and a macOS Apple Silicon device, though graphics developers would spit at the suggested comparison.</p><p>DirectX versions 9-11 had driver manufacturers consuming what is called DXBC (DirectX Byte Code) - game developers would produce DXBC either using a CLI tool to compile their HLSL programs like <code>fxc.exe</code>, or at runtime using the <code>d3dcompiler</code> APIs, and then the driver’s job was to take that decently-optimized shader bytecode and turn it into the actual binary that the GPU would run. This bytecode was an undocumented, proprietary format really only shared between Microsoft and GPU driver manufacturers - excluding a few odd-ball Linux developers who cared to reverse engineer it for Proton.</p><p>With the advent of DirectX 12 and Shader Model 6.0, Microsoft aspirationally had intended to create their own standard IR called DXIR, but in 2021 they <a href="https://github.com/microsoft/DirectXShaderCompiler/commit/61c6573842be58a14e1dfc6b1b3def03d39d9988">removed all language suggesting they might do this</a>. The intent <em>was</em> for DXIR to be the ‘high level’, ‘unoptimized’ IR form which compilers (think: Rust) could target, and then the DXC compiler could lower DXIR into the optimized DXIL bytecode form, a new ‘low level’ post-optimization IR format, before handing it off to graphics drivers to muck with as they please before it gets translated to run on the actual hardware.</p><p>Asked about DXIR documentation, a <a href="https://github.com/microsoft/DirectXShaderCompiler/issues/2389#issuecomment-517076643">Microsoft employee</a> had noted this in 2019:</p><blockquote><p>Unfortunately, documentation on the lowering process [from DXIR to DXIL] is mostly non-existent. […]</p><p>Oh, and DXIR isn’t anything official, but just the first LLVM IR after CodeGen.</p></blockquote><p>As you’ll soon see, this theme of ‘there are no docs, just whatever our compiler actually does’ will become a common pattern.</p><h3 id="dxil">DXIL</h3><p>DXIL (pronunciation?) is the official format that DirectX 12 driver manufacturers consume <em>today</em>.</p><p>A game developer produces DXIL bytecode using the DXC compiler, which is a fork of LLVM/clang heavily modified to support HLSL compilation, and the DirectX APIs hand that DXIL over to the graphics driver which then converts the IR into their own intermediate languages, performing any secret sauce optimization passes on it, and ultimately boiling down to the actual machine code that will run on the GPU hardware.</p><p>Much like the old bytecode format DXBC which DXIL replaced, it is <em>also</em> an undocumented bytecode format, specifically it is LLVM’s version 3.7 post-codegen post-optimization-passes bitecode format. It is undocumented not because nobody wants to document it, but rather because the documentation is literally ‘whatever the Microsoft fork of LLVM v3.7 with all the HLSL changes we made, after CodeGen and optimization passes have occurred, actually emits as LLVM bitcode - plus a small custom container/wrapper file format on top.’</p><h3 id="correcting-the-microsoft-fork-of-llvm">Correcting the Microsoft fork of LLVM</h3><p>Microsoft themselves are well aware that a bunch of independent driver manufacturers relying on and expecting to consume a hyper-specific undocumented LLVM bitcode format specifically produced by their fork is, well, less than ideal - and also aware that their fork of LLVM is not super fun to maintain, either. Quoting <a href="https://github.com/microsoft/DirectXShaderCompiler/issues/5773#issuecomment-1735794551">another Microsoft employee</a> (Sep 2023) who was asked about the potential of adding DirectX 9/10/11 support to the new/better DXC compiler, they stated:</p><blockquote><p>DXC’s fork of LLVM removed and/or damaged much of the code generation layer and infrastructure [of LLVM]. Given that, supporting DXBC generation in DXC would be a massive task to fix and restore broken LLVM functionality. Due to the large scale of this issue and resource constraints on our team we’re not going to address this issue in [the new] DXC [compiler] ever.</p><p>We may support DXBC generation in Clang in the future (we mentioned that in the original proposal to LLVM). That work is unlikely to begin for a few years as our focus will be on supporting DXIL and SPIR-V generation first.</p></blockquote><p>As noted above, in March of 2022, Microsoft had proposed and begun work on <a href="https://discourse.llvm.org/t/rfc-adding-hlsl-and-directx-support-to-clang-llvm/60783">upstreaming HLSL compilation support directly into LLVM/clang proper</a> - work that is still ongoing today - and involved <em>adding back</em> legacy LLVM v3.7 bitcode writing support to modern LLVM/clang versions:</p><blockquote><p>By isolating as much of the DXIL-specific code as possible into a target we hope to minimize the cost on the community to maintain our legacy bitcode writing support.</p></blockquote><p>i.e. the plan to get away fromn their fork is to upstream HLSL and DXIL support to LLVM/clang proper.</p><h2 id="the-challenge-for-gamedevs-webgpu-etc">The challenge for gamedevs, WebGPU, etc.</h2><p>Graphics abstraction layers which aim to provide a unified interface to modern graphics APIs like Metal, Direct3D 12, and Vulkan.. ultimately need to provide a unified shading language as well. If you look today, you’ll find most WebGPU implementations which do this have had a goal of ‘in the future we might be able to emit DXIL directly..’ but in practice, none actually do.</p><p>Instead, basically every WebGPU implementation today behaves as follows:</p><ul><li>The WGSL textual language first gets translated to HLSL at runtime</li><li>HLSL is compiled into DXBC or DXIL using an HLSL compiler</li><li>The optimized DXBC/DXIL is handed to the graphics driver, which then gets converted to the various vendor-specific ILs before finally becoming machine code that runs on the GPU.</li></ul><h3 id="a-quick-detour-spir-v">A quick detour: SPIR-V</h3><p>Vulkan/SPIR-V does much the same as the above, in fact most drivers cannot assume SPIR-V is optimized at all - though some do, and this varies by mobile/desktop GPUs - and have more work to perform to get SPIR-V turned into a <em>driver-compiled</em> native binary.</p><p>Valve has <a href="https://github.com/ValveSoftware/Fossilize">Fossilize</a> and maintains caches of each specific (GPU, driver version, etc.) pairing along with the <em>actual</em> driver-compiled binary for a SPIR-V blob, to enable downloading ‘pre-cached shaders’ from Valve servers ahead of playing games for this reason: so that you don’t spend all day waiting for your computer to go brrr compiling and optimizing SPIR-V shaders into actual native code your GPU understands.</p><p>In other words, DXIL is always post-optimization-passes LLVM <em>bitcode</em>, while SPIR-V can or cannot be an an optimized form, and GPU manufacturers write their drivers based on what SPIR-V looks like in the wild - which may or may not be a pre-optimized form. SPIR-V is closer to hardware than a textual shading language, but still very far from native machine code a GPU understands.</p><p>Only Apple’s Metal graphics API supports compiling directly to the actual target hardware’s native binary format (thanks to that iron fist they hold over their hardware, I guess.)</p><h2 id="to-use-dxcompilerdll-or-not">To use dxcompiler.dll or not?</h2><p>Since WGSL-&gt;HLSL-&gt;DXIL is happening at runtime, WebGPU runtimes are faced with a challenge: do we use the new DXC HLSL compiler, or the old, officially deprecated FXC compiler which has worse performance and codegen quality? On the surface, this hardly sounds like a difficult choice!</p><p>However, despite this, many indie devs and game engines choose to use FXC by default. <a href="https://docs.rs/bevy/latest/i686-pc-windows-msvc/bevy/render/settings/enum.Dx12Compiler.html">Bevy game engine’s documentation</a> puts it really well:</p><blockquote><p>The Fxc compiler (default) is old, slow and unmaintained. However, it doesn’t require any additional .dlls to be shipped with the application.</p><p>The Dxc compiler is new, fast and maintained. However, it requires both <code>dxcompiler.dll</code> and <code>dxil.dll</code> to be shipped with the application. These files can be downloaded from <a href="https://github.com/microsoft/DirectXShaderCompiler/releases">https://github.com/microsoft/DirectXShaderCompiler/releases</a>.</p></blockquote><p>As a result, much software defaults to the old, slow and unmaintained compiler. And it’s not just Bevy: <code>wgpu</code> Rust users, Dawn WebGPU users, etc. are all faced with this same question. It’s likely one of the reasons WebGPU does not support Shader Model 6.0+ functionality today - using the DXC compiler is not so pleasant: it is after all a large, clunky Microsoft fork of a C++ codebase from nearly a decade ago!</p><h2 id="well-why-not-just-statically-link-against-it">Well, why not just statically link against it?</h2><p>You can’t.</p><p>Firstly, there is the issue that <a href="https://github.com/microsoft/DirectXShaderCompiler/issues/4766">Microsoft’s fork of LLVM doesn’t support statically linking</a>. On the surface, this appears just to be due to some cmake files assuming <code>SHARED</code> instead of <code>STATIC</code> when creating libraries, but if you dig into it - as I did - you’ll soon find it is <em>much</em> more involved than that.</p><p>Switching <code>SHARED</code> to <code>STATIC</code> everywhere in CMake files will appear to get you a build with ~15 different static libraries to link against (not pleasant compared to just one.) You might think using cmake <code>OBJECT</code> libraries could solve this, but with this you will quickly encounter an issue where although the cmake files are structured logically as dependants, they actually have implicit dependencies on eachother due to the HLSL changes Microsoft made. I am 80% sure you would need to rewrite every cmake file in the repository to support OBJECT libraries. I can say this, because I tried!</p><p>You might be thinking, linking against ~15 static libraries isn’t SO bad as long as the final executable is static, right?</p><p>Not so fast - many parts of DXC’s COM interface implementation is also explicitly designed to load itself as a DLL, i.e. to load <code>dxcompiler.dll</code> and <code>dxil.dll</code> as dynamic libraries and self-invoke methods.</p><p>OK, we just need to patch the implementation to not call <code>LoadLibraryW</code> then, basically, right?</p><h2 id="introducing-dxildll---the-proprietary-code-signing-blob-for-directx-shaders">Introducing dxil.dll - the proprietary code signing blob for DirectX shaders</h2><p>If you’ve ever built DirectXShaderCompiler from source, you might notice something: dxil.dll doesn’t get built. Why? It’s distributed in every release on GitHub, both for Windows (x86/arm) and Linux (x86 only).</p><p>Strange, I thought the compiler was supposed to be open source? Well, it wouldn’t be the first time<a href="https://github.com/microsoft/win32metadata/issues/766#issuecomment-1150271300">[0]</a><a href="https://github.com/microsoft/Azure-Kinect-Sensor-SDK/issues/1521">[1]</a> I’ve encountered a Microsoft ‘open source’ repository that actually completely depends on some proprietary platform-specific code blobs behind the scenes.</p><p>Incidentally, I stumbled across the <a href="https://microsoft.github.io/DirectX-Specs/d3d/ShaderCache.html">D3D12 Shader Cache API specification</a> which mentions the existence of this proprietary code signing blob as a ‘good reason for invoking the shader compiler at runtime’:</p><blockquote><p>D3D12 will only accept signed shaders. That means that if any patching or runtime optimizations are performed, such as constant folding, the shader must be re-validated and re-signed, which is non-trivial.</p></blockquote><p>And in the recent <a href="https://github.com/microsoft/DirectXShaderCompiler/releases/tag/v1.8.2306-preview">‘preview release’ for Shader Model 6.8 functionality</a>, Microsoft notes how they appear to leverage this DLL to restrict new experimental shader functionality:</p><blockquote><p>The DXIL signing library (dxil.dll/libdxil.so) is not provided with this preview release. DXIL generated with this compiler targeting Shader Model 6.8 is not final, cannot be validated, and is not supported for distribution or execution on machines not running in developer mode.</p></blockquote><p>In other words: if you do not have dxil.dll, then your shaders will not be signed/validated. If your shaders are not signed/validated, then they cannot run on a Windows machine unless it is running in Developer Mode.</p><h2 id="platform-support-challenges">Platform support challenges</h2><p>For a second, I’d like to go back to something I wrote at the start of this article:</p><blockquote><p>For <a href="https://machengine.org/">Mach engine</a> […] we need to compile shader programs into something that Direct3D 12 can consume.</p></blockquote><p>I’d like for us to be able to perform offline shader compilation, and skip out on distributing the heavy DXC dependency, when desired.</p><p>But Microsoft only distributes a copy of dxil.dll for Windows (x86/arm) and Linux (x86). There’s no Linux aarch64 binary. There’s no macOS binary. In other words, you can’t produce builds of your cross-platform game for Windows using offline shader compilation on a mac, or in your Arm Linux CI pipeline. You need a Windows or x86_64 Linux machine to run the proprietary blob.</p><h2 id="recap">Recap</h2><p>To recap:</p><ul><li>We cannot build DXC as a static library, because the decades-old Microsoft fork of LLVM v3.7 has a very messy build-system.</li><li>Even if we could, we cannot build DXC as a static library <strong>because of the proprietary code-signing blob</strong>.</li><li>We cannot compile DirectX HLSL shaders offline on a Mac, or build our cross-platform game in an arm Linux CI pipeline, because Microsoft doesn’t distribute copies of <strong>the proprietary code signing blob</strong> for those platforms.</li></ul><h2 id="going-deeper">Going deeper</h2><h3 id="un-the-build-system">Un#$@&amp;%*! the build system</h3><p>The first problem I wanted to address was how to actually build this codebase into a single static library.</p><p>After several days of attempting to fix the implicit dependencies that changing the cmake virtual libraries from <code>DYNAMIC</code> -&gt; <code>OBJECT</code> surfaces, I gave up. Originally, my intent was to use their existing cmake build system (so as to not diverge from their codebase too much) and just swap the compiler with <code>zig cc</code> as the build toolchain for cross-compilation.</p><p>After it slowly and painfully became apparent that direction was not going to be <em>any</em> better than maintaining the entire buildsystem myself, I decided to just bite the bullet and rewrite the entire CMake build system they had, some ~10.5k lines of code, using <code>build.zig</code> instead. To make things simpler, I chose to build only the two parts we (and others) really care about as consumers of the code: the <code>dxcompiler.dll</code> library, and <code>dxc.exe</code> binary for offline compilation / testing. (we’ll deal with <code>dxil.dll</code> later.)</p><p>This resulted in somewhere around <a href="https://github.com/hexops/mach-dxcompiler/blob/bd0cfbe4230133d8d3b50eedf1a0d0c4a00f47d7/build.zig#L1-L956">~1k lines of build.zig logic</a>, and in practice it’s less than that because much of it is just related to running <code>git clone</code> on the source repository, having the ability for Zig package consumers to use a prebuilt binary instead of building the large C++ library from source, and header/source generation (though we’re still not done with that, thanks to llvm-tablegen)</p><h3 id="un-the-dynamic-library-dependency">Un#$@&amp;%*! the dynamic library dependency</h3><p>As mentioned earlier, DXC is written with the expectation that <code>dxcompiler.dll</code> and <code>dxil.dll</code> exist. Reading the code, it almost appears as if the COM API implementation invokes the DLL, which then invokes itself dynamically depending on which is available.</p><p>Taking some advice from Microsoft, I got my hands dirty, <em>forked their codebase</em> and got to work on the actual C++ code. I began annotating my changes with cute <code>// Mach change start</code> and <code>// Mach change end</code> comments, to know who owns what code. All of this existing as a choice that I hope will come back to haunt my dreams in the future as much as Microsoft’s own choice to underemploy the HLSL team and fork LLVM 3.7 originally.</p><p>I was off to the races: <a href="https://github.com/hexops/DirectXShaderCompiler/blob/4190bb0c90d374c6b4d0b0f2c7b45b604eda24b6/tools/clang/tools/dxcompiler/DXCompiler.cpp#L88">simulating dllmain</a> entrypoints, <a href="https://github.com/hexops/DirectXShaderCompiler/blob/4190bb0c90d374c6b4d0b0f2c7b45b604eda24b6/tools/clang/tools/dxclib/dxc.cpp#L1258">disabling</a> the ability to print the compiler version info derived from the dlls, and <a href="https://github.com/hexops/DirectXShaderCompiler/blob/4190bb0c90d374c6b4d0b0f2c7b45b604eda24b6/include/dxc/Support/dxcapi.use.h#L17">emulating dynamic library function pointer loads</a>.</p><h3 id="un-the-proprietary-code-signing">Un#$@&amp;%*! the proprietary code signing</h3><p>All that was left was that pesky <code>dxil.dll</code> - what sort of magic might Microsoft be employing in that library to “sign shaders”? How can they prevent unsigned shaders from running on Windows machines that aren’t in developer mode? How are they able to distribute that binary on Linux, too?</p><p>I won’t comment on any of those questions, but will say that <a href="https://github.com/hexops/DirectXShaderCompiler/blob/4190bb0c90d374c6b4d0b0f2c7b45b604eda24b6/tools/clang/tools/dxcompiler/MachSiegbertVogtDXCSA.cpp#L178">you’ll find dxil.dll is NOT a dependency of mach-dxcompiler in any form</a>. You can compile an HLSL shader on a macOS machine using mach-dxcompiler, without the proprietary <code>dxil.dll</code> blob - and end up with a DXIL bytecode file that is byte-for-byte equal to one which runs it on a standard Windows box. Enjoy!</p><h2 id="results">Results</h2><p>We now have prebuilt, static binaries of the <code>dxcompiler</code> library, as well as the <code>dxc</code> CLI <a href="https://github.com/hexops/mach-dxcompiler/releases/tag/2024.02.10%2B2c3635c.1">here</a>, with zero dependency on the proprietary <code>dxil.dll</code>. At the time of writing, we have binaries building in our CI pipeline for:</p><ul><li>macOS (the first ever in history), both Apple Silicon (aarch64) and Intel (x86_64).</li><li>Linux, including musl and glibc, as well as aarch64 (first ever in history) and x86_64.</li><li>Windows, x86_64 and aarch64, including for MinGW/GNU ABI (first ever in history?)</li></ul><p>Additionally included is a <a href="https://github.com/hexops/mach-dxcompiler/blob/main/src/mach_dxc.h">small C API</a> the library now exposes, as an alternative to the COM API traditionally required.</p><p>Zig game developers will find the repository also includes a Zig API, see <a href="https://github.com/hexops/mach-dxcompiler/blob/main/src/main.zig"><code>src/main.zig</code></a> tests for usage. By default prebuilt binaries are downloaded/used.</p><p>You can <a href="https://github.com/hexops/mach-dxcompiler">build from source yourself</a> for any OS/arch with only <code>zig</code> and <code>git</code>, just make sure you have <a href="https://machengine.org/about/zig-version/">the right Zig version</a>:</p><pre><code>git clone https://github.com/hexops/mach-dxcompiler
cd mach-dxcompiler/
zig build -Dfrom_source -Dtarget=aarch64-macos
zig build -Dfrom_source -Dtarget=x86_64-windows-gnu
zig build -Dfrom_source -Dtarget=x86_64-linux-gnu
</code></pre><h2 id="caveats">Caveats</h2><p>It’s not all roses - there are some drawbacks:</p><ul><li>Windows MSVC ABI binaries are currently not building due to a small bug in the C bindings - will fix it quickly if important for you, otherwise at our own pace.</li><li>Linux musl binaries are untested, they build fine and I’d be curious to know if they run fine!</li><li>With Mach engine, we plan to use Zig itself as our shading language, not HLSL, so I do not build SPIRV-output support, sorry! I have no plans to add it.</li><li>No plans to update this to support SM6.7 currently (released very recently), though perhaps in the future.</li><li>LLVM’s cmake build system is not trivial, there are some aspects yet-to-be-translated. See <code>generated-include/</code> for specifics which come from the cmake build system still.</li><li>If you use this, you’ll be relying on myself to fix/address any issues. I am the only person working on this, and it exists solely to solve Mach’s own problems. If it works for you, great - but there may be a time we find a better path forward for us and it could get deprecated, so keep that in mind.</li></ul><h2 id="on-a-personal-note">On a personal note</h2><div><p><a href="https://github.com/slimsag"><img src="https://machengine.org/img/slimsag-profile.png"></a></p><div><p>My name is Stephen, I work a normal tech job, and after signing off from work at the end of the day I go online to build <a href="https://machengine.org/">Mach engine</a>. I've been dreaming of being able to build a game engine like this for a long time, and I'm finally doing it!</p><p>FOSS <a href="https://devlog.hexops.com/2021/increasing-my-contribution-to-zig-to-200-a-month#i-grew-up-playing-linux-games-like-mania-drive">is in my roots</a>, I believe we should own our tools, they should empower <em>us</em>-not be part of <a href="https://kristoff.it/blog/the-open-source-game/">the 'open source' game</a> which is all too prevelant today (even among 'open source' engines.) I <em>need</em> Mach to genuinely be <a href="https://softwareyoucan.love/">software you can love</a>.</p><p>My dream is one day to live a simple, modest, life earning a living building Mach for everyone and selling high-quality games. Please consider <a href="https://github.com/sponsors/slimsag">sponsoring my work</a> if you believe in my vision. It means the world to me!</p></div></div><h2 id="thanks-for-reading">Thanks for reading</h2><div><p><img src="https://user-images.githubusercontent.com/3173176/187348488-0b52e87d-3a48-421c-9402-be78e32b5a20.png"></p><ul><li>Check out <a href="https://machengine.org/">machengine.org</a></li><li>Consider <a href="https://github.com/sponsors/slimsag">sponsoring development</a> so we can do more of it!</li><li>Join the <a href="https://discord.gg/XNG3NZgCqp">Mach Discord server</a></li></ul></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ZX – A tool for writing better scripts (145 pts)]]></title>
            <link>https://github.com/google/zx</link>
            <guid>39323986</guid>
            <pubDate>Sat, 10 Feb 2024 06:01:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/google/zx">https://github.com/google/zx</a>, See on <a href="https://news.ycombinator.com/item?id=39323986">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><h2 tabindex="-1" dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/5f714c65dc258cb17ef40c5ac0a477ebf22dfcde8507c93ab8870219d500dcd0/68747470733a2f2f676f6f676c652e6769746875622e696f2f7a782f696d672f6c6f676f2e737667"><img src="https://camo.githubusercontent.com/5f714c65dc258cb17ef40c5ac0a477ebf22dfcde8507c93ab8870219d500dcd0/68747470733a2f2f676f6f676c652e6769746875622e696f2f7a782f696d672f6c6f676f2e737667" alt="Zx logo" height="32" data-canonical-src="https://google.github.io/zx/img/logo.svg"></a> zx</h2>
<div dir="auto" data-snippet-clipboard-copy-content="#!/usr/bin/env zx

await $`cat package.json | grep name`

let branch = await $`git branch --show-current`
await $`dep deploy --branch=${branch}`

await Promise.all([
  $`sleep 1; echo 1`,
  $`sleep 2; echo 2`,
  $`sleep 3; echo 3`,
])

let name = 'foo bar'
await $`mkdir /tmp/${name}`"><pre>#!/usr/bin/env zx

<span>await</span> <span>$</span><span>`cat package.json | grep name`</span>

<span>let</span> <span>branch</span> <span>=</span> <span>await</span> <span>$</span><span>`git branch --show-current`</span>
<span>await</span> <span>$</span><span>`dep deploy --branch=<span><span>${</span><span>branch</span><span>}</span></span>`</span>

<span>await</span> <span>Promise</span><span>.</span><span>all</span><span>(</span><span>[</span>
  <span>$</span><span>`sleep 1; echo 1`</span><span>,</span>
  <span>$</span><span>`sleep 2; echo 2`</span><span>,</span>
  <span>$</span><span>`sleep 3; echo 3`</span><span>,</span>
<span>]</span><span>)</span>

<span>let</span> <span>name</span> <span>=</span> <span>'foo bar'</span>
<span>await</span> <span>$</span><span>`mkdir /tmp/<span><span>${</span><span>name</span><span>}</span></span>`</span></pre></div>
<p dir="auto">Bash is great, but when it comes to writing more complex scripts,
many people prefer a more convenient programming language.
JavaScript is a perfect choice, but the Node.js standard library
requires additional hassle before using. The <code>zx</code> package provides
useful wrappers around <code>child_process</code>, escapes arguments and
gives sensible defaults.</p>
<h2 tabindex="-1" dir="auto">Install</h2>

<h2 tabindex="-1" dir="auto">Documentation</h2>
<p dir="auto">Read documentation on <a href="https://google.github.io/zx/" rel="nofollow">google.github.io/zx</a>.</p>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto"><a href="https://github.com/google/zx/blob/main/LICENSE">Apache-2.0</a></p>
<p dir="auto">Disclaimer: <em>This is not an officially supported Google product.</em></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[BirdLingo: A birdsong learning game (132 pts)]]></title>
            <link>https://jessicalieb.itch.io/birdlingo</link>
            <guid>39323893</guid>
            <pubDate>Sat, 10 Feb 2024 05:37:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jessicalieb.itch.io/birdlingo">https://jessicalieb.itch.io/birdlingo</a>, See on <a href="https://news.ycombinator.com/item?id=39323893">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="community_topic_posts_1071339"><div id="post-9340610" data-post="{&quot;id&quot;:9340610,&quot;user_id&quot;:1986376}"><a href="https://itch.io/profile/ironarachne"></a><div><p>This is awesome! I would pay for a more thorough version of this.</p></div></div><div id="post-9335184" data-post="{&quot;id&quot;:9335184,&quot;user_id&quot;:7197833}"><a href="https://itch.io/profile/smoothiefemale696"></a><div dir="auto"><p>hey i ranked your game and 19 others here:</p>

<p>ur ranking was ok. check out my spreadsheet linked below the video for some feedback. if you would like more coverage i am making another video for subscriber games only. so far i only have 1 subscriber who is a game dev so rankings would be a lot less competitive and i would spend longer on each game.</p></div></div><div id="post-9325027" data-post="{&quot;id&quot;:9325027,&quot;user_id&quot;:2113943}"><a href="https://itch.io/profile/tunegoro"></a><div dir="auto"><p>I had never been aware of the different types of birdsong, but with careful repetition over three levels, I was able to learn the birdsongs beautifully!</p>
<p>A very good learning software full of love for wild birds, meow!</p></div></div><div id="post-9326514" data-post="{&quot;id&quot;:9326514,&quot;user_id&quot;:9854420}"><a href="https://itch.io/profile/jessicalieb"></a><div><p>Wow, that's a great video!&nbsp;Thank you so much for testing my game, I'm glad you like it :)&nbsp;&nbsp;ありがとう！</p></div></div><div id="post-9294954" data-post="{&quot;id&quot;:9294954,&quot;user_id&quot;:4858078}"><a href="https://itch.io/profile/infinity-kitsune27"></a><div><p>This game is really cute :3 Also it's really educational as well so</p></div></div><div id="post-9293211" data-post="{&quot;id&quot;:9293211,&quot;user_id&quot;:9038779}"><a href="https://itch.io/profile/ryocotori"></a><div><p>I'm Japanese and my English isn't very good, but I was able to enjoy this.<br>I love birds, and whenever I hear a bird chirping, I always wonder what kind of bird it is.<br>The types of birds were a little different from those seen in Japan, but the birds that looked similar had similar voices.<br>I want to memorize all the bird calls.</p></div></div><div id="post-9297592" data-post="{&quot;id&quot;:9297592,&quot;user_id&quot;:9854420}"><a href="https://itch.io/profile/jessicalieb"></a><div><p>Thank you! Maybe one day I'll make a version with Japanese birds ;)</p></div></div><div id="post-9290120" data-post="{&quot;id&quot;:9290120,&quot;user_id&quot;:7197833}"><a href="https://itch.io/profile/smoothiefemale696"></a><div dir="auto"><p>hey i really like this a lot. really excellent educational software that plays like a game. im just curious cause i lived in france for 12 months is your first language english or french?? i got past level 1 and part way through level 2 of identifying bird songs.&nbsp;</p><p>also i make YT videos about itch games like this one:</p>

<p>do you want your game reviewed in my next video???</p></div></div><div><div id="post-9291803" data-post="{&quot;id&quot;:9291803,&quot;user_id&quot;:9854420}"><a href="https://itch.io/profile/jessicalieb"></a><div><p>Hi, thank you! My first language is French. It would be really cool to be featured in your video :)</p></div></div><div id="post-9304071" data-post="{&quot;id&quot;:9304071,&quot;user_id&quot;:7197833}"><a href="https://itch.io/profile/smoothiefemale696"></a><div><p>wonderful ill take some gameplay footage now</p></div></div></div><div id="post-9286807" data-post="{&quot;id&quot;:9286807,&quot;user_id&quot;:2595742}"><a href="https://itch.io/profile/queerdisagreeable"></a><div><p>this is exactly scratching the itch of wanting to birdwatch but being too dumb to remember the different calls. i love this. thank you.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Privacy focused platform Skiff is joining Notion, Skiff to be sunset (106 pts)]]></title>
            <link>https://www.notion.so/blog/meet-skiff-the-newest-member-of-the-notion-family</link>
            <guid>39322173</guid>
            <pubDate>Sat, 10 Feb 2024 00:22:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.notion.so/blog/meet-skiff-the-newest-member-of-the-notion-family">https://www.notion.so/blog/meet-skiff-the-newest-member-of-the-notion-family</a>, See on <a href="https://news.ycombinator.com/item?id=39322173">Hacker News</a></p>
Couldn't get https://www.notion.so/blog/meet-skiff-the-newest-member-of-the-notion-family: Error: Parse Error: Header overflow]]></description>
        </item>
        <item>
            <title><![CDATA[All my thoughts after 40 hours in the Vision Pro (109 pts)]]></title>
            <link>https://waitbutwhy.com/2024/02/vision-pro.html</link>
            <guid>39321395</guid>
            <pubDate>Fri, 09 Feb 2024 22:43:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://waitbutwhy.com/2024/02/vision-pro.html">https://waitbutwhy.com/2024/02/vision-pro.html</a>, See on <a href="https://news.ycombinator.com/item?id=39321395">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-10470">

		

		<div>
				
<p>
  I’m writing this on a 30-foot screen on top of a 10,000-foot mountain in Hawaii, at a table in an Austin coffee shop where I’m pretty sure other people are taking photos of me to send to their friends so they can all call me a piece of shit. In the last week, life has gotten weird.
</p>



<p>
  My journey to the Haleakalā shield volcano Austin coffee shop began more than 30 years ago, in 1990, when my parents brought me to something called a “virtual reality exhibit” at the Seaport World Trade Center in Boston. I stood on a little circular pedestal, and the guy handed me a plastic gun and put a big headset on me. Suddenly I was in some cartoon world, in a military uniform, holding a real gun. The person on the pedestal next to me was there, also a cartoon, also holding a gun. After some janky waving and shooting, they kicked me out for the next person in line. 
</p>



<p>
  I had recently read <em>The Phantom Tollbooth</em>, where a kid in the real world crosses a magic threshold and enters a cartoon world.<em> </em>This felt like that. I wanted more.
</p>



<p>
  Then VR disappeared for 25 years. Throughout the ‘90s and 2000s, “virtual reality” was a forgotten dream—a cool concept that never made it. But in the mid-2010s, VR made an unexpected comeback. 20-year-old Palmer Luckey’s duct-taped headset prototype had impressed enough investors for Oculus to become a real company. In 2014, Facebook bought Oculus. Google and Sony got involved. It was all finally happening.
</p>



<p>   In 2016, I decided to write about the VR revolution. I went around Silicon Valley, interviewing people at Google and Facebook to get the full scoop on VR. I even sat down with Mark Zuckerberg.</p>



<figure><a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Zuck.png"><img fetchpriority="high" decoding="async" width="1139" height="797" src="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Zuck.png" alt="" srcset="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Zuck.png 1139w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Zuck-600x420.png 600w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Zuck-750x525.png 750w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Zuck-768x537.png 768w " sizes="(max-width: 1139px) 100vw, 1139px"></a></figure>



<p>
  I demoed everything. It was mind-blowing. VR was about to take over the world. And I was gonna be the one to tell everyone.
</p>



<p>
  Then two things happened:
</p>



<ol>
<li>
  VR didn’t take over the world.
</li>



<li>   I didn’t write a VR post because I fell into a six-year <a href="https://waitbutwhy.com/whatsourproblem" target="_blank" rel="noreferrer noopener">book</a> hole instead. </li>
</ol>



<p>   From the bottom of my book hole, I kept following the story. At Facebook’s 2016 developer conference, Zuckerberg had demoed a new bleeding-edge kind of “standalone, inside out” headset. Up until then, there were two ways to do VR: The first was with a cheap headset, maybe using your phone as a screen, that could do primitive head-movement tracking but had no way to see the environment around you. The second was with external sensors on the walls and a headset that attached to a high-powered PC with a cord. “Standalone” meant the new headset would have the computer inside, with no need for a cable. “Inside out” meant the headset could see the room around you, so you didn’t need external sensors. In 2016, this was just a prototype. Three years later, Facebook launched Oculus Quest.  </p>



<p>   In 2020, standing around during Covid with my dick in my hand like everyone else, I got myself a Quest 2. It was amazing. I loved it. It was my daily post-writing reward activity. I made <a href="https://www.tiltbrush.com/" target="_blank" rel="noreferrer noopener">3D art</a>. I <a href="https://www.meta.com/experiences/2134272053250863/?ranking_trace=0_2134272053250863_SKYLINEWEBQUESTSEARCH_1vKvJ1edv2vQxMeJK" target="_blank" rel="noreferrer noopener">swam with whales</a>. I went on <a href="https://vacationsimulatorgame.com/" target="_blank" rel="noreferrer noopener">cartoon vacations</a>. I exercised by <a href="https://www.meta.com/experiences/2448060205267927/" target="_blank" rel="noreferrer noopener">slashing music</a>. I beat <a href="https://www.meta.com/experiences/2718107161580827/" target="_blank" rel="noreferrer noopener">Trover</a>. </p>



<p>   Then, for some reason, I stopped. I can’t really explain why. I really loved being in the Quest 2. I recently dusted it off to give friends a demo and they were floored, reminding me how great it is. It just didn’t <em>hook </em>me. Maybe it was the solo aspect. I don’t have friends who do VR so there’s no one else to play with. Maybe it’s the friction. It’s minor, but charging the headset, putting it on, and creating a boundary<a href="#footnote-1-10470" id="note-1-10470" rel="footnote">1</a> is still a lot more friction than picking up my phone. Maybe my delight relied more on novelty than I realized. </p>



<p>   It’s not just me. VR blows everyone away when they try it, but it seems to have a hard time hooking people for the long run. After a major wave of hype in the mid-2010s, VR receded into the land of subcultures. </p>



<p>
  And the question is: Is there some fatal flaw to the concept of VR that will always prevent it from achieving mass adoption? Or are we some tipping point away from VR exploding into the stratosphere like the computer and smartphone?
</p>



<h3><strong>Enter Apple</strong>
</h3>



<p>   Everyone remembers where they were when they learned that JFK was shot, a man had landed on the moon, or airplanes had flown into the Twin Towers. I remember where I was when I saw Steve Jobs <a href="https://www.youtube.com/watch?v=VQKMoT-6XSg&amp;ab_channel=ProtectstarInc." target="_blank" rel="noreferrer noopener">unveil the first iPhone</a>. </p>



<p>
  I didn’t always like Apple. My family’s first computer was an Apple 2GS. But then, like many early Apple computer users, I became a PC person. I used an IBM ThinkPad in college and thought Apple people were annoying.
</p>



<p>
  Then Steve Jobs came back to Apple and started Making Apple Great Again. My post-college music composing path forced me to get a 2004 PowerBook G4. After getting used to the interface (<em>why</em> <em>the fuck is there no start button?</em>), I realized that Macs were amazing, and I’ve been an annoying Apple person ever since. But it wasn’t until 2007 that I became a <em>fanboy.</em>
</p>



<p>   In the presentation, when Jobs did the world’s first “swipe to unlock,” the audience made an <a href="https://youtu.be/VQKMoT-6XSg?si=_ruGaoE1NWaLBrjC&amp;t=933" target="_blank" rel="noreferrer noopener">audible gasp</a>. A minute later, he brought up a list of artists in the phone’s “iPod” app and <a href="https://youtu.be/VQKMoT-6XSg?si=WXikR3ntj4j3EXd-&amp;t=972" target="_blank" rel="noreferrer noopener">asked</a>, “Well, how do I scroll through my list of artists? I just take my finger and scroll.” Another audible gasp. It’s weird that something so normal today was jaw-dropping 17 years ago. </p>



<p>   The feeling I had watching that presentation had happened before. I felt it when I was five years old and tried Nintendo for the first time at a friend’s house (<em>I can make something on the TV move by clicking this button??</em>). I felt it in the early ‘90s when my friend showed me how to send an email (<em>You can type something on your computer, hit a button, and it shows up on mine??)</em>.<em> </em>I felt it the first time I test-drove a Tesla (<em>Why is this car accelerating so futuristically?</em>).</p>



<p>
  I’ve learned to see a lot of meaning in these holy shit moments. In most cases, they’ve been followed by an entirely new industry sweeping the world—like the smartphone, video game, internet, and electric car revolutions.
</p>



<p>   In June 2023, Apple <a href="https://www.youtube.com/watch?v=GYkq9Rgoj8E" target="_blank" rel="noreferrer noopener">announced</a> the VR—sorry, <a href="https://www.techradar.com/computing/software/apple-tells-developers-not-to-use-virtual-reality-when-talking-about-vision-pro" target="_blank" rel="noreferrer noopener"><em>spatial computing</em></a><em>—</em>headset that had been long rumored: the Vision Pro.  </p>



<p>
  I watched the presentation, but it wasn’t quite like my experience in 2007. First, I had gotten excited about VR multiple times in the past and ended up disappointed. Second, unlike demoing an iPhone, watching a VR demo on a 2D screen just doesn’t show you what it’s actually like. Oh, also, it was <em>$3,500. </em>I happily shelled out $600 for the first iPhone. But $3,500? For a V1 product that will get way better (and cheaper) in the next few years? When I already have a Meta Quest? Nah. I might be a fanboy but I’m not a chump. It was the obvious grown-up decision to wait it out. Then I ordered one in the first minute after preorders started.
</p>



<p>
  This Monday morning, I went to the Apple Store to put the Vision Pro on my chump face for the first time. The staff member guided me through a demo. And there it was: the holy shit moment.
</p>



<p>
  But it was a holy shit moment with an asterisk. I had experienced full holy shit moments both in 1990 and in 2016 with VR, and these were the notable exceptions to the “holy shit moments are a surefire omen of an industry about to blow up” rule. Was this time different or would history repeat itself?
</p>



<p>
  What I did know was that it was finally time to write a VR post. I wanted to post this week while everyone was hyped up about the Vision Pro. But I didn’t want to write about it before I had used it a <em>lot</em>, so I could experience not only the honeymoon phase but also what it was like to get thoroughly sick of it.
</p>



<p>
  The plan was clear. I went home, told my wife that I would be deeply ignoring her and our baby for the week, and spent twelve hours a day in the headset for four straight days. I’m writing this on Thursday afternoon, having already logged over forty hours. Here are my thoughts.
</p>







<p>
  There are three elements of any VR system: hardware, operating system, and applications. Let’s talk about each.
</p>



<h3><strong>Hardware</strong></h3>



<figure><a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/headset.jpg"><img decoding="async" width="600" height="337" src="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/headset-600x337.jpg" alt="" srcset="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/headset-600x337.jpg 600w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/headset-750x422.jpg 750w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/headset-768x432.jpg 768w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/headset.jpg 980w " sizes="(max-width: 600px) 100vw, 600px"></a></figure>



<p>   Apple Vision Pro (AVP)<a href="#footnote2-1-10470" id="note2-1-10470" rel="footnote2">1</a> is heavy—a decent amount heavier (650 grams) than Meta’s Quest 3 (515 grams). It comes with a fancy band that goes on easily and you tighten with a little knob. It’s awesome. For 12 minutes. Then it started killing my face. With 3,500 regrets, I switched to the other band it comes with, which includes a loop that goes over the top of your head, and thank god for that because it was <em>way </em>better—so good that I am shocked to say that even at the end of a full day wearing it, I didn’t feel a euphoric “ahhh” relief taking it off. At least right now, it seems only a little more uncomfortable than wearing over-ear headphones for long periods of time. This might not apply to everyone, but I have not felt nauseous once while wearing it. </p>



<p>
  That doesn’t mean there’s nothing that sucks about wearing it. The “field of view” isn’t great, meaning there are thick black walls where your peripheral vision is supposed to be, which is a bummer. I can’t imagine it’s great for your eyes. And there’s no way around the fact that you feel like an asshole when other people are in the room. 
</p>



<p>
  There’s an external battery pack that connects to the headset with a cord and typically lives in my pocket. The battery lasts about three hours, but you can plug in the battery to make it last forever, like a computer if the battery only lasted for three hours. (You’re often using it in conjunction with your computer, which makes it a non-issue because you can plug the battery into the computer.)
</p>



<p>   When you put the headset on, it does the AVP version of Face ID: scanning your irises. This is seamless and very futuristic. Then, you see exactly what you saw before putting the headset on. <a href="https://www.youtube.com/watch?v=86Gy035z_KA&amp;ab_channel=MarquesBrownlee" target="_blank" rel="noreferrer noopener">Lots</a> <a href="https://www.youtube.com/watch?v=n7hJlyVDEc8&amp;ab_channel=CleoAbram" target="_blank" rel="noreferrer noopener">of</a> <a href="https://daringfireball.net/2024/01/the_vision_pro" target="_blank" rel="noreferrer noopener">reviewers</a> have marveled over AVP’s “pass-through” capabilities, and the second I put it on, I understood why. While it’s not perfect, it’s <em>almost </em>like you’re wearing a transparent snorkeling mask. The headset is in fact opaque—cameras on the outside transmit the world onto screens on the inside. But the screens are so good and the latency so low that it really seems transparent. Then there’s the much less successful attempt to make it look transparent from the outside as well, using cameras on the inside to broadcast your eyes onto the front of the headset. The goal is that if you’re talking to someone while wearing the headset, it feels to <em>both </em>people like you’re wearing a transparent snorkeling mask. But at least in V1, the eyes don’t show up nearly as well as <a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/applead-eyes.png">advertised</a>. </p>



<p>   The internal screens save energy by doing something clever called “foveated rendering”—i.e. only putting the exact place you’re looking in perfect focus while making the rest of the view lower-res. This is what your actual eyes do, which is why your peripheral vision is blurry. If you watch this <a href="https://x.com/waitbutwhy/status/1755000159698612346?s=20" target="_blank" rel="noreferrer noopener">viewcast</a> I made, you’ll see that most of it is blurry (the sharp part was where I happened to be looking while taking it)—but as the person in the headset, I only ever saw perfect sharpness. </p>



<p>   The way Vision Pro does audio is also cool. There have always been two sound options for me while on my phone or computer: play from the speaker and everyone can hear it or put on headphones and no one can hear it. AVP speakers are somewhere in between. The speakers (which sound great) are small and right above your ears, and while people right next to you can hear what you’re hearing, people in the next room cannot. So in a coffee shop or on an airplane, you still need headphones, but I do a lot of my work in an office in our house with the door open, and it’s been nice to work both without headphones <em>and </em>without bothering anyone in the other room. </p>



<h3><strong>Operating System</strong>
</h3>



<p>
  This was the biggest holy shit of my holy shit moment. Apple is the king of simple intuitive interfaces. Part of what drew those gasps in 2007 was how <em>natural </em>the iPhone’s interface was. You scrolled down by pushing the page up, just like you would in real life. You zoomed by pinching with two fingers. It seemed like magic. AVP’s interface is gaspworthy for the same reason. The main gesture is what I’ve been calling the “eye pinch.”
</p>



<p>   When you press the button at the top of the headset, your apps come up, floating in the room in front of you, looking as real as any other object in the room. They’re fixed in space. You can walk right up to them, and the detail is amazing.<a href="#footnote2-2-10470" id="note2-2-10470" rel="footnote2">2</a>



</p><figure><a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/appsinroom.png"><img decoding="async" width="835" height="511" src="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/appsinroom.png" alt="" srcset="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/appsinroom.png 835w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/appsinroom-600x367.png 600w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/appsinroom-750x459.png 750w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/appsinroom-768x470.png 768w " sizes="(max-width: 835px) 100vw, 835px"></a></figure>



<p>
  Vision Pro’s eye tracking is outrageously good. It knows <em>precisely </em>where you’re looking. So all you do to select an app is look at it and tap your thumb and index finger together. Your hand doesn’t need to move up to do this, just somewhere the headset can see it. Watching the demo, it seemed like this might be annoying to do, but it’s every bit as easy and intuitive as opening an app on a smartphone. 
</p>



<p>   No matter what you’re doing, the eye pinch is the equivalent of touching a finger to a smartphone screen. To scroll, look anywhere in the window, pinch, and move your hand up. To move a window, look at the little bar below the window, pinch, and move it where you want to. To resize the window, look at the window’s corner, pinch, and resize. </p>



<p>   As John Gruber put it in his <a href="https://daringfireball.net/2024/01/the_vision_pro" target="_blank" rel="noreferrer noopener">review</a>: </p>



<p><em>The fundamental interaction model in VisionOS feels like it will be copied by all future VR/AR headsets, in the same way that all desktop computers work like the Mac, and all phones and tablets now work like the iPhone. And when that happens, some will argue that of course they all work that way, because how else could they work? But personal computers didn’t have point-and-click GUIs before the Mac, and phones didn’t have “it’s all just a big touchscreen” interfaces before the iPhone. No other headset today has a “just look at a target, and tap your finger and thumb” interface today. I suspect in a few years they all will.</em>
</p>



<p>   Then there’s the fact that everything you see in front of you is available desktop to work with. On my computer, I’m used to my applications being stacked, and I toggle between them. Or maybe I put a few vertical windows side by side. In AVP, I can put one eight-foot window in front of me, two more on either side of it, and a couple more <em>above </em>them in the sky. Then, if I get up to go to the other room, the windows all stay exactly where they are, waiting for me to come back. If I want to switch work spots, I just hold the headset button and the whole configuration jumps to the new location. This is all way cooler than I’m making it sound, so I made a video to show you how it works:</p>



<figure><p>
<iframe loading="lazy" title="My Work Day in a Vision Pro" width="500" height="281" src="https://www.youtube.com/embed/F3CZD-K04KI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p></figure>



<p>   One thing you’ll notice in the video is that I routinely spin the digital crown on the headset to slide between being entirely in reality, partially in reality, and entirely in a virtual landscape. This is ridiculously fun to do. And it’s a general reminder that AR and VR<a href="#footnote-2-10470" id="note-2-10470" rel="footnote">2</a> being separate categories is a thing of the past. In the Vision Pro, the Quest 3, and any future headset, you can be 100% in the real world (when there’s nothing on the screen and it seems like you’re wearing a snorkeling mask), you can be mostly in the real world except there’s a virtual <a href="https://youtu.be/-dJu9VyIw64?si=CXyrl8KvUcYQ5uYZ&amp;t=449" target="_blank" rel="noreferrer noopener">game board</a> on your kitchen table or a little virtual butterfly fluttering around. You can be halfway between reality and virtual when, say, <a href="https://youtu.be/-dJu9VyIw64?si=N85diDS1-4EDe5-1&amp;t=476" target="_blank" rel="noreferrer noopener">portals open up</a> in the walls around you during a game. Or you can go full virtual. </p>



<h3><strong>Apps</strong>
</h3>



<p>
  There are many categories of spatial computing apps—productivity, entertainment, social, gaming, creative, fitness—and for most of them today, you’ll need a Meta Quest or some other non-Apple headset. There are a small handful of astounding<em> </em>apps for AVP, but they’re more a sampling of what’s possible than an actual app store.
</p>



<p>
  The most “you can absolutely not do this anywhere but a VR headset” thing I did was their little taster menu of immersive entertainment. Entertainment on a headset runs on a spectrum of immersion. The least immersive is watching a normal movie on a massive screen in a virtual space like the moon or a giant theater. Those movies you missed that everyone says are best seen on the big screen—you can see those on a big screen now. 
</p>



<p>
  Next are movies that are framed in a normal rectangle, but they’re 3D looking—like when we used to wear those stupid paper glasses but much, much better. Sometimes, these surprise you when something comes <em>out </em>of the screen to fly through the air or stand on the floor between you and the screen. The AVR comes with one of these—“Encounter Dinosaurs”—and it’s delightful. 
</p>



<p>
  Finally, there’s full immersion, where the scene entirely surrounds you and you actually feel like you’re there. These are better described as “experiences” than “entertainment.” I saw rhinos up close in person last year. Then, this week, I did one of the Vision Pro experiences that’s an up-close hang with rhinos. These two experiences were <em>very </em>similar. Another experience lets you sit in on an Alicia Keys rehearsal where she sings some songs standing two feet away from you. You can watch her for a while, then look over at what the drummer or keyboardist is doing for a while—just like you would if you were actually there.
</p>



<p>
  Photos and videos are also cool. When you take a panoramic photo, you sweep your phone around in a C-shaped arc—but on a flat phone screen, the result is a flat photo. In AVP, panos are C-shaped, like the photo you actually took. The C wraps around you, which I quickly learned brings the memory back way better than the flat version. You can also turn the headset into a camera and record photos and videos, both of which are immersive. When you later view them in the headset, they’re 3D, putting you right back into the actual scene.
</p>



<p>
  Then there’s the infamous Vision Pro avatars. You get one of these by flipping the headset around and letting it take pictures of you from different angles. Then when you FaceTime someone, your avatar mimics whatever facial expressions you’re making. Here’s mine:
</p>



<figure><img loading="lazy" decoding="async" width="636" height="586" src="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/timavatar.png" alt="" srcset="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/timavatar.png 636w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/timavatar-600x553.png 600w " sizes="(max-width: 636px) 100vw, 636px"></figure>



<p>
  The first person I tested it out on was my wife, who immediately gasped in horror, saying I had “little uncanny valley snake eyes rolling around in my skull,” whatever the fuck that means.
</p>



<p>   The uncanny valley she’s upset about is this:<a href="#footnote2-3-10470" id="note2-3-10470" rel="footnote2">3</a>



</p><figure><a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/uncannyvalley.png"><img loading="lazy" decoding="async" width="600" height="324" src="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/uncannyvalley-600x324.png" alt="" srcset="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/uncannyvalley-600x324.png 600w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/uncannyvalley-750x405.png 750w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/uncannyvalley-768x415.png 768w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/uncannyvalley-1536x830.png 1536w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/uncannyvalley-239x130.png 239w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/uncannyvalley.png 2001w " sizes="(max-width: 600px) 100vw, 600px"></a></figure>



<p>
  The idea is that we like faces that are somewhat humanlike, and we like faces that are totally humanlike, but we <em>hate </em>faces that are almost-but-not-totally humanlike. Faces that fall just short of being human give us the collective willies. 
</p>



<p>
  Avatars used to suck. Then they got better. Now they’ve gotten so good they’ve plunged into the uncanny valley. This was always gonna happen at some point on the road to perfect avatars and that time is now.
</p>



<p>   To test it out for myself, I FaceTimed my friend <a href="https://www.tiktok.com/@julesterpak" target="_blank" rel="noreferrer noopener">Jules Terpak</a>, who also has a Vision Pro. First I put her across from me at this table while we sat around with each other’s uncanny valley faces for a few minutes.</p>



<figure><a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Office.jpg"><img loading="lazy" decoding="async" width="2000" height="1082" src="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Office.jpg" alt="" srcset="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Office.jpg 2000w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Office-600x325.jpg 600w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Office-750x406.jpg 750w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Office-768x415.jpg 768w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Office-1536x831.jpg 1536w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Office-239x130.jpg 239w " sizes="(max-width: 2000px) 100vw, 2000px"></a></figure>



<p>
  One very cool thing is that when I moved her window to a different seat at the table, her voice shifted locations to that spot. We concluded that this activity was not actually an upgrade over FaceTime, but that if there were more than two people, it could feel like everyone was sitting around a table together, which would be better than talking to a group FaceTime or Zoom.
</p>



<p>
  Then we shifted locations to Mount Hood.
</p>



<figure><a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Mt-Hood.jpg"><img loading="lazy" decoding="async" width="2000" height="1082" src="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Mt-Hood.jpg" alt="" srcset="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Mt-Hood.jpg 2000w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Mt-Hood-600x325.jpg 600w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Mt-Hood-750x406.jpg 750w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Mt-Hood-768x415.jpg 768w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Mt-Hood-1536x831.jpg 1536w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-Mt-Hood-239x130.jpg 239w " sizes="(max-width: 2000px) 100vw, 2000px"></a></figure>



<p>
  This felt more like we were actually hanging out somewhere, which is an effect you can’t get on FaceTime. 
</p>



<p>
  When we started going into apps together, it felt even more like we were actually doing an activity together, in a way you normally can’t do without being in person. 
</p>



<figure><a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-apps.png"><img loading="lazy" decoding="async" width="2130" height="1592" src="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-apps.png" alt="" srcset="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-apps.png 2130w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-apps-600x448.png 600w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-apps-750x561.png 750w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-apps-768x574.png 768w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-apps-1536x1148.png 1536w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Jules-apps-2048x1531.png 2048w " sizes="(max-width: 2130px) 100vw, 2130px"></a></figure>



<p>   It’s very crude right now, but it’s a primitive version of something we’ll probably all be doing constantly in the 2030s. It’s the next step in a centuries-long human mission to conquer long-distance. First there were letters, then phone calls, then mobile phones<a href="#footnote-3-10470" id="note-3-10470" rel="footnote">3</a> and video calls. The next step is VR hangouts. </p>



<p>   By far the thing I spent the most time doing in the Vision Pro was exactly what I normally do, but the AVP version. When you’re sitting down in front of your computer while wearing the headset, you can open your computer screen as a giant virtual window (which you still control with your normal keyboard and trackpad). Whatever screen you’re used to working on is now much, much bigger. It’s also much more mobile. I don’t usually work on the couch because I prefer my big monitor over my laptop screen. This week, I spent a lot of time working on my couch on a 100-inch monitor. I don’t normally work lying flat in bed because the laptop screen isn’t directly above me. This week I did, putting the screen up on the ceiling. I did some work outside on the porch and some more under a tree. Sometimes I saw the room around me, only with a big screen floating in it. Other times, I went fully immersive, writing on a mountain top, a sand dune, or the moon. And as I mentioned at the beginning of the post, I’m <a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/timincafe-scaled.jpeg">currently</a> using the AVP in a coffee shop, which is officially <a href="https://x.com/waitbutwhy/status/1755672453999710482?s=20" target="_blank" rel="noreferrer noopener">embarrassing</a>. </p>



<p>
  For some odd reason, you can’t open multiple desktops (yet), but you <em>can </em>open some of the things on your desktop as their own apps in separate windows. There’s an AVP iMessage app, so I closed iMessage on my desktop and opened it in an adjacent window. I often remotely cowork with Alicia (WBW’s Manager of Lots of Things), putting her in a little window in the corner of my screen. Now, she’s in her own window. If I’m willing to bite the bullet and switch from Chrome to Safari, I can pull my research and web browsing off the desktop too. The end result is that a single small, immobile computer screen has been replaced with a giant mosaic of screens, for the small price of having a snorkeling mask on my face all day. It kind of feels like you stepped into your computer screen, into the beautiful wallpaper landscape, amongst the windows. Very surreal. I wrote this entire post in the headset and found myself enjoying writing more—and being more focused—than normal.
</p>



<h3><strong>My overall feelings</strong>
</h3>



<p>
  The best way I can describe how I feel about the Vision Pro is a strange combination of utterly thunderstruck and mildly underwhelmed. 
</p>



<p>
  The magical interface, the giant screens, the immersive experiences—they’re just unfathomably cool and awe-inspiring. It feels like a sneak peek at the 2030s.
</p>



<p>
  But after a couple of days, I found myself thinking, “Is that…it?” I had done the small handful of immersive experiences, played some of the small selection of games, looked at a bunch of my panoramic photos, and tried avatar FaceTime—and at the moment, there’s just not that much else to do in the Vision Pro.
</p>



<p>
  The first iPhone left me feeling the same combination of blown away and bored. The phone and I had a torrid honeymoon, but after the novelty of the interface wore off, all it had to offer was the same 16 practical apps.
</p>



<figure><a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/iphone-os1.jpeg"><img loading="lazy" decoding="async" width="259" height="384" src="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/iphone-os1.jpeg" alt=""></a></figure>



<p>
  There was no app store yet, it dropped calls constantly, and the cellular internet (which you couldn’t use while on a call) was painfully slow. The iPhone wasn’t a world-changing device yet. It was the seed from which a world-changing device would grow.
</p>



<p>
  If you zoom out on a story of technology, you usually see a big exponential curve.
</p>



<figure><a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-1.png"><img loading="lazy" decoding="async" width="1187" height="1124" src="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-1.png" alt="" srcset="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-1.png 1187w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-1-600x568.png 600w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-1-750x710.png 750w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-1-768x727.png 768w " sizes="(max-width: 1187px) 100vw, 1187px"></a></figure>



<p>
  But if you look at the curve up close, you see that it’s wavy, made of S-curves.
</p>



<figure><a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-2.png"><img loading="lazy" decoding="async" width="1249" height="1124" src="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-2.png" alt="" srcset="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-2.png 1249w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-2-600x540.png 600w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-2-750x675.png 750w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-2-768x691.png 768w " sizes="(max-width: 1249px) 100vw, 1249px"></a></figure>



<p>
  The first iPhone was such a big deal because it launched a new S. Investors had a new place to pour their money. Developers had a new place to pour their efforts. Creators had a new place to pour their talents. As millions of human hours worked on the collective human project, the next five years were a whirlwind of innovation and excitement. Apple’s keynotes became a must-watch for anyone interested in tech, as each jump between the iPhone 1 &gt; 3G &gt; 3GS &gt; 4 &gt; 4S &gt; 5 was a major leap in hardware and software. It was the steep part of the S.
</p>



<figure><a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-3.png"><img loading="lazy" decoding="async" width="1121" height="986" src="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-3.png" alt="" srcset="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-3.png 1121w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-3-600x528.png 600w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-3-750x660.png 750w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/S-Curves-3-768x676.png 768w " sizes="(max-width: 1121px) 100vw, 1121px"></a></figure>



<p>
  Then, the keynotes got boring. The changes were incremental. Apple stopped innovating and started refining. This coincided with Tim Cook taking over, but it isn’t his fault. The steep part of the S-curve doesn’t go on forever, and companies often reap the biggest rewards in the boring, top part of the S once the industry matures.
</p>



<p>
  Maybe the reason VR has been slow to take off isn’t because there’s something fundamentally wrong with VR. Maybe it’s because, for the last decade, we’ve been working our way through the very early part of the VR S-curve—the slow part where foundational technology is researched and built. My Vision Pro is highly imperfect—overpriced, heavy, slightly glitchy, very limited, creepy-avatared—because that’s exactly what products are like at the bottom of the S. Consumer products aren’t ready for mass adoption during this stage. But it’s the breakthroughs made during these years that set the stage for the explosive exponential phase of the curve.
</p>



<p>   The lesson from past VR hype cycles is to temper expectations. The VR S-Curve explosion may be many years away or never come at all. But the lesson from past Apple launches is don’t bet against Apple, and Apple’s bet is that the Vision Pro could be a seed like the first iPhone—a platform for innovation that kicks a new S-curve into high gear.<a href="#footnote-4-10470" id="note-4-10470" rel="footnote">4</a>  </p>



<h2><strong>Vision Pro, V2 – V10</strong>
</h2>



<p>
  For someone to regularly use a piece of technology, the benefits have to outweigh the costs. Right now, the Vision Pro benefits are probably less than the costs.
</p>


<div>
<figure><a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Scale.png"><img loading="lazy" decoding="async" width="1250" height="807" src="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Scale.png" alt="" srcset="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Scale.png 1250w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Scale-600x387.png 600w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Scale-750x484.png 750w , https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/Scale-768x496.png 768w " sizes="(max-width: 1250px) 100vw, 1250px"></a></figure></div>


<p>   I’ve already paid for mine, which removes one of the costs, and it’s <em>still </em>a question to what extent I’ll choose it over my computer in the long run. In that regard, the AVP might currently be more like those <a href="https://www.seeclearfield.com/assets/images/blogs/bag-phone.jpg">first cell phones</a> you had to carry around with a briefcase than the first iPhone. Would you get a cell phone if the only way they came was attached a briefcase? Maybe, but it’s a close call. </p>



<p>
  For VR to achieve mass adoption, the good needs to be better and the bad needs to be less bad. It’s easy to imagine a pathway to both.
</p>



<p>
  The operating system will get better each year. The two-finger pinch is currently the only gesture. More will be added. Eventually, there may be dozens of ways to make gestures with our fingers, each one a different command, like today’s keyboard shortcuts. When you spend ten minutes setting up an elaborate configuration of windows, you’ll be able to save (and share) it.
</p>



<p>
  Avatars will go from uncanny valley to indistinguishable from your normal face. When you go into immersive environments, you can currently see only your hands. In the future, you’ll be able to identify other objects to remain visible (like a coffee mug). The environments around you will expand from the six current options to hundreds, including delightful fantasy worlds, and they’ll be interactive, allowing you to change things like the weather.
</p>



<p>   The hardware will get continually smaller and more comfortable. The resolution and frame rate will become as advanced as the latency. The battery will get way better. So will the look from the outside: to people in the room, the headset will come to look totally transparent. (My personal fantasy: The computer itself becomes detachable, allowing the headset to be a light, sleek, cool-looking visor. The computer and battery snap together into something the size of a smartphone. You’ll be able to snap it to the back of your visor if you don’t want the cord, but most people will prefer the weight to be somewhere other than their heads. The computer/battery rectangle will also have a screen and function as a smartphone for times when you want to do something with the visor off. The visor will fold neatly onto the rectangle to make the whole thing a single compact object.)</p>



<p>
  Finally, the amount of content, applications, and experiences will multiply by 1,000-fold, just like the apps in the app store did from 2008 to today. There will be a wide array of immersive games and entertainment. People will watch sports from one of many vantage points on the field, sideline, stands, or overhead—next to their friends, who will be able to look at each other and talk as well as if they were actually together in person. Pop stars will play in front of 50,000 people in person and 5 million people virtually. Fitness will become fun, interactive, and social. The best teachers and coaches will reach millions of people. Amazing AI teachers could reach billions. Distance will melt away, allowing people to spend high-quality time with their loved ones, no matter where they are. People who couldn’t dream of traveling the world today will get to enjoy vivid experiences anywhere on the globe. Of course, my silly 2024 imagination can’t scratch the surface any more than people in the briefcase phone days could have predicted Uber, TikTok, or Tinder.
</p>



<p>
  Over time, the price will come down, with some companies making headsets dirt cheap the way they have for smartphones today. As the value proposition gets better and better, more people will have them, enhancing the social component and eradicating any stigma. Mass adoption seems like a very real future possibility.
</p>



<p>   I know what many of you are thinking: A world where everyone is in VR headsets (or visors, or glasses, or contact lenses) sounds<em> </em>dystopian and <a href="https://149909199.v2.pressablecdn.com/wp-content/uploads/2024/02/goldblum.jpg">awful</a>. And granted, this is coming from a guy who thought that world of glazed over people in moving chairs in Wall-E looked like a great place to live—but I’m excited.</p>



<p>
  K can I take this thing off my face now?
</p>



<p>_______</p>


<p><strong>What to read next:</strong></p>
<p><a href="https://waitbutwhy.com/2017/04/neuralink.html" target="_blank" rel="noopener">A post about a technology even more intense than VR</a></p>
<p><a href="https://waitbutwhy.com/2016/03/cryonics.html" target="_blank" rel="noopener">A post about a different technology that’s also even more intense than VR</a></p>
<p><a href="https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html" target="_blank" rel="noopener">A post about a third technology that’s even more intense than VR</a></p>


<p>_______</p>







<p>If you like Wait But Why, sign up for our <strong><a data-formkit-toggle="047cbbd566" href="https://newsletter.waitbutwhy.com/join">email list</a></strong> and we’ll send you new posts when they come out.</p>



<p>To support Wait But Why, visit our <strong><a data-type="URL" data-id="https://patreon.com/waitbutwhy" href="https://patreon.com/waitbutwhy" target="_blank" rel="noreferrer noopener">Patreon page</a></strong>.</p>
<!--/#footnotes--><!--/#footnotes2-->				
				
				
			<!-- /entry-content-wrap -->

			
	</div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reddit beats film industry again, won't have to reveal pirates' IP addresses (246 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/02/reddit-beats-film-industry-again-wont-have-to-reveal-pirates-ip-addresses/</link>
            <guid>39319202</guid>
            <pubDate>Fri, 09 Feb 2024 19:22:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/02/reddit-beats-film-industry-again-wont-have-to-reveal-pirates-ip-addresses/">https://arstechnica.com/tech-policy/2024/02/reddit-beats-film-industry-again-wont-have-to-reveal-pirates-ip-addresses/</a>, See on <a href="https://news.ycombinator.com/item?id=39319202">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/03/getty-reddit-800x533.jpg" alt="The Reddit logo displayed on a smartphone; a laptop is seen in the photo's background.">
      <figcaption><p>Getty Images | NurPhoto </p></figcaption>  </figure>

  




<!-- cache hit 243:single/related:6f87e8dcc5c8a7f7a38e15aa14a895dd --><!-- empty -->
<p>Movie companies have lost a third attempt to unmask Reddit users who posted comments discussing piracy. In an <a href="https://storage.courtlistener.com/recap/gov.uscourts.cand.423189/gov.uscourts.cand.423189.26.0.pdf">order</a> on Wednesday, the US District Court for the Northern District of California rejected movie copyright holders' demand for seven years' worth of "IP address log information" on six Reddit users.</p>
<p>In a <a href="https://storage.courtlistener.com/recap/gov.uscourts.cand.423189/gov.uscourts.cand.423189.1.0.pdf">motion to compel</a> that was <a href="https://arstechnica.com/tech-policy/2024/01/film-studios-demand-ip-addresses-of-people-who-discussed-piracy-on-reddit/">filed last month</a>, movie companies Voltage Holdings and Screen Media Ventures argued that "Reddit users do not have a recognized privacy interest in their IP addresses." But in Wednesday's ruling, US Magistrate Judge Thomas Hixson said, "The Court finds no reason to believe provision of an IP address is not unmasking subject to First Amendment scrutiny."</p>
<p>Voltage Holdings and Screen Media Ventures previously sued the Internet service provider Frontier Communications, alleging that it is liable for its users' copyright infringement. Seeking evidence for that case, the movie companies subpoenaed Reddit in an attempt to prove that Frontier has no meaningful policy for terminating repeat copyright infringers and that this lack of enforcement drew customers to Frontier's service.</p>
<p>"Reddit argues the Court should deny the motion because it is an unmasking subpoena, targeting a potential witness rather than a potential defendant, and is therefore subjected to First Amendment scrutiny," Hixson's order noted. Reddit also argued that the evidence sought by movie companies can be obtained instead from Frontier and from Frontier subscribers.</p>
<p>Hixson's order, which was <a href="https://torrentfreak.com/reddit-doesnt-have-to-share-ip-addresses-of-piracy-commenters-court-rules-240208/">previously reported</a> by Torrent Freak, said that courts use a "higher standard for unmasking a non-party witness" than for potential defendants because "litigation can often continue without interfering with a non-party witness's First Amendment right to anonymity."</p>                                            
                                                        
<h2>Reddit can protect First Amendment rights of users</h2>
<p>The ruling is <a href="https://arstechnica.com/tech-policy/2023/05/judge-wont-force-reddit-to-identify-anonymous-users-who-discussed-piracy/">similar to previous</a> ones in which the <a href="https://arstechnica.com/tech-policy/2023/08/reddit-beats-film-industry-wont-have-to-identify-users-who-admitted-torrenting/">same court denied</a> movie-industry attempts to unmask Reddit users. The fact that movie companies only sought IP addresses instead of names this time around wasn't enough to sway the court.</p>
<p>The previous cases are being called <em>Reddit I</em> and <em>Reddit II</em>. Voltage Holdings was one of the copyright holders involved in <em>Reddit I</em>, while both Voltage Holdings and Screen Media Ventures were involved in <em>Reddit II</em>.</p>
<p>Hixson referred to the prior cases in this week's ruling, saying the third is similar in part because the "court adjudicating the copyright litigation has already ruled [the movie companies] can obtain identifying information from Frontier for IP addresses known to have pirated using Frontier's network." As in the previous cases, the movie companies "cannot show that the information they seek here is unavailable from other sources," Hixson wrote.</p>
<p>Voltage Holdings and Screen Media Ventures cited Reddit posts in which users say that Frontier didn't terminate their Internet service despite sending many copyright infringement notices about torrent downloads. One of the users wrote, "I got a total of 44 emails from frontier about downloading torrents and that it could terminate service. They haven't yet. And I kinda feel like if they didn't do it after 44 emails. That they won't… ."</p>
<p>The movie companies argued that getting these Reddit users' IP addresses is relevant and proportional to the needs of the case because the comments support the allegation "that the ability to pirate content efficiently without any consequences is a draw for becoming a Frontier subscriber... and that Frontier does not have an effective policy for terminating repeat infringers."</p>
<p>But Reddit has the right to refuse to provide that information, Hixson decided. "The Ninth Circuit has recognized that Internet platforms can assert the First Amendment rights of their users, based on the close relationship between the platform and its users and the 'genuine obstacles' users face in asserting their rights to anonymity," Hixson wrote.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla places Microsoft under fire for using deceptive tricks in Edge (123 pts)]]></title>
            <link>https://www.windowscentral.com/software-apps/browsing/hi-microsoft-please-stop-using-harmful-designs-and-deceptive-tactics-to-give-edge-the-competitive-advantage-over-other-browsers-on-windows-says-mozilla</link>
            <guid>39318891</guid>
            <pubDate>Fri, 09 Feb 2024 19:02:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.windowscentral.com/software-apps/browsing/hi-microsoft-please-stop-using-harmful-designs-and-deceptive-tactics-to-give-edge-the-competitive-advantage-over-other-browsers-on-windows-says-mozilla">https://www.windowscentral.com/software-apps/browsing/hi-microsoft-please-stop-using-harmful-designs-and-deceptive-tactics-to-give-edge-the-competitive-advantage-over-other-browsers-on-windows-says-mozilla</a>, See on <a href="https://news.ycombinator.com/item?id=39318891">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-widget-type="contentparsed" id="content">
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" alt="Mozilla Firefox on Windows" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4.jpg"><source type="image/jpeg" alt="Mozilla Firefox on Windows" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4.jpg"><img src="https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-320-80.jpg" alt="Mozilla Firefox on Windows" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/UurQNHnDrjVab5pnJhVwL4.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Future)</span>
</figcaption>
</div>

<div id="article-body">
<h2 id="what-you-need-to-know-3">What you need to know</h2><ul><li>New research commissioned by Mozilla reveals the Microsoft uses harmful designs and deceptive tactics to push its Edge browser to Windows users.</li><li>The report details that the tech giant uses misleading UIs and ads, and more to prevent users from using other browsers aside from Microsoft Edge as default on Windows.</li><li>Mozilla points out that this places other browsers like Google Chrome and Firefox at a disadvantage, and calls on regulators to look into the matter.</li></ul><hr><p>Even in 2024, browser wars continue to be a thing. Users have varied interests and wants regarding the browser they use on their devices. <a data-analytics-id="inline-link" href="https://www.windowscentral.com/tag/google-chrome" data-before-rewrite-localise="https://www.windowscentral.com/tag/google-chrome">Google Chrome</a> and <a data-analytics-id="inline-link" href="https://www.windowscentral.com/tag/microsoft-edge" data-before-rewrite-localise="https://www.windowscentral.com/tag/microsoft-edge">Microsoft Edge</a> are arguably the most popular browsers among users, but is it by choice or design?</p><p>The folks at Mozilla have openly indicated that it's the latter, further throwing blame at Microsoft. The company pointed out that users <a data-analytics-id="inline-link" href="https://go.redirectingat.com/?id=23432X820454&amp;xcust=wp_us_2090802574326933000&amp;xs=1&amp;url=https%3A%2F%2Fresearch.mozilla.org%2Fbrowser-competition%2Fover-the-edge-the-use-of-design-tactics-to-undermine-browser-choice%2F&amp;sref=https%3A%2F%2Fwww.windowscentral.com%2Fsoftware-apps%2Fbrowsing%2Fhi-microsoft-please-stop-using-harmful-designs-and-deceptive-tactics-to-give-edge-the-competitive-advantage-over-other-browsers-on-windows-says-mozilla" data-url="https://research.mozilla.org/browser-competition/over-the-edge-the-use-of-design-tactics-to-undermine-browser-choice/" target="_blank" data-hl-processed="skimlinks" data-placeholder-url="https://go.redirectingat.com/?id=23432X820454&amp;xcust=hawk-custom-tracking&amp;xs=1&amp;url=https%3A%2F%2Fresearch.mozilla.org%2Fbrowser-competition%2Fover-the-edge-the-use-of-design-tactics-to-undermine-browser-choice%2F&amp;sref=https%3A%2F%2Fwww.windowscentral.com%2Fsoftware-apps%2Fbrowsing%2Fhi-microsoft-please-stop-using-harmful-designs-and-deceptive-tactics-to-give-edge-the-competitive-advantage-over-other-browsers-on-windows-says-mozilla" rel="sponsored noopener" referrerpolicy="no-referrer-when-downgrade" data-google-interstitial="false" data-merchant-name="SkimLinks - mozilla.org" data-merchant-id="undefined" data-merchant-url="undefined" data-merchant-network="undefined">don't have free will to use any browser as their default on Windows devices</a>.&nbsp;</p><p>Mozilla tasked Harry Brignull and Cennydd Bowles, alongside researchers and experts, to investigate the matter. As it turns out, Microsoft might be playing a foul game by preventing freedom of choice when selecting default browsers on Windows (<a data-analytics-id="inline-link" href="https://www.techradar.com/computing/browsers/mozilla-blows-the-whistle-on-microsoft-over-the-edge-report-accuses-windows-11-maker-of-browser-bias-and-deceptive-tactics" data-url="https://www.techradar.com/computing/browsers/mozilla-blows-the-whistle-on-microsoft-over-the-edge-report-accuses-windows-11-maker-of-browser-bias-and-deceptive-tactics">via TechRadar</a>).&nbsp;</p><p>In the report "<a data-analytics-id="inline-link" href="https://go.redirectingat.com/?id=23432X820454&amp;xcust=wp_us_1295279187713164300&amp;xs=1&amp;url=https%3A%2F%2Fresearch.mozilla.org%2Ffiles%2F2024%2F01%2FOver-the-Edge-Report-January-2024.pdf&amp;sref=https%3A%2F%2Fwww.windowscentral.com%2Fsoftware-apps%2Fbrowsing%2Fhi-microsoft-please-stop-using-harmful-designs-and-deceptive-tactics-to-give-edge-the-competitive-advantage-over-other-browsers-on-windows-says-mozilla" data-url="https://research.mozilla.org/files/2024/01/Over-the-Edge-Report-January-2024.pdf" target="_blank" data-hl-processed="skimlinks" data-placeholder-url="https://go.redirectingat.com/?id=23432X820454&amp;xcust=hawk-custom-tracking&amp;xs=1&amp;url=https%3A%2F%2Fresearch.mozilla.org%2Ffiles%2F2024%2F01%2FOver-the-Edge-Report-January-2024.pdf&amp;sref=https%3A%2F%2Fwww.windowscentral.com%2Fsoftware-apps%2Fbrowsing%2Fhi-microsoft-please-stop-using-harmful-designs-and-deceptive-tactics-to-give-edge-the-competitive-advantage-over-other-browsers-on-windows-says-mozilla" rel="sponsored noopener" referrerpolicy="no-referrer-when-downgrade" data-google-interstitial="false" data-merchant-name="SkimLinks - mozilla.org" data-merchant-id="undefined" data-merchant-url="undefined" data-merchant-network="undefined">Over the Edge: The Use of Design Tactics to Undermine Browser Choice</a>," the researchers point out how Microsoft has placed its Edge browser on a pedestal across its operating system, leaving its competitors at a disadvantage.&nbsp;</p><p>The report also outlines the deceptive ploys the tech giant leverages to affirm its position in the race for browser dominance, including misleading UIs and ads, alarming notifications that are worded and presented as system warnings, and more.</p><p>Microsoft, Google, and Apple were <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/microsoft-added-to-eu-gatekeeper-list-but-bing-and-edge-are-under-investigation" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/microsoft-added-to-eu-gatekeeper-list-but-bing-and-edge-are-under-investigation">some companies listed as gatekeepers by the EU Commission</a> last year. Microsoft made the list because of its Windows OS and LinkedIn, and Google for its Chrome browser and search engine. The Commission gave the gatekeepers six months to comply with the DMA; failure would attract hefty fines and penalties. One of the requirements under the DMA tasks the companies listed to make their services interoperable.</p><p>Interestingly, Microsoft's Bing was initially listed as a gatekeeper service, but the company argued that <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/bing/microsoft-argues-bing-isnt-big-enough-to-make-eus-gatekeeper-list-says-report" data-before-rewrite-localise="https://www.windowscentral.com/software-apps/bing/microsoft-argues-bing-isnt-big-enough-to-make-eus-gatekeeper-list-says-report">the search engine hadn't hit the threshold to fall under this category</a>. The Commission investigated the matter and recently concluded that <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/microsoft-edge-and-bing-might-get-a-free-pass-from-europes-dma-since-they-arent-dominant-enough-in-digital-markets" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/microsoft-edge-and-bing-might-get-a-free-pass-from-europes-dma-since-they-arent-dominant-enough-in-digital-markets">Bing and Edge aren't dominant enough in digital markets</a>, exempting them from DMA regulation.&nbsp;</p><p>Mozilla hoped that the DMA regulation on Microsoft Edge would give Firefox some breathing space and the opportunity to compete on an even playing field. But as it happens, that ship has seemingly sailed off with its competitive advantage. Microsoft's CEO, Satya Nadella, shares the same sentiments regarding search, adding that <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/bing/google-doesnt-play-fair-with-bing-says-microsoft-ceo-satya-nadella" data-before-rewrite-localise="https://www.windowscentral.com/software-apps/bing/google-doesnt-play-fair-with-bing-says-microsoft-ceo-satya-nadella">Google doesn't play fair with Bing</a>.&nbsp;</p><h2 id="it-apos-s-the-same-script-for-microsoft-just-a-different-play-3">It's the same script for Microsoft, just a different play</h2><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" alt="Microsoft Edge Sidebar on Windows 11 desktop" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" data-normal="https://vanilla.futurecdn.net/windowscentral/media/img/missing-image.svg" data-srcset="https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-1200-80.jpg.webp 1200w" data-sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a.jpg"><source type="image/jpeg" alt="Microsoft Edge Sidebar on Windows 11 desktop" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" data-normal="https://vanilla.futurecdn.net/windowscentral/media/img/missing-image.svg" data-srcset="https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-1200-80.jpg 1200w" data-sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a.jpg"><img src="https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a.jpg" alt="Microsoft Edge Sidebar on Windows 11 desktop" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" data-normal="https://vanilla.futurecdn.net/windowscentral/media/img/missing-image.svg" data-srcset="https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-1200-80.jpg 1200w" data-sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a.jpg" srcset="https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/DwKe9KSfzHNnJi7mcpMD4a-1200-80.jpg 1200w"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Future)</span></figcaption></figure><p>This isn't the first time we've learned about Microsoft pushing its browser and search engine down users' throats. Late last year, some users trying to download Google Chrome while using Microsoft Edge were slapped with a survey asking them to detail <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/browsing/edge-begs-for-answers-microsoft-polling-users-who-download-chrome" data-before-rewrite-localise="https://www.windowscentral.com/software-apps/browsing/edge-begs-for-answers-microsoft-polling-users-who-download-chrome">why they wanted to try another browser</a>.</p><p>How can we forget when Microsoft deliberately placed ads on Google Chrome's download page, perhaps to prevent users from transitioning? The fact that Windows 11 and 10 come with Microsoft Edge preinstalled doesn't improve the situation.</p><p>Mozilla further makes its case in the <a data-analytics-id="inline-link" href="https://go.redirectingat.com/?id=23432X820454&amp;xcust=wp_us_1401121120720174600&amp;xs=1&amp;url=https%3A%2F%2Fresearch.mozilla.org%2Ffiles%2F2024%2F01%2FOver-the-Edge-Report-January-2024.pdf&amp;sref=https%3A%2F%2Fwww.windowscentral.com%2Fsoftware-apps%2Fbrowsing%2Fhi-microsoft-please-stop-using-harmful-designs-and-deceptive-tactics-to-give-edge-the-competitive-advantage-over-other-browsers-on-windows-says-mozilla" data-url="https://research.mozilla.org/files/2024/01/Over-the-Edge-Report-January-2024.pdf" target="_blank" data-hl-processed="skimlinks" data-placeholder-url="https://go.redirectingat.com/?id=23432X820454&amp;xcust=hawk-custom-tracking&amp;xs=1&amp;url=https%3A%2F%2Fresearch.mozilla.org%2Ffiles%2F2024%2F01%2FOver-the-Edge-Report-January-2024.pdf&amp;sref=https%3A%2F%2Fwww.windowscentral.com%2Fsoftware-apps%2Fbrowsing%2Fhi-microsoft-please-stop-using-harmful-designs-and-deceptive-tactics-to-give-edge-the-competitive-advantage-over-other-browsers-on-windows-says-mozilla" rel="sponsored noopener" referrerpolicy="no-referrer-when-downgrade" data-google-interstitial="false" data-merchant-name="SkimLinks - mozilla.org" data-merchant-id="undefined" data-merchant-url="undefined" data-merchant-network="undefined">in-depth report</a> and pleads with regulators to look into the matter to promote healthy competition.</p>
</div>
<div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-zeTUihjaWkqNFfWW59uBBh"><section><p>All the latest news, reviews, and guides for Windows and Xbox diehards.</p></section></div>
<div id="slice-container-authorBio-zeTUihjaWkqNFfWW59uBBh"><p>Kevin Okemwa is a seasoned tech journalist based in Nairobi, Kenya with lots of experience covering the latest trends and developments in the industry. With a passion for innovation and a keen eye for detail, he has written for leading publications such as OnMSFT, MakeUseOf, and Windows Report, providing insightful analysis and breaking news on everything revolving around the Microsoft ecosystem. While AFK and not busy following the ever-emerging trends in tech, you can find him exploring the world or listening to music.</p></div>



</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I write HTTP services in Go after 13 years (686 pts)]]></title>
            <link>https://grafana.com/blog/2024/02/09/how-i-write-http-services-in-go-after-13-years/</link>
            <guid>39318867</guid>
            <pubDate>Fri, 09 Feb 2024 19:00:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grafana.com/blog/2024/02/09/how-i-write-http-services-in-go-after-13-years/">https://grafana.com/blog/2024/02/09/how-i-write-http-services-in-go-after-13-years/</a>, See on <a href="https://news.ycombinator.com/item?id=39318867">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Nearly six years ago I wrote a blog post outlining <a href="https://pace.dev/blog/2018/05/09/how-I-write-http-services-after-eight-years.html" target="_blank" rel="noopener noreferrer">how I write HTTP services in Go</a>, and I’m here to tell you, once again, how I write HTTP services.</p><p>That original post went a little viral and sparked some great discussions that have influenced how I do things today. And after years of hosting the <a href="https://changelog.com/gotime" target="_blank" rel="noopener noreferrer">Go Time podcast</a>, discussing Go on <a href="https://twitter.com/matryer" target="_blank" rel="noopener noreferrer">X/Twitter</a>, and gaining more experience maintaining code like this over years, I thought it was time for a refresh.</p><p>(And for those pedants who notice Go isn’t exactly 13 years old, I started writing HTTP services in Go <a href="https://go.dev/doc/devel/pre_go1#r59" target="_blank" rel="noopener noreferrer">version .r59</a>.)</p><p>This post covers a range of topics related to building services in Go, including:</p><ul><li>Structuring servers and handlers for maximum maintainability&nbsp;</li><li>Tips and tricks for optimizing for a quick startup and graceful shutdown&nbsp;</li><li>How to handle common work that applies to many types of requests</li><li>Going deep on properly testing your services&nbsp;</li></ul><p>From small projects to large, these practices have stood the test of time for me, and I hope they will for you too.</p><h2 id="who-is-this-post-for">Who is this post for?</h2><p>This post is for you. It’s for everybody who plans to write some kind of HTTP service in Go. You may also find this useful if you’re learning Go, as lots of the examples follow good practices. Experienced gophers might also pick up some nice patterns.</p><p>To find this post most useful, you’ll need to know the basics of Go. If you don’t feel like you’re quite there yet, I cannot recommend <a href="https://quii.gitbook.io/learn-go-with-tests/" target="_blank" rel="noopener noreferrer">Learn Go with tests</a> by Chris James enough. And if you’d like to hear more from Chris, you can check out the episode of Go Time we did with Ben Johnson on <a href="https://changelog.com/gotime/278" target="_blank" rel="noopener noreferrer">The files and folders of Go projects</a>.</p><p>If you’re familiar with the previous versions of this post, this section contains a quick summary of what’s different now. If you’d like to start from the beginning, skip to the next section.</p><ol><li>My handlers used to be methods hanging off a server struct, but I no longer do this. If a handler function wants a dependency, it can bloody well ask for it as an argument. No more surprise dependencies when you’re just trying to test a single handler.</li><li>I used to prefer <code>http.HandlerFunc</code> over <code>http.Handler</code> — enough third-party libraries think about <code>http.Handler</code> first that it makes sense to embrace that. <code>http.HandlerFunc</code> is still extremely useful, but now most things are represented as the interface type. It doesn’t make much difference either way.</li><li>I’ve added more about testing including some Opinions™.</li><li>I’ve added more sections, so a full read through is recommended for everybody.</li></ol><h2 id="the-newserver-constructor">The <code>NewServer</code> constructor</h2><p>Let’s start by looking at the backbone of any Go service: the server. The&nbsp; <code>NewServer</code> function makes the main <code>http.Handler</code>. Usually I have one per service, and I rely on HTTP routes to divert traffic to the right handlers within each service because:</p><ul><li><code>NewServer</code> is a big constructor that takes in all dependencies as arguments</li><li>It returns an <code>http.Handler</code> if possible, which can be a dedicated type for more complex situations</li><li>It usually configures its own muxer and calls out to <code>routes.go</code></li></ul><p>For example, your code might look similar to this:</p><div><pre data-expanded="false"><code>func NewServer(
	logger *Logger
	config *Config
	commentStore *commentStore
	anotherStore *anotherStore
) http.Handler {
	mux := http.NewServeMux()
	addRoutes(
		mux,
		Logger,
		Config,
		commentStore,
		anotherStore,
	)
	var handler http.Handler = mux
	handler = someMiddleware(handler)
	handler = someMiddleware2(handler)
	handler = someMiddleware3(handler)
	return handler
}</code></pre></div><p>In test cases that don’t need all of the dependencies, I pass in <code>nil</code> as a signal that it won’t be used.</p><p>The <code>NewServer</code> constructor is responsible for all the top-level HTTP stuff that applies to all endpoints, like CORS, auth middleware, and logging:</p><div><pre data-expanded="false"><code>var handler http.Handler = mux
handler = logging.NewLoggingMiddleware(logger, handler)
handler = logging.NewGoogleTraceIDMiddleware(logger, handler)
handler = checkAuthHeaders(handler)
return handler</code></pre></div><p>Setting up the server is usually a case of exposing it using Go’s built-in <code>http</code> package:</p><div><pre data-expanded="false"><code>srv := NewServer(
	logger,
	config,
	tenantsStore,
	slackLinkStore,
	msteamsLinkStore,
	proxy,
)
httpServer := &amp;http.Server{
	Addr:    net.JoinHostPort(config.Host, config.Port),
	Handler: srv,
}
go func() {
	log.Printf("listening on %s\n", httpServer.Addr)
	if err := httpServer.ListenAndServe(); err != nil &amp;&amp; err != http.ErrServerClosed {
		fmt.Fprintf(os.Stderr, "error listening and serving: %s\n", err)
	}
}()
var wg sync.WaitGroup
wg.Add(1)
go func() {
	defer wg.Done()
	&lt;-ctx.Done()
	if err := httpServer.Shutdown(ctx); err != nil {
		fmt.Fprintf(os.Stderr, "error shutting down http server: %s\n", err)
	}
}()
wg.Wait()
return nil</code></pre></div><h3 id="long-argument-lists">Long argument lists</h3><p>There must be a limit at which point it stops being the right thing to do, but most of the time I am happy adding lists of dependencies as arguments. And while they do sometimes get quite long, I find it’s still worth it.</p><p>Yes, it saves me from making a struct, but the real benefit is that I get slightly more type safety from arguments. I can make a struct skipping any fields that I don’t like, but a function forces my hand. I have to look up fields to know how to set them in a struct, whereas I can’t call a function if I don’t pass the right arguments.</p><p>It’s not so bad if you format it as a vertical list, like I’ve seen in modern frontend code:</p><div><pre data-expanded="false"><code>srv := NewServer(
	logger,
	config,
	tenantsStore,
	commentsStore,
	conversationService,
	chatGPTService,
)</code></pre></div><h2 id="map-the-entire-api-surface-in-routesgo">Map the entire API surface in <code>routes.go</code></h2><p>This file is the one place in your service where all routes are listed.</p><p>Sometimes you can’t help but have things spread around a bit, but it’s very helpful to be able to go to one file in every project to see its API surface.</p><p>Because of the big dependency argument lists in the <code>NewServer</code> constructor, you usually end up with the same list in your routes function. But again, it’s not so bad. And again, you soon know if you forgot something or got the order wrong thanks to Go’s type checking.</p><div><pre data-expanded="false"><code>func addRoutes(
	mux                 *http.ServeMux,
	logger              *logging.Logger,
	config              Config,
	tenantsStore        *TenantsStore,
	commentsStore       *CommentsStore,
	conversationService *ConversationService,
	chatGPTService      *ChatGPTService,
	authProxy           *authProxy
) {
	mux.Handle("/api/v1/", handleTenantsGet(logger, tenantsStore))
	mux.Handle("/oauth2/", handleOAuth2Proxy(logger, authProxy))
	mux.HandleFunc("/healthz", handleHealthzPlease(logger))
	mux.Handle("/", http.NotFoundHandler())
}</code></pre></div><p>In my example, <code>addRoutes</code> doesn’t return an error. Anything that can throw an error is moved to the <code>run</code> function and sorted out before it gets to this point leaving this function free to remain simple and flat. Of course, if any of your handlers do return errors for whatever reason, then fine, this can return an error too.</p><h2 id="func-main-only-calls-run"><code>func main()</code> only calls <code>run()</code></h2><p>The <code>run</code> function is like the <code>main</code> function, except that it takes in operating system fundamentals as arguments, and returns, you guessed it, an error.</p><p>I wish <code>func main()</code> was <code>func main() error</code>. Or like in C where you can return the exit code: <code>func main() int</code>. By having an ultra simple main function, you too can have your dreams come true:</p><div><pre data-expanded="false"><code>func run(ctx context.Context, w io.Writer, args []string) error {
	// ...
}

func main() {
	ctx := context.Background()
	ctx, cancel := signal.NotifyContext(ctx, os.Interrupt)
	defer cancel()
	if err := run(ctx, os.Stdout, os.Args); err != nil {
		fmt.Fprintf(os.Stderr, "%s\n", err)
		os.Exit(1)
	}
}</code></pre></div><p>The code above creates a context, which is cancelled by <code>Ctrl+C</code> or equivalent, and calls down to the <code>run</code> function. If <code>run</code> returns <code>nil</code>, the function exits normally. If it returns an error, we write it to stderr and exit with a non-zero code. If I’m writing a command line tool where exit codes matter, I would return an int as well so I could write tests to assert the right one was returned.</p><p>Operating system fundamentals are passed into run as arguments. For example, you might pass in <code>os.Args</code> if it has flag support, and even <code>os.Stdin</code>, <code>os.Stdout</code>, <code>os.Stderr</code> dependencies. This makes your programs much easier to test because test code can call run to execute your program, controlling arguments, and all streams, just by passing different arguments.</p><p>The following table shows examples of input arguments to the run function:</p><table><thead><tr><th><strong>Value</strong></th><th><strong>Type</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td><code>os.Args</code></td><td><code>[]string</code></td><td>The arguments passed in when executing your program. It’s also used for parsing flags.</td></tr><tr><td><code>os.Stdin</code></td><td><code>io.Reader</code></td><td>For reading input</td></tr><tr><td><code>os.Stdout</code></td><td><code>io.Writer</code></td><td>For writing output</td></tr><tr><td><code>os.Stderr</code></td><td><code>io.Writer</code></td><td>For writing error logs</td></tr><tr><td><code>os.Getenv</code></td><td><code>func(string) string</code></td><td>For reading environment variables</td></tr><tr><td><code>os.Getwd</code></td><td><code>func() (string, error)</code></td><td>Get the working directory</td></tr></tbody></table><p>If you keep away from any global scope data, you can usually use <code>t.Parallel()</code> in more places, to speed up your test suites. Everything is self-contained, so multiple calls to <code>run</code> don’t interfere with each other.</p><p>I often end up with <code>run</code> function signatures that look like this:</p><div><pre data-expanded="false"><code>func run(
	ctx    context.Context,
	args   []string,
	getenv func(string) string,
	stdin  io.Reader,
	stdout, stderr io.Writer,
) error</code></pre></div><p>Now that we’re inside the <code>run</code> function, we can go back to writing normal Go code where we can return errors like it’s nobody’s business. We gophers just love returning errors, and the sooner we admit that to ourselves, the sooner those people on the internet can win and go away.</p><h3 id="gracefully-shutting-down">Gracefully shutting down</h3><p>If you’re running lots of tests, it’s important for your program to stop when each one is finished. (Alternatively, you might decide to keep one instance running for all tests, but that’s up to you.)</p><p>The context is passed through. It gets cancelled if a termination signal comes into the program, so it’s important to respect it at every level. At the very least, pass it to your dependencies. At best, check the <code>Err()</code> method in any long-running or loopy code, and if it returns an error, stop what you’re doing and return it up. This will help the server to gracefully shut down. If you kick off other goroutines, you can also use the context to decide if it’s time to stop them or not.</p><h3 id="controlling-the-environment">Controlling the environment</h3><p>The <code>args</code> and <code>getenv</code> parameters give us a couple of ways to control how our program behaves through flags and environment variables. Flags are processed using the args (as long as you don’t use the global space version of flags, and instead use <code>flags.NewFlagSet</code> inside <code>run</code>) so we can call run with different values:</p><div><pre data-expanded="false"><code>args := []string{
	"myapp",
	"--out", outFile,
	"--fmt", "markdown",
}
go run(ctx, args, etc.)</code></pre></div><p>If your program uses environment variables over flags (or even both) then the <code>getenv</code> function allows you to plug in different values without changing the actual environment.</p><div><pre data-expanded="false"><code>getenv := func(key string) string {
	switch key {
	case "MYAPP_FORMAT":
		return "markdown"
	case "MYAPP_TIMEOUT":
		return "5s"
	default:
		return ""
}
go run(ctx, args, getenv)</code></pre></div><p>For me, using this <code>getenv</code> technique beats using <code>t.SetEnv</code> for controlling environment variables because you can continue to run your tests in parallel by calling <code>t.Parallel()</code>, which <code>t.SetEnv</code> doesn’t allow.</p><p>This technique is even more useful when writing command line tools, because you often want to run the program with different settings to test all of its behavior.</p><p>In the <code>main</code> function, we can pass in the real things:</p><div><pre data-expanded="false"><code>func main() {
	ctx := context.Background()
	ctx, cancel := signal.NotifyContext(ctx, os.Interrupt)
	defer cancel()
	if err := run(ctx, os.Getenv, os.Stderr); err != nil {
		fmt.Fprintf(os.Stderr, "%s\n", err)
		os.Exit(1)
	}
}</code></pre></div><h2 id="maker-funcs-return-the-handler">Maker funcs return the handler</h2><p>My handler functions don’t implement <code>http.Handler</code> or <code>http.HandlerFunc</code> directly, they return them. Specifically, they return <code>http.Handler</code> types.</p><div><pre data-expanded="false"><code>// handleSomething handles one of those web requests
// that you hear so much about.
func handleSomething(logger *Logger) http.Handler {
	thing := prepareThing()
	return http.HandlerFunc(
		func(w http.ResponseWriter, r *http.Request) {
			// use thing to handle request
			logger.Info(r.Context(), "msg", "handleSomething")
		}
	)
}</code></pre></div><p>This pattern gives each handler its own closure environment. You can do initialization work in this space, and the data will be available to the handlers when they are called.</p><p>Be sure to only read the shared data. If handlers modify anything, you’ll need a mutex or something to protect it.</p><p>Storing program state here is not usually what you want. In most cloud environments, you can’t trust that code will continue running over long periods of time. Depending on your production environment, servers will often shut down to save resources, or even just crash for other reasons. There may also be many instances of your service running with requests load balanced across them in unpredictable ways. In this case, an instance would only have access to its own local data. So it’s better to use a database or some other storage API to persist data in real projects.</p><h2 id="handle-decodingencoding-in-one-place">Handle decoding/encoding in one place</h2><p>Every service will need to decode the request bodies and encode response bodies. This is a sensible abstraction that stands the test of time.</p><p>I usually have a pair of helper functions called encode and decode. An example version using generics shows you that you really are just wrapping a few basic lines, which I wouldn’t usually do, however this becomes useful when you need to make changes here for all of your APIs. (For example, say you get a new boss stuck in the 1990s and they want to add XML support.)</p><div><pre data-expanded="false"><code>func encode[T any](w http.ResponseWriter, r *http.Request, status int, v T) error {
	w.WriteHeader(status)
	w.Header().Set("Content-Type", "application/json")
	if err := json.NewEncoder(w).Encode(v); err != nil {
		return fmt.Errorf("encode json: %w", err)
	}
	return nil
}

func decode[T any](r *http.Request) (T, error) {
	var v T
	if err := json.NewDecoder(r.Body).Decode(&amp;v); err != nil {
		return v, fmt.Errorf("decode json: %w", err)
	}
	return v, nil
}</code></pre></div><p>Interestingly, the compiler is able to infer the type from the argument, so you don’t need to pass it when calling encode:</p><div><pre data-expanded="false"><code>err := encode(w, r, http.StatusOK, obj)</code></pre></div><p>But since it is a return argument in decode, you will need to specify the type you expect:</p><div><pre data-expanded="false"><code>decoded, err := decode[CreateSomethingRequest](r)</code></pre></div><p>I try not to overload these functions, but in the past I was quite pleased with a simple validation interface that fit nicely into the decode function.</p><h2 id="validating-data">Validating data</h2><p>I like a simple interface. Love them, actually. Single method interfaces are so easy to implement. So when it comes to validating objects, I like to do this:</p><div><pre data-expanded="false"><code>// Validator is an object that can be validated.
type Validator interface {
	// Valid checks the object and returns any
	// problems. If len(problems) == 0 then
	// the object is valid.
	Valid(ctx context.Context) (problems map[string]string)
}</code></pre></div><p>The <code>Valid</code> method takes a context (which is optional but has been useful for me in the past) and returns a map. If there is a problem with a field, its name is used as the key, and a human-readable explanation of the issue is set as the value.</p><p>The method can do whatever it needs to validate the fields of the struct. For example, it can check to make sure:</p><ul><li>Required fields are not empty</li><li>Strings with a specific format (like email) are correct</li><li>Numbers are within an acceptable range</li></ul><p>If you need to do anything more complicated, like check the field in a database, that should happen elsewhere; it’s probably too important to be considered a quick validation check, and you wouldn’t expect to find that kind of thing in a function like this, so it could easily end up being hidden away.</p><p>I then use a type assertion to see if the object implements the interface. Or, in the generic world, I might choose to be more explicit about what’s going on by changing the decode method to insist on that interface being implemented.</p><div><pre data-expanded="false"><code>func decodeValid[T Validator](r *http.Request) (T, map[string]string, error) {
	var v T
	if err := json.NewDecoder(r.Body).Decode(&amp;v); err != nil {
		return v, nil, fmt.Errorf("decode json: %w", err)
	}
	if problems := v.Valid(r.Context()); len(problems) &gt; 0 {
		return v, problems, fmt.Errorf("invalid %T: %d problems", v, len(problems))
	}
	return v, nil, nil
}</code></pre></div><p>In this code, <code>T</code> has to implement the <code>Validator</code> interface, and the <code>Valid</code> method must return zero problems in order for the object to be considered successfully decoded.</p><p>It’s safe to return <code>nil</code> for problems because we are going to check <code>len(problems)</code>, which will be <code>0</code> for a <code>nil</code> map, but which won’t panic.</p><h2 id="the-adapter-pattern-for-middleware">The adapter pattern for middleware</h2><p>Middleware functions take an <code>http.Handler</code> and return a new one that can run code before and/or after calling the original handler — or it can decide not to call the original handler at all.</p><p>An example is a check to make sure the user is an administrator:</p><div><pre data-expanded="false"><code>func (s *server) adminOnly(h http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		if !currentUser(r).IsAdmin {
			http.NotFound(w, r)
			return
		}
		h(w, r)
	})
}</code></pre></div><p>The logic inside the handler can optionally decide whether to call the original handler or not. In the example above, if <code>IsAdmin</code> is false, the handler will return an <code>HTTP 404 Not Found</code> and return (or abort); notice that the <code>h</code> handler is not called. If <code>IsAdmin</code> is true, the user is allowed to access the route, and so execution is passed to the h handler.</p><p>Usually I have middleware listed in the <code>routes.go</code> file:</p><div><pre data-expanded="false"><code>package app

func addRoutes(mux *http.ServeMux) {
	mux.HandleFunc("/api/", s.handleAPI())
	mux.HandleFunc("/about", s.handleAbout())
	mux.HandleFunc("/", s.handleIndex())
	mux.HandleFunc("/admin", s.adminOnly(s.handleAdminIndex()))
}</code></pre></div><p>This makes it very clear, just by looking at the map of endpoints, which middleware is applied to which routes. If the lists start getting bigger, try splitting them across many lines — I know, I know, but you get used to it.</p><h2 id="sometimes-i-return-the-middleware">Sometimes I return the middleware</h2><p>The above approach is great for simple cases, but if the middleware needs lots of dependencies (a logger, a database, some API clients, a byte array containing the data for “Never Gonna Give You Up” for a later prank), then I have been known to have a function that returns the middleware function.</p><p>The problem is, you end up with code that looks like this:</p><div><pre data-expanded="false"><code>mux.Handle("/route1", middleware(logger, db, slackClient, rroll []byte, handleSomething(handlerSpecificDeps))
mux.Handle("/route2", middleware(logger, db, slackClient, rroll []byte, handleSomething2(handlerSpecificDeps))
mux.Handle("/route3", middleware(logger, db, slackClient, rroll []byte, handleSomething3(handlerSpecificDeps))
mux.Handle("/route4", middleware(logger, db, slackClient, rroll []byte, handleSomething4(handlerSpecificDeps))</code></pre></div><p>This bloats out the code and doesn’t really provide anything useful. Instead, I would have the middleware function take the dependencies, but return a function that takes only the next handler.</p><div><pre data-expanded="false"><code>func newMiddleware(
	logger Logger,
	db *DB,
	slackClient *slack.Client,
	rroll []byte,
) func(h http.Handler) http.Handler</code></pre></div><p>The return type <code>func(h http.Handler) http.Handler</code> is the function that we will call when setting up our routes.</p><div><pre data-expanded="false"><code>middleware := newMiddleware(logger, db, slackClient, rroll)
mux.Handle("/route1", middleware(handleSomething(handlerSpecificDeps))
mux.Handle("/route2", middleware(handleSomething2(handlerSpecificDeps))
mux.Handle("/route3", middleware(handleSomething3(handlerSpecificDeps))
mux.Handle("/route4", middleware(handleSomething4(handlerSpecificDeps))</code></pre></div><p>Some people, but not I, like to formalize that function type like this:</p><div><pre data-expanded="false"><code>// middleware is a function that wraps http.Handlers
// proving functionality before and after execution
// of the h handler.
type middleware func(h http.Handler) http.Handler</code></pre></div><p>This is fine. Do it if you like. I’m not going to come around to your work, wait outside for you, and then walk alongside you with my arm around your shoulders in an intimidating way, asking if you’re pleased with yourself.</p><p>The reason I don’t do it is because it gives an extra level of indirection. When you look at the <code>newMiddleware</code> function’s signature above, it’s very clear what’s going on. If the return type is middleware, you have a little extra work to do. Essentially, I optimize for reading code, not writing it.</p><h3 id="an-opportunity-to-hide-the-requestresponse-types-away">An opportunity to hide the request/response types away</h3><p>If an endpoint has its own request and response types, usually they’re only useful for that particular handler.</p><p>If that’s the case, you can define them inside the function.</p><div><pre data-expanded="false"><code>func handleSomething() http.HandlerFunc {
	type request struct {
		Name string
	}
	type response struct {
		Greeting string `json:"greeting"`
	}
	return func(w http.ResponseWriter, r *http.Request) {
		...
	}
}</code></pre></div><p>This keeps your global space clear and also prevents other handlers from relying on data you may not consider stable.</p><p>You sometimes encounter friction with this approach when your test code needs to use the same types. And to be fair, this is a good argument for breaking them out if that’s what you want to do.</p><h2 id="use-inline-requestresponse-types-for-additional-storytelling-in-tests">Use inline request/response types for additional storytelling in tests</h2><p>If your request/response types are hidden inside the handler, you can just declare new types in your test code.</p><p>This is an opportunity to do a bit of storytelling to future generations who will need to understand your code.</p><p>For example, let’s say we have a <code>Person</code> type in our code, and we reuse it on many endpoints. If we had a <code>/greet</code> endpoint, we might only care about their name, so we can express this in test code:</p><div><pre data-expanded="false"><code>func TestGreet(t *testing.T) {
	is := is.New(t)
	person := struct {
		Name string `json:"name"`
	}{
		Name: "Mat Ryer",
	}
	var buf bytes.Buffer
	err := json.NewEncoder(&amp;buf).Encode(person)
	is.NoErr(err) // json.NewEncoder
	req, err := http.NewRequest(http.MethodPost, "/greet", &amp;buf)
	is.NoErr(err)
	//... more test code here</code></pre></div><p>It’s clear from this test that the only field we care about is the <code>Name</code> field.</p><h2 id="synconce-to-defer-setup"><code>sync.Once</code> to defer setup</h2><p>If I have to do anything expensive when preparing the handler, I defer it until that handler is first called.</p><p>This improves application startup time.</p><div><pre data-expanded="false"><code>func (s *server) handleTemplate(files string...) http.HandlerFunc {
	var (
		init    sync.Once
		tpl     *template.Template
		tplerr  error
	)
	return func(w http.ResponseWriter, r *http.Request) {
		init.Do(func(){
			tpl, tplerr = template.ParseFiles(files...)
		})
		if tplerr != nil {
		http.Error(w, tplerr.Error(), http.StatusInternalServerError)
			return
		}
		// use tpl
	}
}</code></pre></div><p><code>sync.Once</code> ensures the code is only executed one time, and other calls (other people making the same request) will block until it’s finished.</p><ul><li>The error check is outside of the <code>init</code> function, so if something does go wrong we still surface the error and won’t lose it in the logs</li><li>If the handler is not called, the expensive work is never done — this can have big benefits depending on how your code is deployed</li></ul><p>Remember that by doing this, you are moving the initialization time from startup to runtime (when the endpoint is first accessed). I use Google App Engine a lot, so this makes sense for me, but your case might be different, so it’s worth thinking about where and when to use <code>sync.Once</code> in this way.</p><h2 id="designing-for-testability">Designing for testability</h2><p>These patterns evolved partly because of how easy they are to test the code. The <code>run</code> function is a simple way to run your program right from test code.</p><p>You have lots of options when it comes to testing in Go, and it’s less about right and wrong, and more about:</p><ul><li>How easy is it to understand what your program does by looking at the tests?</li><li>How easy is it to change your code without worrying about breaking things?</li><li>If all your tests pass, can you push to production, or does it need to cover more things?</li></ul><h3 id="what-is-the-unit-when-unit-testing">What is the unit when unit testing?&nbsp;</h3><p>Following these patterns, the handlers themselves are also independently testable, but I tend not to do this, and I’ll explain why below. You have to consider what the best approach is for your project.</p><p>To test the handler only, you can:</p><ol><li>Call the function to get the <code>http.Handler</code> — you have to pass in all the required dependencies (this is a feature).</li><li>Call the <code>ServeHTTP</code> method on the <code>http.Handler</code> you get back using a real <code>http.Request</code> and a <code>ResponseRecorder</code> from the <code>httptest</code> package (see <a href="https://pkg.go.dev/net/http/httptest#ResponseRecorder" target="_blank" rel="noopener noreferrer">https://pkg.go.dev/net/http/httptest#ResponseRecorder</a>)</li><li>Make assertions about the response (check the status code, decode the body and make sure it’s right, check any important headers, etc.)</li></ol><p>If you do this, you cut out any middleware like auth, and go straight to the handler code. This is nice if there is some specific complexity you want to build some test support around. However, there’s an advantage when your test code calls APIs in the same way your users will. I err on the side of end-to-end testing at this level, rather than unit testing all the pieces inside.</p><p>I would rather call the <code>run</code> function to execute the whole program as close to how it will run in production as possible. This will parse any arguments, connect to any dependencies, migrate the database, whatever else it will do in the wild, and eventually start up the server. Then when I hit the API from my test code, I am going through all the layers and even interacting with a real database. I am also testing <code>routes.go</code> at the same time.</p><p>I find I catch more issues earlier with this approach and I can avoid specifically testing boilerplate things. It also reduces the repetition in my tests. If I diligently test every layer, I can end up saying the same things multiple times in slightly different ways. You have to maintain all of this, so if you want to change something, updating one function and three tests doesn’t feel very productive. With end-to-end tests, you just have one set of main tests that describe the interactions between your users and your system.</p><p>I still use unit tests within this where appropriate. If I used TDD (which I often do) then I usually have a lot of tests done anyway, which I’m happy to maintain. But I will go back and delete tests if they’re repeating the same thing as an end-to-end test.</p><p>This decision will depend on lots of things, from the opinions of those around you to the complexity of your project, so like all the advice in this post, don’t fight to do this if it just doesn’t work for you.</p><h3 id="testing-with-the-run-function">Testing with the run function</h3><p>I like to call the <code>run</code> function from each test. Each test gets its own self-contained instance of the program. For each test, I can pass different arguments, flag values, standard-in and -out pipes, and even environment variables.</p><p>Since the <code>run</code> function takes a <code>context.Context</code>, and since all our code respects the context (right, everyone? It respects the context, right?) We can get a cancellation function by calling <code>context.WithCancel</code>. By deferring the <code>cancel</code> function, when the test function returns (i.e., when the tests have finished running) the context will be cancelled and the program will gracefully shut down. In Go 1.14 they added the <code>t.Cleanup</code> method which is a replacement for using the <code>defer</code> keyword yourself, and if you’d like to learn more about why that is, check out this issue: <a href="https://github.com/golang/go/issues/37333" target="_blank" rel="noopener noreferrer">https://github.com/golang/go/issues/37333</a>.&nbsp;</p><p>This is all achieved in surprisingly little code. Of course, you have to keep checking <code>ctx.Err</code> or <code>ctx.Done</code> all over the place too:</p><div><pre data-expanded="false"><code>func Test(t *testing.T) {
	ctx := context.Background()
	ctx, cancel := context.WithCancel(ctx)
	t.Cleanup(cancel)
	go run(ctx)
	// test code goes here</code></pre></div><h3 id="waiting-for-readiness">Waiting for readiness</h3><p>Since the <code>run</code> function executes in a goroutine, we don’t really know exactly when it’s going to start up. If we’re going to start hitting the API like real users, we are going to need to know when it’s ready.</p><p>We could set up some way of signalling readiness, like a channel or something — but I prefer to have a <code>/healthz</code> or <code>/readyz</code> endpoint running on the server. As my old grandma used to say, the proof of the pudding is in the actual HTTP requests (she was way ahead of her time).</p><p>This is an example where our efforts to make the code more testable gives us an insight into what our users will need. They probably want to know if the service is ready or not as well, so why not have an official way to find this out?</p><p>To wait for a service to be ready, you can just write a loop:&nbsp;</p><div><pre data-expanded="false"><code>// waitForReady calls the specified endpoint until it gets a 200 
// response or until the context is cancelled or the timeout is 
// reached.
func waitForReady(
	ctx context.Context, 
	timeout time.Duration, 
	endpoint string,
) error {
	client := http.Client{}
	startTime := time.Now()
	for {
		req, err := http.NewRequestWithContext(
			ctx, 
			http.MethodGet, 
			endpoint, 
			nil,
		)
		if err != nil {
			return fmt.Errorf("failed to create request: %w", err)
		}

		resp, err := client.Do(req)
		if err != nil {
			fmt.Printf("Error making request: %s\n", err.Error())
			continue
		}
		if resp.StatusCode == http.StatusOK {
			fmt.Println("Endpoint is ready!")
			resp.Body.Close()
			return nil
		}
		resp.Body.Close()

		select {
		case &lt;-ctx.Done():
			return ctx.Err()
		default:
			if time.Since(startTime) &gt;= timeout {
				return fmt.Errorf("timeout reached while waiting for endpoint")
			}
			// wait a little while between checks
			time.Sleep(250 * time.Millisecond)
		}
	}
}</code></pre></div><h2 id="putting-this-all-into-practice">Putting this all into practice</h2><p>Rolling simple APIs using these techniques remains my favorite way to go. It suits my aims of achieving maintainability excellence with code that’s easy to read, easy to extend by copying patterns, easy for new people to work with, easy to change without worrying, and explicitly done without any magic. This remains true even in cases where I use a code generation framework like our own <a href="https://github.com/pacedotdev/oto" target="_blank" rel="noopener noreferrer">Oto package</a> to write the boilerplate for me based on templates that I customize.</p><p>On bigger projects or in larger organizations, especially one like Grafana Labs, you’ll often come across specific technology choices that impact these decisions. gRPC is a good example. In cases where there are established patterns and experience, or other tools or abstractions that are widely used, you will often find yourself making the pragmatic choice of going with the flow, as they say, although I suspect (or is it hope?) that there is still something useful in this post for you.</p><p>My day job is building out the new <a href="https://grafana.com/products/cloud/irm/">Grafana IRM</a> suite with a talented group within Grafana Labs. The patterns discussed in this post help us deliver tools that people can rely on. “Tell me more about these great tools!,” I hear you scream at your monitor.</p><p>Most people use Grafana to visualize the operation of their systems, and with Grafana Alerting they are pinged when metrics fall outside of acceptable boundaries. With Grafana OnCall, your schedules and escalation rules automate the process of reaching out to the right people when things go wrong.</p><p>Grafana Incident lets you manage those unavoidable all-hands-on-deck moments that most of us are all too familiar with. It creates the Zoom room for you to discuss the issue, a dedicated Slack channel, and tracks the timeline of events while you focus on putting out the fire. In Slack, anything you mark with the robot face emoji as a reaction in the channel will be added to the timeline. This makes it very easy to collect key events as you go along, making debrief or post-incident review discussions much easier.</p><p>Try it out in Grafana Cloud today, or get in touch with your Grafana contact if you’re lucky enough to have one, and ask them about it.</p><p><em><a href="https://grafana.com/products/cloud/?pg=blog&amp;plcmt=body-txt">Grafana Cloud</a> is the easiest way to get started with metrics, logs, traces, dashboards, and more. We have a generous forever-free tier and plans for every use case. <a href="https://grafana.com/auth/sign-up/create-user/?pg=blog&amp;plcmt=body-txt">Sign up for free now</a>!</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spreadsheet "breaks" Apple Vision Pro eye-tracking (142 pts)]]></title>
            <link>https://kguttag.com/2024/02/05/spreadsheet-breaks-the-apple-vision-pros-avp-eye-tracking-foveation-the-first-through-the-optics-pictures/</link>
            <guid>39318860</guid>
            <pubDate>Fri, 09 Feb 2024 19:00:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kguttag.com/2024/02/05/spreadsheet-breaks-the-apple-vision-pros-avp-eye-tracking-foveation-the-first-through-the-optics-pictures/">https://kguttag.com/2024/02/05/spreadsheet-breaks-the-apple-vision-pros-avp-eye-tracking-foveation-the-first-through-the-optics-pictures/</a>, See on <a href="https://news.ycombinator.com/item?id=39318860">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
<h2>Introduction</h2>



<p>Today’s article is just some early findings on the Apple Vision Pro (<strong>AVP</strong>). I’m working on many things related to the AVP, and it will take me a while to prepare all of them for publishing. Among the things I am doing, I am trying to capture “through the optics” pictures of the AVP, and it is unveiling both interesting information on how the AVP works and the second test pattern I tried “broke” the foveated rending of the AVP. </p>



<p>Having done several searches, I have not seen any “through-the-optics” pictures of the AVP yet. They may be out there, but I haven’t found them. So, I thought I would put up a couple of my test pictures to be (hopefully) the first to publish a picture through the AVP’s optics. </p>



<h2>Eye Tracking Display Based Rendering, Mabye “Too smart for its own good” </h2>



<p>The AVP is sometimes “too smart for its own good,” resulting in bad visual artifacts. In addition to being used for selection, the AVP’s eye-tracking varies the resolution and corrects color issues (aberrations) in the optics by pre-processing the image. This makes it tricky to photograph because the camera lens looks different to the human eye.</p>



<p>Today, I threw together some spreadsheets to check my ability to take pictures through the AVP optics. I started with two large Excel spreadsheets displayed using the AVP’s native Excel App. One spreadsheet used black text on a white background, which looked like the AVP was making the text and lines look “bolder/thicker” than they should look, but it didn’t act that crazy; the AVP seems to be “enhancing” (not always what you want) the spreadsheet’s readability.  </p>



<p>But then I tried inverting everything with white text and lines on a black background, and the display started scintillating in a square box that followed the eye tracking. Fortunately, the AVP’s recording captured the effect in the video below. </p>



<figure><p><span><iframe width="1506" height="848" src="https://www.youtube.com/embed/ciXLygHavps?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox"></iframe></span>
</p></figure>



<p><strong>I want to emphasize that it is not just the camera or the AVP’s video capture that shows the problem with the foveated rendering; I see it with my own eyes</strong>. I have provided the spreadsheets below so anyone with an AVP can verify my findings. I have only tested this with the Excel running on the AVP. The effect is most easily seen if you go into “View” in Excel” and make the view smaller with “-” magnifying glass 3 or 4 times to make the text and boxes smaller.</p>











<h2>My First Through-the-Optics Picture Experiments</h2>



<p>With its eye-tracking-based rendering, the AVP will be tricky to capture through the optics. The tracking behaves differently with different cameras and lenses. When setting up the camera, I can see the AVP changing colors, sometimes resulting in pictures that are colored differently than what my eye sees. </p>



<p>It seems pretty clear that the AVP is using “foveated,” variable resolution rendering even on still subjects like a spreadsheet. This re-rendering is based on the eyes and due to the change in the 3-D space locking (aka, SLAM) that caused the artifacts seen in the White text and lines on the BLACK spreadsheet. </p>



<p><strong>Furthermore, the resolution of the displays is definitely lower than the eye’s resolution, as you can easily see the anti-aliasing “twisted rope” rippling effect if you look at the white-on-black spreadsheet.</strong> The highest rendered resolution (“foveated”) part of the image that scintillates. I discussed this issue in <a href="https://kguttag.com/2023/08/05/apple-vision-pro-part-5a-why-monitor-replacement-is-ridiculous/">Apple Vision Pro (Part 5A) – Why Monitor Replacement is Ridiculous</a>, <a href="https://kguttag.com/2023/08/09/apple-vision-pro-part-5b-more-on-monitor-replacement-is-ridiculous/">Apple Vision Pro (Part 5B) – More on Monitor Replacement is Ridiculous</a>, and <a href="https://kguttag.com/2023/08/20/apple-vision-pro-part-5c-more-on-monitor-replacement-is-ridiculous/">Apple Vision Pro (Part 5C) – More on Monitor Replacement is Ridiculous</a>. </p>



<p><b>I should point out that if not for the foveation, the whole image would scintillate. S</b><strong><b>till, the</b> foveated rendering worsens because it creates a visible square at the boundary between the foveated area and the lower-resolution region</strong>. The “foveated rendering” makes it worse by changing the text and lines’ resolution and thickness. I would argue that a more graceful degradation would be to have the whole image rendered the same way (it is not a processing limitation to render a spreadsheet), with the whole image scintillating rather than having boundary lines where it does and does not and with the boldness changing at the boundaries as well. The key point is that the AVP’s display, while much better than almost all other VR/MR headsets, is not, as Apple puts it, “retinal resolution” (or beyond what the eye can see). </p>



<p>Anyway, for the record, below are a couple of through-the-optics test pictures. The first was taken with an R5 camera with a 28mm lens and “pixel shifting” to give a 400-megapixel image. Click on the crop of a very small portion of the center of that picture below to see it in full resolution.</p>



<figure><a href="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-copy-center-crop.jpg?ssl=1"><img decoding="async" width="1024" height="588" data-attachment-id="14070" data-permalink="https://kguttag.com/2024/02/05/spreadsheet-breaks-the-apple-vision-pros-avp-eye-tracking-foveation-the-first-through-the-optics-pictures/2024-02-04-20-8217-28mm_f8_15th-iso400-copy-center-crop/" data-orig-file="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-copy-center-crop.jpg?fit=4198%2C2412&amp;ssl=1" data-orig-size="4198,2412" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS R5&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1707097761&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;28&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="2024-02-04-20-8217-28mm_f8_15th-ISO400-copy-center-crop" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-copy-center-crop.jpg?fit=300%2C172&amp;ssl=1" data-large-file="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-copy-center-crop.jpg?fit=1024%2C588&amp;ssl=1" src="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-copy-center-crop.jpg?resize=1024%2C588&amp;ssl=1" alt="" srcset="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-copy-center-crop.jpg?resize=1024%2C588&amp;ssl=1 1024w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-copy-center-crop.jpg?resize=300%2C172&amp;ssl=1 300w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-copy-center-crop.jpg?resize=768%2C441&amp;ssl=1 768w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-copy-center-crop.jpg?resize=1536%2C883&amp;ssl=1 1536w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-copy-center-crop.jpg?resize=2048%2C1177&amp;ssl=1 2048w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-copy-center-crop.jpg?resize=1200%2C689&amp;ssl=1 1200w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-copy-center-crop.jpg?w=3012&amp;ssl=1 3012w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></a></figure>



<figure><a href="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-very-small-crop.jpg?ssl=1"><img loading="lazy" decoding="async" width="1024" height="432" data-attachment-id="14076" data-permalink="https://kguttag.com/2024/02/05/spreadsheet-breaks-the-apple-vision-pros-avp-eye-tracking-foveation-the-first-through-the-optics-pictures/2024-02-04-20-8217-28mm_f8_15th-iso400-very-small-crop/" data-orig-file="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-very-small-crop.jpg?fit=1348%2C569&amp;ssl=1" data-orig-size="1348,569" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS R5&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1707097761&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;28&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.066666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="2024-02-04-20-8217-28mm_f8_15th-ISO400-very-small-crop" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-very-small-crop.jpg?fit=300%2C127&amp;ssl=1" data-large-file="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-very-small-crop.jpg?fit=1024%2C432&amp;ssl=1" src="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-very-small-crop.jpg?resize=1024%2C432&amp;ssl=1" alt="" srcset="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-very-small-crop.jpg?resize=1024%2C432&amp;ssl=1 1024w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-very-small-crop.jpg?resize=300%2C127&amp;ssl=1 300w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-very-small-crop.jpg?resize=768%2C324&amp;ssl=1 768w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-very-small-crop.jpg?resize=1200%2C507&amp;ssl=1 1200w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-20-8217-28mm_f8_15th-ISO400-very-small-crop.jpg?w=1348&amp;ssl=1 1348w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></a><figcaption>Crop of a very small portion of the original image to show the full detail</figcaption></figure>



<p>The second image below was taken with an Olympus D mark III (Micro Four-Thirds camera) with a 17mm lens. It does not have the resolution of the R5, but the AVP’s eye tracking behaves better with this lens. This camera has a 24mp sensor, and then I used its pixel-shifting feature to capture the image at about 80 megapixels. The whole image (click to see at full resolution) is included below. </p>



<p>If you scroll around the full-resolution image, you can make out the pixel grid through most of the image, yet the text becomes blurrier much more quickly. Preliminarily, this seems to suggest foveated rendering. I have not had time to check yet, but I suspect the resolution falloff coincides with the squares in the white-on-black spreadsheet.</p>



<figure><a href="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?ssl=1"><img loading="lazy" decoding="async" width="1024" height="768" data-attachment-id="14072" data-permalink="https://kguttag.com/2024/02/05/spreadsheet-breaks-the-apple-vision-pros-avp-eye-tracking-foveation-the-first-through-the-optics-pictures/2024-02-04-17-45620-17mm_f8_10th-iso200-copy/" data-orig-file="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?fit=10368%2C7776&amp;ssl=1" data-orig-size="10368,7776" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;8&quot;,&quot;credit&quot;:&quot;Karl Guttag&quot;,&quot;camera&quot;:&quot;E-M5MarkIII&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1707067559&quot;,&quot;copyright&quot;:&quot;KGOTech&quot;,&quot;focal_length&quot;:&quot;17&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.1&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="2024-02-04-17-45620-17mm_f8_10th-ISO200-copy" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?fit=1024%2C768&amp;ssl=1" src="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?resize=1024%2C768&amp;ssl=1" alt="" srcset="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?w=3012&amp;ssl=1 3012w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45620-17mm_f8_10th-ISO200-copy.jpg?w=4518&amp;ssl=1 4518w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></a></figure>



<figure><img loading="lazy" decoding="async" width="1024" height="372" data-attachment-id="14078" data-permalink="https://kguttag.com/2024/02/05/spreadsheet-breaks-the-apple-vision-pros-avp-eye-tracking-foveation-the-first-through-the-optics-pictures/2024-02-04-17-45619-17mm_f8_10th-iso200-close-up-crop/" data-orig-file="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45619-17mm_f8_10th-ISO200-close-up-crop.jpg?fit=1177%2C428&amp;ssl=1" data-orig-size="1177,428" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;8&quot;,&quot;credit&quot;:&quot;Karl Guttag&quot;,&quot;camera&quot;:&quot;E-M5MarkIII&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1707067511&quot;,&quot;copyright&quot;:&quot;KGOTech&quot;,&quot;focal_length&quot;:&quot;17&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.1&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="2024-02-04-17-45619-17mm_f8_10th-ISO200-close-up-crop" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45619-17mm_f8_10th-ISO200-close-up-crop.jpg?fit=300%2C109&amp;ssl=1" data-large-file="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45619-17mm_f8_10th-ISO200-close-up-crop.jpg?fit=1024%2C372&amp;ssl=1" src="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45619-17mm_f8_10th-ISO200-close-up-crop.jpg?resize=1024%2C372&amp;ssl=1" alt="" srcset="https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45619-17mm_f8_10th-ISO200-close-up-crop.jpg?resize=1024%2C372&amp;ssl=1 1024w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45619-17mm_f8_10th-ISO200-close-up-crop.jpg?resize=300%2C109&amp;ssl=1 300w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45619-17mm_f8_10th-ISO200-close-up-crop.jpg?resize=768%2C279&amp;ssl=1 768w, https://i0.wp.com/kguttag.com/wp-content/uploads/2024/02/2024-02-04-17-45619-17mm_f8_10th-ISO200-close-up-crop.jpg?w=1177&amp;ssl=1 1177w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption>Very Small crop from the image above to show the detail</figcaption></figure>



<h2>Conclusion</h2>



<p>Designers have to be careful when it comes to applying technology. Sometimes, the same smarts that make one thing work will make others behave poorly. </p>



<p>The biggest part of the problem could be a bug in the AVP software or the Excel port. I’m not saying it is the end of the world, even if it is not improved. There is probably a way to “tone down” the foveated rending to reduce this problem, <strong>but I don’t think there is any way to eliminate it, given the display resolution</strong>. At the same time, the second test I tried caused it to “break/escape.” Since it happens so readily, this problem will likely show up elsewhere. Fundamentally, it comes down to the display not having a resolution as good as human vision.  </p>
		</div></div>]]></description>
        </item>
    </channel>
</rss>