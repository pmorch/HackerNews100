<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 30 Oct 2024 07:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Australia/Lord_Howe is the weirdest timezone (103 pts)]]></title>
            <link>https://ssoready.com/blog/engineering/truths-programmers-timezones/</link>
            <guid>41992314</guid>
            <pubDate>Wed, 30 Oct 2024 06:21:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ssoready.com/blog/engineering/truths-programmers-timezones/">https://ssoready.com/blog/engineering/truths-programmers-timezones/</a>, See on <a href="https://news.ycombinator.com/item?id=41992314">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
            Timezones are weird. But only finitely so. Here's the exact conceptual model you should have of them.
        </p><div>
            <p>The standard trope when talking about timezones is to rattle off falsehoods
programmers believe about them. These lists are only somewhat enlightening –
it’s really hard to figure out what truth is just from the contours of
falsehood.</p>
<p>So here’s an alternative approach. I’m gonna show you some weird timezones. In
fact, the <em>weirdest</em> timezones. They’re each about as weird as timezones are
allowed to get in some way.</p>
<ul>
<li><code>Asia/Kathmandu</code> has a weird offset from UTC</li>
<li><code>Africa/Casablanca</code> doesn’t fit into the timezone model cleanly, so it’s hard-coded</li>
<li><code>America/Nuuk</code> does daylight savings at -01:00 (yes, with a negative)
<ul>
<li>and <code>Africa/Cairo</code> and <code>America/Santiago</code> do it at 24 o’clock (not 0 o’clock)</li>
</ul>
</li>
<li><code>Australia/Lord_Howe</code>, population 382 and <a href="https://en.wikipedia.org/wiki/Dryococelus_australis">some notable stick
bugs</a>, has the weirdest
daylight savings rule</li>
</ul>
<p>To learn how their weirdness is represented in software, we’ll look at the raw
timezone files that all software ultimately relies on. From there, two things
will become clear:</p>
<ul>
<li>Yeah, this stuff is weird</li>
<li>But only finitely so, because ultimately a computer’s gotta implement them</li>
</ul>
<p>But first, an aside on the calendar.</p>
<h2 id="pgxiiream-pope-gregory-xiii-rules-everything-around-me">PGXIIREAM: Pope Gregory XIII rules everything around me</h2>
<p>Unless you’re doing some fairly exotic things where you’re finding yourself
saying things like</p>
<blockquote>
<p>Oh yeah the OCR on Japanese driving licenses pops out things like “平成 8”,
that’s just <a href="https://en.wikipedia.org/wiki/Japanese_era_name">how they sometimes say
1996</a> over there. That’s why
we have this in the parser:</p>
<pre tabindex="0"><code>eras = { "大正": 1912, "昭和": 1926, "平成": 1989 }
</code></pre><p>One of these days we’ll need to add <code>"令和": 2019</code>, but it hasn’t come up yet.</p>
</blockquote>
<p>or</p>
<blockquote>
<p>We’re gonna need to set up a per-country feature flag when deciding whether
banks are closed for Eid. <a href="https://www.economist.com/middle-east-and-africa/2019/06/06/when-is-eid-al-fitr">Saudi Arabia and Iran don’t agree on when the lunar
month
starts</a>.</p>
</blockquote>
<p>Then yeah, sure, you may need to write software that knows about the Japanese or
Islamic calendar systems.</p>
<p>Cases like this are a small minority. The reality of the world is that the
Western system of timekeeping is the dominant one, and even in e.g. Japan and
the Muslim world, almost everyone who uses computers is familiar with the
Gregorian system.</p>
<p>With computers, we project the Gregorian system into the future and past, which
is called the proleptic Gregorian calendar and isn’t historically accurate but
nobody really cares except <a href="https://en.wikipedia.org/wiki/Old_Style_and_New_Style_dates">Russian revolution
nerds</a>.</p>
<p>This calendar system is pretty much good enough, and barring any <a href="https://en.wikipedia.org/wiki/French_Republican_calendar">rationalist
coups d’etat</a>, is the
one we’ll be stuck with for a long time. It does one thing well: it’s very good
at keeping the sun at the same place in the sky across the years. It doesn’t let
the months drift around the seasons like the Roman calendar did.</p>
<p>Technically, this “keep the sun roughly in the same place whenever it’s the same
time-of-day” is called “mean solar time”. And that’s why GMT, Greenwich Mean
Time, is called that way. It’s about the mean solar time of the <a href="https://en.wikipedia.org/wiki/Royal_Observatory,_Greenwich">English
observatory in
Greenwich</a>.</p>
<p>By the way, we technically don’t call it GMT anymore. Unless you’re talking
about what time people in London say it is, you probably technically mean
<a href="https://en.wikipedia.org/wiki/Coordinated_Universal_Time">UTC</a>.</p>
<p><img src="https://ssoready.com/blog/engineering/truths-programmers-timezones/utc.png" alt=""></p>
<p><a href="https://en.wikipedia.org/wiki/Coordinated_Universal_Time">Coordinated Universal
Time</a> is basically
just a modern formalization of GMT. It’s useful because almost everyone on the
planet has agreed to base their clocks off of an <em>offset</em> from UTC. It’s still a
solar mean time, but the connection to Greenwich isn’t really there anymore.</p>
<p>I bring this up because you may have heard of a weird modern quirk on Pope
Gregory’s sun-following endeavors:</p>
<h2 id="leap-seconds-dont-matter">Leap seconds don’t matter</h2>
<p>The Earth’s rotation is slowing down. Days are getting longer. So you need to
correct for it if you want to keep IRL days in sync with computer days.</p>
<p>The nerd task force assigned to this problem is the <a href="https://en.wikipedia.org/wiki/International_Earth_Rotation_and_Reference_Systems_Service">International Earth
Rotation and Reference Systems
Service</a>,
which has two primary goals:</p>
<ol>
<li>Watch the Earth rotate, and report back on their findings</li>
<li>Break Wikipedia’s CSS with their long name</li>
</ol>
<figure>
<div>
<p><img src="https://ssoready.com/blog/engineering/truths-programmers-timezones/iers.png"></p><figcaption>timecops</figcaption>
</div>
</figure>
<p>If the days are getting longer, and they’re doing so at a fairly unpredictable
rate, the simplest solution is to have IERS occasionally just insert an extra
second in the day to make clocks go slower. It’s called a <a href="https://en.wikipedia.org/wiki/Leap_second">leap
second</a>.</p>
<p>You should completely ignore the fact that this is a thing. It’s a cool novelty,
but it’s effectively just a detail you can ignore, because:</p>
<ol>
<li><a href="https://go.dev/play/p/9RwZu2jmlPl">It’s not like programming languages support representing 61-second minutes
anyway</a></li>
<li>You (and by you I mean your cloud provider) can just run your clocks slower
around the time of the leap second, and pretend to everyone else over
<a href="https://en.wikipedia.org/wiki/Network_Time_Protocol">NTP</a> that their clocks
are running fast. This is called leap smearing.</li>
</ol>
<p>Btw it’s called UTC (Universal Time Coordinated? huh?) because the same folks
who publish UTC also publish UT1, which is UTC sans the leap seconds. There were
other UTs before the Coordinated variant came up.</p>
<h2 id="weird-time-zones">Weird time zones</h2>
<p>OK! Let’s start looking at some weird time zones, and find out how your computer
knows to represent them.</p>
<h2 id="asiakathmandu-is-on-a-weird-offset"><code>Asia/Kathmandu</code> is on a weird offset</h2>
<p>Most of the world is on a whole number of hours before or after UTC. About a
fifth the world by population is on a half-hour offset from UTC; in particular,
India is 5h30m ahead of UTC.</p>
<p>Nepal is 5h45m ahead of UTC:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>$ TZ=UTC date ; TZ=Asia/Kathmandu date
</span></span><span><span>Tue Jul 30 23:52:11 UTC 2024
</span></span><span><span>Wed Jul 31 05:37:11 +0545 2024
</span></span></code></pre></div><p>If you’re like me, you must be have at one point wondered how in the <em>world</em>
your computer knows this fact.</p>
<p>Here’s a hint:</p>
<div><pre tabindex="0"><code data-lang="text"><span><span>$ TZ=Asia/Kathmandu strace -e trace=openat date
</span></span><span><span>...
</span></span><span><span>openat(AT_FDCWD, "/usr/share/zoneinfo/Asia/Kathmandu", O_RDONLY|O_CLOEXEC) = 3
</span></span><span><span>Wed Jul 31 05:40:49 +0545 2024
</span></span></code></pre></div><p>On your filesystem is a database called the IANA Timezone Database, aka tzdb or
zoneinfo. It’s a bunch of binary files, encoded in <a href="https://www.rfc-editor.org/rfc/rfc8536.html">Timezone Information
Format</a>. The names of those files
act as timezone identifiers, which is where you see strings like
<code>America/Los_Angeles</code> or <code>Europe/London</code> come from:</p>
<pre tabindex="0"><code>$ tree /usr/share/zoneinfo
...
├── America
│&nbsp;&nbsp; ├── Los_Angeles
├── Europe
│&nbsp;&nbsp; ├── London
...
</code></pre><p>At the very end of <code>/usr/share/zoneinfo/Asia/Kathmandu</code> is this little string:</p>
<pre tabindex="0"><code>cat /usr/share/zoneinfo/Asia/Kathmandu
...
&lt;+0545&gt;-5:45
</code></pre><p>The syntax is here pretty obtuse, but what it means is:</p>
<blockquote>
<p>Unless otherwise specified, UTC is 5h45m behind this timezone. Call this time
<code>+0545</code>.</p>
</blockquote>
<p>That’s precisely how software can figure out the time in Nepal. That’s also why
the output from <code>date</code> above has <code>+0545</code> in it.</p>
<h2 id="why-strings-like-pdt-or-cet-are-pretty-meaningless">Why strings like <code>PDT</code> or <code>CET</code> are pretty meaningless</h2>
<p>In the example above, <code>+0545</code> is called a “designator”. It’s a pretty-ish string
describing which <em>part</em> of a timezone a timestamp is in. It’s meant to be used
for outputting timestamps, and is only unambiguous if you already know what
timezone the timestamp was taken in.</p>
<p>Just <em>how</em> ambiguous are these designators? I wrote a <code>tzdump</code> script that
converts TZIF files to JSON. Here’s the top hits:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>find -L /usr/share/zoneinfo -type f <span>\
</span></span></span><span><span><span></span>  <span>|</span> xargs -n1 ./tzdump <span>\
</span></span></span><span><span><span></span>  <span>|</span> jq -r <span>'"\(.ID)\t\(.Transitions[].LocalTimeType.Designation)"'</span> <span>\
</span></span></span><span><span><span></span>  <span>|</span> sort <span>|</span> uniq <span>|</span> sort -k <span>2</span> <span>|</span> uniq -f <span>1</span> -c <span>|</span> sort -n <span>|</span> awk <span>'{ print $1 "\t" $3 }'</span> <span>|</span> tail -r
</span></span></code></pre></div><p>The most popular designators are:</p>
<pre tabindex="0"><code>66	CST
58	CDT
56	CET
56	CEST
</code></pre><p>A total of <strong>66 timezones</strong> use <code>CST</code>, either in the past or future. Many
timezones are functionally exact clones of each other – there’s no difference
between <code>America/Phoenix</code> and
<a href="https://en.wikipedia.org/wiki/Creston,_British_Columbia"><code>America/Creston</code></a>,
but they each get their own file – but still. There’s a lot of ambiguity in
there.</p>
<p>In case you’re curious, only 33 designators are unique to a timezone. A lot more
are functionally unique, but I’m too lazy to dedupe logically-equivalent
timezones right now.</p>
<p>As an extra fun bit of trivia, designators are not strictly uppercase/numeric.
<code>ChST</code>, appearing in <code>Pacific/Saipan</code>, stands for Chamorro Standard Time. It’s
the only designator with a lowercase name. <code>CHST</code> is not taken, sadly for those
of us who love bugs.</p>
<h2 id="how-are-timezones-with-dst-represented">How are timezones with DST represented?</h2>
<p>When we looked at Kathmandu, we had this string telling us the Nepalese time
rules:</p>
<pre tabindex="0"><code>&lt;+0545&gt;-5:45
</code></pre><p>Ok, simple enough. But what about a timezone with DST transitions? The syntax
has lots of defaults (DST will be a one-hour jump, it happens at 2am by default,
etc) but <code>Europe/Athens</code> is a good example of one that uses most of the syntax:</p>
<pre tabindex="0"><code>$ cat /usr/share/zoneinfo/Europe/Athens
...
EET-2EEST,M3.5.0/3,M10.5.0/4
</code></pre><p>That syntax means:</p>
<blockquote>
<p>Standard time is called <code>EET</code>, it’s 2 hours ahead of UTC. DST is called <code>EEST</code>
(it’s 3 hours ahead, an implicit default relative to standard time). Start DST
in month <code>3</code> on the last instance of (<code>5</code>) day <code>0</code> (Sunday) in that month, at
3am local (<code>/3</code>). End DST on month <code>10</code> on the last Sunday at 4am local
(<code>5.0/4</code>).</p>
</blockquote>
<p>So yeah, your computer does a bunch of <a href="https://howardhinnant.github.io/date_algorithms.html">kind of
gnarly</a> logic to figure
out what date-and-time a timestamp corresponds to, then figures out whether it’s
inside or outside DST to figure out the current local time. Delightful.</p>
<p>In case you’re curious, the spec says “5” means “last instance of”, and “1”
means “first instance of”. But only weeks “1”, “2”, and “5” are used:</p>
<pre tabindex="0"><code>$ find -L /usr/share/zoneinfo -type f | xargs -n1 ./tzdump | jq -r 'if .Rules.DST == null then empty else "\(.ID)\t\(.Rules.DST.Week)" end' | sort -k2 | uniq -f 1 -c | awk '{ print $1 "\t" $3 }'
18	1
89	2
81	5
</code></pre><p>Here’s a fun twist: on my Mac 100% of timezones either don’t have DST at all or
use this nth-instance-of-day-of-month rules to do DST switching. But inside
<code>/var/db/timezone</code> there’s different versions of tzdb. In there is a version
with other kinds of timezones in it:</p>
<pre tabindex="0"><code>$ cat /var/db/timezone/tz/2024a.1.0/zoneinfo/Africa/Casablanca
...
XXX-2&lt;+01&gt;-1,0/0,J365/23
</code></pre><p>That timezone basically means “we are perpetually on daylight savings”, because
the <code>J###</code> syntax means “<code>###</code>-th day of the year, not counting Feb 29 if there
is one” (J stands for “Julian calendar”).</p>
<p>Technically, that timezone also exercises the prefixless (i.e. without <code>M</code> or
<code>J</code>) syntax for indicating days, where <code>###</code> means “<code>###</code>-th day of year,
counting any Feb 29”. But in this case it’s a distinction without a difference.</p>
<p>(Aside: All this stuff comes from POSIX. <a href="https://www.gnu.org/software/libc/manual/html_node/TZ-Variable.html">GNU’s docs about the POSIX <code>TZ</code> env
var</a>, which
TZIF builds on, are the best I know of online for this stuff.)</p>
<p>But this is just the start of the weirdness that is <code>Africa/Casablanca</code>.</p>
<h2 id="africacasablanca-and-asiagaza-follow-the-moon-but-timezones-follow-the-sun"><code>Africa/Casablanca</code> and <code>Asia/Gaza</code> follow the moon, but timezones follow the sun</h2>
<p>The TZIF format supports three possible rules for deciding on your daylight
savings transition day:</p>
<ul>
<li>Rules like “first Tuesday of March”</li>
<li>Rules like “45th day of the year”</li>
<li>Rules like “45th day of the year, Feb 29 doesn’t count”</li>
</ul>
<p>Morocco and Gaza do their daylight savings based on Ramadan. Ramadan is a month
in the Islamic calendar. The Islamic calendar is based on the moon. The lunar
calendar isn’t a clean multiple of the solar calendar; from the Gregorian
perspective, lunar months seem to slowly “rotate” around the year, because
they’re basically on a different modulo. There’s a problem there for our heroes
at the tzdb.</p>
<p>The solution? The dumbest possible one.</p>
<p>A TZIF file ends with the footer syntax we’ve been talking about to this point.
But it <em>starts</em> with a big long list of historical data about a timezone. If a
country ever changes timezone rules, TZIF represents that by encoding the new
rule in the footer, and hard-coding all the old transitions.</p>
<p>But you can also just take these hard-coded transitions and put them into the
future. The hard-coded transitions take precedence over the footer. So the TZIF
folks:</p>
<ol>
<li>Picked a year far enough into the future (2086, as it turns out)</li>
<li>Wrote a script in
<a href="https://github.com/eggert/tz/blob/339e81d1ade620e70ecc78c2b4ec1309a6b80a2f/asia#L3494-L3512">emacs</a>
<a href="https://github.com/eggert/tz/blob/339e81d1ade620e70ecc78c2b4ec1309a6b80a2f/africa#L861-L878">lisp</a>
to calculate Ramadan</li>
<li>Use the output of that script to generate transitions for Morocco and Gaza</li>
</ol>
<p>And that’s why in practice Morocco and Gaza are just hard-coded in the tzdb,
unlike every other timezone.</p>
<p>In case you’re hoping for more fun timezones like this, I’m afraid you’re out of
luck. The others at the bottom of this list, which filters for transitions
beyond 2025, are just synonyms of Casablanca and Gaza.</p>
<pre tabindex="0"><code>$ find -L /var/db/timezone/tz/2024a.1.0/zoneinfo/ -type f | xargs -n1 ./tzdump | jq 'select(.Transitions[].TransitionTime &gt; 1735689600) | .ID' -r | uniq -c | sort -n
  26 /var/db/timezone/tz/2024a.1.0/zoneinfo//Africa/Cairo
...
  26 /var/db/timezone/tz/2024a.1.0/zoneinfo//US/Pacific
  26 /var/db/timezone/tz/2024a.1.0/zoneinfo//WET
  26 /var/db/timezone/tz/2024a.1.0/zoneinfo//posixrules
 130 /var/db/timezone/tz/2024a.1.0/zoneinfo//Africa/Casablanca
 130 /var/db/timezone/tz/2024a.1.0/zoneinfo//Africa/El_Aaiun
 184 /var/db/timezone/tz/2024a.1.0/zoneinfo//Asia/Gaza
 184 /var/db/timezone/tz/2024a.1.0/zoneinfo//Asia/Hebron
</code></pre><p>It looks like every other timezone just has 26 transitions beyond 2025, which I
think are just there to make software that doesn’t know about the TZIF footer
transition rules be accurate a few years into the future anyway.</p>
<h2 id="americanuuk-transitions-to-dst-at--1-oclock"><code>America/Nuuk</code> transitions to DST at -1 o’clock</h2>
<p><a href="https://en.wikipedia.org/wiki/Nuuk">Nuuk</a> is in
<a href="https://en.wikipedia.org/wiki/Iceland">Greenland</a>, and is part of the <a href="https://en.wikipedia.org/wiki/Special_territories_of_members_of_the_European_Economic_Area">greater
EU cinematic
universe</a>.</p>
<p>All of Europe (idk whether this is an EU/EEZ/EFTA/CoE thing) syncs up their
daylight savings, except for <a href="https://en.wikipedia.org/wiki/Greenland">Iceland</a>,
which doesn’t do DST at all (<code>Atlantic/Reykjavik</code>, which is technically <a href="https://github.com/eggert/tz/blob/7748036bace8562b9c047f368c8eba5f35e8c4b4/backward#L226">an
alias for
<code>Africa/Abidjan</code></a>,
is basically just UTC; their rule string is just <code>GMT0</code>).</p>
<p>Most Europeans are familiar with three major timezones, which we can refer to as
<code>Europe/Lisbon</code> (western), <code>Europe/Brussels</code> (central), and <code>Europe/Athens</code>
(eastern). They’re each one hour ahead of the other, and so their timezone
transitions look like:</p>
<pre tabindex="0"><code># I'm gonna space these out to highlight the symmetry,
# and also spell out the implicit "/2"

Europe/Lisbon:   WET0WEST ,M3.5.0/1,M10.5.0/2
Europe/Brussels: CET-1CEST,M3.5.0/2,M10.5.0/3
Europe/Athens:   EET-2EEST,M3.5.0/3,M10.5.0/4
</code></pre><p>In other words, Lisbon springs forward at 1am, Brussels at 2am, and Athens at
3am. But those times are <em>local</em>. In reality, they’re all at the same instant.</p>
<p>This makes good sense. It’s good for business that the time difference between
any two spots in Europe is always the same.</p>
<p>Greenland would like to be part of the action. Thing is, Greenland is pretty far
west of continental Europe. Whereas Lisbon’s standard time is UTC, Greenland’s
is 3 hours behind UTC. Here’s their daylight transition rules:</p>
<pre tabindex="0"><code>$ cat /var/db/timezone/tz/2024a.1.0/zoneinfo/America/Nuuk
&lt;-02&gt;2&lt;-01&gt;,M3.5.0/-1,M10.5.0/0
</code></pre><p>Take note of <code>M3.5.0/-1</code>. The first part is the standard European DST start day.
The <code>/-1</code> part? That means that instead of doing DST at like 2am (<code>/2</code>),
Greenland does it at -1 o’clock (<code>/-1</code>). The way the rules file is encoded,
daylight savings for Greenland is meant to happen on Sunday, but in fact happens
at 11pm on the Saturday before. Super weird.</p>
<p>I’m guessing this breaks software, because America/Nuuk and its aliases are one
of those timezones whose transition rules are just entirely ommitted in
<code>/usr/share/zoneinfo</code> on my Mac. They’re only available in other copies of tzdb
in <code>/var/db/timezone</code>.</p>
<h2 id="oh-americasantiago-and-africacairo-transition-at-24-oclock">Oh, <code>America/Santiago</code> and <code>Africa/Cairo</code> transition at 24 o’clock</h2>
<p>Nuuk is the earliest anyone does a transition. Santiago and Cairo are the
latest. They both do transitions at 24 o’clock? Like, the next day?</p>
<pre tabindex="0"><code>America/Santiago: &lt;-04&gt;4&lt;-03&gt;,M9.1.6/24,M4.1.6/24
</code></pre><pre tabindex="0"><code>Africa/Cairo: EET-2EEST,M4.5.5/0,M10.5.4/24
</code></pre><p>I think they’re both encoded like that because of weirdness in how the
governments define the rules. Like <code>M10.5.4/24</code> means “last Thurday of October,
24 o’clock”, which really means “the day after the last Thursday of October”.
But that’s not the same thing as “last Friday of October” if the month ends on
Thursday?</p>
<p>Both of these files are also in Mac’s list of naughty timezones that don’t go in
<code>/usr/share/zoneinfo</code>.</p>
<h2 id="australialord_howe-has-the-weirdest-dst-transition"><code>Australia/Lord_Howe</code> has the weirdest DST transition</h2>
<p>When you do a DST transition, you “spring forward” and “fall back”. <em>Surely</em>
everyone agrees it’s a <em>one-hour</em> jump, right?</p>
<p>Here’s a script to check. What is the time difference between standard and
daylight time in every timezone?</p>
<pre tabindex="0"><code>$ find -L /usr/share/zoneinfo -type f | xargs -n1 ./tzdump | jq 'if .Rules.DST == null then "\(.ID)\t0" else "\(.ID)\t\(.Rules.DST.LocalTimeType.UTCOffsetSeconds - .Rules.Std.LocalTimeType.UTCOffsetSeconds)" end' -r | sort -n -k 2 | uniq -c -f 1 | awk '{ print $1 "\t" $3 }'

410	0
2	1800
185	3600
1	7200
</code></pre><p>Hmm. 410 timezones just don’t DST at all. 185 have a 3600-second, i.e. 1-hour,
difference. And then there are the malcontents.</p>
<p>The 7200-second, i.e. 2-hour, jump is <code>Antarctica/Troll</code>. Fitting.</p>
<pre tabindex="0"><code>&lt;+00&gt;0&lt;+02&gt;-2,M3.5.0/1,M10.5.0/3
</code></pre><p>So during the winter (i.e. the northern summer) they use Norway time? But there
are <a href="https://en.wikipedia.org/wiki/Troll_(research_station)">like 6 people over the winter at
Troll</a>? Do these 6 souls
appreciate their contribution to software esoterica? I hope they do. Apparently
they use <a href="https://github.com/eggert/tz/blob/7748036bace8562b9c047f368c8eba5f35e8c4b4/antarctica#L212-L236">like four different times during the
year</a>
down there in practice, but there’s no syntax to express that.</p>
<p>OK but the real question is what’s up with the two 1800 transitions. They’re
synonyms for each other. It’s <code>Australia/Lord_Howe</code>, which has a <strong>powerful</strong>
30-minute DST transition:</p>
<pre tabindex="0"><code>&lt;+1030&gt;-10:30&lt;+11&gt;-11,M10.1.0,M4.1.0
</code></pre><p>10h30m ahead of UTC standard, 11h DST. Love this for them. Running cron jobs on
an hourly basis doesn’t in practice have very weird interactions with DST.
Everywhere else on the planet, every 60 minutes you’re back to the same spot on
the clock.</p>
<p>Except Lord Howe Island. Heroes. On the first Sunday of October, a 60-minute
timegap only puts you halfway around the clock. All your cron jobs are now
staggered relative to the local wall clock.</p>
<p>In case you’re curious, <a href="https://en.wikipedia.org/wiki/Lord_Howe_Island">Lord Howe
Island</a> belongs to Australia. It
has 382 people at the latest census. It’s a bit of a natural paradise, and
apparently to preserve that there’s a cap of 400 tourists at a time.</p>
<p>Probably the most famous aspect of Lord Howe is <a href="https://en.wikipedia.org/wiki/Ball%27s_Pyramid">Ball’s
Pyramid</a>.</p>
<figure>
<div>
<p><img src="https://ssoready.com/blog/engineering/truths-programmers-timezones/balls.png"></p><figcaption>Ball's Pyramid Memorial for Stickbugs and Software Engineers who write Timezone-related Code.</figcaption>
</div>
</figure>
<p>It’s an old collapsed volcano. It looks cool. It has some rare <a href="https://en.wikipedia.org/wiki/Ball%27s_Pyramid#Dryococelus_australis">stick
bugs</a>.</p>
<h2 id="big-takeaways">Big takeaways</h2>
<p>Timezones are weird, but finitely so. All they consist of is:</p>
<ul>
<li>An ID, e.g. <code>America/Los_Angeles</code></li>
<li>A set of hard-coded transitions, which range from the past into the future</li>
<li>A set of rules for how future transitions may happen</li>
</ul>
<p>Any given time in a timezone is just:</p>
<ul>
<li>An offset from UTC</li>
<li>With a “designator” time that doesn’t mean much</li>
<li>(This usually isn’t outputted anywhere) Whether the time is considered DST</li>
</ul>
<p>You can always uniquely identify what UTC time someone is referring to whenever
they tell you their timezone + local time + current time designator. The
timezone + designator gives you an offset, and you can apply the offset to the
local time to get UTC.</p>
<p>Like, it’s weird, it’s quirky, but it’s not like all bets are off.</p>
<p>Also:</p>
<ul>
<li>Don’t let people bully you into thinking that just because something is
complicated, it’s impossible.</li>
<li>This is because almost every standard (except ISO8601, whatever) is
just a file, and you can read it. You are smart. You can do it. Embrace
the weirdness of Greenland’s daylight savings. Believe in yourself.</li>
<li>If I were UN secretary general, I would kick out any countries that I deem
insufficiently considerate of Paul Eggert’s time.</li>
</ul>
<h2 id="appendix-other-weird-stuff-in-zoneinfo">Appendix: Other weird stuff in zoneinfo</h2>
<p>Honestly, there’s some stuff in zoneinfo that I can’t figure out. Even I have
nerd-sniping limits. Exercises for the reader.</p>
<p>These time zones have <em>hundreds</em> of hard-coded transitions out into the future.
I don’t understand why, it’s not like they all have lunar calendar stuff going
on.</p>
<ul>
<li>Asia/Jerusalem has 780 transitions in the future, out of 901 total</li>
<li>Africa/Cairo has 800 transitions in the future, out of 929 total</li>
<li>America/Nuuk has 800 transitions in the future, out of 889 total</li>
<li>America/Santiago has 800 transitions in the future, out of 931 total</li>
<li>Pacific/Easter has 800 transitions in the future, out of 911 total</li>
<li>Asia/Gaza has 982 transitions in the future, out of 1106 total</li>
</ul>
<p>They all lack a rules footer, but our friend Africa/Casablanca has a mere 132
transitions hard-coded and lacks a rules footer too. What’s up with that?</p>
<hr>
<p>P.S. If you’re the type of weird to think this stuff is neat: email me.
<a href="mailto:ulysse.carion@ssoready.com">ulysse.carion@ssoready.com</a> ;)</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wasmer 5.0 (178 pts)]]></title>
            <link>https://wasmer.io/posts/introducing-wasmer-v5</link>
            <guid>41990326</guid>
            <pubDate>Tue, 29 Oct 2024 23:02:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wasmer.io/posts/introducing-wasmer-v5">https://wasmer.io/posts/introducing-wasmer-v5</a>, See on <a href="https://news.ycombinator.com/item?id=41990326">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>We are thrilled to announce the release of <strong>Wasmer 5.0</strong>, the latest milestone in our journey to make WebAssembly the greatest tool for executing software anywhere.</p>
<p>This announcement comes packed with awesome new features:</p>
<ul>
<li>Experimental support for more backends: <strong>V8</strong>, <strong>Wasmi</strong> and <strong>WAMR</strong></li>
<li><strong>iOS</strong> support</li>
<li>Leaner codebase</li>
<li>Enhanced Performance</li>
<li>Upgraded Compilers (now using LLVM 18 and latest Cranelift)</li>
</ul>
<p>Do you like the new features? Don't wait and give us a ⭐️ on Github! <a href="https://github.com/wasmerio/wasmer">github.com/wasmerio/wasmer</a></p>
<hr>
<h2>Key Highlights</h2>
<h2>New experimental backends</h2>
<p>Some time ago <a href="https://github.com/wasmerio/wasmer/discussions/3839">we asked in Wasmer’s Community</a> which backend would you like to see Wasmer support next.</p>
<p>The responses were overwhelming: V8 (the engine behind Google’s Chrome Javascript runtime) was the most voted backend, with 56% of the votes. We learned from the poll results that interpreter support was also a desire from the community.</p>
<p><img src="https://wasmer.io/_next/image?url=https%3A%2F%2Fcdn.wasmer.io%2Fimages%2Fwasmer-backend-poll.original.png&amp;w=1920&amp;q=75" alt="Wasmer Backend Community Poll"></p>
<p>Well, the day has come. We have added support for more backends: V8, Wasmi and also WAMR. All of them are integrated via the <a href="https://github.com/WebAssembly/wasm-c-api">Wasm-C-API</a> , as they all share this external interface in common.</p>
<p>Thanks to the latest additions, now any interpreter or runtime that supports the Wasm-C-API spec can be easily integrated into Wasmer.</p>
<p>We expect that the V8 integration will allow bringing a great debugging experience via the V8 debugger and <a href="https://developer.chrome.com/docs/devtools/">Chrome Devtools</a>. But not only that, having V8 as a backend also means supporting WebAssembly Exceptions and Garbage Collection under the hood. Stay tuned for more news on this front soon.</p>
<p>As of today, Wasmer supports the following backends, so you can run WebAssembly using the Wasmer API in the following contexts:</p>
<ul>
<li><strong>Natively</strong> (via Wasmer native compilers)
<ul>
<li>Singlepass (<code>singlepass</code> feature): ideal for blockchains</li>
<li>Cranelift (<code>cranelift</code> feature): ideal for development</li>
<li>LLVM (<code>llvm</code> feature): ideal for production workloads</li>
</ul>
</li>
<li><strong>Browser</strong>: the browser’s underlying Wasm engine (<code>web</code> feature)
See <a href="https://github.com/wasmerio/wasmer-js">https://github.com/wasmerio/wasmer-js</a> for more info.</li>
<li><strong>JavascriptCore</strong>: JavascriptCore engine from Apple. Ideal if you want to use a lightweight and incredibly performant runtime in macOS (<code>jsc</code> feature)</li>
<li><strong>V8</strong>: Google’s JS V8 engine, ideal if you want to use Wasmer in iOS or Android (<code>v8</code> feature)</li>
<li><strong>Wasmi</strong>: one of the most optimal Rust WebAssembly interpreters. Ideal if you want to use Wasm in <code>nostd</code> environments or blockchains with a pure Rust codebase (<code>wasmi</code> feature)</li>
<li><strong>WAMR</strong>: (<code>wamr</code> feature) ideal for iOS</li>
</ul>
<p>So… how fast are each of the backends?</p>
<h3>Benchmarking the backends</h3>
<p>We have run an extensive set of benchmarks based on <a href="https://wasmi-labs.github.io/blog/posts/wasmi-v0.32/">Wasmi’s great benchmarking blogpost</a> to see how each of these backends behave for diverse scenarios. Here are our findings!</p>
<p><img src="https://wasmer.io/_next/image?url=https%3A%2F%2Fcdn.wasmer.io%2Fimages%2Fwasmer-5-time-argon2.original.png&amp;w=1920&amp;q=75" alt="Wasmer 5 Argon 2 benchmark"></p>
<p><img src="https://wasmer.io/_next/image?url=https%3A%2F%2Fcdn.wasmer.io%2Fimages%2Fwasmer-5-time-bulkops.original.png&amp;w=1920&amp;q=75" alt="Wasmer 5 Bulk Operations benchmark"></p>
<p><img src="https://wasmer.io/_next/image?url=https%3A%2F%2Fcdn.wasmer.io%2Fimages%2Fwasmer-5-time-counter.original.png&amp;w=1920&amp;q=75" alt="Wasmer 5 Counter benchmark"></p>
<p><img src="https://wasmer.io/_next/image?url=https%3A%2F%2Fcdn.wasmer.io%2Fimages%2Fwasmer-5-time-primes.original.png&amp;w=1920&amp;q=75" alt="Wasmer 5 Primes benchmark"></p>
<p><img src="https://wasmer.io/_next/image?url=https%3A%2F%2Fcdn.wasmer.io%2Fimages%2Fwasmer-5-time-fibonacci-iterative.original.png&amp;w=1920&amp;q=75" alt="Wasmer 5 Fibonacci (iterative) benchmark"></p>
<p><img src="https://wasmer.io/_next/image?url=https%3A%2F%2Fcdn.wasmer.io%2Fimages%2Fwasmer-5-time-fibonacci-recursive.original.png&amp;w=1920&amp;q=75" alt="Wasmer 5 Fibonacci (recursive) benchmark"></p>
<p><img src="https://wasmer.io/_next/image?url=https%3A%2F%2Fcdn.wasmer.io%2Fimages%2Fwasmer-5-time-matmul.original.png&amp;w=1920&amp;q=75" alt="Wasmer 5 Matmul benchmark"></p>
<h2>Full iOS Support via WAMR, Wasmi and V8 bindings</h2>
<p>For the first time, Wasmer brings WebAssembly to <strong>iOS</strong> devices through a new interpreted mode.</p>
<p><img src="https://wasmer.io/_next/image?url=https%3A%2F%2Fcdn.wasmer.io%2Fimages%2Fwasmer-5-ios-new.original.png&amp;w=1920&amp;q=75" alt="Wasmer 5 Running on iOS"></p>
<p>About a year ago we added support for <a href="https://wasmer.io/posts/wasmer-3_3-and-javascriptcore">JavacriptCore in Wasmer</a>, with the hope that it would enable a fast runtime on iOS (since the JIT would be unrestricted). Unfortunately, iOS capped the ability of using WebAssembly via JavascriptCore (since iOS 14).</p>
<p>Leveraging the capabilities of <strong>V8</strong>, <strong>Wasmi</strong> and <strong>WebAssembly Micro Runtime (WAMR)</strong>, developers can now run WebAssembly modules seamlessly on iOS thanks to Wasmer 5.0. No changes needed on their codebase. This opens up a world of possibilities for mobile development, enabling high-performance applications on Apple's ecosystem.</p>
<p>We want to thank <a href="https://www.holochain.org/">Holochain</a> as this work wouldn’t be possible without our partnership.</p>
<h2>Leaner codebase</h2>
<p>For the release of Wasmer 5.0 we have put an special emphasis on making Wasmer codebase as lean as possible, so we can develop new features even faster.</p>
<p>As part of this effort, we realized that:</p>
<ul>
<li>Emscripten bindings have been mostly unused in the last two years, mainly influenced by these two factors:
<ul>
<li>Emscripten emits code using WASI systemcalls under the hood when possible, removing the need for having special bindings for Emscripten</li>
<li><a href="https://wasix.org/">WASIX</a> helps to bridge the gap of the WASI systemcalls that are not supported (<code>threads</code>, <code>longjmp/setjmp</code>, <code>fork</code>, …)</li>
</ul>
</li>
<li>Some of the dependencies Wasmer used have been long unmaintained, or duplicated by newer and safer crates</li>
</ul>
<p>Because of that, we decided to drop support for Emscripten and trimmed up the dependencies resulting in a net result of <strong>20k lines of code deleted</strong> in the Wasmer codebase.</p>
<h2>Enhanced Performance</h2>
<p>Module deserialization now is up to 50% faster (that is, when you call <code>Module::deserialize</code> or when you run a module via <code>wasmer run</code>).</p>
<p>Performance is at the heart of Wasmer, and version 5.0 takes it to the next level. These improvements are leveraging essential updates on <strong>rkyv:</strong> the zero-copy deserialization library that we use to deserialize our Modules.</p>
<p>Here’s a benchmark of all the backends using latest Wasmer vs the latest release.</p>
<p><img src="https://wasmer.io/_next/image?url=https%3A%2F%2Fcdn.wasmer.io%2Fimages%2Fwasmer-5-time-deserialize.original.png&amp;w=1920&amp;q=75" alt="Wasmer 5 Time to deserialize a WebAssembly module"></p>
<h2>Upgraded Compilers: Cranelift  and LLVM 18</h2>
<p>The latest Cranelift integration results in significant runtime speed improvements, making your WebAssembly modules execute faster than ever before.</p>
<p>Wasmer 5.0 now includes the most recent version of <strong>LLVM (18)</strong>, ensuring that developers have access to the latest optimizations from the toolchain. The LLVM upgrade enhances compatibility and performance, providing a robust foundation for compiling and running complex WebAssembly modules.</p>
<p>On top of that, Wasmer 5.0 also ships with experimental <em>LoongAarch64</em> support.</p>
<p>We have also benchmarked <code>coremark</code> with the latest version of the compilers to see how they compare:
<img src="https://wasmer.io/_next/image?url=https%3A%2F%2Fcdn.wasmer.io%2Fimages%2Fwasmer-5-time-coremark.original.jpg&amp;w=1920&amp;q=75" alt="Wasmer 5 Coremark results"></p>
<blockquote>
<p>LLVM and Cranelift are about 8% faster in Wasmer v5.0 compared to v4.4.0</p>
</blockquote>
<h2>Getting Started with Wasmer 5.0</h2>
<p>Ready to dive in? Here's how you can start exploring the new features:</p>
<ul>
<li><strong>Download Wasmer 5.0</strong>: Get the latest version from our <a href="https://wasmer.io/">official website</a>.</li>
<li><strong>Update Your Projects</strong>: Upgrade your existing Wasmer projects to leverage the new capabilities.</li>
<li><strong>Explore the Documentation</strong>: Visit our updated docs for detailed guides and tutorials.</li>
<li><strong>Join the Community</strong>: Connect with other developers on our Discord server and share your experiences.</li>
</ul>
<h2>Looking Ahead</h2>
<p>Wasmer 5.0 is a significant step forward in our mission to empower developers thanks of the exciting possibilities that WebAssembly brings to the table. With iOS support, our pluggable backend architecture and the enhanced performance, the possibilities are now endless. We can't wait to see what you'll build next with Wasmer.</p>
<hr>
<p><strong>Stay Updated</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://wasmer.io/">wasmer.io</a></li>
<li><strong>GitHub</strong>: <a href="https://github.com/wasmerio/wasmer">github.com/wasmerio/wasmer</a></li>
<li><strong>Twitter</strong>: <a href="https://twitter.com/wasmerio">@wasmerio</a></li>
<li><strong>Discord</strong>: <a href="https://discord.gg/rWkMNStrEW">Join our community</a></li>
</ul>
<p>Thank you everyone for being part of the Wasmer journey!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RIP botsin.space (153 pts)]]></title>
            <link>https://muffinlabs.com/posts/2024/10/29/10-29-rip-botsin-space/</link>
            <guid>41989511</guid>
            <pubDate>Tue, 29 Oct 2024 21:18:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://muffinlabs.com/posts/2024/10/29/10-29-rip-botsin-space/">https://muffinlabs.com/posts/2024/10/29/10-29-rip-botsin-space/</a>, See on <a href="https://news.ycombinator.com/item?id=41989511">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">
      <main>
        


<p>There's no easy way to put it, so here goes -- after a lot of consideration, I've made the hard (frankly, painful) decision to shut down botsin.space. TLDR: here's the plan:</p>
<ul>
<li>Effective immediately I'm shutting down new account signups</li>
<li>I will switch the site into read-only mode sometime not long after December 15th.</li>
<li>I'll do everything I can to help people migrate their accounts elsewhere, and/or generate archives.</li>
<li>I'll keep the site running in read-only mode at least into March of 2025, and if possible/needed I'll extend that as long as I can.</li>
</ul>
<h2>Why?</h2>
<p>I launched botsin.space in April of 2017, which honestly feels like it was about six thousand years ago. Originally I just wanted to play around with the fediverse and Mastodon. The oauth flow for creating a bot was messy, so I forked Mastodon and fixed it, deployed those changes to botsin.space, and invited people to create bots.</p>
<p>The server was popular with bot allies and artists, people who wanted to get RSS feeds onto the fediverse, as well as students and professors who wanted to work on coding projects or learn about federated social media. There have been some moderation challenges over the years, but to be honest those have never been all that considerable.</p>
<p>But botsin.space has always been a bit of an odd duck with a unique set of challenges. Over the years, the server has grown to have around a few thousand active accounts, which isn't all that many. However, they've generated something like 32 million statuses. Just to put that in perspective, mastodon.social has over 2 million users, who have generated around 110 million statuses. So the usage patterns are very different, and I think it's safe to say the the mastodon codebase is tuned for mastodon.social and not a weird freaky server like botsin.space.</p>
<p>I work on the internet professionally, use Rails at my day job, and server management is part of my job description, so I've been able to use my skills to keep botsin.space running on a relative shoestring budget. Until recently, the whole thing ran on one server. But that's not maintainable, and given that and some other concerns, I think that now is the time to retire the server.</p>
<p>There are four major expenses for botsin.space, in order from least to most expensive:</p>
<ol>
<li>My time. As long as I find managing the server rewarding, this is an expense I'm happy to pay.</li>
<li>Server costs. I've been able to be fairly cheap here until recently.</li>
<li>Database storage. The database for the server lives on a dedicated volume at Digital Ocean, and is currently around 191GB in size. Every time I need to increase the size of this volume, the expense goes up, and it's safe to assume that this will only continue to grow.</li>
<li>File storage and bandwidth. These expenses will also only get more expensive over time. File bandwidth is the #1 charge on the monthly server bill right now. I live in fear of an AI scraper figuring out how to scrape all of these files and bankrupting me overnight.</li>
</ol>
<p>Until recently, my thinking has been: "I'm cool with finding all sorts of weird tricks to keep the server going, and I'll worry about #3 and #4 someday in the future maybe lalalalala I can't hear you." But the recent Mastodon upgrade has caused a significant amount of performance degradation, and I think the only way to really solve it is going to be to throw a lot of money into hardware.</p>
<p>I should mention at this point that I've had a Patreon to help with server expenses, and I've also accepted Paypal donations, and I'm truly grateful for everyone who has ever sent me money to support the server.</p>
<p>However, even with the support, expenses have always outpaced the donations, and while that's been fine with me for a long time, it's not sustainable. I'm fortunate enough to have a career and life where I've been able to support botsin.space, but I can't do it forever, and as the expenses and challenges mount, I find myself thinking about things that I'd probably rather be doing with my time.</p>
<p>With a few exceptions, botsin.space isn't anyone's primary instance, and I've always been mindful of the fact that everyone who supports botsin.space financially has other places and people to think of also, and I am so thankful for the consideration. I hope that everyone who is currently supporting botsin.space finds another instance to support, there are a lot of great instances out there with vibrant communities that need all the help they can get to survive.</p>
<p>So, given two choices -- asking for more donations so I can pay for more hardware to keep the instance running, or retiring it and encouraging people to support more community-oriented instances, I'll choose the second option every time.</p>
<p>As I mentioned above, I'll be working to keep the server stable and running for as long as possible, to give people a chance to migrate their accounts, get archives, etc. If anyone has any questions, please feel free to contact me at <a href="https://muffin.industries/@colin">@colin@muffin.industries</a>. It's probably smarter to ping me there instead of at botsin.space, because it's more likely that your message will be delivered in a timely fashion.</p>
<p>I'd like to thank everyone who has ever run a bot on botsin.space and gotten joy out of it. I'd like to thank all the people who have ever shared their thanks or kind words with me online -- your support has meant the world to me. I'd like to thank all the #botALLY folks, who have been a constant source of inspiration and learning to me for over a decade. Finally, I'd like to thank Johanna, who has always been there for me &lt;3</p>


       </main>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GLP-1 for Everything (140 pts)]]></title>
            <link>https://www.science.org/content/blog-post/glp-1-everything</link>
            <guid>41988285</guid>
            <pubDate>Tue, 29 Oct 2024 19:15:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/blog-post/glp-1-everything">https://www.science.org/content/blog-post/glp-1-everything</a>, See on <a href="https://news.ycombinator.com/item?id=41988285">Hacker News</a></p>
Couldn't get https://www.science.org/content/blog-post/glp-1-everything: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[PhD student finds lost city in Mexico jungle (154 pts)]]></title>
            <link>https://www.bbc.com/news/articles/crmznzkly3go</link>
            <guid>41988171</guid>
            <pubDate>Tue, 29 Oct 2024 19:04:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/crmznzkly3go">https://www.bbc.com/news/articles/crmznzkly3go</a>, See on <a href="https://news.ycombinator.com/item?id=41988171">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p data-component="headline-block"><h2>PhD student finds lost city in Mexico jungle by accident<!-- --></h2></p><p data-component="caption-block"><figcaption>What discovered Mayan city Valeriana might have looked ike<!-- --></figcaption></p><div data-component="text-block"><p>A huge Maya city has been discovered centuries after it disappeared under jungle canopy in Mexico.<!-- --></p><p>Archaeologists found pyramids, sports fields, causeways connecting districts and amphitheatres in the southeastern state of Campeche.<!-- --></p><p><a target="_self" href="https://www.bbc.co.uk/news/av/world-africa-45836912">They uncovered the hidden complex<!-- --></a> - which they have called Valeriana - using Lidar, a type of laser survey that maps structures buried under vegetation.<!-- --></p><p>They believe it is second in density only to Calakmul, thought to be the largest Maya site in ancient Latin America.<!-- --></p><p>The team discovered three sites in total, in a survey area the size of Scotland's capital Edinburgh, “by accident” when one archaeologist browsed data on the internet.<!-- --></p></div><div data-component="text-block"><p>“I was on something like page 16 of Google search and found a laser survey done by a Mexican organisation for environmental monitoring,” explains Luke Auld-Thomas, a PhD student at Tulane university in the US.<!-- --></p><p>It was a Lidar survey, a remote sensing technique which fires thousands of laser pulses from a plane and maps objects below using the time the signal takes to return.<!-- --></p><p>But when Mr Auld-Thomas processed the data with methods used by archaeologists, he saw what others had missed - a huge ancient city which may have been home to 30-50,000 people at its peak from 750 to 850 AD.<!-- --></p><p>That is more than the number of people who live in the region today, the researchers say.<!-- --></p><p>Mr Auld-Thomas and his colleagues named the city Valeriana after a nearby lagoon.<!-- --></p><p>The find helps change an idea in Western thinking that the Tropics was where “civilisations went to die”, says Professor Marcello Canuto, a co-author in the research. <!-- --></p><p>Instead, this part of the world was home to rich and complex cultures, he explains.<!-- --></p><p>We can’t be sure what led to the demise and eventual abandonment of the city, but the archaeologists say climate change was a major factor.<!-- --></p></div><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/443d/live/f774e910-95b8-11ef-bf59-99b64fa9486e.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/443d/live/f774e910-95b8-11ef-bf59-99b64fa9486e.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/443d/live/f774e910-95b8-11ef-bf59-99b64fa9486e.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/443d/live/f774e910-95b8-11ef-bf59-99b64fa9486e.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/443d/live/f774e910-95b8-11ef-bf59-99b64fa9486e.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/443d/live/f774e910-95b8-11ef-bf59-99b64fa9486e.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/443d/live/f774e910-95b8-11ef-bf59-99b64fa9486e.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/443d/live/f774e910-95b8-11ef-bf59-99b64fa9486e.jpg.webp" loading="lazy" alt="Getty Images A photograph of the Calakmul Mayan temple pyramid ruins in Campeche, Mexico"><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>There are no pictures of the city but it had pyramid temples similar to this one in nearby Calakmul<!-- --></figcaption></p></figure><div data-component="text-block"><p>Valeriana has the “hallmarks of a capital city” and was second only in density of buildings to the spectacular Calakmul site, around 100km away (62 miles).<!-- --></p><p><a target="_self" href="https://www.bbc.co.uk/news/world-latin-america-46374651">It is “hidden in plain sight”<!-- --></a>, the archaeologists say, as it is just 15 minutes hike from a major road near Xpujil where mostly Maya people now live.<!-- --></p><p>There are no known pictures of the lost city because “no-one has ever been there”, the researchers say, although local people may have suspected there were ruins under the mounds of earth.<!-- --></p><p>The city, which was about 16.6 sq km, had two major centres with large buildings around 2km (1.2 miles) apart, linked by dense houses and causeways. <!-- --></p><p>It has two plazas with temple pyramids, where Maya people would have worshipped, hidden treasures like jade masks and buried their dead.<!-- --></p><p>It also had a court where people would have played an ancient ball game.<!-- --></p><ul><li><a target="_self" href="https://www.bbc.com/future/article/20241028-lost-cities-how-maya-ruins-have-withstood-the-test-of-time">How ancient Maya cities have withstood the ravages of time<!-- --></a></li></ul><p>There was also evidence of a reservoir, indicating that people used the landscape to support a large population.<!-- --></p><p>In total, Mr Auld-Thomas and Prof Canuto surveyed three different sites in the jungle. They found 6,764 buildings of various sizes.<!-- --></p></div><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/b5eb/live/3a18f290-953a-11ef-89ae-5575c76d98e6.png.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/b5eb/live/3a18f290-953a-11ef-89ae-5575c76d98e6.png.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/b5eb/live/3a18f290-953a-11ef-89ae-5575c76d98e6.png.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/b5eb/live/3a18f290-953a-11ef-89ae-5575c76d98e6.png.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/b5eb/live/3a18f290-953a-11ef-89ae-5575c76d98e6.png.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/b5eb/live/3a18f290-953a-11ef-89ae-5575c76d98e6.png.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/b5eb/live/3a18f290-953a-11ef-89ae-5575c76d98e6.png.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/b5eb/live/3a18f290-953a-11ef-89ae-5575c76d98e6.png.webp" loading="lazy" alt="An illustration showing a map of Valeriana and its location in Mexico."></p></div><p data-component="caption-block"><figcaption>The ruins were found in eastern Mexico, in Campeche<!-- --></figcaption></p></figure><div data-component="text-block"><p>Professor Elizabeth Graham from University College London, who was not involved in the research, says it supports claims that Maya lived in complex cities or towns, not in isolated villages.<!-- --></p><p>"The point is that the landscape is definitely settled - that is, settled in the past - and not, as it appears to the naked eye, uninhabited or ‘wild’," she says.<!-- --></p><p>The research suggests that when Maya civilisations collapsed from 800AD onwards, it was partly because they were so densely populated and could not survive climate problems.<!-- --></p><p>"It's suggesting that the landscape was just completely full of people at the onset of drought conditions and it didn't have a lot of flexibility left. And so maybe the entire system basically unravelled as people moved farther away," says Mr Auld-Thomas.<!-- --></p><p>Warfare and the conquest of the region by Spanish invaders in the 16th century also contributed to eradication of Maya city states.<!-- --></p></div><figure><div data-component="image-block"><p><img src="https://www.bbc.com/bbcx/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/17e5/live/a587fba0-9541-11ef-89ae-5575c76d98e6.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/17e5/live/a587fba0-9541-11ef-89ae-5575c76d98e6.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/17e5/live/a587fba0-9541-11ef-89ae-5575c76d98e6.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/17e5/live/a587fba0-9541-11ef-89ae-5575c76d98e6.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/17e5/live/a587fba0-9541-11ef-89ae-5575c76d98e6.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/17e5/live/a587fba0-9541-11ef-89ae-5575c76d98e6.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/17e5/live/a587fba0-9541-11ef-89ae-5575c76d98e6.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/17e5/live/a587fba0-9541-11ef-89ae-5575c76d98e6.jpg.webp" loading="lazy" alt="Getty Images Majestic Mayan Pyramid 1 at Calakmul rises above the breathtaking Jungle Canopy for as far as the eye can see on a beautiful day in the Calakmul Biosphere Reserve in Campeche Mexico"><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>Evidence of the ruins were found by a plane using laser remote sensing to map beneath the jungle canopy<!-- --></figcaption></p></figure><p data-component="subheadline-block"><h2>Many more cities could be found<!-- --></h2></p><div data-component="text-block"><p>Lidar technology has revolutionised how archaeologists survey areas covered in vegetation, like the Tropics, opening up a world of lost civilisations, explains Prof Canuto.<!-- --></p><p>In the early years of his career, surveys were done by foot and hand, using simple instruments to check the ground inch by inch.<!-- --></p><p>But in the decade since Lidar was used in the Mesoamerican region, he says it’s mapped around 10 times the area that archaeologists managed in about a century of work.<!-- --></p><p>Mr Auld-Thomas says his work suggests there are many sites out there that archaeologists have no idea about.<!-- --></p><p>In fact so many sites have been found that researchers cannot hope to excavate them all.<!-- --></p><p>"I've got to go to Valeriana at some point. It's so close to the road, how could you not? But I can't say we will do a project there," says Mr Auld-Thomas. <!-- --></p><p>"One of the downsides of discovering lots of new Maya cities in the era of Lidar is that there are more of them than we can ever hope to study," he adds.<!-- --></p><p>The research is published in the academic journal Antiquity.<!-- --></p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Digging into PlantStudio, a Bit Late (121 pts)]]></title>
            <link>https://pketh.org/plantstudio.html</link>
            <guid>41988030</guid>
            <pubDate>Tue, 29 Oct 2024 18:49:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pketh.org/plantstudio.html">https://pketh.org/plantstudio.html</a>, See on <a href="https://news.ycombinator.com/item?id=41988030">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>This aesthetic screenshot of an old windows app has been in my <a href="https://pketh.org/decade-of-inspiration.html">inspiration space</a> for ~5 years. Until recently, I assumed that it was just a nostalgia bait concept.</p>

<p><img src="https://pketh.org/images/2024/plantstudio/screenMainWindow.gif"></p>

<p>The calm, serene life associated with gardening pairs suspiciously well with rose-tinted wistfulness for a simpler time in computing. I’m happy to be wrong though, because software doesn’t get more real than <a href="https://www.kurtz-fernhout.com/PlantStudio/">PlantStudio</a>.</p>

<p>Written by Kurtz-Fernhout Software, PlantStudio is a surprisingly deep botany simulator for creating and arranging 3D models of <a href="https://www.kurtz-fernhout.com/PlantStudio/help/plantstudioWhat_is_a_herbaceous_plant.html">herbaceous</a> plants based on how real plants grow, change, fruit, and flower, over their life cycles.</p>

<h2 id="how-to-install">How to Install</h2>

<p>Because the last release of the app was in 2002, and it was for Windows 95/98/2000/NT4, we’ve got a little bit of work to do to get it running on macOS:</p>

<p><img src="https://pketh.org/images/2024/plantstudio/sample-flowers.webp" width="150"></p>

<ol>
  <li><a href="https://www.kurtz-fernhout.com/download_new.html">Download <code>PlantStudio210.zip</code></a> and unzip it</li>
  <li><a href="https://getwhisky.app/">Download Whisky</a> to run windows code in a container called a <code>bottle</code></li>
  <li>In Whisky, click <code>+</code> button to create a new bottle (I set it to Windows 10)</li>
  <li>Click <code>Open C: Drive</code> and copy the <code>PlantStudio210</code> folder into <code>Program Files</code></li>
  <li>Click <code>Run</code> and open <code>Program Files/PlantStudio210/PlantStudio.exe</code></li>
</ol>

<p>PlantStudio lives again 🌱🌺</p>

<h2 id="lets-grow-some-3d-plants">Let’s Grow Some 3D Plants</h2>

<p>After you read or skip the tutorial docs, you’re be greeted with an empty window, which is kind of like the ‘garden’ that your plants will live in. One way to jump in is to <code>File → Open</code> some sample files.</p>

<p>The interface is full of unlabelled and unfamiliar icons, but the hover tooltips in PlantStudio are the most verbose I’ve ever seen – which helps a lot.</p>

<figure>
  <img src="https://pketh.org/images/2024/plantstudio/tutorial-tooltip-cropped.webp">
  <figcaption>
    Rotate mode tooltip
  </figcaption>
</figure>

<p>To fill the garden with our own herbs, shrubs, and flowers, use <code>Plant → Create New…</code> which opens the thorough 10-step <code>Plant Wizard</code>, and teaches us some biology terms along the way.</p>


<figure>
  <figcaption>
    Going through the Plant Wizard…
  </figcaption>
</figure>

<p>Each option button has a detailed little illustration that makes the impacts of technical concepts, like ‘inflorescence’, easy to understand.</p>

<p><img src="https://pketh.org/images/2024/plantstudio/button-illustrations.webp"></p>

<p>I also love the wizard progress icons in the footer. Because the colors match the button illustrations, it’s easy to jump from editing stems and leaves (green icons), to editing flower related options (purple icons). The start and stop traffic lights for the intro and confirmation steps serve as cute bookends.</p>



<blockquote>
  <p>Designers can use color to conceptually link related interfaces together. I did this when I <a href="https://pketh.org/redesigning-an-app.html">redesigned Futureland</a> a couple years ago.</p>
</blockquote>

<p>One thing I kept wishing for while creating plants was the ability to see a live preview while I was selecting options. Maybe they didn’t think of that, or maybe the performance impacts would’ve been too much for the minimum required 100MHz CPU of the day.</p>

<h2 id="cultivating-a-garden">Cultivating a Garden</h2>

<p>As you create plants, they’ll appear in the garden area, where you can arrange them by scaling, rotating, editing, posing, and even changing their age.</p>



<p>It took awhile, but by repeatedly creating plants in the wizard and arranging each one, even I could make something pleasant enough:</p>

<p><img src="https://pketh.org/images/2024/plantstudio/my-garden.webp"></p>

<p>I could’ve probably saved some time by selecting one or multiple plants to <code>Plant → Breed</code> to create offspring. The <code>Breeder</code> lets you define how similar the children are from their parents, and adjust the amount of mutation (random chance changes).</p>

<p><img src="https://pketh.org/images/2024/plantstudio/breeder2.webp"></p>

<h2 id="export-options">Export Options</h2>

<p>You can be creative with your plants models by exporting <code>jpg</code>, <code>3ds</code>, or <code>obj</code> files into other art apps. The <a href="https://www.kurtz-fernhout.com/PlantStudio/gallery.htm">official Gallery</a> has a couple y2k-era masterpieces that were composed with whimsical 3D tools like <a href="https://theinnerframe.org/2015/02/14/bryce-3d-an-epitaph/">Bryce</a>, and then polished in 2D art tools like Paintshop Pro and Photoshop.</p>

<figure>
  <img src="https://pketh.org/images/2024/plantstudio/fairy_flowers.jpg">
  <figcaption>
    Artist's note: "I created this picture with Metacreations Poser3, Bryce3 and Photoshop5. I used Photoshop5 to give the violet leaves some texture, and refined the shape of the leaves and petals..."
    <a href="https://www.kurtz-fernhout.com/PlantStudio/gallery_fairyflowers.htm">(source)</a>
  </figcaption>
</figure>

<p>The process for making these images is strikingly similar to what landscape architects do today. Much like how software designers use mockups, architects use 3D renderings to convince clients, to market their work, and as a starting point for working with contractors.</p>

<p><img src="https://pketh.org/images/2024/plantstudio/plantkind.webp"></p>
<figure>
  <figcaption>
    <a href="https://plantkind.earth/">(source, Plantkind)</a>
  </figcaption>
</figure>

<blockquote>
  <div><p>Also, plants look really cool inside <a href="https://kinopio.club/-inspiration--PvOMf-lSAIAC9INOu8_Ex">Kinopio spaces</a>. Maybe I’ll figure out some kind of ‘integration’ in the future…</p><p>
<img src="https://pketh.org/images/2024/plantstudio/in-kinopio-space.webp" alt=""></p></div>
</blockquote>

<h2 id="so-why-am-i-only-finding-out-about-plantstudio-now">So Why Am I Only Finding Out About Plantstudio Now?</h2>

<p>The husband and wife duo <a href="http://pdfernhout.net/">Paul Fernhout</a> and <a href="http://www.cfkurtz.com/">Cynthia Kurtz</a> were the authors behind Kurtz-Fernhout Software. Unsurprisingly, both have degrees in Biology and Ecology.</p>

<p>Their <a href="https://www.kurtz-fernhout.com/historyandfuture.htm">original goal</a> was to build a gardening simulator to “help people understand how to garden in a more sustainable way in their own backyards”. The simulation was based the EPIC (Erosion/Productivity Impact Calculator) agricultural model by the USDA Agricultural Research Service.</p>

<blockquote>
  <p>We worked as a team on most design phases of the project. Paul did most of the low-level coding, the general architecture, the undo/redo system, the file system, the graphical display, and the 3D turtle engine. Cynthia did most of the translation of the EPIC model, the flowering/fruiting submodel, the plant drawing algorithm, the various window designs, and the artwork, music, and documentation.</p>
</blockquote>

<p>PlantStudio was originally built to draw plants for the gardening simulator, but they “found that everyone tended to like the plant designer so much they wanted to play with it instead of with the garden simulator”, so released it separately.</p>

<p>Not entirely dissimilar to the story behind <a href="https://arstechnica.com/gaming/2015/10/from-simcity-to-well-simcity-the-history-of-city-building-games/">SimCity</a>,</p>

<blockquote>
  <p>While developing his first commercial game […], Will Wright noticed that designing city maps for the player to fly over in a helicopter was more fun than actually [playing the game]. He began expanding his world-building tools as an experiment. He applied various urban planning and computer modelling theories, implementing whatever ideas he’d been reading.</p>
</blockquote>

<p><img src="https://pketh.org/images/2024/plantstudio/simcity-windows-lgr.webp"></p>
<figure>
  <figcaption>
    Sticking to the theme, SimCity for Windows
    <a href="https://www.youtube.com/watch?v=TrScy1icWjI">(source)</a>
  </figcaption>
</figure>

<p>Unfortunately, PlantStudio was <a href="https://www.kurtz-fernhout.com/press.htm">discontinued</a> in 2002,</p>

<blockquote>
  <p>What happened to our old software and the plans for it? We spent years working for other people to pay off money (with interest) we borrowed to finish it and free it.</p>
</blockquote>

<p>I empathize with their story because the world is rarely kind to <a href="https://pketh.org/organic-software.html">organic</a> niche creative consumer software. I’m sure the market at the time was a lot more developer friendly overall, but businesses need to always be reaching new people to sell more licenses.</p>

<p>In an alternate universe, maybe PlantStudio could have survived by evolving into a game in the vein of SimCity and SimEarth, e.g. ‘SimGarden’.</p>

<h2 id="incidental-beauty">Incidental Beauty</h2>

<p>There’s something appealing about objects and interfaces built for purpose, like race cars and professional-use espresso machines. In cases like these, beauty feels like a byproduct of an object built to do it’s job well – and there’s something appealingly genuine about that.</p>

<figure>
  <img src="https://pketh.org/images/2024/plantstudio/26marzocco.webp">
  <figcaption>
    Back when I worked at <a href="https://www.joelonsoftware.com/2010/01/26/why-testers">Fog Creek Software</a> there was a $10k Marzocco professional espresso machine in the break room that we were trained on as part of our onboarding. I don’t even like espresso, but I do miss using it sometimes.
  </figcaption>
</figure>

<p>I’d describe PlantStudio the same way. It doesn’t look or work like a modern app, but anyone can figure it out because it’s interface elements are delightfully chunky, unfussy, and well documented by illustrations, inline text, and tooltips.</p>

<p>It’s definetely not for everyone, but the best things rarely are. Creating those gardens gave me a new perspective – and some new ideas – for my own design work.</p>

<p>It took a while, but I’m glad I found PlantStudio.</p>

<p><img src="https://pketh.org/images/2024/plantstudio/sample-flowers2.webp"></p>

<blockquote>
  <p>Special thanks to Ethan from <a href="https://plantkind.earth/">Plantkind</a> for giving me a bit of insight into his landscape architecture practice for this post.</p>
</blockquote>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI builds first chip with Broadcom and TSMC, scales back foundry ambition (264 pts)]]></title>
            <link>https://www.reuters.com/technology/artificial-intelligence/openai-builds-first-chip-with-broadcom-tsmc-scales-back-foundry-ambition-2024-10-29/</link>
            <guid>41986926</guid>
            <pubDate>Tue, 29 Oct 2024 17:19:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/artificial-intelligence/openai-builds-first-chip-with-broadcom-tsmc-scales-back-foundry-ambition-2024-10-29/">https://www.reuters.com/technology/artificial-intelligence/openai-builds-first-chip-with-broadcom-tsmc-scales-back-foundry-ambition-2024-10-29/</a>, See on <a href="https://news.ycombinator.com/item?id=41986926">Hacker News</a></p>
Couldn't get https://www.reuters.com/technology/artificial-intelligence/openai-builds-first-chip-with-broadcom-tsmc-scales-back-foundry-ambition-2024-10-29/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Using an 8K TV as a Monitor (379 pts)]]></title>
            <link>https://daniel.lawrence.lu/blog/y2023m12d15/</link>
            <guid>41986048</guid>
            <pubDate>Tue, 29 Oct 2024 16:27:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daniel.lawrence.lu/blog/y2023m12d15/">https://daniel.lawrence.lu/blog/y2023m12d15/</a>, See on <a href="https://news.ycombinator.com/item?id=41986048">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header><div><ol><li><a href="#s1"><span>1</span> <span>Pros of using an 8K display</span></a><ol><li><a href="#s1.1"><span>1.1</span> <span>For programming, word processing, etc</span></a></li><li><a href="#s1.2"><span>1.2</span> <span>For photo and video editing</span></a></li><li><a href="#s1.3"><span>1.3</span> <span>For CAD work</span></a></li><li><a href="#s1.4"><span>1.4</span> <span>For gaming/media</span></a></li><li><a href="#s1.5"><span>1.5</span> <span>Cost</span></a></li><li><a href="#s1.6"><span>1.6</span> <span>Connectivity</span></a></li></ol></li><li><a href="#s2"><span>2</span> <span>Potential cons and caveats</span></a><ol><li><a href="#s2.1"><span>2.1</span> <span>Desk and mounting</span></a></li><li><a href="#s2.2"><span>2.2</span> <span>Image quality issues</span></a><ol><li><a href="#s2.2.1"><span>2.2.1</span> <span>Uniformity</span></a></li><li><a href="#s2.2.2"><span>2.2.2</span> <span>Checkerboard effect</span></a></li></ol></li><li><a href="#s2.3"><span>2.3</span> <span>Random software issues</span></a><ol><li><a href="#s2.3.1"><span>2.3.1</span> <span>Nvidia Linux drivers</span></a></li><li><a href="#s2.3.2"><span>2.3.2</span> <span>AMD Linux drivers</span></a></li><li><a href="#s2.3.3"><span>2.3.3</span> <span>Input Signal Plus</span></a></li><li><a href="#s2.3.4"><span>2.3.4</span> <span>Wake up bugs</span></a></li><li><a href="#s2.3.5"><span>2.3.5</span> <span>Having another DisplayPort device</span></a></li></ol></li><li><a href="#s2.4"><span>2.4</span> <span>Display types</span></a></li><li><a href="#s2.5"><span>2.5</span> <span>Coatings</span></a></li></ol></li><li><a href="#s3"><span>3</span> <span>Example devices</span></a></li><li><a href="#s4"><span>4</span> <span>FAQ</span></a></li></ol></div></header><div><figure id="fig1"><a href="https://i.dllu.net/IMG_0043_09ae9580aa76352c.jpg"><img src="https://i.dllu.net/IMG_0043_1200_d9403825ac2b72fc.jpg" alt="A Samsung QN800A. "></a><figcaption><a href="#fig1">FIGURE 1</a> A 65” Samsung QN800A on my desk.</figcaption></figure></div><blockquote>TLDR: If your job is to write code all day or stare at Excel spreadsheets, buy an 8K TV instead of a multi-monitor setup. You can even use the same TV for 4K 120 Hz gaming or watching movies as a bonus!</blockquote><p>For programming, word processing, and other productive work, consider getting an 8K TV instead of a multi-monitor setup.
An 8K TV will have superior image quality, resolution, and versatility compared to multiple 4K displays, at roughly the same size.
As a bonus, an 8K display is also suitable for gaming at 4K 120 Hz, or for full screen media consumption, which is not possible with multiple smaller monitors.</p><p>Currently 8K TVs are found in 55” and above. 
This is about the same width as getting two 27” monitors or two 32” monitors, both common setups for programmers and other professionals.
This is also the same physical width as ultrawide screens, but with a superior resolution of 7680 px wide instead of the common upper limit of 5120 px for ultrawide screens.</p><h2 id="s1"><a href="#s1">1</a> <span>Pros of using an 8K display</span></h2><h2 id="s1.1"><a href="#s1.1">1.1</a> <span>For programming, word processing, etc</span></h2><div><figure id="fig2"><a href="https://i.dllu.net/20190723_150428_481a0539480051a8.jpg"><img src="https://i.dllu.net/20190723_150428_1200_ec928294ca540ab6.jpg" alt="Three 27" 4k="" monitors="" "=""></a><figcaption><a href="#fig2">FIGURE 2</a> Three 27” 4K monitors. An 8K monitor would have similar pixel density but no bezels in between.</figcaption></figure></div><div><figure id="fig3"><a href="https://i.dllu.net/IMG_5245_9d3a5a9f8684b2d6.jpg"><img src="https://i.dllu.net/IMG_5245_1200_92ce89a0232d6c7c.jpg" alt=""></a><figcaption><a href="#fig3">FIGURE 3</a> Some random code displayed on an 8K display. Having seven evenly-spaced columns would be impossible on a dual 4K display setup due to bezels in the middle.</figcaption></figure></div><p>Many programmers use a multi-monitor setup, often with multiple 4K monitors.
The bezels and gaps in between the monitors introduce distractions and one is limited in how one may arrange terminals and windows across multiple displays.
With a single 8K display there is no such problem.</p><p>Consider using a tiling window manager to arrange your windows in a large display.
Tiling window managers exist for all operating systems. Here are some examples that I enjoy:</p><ul><li>For Linux: <a href="https://i3wm.org/">i3</a>, <a href="https://swaywm.org/">Sway</a>. Note that although Nvidia was previously hostile to Wayland and Sway, it now works as of 2023. There are a lot more others.</li><li>For MacOS: <a href="https://github.com/koekeishiya/yabai">Yabai</a></li></ul><p>Productivity is highly sensitive to the display of text.
For this reason, many programmers prefer to use Apple products for their retina displays.
An 8K display will have vastly superior text rendering compared to a single large 4K display, and equivalent text rendering to multiple smaller 4K displays.</p><p>TVs may have a different subpixel layout than monitors, so small text may suffer fringing.
As of writing the Samsung VA and LG IPS panels such as the QN800A have a conventional RGB or BGR subpixel structure. One may also increase the font size or use hidpi scaling which will eliminate all pixel-level concerns.</p><h2 id="s1.2"><a href="#s1.2">1.2</a> <span>For photo and video editing</span></h2><p>Although the main motivation for getting the 8K display was for programming, it is quite nice for photography too.
Apart from the obvious advantage of being able to see a large photo with a sharp resolution, having a high resolution display allows toolbars and such to be legible at a much smaller size relative to the size of the display.
This improves productivity for photo editing. Of course, appropriate hidpi settings may be used to increase the size of toolbars if desired.</p><p>An 8K TV often supports the D65-P3 colour gamut, making it appropriate for photo and video editing.
It may not arrive as well-calibrated as professional monitors out of the box, but it should be possible to calibrate any screen with a display calibrator.
However, extremely colour-sensitive work should still use professional calibrated displays suited for that purpose.</p><h2 id="s1.3"><a href="#s1.3">1.3</a> <span>For CAD work</span></h2><p>CAD work is highly dependent on visualizing fine details.
In particular, a wireframe rendering may become unintelligible if it is of insufficient resolution.
A high resolution display will allow fine details to be seen even while viewing multiple viewports without having to maximize the viewport.
However the viewport may be maximized to occupy the full screen nonetheless, a great advantage compared to multi-monitor setups.</p><h2 id="s1.4"><a href="#s1.4">1.4</a> <span>For gaming/media</span></h2><p>Although this post is mostly focused on productivity, most if not all 8K TVs can be run in 4K at 120 Hz.
Modern TVs have decent input lag in the ballpark of 10 ms and may support FreeSync.
So these are excellent for gaming on the big screen when one needs to take a break from work.
Of course, this may not suffice for competitive professional FPS twitch shooters, but it is pretty darn good.
Multi monitor productivity setups using 4k 60 Hz monitors simply cannot achieve this.</p><p>An 8K TV will also natively support 1440p gaming and media at an exact integer ratio of 3:1 without scaling artifacts that a 4K display would introduce. Perfect for playing the latest titles that your GPU isn’t fast enough to run in 4K.</p><p>Please bear in mind that most GPUs will not run games performantly in 8K and there are basically no 8K movies.</p><p>For watching movies, I set my TV to 4K 120 Hz mode as well.
The 120 Hz is divisible by both 24 fps and 30 fps.
Furthermore, if the media player lags and delays by one frame for some reason, it is still a lot smoother to delay by 1/120 s rather than 1/24 s.</p><h2 id="s1.5"><a href="#s1.5">1.5</a> <span>Cost</span></h2><div><figure id="fig4"><a href="https://s.dllu.net/uHQgpIOWxQDA0fDg.png"><img src="https://s.dllu.net/uHQgpIOWxQDA0fDg.png" alt=""></a><figcaption><a href="#fig4">FIGURE 4</a> An LG Nanocell 99 65” 8K TV was only $1500 at Best Buy.</figcaption></figure></div><p>8K TVs tend to start at around $1500 to $2000 for a 65” one.
This is about the same as getting four 32” 4K monitors.</p><p>However, many people who get a multi-monitor productivity setup also buy a separate 4K TV just for gaming or media consumption.
In this case, having one screen that does it all may save some money.</p><h2 id="s1.6"><a href="#s1.6">1.6</a> <span>Connectivity</span></h2><p>8K TVs may be driven at 8K 60 Hz with no chroma subsampling by using HDMI 2.1, which is available on all current (Nvidia RTX 4000 series and AMD 7000 series) and previous gen (Nvidia RTX 3000 series, AMD 6000 series) graphics cards.
Older computers with GPUs outputting DisplayPort 1.4 may use adapters such as the Club3D one to achieve 8K 60 Hz.</p><h2 id="s2"><a href="#s2">2</a> <span>Potential cons and caveats</span></h2><h2 id="s2.1"><a href="#s2.1">2.1</a> <span>Desk and mounting</span></h2><div><figure id="fig5"><a href="https://i.dllu.net/IMG_0040_101abca0d08bf876.jpg"><img src="https://i.dllu.net/IMG_0040_1200_59264dccd924e751.jpg" alt=""></a><figcaption><a href="#fig5">FIGURE 5</a> My 75” × 42” desk is bigger than a single bed.</figcaption></figure></div><p>When purchasing a large display, one may need to sit farther back from the display when viewing full-screen content.
As such, a deeper desk may be needed.
Most desks are only 30” (76 cm) deep, which is an insufficient distance to sit from the screen.
Please take into consideration the potential extra costs of buying a bigger desk, or consider wall-mounting the display.</p><p>My desk is an Uplift four leg standing desk with a custom 75” × 42” dimension.
You could also buy a large butcher’s block or door and mount it on a desk frame.
Large dining tables or conference room tables work well too.</p><h2 id="s2.2"><a href="#s2.2">2.2</a> <span>Image quality issues</span></h2><h3 id="s2.2.1"><a href="#s2.2.1">2.2.1</a> <span>Uniformity</span></h3><p>Due to manufacturing variance, there may be some nonuniformity in high resolution displays, leading to what is called the “dirty screen effect”. This is not expected to be an issue for programming work, but can be distracting or harmful for photographic work or media consumption. An appropriate calibration can mitigate the problem but it is still recommended to obtain a uniform, professional display for colour-critical work.</p><blockquote>The Samsung QN800A has good gray uniformity. Although the screen is fairly uniform throughout, there’s a bit of dirty screen effect in the center, which could be distracting during sports. The screen is much more uniform in near-dark scenes. Keep in mind that uniformity may vary between units.</blockquote><p>Ratings sites such as <a href="https://www.rtings.com/tv/reviews/samsung/qn800a-8k-qled">RTINGS.com</a> have good measurements of uniformity.</p><div><figure id="fig6"><a href="https://i.dllu.net/dse-large_5fe27ae594205181.jpg"><img src="https://i.dllu.net/dse-large_ef1b0594e5459fb5.jpg" alt=""></a><figcaption><a href="#fig6">FIGURE 6</a> 50% Gray uniformity test from RTINGS.com. Source: <a href="https://www.rtings.com/tv/reviews/samsung/q900-q900r-8k-qled#test_179">RTINGS.com</a>.</figcaption></figure></div><h3 id="s2.2.2"><a href="#s2.2.2">2.2.2</a> <span>Checkerboard effect</span></h3><p>Some 8K TVs have a subtle “checkerboard” effect visible at the 1px scale, such as the Samsung QN700B and QN800A unless you have Game Mode enabled.
<strong>The problem is completely gone once you enable “Game Mode” in the TV</strong>.
This has led to some review comments such as quote a <a href="https://www.bestbuy.com/site/reviews/samsung-55-class-qn700b-neo-qled-8k-smart-tv/6517114">Best Buy review comment</a>,</p><blockquote>This is not a true HDR 8K TV.
To be HDR 8K, each pixel should have the full range of brightness and dimness to comprise an image. But each pixel only seems to have half the number of steps between full dim and full bright.
So to generate certain shades and colors between full bright and black, the pixels require 2 pixels, one that is brighter and one that is dimmer where the average between the pixels is the correct shade, color or value.
For most shades and colors, this alternating pixel technique forms a diagonal patchwork that has a noticeable checkerboard effect. Images viewed up close look bad.
This isn’t noticeable with windows that are pure white and the text is black, as black text on a white background looks good and is true 8k pixel density with no grid pattern and clean edges on the text.  
[…]
My best guess of what this display is doing is… instead of 8K number of pixels each capable of displaying a full range HDR10 1024 color steps per RGB element, they have two sets of pixels each set only capable of displaying 512 steps of information with every other pixel offset in capability by half a step. They combine the two simpler pixel values to achieve the more complex shades in between.
I can hear the Samsung display engineers, “Who would sit that close anyway to be able to see that?” Well, clearly people who want to use it as a computer monitor would.
The 700B is advertised as not just an HDR screen but an HDR10+ plus screen which is 10bit, but this does not seem to be the case as a non HDR image from my computer still requires dithering to achieve the commanded colors and shades.
No other display makers are making a true 8K display at this size at this price point, so I’m going to keep it and just sit further back so I don’t notice the dithering.</blockquote><div><figure id="fig7"><a href="https://i.dllu.net/2024-07-02-10-15-24_DSCF9108_ee0275f38e0c35fe126fbdfd0ccf2b7d3f32ae47_0aac8cf0ffd2700e.jpg"><img src="https://i.dllu.net/2024-07-02-10-15-24_DSCF9108_ee0275f38e0c35fe126fbdfd0ccf2b7d3f32ae47_1a3a0a203c4597ec.jpg" alt=""></a><figcaption><a href="#fig7">FIGURE 7</a> Checkerboard effect.</figcaption></figure></div><p>This does not affect most text rendering, but I have noticed this effect when editing photos.</p><div><figure id="fig8"><a href="https://i.dllu.net/2024-07-02-10-19-06_DSCF9109_4bf015a151e2719a582bf8ad22c1d9da40e291cf_d6e0350e46252b97.jpg"><img src="https://i.dllu.net/2024-07-02-10-19-06_DSCF9109_4bf015a151e2719a582bf8ad22c1d9da40e291cf_be63f7a46e4a6cc2.jpg" alt=""></a><figcaption><a href="#fig8">FIGURE 8</a> Doesn’t typically affect text rendering significantly.</figcaption></figure></div><p>Again, the problem is completely gone once you enable Game Mode on the TV, so be sure to enable it!</p><h2 id="s2.3"><a href="#s2.3">2.3</a> <span>Random software issues</span></h2><p>Since TVs are rarely designed for PC usage as a first class citizen, there may be some weird quirks or bugs.</p><h3 id="s2.3.1"><a href="#s2.3.1">2.3.1</a> <span>Nvidia Linux drivers</span></h3><p>If using Nvidia on Linux, to get 8K 60 Hz working, you need driver <a href="https://www.phoronix.com/news/NVIDIA-535.43.02-Linux-Driver">version 535</a> or later on Linux, which was released in May 2023. Versions prior to that would only do 8K 30 Hz.</p><p>Although Nvidia on Windows has supported 8K 60 Hz as soon as the RTX 3000 series came out, on Linux it took about two years for 8K 60 Hz support to work, spawning a <a href="https://github.com/NVIDIA/open-gpu-kernel-modules/discussions/238">salty thread on GitHub</a>.</p><p>So please make sure to update your drivers!</p><p>As a minor concern, there may be some slight vertical screen tearing between the left and right halves of the display.</p><h3 id="s2.3.2"><a href="#s2.3.2">2.3.2</a> <span>AMD Linux drivers</span></h3><p>Unfortunately, as of writing, on Linux, AMD GPUs do not have HDMI 2.1 so you cannot use an 8K TV in 8K 60 Hz mode unless you use a DisplayPort to HDMI adapter.
It works fine on AMD on Windows, however.</p><p>The AMD on Linux fiasco is because the <a href="https://arstechnica.com/gadgets/2024/02/hdmi-forum-to-amd-no-you-cant-make-an-open-source-hdmi-2-1-driver/">HDMI Forum has prohibited AMD from implementing HDMI 2.1</a> in their open source Linux drivers.</p><h3 id="s2.3.3"><a href="#s2.3.3">2.3.3</a> <span>Input Signal Plus</span></h3><p>To get 8K 60 Hz working, you need to go into TV menus and enable “Input Signal Plus”, “Enhanced HDMI”, or something similar.
For some silly reason, this may be disabled by default, which will relegate you to only 4K or 30 Hz.</p><h3 id="s2.3.4"><a href="#s2.3.4">2.3.4</a> <span>Wake up bugs</span></h3><p>Sometimes if your computer goes to sleep or turns the monitor off to save energy, when waking up the TV will not detect it.
Worse, sometimes when waking up, the TV will revert to only 4K mode, and you’d have to go into the menus to toggle the “Input Signal Plus” setting to make it work properly again.
This is pretty annoying but I just disabled turning off the monitor in my OS.</p><h3 id="s2.3.5"><a href="#s2.3.5">2.3.5</a> <span>Having another DisplayPort device</span></h3><p>When having another DisplayPort device plugged into your GPU, your computer may favor the DisplayPort device upon boot.
This means that when booting up, the BIOS menu, bootloader, and such will get sent to the DisplayPort device instead of the HDMI device.</p><p>This was annoying for me because I have a Valve Index VR headset which uses DisplayPort whereas the TV, using HDMI, is my main display.
I had to unplug the Valve Index, but if anyone knows any other methods then I would be interested to hear them.</p><h2 id="s2.4"><a href="#s2.4">2.4</a> <span>Display types</span></h2><p>Currently, 8K TVs are generally available as “full array backlight” IPS or VA panels.
These will have equivalent or superior contrast compared to most IPS desktop monitors, but will have inferior contrast compared with OLED displays.
OLED 8K TVs exist, but are prohibitively expensive at $30,000 as of writing.
However, OLED displays are prone to burn in when used for productivity work and may have features such as automatic dimming for static scenes, which can be distracting while performing lengthy tasks like programming.</p><h2 id="s2.5"><a href="#s2.5">2.5</a> <span>Coatings</span></h2><p>TVs tend to have a glossy coating for superior image quality. However for brightly lit rooms there may be unavoidable reflections.
For my use case, even though my TV is right next to a window, I have never found any issues focusing on my code with a dark theme.</p><h2 id="s3"><a href="#s3">3</a> <span>Example devices</span></h2><p>Unfortunately, there are very few 8K displays on the market, and many decent ones (such as the 55” Samsung QN700B) are discontinued.
Some 8K TVs include:</p><ul><li>Samsung Q900 series (55” to 82”)</li><li>Samsung Q800T series</li><li>Samsung Q900TS series</li><li>Samsung Q950TS series</li><li>Samsung QN700B series</li><li>Samsung QN800A/B/C series</li><li>Samsung QN900A/B/C</li><li>LG Nanocell 97 series</li><li>LG Nanocell 99 series</li><li>Sony Z8H series</li><li>Sony Z9G series</li><li>TCL Class 6-series 8K</li></ul><p>There are also some crazy $30,000 OLED displays and even crazier huge 262” microled displays that cost millions.</p><p>There is also a Dell UP3218K, but it costs the same as an 8K TV and is much smaller and has many problems. So I do not recommend it unless you really don’t have the desk space. Sitting further back from a bigger screen provides the same field of view as sitting close to a smaller display, and may have less eye strain.</p><p>I am excited about <a href="https://wccftech.com/tcl-unveils-27-inch-8k-57-inch-duhd-240hz-31-inch-4k-oled-dome-several-next-gen-displays/">upcoming TCL 8K displays</a>.</p><h2 id="s4"><a href="#s4">4</a> <span>FAQ</span></h2><blockquote>Isn’t it too big?</blockquote><p>The width and pixel density is the same as two 32” monitors.</p><blockquote>But there are no 8K movies</blockquote><p>I don’t usually watch movies on this, but when I do, I set it to 4K 120 Hz mode.</p><blockquote>But can your GPU even run 8K games?</blockquote><p>I play games in 4K 120 Hz mode. Actually, some games like Factorio could benefit from 8K 60 Hz mode, but those are not graphically intensive. Theoretically, Age of Empires II would be interesting too since you could see a lot of the map at once.</p><blockquote>How about a projector?</blockquote><p>There are no 8K projectors and the pixel density for displaying lots of text is a main motivation for getting an 8K display.</p><blockquote>How about the Apple Vision Pro?</blockquote><p>Despite having much better pixel density than other VR headsets, the pixel density <a href="https://kguttag.com/2024/02/05/spreadsheet-breaks-the-apple-vision-pros-avp-eye-tracking-foveation-the-first-through-the-optics-pictures/">isn’t quite there yet for looking at lots of text such as spreadsheets</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub Cuts AI Deals with Google, Anthropic (741 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2024-10-29/microsoft-s-github-unit-cuts-ai-deals-with-google-anthropic</link>
            <guid>41985915</guid>
            <pubDate>Tue, 29 Oct 2024 16:20:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2024-10-29/microsoft-s-github-unit-cuts-ai-deals-with-google-anthropic">https://www.bloomberg.com/news/articles/2024-10-29/microsoft-s-github-unit-cuts-ai-deals-with-google-anthropic</a>, See on <a href="https://news.ycombinator.com/item?id=41985915">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vector databases are the wrong abstraction (288 pts)]]></title>
            <link>https://www.timescale.com/blog/vector-databases-are-the-wrong-abstraction/</link>
            <guid>41985176</guid>
            <pubDate>Tue, 29 Oct 2024 15:40:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.timescale.com/blog/vector-databases-are-the-wrong-abstraction/">https://www.timescale.com/blog/vector-databases-are-the-wrong-abstraction/</a>, See on <a href="https://news.ycombinator.com/item?id=41985176">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><em>"Your embeddings are out of sync again."</em></p><p>It's a message that haunts engineering teams trying to build AI applications. What starts as a simple vector search implementation inevitably evolves into a complex orchestra of monitoring, synchronization, and firefighting.</p><p>We've spent the past year talking to dozens of engineering teams building AI systems with vector databases, whether semantic search, retrieval-augmented generation (RAG) systems, or AI agents. We learned that while everything works smoothly for simple applications and PoCs, taking these AI systems into production reveals flawed abstractions with vector databases and the way we use them today.&nbsp;</p><p>Here’s one common thread we heard:</p><p><em>"You're building a RAG system, and your team uses Pinecone as a vector database to store and search embeddings. But you can't just use Pinecone—your text data doesn't fit well into Pinecone's metadata, so you're also using DynamoDB to handle those blobs and application data. And for lexical search, you needed OpenSearch. Now you're juggling three systems, and syncing them is a nightmare."</em></p><p>It’s easy to see why. Say you delete a source document in your database because it's outdated. Now you have to:</p><ol><li>Fire up boto3 to remove the record from DynamoDB.</li><li>Remember to update Pinecone to ensure the embedding is deleted.</li><li>Need a POST request to update the lexical search index.</li></ol><p>And you need to do this for every update, addition, or delete to your source documents!</p><p>Managing these configurations isn’t just messy—it’s risky. One missed step, and you're stuck paying for an index you haven’t used in months. One team recently shared how they ended up paying $2,000 a month for an index that should've been deleted four months ago! And that’s not even mentioning the risk of returning incorrect or stale data to your users.</p><p>Sounds familiar? After hearing this pattern repeatedly, we realized something crucial:</p><p><strong>Vector databases are built on the wrong abstraction.</strong></p><p>Vector databases treat embeddings as independent data, divorced from the source data from which embeddings are created, rather than what they truly are: derived data. By treating embeddings as independent data, we’ve created unnecessary complexity for ourselves.</p><p>In this post, we'll propose a better way: treating embeddings more like database indexes through what we call the <strong>"vectorizer"</strong> abstraction. This approach automatically keeps embeddings in sync with their source data, eliminating the maintenance costs that plague current implementations.&nbsp;</p><p>A vectorizer’s equivalent of the <code>CREATE INDEX</code> command is:</p><pre><code>-- Create a vectorizer to embed data in the blogs table
-- Use Open AI text-embedding-3-small model
SELECT ai.create_vectorizer(
    'public.blogs'::regclass,
    embedding =&gt; ai.embedding_openai('text-embedding-3-small', 1536),
    chunking =&gt; ai.chunking_recursive_character_text_splitter('content')
);</code></pre><p>This one command will create embeddings for every entry in the blog table and keep updating those embeddings as you change the data in the blog table. In the immortal words of Ina Garten: how easy is that!&nbsp;</p><p>We’ll detail how we implemented this vectorizer abstraction in PostgreSQL in a new open-source tool called <a href="https://github.com/timescale/pgai/blob/main/docs/vectorizer.md?ref=timescale.com"><u>pgai Vectorizer</u></a>, making it work with the open-source <a href="https://github.com/pgvector/pgvector/blob/master/README.md?ref=timescale.com"><u>pgvector</u></a> and <a href="https://github.com/timescale/pgvectorscale/?ref=timescale.com"><u>pgvectorscale</u></a> extensions for vector search.&nbsp;</p><p>We built a vectorizer for PostgreSQL because many developers regard PostgreSQL as the “Swiss army knife” of databases, as it can handle everything from vectors and text data to JSON documents. We think an “everything database” like PostgreSQL is the solution to eliminate the nightmare of managing multiple databases, making it the ideal home for vectorizers and the foundation for AI applications.</p><p>If you've ever cursed at stale embeddings or questioned why managing vector search feels needlessly complex, this post is for you.</p><h2 id="the-problem-with-vector-databases-and-vector-data-types">The Problem With Vector Databases (and Vector Data Types)</h2><p>Vector databases were developed as specialized systems to handle large volumes of vector embeddings for text, image, and multi-modal data. And, as the utility of vector embeddings became clearer, many general-purpose databases, like PostgreSQL (with pgvector), MySQL, MongoDB, and even Oracle, added vector search support to their general-purpose offerings either officially or via extensions.</p><p>However, the abstraction of vector search capabilities, either in a standalone system or added to an existing database, suffers from a fatal flaw: once embeddings are inserted into the database, <strong>we lose the connection between the unstructured data that is being embedded and the vector embeddings themselves</strong>.</p><p>Without this connection, embeddings are mistakenly treated as standalone data atoms that developers must manage rather than what they truly are: <strong>derived data</strong>. After all, <a href="https://www.timescale.com/blog/a-beginners-guide-to-vector-embeddings/"><u>vector embeddings are high-dimensional representations of their source data</u></a>, whether the source data be text, images, or something else. There is a fundamental connection between the vector embedding and the source data it is generated from.</p><p>When we reconceptualize embeddings as derived data, the absurdity of the current vector database abstraction becomes evident, with embeddings disconnected from their source data. To handle the demands of a production AI system, even the best teams find themselves juggling multiple databases and managing the following:</p><ul><li>Complex ETL (extract-load-transform) pipelines to chunk, format, and create embeddings from source data</li><li>A vector database for embeddings, another database for metadata and app data, and perhaps even a separate lexical search index</li><li>A data sync service to synchronize across various databases to avoid conflicting sources of truth</li><li>Queuing systems for updates and synchronization</li><li>Monitoring tools to catch data drift and deal with rate limits and other errors from the embedding service</li><li>Alert systems for when searches return stale results</li><li>Validation checks across all these systems</li></ul><p>And what if you want to upgrade to a newer embedding model or try a different chunking method? Now you're writing custom code and coordinating changes across multiple data services and databases. For example, we’ve heard teams who’ve put off migrating from OpenAI’s <code>text-embedding-ada-002</code> to the newer text-embedding-3 model family for this very reason.</p><p>These tasks place the burden on the development team to ensure that the embeddings are timeously created as source data changes. Otherwise, they risk embeddings frequently becoming stale, leading to a worse application experience for users.</p><p>Thus, even in the best case, teams spend countless hours writing and debugging synchronization logic, setting up infrastructure to handle embedding updates at scale, and firefighting when these systems inevitably break down.&nbsp;</p><h2 id="a-better-way-let-the-database-handle-the-complexity">A Better Way: Let the Database Handle the Complexity&nbsp;</h2><p>When we reconceptualize embeddings as derived data, the <strong>responsibility for generating and updating them as the underlying data changes can be handed over to the database management system</strong>. This change frees developers from the burden of manually keeping embeddings in sync with the source data. (*Cue in collective developer rejoice*)</p><p>This distinction may not seem critical for simple applications that perform a one-time data import for RAG. But for most real-world applications, data is constantly changing. Consider an e-commerce platform that uses embedding-based semantic search across its product catalog, always evolving with new products and updated descriptions. Or a product assistant RAG app that must be kept up to date with the latest product information to give accurate answers to prospective and current customers.</p><p>Manually tracking these changes and regenerating embeddings is not only labor-intensive and error-prone but also distracts developers from focusing on core business objectives. Why waste valuable development time managing this manually when the database system could handle it for you automatically?</p><h2 id="vectorizers-vector-embeddings-as-indexes">Vectorizers: Vector Embeddings as Indexes</h2><p>A more effective abstraction is conceptualizing vector embeddings not as independent tables or data types but as a <strong>specialized index</strong> on the embedded data. This is not to say that vector embeddings are <em>literally</em> indexes in the traditional sense, like those in PostgreSQL or MySQL, which retrieve entire data rows from indexed tables. Instead, vector embeddings function as an indexing mechanism that retrieves the most relevant parts of the data based on its embeddings.</p><p>Rather than indexes, we can call this new index-like abstraction a “<strong>vectorizer</strong>,” as it creates vectors from the underlying source data it is connected to (in other words, vectorizes them). The vectorizer abstraction offers several key advantages:</p><h3 id="automatic-synchronization">Automatic synchronization</h3><p>One of the primary benefits of indexing in databases is that it automatically keeps the index in sync with the underlying data. When the data in a column changes, the index is updated accordingly. By treating vector embeddings as a form of indexing, we can leverage this same automatic synchronization. The system would ensure that vector embeddings are always up-to-date with the latest data, eliminating the need for manual updates and reducing the risk of errors.</p><h3 id="reinforced-data-embedding-relationship">Reinforced data-embedding relationship</h3><p>When vectors are stored independently, it is easy to lose track of their relationship with the original data. Was this vector generated from a recent update to the data? Or is it an outdated vector from a previous embedding model? These questions are critical, and confusion here can lead to significant errors. The relationship is clear and maintained automatically by tying vector embeddings directly to the data as an index.</p><h3 id="simplified-data-management">Simplified data management</h3><p>Developers often face challenges when managing data synchronization manually. For instance, forgetting to delete data from an old embedding model when the underlying data is deleted can cause inconsistencies. The vectorizer abstraction simplifies this process by making it the system’s responsibility to manage these relationships, thus reducing the cognitive load on developers and minimizing the potential for mistakes.</p><h2 id="vectorizers-are-a-natural-evolution-of-the-core-dbms-promise">Vectorizers Are a Natural Evolution of the Core DBMS Promise&nbsp;</h2><p>The vectorizer concept is a natural evolution of modern database management systems (DBMS) capabilities. Today’s DBMSs are already adept at managing data transformations and synchronizations through declarative constructs like indexes, triggers, and materialized views. The vectorizer abstraction fits neatly into this paradigm, providing a new tool for handling the increasingly important task of managing vector embeddings.</p><p>By embedding this functionality directly into the DBMS, we move closer to fulfilling the ultimate promise of database systems: to manage data in a way that abstracts away the complexities, allowing users to focus on what they do best—building applications, analyzing data, and driving innovation.</p><h2 id="implementing-a-vectorizer-for-postgresql-pgai-vectorizer">Implementing a Vectorizer for PostgreSQL: Pgai Vectorizer</h2><p>The good news is that we don’t have to wait long for the vectorizer dream described above to become a reality. Motivated by the promise of making developers’ burdens lighter, our AI Engineering team at Timescale implemented a vectorizer for PostgreSQL. It’s called <a href="https://github.com/timescale/pgai/blob/main/docs/vectorizer.md?ref=timescale.com"><u>pgai Vectorizer</u></a> (currently in Early Access) and is part of the <a href="https://github.com/timescale/pgai?ref=timescale.com"><u>PGAI project</u></a> to make PostgreSQL better for AI systems and make AI development accessible to developers familiar with PostgreSQL.</p><p>If you’d like to see pgai Vectorizer in action, <a href="https://youtu.be/ZoC2XYol6Zk?ref=timescale.com" rel="noreferrer">check out this demo video </a>on how it automatically creates and updates vector embeddings for data in PostgreSQL.</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/ZoC2XYol6Zk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="Auto Create and Sync Vector Embeddings in 1 Line of SQL (pgai Vectorizer)"></iframe></figure><p>For more advanced use cases, here's how you can use pgai Vectorizer to easily <a href="https://www.timescale.com/blog/which-openai-embedding-model-is-best/"><u>test different embedding models</u></a>, or test which <a href="https://www.timescale.com/blog/which-rag-chunking-and-formatting-strategy-is-best"><u>chunking and formatting strategy fits your data best</u></a>.</p><h3 id="how-pgai-vectorizer-works">How pgai Vectorizer works</h3><p>Let’s move on to some background on how pgai Vectorizer works and how it brings the discussed advantages to life.</p><p>Developers define and create a vectorizer in SQL. The following query creates a vectorizer and specifies the table it acts on, the column to vectorize, the embedding model to use, and additional formatting for other information to include in the source data to be embedded.</p><pre><code>-- Create a vectorizer to automatically embed data in the blogs table
SELECT ai.create_vectorizer(
   'public.blogs'::regclass
   -- Use Open AI text-embedding-3-small model
 , embedding=&gt;ai.embedding_openai('text-embedding-3-small', 1536, api_key_name=&gt;'OPENAI_API_KEY')
   -- Automatically create a StreamingDiskANN index when table has 100k rows
 , indexing =&gt; ai.indexing_diskann(min_rows =&gt; 100000, storage_layout =&gt; 'memory_optimized'),
   -- Apply recursive chunking on the content column
 , chunking=&gt;ai.chunking_recursive_character_text_splitter('content')
   -- Add metadata from other columns to the embedding for better retrieval
 , formatting=&gt;ai.formatting_python_template('Blog title: $title url: $url blog chunk: $chunk')
);
-- The vectorizer will update the embeddings as the source table changes
-- No other user actions are required</code></pre><p>We also define some default chunking functions since long pieces of text need to be split up into multiple smaller chunks to fit inside embedding model token limits.</p><h4 id="tracking-changes-to-source-data">Tracking changes to source data</h4><p>Under the hood, pgai Vectorizer checks for modifications to the source table (inserts, updates, and deletes) and asynchronously creates and updates vector embeddings. Our team built pgai Vectorizer for two deployment types: <a href="https://github.com/timescale/pgai/blob/main/docs/vectorizer-quick-start.md?ref=timescale.com"><u>self-hosted</u></a> and fully managed in <a href="https://console.cloud.timescale.com/signup/?utm_source=blog&amp;utm_medium=website&amp;utm_campaign=vectorlaunch&amp;utm_content=vectorizer-thought-leadership-cta" rel="noreferrer"><u>Timescale Cloud</u></a>.</p><p>In the cloud-hosted implementation of pgai Vectorizer, we use cloud functions in the Timescale Cloud platform to create embeddings. In the open-source version of pgai Vectorizer, embeddings are created by running an external worker.</p><p>Pgai Vectorizer stores the configuration and catalog information along with key internal bookkeeping data inside the database.</p><p>Here’s an overview of the architecture of the pgai Vectorizer system:</p><figure><img src="https://www.timescale.com/blog/content/images/2024/10/Vector-Databases-are-the-wrong-abstraction_pgai_vectorizer_architecture.png" alt="A diagram representing pgai Vectorizer's system overview." loading="lazy" width="2000" height="1136" srcset="https://www.timescale.com/blog/content/images/size/w600/2024/10/Vector-Databases-are-the-wrong-abstraction_pgai_vectorizer_architecture.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2024/10/Vector-Databases-are-the-wrong-abstraction_pgai_vectorizer_architecture.png 1000w, https://www.timescale.com/blog/content/images/size/w1600/2024/10/Vector-Databases-are-the-wrong-abstraction_pgai_vectorizer_architecture.png 1600w, https://www.timescale.com/blog/content/images/size/w2400/2024/10/Vector-Databases-are-the-wrong-abstraction_pgai_vectorizer_architecture.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><i><em>Pgai Vectorizer automatically creates and updates embeddings from a source data table using work queues and configuration tables housed in PostgreSQL. Embeddings are created in an external worker that interacts with embedding services like the OpenAI API.</em></i></figcaption></figure><h4 id="where-are-embeddings-actually-created">Where are embeddings actually created?</h4><p>An important note is that the actual embedding process occurs outside the database in an external process. This helps reduce the load on the database server and means that vectorizers don’t affect the database’s ability to service application queries. It also makes it easier to scale the embedding task independently of other database operations.</p><p>This process first reads the database to see if there is work to be done. If there is, it reads the data from the database, performs chunking and formatting, makes a call to an embedding model provider, such as OpenAI, to generate the embedding, and writes the result back to the database.&nbsp;</p><h4 id="customizing-the-process">Customizing the process</h4><p>Pgai Vectorizer is flexible: You can specify the chunking and formatting rules used to create embeddings. In particular, you can configure which columns of the source table are to be vectorized and the chunking and formatting rules to ensure the source data fits within embedding token limits and that relevant data is contained within each embedding.</p><p>In the Early Access release of pgai Vectorizer, you can customize the choice of OpenAI embedding model (e.g., <code>text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002</code>), chunking strategies to split text into smaller chunks, formatting options to inject additional context into each chunk, and custom indexing configurations for automated index creation and performance tuning. We plan to make this even more flexible soon by allowing users to submit their own Python code to fully customize chunking, embedding, and formatting.</p><p>For example, here’s a vectorizer configured to split HTML source files recursively and create OpenAI embeddings from the source data. You can configure the chunking and formatting to suit your specific application data, whether it be code, documents, markdown, or anything else.</p><pre><code>-- Advanced vectorizer configuration
SELECT ai.create_vectorizer(
   'public.blogs'::regclass,
   destination =&gt; 'blogs_embedding_recursive',
   embedding =&gt; ai.embedding_openai('text-embedding-3-small', 1536),
   -- apply recursive chunking with specified settings for HTML content
   chunking =&gt; ai.chunking_recursive_character_text_splitter(
       'content',
       chunk_size =&gt; 800,
       chunk_overlap =&gt; 400,
       -- HTML-aware separators, ordered from highest to lowest precedence
       separator =&gt; array[
           E'&lt;/article&gt;', -- Split on major document sections
           E'&lt;/div&gt;',    -- Split on div boundaries
           E'&lt;/section&gt;',
           E'&lt;/p&gt;',      -- Split on paragraphs
           E'&lt;br&gt;',      -- Split on line breaks
           E'&lt;/li&gt;',     -- Split on list items
           E'. ',        -- Fall back to sentence boundaries
           ' '          -- Last resort: split on spaces
       ]
   ),
   formatting =&gt; ai.formatting_python_template('title: $title url: $url $chunk')
);</code></pre><p>We plan to detail the design decisions which informed our building of pgai Vectorizer in a future blog post.</p><h2 id="try-pgai-vectorizer-today">Try Pgai Vectorizer Today</h2><p>Try pgai Vectorizer now in Early Access. Open source, built for application devs, and ready to simplify your AI workflows. See how much easier embedding management can be—jump in and let us know what you think. Pick your favorite deployment option: <a href="https://console.cloud.timescale.com/signup/?utm_source=blog&amp;utm_medium=website&amp;utm_campaign=vectorlaunch&amp;utm_content=vectorizer-thought-leadership-cta" rel="noreferrer"><u>fully managed on Timescale Cloud</u></a> or <a href="https://github.com/timescale/pgai/blob/main/docs/vectorizer-quick-start.md?ref=timescale.com"><u>self-hosted in your PostgreSQL environment of choice</u></a> (leave us a GitHub ⭐ along the way).</p><p>Why waste your precious development time manually managing embeddings when you could simply hand this over to your database?</p><p>With pgai Vectorizer, you can. It enables you to keep your vector embeddings always up to date, reinforcing the embedding-data relationship and simplifying your data management. PostgreSQL becomes your AI development platform of choice, allowing you to store all your data in one place and automating embedding management. In addition, pgai Vectorizer builds upon other tools in the PGAI suite, like <a href="https://github.com/timescale/pgvectorscale?ref=timescale.com"><u>pgvectorscale</u></a>, which complements pgvector for high-performance vector search, and the <a href="https://github.com/timescale/pgai?ref=timescale.com"><u>pgai</u></a> extension, which brings AI models closer to your data in PostgreSQL.&nbsp;</p><p>Questions or feedback? Join our <a href="https://discord.gg/KRdHVXAmkp?ref=timescale.com"><u>Discord community</u></a>, where our team is ready to help you make the most of pgai Vectorizer and the rest of the tools in the <a href="https://www.timescale.com/ai?ref=timescale.com"><u>PGAI suite</u></a>.</p><h3 id="learn-more">Learn more</h3><p>Learn more about pgai Vectorizer and how it can help you build better AI systems with PostgreSQL in these companion blogs and videos:</p><ul><li><a href="https://www.timescale.com/blog/how-to-automatically-create-update-embeddings-in-postgresql/"><u>How to Automatically Create &amp; Update Embeddings in PostgreSQL — With One SQL Query</u></a></li><li><a href="https://www.timescale.com/blog/which-openai-embedding-model-is-best/"><u>Which OpenAI Embedding Model Is Best for Your RAG App With Pgvector?</u></a></li><li><a href="https://www.timescale.com/blog/which-rag-chunking-and-formatting-strategy-is-best" rel="noreferrer">Which RAG Chunking and Formatting Strategy Is Best for Your AI App With Pgvector?</a></li><li>Watch 🎥: <a href="https://www.youtube.com/watch?v=j2B5fx1p1Ps&amp;ref=timescale.com" rel="noreferrer">What If Vector Embeddings Were Database Indexes?</a></li></ul>
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New Mac Mini with M4 (437 pts)]]></title>
            <link>https://www.apple.com/newsroom/2024/10/apples-new-mac-mini-is-more-mighty-more-mini-and-built-for-apple-intelligence/</link>
            <guid>41984519</guid>
            <pubDate>Tue, 29 Oct 2024 15:00:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2024/10/apples-new-mac-mini-is-more-mighty-more-mini-and-built-for-apple-intelligence/">https://www.apple.com/newsroom/2024/10/apples-new-mac-mini-is-more-mighty-more-mini-and-built-for-apple-intelligence/</a>, See on <a href="https://news.ycombinator.com/item?id=41984519">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    
    
	
	

</nav>





<main id="main" role="main"> 




<span id="opens-in-new-window">opens in new window</span>
<section>
<article data-analytics-activitymap-region-id="article">






    
    
    









    





    <div>
        
		
        <div>
                    
                    
                        <span>PRESS RELEASE</span>
                    
                    
                        <span>October 29, 2024</span>
                    
                    
                </div>

        <div>
                
                
                
                    <h2>
                        
    
        Apple’s all-new Mac&nbsp;mini is more mighty, more mini, and built for Apple&nbsp;Intelligence
    

                    </h2>
                
            </div>

        <div>
                
                
                    The compact, do-it-all desktop now features the power of M4 and M4&nbsp;Pro, and marks an important environmental milestone as the first carbon neutral Mac
                
            </div>

        
            
    
    
    
    
    

        

    </div>







    
    
    






  
    
    
    
    
      <figure aria-label="Media, A hand holds the all-new Mac mini.">
        <div>
             
              
              <div>
                With M4 and M4 Pro, the new Mac mini brings incredible performance and connectivity in a design that’s small enough to fit in your hand.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2024/10/apples-new-mac-mini-apples-new-mac-mini-is-more-mighty-more-mini-and-built-for-apple-intelligence/article/Apple-Mac-mini-hero.zip" download="" data-analytics-title="download image - Apple-Mac-mini-hero_big" aria-label="Download media, A hand holds the all-new Mac mini."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <div><strong><span>CUPERTINO, CALIFORNIA</span></strong> Apple today unveiled the all-new <a href="https://youtu.be/TtFm9n3NVzE" target="_blank" rel="nofollow" data-analytics-exit-link="">Mac mini</a> powered by the M4 and new M4 Pro chips, and redesigned around Apple silicon to pack an incredible amount of performance into an even smaller form of just 5 by 5 inches. With M4, Mac mini delivers up to 1.8x faster CPU performance and 2.2x faster GPU performance over the M1 model.<sup>1</sup> With M4 Pro, it takes the advanced technologies in M4 and scales them up to tackle even more demanding workloads. For more convenient connectivity, it features front and back ports, and for the first time includes Thunderbolt 5 for faster data transfer speeds on the M4 Pro model. The new Mac mini is also built for Apple Intelligence, the personal intelligence system that transforms how users work, communicate, and express themselves while protecting their privacy. And marking an important environmental milestone, Mac mini is Apple’s first carbon neutral Mac with an over 80 percent reduction in greenhouse gas emissions across its materials, manufacturing, transportation, and customer use.<sup>2</sup> Starting at just $599 with 16GB of memory, the new Mac mini is available to pre-order today, with availability beginning November 8.
</div>
                 
             
                 <div>“The new Mac mini delivers gigantic performance in an unbelievably small design thanks to the power efficiency of Apple silicon and an innovative new thermal architecture,” said John Ternus, Apple’s senior vice president of Hardware Engineering. “Combined with the performance of M4 and the new M4 Pro chip, enhanced connectivity on both the front and back, and the arrival of Apple Intelligence, Mac mini is more capable and versatile than ever, and there is nothing else like it.”
</div>
                 
             
                 <h2><strong>Small, but Fierce</strong>
</h2>
                 
             
                 <div>The new Mac mini footprint is less than half the size of the previous design at just 5 by 5 inches, so it takes up much less space on a desk. The super-compact system is enabled by the incredible power efficiency of Apple silicon and an innovative thermal architecture, which guides air to different levels of the system, while all venting is done through the foot.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>The unbelievably compact form is made possible by the power-efficient performance of Apple silicon combined with an all-new innovative thermal architecture.</div>
        
            <a aria-label="Download video: Mac Mini Thermal Architecture" data-analytics-title="Download video - Mac Mini Thermal Architecture" download="" href="https://www.apple.com/newsroom/videos/videos-2024/autoplay/2024/10/apple-mac-mini-thermal-architecture/downloads/Apple-Mac-mini-thermal-architecture.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>When compared to the best-selling PC desktop in its price range, Mac mini is up to 6x faster at one-twentieth the size.<sup>1</sup> For a wide range of users, from students to aspiring creatives and small business owners, the Mac mini with M4 is a tiny powerhouse. Mac mini with M4 features a 10-core CPU, 10-core GPU, and now starts with 16GB of unified memory. Users will feel the performance of M4 in everything they do, from multitasking across everyday productivity apps to creative projects like video editing, music production, or writing and compiling code.
</div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, A Mac mini user works at a desk surrounded by ceramics pieces.">
        <div>
             
              
              <div>
                Mac mini is more versatile than ever — perfect for anywhere, from home offices to large businesses and beyond.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2024/10/apples-new-mac-mini-apples-new-mac-mini-is-more-mighty-more-mini-and-built-for-apple-intelligence/article/Apple-Mac-mini-lifestyle-small-business.zip" download="" data-analytics-title="download image - Apple-Mac-mini-lifestyle-small-business_big" aria-label="Download media, A Mac mini user works at a desk surrounded by ceramics pieces."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <div><strong>When compared to the Mac mini with Intel Core i7, Mac mini with M4:</strong>
</div>
                 
             
                 <div><ul>
<li>Applies up to 2.8x more audio effect plugins in a Logic Pro project.<sup>1</sup></li>
<li>Delivers up to 13.3x faster gaming performance in World of Warcraft: The War Within.<sup>1</sup></li>
<li>Enhances photos with up to 33x faster image upscaling performance in Photomator.<sup>3</sup></li>
</ul>
</div>
                 
             
                 <div><strong>When compared to the Mac mini with M1, Mac mini with M4:</strong>
</div>
                 
             
                 <div><ul>
<li>Performs spreadsheet calculations up to 1.7x faster in Microsoft Excel.<sup>1</sup></li>
<li>Transcribes with on-device AI speech-to-text up to 2x faster in MacWhisper.<sup>1</sup></li>
<li>Merges panoramic images up to 4.9x faster in Adobe Lightroom Classic.<sup>4</sup></li>
</ul>
</div>
                 
             
                 <h2><strong>Introducing M4 Pro for Pro-Level Performance&nbsp;</strong>
</h2>
                 
             
                 <div>For users who want pro-level performance, Mac mini with M4 Pro features the world’s fastest CPU core<sup>5</sup> with lightning-fast single-threaded performance. With up to 14 cores, including 10 performance cores and four efficiency cores, M4 Pro also provides phenomenal multithreaded performance. With up to 20 cores, the M4 Pro GPU is up to twice as powerful as the GPU in M4, and both chips bring hardware-accelerated ray tracing to the Mac mini for the first time. The Neural Engine in M4 Pro is also over 3x faster than in Mac mini with M1, so on-device Apple Intelligence models run at blazing speed. M4 Pro supports up to 64GB of unified memory and 273GB/s of memory bandwidth — twice as much bandwidth as any AI PC chip —&nbsp;for accelerating AI workloads. And M4 Pro supports Thunderbolt 5, which delivers up to 120 Gb/s data transfer speeds on Mac mini, and more than doubles the throughput of Thunderbolt&nbsp;4.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, The M4 Pro logo.">
        <div>
             
              
              <div>
                The M4 Pro chip takes the advanced technologies debuted in M4 and scales them up to tackle even more demanding workloads.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2024/10/apples-new-mac-mini-apples-new-mac-mini-is-more-mighty-more-mini-and-built-for-apple-intelligence/article/Apple-Mac-mini-M4-Pro-chip.zip" download="" data-analytics-title="download image - Apple-Mac-mini-M4-Pro-chip_big" aria-label="Download media, The M4 Pro logo."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <div><strong>When compared to the Mac mini with Intel Core i7, Mac mini with M4 Pro</strong>:
</div>
                 
             
                 <div><ul>
<li>Performs spreadsheet calculations up to 4x faster in Microsoft Excel.<sup>1</sup></li>
<li><span>Executes scene-edit detection up to 9.4x faster in Adobe Premiere Pro.<sup>3</sup></span></li>
<li>Transcribes with on-device AI speech-to-text up to 20x faster in MacWhisper.<sup>1</sup></li>
<li>Processes basecalling for DNA sequencing in Oxford Nanopore MinKNOW up to 26x faster.<sup>1</sup></li>
</ul>
</div>
                 
             
                 <div><strong>When compared to the Mac mini with M2 Pro, Mac mini with M4 Pro</strong>:
</div>
                 
             
                 <div><ul>
<li>Applies up to 1.8x more audio effect plugins in a Logic Pro project.<sup>1</sup></li>
<li>Renders motion graphics to RAM up to 2x faster in Motion.<sup>6</sup></li>
<li>Completes 3D renders up to 2.9x faster in Blender.<sup>6</sup></li>
</ul>
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, A Mac mini user sits at a desk with three displays and a musical keyboard.">
        <div>
             
              
              <div>
                The Mac mini with M4 Pro comes with Thunderbolt 5 for the first time, which more than doubles transfer speeds, so users will be able to use faster external storage and connect to more accessories at the same time.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2024/10/apples-new-mac-mini-apples-new-mac-mini-is-more-mighty-more-mini-and-built-for-apple-intelligence/article/Apple-Mac-mini-lifestyle-music-studio.zip" download="" data-analytics-title="download image - Apple-Mac-mini-lifestyle-music-studio_big" aria-label="Download media, A Mac mini user sits at a desk with three displays and a musical keyboard."></a>
          </div>
      </figure>
    
  






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Upgraded Connectivity and Display Support&nbsp;</strong>
</h2>
                 
             
                 <div>The new Mac mini features a wide array of ports to drive any setup. It includes front-facing ports for more convenient access, including two USB-C ports that support USB 3, and an audio jack with support for high-impedance headphones. On the back, Mac mini with M4 includes three Thunderbolt 4 ports, while Mac mini with M4 Pro features three Thunderbolt 5 ports. Mac mini comes standard with Gigabit Ethernet, configurable up to 10Gb Ethernet for faster networking speeds, and an HDMI port for easy connection to a TV or HDMI display without an adapter. With M4, Mac mini can support up to two 6K displays and up to one 5K display, and with M4 Pro, it can support up to three 6K displays at 60Hz for a total of over 60 million pixels.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="mac-mini-connectivity">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-aa2a6f58d0676688ce811a3d004a664a" href="#gallery-aa2a6f58d0676688ce811a3d004a664a" data-ac-gallery-trigger="gallery-aa2a6f58d0676688ce811a3d004a664a"><span>Mac mini is shown from the front.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-a000bfc085c36199d7b35221570ec3dd" href="#gallery-a000bfc085c36199d7b35221570ec3dd" data-ac-gallery-trigger="gallery-a000bfc085c36199d7b35221570ec3dd"><span>Mac mini is shown from the back.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-aa2a6f58d0676688ce811a3d004a664a" aria-labelledby="gallery-dotnav-aa2a6f58d0676688ce811a3d004a664a" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:front-facing-ports">
                                
                                <div>
                                    <div>The new front-facing ports on Mac mini include two USB-C ports and an audio jack with support for high-impedance headphones.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/apples-new-mac-mini-apples-new-mac-mini-is-more-mighty-more-mini-and-built-for-apple-intelligence/article/Apple-Mac-mini-front-facing-ports.zip" download="" data-analytics-title="download image - Apple-Mac-mini-front-facing-ports_big" aria-label="Download media, Mac mini is shown from the front."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-a000bfc085c36199d7b35221570ec3dd" aria-labelledby="gallery-dotnav-a000bfc085c36199d7b35221570ec3dd" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:back-facing-ports">
                                
                                <div>
                                    <div>On the back, the M4 model features three Thunderbolt 4 ports, and the M4 Pro model includes Thunderbolt 5 for the first time. Both models also include Gigabit Ethernet and an HDMI port.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/apples-new-mac-mini-apples-new-mac-mini-is-more-mighty-more-mini-and-built-for-apple-intelligence/article/Apple-Mac-mini-back-facing-ports.zip" download="" data-analytics-title="download image - Apple-Mac-mini-back-facing-ports_big" aria-label="Download media, Mac mini is shown from the back."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A New Era with Apple Intelligence on the Mac</strong>
</h2>
                 
             
                 <div>Apple Intelligence ushers in a new era for the Mac, bringing personal intelligence to the personal computer. Combining powerful generative models with industry-first privacy protections, Apple Intelligence harnesses the power of Apple silicon and the Neural Engine to unlock new ways for users to work, communicate, and express themselves on Mac. It is available in U.S. English with macOS Sequoia 15.1. With systemwide Writing Tools, users can refine their words by rewriting, proofreading, and summarizing text nearly everywhere they write. With the newly redesigned Siri, users can move fluidly between spoken and typed requests to accelerate tasks throughout their day, and Siri can answer thousands of questions about Mac and other Apple products. New Apple Intelligence features will be available in December, with additional capabilities rolling out in the coming months. Image Playground gives users a new way to create fun original images, and Genmoji allows them to create custom emoji in seconds. Siri will become even more capable, with the ability to take actions across the system and draw on a user’s personal context to deliver intelligence that is tailored to them. In December, ChatGPT will be integrated into Siri and Writing Tools, allowing users to access its expertise without needing to jump between tools.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="mac-mini-and-apple-intelligence">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-b75292ffad2e1c90bfcda9fb581635af" href="#gallery-b75292ffad2e1c90bfcda9fb581635af" data-ac-gallery-trigger="gallery-b75292ffad2e1c90bfcda9fb581635af"><span>A Writing Tools screen features highlighted text from a scientific paper alongside proofreading and rewriting options.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-d491a29244737305f738517e6fbbbfdb" href="#gallery-d491a29244737305f738517e6fbbbfdb" data-ac-gallery-trigger="gallery-d491a29244737305f738517e6fbbbfdb"><span>A typed request to Siri says, “Show me all files Ian sent last week.”</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-b75292ffad2e1c90bfcda9fb581635af" aria-labelledby="gallery-dotnav-b75292ffad2e1c90bfcda9fb581635af" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:writing-tools">
                                
                                <div>
                                    <div>With brand-new systemwide Writing Tools powered by Apple Intelligence, users can rewrite, proofread, and summarize text virtually everywhere they type.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/apples-new-mac-mini-apples-new-mac-mini-is-more-mighty-more-mini-and-built-for-apple-intelligence/article/Apple-Mac-mini-Writing-Tools.zip" download="" data-analytics-title="download image - Apple-Mac-mini-Writing-Tools_big" aria-label="Download media, A Writing Tools screen features highlighted text from a scientific paper alongside proofreading and rewriting options."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-d491a29244737305f738517e6fbbbfdb" aria-labelledby="gallery-dotnav-d491a29244737305f738517e6fbbbfdb" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:siri">
                                
                                <div>
                                    <div>In the coming months, Siri will be even more capable on macOS Sequoia, with the ability to understand a user’s personal context and deliver intelligence that is tailored to them.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2024/10/apples-new-mac-mini-apples-new-mac-mini-is-more-mighty-more-mini-and-built-for-apple-intelligence/article/Apple-Mac-mini-type-to-Siri.zip" download="" data-analytics-title="download image - Apple-Mac-mini-type-to-Siri_big" aria-label="Download media, A typed request to Siri says, “Show me all files Ian sent last week.”"></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <div>Apple Intelligence does all this while protecting users’ privacy at every step. At its core is on-device processing, and for more complex tasks, Private Cloud Compute gives users access to Apple’s even larger, server-based models and offers groundbreaking protections for personal information. In addition, users can access ChatGPT for free without creating an account, and privacy protections are built in — their IP addresses are obscured and OpenAI won’t store requests. For those who choose to connect their account, OpenAI’s data-use policies apply.
</div>
                 
             
                 <h2><strong>The First Carbon Neutral Mac&nbsp;</strong>
</h2>
                 
             
                 <div>The new Mac mini is Apple’s first carbon neutral Mac, marking a significant milestone toward <a href="https://www.apple.com/environment/" target="_blank">Apple 2030</a>, the company’s goal to be carbon neutral across the entire carbon footprint by the end of this decade.
</div>
                 
             
                 <div>Mac mini is made with over 50 percent recycled content overall, including 100 percent recycled aluminum in the enclosure, 100 percent recycled gold plating in all Apple-designed printed circuit boards, and 100 percent recycled rare earth elements in all magnets. The electricity used to manufacture Mac mini is sourced from 100 percent renewable electricity. And, to address 100 percent of the electricity customers use to power Mac mini, Apple has invested in clean energy projects around the world. Apple has also prioritized lower-carbon modes of shipping, like ocean freight, to further reduce emissions from transportation. Together, these actions have reduced the carbon footprint of Mac mini by over 80 percent.<sup>2</sup> For the small amount of remaining emissions, Apple applies high-quality carbon credits from nature-based projects, like those generated by its innovative <a href="https://www.apple.com/newsroom/2024/03/apples-restore-fund-cultivates-new-roots-in-the-atlantic-forest/" target="_blank">Restore Fund</a>.
</div>
                 
             
                 <div>In another first for Mac mini, the packaging is now entirely fiber-based, bringing Apple closer to its goal to remove plastic from its packaging by 2025.
</div>
                 
             
         </div>
 

    
    
    


    
        
        
        
        
            <figure aria-label="Media, Mac mini with a carbon neutral logo.">
                <div>
                         
                            
                            <div>
                                The new Mac mini is Apple’s first carbon neutral Mac.
                            </div>
                        
                        
                        
                        
                        <a href="https://www.apple.com/newsroom/images/2024/10/apples-new-mac-mini-apples-new-mac-mini-is-more-mighty-more-mini-and-built-for-apple-intelligence/article/Apple-Mac-mini-carbon-neutral.zip" download="" data-analytics-title="download image - Apple-Mac-mini-carbon-neutral_inline" aria-label="Download media, Mac mini with a carbon neutral logo."></a>
                    </div>
            </figure>
        
    










    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>An Unrivaled Experience with macOS Sequoia</strong>
</h2>
                 
             
                 <div><a href="https://www.apple.com/macos/macos-sequoia-preview/" target="_blank">macOS Sequoia</a> completes the new Mac mini experience with a host of exciting features, including iPhone Mirroring, allowing users to wirelessly interact with their iPhone, its apps, and notifications directly from their Mac.<sup>7</sup> Safari, the world’s fastest browser,<sup>8</sup> now offers the Highlights feature, which quickly pulls up relevant information from a site; a smarter, redesigned Reader with a table of contents and high-level summary; and a new Video Viewer to watch videos without distractions. With Distraction Control, users can hide items on a webpage that they may find disruptive to their browsing. Gaming gets even more immersive with features like Personalized Spatial Audio and improvements to Game Mode, along with a breadth of exciting titles, including the upcoming Assassin’s Creed Shadows. Easier window tiling means users can stay organized with a window layout that works best for them. The all-new Passwords app gives convenient access to passwords, passkeys, and other credentials — all stored in one place. And users can apply new, beautiful built-in backgrounds for video calls, which include a variety of color gradients and system wallpapers, or upload their own photos.
</div>
                 
             
         </div>
 

    
    
    


     
     
    
    
        <div>
             
                 
                 
             
                 <div><ul>
<li>Customers can pre-order the new Mac mini with M4 and M4 Pro starting today, Tuesday, October 29, on <a href="https://www.apple.com/store/" target="_blank">apple.com/store</a> and in the Apple Store app in 28 countries and regions, including the U.S. It will start arriving to customers, and in Apple Store locations and Apple Authorized Resellers, beginning Friday, November&nbsp;8.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Mac mini with M4 starts at <strong>$599</strong> (U.S.) and <strong>$499</strong> (U.S.) for education. Additional technical specifications are available at <a href="https://www.apple.com/mac-mini/" target="_blank">apple.com/mac-mini</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Mac mini with M4 Pro starts at <strong>$1,399</strong> (U.S.) and <strong>$1,299</strong> (U.S.) for education. Additional technical specifications are available at <a href="https://www.apple.com/mac-mini/" target="_blank">apple.com/mac-mini</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>New accessories with USB-C — including Magic Keyboard (<strong>$99</strong> U.S.), Magic Keyboard with Touch ID (<strong>$149</strong> U.S.), Magic Keyboard with Touch ID and Numeric Keypad (<strong>$179</strong> U.S.), Magic Trackpad (<strong>$129</strong> U.S.), Magic Mouse (<strong>$79</strong> U.S.), and Thunderbolt 5 Pro Cable (<strong>$69</strong>) —&nbsp;are available at <a href="https://www.apple.com/store/" target="_blank">apple.com/store</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Apple Intelligence is available now as a free software update for Mac with M1 and later, and can be accessed in most regions around the world when the device and Siri language are set to U.S. English. The first set of features is in beta and available with macOS Sequoia 15.1, with more features rolling out in the months to come.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Apple Intelligence is quickly adding support for more languages. In December, Apple Intelligence will add support for localized English in <em>Australia</em>, <em>Canada</em>,<em> Ireland,</em> <em>New Zealand</em>, <em>South Africa</em>, and the <em>U.K.</em>, and in April, a software update will deliver expanded language support, with more coming throughout the year. Chinese, English (India), English (Singapore), French, German, Italian, Japanese, Korean, Portuguese, Spanish, Vietnamese, and other languages will be supported.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>With Apple Trade In, customers can trade in their current computer and get credit toward a new Mac. Customers can visit <a href="https://www.apple.com/shop/trade-in/" target="_blank">apple.com/shop/trade-in</a> to see what their device is worth.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>AppleCare+ for Mac provides unparalleled service and support. This includes unlimited incidents of accidental damage, battery service coverage, and 24/7 support from the people who know Mac best.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Every customer who buys directly from Apple Retail gets access to Personal Setup. In these guided online sessions, a Specialist can walk them through setup, or focus on features that help them make the most of their new device. Customers can also learn more about getting started with their new device with a Today at Apple session at their nearest Apple Store.</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    





    
    
    <div>
            <ol>
<li>Testing was conducted by Apple in September and October 2024. See <a href="https://www.apple.com/mac-mini/" target="_blank">apple.com/mac-mini</a> for more information.</li>
<li>Carbon reductions are calculated against a business-as-usual baseline scenario: No use of clean electricity for manufacturing or product use, beyond what is already available on the latest modeled grid; Apple’s carbon intensity of key materials as of 2015; and Apple’s average mix of transportation modes by product line across three years. Learn more at <a href="https://www.apple.com/environment/" target="_blank">apple.com/2030</a>.</li>
<li>Results are compared to previous-generation 3.2GHz 6-core Intel Core i7-based Mac&nbsp;mini systems with Intel Iris UHD Graphics 630, 64GB of RAM, and 2TB SSD.</li>
<li>Results are compared to previous-generation Mac mini systems with Apple M1, 8-core CPU, 8-core GPU, 16GB of RAM, and 2TB SSD.</li>
<li>Testing conducted by Apple in October 2024 using shipping competitive systems and select industry-standard benchmarks.</li>
<li>Results are compared to previous-generation Mac mini systems with Apple M2 Pro, 12-core CPU, 19-core GPU, 32GB of RAM, and 8TB SSD.</li>
<li>Available on Mac computers with Apple&nbsp;silicon and Intel-based Mac computers with a T2 Security Chip. Requires that iPhone and Mac are signed in with the same Apple&nbsp;Account using two-factor authentication, iPhone and Mac are near each other and have Bluetooth and Wi-Fi turned on, and Mac is not using AirPlay or Sidecar. Some iPhone features (e.g., camera and microphone) are not compatible with iPhone&nbsp;Mirroring.</li>
<li>Testing was conducted by Apple in August 2024. See <a href="https://www.apple.com/safari/" target="_blank">apple.com/safari</a> for more information.</li>
</ol>

        </div>



    
    
    






    

















		
		
			
























		
		

</article>



</section>
</main>


	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing in Pictures: Richard Scarry and the art of children's literature (244 pts)]]></title>
            <link>https://yalereview.org/article/chris-ware-richard-scarry</link>
            <guid>41983622</guid>
            <pubDate>Tue, 29 Oct 2024 13:24:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yalereview.org/article/chris-ware-richard-scarry">https://yalereview.org/article/chris-ware-richard-scarry</a>, See on <a href="https://news.ycombinator.com/item?id=41983622">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                    
        <h2>Writing in Pictures</h2>
            
            <p><a href="https://yalereview.org/author/chris-ware">Chris Ware</a></p>

            
            
                                                                                            <figure>
    <img src="https://d181q449nqu6en.cloudfront.net/content/craft/articles/_850xAUTO_crop_center-center_none/Scarry-Cars-Trucks-Things-That-Go.jpg?mtime=20240908123939&amp;focal=none&amp;tmtime=20240909060114" alt="" loading="lazy">
    <figcaption><p>The original cover sketch for Richard Scarry’s Cars and Trucks and Things That Go, which was first published in 1974. <span>Courtesy Penguin Random House</span></p></figcaption>
</figure>
                                                                                                                                                                <div>
    <p><span>As a boy, </span>I knew I was supposed to like cars and trucks and things that go. But as an unathletic and decidedly unboyish kid, I only got close to liking one car—my mom’s blue Volkswagen Ghia, which she used to ferry me to and from school (and, when she needed some time to herself, to her parents’—my grandparents’—house for an overnight visit). In fact, I didn’t just like that car, I loved it, so much so that the day it was towed away I secretly chipped a piece of the sky-colored paint from the chassis and tearfully hid it in a little box. I never had the chance to develop such a special relationship with a truck or a bus or an airplane or anything else with a motor or wheels—in fact, such things scared me, and to this day I have never changed a tire.</p>
<p>In my grandparents’ second-floor guest room, formerly my mother’s childhood room, one bookcase had a row of children’s books slumped to the side, offering a chronological core sample of my grandmother’s attempts to busy not only her own kids, but all the grandkids who’d stayed there before me. There were the original Oz books, a copy of <em>Ferdinand the Bull</em>, Monro Leaf’s inexplicably compelling yet mildly fascistic <em>Manners Can Be Fun, </em>some 1950s and 1960s Little Golden Books purchased at the Hinky Dinky supermarket down the street, and, among many others I’ve now long forgotten, the big blue, green, and red shiny square of Richard Scarry’s <em>Best Word Book Ever. </em>The largish (even just plain large if you were smallish when holding it) book offered a visual index of the everyday puzzle pieces of life in humble, colored-in line drawings. Each page was a fresh, funny composition of some new angle on the world, making the book a sort of quotidian picture-map containing everything imaginable and unimaginable a kid might be curious about: where and how people lived, slept, ate, played, and worked.</p>
<p>The thing is, “people” weren’t anywhere to be seen in <em>Best Word Book Ever</em>. Instead, the whole world was populated by animals: rabbits, bears, pigs, cats, foxes, dogs, raccoons, lions, mice, and more. Somehow, though, that made the book’s view of life feel more real and more welcoming. A dollhouse-like cutaway view of a rabbit family in their house getting ready for their day didn’t seem to just picture the things themselves—they <em>were </em>the things themselves, exuding a grounded warmth that said, “Yes, everywhere we live in houses and cook together and get dressed, just like you.” </p>
</div>
                                                                                                                                                                                                                                                <p>
    <em>I Am a Bunny </em>stands as one of the true tranquil masterpieces of children’s book art.
    </p>
                                                                                                                                                <div>
    <p>Mirroring these rabbits, across two pages an index-like series of images depicted a bear named Kenny getting out of bed, getting dressed, and going down for breakfast. This would galvanize me to action: I’d take out the book and mimic Kenny, washing my face with a washcloth (which I never did at my own house), brush my teeth, get dressed, and make my bed. Then I’d head downstairs to the kitchen with the book under my pencil-thin arm, where my grandmother would gamely try to serve me the same breakfast Kenny was having, emulating as best she could the individual menu items: pancakes, “warm cereal,” orange juice, bacon, and toast.</p>
<p>A little later in the book, in a two-page spread titled “Mealtime,” a family of orange pigs surrounded a large dinner table laid out with plates and bowls of various foods. The lower left corner of the rightmost page cradled a wooden bowl of evenly green lettuce leaves with three tomato wedges. I don’t know why, but that drawing so thoroughly captured… something for me that, for years at my grandparents’ house, it became my standing side order. While watching television or reading or drawing in the guest room, I’d smell the English muffin toasting and the breaded pork chops and potatoes cooking, and I’d see the setting sunlight warming the house’s old wood shingles—and I’d know my grandmother would have that three-tomato salad on the side, ready for me, just like the pigs were having in Richard Scarry’s book.</p>
<div><p>I must have been a real pain in the ass as a kid. But Richard Scarry somehow made me feel safe and settled.</p></div>
<p><span>this year is </span>the 50th anniversary of Scarry’s 1974 <em>Cars and Trucks and Things That Go, </em>which strikes me as a commemoration worthy of ballyhoo, especially now that, as a dad myself, I’ve spent so much time ferrying my own daughter to and from school and birthday parties in various cars that—well, <em>mostly </em>goed. (I’ve owned five automobiles in my life, all of them cheap, one of which smoked and required the driver’s side door to be kept shut with a bungee cord hooked to the opposite armrest, stretched across both driver and passenger. What can I say? I was a young cartoonist on a cartoonist’s budget.)</p>
<p>Unlike those budget vehicles, however, the new deluxe Penguin Random House anniversary edition of <em>Cars and Trucks and Things That Go </em>is lavishly well-made, attentively reprinted with sharp black lines and warm, rich, watercolors. It includes an especially lively afterword by Scarry’s son Huck, in which he explains, using language even a kid can understand, how his dad wrote and drew the book, as well as hinting at what it was like to grow up as the son of arguably the world’s most popular and successful children’s book author.</p>
<p>Richard McClure Scarry was born on June 5, 1919, in the Dorchester neighborhood of Boston, Massachusetts. His Irish-American father, John James Scarry, ran Scarry’s Department Store so congenially and cannily that even during the Great Depression the whole family—his mother, an aunt, four brothers, and one sister—lived comfortably. According to Walter Retan and Ole Risom’s <em>The Busy, Busy World of Richard Scarry</em>, when Scarry was a boy and his mother asked him to go to the store to get provisions, he would write his grocery list not with words but with pictures. So his mother signed him up for drawing lessons at the Boston Museum of Fine Arts, where she also brought him to see the paintings and sculptures. </p>
<p>It took Scarry, who was uninterested in school, five years to receive his high school diploma, in part because he spent a fair amount of his time lazing around at the public library and visiting burlesque shows (this time, one assumes, without his mother). This disappointed his father, who pressured him into going to a local business school, a fate to which Scarry acceded but loathed so deeply he soon withdrew and re-enrolled at the Museum of Fine Arts. “You will live in a garret and eat nothing but spaghetti,” his father warned. But Richard’s mind was made up. Then, after a few classes and December 7, 1941, he was drafted.</p>
<p>Scarry later recalled his experience in the military as “the best war ever.” At basic training in New Jersey, his commanding officers discovered that he could draw, leading Scarry to be largely excused from the rigors of pushups so that he could work as a sign painter. Leapfrogging to the rank of lieutenant (a prerequisite for his new post as art director of the Army in North Africa), he arrived at the port of Casablanca in somewhat plum circumstances, tasked with creating morale-boosting propaganda by doing things like illustrating information manuals and guidebooks and drawing maps describing the worldwide progress of Allied fighting. He and his fellow officers discovered a nice villa twenty miles outside Oran where they were permitted to stay, borrowing their colonel’s Buick to drive themselves back and forth to work. Later stationed in Venice and Paris, Scarry’s experience of World War II was, well, charmed.</p>
<p>After his discharge in 1946, Scarry moved to New York, where he briefly worked as an art director for <em>Vogue </em>and then in an advertising agency before acquiring an agent, who was able to secure him an illustration job with the then brand-new but now completely forgotten <em>Holiday </em>magazine. The job paid the princely sum of $2,000. (I can confirm from personal experience that such pay has changed little since 1946; $2,000 is still the average, if not generous, going rate for magazine artwork. But plugged into an inflation calculator, $2,000 in 1942 clocks in at $34,524.73 today.) With his living expenses suddenly covered well into the future, Scarry moved into a nicer apartment. He met an advertising copywriter named Patricia Murphy, and in 1948 they got married.</p>
<p>Meanwhile, in Racine, Wisconsin, a printing company named Western Publishing and its imprint Whitman (which had found great success in the 1930s with the Big Little Books and other novelties) were hatching a new idea for children’s literature, a series that would be christened “Little Golden Books.” Up to that point, children’s books had traditionally been a $1.50-and-up Christmas gift—$25.19 in today’s inflationary dollars—luxurious gilt volumes bestowed by great aunts that told of princes and princesses and things that didn’t go anywhere at all. These new Golden Books, by contrast, were to be cheaply produced and democratically priced at twenty-five cents, and would be sold year-round at pharmacies and, as my grandmother referred to them, “dime stores.” </p>
<p>The brainchild of Georges Duplaix and Lucille Ogle, two editors at Western’s recently opened East Coast offices in Poughkeepsie, New York, Golden Books employed displaced if not just plain refugee artists from Europe like Feodor Rojankovsky, Tibor Gergely, and Gustaf Tenggren. Working in a careful, deliberate, and illuminatory style, they carefully limned every hair of every dog—think <em>The Poky Little Puppy</em>—and set every page aglow with a strangely dark, yet warm light. On the page, their paintings were frequently vignetted in darkness, almost as if the artists still felt shadowed by the lingering specter of war. These books, dismissively looked down upon by librarians, were nonetheless immediately, snot-flyingly popular, with orders mounting into the millions of copies. Such publishing numbers were astonishing then (and are even more astonishing now, when 15,000 is considered a gee-whiz success). </p>
<p>Packaged for publishers Richard Simon and Max Schuster and their vice president Albert Leventhal, the entire series was written, drawn, edited, and printed by Western Publishing. A second wave of refugee artists signed on to their roster in 1948, this time escaping Southern California and Walt Disney’s anti-union practices. Among them were John Parr Miller (designer of Dumbo and Geppetto) and the writer-artist team of Alice and Martin Provensen.</p>
<div><p>Scarry wasn’t escaping anything, but he was hired amid this group to do up a four-page promotional brochure for Golden’s push into supermarkets. Impressed by his speedy, quality work, Western followed with a four-book illustration contract, which Scarry flexingly went on to exceed, producing not four, but <em>six </em>books before the one-year deal ran out. (Busy, busy world, indeed.) Wowed, Western signed him on for more, and the Scarrys moved to Connecticut, eventually ending up in Westport, where they went skeet shooting and boating, befriended other Golden Books artists who lived in the area (including Miller and the Provensens), and attended many parties. Then, in 1951, Scarry published his first solo writing and drawing book, <em>The Great Big Car and Truck Book</em>. </p></div>
<p><em><span>the great big car and truck book</span> </em>is, in some ways, the seed-germ of <em>Cars and Trucks and Things That Go</em>. But the differences are revealing. <em>The Great Big Car and Truck Book </em>still follows the house style of Western/Little Golden Books—careful watercolor-and-gouache illustrations that illuminate a text that is about the here and now of what people do all day. Moreover, the people driving the cars and trucks aren’t finely haired rabbits, bears, and pigs, but pink-skinned 1950s human suburbanites. The effect is curious, and, given our now-idea of Scarry, very un-Scarry-like. Like Charles Schulz’s early experiments drawing actual adults in <em>Peanuts </em>(the effect of which is psychedelic), Scarry’s humans feel just, like, <em>wrong</em>. There’s also little to distinguish his work here from other magazine illustrators of the day: the people, while charming enough, are too human to empathize with—oddly blank and impersonal, and advertising-art-like. Scarry had almost always preferred to draw animal stories—<em>Good Night Little Bear, The Bunny Book</em>—in books by his wife or other writers such as his good friend, Danish emigre Ole Risom. But it would be several years before he would do the same in his own books, substituting animals for humans as well as dropping the more labored visual approach for what we now recognize as his mature work.</p>
</div>
                                                                                                                                                                                                                                                <p>
    In Busytown there’s just enough innocent mayhem and tripping and falling to hint at a darker side of things, like failing 1970s marriages and the things on television news that adults were always yelling about. 
    </p>
                                                                                                                                                <div>
    <p>There were, of course, obstacles. One of the less appealing features of Golden’s business practice was that, with rare exceptions, they offered no royalties. This arrangement nagged at Scarry, especially after his and Patricia’s son Huck was born in 1953, so in 1955 he finally asked the imposing white-haired and lavender-blue-eyed Lucille Ogle for a revised contract that included royalties—and an advance. She readily agreed. Surprised, Scarry asked why she hadn’t offered such a deal earlier. “Because you never asked,” she replied.</p>
<p>With this new contract, though, Golden started to send Scarry less work, and he began to wonder if he was being deliberately snubbed because of his higher pay rate. So even as he was producing beautifully wrought paintings for Golden Books, he sought and then secured additional paying work from Western’s competitor Doubleday. He also created some loose storybook proposals of his own authorship in a surprisingly free and zippy pencil style. Freed from the precision of painting, the linework of these sketches—dare I say, cartoons?—came alive on the page like nothing he’d drawn before. I don’t know if the roughs he produced for his efforts were all so lively, but these certainly showed a new direction, if he decided to take it. But when Scarry shopped the proposals around, Golden and every other publisher he approached turned him down, so he shelved them. </p>
</div>
                                                                                                                                                                                                                                <figure>
    <img src="https://d181q449nqu6en.cloudfront.net/content/craft/articles/_850xAUTO_crop_center-center_none/Great-Big-Car-Truck-Book-Frontispiece.jpg?mtime=20240908124019&amp;focal=none&amp;tmtime=20240909060114" alt="" loading="lazy">
    <figcaption><p>Richard Scarry’s <em>The Great Big Car and Truck Book, </em>which was published in 1951, is in some ways the seed-germ of <em>Cars and Trucks and Things That Go. </em><span>Courtesy the Estate of Richard Scarry</span></p></figcaption>
</figure>
                                                                                                                                                                <div>
    <p>In the years that followed, Scarry continued to do exceptional work in Golden’s illuminated-painting mode, most notably his 1963 book <em>I Am a Bunny, </em>with text by his friend Risom. I never read it as a child, but I can now attest to its elegant, quiet beauty, because it was my daughter’s first word book ever, and I read it to her several hundred times. I never tired of its pictures or its words, the simple zen-like magic it evokes of the inevitability of the passing seasons always somehow putting the reader in a pleasant passenger-seat view. <em>I Am a Bunny </em>stands as one of the true tranquil masterpieces of children’s book art.</p>
<p>Even as he was working on <em>I Am a Bunny, </em>Scarry was preparing a proposal for a new kind of word book done in that free pencil style, which he called <em>Best Word Book Ever</em>. This time around, Golden accepted the proposal, and when the book was published, the fully realized Scarry World exploded into view: clean, pencil-line, doodle-like drawings that seemed lively and alive, if not to live on the very page itself. <em>Richard Scarry’s Best Word Book Ever </em>was an immediate hit, becoming one of the bestselling children’s books in history, selling seven million copies by 1975 (including the one my grandmother bought). And though Scarry was only getting a royalty of eight cents a copy (a royalty that, due to the contract he signed, did not rise in value as the price of books went up), the incredible number of copies the book sold meant that money finally started rolling in for the Scarrys.</p>
<p>Scarry produced two more books for Golden in the <em>Best Word Book Ever </em>mold: <em>Busy, Busy World </em>(1965) and <em>Storybook Dictionary </em>(1967)<em>, </em>the latter of which further plied the icono-lexicographical approach of images-as-words that had made <em>Best Word Book Ever </em>so compelling—the little pictures practically ask the reader to pluck them off the page and play with them. At that point, Random House swooped in and bought Scarry’s next book, <em>What Do People Do All Day?</em>, and became his publisher from then on. (Interestingly, after a 1990s bankruptcy, Random House also became the publisher of the entire Little Golden Books catalogue.)</p>
<p>Scarry followed <em>What Do People Do All Day? </em>with a series of books all set within the same society, including (among others) <em>Great Big Schoolhouse</em>, <em>Cars and Trucks and Things That Go, </em>and <em>Busiest People Ever! </em>The Busytown books, as they came to be known—with their dictionary-like visual presentation paired with lightly slapstick situations and the presence of recurring, memorable characters like Huckle Cat, the Pig family, and my favorite, Lowly Worm—grew into a real-feeling big world that Scarry seemed to be letting little ones into. (Lowly was perhaps the first children’s book animal character with a real nod to the ADA and the myth of “dis”-ability, and cheerfully makes his linear form work in all sorts of inspiring and disarmingly moving ways.)</p>
<p>Scarry’s guides to life both reflected and bolstered kids’ lived experience and in some cases, like my own, even provided the template for it. And while often sweet and quiet in its depiction of a picture-perfect society functioning measuredly—was Busytown urban or suburban or . . . European? (Where did all those Tudor homes and corner groceries come from, anyway?)—there’s just enough innocent mayhem and tripping and falling to hint at a darker side of things, like failing 1970s marriages and the things on television news that adults were always yelling about. </p>
<p>The busiest Busytown book is <em>Cars and Trucks and Things That Go</em>. As fascinated by the industrial world as any serious truck-spotting four-year-old, Scarry captures the ballet of traffic in a sort of frozen mimesis that’s reanimated by the act of reading and page-turning itself. Every aspect of life, however flimsily related to internal combustion travel, seems herein represented: whipped-cream delivery vans, mobile libraries, jet-fuel trucks, bookshelf-maker’s cars, ant buses, two-seater crayon cars, ambulances—the lot. There’s a simple, child-sized joy in recognizing the same characters driving by again and again in animal- and vegetable- and fruit-shaped cars while being dwarfed by accurately rendered bulldozers, heavy cranes, and thundering trucks, all traveling, page by page, left to right in the direction of the book—and the left to right of reading itself—through towns and construction sites and beaches and snow, ultimately ending in a calamitous (safe!) crash and a skidding of little cars spinning leftwards and finally stopping in front of (what else?) “Home.” Adding to the delight, throughout the book a tiny character named Gold Bug (who is literally a gold bug) hides on nearly every page, giving the engaged child a chance to find him over and over again in an exercise that would today be called “interactive” but we used to just call “looking.”</p>
<div><p>The Busytown books were enormous successes in America. But Scarry wrote and drew them in Switzerland, where he decided to move in 1967 after a three-week ski vacation with his son. What seems to have been an impulsive decision starts to makes sense if you’ve spent a few days immersed in Scarry’s work writing an essay for <em>The Yale Review</em>: a decidedly un-American tone runs through much of it. By “un-American” I don’t mean anti-American. Instead, I mean there’s a top-down, citizen-as-responsible-contributor, sense-of-oneself-as-part-of-something-bigger that feels, well, civilized. Even as a kid, I noticed that something about <em>Best Word Book Ever </em>felt odd, and I decided that Scarry was a balding Englishman, tweedy with possible pipe and maybe even one of those mountaineering hats with a feather in it. He was not any of those things. But the more one looks at his work, the more one sees how the European daily grocery trip, the walk to a nearby shop or tradesman’s guild, the tiny apple car fit for a worm are not part of the blowout-all-in-for-oneself-oil-fueled-free-for-all toward which America was barreling in the late 1960s. (Except, perhaps, in <em>Cars and Trucks and Things That Go — </em>though Europe has traffic, too.) So it’s perhaps unsurprising that Scarry spent the rest of his life first in Lausanne and then Gstaad, in a lovely chalet, hardly looking back while America slowly ground itself to pieces.</p></div>
<p><span>scarry continued</span> to produce books for another two decades, all of them featuring animals in place of humans. This actually caused a mild panic at Random House when <em>What Do People Do All Day? </em>was being published, with the staff asking: Shouldn’t it be called <em>What Do Animals Do All Day? </em>The dispute was short-lived since the answer (“No!”) was so obvious, but it hints at something important about the narrative energy on which Scarry’s engine runs. In children’s books, animals are frequently introduced as the first vessels to receive the natural empathy with which children are born. See: Golden’s own <em>Baby Farm Animals </em>(pictures by Garth Williams), <em>The Lively Little Rabbit </em>(pictures by Gustaf Tenggren), <em>The Animals of Farmer Jones </em>(pictures by Scarry), and about ten thousand other children’s books (pictures by everyone else). The natural inclination to ask “do animals feel the same things we do?” is confirmed with a smile and a tuck-in, what in literary terms is cumbersomely called “anthropomorphization” but in everyday words is just “caring.”</p>
<p>As we grow up, though, the truth will out: Mrs. Cow makes a good burger, those chicken fingers were Miss Clucky, and don’t forget to check the trap to see if we caught Mr. Mouse. This all then slides into discovering that not everyone is as nice as they seem, and it’s good to protect oneself on the playground; before long, one can even end up in ROTC, heading into basic training and rolling away in a tank. Fold in the especially twenty-first-century phenomenon of the “first-person shooter” in kids’ video games—surely the most telling perversion of literary terminology America could have hoped for to permanently indict itself—and children’s literature, to say nothing of the idea of polite civilization, is easily relegated to the category of the hopelessly naïve.</p>
</div>
                                                                                                                                                                                                                                                <p>
    As fascinated by the industrial world as any serious truck-spotting four-year-old, Scarry captures the ballet of traffic in a sort of frozen mimesis that’s reanimated by the act of reading and page-turning itself.
    </p>
                                                                                                                                                <div>
    <p>Scarry studiously avoided granting cows and chickens driver’s licenses. But the pigs? Where’s the bacon in Kenny’s breakfast coming from? So his representation of animal society indeed raises some odd questions, but rarely seems to have bothered readers (with the exception of those literal-minded Random House editors). By contrast, when Art Spiegelman’s graphic novel <em>Maus: A Survivor’s Tale </em>received the Pulitzer Prize in 1992, it provoked vociferous criticism from people offended by its depiction of its characters as animals. Jews were mice (picking up on Hitler’s calling Jews “vermin” or “rats”), Germans were cats, Americans were dogs, (Christian) Poles were pigs, and the French were (of course) frogs. Not surprisingly, many readers also objected to Spiegelman choosing the comic book—a form associated with children’s literature—to tell the story of his mother’s suicide and his father’s nightmarish time in Auschwitz. </p>
<div><p>Such criticisms entirely missed the point of Spiegelman’s work. Originally written as a short comic strip story for Terry Zwigoff’s 1972 underground comic book <em>Funny Animals</em>—which Zwigoff created to benefit animal rights organizations after visiting a slaughterhouse—the strip was later expanded by Spiegelman into a novel-length work. The book turns on the idea of ideas corrupted to the level of Idea: reducing humanity to something to be exterminated by exterminating the ability to see the human being before your very eyes. Had Spiegelman drawn “actual” people, the reader would no longer be complicit in the psychological deformation of the Holocaust itself. Biographically nonfiction in its text yet fiction in its pictures, the book works an ingenious, tortuous turnaround in the mind—and the eye—of the reader. It could not have been told just in words.</p></div>
<p><span>richard scarry’s work</span> could not have been told just in words, either. As Walter Retan and Ole Risom argue, Scarry “didn’t write his stories; he drew them.” His bestselling book was not titled <em>Best Picture Book Ever, </em>even though that’s really what it is. As children, we see the world in all its detail, texture, and beauty, but when we learn the word for, say, a bird, we cease to see it as clearly or curiously as we did before we categorized and dismissed it. John Updike eloquently and beautifully captures this confounding contradiction in his short story “Pigeon Feathers,” where the main character only notices the iridescent, divine beauty in a pigeon’s plumage after he’s shot several of them to pieces in the rafters of a barn. Like it or not, just as adulthood runs roughshod over childhood, words chew images to shreds, and it’s up to the artist—or the writer or the cartoonist—to put those images back together again. Pictures are our first language for understanding the world, but that doesn’t mean they should be ignored in favor of a second. Or, as Dave Eggers once kindly put it, cartoonists (and I include Scarry in this group) needn’t be punished for having two skills instead of one. </p>
<p>Scarry drove headlong into a picture-world that he illustrated with words, a world which blossomed into life in a way that his earlier books for Golden, in which his pictures illustrated words, simply couldn’t. He kept in touch with his child self so well that, as both his biographers and other writers have highlighted, he didn’t test his books on children, because he had “remained very childlike himself.” And he knew exactly where the child inside him still lived: his kind heart.</p>
</div>
                                                                                                                                                            
                                <div>
                    <p><a href="https://yalereview.org/author/chris-ware">Chris Ware</a> is an artist, writer, and regular contributor to <em>The New Yorker</em>; his book <a href="https://bookshop.org/a/16648/9780375404535"><em>Jimmy Corrigan: The Smartest Kid on Earth</em></a> was awarded the Guardian Prize and <a href="https://bookshop.org/a/16648/9780375424335"><em>Building Stories</em></a> was chosen as a Top Ten Fiction Book by <em>The New York Times.</em> A traveling retrospective of his work began at the Centre Pompidou in 2022 and will conclude at the Centre de Cultura Contemporània in Barcelona in Spring 2025.
                            </p>
                    </div>

                            


    

    
    

            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shopify Is Winning Salesforce Clients, Stoking E-Commerce Rivalry (127 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2024-10-29/shopify-is-winning-salesforce-clients-stoking-e-commerce-rivalry</link>
            <guid>41983607</guid>
            <pubDate>Tue, 29 Oct 2024 13:23:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2024-10-29/shopify-is-winning-salesforce-clients-stoking-e-commerce-rivalry">https://www.bloomberg.com/news/articles/2024-10-29/shopify-is-winning-salesforce-clients-stoking-e-commerce-rivalry</a>, See on <a href="https://news.ycombinator.com/item?id=41983607">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A deep history of Halloween (115 pts)]]></title>
            <link>https://resobscura.substack.com/p/a-very-deep-history-of-halloween</link>
            <guid>41983412</guid>
            <pubDate>Tue, 29 Oct 2024 13:00:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://resobscura.substack.com/p/a-very-deep-history-of-halloween">https://resobscura.substack.com/p/a-very-deep-history-of-halloween</a>, See on <a href="https://news.ycombinator.com/item?id=41983412">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>You know the holiday: the one where people wear outlandish costumes and sweet things are eaten. It’s fun, but also otherworldly, with roots in an ancient belief that </span><em>this evening</em><span> — this one night at the change of the seasons —&nbsp;is when spirits roam the earth. </span></p><p><span>I’m referring, of course, to </span><em><a href="https://en.wikipedia.org/wiki/Chaharshanbe_Suri#Spoon-banging" rel="">qāšoq-zani</a></em><span>, celebrated in Iran on the eve of </span><a href="https://en.wikipedia.org/wiki/Chaharshanbe_Suri" rel="">Chaharshanbe Suri</a><span>, the beginning of the Persian New Year festivities.</span></p><p>And also Halloween. </p><p><em>And</em><span> Día de Muertos. </span></p><p>The days of the calendar differ. But it intrigues me that there is a wide swathe of the world which celebrates a holiday marked by sweets, blurred boundaries between the living and the dead, votive candles or bonfires, and costumes. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcaedd20-3225-4841-95ed-fb7b22f029a3_2090x880.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcaedd20-3225-4841-95ed-fb7b22f029a3_2090x880.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcaedd20-3225-4841-95ed-fb7b22f029a3_2090x880.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcaedd20-3225-4841-95ed-fb7b22f029a3_2090x880.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcaedd20-3225-4841-95ed-fb7b22f029a3_2090x880.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcaedd20-3225-4841-95ed-fb7b22f029a3_2090x880.png" width="1456" height="613" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/dcaedd20-3225-4841-95ed-fb7b22f029a3_2090x880.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:613,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2686298,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcaedd20-3225-4841-95ed-fb7b22f029a3_2090x880.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcaedd20-3225-4841-95ed-fb7b22f029a3_2090x880.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcaedd20-3225-4841-95ed-fb7b22f029a3_2090x880.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fdcaedd20-3225-4841-95ed-fb7b22f029a3_2090x880.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Halloween, Día de Muertos, and Chaharshanbe Suri</figcaption></figure></div><p><span>How much can we really know about things like this — cultural patterns which </span><em>might </em><span>share a common origin in the distant past, but which have no documented historical connection?</span></p><p><span>One of my favorite historians, Carlo Ginzburg, is a specialist in this very question.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-150850410" href="https://resobscura.substack.com/p/a-very-deep-history-of-halloween#footnote-1-150850410" target="_self" rel="">1</a></span><span> Much of Ginzburg’s work explores what you might call the </span><strong>history of liminal states</strong><span> —  moments when the perceived divisions between the ordinary world and the spirit world (or between rule and </span><a href="https://en.wikipedia.org/wiki/Lord_of_Misrule" rel="">misrule</a><span>, or consciousness and unconsciousness) fall apart.</span></p><p><span>Ginzburg’s first book, </span><em><a href="https://en.wikipedia.org/wiki/The_Night_Battles" rel="">The Night Battles</a><span> </span></em><span>(1966), dove into one specific example: the </span><em>benandanti</em><span> (“good walkers”) of the area around Renaissance Venice, a kind of agrarian secret society who believed that they battled witches in their sleep. At the end of the book, Ginzburg argues that these </span><em>benandanti</em><span> were likely a survival from a Neolithic fertility cult. This, in turn, may have had its origin in shamanistic practices from the Central Asian Steppe. </span></p><p><span>Is he right? There’s no smoking gun source. But Ginzburg is an extremely careful scholar, and he has spent decades amassing evidence. Personally, I find the evidence compelling. Familiar things are </span><a href="https://resobscura.substack.com/p/why-i-love-etymologies" rel="">sometimes much older than we assumed</a><span>.</span></p><p>For the rest of this post, I’ll be doing something in Ginsburg’s spirit —&nbsp;but more slapdash — as I do my best to follow the thread of Halloween back as far back as possible. </p><p><span>Halloween has origins in </span><a href="https://en.wikipedia.org/wiki/Samhain" rel="">Samhain</a><span>, a major annual festival of the ancient Celts, which took place on November 1 and was distinguished by bonfires, feasting, and the belief that the spirits of the “Otherworld” roamed the earth on this night. By the ninth century CE, elements of Samhain had been Christianized via the Feast of All Saints, also known as All Hallow’s Day. Folk customs preserved pre-Christian practices on the evening </span><em>before </em><span>All Hallows’s Day (“All Hallow’s Eve”). These, it is claimed, developed into the rudiments of the modern holiday of Halloween in the early modern British Isles, especially Ireland. </span></p><p>Meanwhile, in 16th century Mexico, Aztec devotion to Mictecacihuatl, the Lady of the Dead, merged with the Feast of All Saints. This produced yet another variation on these customs: Día de Muertos. </p><p>So far, so good. But is this really the furthest back we can go? </p><p><span>The earliest </span><a href="https://www.google.com/books/edition/The_Stations_of_the_Sun/t-P24jQyfP0C?hl=en&amp;gbpv=1&amp;pg=PA361&amp;printsec=frontcover&amp;dq=samhain" rel="">reliable written reference</a><span> that I could find is in a tenth century Irish epic poem which speaks of “Samhain, when the summer goes to rest.” A 12th-century Irish source records a week of feasting during this time, when “there would be nothing but meetings and games and amusements and entertainments and eating and feasting" (sounds fun!).</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-150850410" href="https://resobscura.substack.com/p/a-very-deep-history-of-halloween#footnote-2-150850410" target="_self" rel="">2</a></span><span> There is talk of kindling sacred fires, and of spirits and ghosts wandering the earth. But very little detail. </span></p><p><span>This is where archaeology lends a hand. Because it turns out that several passage tombs from Neolithic Ireland are oriented such that their entrances would’ve been lit by the sun on the </span><em>exact day of Samhain</em><span>. Here we have a fascinating example of two different types of historical evidence working in tandem to make a compelling case for a link across several millennia. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F797169b9-1acf-46d8-a67d-7a5e0ba2f050_500x375.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F797169b9-1acf-46d8-a67d-7a5e0ba2f050_500x375.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F797169b9-1acf-46d8-a67d-7a5e0ba2f050_500x375.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F797169b9-1acf-46d8-a67d-7a5e0ba2f050_500x375.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F797169b9-1acf-46d8-a67d-7a5e0ba2f050_500x375.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F797169b9-1acf-46d8-a67d-7a5e0ba2f050_500x375.jpeg" width="500" height="375" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/797169b9-1acf-46d8-a67d-7a5e0ba2f050_500x375.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:375,&quot;width&quot;:500,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Samhain - World History Encyclopedia&quot;,&quot;title&quot;:&quot;Samhain - World History Encyclopedia&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Samhain - World History Encyclopedia" title="Samhain - World History Encyclopedia" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F797169b9-1acf-46d8-a67d-7a5e0ba2f050_500x375.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F797169b9-1acf-46d8-a67d-7a5e0ba2f050_500x375.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F797169b9-1acf-46d8-a67d-7a5e0ba2f050_500x375.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F797169b9-1acf-46d8-a67d-7a5e0ba2f050_500x375.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The Mound of the Hostages, a passage tomb from circa 3100 BCE in Ireland which is aligned with Samhain. </figcaption></figure></div><p><span>The archaeological evidence for this seems pretty robust, and at times is surprisingly detailed —&nbsp;for instance, </span><a href="https://www.tandfonline.com/doi/full/10.1080/14702541.2021.2013521#abstract" rel="">this study</a><span> theorizes that a specific standing stone in Scotland was a place where “local chieftains, titled after the [cuckoo] bird and ‘married’ to the local goddess of sovereignty that personified Venus, were tied to the stone and ritually sacrificed.” This, it is claimed, happened on Samhain “at eight-year intervals from the Bronze Age until the late Iron Age.”</span></p><p>That same study includes a fascinating detail: </p><blockquote><p>The evidence suggests that as part of the ritual the victim was given a drugged drink which reduced him to a state of semi-consciousness; tied to a standing stone and despatched with a sacred weapon.</p></blockquote><p><span>Now we’re getting somewhere. Because both of those things — the </span><a href="https://en.wikipedia.org/wiki/Soma_(drink)" rel="">ritual drug</a><span> and the </span><a href="https://en.wikipedia.org/wiki/Proto-Indo-European_mythology#Cults" rel="">ritual weapon</a><span> — sound </span><em>distinctly </em><span>proto-Indo-European. </span></p><p>Meaning very, very old.</p><p><em><span>If you’re enjoying this post, </span><strong>please consider becoming a</strong><span> </span><strong>paid subscriber</strong><span>. Your support is essential for giving me time to write Res Obscura — one of the few places online with ad-free, original longform historical writing. Paid subscribers also get access to:</span></em></p><ul><li><p><em>Monthly special posts</em></p></li><li><p><em>Future planned Q&amp;As</em></p></li><li><p><em>Early access to works in progress</em></p></li></ul><p><span>Once we get back to proto-Indo-European religion, things invariably get weird (</span><a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=%22intercourse+with+a+mare%22+%22Indo-European%22&amp;btnG=" rel="">phrases like “ritual human-mare intercourse” are not uncommon</a><span>). And, since we’re dealing with a society that existed eight thousand or more years ago, any claim we can make is deeply uncertain. </span></p><p><span>But claims can still be made. In her book </span><em><a href="https://www.google.com/books/edition/Celtic_Cosmology_and_the_Otherworld/9jZbDwAAQBAJ?hl=en&amp;gbpv=1&amp;dq=celtic+cosmology+and+the+otherworld&amp;pg=PP1&amp;printsec=frontcover" rel="">Celtic Cosmology and the Otherworld</a></em><span>, Sharon Paice MacLeod draws on comparative mythology, linguistic evidence, and archaeology to argue for an</span></p><blockquote><p><span>Indo-European cosmology in which deities inhabited the bright sky realm, and human beings —&nbsp;those that “belonged to the earth” —&nbsp;lived below them. In Celtic cultures, at least, there appears to have been a shift; human beings lived in the realm above, and the gods lived below in the Underworld. This may be the result of changes in religious belief and practice which started in the late Bronze Age in Europe, in which the religious focus on the heavens (as evident from pre-Iron Age monuments and alignments) changed to focus on the lower world. All across Europe, offerings began to be made into bodies of water (and ostensibly, into the earth as well). It has been theorized that this took place due to deterioration in climate in the later Bronze Age.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-150850410" href="https://resobscura.substack.com/p/a-very-deep-history-of-halloween#footnote-3-150850410" target="_self" rel="">3</a></span></p></blockquote><p>As an example of post-christian survivals of this cosmology, MacLeod cites the case of an Irish priest living in 8th century Germany —&nbsp;Virgil by name — who angered the Pope himself with his heretical preaching that “there was another world and other men beneath the earth.”</p><p>Back to a potential link between the Persian rites around Nowruz and the modern Halloween. </p><p><span>It at least seems possible that there was a set of proto-Indo-European beliefs and rituals involving an evening which briefly parted the veil between the human world and the world of the dead/spirits/deities (a word which, originally, meant “shining like the sun”). Among the ancient Iranians, this realm of the divine continued to be the sky. And, by extension, the ritual fires which moved from earth </span><em>to </em><span>the sky. It is notable that both Samhain and the festivities before Nowruz involve ritual bonfires. </span></p><p><span>At some point, as MacLeod writes, the Celtic branch of this ritual tradition shifted the location of the spirits/dead/gods from the sky to the earth or water (though still emphasizing links to the sky, via the passage tombs oriented toward the sun). This may be reflected in the archaeological record of the la Tené culture, famous for its votive offerings deposited in wetlands and bogs. In fact, it has been theorized that the famous “</span><a href="https://en.wikipedia.org/wiki/Bog_body" rel="">bog bodies</a><span>” of proto-Celtic Europe were ritual human sacrifices that reflected this tradition —&nbsp;and, indeed, that some bog bodies may have been killed on or around the date of Samhain.</span></p><p><span>Is it coincidence, then, that the term </span><em><a href="https://www.degruyter.com/document/doi/10.1515/fabl.1977.18.1.226/html" rel="">jack-o’-lantern</a></em><span> “comes from the phenomenon of strange lights flickering over peat bogs”? </span></p><p><span>Maybe so. But then again, maybe not. One thing I love about history is that some things </span><em>really do</em><span> go back ten thousand years — the myth of a </span><a href="https://en.wikipedia.org/wiki/*%E1%B8%B0%C3%A9rberos" rel="">dog that guards the gates of the underworld</a><span>, for instance. We can’t always prove the link, but we can find little moments of connection across time that are more than coincidental. </span></p><p>I, for one, find these links beautiful. And also a little spooky. </p><p><span>•&nbsp;A mysterious bronze lion has sat at the top of a pillar in Venice’s St. Mark’s Square since at least the twelfth century. Is it actually Chinese? (</span><em><a href="https://archaeologymag.com/2024/09/lion-of-st-marks-square-in-venice-is-chinese/" rel="">Archaeology Magazine</a></em><span>)</span></p><p><span>•&nbsp;“The Frankfurt Kitchen, as it was known—rational, unpretentious, and socially oriented—was conceived as one of the first steps toward building a better, more egalitarian world in the late 1920s.” (</span><em><a href="https://www.moma.org/interactives/exhibitions/2010/counter_space/the_frankfurt_kitchen/" rel="">Museum of Modern Art </a></em><a href="https://www.moma.org/interactives/exhibitions/2010/counter_space/the_frankfurt_kitchen/" rel="">blog</a><span>)</span></p><p><span>•&nbsp;One of the best academic article titles I’ve ever encountered, found while researching this post: </span><a href="https://www.jstor.org/stable/1259547" rel="">“Kings Dying on Tuesday”</a><span> by G. F. Dalton, 1972. </span></p><p data-attrs="{&quot;url&quot;:&quot;https://resobscura.substack.com/p/a-very-deep-history-of-halloween/comments&quot;,&quot;text&quot;:&quot;Leave a comment&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://resobscura.substack.com/p/a-very-deep-history-of-halloween/comments" rel=""><span>Leave a comment</span></a></p><p data-attrs="{&quot;url&quot;:&quot;https://resobscura.substack.com/p/a-very-deep-history-of-halloween?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://resobscura.substack.com/p/a-very-deep-history-of-halloween?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Launch HN: Integuru (YC W24) – Reverse-engineer internal APIs using LLMs (182 pts)]]></title>
            <link>https://github.com/Integuru-AI/Integuru</link>
            <guid>41983409</guid>
            <pubDate>Tue, 29 Oct 2024 13:00:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Integuru-AI/Integuru">https://github.com/Integuru-AI/Integuru</a>, See on <a href="https://news.ycombinator.com/item?id=41983409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Integuru</h2><a id="user-content-integuru" aria-label="Permalink: Integuru" href="#integuru"></a></p>
<p dir="auto">An AI agent that generates integration code by reverse-engineering platforms' internal APIs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Integuru in Action</h2><a id="user-content-integuru-in-action" aria-label="Permalink: Integuru in Action" href="#integuru-in-action"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Integuru-AI/Integuru/blob/main/integuru_demo.gif"><img src="https://github.com/Integuru-AI/Integuru/raw/main/integuru_demo.gif" alt="Integuru in action" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What Integuru Does</h2><a id="user-content-what-integuru-does" aria-label="Permalink: What Integuru Does" href="#what-integuru-does"></a></p>
<p dir="auto">You use <code>create_har.py</code> to generate a file containing all browser network requests, a file with the cookies, and write a prompt describing the action triggered in the browser. The agent outputs runnable Python code that hits the platform's internal endpoints to perform the desired action.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How It Works</h2><a id="user-content-how-it-works" aria-label="Permalink: How It Works" href="#how-it-works"></a></p>
<p dir="auto">Let's assume we want to download utility bills:</p>
<ol dir="auto">
<li>The agent identifies the request that downloads the utility bills.
For example, the request URL might look like this:
<div data-snippet-clipboard-copy-content="https://www.example.com/utility-bills?accountId=123&amp;userId=456"><pre><code>https://www.example.com/utility-bills?accountId=123&amp;userId=456
</code></pre></div>
</li>
<li>It identifies parts of the request that depend on other requests.
The above URL contains dynamic parts (accountId and userId) that need to be obtained from other requests.

</li>
<li>It finds the requests that provide these parts and makes the download request dependent on them.
<div data-snippet-clipboard-copy-content="GET https://www.example.com/get_account_id
GET https://www.example.com/get_user_id"><pre><code>GET https://www.example.com/get_account_id
GET https://www.example.com/get_user_id
</code></pre></div>
</li>
<li>This process repeats until the request being checked depends on no other request and only requires the authentication cookies.</li>
<li>The agent traverses up the graph, starting from nodes (requests) with no outgoing edges until it reaches the master node while converting each node to a runnable function.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Generate a dependency graph of requests to make the final request that performs the desired action.</li>
<li>Allow input variables (for example, choosing the YEAR to download a document from). This is currently only supported for graph generation. Input variables for code generation coming soon!</li>
<li>Generate code to hit all requests in the graph to perform the desired action.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Setup</h2><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<ol dir="auto">
<li>Set up your OpenAI <a href="https://platform.openai.com/account/api-keys" rel="nofollow">API Keys</a> and add the <code>OPENAI_API_KEY</code> environment variable. (We recommend using models that are at least as capable as OpenAI o1-mini. Models on par with OpenAI o1-preview are ideal.)</li>
<li>Install Python requirements via poetry:

</li>
<li>Open a poetry shell:

</li>
<li>Run the following command to spawn a browser:
<div data-snippet-clipboard-copy-content="poetry run python create_har.py"><pre><code>poetry run python create_har.py
</code></pre></div>
Log into your platform and perform the desired action (such as downloading a utility bill).</li>
<li>Run Integuru:
<div data-snippet-clipboard-copy-content="poetry run python -m integuru --prompt &quot;download utility bills&quot;"><pre><code>poetry run python -m integuru --prompt "download utility bills"
</code></pre></div>
You can also run it via Jupyter Notebook <code>main.ipynb</code></li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">After setting up the project, you can use Integuru to analyze and reverse-engineer API requests for external platforms. Simply provide the appropriate .har file and a prompt describing the action that you want to trigger.</p>
<div data-snippet-clipboard-copy-content="poetry run python -m integuru --help
Usage: python -m integuru [OPTIONS]

Options:
  --model TEXT                    The LLM model to use (default is gpt-4o)
  --prompt TEXT                   The prompt for the model  [required]
  --har-path TEXT                 The HAR file path (default is
                                  ./network_requests.har)
  --cookie-path TEXT              The cookie file path (default is
                                  ./cookies.json)
  --max_steps INTEGER             The max_steps (default is 20)
  --input_variables <TEXT TEXT>...
                                  Input variables in the format key value
  --generate-code                 Whether to generate the full integration
                                  code
  --help                          Show this message and exit."><pre><code>poetry run python -m integuru --help
Usage: python -m integuru [OPTIONS]

Options:
  --model TEXT                    The LLM model to use (default is gpt-4o)
  --prompt TEXT                   The prompt for the model  [required]
  --har-path TEXT                 The HAR file path (default is
                                  ./network_requests.har)
  --cookie-path TEXT              The cookie file path (default is
                                  ./cookies.json)
  --max_steps INTEGER             The max_steps (default is 20)
  --input_variables &lt;TEXT TEXT&gt;...
                                  Input variables in the format key value
  --generate-code                 Whether to generate the full integration
                                  code
  --help                          Show this message and exit.
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=7OJ4w5BCpQ0" rel="nofollow"><img src="https://camo.githubusercontent.com/5359393c728be0d7bba59bdb2927a90484c1f5d30e64f0ff374ca849f9a7bedc/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f374f4a34773542437051302f302e6a7067" alt="Demo Video" data-canonical-src="https://img.youtube.com/vi/7OJ4w5BCpQ0/0.jpg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions to improve Integuru are welcome. Please feel free to submit issues or pull requests on the project's repository.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Info</h2><a id="user-content-info" aria-label="Permalink: Info" href="#info"></a></p>
<p dir="auto">Integuru is built by Integuru.ai. Besides our work on the agent, we take custom requests for new integrations or additional features for existing supported platforms. We also offer hosting and authentication services. If you have requests or want to work with us, reach out at <a href="mailto:richard@taiki.online">richard@taiki.online</a>.</p>
<p dir="auto">We open-source unofficial APIs that we've built already. You can find them <a href="https://github.com/Integuru-AI/APIs-by-Integuru">here</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to get the whole planet to send abuse complaints to your best friends (434 pts)]]></title>
            <link>https://delroth.net/posts/spoofed-mass-scan-abuse/</link>
            <guid>41982698</guid>
            <pubDate>Tue, 29 Oct 2024 11:17:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://delroth.net/posts/spoofed-mass-scan-abuse/">https://delroth.net/posts/spoofed-mass-scan-abuse/</a>, See on <a href="https://news.ycombinator.com/item?id=41982698">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-start"><div><p><time datetime="2024-10-29T10:00:00+0100">October 29, 2024
</time><span>- </span><span><span>11 mins read</span></span></p></div><p>It all begins with one scary email late at night just before I had to go to
sleep:</p><div><pre tabindex="0"><code>From: abuse@hetzner.com
Date: 2024-10-29 01:03:00 CET
Subject: AbuseInfo: Potential Security issue: AS24940: 195.201.9.37

We have received an abuse report from abuse@watchdogcyberdefense.com for your
IP address 195.201.9.37.

We are automatically forwarding this report on to you, for your information.
You do not need to respond, but we do expect you to check it and to resolve any
potential issues.

&gt; To assist you in understanding the situation, we have provided the relevant
&gt; log data below, with timestamps adjusted to our GMT +8 timezone:
&gt;
&gt;                 DateTime   Action      AttackClass      SourceIP Srcport Protocol   DestinationIP DestPort
&gt; 0   28-Oct-2024 19:39:11   DENIED                   195.201.9.37   36163      TCP  202.91.162.233       22
&gt; &lt;snip&gt;
&gt; 20  28-Oct-2024 20:36:33   DENIED                   195.201.9.37   22044      TCP   202.91.161.97       22
&gt; 21  28-Oct-2024 20:41:37   DENIED                   195.201.9.37    9305      TCP   202.91.163.36       22
&gt; 22  28-Oct-2024 20:50:33   DENIED                   195.201.9.37   39588      TCP  202.91.163.199       22
&gt; 23  28-Oct-2024 20:50:58   DENIED                   195.201.9.37   62973      TCP   202.91.161.41       22
&gt; 24  28-Oct-2024 20:51:50   DENIED                   195.201.9.37    3085      TCP   202.91.161.97       22
</code></pre></div><p>At first glance, this sounds pretty bad. One of my servers suddenly deciding to
start sending SSH connections to the wider internet. This is usually a pretty
strong indicator of malware compromise, and I had to act quickly if that was
the case. Luckily, I’ve worked in infosec for a while, and some years ago I
even did some freelance work doing forensics and cleanup of infected servers.</p><p>So, not completely out of my element, I was surprised when after an hour or two
I found no evidence of anything happening out of the ordinary. It’s always hard
to prove a negative, but really, the machine was fine. No odd process, no
filesystem modifications, no odd network traffic (as observed by the
hypervisor, not by the server itself which happens to be a VM - just to be
extra sure!). If it was a malware compromise incident, the malware would have
been pretty stealthy, and that runs against the idea of it having been
commanded to scan the internet - in general, a very loud and noticeable action.</p><p>I turned to the regularly running services on the machine. This is my main
datacenter-hosted server, and I run a bunch of distributed or federated
services on there:</p><ul><li>Syncthing relay.</li><li>Mastodon instance.</li><li>Tor relay (not exit, internal node only).</li><li>Matrix homeserver.</li></ul><p>After close inspection, the Tor relay does connect to a few other relays that
are hosted on port 22, but that’s a very limited set of IPs, and it doesn’t
include anything in the network that sent my ISP the abuse complaint. Unlikely
candidate. I thought maybe Matrix or Mastodon could be abused to send commanded
requests to arbitrary IP:port destinations, but logging for both indicated
nothing of the sort was (visibly) happening. The Sidekiq queue for my Mastodon
instance was also absent of any trace of this, when I’d have expected to see
e.g. retries queued if it was involved.</p><p>What was happening there? Was the abuse complaint just bogus?</p><h2 id="the-smoking-gun">The smoking gun</h2><p>Then, I noticed something in one of my <code>tcpdump</code> that was still running to
monitor traffic involving port 22 on that server. I had originally ran
<code>tcpdump</code> filtering on <code>dst port 22</code>, since this is what would show traffic
originating from my server going to remote destinations. However, for some
reason, I dropped that filter at some point, instead filtering <code>not src host 195.201.9.37</code> instead (my server’s IP). This is when this showed up:</p><div><pre tabindex="0"><code>04:14:25.286063 IP 45.187.212.68.22 &gt; 195.201.9.37.59639: Flags [R.], seq 0, ack 41396686, win 0, length 0
04:14:25.291455 IP 107.152.7.33.22 &gt; 195.201.9.37.39793: Flags [R.], seq 0, ack 1391844539, win 0, length 0
04:14:25.322255 IP 107.91.78.158.22 &gt; 195.201.9.37.48900: Flags [R.], seq 0, ack 1434896088, win 65535, length 0
</code></pre></div><p>Something <em>was</em> in fact going on. But not at all what I was expecting. Turns
out: no connections were coming out of my server and going to the port 22 of
random machines. But some random internet machines <em>were</em> in fact sending me
TCP reset packets.</p><p>If you’ve been around networking/infosec communities for a while, you might now
be screaming: backscatter! Source IP spoofing! And yeah, this was my first
thought too. Let’s do a quick aside to go into what those things mean.</p><h2 id="ip-spoofing-on-the-internet">IP spoofing on the internet</h2><p>Turns out, it’s pretty trivial to send packets to various destinations on the
Internet with a fake source IP address (of course, the destination IP needs to
be correct, since it determines… the destination). Many ISPs adhere to the
<a href="https://www.rfc-editor.org/info/bcp38" target="_blank">Best Current Practice (BCP) 38</a>, which
can be summarized by the following: “if you peer with a network, you should
only allow them to send IP packets using IP address you expect from them”.
Unfortunately, that filtering can often only be done early on in a packet’s
route to its destination. Once the packet gets to a large transit provider,
their peers expect that provider to carry traffic from the whole internet to
them, and thus are not able to do any meaningful filtering.</p><p>Which means, if you just find one transit provider which doesn’t do BCP38
filtering… you can send IP packets tagged with any source IP you want! And
unfortunately, even though the origins of BCP38 date back to 1998… there are
still network providers 25 years later that don’t implement it. APNIC has <a href="https://blog.apnic.net/2023/05/03/why-is-source-address-validation-still-a-problem/" target="_blank">a
great article from last year on the subject</a>.</p><p>The consequences in practice shouldn’t be too bad. TCP, QUIC, and generally
anything using (d)TLS requires roundtrips, which can’t happen when a source IP
is spoofed. Spoofing the source IP means that you get to send a “wrong”
packets, but the replies to that packet still get sent to the source IP you
spoofed, the spoofer doesn’t get to see them and process them. There are a few
well known abuse vectors that rely on spoofing, such as reflection DDoS, but
it’s not usually a concern.</p><p>Unless…</p><h2 id="guessing-the-motive">Guessing the motive</h2><p>Let’s come back to my <code>RST</code> packets. The main hypothesis is that someone is
using my source IP to send outbound connections to the port 22 of various
internet machines. But it doesn’t really make logical sense at a first glance.
Usually, people would do this to scan for open ports or servers with a working
SSH server. However, none of that works when you spoof a source IP, since you
don’t get to see the results of you probing!</p><p>Back in the earlier days of the internet, there used to be a technique called
“Idle Scanning”, which relied on 1. servers being way less busy than today; 2.
network stacks lacking randomization of some fields and using auto-incrementing
predictable counters. This could be used to probe whether a port is open while
spofing a source IP (for anonymity, or to bypass firewalls). But that technique
has been dead and unusable for decades.</p><p>So, maybe someone set up a scanner and typo’d their source IP in a
configuration file, causing random internet machines to think I’m initiating
connections to them? But… the traffic volume seems too low, the duration of
the weirdness too long, and really it would be a stretch anyway.</p><p>Whatever the spoofer’s motive, it’s kind of annoying. Their scan is hitting
honeypots, networks with intrusion detection systems that send (sometimes
automated) abuse complaints, and so on. I wish they’d notice that whatever
they’re doing isn’t working, because I don’t particularly enjoy getting abuse
complaints, and they put me at risk of being kicked out of my hosting provider.</p><p>… wait a minute?!</p><h2 id="the-tor-connection">The Tor connection</h2><p>I mentioned in passing earlier that one of the services I run on my server is a
Tor relay. Relays are internal nodes of the Tor network. They only carry
anonymous, encrypted traffic (in fact, usually with multiple layers of
encryption), and only between consenting opt-in nodes of the Tor network.
Relays aren’t exit nodes, they don’t talk to the open internet. A few selected
relays are also “Guard Nodes”, which can serve as the entry point to the Tor
network. These technically talk to the open internet, but still, only
consenting users connecting to the Tor network.</p><p>For that reason I originally kind of ruled out Tor having any connection (pun
intended) to this abuse issue. And I’m sure some of you were screaming about
it, but hey, you probably have the benefit of 1. hindsight; 2. not being up at
4AM running <code>tcpdump</code>.</p><p>But Tor has one peculiarity: there are actors on the internet that don’t like
it. There are many good and bad reasons for this - I personally view Tor as a
“useful neutral cesspool”, but this is not an article about ethics, and it’s
simple enough to say that some people disagree. Said people range from
“individual hacktivists” to “police forces” to “government agencies”, with
various levels of sophistications and differing techniques.</p><p>Could someone be deliberately trying to induce abuse complaints on Tor network
participants to take down parts of the network (or disincetivize running
internal nodes, which are key for the network’s health)?</p><p>Easy enough to check. I run more relay nodes, so let’s just <code>tcpdump</code> there
too. One at home on my residential IP connection, one on a Linode VPS in Japan:</p><div><pre tabindex="0"><code>04:19:14.705034 IP 198.30.233.69.22 &gt; 172.105.199.155.39998: Flags [R.], seq 0, ack 171173954, win 0, length 0
04:20:15.135733 IP 124.198.33.196.22 &gt; 172.105.199.155.23506: Flags [R.], seq 0, ack 1985822135, win 0, length 0
04:21:30.222739 IP 223.29.149.158.22 &gt; 172.105.199.155.27507: Flags [R.], seq 0, ack 3614869158, win 0, length 0

04:12:39.470366 IP 121.150.242.252.22 &gt; 77.109.152.87.57627: Flags [R.], seq 0, ack 2452733863, win 0, length 0
04:13:05.549920 IP 46.188.201.102.22 &gt; 77.109.152.87.9999: Flags [R.], seq 0, ack 3253922544, win 0, length 0
04:14:33.027326 IP 1.1.195.62.22 &gt; 77.109.152.87.52448: Flags [R.], seq 0, ack 351972505, win 0, length 0
</code></pre></div><p>Annnnnd yep, my two other relays running in completely different countries and
with completely different ISPs are seeing the same spoofed TCP SYN pattern.</p><p>This is when I sent <a href="https://lists.torproject.org/pipermail/tor-relays/2024-October/021953.html" target="_blank">an email to the <code>tor-relays</code> mailing list</a>,
where… it turns out someone had <a href="https://gitlab.torproject.org/tpo/network-health/analysis/-/issues/85" target="_blank">noticed and diagnosed the same thing</a>
a few days before. This spoofing “attack” actually started on other types of
nodes before migrating to relays, and those other nodes were hit with a much
larger volume of spoofed connections, leading to them actually getting
temporarily taken down in some cases! Proving the attack does in fact work…</p><h2 id="you-could-be-the-target-too">You could be the target too!</h2><p>To recap what’s (probably) going on:</p><ol><li>A malicious attacker has access to a network without BCP38 filtering.</li><li>They send TCP connection requests to port 22 on many random internet
machines - possibly deliberately selecting known honeypots or networks known
to send automated abuse complaints.</li><li>Those TCP connection requests use a spoofed source IP address, making the
destination machines think the spoofed source sent that connection. They
become the target of the automated abuse complaints.</li><li>With a large enough volume, the spoofed IP quickly becomes widely
blacklisted from many internet entities following blocklists, and the
hosting provider might take action due to many abuse reports and shut down
the server for being compromised / malicious.</li></ol><p>There is nothing at all in this attack that’s specific to Tor! I’m actually
surprised this is the first time I hear of this, because while ingenious,
nothing in there seems particularly difficult to do for a single motivated
attacker. You, too, can probably make your friend’s hosting provider (with
their consent, of course) shut down their server and cancel their hosting
contract by getting them flooded with well-meaning but confused abuse
complaints.</p><h2 id="conclusion">Conclusion</h2><p>The internet was broken 25 years ago and is still broken 25 years later.
Spoofed source IP addresses should not still be a problem in 2024, but the
larger internet community seems completely unwilling to enforce any kind of
rules or baseline security that would make the internet safer for everyone.
This is not just BCP38 - RPKI is a similar disaster in terms of deployment, and
has only started ramping up because it impacts large internet companies who
started enforcing requirements on their direct peers.</p><p>It’s not clear to me what the next steps are in regards to this attack. It’s
clearly already in the wild. I don’t know if it was already known and
documented. But it still seems to be working, it’s hard to track (I don’t know
of any way one could figure out the real source of a spoofed IP packet - there
is no “after the fact” traceroute, and even if there was, it would have to be
done by some upstream provider to get useful info).</p><p>However, if you now get such an abuse complaint, you might now have a better
idea what to look for and what to reply to your hosting provider to try and
convince them you are in fact a victim and not a perpetrator! Who knows, they
might even care to listen.</p><hr><p><em>This article was written in a rush a few hours before getting on a plane.
Sorry for the lack of proof-reading and potential typos!</em></p><hr></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Insiders Stealing Instagram Usernames? (136 pts)]]></title>
            <link>https://javier.computer/instagram</link>
            <guid>41981289</guid>
            <pubDate>Tue, 29 Oct 2024 09:21:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://javier.computer/instagram">https://javier.computer/instagram</a>, See on <a href="https://news.ycombinator.com/item?id=41981289">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      
      <p>Alright, let me share the full story of how my 14-year-old <a href="https://instagram.com/">Instagram</a> account, @javier, was stolen and ended up in the
hands of a hip-hop producer—and why I believe it was an inside job.</p>

<h3 id="background">Background</h3>

<p>First off, here’s some backstory: I’ve had the @javier username since October 2010, the same month the app launched. I
joined so early, that I even have emails reporting bugs to <a href="https://x.com/joshriedel">@joshriedel</a>, Instagram’s very first employee.</p>



<p>Over the past 14 years, I’ve received countless messages to buy my account. Early on, I made a conscious decision not to
engage with these requests. Rather than blocking people, I simply ignored them or restricted their accounts when that
feature became available.</p>

<p>A few years ago, I even created a quick iMovie compilation of some of the messages I received in 2018. Since then, the
volume of messages has only increased.</p>

<div>
  <video>
    <source data-src="https://img.javier.computer/instagram/username.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
  
  
</div>
<p>I’ve keep taking screenshots of everyone who’s asked about acquiring my account. One interesting pattern: the majority
of these requests come from profiles without any photos. I find it so weird that people are so eager to get a username
when they don’t even share content!</p>

<g>
<!-- photos / custom  -->
<div>
    <figure>
      <picture>
        <source data-srcset="https://img.javier.computer/instagram/0_photos_01_2880.webp 2880w" type="image/webp">
        <source data-srcset="https://img.javier.computer/instagram/0_photos_01_2880.jpg 2880w">
        <img data-src="https://img.javier.computer/instagram/0_photos_01_2880.jpg" src="https://img.javier.computer/instagram/0_photos_01_2880.jpg">
      </picture>
    </figure>
    
  </div>
<!-- photos / custom  -->
<div>
    <figure>
      <picture>
        <source data-srcset="https://img.javier.computer/instagram/0_photos_02_2880.webp 2880w" type="image/webp">
        <source data-srcset="https://img.javier.computer/instagram/0_photos_02_2880.jpg 2880w">
        <img data-src="https://img.javier.computer/instagram/0_photos_02_2880.jpg" src="https://img.javier.computer/instagram/0_photos_02_2880.jpg">
      </picture>
    </figure>
    
  </div>
</g>

<h3 id="the-theft">The Theft</h3>

<p>Alright, back to the story. On Wednesday, October 23rd, around 7 PM Spanish time, after I got killed for the thousandth
time in Elden Ring, I opened Instagram and found myself logged out.</p>

<p>While I’d occasionally received notifications about suspicious activity requiring identity verification, this was
different—a complete logout. When I saw this, I knew my worst fear had finally become reality: I had lost my Instagram
account.</p>

<p>When I attempted to log back in, my password was rejected. Using the password recovery option, I discovered something
alarming: the email associated with my account had been changed to an address I didn’t recognize: r*******e@gmail.com</p>

<p>At this point, my @javier account still displayed all my content, but I knew this wouldn’t last long. I tried
Instagram’s hacked account reporting page, but it was ineffective: when I entered my username the page simply reloaded
without any confirmation.</p>

<div>
  <video>
    <source data-src="https://img.javier.computer/instagram/login.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
  
  
</div>
<p>After exhausting all recovery methods, I refreshed my now-inaccessible account to find all my content replaced by 4
posts. Here’s my account before and after the robbery.</p>



<p>The hackers had moved my content to a new account, @javier.typeshi, stripped of my profile photo and description,
ironically adding the text “meta official”.</p>

<!-- photos / custom  -->
<div>
    <figure>
      <picture>
        <source data-srcset="https://img.javier.computer/instagram/javier_2880.webp 2880w" type="image/webp">
        <source data-srcset="https://img.javier.computer/instagram/javier_2880.jpg 2880w">
        <img data-src="https://img.javier.computer/instagram/javier_2880.jpg" src="https://img.javier.computer/instagram/javier_2880.jpg">
      </picture>
    </figure>
    
  </div>
<p>The profile picture in that account belongs to a man also named Javier Arce. He was a journalist that worked for
@azcentral <a href="https://eu.azcentral.com/story/news/local/phoenix/2024/09/06/javier-arce-la-voz-and-arizona-republic-journalist-dies-at-age-48/75106323007">who sadly passed away from stomach cancer last month</a>.</p>

<p>Before turning to Twitter for help (where I was flooded with recovery scams), I created a new account to request my
content back. They never responded. I knew the chances were pretty low, and that they would probably try to extort me,
but hey I had to ask.</p>

<h3 id="the-investigation">The Investigation</h3>

<p>Ok, before I move on and tell you about the new owner of the account, let’s do some conspirancy talk and let me explain
how I think my account was stolen.</p>

<p>My account was well-protected with 2FA and linked to a unique, private email address that I’d never shared. I use
1Password and am extremely careful about security. I’ve never entered my Instagram credentials on any third-party
websites or apps, nor have I ever shared 2FA codes.</p>

<p>On the day of the event, I received no email or phone notification about any unusual access attempts. So here’s what I
believe it happened: it wasn’t a phising attack, it was somebody from inside the company.</p>

<p>This wouldn’t be unprecedented. <a href="https://www.cshub.com/attacks/news/meta-fires-employees-for-allegedly-hacking-into-users-accounts">Meta has previously fired employees for hacking user accounts</a>, and there’s a thriving
black market for usernames on forums like <a href="https://oguser.com/">oguser.com</a></p>

<h3 id="the-new-owner">The New Owner</h3>

<p>Back to the story. Let me tell you about the new account owner. His name is Javier “Jay” Sang. Looking at the tagged
photos, he seems to be the founder and CEO of a label called Rebel Music.</p>

<!-- photos / custom  -->
<div>
    <figure>
      <picture>
        <source data-srcset="https://img.javier.computer/instagram/jay sang_2880.webp 2880w" type="image/webp">
        <source data-srcset="https://img.javier.computer/instagram/jay sang_2880.jpg 2880w">
        <img data-src="https://img.javier.computer/instagram/jay sang_2880.jpg">
      </picture>
    </figure>
    
  </div>
<p>And do you remember how I take a screenshot of every account that ask me to sell or change my username? Jay did that in April this year. It seems he may have sought alternative means after I didn’t respond to his request lol</p>

<!-- photos / custom  -->
<div>
    <figure>
      <picture>
        <source data-srcset="https://img.javier.computer/instagram/jayrebelmusic_2880.webp 2880w" type="image/webp">
        <source data-srcset="https://img.javier.computer/instagram/jayrebelmusic_2880.jpg 2880w">
        <img data-src="https://img.javier.computer/instagram/jayrebelmusic_2880.jpg" src="https://img.javier.computer/instagram/jayrebelmusic_2880.jpg">
      </picture>
    </figure>
    
  </div>
<h3 id="current-status">Current Status</h3>

<p>As for the current situation: so far, I’ve regained control of the renamed account with all my content and messages, but
I still haven’t recovered my original username.</p>

<p>I’m receiving help from an Instagram employee, and through my network of friends and their connections I’ve made contact
with other folks at the company who have expressed interest in my case and offered their assistance. I’m very grateful
for that.</p>

<p>In fact, I doubt I would have been able to recover my content without those connections at the company. This highlights a serious issue that Instagram and Meta need to address in their account recovery process.</p>

<p>And I’m not the only person with this problem. A few days ago, I learned that @joao, another long-time user, also lost his Instagram handle in a similar way last year, and he still hasn’t heard back from Instagram.</p>

<p>For reasons unknown to me, regaining access to my content was easy, but reclaiming my original username is much harder.
And while I’m optimistic about getting my old username back, I’m sure this won’t be the last hack attempt on my account.</p>

<p>The end. Thanks for reading this far! If you’re wondering how you can help, I’d appreciate it if you shared this thread.
And if you know <a href="https://x.com/mosseri">@mosseri</a>, please let him know one of Instagram’s earliest users is frustrated and thinking of leaving.</p>




      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What happens when people with acute psychosis meet the voices in their heads? (152 pts)]]></title>
            <link>https://www.theguardian.com/news/2024/oct/29/acute-psychosis-inner-voices-avatar-therapy-psychiatry</link>
            <guid>41980986</guid>
            <pubDate>Tue, 29 Oct 2024 08:43:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/news/2024/oct/29/acute-psychosis-inner-voices-avatar-therapy-psychiatry">https://www.theguardian.com/news/2024/oct/29/acute-psychosis-inner-voices-avatar-therapy-psychiatry</a>, See on <a href="https://news.ycombinator.com/item?id=41980986">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><span>I</span>n the summer of 2019, when Joe was 21, he went on a university rugby tour of California. One night, one of his teammates bought some cannabis edibles to share, and Joe ate some. For the next 12 hours, he believed he was in hell. He was on fire; his body was suffused with pain. His ears were filled first with incoherent screaming and then with sinister whispering. Joe’s friends thought their teammate’s bad trip was funny, even as they wrestled him away from the windows when he tried to jump from the seventh floor of their hotel.</p><p>When he woke up the next morning, Joe was still in hell. A devilish, humanoid form lurking in the periphery of his vision was telling him he had died the previous night. A chorus of other voices joined in, wailing in agony. They were entirely real to him, even though he knew they couldn’t be. He had a rugby match to play, and 10 minutes in, he couldn’t see or feel his hands; he couldn’t move. His teammates laughed as he came off the pitch. Poor old Joe.</p><p>The voices came back to the UK with him. “You’re not real,” they told him incessantly. “You’re already dead, so it doesn’t matter if you end it all again.” He saw blurred, demonic faces smirking at him, sometimes at the edge of his eye line, sometimes up against his face, too close to be in focus.</p><figure id="75c14611-ab14-42df-aff4-7dc45fd0a0d4" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:3,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Using avatars in psychosis therapy can help those who hear voices, study finds &quot;,&quot;elementId&quot;:&quot;75c14611-ab14-42df-aff4-7dc45fd0a0d4&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/science/2024/oct/28/using-avatars-in-psychosis-therapy-can-help-those-who-hear-voices-study-finds&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:10,&quot;display&quot;:1,&quot;theme&quot;:0}}"></gu-island></figure><p>His parents knew he had struggled with depression and anxiety before, but Joe didn’t want to tell anyone about the voices. He drank heavily, every blackout providing temporary respite. He would walk for hours, playing music on his headphones, desperate to drown out the voices. At other times Joe would tell the voices to fuck off, shut up, leave him alone. He would find himself saying these things out loud, in public. Seeing himself reflected in the fearful eyes of those he walked past, he was terrified that he would never find a way to be normal among them again.</p><p>Joe was later told he was experiencing acute psychosis. About <a href="https://www.derbyshirehealthcareft.nhs.uk/services/mental-health-and-emotional-wellbeing/early-intervention-psychosis" data-link-name="in body link">two or three people in every 100</a> experience psychosis, when reality is disrupted by delusions or hallucinations. It can be a symptom of schizophrenia or severe depression, but can also be experienced without any other mental health condition. The acute form – the sudden, rapid onset of auditory or visual hallucinations that Joe experienced – can be triggered by drugs in people who, <a href="https://journals.sagepub.com/doi/10.1177/0020764018801690" data-link-name="in body link">because of existing biological and social factors</a>, might be predisposed to psychosis. Hearing voices is <a href="https://www.sciencedirect.com/science/article/abs/pii/S0272735809001615?via%3Dihub" data-link-name="in body link">the most common form</a> of psychosis, affecting <a href="https://pubmed.ncbi.nlm.nih.gov/22446568/" data-link-name="in body link">as many as 70%</a> of people with schizophrenia, and the voices heard tend to be persecutory and distressing. More than one in 10 people with schizophrenia end up <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1845151/" data-link-name="in body link">taking their own lives</a>.</p><p>Antipsychotic medications, the go-to treatment since the mid-20th century, can come with serious side-effects, including weight gain, exhaustion, bed-wetting, sexual dysfunction and severe constipation. And they don’t work for everyone: a quarter of people on antipsychotics will continue to hear voices. The most effective medication, Clozapine, is only used where other antipsychotics have failed because it can cause even more severe side-effects. It was developed in the 1950s; there has been little drug innovation for psychosis in recent decades. There are also non-pharmacological treatments; cognitive behavioural therapy for psychosis (CBTp), when combined with medication, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6280425/" data-link-name="in body link">improves symptoms</a> for about 50% of people.</p><p>After hearing the voices for two and a half years, Joe went to his GP in winter 2021 and received his formal diagnosis. He was put on a low dose of antipsychotic medication, which he hated: he couldn’t get out of bed, couldn’t function and, while it helped with his visual hallucinations, the voices remained. He came off the medication after two months. Depressed, despairing and starting to spiral, he got back in touch with his GP, who told him there was something else to try: an experimental therapy, a clinical trial he could be part of, that turned the traditional treatment model for psychosis on its head.</p><p>If you hear voices, clinicians don’t generally ask what they’re saying to you, beyond whether they are asking you to harm yourself or others. “There’s been a reluctance to engage much with the content of voices,” Ben Alderson-Day, an associate professor of psychology at Durham University who specialises in psychosis, told me. “That’s in part because of a concern that if you ask voice-hearers to elaborate, you might engage in ‘collusion’: you may make [the voices] more real for people.” A clinician may diagnose a patient with psychosis, and prescribe them medication or CBT, without knowing what the patient’s voices say to them.</p><p>This new therapy demanded that voices were listened to closely, and responded to as if they were spoken by entirely real external beings. Trial participants would create an avatar of their voice: a moving, three-dimensional digital embodiment that looks and sounds like the persecutor inside their heads. They would be guided by a therapist to have a dialogue with the voice – and the hope was, through doing so, gain control over it.</p><p>Within a few weeks, the voice that told Joe he was dead – the one he so feared could be real – was manifested in colour in front of him. For the therapy to work, he needed to find the courage to look the demon in the eyes; to challenge and conquer it. If he succeeded, the voices might fade away.</p><hr><p><span>P</span>rof Julian Leff was seven years into his retirement when the idea of avatar therapy came to him. After a celebrated career as a social psychiatrist and schizophrenia specialist at University College London, Leff was sitting at home in Hampstead, pondering the results of a survey that reported the most distressing aspect of hearing voices was the feeling of helplessness. On the rare occasions when his patients had had meaningful exchanges with their voices, he knew they had felt more in control. “I thought, how can I enable the patient to have a dialogue with an invisible voice?” Leff said in an interview for a documentary made in 2018, three years before his death. “If I can somehow manage to create for the patient the image and voice of the person who they hear abusing them, maybe they could learn to overcome this awful persecution.”</p><p>Leff was awarded a small grant for a pilot study in 2008. He recruited Mark Huckvale, professor of speech, hearing and phonetic sciences at UCL, to be in charge of the tech. They tinkered with existing police identikit software, animating digitally created faces in three dimensions so they could nod, smile and maintain eye contact. They combined this with an off-the-shelf programme called Lip Synch, so that the mouth would move appropriately, and voice-changing software, so the avatar could be made to sound male or female, rougher or smoother, higher or lower, older or younger.</p><p>The avatar was a floating, moving head on a computer screen, voiced by Leff, who would be in a separate room to the patient, watching via webcam. He could speak to the patient in his own voice, guiding them through the dialogue, and then switch with the click of a mouse to the role of the avatar on the patient’s screen, its lips synched to his speech. The setup allowed him to act as a therapist to the patient and a puppeteer to the avatar. At first, the avatar would say typical lines the patient had shared with Leff: often degrading, abusive phrases. But over the course of six sessions, the dialogue would change, with the avatar yielding to the patient, transforming from omnipotent to submissive. At all times, Leff and the patient were to treat the avatar as if it were an entirely real third party.</p><p>Sixteen people – all of whom had heard voices for years, despite being on medication – participated in this pilot study. A man who had heard the devil incessantly for 16 years was instructed by Leff to tell his demon avatar he didn’t deserve to be persecuted and he should go back to hell and torment those who did. An older man, who had been woken every morning at 5am for more than three years by the voice of a woman conducting noisy business meetings in his head, was encouraged by Leff to tell her it was unprofessional to allow him to overhear her discussions. To Leff’s surprise, both of these men stopped hearing their voices entirely after only three sessions. While most patients did not experience such a dramatic change, the results were still impressive: for 13 of the 16 participants, voices remained, but they were less frequent and intrusive, and suicidal feelings were significantly reduced.</p><p>The therapy had made a significant difference to a sample group composed of people for whom all other forms of treatment had failed. But other clinicians were wary of taking the results of the pilot seriously, believing they might be a consequence of Leff’s skill as a therapist, rather than the therapy itself. “He did have a magic touch,” Tom Craig, professor of psychiatry at King’s College London (KCL), told me. But Craig was sufficiently impressed by the results to lead a randomised controlled trial on 150 patients, along with Philippa Garety, professor of clinical psychology. Leff trained Craig and the clinical psychologist Tom Ward to deliver the therapy in his place, giving them audio recordings of his sessions and a checklist of how he thought things ought to be done, which Craig and Ward turned into a manual.</p><p>“Within the first couple of cases, we thought: this is extraordinary – something’s really happening here that we’ve never seen before,” Craig said. One participant, Chris, had been persecuted for years by the voices of high court judges who denounced him for intrusive sexual thoughts. Through the therapy, Chris came to accept his sexual urges as normal, and his high court judge avatar ultimately told him he had no case to answer. Free from persecution, Chris was able to go on dates for the first time in years.</p><p>Avatar therapy was <a href="https://www.thelancet.com/journals/lanpsy/article/PIIS2215-0366(17)30427-3/fulltext" data-link-name="in body link">found to be quicker,</a> cheaper and more effective after 12 weeks than any other non-pharmacological intervention currently available for people with psychosis. It worked, even without Leff, on a larger scale, and it worked faster than the control therapy delivered by highly trained clinicians.</p><p>As for the concern that engaging with auditory hallucinations exacerbates psychosis, Al Powers, associate professor of psychiatry at Yale University, told me it was not backed by empirical data. “Despite popular wisdom about not wanting to collude with the voices, the evidence that’s emerging seems to indicate that engagement-based approaches are most effective in terms of increasing control over voices, and also achieving some degree of mastery over them.”</p><p>Despite its early success in trials, Alderson-Day warns against viewing avatar therapy as a cure-all for psychosis. “The idea of a single therapeutic option for all kinds of voices is very unlikely,” he said. “Some people’s auditory experiences aren’t even voice-like, so there won’t be content to work with,” he told me. But if avatar therapy could be quicker and more cost-effective than existing treatments, he said, it was worth pursuing.</p><p>The research team’s next step was to demonstrate that avatar therapy could work when delivered by a broad range of therapists in different locations. A new trial, <a href="https://www.avatartherapytrial.com/" data-link-name="in body link">Avatar 2</a>, began in 2021, and involved 19 trained therapists in four different sites across the UK. There were 345 individuals enrolled in it – including Joe.</p><hr><p><span>J</span>oe was nervous about designing his avatar. No one had ever asked him to describe what his voices looked or sounded like before. He had spent so much energy telling himself they couldn’t be real and now he had to manifest them in the real world. There were other challenges: like most people with psychosis, Joe heard several voices, and he experienced them more as a felt presence, rather than a single entity with a definite physical appearance and a familiar face.</p><p>Tom Ward, who was assigned to be Joe’s therapist, told me the average number of voices heard by people with psychosis is four. “We are looking for the dominant voice that’s causing the most distress.” Joe chose the voice who told him there was no point in living because he was already dead.</p><p>He and Ward began creating the avatar’s face. There was a blizzard of choices in drop-down menus on Ward’s laptop screen: <em>is it a human or non-human entity</em>? If it’s human, what is its <em>gender, age, height (tall, medium, short), ethnicity (European, </em><em>east Asian, </em><em>south Asian, African)</em>? If it’s non-human, <em>does it take the form of a devil, angel, alien, vampire, robot, witch, goblin, elf, beast</em>? Once a basic form is chosen, there are sliders to change the physiognomy: making the nose broader, thinner, shorter or longer; adjusting the eyes, brow and chin; modifying the hairstyle.</p><p>Joe found it hard to describe what the voice looked like: it was often hooded, masked, out of focus, only partially visible. It was demonic, but it didn’t look like a devil. Together, they created the head of a bald man with olive skin, like Joe’s. He chose between five versions of voices, and used sliders to change the pitch, tilt and roughness. The final voice was deeper than any human’s. That’s what made it demonic, for Joe.</p><figure id="1607a6ea-93ed-414d-b6d7-0520c2c5746b" data-spacefinder-role="immersive" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=1300&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=1300&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=1140&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=1140&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=1125&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=1125&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=965&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 740px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 740px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=965&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 740px)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=725&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=725&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=645&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=645&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=465&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="AI Avatars Long Read | Illustration 02 | DIGITAL" src="https://i.guim.co.uk/img/media/79542b4dfbf8276e166ca9b09d6654de11162926/0_0_5000_3000/master/5000.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none" width="465" height="279" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span> Illustration: Nick Kempton</figcaption></figure><p>It wasn’t exactly right, but once Joe was alone with the screen there was something about the avatar that resonated. Ward reminded Joe he was there to support him. Before they went into their separate rooms, they had practised what the avatar was going to say, and how Joe might respond to it. Still, he felt terrified.</p><p>“You’re already dead,” the avatar told him, in a voice that was almost monotone. “You’ve been in hell all this time and this is your existence from now on.”</p><p>“If this is death, it’s exactly the same as what my idea of life was,” Joe replied, a little meekly. He was surprised by how realistic the experience was, how true to life this felt.</p><p>“You’re lying to yourself,” the voice retorted.</p><p>In his own, encouraging voice, Ward reassured Joe, reminding him to hold eye contact, to communicate in strong messages that he was in charge.</p><p>“You’re harder to get hold of today,” the avatar said towards the end of the first session. “You can’t keep it up.”</p><p>“I can keep this up for ever, and I will,” Joe replied. “It’s my life. I have the autonomy here. I’m in control.”</p><p>Joe had 12 weekly sessions. The darkest exchange came in the fourth.</p><p>“You should end it,” the avatar said, casually. “What have you done that’s of any use to anyone?”</p><p>Joe couldn’t answer this.</p><p>In his own voice, Ward interjected to remind Joe about his relationships, his family, the life he had been able to make for himself. “What the avatar is saying is actually not true,” Ward said. “Can you come back with positives?”</p><p>Ward switched back to voicing the avatar. “You agree with me deep down,” it sneered. “You haven’t done anything of use.”</p><p>“No,” Joe said, firmly. “I have a lot of good friendships. I think on balance I have had a good life. It’s been positive. I’ve got more to do.”</p><p>“You’re handling yourself better than I thought,” the avatar replied. “I’d thought you’d be falling apart by now.”</p><hr><p><span>A</span>ll therapy sessions are recorded, and the audio given to the trial participants so they can listen back in their own time and be reminded of how they managed to gain mastery over their voices. With Joe’s agreement, Ward shared the recordings of his sessions with me.</p><p>Ward had delivered avatar therapy to about 80 people before he met Joe. He told me that people with psychosis often feel disempowered and marginalised; they feel as if they don’t have the right to talk. Avatar therapy is about equipping them with the tools to answer back.</p><p>I met Ward in his office at KCL’s Institute of Psychiatry in Denmark Hill, south London. He gave me a demonstration of the avatar design process, so that when we sat down to talk, a disembodied male head was blinking from his laptop in front of us, looking shiftily from side to side throughout our conversation. It still looked like an animated police photofit to me. Perhaps, with a voice to go with it, it would be easier to suspend disbelief.</p><p>Ward told me it can be helpful for many patients to understand their voices as a coping strategy arising from a previous trauma. (While there is no consensus among clinicians about the precise relationship between trauma and hearing voices, there is widespread acceptance that there is often a <a href="https://academic.oup.com/schizophreniabulletin/article/38/4/661/1870563?login=false" data-link-name="in body link">link between the two</a>.) But discovering whether or not a patient’s voices have arisen as a response to trauma isn’t important, Ward told me; the point of the therapy is to find any explanation that gives them a sense of mastery over their voices. This is the principle followed in any psychological intervention, he said.</p><p>Using the manual created from Leff’s instructions as a guide, the therapist plots out how the voice will change as the person is supported to stand up to it. When the voice is a bully, the avatar will begin to recognise the impact of their behaviour, perhaps revealing that they too have once been a victim of bullying. When the voice is a devil, a djinn or some other malevolent spirit, the avatar will reveal that they are not actually very powerful (“‘I’m not a high-ranking demon, I’m a trickster’ – that sort of thing. Things are quite interesting when you voice demons,” Ward said). When the voice resembles someone who abused the patient when the patient was a child, the avatar gradually acknowledges that they are no longer talking to a defenceless boy or girl but instead to an adult with agency.</p><p>Psychiatry professor Al Powers told me he saw potential problems in cases where the voice represented by the avatar belonged to a person who existed in the real world. “That can negatively impact one’s conceptualisation of your relationships with the world, and your family, and other people who are important to you, and that can contain some risks,” he said.</p><p>Before anyone can gain power over their voices, they have to tell their therapist what the voices say to them. It’s often the most degrading content imaginable; racist, sexist, sexually shaming and taboo. In his clinical experience, “You’re a paedophile” is one of the most common phrases repeatedly heard, Ward said. The avatar therapist has to reassure their patient that these phrases are nothing to be ashamed of, but also has to be prepared to deploy them when they are playing the role of avatar.</p><p>For the therapy to work, the therapist has to commit to playing the role of their patient’s tormentor. “You never break the fourth wall,” Ward said. The avatar can be direct – can go for the jugular – <em>because</em> it is not the therapist, and it can lie, or say things that are wrong. Hearing the avatar say these things can give the patient enough distance for them to reflect on and respond to what they usually only hear inside their own head.</p><p>In the Avatar 2 trial, for the first time, therapists went as far as allowing avatars to say things like, “You should end it.” When I brought this up with Ward, he stiffened. This kind of content is only used in specific circumstances, he said, when the patient’s risk of suicide has been assessed as minimal. “You don’t start the first dialogue with that. It comes at a point where you know how the person engages in the dialogue; you know that there is a clinical benefit to [them] voicing a commitment to life, and you know that they will be able to do it.” (I asked three specialists who work on the treatment of psychosis, but were not involved in the trial, about the dangers of the avatar therapist voicing commands to self-harm, and they all told me that, while unconventional, in these circumstances, it would not harm the patient.)</p><p>None of the avatar trials have shown that the therapy could exacerbate psychosis, even if people drop out before they have completed the run of sessions. “People do drop out,” Ward acknowledged. “Sometimes people will say, ‘It was just a bit too much for me.’” They have monitored all the people who had the therapy, tracking any mental health deterioration or hospital admission during and after treatment, and there has been no documented evidence of any crises directly related to avatar therapy during the Avatar 2 trials.</p><p>We are used to imagining those who hear voices as fragile, but Ward sees them as extraordinarily resilient: they can survive both years of the worst kind of internal persecution from their voices, and also the stigma and discrimination their condition is met with by the general public. Nothing simulated on a computer screen could be any more traumatic, he says, than what the people he works with endure in daily life.</p><hr><p><span>B</span>efore and after Joe’s dialogues with the avatar, he and Ward discussed how Joe’s voices might have developed in response to the extreme, heightened terror he had felt during his bad trip. Joe began to think of his voices as an overactive defence mechanism, a maladaptation of his brain as it tried to keep him safe and alert in a world he’d experienced as full of danger.</p><p>“The voices are just your paranoia, your anxiety, your fight-or-flight response gone mad. Give them space, and then you can have a conversation with them,” Joe told me. “I like to think that’s the reason why they started initially, but even if it isn’t, it doesn’t really matter, because it meant I was able to talk to them.”</p><p>By Joe’s seventh session, he was having insightful, poignant conversations with the avatar.</p><p>“Things are going to shit,” it grumbled.</p><p>“It’s not a bad assessment. They aren’t going fantastically,” Joe conceded. “You and I want the same thing – things not to be shit. That’s the goal. Rest assured, we’ll get there. It might take a while.”</p><p>“It’s why you need me.”</p><p>“In a way yeah, I guess. I think we’re working towards the same goal of just being the best version of myself I can be.”</p><p>“That’s what I need from you – to be the best,” the avatar said. “It’s what I’ve always needed.”</p><p>“Yours is not always the most helpful way to go about it, is it?” Joe said. “But I appreciate the sentiment.”</p><p>The dialogue had become a strange kind of couples therapy, in which Ward was playing the avatar and the therapist.</p><p>After four years of arguing with his voice, Joe began to feel compassion – even pity – for his tormentor. In the 10th session, Joe and the avatar discussed what happened in California. Joe described what he went through that night: not only the horror of it (“It was fucking scary, wasn’t it? It felt like a Hitchcock score sounds”) but also the alienation (“I was surrounded by people who found it funny”).</p><p>“You tried to tell yourself it didn’t matter, I wasn’t real,” the avatar said. And then, with resignation, “I’m fading from your life.”</p><p>“You’ll always be there in some form,” Joe reassured it. “But yeah.”</p><p>“Is that OK with you?” it asked. Joe’s tormenting voice had become his anxious companion.</p><p>“Yeah. I can live with that. So long as we’re able to coexist,” he replied.</p><p>“Thank you for listening,” were the avatar’s final words. “Thank you for making room for me.”</p><hr><p><span>A</span>vatar 2 set out to investigate how effective the therapy could be when delivered by therapists with far less experience than Ward and Craig. Some of the participants had been living with voices for decades. Claire was in her early 50s when she enrolled in Avatar 2, at the Manchester research site. She had heard the first voice when she was 10: an adult male, casually telling her to jump out of her bedroom window. It was entirely real to her, external and authoritative, “like an adult telling me what to do”. Claire had been abused from the age of seven. She grew up in a state of constant hypervigilance.</p><p>The nasty voice, the one that told her she was a stupid bitch, arrived when she was 13. “I remember saying, ‘Oh, shut up,’ out loud, and the other girls laughed and said, ‘There’s no one there!’ And then I realised I had to be quiet about them.” The voices became one among many secrets Claire kept, alongside the abuse and her self-harm.</p><p>She spent much of her adult life in psychiatric hospitals. By the time her mental health team’s care coordinator told her about the Avatar 2 trial in 2021, Claire had tried to end her life many times. She had been diagnosed with bipolar disorder, psychotic depression and, at one point, schizoaffective disorder. She was taking antidepressants, mood stabilisers and tranquillisers, as well as antipsychotics; she had tried CBT, cognitive analytic therapy, compassion-focused therapy and group survivor therapy. Still the voices persisted.</p><p>“The state I was in at the time, I thought, they’re not going to accept me on the trial – I’m too unstable,” Claire told me. But she was given a place on the trial, coordinated by Hannah Ball. Ball had only qualified as a psychologist a year before she was trained to deliver avatar therapy. She was assigned to be Claire’s therapist. “Hannah reassured me that nobody had ever had a crisis because of avatar therapy, and I thought, <em>that will be me. I’ll be the first one</em>,” Claire said.</p><p>Claire chose to make an avatar out of the first voice, which she felt shaped all the others. While she and Ball were putting together its angular male face, with its dark eyes and spiky hair that made Claire laugh because it wasn’t quite right, the voices over her right shoulder were enraged: “Don’t do this, you stupid fucking bitch.” The avatar’s northern accent was also not quite right, but there was something about its menacing tone that jolted Claire. As soon as she heard it, it was real to her.</p><p>She felt dizzy and sick in her first session, and Ball had to constantly check in to provide reassurance in her own voice. The dialogue lasted barely 10 minutes and left Claire exhausted, but as she walked home, she was smiling: she had been able to stand up to her voices for the first time in her life. Between sessions, she listened to the audio recordings that Ball had given her to take home, so she could remember what she had achieved and steel herself for her next encounter. (Claire agreed to share these recordings with me.)</p><p>By the third week, she was answering back to the avatar, asserting herself without any prompting from her therapist.</p><p>“Stop saying such nasty things to me. I’m not going to listen to you any more while you say such nasty things,” she told the avatar.</p><p>“I’m not sure what’s got into you,” it replied.</p><p>“I’m going to lay down some rules,” Claire said. “We can still talk, but on my terms, not yours.”</p><p>By the fourth week, Claire’s voices had gone entirely. For the first time in 40 years, she was alone with her own thoughts. Quiet.</p><p>She hadn’t expected them to go. “My aim wasn’t to get rid of them – just to get along with them,” she told me. “I wasn’t quite sure I wanted to let go. I’d never really been on my own. As abusive as it was, it’s still a relationship.”</p><p>Like Joe, she had been encouraged to understand her voices as a faulty self-defence mechanism. They had been trying to look after her: when they told her to end her life, they were trying to find a way to stop her suffering. Their departure was a kind of bereavement.</p><figure id="c77b1fdc-b178-46b7-9399-9bb77acb1aee" data-spacefinder-role="immersive" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=1300&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=1300&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=1140&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=1140&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=1125&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=1125&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=965&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 740px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 740px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=965&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 740px)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=725&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=725&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=645&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=645&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=465&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="AI Avatars Long Read | Illustration 03 | DIGITAL" src="https://i.guim.co.uk/img/media/edd4e67816d6336c959173f32e58b3ffe0679140/0_0_5000_3000/master/5000.jpg?width=465&amp;dpr=1&amp;s=none&amp;crop=none" width="465" height="279" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span> Illustration: Nick Kempton</figcaption></figure><p>In the remaining sessions, Ball helped Claire accept the loss of the voices, and she had an opportunity to say a definitive goodbye. The avatar promised to stay alongside her at a distance, there if needed, but no longer interfering in her life. “I wish you all the best,” it said at the end of the final session.</p><p>“Thank you. I wish you all the best, too,” Claire replied. “I know you had good intentions at heart.”</p><p>Nearly two years on, Claire’s voices have not returned. She’s coming off all her medications. She can go out in public, eat in a noisy restaurant, do voluntary work, give interviews to a journalist – all things that once seemed impossible. “I’m stronger. I’ve gained so much. I now feel I have a life worth living.”</p><p>Ball didn’t have the same level of experience as Leff, Craig or Ward, but she was able to achieve the same outcomes using the manual they developed as her guide. I asked to see the manual, but Ward told me he couldn’t share it with me, because it was “core IP”. The Wellcome Trust, which funds the trial, has been protective of its intellectual property in the past: research teams in Denmark, Australia and Canada that have been experimenting with avatars have been told there are restrictions around calling the work “avatar therapy”.</p><p>Ball told me the manual is not a script, more a set of objectives to aim for in each session: a general structure of how the avatar should change to empower the patient. She listened to recordings of one of Ward’s cases from the first trial, did two closely supervised pilot cases and was then delivering the therapy herself, alone.</p><p>I wondered how comfortable she felt, taking on the role of a malevolent entity that has enormous power over her patient. “It requires a lot of active formulation and reformulation on the spot, and listening out for things that might change how you were initially going to approach a dialogue,” she said.</p><p>I had imagined that only skilled clinicians could be avatar therapists, but Ball was convinced that, if they were willing to take on the challenge, a very wide range of mental health practitioners could do it. “I think you need people who understand relationships and dynamics,” she said. “If you’ve got a sense of who you are as the avatar and the relationship [to the patient], you know how to respond.”</p><hr><p><span>T</span>he results of the Avatar 2 trial, published on Monday, were dramatic. Avatar therapy has been shown to deliver rapid and significant reduction in distress caused by voices. No other psychological intervention has been shown to cause such a significant reduction in the frequency of intrusive voices.</p><p>Earlier this year, the National Institute for Health and Care Excellence announced that it has found avatar therapy to be safe and effective and recommended that it be offered for testing in clinical NHS settings over the next three years. Thirty-eight people have so far been trained to deliver it in the UK, from experienced clinicians to newly qualified psychologists and nurses. The most effective psychological therapy currently offered on the NHS, CBTp, is typically delivered by qualified clinical psychologists in 16 sessions over 12 months. In comparison, avatar therapy could work out as “half the length of time, with less skilled people, so a bit cheaper, and a bit more available”, Tom Craig told me. He hopes it will be part of NHS treatment within five years.</p><p>A small number of practitioners remain hesitant about avatar therapy being delivered by support workers and less experienced psychologists. Prof Neil Thomas, director of the Voices clinic in Melbourne, and lead investigator on the Australian Amethyst avatar therapy trial, said: “Working with people who hear voices is <em>already</em> an area of specialist practice. Using technology as well makes it even more specialist. The process is actually not particularly intuitive for people that have trained in therapy – which involves being supportive to people – to have to role play a nasty voice.”</p><p>But the British team are taking things even further. A newly announced Avatar 3 trial will investigate whether the avatar could be entirely digital and voiced by an artificial intelligence, which would remove the requirement for real-time human voicing of the avatar, and mean it could be widely disseminated. Humans would always be necessary to support the person in their interaction with the avatar and help make meaning of the voices, Craig said, but that would not need to be a trained therapist. It could be “a community nurse, or a nursing assistant”.</p><p>Louise Birkedal Glenthøj, associate professor of psychology at University of Copenhagen and the trial coordinator for Challenge, the Danish trial using avatars in the treatment of psychosis, told me she feared a fully digital avatar powered by AI might have the potential to exacerbate psychosis. “As people with psychosis struggle with grasping reality,” she said, “being in a dialogue with a machine that is not controlled by a therapist might generate psychotic experiences.”</p><p>The Danish team enrolled 270 participants in a trial that investigated how people who hear voices respond to having dialogues with an avatar using virtual reality. “We thought if [we could] integrate this in fully immersive VR, then we would perhaps get some additional benefit in terms of this potentially having a greater treatment effect,” Glenthøj told me. <em>“</em>Having the therapist close by would intuitively be more secure for the patient. We capitalise on this notion of ‘it’s real but it’s not real’. It’s so real that they feel they are in this dialogue with their voice, but it’s not real, and if they take off the headset, then it’s gone.”</p><p>The VR allows the user to situate the avatar in daily life settings, such as on the bus, or in the participant’s home. They also added emotions to the face, so the avatar could smile more and look more friendly as the dialogues progress.</p><p>Glenthøj conceded that VR avatar therapy can be overwhelming for some. “We <em>do </em>see people reacting. They destabilise. They get <em>more</em> psychotic.” As a result, the Danish team progressed more slowly than clinicians on the Avatar 2 trial, and have added safety features, such as a virtual panic button, and regular contact with the participants’ primary care providers throughout treatment. They also gave participants booster sessions at three and six months after treatment, in the hope of making any positive effects more durable. The <a href="https://www.researchsquare.com/article/rs-5180922/v1" data-link-name="in body link">trial ultimately found</a> that VR avatar therapy was significantly more effective at reducing voices compared with supportive counselling.</p><p>Avatar therapy may help in treating mental health conditions beyond psychosis. <a href="https://link.springer.com/article/10.1186/s40337-023-00900-1" data-link-name="in body link">Preliminary research</a> from Ward’s team with an avatar embodying the “anorexic voice” has shown it to be a promising intervention for eating disorders. Glenthøj is researching VR-based avatar therapy for obsessive compulsive disorder. Ward also wants to investigate whether dialogues with avatars could help people who struggle with anxiety or depression. “The technology is about creating this external representation of the dark side of yourself,” Craig said. “At some level, this is about thoughts, isn’t it?”</p><p>In Australia, avatar therapy can take place via telehealth, with therapist and participant often in different parts of the country. “We’ve got a lot of people living in regional areas who have limited access to mental healthcare – let alone to specialist therapies,” Thomas told me. They have drawn on how the British team worked during lockdown to see how it can be delivered remotely.</p><p>Some therapists have tried, in the past, to guide their patients through dialogue with voices via role play, or “chair work” – where the voices are represented by an empty chair with content spoken by the patient – but both these techniques require a leap of faith. With an avatar, it’s the recreation of the voice, not the face, that makes this radical, Thomas said. “It’s called avatar therapy, and that sounds like it’s primarily about the visual representation, but not everyone has an existing image that goes with their voice. I think the auditory transformation is particularly powerful.”</p><p>“The suspension of disbelief is remarkable,” Craig told me. Even though trial participants have signed consent forms and know it is the therapist voicing the avatar, they still relate to it as if it were the voice in their head. “They are put in front of this not very wonderful computer animation, and they’re <em>right in there</em>, talking to their voice.”</p><hr><p><span>‘I</span>t was liberating just to talk to Tom [Ward] about it, because I didn’t speak to anyone else,” Joe told me over coffee in south London. He still had the imposing presence of a rugby player, but he was so softly spoken that I had to strain to hear him talk over the hubbub of the cafe.</p><figure id="a0a9aad5-ad1d-46dc-bd41-dd6cc1c71ae2" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:108,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Therapy wars: the revenge of Freud | Oliver Burkeman&quot;,&quot;elementId&quot;:&quot;a0a9aad5-ad1d-46dc-bd41-dd6cc1c71ae2&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/science/2016/jan/07/therapy-wars-revenge-of-freud-cognitive-behavioural-therapy&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:10,&quot;display&quot;:1,&quot;theme&quot;:0}}"></gu-island></figure><p>A year on from avatar therapy, Joe’s voice was still there, a presence just out of eyeshot, still a distinct external entity and not just an inner monologue. But it was quieter, easier to manage and allowed him to get on with daily life. When it spoke, it was to have the same kind of conversations they’d had in his final sessions with the avatar. “I get it – you’re very on edge,” Joe would tell his voice. “I don’t feel great either. But we are just walking to work at the moment. I promise, we’re good.”</p><p>“It worked because I understood the voices more, I think,” he told me. “My general levels of anxiety stayed pretty high, but I’ve started interpreting the hallucinations as a part of the anxiety.” He still has panic attacks. The anxiety and self-doubt that existed before his bad trip are still there. “You do have to address everything that’s going on to address the voices themselves. They feed on everything else.”</p><p>Joe recently went back to his GP in search of help with his anxiety, but there was no cutting-edge experimental solution delivered by renowned psychologists for him this time. The GP put him on a waiting list for NHS talking therapy, and warned that he could be in for a very long wait.</p><p><em>Names of patients have been changed. </em></p><p><em><span data-dcr-style="bullet"></span> </em>In the UK and Ireland, <a href="https://www.samaritans.org/" data-link-name="in body link">Samaritans</a> can be contacted on freephone 116 123, or email <a href="mailto:jo@samaritans.org" data-link-name="in body link | mailto:jo@samaritans.org">jo@samaritans.org</a> or <a href="mailto:jo@samaritans.ie" data-link-name="in body link | mailto:jo@samaritans.ie">jo@samaritans.ie</a>. In the US, you can call or text the <a href="https://988lifeline.org/" data-link-name="in body link">National Suicide Prevention Lifeline</a> on 988, chat on <a href="https://988lifeline.org/chat/" data-link-name="in body link">988lifeline.org</a>, or <a href="https://www.crisistextline.org/" data-link-name="in body link">text HOME</a> to 741741 to connect with a crisis counsellor. In Australia, the crisis support service <a href="https://www.lifeline.org.au/" data-link-name="in body link">Lifeline</a> is 13 11 14. Other international helplines can be found at <a href="http://www.befrienders.org/" data-link-name="in body link">befrienders.org</a></p><p><span data-dcr-style="bullet"></span> In the UK, the charity <a href="https://www.mind.org.uk/" data-link-name="in body link">Mind</a> is available on 0300 123 3393 and <a href="https://www.childline.org.uk/" data-link-name="in body link">Childline</a> on 0800 1111. In the US, call or text <a href="https://www.mhanational.org/" data-link-name="in body link">Mental Health America</a> at 988 or chat 988lifeline.org. In Australia, support is available at <a href="https://www.beyondblue.org.au/" data-link-name="in body link">Beyond Blue</a> on 1300 22 4636, <a href="https://www.lifeline.org.au/" data-link-name="in body link">Lifeline</a> on 13 11 14, and at <a href="https://mensline.org.au/" data-link-name="in body link">MensLine</a> on 1300 789 978</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built an app to use a QR code as my doorbell (123 pts)]]></title>
            <link>https://dingdongdoorbell.com</link>
            <guid>41980681</guid>
            <pubDate>Tue, 29 Oct 2024 08:03:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dingdongdoorbell.com">https://dingdongdoorbell.com</a>, See on <a href="https://news.ycombinator.com/item?id=41980681">Hacker News</a></p>
<div id="readability-page-1" class="page">
    
  
  <h3>Replace your doorbell with a QR code</h3>
  <p>Ding Dong Doorbell offers a versatile digital doorbell for every entrance.</p><ol> 
    <li>Get a QR code to put at your door</li>
    <li>Visitors scan the QR code using their smartphone camera</li>
    <li>Get a notification on your phone wherever you are!</li>
  </ol>
  <p>Having a doorbell does not need to be complicated.</p>
  <ul>
    <li>Instant notifications anywhere</li>
    <li>No wires, no batteries</li>
    <li>Cover multiple entrances with ease</li>
    <li>Perfect for homes, apartments, offices and temporary setups</li>
    <li>No worries that your expensive doorbell will be vandalized or stolen</li>
  </ul>

  <p>Download the app and get your doorbell QR code today!</p>

  <section id="cta">
    <p><a href="https://play.google.com/store/apps/details?id=za.co.code27.dingdong" target="_blank">
        <img src="https://dingdongdoorbell.com/static/img/GetItOnGooglePlay_Badge_Web_color_English.png" width="270" height="80">
      </a>
      <a href="https://apps.apple.com/us/app/ding-dong-doorbell/id6670178558" target="_blank">
        <img src="https://dingdongdoorbell.com/static/img/Download_on_the_App_Store_Badge_US-UK_RGB_blk_092917.svg" width="240" height="80">
      </a>
    </p>
    <a href="http://eepurl.com/i0e-HI">Join our mailing list</a>
  </section>


  

  

</div>]]></description>
        </item>
    </channel>
</rss>