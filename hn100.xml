<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 06 Dec 2025 18:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[HTML as an Accessible Format for Papers (105 pts)]]></title>
            <link>https://info.arxiv.org/about/accessible_HTML.html</link>
            <guid>46173825</guid>
            <pubDate>Sat, 06 Dec 2025 14:59:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://info.arxiv.org/about/accessible_HTML.html">https://info.arxiv.org/about/accessible_HTML.html</a>, See on <a href="https://news.ycombinator.com/item?id=46173825">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
          
        
      
      <main data-md-component="main">
        <div data-md-component="content">
              <article>
                
                  

  <a href="https://github.com/arXiv/arxiv-docs/blob/develop/source/about/accessible_HTML.md" title="Edit this page">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"></path></svg>
  </a>


<h2 id="html-as-an-accessible-format-for-papers">HTML as an accessible format for papers</h2>
<p>Accessibility barriers in research are not new, but they are urgent. The message we have heard from our community is that arXiv can have the most impact in the shortest time by offering HTML papers alongside the existing PDF.</p>
<p>arXiv has successfully launched papers in HTML format. We are gradually backfilling HTML for arXiv's corpus of over 2 million papers over time. Not every paper can be successfully converted, so a small percentage of papers will not have an HTML version. We will work to improve conversion over time.</p>
<p>The link to the HTML format will appear on abstract pages below the existing PDF download link. Authors will have the opportunity to preview their paper’s HTML as a part of the submission process.</p>
<p>The beta rollout is just the beginning. We have a long way to go to improve HTML papers and will continue to solicit feedback from authors, readers, and the entire arXiv community to improve conversions from LaTeX.</p>
<h2 id="why-experimental-html">Why "experimental" HTML?</h2>
<p>Did you know that 90% of submissions to arXiv are in TeX format, mostly LaTeX? That poses a unique accessibility challenge: to accurately convert from TeX—a very extensible language used in myriad unique ways by authors—to HTML, a language that is much more accessible to screen readers and text-to-speech software, screen magnifiers, and mobile devices. In addition to the technical challenges, the conversion must be both rapid and automated in order to maintain arXiv’s core service of free and fast dissemination.</p>
<p>Because of these challenges we know there will be some conversion and rendering issues. We have decided to launch in beta with “experimental” HTML because:</p>
<ol>
<li>Accessible papers are needed now. We have talked to the arXiv community, especially researchers with accessibility needs, and they overwhelmingly asked us not to wait.</li>
<li>We need your help. The obvious work is done. Reports from the community will help us identify issues we can track back to specific LaTeX packages that are not converting correctly.</li>
</ol>
<h2 id="error-messages-you-may-see-in-html-papers">Error messages you may see in HTML papers</h2>
<p>HTML papers on arXiv.org are a work in progress and will sometimes display errors. As we work to improve accessibility we share with you the causes of these errors and what authors can do to help minimize them. <a href="https://info.arxiv.org/about/accessibility_html_error_messages.html">Learn more about error messages you may see in HTML papers</a></p>
<h2 id="ways-to-help">Ways to help</h2>
<h3 id="1-read-html-papers-and-report-issues">1) Read HTML papers and report issues</h3>
<p>We encourage the community to try out HTML papers in your field:</p>
<h4 id="report-an-issue">Report an issue</h4>
<ul>
<li>Go to the abstract page for a paper you are interested in reading.</li>
<li>Look in the section where you find the link to the PDF download, and click the new link for HTML.</li>
<li>Report issues by either <strong>a)</strong> clicking on the Open Issue button <strong>b)</strong> selecting text and clicking on the Open Issue for Selection button or <strong>c)</strong> use <code>Ctrl+?</code> on your keyboard. If you are using a screen reader, use <code>Alt+y</code> to toggle accessible reporting buttons per paragraph.</li>
</ul>
<p><strong>Please do not create reports that the HTML paper doesn't look exactly like the PDF paper</strong></p>
<p>Our primary goal for this project is to make papers more accessible, so the focus during the beta phase will value function over form. HTML layouts that are incorrect or are illegible are important to report. But we do expect the HTML papers to present differently than the same paper rendered in PDF. Line breaks will occur in different places and there is likely to be more white space. In general, the HTML paper won't present as compactly. Intricate typographic layouts will not be rendered so intricately. This is by design.</p>
<p>HTML is a different medium and brings its own advantages versus PDF. In addition to being much more compatible with assistive technologies, HTML does a far better job adapting to the characteristics of the device you are reading on, including mobile devices.</p>
<h3 id="2-help-improve-the-conversion-from-latex">2) Help improve the conversion from LaTeX</h3>
<p>If you are an author you can help us improve conversions to HTML by following our guide to <a href="https://info.arxiv.org/help/submit_latex_best_practices.html">LaTeX Markup Best Practices for Successful HTML Papers</a>.</p>
<p>If you are a developer and have free development cycles, help us improve conversions! Our collaborators at LaTeXML maintain a <a href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML">list of issues</a> and welcome feedback and developer contributions.</p>
<p>If you are a publisher, member of a society, or conference organizer you can help us improve conversions to HTML by reviewing the .cls files your organization recommends to authors for unsupported packages. Providing .cls files that use supported packages is an easy way to support and sow accessibility in the scientific community. </p>
<h2 id="thank-you-to-our-collaborators">Thank you to our collaborators</h2>
<p>First, we want to share a special thank you to all the scientists with disabilities who have generously shared their insights, expertise, and guidance throughout this project.</p>
<p>We want to thank two organizations without which HTML papers on arXiv would not be possible: The <a href="https://www.latex-project.org/">LaTeX Project</a>, and the <a href="https://math.nist.gov/~BMiller/LaTeXML/">LaTeXML</a> team from NIST. We deeply thank each member of these teams for their knowledge, incredible work, and commitment to accessibility.</p>





                
              </article>
            </div>
        
      </main>
      






    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tiny Core Linux: a 23 MB Linux distro with graphical desktop (193 pts)]]></title>
            <link>http://www.tinycorelinux.net/</link>
            <guid>46173547</guid>
            <pubDate>Sat, 06 Dec 2025 14:18:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.tinycorelinux.net/">http://www.tinycorelinux.net/</a>, See on <a href="https://news.ycombinator.com/item?id=46173547">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
        <h3>Welcome to The Core Project - Tiny Core Linux</h3>
        
        <p>The Core Project is a highly modular based system with community build extensions.
</p><p>
 It starts with a recent Linux kernel, vmlinuz, and our root filesystem and start-up scripts packaged with a basic set of kernel modules in core.gz.
Core (11MB) is simply the kernel + core.gz - this is the foundation for user created desktops, servers, or appliances.
TinyCore is Core + Xvesa.tcz + Xprogs.tcz + aterm.tcz + fltk-1.3.tcz + flwm.tcz + wbar.tcz
</p><p>
TinyCore becomes simply an example of what the Core Project can produce, an 16MB FLTK/FLWM desktop.
</p><p>
CorePlus ofers a simple way to get started using the Core philosophy with its included community packaged
extensions enabling easy embedded frugal or pendrive installation of the user's choice of supported desktop, while
maintaining the Core principal of mounted extensions with full package management.
</p><p>

It is not a complete desktop nor is all hardware completely supported. It represents only the core needed to boot into a very minimal X desktop typically with wired internet access.</p><p>

The user has complete control over which applications and/or additional hardware to have supported, be it for a desktop, a netbook, an appliance, or server, selectable by the user by installing additional applications from online repositories, or easily compiling most anything you desire using tools provided.</p>

<p>The latest version: <b>16.2</b></p>

<h3>News</h3>



<h3>About Our Project</h3>

<p>Our goal is the creation of a nomadic ultra small graphical desktop operating system capable of booting from cdrom, pendrive, or frugally from a hard drive. The desktop boots extremely fast and is able to support additional applications and hardware of the users choice. While Tiny Core always resides in ram, additional applications extensions can either reside in ram, mounted from a persistent storage device, or installed into a persistent storage device.</p>

<p>We invite interested users and developers to explore Tiny Core. Within our forums we have an open developement model. We encourage shared knowledge. We promote community involvement and community built application extensions. Anyone can contribute to our project by packaging their favorite application or hardware support to run in Tiny Core. The Tiny Core Linux Team currently consists of eight members who peruse the forums to assist from answering questions to helping package new extensions.
</p><p>
Join us here and on IRC Freenode <a href="irc://irc.freenode.net/tinycorelinux">#tinycorelinux</a>.
</p><p>
Learn. Share. Grow your knowledge of Linux.
</p><p>
Robert Shingledecker, December 01, 2008 </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GrapheneOS is the only Android OS providing full security patches (153 pts)]]></title>
            <link>https://grapheneos.social/@GrapheneOS/115647408229616018</link>
            <guid>46173407</guid>
            <pubDate>Sat, 06 Dec 2025 13:58:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://grapheneos.social/@GrapheneOS/115647408229616018">https://grapheneos.social/@GrapheneOS/115647408229616018</a>, See on <a href="https://news.ycombinator.com/item?id=46173407">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How I discovered a hidden microphone on a Chinese NanoKVM (211 pts)]]></title>
            <link>https://telefoncek.si/2025/02/2025-02-10-hidden-microphone-on-nanokvm/</link>
            <guid>46173383</guid>
            <pubDate>Sat, 06 Dec 2025 13:54:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://telefoncek.si/2025/02/2025-02-10-hidden-microphone-on-nanokvm/">https://telefoncek.si/2025/02/2025-02-10-hidden-microphone-on-nanokvm/</a>, See on <a href="https://news.ycombinator.com/item?id=46173383">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
	<div itemprop="articleBody">
		<p>NanoKVM is a <strong>hardware KVM switch</strong> developed by the Chinese company Sipeed. Released last year, it enables remote control of a computer or server using a virtual keyboard, mouse, and monitor. Thanks to its compact size and low price, it quickly gained attention online, especially when the company promised to release its code as open-source. However, as we’ll see, the device has some serious security issues. But first, let’s start with the basics.</p>

<h2 id="how-does-the-device-work">How Does the Device Work?</h2>

<p>As mentioned, NanoKVM is a KVM switch designed for remotely controlling and managing computers or servers. It features an HDMI port, three USB-C ports, an Ethernet port for network connectivity, and a special serial interface. The package also includes a small accessory for managing the power of an external computer.</p>

<p>Using it is quite simple. First, you connect the device to the internet via an Ethernet cable. Once online, you can access it through a standard web browser (though <em>JavaScript JIT</em> must be enabled). The device supports Tailscale VPN, but with some effort (read: hacking), it can also be configured to work with your own VPN, such as WireGuard or OpenVPN server. Once set up, you can control it from anywhere in the world via your browser.</p>

<div>
<p><a href="https://telefoncek.si/static/2025/02/NanoKVM.jpg">
<img src="https://telefoncek.si/static/2025/02/NanoKVM.jpg" alt="NanoKVM"></a></p><p>
NanoKVM
</p>
</div>

<p>The device could be connected to the target computer using an HDMI cable, capturing the video output that would normally be displayed on a monitor. This allows you to view the computer’s screen directly in your browser, essentially acting as a virtual monitor.</p>

<p>Through the USB connection, NanoKVM can also emulate a keyboard, mouse, CD-ROM, USB drive, and even a USB network adapter. This means you can remotely control the computer as if you were physically sitting in front of it - but all through a web interface.</p>

<p>While it functions similarly to remote management tools like RDP or VNC, it has one key difference: there’s no need to install any software on the target computer. Simply plug in the device, and you’re ready to manage it remotely. NanoKVM even allows you to enter the BIOS, and with the additional accessory for power management, you can remotely turn the computer on, off, or reset it.</p>

<p>This makes it incredibly useful - you can power on a machine, access the BIOS, change settings, mount a virtual bootable CD, and install an operating system from scratch, just as if you were physically there. Even if the computer is on the other side of the world.</p>

<p>NanoKVM is also quite affordable. The fully-featured version, which includes all ports, a built-in mini screen, and a case, costs just over €60, while the stripped-down version is around €30. By comparison, a similar RaspberryPi-based device, PiKVM, costs around €400. However, PiKVM is significantly more powerful and reliable and, with a KVM splitter, can manage multiple devices simultaneously.</p>

<p>As mentioned earlier, the announcement of the device caused quite a stir online - not just because of its low price, but also due to its compact size and minimal power consumption. In fact, it can be powered directly from the target computer via a USB cable, which it also uses to simulate a keyboard, mouse, and other USB devices. So you have only one USB cable - in one direction it powers NanoKVM, on the other it helps it to simulate keyboard mouse and other devices on a computer you want to manage.</p>

<p>The device is built on the open-source RISC-V processor architecture, and the manufacturer eventually did release the device’s software under an open-source license at the end of last year. (To be fair, one part of the code remains closed, but the community has already found a suitable open-source replacement, and the manufacturer has promised to open this portion soon.)</p>

<p><strong>However, the real issue is security.</strong></p>

<p>Understandably, the company was eager to release the device as soon as possible. In fact, an early version had a minor hardware design flaw - due to an incorrect circuit cable, the device sometimes failed to detect incoming HDMI signals. As a result, the company recalled and replaced all affected units free of charge. Software development also progressed rapidly, but in such cases, the primary focus is typically on getting basic functionality working, with security taking a backseat.</p>

<p>So, it’s not surprising that the developers made some serious missteps - rushed development often leads to stupid mistakes. But some of the security flaws I discovered in my quick (and by no means exhaustive) review are genuinely concerning.</p>

<p>One of the <a href="https://www.hackster.io/news/security-researcher-warns-on-sipeed-s-nanokvm-finds-vulnerabilities-and-a-cat-in-the-firmware-e1157a9ff0f4">first security analysis revealed numerous vulnerabilities</a> - and some rather bizarre discoveries. For instance, a security researcher even found an image of a cat embedded in the firmware. While the Sipeed developers acknowledged these issues and relatively quickly fixed at least some of them, many remain unresolved.</p>

<div>
<p><a href="https://telefoncek.si/static/2025/02/device.jpg">
<img src="https://telefoncek.si/static/2025/02/device.jpg" alt="NanoKVM"></a></p><p>
NanoKVM
</p>
</div>

<p>After purchasing the device myself, I ran a quick security audit and found several alarming flaws. The device initially came with a default password, and <code>SSH</code> access was enabled using this preset password. I reported this to the manufacturer, and to their credit, they fixed it relatively quickly. However, many other issues persist.</p>

<p>The user interface is riddled with security flaws - there’s no CSRF protection, no way to invalidate sessions, and more. Worse yet, the encryption key used for password protection (when logging in via a browser) is <strong>hardcoded and identical</strong> across all devices. This is a major security oversight, as it allows an attacker to easily decrypt passwords. More problematic, this needed to be explained to the developers. Multiple times.</p>

<p>Another concern is the device’s reliance on Chinese DNS servers. And configuring your own (custom) DNS settings is quite complicated. Additionally, the device communicates with Sipeed’s servers in China - downloading not only updates but also the closed-source component mentioned earlier. For this closed source component it needs to verify an identification key, which is stored on the device in plain text. Alarmingly, the device does not verify the integrity of software updates, includes a strange version of the WireGuard VPN application (which does not work on some networks), and runs a heavily stripped-down version of Linux that lacks <code>systemd</code> and <code>apt</code>. And these are just a few of the issues.</p>

<p>Were these problems simply oversights? Possibly. But what additionally raised red flags was the presence of <code>tcpdump</code> and <code>aircrack</code> - tools commonly used for network packet analysis and wireless security testing. While these are useful for debugging and development, they are also <strong>hacking tools</strong> that can be dangerously exploited. I can understand why developers might use them during testing, but they have absolutely no place on a production version of the device.</p>

<p>A Hidden Microphone</p>

<p>And then I discovered something even more alarming - <strong>a tiny built-in microphone that isn’t clearly mentioned in the official documentation</strong>. It’s a miniature SMD component, measuring just 2 x 1 mm, yet capable of recording surprisingly high-quality audio.</p>

<p>What’s even more concerning is that all the necessary recording tools are already installed on the device! By simply connecting via <code>SSH</code> (remember, the device initially used default passwords!), I was able to start recording audio using the amixer and arecord tools. Once recorded, the audio file could be easily copied to another computer. With a little extra effort, it would even be possible to stream the audio over a network, allowing an attacker to eavesdrop in real time.</p>

<div>
<p><a href="https://telefoncek.si/static/2025/02/hidden_microphone.jpg">
<img src="https://telefoncek.si/static/2025/02/hidden_microphone.jpg" alt="Hidden Microphone in NanoKVM"></a></p><p>
Hidden Microphone in NanoKVM
</p>
</div>

<p>Physically removing the microphone is possible, but it’s not exactly straightforward. As seen in the image, disassembling the device is tricky, and due to the microphone’s tiny size, you’d need a microscope or magnifying glass to properly desolder it.</p>

<p><strong>To summarize</strong>: the device is riddled with security flaws, originally shipped with default passwords, communicates with servers in China, comes preinstalled with hacking tools, and even includes a built-in microphone - fully equipped for recording audio - without clear mention of it in the documentation. Could it get any worse?</p>

<p>I am pretty sure these issues stem from extreme negligence and rushed development rather than malicious intent. However, that doesn’t make them any less concerning.</p>

<p>That said, these findings don’t mean the device is entirely unusable.</p>

<p>Since the device is open-source, it’s entirely possible to install custom software on it. In fact, <a href="https://github.com/scpcom/sophgo-sg200x-debian">one user has already begun porting his own Linux distribution</a> - starting with Debian and later switching to Ubuntu. With a bit of luck, this work could soon lead to official Ubuntu Linux support for the device.</p>

<p>This custom Linux version already runs the manufacturer’s modified KVM code, and within a few months, we’ll likely have a fully independent and significantly more secure software alternative. The only minor inconvenience is that installing it requires physically opening the device, removing the built-in SD card, and flashing the new software onto it. However, in reality, this process isn’t too complicated.</p>

<p>And while you’re at it, you might also want to remove the microphone… or, if you prefer, connect a speaker. In my test, I used an 8-ohm, 0.5W speaker, which produced surprisingly good sound - essentially turning the NanoKVM into a tiny music player. Actually, the idea is not so bad, because <a href="https://docs.pikvm.org/audio/">PiKVM also included 2-way audio support for their devices end of last year</a>.</p>

<div>
<p><a href="https://telefoncek.si/static/2025/02/speaker.jpg">
<img src="https://telefoncek.si/static/2025/02/speaker.jpg" alt="Basic board with speaker"></a></p><p>
Basic board with speaker
</p>
</div>

<h2 id="final-thoughts">Final Thoughts</h2>

<p>All this of course raises an interesting question: How many similar devices with hidden functionalities might be lurking in your home, just waiting to be discovered? And not just those of Chinese origin. Are you absolutely sure none of them have built-in miniature microphones or cameras?</p>

<p>You can start with your iPhone - <a href="https://arstechnica.com/tech-policy/2025/01/apple-agrees-to-pay-95m-delete-private-conversations-siri-recorded/">last year Apple has agreed to pay $95 million to settle a lawsuit alleging that its voice assistant Siri recorded private conversations</a>. They shared the data with third parties and used them for targeted ads. “Unintentionally”, of course! Yes, that Apple, that cares about your privacy so much.</p>

<p>And Google is doing the same. They are facing a similar lawsuit over their voice assistant, but the litigation likely won’t be settled until this fall. So no, small Chinese startup companies are not the only problem. And if you are worried about Chinese companies obligations towards Chinese government, let’s not forget that U.S. companies also have obligations to cooperate with U.S. government. While Apple is publicly claiming they do not cooperate with FBI and other U. S. agencies (because thy care about your privacy so much), some media revealed that Apple was holding a series secretive Global Police Summit at its Cupertino headquarters <a href="https://www.forbes.com/sites/thomasbrewster/2024/10/09/apple-sells-privacy-to-consumers-but-its-quietly-helping-police-use-iphones-for-surveillance/">where they taught police how to use their products for surveillance and policing work</a>. And as one of the police officers pointed out - he has “<em>never been part of an engagement that was so collaborative</em>.”. Yep.</p>

<h3 id="ps-how-to-record-audio-on-nanokvm">P.S. How to Record Audio on NanoKVM</h3>

<p>If you want to test the built-in microphone yourself, simply connect to the device via <code>SSH</code> and run the following two commands:</p>

<ul>
  <li><code>amixer -Dhw:0 cset name='ADC Capture Volume 20'</code> (<em>this sets microphone sensitivity to high</em>)</li>
  <li><code>arecord -Dhw:0,0 -d 3 -r 48000 -f S16_LE -t wav test.wav &amp; &gt; /dev/null &amp;</code> (<em>this will capture the sound to a file named <code>test.wav</code></em>)</li>
</ul>

<p>Now, speak or sing (perhaps the Chinese national anthem?) near the device, then press <code>Ctrl + C</code>, copy the <code>test.wav</code> file to your computer, and listen to the recording.</p>

	</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Autism's confusing cousins (107 pts)]]></title>
            <link>https://www.psychiatrymargins.com/p/autisms-confusing-cousins</link>
            <guid>46172443</guid>
            <pubDate>Sat, 06 Dec 2025 11:18:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.psychiatrymargins.com/p/autisms-confusing-cousins">https://www.psychiatrymargins.com/p/autisms-confusing-cousins</a>, See on <a href="https://news.ycombinator.com/item?id=46172443">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!gvh6!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d6dc22d-7d94-465c-9379-b191248a32e0_1152x384.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!gvh6!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d6dc22d-7d94-465c-9379-b191248a32e0_1152x384.jpeg 424w, https://substackcdn.com/image/fetch/$s_!gvh6!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d6dc22d-7d94-465c-9379-b191248a32e0_1152x384.jpeg 848w, https://substackcdn.com/image/fetch/$s_!gvh6!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d6dc22d-7d94-465c-9379-b191248a32e0_1152x384.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!gvh6!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d6dc22d-7d94-465c-9379-b191248a32e0_1152x384.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!gvh6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d6dc22d-7d94-465c-9379-b191248a32e0_1152x384.jpeg" width="1152" height="384" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8d6dc22d-7d94-465c-9379-b191248a32e0_1152x384.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:384,&quot;width&quot;:1152,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:37942,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.psychiatrymargins.com/i/180764157?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d6dc22d-7d94-465c-9379-b191248a32e0_1152x384.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!gvh6!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d6dc22d-7d94-465c-9379-b191248a32e0_1152x384.jpeg 424w, https://substackcdn.com/image/fetch/$s_!gvh6!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d6dc22d-7d94-465c-9379-b191248a32e0_1152x384.jpeg 848w, https://substackcdn.com/image/fetch/$s_!gvh6!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d6dc22d-7d94-465c-9379-b191248a32e0_1152x384.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!gvh6!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d6dc22d-7d94-465c-9379-b191248a32e0_1152x384.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><blockquote><p>“I think that these days what we mean by “autism” is basically “weird person disease.””</p></blockquote><p><strong>Sorbie Richner</strong><span>, </span><a href="https://www.psychiatrymargins.com/p/rich-girl-rehab" rel="">Rich Girl Rehab</a></p><blockquote><p>“Accurate diagnosis requires consideration of multiple diagnoses. Sometimes, different diagnoses can overlap with one another and can only be differentiated in subtle and nuanced ways, but particular diagnoses vary considerably in levels of public awareness. As such, an individual may meet the diagnostic criteria for one diagnosis but self-diagnoses with a different diagnosis because it is better known.”</p></blockquote><p><strong>Sam Fellowes</strong><span>, </span><a href="https://www.cambridge.org/core/journals/royal-institute-of-philosophy-supplements/article/abs/selfdiagnosis-in-psychiatry-and-the-distribution-of-social-resources/91A981A3908EE250DE19CF597277F197" rel="">Self-Diagnosis in Psychiatry and the Distribution of Social Resources</a></p><p>Unsurprisingly, these days I meet many people in the psychiatric clinic who are convinced that they have autism, or suspect (with various degrees of confidence) that they have autism, or report being diagnosed with autism at some point in their lives by some clinician. And for a fair number of such individuals, I cannot say with reasonable certitude that they have autism. The reasons they give for considering autism vary widely, but tend to be along the lines of…</p><ul><li><p>“Eye contact makes me very uncomfortable.”</p></li><li><p>“I suck at small talk.”</p></li><li><p>“I have rigid routines.”</p></li><li><p>“I hyper-focus on my hobbies.”</p></li><li><p>“I am always fidgeting.”</p></li><li><p>“Social interaction exhausts me.”</p></li><li><p>“I really bad at making friends.”</p></li><li><p>“I don’t fit in; people find me weird.”</p></li></ul><p>What’s interesting about many of the items above is that the number one diagnostic possibility in my mind is an anxiety disorder of some sort. I remember seeing a woman who was a classic example of someone with high neuroticism, poor self-esteem, and severe social anxiety, and she had believed for much of her life that she was autistic because some random doctor somewhere at some point (she couldn’t even remember who or what sort of assessment this involved) had told her that she had autism, and she believed it because it fit in with her experience of being awkward-shy-weird.</p><p>It is common for me to meet individuals who think they have autism and find myself thinking, “schizoid,” “obsessive compulsive,” “cluster B,” “social anxiety,” “generalized anxiety,” “trauma,” “socially awkward,”… None of these, however, have the mimetic virality of autism.</p><p>I don’t want to come across as being skeptical of the reality of autism as a diagnosis or as asserting that most people are misdiagnosed. Autism exists, to the extent that any psychiatric disorder exists. Not everyone is misdiagnosed, perhaps even most people.  I am not trying to say, “autism is bullshit.” It’s not. I offer the diagnosis of autism as a clinician perhaps as often as I find myself doubting it.</p><p><span>What intrigues me is that people are drawn to autism as a diagnosis because it seems to offer recognition of something they’ve lived with: they may be deeply awkward, terribly shy, or bad with people, they may struggle with social interactions, they may find other people annoying, other people may find them weird, they may have a hard time connecting to others, they may have been bullied, and they may have directed their loneliness or introversion towards peculiar interests or hobbies. Autism seems to them to capture all that. It seems like an apt and appealing narrative. But autism may also be the only relevant diagnosis they’ve heard of or are familiar with. They haven’t seen any cool TikToks about being schizoid. No one’s offering them quizzes about being schizotypal. A random pediatrician or primary care doc is not going to tell them they have an obsessive-compulsive style of personality. So when some professional doubts that they have “autism,” they see it as a dismissal or rejection of their “lived experience.” </span><em>Of course, I am weird-anxious-awkward. How can you say otherwise?</em><span> What they don’t know is that the choice is not between autism or nothing, but rather between autism and about a dozen other diagnostic possibilities.</span></p><p>So for the sake of our collective sanity, let’s consider a few of them…</p><p><span>To be diagnosed with autism spectrum disorder according to DSM-5, a person must have ongoing </span><strong>difficulties in social communication and interaction</strong><span> in all three areas: trouble with back-and-forth social connection, problems with nonverbal communication like eye contact and body language, and difficulty making or keeping friendships. They also must show at least two types of </span><strong>repetitive or restricted behaviors</strong><span>, such as repetitive movements or phrases, needing things to stay the same, having very intense focused interests, or being unusually sensitive (or under-sensitive) to things like sounds, textures, or lights. These patterns must have been </span><strong>present since early childhood</strong><span> (even if they weren’t noticed until later when life got more complicated), lead to substantial </span><strong>impairment in functioning</strong><span>, and can’t simply be explained by intellectual disability (or other psychiatric disorders).</span></p><p>To “have” autism is simply to demonstrate this cluster of characteristics at the requisite level of severity and pervasiveness. It doesn’t mean that the person has a specific type of brain attribute or a specific set of genes that differentiates them from non-autistics. No such internal essence exists for the notion as currently conceptualized.</p><p><span>Autism spectrum is wide enough to have very different prototypes within it. On one end we have profound autism, representing someone with severe autistic traits who is completely dependent on others for care and has substantial intellectual disability or very limited language ability. At the other end, we have successful nerdy individuals with autistic traits and superior intelligence, often seen in science or academia, à la Sheldon Cooper. (Holden Thorp, editor-in-chief of the </span><em>Science</em><span> journals and former UNC chancellor, for example, has publicly disclosed his own autism diagnosis.) This wide range is confusing enough on its own, even without considering other conditions that can present with autism-like features.</span></p><p><span>Autism cannot be identified via medical “tests.” It is identified via clinical information in the form of history, observation, and interaction, and the less information available or the more unreliable the information provided is, the more uncertain we’ll be. To </span><em>have</em><span> autism is basically a judgment call that one is a good match to a descriptive prototype. We can get this judgment wrong, and we sometimes do get it wrong. (There is nothing wrong with this fallibility as such, as long as we recognize it. Lives have been built on foundations less sturdy.)</span></p><p><span>Autism as a category or identity has taken on a life of its own. I am aware that not everyone in the neurodiversity crowd accepts the legitimacy of clinician judgments or clinical criteria as outlined in the diagnostic manuals, such as the DSM and ICD. There are other ways to ground the legitimacy of self-diagnoses, </span><a href="https://www.tandfonline.com/doi/full/10.1080/09515089.2024.2327823" rel="">in theoretically virtuous accounts or pragmatic uses</a><span>, which require distinct considerations of their own; I don’t reject that. But here, I am concerned with autism as a clinical diagnosis and the accuracy of autism understood in terms of alignment with clinical diagnosis. Would competent and knowledgeable clinicians with access to all relevant clinical information concur that the person’s presentation meets diagnostic criteria for autism? If you don’t really care about that, this post is not for you.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!NXb7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34fe964c-f33d-4e4e-9ad2-8ccb624fe08b_720x472.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!NXb7!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34fe964c-f33d-4e4e-9ad2-8ccb624fe08b_720x472.jpeg 424w, https://substackcdn.com/image/fetch/$s_!NXb7!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34fe964c-f33d-4e4e-9ad2-8ccb624fe08b_720x472.jpeg 848w, https://substackcdn.com/image/fetch/$s_!NXb7!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34fe964c-f33d-4e4e-9ad2-8ccb624fe08b_720x472.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!NXb7!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34fe964c-f33d-4e4e-9ad2-8ccb624fe08b_720x472.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!NXb7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34fe964c-f33d-4e4e-9ad2-8ccb624fe08b_720x472.jpeg" width="720" height="472" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/34fe964c-f33d-4e4e-9ad2-8ccb624fe08b_720x472.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:472,&quot;width&quot;:720,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:97251,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.psychiatrymargins.com/i/180764157?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34fe964c-f33d-4e4e-9ad2-8ccb624fe08b_720x472.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!NXb7!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34fe964c-f33d-4e4e-9ad2-8ccb624fe08b_720x472.jpeg 424w, https://substackcdn.com/image/fetch/$s_!NXb7!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34fe964c-f33d-4e4e-9ad2-8ccb624fe08b_720x472.jpeg 848w, https://substackcdn.com/image/fetch/$s_!NXb7!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34fe964c-f33d-4e4e-9ad2-8ccb624fe08b_720x472.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!NXb7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34fe964c-f33d-4e4e-9ad2-8ccb624fe08b_720x472.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Lascaux Cave</figcaption></figure></div><p>Schizoid personality describes people who have little desire for close relationships and prefer solitary activities. Unlike people who are simply shy or socially anxious, individuals with schizoid personality style genuinely don’t find relationships rewarding or necessary. They typically appear emotionally detached or cold, show restricted emotional expression, seem indifferent to praise or criticism, and have few if any close friends or confidants. They often live quietly on the margins of society, pursuing solitary interests or jobs. They keep their inner worlds (which can be quite rich) private and don’t seek emotional intimacy with others.</p><p>In autism, social difficulties stem from genuine challenges with processing social information: difficulty reading facial expressions, understanding implied meanings, picking up on social cues, knowing unwritten social rules, etc. In schizoid personality, the person typically understands social conventions but simply isn’t motivated to engage with them. They withdraw from genuine disinterest. Schizoid personality also lacks the additional features of autism (repetitive or restricted behaviors, various sensory sensitivities).</p><p>Schizotypal personality describes people who have odd or eccentric beliefs, unusual perceptual experiences, and difficulties with close relationships. Unlike schizoid personality (which involves simple disinterest in relationships), schizotypal includes strange ways of thinking and perceiving the world. People with schizotypal personality might believe in telepathy, feel they have special powers, think random events have special meaning for them personally, or have unusual perceptual experiences (like feeling a presence in the room or hearing whispers). They typically have few close friends, experience social anxiety that doesn’t improve with familiarity, and may appear paranoid or suspicious of others’ motives. Both schizotypal personality and autism can involve social difficulties and odd or eccentric behavior, but in schizotypal personality, the peculiarity comes from magical thinking, paranoid ideas, and perceptual distortions.</p><p>Obsessive-compulsive personality describes people who are preoccupied with orderliness, perfectionism, and control. These individuals are rigid rule-followers who want things to be done “the right way,” have difficulty delegating tasks, and get caught up in details and lists to the point where they lose sight of the main goal. They tend to be workaholics who neglect leisure and friendships, are inflexible about matters of morality or ethics, and are often stubborn and controlling. Both obsessive-compulsive personality and autism can involve rigid adherence to routines, rules, and specific ways of doing things. In obsessive-compulsive personality, the inflexibility comes from anxiety about loss of control. The person is trying to, consciously or unconsciously, manage anxiety through control and perfectionism. In autism, the need for sameness and routine serves different functions. It provides predictability in a world that feels confusing or it helps with sensory regulation rather than anxiety-driven perfectionism.</p><p>Severe social anxiety is an intense, persistent fear of social situations where a person might be judged, embarrassed, or humiliated. Social anxiety disorder involves overwhelming fear that interferes with daily life. People with this condition worry excessively about saying something stupid, looking foolish, or being rejected. They often avoid social situations entirely, which can lead to isolation, difficulty maintaining employment, and problems forming relationships. Both social anxiety and autism involve social difficulties and withdrawal. Social anxiety usually improves significantly in comfortable, safe environments (like with close family or friends), while autistic social differences tend to be more consistent across all contexts.</p><p>Borderline personality disorder involves intense emotional instability, unstable relationships, fear of abandonment, and a shifting sense of self, with people experiencing rapid mood swings and chaotic relationships that alternate between idealization and devaluation of others. While it can resemble autism through social difficulties, emotional dysregulation, rigid thinking, and feeling different from others, the key distinctions are that borderline centers on intense relationship preoccupations and emotional chaos, whereas autism involves genuine difficulty understanding social cues and communication; borderline features rapidly shifting identity and relationship-triggered mood swings, while autism includes stable self-concept, sensory sensitivities, restricted interests, and literal communication that aren’t present in borderline; and borderline symptoms fluctuate dramatically with relationship stability while autistic traits remain consistent across contexts.</p><p>Social communication disorder is a condition in DSM-5 where someone has significant, ongoing difficulty using verbal and nonverbal communication appropriately in social contexts. People with social communication disorder struggle with the “pragmatic” aspects of language, that is, knowing how to use language effectively in social situations. They may have trouble understanding when to take turns in conversation, knowing how much detail to give, adjusting their speaking style for different situations, understanding implied meanings or hints, picking up on nonverbal cues like body language and facial expressions, and knowing how to start, maintain, or end conversations naturally. This makes forming friendships and relationships difficult and affects life functioning. The social communication problems in social communication disorder look nearly identical to the “Criterion A” features of autism. However, unlike autism, people with social communication disorder don’t show repetitive behaviors, restricted interests, sensory sensitivities, or the need for sameness and routine.</p><p>Social communication disorder is rarely diagnosed in favor of autism primarily because autism provides access to critical services, insurance coverage, educational support, and legal protections that social communication disorder does not reliably offer, creating strong practical incentives for families and clinicians to prefer the autism diagnosis. Additionally, autism has an established evidence base, validated assessment tools, clear intervention protocols, and a large supportive community with a neurodiversity-affirming culture, while social communication disorder has none of these. It has no community, minimal research, no specific treatments, and little professional awareness since it was only introduced in the DSM in 2013. Service delivery, insurance, and educational systems are built entirely around autism rather than social communication disorder, and since both conditions require similar interventions for social-communication difficulties, there’s little practical incentive to make the diagnostic distinction, especially when the boundary between them (whether restricted/repetitive behaviors are truly absent or just subtle) is often unclear and clinicians are often unsure the distinction really matters.</p><p>Trauma-related disorders, particularly from early developmental trauma, severe neglect, or disrupted attachment, can mimic autism through social withdrawal and avoidance of eye contact (defensive protection rather than social processing difficulties), communication delays and difficulties (from lack of language exposure or trauma’s impact on brain development), emotional dysregulation and meltdowns (from emotional dysregulation rather than sensory overload), repetitive self-soothing behaviors (anxiety management rather than stimming), sensory sensitivities (hypervigilance rather than sensory processing differences), and rigid need for routine (anxiety-driven safety-seeking rather than cognitive processing style). </p><p>Severe early deprivation can create “quasi-autistic” patterns that can be genuinely difficult to distinguish. The critical distinctions are that trauma-related difficulties typically improve significantly in safe, nurturing environments and with adequate psychological treatment, show more variability across contexts (worse with triggers), are tied to identifiable adverse experiences rather than present from earliest infancy, and lack the restricted interests and genuine social communication processing deficits of autism.</p><p>Social awkwardness refers to social ineptness without meaningful impairment that falls within what is considered normal or typical human variation. This can be mistaken for autism because both may involve limited friendships, preference for solitude, conversation difficulties, reduced eye contact, and intense interests, particularly fueled by online self-diagnosis culture and broad autism awareness. The key distinctions are that socially awkward individuals understand what they should do socially but find it difficult or uninteresting (versus genuinely not understanding unwritten rules), show significant improvement with practice and maturity, are more comfortable in specific contexts, lack the sensory sensitivities and restricted/repetitive behaviors required for autism diagnosis, and generally achieve life goals despite awkwardness rather than experiencing clinically significant impairment.</p><p>Selective Mutism, Intellectual Disability (without autism), Stereotypic Movement Disorder, Attention-Deficit/Hyperactivity Disorder (ADHD), Schizophrenia Spectrum Disorders, Avoidant Personality Disorder, Attachment Disorders, Generalized Anxiety Disorder, Obsessive-Compulsive Disorder, and Rett Syndrome (a characteristic pattern of developmental regression after initial normal development, typically 6-18 months).</p><p>Comorbidity is possible and expected. Someone can be autistic and have maladaptive personality patterns, trauma histories, or anxiety disorders that complicate the presentation. Developmental context, response to relationships, and subjective experiences are all very important in looking beyond the surface presentation to understanding the meaning and functions of behaviors.</p><p><em>See also:</em></p><div data-component-name="DigestPostEmbed"><a href="https://www.psychiatrymargins.com/p/it-is-not-ludicrous-for-mildly-and" rel="noopener" target="_blank"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!m4UH!,w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29b0ee8e-8905-4305-bd23-9a32a74a0fc0_736x414.jpeg"><img src="https://substackcdn.com/image/fetch/$s_!m4UH!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29b0ee8e-8905-4305-bd23-9a32a74a0fc0_736x414.jpeg" sizes="100vw" alt="It is not ludicrous for mildly and severely impaired to have the same diagnosis" width="140" height="140"></picture></div></a></div><div data-component-name="DigestPostEmbed"><a href="https://www.psychiatrymargins.com/p/the-overdiagnosis-confusion" rel="noopener" target="_blank"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!pyp8!,w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb66d64d-46e4-4555-b163-1871fe295d11_742x550.jpeg"><img src="https://substackcdn.com/image/fetch/$s_!pyp8!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb66d64d-46e4-4555-b163-1871fe295d11_742x550.jpeg" sizes="100vw" alt="The “Overdiagnosis” Confusion" width="140" height="140"></picture></div></a></div><p data-attrs="{&quot;url&quot;:&quot;https://www.psychiatrymargins.com/p/autisms-confusing-cousins?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.psychiatrymargins.com/p/autisms-confusing-cousins?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux Instal Fest Belgrade (106 pts)]]></title>
            <link>https://dmz.rs/lif2025_en</link>
            <guid>46172167</guid>
            <pubDate>Sat, 06 Dec 2025 10:20:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dmz.rs/lif2025_en">https://dmz.rs/lif2025_en</a>, See on <a href="https://news.ycombinator.com/item?id=46172167">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        

        <h2>Where and when</h2>

        <p>Linux Install Fest will be held on December 9, 2025 in the JAG3 classroom of the Faculty of Mathematics, at
            <a href="https://www.openstreetmap.org/node/3807078606">Jagićeva 5, Belgrade</a>. Entry to the classroom is possible from 6 pm to 9 pm.</p>

        <p>Jagićeva street is located between the  <a href="https://www.openstreetmap.org/node/6670711291"><em>Pijaca
                    Đeram</em></a> station where trams 5, 6, 7L and 14 stop, and the <a href="https://www.openstreetmap.org/node/1693535022"><em>Crveni krst</em></a> station where buses 21 and 83 stop, as well as trolleybuses 19, 22 and 29.</p>

        <h2>Program schedule</h2>

        <p>The goal of the gathering is to help interested install the Linux operating system on laptops. Several people with working Linux experience will be present at the event. In addition, depending on the interest of those present, short trainings related to the command line, git, web services, C programming, etc. can be held.</p>

        <p>After 9 p.m., we can continue socializing in one of the nearby bars.</p>

        <h2>Linux distributions</h2>

        <p>Linux is the core of the operating system, on which other programs are installed. All of these together make up a particular <em>Linux distribution</em>. There are many distributions, but we recommend the ones with a long tradition like the following:
        </p>

        <ul>
            <li><strong>The Debian</strong> distribution is probably the most suitable for Linux beginners. Known derivatives of Debian are Ubuntu, Mint and Zorin.</li>
            <li><strong>Fedora</strong> is also suitable for Linux beginners. It differs from the Debian distribution by the faster release of new versions, which in practice means that users have newer versions of the program.</li>
            <li><strong>Arch</strong> is a Linux distribution that allows the user to easily configure all parts of the system. This distribution is intended for people with significant Linux experience.</li>
        </ul>

        <p>If you are a beginner and haven't decided which distribution you want to install, we recommend Fedora or Debian. Regardless of which distribution you have, you will be able to run all programs intended for Linux.</p>

        <h2>End of 10</h2>

        <p>This year's Linux Install Fest is organized as part of the global <a href="https://endof10.org/">End of 10</a>
            campaign, which promotes the Linux operating system as a replacement for Windows 10.</p>

        <p>For a long time now, the Windows operating system has become increasingly unfriendly to users. On the contrary, many Linux distributions have improved the user experience to the maximum, and today we can claim that Linux enables significantly more pleasant work, regardless of the user's technical knowledge.</p>

        <p>Windows imposes on users functionalities that users do not want to use, such as: cloud integrations, AI, advertisements, mandatory accounts, and the like. These functionalities serve above all to increase Microsoft's profits, and have no benefit for most end users. Also, basic programs such as calendars, calculators or text editors have become slow and full of bugs. With useless functionalities, Windows becomes more demanding every year and requires the purchase of better hardware, leading to an increase in electronic waste. Unlike Windows, the latest Linux distributions work very well on computers that are more than a decade old.</p>

        <p>The choice of an operating system is no longer just a technical decision, but also an environmental attitude.</p>

        <h2>Installation methods</h2>

        <p>We can install Linux in three ways:</p>

        <ol>
            <li><strong>Inside a virtual machine on Windows.</strong> In this way, the user retains his existing operating system and the data on it. Linux in a virtual machine will be significantly slower than an installation without virtualization.
            </li>
            <li><strong>In addition to the existing operating system.</strong> If it is possible to shrink one of your partitions and free up at least 10GB of space, you can install a Linux operating system in addition to Windows. When booting the computer, the user will be able to choose whether to boot Windows or Linux. With such an installation, there is a certain risk that one of the subsequent Windows updates will reset the bootloader settings, after which a small intervention is required to make the Linux system accessible again.</li>
            <li><strong>By completely removing the Windows system.</strong> In place of the Windows partition, a new partition with the Linux distribution will be placed. Additional partitions that exist may or may not be removed.</li>
        </ol>

        <h2>Before arrival</h2>

        <p>In order for the installation to be effective, before coming to the Linux Instal Fest, it is necessary to make a backup of the data from the system partition if you decide on the second or third installation option. If you have two partitions (for example, C and D), move the data from the system partition (C:) that you want to keep to the non-system partition (D:). If you don't have an additional partition, you can use a USB flash drive. Pay attention to the files inside the user directory (Desktop, Downloads, Documents,... ), and export bookmarks and passwords from the browser.</p>

        <p>Also, before your arrival, you can familiarize yourself with the appearance and way of functioning of various Linux distributions. You can try some Linux distributions through the browser, without any installation, on the
        <a href="https://distrosea.com/">DistroSea</a> website (sometimes it is necessary to wait a short time to free up resources on the site). Please note that the operating system on this site is many times slower than the system installed on your computer.
        </p>

        <h2>Organizer</h2>

        <p>The organizer of the event is <a href="https://dmz.rs/en/">Decentrala</a> - a group of enthusiasts gathered around the ideas of decentralization and free dissemination of knowledge. So far, we have organized more than <a href="https://dmz.rs/en/events_archive">300 events</a>, and we regularly announce the next events on the <a href="https://dmz.rs/en/events">Events</a> page.
        </p>

        <p>In the following period, two more events for Linux beginners will be held at the same location (classroom JAG3):</p>
        <ul>
            <li><strong>Tuesday December 16</strong> -  Introduction to the Linux command line</li>
            <li><strong>Tuesday, December 23</strong> - Introduction to Git</li>
        </ul>
        <p>Events start at 6pm.</p>

        <h2>Ponovo</h2>
        <p>You can bring defective devices to the Linux install fest: laptops, phones, desktop computers, monitors... We will deliver them to the organization <a href="https://ponovo.rs/">Ponovo</a> in Kikinda during January. This organization will repair these devices and thereby prevent the increase of electronic waste.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Schizophrenia sufferer mistakes smart fridge ad for psychotic episode (375 pts)]]></title>
            <link>https://old.reddit.com/r/LegalAdviceUK/comments/1pc7999/my_schizophrenic_sister_hospitalised_herself/</link>
            <guid>46171425</guid>
            <pubDate>Sat, 06 Dec 2025 07:31:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/LegalAdviceUK/comments/1pc7999/my_schizophrenic_sister_hospitalised_herself/">https://old.reddit.com/r/LegalAdviceUK/comments/1pc7999/my_schizophrenic_sister_hospitalised_herself/</a>, See on <a href="https://news.ycombinator.com/item?id=46171425">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Need some advice. She's not really capable of organising most of her own affairs.</p>

<p>She spent 2 days under monitoring. This isn't the first time she's been kept in as she has had previous psychotic episodes once every two years or so.</p>

<p>During this time her medications were adjusted.</p>

<p>She also rang me during this time to tell me that "someone was trying to communicate with her through her fridge." She booked a taxi to A&amp;E and was driven there.</p>

<p>I've finally got her back home a few days ago. However, when I was scrolling on Facebook today I saw an advert on a smart fridge which stated the words, "WE'RE SORRY WE UPSET YOU, CAROL." It was set against a creepy yellow background and was very ominous. Upon closer inspection it was an advert for some TV show.</p>

<p>That's my sister's name. Carol. I sent her the photo and asked if this was what she saw. She confirmed it.</p>

<p>Some creepy advert in a place where an advert shouldn't usually go has sent her to the bloody hospital and triggered a review of the efficiacy of her antipyshotics.</p>

<p>Is this even legal in the UK? Running creepy adverts like that on a smart fridge with absolutely no way of knowing who could've seen them?</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wolfram Compute Services (205 pts)]]></title>
            <link>https://writings.stephenwolfram.com/2025/12/instant-supercompute-launching-wolfram-compute-services/</link>
            <guid>46171394</guid>
            <pubDate>Sat, 06 Dec 2025 07:21:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://writings.stephenwolfram.com/2025/12/instant-supercompute-launching-wolfram-compute-services/">https://writings.stephenwolfram.com/2025/12/instant-supercompute-launching-wolfram-compute-services/</a>, See on <a href="https://news.ycombinator.com/item?id=46171394">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p><img title="Instant Supercompute: Launching Wolfram Compute Services" src="https://content.wolfram.com/sites/43/2025/11/sw11252025heroimg1.png" alt="Instant Supercompute: Launching Wolfram Compute Services" width="620" height="540"></p>
<div id="gpt-stripe">
<p>To immediately enable Wolfram Compute Services in Version 14.3 Wolfram Desktop systems, run</p>
<div data-c2c-file="https://content.wolfram.com/sites/43/2025/12/sw12022025banner-2img1_copy.txt" data-c2c-type="text/html" id="writtings-c2c_above"><tt>RemoteBatchSubmissionEnvironment["WolframBatch"]</tt><p>.</p></div>
<p>(The functionality is automatically available in the <a href="https://www.wolfram.com/cloud/">Wolfram Cloud</a>.)</p>
</div>
<h2 id="scaling-up-your-computations">Scaling Up Your Computations</h2>
<p>Let’s say you’ve done a computation in <a href="https://www.wolfram.com/language/">Wolfram Language</a>. And now you want to scale it up. Maybe 1000x or more. Well, <a href="https://www.wolfram.com/compute-services/">today we’ve released</a> an extremely streamlined way to do that. Just wrap the scaled up computation in <tt><a href="http://reference.wolfram.com/language/ref/RemoteBatchSubmit.html">RemoteBatchSubmit</a></tt> and off it’ll go to our new <a href="https://www.wolfram.com/compute-services/">Wolfram Compute Services system</a>. Then—in a minute, an hour, a day, or whatever—it’ll let you know it’s finished, and you can get its results.</p>
<p>For decades I’ve often needed to do big, crunchy calculations (<a href="https://writings.stephenwolfram.com/all-by-date/">usually for science</a>). With large volumes of data, millions of cases, rampant <a href="https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility">computational irreducibility</a>, etc. I probably have more compute lying around my house than most people—these days about 200 cores worth. But many nights I’ll leave all of that compute running, all night—and I still want much more. Well, as of today, there’s an easy solution—for everyone: just seamlessly send your computation off to Wolfram Compute Services to be done, at basically any scale.</p>
<p>For nearly 20 years we’ve had built-in functions like <tt><a href="http://reference.wolfram.com/language/ref/ParallelMap.html">ParallelMap</a></tt> and <tt><a href="http://reference.wolfram.com/language/ref/ParallelTable.html">ParallelTable</a></tt> in Wolfram Language that make it immediate to parallelize subcomputations. But for this to really let you scale up, you have to have the compute. Which now—thanks to our new Wolfram Compute Services—everyone can immediately get.<span id="more-71678"></span></p>
<p>The <a href="https://reference.wolfram.com/language/guide/RemoteBatchJobs.html">underlying tools</a> that make Wolfram Compute Services possible have existed in the Wolfram Language for several years. But what Wolfram Compute Services now does is to pull everything together to provide an extremely streamlined all-in-one experience. For example, let’s say you’re working in a notebook and building up a computation. And finally you give the input that you want to scale up. Typically that input will have lots of dependencies on earlier parts of your computation. But you don’t have to worry about any of that. Just take the input you want to scale up, and feed it to <tt>RemoteBatchSubmit</tt>. Wolfram Compute Services will automatically take care of all the dependencies, etc. </p>
<p>And another thing: <tt>RemoteBatchSubmit</tt>, like every function in Wolfram Language, is dealing with symbolic expressions, which can represent anything—from numerical tables to images to graphs to user interfaces to videos, etc. So that means that the results you get can immediately be used, say in your Wolfram Notebook, without any importing, etc.</p>
<p>OK, so what kinds of machines can you run on? Well, Wolfram Compute Services gives you a <a href="https://www.wolfram.com/compute-services/#machine-instance-categories">bunch of options</a>, suitable for different computations, and different budgets. There’s the most basic 1 core, 8 GB option—which you can use to just “get a computation off your own machine”. You can pick a machine with larger memory—currently up to about 1500 GB. Or you can pick a machine with more cores—currently up to 192. But if you’re looking for even larger scale parallelism Wolfram Compute Services can deal with that too. Because <tt><a href="http://reference.wolfram.com/language/ref/RemoteBatchMapSubmit.html">RemoteBatchMapSubmit</a></tt> can map a function across any number of elements, running on any number of cores, across multiple machines. </p>
<h2 id="a-simple-example">A Simple Example</h2>
<p>OK, so here’s a very simple example—that happens to come from <a href="https://writings.stephenwolfram.com/2023/11/aggregation-and-tiling-as-multicomputational-processes/#polygonal-shapes">some science I did a little while ago</a>. Define a function <tt>PentagonTiling</tt> that randomly adds nonoverlapping pentagons to a cluster:</p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg1.png" alt="" title="" width="407" height="74"> </p>

<p>For 20 pentagons I can run this quickly on my machine:</p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg2.png" alt="" title="" width="205" height="153"> </p>

<p>But what about for 500 pentagons? Well, the computational geometry gets difficult and it would take long enough that I wouldn’t want to tie up my own machine doing it. But now there’s another option: use Wolfram Compute Services!</p>
<p>And all I have to do is feed my computation to <tt>RemoteBatchSubmit</tt>:</p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg3.png" alt="" title="" width="600" height="108"> </p>

<p>Immediately, a job is created (with all necessary dependencies automatically handled). And the job is queued for execution. And then, a couple of minutes later, I get an email: </p>
<p><img src="https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg4.png" alt="Email confirming batch job is starting" title="Email confirming batch job is starting" width="360" height="287"></p>
<p>Not knowing how long it’s going to take, I go off and do something else. But a while later, I’m curious to check how my job is doing. So I click the link in the email and it takes me to a dashboard—and I can see that my job is successfully running:</p>
<p><img src="https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg5.png" alt="Wolfram Compute Services dashboard" title="Wolfram Compute Services dashboard" width="619" height="295"></p>
<p>I go off and do other things. Then, suddenly, I get an email:</p>
<p><img src="https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg6.png" alt="Email confirming batch job success" title="Email confirming batch job success" width="611" height="657"></p>
<p>It finished! And in the mail is a preview of the result. To get the result as an expression in a Wolfram Language session I just evaluate a line from the email: </p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg7.png" alt="" title="" width="673" height="380"> </p>

<p>And this is now a computable object that I can work with, say computing areas</p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg8.png" alt="" title="" width="322" height="43"> </p>

<p>or counting holes:</p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025simpleimg9.png" alt="" title="" width="293" height="93"> </p>

<h2 id="large-scale-parallelism">Large-Scale Parallelism</h2>
<p>One of the great strengths of Wolfram Compute Services is that it makes it easy to use large-scale parallelism. You want to run your computation in parallel on hundreds of cores? Well, just use Wolfram Compute Services! </p>
<p>Here’s an example that came up in some recent work of mine. I’m searching for a cellular automaton rule that generates a pattern with a “lifetime” of exactly 100 steps. Here I’m testing 10,000 random rules—which takes a couple of seconds, and doesn’t find anything:</p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg1.png" alt="" title="" width="516" height="91"> </p>

<p>To test 100,000 rules I can use <tt><a href="http://reference.wolfram.com/language/ref/ParallelSelect.html">ParallelSelect</a></tt> and run in parallel, say across the 16 cores in my laptop:</p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg2.png" alt="" title="" width="516" height="91"> </p>

<p>Still nothing. OK, so what about testing 100 million rules? Well, then it’s time for Wolfram Compute Services. The simplest thing to do is just to submit a job requesting a machine with lots of cores (here 192, the maximum currently offered): </p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg3.png" alt="" title="" width="660" height="179"> </p>

<p>A few minutes later I get mail telling me the job is starting. After a while I check on my job and it’s still running:</p>
<p><img src="https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg4.png" alt="Email confirming batch job is starting" title="Email confirming batch job is starting" width="360" height="287"></p>
<p>I go off and do other things. Then, after a couple of hours I get mail telling me my job is finished. And there’s a preview in the email that shows, yes, it found some things:</p>
<p><img src="https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg5.png" alt="Email confirming batch job success" title="Email confirming batch job success" width="360" height="461"></p>
<p>I get the result:</p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg6.png" alt="" title="" width="684" height="115"> </p>

<p>And here they are—rules plucked from the hundred million tests we did in the computational universe:</p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg7.png" alt="" title="" width="518" height="244"> </p>

<p>But what if we wanted to get this result in less than a couple of hours? Well, then we’d need even more parallelism. And, actually, Wolfram Compute Services lets us get that too—using <tt>RemoteBatchMapSubmit</tt>. You can think of <tt>RemoteBatchMapSubmit</tt> as a souped up analog of <tt>ParallelMap</tt>—mapping a function across a list of any length, splitting up the necessary computations across cores that can be on different machines, and handling the data and communications involved in a scalable way. </p>
<p>Because <tt>RemoteBatchMapSubmit</tt> is a “pure <tt><a href="http://reference.wolfram.com/language/ref/Map.html">Map</a></tt>” we have to rearrange our computation a little—making it run 100,000 cases of selecting from 1000 random instances:</p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg8.png" alt="" title="" width="630" height="219"> </p>

<p>The system decided to distribute my 100,000 cases across 316 separate “child jobs”, here each running on its own core. How is the job doing? I can get a dynamic visualization of what’s happening:</p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg9.png" alt="" title="" width="359" height="225"> </p>

<p>And it doesn’t take many minutes before I’m getting mail that the job is finished:</p>
<p><img src="https://content.wolfram.com/sites/43/2025/11/sw11252025largeimg12.png" alt="Email providing job details" title="Email providing job details" width="454" height="430"></p>
<p>And, yes, even though I only had to wait for 3 minutes to get this result, the total amount of computer time used—across all the cores—is about 8 hours. </p>
<p>Now I can retrieve all the results, using <tt><a href="http://reference.wolfram.com/language/ref/Catenate.html">Catenate</a></tt> to combine all the separate pieces I generated:</p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025large-aimg1.png" alt="" title="" width="503" height="267"> </p>

<p>And, yes, if I wanted to spend a little more, I could run a bigger search, increasing the 100,000 to a larger number; <tt>RemoteBatchMapSubmit</tt> and Wolfram Compute Services would seamlessly scale up.</p>
<h2 id="its-all-programmable">It’s All Programmable!</h2>
<p>Like everything around Wolfram Language, Wolfram Compute Services is fully programmable. When you submit a job, there are lots of options you can set. We already saw the option <tt><a href="https://reference.wolfram.com/language/ref/RemoteMachineClass.html">RemoteMachineClass</a></tt> which lets you choose the type of machine to use. Currently the choices range from <tt>"</tt><span>Basic1x8</span><tt>"</tt> (1 core, 8 GB) through <tt>"</tt><span>Basic4x16</span><tt>"</tt> (4 cores, 16 GB) to “parallel compute” <tt>"</tt><span>Compute192x384</span><tt>"</tt> (192 cores, 384 GB) and “large memory” <tt>"</tt><span>Memory192x1536</span><tt>"</tt> (192 cores, 1536 GB).</p>
<p>Different classes of machine cost different numbers of credits to run. And to make sure things don’t go out of control, you can set the options <tt><a href="http://reference.wolfram.com/language/ref/TimeConstraint.html">TimeConstraint</a></tt> (maximum time in seconds) and <tt><a href="https://reference.wolframcloud.com/language/ref/CreditConstraint.html">CreditConstraint</a></tt> (maximum number of credits to use). </p>
<p>Then there’s notification. The default is to send one email when the job is starting, and one when it’s finished. There’s an option <tt><a href="https://reference.wolfram.com/language/ref/RemoteJobName.html">RemoteJobName</a></tt> that lets you give a name to each job, so you can more easily tell which job a particular piece of email is about, or where the job is on the web dashboard. (If you don’t give a name to a job, it’ll be referred to by the UUID it’s been assigned.)</p>
<p>The option <tt><a href="https://reference.wolfram.com/language/ref/RemoteJobNotifications.html">RemoteJobNotifications</a></tt> lets you say what notifications you want, and how you want to receive them. There can be notifications whenever the status of a job changes, or at specific time intervals, or when specific numbers of credits have been used. You can get notifications either by email, or by text message. And, yes, if you get notified that your job is going to run out of credits, you can always go to the <a href="https://account.wolfram.com/login/oauth2/sign-in" target="_blank" rel="noopener">Wolfram Account portal</a> to top up your credits.</p>
<p>There are many properties of jobs that you can query. A central one is <tt>"EvaluationResult"</tt>. But, for example, <tt>"<a href="http://reference.wolfram.com/language/ref/EvaluationData.html">EvaluationData</a>"</tt> gives you a whole association of related information:</p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025programmableimg1.png" alt="" title="" width="657" height="221"> </p>

<p>If your job succeeds, it’s pretty likely <tt>"EvaluationResult"</tt> will be all you need. But if something goes wrong, you can easily drill down to study the details of what happened with the job, for example by looking at <tt>"JobLogTabular"</tt>.</p>
<p>If you want to know all the jobs you’ve initiated, you can always look at the web dashboard, but you can also get symbolic representations of the jobs from: </p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025programmableimg3-a.png" alt="" title="" width="547" height="214"> </p>

<p>For any of these job objects, you can ask for properties, and you can for example also apply <tt><a href="https://reference.wolfram.com/language/ref/RemoteBatchJobAbort.html">RemoteBatchJobAbort</a></tt> to abort them.</p>
<p>Once a job has completed, its result will be stored in Wolfram Compute Services—but only for a limited time (currently two weeks). Of course, once you’ve got the result, it’s very easy to store it permanently, for example, by putting it into the Wolfram Cloud using <tt><a href="https://reference.wolfram.com/language/ref/CloudPut.html">CloudPut</a></tt>[<i>expr</i>]. (If you know you’re going to want to store the result permanently, you can also do the <tt>CloudPut</tt> right inside your <tt>RemoteBatchSubmit</tt>.) </p>
<p>Talking about programmatic uses of Wolfram Compute Services, here’s another example: let’s say you want to generate a compute-intensive report once a week. Well, then you can put together several very high-level Wolfram Language functions to deploy a scheduled task that will run in the Wolfram Cloud to initiate jobs for Wolfram Compute Services:</p>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/11/sw11252025programmableimg4.png" alt="" title="" width="485" height="14"> </p>

<p>And, yes, you can initiate a Wolfram Compute Services job from any Wolfram Language system, whether on the desktop or in the cloud. </p>
<h2 id="and-theres-more-coming">And There’s More Coming…</h2>
<p>Wolfram Compute Services is going to be very useful to many people. But actually it’s just part of a much larger constellation of capabilities aimed at broadening the ways Wolfram Language can be used.</p>
<p>Mathematica and the Wolfram Language <a href="https://www.wolfram.com/mathematica/scrapbook/">started—back in 1988</a>—as desktop systems. But even at the very beginning, there was a capability to run the notebook front end on one machine, and then have a “<a href="https://reference.wolfram.com/language/howto/ConnectToARemoteKernel.html">remote kernel</a>” on another machine. (In those days we supported, among other things, communication via phone line!) In 2008 we introduced built-in parallel computation capabilities like <tt>ParallelMap</tt> and <tt>ParallelTable</tt>. Then in 2014 we introduced the <a href="https://www.wolframcloud.com/">Wolfram Cloud</a>—both replicating the core functionality of <a href="https://www.wolfram.com/notebooks/">Wolfram Notebooks</a> on the web, and providing services such as <a href="https://reference.wolfram.com/language/guide/CreatingAnInstantAPI.html">instant APIs</a> and <a href="https://reference.wolfram.com/language/ref/ScheduledTask.html">scheduled tasks</a>. Soon thereafter, we introduced the <a href="https://www.wolfram.com/enterprise-private-cloud/">Enterprise Private Cloud</a>—a private version of Wolfram Cloud. In 2021 we introduced <a href="https://www.wolfram.com/application-server/">Wolfram Application Server</a> to deliver high-performance APIs (and it’s what we now use, for example, for <a href="https://www.wolframalpha.com/">Wolfram|Alpha</a>). Along the way, in 2019, we introduced <a href="https://www.wolfram.com/engine/">Wolfram Engine</a> as a streamlined server and command-line deployment of Wolfram Language. Around Wolfram Engine we built <a href="https://www.wolfram.com/wstpserver/">WSTPServer</a> to serve Wolfram Engine capabilities on local networks, and we introduced <a href="https://www.wolfram.com/wolframscript/">WolframScript</a> to provide a deployment-agnostic way to run command-line-style Wolfram Language code. In <a href="https://writings.stephenwolfram.com/2020/12/launching-version-12-2-of-wolfram-language-mathematica-228-new-functions-and-much-more/#big-computations-send-them-to-a-cloud-provider">2020 we then introduced</a> the first version of <tt>RemoteBatchSubmit</tt>, to be used with cloud services such as <a href="https://reference.wolfram.com/language/ref/batchcomputationprovider/AWSBatch.html">AWS</a> and <a href="https://reference.wolfram.com/language/ref/batchcomputationprovider/AzureBatch.html">Azure</a>. But unlike with Wolfram Compute Services, this required <a href="https://reference.wolfram.com/language/workflow/SetUpTheAWSBatchComputationProvider.html">“do it yourself” provisioning</a> and licensing with the cloud services. And, finally, now, that’s what we’ve automated in Wolfram Compute Services.</p>
<p>OK, so what’s next? An important direction is the forthcoming Wolfram HPCKit—for organizations with their own large-scale compute facilities to set up their own back ends to <tt>RemoteBatchSubmit</tt>, etc. <tt>RemoteBatchSubmit</tt> is built in a very general way, that allows different “<a href="https://reference.wolfram.com/language/guide/RemoteBatchJobs.html#179238631">batch computation providers</a>” to be plugged in. Wolfram Compute Services is initially set up to support just one standard batch computation provider: <tt>"WolframBatch"</tt>. HPCKit will allow organizations to configure their own compute facilities (often with our help) to serve as batch computation providers, extending the streamlined experience of Wolfram Compute Services to on-premise or organizational compute facilities, and automating what is often a rather fiddly job process of submission (which, I must say, personally reminds me a lot of the mainframe job control systems I used in the 1970s). </p>
<p>Wolfram Compute Services is currently set up purely as a batch computation environment. But within the Wolfram System, we have the capability to support synchronous remote computation, and we’re planning to extend Wolfram Compute Services to offer this—allowing one, for example, to seamlessly run a remote kernel on a large or exotic remote machine. </p>
<p>But this is for the future. Today we’re launching the first version of Wolfram Compute Services. Which makes “supercomputer power” immediately available for any Wolfram Language computation. I think it’s going to be very useful to a broad range of users of Wolfram Language. I know I’m going to be using it a lot.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PalmOS on FisherPrice Pixter Toy (156 pts)]]></title>
            <link>https://dmitry.gr/?r=05.Projects&amp;proj=27.%20rePalm#pixter</link>
            <guid>46170309</guid>
            <pubDate>Sat, 06 Dec 2025 03:17:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dmitry.gr/?r=05.Projects&#x26;proj=27.%20rePalm#pixter">https://dmitry.gr/?r=05.Projects&#x26;proj=27.%20rePalm#pixter</a>, See on <a href="https://news.ycombinator.com/item?id=46170309">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>




<p><span>rePalm</span>
<a href="https://photos.app.goo.gl/ubrrKSnMi0UoKEa03">Photo Album</a>(constantly updated)
</p><h2>Table of Contents</h2>
<ol type="1"><li><a href="#_TOC_d6004cc94a9c0596eceb597fffab171b">Blog-style updates</a><ol type="a"><li><a href="#_TOC_105d081c20da41387dcb640d7844e380">BLOG</a></li><li><a href="#_TOC_663662b91f36a398f3dd1022569cb7e1">Dec 5, 2025 - Pixter</a><ol type="I"><li><a href="#_TOC_317c392cf501b6b4320a3115280d293e">Getting started with Pixter</a></li><li><a href="#_TOC_ccf13f871bff4d85711b6c2982adaca7">Initial Slow Pixter Color Bringup</a></li><li><a href="#_TOC_a23bcb0f34045da3628fbb9c63dc9cd8">The Worst ARM SoC I've Seen Yet</a></li><li><a href="#_TOC_32a452a8a1d23aa3378b2fa796f23911">Pixter Memories</a></li><li><a href="#_TOC_c6090cdcd19a87ac82f0678f94ca5682">Pixter Displays</a></li><li><a href="#_TOC_15afaf19e9f1c29c9df05efc98623567">Making Pixter IrDA work</a></li><li><a href="#_TOC_6aaa83ffbda119675aa2b1a85d121186">Getting and Flashing the Pixter Carts</a></li><li><a href="#_TOC_81c94ecd14afaae13888291ae522ac30">Pixter Polish</a></li><li><a href="#_TOC_a23619cfc40ca570c4e32829136a083b">Battery State</a></li><li><a href="#_TOC_41361f59557a0b66300dbfbb53bf5e60">ARM7 quirks</a><ol type="A"><li><a href="#_TOC_55d2a6f8599932d97309a32336a88e3b">What exactly does ARM7 do with PC[1] in ARM mode?</a></li></ol></li><li><a href="#_TOC_a068d6e9b5f120e3dbc023accff99cfa">Pixter Multimedia</a></li><li><a href="#_TOC_d02db4cca336224e352d18884fb87bbf">Some More Pixter Polish</a></li><li><a href="#_TOC_db89a79a972ee06eda00fd6ec56af499">Pixter Results</a></li></ol></li><li><a href="#_TOC_4cf9ff9167b06c4f8aa708bac38bebd4">Nov 2, 2025 - summary of what you missed</a></li></ol></li><li><a href="#_TOC_4c49906dca074ffeea2a31a3da78a946">The original article about the start of the project</a><ol type="a"><li><a href="#_TOC_c38a777301478b17b8065df633c16073">PalmOS Architecture (and a bit of history)</a><ol type="I"><li><a href="#_TOC_16d2b386b2034b9488996466aaae0b57">History</a></li><li><a href="#_TOC_fe46700337bda9932cad30ebb5092816">Modules? Libraries? DALs? Drivers?</a></li></ol></li><li><a href="#_TOC_244123db096496b6518454bdcd8d458a">Towards the first unauthorized PalmOS port</a><ol type="I"><li><a href="#_TOC_7690ee3e298ae7406f138709ec026dce">So what's so hard?</a></li><li><a href="#_TOC_274e47df117091e2557aef0ecc391316">ROM formats are hard</a></li><li><a href="#_TOC_19186ee232b2454827d3f2865b5f6e69">So write a DAL and you're done!</a></li><li><a href="#_TOC_49caf94f20bd2e5f2db1081947789a60">Minimal DAL</a></li><li><a href="#_TOC_ef4090e17154674f80d64ad2111ea396">Drawing is hard</a></li><li><a href="#_TOC_b5690009716e72d140983f70b9681f50">Theft is a form of flattery, right?</a></li><li><a href="#_TOC_d6b64b427e5aaef1676407293aca6f38">Meticulously-performed imitation is also a form of flattery, no?</a></li><li><a href="#_TOC_353f99c16369230cb5399b32ba50446a">Virtual SD card</a></li><li><a href="#_TOC_353a28e51ebccb5135d5ba38c4d440e5">Which device ROM are you using?</a></li><li><a href="#_TOC_7af9e60baebf45eba73fb5a032144d71">So you're done, right? It works?</a></li></ol></li><li><a href="#_TOC_b8af925e2e0ccf5d333ef97c97cfa358">Towards the first pirate PalmOS device</a><ol type="I"><li><a href="#_TOC_f678de22decd6176f0c5a83b196ea618">A little bit about normal PalmOS 5.x devices, their CPUs, and the progress since...</a></li><li><a href="#_TOC_fa633dde76a9d5962249bd20bd69ed1d">ARMv7M</a></li><li><a href="#_TOC_a6683a2f1a734ad2e0c8266c58d6814c">My kingdom for an ARM!</a></li><li><a href="#_TOC_1576edec6568c60734a8c8f578946c2a">But what if we try?</a></li></ol></li><li><a href="#_TOC_0be92df30c61e06c706246f9f35b14fe">We need hardware, but developing on hardware is ... hard</a><ol type="I"><li><a href="#_TOC_1866711c0f60ccdc92f2b71753fadf1f">CortexEmu to the rescue</a></li><li><a href="#_TOC_fb27a2d36a554d080bd29f19319dd4ba">Waaaah! You promised real hardware</a></li></ol></li><li><a href="#_TOC_afaee39943998caadf5b45eb09ca52ff">Um, but now we need a kernel...</a><ol type="I"><li><a href="#_TOC_f4ed5002aeb6070729ce9b6df22517aa">Need a kernel? Why not Linux?</a></li></ol></li><li><a href="#_TOC_934bffe7eb7428a2ecd772ae407ba2bd">So, uh, what about all that pesky ARM code?</a><ol type="I"><li><a href="#_TOC_99433f6c0ccf629e79759495dd2a3895">The ARM code still was a problem</a></li><li><a href="#_TOC_321e6b87e6ca9bede1defae0487f6d3b">You do not mean...?</a></li><li><a href="#_TOC_811139ec6ba0b492d7e119279ce3fe81">But isn't writing an emulator in C kind of slow?</a></li><li><a href="#_TOC_7da84df7c7794732114e4f17174e44ae">So, is it fast enough now?</a></li></ol></li><li><a href="#_TOC_6157fbbda2d6ba3e17ac7f1d2dcb03bb">You do not mean...? (pt2)</a><ol type="I"><li><a href="#_TOC_3204170ab6cefc87ff0b9e8bbf15e3c3">Just in time: this</a></li><li><a href="#_TOC_6c1e3d4f3650586ef87c08dcb6a56032">JITs: how do we start?</a></li><li><a href="#_TOC_317e071be8e7e97a898025ca4f5d6a2d">Parlez-vous ARM?</a></li><li><a href="#_TOC_0bc5b46b49b772d9f98167f3d38c57cd">2 Thumbs do not make an ARM</a></li></ol></li><li><a href="#_TOC_7d2bad5e5df9b51e6561930af5281c4b">A JIT's job is never over</a><ol type="I"><li><a href="#_TOC_0bf44f2f0483b69f4f788aa7476bcfdf">LDM and STM, may they burn in hell forever!</a><ol type="A"><li><a href="#_TOC_154e4d4907e66b0615bf614b8b04b3f2">How LDM/STM work in ARM</a></li><li><a href="#_TOC_8bbe9e91149d059ee85d3694c813b8e7">How LDM/STM work in Thumb2</a></li><li><a href="#_TOC_e850194f609729b7a92dc19d57efffce">But wait, there's more ... pain</a></li><li><a href="#_TOC_6dae46dec6458f7e262d1dde02676949">Translating LDM/STM</a></li></ol></li><li><a href="#_TOC_1db9dab871ed72bf21793712aaa1571a">Slightly less hellish instructions</a></li><li><a href="#_TOC_0b703df619f55a061fa3080cd285e905">Conditional instructions</a></li><li><a href="#_TOC_12a7cbf0d95e0874700a526b0c606f24">Jumps &amp; Calls</a></li><li><a href="#_TOC_1845170175d6cd3ee7a45bcdcf60a99d">Translating a TU</a></li><li><a href="#_TOC_d8be03a7734ce336e0e95c12bed0d3d7">And if the TC is full?</a></li><li><a href="#_TOC_86491a45a2021ee669a55df54ecccd5d">Growing up</a></li><li><a href="#_TOC_1736a13ea992c6d293687480e5f8eba4">The Cortex-M0 backend</a><ol type="A"><li><a href="#_TOC_85e1b5d18cc909adc0ec42cefc752374">Why this is insane</a></li><li><a href="#_TOC_5f936d66726370eea0749c9a4d3cca5c">The basics</a></li><li><a href="#_TOC_3d1b169dc1c246143311667973d27191">Fault dispatching</a></li></ol></li></ol></li><li><a href="#_TOC_6edec3a664ff4b245910e38197c368f5">Is PACE fast enough?</a><ol type="I"><li><a href="#_TOC_8406e71f183218c42ea61761bec7f300">Those indirect jumps...</a></li><li><a href="#_TOC_eb78374ce478e8ce5e126397507be744">A special solution for a special problem</a></li><li><a href="#_TOC_53097c4149f9f99536f550859bf51298">Any 68k emulator...</a></li></ol></li><li><a href="#_TOC_04125366fb7868c0c90ac612ebd9446c">But, you promised hardware...</a><ol type="I"><li><a href="#_TOC_7dc6f1c77b85c0e75518885955ed41e3">Hardware has bugs</a></li><li><a href="#_TOC_430d6ee50c9ff1aa84546049d1a6a3aa">So why the 0x80000000 limit?</a></li><li><a href="#_TOC_d9c532a1d434bda469b4565b0fa78d0b">Two wrongs do not make a right, but do two nasty hacks?</a></li></ol></li><li><a href="#_TOC_fd61d91f4f762f98fe9d08c759298fac">Tales of more PalmOS reverse engineering</a><ol type="I"><li><a href="#_TOC_70c487f74203eb4f8470c3c652adec8e">SD-card Support</a></li><li><a href="#_TOC_0745eb1e96d7eecb7dca979ac0c5641d">Serial Port Support</a><ol type="A"><li><a href="#_TOC_f0938d2fb6ec341fc50c3cc32a68cf79">Yes, you can try it!</a></li></ol></li><li><a href="#_TOC_ca36ea3a859782b7e0e5a14e7999a0d2">Vibrate &amp; LED support</a></li><li><a href="#_TOC_09dd8d91380adf4a8376b97b0dbe8cbd">Networking support (WIP)</a><ol type="A"><li><a href="#_TOC_3a225f6b197aff0014031e11feafd006">False starts</a></li><li><a href="#_TOC_70f2cfa9e150ffd5e72c9dfa0b6a2e35">The scary way forward</a></li><li><a href="#_TOC_7cb40e1cb574360af15a7a7bfcab368a">Those who study history...</a></li><li><a href="#_TOC_4310dcbc6aabcc166c70891f443152b8">On to OS 5's Net.lib</a></li><li><a href="#_TOC_0f72c0cb93852eff2102a38c6867c3b0">I found a bug!</a></li><li><a href="#_TOC_0cedc678c13085bef12438ec8e144a5a">Well, that was easy...</a></li><li><a href="#_TOC_0ed61b57f60d1619623ad9529ec24522">NOT!</a></li><li><a href="#_TOC_b7ea5704d8c610fefee98b6e893f4285">More reverse engineering</a></li></ol></li><li><a href="#_TOC_0e86ad5bf27c5b7db90e96d69a6a20f1">1.5 density support</a><ol type="A"><li><a href="#_TOC_1dd41736817f8594b13c015f5d675061">Density basics</a></li><li><a href="#_TOC_3888d6ea493b8540d9b222eda870a34b">How does it all fall apart?</a></li><li><a href="#_TOC_6dc1fcfd40eac977ca8de78c302e161a">How do we fix it?</a></li><li><a href="#_TOC_81e1dca6c4086b8ca08fdd313aab38ef">And now, for some polish</a></li></ol></li><li><a href="#_TOC_fb8dffd581e4c5c2fb3a602c9968dfa1">Dynamic Input Area/Pen Input Manager Services support</a><ol type="A"><li><a href="#_TOC_55c4ffa0cef8df0ca7dada39de0c7edc">DIA/PINS basics</a></li><li><a href="#_TOC_f972738a6fc57f587b6b8217a3a8c3ff">How it works pre-garnet</a></li><li><a href="#_TOC_7a4af6319253fe4958ef467593058a76">The intricacies of writing a DIA implementation</a></li></ol></li><li><a href="#_TOC_9452c577c360e42af5e333b94545a583">Audio support</a><ol type="A"><li><a href="#_TOC_401cba25ab569a340588aba30df19598">PalmOS Audio basics</a></li><li><a href="#_TOC_7e67a64aa2db4bac832171b0201d5059">PalmOS sampled sudio support</a></li><li><a href="#_TOC_e29e5b41fd7910dd365d892a74032818">Why audio is hard &amp; how PalmOS makes it easy</a></li><li><a href="#_TOC_141eb8494d23c01acb07946b8dfae14d">How rePalm does audio mixing</a></li><li><a href="#_TOC_a6ab4fb079f26742eb2b15a40f8c415e">How do assembly and audio mix?</a></li><li><a href="#_TOC_c9a3edc13d1d9b624900782475cb37d0">rePalm's audio hw driver architecture</a></li><li><a href="#_TOC_2cc9187af12cfb288552a94945e2576f">Microphone</a></li></ol></li><li><a href="#_TOC_2d69b048c7fa078b50826e0bb14ef187">Zodiac support</a><ol type="A"><li><a href="#_TOC_9abd84aae09c84b126622be17538bb11">Tapwave Zodiac primer</a></li><li><a href="#_TOC_3ae834b010d019ad46839d53a26fc246">The reverse engineering</a></li><li><a href="#_TOC_488e310c3fbbea8ddc8055dce2fbd0eb">The "GPU"</a></li><li><a href="#_TOC_e5161cb0029a5c9e6b45aedc75ec628c">Other Tapwave APIs</a></li></ol></li></ol></li><li><a href="#_TOC_971499a21e41b5eede224c94b7f329cf">Real hardware: reSpring</a><ol type="I"><li><a href="#_TOC_b9dc6effb2e2905b150bdb2f7431d48b">The ultimate Springboard accessory</a></li><li><a href="#_TOC_523dfe92d22dbe6fd0c936743d86a610">Interfacing with the Visor</a></li><li><a href="#_TOC_d4b36e25c7ff304278d8f8203382ad65">Version 1</a></li><li><a href="#_TOC_140b7a05f413da05bcf245962e8ef816">Bringup of v1</a></li><li><a href="#_TOC_7d7efb1fd00e505e192d7de552b38a5c">Let's stick it into a Visor?</a><ol type="A"><li><a href="#_TOC_cc4796dbaf2dc5b25a09a60a68dce960">Getting recognized</a></li><li><a href="#_TOC_8c44784826fb6a797ca8f9ddef7f17d1">Saving valuable space</a></li><li><a href="#_TOC_cf948ca3c9fa8aa0d50b7af90489dbab">Communications</a></li><li><a href="#_TOC_a08fa204773f1401ecad0ad320f0e29f">Early Visor support</a></li></ol></li><li><a href="#_TOC_efa1a6bae85982abb5eb2f5b1cdfc635">Making it work well</a><ol type="A"><li><a href="#_TOC_60071961fe2964324372b9a5f34e819a">Initial data</a></li><li><a href="#_TOC_265eae2e494574477805623b3356ea35">Sending display data</a></li><li><a href="#_TOC_c77b699ee26bfeed9429d18ac6eaf913">Buttons, pen, brightness, contrast, and battery info</a></li><li><a href="#_TOC_eccf95f0e1bd185a785e1e8a17db8566">Microphone support</a></li></ol></li><li><a href="#_TOC_c730389bc8d99e59c867766babdd48b5">Polish</a><ol type="A"><li><a href="#_TOC_0fc38b86ec3a198dd384a33f1ba51090">Serial/IrDA</a></li><li><a href="#_TOC_b50a7cf91ffc6c447c18e7bc3e5d2ba5">Alarm LED</a></li><li><a href="#_TOC_c329847c5a9eb54120dcc6a37e7688cd">Software update</a></li></ol></li><li><a href="#_TOC_9b6a7a6a1e5e220ce79d2c1fb3055b4b">Onboard NAND</a><ol type="A"><li><a href="#_TOC_c822baa4a271b34914d0d52b7daf51fe">You wanted pain? Here's some NAND</a></li><li><a href="#_TOC_6b3b62f6a546e9fc2070dadae82f7fb6">To write an FTL...</a></li></ol></li><li><a href="#_TOC_c2a5006b48989e3cbd0a40a6c28ae0a5">One final WTF</a></li></ol></li><li><a href="#_TOC_9b23c2379c1d04a1e2c5f7bd55e5b11d">More real hardware</a><ol type="I"><li><a href="#_TOC_68d5b3fecf777afa589daf30f3003eed">rePalm-MSIO</a><ol type="A"><li><a href="#_TOC_b78ced7630516f39a9df67f8bff3fbcb">MCU selection</a></li><li><a href="#_TOC_63dbebc501303d2fbc119f39fd5fa3a9">The bugs...</a></li><li><a href="#_TOC_12902d19af5dcccb4930367282858fd6">MSIO low level</a></li><li><a href="#_TOC_b3a6a302f1a4b30ed9243ec16e09d331">MSIO high level</a></li><li><a href="#_TOC_8bef4bd1a59725a78a239166683e5005">MSIO performance</a></li><li><a href="#_TOC_0ef17952991bb23ceb3eff5d58852ff5">Other loose ends</a></li></ol></li><li><a href="#_TOC_7d49aaed1771a47099d2087b01e38be4">AximX3</a></li><li><a href="#_TOC_37411efaa3076380c4c52b43da1a7de7">STM32F469 Discovery Board</a></li><li><a href="#_TOC_0734fd58b98b17e23027547eec1258f5">RP2040</a><ol type="A"><li><a href="#_TOC_da19cdc85215569c48f1e5adbb0dcceb">It is possible!</a></li><li><a href="#_TOC_71fc1629af9b6f7f996c71b3442f6138">Memories</a></li><li><a href="#_TOC_a458b10a6c13066f378af7a655517e3f">PACE again</a></li></ol></li></ol></li><li><a href="#_TOC_8c65bb84ff7790f79c8b425f7bdc1116">So where does this leave us?</a></li><li><a href="#_TOC_4c200f344d32f6a87d65cd4615afc915">Source Code</a><ol type="I"><li><a href="#_TOC_30c25f0330c9b505cc348823769f06d6">Source intro</a></li><li><a href="#_TOC_dc2be8290c0302afb4d265bad618ed1c">Building basics</a></li><li><a href="#_TOC_0092c8837761d29c05d04f994e095d6d">Building PACE</a></li></ol></li><li><a href="#_TOC_e797f665d200ef27bdbf6f28bf3f764c">Article update history</a></li><li><a href="#_TOC_7e1e75c32bc9b275daf70df8cba8efb5">Comments...</a></li></ol></li></ol>






<h2>Blog-style updates</h2>
<h2>BLOG</h2>
<p>I have decided to change the format of this article to be more blog-like as further development is being done in parallel on many fronts and will be hard to follow if I just update the main (now-huge) article body. So what has transpired since? 
</p>

<h2>Dec 5, 2025 - Pixter</h2>
<p><a href="https://dmitry.gr/images/rePalm-PixterColorAboutScreenLarge.jpg"><img src="https://dmitry.gr/images/rePalm-PixterColorAboutScreenSmall.jpg" alt="Pixter Color showing PalmOS 5.2.1 infor panel"></a>
<a name="_TOC_317c392cf501b6b4320a3115280d293e"></a></p><h3>Getting started with Pixter</h3>
<p>Fisher-Price (owned by Mattel) produced some toys in the early 2000 under the <a href="https://en.wikipedia.org/wiki/Pixter">Pixter</a> brand. They were touchscreen-based drawing toys, with cartridge-based <a href="https://en.wikipedia.org/wiki/Pixter">extra games</a> one could plug in. Pixter devices of the first three generations ("classic", "plus", and "2.0") featured 80x80 black-and-white screens, which makes them of no interest for rePalm. The last two generations of Pixter ("color" and "multimedia") featured 160x160 color displays. Now, this was more like it! Pixter was quite popular, as far as kids' toys go, in USA in the early 2000s. A friend brought it to my attention a year ago as a potential rePalm target. The screen resolution was right and looking inside a "Pixter Color" showed an ARM SoC - a <a href="https://web.archive.org/web/20250206223428/https://www.keil.com/dd/docs/datashts/philips/lh75401_lh75411_ds.pdf">Sharp LH75411</a>. The device had sound (games made noises), and touch panel was resistive. In theory - a viable rePalm target indeed.
</p>
<p>My initial work involved figuring out how the last two generations of Pixter work and how to get code execution on them, which I <a href="https://dmitry.gr/?r=05.Projects&amp;proj=37.%20Pixter">wrote a separate article on</a> (which may not yet be publicly up -- I am but one man and editing takes time). The short of it is that the cartridge slot includes access to the full memory bus and two chip-select lines allowing one to connect two memories or memory-like things to the device. The first (seen at PA <span>0x48000000</span>) must connect to a 16-bit-wide ROM which would normally contain the game. I would put a PalmOS ROM there, of course. However, it would need to be formatted such that the Pixter boots it as a game, instead of assuming that the cartridge is invalid. Reverse engineering the Pixter ROM showed me the minimal way to make my ROM bootable. This requires a simple 44-byte header, with the following values at the following offsets: <span>u32@0x00 - 0xAA5566CC</span> (magic number), <span>u16@0x04 - 0x0001</span> (required version number), <span>u16@0x06 - 0x293c</span> (VM instruction to do a native callout to offset 0x28), <span>u32@0x10 - 0x48000006</span> (address where the first VM instr is to be seen, I use <span>0x48000006</span>), <span>u32@0x28 - 0x48??????</span> (address where Pixter OS will jump to in THUMB mode, where our actual execution will begin). I place some code before the <span>0x28</span> word to switch to ARM mode and disable interrupts, then jump to my PalmOS ROM which will start at offset <span>0x30</span> (for roundness). Thus, after this now-48-byte header, there can follow a normal PalmOS ROM. Pixter Color contains 128KB of RAM the motherboard, which is too little for PalmOS, so we'll use the second chip-select line to attach some RAM. Pixter Multimedia has 4MB of SDRAM onboard, which makes it able to run PalmOS without external RAM.
</p>
<h3>Initial Slow Pixter Color Bringup</h3>
<p>The pinout of the SoC on the Pixter Color was easy to work out since the chip is in an LQFP package and I could buzz-out the pin connections. The <a href="https://web.archive.org/web/20240719161636/https://www.keil.com/dd/docs/datashts/philips/lh754xx_um.pdf">User's Guide for Sharp LH75411</a> was available. Debugging on real hardware is hard, of course, so I wrote a Pixter Color emulator, as detailed in my <a href="https://dmitry.gr/?r=05.Projects&amp;proj=37.%20Pixter">Pixter article</a>. With this, I was able to bring up a minimal PalmOS image relatively quickly. Then, it was on to making it work on the real device. This was quite a bit more work. <a href="https://github.com/GeorgeRudolf">George</a> designed a board with a 1MB NOR flash for the OS and some RAM for PalmOS to use, and <a href="https://jlcpcb.com/">JLC</a> assembled a few for me. There were a few design decisions made during Pixter Color's design that complicated this project, unfortunately.
</p>
<p>Memories are connected to a SoC over a bus. A bus has a width, denominated in bits. For 32-bit ARM chips, external busses are usually 8, 16, or 32 bits wide. The wider the bus, the more bits can be sent over it in the same number of clocks, meaning that it is faster. Obviously, if you write a properly-aligned 32-bit word in your code, a 32-bit bus can transfer it to memory in one transfer. A 16-bit bus will need two -- one for the lower halfword, one for the higher. An 8-bit-wide bus will need 4 transfers to transfer the word, thus being 4 times slower. However, this does not mean that a narrower bus is always slower. Consider the case of writing a single byte. The 8-bit-wide bus can do this in a single transfer. What do the 16 and 32 bit busses do in this case? Guess!
</p>
<p>There are two guesses you could have come up with. The first is: read a bus-width-sized quantity of memory, modify the requisite byte, and then write a bus-width-sized quantity of memory back. This would require two bus transactions for both the 16 and the 32 bit wide busses. This is <em>not</em> what is done, for a variety of reasons which are quite out of scope here. What is actually done is that besides the access, data, and control lines, the wider busses also have a few extra lines, which are called "byte lane select" lines. They tell the memory which of the bytes in the addressed bus-width-sized memory location being addressed are active. So, to write a byte on a 32-bit-wide bus, only one of the byte lane select lines will be active, and the memory will not overwrite the other 3 bytes. This does mean that the memory chips need to support this sort of thing, and they do. Of course this is not an issue for reads - the unneeded 3 bytes of memory for a byte-sized read on a 32-bit-bus can just be ignored by the SoC. Easy!
</p>
<p>So, what were the design decisions in Pixter Color that made my life harder? Pixter Color's external cartridge slot exposes 24 bits of address and 16 bits of data. Since ROM is read-only, it needs no byte lane selects and indeed runs in 16-bit-wide mode. Sadly, byte lane select lines are <em>NOT</em> brought out to the cartridge slot. So, what would happen if I were to attach 16-bit RAM without them? Given the explanation above, it is clear -- reads would work fine. Word and halfword writes would work fine too. Byte writes would corrupt the neighboring byte. Clearly this is not going to work for booting PalmOS, which expects all RAM to be byte-addressable. What options are left? Just one -- RAM must be attached in 8-bit-wide mode. This does not require byte lane select lines and will correctly work for attaching RAM to Pixter Color via the cart slot. Sadly, as described earlier, this means that this memory if slower for larger access sizes, which are more common.
</p>
<p>There is more to consider here. When memory is accessed, it needs some time from being given an address and being asked to read it until it is expected to reply. Same applies for writes. To give it time, wait states are inserted. A normal bus access with no wait states might reasonably take two bus cycles to read a single bus-width-sized memory amount. The first cycle will present the address to the memory chip, and by the second, it is expected to have a reply ready to be read from the data lines of the bus. If the memory cannot reply that fast (in one cycle, basically), it will need wait states. What determines whether it can reply? Memories come in speed grades, which among other things, tell you how fast it could reply. For example on my Pixter Color cartridges, I use "-70" memory which can reply in 70 nanoseconds. Speed of light is also nonzero, and traces on boards and in connectors have inductance and capacitance, which, together, mean that the signals take time to travel from the SoC to the memory and back. Taken all together, one needs to configure the wait states such that the memory has enough time from truly seeing the control signals to the SoC truly seeing the replies. In Pixter Color's case at the rates I run the bus, this means the external memory runs with 2 wait states. The practical upshot of this is somewhat sad. Imagine a typical 32-bit read of external memory. Since the bus is 8-bits-wide, this will take 4 accesses. With 2 wait states, each access takes 4 cycles. This means the entire 32-bit-wide read takes as much as 4 x 4 = 16 cycles. Now, normally, the SoC's cache would absorb this slowness for reads and the write buffer would help on writes. Which brings us to...
</p>
<h3>The Worst ARM SoC I've Seen Yet</h3>
<p><a href="https://dmitry.gr/images/rePalm-PixterColorWarfareLarge.jpg"><img src="https://dmitry.gr/images/rePalm-PixterColorWarfareSmall.jpg" alt="Pixter Color playing Warfare Inc game"></a></p><p>The SoC in Pixter Color has the most minimal ARM7 configuration I've ever seen. The ARM7 CPU design is sold by ARM with a few configuration options that one decides on before instantiating it on a chip. One of the options is whether there is a cache, and of what size. Sharp went with "no thanks". Strike one! The next is whether there is an MMU. This is piece of hardware that allows very granular memory protection and mapping. Sharp went with "no". Strike two! Lacking that, there is an MPU option. This is a simpler memory protection unit - no mapping ability and limited number of regions of protection, but it is still better than nothing. The NintendoDS CPU uses this option, for example. This configuration is so simple, it basically costs no extra silicon at all -- no reason not to choose it. Sharp went with "nah". Strike three!
</p>
<p>But this gets even more fun, actually. ARM architectures before version 6 did not really support unaligned memory accesses. An unaligned write acted as if the lower address bits were zero, while an unaligned read would rotate the read word such that the "addressed" byte was at the bottom. Neither of those behaviours act like real unaligned memory access. That is to say that unaligned accesses were almost always a logic error. To catch them, ARM cores have a configuration bit to enable "alignment checking" which will cause an exception if an unaligned access is attempted. Since such accesses are almost always a bug, this checking should almost always be enabled. To configure whether it is or is not enabled, one uses coprocessor 15, which itself is optional. Sharp went with "ooh...optional, eh? NOPE!". Lacking a coprocessor 15, all configurable options become hardcoded to a set value with no ability to change them. In the case of the SoC in Pixter Color this means that alignment checking does not exist, since Sharp could not be bothered to enable it (at a cost of a dozen transistors, no more). Additionally, this means the exception vectors are always at <span>0x00000000</span>, since the ability to relocate them to <span>0xffff0000</span> is configured by cp15. This forces us to configure some memory to exist at address zero, which makes trapping NULL-pointer accesses impossible. There goes another error class we cannot trap. We're at five strikes by now... Jeez, Sharp!
</p>
<p>Without a cache, our 63MHz CPU ends up spending most of its time waiting on memory. Sharp did put in 16KB of <span>TCM</span> (tightly coupled memory) into the chip. This memory is accessible in a single cycle, making it rather fast. It can also appear anywhere in the address space (it is movable and overlays anything). But it is only 16KB which is very little. There is also 32KB of <span>eSRAM</span> (embedded SRAM) in the chip, which operates with no wait states and is 32 bits wide. This means that accessing it takes two cycles per word -- still quite fast. Pixter Color designers added 128KB of RAM onto the motherboard, as I had mentioned earlier. It is on a 16-bit-wide bus with one wait state. This means that for 32-bit reads, it takes 2 x 3 = 6 cycles per access, making it more than twice as fast the external RAM I put on my external cart. Sadly, 128KB is also not that much in PamOS 5's terms. It does give me a place to put the framebuffer and kernel globals. Better than nothing I guess.
</p>
<h3>Pixter Memories</h3>
<p>Given the complete lack of an MMU or an MPU, how can we protect the PalmOS storage heap from unintended or accidental modification? There is no obvious way. It is not strictly mandatory, of course, but highly desired. An idea came suddenly, while brainstorming how to connect more RAM to the device. Recall those byte lane select lines I explained earlier. They are only meaningful for writes, since for reads, the SoC can just ignore data it does not need. But what do memory chips <em>actually</em> do with those lines on reads? Turns out that they do not ignore them, they use them to mask output lanes. This means that a 16-bit-wide RAM can be used as an 8-bit-wide-ram of double the size by connecting its lower 8 data lines to the higher 8 data lines, connecting an unused address line to byte lane select, and the same address line through an inverter to another byte lane select. Think about it (or look at the schematic below).
</p>
<p>This scheme can be expanded further to use a 2-to-4 decoder to connect two x16 RAMS as a x8 RAM with 4x the size. Why am I telling you this? Because the largest PSRAM that could be located for this project was 16x4M, meaning that each chip of it has 4mega words of 16 bit-wide memory (8MB). Two such chips would make 16MB of memory, which is as much as Pixter's 24 external address lines would allow addressing. The 2-to-4 decoder would make this possible. Now, back to protection. Say, we decide up front to use the first 1/4 of the external ram as the dynamic heap, and the last 3/4 as the storage heap. The logical OR of the top address bits would be one for any storage access and zero for dynamic memory access. Add one more gate and a GPIO pin, and we have ability to ignore write to the storage area by blocking the "write enable" signal. Now, this will not <em>tell us</em> that an access was blocked - the Pixter Cart slot lacks an ability for us to send back an error to the SoC, but at least the erroneous write would be ignored. This scheme was implemented, tested, and found working! Cool!
</p>
<p>Why was PSRAM used? Pixter Color's SoC lacks any support for dynamic memory, which is what we use nowadays. Real SRAM (static memory), does not come in megabyte sizes, at least not on the budget I had in mind. PSRAM is a nice middle ground. It is dynamic memory with internal mechanisms to refresh itself. Externally it pretends to be static memory. It is not as cheap as dynamic memory, but when you need huge SRAMs, PSRAM might be all you can realistically get.
</p>
<p><a href="https://dmitry.gr/images/rePalm-PixterColorWithCartsLarge.jpg"><img src="https://dmitry.gr/images/rePalm-PixterColorWithCartsSmall.jpg" alt="Pixter Color showing rePalm boot screen surrounded by 8 rePalm Pixter Color cartridges"></a></p><p>The first revision boards had just 1MB of flash, as I had mentioned. This is rather little to squeeze in a full PalmOS 5 image. I did manage, with a lot of effort, but it was tight and I had to make some tough decisions and even rewrite one library in assembly to save ten bytes! Needless to say, revision 2 boards featured a much more roomy 8MB flash chip. This allowed for inclusion of all the standard PalmOS PIM apps as well as some games and utilities. There is even 2MB still free in ROM. The only issue was that this part was not stocked by JLC, forcing me to order it separately, and wait for them to receive it before they could assemble the boards for me. As the PSRAM and the Flash are both BGA-packaged chips, assembling at home was a non-starter.
</p>
<h3>Pixter Displays</h3>
<p>The first Pixter Color I got my hands on (and, really, most of the Pixter Color devices produced) featured an STN color display of such poor quality, that I struggled to call it "color". If you recall color laptop displays from the early 1990s, you can imagine this one too. The colors shifted with the slightest head movement, and the contrast slider allowed free adjustment from "muddy washed out dark browns" to "muddy washed out light greys" without any good middle "passable colors" state. Well, you play with what you have. STN displays need their controller to work hard to show gradations of color. This is done by temporal dithering (quickly alternating a pixel between on and off to create the illusion of a middle state). The ditherrer in the SoC allowed 15 brightness values per color channel. Yes, not 16. Indeed there are 16 values, but the middle two produce the same brightness, as is clearly documented in the SoC's user guide. This means that with this SoC, this display could display 15 x 15 x 15 = 3375 colors. 
</p>
<p>The display controller supports direct color mode, but sadly not in the normal RGB565 mode, but in the who-the-hell-asked-for-this XRGB1555 mode which PalmOS (and literally every other piece of software to ever use 16-bits-per-pixel displays) has no use for. Oh well, not like this display could display enough colors to make the 16-bits-per-pixel mode worth it. I decided to just support the 1, 2, and 4 bits-per-pixel greyscale modes and the 8-bits-per-pixel paleted color mode. This should be enough to run most PalmOS 5 software and, given the shittiness of this device, one should grade on a curve! When PalmOS sets a palete entry, I pick the closest of the 3375 colors to the requested RGB888 triple. 
</p>
<h3>Making Pixter IrDA work</h3>
<p><a href="https://dmitry.gr/images/rePalm-PixterColorIrDA.jpg"><img src="https://dmitry.gr/images/rePalm-PixterColorIrDA.jpg" alt="Pixter Color recieving a hand-drawn note over InfraRed"></a></p><p>Most SoCs' UARTs support IrDA SIR modulation, allowing one to simply connect an IrDA transceiver to the pins and immediately send and receive bytes via InfraRed. Of course the minimum-spec SoC in the Pixter Color does not have this option. I bet they saved a whole 0.0001 square millimeters of silicon by not having this option, the stingy bastards! I wanted InfraRed to work, though. There are chips that simply convert normal serial port signals to IrDA SIR modulation and back. This would be the simple solution, but due to how they work, they also need a stable clock input at the precise rate of 16x the current baudrate. As making IrDA work properly requires ability to negotiate a variable baudrate between 9600bps and 115,200bps, this means I'd need ability to drive out a stable variable clock on a cartridge pin. While this SoC can output a given clock, none of the pins capable of it connect to the cartridge slot. No, this approach would not work. What alternatives are there?
</p>
<p>Well, I did say that most SoCs' UARTs support IrDA SIR modulation. This is also true of small cheap microcontrollers, and even chinese clones of small cheap microcontrollers. Thus, the new plan was to use a simple microcontroller to talk IrDA to an InfraRed transceiver and normal serial port protocol to the SoC, over the cart slot. Luckily, among the various pins connected to the cart slot, there are two complete serial ports available for functional assignment to some of the pins. Score! One can be used for serial debugging and the other -- for this. A thought occurs, however. We need to not only send data to and from this microcontroller, but also control signals, eg to tell it to adjust the baudrate, or to update its firmware. This means that we need to talk to it at a higher rate than InfraRed ever would use, to provide for the extra overhead of whatever protocol I invent to make this all work. I decided on 2x the max IrDA rate - 230,400bps. The microcontroller chosen was the very cheap <a href="https://global.geehy.com/product/fifth/APM32F003">APM32F003F6U6</a> from Geehy. It had two serial ports with IrDA abilities, could be clocked from an external oscillator at a frequency quite amenable to generating UART clocks (11.0592 MHz), and was available as a stock part at JLCPCB. I figured that it was just like any other cheap Cortex-M0 and I would be able to find a common language with it. This turned out to be true, and it took only an hour to get CortexProg to program it.
</p>
<p>Getting this microcontroller to do UART was harder. The documentation was rather sparse, and I searched in vain for any way to assign a given pin to be a GPIO or a function pin. This is typical in most microcontrollers, including other families of MCUs from Geehy. But not this one, evidently. Eventually, I figured out that if you enable a peripheral, it simply takes over the requisite pins on this chip. This, however, did not explain why I could get UART1 working, but not UART3. Eventually, I realized that while UART1 had simply an enable bit, UART2 has <em>that</em> plus an extra "ENABLE" register which needs to be set to enable it, while UART3 has <em>that</em> plus an extra-extra "IO ENABLE" register that also needs to be set. Docs were not at all clear about this. This got me to another impasse. UART3 receive worked fine, but transmit did not, pin just sat at zero volts. It is, of course, at this point that I noted that the pin that UART3 used for TX is a hardware open-collector pin, meaning that It simply cannot source any current, only sink it. In human terms, this means: it needs a pull-up resistor to be of any use at all whatsoever. So, I enabled the pull-up on the Pixter Color's SoC side of that wire, and I had bidirectional communication!
</p>
<p>Designing protocols over UARTs is a bit of a pain. Almost any noise on an otherwise-idle line will turn into a <span>0xFF</span> byte. Any character can be lost to a framing error if noise causes its stop bit to appear low. And any character can be corrupted by noise during its data bits. Parity can be used to add some resilience to this, allowing, at least, likely detection of corrupted bytes. But parity support is not always present and does not always work. Since any byte can also go missing, how does one design a resilient protocol? If you send a length byte, and it gets corrupted, the reciever might be waiting for a lot more data than you intend to send, and thus get stuck. Conversely, the reciver might think the packet ended sooner than it really did and interpret the next byte of data at a packet header -- not good. Many ways can be invented to resolve this. A typical one is to simply somehow mark "start of packet" allowing the reciever to resynchronize in case of a sync-loss. A special byte can be used, but then that byte is not allowed in the packet contents. It must be escaped somehow. And what if the packet being sent happens to be made of just that byte? Escaping it might blow the packet size up by a factor of two. Another common method is to use the UART in 9-bit-mode, and just use the top (8th) bit as a "start of packet" marker. This has the benefit of not needing any escaping. The issue is that 9-bit-character support is not uniform among all the UARTs our there. Pixter SoC's UARTs, for example, do not support this. Not good. A third method is using a <span>BREAK</span>. This is when the data line for the UART is low for a full character length, including the stop bit. Most UARTs support recieving this and noting it as such. Sending it is a bit harder. Some UARTs, like the one in the APM32F003F6U6, can send a proper-length break simply by setting a bit and waiting for it to self-clear. This is not common. Most commonly, there is simply a "SEND BREAK" bit that lowers the TX line, and it is up to you to make sure you keep it low long enough. Annoying. This is what the Pixter SoC can do. At least this is what it advertises being able to do. In reality, I found that it worked unreliably. Sometimes using this feature would place the UART into a weird state where it could not transmit again. I found a workaround: I can reconfigure the TX pin as a GPIO and literally just take it low, wait, then reconfigure it back. The UART unit need not even know, and it does not get wedged! Win!
</p>
<p>The protocol I designed is simple but not symmetric, since while Pixter might have a lot of control data to send to the microcontroler (configuration, updates), the microcontroller rarely has much to say to the Pixter other than what InfraRed data it got. From microcontroller to Pixter, it is as follows: any byte received is an InfraRed data byte, unless preceded by a <span>BREAK</span>. If it was, the top 2 bits determine what it is. 00 means that it is a start byte of a longer packet, the lower 6 bits give the packet type. Each packet type has a fixed length. 01 means that it is a lower nibble of a non-first byte of a longer packet, bits 4 and 5 must be zero. 10 means that it is a higher nibble of a non-first byte of a longer packet, bits 4 and 5 must be zero. 11 means it is a one-byte control packet. You can see that "longer packets" thus get blown up in size by a factor of 4. This is fine since this is rare, the only such packet defined is the "version info packet". Actual IrDA data arriving can interrupt transmission of such packets, since any byte not preceded by a <span>BREAK</span> is treated entirely differently. The one-byte control packets allow for flow control. This is needed since this interface is at 230,400bps while IrDA is at 115,200 max. Pushback ability is needed from the microcontroller to PalmOS to keep it from overflowing the microcontroller's TX buffer. This range is also used to signal various framing errors in received IrDA data. For more details you can see "pixterComms.h".
</p>
<p>The protocol from the Pixter to the MCU is different. Here, a <span>BREAK</span> is sent before the start of a packet. Then comes a byte that describes the packet. The top 2 bits determine packet type. 00 - simple command where bits 0..5 determine command type, each has a fixed length. Examples are: "get version info", "reset", "set IrDA config". 01 - IrDA data. Bits 0..5 give data length minus one. That many bytes of data to send follow. 10 - firmware update data. Same length encoding as for IrDA data. 11 - reserved for future use. Firmware data is further decoded based on the first few bytes. Again, for details see "pixterComms.h". When PalmOS starts trying to send IrDA data, a packet is sent off to the microcontroller right away, no waiting. This means that usually it just contains one byte of data. By the time it is sent, PalmOS might have added 5 or 6 bytes more to the TX buffer, and those are sent in a longer packet, by the time that is sent, much more data has been added to the TX buffer, and maximum-length packets can be sent to the MCU. Keep in mind also that Pixter-to-MCU comms are <em>at least</em> 2x as fast as IrDA comms are, which helps here. This design minimizes delays to <em>start</em> getting the data out. This matters since IrDA protocol timeouts give a limited amount of time to <em>START</em> recieving data, with more time available once the data starts coming in.
</p>
<p><a href="https://dmitry.gr/images/rePalm-PixterInfraRedDebugLarge.png"><img src="https://dmitry.gr/images/rePalm-PixterInfraRedDebugSmall.png" alt="A screenshot of Saleae Logic software debugging InfraRed communications with two lines depicting UART traffic and two depicting IrDA traffic, one inverted"></a></p><p>Debugging IrDA was a <em>huge</em> pain in the posterior, exacerbated by the fact that there exist no good working IrDA SIR decoders for <a href="https://saleae.com/">Saleae Logic</a>. Without my Logic 16 PRO and various analyzers, I'd be very lost. Seriously, this thing is a huge force multiplier, if you do not have one, you are developing on hard mode for no reason. I do not get paid to say this, I just really love this thing! In any case, since there was no analyzer for IrDA SIR, I wrote one. It properly decodes all bit lengths, parity settings, marks start and stop bits, shows errors, and supports both inverted (RX) and normal (TX) signaling. Most importantly, it allowed me to debug a few issues I had caused. As I <a href="https://dmitry.gr/?r=05.Projects&amp;proj=35.%20Linux4004">had done in the past</a>, I sent my analyzer's source to the good people at Saleae for consideration for inclusion in the Logic software, so that no others will ever need to suffer the indignity of decoding IrDA SIR one bit at a time by hand.
</p>
<p>The practical upshot of all of this is that it all works! IrDA communications work. MCU firmware updates also work. For that last one to work, there is a tiny (400 bytes) bootloader in the MCU that copies an uploaded validated image to the main flash area on boot if the version field differs. If the image was not fully uploaded, it will not be seen as valid. If the copy is interrupted, it'll resume on next boot. There is way to brick the MCU as long as the bootloader is not touched!
</p>
<p>There was one more thing the MCU needed to do. There is a pin on the cart slot that needs to be high for the Pixter Color to believe that a cart is inserted. After this check, the pin is usable for ... whatever. I ended up not using it for anything, but it is wired to the MCU. This does mean that soon after boot, the MCU needs to raise it and keep it high until rePalm takes over from Pixter's OS. It does this. Without this code, Pixter Color will boot-loop as long as the cart is inserted, neither booting nor giving up, forever. Curiously, Pixter Multimedia does not care about this pin and never checks it.
</p>
<h3>Getting and Flashing the Pixter Carts</h3>
<p><a href="https://dmitry.gr/images/rePalm-PixterColor-CartSchem.pdf"><img src="https://dmitry.gr/images/rePalm-PixterColor-CartSchemSmall.png" alt="Pixter Color cart Schematic"></a></p><p>Since the cartridge boards feature a parallel 16-bit-wide NOR flash, I needed some way to program them initially. <a href="https://github.com/GeorgeRudolf">George</a> designed and JLCPCB manufactured a flasher board for me, based on the wonderful <a href="https://www.raspberrypi.com/products/rp2350/">RP2350</a>, which is pretty much the best microcontroller you can get today (not merely an opinion, a true fact, fight me!). This board also has a cart slot similar to the one in Pixter, the <em>VERY</em> not cheap <a href="https://www.digikey.com/en/products/detail/edac-inc/302-060-221-201/21847827">302-060-221-201</a>. I use this to program each Pixter Color cart once. I then use CortexProg to program the microcontroller. After this, self-firmware-update from inside PalmOS can be used for flashing, as long as you do not accidentally flash a broken image!
</p>
<p>I wrote a PalmOS updater that loads the update (<span>/ROM.BIN</span>) from an SD card into RAM and then disables interrupts (since various drivers might be part of the OS image which we are about to slowly partially erase and overwrite), and then flashes the NOR flash with the new image. Before doing this, it also updates the MCU firmware (<span>/FIRMWARE.BIN</span>), if the replacement firmware has a higher version number. The entire process takes slightly more than four minutes, making it much faster than manual flashing with the flashing tool described above. Also, this brings updates to the users of these carts who do not have a flashing tool I described above.
</p>
<p>Did I say <em>users</em>? Yes! Fifteen of these were manufactured for those who wanted them and are now with their happy users. The cost to manufacture them ended up being around $50 each, making them a bit more expensive than a used Pixter Color on eBay. There is a chance that I'll run another production run, so if you want one, <a href="mailto:pixtercarts@dmitry.gr">email me</a>. Alternatively, you can have your own boards made and assembled using <a href="https://dmitry.gr/images/rePalm-PixterColorCartGerbers.zip">these files</a>. Board thickness should be 1.2mm. Initial flashing is left as an exercise to the reader.
</p>
<h3>Pixter Polish</h3>
<p><a href="https://dmitry.gr/images/rePalm-PixterColorPalmkedexLarge.jpg"><img src="https://dmitry.gr/images/rePalm-PixterColorPalmkedexSmall.jpg" alt="Pixter Color running Palmkedex showing Marill's page"></a></p><p>Now that basic PalmOS 5 worked (slowly), it was time for some polish. First of all, those buttons below the screen initially did nothing. But why not make them do something? The first one looked like a pencil. I wired it up to send a special unused keycode, and then wrote a tiny hack called <span>PixterEnabler</span> that catches this key and toggles onscreen writing. Since there was no documented API to control on-screen writing, I had to reverse-engineer the <span>GrafitiAnywhere</span> module. While doing that, I found that it had an unused-ever-before capability to change the ink color. I went with bright green.
</p>
<p>The third from the right button was used in Pixter's native OS to bring up settings, which include contrast adjustment. I wired this up to bring up the PalmOS contrast adjustment dialog. Reverse engineering how Pixter Color controls display contrast took some work. It is weird. It uses an R-2R resistor ladder and 4 GPIO pins to create one of 16 voltage levels that are then fed as an input to the display driver. Figuring it out took a while, wiring it up to PalmOS took all of a few seconds. Cool! This would do for now. More later.
</p>
<p>Pixter Color's CPU is simply not fast enough to do sampled audio playback. Lacking a real codec with a DAC, one would have to use the PWM unit, and take an interrupt every sample to reset it to a new value. Given the slowness of the CPU and memory subsystem, this would not work. I did try it. 44,100Hz uncompressed WAV playback used about 98% of the CPU cycles. This means that games with audio would be too slow to play and realtime MP3 decoding is a fevered dream of a madman. Given this, I decided to instead support the "simple sound" API of PalmOS. You may know it as "the beeps and the boops" that the earlier devices used. This can be done by simply programming the PWM unit once as "tone start" and again at "tone end". This allows for simple tunes, alarm sounds, and UI clicks to work. Good enough.
</p>
<p>Pixter devices also have an internal melody chip, as <a href="https://dmitry.gr/?r=05.Projects&amp;proj=37.%20Pixter">my main Pixter article mentions</a>. I thought that it would be cool to allow starting and stopping melody playback from PalmOS. The timing on the control interface is rather tight, forcing me to write the code in ARM assembly and use rePalm-specific high-resolution timer API. Nonetheless, it worked and you can indeed start and stop melody playback using the <span>PixterMelodyCtl</span> app. Since the playback is entirely independent of the OS, it will continue until stopped, including across firmware updates. I did code <span>PixterMelodyCtl</span> to send the "stop melody" command on PalmOS reset, so that at least it would stop on reboot. A video of this is in the rePalm photos album linked-to above.
</p>
<p>Pixter Color actually has one physical button. It is the pinhole on the back that the native Pixter OS uses to cause pen recalibration. This makes sense since a messed-up calibration would make tapping on-screen buttons impossible, so a real button is needed. I wired this up in PalmOS as hard button #1, and it can be mapped to any application using the usual Buttons Prefs Panel. I considered wiring this up as a soft reset button, as it is reminiscent of those, but the device has a perfectly working power switch on the side, toggling which causes a perfectly good reset. Actually making this button work was nontrivial. You see, it is not wired to any pin that can cause an interrupt to the CPU. Instead, in the timer-overflow handler which runs in FIQ mode (for speed) at around 120Hz, I check its state, do some quick debouncing, and if it changed state, enqueue a normal low-priority interrupt that will later be handled to deal with it. The same check-and-debounce-in-periodic-FIQ method is used to detect SD card insert/remove, for the same reason.
</p>
<p>There is, of course, no SDIO support in Pixter Color's SoC. There is SPI support, but none of the pins available on the cart slot are connected to the SPI unit in the SoC, so that would be of no use either. I ended up bit-banging the SPI interface for SD card support in assembly. You'll recall that the CPU in Pixter Color is super slow, and so is the memory. I spent a little bit of my fast TCM to keep these SPI bit-banging routines fast. The final result is that my code reaches access speeds around 3.8Mbit/s, which is not all that terrible. Of course, this uses the CPU so nothing else can really transpire while this goes on. Oh well. It does work, allowing backups to card and loading games from card!
</p>
<h3>Battery State</h3>
<p><a href="https://dmitry.gr/images/rePalm-PixterColorBatteryVoltageLarge.jpg"><img src="https://dmitry.gr/images/rePalm-PixterColorBatteryVoltageSmall.jpg" alt="Pixter Color showing a battery voltage of 5.34V at a charge state of 73%"></a></p><p>Luckily, converting a voltage to an approximate state of charge for alkaline batteries is trivial. Once I figured out how the battery voltage was hooked up to the SoC's ADC and at what scale (0.25, evidently), I was able to measure battery voltage. A conversion of battery voltage occurs at every pen down, pen movement, or every 500ms. These values are smoothed and converted to a percentage that is properly handed to PalmOS. Curiously, in PalmOS 5, there is no official or even unofficial API to get battery voltage, only percent charge. This is actually not unreasonable, since battery technologies evolve and user-level applications have no business trying to understand voltages. Current battery state of charge is enough for applications. That being said, in PalmOS 4, there was such an API. In PalmOS 5, for compatibility it still exists, but in a fake way. It will read the current state of charge and map it linearly onto 3.7V - 4.2V range. I decided that it would be hilarious to expose the true battery voltage to applications that ask for it, so I added a small hack in my DAL to do so. Now applications using PalmOS 4 APIs can query and properly display the true battery voltage. The reason this is funny is because Pixter runs on 4 series-connected AA batteries, which means it'll see around 6V when full. No Palm OS device before had ever run on such a high battery voltage and I was curious what applications would do with this, and whether anything would break. Nothing did.
</p>
<h3>ARM7 quirks</h3>
<p>The ARM7 core used by Pixter's SoC implements ARM architecture version 4T, which is, in theory, good enough for PalmOS 5.x. You could have guessed this based on the whole story above - I got it to work afterall, right? Well, PalmOS ran on a number of ARMv4T processors, but all of them were ARM9 CPU or later. ARM7 CPU design is a bit older and a bit slower, which is not a disaster and you are probably tired of hearing about the slowness already, but it has a few other quirks which would turn out to become quite a pain when it came time to run my favourite PalmOS game - <a href="https://palmdb.net/app/warfare-inc">Warfare, Inc.</a>.
</p>
<p>As mentioned elsewhere in this increasingly long article, ARMv4T processors can execute instructions in one of two formats. ARM instructions are always 4 bytes long and occur only at memory addresses divisibly by 4 (this is called "self-aligned"). Thumb instructions are always 2 bytes long (do not believe anyone who tells you that the <span>BL</span> instruction is 4 bytes long, in ARMv4T, <span>BL</span> is actually two instructions, each of which can be executed independently and each is two bytes long), occurring at memory locations divisible by 2 (also self-aligned). These instructions cannot be freely mixed, since the CPU would not know how to interpret the next bytes. Instead, the CPU has an internal method to track which instruction set mode it is in (bit 5 in <span>CPSR</span>, if you are curious). There are a few ways to switch this mode. In ARMv4T, there are precisely two ways. One of them is returning from an exception. This is only used by the OS kernel and not by any normal user code. The second is the <span>BX</span> (branch and exchange) instruction. This instruction takes a register as a parameter and jumps to the address it contains. Since both ARM and Thumb instructions occur at even addresses, the lowest bit of the address register is by-definition not meaningful. The CPU uses that bit to decide what mode to switch to - ARM if it is zero, Thumb if it is one. Good so far. Let us analyze all 4 possible cases of the lower 2 bits of the register passed to <span>BX</span>. "01" and "11" are both valid options, both go to Thumb code either at an address that is even but not divisible by 4, or to an address that is divisible by 4. "00" is also a valid option. This will go to ARM code at an address divisible by 4, as ARM instructions ought to be. Quite clear. It is the last case -- the "10" case that is of most interest to us.
</p>
<p>ARM architecture reference manual says "If Rm[1:0] == 0b10, the result is UNPREDICTABLE, as branches to non word-aligned addresses are impossible in ARM state." OK, fine. Most often <span>BX</span> is used to return from functions. Clearly the return address should always be valid and this case should not come up. The second-most common use case of <span>BX</span> is to call a function via a function pointer. This should also only use valid pointers with proper alignment and nothing should ever be the matter. Fine. But, there is a third case. Say you are executing in Thumb mode, but wish to call an ARM function. You cannot directly <span>BL</span> to it, since that will leave you in Thumb mode. You could calculate its address and <span>BX</span> to the register containing it, but this is a lot of cycles. There is a third method, and a common one. You <span>BL</span> to a tiny thunk containing a single Thumb instruction: <span>BX PC</span>. Since when it is read, PC never has the low bit set, and since in Thumb mode it reads as the address of the current instruction plus 4, this will execute a <span>BX</span> with a value with the lowest bit clear and the rest of the bits pointing 4 bytes past this instruction's start (2 bytes past its end). This will cause a switch to ARM mode and continuation of execution at that address in ARM mode. There, one places an ARM <span>B</span> instruction to jump to the desired function. When that function returns (using <span>BX LR</span>), it will jump back to Thumb mode at the call site just past the <span>BL</span>, since the <span>BL</span> had set up the <span>LR</span> register thusly, as is its job. Did you spot a potential issue?
</p>
<p>This will all work wonderfully as long as the <span>BX PC</span> instruction is at an address divisible by 4. If it is not, we end up with the above-mentioned "10" case which is, I quote again "UNPREDICTABLE". Does the ARM ARM tell us anything more about this precise case? It does (in the section on the <span>BX</span> instruction)! "Register 15 can be specified for &lt;Rm&gt;. If this is done, R15 is read as normal for Thumb code, that is, it is the address of the BX instruction itself plus 4. If the BX instruction is at a word-aligned address, this results in a branch to the next word, executing in ARM state. However, if the BX instruction is not at a word-aligned address, this means that the results of the instruction are UNPREDICTABLE (because the value read for R15 has bits[1:0]==0b10)." Well, that is pretty clear, this case is unpredictable and nobody should do this. Fine!
</p>
<p>The issue is, some PalmOS games that were compiled with an antique version of ARM gcc <em>DO</em> do this. I ran into this while writing the main article on the project, and <a href="#bxpc">mentioned the special handling I had to do for it</a>. Somehow, this never broke on any PalmOS 5 device. What gives? It turns out that on ARMv5 and later, whenever the CPU is in ARM mode, the lower 2 bits of <span>PC</span> are forced to zero immediately on any write. So the <span>BX PC</span> at an address that is not divisible by 4 will simply jump to an address 2 less, which is divisible by 4. This seems to be what the old ARM gcc version expected and relied on. However, PalmOS 5 ran on ARMv4T as well. How did it ever work there? Well, it seems that ARM9 CPUs do the same thing. All PalmOS 5 devices on ARMv4T CPUs used ARM9 cores. No PalmOS 5 device ever ran on an ARM7 core. <b>I made the first one!</b> So, what does ARM7 do in this case?
</p>
<h4>What exactly does ARM7 do with PC[1] in ARM mode?</h4>
<p>This investigation took quite a bit of time, since I wanted to make sure I understood the behaviour entirely so that I could emulate it properly in <a href="https://github.com/uARM-Palm/uARM">uARM</a> for simplified debugging in the future. I found no information on this anywhere, so this might be the first documentation on the subject. ARM7 CPUs do not force <span>PC</span>[bit 1] to 0 when PC is written. You can write <span>PC</span> using any method you choose with that bit set, and nothing bad will befall you ... at least not immediately. Instruction fetches in ARM mode do not send <span>PC</span>[bits 0..1] on the bus, so instructions will continue to be fetched and execute as expected. If an exception is taken, the value of <span>PC</span> seen by the exception handler will reflect the true value of <span>PC</span>[bit 1], and a return from exception will properly restore it. The value of <span>PC</span>[bit 1] will survive a function call and return as well, causing no ill effects. Reading <span>PC</span> directly will also show the true value of <span>PC</span>[bit 1]. This is where you're likely to hit your first problem. You see, ARM instructions make it rather difficult to load large immediate values into registers, so it is common to load them from a "literal pool" - literally a set of word-sized constants at the end of the current function. Such a load usually takes the form of a PC-relative load instruction, like this: <span>LDR Rx, [PC, #0x124]</span>. Since <span>PC</span> is expected to always be word-aligned, the offsets used also are, producing a word-aligned address whence a word will be loaded. What happens if our <span>PC</span>[bit 1] is set? The produced address will not be word aligned. What happens then? If your CPU has alignment checking enabled, you take an exception due to a misaligned load. And what if your CPU, like the one in Pixter Color's SoC, has no alignment checking ability, or if you simply turned alignment checking off? ARM ARM quoth: "Load single word ARM instructions are architecturally defined to rotate right the word-aligned data transferred by a non word-aligned address one, two or three bytes depending on the value of the two least significant address bits." So, you'll simply load the immediate value you intended to load, except rotated right by 16 bits (swapping the lower and the upper halfwords). I'll let you imagine the havoc that doing this to all constants would cause.
</p>
<p>Curiously, there is another place this can cause issues. A typical way to call an OS kernel is a <span>SWI</span> instruction, which, in ARM mode, encodes a 24-bit immediate in its lower 24 bits. A kernel would usually read the immediate to figure out what the requested syscall number is. Since in the exception handler, <span>LR</span> is expected to point just past the <span>SWI</span> instruction, a typical way to get this immediate is <span>LDR R0, [LR, #-4];  BIC R0, #0xFF000000</span>. See the issue here? If <span>PC</span> was misaligned, your kernel would have just taken an alignment fault, or (if alignment checking is off) simply read the wrong value. A kernel aware of this quirk would instead do something like this: <span>BIC R0, LR, #3;  LDR R0, [R0, #-4];  BIC R0, #0xFF000000</span>. Fun story: <a href="https://elixir.bootlin.com/linux/v6.18/source/arch/arm/kernel/entry-common.S#L199">Looking at what Linux does</a>, it looks like a <b>possible user-space DoS on Linux in just two instructions</b>. Would that be a record? If the kernel was configured to support OABI (exclusively or together with EABI), the following two-instr binary will simply crash the kernel if the core has alignment checking: <span>SUB PC, PC, #2;  SWI 0</span>. I am not sure how common such configs are, but someone should maybe fix that? 
</p>
<p>But OK, back to my favourite game. Since ARM code execution is unimpeded by <span>PC</span>[bit 1], the faulty code crashes after an arbitrary delay following <span>PC</span>[bit 1] being set, or maybe does not crash at all, but malfunctions. If I had alignment checking, I could detect the most likely cause of crash (unaligned literal load) and fix it. Lacking that, what could I do? I decided on a complex, partial, and heuristic-full solution. To call into ARM-native code, PalmOS applications use an OsCall called <span>PceNativeCall</span>. It gets a function pointer to jump to in native ARM mode, and a parameter to pass to the code. I patched this function with my own wrapper that does the following: First, determine which memory heap the code pointer is in. Second, manually walk the heap structures to find which memory chunk the pointer is in. Third, assume that the entire memory chunk is ARM code and apply the heuristic to it. The heuristic produces no false positives or negatives across all the games I tested, so I am satisfied with it. It is this: (1) A valid thumb <span>BL</span> at a proper 2-byte boundary pointing to somewhere inside the chunk at a 2 but not 4 byte boundary, (2)  A <span>BX PC</span> at that location, (3) The <span>BX PC</span> is followed by a valid ARM <span>B</span> with a target somewhere inside the chunk, and (4) The target instruction is unconditional, making it a likely first instruction in a valid function.
</p>
<p>OK, so, say I find the problematic <span>BX PC</span>. What now? It is not like I can fix it. To fix it requires two bytes of extra space that I do not have, and editing of all the callsites. Instead, I simply replace the <span>BX PC</span> with an invalid instruction in a special format. My kernel has a handler for the invalid instruction trap that checks for Thumb-mode execution of that exact instruction. It will <em>correctly</em> adjust <span>PC</span> and return in ARM mode to the ARM <span>B</span> instruction, allowing it to continue with <span>PC</span>[bit 1] properly cleared. This does mean that (1) I am editing the game binary in RAM and some game might detect this and get upset, and (2) depending on how often this callsite is called, a whole lot of exceptions might be being taken, costing a lot of performance.  The first case is simple - seemingly no games get upset because usually they do self-checking before calling the code. The second case is addressed by making the handler as simple and light as possible, minimizing the penalty. This is the best I can do, and it works! Since the issue is found in the ARM7TDMI core, I named by hack to work around it <span>LEG7IMDT</span>, of course.
</p>
<h3>Pixter Multimedia</h3>
<p>The last generation of Pixter was the "Pixter Multimedia". This one was even fancier - it had some buttons (a directional pad and A/B buttons) and a better SoC: <a href="https://web.archive.org/web/20240812134113/https://www.nxp.com/docs/en/data-sheet/LH79524_525_N.pdf">Sharp LH79524</a>. It also supported some fancier multimedia game carts, some featuring rudimentary video playback. Inside, it sported a real DAC (<href="https: web.archive.org="" web="" 20170305140713="" http:="" www.ti.com="" general="" docs="" lit="" getliterature.tsp?genericpartnumber="tlv320dac26&amp;fileType=pdf&quot;">TLV320DAC26), connected by I2S to the SoC. There was also 4 whole megabytes of SDRAM in the device. Up front, and most noticeable of all, was the TFT screen. Still 160x160 but now with a better contrast ratio than the Pixter Color's STN screen's 1:2. Of course I wanted to support this one as well. What would that take?
</href="https:></p>
<p>The SoC uses the same ARM7 core, but now in much better configuration: it now had an MMU and 8KB of cache. The TCM is gone, however. This is a worthy trade. With an MMU, a number of things get better: NULL pointers can be caught, real memory protection is possible for the storage heap, and a simpler solution to the ARM7 quirks might be possible instead of <span>LEG7IMDT</span>. With a cache, much of the memory latency can be hidden for tasks with a small working set. Overall this device performs <em>significantly</em> better!
</p>
<p>Audio support was actually rather simple. Once I figured out how the SPI interface of the codec was wired to the SoC (it was bit-banged using some GPIOs), it was simply a matter of configuring the DMA for the data and configuring the DAC for the proper sample rate. I made it build-time-configurable in the source, but settled on 44.1KHz - a perfectly good sample rate. The codec supports driving a single speaker (as is present in the Pixter Multimedia) or a set of headphones in glorious full stereo. As I designed rePalm to make supporting new hardware easy, it took only a few hours of work to hook up audio support and hear it work. This device is fast enough to play uncompressed audio and even do so while a game is running, making playing Warfare, Inc even more fun, with the units calling out "on my way, sir!" when you direct them somewhere. Same as in Pixter Color, I hooked up the battery sense to the OS (here the scale was 0.27). There is also a volume knob on the side of Pixter Multimedia. As the DAC has no analog "gain" input, I was not quite sure where it could possibly be hooked up to work. The mystery was solved after some investigation. It is an analog input to the SoC's ADC, nothing more. It is up to software to do anything with this information. I decided to save this for later, but maybe I'll convert it to a jog-wheel-like thing. Anyways, simple game soundbites and uncompressed audio were not the extent of my aspirations -- I wanted real MP3 playback from SD card to work!
</p>
<p>Everything I said about SD card support on Pixter Color still held here - I was bit-banging SPI to talk to the card. The SoC in Pixter Multimedia had a different clock tree, and I played around with a lot of options, finally settling on a rather significant CPU overclock of 102MHz (documented max is 75MHz) while keeping the AHB speed at 51MHz. This provided stability and just barely enough cycles to decode mono 96Kbps MP3s. Higher clock rates allow higher quality music, but not all tested Pixter Multimedia units could clock higher than 110MHz.
</p>
<p>Pixter Multimedia display proved to be a pain point, however. It is indeed 160x160, but for some reason stock Pixter software was configuring it for 162x160. It took me very little time to figure out why - the display eats the first two columns of data. This is despite any configuration change. It does not mater if you adjust the HBP or HFP or HSYNC length. Unfortunately, losing the <em>FIRST</em> pixels of a row is very very bad for us! Why? Many parts of PalmOS, assume that every display line begins at a 2-byte boundary. My blitter does as well, for efficiency. There is no assumption that every line follows the previous one in memory, so in theory we can simply have a 160x160 display with a 162x160 framebuffer in memory, and claim that the framebuffer starts 2 pixels in. Will it work? Let's math! SoC hardware forces the display data to start at a 4-byte boundary. At 16bpp, two pixels are 4 bytes, so an address two bytes into a line is 4-byte aligned -- a superset of being 2 bytes aligned. Good. At 8bpp, two pixels are 2 bytes, so an address two bytes into a line is 2-byte aligned - good enough. Things begin to fall apart at 4bpp and below. At 4 bpp, two pixels are a single byte and the blitter will be quite unhappy at a line not starting at a two byte boundary. At 2 and 1 bpp, the line does not even start at a byte boundary. No good! What could I do?
</p>
<p>Had I had no MMU, the game would be over right there, but I did have one! I decided to do the same thing I had <a href="#timeddisplay">done before</a> for another reason. The short of it is: create a fake framebuffer, aligned as the OS wants it. Protect it using the MMU. Anytime a write is attempted, take a fault, unprotect it, and start a 60Hz timer to convert the data to the proper format and alignment and transfer to the real framebuffer. After a few such copies, re-protect the original framebuffer and disable the timer. In turn, that allows for fast refreshes while drawing is ongoing and allows us to stop the CPU waste when this is no longer needed. This allows for 1/2/4bpp modes to work and only wastes CPU on drawing when actual drawing is ongoing. I wrote the transfer funcs in assembly for speed. This also allows us to use 16bpp mode. You'll recall that I mentioned that these Sharp SoCs use the idiotic XRGB1555 mode, while PalmOS needs and assumes the common-and-sane RGB565. Well, now that I had an ability to "convert" data on each draw, why not support 16bpp as well? I did and it is glorious! Photo-viewing apps worked now, even if only using 32768 colors
</p>
<p>As foreshadowed earlier, <span>LEG7IMDT</span> is not needed on Pixter Multimedia. Any sane code running with <span>PC</span>[bit 1] set would either run fine to completion or hit an alignment fault when it attempted to load an immediate from the literal pool. My alignment fault handler simply checks if the CPU was in ARM mode with <span>PC</span>[bit 1] set, clears it, and returns. If this fixes the issue - good. If not, we trap again and this time it is fatal since the <span>PC</span>[bit 1] being set was clearly not the issue. This is indeed simpler than walking memory heaps and patching random executables live.
</p>

<h3>Some More Pixter Polish</h3>
<p><a href="https://dmitry.gr/images/rePalm-PixterMultiWrongDeviceLarge.jpg"><img src="https://dmitry.gr/images/rePalm-PixterMultiWrongDeviceSmall.jpg" alt="Pixter Multimedia showing a simple white message on black background that it is the wrong device to boot this cart"></a></p><p>Since both Pixter Color and Pixter Multimedia use the same cart slot, the same cart can be used in both, hardware-wise. But since rePalm kernel builds rather differently for MMU and MMU-less systems, I did not want to try to make a universal build. Instead, you can use the self-update mechanism to flash one of the two images to switch between them. Of course, if you only have a Pixter Color, you would not want to flash the Pixter Multimedia image since you'd then be unable to boot to flash back. I did want to be a bit more user-friendly. Luckily, long ago I added a capability to run some code very early in rePalm boot. On Pixter, I used it to check the SoC type before boot. What good is that? If it does not match the current build, I can use rePalm's simple fixed-width character renderer on the framebuffer still enabled from Pixter's OS's boot and show a message. Here you can see what it looks like.
</p>
<p>At some point during the project, I saw a weird Pixter Color. It seemed to have a much better screen than others. It also did not boot my Pixter Color image. To be more precise, it booted fine, based on the serial console, but the display was off. Some investigation revealed that there was a small production run of Pixter Color device with the Pixter Multimedia's TFT screen. I changed my code to detect screen type (based on how Pixter's OS had set it up) and handle both. The good news is that the TFT display on Pixter Color can display the full 4096 color-palette that 12 bits per pixel would allow, rather than the 3375 colors the STN could. There was bad news too, though. Being the same display as Pixter Multimedia, it still ate the first two columns of pixels. Pixter Color had not yet sprouted an MMU so my old tricks would not work. Initially I simply disabled 1/2/4 bpp modes. This did not seem to break any applications, but it confused many since very few actually check for errors when they call <span>WinScreenMode</span> to set screen depth. I decided that a low-performing solution is better than one that confuses apps, so I added a 60Hz interrupt that copies the data in the proper format from a fake framebuffer to a real one. Basically, this is the same as what I did for Pixter Multimedia, but without the ability to stop doing it when the display stops being changed by the app. I'd estimate the performance cost of this to be around 20% of Pixter Color's CPU budget. Luckily, when running at 8bpp, this is not an issue. I then did the same thing to enable 16bpp on both the STN and TFT displays. The cost is immense (30% CPU on TFT, 46% on STN due to needing to apply STN correction curves). Due to this I have the device boot in 8bpp mode which has color and performs well, but if any app requests 16bpp, it is available. After some more thought about how cruel it is to steal 46% of an already slow CPU, I changed this to a 30Hz interrupt, halving the cost.
</p>
<p><a href="https://dmitry.gr/images/rePalm-PixterMultiButtonsPanelLarge.jpg"><img src="https://dmitry.gr/images/rePalm-PixterMultiButtonsPanelSmall.jpg" alt="Pixter Multimedia showing the 'Buttons' control panel with cons matchng Pixter's silkscreened buttons"></a></p><p>I wanted to make a good use of ALL the silkscreened buttons under the display, not just the three I had assigned before. I mapped them all to a purpose, and even took the time to draw pixel-perfect icons for them to integrate into the <span>Buttons</span> Prefs Panel on both devices. The mapping is the same on both devices, even though the button spacing is not the same and required individual silkscreen resource files. The first button toggles on-screen writing, the next 4 act like the normal application buttons on palm devices. The next one (that looks like an explosion) opens the menu. The one after that, which looks like a magic wand, opens the contrast adjustment dialog. Why? Original Pixter OS used it for that and I desired some consistency. The one after (folder) brings up the find dialog. And, of course, the home icon opens the app launcher. Overall sane, I think.
</p>

<h3>Pixter Results</h3>
<p>This is the first primary-battery-powered color PalmOS device. This is the first primary-battery-powered PalmOS 5 device. Pixter Color is also the worst-performing PalmOS device ever. But it does work... There are a lot of photos and videos in the rePalm photo album linked-to on top of this page.
</p>
<p>I did some benchmarks and found that Pixter Multimedia performs approximately on par with Palm Tungsten T. Pixer Color ... looks cute trying, but the benchmark results are comical -- it is 6% as fast as a T|T. But for basic PIM and many games this is plenty. Warfare Inc works! What more could you ask for? To download the latest update images, <a href="https://dmitry.gr/images/rePalm-PixterBinaries.zip">click here</a>. You can use them to flash boards you make or to update boards you got from me.
</p>


<h2>Nov 2, 2025 - summary of what you missed</h2>
<p>
I have made builds for Pimoroni Presto, the DEFCON32 badge, and worked on PalmCard - a replacement memory card for Palm Pilot classic that uses RP2040 to run rePalm and makes a terminal out of the Palm. Lately I've been working on supporting Fisher-Price Pixter Color. All of this can be seen in the photo album. Future updates will be more detailed, but I am too lazy to write about the last few years of development here since it really was mostly just new device support and bug fixes. Soeone who is not me also did some work on rePalm - there is now a working nintendo DS port. I helped only a little, most of the work was not mine, and this is awesome!
</p>
<h2>The original article about the start of the project</h2>
<h2>PalmOS Architecture (and a bit of history)</h2>
<h3>History</h3>
<p>PalmOS before 5.4 kept all data in RAM in databases. They came in two types: record databases (what you'd imagine it to be) and resource databases (similar to MacOS classic resources). Each database had a type and a creator ID, each a 32-bit integer, customarily with each 8-bit piece being an ascii char. Most commonly any application would create databases with their creator ID set to its. Certain types also had meaning, like for example <span>appl</span> was an appliction and <span>panl</span> was a preference panel.
</p>
<p>PalmOS started out on Motorola 68k processors and ran on them from first development all the way to version 4.x. For version 5, Palm Inc chose to switch to ARM processors, as they allowed a lot more speed (which is always a plus). But what to do about all the software? Lots of PalmOS apps were written for OS 4.x and compiled for m68k processor. Palm Inc introduced <span>PACE</span> - Palm Application Compatibility Extension. <span>PACE</span> intercepted the OsCall <span>SysAppLaunch</span> (and a number of others) and emulated m68k processor, allowing all the old software to run. When m68k apps called an OsCall, <span>PACE</span> would translate the parameters and call the ARM Native OsCall. This meant that while the app's logic was running in emulation, all OsCalls were native ARM and fast. Combine this with the fact that PalmOS 4.x devices usually ran at 33MHz, and PalmOS 5.x devices usually ran at hundreds, there was almost no slowdown, most old apps compiled for PalmOS 4.x ran at a perfectly good speed. It was even good enough for Palm Inc, since most built-in apps (like calendar and contacts were still m68k apps, not ARM). There was also PalmOS 6.x (Cobalt) but it never really saw the light of day and is beyond the scope of this document.
</p>
<p>Palm Inc never documented how to write full Native ARM applications on PalmOS 5.x. It as possible, but not documented. The best official way to get the full speed of the new ARM processors was to use the OsCall <span>PceNativeCall</span> to jump into a small bit of native ARM code that Palm Inc called "ARMlet"s and later "PNOlet"s. Palm said that only the hottest pieces of code should be treated this way, and it was rather hard to call OsCalls from these bits of native ARM code (you had to call back into <span>PACE</span>, which would marshal the parameters for the native API, and then call it. The ways to call the real Native OsCalls were also not documented.

</p>
<p>PalmOS 5.x kept a lot of the design of PalmOS 4.x, including the shared heap, lack of protected memory, and lack of proper documented multithreading. A new thing was that PalmOS 5.x supported loadable modules. In fact, every Native ARM application or library in PalmOS 5.x is a module. Each module has a module ID, which is required to be system-unique and exist in the range of 0..1023. This is probably why Palm Inc never documented how to produce full Native applications - they could never allow more than 1024 of them to exist.
</p>
<p>PalmOS licensees (sony, handspring, etc) got the sources to the OS and all of this knowledge of course. They were able to customize the OS as needed and then shipped it, but the architecture was always mostly the same. This also aids us a lot.
</p>
<h3>Modules? Libraries? DALs? Drivers?</h3>
<p>The kernel of the OS, memory management, most of the drivers, and low level CPU wrangling is done by the <span>DAL</span>. <span>DAL</span>(Module ID 0) exports about 200 OsCalls, give or take based on the PalmOS version. These are low level things like getting battery state, raw access to screen drawing primitives, module loading and unloading, memory map management, interrupt management, etc. Basically these are functions that no user-facing app would ever need to use. On top of the <span>DAL</span> lives <span>Boot</span>. <span>Boot</span>(Module ID 1) provides a lot of the lower-level user-facing OsCalls. Implemented here are things like the DataManager, MemoryManager, AlarmManager, ExchangeManager, BitmapManager, and WindowManager. Feel free to refer to the PalmOS SDK for details on all of those. On top of <span>Boot</span> lives <span>UI</span>. <span>UI</span>(Module ID 2) provides all of the UI primites to the user. These are things like controls (buttons, sliders, etc), forms, menus, tables, and so on. These three modules together make up the core of PalmOS. You could, in fact, almost boot a ROM containing just these three files.
</p>
<p>These first three modules are actually somewhat special, being the core of the OS. They are always loaded, and their exported functions are always accessible via a special shortcut. For modules 0, 1, and 2, you can call an exported function number N by executing these two instructions: <span>LDR R12, [R9, #-4 * (module_ID + 1)]; LDR PC, [R12, #4 * func_no]</span>. This shortcut exists for easy calls to OsCalls by native modules and only works because these modules are always loaded. This is not a general rule, and this will <em>NOT</em> work for any other modules. You might ask if one can also write to these tables of function pointers to replace them. Yes, yes you can and this was often done by what were called "hacks" and also is liberally used by the OS itself (but not via direct writes but via an OsCall: <span>SysPatchEntry</span>).
</p>
<p>PalmOS lacks any memory protection, any user code can access hardware. PalmOS actually uses this - things like SD card drivers, and drivers for other peripherals are usually separate modules and not part of the <span>DAL</span>. The <span>Boot</span> module will load all PalmOS resource databases of certain types at boot, allowing them to initialize. An incomplete list of these types is: <span>libs</span>(slot driver), <span>libf</span>(filesystem driver), <span>vdrv</span>(serial port driver), <span>aext</span>(system extension), <span>aexo</span>(OEM extension). These things being separate is actually very convenient, since that means that they can be easily removed/replaced. There are of course corner cases, since PalmOS developers never anticipated this. For example, if <em>NO</em> serial drivers are loaded, the OS will crash as it never expected this. Luckily, this is also easy to work around.
</p>
<p>Anytime a module is loaded, the entry point is called with a special code, and the module is free to initialize, set up hardware, etc. When it is unloaded, it gets another code, and can deinitialize. There is another special code modules can get and that is from <span>PACE</span>. If you remember, I said that <span>PACE</span> marshals parameters from m68k apps to OsCalls and back, but <span>PACE</span> cannot possibly know about parameters that a random native library takes, so the marshalling there must be done by the library itself. This special code is used to tell the library to: read parameters from the m68k emulated stack, process them, and put the result unto the emulated m68k registers (<span>PACE</span> exports functions to actually manage the emulated state, so the libraries do not need to know of its insides).
</p>

<h2>Towards the first unauthorized PalmOS port</h2>
<h3>So what's so hard?</h3>
<p>As I mentioned, none of the native API of PalmOS 5.x was ever documented. There was a small number of people who figured out some parts of it, but nobody really got it all, or even close to it. To start with, because large parts are not useful to an app developer, and thus attracted no interest. This is a problem, however, if one wants to make a new device. So I had to actually do a lot of reverse engineering for this project - a lot of boring reverse engineering of very boring APIs that I still had to implement. Oh, and I needed a kernel, and actual hardware to run on.
</p>
<h3>ROM formats are hard</h3>
<p>To start with, I wrote a tool to split apart and put back together working PalmOS ROM images. The format is rather convoluted, and changed between versions, but after a lot of work the "splitrom" tool can now successfully split a PalmOS ROM from pre-release pre-v.1.0 PalmOS devices all the way to the PalmOS 6.0 cobalt ROMs. The "mkrom" tool can now produce valid PalmOS 5.x images - I never bothered to actually make it produce other versions as I did not need it. At this point I took a detour from the project to collect PalmOS ROMs. I now have one from almost every device and prototype. I'll share them with the world later. I tested this by pulling apart a T|T3 ROM, replacing some files, putting it back together, and reflashing my T|T3. It booted! Cool!
</p>
<h3>So write a DAL and you're done!</h3>
<p>I had no hardware to test on, no kernel to use, and a lot more "maybe"s than I was willing to live with, so it was time for action. The quickest way I could think of to try it was to use a real ARM processor and an existing kernel - linux. Since my desktop uses an x86 processor and not ARM, qemu was used. I wrote a basic rudimentary DAL that simply logged any function called and then crashed on purpose. At boot, it did same as PalmOS's <span>DAL</span> does: load <span>Boot</span> and in a new thread call <span>PalmOSMain</span> OsCall. I then wrote a simple "runner" app that used mmap() to map an area of memory at a particular location backed by "rom.bin" and another by "ram.bin" and tried to boot it. I got some logged messages and a crash, as expected. Cool! I guess the concept could work. So, what is the minimum number of functions my <span>DAL</span> needs to boot? Turns out that most of them! Sad day...
</p>
<h3>Minimal DAL</h3>
<p>It took months, but I got most of the <span>DAL</span> implemented, and it ran inside my "runner" inside qemu. It was a very scary setup. Since it was all a userspace app under Linux, I had to call back out to the "runner" to request things like thread creation, etc. It was a mess. Current <b>rePalm</b> code still supports this mode, but I do not expect to use it much, for a variety of reasons. To start with, Linux kernel lacks some API that PalmOS simply needs, for example ability to disable and re-enable task switching. Yup... PalmOS sometimes asks for preemption to be disabled. Linux lacks that ability. PalmOS also needs ability to remotely pause and resume a thread, without the thread's consent. The pthreads library lacks such ability as well. I hacked together some hacks using ptrace, but it was a mess. Fun story: since my machine is multi-core, and I never set any affinities, this was the first time ever that PalmOS ran on a multi-core device. I did not realize it till much later, but that is kind of cool, no?
</p>
<h3>Drawing is hard</h3>
<p>There was one problem. For some reason, things like drawing line, rectangles, circles, and bitmaps were all part of the <span>DAL</span>. Now, it is not hard to draw a line, but things like "draw a rounded rectangle with foreground color of X and a background color of Y, using drawing mode 'mask' on this canvas" or "draw this compresed 16-bit full-color 144ppi image on this 4-bits-per-pixel 108ppi canvas with dithering, respecting transparency colors, and using 'invert' mode" or even "print string 'Preferences' with background color X, foreground Y, text color Z, dotted-underlined, using this low-density font on this 1.5 density canvas" get convoluted quickly. And yes, the <span>DAL</span> is expected to handle this all. Oh, and none of this was ever documented of course! This was a nightmare. At first I treated all drawing functions as NOPs and just logged the drawn text to know how far my boot has gotten. This allowed me to implement many of the other OsCalls that <span>DAL</span> must provide, but eventually I had to face having to draw. My first approach was to just implement things myself, based on function names and some reverse engineering. This approach failed quickly - the matrix of possibilities was simply too large. There are 8 drawing modes, 3 supported densities, 4 image compression formats, 5 supported color depths, and two font formats. It was not possible to think of everything, especially with no way to be sure I had it right. I am not sure if some of these modes ever got exercised by any software in existence at all, but it did not matter - it had to be pixel exact! What to do?
</p>
<h3>Theft is a form of flattery, right?</h3>
<p>I decided on a stopgap measure. I disassembled the Zire72 <span>DAL</span>. And I copied each of the necessary functions, and all the functions they called, and all of the functions those functions called, and so on. I then cleaned up their direct references to Zire <span>DAL</span>'s globals, and to each other, and I stuck it all into a giant "drawing.S" file. It was over 30,000 lines long, and I mostly had no idea how it worked. Or if it worked...
</p>
<p>It did! Not right away, of course, but it did. Colors were messed up, artifacts everywhere, but I saw the touchscreen calibration screen after boot! Success, yes? Well, not even remotely. To start with, it turns out that in the interest of optimization, PalmOS's drawing code happily sticks its fingers into the display driver's globals. My display "driver" at this point was just an area of memory backed by an SDL surface. It took a lot of work (throwaway work - the worst kind) to figure out what it was looking for and give it to it. But after a few more weeks, Zire72's <span>DAL</span>'s drawing code happily ran under <b>rePalm</b> and I was able to see things drawn correctly. After hooking up rudimentary fake touchscreen support, I was even able to interact with the virtual device and see the home screen. Great, but this was all a waste. I do not own that code and cannot ship it. I also cannot improve it, expand it, fix it, or even claim to entirely understand it. This was not a path forward.
</p>
<h3>Meticulously-performed imitation is also a form of flattery, no?</h3>
<p>The time had come. I rewrote the drawing code. Function by function. Line by line. Assembly statement by assembly statement. I tested it after replacing every function as best as I could. Along the way I gained the understanding of how PalmOS draws, what shortcuts for what common cases there are, etc. This effort took two months, after them, 30,000 lines of uncommented assembly turned into 8,000 lines of C. <b>rePalm</b> finally was once again purely my own code! Along the way I optimized a few things and added support for one-and-a-half density, something that the Zire72 <span>DAL</span> never supported. Of all the parts of this project, this was the hardest to slog through, because at the end of every function decoded, understood, and rewritten, there was no noticeable movement forward - the goal was just to not break anything, and there were always dozens of thousands of lines of code to disasemble, understand, and rewrite in C.
</p>
<h3>Virtual SD card</h3>
<p>For testing it would be convenient to be able to load programs easier into the device than baking them into the ROM. I wrote a custom slot driver that did nothing, but only allowed you to use my custom filesystem. That filesystem used hypercalls to reach code in the "runner" to perform filesystem ops on the host. Basically this created a shared folder between my <span>PC</span> and <b>rePalm</b>. I used this to verify that most software and games worked as expected
</p>
<h3>Which device ROM are you using?</h3>
<p>ANY! I tested pre-production Tungsten T image, I tested LifeDrive image, even Sony TH55 ROM boots! Yes, there were custom per-device and per-OS-version tweaks, but I was able to get them to apply automatically at runtime. For example, determining which OS version is running is easily done by examining the number of exported entrypoints of <span>Boot</span>. And determining if the ROM is a Sony device is easy by looking for <span>SonyDAL</span> module. We then refuse to load it, and fake-export equivalent functions ourselves. Why does the <span>DAL</span> need to know the OS version? Some <span>DAL</span> entrypoints changed between PalmOS 5.0 and PalmOS 5.2, and PalmOS 5.4 or later expect a few extra behaviours out of existing funcs that we need to support.
</p>
<h3>So you're done, right? It works?</h3>
<p>At this point, <b>rePalm</b> sort of worked. It was a window on my desktop that ran <em>REAL UNMODIFIED PalmOS</em> with only a single file in the ROM replaced - the <span>DAL</span>. Time to call it done, and pick a new project, right? Well, not quite. Like I said, Linux was not an ideal kernel for this, and making a slightly-more-open PalmOS simulator was not my goal. I wanted to make a device...
</p>

<h2>Towards the first pirate PalmOS device</h2>
<h3>A little bit about normal PalmOS 5.x devices, their CPUs, and the progress since...</h3>
<p>In order to understand the difficulties I faced, it is necessary to explain some more about how PalmOS 5.x devices usually worked. PalmOS 5.x targetted ARMv4T or ARMv5 CPUs. They had 4-32MB of flash or ROM to contain the ROM, and 8-128MB or RAM for runtime allocations and data storage. PalmOS 5.4 added NVFS, which I shall for now pretend does not exist (as we all wished we could when NVFS first came out). ARMv4T and ARMv5 CPUs implement two separate instruction sets: ARM and Thumb. ARM instructions are each exactly 4 bytes, and are the original instruction set for ARM CPUs. Thumb was added in v4T as a method of improving code density. It is a set of 2-byte long instructions that implement the most common operations the code might want to do, and by being half the size improve code density. Obviously, you do not get something for nothing. In the CPUs back then, Thumb instructions had one extra pipeline stage, so this caused them to be slower in code with a lot of jumps. Also, as the instructions themselves were simpler, sometimes it took more of them to do the same thing. Thumb instructions, in most cases, also only have access to half as many registers as ARM instructions, further leading to slightly less optimal code. But, in general Thumb code was smaller, and speed was not a factor, so large parts of PalmOS were compiled in Thumb mode. (Sony bucks this trend, having splurged for larger flash chips and compiling the entire OS in ARM mode). Some things could also not at all be done in Thumb, for example, 32x32-&gt;64 bit multiply, and some were very suboptimal to do in Thumb (like a lot of the drawing code with a lot of complex bit shifts and addressing). These speed-critical pieces were always compiled in ARM mode in PalmOS. Also all library entry points were always in ARM mode with no other options, so even libraries entirely compiled as Thumb, had small thunks from ARM to Thumb mode on each entrypoint.
</p>
<p>How does one actually switch modes between ARM and Thumb in ARMv5? Certain, but not all, instructions that change control flow perform the change. Since all ARM instructions are 4-bytes long and always aligned on a 4-byte boundary, any valid ARM instruction's address has the low two bits cleared. Thumb instructions are 2 bytes long, and thus have the bottom one bit cleared. 32-bit-long Thumb2 instructions are also aligned on a 2-byte boundary. This means that for any instruction in any mode, the lower bit of its address is always clear. ARM used this fact for mode switching. The <span>BX</span> instruction would now look at the bottom bit of the register you're jumping to, and if it was 1, treat the destination as Thumb, else as ARM. Any instruction that loads <span>PC</span> with a word will do the same: <span>POP</span>, <span>LDM</span>, <span>LDR</span> instructions. Arithmetic done on <span>PC</span> in Thumb mode does not change to ARM mode ever (low bit ignored) and arithmetic done on <span>PC</span> in ARM mode is undefined if the lower 2 bits produced are nonzero (<em>CAUTION</em>: this is one of the things that ARMv7 changed: this now has defined behaviour). Also an extra instruction was added for easy calls between modes: <span>BLX</span>. There is a form of it that takes a relative offset encoded in the instruction itself, which basically acts like a <span>BL</span>, but also switches modes to whatever <em>NOT</em> the current mode is. There is also a register mode of it that combines what a <span>BX</span> does with saving the return address. Of course to make sure that returns to Thumb mode work as expected, Thumb instructions that save a return address, namely <span>BL</span> and <span>BLX</span> set the lower bit of <span>LR</span>.
</p>
<p>ARMv5 at this point in time is ancient history. ARM architecture is up to v8.x by now, with 64-bit-wide-registers and a completely different instruction set. ARMv7 is still often seen around (v8 can also run in v7 mode) and is actually an almost perfect (but actually not entirely so) superset of ARMv5. So I could basically take a dev board for any ARMv7 chip, which are abundant and cheap, and use that as my base, right? Technically yes, but I did not go this way. To start with, few of these CPUs are documented well, so unless you use linux kernel, you'll never get them up - writing your own kernel and drivers for them is not feasible (I am looking at you, allwinner). "But," you might object, "what about Raspberry Pi, isn't its CPU fully documented?" I considered it, but discarded the idea - RasPi is terribly unstable, and I had no desire to build on such a shaky platform. Launch firefox on your RasPi, open dailymail or some other complex site, and go away, come back in 2 weeks, I guarantee you'll be greeted by a hung screen and a kernel panic on the serial console. If even Linux kernel developers cannot make this thing work stably, I had no desire to try. No thanks. So what then?
</p>
<h3>ARMv7M</h3>
<p>The other option was to use a microcontroller - they are plentiful, documented, cheap, and available. ARM designs and sells a large number of small cores under the Cortex brand. Cortex-M0/M0+/M1 are cores based on the ARMv6M spec - basically they run the same Thumb instruction set that ARMv5 CPUs did, with a few extra instructions to allow them to manage privileged state (<span>MRS</span>/<span>MSR</span>/<span>CPS</span>). Cortex-M23 is their successor, which adds a few extra instructions (<span>DIV</span>/<span>CBZ</span>/<span>CBNZ</span>/<span>MOVW</span>/<span>MOVT</span>/<span>B.W</span>) which makes it a bit less of a pain in the ass, but it still is very much a pain for complex work. Cortex-M3/M4/M7 implement ARMv7M spec, which has a very expanded Thumb2 instruction set. It is the same instruction set that ARM introduced into the ARM cores back in the day with ARMv6T2 architecture CPUs. These instructions are a mix of 2 and 4-byte long pieces and are actually pretty good for complex code, supporting long multiplies, complex control flow, and bitfield operations. They can also address all registers and not just half of them like the Thumb instruction set of yore. Cortex-M33 is the successor to these, adding a few more things we do not currently care about. Optionally, these cores can also include an FPU for hardware floating point support. We also do not care about that. There is only one problem: <em>None of these CPUs support ARM instuctions</em>. They all only run Thumb/Thumb2. This means we can run most of PalmOS's <span>Boot</span> and <span>UI</span>, but many other things will fail. Not acceptable. Well, actually, since every library has to be entered in ARM mode, nothing will run...
</p>
<h3>My kingdom for an ARM!</h3>
<p>It is at this point that I decided to extend PalmOS's module format to support direct entry into Thumb mode and converted my <span>DAL</span> to this now format. I also taught my module loader to understand when an library's entry point points to a simple ARM-to-Thumb thunk, and to resolve this directly. This allowed an almost complete boot without needing ARM. But this was not a solution. Large parts of the OS were still in ARM mode (things like <span>MemMove</span>, <span>MemCmp</span>, division routines), and if the goal was to run an unmodified OS and apps, editing everything everywhere was not an option. Some things we could just patch via <span>SysPatchEntry</span>. This I did to the abovementioned <span>MemMove</span> and <span>MemCmp</span> for speed, providing optimal Thumb2 implementations. Other things I could do nothing about - things like integer division (which ARMv5 has no instruction for) were scattered in almost every library, and could not be patched away as they were not exported. We really did need something that ran ARM instructions.
</p>
<h3>But what if we try?</h3>
<p>What exactly will happen if we try to switch an ARMv7M microcontroller into ARM mode? The manual luckily is very clear on that. It <em>WILL</em> switch, clear the status bit that indicated we're in Thumb mode, and then when it tries to execute the next instruction, it will take a <span>UsageFault</span> since it cannot execute in this mode. The Thumb <span>BLX</span> instruction of the form that always switches modes is undefined in ARMv7M, and if executed, the CPU will take a <span>UsageFault</span> as well, indicating in invalid instruction. This all sounds grim, but this is actually fantastic news! We can catch a <span>UsageFault</span>... If you see where I am going with this, and are appropriately horrified, thanks for paying attention! We'll come back to this story arc later, to give everyone a chance to catch up.
</p>

<h2>We need hardware, but developing on hardware is ... hard</h2>
<h3>CortexEmu to the rescue</h3>
<p>I thought I could make this all work on a Cortex-M class chip, but I did not want to develop on one - too slow and painful. I also did not find any good emulators for Cortex-M class chips. At this point, I took a two-week-long break from this project to write CortexEmu. It is a fully functional Cortex-M0/M3/M23 emulator that faithfully emulates real Cortex hardware. It has a GDB stub so I can attach GDB to it to debug the running code, It has rudimentary hardware emulated to show a screen, and support an RTC, a console, and a touchscreen. It supports privileged and unprivileged mode, and emulates the memory protection unit (MPU) as well. CortexEmu remains the best way to develop <b>rePalm</b>.
</p>
<h3>Waaaah! You promised real hardware</h3>
<p>Yes, yes, we'll get to that, and a lot more later, but that is still months later in the story, so be patient!
</p>

<h2>Um, but now we need a kernel...</h2>
<h3>Need a kernel? Why not Linux?</h3>
<p>PalmOS needs a kernel with a particular set of primitives. We already discussed some (but definitely not all) reasons why Linux is a terrible choice. Add to that the fact that Cortex-M3 compatible linux is slow <em>AND</em> huge, it was simply not an option. So, what is?
</p>
<p>I ended up writing my own kernel. It is simple, and works well. It will run on any Cortex-M class CPU, supports multithreading with priorities, precise timers, mutexes, semaphores, event groups, mailboxes, and all the primitives PalmOS wants like ability to force-pause threads, and ability to disable task switching. It also takes advantage of the MPU to add some basic safety like stack guards. Also, there is great (&amp; fast) support for thread local storage, which comes in handy later. Why write my own kernel, aren't there enough out there? None of the ones out there really had the primitives I needed and bolting them on would take just as long.
</p>

<h2>So, uh, what about all that pesky ARM code?</h2>
<h3>The ARM code still was a problem</h3>
<p>PalmOS still would not boot all the way to UI because of the ARM code. But, if you remember, as few paragraphs ago I pointed out that we can trap attempts to get into ARM mode. I wrote a <span>UsageFault</span> handler that did that, and then...I emulated it
</p>
<h3>You do not mean...?</h3>
<p>Oh, but I do. I wrote an ARM emulator that would read each instruction and execute it, until the code exited ARM mode, at which point I'd exit the emulation and resume native execution. The actual details of how this works are interesting since the emulator needs its own stack and cannot run on the stack of the emulated code. There also needs to be a place to stash the emulated registers since we cannot just keep them in the real registers (not enough registers for both). Exiting emulation is also kind of fun since you need to load ALL register and status register as well all at once atomically. Not actually trivial on Cortex-M. Well, in any case, "emu.c" and "emuC.c" have the code - go wild and explore.
</p>
<h3>But isn't writing an emulator in C kind of slow?</h3>
<p>You have no idea! The emulator was slow. I instrumented CortexEmu to count cycles, and came up with an average of 170 cycles of host CPU to emulate a single ARM instruction. Not good enough. Not even remotely. It is well known that emulators written in C are slow. C compilers kind of suck at optimizing emulator code. So what next? Well, I went ahead and rewrote the emulator core in assembly. Actually I did it twice. Once for ARMv7M (Cortex-M3 target) and once for ARMv6M (Cortex-M0 target). The speed improved a lot. Now for the M3 core I was averaging 14 cycles per cycle, and for the M0 it was 19. A very respectable emulator performance if I do say so myself.
</p>
<h3>So, is it fast enough now?</h3>
<p>As mentioned before, on original PalmOS devices, ARM code was generally faster than Thumb, so most of the hottest, tightest, fastest code was written in ARM. For us, ARM is 14x slower than Thumb. So the code that was meant to be fastest is slow. But let us take an inventory of this code and see what it really is. Division routines are part of it. ARMv7M implements division in hardware, but ARMv5 did not (nor does ARMv6M). These routines are a hundred cycles or so in ARM mode. <span>MemMove</span>, <span>MemMSet</span> and <span>MemCmp</span> We spoke about already, and we do not care because we replaced them, but lots of libraries had their own internal copies we cannot replace. My guess is that the compiler prefers to inline its own "memset" and "memcpy" in most cases. That made up a large part of the boot process's ARM code usage. Luckily, all of these functions are the same everywhere...
</p>
<p>So, can we pattern-match some of these in the emulator code and execute faster native routines? I did this and boot process did go faster. The average per-instr overhead rose due to matching, but boot time shrank. Cool. But what happens <em>after</em> boot? After boot we meet the real monster... <span>PACE</span>'s m68k emulator is written in ARM. 60 kilobytes of what is clearly hand-written assembly with lots of clever tricks. Clever tricks suck when you're stuck emulating them... So this means that every single m68k application (which is most of them) is now running under double emulation. Gross... Oh, also: slow. Something had to be done. I considered rewriting <span>PACE</span>, but that is a poor solution - there are a lot of ARM libraries and I cannot rewrite them all. Plus, in what way can I claim to be running an unmodified OS if I replace every bit of it?</p>
<p>There is one more way to make non-native code fast...</p>
<h2>You do not mean...? (pt2)</h2>
<h3>Just in time: this</h3>
<p><span>PACE</span> contains a lot of hot code that is static. On real devices it lives in ROM and does not change. Most libraries are the same. So, what can we do to make it run faster? Translate it to what we can run natively, of course. Most people would not take on a task of writing a just-in-time translator alone. But that is just because they are wimps :) (Or maybe they reasonably assume that it is a huge time sink with more corner cases than one could shake a stick at)
</p>
<h3>JITs: how do we start?</h3>
<p>Basically the same way we did for the emulator. We create a per-thread translation cache (TC) which will hold our translations. Why per thread? Because this avoids the problem of one thread flushing the cache while another is running in it with no end in sight. The TC will contain translation units (TU) each of which represents some translated code. Each TU contains its original "source" ARM address, and then just valid Thumb2 code. There will also be a hashtable which will map source "ARM" addresses to a bucket where the first TU for that hash value is stored. Each bucket is a linked list, and 4096 buckets are used. This is configurable. A fast &amp; simple hash is used. Tested on a representative sample of addresses it gave good distribution. Now, whenever we take a <span>UsageFault</span> that indicates an attempted entry to ARM mode, we lookup the desired address in the hashtable. If we get a hit, we simply replace the <span>PC</span> in the exception frame with the "code" pointer of the matching TU and return. The CPU proceeds to execute native code quickly. Wonderful! What if we do not get a hit? We then save the state and replace the <span>PC</span> in the exception frame with the address of the translation code (we do not want to translate in kernel mode).
</p>
<h3>Parlez-vous ARM?</h3>
<p>The front end of a JIT basically just needs to ingest ARM instructions and understand them. We'll trap on any we do not understand, and try to translate all those that we do. Here we hit our first snag. Some games use instructions that are not valid. Bejeweled, I am looking at you! The game "Bejeweled" has some ARM code included in it and it likes to return by executing <span>LDMDB R11, {R0-R12, SP, PC}^</span>. Ignoring the fact that R0-R2 and R12 do not need to be saved and they are being inefficient, that is also not a valid instruction to execute in user mode at all. That little caret at the end means "also transfer <span>SPSR</span> to <span>CPSR</span>". That request is invalid in user mode and ARM architecture reference manual is very clear that executing this in user mode will have undefined effects. This explains why Bejeweled did not run under <b>rePalm</b> under QEMU. QEMU correctly refused to execute this insanity. Well, I dragged out a Palm device out of a drawer and tested to see what actually happens if you execute this. Turns out that it is just ignored. Well, I guess my JIT will do that too. My emulator cores had no trouble with this instr since as this instr is undefined, treating it like it has no caret was safe, and thus they never even checked the bit that indicated it.
</p>
<p>Luckily for us, ARM only has a few instruction formats. Unluckily for us they are all pretty complex. Luckily, decoding is easy. Almost every ARM instruction is conditional and the top 4 bits determine if it executes at all or does not. Data Processing operations are always 3-operand. Destination reg, Source reg, and "Operand" which is ARM's addressing mode 1. It can be an immediate of certain forms, a register, a register shifted by an immediate, or a register shifted by a register. Say what?! Yup, you can do things like <span>ADD R0, R1, R2, ROR R3</span>. Be scared. Be very scared! Setting flags is optional. Loading/storing bytes or words uses addressing mode 2, which allows a use of a register plus/minus an immediate, or register plus/minus register, or register plus/minus register shifted by an immediate. All of these modes can be index, postindex, or index-with-writeback, so scary things like <span>LDR R0, [R1], R2, LSL #12</span> can be concocted. Loading/storing halfwords or signed data uses addressing mode 3, which is just like mode 2 except no register shifts are available. This mode is also used for <span>LDRD</span> and <span>STRD</span> instructions that some ARMv5 cores implement (this is part of the optional DSP extension). Addressing mode 4 is used for <span>LDM</span> and <span>STM</span> instructions, which are terrifying in their complexity and number of corner cases. They can load or store any subset of registers to a given base address with pre-or-post increment-or-decrement and optional writeback. They are used for stack ops. And last, but not least, there are branches which are all encoded simply and decode easily. Phew...
</p>
<h3>2 Thumbs do not make an ARM</h3>
<p>Initially the thought was that the translation cannot be all that hard? The instructions look similar, and it shouldn't be all that bad. Then reality hit. Hard. Thumb2 has a lot of restrictions on operands, like for example <span>SP</span> cannot at all be treated like a general register, and <span>LR</span> and <span>PC</span> cannot ever be loaded together. It also lacks anything equalling addressing mode 1's ability to shift a register by a register as a third operand to an ALU operation. It lacks ability to shift a third register by more than 3, like mode 2 can in ARM. I am not even going to talk about <span>LDM</span> and <span>STM</span>! Oh, and then there is the issue of not letting the translated code know it is being translated. This means that it must still think it is running from original place, and if it reads itself, see ARM instructions. This means that we cannot ever leak PC's real value into any executable state. The practical upshot of that is that we can never emit a <span>BL</span> instruction, and whenever <span>PC</span> is read, we must instead produce an immediate value which is equal to what <span>PC</span> would have been, had the actual ARM code run from its actual place in memory. Not fun...
</p>
<p>Thumb2's <span>LDM</span>/<span>STM</span> actually lack half the modes that ARM has (modes <span>ID</span> and <span>DA</span>) so we'd have to expand those instructions to a lot more code. Oh, and Thumb has limits on writeback that do not match ARM's (more strict) and also you can never use <span>SP</span> in the register set, nor can you ever store <span>PC</span> this way in Thumb2. At this point it becomes abundantly clear that this will not be an easy instruction in -&gt; instruction out job. We'll need places to store temporary immediates, we'll need to rewrite lots of instructions, and we'll need to do it all without causing side effects. Oh, and it should be fast too!
</p>

<h2>A JIT's job is never over</h2>
<h3>LDM and STM, may they burn in hell forever!</h3>
<h4>How LDM/STM work in ARM</h4>
<p>ARM has two multiple-register ops: <span>LDM</span> and <span>STM</span>. Each has a few addressing modes. First is the order: up or down in addresses (that is, does the base register address where to store the lowest-numbered register or highest. Next is whether the base register itself is to be used, or should it be incremented/decremented first. This gives us the four basic modes: <span>IA</span>("increment after"), <span>IB</span>("increment before"), <span>DA</span>("decrement after"), <span>DB</span>("decrement before"). Besides that, it is optional to writeback the updated base address to the base register. There are of course corner cases, like what value gests stored if base register with writeback is stored, or what value the base register will have if loaded, while writeback is also specified. ARM spec explicitly defines some of these cases as having unpredictable consequences.
</p>
<p>For stack, ARM uses a full-descending stack. That means that at any point, the <span>SP</span> register points to the last ALREADY USED stack position. So, to pop a value, you load it from <span>[SP]</span>, and then increment <span>SP</span> by 4. This would be done using an <span>LDM</span> instruction with an <span>IA</span> addressing mode. To push a value unto the stack, one should first decrement <span>SP</span> by 4, and then store the desired value into <span>[SP]</span>. This corresponds to an <span>STM</span> instruction with an <span>DB</span> addressing mode. <span>IB</span> and <span>DA</span> modes are not used for stack in normal ARM code. 
</p>
<h4>How LDM/STM work in Thumb2</h4>
<p>So why did I tell you all this? Well, while designing the Thumb2 instruction set, ARM decided what to support and what not to. This basically meant that uncommon things did not get carried forward. Yup...you see where this is going. Thumb2 does not support <span>IB</span> and <span>DA</span> modes. At all. Not cool. But there is more. Thumb2 forbids using <span>PC</span> or <span>SP</span> registers in the list of registers to be stored for <span>STM</span>. Thumb2 also forbids ever loading <span>SP</span> using <span>LDM</span>, also if an <span>LDM</span> loads <span>PC</span>, it may not also load <span>LR</span>, and if it loads <span>LR</span>, it may not also load <span>PC</span>. There is more yet... <span>PC</span> is not allowed as the base register, and the register list must be at least two registers long. This is a somewhat-complete list of what Thumb2 is missing compared to ARM.
</p>
<p>But wait, there is more. Even the instrutions that map nicely from ARM to Thumb2 and comply with all the restrictions of Thubm2 are not that simple to translate. For example, storing <span>PC</span>, is as always hard - we need a spare register to store the expected PC value so we can push it. But, registers are pushed in order, so depending on what register we pick as our temporary reg, it might be out of other relative to others, we might need to split the store into a few stores. But, there is more yet. What if the store was to <span>SP</span> or included <span>SP</span>? We changed SP by pushing our temp reg, so we need to adjust for that. But what if this was a <span>STMDB SP!</span>(aka: <span>PUSH</span>). Then we cannot pre-push a temp register that easily...
</p>
<h4>But wait, there's more ... pain</h4>
<p>There is another complication. <span>LDM</span>/<span>STM</span> is expected to act as an atomic instruction to userspace. It is either aborted or resumable at system level. But in Thumb2 in Cortex-M chips, <span>SP</span> is special since the exception frame gets stored there. This means that <span>SP</span> must always be valid, and any data stored BELOW <span>SP</span> is not guaranteed to ever persist (since an interrupt may happen anytime). Luckily, on ARM it was also discouraged to store data below <span>SP</span> and this was rarely done. There is one common piece of PalmOS code that does this: the code around <span>SysLinkerStub</span> that is used to lazy-load libraries. For other reasons rePalm replaced this code anyways though. In all other cases the JIT will emit a warning if an attempt is made to load/store below <span>SP</span>.
</p>
<p>As you see, this is very very very complex. In fact, the complete code to translate <span>LDM</span>/<span>STM</span> ended up being just over four thousand lines long and the worst-case translation can be 60-ish bytes. Luckily this is only for very weird instructions the likes of which I have never seen in real code. "So," you might ask, "how could this be tested if no code uses it?" I actually used a modified version of my <a href="https://github.com/uARM-Palm/uARM">uARM</a> emulator to emulate both orignal code and translated code to verify that each destination address is loaded/stored once exactly and with proper vales only, and then made a test program that would generate a lot of random valid <span>LDM</span>/<span>STM</span> instructions. It was then left to run over a few weeks. All bugs were exterminated with extreme prejudice, and I am now satisfied that it works. So here is how the JIT handles it, in general (look in "emuJit.c" for details).
</p>
<h4>Translating LDM/STM</h4>
<ol><li>Check if the instruction triggers any undefined behaviour, or is otherwise not defined to act in a particular way as per the ARM Architecture Reference Manual. If so, log an error and bail out.</li><li>Check if it can be emitted as a Thumb2 <span>LDM</span>/<span>STM</span>, that is: does it comply with ALL the restrictions Thumb2 imposes, and if so, and also if <span>PC</span> is not being stored, emit a Thumb2 <span>LDM</span>/<span>STM</span></li><li>Check if it can be emitted as a <span>LDR</span>/<span>STR</span>/<span>LDRD</span>/<span>STRD</span> while complying with Thumb2 limits on those. If so, that is emitted.</li><li>A few special fast cases to emit translations for common cases that are not covered by the above (for example ADS liked to use <span>STMIB</span> for storing function parameters to stack)</li><li>For unsupported modes <span>IB</span> and <span>DA</span>, if no writeback is used, they can be rewritten in terms of the supported modes.</li><li>If instruction loads <span>SP</span>, it is impossible to emit a valid translation due to ohw ARMv7-M uses <span>SP</span>. For this one special case, the JIT emits a special undefined instruction and we trap it and emulate it. Luckily no common code uses this ever!</li><li>Finally, the generic slow path is taken:<ol><li>Generate a list of registers to be loaded/stored, and at what addresses.</li><li>Calculate writeback if needed.</li><li>If needed, allocate a temporary register or two (we need two if storing PC and SP) and spill their contents to stack</li><li>For all registers left to be loaded/stored, see how many we can load/store at once, and do so. This involves emitting a set of instructions: <span>LDR</span>/<span>STR</span>/<span>LDRD</span>/<span>STRD</span>/<span>LDM</span>/<span>STM</span> until all is done.</li><li>If we had allocated temporary registers, restore them</li></ol></li></ol>

<h3>Slightly less hellish instructions</h3>
<p>Addressing mode 1 was hard as well. Basically thanks to those rotate-by-register modes, we need a temporary register to calculate that value, so we can then use it. If the destination register is not used, we can use that as temp storage, since it is about to be overwritten anyways by the result, unless it is also one of the other source operands..or <span>SP</span>...or <span>PC</span>... oh god, this is becoming a mess. Now what if <span>PC</span> is also an operand? We need a temporary register to load the "fake" <span>PC</span> value into before we can operate on it. But once again we have no temporary registers. This got messy very quickly. Feel free to look in "emuJit.c" for details. Long story short: we do our best to not spill things to stack but sometimes we do have to.
</p>
<p>The same applies to some complex addressing modes. Thumb2 optimized its instructions for common cases, which makes uncommon cases very hard to translate. Here it is even harder to find temporary registers, because if we push anything, we might need to account for that if our base register is <span>SP</span>. Once again: long story, scary story, see "emuJit.c". Basically: common things get translated efficiently, uncommon ones are not. Special case is PC-based loads. These are used to load constant data. In most cases we inline the constant data into the produced translations for speed. 
</p>
<h3>Conditional instructions</h3>
<p>Thumb2 does have ways to make conditional instructions: the <span>IT</span> instruction that makes the next 1-4 instructions conditional. I chose not to use it due to the fact that it also changes how flags get set by 2-byte Thumb instructions and I did not want to special case it. Also sometimes 4 instructions are not enough for a translation. Eg: some <span>STMDA</span> instructions expand to 28 instructions or so. I just emit a branch of opposite polarity (condition) over the translation. This works since these branches are also just 2 bytes long for all possible translation lengths.
</p>
<h3>Jumps &amp; Calls</h3>
<p>This is where it gets interesting. Basically there are two type of jumps/calls. Those whose destinations are known at translation time, and those whose are not. Those whose addresses are known at translation time are pretty simple to handle. We look up the destination address in our TC. If it is found, we literally emit a direct jump to that TU. This makes hot loops fast - no exit from translated code is needed. Indirect or computed jumps are not common, so one would think that they are not that important. This is wrong because there is one type of such jump that happens a lot: function return. We do not, at translation time, know where the return is going to go to. So how do we handle it? Well, if the code directly loads <span>PC</span>, everything will work as expected. Either it will be an ARM address and our <span>UsageFault</span> handler will do its thing or it will be a Thumb address and our CPU will jump to it directly. An optimization exists in case an actual <span>BX LR</span> instruction is seen. We then emit a direct jump to a function that looks up <span>LR</span> in the hash - this saves us the time needed to take an exception and return from it (~60 cycles). Obviously more optimizations are possible, and more will be added, but for now, this is how it is. So what do we do for a jump whose destination is known and we haven't yet translated it? We leave ourselves a marker, namely an instruction we know is undefined, and we follow that up with the target address. This way if the jump is ever actually taken (not all are), we'll take the fault, translate, and then replace that undefined instr and the word following it with an actual jump. Next time that jump will be fast, taking no faults.
</p>
<h3>Translating a TU</h3>
<p>The process is easy: translate instructions until we reach one that we decide is terminal. What is terminal? An unconditional branch is terminal. A call is too (conditional or not). Why? Because someone might return from it, and we'd rather have the return code be in a new TU so we can then find it when the return happens. An unconditional write to <span>PC</span> of any sort is terminal as well. There is a bit of cleverness also for jumps to nearby places. As we translate a TU, we keep track of the last few dozen instructions we translated and where their translations ended up. This way if we see a short jump backwards, we can literally inline a jump to that translation right in there, thus creating a wonderfully fast translation of this small loop. But what about short jumps forward? We remember those as well, and if before we reach our terminal instr we translate an address we remembered a past jump to from this same TU, we'll go back and replace that jump with a short one to here.
<a name="_TOC_d8be03a7734ce336e0e95c12bed0d3d7"></a></p><h3>And if the TC is full?</h3>
<p>You might notice that I said we emit jumps between TUs. "Doesn't this mean," you might ask, "that you cannot just delete a single TU?" This is correct. Turns out that keeping track of which TUs are used a lot and which are not is too much work, and the benefits of inter-TU jumps are too big to ignore. So what do we do when the TC is full? We flush it - literally throw it all away. This also helps make sure that old translations that are no longer needed eventually do get tossed. Each thread's TC grows up to a maximum size. Some threads never run a lot of ARM and end up with small TCs. The TC of the main UI thread will basically always grow to the maximum (currently 32KB).
</p>
<h3>Growing up</h3>
<p>After the JIT worked, I <em>rewrote it</em>. The initial version was full of magic values and holes (cases that could happen in legitimate code but would be mistranslated). It also sometimes emitted invalid opcodes that Cortex-M4 would still execute (despite docs saying they were not allowed). The JIT was split into two pieces. The first was the frontend that ingested ARM instructions, maintained the TC, and kept track of various other state. The second was the backend. The backend had a function for each possible ARMv5 addressing mode or instruction format, and given <b>ANY</b> valid ARMv5 instruction, it could produce a sequence of ARMv7M instructions to perform the same task. For common cases the sequence was well optimized, for uncommon ones, it was not. However, the backend handles <em>ANY</em> possible valid ARMv5 request, even insane things like, for example,  <span>RSBS PC, SP, PC, ROR SP</span>. No sane person would ever produce this instruction, but the backend will properly translate it. I wrote tests and ran them automatically to verify that all possible inputs are handled, and correctly so. I also optimized the hottest path in the whole system - the emulation of the <span>BLX</span> instruction in thumb. It is now a whopping 50 cycles faster, which noticeably impacted performance. As an extra small optimization, I noticed that oftentimes Thumb code would use a <span>BLX</span> simply to jump to an OsCall (which due to using R12 and R9 cannot be written in Thumb mode). The new <span>BLX</span> handler detects this and skips emulation by calling the requisite OsCall directly.
</p>
<p>I then wrote a sub-backend for the EDSP extension (ARMv5E instructions) since some Sony apps use them. The reason for a separate sub-backend is that ARMv7E (Cortex-M4) has instructions we can use to translate EDSP instructions very well, while ARMv7 (Cortex-M3) does not, and requires longer instruction sequences to do the same work. rePalm supports both.
</p>
<p>Later, I went back and, despite it being a huge pain, worked out a way to use the <span>IT</span> instruction on Cortex-M3+. This resulted in a huge amount of code refactoring - basically pushing "condition code" to every backend function and expecting it to conditionalize itself however it wishes. This produced a change with an over-4000-line diff but it workes very well and resulted in a noticeable speed icnrease!
</p>
<h3>The Cortex-M0 backend</h3>
<h4>Why this is insane</h4>
<p>It was quite an endeavor, but I wanted to see if I could make a working Cortex-M0 backend for my JIT. Cortex-M0 executes the ARMv6-m instruction set. This is basically just Thumb-1, with a few minor additions. Why is this scary? In Thumb-1, most instructions only have access to half the registers (r0..r7). Only three instructions have access to high registers: <span>CMP</span>, <span>MOV</span>, and <span>ADD</span>. Almost all Thumb-1 instructions always set flags. There are also no long-multiply instructions in Thumb-1. And, there is no <span>RRX</span> rotation mode at all. The confluence of all these issues makes attempting a one-to-one instruction-to-instruction translation from ARM to Thumb-1 a non-starter.
</p>
<p>To make it all work, we'll need some temporary working space: a few registers. It is all doable with three with a lot of work, and comfortable with four. So I decided to use four work registers. We'll also need a register to point to our context (the place where we'll store extra state). And, for speed, we'll want a reg to store the virtual status register. Why do we need one of those? Because almost all of our Thumb-1 instructions clobber flags, whereas the ARM code we're translating expects flags to stick around during long instruction sequences. So our total is: 6. We need 6 registers. They need to be low registers since, as we had discussed, high registers are basically useless in Thumb-1. 
</p>
<h4>The basics</h4>
<p>Registers r0 through r3 are temporary work registers for us. The r4 register is where we keep our virtual status register, and r5 points to our context. We use r12 as another temporary. Yes it is a high-reg but sometimes we really just need to store something, so only being able to <span>MOV</span> something in and out of it is enough. So, what's in a context? Well, then state of the virtual r0 through r5 registers, as well as the virtual r12 and the virtual lr register. There, obviously, needs to be a separate context for every thread, since they may each run different ARM code. We allocate one the first time a thread runs ARM (it is actually part of the JIT state, and we copy it if we reallocate the JIT state). 
</p>
<p>"But," you might say, "if PalmOS's Thumb code expects register values in registers, and our translated ARM code keeps some of them in a weird context structure, how will they work together?" This is actually complex. Before every translation unit, we emit a prologue. It will save the registers from our real registers into the context. At the end of every translation unit, we emit an epilogue that restores registers from the context into the real registers. When we generate jumps between translation units, we jump past these pieces of code, so as long as we are running in the translated code, we take no penalty for saving/restoring contexts. We only need to take that penalty when switching between translated code and real Thumb code. Actually, it turns out that the prologue and epilogue are large enough that emitting then inside every TU is a huge waste of space, so we just keep a copy of each inside a special place in the context, and have each TU just call them as needed. A later speed improvement I added was to have multiple epilogues, based on whether we know that the code is jumping to ARM code, Thumb code, or "not sure which". This allows us to save a few cycles on exiting translated code. Every cycle counts!
</p>
<h4>Fault dispatching</h4>
<p>There is just one more problem: Those <span>BLX</span> instructions in Thumb mode. If you remember, I wrote about how they do not exist in ARMv7-m. They also do not exist in ARMv6-m. So we also need to emulate them. But, unlike ARMv7-m, ARMv6-m has no real fault handling ability. All faults are considered unrecoverable and cause a <span>HardFault</span> to occur. Clearly something had to be done to work around that. This actually led to a rather large side-project, which I published separately: <a href="https://dmitry.gr/?r=05.Projects&amp;proj=27.%20m0FaultDispatch">m0FaultDispatch</a>. In short: I found a way to completely and correctly determine the fault cause on the Cortex-M0, and recover as needed from many types of faults, including invalid memory accesses, unaligned memory accesses, and invalid instructions. With this final puzzle piece found, the Cortex-M0 JIT was functional.
</p>


<h2>Is PACE fast enough?</h2>
<h3>Those indirect jumps...</h3>
<p>Unfortunately, emulation almost always involves a lot of indirect jumps. Basically that is how one does instruction decoding. 68k being a CISC architecture with variable-length instructions means that the decoding stage is complex. <span>PACE</span>'s emulator is clearly hand-written in assembly, with some tricks. It is all ARM. It is actualy the same instruction-for-instruction from PalmOS 5.0 to PalmOS 5.4. The surrounding code changed, but the emulator core did not. This is actually good news - means it was good as is. My JIT properly and correctly handles translating <span>PACE</span>, as evidenced by the fact that rePalm works on ARMv7-M. The main problem is that every instruction emulated requires at least one indirect jump (for common instructions), two for medium-comonness ones, and up to three some some rare ones. Due to how my JIT works, each indirect jump that is not a function return requires an exception to be taken (14 cycles in, 12 out), some glue code (~30 cycles), and a hash lookup (~20 cycles). So even in case that the target code has been translated, this adds 70-ish cycles to each indirect jump. This puts a ceiling on the efficiency of the 68k emulator at 1/70th the speed. Not great. <span>PACE</span> usually is about 1/15 the speed of the native code, so that is quite a slowdown. I considered writing better translation just for <span>PACE</span>, but it is quite nontrivial to do fast. Simply put, there isn't a simple fast way to translate something like <span>LDR R0, [R11, R1, LSL #2]; ADD PC, R11, R0</span>. There simply is no way to know where that jump will go, or that even R11 points to a location that is immutable. Sadly that is what <span>PACE</span>'s top level dispatch looks like.
</p>
<h3>A special solution for a special problem</h3>
<p>I had already fulfilled my goal of running PalmOS unmodified - <span>PACE</span> does work with my JIT, and the OS is usable and not slow, but I wanted a better solution and decided that <span>PACE</span> is a unique-enough problem to warrant it. The code emulator in <span>PACE</span> has a single entry point, and only calls out to other code in a 10 clear cases: Line1010 (instruction starting with 0xA), Line1111 (instruction starting with 0xF), TRAP0, TRAP8, TRAPF (OsCall), Division By Zero, Illegal instrction, Unimplemented instruction, Trace Bit being set, and hitting a PC value of precisely 0xFFFFFFF0. So what to do? I wrote a tool "patchpace" that will take in a PACE.prc from any PalmOS device, analyze it to find where those handlers are in the binary, and find the main emulator core. It will then replace the core (in place if there is enough space, appended to the binary if not) with code you provide. The handler addresses will be inserted into your code at offsets the header provides, and a jump to your code will be placed where the old emulator core was. The header is very simple (see "patchpace.c") and just includes halfword offsets from the start of the binary to the entry, and to where to insert jumps to each of the abovementioned handlers as <span>BL</span> or <span>BLX</span> instructions). The only param to the emulator is the state. It is structured thusly: first word is free for emulator to use as it pleases, then 8 D-regs, then the 8 A-regs, then PC, and then SR. No further data is allowed (PACE uses data after here). This same state must be passed to all the handlers. TRAPF handler also needs the next word passed to it (OsCall number). Yes, you understand this correctly, this allows you to bring your own 68k emulator to the party. Any 68k emulator will do, it does not need to know anything about PalmOS at all. Pretty sweet!
</p>
<h3>Any 68k emulator...</h3>
<p>So where do we get us a 68k emulator? Well, anywhere? I wrote a simple one in C to test this idea, and it worked well, but really for this sort of thing you want assembly. I took PACE's emulator as a style guide, and did a <em>LOT</em> of work to produce a thumb2 68k emulator. It is much more efficient than PACE ever was. This is included in the "mkrom" folder as "PACE.0003.patch". As stated before, this is entirely optional and not required. But it does improve raw 68k speed by about 8.4x in the typical case.
</p>

<h2>But, you promised hardware...</h2>
<h3>Hardware has bugs</h3>
<p>I needed a dev board to play with. The STM32F429 discovery board seemed like a good start. It has 8MB of RAM which is enough, 2MB of flash which is good, a display with a touchscreen. Basically it is perfect on paper. Oh, if only I knew how imperfect the reality is. Reading the STM32F429 reference manual it does sound like the perfect chip for this project. And ST does not quite go out of their way to tell you where to find the problems. The errata sheet is damning. Basically if you make the CPU run from external memory, put the stack in external memory, and SDRAM FIFO is on, exceptions will crash the chip (incorrect vector address read). OK, I can work around that - just turn off the FIFO. Next erratum: Same story but if the FIFO is off, sometimes writes will be ignored and not actually write. Ouchy! Fine! I'll move my stacks to internal RAM. It is quite a rearchitecturing, but OK, fine! Still crashes. No errata about that! What gives? I removed <b>rePalm</b> and created a 20-line repro scenario. This is not in ST's errata sheet, but here is what I found: if <span>PC</span> points to external RAM, and <span>WFI</span> instruction is executed (to wait for interrupts in a low power mode), and then an interrupt happens after more than 60ms, the CPU will take a random interrupt vector instead of the correct one after waking up! Just imagine how long that took to figure out! How many sleepless nights ripping my hair out at random crashes in interrupt handlers that simply could not possibly be executing at that time! I worked around this by not using WFI. Power is obviously wasted this way, but this is ok for development for now, until I design a board with a chip that actually works!
</p>
<p>Next issue: RAM adddress. STM32F429 supports two banks of RAM 0 and 1. Bank 0 starts at <span>0xC0000000</span> and Bank 1 at <span>0xD0000000</span>. This is a problem because PalmOS needs both RAM and flash to be below <span>0x80000000</span>. Well, we're lucky. RAM Bank 0 is remappable to <span>0x00000000</span>. Sweet.... Until you realize that whoever designed this board hated us! The board only has one RAM chip connected, so logically it is Bank 0. Right? Nope! It is Bank 1, and that one is not remappable. Well, damn! Now we're stuck and this board is unusable to boot PalmOS. The <span>0x80000000</span> limit is rather set in stone.
</p>
<h3>So why the 0x80000000 limit?</h3>
<p>PalmOS has two types of memory chunks: movable and nonmovable. This is what an OS without access to an MMU does to avoid too much memory fragmentation. Basically when a movable chunk is not locked, the OS can move it, and one references it using a "handle". One can then lock it to get a pointer, use it, and then unlock when done. So what has this got to do with <span>0x80000000</span>? PalmOS uses the top bit of a pointer to indicate if it is a handle or an actual pointer. The top bit being set indicates a handle, clear indicates a pointer. So now you see that we cannot really live with RAM and ROM above <span>0x80000000</span>. But then again, maybe...
</p>
<h3>Two wrongs do not make a right, but do two nasty hacks?</h3>
<p>Given that I've already decided that this board was only for temporary development, why not go further? Handle-vs-pointer disambiguation is only done in a few places. Why not patch them to invert the condition? At least for now. No, not at runtime. I actually disassembled and hand-patched 58 places total. Most were in <span>Boot</span>, where the MemoryManager lives, a few were in <span>UI</span> since the code for text fields likes to find out of a pointer passed to it is a pointer (noneditable) or a handle (editable). There were also a few in <span><span>PACE</span></span> since m68k had a SysTrap to detemine the kind of pointer, which <span><span>PACE</span></span> implemented internally. Yes, this is not anymore "unmodified PalmOS" but this is only temporary, so I am willing to live with it! But, you might ask, didn't you also say that ROM <em>and</em> RAM both need to be below <span>0x80000000</span>? If we invert the condition, we need them both above. But flash is at <span>0x08000000</span>... Oops. Yup, we cannot use flash anymore. I changed the RAM layout again, carving out 2MB at <span>0xD0600000</span> to be the fake "ROM" and I copy the flash to it at boot. It works!
</p>


<h2>Tales of more PalmOS reverse engineering</h2>
<h3>SD-card Support</h3>
<p>Luckily, I had written a slot driver for PalmOS before, so writing an SD card driver was not hard. In fact, I reused some PowerSDHC source code! rePalm supports SD cards now on the STM32F469 dev board. On the STM32F429 board, they are also supported, but since the board lacks a slot, you need to wire them up yourself (CLK -&gt; C12, CMD -&gt; D2, DAT_0 -&gt; C8). Due to how the board is already wired, only one-bit-wide bus will work (DAT_1 and DAT_2 are used for other tthings and cannot be remapped to other pins), so that limits the speed. Also since your wires will be long and floppy, they maximum speed is also limited. This means that on the STM32F429 the speed is about 4Mbit/sec. On the STM32F469 board the speed is a much more respectable 37MBit/sec. Higher speeds could be reached with DMA, but this is good enough for now. While writing the SD card support for the STM32F4 chips, I found a hardware bug, one that was very hard to debug. The summary is this: SD bus allows the host to stop the clock anytime. So the controller has a function to stop it anytime it is not sending commands or sending/receiving data. Good so far. But that data lines can also be used to signal that the card is busy. Specifically, the DAT_0 line is used for that. The problem is that most cards use the clock line as a reference as to when they can change the state of the DAT lines. This means that if you do something that the card can be busy after, like a write, and then shut down the clock, the card will keep the DAT_0 line low forever, since it is waiting for the clock to tick to raise it. "So," you will ask, "why not enable clock auto-stopping except for this one command?" It does not work since clock auto-stopping cannot be easily flipped on and off. Somehow it confuses the module's internal state machine if it is flipped while the clock is running. So, why stop the clock at all? Minor power savings. Definitely not enough to warrant this mess, so I just disabled the auto-stopping function. A week to debug, and a one line fix! The slot driver can be seen in the "slot_driver_stm32" directory.
</p>
<h3>Serial Port Support</h3>
<p>Palm Inc did document how to write a serial port driver for PalmOS 4. There were two types: virtual drivers and serial drivers. The former was for ports that were not hardwired to the external world (like the port connected to the bluetooth chip or the Infra-red port), and the second for ports that were (like the cradle serial port). PalmOS 5 merged the two types into a unified "virtual" type. Sadly this was not documented. It borrowed from both port types in PalmOS 4. I had to reverse engineer the OS for a long time to figure it out. I produced a working idea of how this works on PalmOS 5, and you can see it in "vdrvV5.h" include file. This information is enough to produce a working driver for a serial port, IrDA SIR port, and USB for HotSync purposes.
</p>
<p>Actually making the serial port work on the STM32F4 hardwre was a bit hard. The hardware has only a single one-byte buffer. This means that to not lose any received data at high data rates, one needs to use hardware flow control or make the serial port interrupt the highest priority and hope for the best. This was unacceptable for me. I decided to use DMA. This was a fun chance to write my first PalmOS 5 library that can be used by other libraries. I wrote a DMA library for STM32F4-series chips. The code is in the "dma_driver_stm32" directory. With this, one would think that all would be easy. No. DMA needs to know how many bytes you expect to receive. In case of generic UART data receive, we do not know this. So how do we solve this? With cleverness. DMA can interrupt us when half of a transfer is done, and again when it is all done. DMA can be circular (restart from beginning when done). This gets us almost as far as we need to go. Basically as long as data keeps arriving, we'll keep getting one of these interrupts, and then the other in order. In our interrupt handler, we just need to see how far into the buffer we are, and report the bytes since last time we checked as new data. As long as our buffer is big enough that it does not overflow in the time it takes us to handle these interrupts we're all set, right? Not quite. What if we get just one byte? This is less than half a transfer so we'll never get an interrupt at all, and thus will never report this to the clients. This is unacceptable. How? STM32F4 UART has "IDLE detect" mode. This will interrupt us if after a byte has been RXed, four bit times have expired with no further character starting. This is basically just what we need. If we wire this interrupt to our previous handling code for the circular buffer, we'll always be able to receive data as fast as it comes, no matter the sizes. Cool! The Serial driver I produced does this, and can be seen in the "uart_driver_stm32" directory. I was able to successfully Hotsync over it! IrDA is supported too. It works well. See the photo album for a video demo!
</p>
<h4>Yes, you can try it!</h4>
<p>If you want to try, on the STM32F429 discovery board, the "RX" unpopulated 0.1 inch hole is the STM32's transmit (yes I know, weird label for a transmit pin). B7 is STM32's receive pin. If you connect a USB-to-serial adapter there, you can hotsync over serial. If you instead connect an IrDA SIR transceiver there, you'll get working IR. I used MiniSIR2 transceiver from Novalog, Inc. It is the same one as most Palm devices use.
</p>
<h3>Vibrate &amp; LED support</h3>
<p>Adding vibration and LED support was never documented, since those are hardware features that vendors handle. Luckily, I had reverse engineered this a long time ago, when I was <a href="http://www.palminfocenter.com/news/8274/adding-vibration-alarm-to-the-palm-tx/">adding vibration support to T|X</a>. Turns out that I almost got it all right back then. A bit more reverse engineering yielded a complete result of the proper API. LED follows the same API as vibrator: one "GetAttributes" function and one "SetAttributes" function. The settable things are the pattern, speed, delay in betweern repetitions, and number of repetitions. The OS uses them as needed and automatically adds "Vibrate" and "LED" settings to "Sounds and Alerts" preferences panel if it notices the hardware is supported. And rePalm now supports both! The code is in "halVibAndLed.c", feel free to peruse it at your leisure.
</p>
<h3>Networking support (WIP)</h3>
<h4>False starts</h4>
<p>I really wanted to add support for networking to rePalm. There were a few ways I could think of to do that, such that all existing apps would work. One could simply replace <span>Net.lib</span> with one with a similar interface but controlled by me. I could then wire it up to any interface I wanted to, and all would be magical. This is a poor approach. To start with, while large parts of <span>Net.lib</span> are documented, there are many parts that are not. Having to figure them out would be hard, and proving correctness and staying bug-compatible even more so. Then there is the issue with wanting to run an unmodified PalmOS. Replacing random libraries diminishes the ability to claim that. No, this approach would not work. The next possibility was to make a fake serial interface, and tell PalmOS to connect via it, via SLIP or PPP to a fake remote machine. The other end of this serial port could go to a thread that talks to our actual network interface. This can be made to work. There would be overhead of encoding and decoding PPP/SLIP frames, and the UI would be confusing and all wrong. Also, I'd need to find ways to make the config UI. This is also quite a mess. But at least this mess is achievable. But maybe there is a better approach?
</p>
<h4>The scary way forward</h4>
<p><em>Conceptually</em>, there is a better approach. PalmOS's <span>Net.lib</span> supports pluggable network interfaces (I call it a NetIF driver). You can see a few on all PalmOS devices: PPP, SLIP, Loopback. Some others also have one for WiFi or Cellular. So all I have to do is produce a NetIF driver. Sounds simple enough, no? Just as you'd expect, the answer is a strong, resounding, and unequivocal "no!" Writing NetIF drivers was never documented. And a network interface is a lot harder than a serial port driver (which was the previous plug-in driver interface of PalmOS that I had reverse engineered). Reverse engineering this would be hard.
</p>
<h4>Those who study history...</h4>
<p>I started with some PalmOS 4.x devices and looked at SLIP/PPP/Loopback NetIF drivers. Why? Like I had mentioned earlier, in 68k, the compiler tends to leave function names around in the binary unless turned off. This is a huge help in reverse engineering. Now, do not let this fool you, function names alone are not <em>that</em> much help. You still need to guess structure formats, parameters, etc. Thus despite the fact that <span>Net.lib</span> and NetIF driver interface both changed between PalmOS 4.x and PalmOS 5.x, figuring out how NetIF drivers worked in PalmOS 4.x would still provide some foundational knowledge. It took a few weeks until I thought I had that knowledge. Then I asked myself: "Was there a PalmOS 4.x device with WiFi?" Hm... There was. Alphasmart Dana Wireless had WiFi. Now that I thought I had a grip on the basics of how these NetIF drivers worked, it was time to look at a more complex one since PPP, SLIP, and Loopback are all very simple. Sadly, Alphasmart's developers knew how to turn off the insertion of function names into the binary. Their WiFi driver was still helpful, but it took weeks of massaging to make sense of it. It is approximately at this point that I realized that <span>Net.lib</span> had many versions and I had to look at others. I ended up disassembling each version of <span>Net.lib</span> that existed to see the evolution of the NetIF driver interface and <span>Net.lib</span> itself. Thus I looked at Palm V's version, Palm Vx's, Palm m505's, and Dana's. The most interesting changes were with v9, where support for ARP &amp; DHCP was merged into <span>Net.lib</span>, whereas previously each NetIF driver that needed those, embedded their own logic for them.
</p>
<h4>On to OS 5's Net.lib</h4>
<p>This was all nice and great, but I was not really in this to understand how NetIF drivers worked in PalmOS 4.x. Time had come to move on to reverse-engineering how PalmOS 5.x did it. I grabbed a copy of <span>Net.lib</span> from the T|T3, and started tracing out its functions, matching them up to their PalmOS 4.x equivalents. It took a few more weeks, but I more or less understood how PalmOS 5.x <span>Net.lib</span> worked.
</p>
<h4>I found a bug!</h4>
<p>Along the way I found an actual bug: a use-after-free in arp_close()
</p>
<p>NETLIB_T3:0001F580                 CMP             R4, #0        ; Linked list is empty?
NETLIB_T3:0001F584                 BEQ             loc_1F5A4     ; if so, lust skip this entire thing
NETLIB_T3:0001F588                 B               loc_1F590     ; else go free it one-by-one
NETLIB_T3:0001F58C
NETLIB_T3:0001F58C loc_1F58C:
NETLIB_T3:0001F58C                 BEQ             loc_1F598     ; this instr here is harmless, but makes no sense! We only get here on "NE" condition
NETLIB_T3:0001F590
NETLIB_T3:0001F590 loc_1F590:
NETLIB_T3:0001F590                 MOV             R0, R4        ; free the node
NETLIB_T3:0001F594                 BL              MemChunkFree  ; after this, memory pointed to by R4 is invalid (freed)
NETLIB_T3:0001F598
NETLIB_T3:0001F598 loc_1F598:
NETLIB_T3:0001F598                 LDR             R4, [R4]      ; load "-&gt;next" from now-invalid memory...
NETLIB_T3:0001F59C                 CMP             R4, #0        ; see if it is NULL
NETLIB_T3:0001F5A0                 BNE             loc_1F58C     ; and if not, loop to free that node too
NETLIB_T3:0001F5A4 loc_1F5A4:
</p>
<h4>Well, that was easy...</h4>
<p>Then I started disassembling PalmOS 5.x SLIP/PPP/Loopback NetIF drivers to see how they had changed from PalmOS 4.x. I assumed that nobody really changed their logic, so any changes I see could be hints on changed in the <span>Net.lib</span> and NetIF structure between PalmOS 4.x and PalmOS 5.x. It turned out that not that much had changed. Structures got realigned, a few attribute values got changed, but otherwise it was pretty close. It is at this point that I congratulated myself, and decided to start writing my own NetIF driver to test my understanding.
</p><h4>NOT!</h4>
<p>The self-congratulating did not last long. It turned out that in my notes I marked a few things I had thought inconsequential as "to do: look into this later". Well, it appears that they were not inconsequential. For example: the callback from DHCP to the NetIF driver to notify it of DHCP status was <em>NOT</em> purely informative as I had thought, and in fact a large amount of logic has to exist inside it. That logic, in turn, touches the insides of the DhcpState structure, half of which I had not fully understood since I thought it was opaque to the NetIF driver. Damn, well, back to IDA and more reverse engineering. At some point in time here, to understand what various callbacks between <span>Net.lib</span> and the NetIF driver did, I realized that I need to understand DHCP and ARP a lot better than I did. After sinking some hours into reading the DHCP and ARP RFCs, I dove back into the disassembled code. It all sort of made sense. I'll summarize the rest of the story: it took another three weeks to document every structure and function that ARP and DHCP code uses.
</p>
<h4>More reverse engineering</h4>
<p>There was just one more thing left. As the NetIF driver comes up, it is expected to show UI and call back into <span>Net.lib</span> at various times. Different NetIF drivers I disassembled did this in very different ways, so I was not clear as to what was the proper way to do this. At this point I went to my archive of all the PalmOS ROMs, and wrote a tool to find all the files with the type <span>neti</span>(NetIF drivers have this type), skip all that are PPP, SLIP, or Loopback, and copy the rest to a folder, after deduplicating them. I then disassembled them all, producing diagrams and notes about how each brought itself up and down, where UI was shown or hidden, and when each step was taken. While doing this, I saw some (but not much) logging in some of these drivers, so I was able to rename my own names for various values and structs to more proper ones that writers of those NetIF drivers were kind enough to leak in their log statements. I ended up disassembling: Sony's "CFEtherDriver" from the UX50, Hagiwara's WiFi memorystick driver "HNTMSW_neti", Janam's "WLAN NetIF" from the XP30, Sony's "CFEtherDriver" from the TH55, PalmOne's "PxaWiFi" from Tungsten C, PalmOne's "WiFiLib" from the TX, and PalmOne's "WiFiLib" from their WiFi SD card. Phew, that was a lot! Long story short: the reverse engineered NetIF interface is documented in "netIfaceV5.h" and it is enough that I think a working NetIF driver can be written using it.
</p>
<p>"You think?" you might ask, "have you not tested it?". Nope, I am still writing my NetIF driver so stay tuned...
</p>

<h3>1.5 density support</h3>
<h4>Density basics</h4>
<p><img src="https://dmitry.gr/images/rePalm1.5ddBad.png" alt="Bad rendered PalmOS"></p><p>PalmOS since version 4.2 has support for multiple screen densities. That is to say that one could have a device with a screen of the same size, but more pixels in it and still see things rendered at the same size, just with more detail. Sony did have high-res screens before Palm, and HandEra did before both of them, but Palm's solution was the first OS-scale one, so that is the one that PalmOS 5 used. The idea is simple. Each Bitmap/Window/Font/etc has a coordinate system associated with it, and all operations use that to decide how to scale things. 160x160 screens were termed 72ppi (no relation to actual points or inches), and the new 320x320 ones were 144ppi (double density). This made life easy - when the proper density image/font/etc was missing, one could pixel-double the low-res one. The reverse worked to. Pen coordinates also had to be adjusted of course since now the developer could request to work in a particular coordinate system, and the whole system API then had to.
</p>
<p>How was this implemented? A few coordinate systems are always in play: native (what the display is), standard (UI layout uses this), and active (what the user set using <span>WinSetCordinateSystem</span>). So given three systems, there are at any point in time 6 scaling factors to convert from any to any other. PalmOS 5.0 used just one. This was messy and we'll not talk about this further. Lets just say this solution did not stick. PalmOS 5.2 and later use 4 scaling factors, representing bidirectional transforms between active and native, and native and standard. Why not the third pair? It is used uncommonly enough that doing two transformations is OK. Since floating-point math is slow on ARMv5, fixed point numbers are used. Here there is a difference between PalmOS 5.2 and PalmOS 5.4. The former uses 16-bit fixed point numbers in 10.6 format, the latter uses 32-bit numbers in 16.16 format. I'll let you read up about fixed-point numbers on your own time, but the crux of the matter is that the number of fraction bits limits the precision of the number itself and the math you can do with it. Now, for precise powers of two, one does not need that many bits, so while there were only 72ppi an 144ppi screens, 10.6 was good enough, with scale factors always being 0x20 (x0.5), 0x40 (x1.0), and 0x80 (x2.0) . PalmOS 5.4 added support for one-and-a-half density due to the overabundance of cheap 320x240 displays at the time. This new resolution was specified as 108ppi, or precisely 1.5 times the standard resolution. Technically everything in PalmOS 5.2 will work as is, and if you give PalmOS 5.2 such a screen, it will more or less sort of work. To the right you can see what that looks like. Yes, not pretty. But it does not crash, and things sort of work as you'd expect. So why does it look like crap? Well, that scaling thing. Let's see what scale factors we might need now. First of all, PalmOS will not ever scale between 108 and 144ppi for bitmaps or fonts, so those scale factors are not necessary (rePalm will in one special case: to draw 144ppi bitmaps on 108ppi screen, when no 72ppi or 108ppi bitmap is available). So the only new scale factors introduced are between standard and 1.5 densities. From standard to 108ppi the scale factor is 1.5, which is representable as 0x60 in 10.6 fixed point format. So far so good, that is exact and math will work perfectly every time. But from 108ppi to 72ppi the scale factor is 2/3, which is <strong>NOT</strong> representable exactly in binary (no matter how many bits of precision you have). The simple rule with fixed-point math is that when your numbers are not representable exactly, your rounding errors will accumulate to more than one once the values you operate on are greater than one over your LSB. So for 10.6, the LSB is 1/64, so once we start working with numbers over 64, rounding will have errors of over one. This is a problem, since PalmOS routinely works with numbers over 64 when doing UI. Hell, the screen's standard-density width is 160. Oops... These accumulated rounding errors are what you see in that screenshot. Off by one here, off by one there, they add up to that mess. 108ppi density became officially supported in PalmOS 5.4. So what did they do to make it work? Switch to 16.16 format. The LSB there is 1/65536, so math on numbers up to 65536 will round correctly. This is good enough since all of PalmOS UI uses 16-bit numbers for coordinates.
</p>
<h4>How does it all fall apart?</h4>
<p>So why am I telling you all this? Well, PalmOS 5.4 has a few other things in it that make it undesirable for rePalm (rePalm can run PalmOS 5.4, but I am not interested in supporting it) due to NVFS, which is mandatory in 5.4. I wanted PalmOS 5.2 to work, but I also wanted 1.5 density support, since 320x240 screens still are quite cheap, and in fact my STM32F427 dev board sports one. We cannot just take Boot.prc from PalmOS 5.4 and move it, since that also brings NVFS. So what to do? I decided to take an inventory of every part of the OS that uses these scaling values. They are hidden inside the "Window" structure, so mostly this was inside <span>Boot</span>. But there are other ways to fuck up. For example in a few places in <span>UI</span>, sequences like this can be seen: <span>BmpGetDensity(</span> <span>WinGetBitmap(</span> <span>WinGetDisplayWindow()))</span>. This is clearly a recipe for trouble because code that was never written to see anything other than a 72 or a 144 as a reply is about to see a 108. But, some of that is harmless, if math is not being done with it. It can quite harmful, however, if it is used in math. I disassembled the <span>Boot</span> from a PalmOS 5.4 device (Treo 680) and one from a PalmOS 5.2 device (Tungsten T3). For each place I found in the T3 ROM that looked weird, I checked what the PalmOS 5.4 <span>Boot</span> did. That provided most of the places of worry. I then searched the PalmOS 5.4 ROM for any references to <span>0x6C</span> as that is 108 in hex, and a very unlikely constant to occur in code naturally for any other reason (luckily). I also looked at every single division to see if coordinate scaling was involved. This produced a complete list of all the places in the ROM that needed help. There were over 150...
</p>
<h4>How do we fix it?</h4>
<p>Patching this many places is doable, but what if tomorrow I decide to use the <span>Boot</span> from another device? No, this was not a good solution. I opted instead to write an OEM extension (a module that the OS will load at boot no matter what) and fix this. But how? If the ROM is read only, and we do not have an MMU to map a page over the areas we want to fix, how to fix them? Well, every such place is logically in a function. And every function is sometimes called. It may be called by a timer, a notification, be a thread, or be a part of what the user does. Luckily PalmOS only expect UI work form the UI thread, so <strong>ALL</strong> all them were only called from use-facing functions. Sadly some were buried quite deep. I got started writing replacement functions, basing them on what the <span>Boot</span> from PalmOS 5.4 did. For most functions I wrote <em>full</em> patches (that is my patch entirely replaces the original function in the dispatch table, never calling back to the original). I wrote 73 of those: <span>FntBaseLine</span>, <span>FntCharHeight</span>, <span>FntLineHeight</span>, <span>FntAverageCharWidth</span>, <span>FntDescenderHeight</span>, <span>FntCharWidth</span>, <span>FntWCharWidth</span>, <span>FntCharsWidth</span>, <span>FntWidthToOffset</span>, <span>FntCharsInWidth</span>, <span>FntLineWidth</span>, <span>FntWordWrap</span>, <span>FrmSetTitle</span>, <span>FrmCopyTitle</span>, <span>CtlEraseControl</span>, <span>CtlSetValue</span>, <span>CtlSetGraphics</span>, <span>CtlSetSliderValues</span>, <span>CtlHandleEvent</span>, <span>WinDrawRectangleFrame</span>, <span>WinEraseRectangleFrame</span>, <span>WinInvertRectangleFrame</span>, <span>WinPaintRectangleFrame</span>, <span>WinPaintRoundedRectangleFrame</span>, <span>WinDrawGrayRectangleFrame</span>, <span>WinDrawWindowFrame</span>, <span>WinDrawChar</span>, <span>WinPaintChar</span>, <span>WinDrawChars</span>, <span>WinEraseChars</span>, <span>WinPaintChars</span>, <span>WinInvertChars</span>, <span>WinDrawInvertedChars</span>, <span>WinDrawGrayLine</span>, <span>WinEraseLine</span>, <span>WinDrawLine</span>, <span>WinPaintLine</span>, <span>WinInvertLine</span>, <span>WinFillLine</span>, <span>WinPaintLines</span>, <span>WinGetPixel</span>, <span>WinGetPixelRGB</span>, <span>WinPaintRectangle</span>, <span>WinDrawRectangle</span>, <span>WinEraseRectangle</span>, <span>WinInvertRectangle</span>, <span>WinFillRectangle</span>, <span>WinPaintPixels</span>, <span>WinDisplayToWindowPt</span>, <span>WinWindowToDisplayPt</span>, <span>WinScaleCoord</span>, <span>WinUnscaleCoord</span>, <span>WinScalePoint</span>, <span>WinUnscalePoint</span>, <span>WinScaleRectangle</span>,
<span>WinUnscaleRectangle</span>, <span>WinGetWindowFrameRect</span>, <span>WinGetDrawWindowBounds</span>, <span>WinGetBounds</span>, <span>WinSetBounds</span>, <span>WinGetDisplayExtent</span>, <span>WinGetWindowExtent</span>, <span>WinGetClip</span>, <span>WinSetClip</span>, <span>WinClipRectangle</span>, <span>WinDrawBitmap</span>, <span>WinPaintBitmap</span>, <span>WinCopyRectangle</span>, <span>WinPaintTiledBitmap</span>, <span>WinCreateOffscreenWindow</span>, <span>WinSaveBits</span>, <span>WinRestoreBits</span>,
<span>WinInitializeWindow</span>. A few things were a bit too messy to replace entirely. An example of that was <span>PrvDrawControl</span> a function that makes up the guts of <span>CtlDrawControl</span>, but is also used in a lot of places like event handling for controls. What to do? Well, I can replace all callers of it: <span>FrmHandleEvent</span> and <span>CtlDrawControl</span>, but that does not help since <span>PrvDrawControl</span> itself has issues and is HUGE and complex. After tracing it very carefully, I realized that it only really cares about density in one special case, when drawing a frame of type <span>0x4004</span>, in which case it instead sets the coordinate system to native, and draws a frame manually, and then resets the coordinate system. So, what I did is set a special global before calling it if the frame type requested is that special one, and the frame drawing function, the one I had already rewritten (<span>WinDrawRectangleFrame</span>) then sees that flag and instead does this special one thing. The same had to be done for erasing frame type <span>0x4004</span>, and the same method was employed. The results? It worked!
</p>
<p><img src="https://dmitry.gr/images/rePalm1.5ddGood.png" alt="Well rendered PalmOS"></p><p>There was one more complex case left - drawing a window title. It was buried deep inside <span>FrmDrawForm</span> since a title is technically a type of a frame object. To intercept this without rewriting the entire function, before it runs, I converted a title object to a special king of a list object, and saved the original object in my globals. Why a list? <span>FrmDrawForm</span> will call <span>LstDrawList</span> on a list object, and will not peek inside. I then intercept <span>LstDrawList</span>, check for our magic pointer, if so, draw the title, else let the original <span>LstDrawList</span> function run. On the way out of <span>FrmDrawForm</span>, this is all undone. For form title setting functions, I just replaced them since they redraw the title manually, and I already had written a title drawing function. There was one small thing left: the little (i) icon on forms that have help associated with them. It looked bad when tapped. My title drawing function drew it perfectly, but the tap responce was handled by <span>FrmHandleEvent</span> - another behemoth I did not want to replace. I looked at it, and saw that the handling of the user taps on the help (i) icon was pretty early on. So, I duplicated that logic (and some that preceded it) in my patch for <span>FrmHandleEvent</span> and did not let the original function get that event. It worked perfectly! So thus we have four more partial patches: <span>LstDrawList</span>, <span>FrmDrawForm</span>, <span>FrmHandleEvent</span>, and <span>CtlDrawControl</span>.
</p>
<h4>And now, for some polish</h4>
<p>Still one thing was left to do: proper support for 1.5 density feature set as defined by the SDK. So: I modified the DAL to allow me to patch functions that do not exist in the current OS version at all, since some new ones were added after 5.2 to make this feature set work: <span>WinGetScalingMode</span> and <span>WinSetScalingMode</span>. Then I modified <span>PACE</span>'s 68k dispatch handler for sysTrapHighDensityDispatch to handle the new 68K trap selectors <span>HDSelectorWinSetScalingMode</span> and <span>HDSelectorWinGetScalingMode</span>, letting the rest of the old ones be handled by <span>PACE</span> as they were. I also got a hold of 108ppi fonts, and wrote some code to replace the system fonts with them, and I got a hold of 108ppi system images (like the alert icons) and made my extension put them in the right places.
</p>
<p>The result? The system looks pretty good! There are still things left to patch, technically, and "main.c" in the "Fix1.5DD" folder has a comment listing them, but they are all minor and the system looks great as is. The "Fix1.5DD" extension is part of the source code that I am releasing with rePalm, and you can see the comparison "after" screenshot just above to the right. It is about 4000 lines of code, in 77 patches and a bit of glue and install logic.
</p>

<h3>Dynamic Input Area/Pen Input Manager Services support</h3>
<h4>DIA/PINS basics</h4>
<p>PalmOS initially supported square screens. A few OEMS (Handera, Sony) did produce non-square screens, but this was not standard. Sony made quite a headway with their 320x480 Sony Clie devices. But their API was sony-only and was not adopted by others. When PalmOS 5.2 added support for non-square screens, Palm made an API that they called PINS (or alternatively DIA or AIA). It was not as good as Sony's API but it was official, and thus everyone migrated to it. Later sony devices were forced to support it too. Why was it worse? Sony's API was simple: collapse dynamic input area, or bring it back. Enable or disable the button to do so. Easy. Palm's API tries to be smart, with things like per-form policies, and a whole lot of mess. It also has the simple things: put area down or up, or enable or disable the button. But all those settings get randomly mutated/erased anytime a new form comes onscreen, which makes it a huge pain! Well, in any case. That is the public API. How does it all work? In PalmOS 5.4, this is all part of the OS proper, and integrated into <span>Boot</span>.
</p>
<h4>How it works pre-garnet</h4>
<p>But, as I had said, I was tergetting PalmOS 5.2. There, it was not a part of the OS, it was an extension. The DAL presents to the system a raw screen of whatever the actual resolution is (commonly 320x480) and the extension hides the bottom area from the apps and draws the dynamic input area on it. This requires some interception of some OS calls, like <span>FrmDrawForm</span> (to apply the new policy), <span>FrmSetActiveForm</span> (to apply policy to re-activated already drawn forms), <span>SysHandleEvent</span> (to handle events in the dynamic input area), and <span>UIReset</span> (to reset to defaults the settings on app switching). There are also some things we want to be notified about, like screen color depth change. When that happens, we may need to redraw the input area. That is the gist of it. There are a lot of small but significant specifics though.
</p>
<h4>The intricacies of writing a DIA implementation</h4>
<p>Before embarking on writing my own DIA implementation, I tried all the existing ones to see if they would support resolution other than 320x480. I do not want to write pointles code, afterall. None of them worked well. Even such simple things as 160x240 (direct 2x downscaling) were broken. Screens with different aspect ratios like the common 240x320 and 160x220 were even more broken. Why? I guess nobody ever writes generic code. It is simpler to just hack things up for "now" with no plan for "later". Well, I decided to write a DIA implementation that could support almost any resolution.
</p>
<p>When the DIA is collapsed, a status bar is shown. It shows small icons like the home button and menu button, as well as the button to unhide the input area. I tried to make everything as generic as possible. For every screen resolution possible, one can make a skin. A skin is a set of graphics depicting the DIA, as well as some integers describing the areas on it, and how they act (what key codes they send, what they do). The specifics are described in the code and comments and samples (3 skins designed to look similar to sony's UIs). They also define a "notification tray" area. Any app can add icons there. Even normal 68k apps can! I am including an example of this too. The clock you see in the status bar is actually a 68k app caled "NotifGeneral" and its source is provided as part of rePalm's source code! My sample DIA skins currently support 320x480 in double-density, 240x320 in 1.5 density, and 160x220 single density. The cool part? The same codebase supports all of these resolutions despite them having different aspect ratios. NotifGeneral also runs on all of those unmodified. Cool, huh? The source code for the DIA implementation is also published with rePalm, of course!
</p>


<h3>Audio support</h3>
<h4>PalmOS Audio basics</h4>
<p>Since PalmOS 1.0, there has been support for simple sound via a piezo speaker. That means simple beeps. The official API allows one to: play a MIDI file (one channel, square waves only), play a tone of a given volume and amplitude (in background or in foreground), and stop the tone. In PalmOS 5.0, the low level API that backs this simple sound API is almost the same as the high-level official API. <span>HALSoundPlay</span> is used to start a tone for a given duration. The tone runs in the background, the func itself returns directly and immediately. If another tone had previously been started, it is replaced with the new one. A negative duration value means that the tone will never auto-stop. <span>HALSoundOff</span> stops a currently-playing tone, if there is one. <span>HALPlaySmf</span> plays a MIDI tune. This one is actually optional. If the <span>DAL</span> returns an error, <span>Boot</span> will interpret the MIDI file itself, and make a series of calls to <span>HALSoundPlay</span>. This means that unless you have special hardware that can play MIDI better than simple one-channel square waves, it makes no sense to implement <span>HALPlaySmf</span> in your <span>DAL</span>.
</p>
<h4>PalmOS sampled sudio support</h4>
<p>Around the time PalmOS 5.0 came out, the sampled sound API made an appearance. Technically it does not require PalmOS 5.0, but I am not aware of any Palm OS 4 device that implement this API. There were previous vendor-specific audio APIs in older PalmOS releases, but they were nonstandard and generally depended on custom hardware accelerator chips, since 68k processor is not really fast enough to decode any complex audio formats. The sampled sound API is obviously more complex than the simple sound API, but it is easily explained with the concept of streams. One can create an input or output stream, set volume and pan for it, and get a callback when data is available (input) or needed (output). For output streams, the system is expected to mix them together. That means that more than one audio stream may play at the same time and they should all be heard. Simple sound API should also work concurrently. PalmOS never really required support for more than one input stream, so at least that is nice.
</p>
<p>A stream (in or out) has a few immutable properties. The three most important ones are the sample rate, the channel number, and the sample format. The sample rate is basically how many samples per second there are. CD audio uses 44,100 per second, most DVDs use 48,000 per second, and cheap voice recorders use 8,000 (approximately telephone quality). PalmOS support only two channel widths: 1 and 2. These are commonly known as "mono", and "stereo". Sample type is a representation of how each sample is represented in the data stream. PalmOS API documents the following sample types: signed and unsigned 8-bit values, signed 16-bit values of any endianness, signed 32-bit values of any endianness, single-precision floating point values of any endianness. As far as I can tell, the only formats ever supported by actual devices were the 8 and 16-bit ones.
</p>
<h4>Why audio is hard &amp; how PalmOS makes it easy</h4>
<p>Mixing audio is hard. Doing it in good quality is harder, and doing it fast is harder yet. Why? The audio hardware can only output one stream, so you need to mix multiple streams into one. Mixing may involve format conversion, for example if hardware needs signed 16-bit little-endian samples and one of the streams is in float format. Mixing almost certainly involves scaling since each stream has a volume and may have a pan applied. And, hardest of all, mixing may involve resampling. If, for example, the hardware runs at 48,000 samples per second, and a client requested to play a stream with 44,100 samples per second, more samples are needed than are provided - one needs to generate more samples. This is all pretty simple to do, if you have large buffers to work with, but that is also a bad idea, since that adds a lot of latency - the larger your buffer, the more time passes between the app providing audio data and the audio coming out the speaker. In the audio world, you are forced to work with relatively small buffers. Users will also notice if you are late delivering audio samples to the hardware (they'll hear it). This means that you are always on a very tight schedule when dealing with audio.
</p>
<p>What do existing PalmOS <span>DAL</span>s do to address all this difficulty? Mostly, they shamelessly cut corners. All existing <span>DAL</span>s have a very bad resampler - it simply duplicates samples as needed to upsample (convert audio to a higher sampling rates), and drops samples as needed to downsample (convert audio to a lower sampling rates). Why is this bad? Well, when resampling between sample rates that are close to each other in this manner, this method will introduce noticeable artifacts. What about format conversions? Well, only supporting four formats is pretty easy - the mixing code was duplicated four times in the <span>DAL</span>, once for each time.
</p>
<h4>How rePalm does audio mixing</h4>
<p>I wanted rePalm to produce good audio quality, and I wanted to support all the formats that PalmOS API claimed were supported. Actually, I ended up supporting even more formats: signed and unsigned 8, 16, and 32-bit integer, as well as single-precision floating-point samples in any endianness. For sample rates, rePalm's mixer supports: 8,000, 11,025, 16,000, 22,050, 24,000, 32,000, 44,100, and 48,000 samples per second. The format the output hardware uses is decided by the hardware driver at runtime in rePalm. Mono and stereo hardware is supported, any sample rate is supported, and any sample format is supported for native hardware output. If you now consider the matrix of all the possible stream input and output formats, sample rates, and channel numbers, you'll realize that it is a very large matrix. Clearly the PalmOS approach of duplicating the code 4 times will not work, since we'd have to duplicate it hundreds or thousands of times. The alternative approach of using generic code that switches based on the types is too slow (the switching logic simply wastes too many cycles per sample). No simple solutions here. But before we even get to resampling and mixing, we need to work out how to deal with buffering.
</p>
<p>The initial approach involved each channel having a single circular buffer that the client would write and the mixer would read. This turned out to be too difficult to manage in assembly. Why in assembly? We'll get to that soon. The final approach I settled on was actually simpler to manage. Each stream has a few buffers (buffer depth is currently defined to be four), and after any buffer is 100% filled, it is sent to the mixer. If there are no free buffers, the client blocks (as PalmOS expects). If the mixer has no buffers for a stream, the stream does not play, as PalmOS API specifies. This setup is easy to manage from both sides, since the mixer now never has to deal with partially-filled buffers or sorting out the circular-buffer wraparound criteria. A semaphore is used to block the client conveniently when there are no buffers to fill. "But," you might ask, "what if the client does not give a full buffer's worth of data?" Well, we do not care. Eventually if the client wants the audio to play, they'll have to give us more samples. And in any case, remember how above we discussed that we have to use small buffers? Any useful audio will be big enough to fill at least a few buffers.
</p>
<p>One mustn't forget that supporting sampled sound API does not absolve you from having to support simple sound functions. rePalm creates a sound stream for simple sound support, and uses it to play the required tones. They are generated from an interpolated sine wave at request time. To support doing this without any pesky callbacks, the mixer supports special "looped" channels. This means that once the data buffer is filled, it is played repeatedly until stopped. Since at least one complete wave must fit into the buffer, rePalm refuses to play any tones under 20Hz. This is acceptable to me.
</p>
<h4>How do assembly and audio mix?</h4>
<p>The problem of resampling, mixing, and format conversion loomed large over me. The naive approach of taking a sample from each stream, mixing it into the output stream, and then doing the same for the next stream is too slow, due to the constant "switch"ing required based on sample types and sample rates. Resampling is also complex if done in good (or at least passable) quality. So what does rePalm's <span>DAL</span> do? For resampling, a large number of tables are used. For upsampling, a table tells us how to linearly interpolate between input samples to produce output samples.  One such carefully-tuned table exists for each pair of frequencies. For downsampling, a table tells us how many samples to average and at what weight. One such table exists for each pair of frequencies. Both of these approaches are strictly better than what PalmOS does. But, if mixing was already hard, now we just made it harder. Let's try to split it into chewable chunks. First, we need an intermediate format - a format we can work with efficiently and quickly, without serious data loss. I picked signed 32-bit fixed point with 8 integer bits and 24 fraction bits. Since no PalmOS device ever produced audio at more than 24-bit resolution, this is acceptable. The flow is <em>conceptually</em> simple: first zero-fill an intermediate buffer. Then, for each stream for which we have buffers of data, mix said buffer(s) into the intermediate buffer, with resampling as needed. Then clip the intermediate buffer's samples, since mixing two loud streams can produce values over the maximum allowed. And, finaly, convert the intermediate buffer into the format hardware supports, and hand it off to the hardware. rePalm does not bother with a stereo intermediate buffer if the audio hardware is mono only. The intermediate buffer is only in stereo if the hardware is! How do we get this much flexibility? Because of how we mix things into it.
</p>
<p>The only hard part from above is that "mix buffers into the intermediate buffer with resampling" step. In fact, not only do we need to resample, but we also need to apply volume, pan, and possibly convert from mono to stereo or from stereo to mono. The most optimal approach is to write a custom well-tuned mix function for every possible combination of inputs and outputs. The number of combinations is dizzying. Input has 8 possible rates, 2 possible channel configs, and 12 possible sample types. Output has 8 possible rates and 2 possible channel configs. This means that there is a total of just over 3,000 combinations (8 * 2 * 12 * 8 * 2). I was not going to write 3072 functions by hand. In fact, even auto-generating them at build time (if I were to somehow do that) would bloat rePalm's <span>DAL</span>'s code size to megabytes. No, another approach was needed.
</p>
<p>I decided that I could reuse some things I learned while I was writing the JIT, and also reuse some of its code. That's right! When you create a stream, a custom mix function is created just for that stream's configuration, and for your hardware's output configuration. This custom assembly code uses all the registers optimally and, in fact, it manages to use no stack at all! The benefit is clear! The mixing code is always optimal since it is custom for your configuration. For example, if the hardware only supports mono output, the mixing code will downmix before upsampling (to do it to fewer samples), but will only downmix after downsampling (once again, so less math is needed). Since there are three major cases: upsampling, downsampling, and no-resampling, there are three paths through the codegen to produce mix functions. Each mix function matches a very simple prototype: <span>int32_t* (*MixInF)(int32_t* dst, const void** srcP, uint32_t maxOutSamples, void* resampleStateP, uint32_t volumeL, uint32_t volumeR, uint32_t numInSamples)</span>. It returns the pointer to the first intermediate buffer sample NOT written. <span>srcP</span> is updated to point to the first input audio sample not consumed, <span>maxOutSamples</span> limits how many audio samples may be produced, <span>numInSamples</span> limits how many audio samples may be consumed. Mix functions return when either limit is reached. Resampling logic may have long-lived state, so that is stored in a per-stream data structure (5 words), and passed in as <span>resampleStateP</span>. The actual resample table pointer is encoded in the function itself (for speed), since it will never change. Why? Because the stream's sample rate is constant, and the hardware will not magically grow ability to play at another sample rate at a later time. The stream's volume and pan, however, may be changed anytime, so they are not hardcoded into the function body. They are provided as parameters at mixing time. I actually considered hardcoding them in, and re-generating the mix function anytime the volume or pan changed, but the gain would have been too small to matter, so I decided against it. Instead we simply pre-calculate "left volume" and "right volume" from the user settings of volume" and "pan" and pass them to the mix function.
</p>
<p>Having a mix function that nice makes the rest of the mixer easy. Simply: call the mix function for each non-paused stream as long as there are buffers to consume and the output buffer is not full. If we fully consume a buffer, release it to the user. If not, just remember how many samples in there we haven't yet used for later. That is all! So does all this over-complex machinery work? Yes it does! The audio mixer is about 1,500 lines, BUT it can resample and mix streams realtime at under 3 million cycles per stream per second, which is much better than PalmOS did, and with better quality to boot! The code is in "audio.c".
</p>

<h4>rePalm's audio hw driver architecture</h4>
<p>rePalm's audio hardware layer is very simple. For simple sound support, one just provides the funcs for that and the sound layer clals them directly. For sampled audio, the audio init function tells the audio mixer the native channel number and sample rate. What about native sample format? The code provides an inline function to convert a sample from the mixer's intermediate format (8.24 signed integer) to whatever format the hardware needs. Thus, the hardware's native sample format is defined by this inline function. At init time the hw layer provides to the mixer all this info, as well as the size of the hardware audio buffer. This buffer is needed since interrupts have latency and we need the audio hw to always have some audio to play.
</p>
<p>On the STM32F429 board, audio output is on pin A5. The audio is generated using a PWM channel, running at 48,000 samples per second, in mono mode. Since the PWM clock runs at 192MHz, if we want to output 48,000 samples per second, the PWM unit will only be able to count to 4000. Yes, indeed, for this board, since it lacks any real audio output hardware, we're stuck with just about 12-bit precision. This is good enough for testing purposes and actually doesn't sound all that bad. The single-ended output directly from the pin of the microcontroller cannot provide much power, but with a small speaker, the sound is clear and sounds great! I will upload an image with audio support soon.
</p>
<p>On reSpring, the CPU clock (and thus PWM clock) is at 196.6MHz. Why this weird frequency? Because it is precisely 48,000 x 4096. This allows us to not need to scale audio in a complex fashion, like we do on the STM32F429 board. Just saturating it to 12 bits will work. Also, on reSpring, two pins are used to output audio, in opposite polarity, this gives us twice the voltage swing, producing louder sounds.
</p>
<h4>Microphone</h4>
<p>I did not implement a mixer/resampler for the microphone - PalmOS never supported more than one user of a microphone at a time, so why bother? - no apps will do so. Instead, whichever sampling rate was requested, I pass that to the hardware driver and have it actually run at that sampling rate. As for sample type, same as for audio out, a custom function is generated to convert the sample format from the input (16 bit little-endian mono), to whatever the requested format was. The generated code is pretty tight and works well!
</p>

<h3>Zodiac support</h3>
<h4>Tapwave Zodiac primer</h4>
<p><a href="https://en.wikipedia.org/wiki/Tapwave_Zodiac">Tapwave Zodiac</a> was a rather unusual PalmOS device released in 2003. It was designed for gaming and had some special hardware just for that: landscape screen, an analog stick, a Yamaha Midi chip, and an ATI Imageon W4200 graphics accelerator with dedicated graphics RAM. There was a number of Tapwave-exclusive titles released that used the new hardware well, including some fancy 3D games. Of course this new hardware needed OS support. Tapwave introduced a number of new APIs, and, luckily, documented them quite well. The new API was quite well designed and easy to follow. The documentation was almost perfect. Kudos, Tapwave! Of course, I wanted to support Tapwave games in rePalm.
</p>
<h4>The reverse engineering</h4>
<p>Tapwave's custom API were all exposed via a giant table of function pointers given to all Tapwave-targetting apps, after they pass the signature checks (Tapwave required approvals and app signing). But, of course, somewhere they had to go to some library or hardware. Digging in, it became clear that most of them go to <span>Tapwave Application Layer</span>(<span>TAL</span>). This module is special, in that on the Zodiac, like the <span>DAL</span>, <span>Boot</span>, and <span>UI</span>, the <span>TAL</span> can be accessed directly off of <span>R9</span> via <span>LDR R12, [R9, #-16]; LDR PC, [R12, #4 * tal_func_no]</span>. But, after spending a lot of time in the <span>TAL</span>, I realized that it was just a wrapper. All the other libraries were too: <span>Tapwave Midi Library</span> and <span>Tapwave Multiplayer Library</span>. All the special sauce was in the DAL. And, boy, was there a lot of special sauce. Normal PalmOS DALs have about 230 entrypoints. Tapwave's has 373!
</p>
<p>A lot of tracing through the <span>TAL</span>, and a lot of trawling through the CPU docs got me the names and params to most of the extra exported <span>DAL</span> funcs. I was able to deduce what all but 14 functions do! And as for those 14: I could find no uses of any of them anywhere in the device's software! The actual implementations underneath matter a bit less since I am just reimplementing them. My biggest worries were, of course, the graphics acceleration APIs. Turned out that that part was the easiest!
</p>
<h4>The "GPU"</h4>
<p>Zodiac's graphics accelerator was pretty fancy for a handheld device at the time, but it is also quite basic. It has 8MB of memory built in, and accelerates only 2D operations. Basically, it can: copy rectangles of image data, blend rectangles between layers with constant or parametric alpha blending, do basic bilinear resizing, and draw lines, rectangles, and points. It operates only on 16-bit RGB565LE layers. This was actually quite easy to implement. Of course doing this in software would not be fast, but for the purposes of my proof of concept, it was good enough. A few days of work, and ... it works! A few games ran.
</p>
<p>Next step is still in-progress: using the DMA2D unit in the STM32 to accelerate most of the things the ATI chip can do. Except for image resizing, it can do them all in one pass or two! For extra credit, it can also operate in the background like the ATI chip did to the CPU in the Zodiac. But that is for later...
</p>
<h4>Other Tapwave APIs</h4>
<p>Input subsystem in the Zodiac was quite special and required some work. Instead of the usual PalmOS methods of reading keys, touch, etc, they introduced a new "input queue" mechanism that allowed all of these events to be delivered all into one place. I had to reimplement this from nothing but the documented high level API and disassembly. It worked: rePalm now has a working implementation of TwInput and can be used as reference for anyone who also for some reason wants to implement it.
</p>
<p>TwMidi was mostly reverse engineered in a week. But I did not write a midi sequencer. I could and shall, but not yet. The API is known and that is as far as I needed to go to return proper error codes to allow the rest of the system to go on.
</p>

<h2>Real hardware: reSpring</h2>
<h3>The ultimate Springboard accessory</h3>
<p>Back when <a href="https://en.wikipedia.org/wiki/Handspring_(company)">Handspring</a> first released the Visor, its <a href="https://en.wikipedia.org/wiki/Springboard_Expansion_Slot">Springboard Expansion Slot</a> was one of the most revolutionary features. It allowed a few very cool expansion devices, like <a href="https://web.archive.org/web/20190921012909/https://www.zdnet.com/product/handspring-visorphone/">cellular phones</a>, <a href="https://web.archive.org/web/20110111075957/http://www.agentland.com/Store/129.html">GPS receivers</a>, <a href="https://web.archive.org/web/20080515225204/http://www.visorcentral.com/content/Stories/1329-1.htm">barcode readers</a>, <a href="https://web.archive.org/web/20160314022653/https://the-gadgeteer.com/2001/06/29/innopocket_flashplus_plug_and_play_compact_flash_springboard_adapter">expansion card readers</a>, and <a href="https://web.archive.org/web/20190403061919/https://the-gadgeteer.com/2000/04/07/eyemodule_visor_springboard_review/">cameras</a>. Springboard slot is cool because it is a literal direct connection to the CPU's data and address bus. This provides a lot of expansion opportunities. I decided that the first application of rePalm should be a Springboard accessory that will, when pluged in, upgrade a Visor to PalmOS 5. The idea is that reSpring will run rePalm on its CPU, and the Visor will act as the screen, touch, and buttons. I collaborated with <a href="mailto:george.rudolf.mezzomo@gmail.com">George Rudolf Mezzomo</a> on reSpring, with me setting the specs, him doing the schematics and layout, and me doing the software and drivers.
</p>
<h3>Interfacing with the Visor</h3>
<p>To the Visor, the sprinboard module looks like two memory areas (two chip select lines), each a few megabytes large at most. The first must have a valid ROM image for the Visor to find, structured like a PalmOS ROM memory, with a single heap. Usually that heap contains a single application - the driver for this module. The second chip select is usually used to interface to whatever hardware the Springboard unit has. For reSpring I decided to do things differently. There were a few reasons. The main reason was that a NOR flash to store the ROM would take up board space, but also because I really did not want to manage so many different flashable components on the board. There was a third reason too, but we'll need to get back to that in a bit.
</p>
<p>The Visor expects to interface with the Springboard by doing memory accesses to it (reads and writes) and the module is expected to basically behave like a synchronous memory device. That means that there is no "I am ready to reply" line, instead you have a fixed number of cycles to reply to any request. When a module is inserted, the Visor configured that number to be six, but it can then be lowered by the module's driver app. Trying to reply to requests coming in with a fixed (and very short) deadline would be a huge CPU load for our ARM CPU. I decided that the easiest way to accomplish this is to actually put a RAM there, and let the Visor access that. But, then, how will we access it, if the Visor can do so anytime? Well, there are special types of RAM that allow this.
</p>
<p>Yes, the elusive (and expensive) dual-ported RAM. I decided that reSpring would use a small amount of dual-ported RAM as a malbox between the Visor and rePalm's CPU.  This way the Visor could access it anytime, and so could rePalm. The Springboard slot also has two interrupt request lines, one to the Visor, one to the module. These can be used to signal when a message is in the mailbox. There are two problems. The first is that dual-ported RAMs are usually large, mostly due to the large number of pins needed. Since the Visor needs a 16-bit-wide memory in the Springboard slot, our hypotherical dual-ported RAM would need to be 16-bit wide. And then we need address lines, control lines, byte lane select lines, and chip select lines. If we were to use a 4KB memory, for example, we'd need 11 address lines, 16 data lines, 2 byte lane select lines, one chip select line, one output enable line, and one write enable line, PER PORT! Add in at least two power pins, and our hypothetical chip is a 66-pin monstrosity. Since 66-pin packages do not exist, we're all in for a 100-pin part. And 4KB is not even much. Ideally we'd like to fit our entire framebuffer in there to avoid complex piecewise transfers. Sadly, as the great philosopher Jagger once said, "You can't always get what you want." Dual-ported RAMs are <em>very</em> expensive. There are only two companies making them, and they charge <em>a lot</em>. I settled on the 4KB part purely based on cost. Even at this measly 4KB size, this one RAM is <em>by far</em> the most expensive component on the board at $25. Given that the costs of putting in a 64KB part (my preferred size) were beyond my imagination (and beyond my wallet's abilities), I decided to invent a complex messaging protocol and make it work over a 4KB RAM used as a bidirectional mailbox.
</p>
<p>But, let us get back to our need for a ROM to hold our driver program. Nowhere in the Sprinboard spec is there actually a requirement for a ROM, just a memory. So what does that mean? We can avoid that extra chip by having the reSpring CPU contain the ROM image inside it, and quickly write it into the dual-ported RAM on powerup. Since the Visor gives the module up to three seconds to produce a valid card header, we have plenty of time to boot up and write the ROM to our RAM. One chip fewer to buy and place on the board is wonderful!
</p>
<h3>Version 1</h3>
<p>I admit: there was a bit of feature creep, but the final hardware design for version 1 ended up being: 8MB of RAM, 128MB of NAND flash, a 192MHz CPU with 2MB of flash for the OS, a microSD card slot, a speaker for audio out, and an amplifier to use the in-Visor microphone for audio in. Audio out will be done the same way as on the STM32F429 board, audio in will be done via the real ADC. The main RAM is on a 32-bit wide bus running at 96MHz (384MB/s bandwidth). The NAND flash is on a QSPI bus at 96MHz (48MB/s bandwidth). The OS will be stored in the internal flash of the STM32F469 CPU. The onboard NAND is just an exploration I would like to do. It will either be an internal SD card, or maybe storage for something like NVFS(but not as unstable), when I've had time to write it.
</p>
<p>So, when is this happening? Five version 1 boards were delivered to me in late November 2019!
</p>
<h3>Bringup of v1</h3>
<p>Having hardware in-hand is great. It is greater yet when it work right the vey first time. Great like unicorns, and just as likely. Nope... nothing worked right away. The boards did not want to talk to the debugger at all, and after weeks of torture, I realized some pull ups and downs were missing from the boards. This was not an issue on STM's dev boards since they include these pull ups/downs. Once the CPU started talking to me, it became evident very quickly that it was very very unstable. It is specified to run at 180MHz (yes, this means that normally we are overclocking it by 9.2% to 196.6MHz). On the reSpring boards the CPU would not run with anystability over 140MHz. I checked power supply, and decoupling caps. All seemed to be in place, until... No VCAP1 and VCAP2. The CPU core runs at a lower voltage than 3.3V, so the CPU has an internal regulator. This regulator needs capacitors to stabilize its output in the face of variable consumption by the CPU. That is what VCAP1 and VCAP2 pins are for. Well, the board had no capacitors on VCAP1 and VCAP2. The internal regulator output was swinging wildly (+/- 600mV on a 1.8V supply is a <em>lot</em> of swing!). In fact, it is amazing that the CPU ran at all with such an unstable supply! Well, after another rework under the microscope with two capacitors were added, the board was stable. On to the next problem...
</p>
<p>The next issue was SDRAM. The main place the code runs from and data is stored. The interface seemed entirely borked. Any word that was written, the 15th bit would always read as 1, and 0th and 1st bits would always read as a zero. Needless to say, this is not acceptable for a RAM which I hoped to run code from. This was a giant pain to debug, but in the end it there out to be a typo in GPIO config not mapping the two lower bits to be SDRAM DQ0 and DQ1. This left only bit 15 stuck high to resolve. That issue did not replicate on other boards, so that was a local issue to one board. A lot of careful microscoping revealed a gob of solder under the pin left from PCBA, which was shorting to a nearby pin that was high. Lifting the pin, wicking the solder off, and reconnecting the pin to the PCB resolved this issue. SDRAM now worked. Since this SDRAM was quite different than the one on the STM32F429 discovery board, I had to dig up the configs to use for it, and translate between the timings STM uses and the RAM datasheet uses to come up with proper settings. The result was quite fast SDRAM which seems stable. Awesome!
</p>
<p>Of course this was not nearly the end of it. I could not access the dual-ported SRAM at all. A quick check with the board layout revelaed that its chip select pin was not at all wired to the STM. Out came the microscope and soldering iron, and a wire was added. Lo and behold, SRAM was accessible. More datasheet reading ensued to configure it properly. While doing that, I noticed that it's power consumption is listed as <em>"low"</em>, just 380 mW!!! So not only is this the most expensive chip on the board, it is also the most power hungry! It really needs to go!
</p>
<p>I can tell you of more reworks that followed after some in-Visor testing, just to keep all the rework story together. It turned out that the line to interrupt the visor was never connected anywhere, so I wired that up to PA4, so that reSpring could send an IRQ to the visor. Also it turned out that SRAM has a lot of "modes" and it was configured for the wrong one. Three separate pins had to be reworked to switch it from "master" mode into "slave" mode. These modes configure how multiple such SRAMs can be used together. As reSpring only has one, logically it was configured as master. This turns out to have been wrong. Whoops.
</p>
<h3>Let's stick it into a Visor?</h3>
<h4>Getting recognized</h4>
<p><img src="https://dmitry.gr/images/rePalm-visor-boot-1.jpg" alt="reSpring module recognized by the Visor"></p><p>So simple, right? Just stick it into the Visor and be done with it? Reading and re-reading the Handspring Springboard Development Guide provided almost all the info needed, in theory. Practice was different. For some reason, no matter how I formatted the fake ROM in the shared SRAM, the Visor would not recognize it. Finally I gave  up on this approach, and wrote a test app to just dump what the Visor sees to screen, in a series of messageboxes. Springboard ROM is always mapped at <span>0x28000000</span>. I quickly realized the issues. First, the visor Springboard byteswaps all accesses. This is because most of the world is little-endian, while the 68k CPU is big-endian. To allow peripheral designers to not worry, Handspring byteswaps the bus. "But," you might say, "what about non-word accesses?" There are no such accesses. Visor always accesses 16 bits at a time. There are no byte-select lines. For us this is actually kind of cool. As long as we communicate using only 16-bit quantities, no byteswapping in software is needed. There was another issue: the Visor saw <em>every other</em> word that reSpring wrote. This took some investigation, but the result was both hilarious and sad at the same time. Despite all accesses to Springboard being 16-bit-wide, address line 0 is wired to the Springboard connector. Why? Who knows? But it is always low. On reSpring board, Springboard connector's A0 was wired to RAM's A0. But since it is always 0, this means the Visor can only access every other word of RAM - the even addresses. <em>...sigh...</em> So we do not have 4K of shared RAM. We have 2K... But, now that we know all this, can we get the visor to recognize reSpring as a Springboard module? <em>YES!</em>. The image on the right was taken the first time the reSpring module was recognized by the Visor.
</p>
<h4>Saving valuable space</h4>
<p>Of course, this was only the beginning of the difficulties. Applications run right from the ROM of the module. This is good and bad. For us this is mostly bad. What does this mean? The ROM image we put in the SRAM must remain there, forever. So we need to make it as small as possible. I worked very hard to minimize the size, and got it down to about 684 bytes. Most of my attempts to overlap structures to save space did not work - the Visor code that validates the ROM on the Springboard module is merciless. The actual application is tiny. It implements the simplest possible messaging protocol (one word at a time) to communicate with the STM. It implements no graphics support and no pen support. So what <em>does</em> it do? It downloads a larger piece of code, one word at a time, from the STM. This code is stored in the Visor's RAM and can run from there. It then simply jumps to that code. Why? This allows us to save valuable SRAM space. So we end up with 2K - 684bytes = 1.3K of ram for sending data back and forth. Not much but probably passable.
</p>
<h4>Communications</h4>
<p>So, we have 1.3KB of shared RAM, an interrupt going each way, how do we communicate? I designed two communications protocols: a simple one and a complex one. The simple one is used only to bootstrap the larger code into Visor RAM. It sends a single 16-bit message and gets a single 16-bit response. The messages implemented are pretty basic: a request to reply - just to check comms, a few requests to get information on where in the shared memory the large mailboxes are for the complex protocol, a request for how big the downloaded code is, and the message to download the next word of code. Once the code is downloaded and knows what the locations and sizes of mailboxes are, it uses the complex protocol. How does it differ? A large chunk of data is placed in the mailbox, and then the simple protocol is used to indicate a request and get a response. The mailboxes are unidirectional, and sized very differently. The STM-to-Visor mailbox occupies about 85% of the space, while the mailbox in the other direction is tiny. The reason is obvious - screen data is large.
</p>
<p>All requests are always originated from the Visor and get a response from the reSpring module. If the module has something to tell the Visor, it will raise an IRQ, and the visor will send a request for the data. If the visor has nothing to send, it will simply send an empty NOP message. How does the Visor send a request? First, the data is written to the mailbox, then the message type is written to a special SRAM location, and then a special marker indicating that the message is done is written to another SRAM location. An IRQ is then raised to the module. The IRQ handler in the STM looks for this "message valid" marker, and if it is found the message is read and replied to: first the data is written to the mailbox, then message type is written to the shared SRAM location for message type, and then the "this is a reply" marker is written to the marker SRAM location. This whole time, the Visor is simply loop-reading the marker SRAM location waiting for it to change. Is this busy waiting a problem? No. The STM is so fast, and the code to handle the IRQ does so little processing that the replies often come in microseconds.
</p>
<p>A careful reading of the Handspring Springboard Development Guide might leave you with a question: "what exactly do you mean when you say 'interrupt to the module'? There are no pins that are there for that!" Indeed. There are, however, two chip-select lines going to the module. The first must address the ROM (SRAM for us). The chip-select line second is free for the module to use. Its base address in Visor's memory map is <span>0x29000000</span>. We use that as the IRQ to the STM, and simply access <span>0x29000000</span> to cause an interrupt to the STM.
</p>
<h4>Early Visor support</h4>
<p>At this point, some basic things could be tested, but they all failed on Visor Deluxe and Visor Solo. In fact, everything crashed shortly after the module was inserted. Why? Actually the reason is obvious - they run PalmOS 3.1, while all other Visors ran PalmOS 3.5. A surprising number of APIs one comes to rely on in PalmOS programming are simply not available on PalmOS 3.1. Such simple things like <span>ErrAlertCustom()</span>, <span>BmpGetBits()</span>, <span>WinPalette()</span>, and <span>WinGetBitmap()</span> simply do not exist. I had to write code to avoid using these in PalmOS 3.1. But some of them are needed. For example, how do I directly copy bits into the display framebuffer if I cannot get a pointer to the framebuffer via <span>BmpGetBits( WinGetBitmap( WinGetDisplayWindow ()))</span>? I attempted to just dig into the structures of windows and bitmaps myself, but it turns out that the display bitmap is not a valid bitmap in PalmOS 3.1 at all. At the end, I realized that PalmOS 3.1 only supported MC68EZ328 and MC68328 processors, and both of them configure the display controller base address in the same register, so I just read it directly. As for palette setting, it is not needed since PalmOS 3.1 does not support color or palettes. Easy enough.
</p>
<h3>Making it work well</h3>
<h4>Initial data</h4>
<p><img src="https://dmitry.gr/images/rePalm-visor-screen-1.jpg" alt="Visor showing garbled OS5.2 touch screen calibration dialog"></p><p>Some data is needed by rePalm before it can properly boot: screen resolution and supported depths, hardware flags (eg: whether screen has brightness or contrast adjustment), and whether the device as an alert LED (yes, you read that right, more on this later). Thus rePalm does not boot until it gets a "continue boot" message that is sent by the code on the Visor once it collects all this info.
</p>
<h4>Sending display data</h4>
<p>The highest-bandwidth data we need to transfer between the Visor and the reSpring module is the display data. For example for a 160x160 scren at 16 bits per pixel at 60 FPS, we'd need to transfer 160x160x16x60 = 23.44Mbps. Not a low data rate at all to attempt on a 33MHz 68k CPU. In fact, I do not think this is even possible. For 4 bits-per-pixel greyscale the numbers look a little better: 160x160x4x60 = 5.86Mbps. But there is a second problem. Each message needs a full round trip. We are limited by Visor's interrupt latency and our general round-trip latency. Sadly that latency is as high as 2-4ms. So we need to minimize the number of packets sent. We'll come back to this later. Initially I just sent the data piecewise and displayed it onscreen. Did it work the first time? Actually, almost. The image to the right shows the results. All it took was a single byteswap to get it to work perfectly!
</p>
<p>It was quite slow, however - about 2 frames per second. Looking into it, I realized that the call to MemMove was one of the reasons. I wrote a routine optimized to move the large chunks of data, given that it was not overlapped and always aligned. This improved the refresh rate to about 8 frames per second on the greyscale devices. More improvement was needed. The major issue was the round trip time of copying data, waiting, copying it out, and so on. How do we minimize the number of round trips? Yup - compress the data. I wrote a very very fast lossless image compressor on the STM. It works somewhat like LZ, with a hashtable to find previous occurrences of a data pattern. The compression rations were very very good, and refresh rates went up to 30-40 FPS on the greyscale devices. Color Bejeweled became playable even!
</p>
<p>Actually getting the display data was also quite interesting. PalmOS 5 expects the display to just be a framebuffer that may be written to freely. While there are API to draw, one may also just write to the framebuffer. This means that there isn't really a way to get notified when the image onscreen changes. We could send screen data constantly. In fact, this is what I did initially. This depletes the Visor battery at about two percent a minute since the CPU is constantly busy. Clearly this is not the way to go. But how can we get notified when someone draws? The solution is a fun one: we use the MPU. We can protect the framebuffer from writes. Reads are allowed but any write causes an exception. We handle the exception by setting a timer for 1/60 of a second later, and then permit the writes and return. The code that was drawing them resumes, none the wiser. When our timer fires, we re-lock the framebuffer, and request to transfer a screenful of data to Visor. This allows us to not send the same data over and over. Sometimes writes to screen also change nothing, so I later added a second layer where anytime we send a screenful of data, we keep a copy, and next time we're asked to send, we compare, and do nothing if the image is the same. Together with compression, these two techniques bring us to a reasonable power usage and screen refresh rate.
</p>
<h4>Buttons, pen, brightness, contrast, and battery info</h4>
<p>Since the Visor can send data to the reSpring module anytime it wishes, sending button and pen info is easy, just send a message with the data. For transferring data the other way, the design is also simple. If the module requests an IRQ, the visor will send a NOP message, in reply the module will send its request. There are requests for setting display palette, brightness, contrast, or battery info. Visor will perform the requested action, and perhaps reply (eg: for battery info).
</p>
<h4>Microphone support</h4>
<p>The audio amp turned out to be quite miswired on v1 boards, but after some complicated reworks, it was possible to test basic audio recording functionality. It worked! Due to how the reworks worked, the qulity was not stellar, but I could recognize my voice as I said "1 2 3 4 5 6 7" to the voice memo app. But, in reality, amplifying the visor mic is a huge pain - we need a 40dB gain to get anything useful out of the ADC. The analog components of doing this properly and noise-free are just too expensive and numerous, so for v2 it was decided to just populate a digital mic on the board - it is actually cheaper. Plus, <em>no</em> analog is the best amount of analog for a board!
</p>

<h3>Polish</h3>
<h4>Serial/IrDA</h4>
<p>I support forwarding the Visor's serial port to reSpring. What is this for? HotSync (works) and IR beaming (mostly works). This is actually quite a hard problem to solve. To start with, in order to support PalmOS 3.1, one must use the <span>Old Serial Manager</span> API. I had never used them since PalmOS 4.5 introduced the <span>New Serial Manager</span> and I had almost never written any code for PalmOS before 4.1. The APIs are actually similar, and both quite hostile to what we need. We need to be able to be told when data arrives, without busy-waiting for it. Seemingly there is no API for this. Repeatedly and constantly checking for data works, but wastes battery. Finally I figured out that by using the "receive window" and "wakeup handler" both of which are halfway-explained in the manual, I can get what I need - a callback when data arrives. I also found that, while lightly documented, there is a way to give the Serial manager a larger receive buffer. This allows us to not drop received data even if we take a few milliseconds to get it out of the buffer. I was able to use all of this to wire up Visor's serial port to a driver in reSpring. Sadly, beaming requires a rather quick response rate, which is hard to reach with our round-trip latency. Beaming works, but not every time. Hotsync does work, even over USB.
</p>
<h4>Alarm LED</h4>
<p>Since rePalm supports alarm LEDs and some Visors have LEDs (Pro, Prism, and Edge), I wanted to wire one up to the other. There are no public API for LED access in the Handspring devices. Some reverse engineering showed that Handspring HAL does have a function to set the LED state: <span>HalLEDCommand()</span>. It does precisely what I want, and can be called simply as <span>TRAP #1; dc.w 0xa014</span>. There is an issue. Earlier versions of Handspring HAL lack this function, and if you attempt to call it, they will crash. "Surely," you might say, "all devices that support the LED implement this function!" Nope... Visor Prism devices sold in the USA do not. The EFIGS version does, as do all later devices. This convenient hardware-independent function was not available to me thus. What to do? Well, there are only three devices that have a LED, and I can detect them. Let's go for direct hardware access then! On the visor edge the LED is on GPIO K4, on the Pro, it is K3, and on the Prism it is C7. We can write this GPUI directly and it works as expected.
</p>
<p><img src="https://dmitry.gr/images/rePalm-visor-update.jpg" alt="Visor showing garbled OS5.2 touch screen calibration dialog"></p><p>There are two driver modes for LED and vibrator in rePalm - simple and complex. Simple mode has rePalm give the LED/vibrator very simple "turn on now" "turn off now" commands. This is suitable for a directly wired LED/vibrator. In the reSpring case we actually prefer to use the complex driver, where the OS tells us "here is the LED/vibrator pattern, here is how fast to perform it, this many times, with this much time in between. This is suitable for when you have an external controller that drives the LED/vibrator. Here we do have one: the Visor is our external controller. So we simply send these commands to the Visor and our downloaded code performs the proper actions using a simple state machine.
</p>
<h4>Software update</h4>
<p>I wanted reSpring to be able to self-update from SD card. How could this be accomplished? Well, the flash in the STM32 can be written by code running on the STM32, so logically it should not be hard. A few complications exist: to start with, the entire PalmOS is running form flash, including drivers for various hardware pieces. Our comms layer to talk to the Visor is also in there. So to perform the update we need to stop the entire OS and disable all interrupts and drivers. OK, that is easy enough, but among those drivers are the drivers for the SD card, where our update is. We need that. Easy to solve: copy the update to RAM before starting the update - RAM needs no drivers. But how do we show the progress to the user - our framebuffer is not real, making visor show it requires a lot of code and working interrupts. There was no chance this would work as normal.
</p>
<p>I decided that the best way to do this was to have the Visor draw the update UI itself, and just use a single SRAM location to show progress. Writing a single SRAM location is something our update process can do with no issues since the SRAM needs no drivers - it is just memory mapped. The rest was easy: a program to load the update into RAM, send the "update now" message, and then flash the ROM, all the while writing to the proper SRAM location the "percent completed". This required exporting the "send a message" API from the rePalm DAL for applications to use. I did that.
</p>
<h3>Onboard NAND</h3>
<h4>You wanted pain? Here's some NAND</h4>
<p>The reSpring board has 256MB of NAND flash on a QSPI bus. Why? Because at the time it was designed, I thought it would be cool, and it was quite cheap. NAND is the storage technology underlying most modern storage - your SD cards, your SSD, and the storage in your phone. But, NAND is hard - it has a number of anti-features that make it rather difficult to use for storage. First, NAND may not properly store data - error correction is needed as it may occasionally flip a bit or two. Worse, more bit flips may accumulate over time, to a point where error correction may not be enough, necessitating moving data when such a time approaches. The smallest addressable unit of NAND is a page. That is the size of NAND that may be read or programmed. Programming only flips one bits to zero, not the reverse. The only way to get one bits back is an erase operation. But that operates on a block - a large collection of pages. Because you need error correcting codes, AND bits can only be flipped from one to zero, overwriting data is hard (since the ECC code you use almost certainly will need more ones). There are usually limits to how many times a page may be programmed between erases anyways. There are also usually requirements that pages in a block be programmed in order. And, for extra fun, blocks may go bad (failing to erase or program). In fact a NAND device may ship with bad blocks directly from the factory! Clearly this is not at all what you think of when you imagine block storage. NAND requires careful management to use for storage. Since blocks die due to wear, caused by erasing, you want to evenly wear across the entire device. This may in turn necessitate movinig more data. At the same time while you move data, power may go out so you need to be careful when and what is erased and where it is written. Keeping a consistent idea of what is stored where is hard. This is the job of an FTL - a flash translation layer. An FTL takes the mess that is nand and presents it as a normal block device with a number of sectors which maybe read and written to randomly, with no concern for things like error correction, erase counts, and page partial programming limits.
</p>
<h4>To write an FTL...</h4>
<p>I had written an FTL long ago, so I had some basic idea of the process involved. This was, however, more than a decade ago. It was fun to try to do it again, but better. This time I set out with a few goals. The number one priority was to absolutely never lose any data in face of random power loss since the module may be removed from the Visor randomly at any time. The FTL I produced will never lose any data, no matter when you randomly cut its power. A secondary priority was to minimize the amount of RAM used, since, afterall, reSpring only has 8MB of it!
</p>
<p>The pages in the NAND on reSpring are 2176 bytes in size. Of that, 4 are reserved for "bad block marker", 28 are free to use however you wish, with <em>no</em> error correction protection, and the rest is split into 4 equal parts of 536 bytes, which, if you desire, the chip can error-correct (by using the last 16 of those bytes for the ECC code). This means that per page we have 2080 error-corrected bytes and 28 non-error-corrected bytes. Blocks are 64 pages each, and the device has 2048 blocks, of which they promise at least 2008 will be good from the factory. Having the chip do the ECC for us is nice - it has a special hardware unit and can do it much faster then our CPU ever could in software. It will even report to us how many bits were corrected on each read. This information is vital because it tells us about the health of this page and thus informs our decision as to when to relocate the data before it becomes unreadable.
</p>
<p>I decided that I would like my FTL to present itself as a block device with 4K blocks. This is the cluster size FAT16 should optimally use on our device, and having larger blocks allows us to have a smaller mapping table (the map from virtual "sector number" to real "page number"). Thus we'd treat two pages together as one always. This means that each of our virtual pages will have 4160 bytes of error-corrected data and 56 bytes of non-erorr corrected data. Since our flash allows writing the same page twice, we'll use the un-error-corrected area ourselves with some handmade error corection to store some data we want to persist. This will be things like how many times this block has been erased, same for prev and next blocks, and the current generation counter to figure out how old the information is. The handmade ECC was trivial: hamming code to correct up to one bit of error, and then replicate the info plus the hamming code three times. This should provide enough protection. Since this only used the un-error-corrected part of the pages, we can then easily write error-correctd-data over this with no issues. Whenever we erase a page, we write this data to it immediately. If we are interrupted, the pages around it have the info we need and we can resume said write after power is back on.
</p>
<p>The error-corected data contains the user data (4096 bytes of it) and our service data, such as what vitual sector this data is for, generation counter, info on this and a few neighboring blocks, and some other info. This info allows us to rebuild the mapping table after a power cycle. But clearly reading the entire device each power on is slow and we do not want to do this. We thus support checkpoints. Whenever the device is powered off, or the FTL is unmounted, we write a checkpoint. It contains the mapping data and some other info that allows us to quickly resume operation without scanning the entire device. Of course in case of an unexpected power off we do need to do a scan. For those cases there is an optimization too - a directory at the end of each block tells us what it contains - this allows the scan to read only 1/32nd of the device instead of 100% of it - a 32x speedup!
</p>
<p>Read and write requests from PalmOS directly map to the FTL layer's read and write. Except there is a problem - PalmOS only supports block devices with sector sizes of 512 bytes. I wrote a simple translation layer that does read-modify-write as needed to map my 4K sectors to PalmOS's 512-byte sectors, if PalmOS's request did not perfectly align with the FTL's 4K sectors. This is not as scary or as slow as you imagine it, because PalmOS uses FAT16 to format the device. When it does, it asks the device about its preferred block size. We repy with 4K and from then on, PalmOS's FAT driver only writes complete 4K clusters - which align perfectly with out 4K FTL sectors. The runtime memory usage of the FTL is only 128KB - not bad at all, if I do say so myself! I wrote a very torturous set of tests for the FTL and ran it on my computer over a few nights. The test simulated data going bad, power off randomly, etc. The FTL passed. There is actually a lot more to this FTL, and you are free to go look at the source code to see more.
</p>
<h3>One final WTF</h3>
<p>Among all this work, rePalm worked well, mostly. Occasionally it would lose a message from the Visor to the module or vice-versa. I spent a lot of time debugging this and came to a startling realization. The dual-ported SRAM does not actually support simultaneous access to the same address by both ports at once. This is documented in its datasheet as a "helpful feature" but it is anything but. Now, it might be reasonable to not allow two simultaneous writes to the same word, sure. But two reads should work, and a read and a write should work too (with a read returning the old data or the new data, or even a mix of the two). This SRAM instead signals "busy" (which is otherwise never does) to one side. Since it is not supposed to ever be busy, and the Springboard slot does not even have a BUSY pin, these signals were wired nowhere. This is where I found this stuff in the footnote in the manual. It said that switching the chip to SLAVE mode and raising the BUSY pins (which are now inputs) to HIGH will allow simultaneous access. Well, it sort of does. There is no more busy signalling, but sometimes a write will be <em>DROPPED</em> if it is executed concurrently with a read. And a read will sometimes return <em>ZERO</em> if executed concurrently with another read or write, even if the old and new data were both not zero. There seems to be no way around this. Another company's dual-ported SRAM had the same nonsense limitation, leading me to believe that nobody in the industry makes REAL dual-ported SRAMs. This SRAM has something called "semaphores" which can be used to implement actual semaphores that are truly shared by both devices, but otherwise it is not true dual-ported RAM. Damn! 
</p>
<p>Using these semaphores would require significant rewiring: we'd need a new chip select line going to this chip, and need to invent a new way to interrupt the STM since the second chip select line would be now used to access semaphores. This was beyond my rework abilities, so I just beefed up the protocol to avoid these issues. Now the STM will write each data word that might be concurently read 64 times, and then read it back to verify it was written. The comms protocol was also modified to never ever use zeroes, and thus if a zero is seen, it is clear that a re-read was necessary. With these hacks the communication is stable, but in the next board rev rev I think we'll wire up the semaphores to avoid this nasty hack!
</p>

<h2>More real hardware</h2>
<h3>rePalm-MSIO</h3>
<p><a href="https://dmitry.gr/images/rePalm-MSIO_board.jpg"><img src="https://dmitry.gr/images/rePalm-MSIO_board.jpg" alt="rePalm-MSIO first board"></a></p><p>After <a href="https://dmitry.gr/?r=05.Projects&amp;proj=31.%20Memory%20Stick">documenting the Sony MemoryStick protocol</a>, an opportunity presented itself - why not a rePalm version on a MemoryStick? In theory, I could get a microcontroller to act as a MemoryStick device, load a program unto the host Sony PalmOS device, and then take over it, like reSpring did. That was the idea, of course. The space is tight, and timing requirement insane. The fact that the MemoryStick protocol is so much unlike any normal sane bus means that there will be no simple solutions. However, I was determined to make this work.
</p>
<h4>MCU selection</h4>
<p>STM32F429 and an SDRAM chip together would take up too much space to fit inside a MemoryStick slot. Instead, a 64-pin STM32H7 chip is used. It has 1.25MB of internal ram, which is a bit little for PalmOS. Luckily, it supports a rather rare thing: a read/write QSPI interface - perfect for interfacing with QSPI PSRAM chips like APS6404L from APMemory! This allows for 8MB of RAM without taking up a lot of board space or needing a boatload of pins! STM32H7 is also a Cortex-M7, which is quite an improvement from the Cortex-M4 core in the STM32F429. M7 is faster per-cycle, and has a cache! The fact that STM32F429 had no cache was a serious handicapping factor for it when running code from RAM, since the RAM was limited to half the core clock speed. With a small-enough working set, the M7 can operate at full speed from cache! Cool! There is also <span>TCM</span> - some memory near the core that always operates at full speed with no delay or wait-states!
</p>
<p>I laid out the board such that it would fit into the MemoryStick slot. It is a 4-layer board (which is apparently very cheap now). This makes routing easier and signal integrity better. With the proper board thickness, there is just enough space for the chips to fit. It all works, inserts, clicks, everything! Pretty amazing, actually. Of course, there were errors, but by the second revision of the board, only one bodge wire was needed, as you can see in the picture. The board is precisely the size of a MemoryStick. There is extra that sticks out, those are the debugging headers and it is break-away. I have one where I did break it away and it is amazing how well it fits inside.
</p>

<h4>The bugs...</h4>
<p>Of course, this being an STM chip, there were bugs. The chip would sometimes lock up entirely when executing from QSPI RAM. When consulted, ST suggested changing the MPU parameters to make the QSPI RAM uncacheable. This is an idiotic suggestion, because even if it worked (spoiler: it does not), it would make that RAM slow beyond any degree of usefulness. In any case, when I tried that, the RAM gets corrupted. I verified with bus traces and presented ot STM. Eventually they admitted that any writes to the QSPI interface that are not sequential and word-sized will cause corruption. Somehow, that info tells me precisely what was the only test they ever ran on this peripheral. Sigh...
</p>
<p>Luckily, with the cache on, the dirty cache-line eviction will always sequentially write an integer number of words, so there is hope. Sadly, the chip would work for a while, and then lock up. The lock up was very strange, my debugger would be unable to connect to the core in this state at all, but it could access the debug access port itself. This lead me to believe that it was not the core that locked up but the internal AHB fabric. I was able to confirm this by attaching to another debugger access port (the one on AHB3), where I could look around but have no access to the main AHB busses. STM had no ideas.
</p>
<p>Given what I knew about how AHB buses works, guesses on how ST likely designed the arbiters, and how ST likely wired up their QSPI unit to it all, I guessed at the issue, and a workaround the might work. After some prototyping, I can confirm that it does. The performance cost is about 20% (compared to no workaround enabled), but at least no more hangs. Why am I being so cagey about what the workaround is? Well, while denying the issue exists, STM asked for the precise details of my workaround once they heard I had found one. Apparently an actually-important client also hit this issue. I am currently refusing to disclose the workaround until they agree to admit the issue. So far it is a stalemate, which is fine - I am losing no sales over it. Them...?
</p>
<h4>MSIO low level</h4>
<p>The main signal that controls the protocol phases is <span>BS</span>, and it always leads the actual state transition by a cycle, which makes it very hard to use for anything. If only it were not one cycle early, I could use it (and its inverse) as chip-selects and try to use the hardware SPI bus units somehow. After some head-scratching, a solution became evident. Two flip flops will do. Running the BS signal through them will delay it a cycle. Finding a dual-negative-edge-triggered flip-flop turned out to be impossible, so an inverter was thrown into the mix, so that I could use an easily-available <span>SN74LVC74A</span>.
</p>
<p>With the BS signal delayed, it could be used as chip select for some SPI units. To make this work, I wired <em>THREE</em> SPI units together. The first edge of <span>BS</span> Triggers a DMA channel that enables three SPI units: one receives the <span>TPC</span>, and the second and third are ready to receive the data that follows. We'll have no time to validate the <span>TPC</span> in the meantime, so we prime the SPI unit to receive it no matter what. This is harmless. This first <span>BS</span> edge also triggers a software interrupt. Assuming not too many delays, we'll arrive into the IRQ after the TPC has already been received and, if the transaction is a write, the data is already on on the way coming in. If we are less lucky, data might have even already been entirely received. Here we can validate the <span>TPC</span> and check its direction. If this is a READ, we need to send the handshaking pattern immediately, so we use one of the SPI units to do that now. While that goes on, we find the data and queue it up for transmission, telling the SPI unit to also send the CRC after it. If this was a WRITE, we had two SPI units receiving the data. One copied the data to RAM, the second to the CRC unit (STM32H7 cannot CRC incoming data if we do not up front know the length). We quickly check the CRC and configure one of the SPI units to send the handshaking pattern to acknowledge the data.
</p>
<p>"Now, this all sounds very fragile," an astute observer would say. Yes! Very. It also means that we cannot ever disable interrupts for very long, since there is only a few cycles of leeway between the data being sent to us and a reply being needed to avoid the host timing out. I had to rearchitect rePalm kernel's interrupt handling a little bit, to allow some interrupts to <em>NEVER</em> be disabled, in return for some concessions from those interrupt handlers: they do not make any syscalls or modify any state shared with any other piece of code. So then how do we interface with them? When an MSIO transaction finishes, the data is placed into a shared buffer, and a software interrupt is triggered, which is handled normally by normal code with normal constraints. This can be disabled, prioritized, etc, since it is not time critical anymore. Of course, all the time-critical code must be run from the <span>ITCM</span> (the tightly-coupled instruction memory) to make the deadlines.
</p>
<p>When the STM32H7 runs at 320MHz, this works most of the time with newer palm devices, since they run the MSIO interface at 16MHz, giving me some breathing room. Older devices like the S500C are tougher. They run the MSIO bus at 20MHz, and the timings are very tight. Things work well, but if the core is waiting for instruction fetch from QSPI, it will not jump to the interrupt handler till that compltes, causing larger latency. Sometimes this causes an MSIO interrut handler to be late and miss the proper window to ACK some transaction. My host-side driver retries and papers over this. The real solution is a tiny FPGA to offload this from the main MCU. I'm looking into this.
</p>
<h4>MSIO high level</h4>
<p><a href="https://dmitry.gr/images/rePalm-MSIO_S500.jpg"><img src="https://dmitry.gr/images/rePalm-MSIO_S500.jpg" alt="rePalm-MSIO running on a PEG-S500C"></a></p><p>As there exist no MSIO drivers for rePalm, I had to write and provide them. But how would a user get them unto the device? In theory, as far as my reverse-engieering can tell, a MemoryStick may have multiple functions, possibly memory and one or more IO functions. No such stick was observed in the wild, so I set out to create the first. Why not? The logic of how it should work is rather simple - function 0xFF should be memory, and any other unused function number could be for rePalm IO. I picked the function number 0x64. Why pretend to be memory at all? To give the user the driver, of course!
</p>
<p>My code does the minimum to pretend to be a read-only MemoryStick with 4MB of storage. As MemorySticks are raw NAND devices, my code pretends to be a perfect one - no bad blocks, no error correction ever needed. The fake medum is "formatted" with FAT12 and contains a rather curious filesystem indeed. To support <em>ALL</em> the sony devices, the driver is needed in a few places. Anything with PalmOS 4.0 or later will show files in <span>/PALM/LAUNCHER</span> to the user, and will auto-launch <span>/PALM/START.prc</span> on insertion. Anything with earlier PalmOS versions will only allow the user to browse <span>/PALM/PROGRAMS/MSFILES</span>. All but the first Sony devices also had another way to auto-launch an executable on stick insertion - a Sony utiliy called "MS AutoRun". It reads a config file at <span>/DEFAULT.ARN</span> and loads the specified program to RAM on insertion. Auto-run is never triggered if the MemoryStick was aleady inserted at device boot, so we cannot rely on it. This is why we need the file to be itself visible and accessible to the user for manual launching. Let's count then, how many copies of the driver app our MemoryStick needs. One in <span>/PALM/LAUNCHER</span>, one in <span>/PALM/PROGRAMS/MSFILES</span>, and one as <span>/PALM/START.prc</span>. Three copies. Now, this will not do! If only FAT12 supported hard links...
</p>
<p>But, wait, if the filesystem is read-only, it <em>DOES</em> support hard links! More than one directory entry may reference the same cluster chain. This is only a problem when the file is deleted, which does not happen to a read-only filesystem. The filesystem thus contains a <span>PALM</span> directory in the root, That contains <span>DEFAULT.ARN</span> file, pointing to a cluster with its contents, a <span>PROGRAMS</span> directory, a <span>LAUNCHER</span> directory, and a directory entry with the name <span>START.PRC</span> pointing to the first cluster of our driver. <span>PROGRAMS</span> contains an <span>MSFILES</span> directory, which itself contains another directory entory pointing to the driver, this one with the name <span>DRIVER.PRC</span>. <span>/PALM/LAUNCHER</span> contains the third directory entry pointing to the driver, also named <span>DRIVER.PRC</span>. PalmOS does not do a file system check on read-only media, so no issue is ever hit - it all works.
</p>
<h4>MSIO performance</h4>
<p>Some Sony devices have actual exported MSIO API in their MemoryStick drivers which I was able to reverse engineer (<a href="https://www.reddit.com/r/Palm/comments/12li6t5/complete_reverseengineering_of_the_msio_api/?">and publish</a>). Some others did not, but Sony published updates that included such API. Usually these updates came with MSIO peripherals like the MemoryStick Bluetooth adapter or the MemoryStick Camera. And some devices never had any official MSIO suport at all. I wanted to support them all, and since I had already reverse engineered how the MemoryStick Host chip (MB86189) worked, I was able to just write my own drivers, talking to it directly. This worked for some devices. Others do not have direct access to the chip, since the DSP controls it. Sony DSP is not documented, the firmware is encrypted, and the key is not known. Here, I was stuck for a while. Eventually I was able to figure out just enough to be able to send and receive raw <span>TPC</span>s via the DSP. This worked well on almost all devices, except the N7xx series devices. Their DSP firmware was the oldest of all (as far as I can tell) and the best bandwidth I was able to coax out of it was 176Kbit/s. Needless to say that this is not quite good enough for live video (basically what rePalm does). It works, but the quality is not great.
</p>
<p>As MSIO allows transfers of no more than 512 bytes per transfer, transferring screen image data is complex. The same compression is used here as was used in reSpring. Even then, performance varies based on the device and screen configuration. On low-resolution devices, everything is fast. On high-resolution ones (except N7xx), 35 FPS is reachable in 16bits-per-pixel mode. It is faster on greyscale devices. The lone PalmOS 4 HiRes+ device (NR70V) lags behind at around 20FPS. This is because there is simply so much data to transfer each frame - 300KB.
</p>
<h4>Other loose ends</h4>
<p>Curiously, it seems that Asus licensed the MemoryStick IP from Sony, so the Asus PalmOS devices (s10 and s60 families) also use MemoryStick. I added support for them. For each device,  I wired up as much as possible to rePalm. Devices with a LED have it wired to the attention manager, devices with the vibrate motor have that wired up as well. Sound is a bit more complex. Some of these devices had a DSP for MP3 decoding, but the ability to play raw sampled sound is limited, since 68K was unlikely to be able to do it fast enough anyways. There exists a sony API to play 8KHz 4-bits-per-sapme ADPCM. I considered wiring that up to the sound output of rePalm, but did not get around to it. It is likely not worth it as the quality will be atrocious. I did consider the alternative - have rePalm encode its output as MP3, and somehow find a way to feed that to the DSP, but I was stymied in my efforts. In most of the devices, the DSP firmware reads the MP3 file directly from the MemoryStick, bypassing the OS entirely, leading me to believe that I may not find a way to inject MP3 data even if I made it.
</p>
<p>Initially, I did the development on STM32H7B0RB. This variant has only 128KB of flash, which is, of course, not enough to contain PalmOS. I used some of the RAM to contain a ROM image, which I loaded over SWD each time. This worked well enough, but was not really fun as it could not be used away from a computer. Luckily, I was able (with a lot of help from an unnamed source) to get some of the STM32H7 chips with 2MB of internal flash. This <em>IS</em> enough to fit PalmOS, so now I have variants that boot directly on insertion. The latest boards also have some onboard NAND flash that acts as a built-in storage device for user using my FTL, mentioned before. The photo album (linked above) has more photos and videos! <a href="https://photos.app.goo.gl/4NGYzd1ejggu1RV3A">Here is one</a>. Enjoy!
</p>
<h3>AximX3</h3>
<p><a href="https://dmitry.gr/images/rePalm-AximX3.jpg"><img src="https://dmitry.gr/images/rePalm-AximX3.jpg" alt="Axim X3 running PalmOS"></a></p><p>This was a fun target just for shits and giggles. As this runs an ARMv5T CPU, my kernel was forced to adapt to this world. It was not terribly difficult and it works now. Curiously, this device is rather similar internally to the Palm Tungsten T3, so this same rePalm build can run with few modifications on the T|T3 as well.
</p>
<p>I put a lot of work into this device. Luckily, a lot of the initial investigation of the hardware was already done as part of my <a href="https://github.com/uARM-Palm/uARM">uARM-Palm</a> project. Almost everything works. Audio in and out work, SD card works, infrared works, touch and buttons work, battery reporting works, and the screen works. Missing is only USB and sleep/wake. The first I see no point in, the second is complicated by the built-in bootloader. Initial builds of this used a WinCE loader I wrote to load the ROM into RAM and run from there. Further investigation of the device ROM indicated to me that there is a rather complete bootloader there, capable of flashing the device ROM from the SD card. I decided to exploit that, and with some changes, now rePalm can be flashed to ROM of the device and boot directly. Yes!
</p>
<p>How? The stock bootloader has a mode for this. If an image file is placed on the SD card as <span>/P16R_K0.NB0</span>, the card is inserted, jog wheel select and the second app button are held, and the device resetted, it'll flash the image to flash, right after the bootloader. This can be used to flash rePalm, or to reflash the stock image. Depending on the AximX3 version (there are three), the amount of flash and RAM differs. rePalm detects the available RAM and uses it all!
</p>
<h3>STM32F469 Discovery Board</h3>
<p><a href="https://dmitry.gr/images/rePalm-STM32F469DISCO.jpg"><img src="https://dmitry.gr/images/rePalm-STM32F469DISCO.jpg" alt="STM32F469DISCO board running PalmOS"></a></p><p>This was a quick little hack to see in real life PalmOS running on a 3x density display. No such device ever shipped. The <a href="https://www.st.com/en/evaluation-tools/32f469idiscovery.html">STM32F469DISCOVERY</a> board has a 480x800 display, of which 480x720 is used as a 3x density display with a dynamic input area. This board has a capacitive touch screen, which makes it ill-suited for PalmOS. Capacitive touch screens are very bad for precise tapping of small elements, since your finger would normally obscure whatever it is that you are trying to tap. This screen being rather large helps a little, but not really all that much. I got this board working well enough to see what it is like, but put little work into it afterwards. Screen, touch, and SD card are the only things supported. It does not help that just like the STM32F429, STM32F469 lacks any cache, making it rather slow when running out of SDRAM.
</p>

<h3>RP2040</h3>
<p><a href="https://dmitry.gr/images/rePalm-RP2040.jpg"><img src="https://dmitry.gr/images/rePalm-RP2040.jpg" alt="Raspberry Pi Pico running PalmOS"></a>
<a name="_TOC_da19cdc85215569c48f1e5adbb0dcceb"></a></p><h4>It is possible!</h4>
<p>How little RAM/CPU does PalmOS 5 really require? Since rePalm had support (at least in theory) for Cortex-M0, I wanted to try on real hardware, as previously the support was tested on CortexEmu only. There does happen to be one Cortex-M0 chip out there with enough ram - the RP2040 - the chip in the $4 <a href="https://www.raspberrypi.com/products/raspberry-pi-pico/">Raspberry Pi Pico</a>. I then sought out a display with a touchscreen that could be easily bought. There were actually not that many options, but <a href="https://www.waveshare.com/pico-restouch-lcd-2.8.htm">this one</a> seemed like a good fit. It turned out, after some investigation, that driving it properly and quickly will not be at all easy. RP2040's special sauce - the PIO - to the rescue! <a href="https://dmitry.gr/?r=06.%20Thoughts&amp;proj=09.ComplexPioMachines">I found a way to do it</a>. I switched the resistors on the screen's board from "SPI" to "SDIO" to enable the SD card, and I wired up the LED to be the alarm LED for PalmOS. Those were the easy things.
</p>
<p>As this project depends on some undocumented behaviour in the Cortex-M chips, it was always unknown what would happen in some cases. For example, Cortex-M3 causes a <span>UsageFault</span> when you jump to an address without the bottom bit set, indicating a switch to ARM mode. What would Cortex-M0 do? Turns out - it simply causes a <span>HardFault</span>. <a href="https://dmitry.gr/?r=05.Projects&amp;proj=27.%20m0FaultDispatch">m0FaultDispatch</a> to the rescue! It is able to categorize all the causes of a <span>HardFault</span> and wire them to the proper place. I did find one difference from the Cortex-M3. When the Cortex-M3 executes a <span>BX PC</span> instruction, it will execute a jump to the current address plus 4, in ARM mode. This differs from what ARMv5 chips do when you execute that same instruction in Thumb mode. They jump to the current address plus 4, rounded down to the nearest multiple of 4, in ARM mode. This difference my JIT and emulator code alrady handled. But Cortex-M0 does yet a third thing in this case. It actually seems to treat the actual instruction as invaild. PC is not changed, mode is not changed, and a <span>HardFault</span> is taken right on the instruction itself. Curiously, this does not happen if another non-PC register with the low bit clear is used. Well, in any case, I adjusted the JIT and the emulator code to handle this. I also modified CortexEmu to emulate this properly.
</p>
<h4>Memories</h4>
<p>RP2040 lacks any flash, it uses an external Q/D/SPI flash for code and data storage. This is convenient when you have a lot of data. For rePalm this means we can have a ROM as big as the biggest flash chip we can buy. The Pi Pico comes with a 2MB chip, so I targetted that. The RAM situation is much tighter. There is just 264KB of RAM in there. This is not much. The last PalmOS device to have this little RAM ran PalmOS 1.0. But it is worth trying. One of the largest RAM expenditures are graphics. The primary one is the framebuffer. PalmOS assumes that the display has a framebuffer that is directly accessible by the CPU. This means that if I wanted to use the entire 320x240 display in truecolor mode, the framebuffer would occupy 150Kb. Oof! Well, how much <em>IS</em> acceptable?
</p>
<p>Some experimentation followed. To boot successfully and to launch the launcher, preferences app, and the digitizer calibration panel successfully, approximately 128KB of dynamic RAM is necessary. The various default databases as well as PACE temporary databases in the storage heap mandate a storage heap of at least 50KB. A 64KB minimum storage heap size is preferred, really, so we do not immediately run out of space at boot. And rePalm's DAL needs at least 15KB of memory for its data structures and about 24KB for the kernel heap where stacks and various other data structures are allocated. Let's add those up. The sum is 231KB. that leaves at most 33KB for the framebuffer. There are a few options. We can use the whole screen at 2 bits per pixel (4 greys). This will need a 18.75KB framebuffer. We can use a square 240x240 screen at 4 bits per pixel, for a 28.125KB framebuffer. We can also use the standard low-density resolution of 160x160 at a whopping 8 bits per pixel (the only non-greyscale option).
</p>
<p>One might notice that the above memory areas did not include a JIT translation cache. This is correct. While my JIT does indeed support targetting the Cortex-M0, there simply is not enough space to make it worthwhile. I instead enabled the <span>asmM0</span> ARM emulator core since it needs no extra space of any sort. Not wonderful, but oh well. We knew all along that compromises would need to be made! As long as I'm just showing off, let's have a full-screen experience, with a dynamic input area and all! 320x240 it is! The second core of the RP2040 is not currently used (yet).
</p>
<h4>PACE again</h4>
<p>My previously-mentioned Cortex-M3-targetting patched <span>PACE</span> is of no use on a Cortex-M0. Combine this with the fact that I cannot use the JIT means that all the 68K code will be running under double emulation (68K emulated by ARM, ARM itself emulated in thumb). It was time to write a whole new 68k emulator, in Thumb-1 assembly, of course. I give you <span>PACE.m0</span>. It is actually rather fast, competing well with Palm's ARM PACE in performance, as tested on my Tungsten T3. It really helped make the RP2040 build usable. It is now no slower than a Tunsten T was.
</p>

<h2>So where does this leave us?</h2>
<p>There is still a lot to do: implement BT, WiFi, USB, debug NVFS some more, and probably many more things. However, I am releasing some little preview images to try, if you happen to have an STM32F429 discovery board, an AximX3, a raspberryPi Pico with the proper screen. No support for USB. Anyways if you want to play with it, here: <a href="https://drive.google.com/file/d/1u8zcfhuRAaH1dAfQWU3pHrjZMHxFsHBn/view?usp=share_link">LINK</a>. I am also continuing to work on the reSpring/MSIO/and ther hardware options and you might even be able to get your hands on one soon :) If you already have a reSpring module (you know who you are), the archive linked to above has an update to 1.3.0.0 for you too.
</p>

<h2>Source Code</h2>
<h3>Source intro</h3>
<p><a href="https://dmitry.gr/images/rePalm_sources_0000.tar.bz2">Version 0000 source download</a> is here. This is a very very very early release of the source code, just to allow people to browse this codebase and see what it is. The README explains the basic directory structure, and there is a LICENSE document in each directory. Building this requires a modern (read: mine) build of PilRC (included) and an ARM cross-gcc toolchain. Some builds require a PalmOS-specific 68k toolchain too, <a href="https://www.reddit.com/r/Palm/comments/p81m58/announce_new_gcc_or_palmos_again/">from here</a>, for example.
</p>
<h3>Building basics</h3>
<p>Building a working image is a multi-step process. First the DAL needs to be built. This is accomplished by running <span>make</span> in the <span>myrom/dal</span> directory. Some params need to be passed to it. For example, to build for rPI-Pico with the waveshare display, the command <span>make BUILD=RP2040_Waveshare</span> will do. For some cases, makefile itself will need to be edited. For the abovementioned build, for example, we do not want to use jit, preferring the emulator instead. To do this, you'll want to comment out the line <span>ENABLE_JIT		= yes</span> and uncomment the one that says <span>EMU_CORE	= asmM0</span>. This will build the DAL.prc. The next step is to build a full ROM image. This is done from the <span>myrom</span> directory. Again, <span>make</span> is used. The parameters now are the build type (which determines the ROM image parameters) and the directory of files to include in the ROM. For the RP2040_Waveshare build, the proper incantation is <span>make RP2040_Waveshare FILESDIR=files_RP2040_Waveshare</span>. The files directory given already contains some other things from rePalm, like PACE and rePalm information preferences panel.
</p>
<h3>Building PACE</h3>
<p>The PACE patch is a binary patch unto PACE. It is built in a few steps. First the patch itself is assembled using <span>make</span> in the <span>myrom/paceM0</span> directory. This will produce the patch as a ".bin" file. Then using the <span>patchpace</span> tool (which you must also build) you can apply this patch to an unmodified PACE.prc file (a copy of which can be found, for exmaple, in the <span>AximX3</span> directory). This patched pace can now replace the stock one in the destination files directory.
</p>


<h2>Article update history</h2>
<ol>
<li>image above was updated to v00001: jit is now on (much faster), RTC works (time), notepad added, touch response improved</li>
<li>image above was updated to v00002: grafitti area now drawn, grafitti works, more apps added (Bejeweled removed for space reasons)</li>
<li>image above was updated to v00003: ROM is now compressed to allow more things to be in it. This is ok since we unpack it to RAM anyways. some work done on SD card support</li>
<li>Explained how LDM/STM are translated</li>
<li>Wrote a bit about SD card support</li>
<li>Wrote a bit about serial port support</li>
<li>Wrote a bit about Vibrate &amp; LED support</li>
<li>Wrote the first part about NetIF drivers</li>
<li>image above was updated to v00004: some drawing issues fixed (underline under memopad text field), alert LED now works, SD card works (if you wire it up to the board)</li>
<li>image above was updated to v00005: some support for 1.5 density displays works so image now uses the full screen</li>
<li>Wrote the document section on 1.5-density display support</li>
<li>Wrote the document section on DIA support and uploaded v000006 image with it</li>
<li>Wrote a section on <span>PACE</span>, uploaded image v000007 with much faster 68k execution and some DIA fixes</li>
<li>Uploaded image v000008 with IrDA support</li>
<li>Wrote about audio support</li>
<li>Wrote about reSpring</li>
<li>Uploaded image v000009 with preliminary audio support</li>
<li>Uploaded image v000010 with new JIT backend and multiple JIT fixes</li>
<li>Uploaded image v000011 with an improved JIT backend and more JIT fixes, and an SD-card based updater. Wrote about the Cortex-M0 backend</li>
<li>Wrote a lot about reSpring hardware v1 bring up and current status</li>
<li>Uploaded STM32F429 discovery image v000012 with significant speedups and some fixes (grafiti, notepad)! (this corresponds to rePalm v 1.1.1.8)</li>
<li>Uploaded STM32F429 and, <b>for the first time ever</b>, reSpring images for v 1.3.0.0 with many speedups, wrote about mic support and Zodiac support</li>
<li>Apr 15, 2023: PACE for M0, rePalm hardware update: MSIO, AximX3, RP2040, new downloads</li>
<li>Sep 3, 2023: Source dode posted for the first time</li>
</ol>


<!--- We do not show this to the user, but ToC system will index this and we'll get a link to comments in the ToC -->










					
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Have I been Flocked? – Check if your license plate is being watched (267 pts)]]></title>
            <link>https://haveibeenflocked.com/</link>
            <guid>46170302</guid>
            <pubDate>Sat, 06 Dec 2025 03:16:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://haveibeenflocked.com/">https://haveibeenflocked.com/</a>, See on <a href="https://news.ycombinator.com/item?id=46170302">Hacker News</a></p>
Couldn't get https://haveibeenflocked.com/: Error: Request failed with status code 429]]></description>
        </item>
        <item>
            <title><![CDATA[YouTube caught making AI-edits to videos and adding misleading AI summaries (360 pts)]]></title>
            <link>https://social.growyourown.services/@FediTips/115668457530054406</link>
            <guid>46169554</guid>
            <pubDate>Sat, 06 Dec 2025 01:15:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://social.growyourown.services/@FediTips/115668457530054406">https://social.growyourown.services/@FediTips/115668457530054406</a>, See on <a href="https://news.ycombinator.com/item?id=46169554">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Sam Altman's Dirty DRAM Deal (301 pts)]]></title>
            <link>https://www.mooreslawisdead.com/post/sam-altman-s-dirty-dram-deal</link>
            <guid>46169224</guid>
            <pubDate>Sat, 06 Dec 2025 00:24:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mooreslawisdead.com/post/sam-altman-s-dirty-dram-deal">https://www.mooreslawisdead.com/post/sam-altman-s-dirty-dram-deal</a>, See on <a href="https://news.ycombinator.com/item?id=46169224">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="ltr" data-id="content-viewer" data-rce-version="10.151.0" data-hook="post-description"><p data-breakout="normal"><h3 dir="auto" id="viewer-d069j168"><span><strong><span>Or: How the AI Bubble, Panic, and Unpreparedness Stole Christmas</span></strong></span></h3></p><p dir="auto" id="viewer-iyj63346"><span><em><span>Written by Tom of Moore’s Law Is Dead</span></em></span></p><p dir="auto" id="viewer-uoucf348"><span><em><span>Special Assistance by KarbinCry &amp; kari-no-sugata</span></em></span></p><div id="viewer-fnmwj1929" data-breakout="normal"><figure data-hook="figure-IMAGE"><div id="fnmwj1929" data-hook="image-viewer"><wow-image id="cd85b6_f91e58b7b125467bb253041e09ed5d20~mv2.png" data-image-info="{&quot;containerId&quot;:&quot;fnmwj1929&quot;,&quot;alignType&quot;:&quot;center&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;isLQIP&quot;:true,&quot;isSEOBot&quot;:false,&quot;lqipTransition&quot;:&quot;blur&quot;,&quot;encoding&quot;:&quot;AVIF&quot;,&quot;imageData&quot;:{&quot;width&quot;:1357,&quot;height&quot;:764,&quot;uri&quot;:&quot;cd85b6_f91e58b7b125467bb253041e09ed5d20~mv2.png&quot;,&quot;name&quot;:&quot;&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-motion-part="BG_IMG fnmwj1929" data-bg-effect-name="" data-has-ssr-src="true" data-animate-blur="" data-is-responsive="true"><img src="https://static.wixstatic.com/media/cd85b6_f91e58b7b125467bb253041e09ed5d20~mv2.png/v1/fill/w_49,h_28,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_avif,quality_auto/cd85b6_f91e58b7b125467bb253041e09ed5d20~mv2.png" alt="ree" data-pin-url="https://www.mooreslawisdead.com/post/sam-altman-s-dirty-dram-deal" data-pin-media="https://static.wixstatic.com/media/cd85b6_f91e58b7b125467bb253041e09ed5d20~mv2.png/v1/fill/w_1357,h_764,al_c,q_90/cd85b6_f91e58b7b125467bb253041e09ed5d20~mv2.png" draggable="false"></wow-image></div></figure></div><p data-breakout="normal"><h4 dir="auto" id="viewer-mwk4q619"><span><strong><span><u><span>Introduction — The Day the RAM Market Snapped</span></u></span></strong></span></h4></p><div id="viewer-bqpds2571" data-breakout="normal"><figure data-hook="figure-IMAGE"><div id="bqpds2571" data-hook="image-viewer"><wow-image id="cd85b6_5da956c69d6a4fe0a34c46832933c897~mv2.jpg" data-image-info="{&quot;containerId&quot;:&quot;bqpds2571&quot;,&quot;alignType&quot;:&quot;center&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;isLQIP&quot;:true,&quot;isSEOBot&quot;:false,&quot;lqipTransition&quot;:&quot;blur&quot;,&quot;encoding&quot;:&quot;AVIF&quot;,&quot;imageData&quot;:{&quot;width&quot;:1308,&quot;height&quot;:417,&quot;uri&quot;:&quot;cd85b6_5da956c69d6a4fe0a34c46832933c897~mv2.jpg&quot;,&quot;name&quot;:&quot;&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-motion-part="BG_IMG bqpds2571" data-bg-effect-name="" data-has-ssr-src="true" data-animate-blur="" data-is-responsive="true"><img src="https://static.wixstatic.com/media/cd85b6_5da956c69d6a4fe0a34c46832933c897~mv2.jpg/v1/fill/w_147,h_47,al_c,q_80,usm_0.66_1.00_0.01,blur_2,enc_avif,quality_auto/cd85b6_5da956c69d6a4fe0a34c46832933c897~mv2.jpg" alt="ree" data-pin-url="https://www.mooreslawisdead.com/post/sam-altman-s-dirty-dram-deal" data-pin-media="https://static.wixstatic.com/media/cd85b6_5da956c69d6a4fe0a34c46832933c897~mv2.jpg/v1/fill/w_1308,h_417,al_c,q_85/cd85b6_5da956c69d6a4fe0a34c46832933c897~mv2.jpg" draggable="false"></wow-image></div></figure></div><p dir="auto" id="viewer-vficr646"><span><span>At the beginning of November, I ordered a 32GB DDR5 kit for pairing with a Minisforum BD790i X3D motherboard, and three weeks later those very same sticks of DDR5 are now listed for a staggering $330– a 156% increase in price from less than a month ago! At this rate, it seems likely that by Christmas, that DDR5 kit alone could be worth more than the entire Zen 4 X3D platform I planned to pair it with! How could this happen, and more specifically – how could this happen THIS quickly? Well, buckle up! I am about to tell you the story of Sam Altman’s Dirty DRAM Deal, or: How the AI bubble, panic, and unpreparedness stole Christmas...</span></span></p><p dir="auto" id="viewer-7zi9o4292"><span><span>But before I dive in, let me make it clear that my RAM kit’s 156% jump in price isn’t a fluke or some extreme example of what's going on right now. Nope, and in fact, I'd like to provide two more examples of how how impossible it is becoming to get ahold of RAM - these were provided by a couple of our sources within the industry:</span></span></p><div data-breakout="normal"><ol><li dir="auto" aria-level="1"><p dir="" id="viewer-dtipn996"><span><span>One source that works at a US Retailer, stated that a RAM Manufacturer called them in order to inquire if they might buy RAM from </span><em><span>them</span></em><span>&nbsp;to stock up for their other customers.  This would be like Corsair asking a Best Buy if they had any RAM around.</span></span></p></li><li dir="auto" aria-level="1"><p dir="" id="viewer-mb4up1194"><span><span>Another source that works at a Prebuilt PC company, was recently given an estimate for when they would receive RAM orders if they placed them now…and they were told December…of </span><strong><u><span>2026</span></u></strong><span>!</span></span></p></li></ol></div><p dir="auto" id="viewer-nzsp6656"><span><span>So what happened?&nbsp; Well, it all comes down to three perfectly synergistic events:</span></span></p><div data-breakout="normal"><ol><li dir="auto" aria-level="1"><p dir="" id="viewer-h98k11392"><span><span>OpenAI executed </span><strong><u><span>two</span></u></strong><span>&nbsp;unprecedented RAM deals that took everyone by surprise.</span></span></p></li><li dir="auto" aria-level="1"><p dir="" id="viewer-h0f6f1540"><span><span>The secrecy and size of the deals triggered full-scale panic buying from everyone else.</span></span></p></li><li dir="auto" aria-level="1"><p dir="" id="viewer-o4kbn1614"><span><span>The market had almost zero safety stock left due to tariffs, worry about </span><em><span>decreasing</span></em><span> RAM prices over the summer, and stalled equipment transfers.</span></span></p></li></ol></div><p dir="auto" id="viewer-0esvm672"><span><span>Below, we’re going to walk through each of these factors — and then I’m going to warn you about which hardware categories will be hit the hardest, which products are already being cancelled, and what you should buy </span><em><span>right now</span></em><span>&nbsp;before the shelves turn into a repeat of 2021–2022...because this is doomed to turn into much more than just RAM scarcity...</span></span></p><p data-breakout="normal"><h4 dir="auto" id="viewer-crv5b1768"><span><strong><span><u><span>Part I —OpenAI wasn’t Very “Open”</span></u></span></strong></span></h4></p><div id="viewer-7088y4730" data-breakout="normal"><figure data-hook="figure-IMAGE"><div id="7088y4730" data-hook="image-viewer"><wow-image id="cd85b6_0e9fad9a587a49e8ab8e156cc4abd177~mv2.jpg" data-image-info="{&quot;containerId&quot;:&quot;7088y4730&quot;,&quot;alignType&quot;:&quot;center&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;isLQIP&quot;:true,&quot;isSEOBot&quot;:false,&quot;lqipTransition&quot;:&quot;blur&quot;,&quot;encoding&quot;:&quot;AVIF&quot;,&quot;imageData&quot;:{&quot;width&quot;:800,&quot;height&quot;:533,&quot;uri&quot;:&quot;cd85b6_0e9fad9a587a49e8ab8e156cc4abd177~mv2.jpg&quot;,&quot;name&quot;:&quot;&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-motion-part="BG_IMG 7088y4730" data-bg-effect-name="" data-has-ssr-src="true" data-animate-blur="" data-is-responsive="true"><img src="https://static.wixstatic.com/media/cd85b6_0e9fad9a587a49e8ab8e156cc4abd177~mv2.jpg/v1/fill/w_144,h_96,al_c,q_80,usm_0.66_1.00_0.01,blur_2,enc_avif,quality_auto/cd85b6_0e9fad9a587a49e8ab8e156cc4abd177~mv2.jpg" alt="ree" data-pin-url="https://www.mooreslawisdead.com/post/sam-altman-s-dirty-dram-deal" data-pin-media="https://static.wixstatic.com/media/cd85b6_0e9fad9a587a49e8ab8e156cc4abd177~mv2.jpg/v1/fill/w_800,h_533,al_c,q_85/cd85b6_0e9fad9a587a49e8ab8e156cc4abd177~mv2.jpg" draggable="false"></wow-image></div></figure></div><p dir="auto" id="viewer-y2jf858057"><span><span>On October 1st&nbsp;OpenAI signed two </span><em><span>simultaneous </span></em><span>deals with Samsung and SK Hynix for 40% of the worlds DRAM supply.&nbsp; Now, did OpenAI’s competition suspect some big RAM deals could be signed in late 2025? Yes. Ok, but did they think it would be deals this huge and with multiple companies? NO!&nbsp; In fact, if you go back and read reporting on Sam Altman’s now infamous trip to South Korea on October 1st, even just </span><strong><u><span>mere hours </span></u></strong><span>before&nbsp;the massive deals with Samsung and SK Hynix were </span><em><span>simultaneously </span></em><span>signed</span><strong><span> – </span></strong><span>most reporting simply mentioned vague reports about Sam talking to Samsung, SK Hynix, TSMC, and Foxconn. But the reporting at the time was soft, almost dismissive — “exploring ties,” “seeking cooperation,” “probing for partnerships.” Nobody hinted that OpenAI was about to swallow </span><strong><u><span>up to 40% of global DRAM output</span></u></strong><strong><span> </span></strong><span>– even on morning before it happened! Nobody saw this coming - this is clear in the lack of reporting about the deals before they were announced, and every MLID Source who works in DRAM manufacturing and distribution insist this took everyone in the industry by surprise.</span></span></p><p dir="auto" id="viewer-ld2h81910"><span><span>To be clear - the shock wasn’t that OpenAI made a big deal, no, it was that they made two massive deals </span><strong><u><span>this big</span></u></strong><strong><em><span>, </span></em></strong><span>at the same time, with Samsung and SK Hynix </span><strong><u><span>simultaneously</span></u></strong><span>! In fact, according to our sources - both companies had no idea how big each other's deal was, nor how close to simultaneous they were. And this secrecy mattered. It mattered a lot.</span></span></p><p dir="auto" id="viewer-9z90v1916"><span><span>Had Samsung known SK Hynix was about to commit a similar chunk of supply — or vice-versa — the pricing and terms would have likely been different. </span><strong><span>It’s entirely conceivable they wouldn’t have both agreed to supply such a substantial part of global supply if they had known more...</span></strong><span>but at the end of the day - OpenAI did succeed in keeping the circles tight, locking down the NDAs, and leveraging the fact that these companies assumed the other wasn’t giving up </span><strong><u><span>this</span></u></strong><span>&nbsp;much wafer volume simultaneously…in order to make a surgical strike on the global RAM supply chain…and it's worked so far...</span></span></p><p data-breakout="normal"><h4 dir="auto" id="viewer-sus705085"><span><span><u><span>Part II — Instant Panic: How did we miss this?</span></u></span></span></h4></p><div id="viewer-8vl055947" data-breakout="normal"><figure data-hook="figure-IMAGE"><div id="8vl055947" data-hook="image-viewer"><wow-image id="cd85b6_a5407381628b4f0594299b17d4002d5a~mv2.avif" data-image-info="{&quot;containerId&quot;:&quot;8vl055947&quot;,&quot;alignType&quot;:&quot;center&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;isLQIP&quot;:true,&quot;isSEOBot&quot;:false,&quot;lqipTransition&quot;:&quot;blur&quot;,&quot;encoding&quot;:&quot;AVIF&quot;,&quot;imageData&quot;:{&quot;width&quot;:2000,&quot;height&quot;:1200,&quot;uri&quot;:&quot;cd85b6_a5407381628b4f0594299b17d4002d5a~mv2.avif&quot;,&quot;name&quot;:&quot;&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-motion-part="BG_IMG 8vl055947" data-bg-effect-name="" data-has-ssr-src="true" data-animate-blur="" data-is-responsive="true"><img src="https://static.wixstatic.com/media/cd85b6_a5407381628b4f0594299b17d4002d5a~mv2.avif/v1/fill/w_147,h_88,al_c,q_80,usm_0.66_1.00_0.01,blur_2,enc_avif,quality_auto/cd85b6_a5407381628b4f0594299b17d4002d5a~mv2.avif" alt="ree" data-pin-url="https://www.mooreslawisdead.com/post/sam-altman-s-dirty-dram-deal" data-pin-media="https://static.wixstatic.com/media/cd85b6_a5407381628b4f0594299b17d4002d5a~mv2.avif/v1/fill/w_2000,h_1200,al_c,q_90/cd85b6_a5407381628b4f0594299b17d4002d5a~mv2.avif" draggable="false"></wow-image></div></figure></div><p dir="auto" id="viewer-vd5g5348357"><span><span>Imagine you're running a hyper scaler, or maybe you’re a major OEM, or perhaps pretend that you are simply one of OpenAI’s chief competitors: On October 1st of 2025, you would have woken up to the news that OpenAI had just cornered the memory market more aggressively than any company in the last decade, and you hadn't heard even a murmur that this was coming beforehand! Well, you would probably make some follow-up calls to colleagues in the industry, and then also quickly hear rumors that it wasn't just you - also the two largest suppliers didn’t even see each other’s simultaneous cooperation with OpenAI coming </span><em><span>either</span></em><span>! You wouldn't go: “Well, that’s an interesting coincidence”, no, you would say: </span><strong><span>“WHAT ELSE IS GOING ON THAT WE DON’T KNOW ABOUT?”</span></strong></span></p><p dir="auto" id="viewer-41syk5740"><span><span>Again – it’s not the size of the deals that's solely the issue here, no, it’s also the </span><em><span>unexpectedness</span></em><span>&nbsp;and </span><em><span>brazenness </span></em><span>of them. On October 1st silicon valley executives and procurement managers panicked over concerns like these:</span></span></p><div data-breakout="normal"><ul><li dir="auto" aria-level="1"><p dir="" id="viewer-s28f810585"><span><span>What other deals don’t we know about? Is this just the first of many?</span></span></p></li><li dir="auto" aria-level="1"><p dir="" id="viewer-1x3lo11123"><span><span>None of our DRAM suppliers warned us ahead of time! We have to assume they also won't in the future, and that it’s possible </span><em><span>all</span></em><span>&nbsp;of global DRAM could be bought up without us getting a single warning!</span></span></p></li><li dir="auto" aria-level="1"><p dir="" id="viewer-r2q6311328"><span><span>We know OpenAI’s competitors are already panic-buying!&nbsp; If we don’t move </span><em><span>now, </span></em><span>we might be locked out of the market until 2028!</span></span></p></li></ul></div><p dir="auto" id="viewer-usn755760"><span><span>OpenAI’s competitors, OEMs, and cloud providers scrambled to secure whatever inventory remained out of </span><strong><u><span>self-defense</span></u></strong><span>, and self-defense in a world that was entirely </span><em><span>defenseless</span></em><span>&nbsp;due to the accelerant I’ll now explain in Part III...</span></span></p><p data-breakout="normal"><h4 dir="auto" id="viewer-6ee7h11814"><span><strong><span><u><span>Part III — There Wasn't any Safety Stock</span></u></span></strong></span></h4></p><div id="viewer-gzaj714965" data-breakout="normal"><figure data-hook="figure-IMAGE"><div id="gzaj714965" data-hook="image-viewer"><wow-image id="cd85b6_62f5f608d5d54be99f8f664b9ad6fb3b~mv2.jpg" data-image-info="{&quot;containerId&quot;:&quot;gzaj714965&quot;,&quot;alignType&quot;:&quot;center&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;isLQIP&quot;:true,&quot;isSEOBot&quot;:false,&quot;lqipTransition&quot;:&quot;blur&quot;,&quot;encoding&quot;:&quot;AVIF&quot;,&quot;imageData&quot;:{&quot;width&quot;:816,&quot;height&quot;:635,&quot;uri&quot;:&quot;cd85b6_62f5f608d5d54be99f8f664b9ad6fb3b~mv2.jpg&quot;,&quot;name&quot;:&quot;&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-motion-part="BG_IMG gzaj714965" data-bg-effect-name="" data-has-ssr-src="true" data-animate-blur="" data-is-responsive="true"><img src="https://static.wixstatic.com/media/cd85b6_62f5f608d5d54be99f8f664b9ad6fb3b~mv2.jpg/v1/fill/w_147,h_114,al_c,q_80,usm_0.66_1.00_0.01,blur_2,enc_avif,quality_auto/cd85b6_62f5f608d5d54be99f8f664b9ad6fb3b~mv2.jpg" alt="ree" data-pin-url="https://www.mooreslawisdead.com/post/sam-altman-s-dirty-dram-deal" data-pin-media="https://static.wixstatic.com/media/cd85b6_62f5f608d5d54be99f8f664b9ad6fb3b~mv2.jpg/v1/fill/w_816,h_635,al_c,q_85/cd85b6_62f5f608d5d54be99f8f664b9ad6fb3b~mv2.jpg" draggable="false"></wow-image></div></figure></div><p dir="auto" id="viewer-01g9257805"><span><span>Normally, the DRAM market has buffers: warehouses of emergency stock, excess wafer starts, older DRAM manufacturing machinery being sold off to budget brands while the big brands upgrade their production lines…but not in 2025, in 2025 those would-be buffers were depleted for three separate reasons:</span></span></p><div data-breakout="normal"><ol><li dir="auto" aria-level="1"><p dir="" id="viewer-c7ywp13221"><span><strong><span>Tariff Chaos. </span></strong><span>Companies had deliberately reduced how much DRAM they ordered for their safety stock over the summer of 2025 because tariffs were changing almost weekly. Every RAM purchase risked being made at the wrong moment – and so fewer purchases were made.</span></span></p></li><li dir="auto" aria-level="1"><p dir="" id="viewer-2wsof12359"><span><strong><span>Prices had been falling all summer. </span></strong><span>Because of the hesitancy to purchase as much safety stock as usual, RAM prices were also genuinely falling over time.&nbsp; And,</span><strong><span> </span></strong><span>obviously when memory is getting cheaper month over month, the </span><em><span>last</span></em><span> thing you’d feel is pressured to buy a commodity that could be cheaper the next month…so everyone waited.</span></span></p></li><li dir="auto" aria-level="1"><p dir="" id="viewer-spxfn12366"><span><strong><span>Secondary RAM Manufacturing Had Stalled. </span></strong><span>Budget brands normally buy older DRAM fabrication equipment from mega-producers like Samsung when Samsung upgrades their DRAM lines to the latest and greatest equipment.&nbsp; This allows the DRAM market to </span><em><span>expand </span></em><span>more than it would otherwise because it makes any upgrading of the fanciest production lines to still be </span><em><span>additive </span></em><span>change to the market. However, Korean memory firms have been terrified that reselling old equipment to China-adjacent OEMs might trigger U.S. retaliation…and so those machines have been sitting idle in warehouses since early spring.</span></span></p></li></ol></div><p dir="auto" id="viewer-ihchv12373"><span><strong><span>Yep, there was no cushion. </span></strong><span>OpenAI hit the market at the exact moment it was least prepared. </span><em><span>&nbsp;</span></em></span></p><p data-breakout="normal"><h4 dir="auto" id="viewer-wtilz24105"><span><span><u><span>Part IV — Artificial</span></u></span><strong><span><u><span>&nbsp;</span></u></span></strong><span><u><span>Scarcity</span></u></span></span></h4></p><div id="viewer-o4cs624842" data-breakout="normal"><figure data-hook="figure-IMAGE"><div id="o4cs624842" data-hook="image-viewer"><wow-image id="cd85b6_b93fa5d524fe49b4a947ad7903af9a0b~mv2.jpg" data-image-info="{&quot;containerId&quot;:&quot;o4cs624842&quot;,&quot;alignType&quot;:&quot;center&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;isLQIP&quot;:true,&quot;isSEOBot&quot;:false,&quot;lqipTransition&quot;:&quot;blur&quot;,&quot;encoding&quot;:&quot;AVIF&quot;,&quot;imageData&quot;:{&quot;width&quot;:1330,&quot;height&quot;:618,&quot;uri&quot;:&quot;cd85b6_b93fa5d524fe49b4a947ad7903af9a0b~mv2.jpg&quot;,&quot;name&quot;:&quot;&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-motion-part="BG_IMG o4cs624842" data-bg-effect-name="" data-has-ssr-src="true" data-animate-blur="" data-is-responsive="true"><img src="https://static.wixstatic.com/media/cd85b6_b93fa5d524fe49b4a947ad7903af9a0b~mv2.jpg/v1/fill/w_147,h_68,al_c,q_80,usm_0.66_1.00_0.01,blur_2,enc_avif,quality_auto/cd85b6_b93fa5d524fe49b4a947ad7903af9a0b~mv2.jpg" alt="ree" data-pin-url="https://www.mooreslawisdead.com/post/sam-altman-s-dirty-dram-deal" data-pin-media="https://static.wixstatic.com/media/cd85b6_b93fa5d524fe49b4a947ad7903af9a0b~mv2.jpg/v1/fill/w_1330,h_618,al_c,q_85/cd85b6_b93fa5d524fe49b4a947ad7903af9a0b~mv2.jpg" draggable="false"></wow-image></div></figure></div><p dir="auto" id="viewer-szp4a57677"><span><span>And now time for the biggest twist of all, a twist that’s actually </span><em><span>public information</span></em><span>, and therefore should be getting discussed by far more people in this writer's opinion: OpenAI isn’t even bothering to buy finished memory modules!  No, their deals are unprecedentedly only for raw wafers — uncut, unfinished, and not even allocated to a specific DRAM standard yet. It’s not even clear if they have decided yet on how or when they will finish them into RAM sticks or HBM!&nbsp; Right now it seems like these wafers will just be stockpiled in warehouses – like a kid who hides the toybox because they’re afraid nobody wants to play with them, and thus selfishly feels nobody but them should get the toys!</span></span></p><p dir="auto" id="viewer-n47a024642"><span><span>And let’s just say it: Here is the uncomfortable truth Sam Altman is always loath to admit in interviews: </span><strong><span>OpenAI is worried about losing its lead. </span></strong><span>The last 18 months have seen competitors catching up fast — Anthropic, Meta, xAI, and specifically Google’s Gemini 3 has gotten a ton of praise just in the past week. Everyone’s chasing training capacity. Everyone needs memory. DRAM is the lifeblood of scaling inference and training throughput. Cutting supply to your rivals is not a conspiracy theory. It’s a business tactic as old as business itself.&nbsp; And so, when you consider how secretive OpenAI was about their deals with Samsung and SK Hynix, but additionally how unready they were to immediately utilize their warehouses of DRAM wafers – it sure seems like a primary goal of these deals was to </span><em><span>deprive the market</span></em><span>, and not just an attempt to protect OpenAI's own supply…</span></span></p><p data-breakout="normal"><h4 dir="auto" id="viewer-giwko29374"><span><span><u><span>Part V — What will be cancelled? What should you buy now?</span></u></span></span></h4></p><div id="viewer-8y12c48912" data-breakout="normal"><figure data-hook="figure-IMAGE"><div id="8y12c48912" data-hook="image-viewer"><wow-image id="cd85b6_78bf030c32f246ee9300997905234ed8~mv2.jpg" data-image-info="{&quot;containerId&quot;:&quot;8y12c48912&quot;,&quot;alignType&quot;:&quot;center&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;isLQIP&quot;:true,&quot;isSEOBot&quot;:false,&quot;lqipTransition&quot;:&quot;blur&quot;,&quot;encoding&quot;:&quot;AVIF&quot;,&quot;imageData&quot;:{&quot;width&quot;:1920,&quot;height&quot;:1080,&quot;uri&quot;:&quot;cd85b6_78bf030c32f246ee9300997905234ed8~mv2.jpg&quot;,&quot;name&quot;:&quot;&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-motion-part="BG_IMG 8y12c48912" data-bg-effect-name="" data-has-ssr-src="true" data-animate-blur="" data-is-responsive="true"><img src="https://static.wixstatic.com/media/cd85b6_78bf030c32f246ee9300997905234ed8~mv2.jpg/v1/fill/w_147,h_83,al_c,q_80,usm_0.66_1.00_0.01,blur_2,enc_avif,quality_auto/cd85b6_78bf030c32f246ee9300997905234ed8~mv2.jpg" alt="ree" data-pin-url="https://www.mooreslawisdead.com/post/sam-altman-s-dirty-dram-deal" data-pin-media="https://static.wixstatic.com/media/cd85b6_78bf030c32f246ee9300997905234ed8~mv2.jpg/v1/fill/w_1920,h_1080,al_c,q_90/cd85b6_78bf030c32f246ee9300997905234ed8~mv2.jpg" draggable="false"></wow-image></div></figure></div><p dir="auto" id="viewer-7gdlx57539"><span><span>Alright, now that we are done explaining the </span><em><span>how</span></em><span>, let’s get to the “</span><em><span>now what?”</span></em><span>&nbsp;– because even if the RAM shortage miraculously improves immediately behind the scenes – even if the AI Bubble instantly popped or 10 companies started tooling up for more DRAM capacity this second (and many are, to be fair), at a minimum the </span><strong><span>next six to nine months are already screwed</span></strong><span>.</span><strong><span>&nbsp; See above: DRAM manufactures are quoting 13-Month lead times for DDR5! &nbsp;</span></strong><span>This is not a temporary blip. This could be a once-in-a-generation shock. So what gets hit first?  What gets hit hardest?  Well, below is an E through S-Tier ranking of which products are "the most screwed":</span></span></p><div data-breakout="normal"><ul><li dir="auto" aria-level="1"><p dir="" id="viewer-cs0q932325"><span><strong><span>S-Tier (Already Screwed – Too Late to Buy) -</span></strong></span></p><ul><li dir="auto" aria-level="2"><p dir="" id="viewer-14fa830553"><span><strong><span>RAM itself, obviously.</span></strong><span>&nbsp;RAM prices have “exploded”. The detonation is in the past.</span></span></p></li></ul></li><li dir="auto" aria-level="1"><p dir="" id="viewer-u2bqp30557"><span><strong><span>A-Tier (Almost Screwed – Don’t Wait to Buy!!!)</span></strong></span></p><ul><li dir="auto" aria-level="2"><p dir="" id="viewer-78rpb30560"><span><strong><span>SSDs.</span></strong><span> These tends to follow DRAM pricing with a lag.</span></span></p></li><li dir="auto" aria-level="2"><p dir="" id="viewer-k091o30564"><span><strong><span>Small Prebuilt PC Companies.</span></strong><span> That lack large buffers of inventory.</span></span></p></li><li dir="auto" aria-level="2"><p dir="" id="viewer-gkcew30568"><span><strong><span>RADEON GPUs</span></strong><span>. AMD doesn’t bundle RAM in their BOM kits to AIBs the way Nvidia does. In fact, the </span><strong><span>RX 9070 GRE 16GB this channel leaked months ago is almost certainly cancelled according to our sources</span></strong><span>.</span></span></p></li><li dir="auto" aria-level="2"><p dir="" id="viewer-grjn430574"><span><strong><span>XBOX. </span></strong><span>Microsoft didn’t plan. Prices may rise and/or supply may dwindle in 2026.</span></span></p></li></ul></li><li dir="auto" aria-level="1"><p dir="" id="viewer-ccnw430578"><span><strong><span>B-Tier (Eventually Screwed – Don’t wait much longer to buy!)</span></strong></span></p><ul><li dir="auto" aria-level="2"><p dir="" id="viewer-tzlir30581"><span><strong><span>Nvidia GPUs. </span></strong><span>Nvidia maintains large memory inventories for its board partners, giving them a buffer. But high-capacity GPUs (like a hypothetical 24GB 5080 SUPER) are on ice for now because </span><em><span>those</span></em><span>&nbsp;stores were never sufficiently built up. In fact, Nvidia is quietly telling partners that their SUPER refresh “might” launch </span><strong><span>Q3 2026 </span></strong><span>– although most partners think it’s just a placeholder for when Nvidia expects new capacity to come online, and thus SUPER may never launch.</span></span></p></li></ul></li><li dir="auto" aria-level="1"><p dir="" id="viewer-qb66e30589"><span><strong><span>C-Tier (Think about buying soon)</span></strong></span></p><ul><li dir="auto" aria-level="2"><p dir="" id="viewer-rk4er30592"><span><strong><span>Laptops and phones. </span></strong><span>These companies negotiate immense long-term contracts, so they’re not hit immediately. But once their stockpiles run dry, watch out!</span></span></p></li></ul></li><li dir="auto" aria-level="1"><p dir="" id="viewer-92ofb30596"><span><strong><span>D-Tier (Consider buying soon, but there’s no rush)</span></strong></span></p><ul><li dir="auto" aria-level="2"><p dir="" id="viewer-rx6uc30599"><span><strong><span>PlayStation. </span></strong><span>Sony planned better than almost anyone else. They bought aggressively during the summer price trough, which is why they can afford a Black Friday discount while everyone else is raising prices.</span></span></p></li></ul></li><li dir="auto" aria-level="1"><p dir="" id="viewer-cfj6c30603"><span><strong><span>E-Tier (Prices might actually </span></strong><strong><em><span>drop</span></em></strong><strong><span>)</span></strong></span></p><ul><li dir="auto" aria-level="2"><p dir="" id="viewer-bz4wm30608"><span><strong><span>Anything without RAM. </span></strong><span>Specifically CPUs that do not come with coolers could see price </span><em><span>drops</span></em><span>&nbsp;over time since there could be a </span><em><span>drop</span></em><span>&nbsp;in demand for CPUs if nobody has the RAM to feed them in systems.</span></span></p></li></ul></li><li dir="auto" aria-level="1"><p dir="" id="viewer-rsa7r30616"><span><strong><span>???-Tier —Steam Machine. </span></strong><span>Valve keeps things quiet, but the big unknown is whether they pre-bought RAM months ago before announcing their much-hyped Steam Machine. If they did already stockpile an ample supply of DDR5 - then Steam Machine should launch fine, but supply could dry up temporarily at some point while they wait for prices to drop. However, if they didn’t plan ahead - expect a high launch price and very little resupply…it might even need to be cancelled or there might need to be a variant offered without RAM included (BYO RAM Edition!).</span></span></p></li></ul></div><p dir="auto" id="viewer-xmjnz56999"><span><span>And that’s it!  This last bit was the most important part of the article in this writer's opinion – an attempt at helping you avoid getting burned. Well, actually, there is one other important reason for this article’s existence I'll tack onto the end – a hope that other people start digging into what’s going on at OpenAI.&nbsp; I mean seriously – do we even have a single reliable audit of their financials to back up them outrageously spending this much money…</span><em><span>for this?</span></em><span>&nbsp; Heck, I’ve even heard from numerous sources that OpenAI is “buying up the manufacturing equipment as well” – and without mountains of concrete proof, and/or more input from additional sources on what that really means…I don’t feel I can touch that hot potato without getting burned…</span><strong><span>but I hope someone else will…</span></strong></span></p><p dir="auto" id="viewer-khuso59102"><span><span>Sources:</span></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Adenosine on the common path of rapid antidepressant action: The coffee paradox (185 pts)]]></title>
            <link>https://genomicpress.kglmeridian.com/view/journals/brainmed/aop/article-10.61373-bm025c.0134/article-10.61373-bm025c.0134.xml</link>
            <guid>46168057</guid>
            <pubDate>Fri, 05 Dec 2025 22:10:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://genomicpress.kglmeridian.com/view/journals/brainmed/aop/article-10.61373-bm025c.0134/article-10.61373-bm025c.0134.xml">https://genomicpress.kglmeridian.com/view/journals/brainmed/aop/article-10.61373-bm025c.0134/article-10.61373-bm025c.0134.xml</a>, See on <a href="https://news.ycombinator.com/item?id=46168057">Hacker News</a></p>
<div id="readability-page-1" class="page"><div lang="en" dir="ltr">
<section id="s1">
<h2 id="d22204395e184">Introduction</h2>
<p id="p-1">As Claude Bernard understood in laying the foundations of experimental medicine, each scientific generation brings us closer to mechanistic truth, yet complete understanding remains elusive (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R1">1</a>). This has been particularly evident in psychiatric therapeutics, where chance preceded knowledge for a long time. For over twenty years now, we had evidence suggesting that ketamine was a rapid anti-depressant. We knew the electrically charged scalpel of electroconvulsive therapy worked when nothing else did. And we had long suspected that depriving people of sleep benefited them in a transient way. All we were lacking was the mechanistic thread connecting these varied interventions, the common path which might allow for rational, instead of empirical, therapeutic development.</p>
<p id="p-2">In a study that demonstrates what modern neuroscience can do when technical virtuosity meets conceptual clarity, Yue and colleagues led by Professor Min-Min Luo now provide that thread (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). Using genetically encoded adenosine sensors, a comprehensive genetic and pharmacological dissection, and immediate therapeutic translation they show that adenosine signalling is the convergent mechanism of rapid-acting antidepressant therapies. It is a new way of thinking about treatment-resistant depression and not just an incremental science.</p>
</section>
<section id="s2">
<h2 id="d22204395e201">The technical achievement</h2>
<p id="p-3">The precise timing is what gives the work its compelling quality. The authors applied GRABAdo1.0, a GPCR-based sensor for adenosine, to monitor online adenosine changes in mood-regulating circuits (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). Injection of ketamine (10 mg/kg) and application of electroconvulsive therapy resulted in a substantial spike in extracellular adenosine in the medial prefrontal cortex and hippocampus with peak amplitudes of ∼15% ΔF/F, which peaked in ∼500 s and lasted about 30 minutes above the baseline (Extended Data Fig. 1d–h in <a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">ref. 2</a>). The specificity to regions is also telling. Even though adenosine increases occurred in the mPFC and hippocampus, no surge occurred in the nucleus accumbens, suggesting affective circuits, not reward circuits.</p>
<figure itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" data-figureid="F1" id="F1" data-jats-position="float" data-jats-orientation="portrait"><div><p><img data-size="orig" src="https://genomicpress.kglmeridian.com/view/journals/brainmed/aop/article-10.61373-bm025c.0134/bm025c0134f1.tif" alt="Figure 1."><img data-size="full" src="https://genomicpress.kglmeridian.com/view/journals/brainmed/aop/article-10.61373-bm025c.0134/full-bm025c0134f1.jpg" alt="Figure 1."><img data-size="inline" src="https://genomicpress.kglmeridian.com/view/journals/brainmed/aop/article-10.61373-bm025c.0134/inline-bm025c0134f1.jpg" alt="Figure 1."></p></div><figcaption itemprop="description"><span>Figure 1.</span><span>Adenosine Signaling: Convergent Mechanisms for Rapid Antidepressants. Three distinct interventions—ketamine (pharmacological), electroconvulsive therapy/ECT (electrical), and acute intermittent hypoxia/aIH (physiological)—converge on a common mechanism: adenosine surges in the medial prefrontal cortex (mPFC). Ketamine triggers adenosine release through metabolic modulation (decreased ATP/ADP ratio) and ENT1/2-mediated efflux, without causing neuronal hyperactivity. ECT produces adenosine surges via neuronal hyperactivity and rapid metabolic demand. aIH generates adenosine through controlled hypoxia in a non-invasive manner. All three interventions activate A1 and A2A adenosine receptors in the mPFC, detected in real-time using fiber photometry with genetically encoded sensors (GRABAdo1.0). This adenosine signaling triggers downstream synaptic plasticity mechanisms (BDNF upregulation, mTOR activation, neuroplasticity), resulting in rapid antidepressant effects with onset in hours and duration lasting days. Clinical Considerations: The adenosine mechanism raises important questions about caffeine consumption patterns. <i data-jats-toggle="yes">Tonic signaling</i> (chronic/baseline coffee consumption) appears protective against depression and may help prevent depressive episodes. <i data-jats-toggle="yes">Phasic signaling</i> (acute pre-treatment coffee) raises mechanistic concerns about potential interference with the adenosine surge during ketamine/ECT administration, though this remains speculative and requires clinical validation. The dual nature of caffeine's effects—protective chronically, potentially interfering acutely—reflects the distinction between tonic baseline adenosine receptor modulation and phasic adenosine surge responses to rapid-acting treatments.</span><p>Citation: Brain Medicine 2025; <a href="https://doi.org/10.61373/bm025c.0134">10.61373/bm025c.0134</a></p></figcaption><ul data-listtype="figure-links"><li data-linktype="downloadppt"><a>Download as Powerpoint</a></li><li data-linktype="downloadfigure"><a>Download Figure</a></li></ul></figure>
<p id="p-5">The dose-response-use relationships were clear-cut. When the doses of ketamine were 5 mg/kg, modest signals were seen. But then, at 10 and 20 mg/kg there were very clear effects. The higher doses increased the duration of response but had no effect on the peak amplitude. Two-photon imaging showed that the adenosine signal was spatially diffuse. The kinetics was different from that of acute hypoxia which was used by the authors as a positive control. Ketamine at the standard antidepressant dose (10 mg/kg) produced peak amplitudes of approximately 15% ΔF/F, while higher doses (20–50 mg/kg) reached approximately 35% ΔF/F, still substantially lower than the ∼60% ΔF/F observed with acute hypoxia. However, ketamine's decay rate was much slower, taking greater than 500s compared to the hypoxia decay rate of around 50s. The less pronounced peak but prolonged duration suggests that ketamine causes a sustained metabolic modulation rather than acute cellular stress.</p>
<p id="p-6">This temporal resolution matters. Measuring constant receptor expression or a single-time point tissue sample would have led to missing the adenosine surge that would turn on and off. Only through continuous optics monitoring could it become possible to find a dynamic signal necessary for therapy.</p>
</section>
<section id="s3">
<h2 id="d22204395e235">Determining cause and effect in biology</h2>
<p id="p-7">The rigor of the mechanistic proof is exemplary. The importance of the mechanism indicated by the convergence of genetic and pharmacological approaches is shown by studies. Adora1<sup>−/−</sup> and Adora2a<sup>−/−</sup> mice lost all of the antidepressant efficacy of ketamine in two standard tests for depression. The first being the forced swim test which measures behavioral despair and the other the sucrose preference test which measures anhedonia (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). Results were not paradigm-specific. The necessity also applied in the chronic restraint stress model and the lipopolysaccharide model of inflammatory depression (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R3">3</a>, <a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R4">4</a>). Post-hoc acute pharmacological blockade with selective antagonists PSB36 (A1) and ZM241385 (A2A) also completely stripped therapeutic responses to ketamine. This was the case at both 1-hour and 24 hours post-treatment.</p>
<p id="p-8">The circuit-specificity is equally convincing. Scientists administered AAV-mediated CRISPR-Cas9 to internalize sgRNAs that target Adora1 and Adora2a within the mPFC. The loss of local receptor was sufficient to negate the effect of systemic ketamine (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). This confirms the mPFC as a key node—consistent with established mood and executive function roles, now established mechanistically.</p>
<p id="p-9">The sufficiency experiments complete the logical circle. According to research, adenosine may act to prevent or reverse the onset of some diseases. In fact, direct infusion of adenosine into the mPFC produced antidepressant-like effects lasting 24 hours (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). More elegantly, optogenetic stimulation of astrocytes expressing cOpn5, optogenetic tools that trigger Ca²⁺-dependent ATP release and subsequent CD73-mediated adenosine production, produces therapeutic actions, and this effect was extinguished in Nt5e<sup>−/−</sup> mice lacking CD73 (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>, <a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R5">5</a>). Systemic delivery of selective agonists (CHA for A1, CGS21680 for A2A) produced rapid antidepressant responses, with A1-only action potent enough to sustain effects for 24 hours (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>).</p>
<p id="p-10">This mechanism was shown with a degree of thoroughness the field demands but rarely achieves.</p>
</section>
<section id="s4">
<h2 id="d22204395e281">Mitochondria, not neuronal hyperactivity</h2>
<p id="p-11">The upstream mechanism represents genuinely novel biology. Rather than generating adenosine through extracellular ATP hydrolysis, ketamine directly modulates mitochondrial function to increase intracellular adenosine, which then exits cells via equilibrative nucleoside transporters (ENT1/2). The authors demonstrate this in isolated mPFC mitochondria that are incubated with [<sup>13</sup>C<sub>3</sub>]pyruvate. Ketamine (≥2 μM—therapeutically relevant concentrations) (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R6">6</a>, <a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R7">7</a>) dose-dependently suppressed <sup>13</sup>C enrichment of TCA cycle intermediates fumarate, malate, and aspartate while causing accumulation of pyruvate (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>).</p>
<p id="p-12">This metabolic brake cascades into adenosine production. Using PercevalHR sensors to measure intracellular ATP/ADP ratios in vivo, they show that ketamine quickly decreases this ratio in CaMKII⁺ pyramidal neurons (largest effect), GABAergic interneurons (transient reduction with rebound), and astrocytes (sustained decrease) (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). The timing is telling: the ATP/ADP ratio decrease comes before the extracellular adenosine surge, making metabolic perturbation upstream.</p>
<p id="p-13">Critically, this occurs without neuronal hyperactivity. By analyzing calcium signaling response in pyramidal and GABAergic neurons to therapeutic doses of ketamine using GCaMP8s, it was found that ketamine at 10 mg/kg did not increase Ca²⁺ signaling in pyramidal neurons and actually decreased activity of GABAergic interneurons (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). This overturns the assumption that seizure-like neuronal hyperactivity is necessary for rapid antidepressant action. The mechanism is metabolic modulation driving adenosine efflux via equilibrative nucleoside transporters, not excitotoxic processes.</p>
<p id="p-14">The authors demonstrate that dipyridamole, an ENT1/2 inhibitor, reduces the adenosine signal induced by ketamine, confirming the role of these transporters (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). In contrast, genetic depletion of CD73 (which hydrolyzes extracellular ATP to adenosine) has no effect on ketamine-induced adenosine surges.¹ The adenosine arises intracellularly and exits through ENT1/2 transporters in response to the concentration gradient produced by metabolic shifts.</p>
</section>
<section id="s5">
<h2 id="d22204395e323">From mechanism to molecules</h2>
<p id="p-15">This work goes beyond descriptive neuroscience in its immediate therapeutic translation. Adenosine dynamics appear to act as a functional biomarker in their hands. Based on this observation, the authors synthesized 31 ketamine derivatives by inducing systematic changes in chemical groups affecting their metabolism and receptor binding (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). Screening identified deschloroketamine (DCK) and deschloro-N-ethyl-ketamine (2C-DCK) as compounds showing 40-80% stronger adenosine signals than ketamine at equivalent doses.</p>
<p id="p-16">The effects of this drug on behavior were noticed immediately. DCK produced significant antidepressant effects at 2 mg/kg (compared to 10 mg/kg for ketamine) with only a little hyperlocomotion at this dose (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). This shows a dissociation between therapeutic and psychomimetic effects. In particular, DCK at therapeutic doses showed only a small amount of locomotor activation. On the other hand, ketamine at 10 mg/kg produced significant hyperlocomotion. The enhanced therapeutic index indicates that promoting signaling downstream of adenosine rather than optimizing NMDA receptor nonspecific blockade broadens the safe window.</p>
<p id="p-17">The authors provide clear evidence for the dissociation between NMDAR antagonism and the release of adenosine. Studies showed that compounds such as 3'-Cl-ketamine blocked NMDARs with high potency (IC₅₀ comparable to ketamine in cortical slice recordings) but did not induce adenosine surges and are ineffective as an antidepressant (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). The correlation between the estimated in vivo NMDAR inhibitions (derived from the ex vivo IC<sub>50</sub> values and brain tissue concentrations) and adenosine modulation was non-significant (Pearson r, P = 0.097).¹ Therefore, NMDAR antagonism is neither necessary nor sufficient; the therapeutic action operates via ketamine's direct mitochondrial actions.</p>
<p id="p-18">This metabolic evidence is consistent with the parent compound driving adenosine release. In contrast, ketamine's primary metabolites—norketamine and (2R,6R)-hydroxynorketamine—do not produce adenosine responses at equivalent doses (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). Notably, hydroxynorketamine does have antidepressant properties in some studies (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R8">8</a>). Inhibition of metabolism is important: CYP3A4 inhibitors (ketoconazole, ritonavir) potentiated the adenosine signal, whilst CYP2B6 inhibition (ticlopidine) did not (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>).</p>
</section>
<section id="s6">
<h2 id="d22204395e361">Electroconvulsive therapy and beyond</h2>
<p id="p-19">The adenosine framework extends beyond ketamine. Seizures induced by electroconvulsive therapy (ECT) in anesthetized mice (40 mA, 100 Hz, 10s) mediated an adenosine surge in medial prefrontal cortex (mPFC) comparable in magnitude to that of ketamine but with faster kinetics (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). That is, the onset and decay of adenosine signaling are faster, consistent with the idea that ECT produces intense but brief neuronal firing. According to the authors, the requirement for adenosine to mediate these antidepressant effects is also the same. Adora1<sup>−/−</sup> mice (lacking the adenosine receptor A1) and Adora2a<sup>−/−</sup> mice (lacking the adenosine receptor A2A) did not respond to ECT with reductions in immobility in forced swim test or restored preference for sucrose in sucrose preference test (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>).</p>
<p id="p-20">The researchers found that acute intermittent hypoxia (aIH), which is a controlled reduction in oxygen that consists of 5 cycles of 9% O₂ for a duration of 5 min, interspersed with 21% O₂, when done daily for 3 days produces antidepressant effects that were entirely reliant on adenosine signaling.¹ Most importantly, from a clinical perspective, aIH is non-invasive, has been shown to be safe in other clinical contexts (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R9">9</a>), does not require any complex machinery as long as oxygen can be controlled, and could be rolled out in low-resourced settings. Adenosine receptor knockout mice had no antidepressant effects from aIH, which indicates that aIH, ketamine, and ECT share identical mechanistic dependence on adenosine signaling (<a href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">Figure 1</a>) (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>).</p>
</section>
<section id="s7">
<h2 id="d22204395e391">The coffee question: Clinical and mechanistic insights</h2>
<p id="p-21">It is certainly a paradoxical sort of story worth noticing. The most commonly consumed psychoactive drug in the world is caffeine, which functions as an adenosine receptor antagonist (<a href="#F2" data-jats-ref-type="fig" data-jats-rid="F2">Figure 2</a>). The study makes it clear that “the possibility of dietary caffeine interfering with these treatments (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>, <a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R10">10</a>, <a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R11">11</a>).” The warning has mechanistic grounding: if activation of adenosine receptors is necessary for therapeutic effectiveness, and caffeine is an adenosine receptor antagonist, then coffee drinking can be expected to blunt treatment response.</p>
<figure itemprop="image" itemscope="itemscope" itemtype="https://schema.org/ImageObject" data-figureid="F2" id="F2" data-jats-position="float" data-jats-orientation="portrait"><div><p><img data-size="orig" src="https://genomicpress.kglmeridian.com/view/journals/brainmed/aop/article-10.61373-bm025c.0134/bm025c0134f2.tif" alt="Figure 2."><img data-size="full" src="https://genomicpress.kglmeridian.com/view/journals/brainmed/aop/article-10.61373-bm025c.0134/full-bm025c0134f2.jpg" alt="Figure 2."><img data-size="inline" src="https://genomicpress.kglmeridian.com/view/journals/brainmed/aop/article-10.61373-bm025c.0134/inline-bm025c0134f2.jpg" alt="Figure 2."></p></div><figcaption itemprop="description"><span>Figure 2.</span><span>The coffee paradox in adenosine-mediated antidepressant action. Depression (left) and coffee consumption (right) are both linked through adenosine signaling (center), creating a pharmacological paradox: chronic coffee drinking appears protective against depression through tonic adenosine receptor modulation, while acute pre-treatment caffeine may attenuate the phasic adenosine surge required for rapid antidepressant responses to ketamine and electroconvulsive therapy.</span><p>Citation: Brain Medicine 2025; <a href="https://doi.org/10.61373/bm025c.0134">10.61373/bm025c.0134</a></p></figcaption><ul data-listtype="figure-links"><li data-linktype="downloadppt"><a>Download as Powerpoint</a></li><li data-linktype="downloadfigure"><a>Download Figure</a></li></ul></figure>
<p id="p-23">The epidemiological literature paints a different picture. The findings of a number of meta-analyses indicate that chronic coffee consumption protects against depression. One meta-analysis found that RR coffee 0.757, RR caffeine 0.721 (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R12">12</a>). Another one found RR 0.76, with an optimal protective effect at ∼400 mL/day (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R13">13</a>). In comparison to many drug treatments that have an effect size in this range, this is not a small effect size. A risk reduction of 20 to 25% is quite impressive.</p>
</section>
<section id="s8">
<h2 id="d22204395e429">Ideas based on known pharmacology, but not yet directly</h2>
<p id="p-24">One might find answers in the tonic and phasic adenosine signaling and if there is any receptor reserve. Ongoing caffeine use will cause a modest (∼20%) upregulation of A1 receptors, but crucially, this upregulation does not interfere with any functional signaling capacity of the receptor upon binding of adenosine (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R14">14</a>). The receptors are still functional; there are just more of them.</p>
<p id="p-25">Furthermore, adenosine receptors show a significant “spare receptor” reserve, with A2A receptor reserve estimated to be 70–90% and 10–64% for A1 receptors. It means a 5–10% occupancy of the receptor can give rise to approximately a 50% maximal effect (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R15">15</a>, <a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R16">16</a>). An antagonist must occupy more than 95% of the receptors to block any effect when spare receptors are present (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R15">15</a>).</p>
<p id="p-26">The pharmacokinetics of caffeine is relevant here. Caffeine has a half-life of 3–7 hours and a peak concentration 45–60 minutes after ingestion, with a receptor occupancy of ∼50%–65% between doses in regular consumers (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R11">11</a>, <a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R17">17</a>).</p>
<p id="p-27">When there is chronic consumption, there is usually a tonic effect which results in more receptors being upregulated in addition to a maintained spare receptor reserve. While there is partial occupancy on the receptors, there is no complete occupancy. The fundamental adenosinergic tone might be augmented in the presence of the antagonist consistent with epidemiological protection from depression.</p>
<p id="p-28">Prior consumption of caffeine (phasic blockade) must be overcome by the adenosine surge following ketamine or ECT application. When caffeine occupies 50–65% of receptors, there's still considerable receptor reserve available. This means the adenosine surge has to work harder to overcome the blockade, weakening the signal without wiping it out completely. With considerable but not infinite receptor reserve, adenosine signal decreases but does not get obliterated.</p>
<p id="p-29">More tailored approaches instead of outright bans are suggested by this pharmacologcial analysis.</p>
<ul data-jats-list-type="bullet"><li><p id="p-30">Regular caffeine/coffee use pre-ketamine is probably not contraindicated. Epidemiological data suggest a possible benefit of that use.</p></li><li><p id="p-31">Having coffee just before the treatment is more concerning. Patients may be recommended caffeine washout to achieve optimal adenosine receptor availability during the critical adenosine spike.</p></li><li><p id="p-32">Drinking coffee after treatment is probably safe once the first plasticity mechanisms are already established.</p></li></ul>
<p id="p-33">Can we test whether regular coffee drinkers show blunted ketamine responses? Does controlled caffeine washout enhance outcomes? Is there a link between caffeine use and the response? The current paper offers the mechanistic foundation to pose such questions rigorously.</p>
<p id="p-34">But these things are still open empirical questions, sadly. This system has not yet undergone quantitative pharmacology that links chronic receptor modulation with acute receptor reserve and surge amplitudes large enough to overcome partial blockade. Yue et al. clarify mechanisms to ensure that scientists pose the right questions.</p>
</section>
<section id="s9">
<h2 id="d22204395e484">What remains unknown</h2>
<p id="p-35">What makes this piece valuable is its honesty about the boundaries of its work. Several questions merit attention.</p>
<p id="p-36">The mechanisms linking acute adenosine surges to sustained plasticity are not well defined. The authors demonstrate that the upregulation of BDNF [a key transducer of antidepressant effects (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R18">18</a>)] produced by ketamine requires the A1 and A2A receptors (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>), linking adenosine to established pathways of neuroplasticity. Still, more elaboration is needed on how a surge of adenosine for ∼30 minutes produces antidepressant effects extending over days-to-weeks. HOMER1A activation and stimulation of the mTOR pathway are cited in the paper as likely downstream effectors (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>, <a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R19">19</a>, <a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R20">20</a>) but the full signalling pathway has yet to be defined.</p>
<p id="p-37">Second, the hippocampal story is incomplete. After ketamine, adenosine levels soared in the hippocampus in a manner comparable to that in the mPFC (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). It should be noted that optogenetic initiation of adenosine and the direct infusion of adenosine into the dorsal hippocampus did not produce an antidepressant effect (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>). This suggests functional heterogeneity, possibly along the dorsal–ventral axis. With the ventral hippocampus having greater associations with mood circuits and the dorsal hippocampus serving cognitive and spatial functions. The authors rightly highlight the need for an investigation of this complex matter.</p>
<p id="p-38">We will need to incorporate these into our understanding of the relationship between adenosine and the other proposed ketamine mechanisms. In this area, there has been interest in NMDAR antagonism (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R21">21</a>), AMPA receptor potentiation (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R22">22</a>), mTOR activation (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R23">23</a>) and various metabolite effects (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R8">8</a>). The current work shows that adenosine is necessary and sufficient and that the NMDAR block dissociates from therapeutic action across derivatives. lthough the position of adenosine in the signaling cascade remains unclear, whether it operates in parallel with, upstream of, or downstream from other mechanisms, the authors' data suggest that adenosine may be the primary initiating signal and that other mechanisms are downstream consequences but this is yet to be validated.</p>
<p id="p-39">To apply this finding to treatment resistant depression in humans, we have to keep in mind the heterogeneity that clinical psychiatry so well knows. Some patients do not respond to ketamine and not all respond to ECT. Do nonresponders have defects in how they produce adenosine, express receptors, or couple receptor signaling? Can adenosine dynamics—appraised with PET tracers for A1 and A2A receptors and, if predictive, using peripheral biomarkers—sample patients likely to respond? These questions ultimately determine clinical utility.</p>
</section>
<section id="s10">
<h2 id="d22204395e536">A framework for rational development</h2>
<p id="p-40">Unfortunately, psychiatry has depended much more on serendipity than mechanism for a long time. The monoamine hypothesis was discovered accidentally (as with iproniazid and imipramine). The atypical antipsychotics resulted from chemical modifications aimed at fewer side effects. Finally, the discovery of ketamine's antidepressant properties occurred by accident during studies of its properties. We have been, in Baudrillard's concept, cartographers mapping territories we have not yet crossed: “The territory no longer precedes the map, nor survives it. Henceforth, it is the map that precedes the territory (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R24">24</a>).” We say we know what works without knowing why.</p>
<p id="p-41">In contrast, Yue et al. provide an extraodinary map after exquisitely researching the territory. With adenosine as the mechanistic target, the authors have already demonstrated proof-of-principle: derivatives with enhanced adenosine signaling show improved therapeutic indices.¹ The path forward involves:</p>
<ul data-jats-list-type="bullet"><li><p id="p-42"><b>Medicinal chemistry optimization</b> of adenosine-enhancing compounds, prioritizing metabolic mitochondrial modulators over NMDAR antagonists.</p></li><li><p id="p-43"><b>Allosteric modulation</b> of A1 and A2A receptors to enhance endogenous signaling without tonic activation.</p></li><li><p id="p-44"><b>Non-pharmacological interventions</b> (aIH, potentially others) that leverage adenosine biology.</p></li><li><p id="p-45"><b>Biomarker development</b> for patient stratification and response prediction.</p></li><li><p id="p-46"><b>Combination strategies</b> targeting complementary nodes in the adenosine-plasticity cascade.</p></li></ul>
<p id="p-47">The technical platform is robust: genetically encoded sensors provide real-time functional readouts for compound screening; the behavioral assays are well-validated; the genetic models allow mechanistic dissection; the therapeutic endpoints (onset, duration, side effects) are clinically meaningful.</p>
<p id="p-48">Most critical is that the work establishes that rapid antidepressant action is not a pharmacological curiosity of a dissociative anesthetic. A reproducible neurobiological phenomenon, adenosine-driven plasticity in mood-regulatory circuits, can be triggered by multiple routes. This converts an empirical observation (ketamine works fast) into a biological principle (adenosine surges trigger antidepressant plasticity) that guides rational therapeutic development (<a href="#T1" data-jats-ref-type="table" data-jats-rid="T1">Table 1</a>).</p>
<figure id="T1" data-jats-position="float" data-jats-orientation="portrait"><p><span>Table 1.</span><span>Clinical Implications of Adenosine-Based Antidepressant Mechanisms</span></p>

<div><table>
<colgroup data-jats-span="1">
<col data-jats-span="1">
<col data-jats-span="1">
<col data-jats-span="1">
</colgroup>
<thead>
<tr>
<th rowspan="1" colspan="1">Clinical Domain</th>
<th rowspan="1" colspan="1">Key Finding</th>
<th rowspan="1" colspan="1">Clinical Action</th>
</tr>
</thead>
<tbody>
<tr>
<td rowspan="1" colspan="1"><b>Caffeine &amp; Treatment Timing</b></td>
<td rowspan="1" colspan="1"></td>
<td rowspan="1" colspan="1"></td>
</tr>
<tr>
<td rowspan="1" colspan="1">Chronic consumption</td>
<td rowspan="1" colspan="1">Protective: 20–25% risk reduction (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R12">12</a>, <a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R13">13</a>)</td>
<td rowspan="1" colspan="1">Continue usual intake; may prevent depression</td>
</tr>
<tr>
<td rowspan="1" colspan="1">Acute pre-treatment</td>
<td rowspan="1" colspan="1">Occupies 50–65% receptors for 3–7 h (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R15">15</a>, <a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R16">16</a>)</td>
<td rowspan="1" colspan="1">Consider 12–24 h washout before ketamine/ECT<a href="#t1f1" data-jats-ref-type="fn" data-jats-rid="t1f1"><sup>*</sup></a></td>
</tr>
<tr>
<td rowspan="1" colspan="1">Mechanistic basis</td>
<td rowspan="1" colspan="1">Tonic signaling (baseline) vs. phasic signaling (treatment surge)</td>
<td rowspan="1" colspan="1">Distinguish chronic protective effects from acute interference potential<a href="#t1f1" data-jats-ref-type="fn" data-jats-rid="t1f1"><sup>*</sup></a></td>
</tr>
<tr>
<td rowspan="1" colspan="1"><b>Novel Therapeutics</b></td>
<td rowspan="1" colspan="1"></td>
<td rowspan="1" colspan="1"></td>
</tr>
<tr>
<td rowspan="1" colspan="1">Improved derivatives</td>
<td rowspan="1" colspan="1">DCK: 5 × lower dose, reduced side effects (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Monitor clinical trials of optimized compounds</td>
</tr>
<tr>
<td rowspan="1" colspan="1">Non-pharmacological</td>
<td rowspan="1" colspan="1">aIH produces adenosine-dependent effects (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Consider for drug-intolerant patients; scalable alternative to ECT</td>
</tr>
<tr>
<td rowspan="1" colspan="1">A1 receptor agonists</td>
<td rowspan="1" colspan="1">Sufficient for 24 h antidepressant action (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Potential monotherapy or adjunct strategy</td>
</tr>
<tr>
<td rowspan="1" colspan="1">A2A receptor role</td>
<td rowspan="1" colspan="1">Contributes to acute effects; less sustained than A1 (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">May complement A1 activation in combination approaches</td>
</tr>
<tr>
<td rowspan="1" colspan="1"><b>Mechanistic Insights</b></td>
<td rowspan="1" colspan="1"></td>
<td rowspan="1" colspan="1"></td>
</tr>
<tr>
<td rowspan="1" colspan="1">Mitochondrial targeting</td>
<td rowspan="1" colspan="1">Ketamine modulates metabolism directly, not primarily via NMDAR (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Focus drug development on metabolic modulators over NMDAR antagonists</td>
</tr>
<tr>
<td rowspan="1" colspan="1">ENT1/2 transporters</td>
<td rowspan="1" colspan="1">Mediate adenosine efflux from intracellular compartment (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Consider ENT modulation as therapeutic strategy</td>
</tr>
<tr>
<td rowspan="1" colspan="1">Metabolic brake</td>
<td rowspan="1" colspan="1">Decreased ATP/ADP ratio precedes adenosine surge (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Target upstream metabolic pathways for novel interventions</td>
</tr>
<tr>
<td rowspan="1" colspan="1"><b>Patient Stratification</b></td>
<td rowspan="1" colspan="1"></td>
<td rowspan="1" colspan="1"></td>
</tr>
<tr>
<td rowspan="1" colspan="1">Genetic predictors</td>
<td rowspan="1" colspan="1">A1/A2A polymorphisms may predict response</td>
<td rowspan="1" colspan="1">Consider genotyping in treatment-resistant cases<a href="#t1f1" data-jats-ref-type="fn" data-jats-rid="t1f1"><sup>*</sup></a></td>
</tr>
<tr>
<td rowspan="1" colspan="1">Biomarker development</td>
<td rowspan="1" colspan="1">Real-time adenosine monitoring validated; peripheral markers possible (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Research protocols for response prediction; drug screening platform</td>
</tr>
<tr>
<td rowspan="1" colspan="1">Treatment history</td>
<td rowspan="1" colspan="1">Chronic caffeine users may have upregulated receptors with preserved reserve (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R14">14</a>–<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R16">16</a>)</td>
<td rowspan="1" colspan="1">Caffeine history as potential predictor (requires validation)<a href="#t1f1" data-jats-ref-type="fn" data-jats-rid="t1f1"><sup>*</sup></a></td>
</tr>
<tr>
<td rowspan="1" colspan="1"><b>Treatment Optimization</b></td>
<td rowspan="1" colspan="1"></td>
<td rowspan="1" colspan="1"></td>
</tr>
<tr>
<td rowspan="1" colspan="1">Mechanism separation</td>
<td rowspan="1" colspan="1">Antidepressant ≠ psychomimetic effects (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Lower doses reduce dissociation/abuse risk</td>
</tr>
<tr>
<td rowspan="1" colspan="1">Circuit specificity</td>
<td rowspan="1" colspan="1">mPFC adenosine necessary &amp; sufficient (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Future: regional targeting strategies; hippocampal effects require further study</td>
</tr>
<tr>
<td rowspan="1" colspan="1">Temporal dynamics</td>
<td rowspan="1" colspan="1">∼30 min adenosine surge → days of benefit (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Optimize inter-treatment intervals; single surge sufficient for sustained effects</td>
</tr>
<tr>
<td rowspan="1" colspan="1">Dose-response</td>
<td rowspan="1" colspan="1">Higher doses prolong duration without increasing peak (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Titrate for optimal balance of efficacy and side effects</td>
</tr>
<tr>
<td rowspan="1" colspan="1"><b>Safety &amp; Side Effects</b></td>
<td rowspan="1" colspan="1"></td>
<td rowspan="1" colspan="1"></td>
</tr>
<tr>
<td rowspan="1" colspan="1">Therapeutic window</td>
<td rowspan="1" colspan="1">DCK effective at 2 mg·kg⁻¹ with minimal hyperlocomotion vs. ketamine 10 mg·kg⁻¹ (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Enhanced safety profile possible with adenosine-optimized compounds</td>
</tr>
<tr>
<td rowspan="1" colspan="1">Dissociation avoidance</td>
<td rowspan="1" colspan="1">Adenosine mechanism separable from NMDAR psychotomimetic effects (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Target adenosine pathway to minimize dissociative experiences</td>
</tr>
<tr>
<td rowspan="1" colspan="1"><b>Non-Pharmacological Interventions</b></td>
<td rowspan="1" colspan="1"></td>
<td rowspan="1" colspan="1"></td>
</tr>
<tr>
<td rowspan="1" colspan="1">aIH advantages</td>
<td rowspan="1" colspan="1">Non-invasive, safe profile in humans, no complex equipment required (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R9">9</a>, <a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Implement in low-resource settings; option for treatment-resistant patients</td>
</tr>
<tr>
<td rowspan="1" colspan="1">ECT mechanistic insight</td>
<td rowspan="1" colspan="1">Adenosine mediates ECT effects; A1/A2A receptors required (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Optimize ECT protocols based on adenosine dynamics; predict responders<a href="#t1f1" data-jats-ref-type="fn" data-jats-rid="t1f1"><sup>*</sup></a></td>
</tr>
<tr>
<td rowspan="1" colspan="1">Sleep deprivation</td>
<td rowspan="1" colspan="1">Known to increase adenosine (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R20">20</a>)</td>
<td rowspan="1" colspan="1">Investigate adenosine monitoring during sleep deprivation therapy<a href="#t1f1" data-jats-ref-type="fn" data-jats-rid="t1f1"><sup>*</sup></a></td>
</tr>
<tr>
<td rowspan="1" colspan="1"><b>Biomarker Applications</b></td>
<td rowspan="1" colspan="1"></td>
<td rowspan="1" colspan="1"></td>
</tr>
<tr>
<td rowspan="1" colspan="1">Drug development</td>
<td rowspan="1" colspan="1">Adenosine dynamics as functional readout for compound screening (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Use GRABAdo sensors for phenotypic drug discovery</td>
</tr>
<tr>
<td rowspan="1" colspan="1">Response prediction</td>
<td rowspan="1" colspan="1">PET tracers for A1/A2A available; peripheral markers under investigation</td>
<td rowspan="1" colspan="1">Develop clinical-grade adenosine monitoring protocols<a href="#t1f1" data-jats-ref-type="fn" data-jats-rid="t1f1"><sup>*</sup></a></td>
</tr>
<tr>
<td rowspan="1" colspan="1">Treatment monitoring</td>
<td rowspan="1" colspan="1">Real-time adenosine measurement feasible (<a href="#" title="" data-jats-ref-type="bibr" data-jats-rid="R2">2</a>)</td>
<td rowspan="1" colspan="1">Potential for dose optimization during treatment<a href="#t1f1" data-jats-ref-type="fn" data-jats-rid="t1f1"><sup>*</sup></a></td>
</tr>
<tr>
<td rowspan="1" colspan="1"><b>Combination Strategies</b></td>
<td rowspan="1" colspan="1"></td>
<td rowspan="1" colspan="1"></td>
</tr>
<tr>
<td rowspan="1" colspan="1">With existing SSRIs</td>
<td rowspan="1" colspan="1">Adenosine pathway may complement monoaminergic effects</td>
<td rowspan="1" colspan="1">Investigate sequential or concurrent administration<a href="#t1f1" data-jats-ref-type="fn" data-jats-rid="t1f1"><sup>*</sup></a></td>
</tr>
<tr>
<td rowspan="1" colspan="1">With psychotherapy</td>
<td rowspan="1" colspan="1">Rapid symptom relief may enhance therapy engagement</td>
<td rowspan="1" colspan="1">Time psychotherapy sessions to peak neuroplasticity window<a href="#t1f1" data-jats-ref-type="fn" data-jats-rid="t1f1"><sup>*</sup></a></td>
</tr>
<tr>
<td rowspan="1" colspan="1">Multi-modal approaches</td>
<td rowspan="1" colspan="1">Combine pharmacological + aIH for additive effects</td>
<td rowspan="1" colspan="1">Pilot studies of combination protocols<a href="#t1f1" data-jats-ref-type="fn" data-jats-rid="t1f1"><sup>*</sup></a></td>
</tr>
</tbody>
</table></div>

</figure>
</section>
<section id="s11">
<h2 id="d22204395e1169">Conclusions</h2>
<p id="p-53">As we have previously written about the psychotherapeutics, it is only time that will tell how far our conceptions of causation are from physical reality. Yue et al. have greatly shortened that distance. The overarching mechanism or platform refers to elements including genetically encoded sensors, validated targets, proof-of-principle molecules, non-drug alternatives and the general model explaining disparate interventions.</p>
<p id="p-54">The adenosine hypothesis can be tested with readily available tools and immediate therapeutic implications. Yue et al. have given the field the aerial view after decades wandering through the forest of empirical psychopharmacology and not looking beyond the next tree.</p>
<p id="p-55">Perhaps the most intriguing implication of this work lies in an unexpected connection: the most rigorous mechanistic dissection of rapid antidepressant action identifies adenosine as the critical mediator, yet adenosine receptors are the primary target of caffeine, the world's most widely consumed psychoactive substance. Is this merely coincidence, or does it reveal something fundamental about why humans have gravitated toward caffeine consumption across cultures and millennia? The epidemiological protection that chronic coffee drinking confers against depression may represent an inadvertent form of adenosinergic modulation operating at population scale. Yet the same mechanism that provides tonic benefit might interfere with phasic therapeutic surges during acute treatment.</p>
<p id="p-56">The coffee paradox demands resolution through carefully designed clinical studies. Do regular coffee drinkers show altered responses to ketamine or electroconvulsive therapy? Does pre-treatment caffeine washout enhance therapeutic outcomes? Can we develop dosing strategies that preserve the protective effects of chronic consumption while optimizing acute treatment responses? The convergence of the world's most prevalent psychoactive drug with the mechanistic lynchpin of our most effective rapid antidepressants is unlikely to be accidental. Understanding this intersection may illuminate both the widespread appeal of caffeine and the optimization of adenosine-targeted therapeutics. The next generation of clinical trials should systematically examine caffeine consumption patterns as a critical variable in treatment response, transforming an apparent pharmacological complication into a therapeutic opportunity.</p>
</section>
<section id="s12">
<h2 id="d22204395e1183">Author contributions</h2>
<p id="p-57">Both authors contributed equally and fully to this article.</p>
</section>
<section id="s13">
<h2 id="d22204395e1190">Funding sources</h2>
<p id="p-58">The authors are supported by funding from the NIH/National Institute of Mental Health (R0MH127423).</p>
</section>
<section id="s14">
<h2 id="d22204395e1197">Author disclosures</h2>
<p id="p-59">The authors declare no conflict of interests.</p>
</section>
</div><section id="references"><h2 id="d22204395e1207">References</h2><ul><li><div itemprop="citation" itemscope="itemscope" data-refid="R1" data-publicationtype="book" data-source="An introduction to the study of experimental medicine" data-year="1957" data-fpage="226"><p><span>1. </span></p><div><p><span itemprop="familyName">Bernard</span> <span itemprop="givenName">C</span></p><p>. <span>An introduction to the study of experimental medicine</span>. </p><p>New York</p><p>: </p><p>Dover Publications</p><p>; <span>1957</span>. <span>226</span> p.</p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R2" data-publicationtype="journal" data-articletitle="Adenosine signalling drives antidepressant actions of ketamine and ECT" data-source="Nature" data-year="2025" data-pubiddoi="10.1038/s41586-025-09755-9" data-pubidpmid="41193806"><p><span>2. </span></p><div><p><span itemprop="familyName">Yue</span> <span itemprop="givenName">C</span></p><p>, </p><p><span itemprop="familyName">Wang</span> <span itemprop="givenName">N</span></p><p>, </p><p><span itemprop="familyName">Zhai</span> <span itemprop="givenName">H</span></p><p>, </p><p><span itemprop="familyName">Yuan</span> <span itemprop="givenName">Z</span></p><p>, </p><p><span itemprop="familyName">Cui</span> <span itemprop="givenName">Y</span></p><p>, </p><p><span itemprop="familyName">Quan</span> <span itemprop="givenName">J</span></p><p>, <span> et al.</span> <span itemprop="name headline">Adenosine signalling drives antidepressant actions of ketamine and ECT</span>. <span>Nature</span>. <span>2025</span>. DOI: <span data-jats-pub-id-type="doi">10.1038/s41586-025-09755-9</span>. PMID: <span data-jats-pub-id-type="pmid">41193806</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R3" data-publicationtype="journal" data-articletitle="NMDA receptor blockade by ketamine abrogates lipopolysaccharide-induced depressive-like behavior in C57BL/6J mice" data-source="Neuropsychopharmacology" data-year="2013" data-volume="38" data-issue="9" data-fpage="1609" data-lpage="16" data-pubiddoi="10.1038/npp.2013.71" data-pubidpmid="23511700" data-pubidpmcid="PMC3717543"><p><span>3. </span></p><div><p><span itemprop="familyName">Walker</span> <span itemprop="givenName">AK</span></p><p>, </p><p><span itemprop="familyName">Budac</span> <span itemprop="givenName">DP</span></p><p>, </p><p><span itemprop="familyName">Bisulco</span> <span itemprop="givenName">S</span></p><p>, </p><p><span itemprop="familyName">Lee</span> <span itemprop="givenName">AW</span></p><p>, </p><p><span itemprop="familyName">Smith</span> <span itemprop="givenName">RA</span></p><p>, </p><p><span itemprop="familyName">Beenders</span> <span itemprop="givenName">B</span></p><p>, <span> et al.</span> <span itemprop="name headline">NMDA receptor blockade by ketamine abrogates lipopolysaccharide-induced depressive-like behavior in C57BL/6J mice</span>. <span>Neuropsychopharmacology</span>. <span>2013</span>;<span>38</span>(</p><p>9</p><p>):<span>1609</span>–<span>16</span>. DOI: <span data-jats-pub-id-type="doi">10.1038/npp.2013.71</span>. PMID: <span data-jats-pub-id-type="pmid">23511700</span>; PMCID: <span data-jats-pub-id-type="pmcid">PMC3717543</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R4" data-publicationtype="journal" data-articletitle="Overview of neuroimmune stress interactions. Implications for susceptibility to inflammatory disease" data-source="Ann NY Acad Sci" data-year="1995" data-volume="771" data-fpage="364" data-lpage="71" data-pubiddoi="10.1111/j.1749-6632.1995.tb44695.x" data-pubidpmid="8597414"><p><span>4. </span></p><div><p><span itemprop="familyName">Sternberg</span> <span itemprop="givenName">EM</span></p><p>, </p><p><span itemprop="familyName">Licinio</span> <span itemprop="givenName">J</span></p><p>. <span itemprop="name headline">Overview of neuroimmune stress interactions. Implications for susceptibility to inflammatory disease</span>. <span>Ann NY Acad Sci</span>. <span>1995</span>;<span>771</span>:<span>364</span>–<span>71</span>. DOI: <span data-jats-pub-id-type="doi">10.1111/j.1749-6632.1995.tb44695.x</span>. PMID: <span data-jats-pub-id-type="pmid">8597414</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R5" data-publicationtype="journal" data-articletitle="Astrocytes release ATP/ADP and glutamate in flashes via vesicular exocytosis" data-source="Mol Psychiatry" data-year="2025" data-volume="30" data-issue="6" data-fpage="2475" data-lpage="89" data-pubiddoi="10.1038/s41380-024-02851-8" data-pubidpmid="39578520"><p><span>5. </span></p><div><p><span itemprop="familyName">Li</span> <span itemprop="givenName">H</span></p><p>, </p><p><span itemprop="familyName">Zhao</span> <span itemprop="givenName">Y</span></p><p>, </p><p><span itemprop="familyName">Dai</span> <span itemprop="givenName">R</span></p><p>, </p><p><span itemprop="familyName">Geng</span> <span itemprop="givenName">P</span></p><p>, </p><p><span itemprop="familyName">Weng</span> <span itemprop="givenName">D</span></p><p>, </p><p><span itemprop="familyName">Wu</span> <span itemprop="givenName">W</span></p><p>, <span> et al.</span> <span itemprop="name headline">Astrocytes release ATP/ADP and glutamate in flashes via vesicular exocytosis</span>. <span>Mol Psychiatry</span>. <span>2025</span>;<span>30</span>(</p><p>6</p><p>):<span>2475</span>–<span>89</span>. DOI: <span data-jats-pub-id-type="doi">10.1038/s41380-024-02851-8</span>. PMID: <span data-jats-pub-id-type="pmid">39578520</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R6" data-publicationtype="journal" data-articletitle="Ketamine administration in depressive disorders: a systematic review and meta-analysis" data-source="Psychopharmacology (Berl)" data-year="2014" data-volume="231" data-issue="18" data-fpage="3663" data-lpage="76" data-pubiddoi="10.1007/s00213-014-3664-5" data-pubidpmid="25038867"><p><span>6. </span></p><div><p><span itemprop="familyName">Fond</span> <span itemprop="givenName">G</span></p><p>, </p><p><span itemprop="familyName">Loundou</span> <span itemprop="givenName">A</span></p><p>, </p><p><span itemprop="familyName">Rabu</span> <span itemprop="givenName">C</span></p><p>, </p><p><span itemprop="familyName">Macgregor</span> <span itemprop="givenName">A</span></p><p>, </p><p><span itemprop="familyName">Lancon</span> <span itemprop="givenName">C</span></p><p>, </p><p><span itemprop="familyName">Brittner</span> <span itemprop="givenName">M</span></p><p>, <span> et al.</span> <span itemprop="name headline">Ketamine administration in depressive disorders: a systematic review and meta-analysis</span>. <span>Psychopharmacology (Berl)</span>. <span>2014</span>;<span>231</span>(</p><p>18</p><p>):<span>3663</span>–<span>76</span>. DOI: <span data-jats-pub-id-type="doi">10.1007/s00213-014-3664-5</span>. PMID: <span data-jats-pub-id-type="pmid">25038867</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R7" data-publicationtype="journal" data-articletitle="Ketamine and Ketamine metabolite pharmacology: insights into therapeutic mechanisms" data-source="Pharmacol Rev" data-year="2018" data-volume="70" data-issue="3" data-fpage="621" data-lpage="60" data-pubiddoi="10.1124/pr.117.015198" data-pubidpmid="29945898" data-pubidpmcid="PMC6020109"><p><span>7. </span></p><div><p><span itemprop="familyName">Zanos</span> <span itemprop="givenName">P</span></p><p>, </p><p><span itemprop="familyName">Moaddel</span> <span itemprop="givenName">R</span></p><p>, </p><p><span itemprop="familyName">Morris</span> <span itemprop="givenName">PJ</span></p><p>, </p><p><span itemprop="familyName">Riggs</span> <span itemprop="givenName">LM</span></p><p>, </p><p><span itemprop="familyName">Highland</span> <span itemprop="givenName">JN</span></p><p>, </p><p><span itemprop="familyName">Georgiou</span> <span itemprop="givenName">P</span></p><p>, <span> et al.</span> <span itemprop="name headline">Ketamine and Ketamine metabolite pharmacology: insights into therapeutic mechanisms</span>. <span>Pharmacol Rev</span>. <span>2018</span>;<span>70</span>(</p><p>3</p><p>):<span>621</span>–<span>60</span>. DOI: <span data-jats-pub-id-type="doi">10.1124/pr.117.015198</span>. PMID: <span data-jats-pub-id-type="pmid">29945898</span>; PMCID: <span data-jats-pub-id-type="pmcid">PMC6020109</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R8" data-publicationtype="journal" data-articletitle="NMDAR inhibition-independent antidepressant actions of ketamine metabolites" data-source="Nature" data-year="2016" data-volume="533" data-issue="7604" data-fpage="481" data-lpage="6" data-pubiddoi="10.1038/nature17998" data-pubidpmid="27144355" data-pubidpmcid="PMC4922311"><p><span>8. </span></p><div><p><span itemprop="familyName">Zanos</span> <span itemprop="givenName">P</span></p><p>, </p><p><span itemprop="familyName">Moaddel</span> <span itemprop="givenName">R</span></p><p>, </p><p><span itemprop="familyName">Morris</span> <span itemprop="givenName">PJ</span></p><p>, </p><p><span itemprop="familyName">Georgiou</span> <span itemprop="givenName">P</span></p><p>, </p><p><span itemprop="familyName">Fischell</span> <span itemprop="givenName">J</span></p><p>, </p><p><span itemprop="familyName">Elmer</span> <span itemprop="givenName">GI</span></p><p>, <span> et al.</span> <span itemprop="name headline">NMDAR inhibition-independent antidepressant actions of ketamine metabolites</span>. <span>Nature</span>. <span>2016</span>;<span>533</span>(</p><p>7604</p><p>):<span>481</span>–<span>6</span>. DOI: <span data-jats-pub-id-type="doi">10.1038/nature17998</span>. PMID: <span data-jats-pub-id-type="pmid">27144355</span>; PMCID: <span data-jats-pub-id-type="pmcid">PMC4922311</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R9" data-publicationtype="journal" data-articletitle="Therapeutic potential of intermittent hypoxia: a matter of dose" data-source="Am J Physiol Regul Integr Comp Physiol" data-year="2014" data-volume="307" data-issue="10" data-fpage="R1181" data-lpage="97" data-pubiddoi="10.1152/ajpregu.00208.2014" data-pubidpmid="25231353" data-pubidpmcid="PMC4315448"><p><span>9. </span></p><div><p><span itemprop="familyName">Navarrete-Opazo</span> <span itemprop="givenName">A</span></p><p>, </p><p><span itemprop="familyName">Mitchell</span> <span itemprop="givenName">GS</span></p><p>. <span itemprop="name headline">Therapeutic potential of intermittent hypoxia: a matter of dose</span>. <span>Am J Physiol Regul Integr Comp Physiol</span>. <span>2014</span>;<span>307</span>(</p><p>10</p><p>):<span>R1181</span>–<span>97</span>. DOI: <span data-jats-pub-id-type="doi">10.1152/ajpregu.00208.2014</span>. PMID: <span data-jats-pub-id-type="pmid">25231353</span>; PMCID: <span data-jats-pub-id-type="pmcid">PMC4315448</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R10" data-publicationtype="journal" data-articletitle="The physiological effects of caffeine on synaptic transmission and plasticity in the mouse hippocampus selectively depend on adenosine A1 and A2A receptors" data-source="Biochem Pharmacol" data-year="2019" data-volume="166" data-fpage="313" data-lpage="21" data-pubiddoi="10.1016/j.bcp.2019.06.008" data-pubidpmid="31199895"><p><span>10. </span></p><div><p><span itemprop="familyName">Lopes</span> <span itemprop="givenName">JP</span></p><p>, </p><p><span itemprop="familyName">Pliássova</span> <span itemprop="givenName">A</span></p><p>, </p><p><span itemprop="familyName">Cunha</span> <span itemprop="givenName">RA</span></p><p>. <span itemprop="name headline">The physiological effects of caffeine on synaptic transmission and plasticity in the mouse hippocampus selectively depend on adenosine A<sub>1</sub> and A<sub>2A</sub> receptors</span>. <span>Biochem Pharmacol</span>. <span>2019</span>;<span>166</span>:<span>313</span>–<span>21</span>. DOI: <span data-jats-pub-id-type="doi">10.1016/j.bcp.2019.06.008</span>. PMID: <span data-jats-pub-id-type="pmid">31199895</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R11" data-publicationtype="journal" data-articletitle="Actions of caffeine in the brain with special reference to factors that contribute to its widespread use" data-source="Pharmacol Rev" data-year="1999" data-volume="51" data-issue="1" data-fpage="83" data-lpage="133" data-pubidpmid="10049999"><p><span>11. </span></p><div><p><span itemprop="familyName">Fredholm</span> <span itemprop="givenName">BB</span></p><p>, </p><p><span itemprop="familyName">Bättig</span> <span itemprop="givenName">K</span></p><p>, </p><p><span itemprop="familyName">Holmén</span> <span itemprop="givenName">J</span></p><p>, </p><p><span itemprop="familyName">Nehlig</span> <span itemprop="givenName">A</span></p><p>, </p><p><span itemprop="familyName">Zvartau</span> <span itemprop="givenName">EE</span></p><p>. <span itemprop="name headline">Actions of caffeine in the brain with special reference to factors that contribute to its widespread use</span>. <span>Pharmacol Rev</span>. <span>1999</span>;<span>51</span>(</p><p>1</p><p>):<span>83</span>–<span>133</span>. PMID: <span data-jats-pub-id-type="pmid">10049999</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R12" data-publicationtype="journal" data-articletitle="Coffee and caffeine consumption and depression: A meta-analysis of observational studies" data-source="Aust N Z J Psychiatry" data-year="2016" data-volume="50" data-issue="3" data-fpage="228" data-lpage="42" data-pubiddoi="10.1177/0004867415603131" data-pubidpmid="26339067"><p><span>12. </span></p><div><p><span itemprop="familyName">Wang</span> <span itemprop="givenName">L</span></p><p>, </p><p><span itemprop="familyName">Shen</span> <span itemprop="givenName">X</span></p><p>, </p><p><span itemprop="familyName">Wu</span> <span itemprop="givenName">Y</span></p><p>, </p><p><span itemprop="familyName">Zhang</span> <span itemprop="givenName">D</span></p><p>. <span itemprop="name headline">Coffee and caffeine consumption and depression: A meta-analysis of observational studies</span>. <span>Aust N Z J Psychiatry</span>. <span>2016</span>;<span>50</span>(</p><p>3</p><p>):<span>228</span>–<span>42</span>. DOI: <span data-jats-pub-id-type="doi">10.1177/0004867415603131</span>. PMID: <span data-jats-pub-id-type="pmid">26339067</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R13" data-publicationtype="journal" data-articletitle="Coffee, tea, caffeine and risk of depression: A systematic review and dose-response meta-analysis of observational studies" data-source="Mol Nutr Food Res" data-year="2016" data-volume="60" data-issue="1" data-fpage="223" data-lpage="34" data-pubiddoi="10.1002/mnfr.201500620" data-pubidpmid="26518745"><p><span>13. </span></p><div><p><span itemprop="familyName">Grosso</span> <span itemprop="givenName">G</span></p><p>, </p><p><span itemprop="familyName">Micek</span> <span itemprop="givenName">A</span></p><p>, </p><p><span itemprop="familyName">Castellano</span> <span itemprop="givenName">S</span></p><p>, </p><p><span itemprop="familyName">Pajak</span> <span itemprop="givenName">A</span></p><p>, </p><p><span itemprop="familyName">Galvano</span> <span itemprop="givenName">F</span></p><p>. <span itemprop="name headline">Coffee, tea, caffeine and risk of depression: A systematic review and dose-response meta-analysis of observational studies</span>. <span>Mol Nutr Food Res</span>. <span>2016</span>;<span>60</span>(</p><p>1</p><p>):<span>223</span>–<span>34</span>. DOI: <span data-jats-pub-id-type="doi">10.1002/mnfr.201500620</span>. PMID: <span data-jats-pub-id-type="pmid">26518745</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R14" data-publicationtype="journal" data-articletitle="Role of adenosine receptors in caffeine tolerance" data-source="J Pharmacol Exp Ther" data-year="1991" data-volume="256" data-issue="1" data-fpage="62" data-lpage="8" data-pubidpmid="1846425"><p><span>14. </span></p><div><p><span itemprop="familyName">Holtzman</span> <span itemprop="givenName">SG</span></p><p>, </p><p><span itemprop="familyName">Mante</span> <span itemprop="givenName">S</span></p><p>, </p><p><span itemprop="familyName">Minneman</span> <span itemprop="givenName">KP</span></p><p>. <span itemprop="name headline">Role of adenosine receptors in caffeine tolerance</span>. <span>J Pharmacol Exp Ther</span>. <span>1991</span>;<span>256</span>(</p><p>1</p><p>):<span>62</span>–<span>8</span>. PMID: <span data-jats-pub-id-type="pmid">1846425</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R15" data-publicationtype="journal" data-articletitle="Inverse agonists and neutral antagonists of recombinant human A1 adenosine receptors stably expressed in Chinese hamster ovary cells" data-source="Mol Pharmacol" data-year="1998" data-volume="53" data-issue="5" data-fpage="886" data-lpage="93" data-pubidpmid="9584215"><p><span>15. </span></p><div><p><span itemprop="familyName">Shryock</span> <span itemprop="givenName">JC</span></p><p>, </p><p><span itemprop="familyName">Ozeck</span> <span itemprop="givenName">MJ</span></p><p>, </p><p><span itemprop="familyName">Belardinelli</span> <span itemprop="givenName">L</span></p><p>. <span itemprop="name headline">Inverse agonists and neutral antagonists of recombinant human A1 adenosine receptors stably expressed in Chinese hamster ovary cells</span>. <span>Mol Pharmacol</span>. <span>1998</span>;<span>53</span>(</p><p>5</p><p>):<span>886</span>–<span>93</span>. PMID: <span data-jats-pub-id-type="pmid">9584215</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R16" data-publicationtype="journal" data-articletitle="A2A-adenosine receptor reserve for coronary vasodilation" data-source="Circulation" data-year="1998" data-volume="98" data-issue="7" data-fpage="711" data-lpage="8" data-pubiddoi="10.1161/01.cir.98.7.711" data-pubidpmid="9715864"><p><span>16. </span></p><div><p><span itemprop="familyName">Shryock</span> <span itemprop="givenName">JC</span></p><p>, </p><p><span itemprop="familyName">Snowdy</span> <span itemprop="givenName">S</span></p><p>, </p><p><span itemprop="familyName">Baraldi</span> <span itemprop="givenName">PG</span></p><p>, </p><p><span itemprop="familyName">Cacciari</span> <span itemprop="givenName">B</span></p><p>, </p><p><span itemprop="familyName">Spalluto</span> <span itemprop="givenName">G</span></p><p>, </p><p><span itemprop="familyName">Monopoli</span> <span itemprop="givenName">A</span></p><p>, <span> et al.</span> <span itemprop="name headline">A2A-adenosine receptor reserve for coronary vasodilation</span>. <span>Circulation</span>. <span>1998</span>;<span>98</span>(</p><p>7</p><p>):<span>711</span>–<span>8</span>. DOI: <span data-jats-pub-id-type="doi">10.1161/01.cir.98.7.711</span>. PMID: <span data-jats-pub-id-type="pmid">9715864</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R17" data-publicationtype="journal" data-articletitle="Adenosine A2A receptor occupancy by caffeine after coffee intake in Parkinson's disease" data-source="Mov Disord" data-year="2022" data-volume="37" data-issue="4" data-fpage="853" data-lpage="7" data-pubiddoi="10.1002/mds.28897" data-pubidpmid="35001424" data-pubidpmcid="PMC9306703"><p><span>17. </span></p><div><p><span itemprop="familyName">Ishibashi</span> <span itemprop="givenName">K</span></p><p>, </p><p><span itemprop="familyName">Miura</span> <span itemprop="givenName">Y</span></p><p>, </p><p><span itemprop="familyName">Wagatsuma</span> <span itemprop="givenName">K</span></p><p>, </p><p><span itemprop="familyName">Toyohara</span> <span itemprop="givenName">J</span></p><p>, </p><p><span itemprop="familyName">Ishiwata</span> <span itemprop="givenName">K</span></p><p>, </p><p><span itemprop="familyName">Ishii</span> <span itemprop="givenName">K</span></p><p>. <span itemprop="name headline">Adenosine A<sub>2A</sub> receptor occupancy by caffeine after coffee intake in Parkinson's disease</span>. <span>Mov Disord</span>. <span>2022</span>;<span>37</span>(</p><p>4</p><p>):<span>853</span>–<span>7</span>. DOI: <span data-jats-pub-id-type="doi">10.1002/mds.28897</span>. PMID: <span data-jats-pub-id-type="pmid">35001424</span>; PMCID: <span data-jats-pub-id-type="pmcid">PMC9306703</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R18" data-publicationtype="journal" data-articletitle="BDNF – a key transducer of antidepressant effects" data-source="Neuropharmacology" data-year="2016" data-volume="102" data-fpage="72" data-lpage="9" data-pubiddoi="10.1016/j.neuropharm.2015.10.034" data-pubidpmid="26519901" data-pubidpmcid="PMC4763983"><p><span>18. </span></p><div><p><span itemprop="familyName">Björkholm</span> <span itemprop="givenName">C</span></p><p>, </p><p><span itemprop="familyName">Monteggia</span> <span itemprop="givenName">LM</span></p><p>. <span itemprop="name headline">BDNF – a key transducer of antidepressant effects</span>. <span>Neuropharmacology</span>. <span>2016</span>;<span>102</span>:<span>72</span>–<span>9</span>. DOI: <span data-jats-pub-id-type="doi">10.1016/j.neuropharm.2015.10.034</span>. PMID: <span data-jats-pub-id-type="pmid">26519901</span>; PMCID: <span data-jats-pub-id-type="pmcid">PMC4763983</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R19" data-publicationtype="journal" data-articletitle="Increased signaling via adenosine A1 receptors, sleep deprivation, imipramine, and ketamine inhibit depressive-like behavior via induction of Homer1a" data-source="Neuron" data-year="2015" data-volume="87" data-issue="3" data-fpage="549" data-lpage="62" data-pubiddoi="10.1016/j.neuron.2015.07.010" data-pubidpmid="26247862" data-pubidpmcid="PMC4803038"><p><span>19. </span></p><div><p><span itemprop="familyName">Serchov</span> <span itemprop="givenName">T</span></p><p>, </p><p><span itemprop="familyName">Clement</span> <span itemprop="givenName">HW</span></p><p>, </p><p><span itemprop="familyName">Schwarz</span> <span itemprop="givenName">MK</span></p><p>, </p><p><span itemprop="familyName">Iasevoli</span> <span itemprop="givenName">F</span></p><p>, </p><p><span itemprop="familyName">Tosh</span> <span itemprop="givenName">DK</span></p><p>, </p><p><span itemprop="familyName">Idzko</span> <span itemprop="givenName">M</span></p><p>, <span> et al.</span> <span itemprop="name headline">Increased signaling via adenosine A1 receptors, sleep deprivation, imipramine, and ketamine inhibit depressive-like behavior via induction of Homer1a</span>. <span>Neuron</span>. <span>2015</span>;<span>87</span>(</p><p>3</p><p>):<span>549</span>–<span>62</span>. DOI: <span data-jats-pub-id-type="doi">10.1016/j.neuron.2015.07.010</span>. PMID: <span data-jats-pub-id-type="pmid">26247862</span>; PMCID: <span data-jats-pub-id-type="pmcid">PMC4803038</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R20" data-publicationtype="journal" data-articletitle="mTOR-dependent synapse formation underlies the rapid antidepressant effects of NMDA antagonists" data-source="Science" data-year="2010" data-volume="329" data-issue="5994" data-fpage="959" data-lpage="64" data-pubiddoi="10.1126/science.1190287" data-pubidpmid="20724638" data-pubidpmcid="PMC3116441"><p><span>20. </span></p><div><p><span itemprop="familyName">Li</span> <span itemprop="givenName">N</span></p><p>, </p><p><span itemprop="familyName">Lee</span> <span itemprop="givenName">B</span></p><p>, </p><p><span itemprop="familyName">Liu</span> <span itemprop="givenName">RJ</span></p><p>, </p><p><span itemprop="familyName">Banasr</span> <span itemprop="givenName">M</span></p><p>, </p><p><span itemprop="familyName">Dwyer</span> <span itemprop="givenName">JM</span></p><p>, </p><p><span itemprop="familyName">Iwata</span> <span itemprop="givenName">M</span></p><p>, <span> et al.</span> <span itemprop="name headline">mTOR-dependent synapse formation underlies the rapid antidepressant effects of NMDA antagonists</span>. <span>Science</span>. <span>2010</span>;<span>329</span>(</p><p>5994</p><p>):<span>959</span>–<span>64</span>. DOI: <span data-jats-pub-id-type="doi">10.1126/science.1190287</span>. PMID: <span data-jats-pub-id-type="pmid">20724638</span>; PMCID: <span data-jats-pub-id-type="pmcid">PMC3116441</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R21" data-publicationtype="journal" data-articletitle="Antidepressant effects of ketamine in depressed patients" data-source="Biol Psychiatry" data-year="2000" data-volume="47" data-issue="4" data-fpage="351" data-lpage="4" data-pubiddoi="10.1016/s0006-3223(99)00230-9" data-pubidpmid="10686270"><p><span>21. </span></p><div><p><span itemprop="familyName">Berman</span> <span itemprop="givenName">RM</span></p><p>, </p><p><span itemprop="familyName">Cappiello</span> <span itemprop="givenName">A</span></p><p>, </p><p><span itemprop="familyName">Anand</span> <span itemprop="givenName">A</span></p><p>, </p><p><span itemprop="familyName">Oren</span> <span itemprop="givenName">DA</span></p><p>, </p><p><span itemprop="familyName">Heninger</span> <span itemprop="givenName">GR</span></p><p>, </p><p><span itemprop="familyName">Charney</span> <span itemprop="givenName">DS</span></p><p>, <span> et al.</span> <span itemprop="name headline">Antidepressant effects of ketamine in depressed patients</span>. <span>Biol Psychiatry</span>. <span>2000</span>;<span>47</span>(</p><p>4</p><p>):<span>351</span>–<span>4</span>. DOI: <span data-jats-pub-id-type="doi">10.1016/s0006-3223(99)00230-9</span>. PMID: <span data-jats-pub-id-type="pmid">10686270</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R22" data-publicationtype="journal" data-articletitle="NMDA receptor blockade at rest triggers rapid behavioural antidepressant responses" data-source="Nature" data-year="2011" data-volume="475" data-issue="7354" data-fpage="91" data-lpage="5" data-pubiddoi="10.1038/nature10130" data-pubidpmid="21677641" data-pubidpmcid="PMC3172695"><p><span>22. </span></p><div><p><span itemprop="familyName">Autry</span> <span itemprop="givenName">AE</span></p><p>, </p><p><span itemprop="familyName">Adachi</span> <span itemprop="givenName">M</span></p><p>, </p><p><span itemprop="familyName">Nosyreva</span> <span itemprop="givenName">E</span></p><p>, </p><p><span itemprop="familyName">Na</span> <span itemprop="givenName">ES</span></p><p>, </p><p><span itemprop="familyName">Los</span> <span itemprop="givenName">MF</span></p><p>, </p><p><span itemprop="familyName">Cheng</span> <span itemprop="givenName">PF</span></p><p>, <span> et al.</span> <span itemprop="name headline">NMDA receptor blockade at rest triggers rapid behavioural antidepressant responses</span>. <span>Nature</span>. <span>2011</span>;<span>475</span>(</p><p>7354</p><p>):<span>91</span>–<span>5</span>. DOI: <span data-jats-pub-id-type="doi">10.1038/nature10130</span>. PMID: <span data-jats-pub-id-type="pmid">21677641</span>; PMCID: <span data-jats-pub-id-type="pmcid">PMC3172695</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R23" data-publicationtype="journal" data-articletitle="Synaptic plasticity and depression: new insights from stress and rapid-acting antidepressants" data-source="Nat Med" data-year="2016" data-volume="22" data-issue="3" data-fpage="238" data-lpage="49" data-pubiddoi="10.1038/nm.4050" data-pubidpmid="26937618" data-pubidpmcid="PMC5405628"><p><span>23. </span></p><div><p><span itemprop="familyName">Duman</span> <span itemprop="givenName">RS</span></p><p>, </p><p><span itemprop="familyName">Aghajanian</span> <span itemprop="givenName">GK</span></p><p>, </p><p><span itemprop="familyName">Sanacora</span> <span itemprop="givenName">G</span></p><p>, </p><p><span itemprop="familyName">Krystal</span> <span itemprop="givenName">JH</span></p><p>. <span itemprop="name headline">Synaptic plasticity and depression: new insights from stress and rapid-acting antidepressants</span>. <span>Nat Med</span>. <span>2016</span>;<span>22</span>(</p><p>3</p><p>):<span>238</span>–<span>49</span>. DOI: <span data-jats-pub-id-type="doi">10.1038/nm.4050</span>. PMID: <span data-jats-pub-id-type="pmid">26937618</span>; PMCID: <span data-jats-pub-id-type="pmcid">PMC5405628</span></p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li><li><div itemprop="citation" itemscope="itemscope" data-refid="R24" data-publicationtype="book" data-source="Simulacra and simulation" data-year="1994" data-fpage="164"><p><span>24. </span></p><div><p><span itemprop="familyName">Baudrillard</span> <span itemprop="givenName">J</span></p><p>. <span>Simulacra and simulation</span>. </p><p>Ann Arbor</p><p>: </p><p>University of Michigan Press</p><p>; <span>1994</span>. <span>164</span> p.</p></div></div><ul data-listtype="ref-links"><li data-linktype="openurl"><a>OpenURL</a></li><li data-linktype="pubmed"><a>PubMed</a></li><li data-linktype="googlescholar"><a>Google Scholar</a></li><li data-linktype="crossref"><a>Crossref</a></li></ul></li></ul></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Frank Gehry has died (181 pts)]]></title>
            <link>https://www.bbc.co.uk/news/articles/c5y2p22z9gno</link>
            <guid>46167621</guid>
            <pubDate>Fri, 05 Dec 2025 21:31:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.co.uk/news/articles/c5y2p22z9gno">https://www.bbc.co.uk/news/articles/c5y2p22z9gno</a>, See on <a href="https://news.ycombinator.com/item?id=46167621">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main id="main-content" data-testid="main-content"><article><header data-component="headline-block"></header><div data-component="image-block"><figure><p><span><picture><source srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/1b2b/live/ca170da0-d215-11f0-9fb5-5f3a3703a365.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/1b2b/live/ca170da0-d215-11f0-9fb5-5f3a3703a365.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/1b2b/live/ca170da0-d215-11f0-9fb5-5f3a3703a365.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/1b2b/live/ca170da0-d215-11f0-9fb5-5f3a3703a365.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/1b2b/live/ca170da0-d215-11f0-9fb5-5f3a3703a365.jpg.webp 800w, https://ichef.bbci.co.uk/ace/standard/976/cpsprodpb/1b2b/live/ca170da0-d215-11f0-9fb5-5f3a3703a365.jpg.webp 976w" type="image/webp"><img alt="Architect Frank Gehry attends the official groundbreaking of &quot;The Grand&quot; a Frank Gehry designed mixed-use development in downtown Los Angeles, California, U.S., February 11, 2019." src="https://ichef.bbci.co.uk/ace/standard/3840/cpsprodpb/1b2b/live/ca170da0-d215-11f0-9fb5-5f3a3703a365.jpg" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/1b2b/live/ca170da0-d215-11f0-9fb5-5f3a3703a365.jpg 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/1b2b/live/ca170da0-d215-11f0-9fb5-5f3a3703a365.jpg 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/1b2b/live/ca170da0-d215-11f0-9fb5-5f3a3703a365.jpg 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/1b2b/live/ca170da0-d215-11f0-9fb5-5f3a3703a365.jpg 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/1b2b/live/ca170da0-d215-11f0-9fb5-5f3a3703a365.jpg 800w, https://ichef.bbci.co.uk/ace/standard/976/cpsprodpb/1b2b/live/ca170da0-d215-11f0-9fb5-5f3a3703a365.jpg 976w" width="3840" height="2187.8608336203924"></picture></span><span role="text"><span>Image source, </span>REUTERS/Mike Blake/File Photo</span></p></figure></div><div data-component="text-block"><p><b>Frank Gehry, one of the most influential architects of the last century, has died aged 96.</b></p><p>Gehry was acclaimed for his avant garde, experimental style of architecture. His titanium-covered design of the Guggenheim Museum in Bilbao, Spain, catapulted him to fame in 1997. </p><p>He built his daring reputation years before that when he redesigned his own home in Santa Monica, California, using materials like chain-link fencing, plywood and corrugated steel.</p><p>HIs death was confirmed by his chief of staff Meaghan Lloyd. He is survived by two daughters from his first marriage, Leslie and Brina; his wife, Berta Isabel Aguilera, and their two sons, Alejandro and Samuel, </p></div><div data-component="image-block"><figure><p><span><picture><source srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/a09e/live/d722d3b0-d217-11f0-9ff5-d97ce7f38231.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/a09e/live/d722d3b0-d217-11f0-9ff5-d97ce7f38231.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/a09e/live/d722d3b0-d217-11f0-9ff5-d97ce7f38231.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/a09e/live/d722d3b0-d217-11f0-9ff5-d97ce7f38231.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/a09e/live/d722d3b0-d217-11f0-9ff5-d97ce7f38231.jpg.webp 800w, https://ichef.bbci.co.uk/ace/standard/976/cpsprodpb/a09e/live/d722d3b0-d217-11f0-9ff5-d97ce7f38231.jpg.webp 976w" type="image/webp"><img alt="A view of the Guggenheim Museum Bilbao" loading="lazy" src="https://ichef.bbci.co.uk/ace/standard/1024/cpsprodpb/a09e/live/d722d3b0-d217-11f0-9ff5-d97ce7f38231.jpg" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/a09e/live/d722d3b0-d217-11f0-9ff5-d97ce7f38231.jpg 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/a09e/live/d722d3b0-d217-11f0-9ff5-d97ce7f38231.jpg 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/a09e/live/d722d3b0-d217-11f0-9ff5-d97ce7f38231.jpg 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/a09e/live/d722d3b0-d217-11f0-9ff5-d97ce7f38231.jpg 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/a09e/live/d722d3b0-d217-11f0-9ff5-d97ce7f38231.jpg 800w, https://ichef.bbci.co.uk/ace/standard/976/cpsprodpb/a09e/live/d722d3b0-d217-11f0-9ff5-d97ce7f38231.jpg 976w" width="1024" height="576"></picture></span><span role="text"><span>Image source, </span>Getty Images</span></p><figcaption><span>Image caption, </span><p>The Guggenheim Museum Bilbao, one of Gehry's most famous works</p></figcaption></figure></div><div data-component="text-block"><p>Born in Toronto in 1929, Gehry moved to Los Angeles as a teenager to study architecture at the University of Southern California before completing further study at  the Harvard Graduate School of Design in 1956 and 1957.</p><p>After starting his own firm, he broke from the traditional architectural principles of symmetry, using unconventional geometric<b> </b>shapes and unfinished<b> </b>materials in a style now known as deconstructivism. </p><p>"I was rebelling against everything," Gehry said in an interview with The New York Times in 2012.</p><p>His work in Bilbao put him in high demand, and he went on to design iconic structures in cities all over the world: the Jay Pritzker Pavilion in Chicago's Millennium Park, the Gehry Tower in Germany, and the Louis Vuitton Foundation in Paris. </p></div><div data-component="text-block"><p>"He bestowed upon Paris and upon France his greatest masterpiece," said Bernard Arnault, the CEO of LVMH, the worlds largest luxury goods company which owns Louis Vuitton.</p><p>With a largely unpredictable style, no two of his works look the same. Prague's Dancing House, finished in 1996, looks like a glass building folding in on itself; his Hotel Marques in Spain, built in 2006, features thin sheets of wavy, multicoloured metal; his design for a business school in Sydney looks like a <a href="https://www.bbc.co.uk/news/world-australia-31087980">brown paper bag</a>.</p><p>Gehry won the coveted Pritzker Architecture Prize for lifetime achievement in 1989, when he was 60, with his work described as having a "highly refined, sophisticated and adventurous aesthetic".</p><p>"His designs, if compared to American music, could best be likened to Jazz, replete with improvisation and a lively unpredictable spirit," ther Pritzker jury said at the time.</p></div><div data-component="text-block"><p>Gehry was awarded the Order of Canada in 2002 and the Presidential Medal of Freedom, the highest civilian honour in the US, in 2016. </p></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A $20 drug in Europe requires a prescription and $800 in the U.S. (245 pts)]]></title>
            <link>https://www.statnews.com/2025/10/31/why-miebo-costs-40-times-more-than-its-european-version/</link>
            <guid>46167557</guid>
            <pubDate>Fri, 05 Dec 2025 21:27:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.statnews.com/2025/10/31/why-miebo-costs-40-times-more-than-its-european-version/">https://www.statnews.com/2025/10/31/why-miebo-costs-40-times-more-than-its-european-version/</a>, See on <a href="https://news.ycombinator.com/item?id=46167557">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A month’s supply of Miebo, Bausch &amp; Lomb’s prescription dry eye drug, costs $800 or more in the U.S. before insurance. But the same drug — sold as <a href="https://ois.net/novaliq-transforming-tears/" target="_blank" rel="noopener">EvoTears</a> — has been available over-the-counter (OTC) in Europe since 2015 for about $20. I ordered it online from an overseas pharmacy for $32 including shipping, and it was delivered in a week.&nbsp;</p>



<p>This is, of course, both shocking and unsurprising. A 2021 RAND <a href="https://www.rand.org/news/press/2021/01/28.html" target="_blank" rel="noopener">study</a> found U.S. prescription drug prices are, on average, more than 2.5 times higher than in 32 other developed nations. Miebo exemplifies how some pharmaceutical companies exploit regulatory loopholes and patent protections, prioritizing profits over patients, eroding trust in health care. But there is a way to fix this loophole.</p>



<p>In December 2019, Bausch &amp; Lomb, formerly a division of Valeant, acquired the exclusive license for the commercialization and development in&nbsp;the United States&nbsp;and&nbsp;Canada&nbsp;for NOV03, now called Miebo in the U.S. Rather than getting an approval for an OTC drug, like it is in Europe, Bausch secured U.S. Food and Drug Administration approval as a prescription medication, subsequently pricing it at a high level. Currently, according to GoodRx, a monthly supply of Miebo will cost $830.27 at Walgreens, and it’s listed at $818.38 on <a href="https://pharmacy.amazon.com/dp/B0CJV1CC69" target="_blank" rel="noopener">Amazon Pharmacy</a>.</p>



<p>The strategy has paid off: Miebo’s 2024 sales — its first full year — hit <a href="https://ir.bausch.com/sites/bauschhealth-ir/files/2025-02/4q24-bausch-lomb-earnings-presentation.pdf" target="_blank" rel="noopener">$172 million</a>, surpassing the company’s projections of $95 million. The company now forecasts sales to exceed <a href="https://www.fiercepharma.com/marketing/bausch-lomb-taps-broadcaster-erin-andrews-push-fast-growing-dry-eye-disease-drug" target="_blank" rel="noopener">$500 million annually</a>. At European prices, those sales would be less than $20 million. Emboldened with Miebo’s early success, Bausch &amp; Lomb raised the price another 4% in 2025, according to the drug price tracking firm 46brooklyn.</p>



<p>Bausch &amp; Lomb has a track record of prioritizing profits over patients. As Valeant, its business model was simple: buy, gut, gouge, repeat. In 2015, it raised prices for Nitropress and Isuprel by over <a href="https://www.wsj.com/articles/pharmaceutical-companies-buy-rivals-drugs-then-jack-up-the-prices-1430096431?mod=article_inline" target="_blank" rel="noopener">200% and 500%</a>, respectively, triggering a 2016 congressional hearing. Despite promises of reform, little has changed. When he was at Allergan, Bausch &amp; Lomb’s current CEO, Brent Saunders, pledged “<a href="https://www.linkedin.com/pulse/allergans-social-contract-protect-medical-innovation-from-goldberg/" target="_blank" rel="noopener">responsible pricing</a>” but tried to extend patent protection for Allergan’s drug Restasis (another dry eye drug) through a <a href="https://www.statnews.com/pharmalot/2018/07/20/allergan-mohawk-patent-restasis/">dubious deal with the Mohawk Indian tribe</a>, later rejected by courts.</p>





<p>Now at Bausch &amp; Lomb, Saunders oversaw Miebo’s launch, claiming earlier this year in an investor call, “We are once again an innovation company.” But finding a way to get an existing European OTC drug to be a prescription drug in the U.S. with a new name and a 40-fold price increase is not true innovation — it’s a price-gouging strategy.</p>



<p>Bausch &amp; Lomb could have pursued OTC approval in the U.S., leveraging its expertise in OTC eye drops and lotions. However, I could not find in transcripts or presentations any evidence that Baush &amp; Lomb seriously pursued this. Prescription status, however, ensures much higher prices, protected by patents and limited competition. Even insured patients feel the ripple effects: Coupons may reduce out-of-pocket costs, but insurers pay hundreds per prescription, driving up premiums and the overall cost of health care for everyone.</p>



<p>In response to questions from STAT about why Miebo is an expensive prescription drug, a representative said in a statement, “The FDA determined that MIEBO acts at the cellular and molecular level of the eye, which meant it had to go through the same rigorous process as any new pharmaceutical — a full New Drug Application. Unlike in Europe, where all medical device eye drops are prescription-free and cleared through a highly predictable and fast pathway, we were required to design, enroll and complete extensive clinical trials involving thousands of patients, and provide detailed safety and efficacy data submissions. Those studies took years and significant investment, but they ensure that MIEBO meets the highest regulatory standards for safety and effectiveness.”</p>



<p>Bausch &amp; Lomb’s carefully worded response expertly sidesteps the real issue. The FDA’s test for OTC status isn’t a drug’s mechanism of action — it’s whether patients can use it safely without a doctor. Miebo’s track record as an OTC product in Europe for nearly a decade shows it meets that standard. Bausch &amp; Lomb provides no evidence, or even assertion, that it ever tried for OTC approval in the U.S. Instead, it pursued the prescription route — not because of regulatory necessity, but as a business strategy to secure patents and command an $800 price. In doing so, B&amp;L is weaponizing a regulatory loophole against American patients, prioritizing profit over access, and leaving their “significant investment” as the cost of monopoly, not medical necessity.</p>



<p>Even if you accept Bausch &amp; Lomb’s self-serving rationale, the answer is not to allow the loophole to persist, but to close it.&nbsp;The FDA could require any drug approved as OTC internationally be considered for OTC status in the United States before greenlighting it as a prescription product — and mandate retroactive review of cases like Miebo.</p>





<p>The FDA’s OTC monograph process, which assesses the safety and efficacy of nonprescription drugs, makes this feasible, though it may need to be adjusted slightly. Those changes might involve incorporating a mechanism to make sure that overseas OTC status triggers a review of U.S. prescription drugs containing the same active ingredients or formulations for potential OTC designation; developing criteria to assess equivalency in safety and efficacy standards between U.S. OTC requirements and those of other countries; and establishing a retroactive review pathway within the monograph process to handle existing prescription drugs already marketed OTC internationally.</p>



<p>EvoTears thrives abroad without safety concerns, countering industry claims of stricter U.S. standards. This reform would deter companies from repackaging OTC drugs as high-cost prescriptions, fostering competition and lowering prices.</p>



<p>While this tactic isn’t widespread, it joins loopholes like late-listed patents, picket fence patents, or pay-for-delay generic deals that undermine trust in an industry whose employees largely aim to save lives.</p>



<p>Miebo also shows how global reference pricing could save billions. Aligning with European prices could cut consumer costs while reducing doctor visits, pharmacy time, and administrative burdens. For patients who skip doses to afford groceries, lower prices would mean better access and health. Reforms like the 2022 Inflation Reduction Act’s Medicare price negotiations set a precedent, but targeted rules are urgently needed.</p>



<p>Unexplained differences in drug prices between the U.S. and other wealthy countries erode the public’s trust in health care. Companies like Bausch &amp; Lomb exploit systemic gaps, leaving patients and payers to foot exorbitant bills. An OTC evaluation rule, with retroactive reviews, is a practical first step, signaling that patient access takes precedence over corporate greed.</p>



<p>Let’s end the price-gouging practices of outliers and build a health care system that puts patients first. Just as targeting criminal outliers fosters a law-abiding society, holding bad pharmaceutical actors accountable is crucial for restoring trust and integrity to our health care system. While broader approaches to making health care more fair, accessible, and affordable are needed, sometimes the way to save billions is to start by saving hundreds of millions.</p>



<p><em>David Maris is a six-time No. 1 ranked pharmaceutical analyst with more than two decades covering the industry. He currently runs </em><a href="https://phalanxinvpartners.com/" target="_blank" rel="noopener"><em>Phalanx Investment Partners</em></a><em>, a family office; is a partner in </em><a href="https://www.passes.com/wallstbeats" target="_blank" rel="noopener"><em>Wall Street Beats</em></a><em>; and is co-author of the recently published book “</em><a href="https://a.co/d/5Lj1bAa" target="_blank" rel="noopener"><em>The Fax Club Experiment</em></a><em>.” He is currently working on his next book about </em><em>health care in America.</em> <em></em></p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Leaving Intel (310 pts)]]></title>
            <link>https://www.brendangregg.com/blog//2025-12-05/leaving-intel.html</link>
            <guid>46167552</guid>
            <pubDate>Fri, 05 Dec 2025 21:27:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.brendangregg.com/blog//2025-12-05/leaving-intel.html">https://www.brendangregg.com/blog//2025-12-05/leaving-intel.html</a>, See on <a href="https://news.ycombinator.com/item?id=46167552">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p>I've resigned from Intel and accepted a new opportunity. If you are an Intel employee, you might have seen my fairly long email that summarized what I did in my 3.5 years. Much of this is public:</p>

<ul>
<li><a href="https://www.brendangregg.com/blog/2024-10-29/ai-flame-graphs.html">AI flame graphs</a> and released them as <a href="https://github.com/intel/iaprof">open source</a></li>
<li><a href="https://www.brendangregg.com/blog/2025-05-01/doom-gpu-flame-graphs.html">GPU subsecond-offset heatmap</a></li>
<li>Worked with Linux distros to enable <a href="https://www.brendangregg.com/blog/2024-03-17/the-return-of-the-frame-pointers.html">stack walking</a></li>
<li>Was interviewed by the WSJ about eBPF for <a href="https://www.wsj.com/articles/how-the-crowdstrike-tech-outage-reignited-a-battle-over-the-heart-of-microsoft-systems-72b62c90?utm_source=chatgpt.com">security monitoring</a></li>
<li>Provided leadership on the eBPF Technical Steering Committee (<a href="https://ebpf.foundation/bsc/">BSC</a>)</li>
<li>Co-chaired USENIX <a href="https://www.brendangregg.com/blog/2023-02-17/srecon-apac-2023.html">SREcon APAC 2023</a></li>
<li>Gave 6 conference keynotes</li>
</ul>

<p>It's still early days for AI flame graphs. Right now when I browse CPU performance case studies on the Internet, I'll often see a CPU flame graph as part of the analysis. We're a long way from that kind of adoption for GPUs (and it doesn't help that our open source version is Intel only), but I think as GPU code becomes more complex, with more layers, the need for AI flame graphs will keep increasing.</p>

<p>I also supported cloud computing, participating in 110 customer meetings, and created a company-wide strategy to win back the cloud with 33 specific recommendations, in collaboration with others across 6 organizations. It is some of my best work and features a visual map of interactions between all 19 relevant teams, described by Intel long-timers as the first time they have ever seen such a cross-company map. (This strategy, summarized in a slide deck, is internal only.)</p>

<p>I always wish I did more, in any job, but I'm glad to have contributed this much especially given the context: I overlapped with Intel's toughest 3 years in history, and I had a hiring freeze for my first 15 months.</p>

<p>My fond memories from Intel include 
meeting <a href="https://www.brendangregg.com/blog/images/2022/Brendan_Linus_Sep2022_01crop.jpg">Linus</a> at an Intel event who said "everyone is using <em>fleme</em> graphs these days" (Finnish accent),
meeting Pat Gelsinger who knew about my work and introduced me to everyone at an exec all hands,
surfing lessons at an Intel Australia and HP offsite (<a href="https://www.brendangregg.com/blog/images/2024/Intel_HP_Urbnsurf_2024.mp4">mp4</a>),
and meeting <a href="https://www.linkedin.com/posts/harshad-sane-56711a11_thrilled-to-meet-in-person-with-brendan-gregg-activity-6980768411198922753-Dw_k?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAA8VAMBqJml4viT3EVYGfzv-hLOE0rjdIE">Harshad Sane</a> (Intel cloud support engineer) who helped me when I was at Netflix and now has joined Netflix himself -- we've swapped ends of the meeting table. I also enjoyed meeting Intel's hardware fellows and senior fellows who were happy to help me understand processor internals. (Unrelated to Intel, but if you're a Who fan like me, I recently met some other <a href="https://www.brendangregg.com/blog/images/2025/brendan_mccoy.jpg">people</a> <a href="https://www.brendangregg.com/blog/images/2025/brendan_hines.jpg">as</a> <a href="https://www.brendangregg.com/blog/images/2025/brendan_ford.jpg">well</a>!)</p>

<p>My next few years at Intel would have focused on execution of those 33 recommendations, which Intel can continue to do in my absence. Most of my recommendations aren't easy, however, and require accepting change, ELT/CEO approval, and multiple quarters of investment. I won't be there to push them, but other employees can (my CloudTeams strategy is in the inbox of various ELT, and in a shared folder with all my presentations, code, and weekly status reports). This work will hopefully live on and keep making Intel stronger. Good luck.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Perpetual futures, explained (115 pts)]]></title>
            <link>https://www.bitsaboutmoney.com/archive/perpetual-futures-explained/</link>
            <guid>46167500</guid>
            <pubDate>Fri, 05 Dec 2025 21:23:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bitsaboutmoney.com/archive/perpetual-futures-explained/">https://www.bitsaboutmoney.com/archive/perpetual-futures-explained/</a>, See on <a href="https://news.ycombinator.com/item?id=46167500">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><em>Programming note</em>: <em>Bits about Money is </em><a href="https://www.bitsaboutmoney.com/memberships/" rel="noreferrer"><em>supported by our readers</em></a><em>. I generally forecast about one issue a month, and haven't kept that pace that this year. As a result, I'm working on about 3-4 for December.</em></p><p>Much financial innovation is in the ultimate service of the real economy. Then, we have our friends in crypto, who occasionally do intellectually interesting things which do not have a locus in the real economy. One of those things is perpetual futures (hereafter, perps), which I find fascinating and worthy of study, the same way that a virologist just loves geeking out about furin cleavage sites.</p><p>You may have read a lot about stablecoins recently. I may write about them (again; see <a href="https://www.bitsaboutmoney.com/archive/stablecoin-mechanisms-and-use-cases/">past BAM issue</a>) in the future, as there has in recent years been <a href="https://www.stablecoin.fyi/">some uptake</a> of them for payments. But it is useful to understand that a plurality of stablecoins collateralize perps. Some observers are occasionally <em>strategic </em>in whether they acknowledge this, but for payments use cases, it does not require a lot of stock to facilitate massive flows. And so of the <a href="https://defillama.com/stablecoins">$300 billion or so in stablecoins presently outstanding</a>, <a href="https://cryptoquant.com/asset/stablecoin/chart/exchange-flows/exchange-reserve?exchange=all_exchange&amp;window=DAY&amp;sma=0&amp;ema=0&amp;priceScale=log&amp;metricScale=linear&amp;chartStyle=line">about a quarter</a> sit on exchanges. The majority of that is collateralizing perp positions.</p><p>Perps are the dominant way crypto trades, in terms of volume. (It bounces around but is typically <a href="https://cryptoquant.com/insights/quicktake/691f2c39e69e12693d3aa0bf-Spot-vs-Derivative-Volume-Ratio-Are-Real-Buyers-Taking-Control">6-8 times larger than spot</a>.) This is similar to most traditional markets: where derivatives are available, derivative volume swamps spot volume. The degree to which depends on the market, Schelling points, user culture, and similar. For example, in India, most retail investing in equity is actually through derivatives; this is not true of the U.S. In the U.S., most retail equity exposure is through the spot market, directly holding stocks or indirectly through ETFs or mutual funds. Most <em>trading volume of the stock indexes</em>, however, is via derivatives.&nbsp;</p><h2 id="beginning-with-the-problem">Beginning with the problem</h2><p>The large crypto exchanges are primarily casinos, who use the crypto markets as a source of numbers, in the same way a traditional casino might use a roulette wheel or set of dice. The function of a casino is for a patron to enter it with money and, statistically speaking, exit it with less. Physical casinos are often huge capital investments with large ongoing costs, including the return on that speculative capital. If they could choose to be less capital intensive, they would do so, but they are partially constrained by market forces and partially by regulation.</p><p>A crypto exchange is also capital intensive, not because the website or API took much investment (relatively low, by the standards of financial software) and not because they have a physical plant, but because trust is expensive. Bettors, and the more sophisticated market makers, who are the primary source of action for bettors, need to trust that the casino will actually be able to pay out winnings. That means the casino needs to keep assets (generally, mostly crypto, but including a smattering of cash for those casinos which are anomalously well-regarded by the financial industry) on hand exceeding customer account balances.</p><p>Those assets are… sitting there, doing nothing productive. And there is an implicit cost of capital associated with them, whether nominal (and borne by a gambler) or material (and borne by a sophisticated market making firm, crypto exchange, or the crypto exchange’s affiliate which trades against customers [0]).</p><p>Perpetual futures exist to provide the risk gamblers seek while decreasing the total capital requirement (shared by the exchange and market makers) to profitably run the enterprise.</p><h2 id="perps-predate-crypto-but-found-a-home-there">Perps predate crypto but found a home there</h2><p>In the commodities futures markets, you can contract to either buy or sell some standardized, valuable thing at a defined time in the future. The overwhelming majority of contracts do not result in taking delivery; they’re cancelled by an offsetting contract before that specified date.</p><p>Given that speculation and hedging are such core use cases for futures, the financial industry introduced a refinement: cash-settled futures. Now there is a reference price for the valuable thing, with a great deal of intellectual effort put into making that reference price robust and fair (not always successfully). Instead of someone notionally taking physical delivery of pork bellies or barrels of oil, people who are net short the future pay people who are net long the future on delivery day. (The mechanisms of this clearing are fascinating but outside today’s scope.)</p><p>Back in the early nineties economist Robert Shiller <a href="https://ideas.repec.org/a/bla/jfinan/v48y1993i3p911-31.html">proposed a refinement</a> to cash settled futures: if you don’t actually want pork bellies or oil barrels for consumption in April, and we accept that almost no futures participants actually do, why bother closing out the contracts in April? Why fragment the liquidity for contracts between April, May, June, etc? Just keep the market going <em>perpetually</em>.</p><p>This achieved its first widespread popular use in crypto (Bitmex is generally credited as being the popularizer), and hereafter we’ll describe the standard crypto implementation. There are, of course, variations available.</p><h2 id="multiple-settlements-a-day">Multiple settlements a day</h2><p>Instead of all of a particular futures vintage settling on the same day, perps settle multiple times a day for a particular market on a particular exchange. The mechanism for this is the <em>funding rate</em>. At a high level: winners get paid by losers every e.g. 4 hours and then the game continues, unless you’ve been blown out due to becoming overleveraged or for other reasons (discussed in a moment).</p><p>Consider a toy example: a retail user buys 0.1 Bitcoin via a perp. The price on their screen, which they understand to be for Bitcoin, might be $86,000 each, and so they might pay $8,600 cash. Should the price rise to $90,000 before the next settlement, they will get +/- $400 of winnings credited to their account, and their account will continue to reflect exposure to 0.1 units of Bitcoin via the perp. They might choose to sell their future at this point (or any other). They’ll have paid one commission (and a spread) to buy, one (of each) to sell, and perhaps they’ll leave the casino with their winnings, or perhaps they’ll play another game.</p><p>Where did the money come from? Someone else was symmetrically short exposure to Bitcoin via a perp. It is, with some very important caveats incoming, a closed system: since no good or service is being produced except the speculation, winning money means someone else lost.</p><p>One fun wrinkle for funding rates: some exchanges cap the amount the rate can be for a single settlement period. This is similar in intent to traditional markets’ usage of <a href="https://www.nyse.com/publicdocs/nyse/NYSE_MWCB_FAQ.pdf">circuit breakers</a>: designed to automatically blunt out-of-control feedback loops. It is dissimilar in that it cannot actually break circuits: changes to funding rate can delay realization of losses but can’t prevent them, since they don’t prevent the realization of symmetrical gains.</p><p>Perp funding rates also embed an interest rate component. This might get quoted as 3 bps a day, or 1 bps every eight hours, or similar. However, because of the impact of leverage, gamblers are paying more than you might expect: at 10X leverage that’s 30 bps a day. Consumer finance legislation standardizes borrowing costs as APR rather than basis points per day so that an unscrupulous lender can’t bury a 200% APR in the fine print.</p><h2 id="convergence-in-prices-via-the-basis-trade">Convergence in prices via the basis trade</h2><p>Prices for perps do not, as a fact of nature, exactly match the underlying. That is a <em>feature</em> for some users.</p><p>In general, when the market is exuberant, the perp will trade above spot (the underlying market). To close the gap, a sophisticated market participant should do the <em>basis trade</em>: make offsetting trades in perps and spot (short the perp and buy spot, here, in equal size). Because the funding rate is set against a reference price for the underlying, longs will be paying shorts more (as a percentage of the perp’s current market price). For some of them, that’s fine: the price of gambling went up, oh well. For others, that’s a market incentive to close out the long position, which involves selling it, which will decrease the price at the margin (in the direction of spot).</p><p>The market maker can wait for price convergence; if it happens, they can close the trade at a profit, while having been paid to maintain the trade. If the perp continues to trade rich, they can just continue getting the increased funding cost. To the extent this is higher than <em>their own</em> cost of capital, this can be extremely lucrative.</p><p>Flip the polarities of these to understand the other direction.</p><p>The basis trade, classically executed, is delta neutral: one isn’t exposed to the underlying itself. You don’t need any belief in Bitcoin’s future adoption story, fundamentals, market sentiment, halvings, none of that. You’re getting paid to provide the gambling environment, including a really important feature: the perp price needs to stay <em>reasonably</em> close to the spot price, close enough to continue attracting people who want to gamble. You are also renting access to your capital for leverage.</p><p>You are also underwriting the exchange: if they blow up, your collateral becoming a claim against the bankruptcy estate is <em>the happy</em> scenario. (As one motivating example: Galois Capital, a crypto hedge fund doing basis trades, had ~40% of its assets on FTX when it went down. They then wound down the fund, selling the bankruptcy claim for <a href="https://www.ft.com/content/a06b77bc-52ac-4901-98d7-8c567449262e">16 cents on the dollar</a>.)</p><p>Recall that the market can’t function without a system of trust saying that someone is good for it if a bettor wins. Here, the market maker is good for it, via the collateral it kept on the exchange.</p><p>Many market makers function across many different crypto exchanges. This is one reason they’re so interested in capital efficiency: fully collateralizing all <em>potential</em> positions they could take across the universe of venues they trade on would be prohibitively capital intensive, and if they do not pre-deploy capital, they miss profitable trading opportunities. [1]</p><h2 id="leverage-and-liquidations">Leverage and liquidations</h2><p>Gamblers like risk; it amps up the fun. Since one has many casinos to choose from in crypto, the ones which only “regular” exposure to Bitcoin (via spot or perps) would be offering a less-fun product for many users than the ones which offer leverage. How much leverage? <em>More leverage</em> is always the answer to that question, until predictable consequences start happening.</p><p>In a standard U.S. brokerage account, <a href="https://www.ecfr.gov/current/title-12/chapter-II/subchapter-A/part-220?toc=1">Regulation T</a> has, for almost 100 years now, set maximum leverage limits (by setting minimums for margins). These are 2X at position opening time and 4X “maintenance” (before one closes out the position). Your brokerage would be obligated to forcibly close your position if volatility causes you to exceed those limits.</p><p>As a simplified example, if you have $50k of cash, you’d be allowed to buy $100k of stock. You now have $50k of equity and a $50k loan: 2x leverage. Should the value of that stock decline to about $67k, you still owe the $50k loan, and so only have $17k remaining equity. You’re now on the precipice of being 4X leveraged, and should expect a margin call very soon, if your broker hasn’t “blown you out of the trade” already.</p><p>What part of that is relevant to crypto? For the moment, just focus on that number: 4X.</p><p>Perps are offered at 1X (non-levered exposure). But they’re <a href="https://www.binance.com/en/square/post/24757521817370">routinely offered</a> at 20X, 50X, and 100X. SBF, during his press tour / regulatory blitz about being a responsible financial magnate fleecing the customers <em>in an orderly fashion</em>, voluntarily <a href="https://www.coindesk.com/markets/2021/07/25/ftx-cuts-leverage-limit-to-20x-from-100x-as-criticism-of-margin-trading-in-crypto-grows">self-limited FTX to 20X</a>.</p><p>One reason perps are structurally better for exchanges and market makers is that they simplify the business of blowing out leveraged traders. The exact mechanics depend on the exchange, the amount, etc, but generally speaking you can either force the customer to enter a closing trade or you can assign their position to someone willing to bear the risk in return for a discount.</p><p>Blowing out losing traders is lucrative for exchanges except when it catastrophically isn’t. It is a priced service in many places. The price is quoted to be low (<a href="https://www.binance.com/en/square/post/26755786144026">“a nominal fee of 0.5%</a>” is one way Binance describes it) but, since it is calculated from the amount at risk, it can be a large portion of the money lost. If the account’s negative balance is less than the liquidation fee, wonderful, thanks for playing and the exchange / “the insurance fund” keeps the rest, as a tip.</p><p>In the case where the amount an account is negative by is more than the fee, that “insurance fund” can choose to pay the winners on behalf of the liquidated user, at management’s discretion. Management will <em>usually</em> decide to do this, because a casino with a reputation for not paying winners will not long remain a casino.</p><p>But tail risk is a real thing. The capital efficiency <em>has a price</em>: there physically does not exist enough money in the system to pay all winners given sufficiently dramatic price moves. Forced liquidations happen. Sophisticated participants withdraw liquidity (for reasons we’ll soon discuss) or the exchange becomes overwhelmed technically / operationally. The forced liquidations eat through the diminished / unreplenished liquidity in the book, and the magnitude of the move increases.</p><p>Then crypto <a href="https://unchainedcrypto.com/the-chopping-block-inside-the-19b-perp-crash-adl-explained-binances-usde-staked-token-depeg-and-the-hyperliquid-whale-debate/">gets reminded</a> about automatic deleveraging (ADL), a detail to perp contracts that few participants understand.</p><h2 id="we-have-altered-the-terms-of-your-unregulated-futures-investment-contract">We have altered the terms of your unregulated futures investment contract.</h2><p>(<a href="https://www.youtube.com/watch?v=3D8TEJtQRhw">Pray we do not alter them further.</a>)</p><p>Risk in perps has to be symmetric: if (accounting for leverage) there are 100,000 units of Somecoin exposure long, then there are 100,000 units of Somecoin exposure short. This does not imply that the shorts or longs are sufficiently capitalized to <em>actually pay</em> for all the exposure in all instances.</p><p>In cases where management deems paying winners from the insurance fund would be too costly and/or impossible, they automatically deleverage some winners. In theory, there is a published process for doing this, because it would be confidence-costing to ADL non-affiliated accounts but pay out affiliated accounts, one’s friends or particularly important counterparties, etc. In theory.</p><p>In theory, one likely ADLs accounts which were quite levered before ones which were less levered, and one ADLs accounts which had high profits before ones with lower profits. In theory. [2]</p><p>So perhaps you understood, prior to a 20% move, that you were 4X leveraged. You just earned 80%, right? Ah, except you were only 2X leveraged, so you earned 40%. Why were you <em>retroactively</em> only 2X? That’s what automatic deleveraging means. Why couldn’t you get the other 40% you feel entitled to? Because the collective group of losers doesn’t have enough to pay you your winnings and the insurance fund was insufficient or deemed insufficient by management.</p><p>ADL is particularly painful for sophisticated market participants doing e.g. a basis trade, because they thought e.g. they were 100 units short via perps and 100 units long <em>somewhere else</em> via spot. If it turns out they were actually 50 units short via perps, but 100 units long, their net exposure is +50 units, and they have very possibly just gotten absolutely shellacked.</p><p>In theory, this can happen to the upside or the downside. <em>In practice</em> in crypto, this seems to usually happen after sharp decreases in prices, not sharp increases. For example, October 2025 saw widespread ADLing as (more than) <a href="https://www.bloomberg.com/news/articles/2025-11-22/crypto-s-brutal-month-triggers-a-stress-test-for-wall-street">$19 billion of liquidations</a> happened, across a variety of assets. Alameda’s CEO Caroline Ellison <a href="https://www.wsj.com/livecoverage/sam-bankman-fried-trial-ftx-caroline-ellison/card/alameda-research-lost-100-million-on-terrausd-uhsJkMxHAu4TU4PJV9Kd?gaa_at=eafs&amp;gaa_n=AWEtsqcUTBS1ClKudIOSulhPczCueQrmHacrKc48MbNkyWvrvttdiJEOV6gGYvaIfpg%3D&amp;gaa_ts=692e37a5&amp;gaa_sig=OrKMG6Tx7IV1mr9NebTACUXOFFABpI3lO-JBghpvChgBNyGFFAN1xPsB-zf6tnqA0JoIWdfvQPbD7ne_aFDiVQ%3D%3D">testified</a> that they lost over $100 million during the collapse of Terra’s stablecoin in 2022, but since FTX’s insurance fund <a href="https://www.theblock.co/post/255352/ftx-used-random-numbers-to-generate-the-size-of-its-insurance-fund">was made up</a>; when leveraged traders lost money, their positions were frequently taken up by Alameda. That was quite lucrative much of the time, but catastrophically expensive during e.g. the Terra blowup. Alameda was a good loser and paid the winners, though: with other customers’ assets that they “borrowed.”</p><h2 id="an-aside-about-liquidations">An aside about liquidations</h2><p>In the traditional markets, if one’s brokerage deems one’s assets are unlikely to be able to cover the margin loan from the brokerage one has used, one’s brokerage will issue a margin call. Historically that gave one a relatively short period (typically, a few days) to post additional collateral, either by moving in cash, by transferring assets from another brokerage, or by experiencing appreciation in the value of one’s assets. Brokerages have the option, and in some cases the requirement, to manage risk after or during a margin call by forcing trades on behalf of the customer to close positions.</p><p>It sometimes surprises crypto natives that, in the case where one’s brokerage account goes negative and all assets are sold, with a negative remaining balance, the traditional markets largely <em>still expect you to pay that balance</em>. This contrasts with crypto, where the market expectation for many years was that the customer was Daffy Duck with a gmail address and a pseudonymous set of numbered accounts recorded on a blockchain, and dunning them was a waste of time. Crypto exchanges have mostly, in the intervening years, either stepped up their game regarding <a href="https://www.bitsaboutmoney.com/archive/kyc-and-aml-beyond-the-acronyms/">KYC</a> or pretended to do so, but the market expectation is still that a defaulting user will basically never successfully recover. (Note that the legal obligation to pay is not coextensive with users actually paying. The retail speculators with $25,000 of capital that the pattern day trade rules are worried about will often not have $5,000 to cover a deficiency. On the other end of the scale, when a hedge fund blows up, the fund entity is wiped out, but its limited partners—pension funds, endowments, family offices—are not on the hook to the prime broker, and nobody expects the general partner to start selling their house to make up the difference.)&nbsp;</p><p>So who bears the loss when the customer doesn’t, can’t, or won’t? The waterfall depends on market, product type, and geography, but as a sketch: brokerages bear the loss first, out of their own capital. They’re generally required to keep a reserve for this purpose.&nbsp;</p><p>A brokerage will, in the ordinary course of business, have obligations to other parties which would be endangered if they were catastrophically mismanaged and could not successfully manage risk during a downturn. (It’s been known to happen, and even can be associated with <a href="https://www.nytimes.com/2007/11/30/business/30citadel.html">assets rather than liabilities</a>.) In this case, most of those counterparties are partially insulated by structures designed to insure the peer group. These include e.g. clearing pools, guaranty funds capitalized by the member firms of a clearinghouse, the clearinghouse’s own capital, and perhaps mutualized insurance pools. That is the rough ordering of the waterfall, which varies depending geography/product/market.</p><p>One can imagine a true catastrophe which burns through each of those layers of protection, and in that case, the clearinghouse might be forced to assess members or allocate losses across survivors. That would be a very, very bad day, but contracts exist to be followed on very bad days.</p><p>One commonality with crypto, though: this system is also not fully capitalized against all possible events at all times. Unlike crypto, which for contingent reasons pays some lip service to being averse to credit even as it embraces leveraged trading, the traditional industry relies <em>extensively</em> on underwriting risk of various participants.</p><h2 id="will-crypto-successfully-%E2%80%9Cexport%E2%80%9D-perps">Will crypto successfully “export” perps?</h2><p>Many crypto advocates believe that they have something which the traditional finance industry desperately needs. Perps are crypto’s most popular and lucrative product, but they probably won’t be adopted materially in traditional markets.</p><p>Existing derivatives products already work reasonably well at solving the cost of capital issue. Liquidations are not the business model of traditional brokerages. And learning, on a day when markets are 20% down, that you might be hedged or you might be bankrupt, is not a prospect which fills traditional finance professionals with the warm fuzzies.</p><p>And now you understand the crypto markets a bit better.</p><p>[0] Brokers trading with their own customers can happen in the ordinary course of business, but has been progressively discouraged in traditional finance, as it enables frontrunning.&nbsp;</p><p>Frontrunning, while it is understood in the popular parlance to mean “trading before someone else can trade” and often brought up in discussions of high frequency trading using very fast computers, does not historically mean that. It historically describes a single abusive practice: a broker could basically use <em>the slowness</em> of traditional financial IT systems to give conditional post-facto treatment to customer orders, taking the other side of them (if profitable) or not (if not). Frontrunning basically disappeared because customers now get order confirms almost instantly by computer not at end of day via a phone call. The confirm has the price the trade executed at on it.&nbsp;</p><p>In classic frontrunning, you sent the customer’s order to the market (at some price X), waited a bit, and then observed a later price Y. If Y was worse for the customer than X, well, them’s the breaks on Wall Street. If Y was better, you congratulated the customer on their investing acumen, and informed them that they had successfully transacted at Z, a price of your choosing between X and Y. You then fraudulently inserted a recorded transaction between the customer and yourself earlier in the day, at price Z, and assigned the transaction which happened at X to your own account, not to the customer’s account.</p><p>Frontrunning was a lucrative scam while it lasted, because (effectively) the customer takes 100% of the risk of the trade but the broker gets any percentage they want of the first day’s profits. This is potentially <em>so</em> lucrative that smart money (and some investors in his funds!) thought Madoff was doing it, thus generating the better-than-market stable returns for over a decade through malfeasance. Of frontrunning Madoff was entirely innocent.</p><p>Some more principled crypto participants have attempted to discourage exchanges from trading with their own customers. They have mostly been unsuccessful: Merit Peak Limited is Binance’s captive entity which does this. It also is occasionally described by U.S. federal agencies as running a sideline in money laundering, Alameda Research was FTX’s affiliated trading fund. Their management was criminally convicted of money laundering. etc, etc.</p><p>One of the reasons this behavior is so adaptive is because the billions of dollars sloshing around can be described to banks as “proprietary trading” and “running an OTC desk”, and an inattentive bank (like, say, Silvergate, as <a href="https://www.bitsaboutmoney.com/archive/debanking-and-debunking/">recounted here</a>) might miss the customer fund flows they would have been formally unwilling to facilitate. This is a useful feature for sophisticated crypto participants, and so some of them do not draw attention to the elephant in the room, even though it is averse to their interests.</p><p>[1] Not <em>all</em> crypto trades are pre-funded. Crypto OTC transactions sometimes settle on T+1, with the OTC desk essentially extending credit in the fashion that a prime broker would in traditional markets. But most transactions on exchanges have to be paid immediately in cash already at the venue. This is very different from traditional equity market structure, where venues don’t typically receive funds flow at all, and settling/clearing happens after the fact, generally by a day or two.</p><p>[2] I note, for the benefit of readers of footnote 0, that there is often a substantial gap between the time when market dislocation happens and when a trader is informed they were ADLed. The implications of this are left as an exercise to the reader.</p>

        

        <div>
          <h2>Want more essays in your inbox?</h2>
          <p>I write about the intersection of tech and finance, approximately biweekly. It's free.</p>
                  </div>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The missing standard library for multithreading in JavaScript (121 pts)]]></title>
            <link>https://github.com/W4G1/multithreading</link>
            <guid>46167349</guid>
            <pubDate>Fri, 05 Dec 2025 21:09:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/W4G1/multithreading">https://github.com/W4G1/multithreading</a>, See on <a href="https://news.ycombinator.com/item?id=46167349">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
  <p><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/38042257/523092640-e7750ae6-3acd-4c81-9417-3979f51535f3.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjUwMjgxMDIsIm5iZiI6MTc2NTAyNzgwMiwicGF0aCI6Ii8zODA0MjI1Ny81MjMwOTI2NDAtZTc3NTBhZTYtM2FjZC00YzgxLTk0MTctMzk3OWY1MTUzNWYzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMDYlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjA2VDEzMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWI0MzJhNmRlYjNjZGU1ZTljZTllZGU4OTcwNjk1YzkyMzQwYzVmZmYyYmZlMmYzZGRiY2Q2MjJjMjU4MGI4MTcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.DHgHFSJx_9Gw9XhtiiGubAdkFlmR3iKeU7IIVB9IVbk"><img width="150" height="128" alt="Logo" src="https://private-user-images.githubusercontent.com/38042257/523092640-e7750ae6-3acd-4c81-9417-3979f51535f3.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjUwMjgxMDIsIm5iZiI6MTc2NTAyNzgwMiwicGF0aCI6Ii8zODA0MjI1Ny81MjMwOTI2NDAtZTc3NTBhZTYtM2FjZC00YzgxLTk0MTctMzk3OWY1MTUzNWYzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEyMDYlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMjA2VDEzMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWI0MzJhNmRlYjNjZGU1ZTljZTllZGU4OTcwNjk1YzkyMzQwYzVmZmYyYmZlMmYzZGRiY2Q2MjJjMjU4MGI4MTcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.DHgHFSJx_9Gw9XhtiiGubAdkFlmR3iKeU7IIVB9IVbk"></a></p><p dir="auto"><h2 tabindex="-1" dir="auto">Multithreading.js</h2><a id="user-content-multithreadingjs" aria-label="Permalink: Multithreading.js" href="#multithreadingjs"></a></p>
  <p dir="auto">
    <strong>Robust, Rust-inspired concurrency primitives for the JavaScript ecosystem.</strong>
  </p>
<p dir="auto"><a href="https://github.com/W4G1/multithreading/blob/main/LICENSE.md"><img src="https://camo.githubusercontent.com/0f2f1b81c52c18193dbc43123d819500b85c952273a3d1d6f265f93ae524c71d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f573447312f6d756c7469746872656164696e67" alt="License" data-canonical-src="https://img.shields.io/github/license/W4G1/multithreading"></a>
<a href="https://www.npmjs.com/package/multithreading" rel="nofollow"><img src="https://camo.githubusercontent.com/1e90de1d47248ab4c4255dac578c47550be035ea1fda1977bc961ed940cac7ce/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f64772f6d756c7469746872656164696e673f636f6c6f723d253233383935364646" alt="Downloads" data-canonical-src="https://img.shields.io/npm/dw/multithreading?color=%238956FF"></a>
<a href="https://www.npmjs.com/package/multithreading?activeTab=versions" rel="nofollow"><img src="https://camo.githubusercontent.com/5561e74e1364b345569ca1eb2f6324ee368a05911ae2a603484a27d2ddf837a5/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f6d756c7469746872656164696e67" alt="NPM version" data-canonical-src="https://img.shields.io/npm/v/multithreading"></a>
<a href="https://github.com/W4G1/multithreading"><img src="https://camo.githubusercontent.com/6250c9873c1acbf5b0d4e369a59f70a8f4c543227b141845cadfa7d9fbf11893/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f573447312f6d756c7469746872656164696e673f6c6f676f3d676974687562266c6162656c3d53746172266c6162656c436f6c6f723d726762283236253243253230333025324325323033352926636f6c6f723d7267622831332532432532303137253243253230323329" alt="GitHub Repo stars" data-canonical-src="https://img.shields.io/github/stars/W4G1/multithreading?logo=github&amp;label=Star&amp;labelColor=rgb(26%2C%2030%2C%2035)&amp;color=rgb(13%2C%2017%2C%2023)"></a></p>
</div>

<p dir="auto"><strong>Multithreading</strong> is a TypeScript library that brings robust, Rust-inspired concurrency primitives to the JavaScript ecosystem. It provides a thread-pool architecture, strict memory safety semantics, and synchronization primitives like Mutexes, Read-Write Locks, and Condition Variables.</p>
<p dir="auto">This library is designed to abstract away the complexity of managing <code>WebWorkers</code>, serialization, and <code>SharedArrayBuffer</code> complexities, allowing developers to write multi-threaded code that looks and feels like standard asynchronous JavaScript.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install multithreading"><pre>npm install multithreading</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Core Concepts</h2><a id="user-content-core-concepts" aria-label="Permalink: Core Concepts" href="#core-concepts"></a></p>
<p dir="auto">JavaScript is traditionally single-threaded. To achieve true parallelism, this library uses Web Workers. However, unlike standard Workers, this library offers:</p>
<ol dir="auto">
<li><strong>Managed Worker Pool</strong>: Automatically manages a pool of threads based on hardware concurrency.</li>
<li><strong>Shared Memory Primitives</strong>: Tools to safely share state between threads without race conditions.</li>
<li><strong>Scoped Imports</strong>: Support for importing external modules and relative files directly within worker tasks.</li>
<li><strong>Move Semantics</strong>: Explicit data ownership transfer to prevent cloning overhead.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto">The entry point for most operations is the <code>spawn</code> function. This submits a task to the thread pool and returns a handle to await the result.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { spawn } from &quot;multithreading&quot;;

// Spawn a task on a background thread
const handle = spawn(() => {
  // This code runs in a separate worker
  const result = Math.random();
  return result;
});

// Wait for the result
const result = await handle.join();

if (result.ok) {
  console.log(&quot;Result:&quot;, result.value); // 0.6378467071314606
} else {
  console.error(&quot;Worker error:&quot;, result.error);
}"><pre><span>import</span> <span>{</span> <span>spawn</span> <span>}</span> <span>from</span> <span>"multithreading"</span><span>;</span>

<span>// Spawn a task on a background thread</span>
<span>const</span> <span>handle</span> <span>=</span> <span>spawn</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>// This code runs in a separate worker</span>
  <span>const</span> <span>result</span> <span>=</span> <span>Math</span><span>.</span><span>random</span><span>(</span><span>)</span><span>;</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span><span>)</span><span>;</span>

<span>// Wait for the result</span>
<span>const</span> <span>result</span> <span>=</span> <span>await</span> <span>handle</span><span>.</span><span>join</span><span>(</span><span>)</span><span>;</span>

<span>if</span> <span>(</span><span>result</span><span>.</span><span>ok</span><span>)</span> <span>{</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>"Result:"</span><span>,</span> <span>result</span><span>.</span><span>value</span><span>)</span><span>;</span> <span>// 0.6378467071314606</span>
<span>}</span> <span>else</span> <span>{</span>
  <span>console</span><span>.</span><span>error</span><span>(</span><span>"Worker error:"</span><span>,</span> <span>result</span><span>.</span><span>error</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Passing Data: The <code>move()</code> Function</h2><a id="user-content-passing-data-the-move-function" aria-label="Permalink: Passing Data: The move() Function" href="#passing-data-the-move-function"></a></p>
<p dir="auto">Because Web Workers run in a completely isolated context, functions passed to <code>spawn</code> cannot capture variables from their outer scope. If you attempt to use a variable inside the worker that was defined outside of it, the code will fail.</p>
<p dir="auto">To get data from your main thread into the worker, you have to use the <code>move()</code> function.</p>
<p dir="auto">The <code>move</code> function accepts a variable number of arguments. These arguments are passed to the worker function in the order they were provided. Despite the name, <code>move</code> handles data in two ways:</p>
<ol dir="auto">
<li><strong>Transferable Objects (e.g., <code>ArrayBuffer</code>, <code>Uint32Array</code>):</strong> These are "moved" (zero-copy). Ownership transfers to the worker, and the original becomes unusable in the main thread.</li>
<li><strong>Non-Transferable Objects (e.g., JSON, numbers, strings):</strong> These are cloned via structured cloning. They remain usable in the main thread.</li>
</ol>

<div dir="auto" data-snippet-clipboard-copy-content="import { spawn, move } from &quot;multithreading&quot;;

// Will be transfered
const largeData = new Uint8Array(1024 * 1024 * 10); // 10MB
// Will be cloned
const metaData = { id: 1 };

const handle = spawn(move(largeData, metaData), (data, meta) => {
  console.log(&quot;Processing ID:&quot;, meta.id);
  return data.byteLength;
});

await handle.join();"><pre><span>import</span> <span>{</span> <span>spawn</span><span>,</span> <span>move</span> <span>}</span> <span>from</span> <span>"multithreading"</span><span>;</span>

<span>// Will be transfered</span>
<span>const</span> <span>largeData</span> <span>=</span> <span>new</span> <span>Uint8Array</span><span>(</span><span>1024</span> <span>*</span> <span>1024</span> <span>*</span> <span>10</span><span>)</span><span>;</span> <span>// 10MB</span>
<span>// Will be cloned</span>
<span>const</span> <span>metaData</span> <span>=</span> <span>{</span> <span>id</span>: <span>1</span> <span>}</span><span>;</span>

<span>const</span> <span>handle</span> <span>=</span> <span>spawn</span><span>(</span><span>move</span><span>(</span><span>largeData</span><span>,</span> <span>metaData</span><span>)</span><span>,</span> <span>(</span><span>data</span><span>,</span> <span>meta</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>"Processing ID:"</span><span>,</span> <span>meta</span><span>.</span><span>id</span><span>)</span><span>;</span>
  <span>return</span> <span>data</span><span>.</span><span>byteLength</span><span>;</span>
<span>}</span><span>)</span><span>;</span>

<span>await</span> <span>handle</span><span>.</span><span>join</span><span>(</span><span>)</span><span>;</span></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">SharedJsonBuffer: Complex Objects in Shared Memory</h2><a id="user-content-sharedjsonbuffer-complex-objects-in-shared-memory" aria-label="Permalink: SharedJsonBuffer: Complex Objects in Shared Memory" href="#sharedjsonbuffer-complex-objects-in-shared-memory"></a></p>
<p dir="auto"><code>SharedJsonBuffer</code> enables Mutex-protected shared memory for JSON objects, eliminating the overhead of <code>postMessage</code> data copying. It supports partial updates by utilizing <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy" rel="nofollow">Proxies</a> under the hood, reserializing only changed bytes rather than the entire object tree for high-performance state synchronization, especially with large JSON objects.</p>
<p dir="auto"><strong>Note:</strong> Initializing a <code>SharedJsonBuffer</code> has a performance cost. For single-use transfers, <code>SharedJsonBuffer</code> is slower than cloning. This data structure is optimized for large persistent shared state or objects that need to be passed around frequently between threads without repeated copying.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { spawn, move, Mutex, SharedJsonBuffer } from &quot;multithreading&quot;;

const sharedState = new Mutex(new SharedJsonBuffer({
  score: 0,
  players: [&quot;Main Thread&quot;],
  level: {
    id: 1,
    title: &quot;Start&quot;,
  },
}));

await spawn(move(sharedState), async (lock) => {
  using guard = await lock.acquire();

  const state = guard.value;

  console.log(`Current Score: ${state.score}`);

  // Modify the data
  state.score += 100;
  state.players.push(&quot;Worker1&quot;);

  // End of scope: Lock is automatically released here
}).join();

// Verify on main thread
using guard = await sharedState.acquire();

console.log(guard.value); // { score: 100, players: [&quot;Main Thread&quot;, &quot;Worker1&quot;], ... }"><pre><span>import</span> <span>{</span> <span>spawn</span><span>,</span> <span>move</span><span>,</span> <span>Mutex</span><span>,</span> <span>SharedJsonBuffer</span> <span>}</span> <span>from</span> <span>"multithreading"</span><span>;</span>

<span>const</span> <span>sharedState</span> <span>=</span> <span>new</span> <span>Mutex</span><span>(</span><span>new</span> <span>SharedJsonBuffer</span><span>(</span><span>{</span>
  <span>score</span>: <span>0</span><span>,</span>
  <span>players</span>: <span>[</span><span>"Main Thread"</span><span>]</span><span>,</span>
  <span>level</span>: <span>{</span>
    <span>id</span>: <span>1</span><span>,</span>
    <span>title</span>: <span>"Start"</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span><span>)</span><span>;</span>

<span>await</span> <span>spawn</span><span>(</span><span>move</span><span>(</span><span>sharedState</span><span>)</span><span>,</span> <span>async</span> <span>(</span><span>lock</span><span>)</span> <span>=&gt;</span> <span>{</span>
  using <span>guard</span> <span>=</span> <span>await</span> <span>lock</span><span>.</span><span>acquire</span><span>(</span><span>)</span><span>;</span>

  <span>const</span> <span>state</span> <span>=</span> <span>guard</span><span>.</span><span>value</span><span>;</span>

  <span>console</span><span>.</span><span>log</span><span>(</span><span>`Current Score: <span><span>${</span><span>state</span><span>.</span><span>score</span><span>}</span></span>`</span><span>)</span><span>;</span>

  <span>// Modify the data</span>
  <span>state</span><span>.</span><span>score</span> <span>+=</span> <span>100</span><span>;</span>
  <span>state</span><span>.</span><span>players</span><span>.</span><span>push</span><span>(</span><span>"Worker1"</span><span>)</span><span>;</span>

  <span>// End of scope: Lock is automatically released here</span>
<span>}</span><span>)</span><span>.</span><span>join</span><span>(</span><span>)</span><span>;</span>

<span>// Verify on main thread</span>
using <span>guard</span> <span>=</span> <span>await</span> <span>sharedState</span><span>.</span><span>acquire</span><span>(</span><span>)</span><span>;</span>

<span>console</span><span>.</span><span>log</span><span>(</span><span>guard</span><span>.</span><span>value</span><span>)</span><span>;</span> <span>// { score: 100, players: ["Main Thread", "Worker1"], ... }</span></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Synchronization Primitives</h2><a id="user-content-synchronization-primitives" aria-label="Permalink: Synchronization Primitives" href="#synchronization-primitives"></a></p>
<p dir="auto">When multiple threads access shared memory (via <code>SharedArrayBuffer</code>), race conditions occur. This library provides primitives to synchronize access safely.</p>
<p dir="auto"><strong>Best Practice:</strong> It is highly recommended to use the asynchronous methods (e.g., <code>acquire</code>, <code>read</code>, <code>write</code>, <code>wait</code>) rather than their synchronous counterparts. Synchronous blocking halts the entire Worker thread, potentially pausing other tasks sharing that worker.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">1. Mutex (Mutual Exclusion)</h3><a id="user-content-1-mutex-mutual-exclusion" aria-label="Permalink: 1. Mutex (Mutual Exclusion)" href="#1-mutex-mutual-exclusion"></a></p>
<p dir="auto">A <code>Mutex</code> ensures that only one thread can access a specific piece of data at a time.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Option A: Automatic Management (Recommended)</h4><a id="user-content-option-a-automatic-management-recommended" aria-label="Permalink: Option A: Automatic Management (Recommended)" href="#option-a-automatic-management-recommended"></a></p>
<p dir="auto">This library leverages the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/using" rel="nofollow">Explicit Resource Management</a> proposal (<code>using</code> keyword). When you acquire a lock, it returns a guard. When that guard goes out of scope, the lock is automatically released.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { spawn, move, Mutex } from &quot;multithreading&quot;;

const buffer = new SharedArrayBuffer(4);
const counterMutex = new Mutex(new Int32Array(buffer));

spawn(move(counterMutex), async (mutex) => {
  // 'using' automatically calls dispose() at the end of the scope
  using guard = await mutex.acquire();
  
  guard.value[0]++;
  
  // End of scope: Lock is automatically released here
});"><pre><span>import</span> <span>{</span> <span>spawn</span><span>,</span> <span>move</span><span>,</span> <span>Mutex</span> <span>}</span> <span>from</span> <span>"multithreading"</span><span>;</span>

<span>const</span> <span>buffer</span> <span>=</span> <span>new</span> <span>SharedArrayBuffer</span><span>(</span><span>4</span><span>)</span><span>;</span>
<span>const</span> <span>counterMutex</span> <span>=</span> <span>new</span> <span>Mutex</span><span>(</span><span>new</span> <span>Int32Array</span><span>(</span><span>buffer</span><span>)</span><span>)</span><span>;</span>

<span>spawn</span><span>(</span><span>move</span><span>(</span><span>counterMutex</span><span>)</span><span>,</span> <span>async</span> <span>(</span><span>mutex</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>// 'using' automatically calls dispose() at the end of the scope</span>
  using <span>guard</span> <span>=</span> <span>await</span> <span>mutex</span><span>.</span><span>acquire</span><span>(</span><span>)</span><span>;</span>
  
  <span>guard</span><span>.</span><span>value</span><span>[</span><span>0</span><span>]</span><span>++</span><span>;</span>
  
  <span>// End of scope: Lock is automatically released here</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Option B: Manual Management (Bun / Standard JS)</h4><a id="user-content-option-b-manual-management-bun--standard-js" aria-label="Permalink: Option B: Manual Management (Bun / Standard JS)" href="#option-b-manual-management-bun--standard-js"></a></p>
<p dir="auto">If you are using <strong>Bun</strong> or prefer standard JavaScript syntax, you must manually release the lock using <code>drop()</code>.</p>
<p dir="auto"><strong>Note on Bun:</strong> While Bun is supported, it's runtime automatically polyfills the <code>using</code> keyword whenever a function is stringified. This transpiled code relies on specific internal globals made available in the context where the function is serialized. Because the worker runs in a different isolated context where these globals are not registered, code with <code>using</code> will fail to execute.</p>
<p dir="auto">Always use a <code>try...finally</code> block to ensure the lock is released even if an error occurs.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { spawn, move, Mutex } from &quot;multithreading&quot;;

const counterMutex = new Mutex(new Int32Array(new SharedArrayBuffer(4)));

spawn(move(counterMutex), async (mutex) => {
  // Note that we have to import drop here, otherwise it wouldn't be available
  const { drop } = await import(&quot;multithreading&quot;);

  // 1. Acquire the lock manually
  const guard = await mutex.acquire();

  try {
    // 2. Critical Section
    guard.value[0]++;
  } finally {
    // 3. Explicitly release the lock
    drop(guard);
  }
});"><pre><span>import</span> <span>{</span> <span>spawn</span><span>,</span> <span>move</span><span>,</span> <span>Mutex</span> <span>}</span> <span>from</span> <span>"multithreading"</span><span>;</span>

<span>const</span> <span>counterMutex</span> <span>=</span> <span>new</span> <span>Mutex</span><span>(</span><span>new</span> <span>Int32Array</span><span>(</span><span>new</span> <span>SharedArrayBuffer</span><span>(</span><span>4</span><span>)</span><span>)</span><span>)</span><span>;</span>

<span>spawn</span><span>(</span><span>move</span><span>(</span><span>counterMutex</span><span>)</span><span>,</span> <span>async</span> <span>(</span><span>mutex</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>// Note that we have to import drop here, otherwise it wouldn't be available</span>
  <span>const</span> <span>{</span> drop <span>}</span> <span>=</span> <span>await</span> <span>import</span><span>(</span><span>"multithreading"</span><span>)</span><span>;</span>

  <span>// 1. Acquire the lock manually</span>
  <span>const</span> <span>guard</span> <span>=</span> <span>await</span> <span>mutex</span><span>.</span><span>acquire</span><span>(</span><span>)</span><span>;</span>

  <span>try</span> <span>{</span>
    <span>// 2. Critical Section</span>
    <span>guard</span><span>.</span><span>value</span><span>[</span><span>0</span><span>]</span><span>++</span><span>;</span>
  <span>}</span> <span>finally</span> <span>{</span>
    <span>// 3. Explicitly release the lock</span>
    <span>drop</span><span>(</span><span>guard</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">2. RwLock (Read-Write Lock)</h3><a id="user-content-2-rwlock-read-write-lock" aria-label="Permalink: 2. RwLock (Read-Write Lock)" href="#2-rwlock-read-write-lock"></a></p>
<p dir="auto">A <code>RwLock</code> is optimized for scenarios where data is read often but written rarely. It allows <strong>multiple</strong> simultaneous readers but only <strong>one</strong> writer.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { spawn, move, RwLock } from &quot;multithreading&quot;;

const lock = new RwLock(new Int32Array(new SharedArrayBuffer(4)));

// Spawning a Writer
spawn(move(lock), async (l) => {
  // Blocks until all readers are finished (asynchronously)
  using guard = await l.write(); 
  guard.value[0] = 42;
});

// Spawning Readers
spawn(move(lock), async (l) => {
  // Multiple threads can hold this lock simultaneously
  using guard = await l.read(); 
  console.log(guard.value[0]);
});"><pre><span>import</span> <span>{</span> <span>spawn</span><span>,</span> <span>move</span><span>,</span> <span>RwLock</span> <span>}</span> <span>from</span> <span>"multithreading"</span><span>;</span>

<span>const</span> <span>lock</span> <span>=</span> <span>new</span> <span>RwLock</span><span>(</span><span>new</span> <span>Int32Array</span><span>(</span><span>new</span> <span>SharedArrayBuffer</span><span>(</span><span>4</span><span>)</span><span>)</span><span>)</span><span>;</span>

<span>// Spawning a Writer</span>
<span>spawn</span><span>(</span><span>move</span><span>(</span><span>lock</span><span>)</span><span>,</span> <span>async</span> <span>(</span><span>l</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>// Blocks until all readers are finished (asynchronously)</span>
  using <span>guard</span> <span>=</span> <span>await</span> <span>l</span><span>.</span><span>write</span><span>(</span><span>)</span><span>;</span> 
  <span>guard</span><span>.</span><span>value</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>42</span><span>;</span>
<span>}</span><span>)</span><span>;</span>

<span>// Spawning Readers</span>
<span>spawn</span><span>(</span><span>move</span><span>(</span><span>lock</span><span>)</span><span>,</span> <span>async</span> <span>(</span><span>l</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>// Multiple threads can hold this lock simultaneously</span>
  using <span>guard</span> <span>=</span> <span>await</span> <span>l</span><span>.</span><span>read</span><span>(</span><span>)</span><span>;</span> 
  <span>console</span><span>.</span><span>log</span><span>(</span><span>guard</span><span>.</span><span>value</span><span>[</span><span>0</span><span>]</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">3. Semaphore</h3><a id="user-content-3-semaphore" aria-label="Permalink: 3. Semaphore" href="#3-semaphore"></a></p>
<p dir="auto">A <code>Semaphore</code> limits the number of threads that can access a resource simultaneously. Unlike a Mutex (which allows exactly 1 owner), a Semaphore allows <code>N</code> owners. This is essential for rate limiting, managing connection pools, or bounding concurrency.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { spawn, move, Semaphore } from &quot;multithreading&quot;;

// Initialize with 3 permits (allowing 3 concurrent tasks)
const semaphore = new Semaphore(3);

for (let i = 0; i < 10; i++) {
  spawn(move(semaphore), async (sem) => {
    console.log(&quot;Waiting for slot...&quot;);
    
    // Will wait (async) if 3 threads are already working
    using _ = await sem.acquire(); 
    
    console.log(&quot;Acquired slot! Working...&quot;);

    await new Promise(r => setTimeout(r, 1000));
    
    // Guard is disposed automatically, releasing the permit for the next thread
  });
}"><pre><span>import</span> <span>{</span> <span>spawn</span><span>,</span> <span>move</span><span>,</span> <span>Semaphore</span> <span>}</span> <span>from</span> <span>"multithreading"</span><span>;</span>

<span>// Initialize with 3 permits (allowing 3 concurrent tasks)</span>
<span>const</span> <span>semaphore</span> <span>=</span> <span>new</span> <span>Semaphore</span><span>(</span><span>3</span><span>)</span><span>;</span>

<span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>10</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
  <span>spawn</span><span>(</span><span>move</span><span>(</span><span>semaphore</span><span>)</span><span>,</span> <span>async</span> <span>(</span><span>sem</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"Waiting for slot..."</span><span>)</span><span>;</span>
    
    <span>// Will wait (async) if 3 threads are already working</span>
    using <span>_</span> <span>=</span> <span>await</span> <span>sem</span><span>.</span><span>acquire</span><span>(</span><span>)</span><span>;</span> 
    
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"Acquired slot! Working..."</span><span>)</span><span>;</span>

    <span>await</span> <span>new</span> <span>Promise</span><span>(</span><span>r</span> <span>=&gt;</span> <span>setTimeout</span><span>(</span><span>r</span><span>,</span> <span>1000</span><span>)</span><span>)</span><span>;</span>
    
    <span>// Guard is disposed automatically, releasing the permit for the next thread</span>
  <span>}</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Manual Release</h4><a id="user-content-manual-release" aria-label="Permalink: Manual Release" href="#manual-release"></a></p>
<p dir="auto">Like the Mutex, if you cannot use the <code>using</code> keyword, you can manually manage the lifecycle.</p>
<div dir="auto" data-snippet-clipboard-copy-content="spawn(move(semaphore), async (sem) => {
  const { drop } = await import(&quot;multithreading&quot;);
  // Acquire 2 permits at once
  const guard = await sem.acquire(2);
  
  try {
    // Critical Section
  } finally {
    // Release the 2 permits
    drop(guard);
  }
});"><pre><span>spawn</span><span>(</span><span>move</span><span>(</span><span>semaphore</span><span>)</span><span>,</span> <span>async</span> <span>(</span><span>sem</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> <span>{</span> drop <span>}</span> <span>=</span> <span>await</span> <span>import</span><span>(</span><span>"multithreading"</span><span>)</span><span>;</span>
  <span>// Acquire 2 permits at once</span>
  <span>const</span> <span>guard</span> <span>=</span> <span>await</span> <span>sem</span><span>.</span><span>acquire</span><span>(</span><span>2</span><span>)</span><span>;</span>
  
  <span>try</span> <span>{</span>
    <span>// Critical Section</span>
  <span>}</span> <span>finally</span> <span>{</span>
    <span>// Release the 2 permits</span>
    <span>drop</span><span>(</span><span>guard</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">4. Condvar (Condition Variable)</h3><a id="user-content-4-condvar-condition-variable" aria-label="Permalink: 4. Condvar (Condition Variable)" href="#4-condvar-condition-variable"></a></p>
<p dir="auto">A <code>Condvar</code> allows threads to wait for a specific condition to become true. It saves CPU resources by putting the task to sleep until it is notified, rather than constantly checking a value.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import { spawn, move, Mutex, Condvar } from &quot;multithreading&quot;;

const mutex = new Mutex(new Int32Array(new SharedArrayBuffer(4)));
const cv = new Condvar();

spawn(move(mutex, cv), async (lock, cond) => {
  using guard = await lock.acquire();
  
  // Wait until value is not 0
  while (guard.value[0] === 0) {
    // wait() unlocks the mutex, waits for notification, then re-locks
    await cond.wait(guard);
  }
  
  console.log(&quot;Received signal, value is:&quot;, guard.value[0]);
});"><pre><span>import</span> <span>{</span> <span>spawn</span><span>,</span> <span>move</span><span>,</span> <span>Mutex</span><span>,</span> <span>Condvar</span> <span>}</span> <span>from</span> <span>"multithreading"</span><span>;</span>

<span>const</span> <span>mutex</span> <span>=</span> <span>new</span> <span>Mutex</span><span>(</span><span>new</span> <span>Int32Array</span><span>(</span><span>new</span> <span>SharedArrayBuffer</span><span>(</span><span>4</span><span>)</span><span>)</span><span>)</span><span>;</span>
<span>const</span> <span>cv</span> <span>=</span> <span>new</span> <span>Condvar</span><span>(</span><span>)</span><span>;</span>

<span>spawn</span><span>(</span><span>move</span><span>(</span><span>mutex</span><span>,</span> <span>cv</span><span>)</span><span>,</span> <span>async</span> <span>(</span><span>lock</span><span>,</span> <span>cond</span><span>)</span> <span>=&gt;</span> <span>{</span>
  using <span>guard</span> <span>=</span> <span>await</span> <span>lock</span><span>.</span><span>acquire</span><span>(</span><span>)</span><span>;</span>
  
  <span>// Wait until value is not 0</span>
  <span>while</span> <span>(</span><span>guard</span><span>.</span><span>value</span><span>[</span><span>0</span><span>]</span> <span>===</span> <span>0</span><span>)</span> <span>{</span>
    <span>// wait() unlocks the mutex, waits for notification, then re-locks</span>
    <span>await</span> <span>cond</span><span>.</span><span>wait</span><span>(</span><span>guard</span><span>)</span><span>;</span>
  <span>}</span>
  
  <span>console</span><span>.</span><span>log</span><span>(</span><span>"Received signal, value is:"</span><span>,</span> <span>guard</span><span>.</span><span>value</span><span>[</span><span>0</span><span>]</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Channels (MPMC)</h2><a id="user-content-channels-mpmc" aria-label="Permalink: Channels (MPMC)" href="#channels-mpmc"></a></p>
<p dir="auto">For higher-level communication, this library provides a <strong>Multi-Producer, Multi-Consumer (MPMC)</strong> bounded channel. This primitive mimics Rust's <code>std::sync::mpsc</code> but allows for multiple consumers. It acts as a thread-safe queue that handles backpressure, blocking receivers when empty and blocking senders when full.</p>
<p dir="auto">Channels are the preferred way to coordinate complex workflows (like job queues or pipelines) between workers without manually managing locks.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Key Features</h3><a id="user-content-key-features" aria-label="Permalink: Key Features" href="#key-features"></a></p>
<ul dir="auto">
<li><strong>Arbitrary JSON Data:</strong> Channels are backed by <code>SharedJsonBuffer</code>, allowing you to send any JSON-serializable value (objects, arrays, strings, numbers, booleans) through the channel, not just raw integers.</li>
<li><strong>Bounded:</strong> You define a capacity. If the channel is full, <code>send()</code> waits. If empty, <code>recv()</code> waits.</li>
<li><strong>Clonable:</strong> Both <code>Sender</code> and <code>Receiver</code> can be cloned and moved to different workers.</li>
<li><strong>Reference Counted:</strong> The channel automatically closes when all Senders are dropped (indicating no more data will arrive) or all Receivers are dropped.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example: Worker Pipeline with Objects</h3><a id="user-content-example-worker-pipeline-with-objects" aria-label="Permalink: Example: Worker Pipeline with Objects" href="#example-worker-pipeline-with-objects"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import { spawn, move, channel } from &quot;multithreading&quot;;

// Create a channel that holds objects
const [tx, rx] = channel<{ hello: string }>();

// Producer Thread
spawn(move(tx), async (sender) => {
  await sender.send({ hello: &quot;world&quot; });
  await sender.send({ hello: &quot;multithreading&quot; });
  // Sender is destroyed here, automatically closing the channel
  // because the last `tx` goes out of scope here.
});

// Consumer Thread
spawn(move(rx.clone()), async (receiver) => {
  for await (const value of receiver) {
    console.log(value); // { hello: &quot;world&quot; }
  }
});

// Because we cloned rx, the main thread also still has a handle
for await (const value of rx) {
  console.log(value); // { hello: &quot;world&quot; }
}"><pre><span>import</span> <span>{</span> <span>spawn</span><span>,</span> <span>move</span><span>,</span> <span>channel</span> <span>}</span> <span>from</span> <span>"multithreading"</span><span>;</span>

<span>// Create a channel that holds objects</span>
<span>const</span> <span>[</span><span>tx</span><span>,</span> <span>rx</span><span>]</span> <span>=</span> <span>channel</span><span>&lt;</span><span>{</span> <span>hello</span>: <span>string</span> <span>}</span><span>&gt;</span><span>(</span><span>)</span><span>;</span>

<span>// Producer Thread</span>
<span>spawn</span><span>(</span><span>move</span><span>(</span><span>tx</span><span>)</span><span>,</span> <span>async</span> <span>(</span><span>sender</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>await</span> <span>sender</span><span>.</span><span>send</span><span>(</span><span>{</span> <span>hello</span>: <span>"world"</span> <span>}</span><span>)</span><span>;</span>
  <span>await</span> <span>sender</span><span>.</span><span>send</span><span>(</span><span>{</span> <span>hello</span>: <span>"multithreading"</span> <span>}</span><span>)</span><span>;</span>
  <span>// Sender is destroyed here, automatically closing the channel</span>
  <span>// because the last `tx` goes out of scope here.</span>
<span>}</span><span>)</span><span>;</span>

<span>// Consumer Thread</span>
<span>spawn</span><span>(</span><span>move</span><span>(</span><span>rx</span><span>.</span><span>clone</span><span>(</span><span>)</span><span>)</span><span>,</span> <span>async</span> <span>(</span><span>receiver</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>for</span> <span>await</span> <span>(</span><span>const</span> <span>value</span> <span>of</span> <span>receiver</span><span>)</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>value</span><span>)</span><span>;</span> <span>// { hello: "world" }</span>
  <span>}</span>
<span>}</span><span>)</span><span>;</span>

<span>// Because we cloned rx, the main thread also still has a handle</span>
<span>for</span> <span>await</span> <span>(</span><span>const</span> <span>value</span> <span>of</span> <span>rx</span><span>)</span> <span>{</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>value</span><span>)</span><span>;</span> <span>// { hello: "world" }</span>
<span>}</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Importing Modules in Workers</h2><a id="user-content-importing-modules-in-workers" aria-label="Permalink: Importing Modules in Workers" href="#importing-modules-in-workers"></a></p>
<p dir="auto">This library simplifies module loading within Web Workers by supporting standard dynamic <code>await import()</code> calls. It automatically handles path resolution, allowing you to import dependencies relative to the file calling <code>spawn</code>, rather than the worker's internal location.</p>
<p dir="auto">You can import:</p>
<ol dir="auto">
<li><strong>External Libraries:</strong> Packages from npm or CDNs (depending on your environment).</li>
<li><strong>Relative Files:</strong> Local modules relative to the file where <code>spawn</code> is executed.</li>
</ol>
<p dir="auto"><strong>Note:</strong> The function passed to <code>spawn</code> must be self-contained or explicitly import what it needs. It cannot access variables from the outer scope unless they are passed via <code>move()</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example: Importing Relative Files and External Libraries</h3><a id="user-content-example-importing-relative-files-and-external-libraries" aria-label="Permalink: Example: Importing Relative Files and External Libraries" href="#example-importing-relative-files-and-external-libraries"></a></p>
<p dir="auto">Assume you have a file structure:</p>
<ul dir="auto">
<li><code>main.ts</code></li>
<li><code>utils.ts</code> (contains <code>export const magicNumber = 42;</code>)</li>
</ul>

<div dir="auto" data-snippet-clipboard-copy-content="// main.ts
import { spawn } from &quot;multithreading&quot;;

spawn(async () => {
  // Importing relative files
  const utils = await import(&quot;./utils.ts&quot;);
  // Importing external libraries
  const { default: _ } = await import(&quot;lodash&quot;);

  console.log(&quot;Magic number from relative file:&quot;, utils.magicNumber);
  console.log(&quot;Random number via lodash:&quot;, _.random(1, 100));
  
  return utils.magicNumber;
});"><pre><span>// main.ts</span>
<span>import</span> <span>{</span> <span>spawn</span> <span>}</span> <span>from</span> <span>"multithreading"</span><span>;</span>

<span>spawn</span><span>(</span><span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>// Importing relative files</span>
  <span>const</span> <span>utils</span> <span>=</span> <span>await</span> <span>import</span><span>(</span><span>"./utils.ts"</span><span>)</span><span>;</span>
  <span>// Importing external libraries</span>
  <span>const</span> <span>{</span> <span>default</span>: <span>_</span> <span>}</span> <span>=</span> <span>await</span> <span>import</span><span>(</span><span>"lodash"</span><span>)</span><span>;</span>

  <span>console</span><span>.</span><span>log</span><span>(</span><span>"Magic number from relative file:"</span><span>,</span> <span>utils</span><span>.</span><span>magicNumber</span><span>)</span><span>;</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>"Random number via lodash:"</span><span>,</span> <span>_</span><span>.</span><span>random</span><span>(</span><span>1</span><span>,</span> <span>100</span><span>)</span><span>)</span><span>;</span>
  
  <span>return</span> <span>utils</span><span>.</span><span>magicNumber</span><span>;</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Browser Compatibility</h2><a id="user-content-browser-compatibility" aria-label="Permalink: Browser Compatibility" href="#browser-compatibility"></a></p>
<p dir="auto"><strong>Core features</strong> (like <code>spawn</code> and <code>move</code>) work in all modern browsers without special configuration.</p>
<p dir="auto"><strong>Synchronization primitives</strong> (<code>Mutex</code>, <code>RwLock</code>, <code>SharedJsonBuffer</code>, etc.) rely on <code>SharedArrayBuffer</code>, which requires your page to be <strong>Cross-Origin Isolated</strong>. To use these specific features, your server must send the following headers:</p>
<div dir="auto" data-snippet-clipboard-copy-content="Cross-Origin-Opener-Policy: same-origin
Cross-Origin-Embedder-Policy: require-corp"><pre><span><span>Cross-Origin-Opener-Policy:</span> same-origin</span>
<span><span>Cross-Origin-Embedder-Policy:</span> require-corp</span></pre></div>
<p dir="auto">If these headers are missing, basic threading will work, but attempting to use synchronization primitives will result in an error.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Content Security Policy (CSP)</h3><a id="user-content-content-security-policy-csp" aria-label="Permalink: Content Security Policy (CSP)" href="#content-security-policy-csp"></a></p>
<p dir="auto">This library utilizes dynamic imports via <code>data:</code> URLs to generate worker entry points on the fly without requiring separate physical files.</p>
<p dir="auto">If your application uses a Content Security Policy (CSP), you must ensure that your <code>script-src</code> and <code>worker-src</code> directives allow the <code>data:</code> scheme.</p>
<p dir="auto"><strong>Required CSP Headers:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="Content-Security-Policy: script-src 'self' data:; worker-src 'self' data:;"><pre><span><span>Content-Security-Policy:</span> script-src 'self' data:; worker-src 'self' data:;</span></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">API Reference</h2><a id="user-content-api-reference" aria-label="Permalink: API Reference" href="#api-reference"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Runtime</h3><a id="user-content-runtime" aria-label="Permalink: Runtime" href="#runtime"></a></p>
<ul dir="auto">
<li><strong><code>spawn(fn)</code></strong>: Runs a function in a worker.</li>
<li><strong><code>spawn(move(arg1, arg2, ...), fn)</code></strong>: Runs a function in a worker with specific arguments transferred or cloned.</li>
<li><strong><code>initRuntime(config)</code></strong>: Initializes the thread pool (optional, lazy loaded by default).</li>
<li><strong><code>shutdown()</code></strong>: Terminates all workers in the pool.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Memory Management</h3><a id="user-content-memory-management" aria-label="Permalink: Memory Management" href="#memory-management"></a></p>
<ul dir="auto">
<li><strong><code>move(...args)</code></strong>: Marks arguments for transfer (ownership move) or clone, depending on the data type. Accepts a variable number of arguments which map to the arguments of the worker function.</li>
<li><strong><code>drop(resource)</code></strong>: Explicitly disposes of a resource (calls <code>[Symbol.dispose]</code>). This is required for manual lock management in environments like Bun.</li>
<li><strong><code>SharedJsonBuffer</code></strong>: A class for storing JSON objects in shared memory.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Channels (MPMC)</h3><a id="user-content-channels-mpmc-1" aria-label="Permalink: Channels (MPMC)" href="#channels-mpmc-1"></a></p>
<ul dir="auto">
<li><strong><code>channel&lt;T&gt;(capacity)</code></strong>: Creates a new channel. Returns <code>[Sender&lt;T&gt;, Receiver&lt;T&gt;]</code>.</li>
<li><strong><code>Sender&lt;T&gt;</code></strong>:
<ul dir="auto">
<li><code>send(value)</code>: Async. Returns <code>Promise&lt;Result&lt;void, Error&gt;&gt;</code>.</li>
<li><code>sendSync(value)</code>: Blocking. Returns <code>Result&lt;void, Error&gt;</code>.</li>
<li><code>clone()</code>: Creates a new handle to the same channel (increments ref count).</li>
<li><code>close()</code>: Manually closes the channel for everyone.</li>
</ul>
</li>
<li><strong><code>Receiver&lt;T&gt;</code></strong>:
<ul dir="auto">
<li><code>recv()</code>: Async. Returns <code>Promise&lt;Result&lt;T, Error&gt;&gt;</code>.</li>
<li><code>recvSync()</code>: Blocking. Returns <code>Result&lt;T, Error&gt;</code>.</li>
<li><code>clone()</code>: Creates a new handle to the same channel.</li>
<li><code>close()</code>: Manually drops this handle.</li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Synchronization</h3><a id="user-content-synchronization" aria-label="Permalink: Synchronization" href="#synchronization"></a></p>
<ul dir="auto">
<li><strong><code>Mutex&lt;T&gt;</code></strong>:
<ul dir="auto">
<li><code>acquire()</code>: Async lock (Recommended). Returns <code>Promise&lt;MutexGuard&gt;</code>.</li>
<li><code>tryLock()</code>: Non-blocking attempt. Returns boolean.</li>
<li><code>acquireSync()</code>: Blocking lock (Halts Worker). Returns <code>MutexGuard</code>.</li>
</ul>
</li>
<li><strong><code>RwLock&lt;T&gt;</code></strong>:
<ul dir="auto">
<li><code>read()</code>: Async shared read access (Recommended).</li>
<li><code>write()</code>: Async exclusive write access (Recommended).</li>
<li><code>readSync()</code> / <code>writeSync()</code>: Synchronous/Blocking variants.</li>
</ul>
</li>
<li><strong><code>Semaphore</code></strong>:
<ul dir="auto">
<li><code>acquire(amount?)</code>: Async wait for <code>n</code> permits. Returns <code>SemaphoreGuard</code>.</li>
<li><code>tryAcquire(amount?)</code>: Non-blocking. Returns <code>SemaphoreGuard</code> or <code>null</code>.</li>
<li><code>acquireSync(amount?)</code>: Blocking wait. Returns <code>SemaphoreGuard</code>.</li>
</ul>
</li>
<li><strong><code>Condvar</code></strong>:
<ul dir="auto">
<li><code>wait(guard)</code>: Async wait (Recommended). Yields execution.</li>
<li><code>notifyOne()</code>: Wake one waiting thread.</li>
<li><code>notifyAll()</code>: Wake all waiting threads.</li>
<li><code>waitSync(guard)</code>: Blocking wait (Halts Worker).</li>
</ul>
</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Technical Implementation Details</h2><a id="user-content-technical-implementation-details" aria-label="Permalink: Technical Implementation Details" href="#technical-implementation-details"></a></p>
<p dir="auto">For advanced users interested in the internal mechanics:</p>
<ul dir="auto">
<li><strong>Serialization Protocol</strong>: The library uses a custom "Envelope" protocol (<code>PayloadType.RAW</code> vs <code>PayloadType.LIB</code>). This allows complex objects like <code>Mutex</code> handles to be serialized, sent to a worker, and rehydrated into a functional object connected to the same <code>SharedArrayBuffer</code> on the other side.</li>
<li><strong>Atomics</strong>: Synchronization is built on <code>Int32Array</code> backed by <code>SharedArrayBuffer</code> using <code>Atomics.wait</code> and <code>Atomics.notify</code>.</li>
<li><strong>Import Patching</strong>: The <code>spawn</code> function analyzes the stack trace to determine the caller's file path. It then regex-patches <code>import()</code> statements within the worker code string to ensure relative paths resolve correctly against the caller's location, rather than the worker's location.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Judge Signals Win for Software Freedom Conservancy in Vizio GPL Case (194 pts)]]></title>
            <link>https://fossforce.com/2025/12/judge-signals-win-for-software-freedom-conservancy-in-vizio-gpl-case/</link>
            <guid>46166994</guid>
            <pubDate>Fri, 05 Dec 2025 20:42:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fossforce.com/2025/12/judge-signals-win-for-software-freedom-conservancy-in-vizio-gpl-case/">https://fossforce.com/2025/12/judge-signals-win-for-software-freedom-conservancy-in-vizio-gpl-case/</a>, See on <a href="https://news.ycombinator.com/item?id=46166994">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="overflow-container" role="main">
		<article>
				
				<div>
					<h3><em>A California judge has tentatively sided with Software Freedom Conservancy in its GPL case over Vizio’s SmartCast TVs, but the final outcome of this week’s hearing is still pending.</em></h3>
<figure id="attachment_2350312" aria-describedby="caption-attachment-2350312"><img decoding="async" src="https://fossforce.com/wp-content/uploads/2025/12/television-5017870_1280.jpg" alt="" width="700" height="451" srcset="https://fossforce.com/wp-content/uploads/2025/12/television-5017870_1280.jpg 700w, https://fossforce.com/wp-content/uploads/2025/12/television-5017870_1280-300x193.jpg 300w, https://fossforce.com/wp-content/uploads/2025/12/television-5017870_1280-175x113.jpg 175w" sizes="(max-width: 700px) 100vw, 700px"><figcaption id="caption-attachment-2350312">Source: Pixabay</figcaption></figure>
<p>We’re waiting to hear the final outcome of a legal case involving the GPL that harkens back to the bad “good ol’ days” of Linux and open source.</p>
<p>This case involves an action brought against Vizio — a maker of relatively low‑cost flat panel TVs — by <a href="https://fossforce.com/2016/06/oftware-freedom-conservancy-karen-sandler-foss-iot/" target="_blank">Software Freedom Conservancy</a>, which claims that the company has been in violation of the General Public License, version 2 and Lesser General Public License, version 2.1 for many years. The case centers around the company’s SmartCast TVs, which employ Linux, BusyBox, and other software licensed under GPLv2 and LGPLv2.1, without making source code available.</p>
<p>SFC’s standing in the case is as a purchaser of a Vizio smart TV and not as a copyright holder.</p>
<p><a href="https://sfconservancy.org/news/2025/dec/04/tentative-vizio-ruling-in-favor-of-sfc/" target="_blank">SFC has reported</a> that early Thursday morning Judge Sandy N. Leal of the Superior Court of California issued a tentative ruling supporting SFC’s claim that Vizio has a duty to provide SFC with the complete source code covered under open source licenses to a TV it purchased. Being tentative, the ruling isn’t final– such rulings are issued so that the parties know how the judge is leaning and can tailor their oral arguments — and it was issued before a hearing scheduled for 10 a.m. PST the same day.</p>
<p>So far there’s been no news coming out of that hearing, although we’ve reached out to SFC for a comment.</p><p><a target="_blank" href="https://shareasale.com/r.cfm?b=1210138&amp;u=3049832&amp;m=80177&amp;urllink=&amp;afftrack="><img decoding="async" src="https://static.shareasale.com/image/80177/18009015663533991438.jpg" alt="Premium VPS Hosting at a fraction of the cost"></a></p>
<h2>A Predictable Outcome</h2>
<p>These days the GPL and other open source licenses have been court tested enough to make the outcome in a case like this somewhat predictable: the courts will support the terms of the license. This hasn’t always been the case. For many years after the first adoption of the GPL as a free software license, and even later when the term open source came into use, it wasn’t clear whether courts would support the terms of open source licensing.</p>
<p>That began to change in the first decade of the 21st century as cases were brought against violators of open source licenses, with license terms being upheld by the courts.</p>
<p>Then in September 2007 the Software Freedom Law Center filed the first-ever US GPL enforcement lawsuit. The defendant was Monsoon Multimedia, for its Hava <a href="https://en.wikipedia.org/wiki/Place_shifting" target="_blank">place‑shifting devices</a> that SFLC claimed shipped with BusyBox installed without provisions for the source code.​ That case was dismissed about a month later, after Monsoon agreed to publish source code, appoint a compliance officer, notify customers of their GPL rights, and pay an undisclosed sum.​</p>
<p>Later that year, SFLC brought additional BusyBox-related GPL suits against other vendors, including Xterasys and Verizon, over failure to provide source code. Those were also settled with compliance commitments and payments.</p>
<h2>Vizio: A Goliath in Disguise</h2>
<p>In the case against Vizio, SFC is going against a company that can afford a deep pocket defense if it decides to play hardball. The Irvine, California-based company that was founded in 2002 as a designer of televisions, soundbars, and related software and accessories, was acquired by Walmart for $2.3 billion in a deal that was announced in February 2024 and closed that December.</p><p><a rel="sponsored" href="https://www.awin1.com/cread.php?s=4589764&amp;v=96539&amp;q=588268&amp;r=2117951">
    <img decoding="async" src="https://www.awin1.com/cshow.php?s=4589764&amp;v=96539&amp;q=588268&amp;r=2117951">
</a></p>
<p>While the acquisition was in progress, Bloomberg announced that Walmart planned to end sales of Vizio products at Amazon and Best Buy in order to turn the company into a private label brand available only at Walmart and Sam’s Club locations.</p>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img alt="Christine Hall" src="https://secure.gravatar.com/avatar/7e2b94e60f27405240d50a7901d0b5c0c8db583d72063ee6ce740322ca0127c9?s=100&amp;d=mm&amp;r=pg" srcset="https://secure.gravatar.com/avatar/7e2b94e60f27405240d50a7901d0b5c0c8db583d72063ee6ce740322ca0127c9?s=200&amp;d=mm&amp;r=pg 2x" height="100" width="100" itemprop="image"></p><div><p>Christine Hall has been a journalist since 1971. In 2001, she began writing a weekly consumer computer column and started covering Linux and FOSS in 2002 after making the switch to GNU/Linux. Follow her on Twitter: <a href="https://twitter.com/BrideOfLinux">@BrideOfLinux</a></p></div></div>								</div>
		
		<div>
	<div><ul><li><a href="https://fossforce.com/2025/08/smart-gadgets-dumb-ideas-why-consumer-iot-went-off-the-rails/">‘Smart’ Gadgets, Dumb Ideas: Why Consumer IoT Went Off the Rails</a></li></ul></div><div><ul><li><a href="https://fossforce.com/2025/11/ten-reasons-and-five-exceptions-to-choose-open-source-over-freemium/">Ten Reasons (and Five Exceptions) to Choose Open Source Over Freemium</a></li><li><a href="https://fossforce.com/2025/11/odf-1-4-standard-set-for-debut-why-this-is-important/">ODF 1.4 Standard Set for Debut: Why This Is Important</a></li></ul></div></div>	</article>
	    
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Advertising as a major source of human dissatisfaction (2019) [pdf] (197 pts)]]></title>
            <link>https://www.andrewoswald.com/docs/AdvertisingMicheletal2019EasterlinVolume.pdf</link>
            <guid>46166709</guid>
            <pubDate>Fri, 05 Dec 2025 20:18:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.andrewoswald.com/docs/AdvertisingMicheletal2019EasterlinVolume.pdf">https://www.andrewoswald.com/docs/AdvertisingMicheletal2019EasterlinVolume.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=46166709">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Framework Sponsors CachyOS (172 pts)]]></title>
            <link>https://discuss.cachyos.org/t/framework-sponsorship-for-cachyos/19376</link>
            <guid>46166536</guid>
            <pubDate>Fri, 05 Dec 2025 20:03:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://discuss.cachyos.org/t/framework-sponsorship-for-cachyos/19376">https://discuss.cachyos.org/t/framework-sponsorship-for-cachyos/19376</a>, See on <a href="https://news.ycombinator.com/item?id=46166536">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting" id="main-outlet" role="main">
      <meta itemprop="headline" content="Framework Sponsorship for CachyOS">
      
      <meta itemprop="datePublished" content="2025-12-04T20:30:18Z">
        <meta itemprop="articleSection" content="Announcements">
      <meta itemprop="keywords" content="">
      


          <div id="post_1">
            <div>
              

                

              <p><span>
                  <time datetime="2025-12-04T20:30:19Z">
                    December 4, 2025,  8:30pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-04T20:30:19Z">
              <span itemprop="position">1</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>Hey CachyOS Community,</p>
<p>We have some massive news to share today. Framework, the company behind the modular and repairable laptop revolution, is now sponsoring CachyOS.</p>
<p>For an open-source project like ours, finding hardware partners who genuinely care about Linux is rare. Framework has not only provided us with a Framework Laptop 16 to help us optimize our kernel and packages on modern hardware, but they have also committed to a $250 monthly donation.</p>
<p>While we are still a community-driven project, this contribution amounts to about 10% of our total monthly donations. Every bit of support like this helps stabilize our infrastructure and fuels our ultimate goal: eventually working on CachyOS full-time to bring you the fastest, most optimized Linux experience possible.</p>
<p>Please go show them some love and check out their blog post regarding further sponsorships:</p>


<p>Thanks to Framework and thanks to all of you for using CachyOS!</p>
            </div>

            


            
          </div>
          <div id="post_2" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discuss.cachyos.org/u/recall"><span itemprop="name">recall</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-04T20:49:13Z">
                    December 4, 2025,  8:49pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-04T20:49:13Z">
              <span itemprop="position">2</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Name a more iconic duo</p>
<p>[congratulations, its well deserved]</p>
            </div>

            


            
          </div>
          <div id="post_3" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discuss.cachyos.org/u/Rabcor"><span itemprop="name">Rabcor</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-04T23:55:24Z">
                    December 4, 2025, 11:55pm
                  </time>
                  <meta itemprop="dateModified" content="2025-12-04T23:55:24Z">
              <span itemprop="position">3</span>
              </span>
            </p>
            <p>This is fantastic news! Congratulations.</p>

            


            
          </div>
          <div id="post_4" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discuss.cachyos.org/u/Dagrod"><span itemprop="name">Dagrod</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-05T00:08:39Z">
                    December 5, 2025, 12:08am
                  </time>
                  <meta itemprop="dateModified" content="2025-12-05T00:08:39Z">
              <span itemprop="position">4</span>
              </span>
            </p>
            <p>I’m impressed. Congratulations on this success, may it advance the project!</p>

            


            
          </div>
          <div id="post_5" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://discuss.cachyos.org/u/cscs"><span itemprop="name">cscs</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-12-05T00:10:11Z">
                    December 5, 2025, 12:10am
                  </time>
                  <meta itemprop="dateModified" content="2025-12-05T00:10:11Z">
              <span itemprop="position">5</span>
              </span>
            </p>
            <p>Someone tell cloudflare so they can match it. <img src="https://discuss.cachyos.org/images/emoji/twitter/smiling_face_with_sunglasses.png?v=14" title=":smiling_face_with_sunglasses:" alt=":smiling_face_with_sunglasses:" loading="lazy" width="20" height="20"></p>

            


            
          </div>
          <div id="post_6" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>I just switched to CachyOS a few days ago. Really look forward to future updates!</p>

            


            
          </div>
    </div></div>]]></description>
        </item>
    </channel>
</rss>