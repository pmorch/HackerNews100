<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 10 May 2024 13:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The most backdoor-looking bug I've ever seen (2021) (120 pts)]]></title>
            <link>https://words.filippo.io/dispatches/telegram-ecdh/</link>
            <guid>40315274</guid>
            <pubDate>Fri, 10 May 2024 03:33:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://words.filippo.io/dispatches/telegram-ecdh/">https://words.filippo.io/dispatches/telegram-ecdh/</a>, See on <a href="https://news.ycombinator.com/item?id=40315274">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
            <!--kg-card-begin: markdown--><p>This is the story of a bug that was discovered and fixed in Telegram's self-rolled cryptographic protocol about seven years ago. The bug didn't get any press, and no one seems to know about it, probably because it was only published in Russian.</p>
<p>To this day, it's the most backdoor-looking bug I've ever seen.</p>
<p>Google Translate does a good enough job on the <a href="https://habrahabr.ru/post/206900/?ref=words.filippo.io">original article</a>, which is still available on Habr, but I'm going to walk you through it along with some context.</p>
<p>Telegram is a popular chat app that uses its own... bizarre protocol to encrypt chats, called MTProto. The protocol is used both to encrypt all messages to the Telegram server, and to encrypt opt-in 1:1 end-to-end "Secret Chats".<sup><a href="#fn1" id="fnref1">[1]</a></sup> In text I can't do justice to the facial expressions of cryptographers when you mention Telegram's protocol, so just believe me that it's <em>weird</em>.</p>
<p>The current consensus seems to be that the latest version is not broken in known ways that are severe or relevant enough to affect end users, assuming the implementation is correct. That is about as safe as leaving exposed wires around your house because they are either not live or placed high enough that no one should touch them.</p>
<p>The original version was, however, completely broken, in the most puzzling of ways.</p>
<p>End-to-end Telegram chat sessions use <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange?ref=words.filippo.io">finite-field Diffie-Hellman</a><sup><a href="#fn2" id="fnref2">[2]</a></sup> to establish a shared key between the two participants. The negotiation happens through messages relayed by the Telegram server. Diffie-Hellman is a fundamental building block of many cryptosystems, and it allows two parties to establish a shared secret that any eavesdroppers can't derive. It is however only one part of a secure key exchange, because an attacker capable of intercepting the messages could simply establish two separate sessions with the two parties, carrying out a <a href="https://en.wikipedia.org/wiki/Person-in-the-middle_attack?ref=words.filippo.io">Person-in-the-Middle</a> attack. The parties need some way to verify they derived the same secret. In TLS, they use a signature from a certificate. In most secure chat apps, there is a fingerprint ("Safety Numbers" in Signal) that the two parties can compare out-of-band.<sup><a href="#fn3" id="fnref3">[3]</a></sup> What's important is that if the two sides derived the same secret, they can be sure no one else has access to it.</p>
<p>The Telegram key exchange is described in <a href="https://web.archive.org/web/20131220000537/https://core.telegram.org/api/end-to-end#key-generation">the "Key Generation" section of Telegram's end-to-end API docs</a>. Concretely, Alice requests the DH parameters <code>(p, g)</code> from Telegram, painstakingly verifies them, computes a random <code>a</code> value, and sends <code>g^a mod p</code> to Telegram. Bob receives <code>(p, g, g^a mod p)</code>, similarly computes <code>b</code> and <code>g^b mod p</code>, and sends the latter back (along with a truncated hash of the derived key, for some reason).</p>
<p>Now, normally the two sides would compute the shared key as <code>(g^a)^b mod p</code> and <code>(g^b)^a mod p</code>. Instead, the original version of MTProto computed it as</p>
<pre><code>(g^a)^b mod p XOR nonce
</code></pre>
<p>where <code>nonce</code> was an arbitrary, supposedly random value sent by the server along with the peer's public contribution.</p>
<p>This was a completely non-standard and useless addition, and all it did was let the server perform an undetected Person-in-the-Middle attack. Let's see how.</p>
<p>In a normal PitM, the server negotiates two separate Diffie-Hellman sessions with Alice and Bob, who end up with different shared keys, which they could detect by comparing fingerprints.</p>
<pre><code>Alice                     Telegram              Bob

a = random()       
A = g^a mod p       -&gt;
                        t = random()
                        T = g^t mod p -&gt;
                                          b = random()
                                      &lt;-  B = g^b mod p
                                          key = T^b mod p
                    &lt;-  T
key = T^a mod p

                    T^a mod p != T^b mod p
</code></pre>
<p>With the nonce addition, however, the server could "fix" Alice's key to match Bob's by manipulating Alice's nonce. The two parties would end up with the same fingerprint, and couldn't tell that an attack happened, but the server (and no one else) would know the shared key, allowing it to decrypt all messages.</p>
<pre><code>nonce_bob = random()
key_bob = T^b mod p  XOR  nonce_bob

nonce_alice = A^t mod p  XOR  B^t mod p  XOR  nonce_bob
key_alice = T^a mod p  XOR  nonce_alice =
  T^a mod p  XOR  (A^t mod p  XOR  B^t mod p  XOR  nonce_bob) =
  B^t mod p  XOR  nonce_bob = key_bob
</code></pre>
<p>Why do I say this addition was useless? Because it literally had no purpose! Indeed, the vulnerability was <a href="https://web.archive.org/web/diff/20131220000537/20131225140924/http://core.telegram.org/api/end-to-end">fixed by silently removing the nonce step from the docs</a>.<sup><a href="#fn4" id="fnref4">[4]</a></sup> <a href="https://core.telegram.org/constructor/encryptedChatRequested?layer=11&amp;ref=words.filippo.io">A later API revision</a> removed the nonce parameter with the caption "Improve secret chats". All <a href="https://web.archive.org/web/20131028041748/http://core.telegram.org/constructor/encryptedChatRequested">the original API reference</a> said about the nonce is "Random server sequence for calculation of key".</p>
<p>I never heard a plausible explanation for why the designers of MTProto went out of their way to add useless complexity to their protocol, with the only outcome of making undetectable interception possible.</p>
<p><strong>Edit (2021-01-11)</strong>: <a href="https://twitter.com/asdofindia/status/1348491279798128641?ref=words.filippo.io">@asdofindia linked me on Twitter</a> to <a href="https://telegram.org/blog/crowdsourcing-a-more-secure-future?ref=words.filippo.io">an official statement by Telegram about this</a> that I couldn't find anymore. It claims the nonce was there to protect clients with weak random number generators. Here's what I had buried into a footnote when I couldn't find a citation to attribute that explanation to Telegram:</p>
<blockquote>
<p>This doesn't make sense for a number of reasons: 1) clients with weak randomness are likely to be toast anyway, because Telegram's bizarro not-a-MAC relies on randomness in the payload to avoid an offline decryption oracle (there is a plaintext hash of the payload on the wire, I told you this was weird!); 2) the API also allows clients to request random bytes from the server to XOR with their secret share; and 3) defending against weak randomness by relying on a server contribution defends against everything but the server, which is the relevant attacker in the end-to-end setting. (Said another way, anyone that can intercept client-server messages can see the extra randomness, making it moot.) Non-practitioners might think this is a reasonable defense in depth, belts and suspenders kind of thing, but in cryptography engineering adding complexity to defend against scenarios that lead to compromise anyway is simply pointless.</p>
</blockquote>
<p>Anyway, it's been a while, the world is a different place now, and maybe <a href="https://en.wikipedia.org/wiki/Hanlon%27s_razor?ref=words.filippo.io">Hanlon's razor</a> cuts deeper than I thought. I think there are better reasons not to use Telegram today than this old bug<sup><a href="#fn1" id="fnref1:1">[1:1]</a></sup>, but it's still what I think about every time people talk about far-fetched "bugdoors". The bar is high!</p>
<h2 id="the-picture">The picture</h2>
<p>In other news, this newsletter is going to pivot into Rome photoblogging. (Not really, if you made it this far and like cryptography engineering, you should <a href="https://buttondown.email/cryptography-dispatches?tag=header&amp;ref=words.filippo.io">subscribe</a> or <a href="https://twitter.com/FiloSottile?ref=words.filippo.io">follow me on Twitter</a>.)</p>
<p><img src="https://words.filippo.io/content/images/2022/01/ee618b89-a8fa-45a2-af01-6f9955d2c99a.jpeg" alt="St. Peter's reflecting in the Tevere" loading="lazy"></p>
<hr>
<section>
<ol>
<li id="fn1"><p>By the way, aside from all the cryptographic weirdness and the unexplained backdoor-looking bug, the real reason you should not trust Telegram's encryption is that it's off by default, inconvenient to use, and simply unavailable in groups, meaning most messages flow unencrypted on Telegram's servers. Nonetheless, Telegram markets itself as a secure chat app, with misleading copy along the lines of "everything is encrypted, Secret Chats are just <em>more</em> encrypted!" They explain in their FAQ that it's all about backups, and that other more secure apps "<a href="https://telegram.org/faq?ref=words.filippo.io#dev_page_content:~:text=Other%20apps%20ignore%20the%20need%20for,before%20ever%20reaching%20a%20million%20users.">never reach a million users</a>". <a href="https://twitter.com/signalapp/status/1347240006444675072?ref=words.filippo.io">In other news</a>. <a href="#fnref1">↩︎</a> <a href="#fnref1:1">↩︎</a></p>
</li>
<li id="fn2"><p>Diffie-Hellman over finite fields is how it was originally designed, but today we'd use Elliptic-Curve Diffie-Hellman, which is faster, has smaller outputs, and is safer. FFDH has many of <a href="https://buttondown.email/cryptography-dispatches/archive/557475c5-9781-47e0-a640-5734bc849bc7?ref=words.filippo.io">the same issues as DSA</a> (FFDH is to DSA like ECDH is to ECDSA and EdDSA.) Current-day MTProto 2.0 still uses FFDH, but that's far from the most anachronistic choice in it. <a href="#fnref2">↩︎</a></p>
</li>
<li id="fn3"><p>This is admittedly not a particularly strong authentication strategy, but it relies on the assumption that even if 1% of users check their fingerprints, systematic PitM is likely to be detected, and high-risk users can be extra careful and consistently check fingerprints. I hope solutions like key transparency can improve this picture in the coming years without changing the default UX. <a href="#fnref3">↩︎</a></p>
</li>
<li id="fn4"><p>Can we talk about how cool the Wayback Machine Compare feature is? Now is a good time to <a href="https://archive.org/donate/">donate to the Internet Archive</a>, by the way. <a href="#fnref4">↩︎</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->
        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wprs – rootless remote desktop for Wayland (and X11, via XWayland) applications (113 pts)]]></title>
            <link>https://github.com/wayland-transpositor/wprs</link>
            <guid>40313798</guid>
            <pubDate>Thu, 09 May 2024 23:02:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/wayland-transpositor/wprs">https://github.com/wayland-transpositor/wprs</a>, See on <a href="https://news.ycombinator.com/item?id=40313798">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">wprs</h2><a id="user-content-wprs" aria-label="Permalink: wprs" href="#wprs"></a></p>
<p dir="auto">Like <a href="https://en.wikipedia.org/wiki/Xpra" rel="nofollow">xpra</a>, but for Wayland, and written in
Rust.</p>
<p dir="auto">wprs implements rootless remote desktop access for remote Wayland (and X11, via
XWayland) applications.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building</h2><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<p dir="auto"><code>cargo build --profile=release-lto  # or release, but debug is unusably slow</code></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">On the remote host, enable wprsd:</p>
<div dir="auto" data-snippet-clipboard-copy-content="loginctl enable-linger
systemctl --user enable wprsd.service
systemctl --user start wprsd.service"><pre>loginctl enable-linger
systemctl --user <span>enable</span> wprsd.service
systemctl --user start wprsd.service</pre></div>
<p dir="auto">On the local host:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# starts application on the remote host (starts ssh connection, forwards sockets, starts wprsc, runs application)
wprs <remote_host> run <application>

# stops local wprs connections, leaving remote session running (tear down ssh connection and forwarded sockets, stops wprsc)
wprs <remote_host> detach

# attaches to remote wprs session (starts ssh connection, forwards sockets, starts wprsc)
wprs <remote_host> attach"><pre><span><span>#</span> starts application on the remote host (starts ssh connection, forwards sockets, starts wprsc, runs application)</span>
wprs <span>&lt;</span>remote_host<span>&gt;</span> run <span>&lt;</span>application<span>&gt;</span>

<span><span>#</span> stops local wprs connections, leaving remote session running (tear down ssh connection and forwarded sockets, stops wprsc)</span>
wprs <span>&lt;</span>remote_host<span>&gt;</span> detach

<span><span>#</span> attaches to remote wprs session (starts ssh connection, forwards sockets, starts wprsc)</span>
wprs <span>&lt;</span>remote_host<span>&gt;</span> attach</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">System Tuning</h2><a id="user-content-system-tuning" aria-label="Permalink: System Tuning" href="#system-tuning"></a></p>
<p dir="auto">Increasing linux's socket buffer limits as described in
<a href="https://wiki.archlinux.org/title/sysctl#Increase_the_memory_dedicated_to_the_network_interfaces" rel="nofollow">https://wiki.archlinux.org/title/sysctl#Increase_the_memory_dedicated_to_the_network_interfaces</a>
will result in improved performance.</p>
<p dir="auto">TODO: test ssh socket forwarding performance with different values of
wmem_default. wprs uses setsockopt to increase its buffer size, but it doesn't
seem that ssh does.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration Files</h2><a id="user-content-configuration-files" aria-label="Permalink: Configuration Files" href="#configuration-files"></a></p>
<p dir="auto">You can create configuration files for <code>wprsc</code> and <code>wprsd</code> instead of passing additional
arguments to <code>wprs</code>. To see what options are available, run <code>wprsc --help</code> and
<code>wprsd --help</code>.</p>
<p dir="auto">To generate the default configs, run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# on your local machine
wprsc --print-default-config-and-exit=true > ~/.config/wprs/wprsc.ron"><pre><span><span>#</span> on your local machine</span>
wprsc --print-default-config-and-exit=true <span>&gt;</span> <span>~</span>/.config/wprs/wprsc.ron</pre></div>
<p dir="auto">and</p>
<div dir="auto" data-snippet-clipboard-copy-content="# on your remote machine
wprsd --print-default-config-and-exit=true > ~/.config/wprs/wprsd.ron"><pre><span><span>#</span> on your remote machine</span>
wprsd --print-default-config-and-exit=true <span>&gt;</span> <span>~</span>/.config/wprs/wprsd.ron</pre></div>
<p dir="auto">Then update the <code>wprsc.ron</code> and <code>wprsd.ron</code> files with your desired settings.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Current Limitations</h2><a id="user-content-current-limitations" aria-label="Permalink: Current Limitations" href="#current-limitations"></a></p>
<p dir="auto">Currently only the the Core and XDG shell protocols are implemented. In
particular, hardware rendering/dmabuf support is not yet implemented.</p>
<ul dir="auto">
<li>Damage passthough is not yet implemented.</li>
<li>Touch event support is not yet implemented.</li>
<li>Drag-and-drop may be wonky in some cases.</li>
<li>XWayland drag-and-drop is not (yet?) implemented.</li>
<li>webauthn security keys don't yet work in browsers</li>
</ul>
<p dir="auto">Generally, wprs will aim to support as many protocols as feasible, it's a
question of time and prioritization.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<p dir="auto">On the remote (server) side, <code>wprsd</code> implements a wayland compositor using
<a href="https://github.com/Smithay/smithay">Smithay</a>. Instead of compositing and
rendering though, wprsd serializes the state of the wayland session and sends it
to the connected wprsc client using a custom protocol.</p>
<p dir="auto">On the local (client) side, <code>wprsc</code> implements a wayland client (using the
<a href="https://github.com/Smithay/client-toolkit">Smithay Client Toolkit</a> that creates
local wayland objects that correspond to remote wayland objects. For example, if
a remote application running against wprsd creates a surface and an
xdg-toplevel, wprsc will create a surface with the same contents, an
xdg-toplevel with the same metadata, etc.. From the local compositor's point of
view, wprsc is just a normal application with a bunch of windows. Input and
other events from the local compositor that wprsc are serialized and sent to
wprsd, which forwards them to the appropriate application (the owner of the
surface which the wprsc surface which received the events corresponds to).</p>
<p dir="auto">wprs supports session resumption (wprsc disconnection and later reconnection and
wprsc restarts). The wayland protocol is not natively resumable in this way
because it relies on shared state between the compositor and client
applications. By implementing a wayland compositor locally relative to the
application, wprsd stores all state necessary for wayland applications and is
also able to store sufficient state (e.g., the buffer contents for each surface
as of the last commit) for a newly-connected wprsc to correctly set up all
necessary wayland objects. wprsc is stateless, but wprsd is not, so a wprsd
restart will still terminate all wayland applications running against it, like
with any other wayland compositor.</p>
<p dir="auto">Communication between wprsd and wprsc happens over unix domain sockets; wprsd
creates a socket and wprsc connects to it. The default mode of operation is to,
on the client side, use ssh to forward a local socket to the remote wprsd
socket, but a different transport could be used with, for example, socat or a
custom proxy application. A launcher script (<code>wprs</code>) is provided which sets up
the ssh socket forwarding.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Protocol</h3><a id="user-content-protocol" aria-label="Permalink: Protocol" href="#protocol"></a></p>
<p dir="auto">The custom protocol used to serialize and transmit wayland state between wprsc
and wprsd is a simplified version of the wayland protocol. Wayland objects are
represented as rust types and serialized using
<a href="https://github.com/rkyv/rkyv">rkyv</a>. Unlike the wayland protocol, the wprs
protocol tries to be idempotent when possible. For example, instead of the
repeated back-and-forth involved in created a surface, creating an xdg-surface,
creating an xdg-toplevel, waiting for it to be configured, creating a buffer,
attaching the buffer, and comitting it, wprsd will send a single commit message
to wprsc with the complete state of the surface (surface's attached buffer
contents (if any), its role (if any) and any associated metadata, etc.) and
wprsc will execute the appropriate dance with the local compositor.</p>
<p dir="auto">Frame callbacks are scheduled locally by wprsd at the configured framerate, they
are not forwarded from wprsc as that would introduce an unacceptable amount of
frame latency due to network round-trips. When no wprsc is connected, wprsd
pauses sending frame callbacks to wayland applications.</p>
<p dir="auto">Buffer compression is handled using a custom multithreaded and SIMD-accelerated
lossless image compression algorithm:</p>
<ol dir="auto">
<li>Transpose the image from an <a href="https://en.wikipedia.org/wiki/AoS_and_SoA" rel="nofollow">array of structures to a struct of
arrays</a>. This makes the subequent
steps significantly faster by letting them be implemented with SIMD
instructions and additionally improves the compression ratio because each
color channel is more closely spatially correlated with itself than with the
other
channels.</li>
<li>Apply an adjacent (wrapping) difference to each color channel (differential
pulse-code modulation). This improves the compression ratio by taking
advantage of spatial correlation and transforms (for example) a solid-colored
line into a single color byte and then a sequence of 0-bytes, or a gradient
into a sequence of 1-bytes, etc.</li>
<li>Transform each color channel into a
<a href="https://en.wikipedia.org/wiki/Y%E2%80%B2UV" rel="nofollow">YUV</a>-like color space: <code>y := g, u := b - g, v := r - g, a := a</code>. This improves the compression ratio in a
similar way as the previous step but by taking advantage of cross-color
correlation.</li>
<li>Compress the data with zstd.
This algorithm was designed for reasonably good compression ratios while being
extremely last: single-digit milliseconds per frame. Decompression is done by
inverting those steps.</li>
</ol>
<p dir="auto">This protocol is <em>not stable</em>: there is no guarantee that different versions of
wprsc and wprsd, or wprsc and wprsd built with different versions of
dependencies or even rustc will be compatible. This may change in the future,
but it will not happen soon.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Comparison to Waypipe</h3><a id="user-content-comparison-to-waypipe" aria-label="Permalink: Comparison to Waypipe" href="#comparison-to-waypipe"></a></p>
<p dir="auto"><a href="https://gitlab.freedesktop.org/mstoeckl/waypipe" rel="nofollow">Waypipe</a>'s model is analogous
to X forwarding, while wprs's model is analgous to Xpra. Waypipe ~transparently
forwards messages between the local compositor and the remote application, so
the client ends up being stateful and sessions can only be resumed through
network reconnections, not client restarts. There are tradeoffs to the two
approaches. Waypipe's approach is partially forward-compatible: it can support
new wayland protocols automatically, however those protocols may be broken if
they use shared resources in a way that waypipe doesn't know how to handle.
wprs, on the other hand, requires explicit implementation for every wayland
protocol.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">XWayland</h3><a id="user-content-xwayland" aria-label="Permalink: XWayland" href="#xwayland"></a></p>
<p dir="auto">XWayland support is implemented as a separate binary, <code>xwayland-xdg-shell</code>. The
binary implements a wayland compositor (but only for the protocol features used
by xwayland) and client, just like wprsd and wprsc, but in a single binary (so
skipping the serialization/deserialization). This is the same model as
<a href="https://github.com/talex5/wayland-proxy-virtwl#xwayland-support">xwayland-proxy-virtwl</a>,
which is itself inspired by
<a href="https://chromium.googlesource.com/chromiumos/platform2/+/main/vm_tools/sommelier/" rel="nofollow">sommelier</a>.
xwayland-xdg-shell was primarily written (instead of just using
xwayland-proxy-virtwl) so as to share a common design/codebase with wprs and to
make use of common wayland development in the form of Smithay and its wayland
crates. Additionally, xwayland-xdg-shell is more narrowly focused and its sole
purpose is xwayland support, not virtio-gpu or virtwl.</p>
<p dir="auto">Like xwayland-proxy-virtwl, xwayland-xdg-proxy can be used to implement external
xwayland support for any wayland compositor instead of re-implementing it inside
the compositor. Aside from eliminating the need to implement xwayland support in
every compositor, this approach has been reported to result in better xwayland
scaling than native xwayland support in some compositor, and it allows xwayland
applications to be treated more like regular wayland applications instead of
getting special access.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Security</h3><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto">wprsd is a wayland compositor, so it has access to all surfaces displayed by
applications running against it and it can inject input into them. Any process
which implements the wprs protocol and connects to the wprs socket will have the
same access. For that reason, the wprs socket is created in a directory which
only the user has access to ($XDG_RUNTIME_DIR) and the socket itself is only
readable/writable by the user. Malicious applications running as the same user
as wprsd can still access this socket, but at that point you have bigger
problems.</p>
<p dir="auto">wprs does not do any auth of its own, it relies entirely on whatever transport
is being used (ssh, in the default case).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Thanks</h2><a id="user-content-thanks" aria-label="Permalink: Thanks" href="#thanks"></a></p>
<p dir="auto">Huge thanks to the following excellent projects for making this project
significantly easier than it otherwise would have been:</p>
<ul dir="auto">
<li><a href="https://github.com/Smithay">Smithay</a></li>
<li><a href="https://github.com/rkyv/rkyv">rkyv</a></li>
<li><a href="https://github.com/tokio-rs/tracing">tracing</a></li>
<li><a href="https://github.com/wolfpld/tracy">Tracy</a></li>
</ul>
<p dir="auto">Thanks to <a href="https://gitlab.freedesktop.org/mstoeckl/waypipe" rel="nofollow">Waypipe</a> and
<a href="https://github.com/talex5/wayland-proxy-virtwl#xwayland-support">xwayland-proxy-virtwl</a>
for paving the way in this problem space.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple apologizes for iPad 'Crush' ad that 'missed the mark' (263 pts)]]></title>
            <link>https://www.theverge.com/2024/5/9/24153113/apple-ipad-ad-crushing-apology</link>
            <guid>40313733</guid>
            <pubDate>Thu, 09 May 2024 22:50:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/5/9/24153113/apple-ipad-ad-crushing-apology">https://www.theverge.com/2024/5/9/24153113/apple-ipad-ad-crushing-apology</a>, See on <a href="https://news.ycombinator.com/item?id=40313733">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Apple has apologized after a commercial meant to showcase its <a href="https://www.theverge.com/24151128/apple-ipad-pro-2024-hands-on">brand-new iPad Pro</a> drew widespread criticism among the creative community. In a statement <a href="https://adage.com/article/digital-marketing-ad-tech-news/apple-apologizes-ipad-pro-crushed-ad-it-missed-mark/2559321">provided to <em>Ad Age</em></a>, Tor Myhren, Apple’s vice president of marketing, said the company “missed the mark.”</p><p>“Creativity is in our DNA at Apple, and it’s incredibly important to us to design products that empower creatives all over the world,” Myhren told <em>Ad Age</em>. “Our goal is to always celebrate the myriad of ways users express themselves and bring their ideas to life through iPad. We missed the mark with this video, and we’re sorry.”</p><p>On Tuesday, Apple introduced the <a href="https://www.theverge.com/24151128/apple-ipad-pro-2024-hands-on">M4-powered iPad Pro</a>, which the company described as its thinnest product ever. To advertise all the creative possibilities with the iPad, it released a “Crush!” commercial that shows things like a piano, record player, paint, and other works flattening under the pressure of a hydraulic press. At the end, only one thing remains: an iPad Pro.</p><p>The ad rubbed some creatives the wrong way. Hugh Grant <a href="https://twitter.com/HackedOffHugh/status/1788183871504204257">called it</a> a “destruction of human experience,” while <em>Handmaid’s Tale</em> director Reed Morano <a href="https://twitter.com/reedmorano/status/1788298509780685261">told Apple CEO</a> Tim Cook to “read the room” in a post on X. Apple didn’t immediately respond to <em>The Verge</em>’s request for comment.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The world has probably passed peak pollution (157 pts)]]></title>
            <link>https://www.sustainabilitybynumbers.com/p/peak-pollution</link>
            <guid>40313451</guid>
            <pubDate>Thu, 09 May 2024 22:11:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sustainabilitybynumbers.com/p/peak-pollution">https://www.sustainabilitybynumbers.com/p/peak-pollution</a>, See on <a href="https://news.ycombinator.com/item?id=40313451">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>The health impacts of air pollution are often underrated. There are a </span><a href="https://ourworldindata.org/data-review-air-pollution-deaths" rel="">range of estimates</a><span> for how many people die prematurely from local air pollution every year.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-144199988" href="https://www.sustainabilitybynumbers.com/p/peak-pollution#footnote-1-144199988" target="_self" rel="">1</a></span><span> All are in the low millions. The World Health Organization </span><a href="https://www.who.int/health-topics/air-pollution" rel="">estimates around</a><span> 7 million.</span></p><p>The good news, then, is that the world is probably passed “peak pollution”. I say “probably” because confidently declaring a peak is, apparently, the best way to make sure it doesn’t happen.</p><p><span>Here, I’m talking specifically about emissions of harmful </span><em>local</em><span> air pollutants: gases like nitrogen oxides (NOx), sulphur dioxide which causes acid rain, carbon monoxide, black carbon, organic carbon, non-methane volatile organic compounds. I’m not talking about greenhouse gases.</span></p><p><span>The </span><a href="https://github.com/JGCRI/CEDS/tree/master" rel="">Community Emissions Data System (CEDS)</a><span> recently extended its long-term dataset on emissions of air pollutants up to the end of 2022.</span></p><p><span>I updated this data in our explorer tool </span><a href="https://ourworldindata.org/explorers/air-pollution" rel="">on Our World in Data</a><span> (where you can explore the trends by country).</span></p><p>What’s striking is that emissions appear to have peaked for all of these pollutants, with the exception of ammonia, which is almost entirely produced by agriculture. Organic carbon and NMVOCs are not quite out of the clear yet, but might not reach their previous peaks again.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8407a523-3c57-4fd2-a5a5-43c092800f6e_1600x1130.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8407a523-3c57-4fd2-a5a5-43c092800f6e_1600x1130.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8407a523-3c57-4fd2-a5a5-43c092800f6e_1600x1130.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8407a523-3c57-4fd2-a5a5-43c092800f6e_1600x1130.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8407a523-3c57-4fd2-a5a5-43c092800f6e_1600x1130.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8407a523-3c57-4fd2-a5a5-43c092800f6e_1600x1130.png" width="1456" height="1028" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8407a523-3c57-4fd2-a5a5-43c092800f6e_1600x1130.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1028,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8407a523-3c57-4fd2-a5a5-43c092800f6e_1600x1130.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8407a523-3c57-4fd2-a5a5-43c092800f6e_1600x1130.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8407a523-3c57-4fd2-a5a5-43c092800f6e_1600x1130.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8407a523-3c57-4fd2-a5a5-43c092800f6e_1600x1130.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Of course, emissions are not falling everywhere. They’ve fallen steeply in richer countries like the US and much of Europe. And the big turning point for the global figures has been the rapid turnaround in China. Emissions have declined rapidly in the last decade, with huge gains for public health.</p><p><span>It’s in low and lower-middle income countries where emissions are still rising, and pollution levels in cities are the highest. This is not surprising: air pollution is one of the few areas where the “</span><a href="https://en.wikipedia.org/wiki/Kuznets_curve#Environmental_Kuznets_curve" rel="">Environmental Kuznets Curve</a><span>” tells a pretty accurate and consistent story.</span></p><p>Air pollution increases as countries develop, gain access to energy, and industrialise. They then fall once a country gets rich enough to impose pollution standards and limits without infringing on development and the move away from energy poverty.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463777f7-346d-40ca-94da-d0f2027445c0_1600x1130.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463777f7-346d-40ca-94da-d0f2027445c0_1600x1130.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463777f7-346d-40ca-94da-d0f2027445c0_1600x1130.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463777f7-346d-40ca-94da-d0f2027445c0_1600x1130.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463777f7-346d-40ca-94da-d0f2027445c0_1600x1130.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463777f7-346d-40ca-94da-d0f2027445c0_1600x1130.png" width="1456" height="1028" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/463777f7-346d-40ca-94da-d0f2027445c0_1600x1130.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1028,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463777f7-346d-40ca-94da-d0f2027445c0_1600x1130.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463777f7-346d-40ca-94da-d0f2027445c0_1600x1130.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463777f7-346d-40ca-94da-d0f2027445c0_1600x1130.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F463777f7-346d-40ca-94da-d0f2027445c0_1600x1130.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The goal now is to see if countries can move through this curve much faster – and with lower levels of pollution – than countries like the US or the UK did. This should be doable: we’ve learned a lot over the last 50 years about how to produce energy with less pollution, what technologies work and don’t work, and have reduced the costs of solutions that were expensive in their early days.</p><p><span>Note that this is not a finger-pointing exercise where rich countries tell poorer ones not to pollute. We’re mostly talking about </span><em>local</em><span> air pollution. The negative impacts of pollution are felt by domestic populations. It’s about how we ensure that the poorest countries can gain access to energy, alleviate poverty, and develop while limiting the number of people who die prematurely from air pollution in the process.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cubic millimetre of brain mapped in spectacular detail (151 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-024-01387-9</link>
            <guid>40313193</guid>
            <pubDate>Thu, 09 May 2024 21:36:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-024-01387-9">https://www.nature.com/articles/d41586-024-01387-9</a>, See on <a href="https://news.ycombinator.com/item?id=40313193">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>Researchers have mapped a tiny piece of the human brain in astonishing detail. The resulting cell atlas, which was described today in <i>Science</i><sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup> and is <a href="https://h01-release.storage.googleapis.com/data.html" data-track="click" data-label="https://h01-release.storage.googleapis.com/data.html" data-track-category="body text link">available online</a>, reveals new patterns of connections between brain cells called neurons, as well as cells that wrap around themselves to form knots, and pairs of neurons that are almost mirror images of each other.</p><p>The 3D map covers a volume of about one cubic millimetre, one-millionth of a whole brain, and contains roughly 57,000 cells and 150 million synapses — the connections between neurons. It incorporates a colossal 1.4 petabytes of data. “It’s a little bit humbling,” says Viren Jain, a neuroscientist at Google in Mountain View, California, and a co-author of the paper. “How are we ever going to really come to terms with all this complexity?”</p><h2>Slivers of brain</h2><p>The brain fragment was taken from a 45-year-old woman when she underwent surgery to treat her epilepsy. It came from the cortex, a part of the brain involved in learning, problem-solving and processing sensory signals. The sample was immersed in preservatives and stained with heavy metals to make the cells easier to see. Neuroscientist Jeff Lichtman at Harvard University in Cambridge, Massachusetts, and his colleagues then cut the sample into around 5,000 slices — each just 34 nanometres thick — that could be imaged using electron microscopes.</p><p>Jain’s team then built artificial-intelligence models that were able to stitch the microscope images together to reconstruct the whole sample in 3D. “I remember this moment, going into the map and looking at one individual synapse from this woman’s brain, and then zooming out into these other millions of pixels,” says Jain. “It felt sort of spiritual.”</p><figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-024-01387-9/d41586-024-01387-9_27068610.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-024-01387-9/d41586-024-01387-9_27068610.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="Rendering of a neuron with a round base and many branches, on a black background." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-024-01387-9/d41586-024-01387-9_27068610.jpg">
  <figcaption>
   <p><span>A single neuron (white) shown with 5,600 of the axons (blue) that connect to it. The synapses that make these connections are shown in green.</span><span>Credit: Google Research &amp; Lichtman Lab (Harvard University). Renderings by D. Berger (Harvard University)</span></p>
  </figcaption>
 </picture>
</figure><p>When examining the model in detail, the researchers discovered unconventional neurons, including some that made up to 50 connections with each other. “In general, you would find a couple of connections at most between two neurons,” says Jain. Elsewhere, the model showed neurons with tendrils that formed knots around themselves. “Nobody had seen anything like this before,” Jain adds.</p><p>The team also found pairs of neurons that were near-perfect mirror images of each other. “We found two groups that would send their dendrites in two different directions, and sometimes there was a kind of mirror symmetry,” Jain says. It is unclear what role these features have in the brain.</p><h2>Proofreaders needed</h2><p>The map is so large that most of it has yet to be manually checked, and it could still contain errors created by the process of stitching so many images together. “Hundreds of cells have been ‘proofread’, but that’s obviously a few per cent of the 50,000 cells in there,” says Jain. He hopes that others will help to proofread parts of the map they are interested in. The team plans to produce similar maps of brain samples from other people — but a map of the entire brain is unlikely in the next few decades, he says.</p><p>“This paper is really the tour de force creation of a human cortex data set,” says Hongkui Zeng, director of the Allen Institute for Brain Science in Seattle. The vast amount of data that has been made freely accessible will “allow the community to look deeper into the micro-circuitry in the human cortex”, she adds.</p><p>Gaining a deeper understanding of how the cortex works could offer clues about how to treat some psychiatric and neurodegenerative diseases. “This map provides unprecedented details that can unveil new rules of neural connections and help to decipher the inner working of the human brain,” says Yongsoo Kim, a neuroscientist at Pennsylvania State University in Hershey.</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sioyek is a PDF viewer with a focus on textbooks and research papers (266 pts)]]></title>
            <link>https://github.com/ahrm/sioyek</link>
            <guid>40313143</guid>
            <pubDate>Thu, 09 May 2024 21:28:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ahrm/sioyek">https://github.com/ahrm/sioyek</a>, See on <a href="https://news.ycombinator.com/item?id=40313143">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Sioyek</h2><a id="user-content-sioyek" aria-label="Permalink: Sioyek" href="#sioyek"></a></p>
<p dir="auto">Sioyek is a PDF viewer with a focus on textbooks and research papers.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contents</h2><a id="user-content-contents" aria-label="Permalink: Contents" href="#contents"></a></p>
<ul dir="auto">
<li><a href="#install">Installation</a></li>
<li><a href="#documentation">Documentation</a></li>
<li><a href="#feature-video-overview">Video Demo</a></li>
<li><a href="#features">Features</a></li>
<li><a href="#build-instructions">Build Instructions</a></li>
<li><a href="#donation">Buy Me a Coffee (or a Book!)</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Official packages</h3><a id="user-content-official-packages" aria-label="Permalink: Official packages" href="#official-packages"></a></p>
<p dir="auto">There are installers for Windows, macOS and Linux. See <a href="https://github.com/ahrm/sioyek/releases">Releases page</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Homebew Cask</h3><a id="user-content-homebew-cask" aria-label="Permalink: Homebew Cask" href="#homebew-cask"></a></p>
<p dir="auto">There is a homebrew cask available here: <a href="https://formulae.brew.sh/cask/sioyek" rel="nofollow">https://formulae.brew.sh/cask/sioyek</a>. Install by running:</p>
<div data-snippet-clipboard-copy-content="brew install --cask sioyek"><pre><code>brew install --cask sioyek
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Third-party packages for Linux</h3><a id="user-content-third-party-packages-for-linux" aria-label="Permalink: Third-party packages for Linux" href="#third-party-packages-for-linux"></a></p>
<p dir="auto">If you prefer to install sioyek with a package manager, you can look at this list. Please note that they are provided by third party packagers. USE AT YOUR OWN RISK! If you're reporting a bug for a third-party package, please mention which package you're using.</p>
<table>
<thead>
<tr>
<th>Distro</th>
<th>Link</th>
<th>Maintainer</th>
</tr>
</thead>
<tbody>
<tr>
<td>Flathub</td>
<td><a href="https://flathub.org/apps/details/com.github.ahrm.sioyek" rel="nofollow">sioyek</a></td>
<td><a href="https://flathub.org/apps/details/com.github.ahrm.sioyek" rel="nofollow">@nbenitez</a></td>
</tr>
<tr>
<td>Alpine</td>
<td><a href="https://pkgs.alpinelinux.org/packages?name=sioyek" rel="nofollow">sioyek</a></td>
<td><a href="https://github.com/jirutka">@jirutka</a></td>
</tr>
<tr>
<td>Arch</td>
<td><a href="https://aur.archlinux.org/packages/sioyek" rel="nofollow">AUR sioyek</a></td>
<td><a href="https://github.com/goggle">@goggle</a></td>
</tr>
<tr>
<td>Arch</td>
<td><a href="https://aur.archlinux.org/packages/sioyek-git/" rel="nofollow">AUR sioyek-git</a></td>
<td><a href="https://github.com/hrdl-github">@hrdl-github</a></td>
</tr>
<tr>
<td>Arch</td>
<td><a href="https://aur.archlinux.org/packages/sioyek-appimage/" rel="nofollow">AUR sioyek-appimage</a></td>
<td><a href="https://github.com/DhruvaSambrani">@DhruvaSambrani</a></td>
</tr>
<tr>
<td>Debian</td>
<td><a href="https://packages.debian.org/sioyek" rel="nofollow">sioyek</a></td>
<td><a href="https://github.com/viccie30">@viccie30</a></td>
</tr>
<tr>
<td>NixOS</td>
<td><a href="https://search.nixos.org/packages?channel=unstable&amp;show=sioyek&amp;from=0&amp;size=50&amp;sort=relevance&amp;type=packages&amp;query=sioyek" rel="nofollow">sioyek</a></td>
<td><a href="https://github.com/podocarp">@podocarp</a></td>
</tr>
<tr>
<td>openSUSE</td>
<td><a href="https://build.opensuse.org/package/show/Publishing/sioyek" rel="nofollow">Publishing</a></td>
<td><a href="https://github.com/uncomfyhalomacro">@uncomfyhalomacro</a></td>
</tr>
<tr>
<td>openSUSE</td>
<td><a href="https://build.opensuse.org/package/show/openSUSE:Factory/sioyek" rel="nofollow">Factory</a></td>
<td><a href="https://github.com/uncomfyhalomacro">@uncomfyhalomacro</a></td>
</tr>
<tr>
<td>Ubuntu</td>
<td><a href="https://packages.ubuntu.com/sioyek" rel="nofollow">sioyek</a></td>
<td><a href="https://github.com/viccie30">@viccie30</a></td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">You can view the official documentation <a href="https://sioyek-documentation.readthedocs.io/en/latest/" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feature Video Overview</h2><a id="user-content-feature-video-overview" aria-label="Permalink: Feature Video Overview" href="#feature-video-overview"></a></p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=yTmCI0Xp5vI" rel="nofollow"><img src="https://camo.githubusercontent.com/3bbdb00658bc336a5da25c541e8141b7d38738232eba44310c960639633bb396/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f79546d43493058703576492f302e6a7067" alt="Sioyek feature overview" data-canonical-src="https://img.youtube.com/vi/yTmCI0Xp5vI/0.jpg"></a></p>
<p dir="auto">For a more in-depth tutorial, see this video:</p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=RaHRvnb0dY8" rel="nofollow"><img src="https://camo.githubusercontent.com/b1817153034c5bf93e9b14a37292ae3bf2e949d900169928f9720ece7832d452/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f52614852766e62306459382f302e6a7067" alt="Sioyek Tutorial" data-canonical-src="https://img.youtube.com/vi/RaHRvnb0dY8/0.jpg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Quick Open</h3><a id="user-content-quick-open" aria-label="Permalink: Quick Open" href="#quick-open"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description recent_docs.mp4">recent_docs.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/6392321/125321111-9b29dc00-e351-11eb-873e-94ea30016a05.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEyNTMyMTExMS05YjI5ZGMwMC1lMzUxLTExZWItODczZS05NGVhMzAwMTZhMDUubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9M2I5NGE4NzVlMDQ4NjA4YjRmZjFkNzUzODVkZWVmMzMwNTYwZDU2Y2Y2ZmZjNWM3ZjUzNmM4MjExNzg0OWI0YiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.CgEbCL-dJokkAf-td825PN-E02l_-7J2M1w6T2cQgIo" data-canonical-src="https://private-user-images.githubusercontent.com/6392321/125321111-9b29dc00-e351-11eb-873e-94ea30016a05.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEyNTMyMTExMS05YjI5ZGMwMC1lMzUxLTExZWItODczZS05NGVhMzAwMTZhMDUubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9M2I5NGE4NzVlMDQ4NjA4YjRmZjFkNzUzODVkZWVmMzMwNTYwZDU2Y2Y2ZmZjNWM3ZjUzNmM4MjExNzg0OWI0YiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.CgEbCL-dJokkAf-td825PN-E02l_-7J2M1w6T2cQgIo" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">You can quickly search and open any file you have previously interacted with using sioyek.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Table of Contents</h3><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description toc.mp4">toc.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/6392321/125321313-cf050180-e351-11eb-9275-c2759c684af5.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEyNTMyMTMxMy1jZjA1MDE4MC1lMzUxLTExZWItOTI3NS1jMjc1OWM2ODRhZjUubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OTZhOGM4NmVhNGQyOWE4MTZjYTllMjhkZDBiN2FlOGUwOGU0MjlkYmVmODk1NGJhMmZiODA1NTM3MWIyMDBmYiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.e26EJM2s5-akKXn_7bEAC91YYYBtavP0lVelx94xGT8" data-canonical-src="https://private-user-images.githubusercontent.com/6392321/125321313-cf050180-e351-11eb-9275-c2759c684af5.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEyNTMyMTMxMy1jZjA1MDE4MC1lMzUxLTExZWItOTI3NS1jMjc1OWM2ODRhZjUubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OTZhOGM4NmVhNGQyOWE4MTZjYTllMjhkZDBiN2FlOGUwOGU0MjlkYmVmODk1NGJhMmZiODA1NTM3MWIyMDBmYiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.e26EJM2s5-akKXn_7bEAC91YYYBtavP0lVelx94xGT8" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">You can search and jump to table of contents entries.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Smart Jump</h3><a id="user-content-smart-jump" aria-label="Permalink: Smart Jump" href="#smart-jump"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description jump.mp4">jump.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/6392321/125321419-e5ab5880-e351-11eb-9688-95374a22774f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEyNTMyMTQxOS1lNWFiNTg4MC1lMzUxLTExZWItOTY4OC05NTM3NGEyMjc3NGYubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YzhjYjZjZjQ1ZGU5OTlhNTFkZjU1NjJiNjk1ZjIyYWYzMTA2M2EyNDBmNzE3M2FlZjZjMDJiMzhlNDQxNDlmOCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.mcFpCPbTqmL1-BVLl5ZJ4LzElUkQRX-sk34sPf8c3OY" data-canonical-src="https://private-user-images.githubusercontent.com/6392321/125321419-e5ab5880-e351-11eb-9688-95374a22774f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEyNTMyMTQxOS1lNWFiNTg4MC1lMzUxLTExZWItOTY4OC05NTM3NGEyMjc3NGYubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YzhjYjZjZjQ1ZGU5OTlhNTFkZjU1NjJiNjk1ZjIyYWYzMTA2M2EyNDBmNzE3M2FlZjZjMDJiMzhlNDQxNDlmOCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.mcFpCPbTqmL1-BVLl5ZJ4LzElUkQRX-sk34sPf8c3OY" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">You can jump to any referenced figure or bibliography item <em>even if the PDF file doesn't provide links</em>. You can also search the names of bibliography items in google scholar/libgen by middle clicking/shift+middle clicking on their name.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Overview</h3><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description overview.mp4">overview.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/6392321/154683015-0bae4f92-78e2-4141-8446-49dd7c2bd7c9.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzE1NDY4MzAxNS0wYmFlNGY5Mi03OGUyLTQxNDEtODQ0Ni00OWRkN2MyYmQ3YzkubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OGJhYTQ1ZmI0M2JiMDU4MDZmMDY0ZGMxMjZiNjg4NWE0OGNlMzJmMGNjYzk0NzgxOTBhYzVhZTJhMzFjYTIxMyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.73JERWG0v6CTuvhWn5BzMFMGTGWOqNXl7OgjBWog3Cg" data-canonical-src="https://private-user-images.githubusercontent.com/6392321/154683015-0bae4f92-78e2-4141-8446-49dd7c2bd7c9.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzE1NDY4MzAxNS0wYmFlNGY5Mi03OGUyLTQxNDEtODQ0Ni00OWRkN2MyYmQ3YzkubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OGJhYTQ1ZmI0M2JiMDU4MDZmMDY0ZGMxMjZiNjg4NWE0OGNlMzJmMGNjYzk0NzgxOTBhYzVhZTJhMzFjYTIxMyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.73JERWG0v6CTuvhWn5BzMFMGTGWOqNXl7OgjBWog3Cg" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">You can open a quick overview of figures/references/tables/etc. by right clicking on them (Like Smart Jump, this feature works even if the document doesn't provide links).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mark</h3><a id="user-content-mark" aria-label="Permalink: Mark" href="#mark"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description mark.mp4">mark.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/6392321/125321811-505c9400-e352-11eb-85e0-ffc3ae5f8cb8.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEyNTMyMTgxMS01MDVjOTQwMC1lMzUyLTExZWItODVlMC1mZmMzYWU1ZjhjYjgubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MzlhZjA5YzFlOGYwNjIyMTUwMTY2YmU5ZTdmM2JhOWRiYWY5NjY0ZDljNWJjZTc0OGRhNTY5NjI0YmRjODEyNSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.AmelCLzLeOa-CMTR1mZdOh2LpzR787V2c46m0RFUDRI" data-canonical-src="https://private-user-images.githubusercontent.com/6392321/125321811-505c9400-e352-11eb-85e0-ffc3ae5f8cb8.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEyNTMyMTgxMS01MDVjOTQwMC1lMzUyLTExZWItODVlMC1mZmMzYWU1ZjhjYjgubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MzlhZjA5YzFlOGYwNjIyMTUwMTY2YmU5ZTdmM2JhOWRiYWY5NjY0ZDljNWJjZTc0OGRhNTY5NjI0YmRjODEyNSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.AmelCLzLeOa-CMTR1mZdOh2LpzR787V2c46m0RFUDRI" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Sometimes when reading a document you need to go back a few pages (perhaps to view a definition or something) and quickly jump back to where you were. You can achieve this by using marks. Marks are named locations within a PDF file (each mark has a single character name for example 'a' or 'm') which you can quickly jump to using their name. In the aforementioned example, before going back to the definition you mark your location and later jump back to the mark by invoking its name. Lower case marks are local to the document and upper case marks are global (this should be very familiar to you if you have used vim).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bookmarks</h3><a id="user-content-bookmarks" aria-label="Permalink: Bookmarks" href="#bookmarks"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description bookmarks.mp4">bookmarks.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/6392321/125322503-1a6bdf80-e353-11eb-8018-5e8fc43b8d05.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEyNTMyMjUwMy0xYTZiZGY4MC1lMzUzLTExZWItODAxOC01ZThmYzQzYjhkMDUubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MjcyZGI1Y2QzMzdlZTEwMTJkMzAyZjE5ZmVhZTEwZjkyNjY4N2YwNzBiMjdhMGFjMTA4MzA3ODhjNjM5YTM4ZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.eXA1H8apV3pXKK-90BZi2Y5BkjkJw0VeEWVkzYQ6tQ4" data-canonical-src="https://private-user-images.githubusercontent.com/6392321/125322503-1a6bdf80-e353-11eb-8018-5e8fc43b8d05.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEyNTMyMjUwMy0xYTZiZGY4MC1lMzUzLTExZWItODAxOC01ZThmYzQzYjhkMDUubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MjcyZGI1Y2QzMzdlZTEwMTJkMzAyZjE5ZmVhZTEwZjkyNjY4N2YwNzBiMjdhMGFjMTA4MzA3ODhjNjM5YTM4ZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.eXA1H8apV3pXKK-90BZi2Y5BkjkJw0VeEWVkzYQ6tQ4" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Bookmarks are similar to marks except they are named by a text string and they are all global.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Highlights</h3><a id="user-content-highlights" aria-label="Permalink: Highlights" href="#highlights"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description highlights.mp4">highlights.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/6392321/130956728-7e0a87fa-4ada-4108-a8fc-9d9d04180f56.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEzMDk1NjcyOC03ZTBhODdmYS00YWRhLTQxMDgtYThmYy05ZDlkMDQxODBmNTYubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MTk0ZThiZTZiZmU0ZjhhMzhiOTcwOGFlY2FmMzEwZTU0YmQ4MGFmYTgxYjBlY2E0MTlkYjNkNDViZThhZDI2MCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.HbkEAIDP6hnEgafwmccUAEOeyipy5fPzhHHkKfiAaGo" data-canonical-src="https://private-user-images.githubusercontent.com/6392321/130956728-7e0a87fa-4ada-4108-a8fc-9d9d04180f56.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEzMDk1NjcyOC03ZTBhODdmYS00YWRhLTQxMDgtYThmYy05ZDlkMDQxODBmNTYubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MTk0ZThiZTZiZmU0ZjhhMzhiOTcwOGFlY2FmMzEwZTU0YmQ4MGFmYTgxYjBlY2E0MTlkYjNkNDViZThhZDI2MCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.HbkEAIDP6hnEgafwmccUAEOeyipy5fPzhHHkKfiAaGo" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Highlight text using different kinds of highlights. You can search among all the highlights.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Portals (this feature is most useful for users with multiple monitors)</h3><a id="user-content-portals-this-feature-is-most-useful-for-users-with-multiple-monitors" aria-label="Permalink: Portals (this feature is most useful for users with multiple monitors)" href="#portals-this-feature-is-most-useful-for-users-with-multiple-monitors"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description portal.mp4">portal.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/6392321/125322657-41c2ac80-e353-11eb-985e-8f3ce9808f67.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEyNTMyMjY1Ny00MWMyYWM4MC1lMzUzLTExZWItOTg1ZS04ZjNjZTk4MDhmNjcubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OGMxZWU2NTNmYzdiN2NmODI1ZmQzNDcwN2E4OTUwNmY2ZmEyN2NmNDFiM2IwOTQyMjQ2NTEwZjhiZmFhMGMwYyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.tnn-Y723I7iEw-gZjhO75Rwk5mFab8XLd-BKNDCrQEE" data-canonical-src="https://private-user-images.githubusercontent.com/6392321/125322657-41c2ac80-e353-11eb-985e-8f3ce9808f67.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEyNTMyMjY1Ny00MWMyYWM4MC1lMzUzLTExZWItOTg1ZS04ZjNjZTk4MDhmNjcubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OGMxZWU2NTNmYzdiN2NmODI1ZmQzNDcwN2E4OTUwNmY2ZmEyN2NmNDFiM2IwOTQyMjQ2NTEwZjhiZmFhMGMwYyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.tnn-Y723I7iEw-gZjhO75Rwk5mFab8XLd-BKNDCrQEE" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Suppose you are reading a paragraph which references a figure which is not very close to the current location. Jumping back and forth between the current paragraph and the figure can be very annoying. Using portals, you can link the paragraph's location to the figure's location. Sioyek shows the closest portal destination in a separate window (which is usually placed on a second monitor). This window is automatically updated to show the closest portal destination as the user navigates the document.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configuration</h3><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description config.mp4">config.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/6392321/125337160-e4832700-e363-11eb-8801-0bee58121c2d.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEyNTMzNzE2MC1lNDgzMjcwMC1lMzYzLTExZWItODgwMS0wYmVlNTgxMjFjMmQubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NGE3NmViNjU3YjQxZTQ3ZTYzODEzNmY3NDIxMTE4ZmE3YTlmOWZkYjY4MThiZTc2YzJhYjNlZDFmYzZjY2I5NSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.ruxUPlLfOjuotsHBJRfFgE5VcBmMNTjluhNgVTLDRDU" data-canonical-src="https://private-user-images.githubusercontent.com/6392321/125337160-e4832700-e363-11eb-8801-0bee58121c2d.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUzMDY3MDQsIm5iZiI6MTcxNTMwNjQwNCwicGF0aCI6Ii82MzkyMzIxLzEyNTMzNzE2MC1lNDgzMjcwMC1lMzYzLTExZWItODgwMS0wYmVlNTgxMjFjMmQubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDUxMCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA1MTBUMDIwMDA0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NGE3NmViNjU3YjQxZTQ3ZTYzODEzNmY3NDIxMTE4ZmE3YTlmOWZkYjY4MThiZTc2YzJhYjNlZDFmYzZjY2I5NSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.ruxUPlLfOjuotsHBJRfFgE5VcBmMNTjluhNgVTLDRDU" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">You can customize all key bindings and some UI elements by editing <code>keys_user.config</code> and <code>prefs_user.config</code>. The default configurations are in <code>keys.config</code> and <code>prefs.config</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build Instructions</h2><a id="user-content-build-instructions" aria-label="Permalink: Build Instructions" href="#build-instructions"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Linux</h3><a id="user-content-linux" aria-label="Permalink: Linux" href="#linux"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Fedora</h4><a id="user-content-fedora" aria-label="Permalink: Fedora" href="#fedora"></a></p>
<p dir="auto">Run the following commands to install dependencies, clone the repository and compile sioyek on Fedora (tested on Fedora Workstation 36).</p>
<div data-snippet-clipboard-copy-content="sudo dnf install qt5-qtbase-devel qt5-qtbase-static qt5-qt3d-devel harfbuzz-devel
git clone --recursive https://github.com/ahrm/sioyek
cd sioyek
./build_linux.sh"><pre><code>sudo dnf install qt5-qtbase-devel qt5-qtbase-static qt5-qt3d-devel harfbuzz-devel
git clone --recursive https://github.com/ahrm/sioyek
cd sioyek
./build_linux.sh
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Generic distribution</h4><a id="user-content-generic-distribution" aria-label="Permalink: Generic distribution" href="#generic-distribution"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Install Qt 5 and make sure <code>qmake</code> is in <code>PATH</code>.</p>
<p dir="auto">Run <code>qmake --version</code> to make sure the <code>qmake</code> in path is using Qt 5.x.</p>
</li>
<li>
<p dir="auto">Install <code>libharfbuzz</code>:</p>
</li>
</ol>
<div data-snippet-clipboard-copy-content="sudo apt install libharfbuzz-dev"><pre><code>sudo apt install libharfbuzz-dev
</code></pre></div>
<ol start="3" dir="auto">
<li>Clone the repository and build:</li>
</ol>
<div data-snippet-clipboard-copy-content="git clone --recursive https://github.com/ahrm/sioyek
cd sioyek
./build_linux.sh"><pre><code>git clone --recursive https://github.com/ahrm/sioyek
cd sioyek
./build_linux.sh
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Windows</h3><a id="user-content-windows" aria-label="Permalink: Windows" href="#windows"></a></p>
<ol dir="auto">
<li>Install Visual Studio (tested on 2019, other relatively recent versions should work too)</li>
<li>Install Qt 5 and make sure qmake is in <code>PATH</code>.</li>
<li>Clone the repository and build using 64 bit Visual Studio Developer Command Prompt:</li>
</ol>
<div data-snippet-clipboard-copy-content="git clone --recursive https://github.com/ahrm/sioyek
cd sioyek
build_windows.bat"><pre><code>git clone --recursive https://github.com/ahrm/sioyek
cd sioyek
build_windows.bat
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mac</h3><a id="user-content-mac" aria-label="Permalink: Mac" href="#mac"></a></p>
<ol dir="auto">
<li>Install Xcode.</li>
<li>Clone the repository and build: (The code below is in Zsh, which is the default shell on macOS.)</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="(
setopt PIPE_FAIL PRINT_EXIT_VALUE ERR_RETURN SOURCE_TRACE XTRACE

git clone --recursive https://github.com/ahrm/sioyek
cd sioyek
chmod +x build_mac.sh

brew install 'qt@5' freeglut mesa harfbuzz

export PATH=&quot;/opt/homebrew/opt/qt@5/bin:$PATH&quot;
#: The above is needed to make =qmake= from =qt= be found.
#: Find the path using =brew info 'qt@5'=.

MAKE_PARALLEL=8 ./build_mac.sh

mv build/sioyek.app /Applications/
sudo codesign --force --sign - --deep /Applications/sioyek.app
)"><pre>(
setopt PIPE_FAIL PRINT_EXIT_VALUE ERR_RETURN SOURCE_TRACE XTRACE

git clone --recursive https://github.com/ahrm/sioyek
<span>cd</span> sioyek
chmod +x build_mac.sh

brew install <span><span>'</span>qt@5<span>'</span></span> freeglut mesa harfbuzz

<span>export</span> PATH=<span><span>"</span>/opt/homebrew/opt/qt@5/bin:<span>$PATH</span><span>"</span></span>
<span><span>#</span>: The above is needed to make =qmake= from =qt= be found.</span>
<span><span>#</span>: Find the path using =brew info 'qt@5'=.</span>

MAKE_PARALLEL=8 ./build_mac.sh

mv build/sioyek.app /Applications/
sudo codesign --force --sign - --deep /Applications/sioyek.app
)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Donation</h2><a id="user-content-donation" aria-label="Permalink: Donation" href="#donation"></a></p>
<p dir="auto">If you enjoy sioyek, please consider donating to support its development.</p>
<p dir="auto"><a href="https://www.buymeacoffee.com/ahrm" rel="nofollow"><img src="https://camo.githubusercontent.com/4412aa44a78a18c03862fd7da2de5bd81e3817a3adec90fdd41671170a206abd/68747470733a2f2f63646e2e6275796d6561636f666665652e636f6d2f627574746f6e732f64656661756c742d6f72616e67652e706e67" alt="Buy Me A Coffee" height="41" width="174" data-canonical-src="https://cdn.buymeacoffee.com/buttons/default-orange.png"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How bad are satellite megaconstellations for astronomy? (101 pts)]]></title>
            <link>https://www.leonarddavid.com/blinded-by-the-light-megaconstellation-clash-with-astronomical-peer-groups/</link>
            <guid>40312469</guid>
            <pubDate>Thu, 09 May 2024 20:11:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.leonarddavid.com/blinded-by-the-light-megaconstellation-clash-with-astronomical-peer-groups/">https://www.leonarddavid.com/blinded-by-the-light-megaconstellation-clash-with-astronomical-peer-groups/</a>, See on <a href="https://news.ycombinator.com/item?id=40312469">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<div id="attachment_41665"><p><a href="https://www.leonarddavid.com/wp-content/uploads/2024/05/wait-a-minute-elevator-leonard-scaled.jpg"><img fetchpriority="high" decoding="async" aria-describedby="caption-attachment-41665" src="https://www.leonarddavid.com/wp-content/uploads/2024/05/wait-a-minute-elevator-leonard-263x350.jpg" alt="" width="263" height="350" srcset="https://www.leonarddavid.com/wp-content/uploads/2024/05/wait-a-minute-elevator-leonard-263x350.jpg 263w, https://www.leonarddavid.com/wp-content/uploads/2024/05/wait-a-minute-elevator-leonard-768x1024.jpg 768w, https://www.leonarddavid.com/wp-content/uploads/2024/05/wait-a-minute-elevator-leonard-150x200.jpg 150w, https://www.leonarddavid.com/wp-content/uploads/2024/05/wait-a-minute-elevator-leonard-1152x1536.jpg 1152w, https://www.leonarddavid.com/wp-content/uploads/2024/05/wait-a-minute-elevator-leonard-1536x2048.jpg 1536w, https://www.leonarddavid.com/wp-content/uploads/2024/05/wait-a-minute-elevator-leonard-scaled.jpg 1920w" sizes="(max-width: 263px) 100vw, 263px"></a></p><p id="caption-attachment-41665">Wait a minute.<br>Image credit: Barbara David</p></div>
<p>Over the last number of years, our planet has become encircled by Starlink, OneWeb, and other “megaconstellation” satellites.</p>
<p>Yes, the emergence of those megaconstellations offers great benefit for humanity. But in a wait-a-minute pause, there are also substantial costs, including the imposition on humankind’s ongoing and growing thirst for astronomical peering into the surrounding universe.</p>
<p>That’s the view of David Koplow, the Scott K. Ginsburg Professor of Law at Georgetown University Law Center in Washington, D.C.</p>
<div id="attachment_31178"><p><a href="https://www.leonarddavid.com/wp-content/uploads/2022/02/starlink-2.jpg"><img decoding="async" aria-describedby="caption-attachment-31178" src="https://www.leonarddavid.com/wp-content/uploads/2022/02/starlink-2-350x233.jpg" alt="" width="350" height="233" srcset="https://www.leonarddavid.com/wp-content/uploads/2022/02/starlink-2-350x233.jpg 350w, https://www.leonarddavid.com/wp-content/uploads/2022/02/starlink-2-1024x682.jpg 1024w, https://www.leonarddavid.com/wp-content/uploads/2022/02/starlink-2-200x133.jpg 200w, https://www.leonarddavid.com/wp-content/uploads/2022/02/starlink-2-768x512.jpg 768w, https://www.leonarddavid.com/wp-content/uploads/2022/02/starlink-2.jpg 1280w" sizes="(max-width: 350px) 100vw, 350px"></a></p><p id="caption-attachment-31178">Starlink constellation pass overhead near Carson National Forest, New Mexico, photographed soon after launch. &nbsp;<br>SpaceX Starlink Satellites over Carson National Forest, New Mexico, photographed soon after launch.<br>Credit: Mike Lewinsky/Creative Commons Attribution 2.0</p></div>
<p>“We are just beginning to appreciate how bad the disruption can be for land-based and space-based telescopes, and as more and more satellite overflights occur, the problems will only intensify,” Koplow told <em>Inside Outer Space</em>.</p>
<p><strong>Legal rights</strong></p>
<p>Koplow’s concerns have been voiced in several scholarly works, the titles of which underscore his qualms, such as: “<em>Large Constellations of Small Satellites: The Good, the Bad, the Ugly and the Illegal</em>,” as well as “<em>Blinded by the Light: Resolving the Conflict Between Satellite Megaconstellations and Astronomy</em>.”</p>
<div id="attachment_22571"><p><a href="https://www.leonarddavid.com/wp-content/uploads/2020/02/starlink-n.jpg"><img decoding="async" aria-describedby="caption-attachment-22571" src="https://www.leonarddavid.com/wp-content/uploads/2020/02/starlink-n-350x240.jpg" alt="" width="350" height="240" srcset="https://www.leonarddavid.com/wp-content/uploads/2020/02/starlink-n-350x240.jpg 350w, https://www.leonarddavid.com/wp-content/uploads/2020/02/starlink-n-1024x703.jpg 1024w, https://www.leonarddavid.com/wp-content/uploads/2020/02/starlink-n-200x137.jpg 200w, https://www.leonarddavid.com/wp-content/uploads/2020/02/starlink-n-768x527.jpg 768w, https://www.leonarddavid.com/wp-content/uploads/2020/02/starlink-n.jpg 1138w" sizes="(max-width: 350px) 100vw, 350px"></a></p><p id="caption-attachment-22571">Starlink satellites visible in a mosaic of an astronomical image.<br>Courtesy of NSF’s<br>National Optical-Infrared Astronomy Research Laboratory/NSF/AURA/CTIO/DELVE)</p></div>
<p>&nbsp;“The world has mostly been assuming that the relevant international law basically allows the satellite companies to do whatever they want in space, while forcing the observatories to adapt as well as they can,” Koplow advised.&nbsp;</p>
<p>But in reality, Koplow continues, the legal regime is not so one-sided. “Astronomers also have legal rights to free use of space, and they need not stand by idly while their profession is damaged.”</p>
<p><strong>Hair on fire</strong></p>
<p>Koplow points out that in 2019 the world of optical and radio astronomy changed abruptly and massively when the first SpaceX batch of 60 Starlink satellites was lofted.</p>
<p>“Jolted by the sudden brightness of those spacecraft, and alarmed by the prospect of their legions of successors, observatories scrambled to respond,” Koplow observes.</p>
<p>They did so by studying and documenting the true dimensions of the problem, beginning to invent or conceptualize mitigation measures, and entering into discussions with SpaceX and other companies.</p>
<p>“Some astronomers see this as a true ‘hair on fire’ emergency, heralding irretrievable losses to space science; others present a more sanguine face, depicting this as yet another challenge to be surmounted in surveying a decreasingly pristine sky,” Koplow remarks.</p>
<div id="attachment_36401"><p><a href="https://www.leonarddavid.com/wp-content/uploads/2023/03/ASTRONOMY-IMAGE-ESO-scaled.jpg"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-36401" src="https://www.leonarddavid.com/wp-content/uploads/2023/03/ASTRONOMY-IMAGE-ESO-350x173.jpg" alt="" width="350" height="173" srcset="https://www.leonarddavid.com/wp-content/uploads/2023/03/ASTRONOMY-IMAGE-ESO-350x173.jpg 350w, https://www.leonarddavid.com/wp-content/uploads/2023/03/ASTRONOMY-IMAGE-ESO-1024x507.jpg 1024w, https://www.leonarddavid.com/wp-content/uploads/2023/03/ASTRONOMY-IMAGE-ESO-200x99.jpg 200w, https://www.leonarddavid.com/wp-content/uploads/2023/03/ASTRONOMY-IMAGE-ESO-768x381.jpg 768w, https://www.leonarddavid.com/wp-content/uploads/2023/03/ASTRONOMY-IMAGE-ESO-1536x761.jpg 1536w, https://www.leonarddavid.com/wp-content/uploads/2023/03/ASTRONOMY-IMAGE-ESO-2048x1015.jpg 2048w" sizes="(max-width: 350px) 100vw, 350px"></a></p><p id="caption-attachment-36401">Image credit: ESO/P. Horálek</p></div>
<p><strong>Incipient clash</strong></p>
<p>That said, the astronomical community has related that the time and the financial costs of conducting effective astronomy will rise considerably, Koplow says, “and that some important data will simply be irretrievable, with concomitant losses for science and the future exploration and use of space.”</p>
<p>In his “Blinded by the Light” treatise, Koplow describes the incipient clash between satellite megaconstellations and astronomy, assesses the relevant international and domestic legal authorities, and proposes compromise solutions to mitigate the damage.</p>
<p>“Overall, the thesis is that a better balance must be struck between these competing types of space activities,” Koplow adds, “without ceding to either a comprehensive right to proceed in disregard of the key functions of the other.”</p>
<div id="attachment_12276"><p><a href="https://www.leonarddavid.com/wp-content/uploads/2017/10/oneweb.jpg"><img loading="lazy" decoding="async" aria-describedby="caption-attachment-12276" src="https://www.leonarddavid.com/wp-content/uploads/2017/10/oneweb-350x144.jpg" alt="" width="350" height="144" srcset="https://www.leonarddavid.com/wp-content/uploads/2017/10/oneweb-350x144.jpg 350w, https://www.leonarddavid.com/wp-content/uploads/2017/10/oneweb-200x82.jpg 200w, https://www.leonarddavid.com/wp-content/uploads/2017/10/oneweb-768x316.jpg 768w, https://www.leonarddavid.com/wp-content/uploads/2017/10/oneweb-1024x421.jpg 1024w, https://www.leonarddavid.com/wp-content/uploads/2017/10/oneweb.jpg 1200w" sizes="(max-width: 350px) 100vw, 350px"></a></p><p id="caption-attachment-12276">Credit: OneWeb</p></div>
<p><strong>Voluntary measures</strong></p>
<p>Koplow acknowledges that some satellite companies have voluntarily invested considerable corporate talent and money in efforts to mitigate their interference with astronomy.&nbsp;</p>
<p>“But these voluntary measures are not adequate to solve the problem, they are not durable and reliable, and they have not been adopted by all the companies,” Koplow suggests.</p>
<p>“A stronger response is necessary,” Koplow concludes.</p>
<p>To gain access to “<em>Blinded by the Light: Resolving the Conflict Between Satellite Megaconstellations and Astronomy” </em>go to: <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4346299">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4346299</a></p>
<p><em>To review the paper “Three Things I Hate About Large Constellations of Small Satellites” </em>go to: <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4503593">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4503593</a></p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The history of 'OK' (2023) (103 pts)]]></title>
            <link>https://people.howstuffworks.com/history-ok.htm</link>
            <guid>40312434</guid>
            <pubDate>Thu, 09 May 2024 20:07:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://people.howstuffworks.com/history-ok.htm">https://people.howstuffworks.com/history-ok.htm</a>, See on <a href="https://news.ycombinator.com/item?id=40312434">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="editorial-body">

					
	
				
	
																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																																									
				


	


	<div id="page0" data-slide="0" data-track-gtm="Content">	
					<div>
<figure>
			
		
	
								
		
		
																																																								
			<picture>
				<source media="(max-width: 320px)" srcset="https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL09LLWhpc3RvcnktMS5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMyMH0sInRvRm9ybWF0IjoiYXZpZiJ9fQ==" type="image/avif"><source media="(min-width: 321px) and (max-width: 599px)" srcset="https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL09LLWhpc3RvcnktMS5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjQyMH0sInRvRm9ybWF0IjoiYXZpZiJ9fQ==" type="image/avif"><source media="(min-width: 600px)" srcset="https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL09LLWhpc3RvcnktMS5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjgyOH0sInRvRm9ybWF0IjoiYXZpZiJ9fQ==" type="image/avif">
				<source media="(max-width: 320px)" srcset="https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL09LLWhpc3RvcnktMS5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMyMH19fQ=="><source media="(min-width: 321px) and (max-width: 599px)" srcset="https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL09LLWhpc3RvcnktMS5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjQyMH19fQ=="><source media="(min-width: 600px)" srcset="https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL09LLWhpc3RvcnktMS5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjgyOH19fQ==">
				<img src="https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL09LLWhpc3RvcnktMS5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjgyOH19fQ==" alt="OK word" width="828" height="465">
			</picture>
			

		
	

					
	
	<figcaption>
											The spread of "OK" shows how important an all-purpose word can be. <span>Foxys Graphic/Shutterstock</span>
								</figcaption>

	</figure>
	</div>
	





	
		<p>"OK" is probably the <a href="https://www.npr.org/2010/11/20/131390650/ok-how-two-letters-made-america-s-greatest-word">most spoken word</a> in the world — besides English, people say "OK" in a dozen languages, including Spanish, Italian and Russian — and yet almost nobody can tell you what those two letters stand for or where the word came from.</p>

		
	
					
				
				


	
		<p>Was it borrowed from the <a href="https://www.google.com/books/edition/OK/mPhj9DIXCWAC?hl=en&amp;gbpv=1&amp;bsq=okeh">indigenous Choctaw word</a> "okeh," meaning, roughly, "OK"? Did it originate with a Boston baker named Otto Kimmel who liked to <a href="https://www.google.com/books/edition/OK/mPhj9DIXCWAC?hl=en&amp;gbpv=1">frost his initials</a> into his cookies? Does it have anything to do with the state of Oklahoma (OK) or the musical "<a href="https://youtu.be/kGXu0j6QDJ8">Oklahoma!</a>"?</p>

		
	
								

		
	
											

						
				
				


	
		<p>Nope, nope and nope. In fact, there's <a href="https://www.google.com/books/edition/OK/mPhj9DIXCWAC?hl=en&amp;gbpv=1&amp;bsq=okeh">no evidence</a> that "okeh" was part of the Chocktaw language.</p>

		
	
													
				
				


	
		<p>"OK is the greatest American word," says <a href="https://cla.umn.edu/about/directory/profile/aliber">Anatoly Liberman</a>, a linguist, translator and language professor at the University of Minnesota. "The history of OK is a history of incredible success, but nobody could have predicted that success."</p>

		
	
					
				
				


	
		<p>As you'll see, OK began as a piece of insider slang from the late 1830s and rode a (losing) presidential campaign to nationwide fame and eventually worldwide ubiquity.</p>

		
	
					
				
						
						

				
				

		
	




</div>		<div data-track-gtm="TOC">
			<p><strong>Contents</strong></p><ol>
						
					
																
										
					<li>
						<a data-target="pt1" href="#pt1">The Acronym Craze of the 1830s</a>
					</li>
							
					
																
										
					<li>
						<a data-target="pt2" href="#pt2">Misspelling Words Was Also a Thing</a>
					</li>
							
					
																
										
					<li>
						<a data-target="pt3" href="#pt3">The Very First Use of OK</a>
					</li>
							
					
																
										
					<li>
						<a data-target="pt4" href="#pt4">"Old Kinderhook" Takes "OK" National</a>
					</li>
										</ol>
		</div>



		
	<div id="page-wrap1" x-data="{ pageVisible : true }"><h2 data-page-nbr="1" data-logged="false" data-page-url="history-ok1.htm">
			


<span @click="pageVisible = !pageVisible" aria-expanded="true" aria-controls="page1" role="button">

			<svg :class="{ 'rotate-180' : !pageVisible, '' : pageVisible }" xmlns="http://www.w3.org/2000/svg" width="22" height="10" viewBox="0 0 28.396 13.211"><path d="M4398.8,5158.252l13.224,10.507,12.357-10.507" transform="translate(-4397.399 -5156.842)" fill="none" stroke-linecap="round" stroke-width="2"></path></svg>
	
		<span>The Acronym Craze of the 1830s</span>

	
</span>		</h2>

				

<div id="page1" data-slide="1" data-track-gtm="Content" x-show.transition="pageVisible === true">	
						
	





	
		<p>In the early 19th century, new printing technologies dramatically reduced the cost of publishing a daily newspaper, and there was a resulting explosion of inexpensive new dailies known collectively as the <a href="https://blogs.ubc.ca/etec540sept09/2009/10/19/the-rise-of-penny-newspapers-and-their-influence-on-mass-media/">penny press</a>. Competing for readers, penny papers in cities like New York, Philadelphia and Boston published not only straight news stories, but also witty takes on the latest political scandals, social scenes and popular trends.</p>

		
	
					
				
				


	
		<p>Think of it as the internet of the 1830s. And much like the internet, the lively back-and-forth chatter between penny paper editors gave birth to a new way of writing and eventually a new way of speaking.</p>

		
	
								

		
	
										
				
				


	
		<p>"Beginning in the summer of 1838, there developed in Boston a remarkable vogue of using abbreviations. It might well be called a craze," <a href="https://www.jstor.org/stable/453580">wrote</a> the famed etymologist <a href="https://www.nytimes.com/2002/10/18/nyregion/allen-read-96-the-ok-expert-is-dead.html">Allen Walker Read</a>, who was the first person to trace the full history of OK.</p>

		
	
					
				
				


	
		<p>Take these examples from Boston's Morning Post, whose editor, Charles Gordon Greene, sprinkled his columns with winking acronyms for everything and anything:</p>

		
	
					
				
				


	
		<div>
	<ul><li><span>O.F.M. ("our first men")</span></li><li><span>W.O.O.O.F.C. ("with one of our first citizens")</span></li><li><span>R.T.B.S. ("remains to be seen")</span></li><li><span>D.L.E.C. ("do let 'em come")</span></li><li><span>G.T.D.H.D. ("give the devil his due")</span></li><li><span>W.Y.G. ("will you go?")</span></li></ul>
</div>


		
	
		
				
				


	
		<p>By 1939, the "initial language," as it was sometimes called, had arrived in New York City and had already leapt from print to fashionable slang. "This is a species of spoken shorthand, which is getting into very general use among loafers and gentlemen of the fancy," <a href="https://www.jstor.org/stable/453580">wrote the editors</a> of New York's Evening Tattler.</p>

		
	
					
				
				


	
		<p>The editors even claimed to have overheard a conversation between two young sweethearts, where the girl turned to her beau and said, "O.K.K.B.W.P." "What could she have meant," wrote the Evening Tattler, "but 'One Kind Kiss Before We Part'?"</p>

		
	
					
				
				
	
									
				

		
	




</div>

			</div>


		
	<div id="page-wrap2" x-data="{ pageVisible : true }"><h2 data-page-nbr="2" data-logged="false" data-page-url="history-ok2.htm">
			


<span @click="pageVisible = !pageVisible" aria-expanded="true" aria-controls="page2" role="button">

			<svg :class="{ 'rotate-180' : !pageVisible, '' : pageVisible }" xmlns="http://www.w3.org/2000/svg" width="22" height="10" viewBox="0 0 28.396 13.211"><path d="M4398.8,5158.252l13.224,10.507,12.357-10.507" transform="translate(-4397.399 -5156.842)" fill="none" stroke-linecap="round" stroke-width="2"></path></svg>
	
		<span>Misspelling Words Was Also a Thing</span>

	
</span>		</h2>

				

<div id="page2" data-slide="2" data-track-gtm="Content" x-show.transition="pageVisible === true">	





	
		<p>In addition to the abbreviation craze, 19th-century Americans thought it was really funny to purposely misspell stuff. Read, the etymologist, cited the example of the comic writer George W. Arnold, who used the pen name "Joe Strickland" to write mangled letters to his fictional family, like this one from a trip abroad: "when I got here tha axt me if I was evver in Turky before. no ses I. but i've had a darn menny turkeys in me."</p>

		
	
					
				
				


	
		<p>By the late 1830s, the (hilarious) misspelling trend had combined with the acronym craze to produce punchy abbreviations like:</p>

		
	
								

		
	
										
				
				


	
		<div>
	<ul><li><span>K.G. for "no go" (as if spelled "know go")</span></li><li><span>K.Y. for "no use" (as if spelled "know yuse")</span></li><li><span>O.W. for "all right" (as if spelled "oll wright")</span></li></ul>
</div>


		
	
		
				
				


	
		<p>Absolutely no one says K.G. or O.W. anymore, but believe it or not, that witty wordplay laid the groundwork for the arrival of a two-letter abbreviation that would conquer the world.</p>

		
	
					
				
				
	
				
				

		
	




</div>

			</div>


		
	<div id="page-wrap3" x-data="{ pageVisible : true }"><h2 data-page-nbr="3" data-logged="false" data-page-url="history-ok3.htm">
			


<span @click="pageVisible = !pageVisible" aria-expanded="true" aria-controls="page3" role="button">

			<svg :class="{ 'rotate-180' : !pageVisible, '' : pageVisible }" xmlns="http://www.w3.org/2000/svg" width="22" height="10" viewBox="0 0 28.396 13.211"><path d="M4398.8,5158.252l13.224,10.507,12.357-10.507" transform="translate(-4397.399 -5156.842)" fill="none" stroke-linecap="round" stroke-width="2"></path></svg>
	
		<span>The Very First Use of OK</span>

	
</span>		</h2>

				

<div id="page3" data-slide="3" data-track-gtm="Content" x-show.transition="pageVisible === true">	





	
		<p>Before we get to the fateful date of March 21, 1839, let's tip our hats one more time to Allen Walker Read, the man who solved the mystery of OK's origins. Keep in mind that Read was working in the 1960s, decades before searchable digital newspaper archives.</p>

		
	
					
				
				


	
		<p>"Read must have spent hundreds of hours digging through tons and tons of physical newspapers, journals, private letters and other documents," says Liberman, who writes the weekly <a href="https://blog.oup.com/category/series-columns/oxford_etymologist/">Oxford Etymologist</a> blog and knows firsthand how hard it is to track down the history of words. "What that man did was absolutely astounding."</p>

		
	
								

		
	
										
				
				


	
		<p>OK, back to our story.</p>

		
	
					
				
				


	
		<p>In the spring of 1839, the editor of Boston's Morning Post, Charles Gordon Greene, was engaged in some good-natured trash talk with the editors of the Providence Journal in Rhode Island<i>.</i> It had to do with a semi-satirical citizens group in Boston called the Anti-Bell-Ringing Society (or A.B.R.S.), of which Greene was a member.</p>

		
	
					
				
				


	
		<p>The Providence paper poked fun at Greene and the A.B.R.S. and Greene had to set the record straight. So it was that on March 21, 1839, at the end of a short paragraph defending the A.B.R.S., Greene printed the following words: "<i>o.k.</i> — all correct."</p>

		
	
					
				
				


	
		<p>See what he did there? Similar to using O.W. for "oll wright," Greene had coined a new misspelled acronym: O.K. for "oll korrect." Three days after Greene introduced OK to the world, the Providence Journal editors responded with an "O.K." of their own.</p>

		
	
					
				
				


	
		<p>Like other offbeat acronyms of the day, O.K. was an inside joke randomly thrust into general circulation. But unlike O.W. or K.G., which enjoyed brief popularity in the 1830s, O.K. didn't die out.</p>

		
	
					
				
				


	
		<p>"Nobody knew that this facetious abbreviation would have such a long and happy life," says Liberman.</p>

		
	
					
				
				
	
				
				

		
	




</div>

			</div>


		
	<div id="page-wrap4" x-data="{ pageVisible : true }"><h2 data-page-nbr="4" data-logged="false" data-page-url="history-ok4.htm">
			


<span @click="pageVisible = !pageVisible" aria-expanded="true" aria-controls="page4" role="button">

			<svg :class="{ 'rotate-180' : !pageVisible, '' : pageVisible }" xmlns="http://www.w3.org/2000/svg" width="22" height="10" viewBox="0 0 28.396 13.211"><path d="M4398.8,5158.252l13.224,10.507,12.357-10.507" transform="translate(-4397.399 -5156.842)" fill="none" stroke-linecap="round" stroke-width="2"></path></svg>
	
		<span>"Old Kinderhook" Takes "OK" National</span>

	
</span>		</h2>

				

<div id="page4" data-slide="4" data-track-gtm="Content" x-show.transition="pageVisible === true">	
					<div>
<figure>
			
		
	
								
		
		
																																																								
			<picture>
				<source media="(max-width: 320px)" data-srcset="https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL09LLWhpc3RvcnktMy0uanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMjB9LCJ0b0Zvcm1hdCI6ImF2aWYifX0=" type="image/avif"><source media="(min-width: 321px) and (max-width: 599px)" data-srcset="https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL09LLWhpc3RvcnktMy0uanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjo0MjB9LCJ0b0Zvcm1hdCI6ImF2aWYifX0=" type="image/avif"><source media="(min-width: 600px)" data-srcset="https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL09LLWhpc3RvcnktMy0uanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjo4Mjh9LCJ0b0Zvcm1hdCI6ImF2aWYifX0=" type="image/avif">
				<source media="(max-width: 320px)" data-srcset="https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL09LLWhpc3RvcnktMy0uanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMjB9fX0="><source media="(min-width: 321px) and (max-width: 599px)" data-srcset="https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL09LLWhpc3RvcnktMy0uanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjo0MjB9fX0="><source media="(min-width: 600px)" data-srcset="https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL09LLWhpc3RvcnktMy0uanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjo4Mjh9fX0=">
				<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAJCAQAAACRI2S5AAAAEElEQVR42mNkIAAYRxWAAQAG9gAKqv6+AwAAAABJRU5ErkJggg==" data-src="https://media.hswstatic.com/eyJidWNrZXQiOiJjb250ZW50Lmhzd3N0YXRpYy5jb20iLCJrZXkiOiJnaWZcL09LLWhpc3RvcnktMy0uanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjo4Mjh9fX0=" alt="Martin Van Buren 1840 campaign" width="828" height="648">
			</picture>
			

		
	

					
	
	<figcaption>
											This political cartoon shows Martin Van Buren, who ran unsuccessfully against William Henry Harrison, known as the "log cabin and hard cider" candidate, during the 1840 presidential campaign. Van Buren's "OK" nickname is prominent. <span>Bettman/Getty Images</span>
								</figcaption>

	</figure>
	</div>
	





	
		<p>If you thought that the word OK <a href="https://www.npr.org/templates/story/story.php?storyId=5170008">originated</a> with Martin Van Buren, you'd be half right. The eighth president of the United States <a href="https://www.nps.gov/mava/index.htm">hailed from the small town</a> of Kinderhook, New York. Like his mentor and fellow Democrat Andrew Jackson, who was known as "Old Hickory," Van Buren's nickname was "Old Kinderhook."</p>

		
	
					
				
				


	
		<p>In the 1840 presidential election, William Henry Harrison and the Whig party challenged the incumbent Van Buren. Harrison's supporters came up with the catchy (for its time) campaign slogan (<a href="https://potus-geeks.livejournal.com/425230.html">and song</a>), "Tippecanoe and Tyler Too." The Democrats swung back with a slogan of their own: "O.K." <a href="https://www.history.com/news/the-birth-of-ok-175-years-ago">As in</a>, "Old Kinderhook is OK!"</p>

		
	
								

		
	
										
				
				


	
		<p>"[Van Buren] got the nickname Old Kinderhook, and early in 1840, OK clubs sprung up with the slogan, 'OK is OK.' So taking that funny little word and making it a mainstay of the political conversation in 1840, suddenly OK was <i>way</i> OK," said the late linguist Allan Metcalf <a href="https://www.npr.org/2010/11/20/131390650/ok-how-two-letters-made-america-s-greatest-word">in a 2010 NPR interview</a>. Metcalf was the author of "<a href="https://www.amazon.com/OK-Improbable-Story-Americas-Greatest/dp/0199892539">OK: The Improbable Story of America's Greatest Word</a>." Van Buren lost badly, but OK definitely won.</p>

		
	
					
				
				


	
		<p>After 1840, the word spread like wildfire and never looked back. Originally, OK appeared in telegraph messages (which may account for its international spread) and documents but not in everyday speech as it was "slangy." But that changed over time. </p>

		
	
					
				
				


	
		<p><a href="https://www.bbc.com/news/magazine-12503686">In an article for BBC Magazine</a>, Metcalf speculated as to why OK was popular all over the world: "It's not that it was needed to 'fill a gap' in any language. Before 1839, English speakers had 'yes,' 'good,' 'fine,' 'excellent,' 'satisfactory' and 'all right.' What OK provided that the others did not was neutrality, a way to affirm or to express agreement without having to offer an opinion. ... OK allows us to view a situation in simplest terms, just OK or not."</p>

		
	
					
				
				
	
					

				

		
	




</div>

			</div>





				</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It's always TCP_NODELAY (719 pts)]]></title>
            <link>https://brooker.co.za/blog/2024/05/09/nagle.html</link>
            <guid>40310896</guid>
            <pubDate>Thu, 09 May 2024 17:54:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://brooker.co.za/blog/2024/05/09/nagle.html">https://brooker.co.za/blog/2024/05/09/nagle.html</a>, See on <a href="https://news.ycombinator.com/item?id=40310896">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post">


<p>It's not the 1980s anymore, thankfully.</p>

<p>The first thing I check when debugging latency issues in distributed systems is whether <a href="https://linux.die.net/man/7/tcp">TCP_NODELAY</a> is enabled. And it’s not just me. Every distributed system builder I know has lost hours to latency issues quickly fixed by enabling this simple socket option, suggesting that the default behavior is wrong, and perhaps that the whole concept is outmoded.</p>

<p>First, let’s be clear about what we’re talking about. There’s no better source than John Nagle’s <a href="https://datatracker.ietf.org/doc/html/rfc896">RFC896</a> from 1984<sup><a href="#foot1">1</a></sup>. First, the problem statement:</p>

<blockquote>
  <p>There is a special problem associated with small  packets.   When TCP  is  used  for  the transmission of single-character messages originating at a keyboard, the typical result  is  that  41  byte packets (one  byte  of data, 40 bytes of header) are transmitted for each byte of useful data.  This 4000%  overhead  is  annoying but tolerable on lightly loaded networks.</p>
</blockquote>

<p>In short, Nagle was interested in better amortizing the cost of TCP headers, to get better throughput out of the network. Up to 40x better throughput! These tiny packets had two main causes: human-interactive applications like shells, where folks were typing a byte at a time, and poorly implemented programs that dribbled messages out to the kernel through many <code>write</code> calls. Nagle’s proposal for fixing this was simple and smart:</p>

<blockquote>
  <p>A  simple and elegant solution has been discovered.</p>
</blockquote>

<blockquote>
  <p>The solution is to inhibit the sending of new TCP  segments  when new  outgoing  data  arrives  from  the  user  if  any previously transmitted data on the connection remains unacknowledged.</p>
</blockquote>

<p>When many people talk about Nagle’s algorithm, they talk about timers, but RFC896 doesn’t use any kind of timer other than the round-trip time on the network.</p>

<p><em>Nagle’s Algorithm and Delayed Acks</em></p>

<p>Nagle’s nice, clean, proposal interacted poorly with another TCP feature: delayed <code>ACK</code>. The idea behind delayed <code>ACK</code> is to delay sending the acknowledgement of a packet at least until there’s some data to send back (e.g. a <code>telnet</code> session echoing back the user’s typing), or until a timer expires. <a href="https://datatracker.ietf.org/doc/html/rfc813">RFC813</a> from 1982 is that first that seems to propose delaying <code>ACKs</code>:</p>

<blockquote>
  <p>The receiver of data will   refrain   from   sending   an   acknowledgement   under   certain circumstances, in which case it must set a timer which  will  cause  the acknowledgement  to be sent later.  However, the receiver should do this only where it is a reasonable guess that some other event will intervene and prevent the necessity of the timer  interrupt.</p>
</blockquote>

<p>which is then formalized further in <a href="https://datatracker.ietf.org/doc/html/rfc1122">RFC1122</a> from 1989. The interaction between these two features causes a problem: Nagle’s algorithm is blocking sending more data until an <code>ACK</code> is received, but delayed ack is delaying that <code>ack</code> until a response is ready. Great for keeping packets full, not so great for latency-sensitive pipelined applications.</p>

<p>This is a point Nagle has made himself several times. For example in this <a href="https://news.ycombinator.com/item?id=10608356">Hacker News comment</a>:</p>

<blockquote>
  <p>That still irks me. The real problem is not tinygram prevention. It’s ACK delays, and that stupid fixed timer. They both went into TCP around the same time, but independently. I did tinygram prevention (the Nagle algorithm) and Berkeley did delayed ACKs, both in the early 1980s. The combination of the two is awful.</p>
</blockquote>

<p>As systems builders this is should be a familiar situation: two reasonable features of the system that interact to create an undesirable behavior. This kind of interaction is one of the things that makes protocol design so hard.</p>

<p><em>Is Nagle blameless?</em></p>

<p>Unfortunately, it’s not just delayed ACK. Even without delayed ack and that <em>stupid fixed timer</em>, the behavior of Nagle’s algorithm probably isn’t what we want in distributed systems. A single in-datacenter RTT is typically around 500μs, then a couple of milliseconds between datacenters in the same region, and up to hundreds of milliseconds going around the globe. Given the vast amount of work a modern server can do in even a few hundred microseconds, delaying sending data for even one RTT isn’t clearly a win.</p>

<p>To make a clearer case, let’s turn back to the justification behind Nagle’s algorithm: amortizing the cost of headers and avoiding that 40x overhead on single-byte packets. But does anybody send single byte packets anymore? Most distributed databases and systems don’t. Partially that’s because they simply have more to say, partially its because of additional overhead of protocols like TLS, and partially its because of encoding and serialization overhead. But mostly, they have more to say.</p>

<p>The core concern of not sending tiny messages is still a very real one, but we’ve very effectively pushed that into the application layer. Sending a byte at a time wrapped in JSON isn’t going to be very efficient, no matter what Nagle’s algorithm does.</p>

<p><em>Is Nagle needed?</em></p>

<p>First, the uncontroversial take: if you’re building a latency-sensitive distributed system running on modern datacenter-class hardware, enable <code>TCP_NODELAY</code> (disable Nagle’s algorithm) without worries. You don’t need to feel bad. It’s not a sin. It’s OK. Just go ahead.</p>

<p>More controversially, I suspect that Nagle’s algorithm just isn’t needed on modern systems, given the traffic and application mix, and the capabilities of the hardware we have today. In other words, <code>TCP_NODELAY</code> should be the default. That’s going to make some “<code>write</code> every byte” code slower than it would otherwise be, but those applications should be fixed anyway if we care about efficiency.</p>

<p><em>Footnotes</em></p>

<ol>
  <li><a name="foot1"></a> I won’t got into it here, but RFC896 is also one of the earliest statements I can find of metastable behavior in computer networks. In it, Nagle says: “This condition is stable. Once the  saturation point has been reached, if the algorithm for selecting packets to be dropped is fair, the network will continue to operate in a degraded condition.”</li>
</ol>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Leaked deck reveals how OpenAI is pitching publisher partnerships (294 pts)]]></title>
            <link>https://www.adweek.com/media/openai-preferred-publisher-program-deck/</link>
            <guid>40310228</guid>
            <pubDate>Thu, 09 May 2024 16:56:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.adweek.com/media/openai-preferred-publisher-program-deck/">https://www.adweek.com/media/openai-preferred-publisher-program-deck/</a>, See on <a href="https://news.ycombinator.com/item?id=40310228">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-continue-reading-wrapper="">
                                    



<div>
		
		<p>Mark your calendar for Mediaweek, October 29-30 in New York City. We’ll unpack the biggest shifts shaping the future of media—from tv to retail media to tech—and how marketers can prep to stay ahead. <a href="https://event.adweek.com/mediaweek-2024/4442894?ref=nativep1&amp;itm_source=ROS&amp;itm_medium=display&amp;itm_campaign=nativeMediaweek24&amp;itm_content=p1"><strong>Register</strong></a> with early-bird rates before sale ends!</p>
	</div>


<div><p>The generative artificial intelligence firm OpenAI has been pitching partnership opportunities to news publishers through an initiative called the Preferred Publishers Program, according to a deck obtained by ADWEEK and interviews with four industry executives.</p><p>OpenAI has been courting premium publishers dating back to July 2023, when it struck a licensing agreement with the Associated Press. It has since inked public partnerships with Axel Springer, The Financial Times, <a href="https://www.adweek.com/media/le-monde-english-subscribers-olympics/" target="_blank" rel="noreferrer noopener">Le Monde</a>, Prisa and Dotdash Meredith, although it has declined to share the specifics of any of its deals.</p><p>A representative for OpenAI disputed the accuracy of the information in the deck, which is more than three months old. The <a href="https://www.adweek.com/category/artificial-intelligence/" target="_blank">gen AI</a> firm also negotiates deals on a per-publisher basis, rather than structuring all of its deals uniformly, the representative said.</p><p>“We are engaging in productive conversations and partnerships with many news publishers around the world,” said a representative for OpenAI. “Our confidential documents are for discussion purposes only and ADWEEK’s reporting contains a number of mischaracterizations and outdated information.”</p><p>Nonetheless, the leaked deck reveals the basic structure of the partnerships OpenAI is proposing to media companies, as well as the incentives it is offering for their collaboration.</p><section> <p><a href="https://www.adweek.com/media/publishers-ai-licensing-negotiations-mark-an-inflection-point/" target="_blank"><img decoding="async" src="https://static-prod.adweek.com/wp-content/uploads/2023/11/publisher-ai-licensing-2023-640x360.jpg" alt="Copyright law favors creators, but commercial compromise offers a hedge against uncertainty."></a></p>  </section><h4><strong>Details from the pitch deck</strong></h4><p>The Preferred Publisher Program has five primary components, according to the deck.</p><p>First, it is available only to “select, high-quality editorial partners,” and its purpose is to help ChatGPT users more easily discover and engage with publishers’ brands and content.</p><p>Additionally, members of the program receive priority placement and “richer brand expression” in chat conversations, and their content benefits from more prominent link treatments. Finally, through PPP, OpenAI also offers licensed financial terms to publishers.</p><p>The financial incentives participating publishers can expect to receive are grouped into two buckets: guaranteed value and variable value.</p><p>Guaranteed value is a licensing payment that compensates the publisher for allowing OpenAI to access its backlog of data, while variable value is contingent on display success, a metric based on the number of users engaging with linked or displayed content.</p><p>The resulting financial offer would combine the guaranteed and variable values into one payment, which would be structured on an annual basis.&nbsp;</p><p>“The PPP program is more about scraping than training,” said one executive. “OpenAI has presumably already ingested and trained on these publishers’ archival data, but it needs access to contemporary content to answer contemporary queries.”</p><!--nextpage--><p>In return for these payments, OpenAI would gain two benefits. </p><p>It would have the ability to train on a publisher’s content and the license to display that information in ChatGPT products, complete with attribution and links. It would also get to announce the publisher as a preferred partner and work with them to build out these experiences.</p><h4><strong>Participation boosts publisher payouts</strong></h4><p>According to the deck, publisher participation in PPP creates a better experience for OpenAI users, which will help shift engagement toward browsing, i.e. queries that result in responses with links.</p><p>Roughly 25% of ChatGPT users already use the browse function, but the company expects that a majority of users will do so once the feature is broadly rolled out. If more users engage with publishers’ links, the <a href="https://www.adweek.com/category/media-news/" target="_blank" rel="noreferrer noopener">media companies</a> could earn larger payments for their variable value.&nbsp;</p><p>PPP members will see their content receive its “richer brand expression” through a series of content display products: the branded hover link, the anchored link and the in-line treatment.</p><p>In the hover treatment, which is available today, OpenAI will hyperlink keywords in its responses to search queries. The links appear as blue text and reveal a clickable tab when moused over. </p><p>In the anchor treatment, branded, clickable buttons appear below ChatGPT’s response to a user query. And the in-line product inserts a pullquote into the text of ChatGPT’s response, whose font is larger and includes a clickable, branded link.&nbsp;</p><p>All three content display products seek to cite the publishers whose writing is being used to answer the search query, although the setup will likely lead fewer users to visit publishers’ websites.&nbsp;</p><p>A recent model from The Atlantic found that if a search engine like Google were to integrate AI into search, it would answer a user’s query 75% of the time without requiring a clickthrough to its website.</p><h4><strong>Where publishers go from here</strong></h4><p>The details of the program add further color to the complicated relationship between digital publishers and OpenAI. The uncertain legal standing of the data-scraping methodology that OpenAI uses to power its large-language models has made licensing negotiations between the two parties complex.</p><p>While some publishers have opted to partner with OpenAI, others, <a href="https://www.adweek.com/media/open-ai-response-new-york-times-lawsuit/" target="_blank">including recent NewFronts participant The New York Times</a> and eight Alden Global Capital titles, have sued the tech firm on the grounds that it has used copyrighted articles without permission.</p><p>The vast majority of news publishers, as well as independent websites, have neither partnered with OpenAI nor taken legal action. According to one media executive, through programs such as Preferred Publisher, OpenAI is looking to change that.</p><p>“At the recent Aspen Conference in New York on AI and the news,” the person said, “OpenAI was very open about their need to attract publishers into their partnership program.”&nbsp;</p><!--nextpage--><p><em>This story has updated to include a response from OpenAI.</em></p></div>
<div id="meter-count">
  
  
    
    
  
  <a href="#" onclick="ShowAndHide()">
    
  </a>
  
  
  <div>
        <p>
          <h3>Enjoying Adweek's Content? Register for More Access!</h3>
        </p>
      </div>
</div>                                                                    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Leaked FBI Email Reportedly Shows Desperation to Justify Warrantless Wiretaps (161 pts)]]></title>
            <link>https://gizmodo.com/leaked-fbi-email-warrantless-wiretaps-section-702-1851464520</link>
            <guid>40309957</guid>
            <pubDate>Thu, 09 May 2024 16:34:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/leaked-fbi-email-warrantless-wiretaps-section-702-1851464520">https://gizmodo.com/leaked-fbi-email-warrantless-wiretaps-section-702-1851464520</a>, See on <a href="https://news.ycombinator.com/item?id=40309957">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Congress reauthorized America’s warrantless wiretapping program last month after some <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/national-security-threat-likely-nukes-in-space-1851257693&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/national-security-threat-likely-nukes-in-space-1851257693">successful fearmongering</a></span> by national security hawks on Capitol Hill. But an internal FBI email, leaked to <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.wired.com/story/fbi-section-702-us-person-queries-email/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.wired.com/story/fbi-section-702-us-person-queries-email/" target="_blank" rel="noopener noreferrer">Wired</a></span> on Wednesday, may accidentally reveal how the federal law enforcement agency plans to overstep the spirit of the law, while technically maintaining the letter of the law.<br></p><div data-video-id="196937" data-monetizable="false" data-position="sidebar" data-video-title="Approaching Queerness in Doctor Who" data-video-blog-id="4" data-video-network="gizmodo" data-video-duration="72" data-playlist="196937,196931,196911" data-current="196937"><div><p>Approaching Queerness in Doctor Who</p></div><video disablepictureinpicture="" muted="" playsinline="" width="100%" height="100%" crossorigin="anonymous" preload="none"><source data-src="https://vid.kinja.com/prod/196937/196937_240p.mp4" label="240p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/196937/196937_480p.mp4" label="480p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/196937/196937_720p.mp4" label="720p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/196937/196937_1080p.mp4" label="1080p" type="video/mp4"><track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/22499.vtt" srclang="en"></video><div><ul><li data-label="">Off</li><li data-label="English">English</li></ul></div></div><p>The controversial spying program is Section 702 in the Foreign Intelligence Surveillance Act (FISA) and allows the interception of foreign communications that sometimes include American citizens. The program ostensibly includes safeguards to ensure the law isn’t being used to unnecessarily spy on Americans, but it’s pretty clear from this new email that the FBI likes being able to get communications from Americans.<br></p><p>The email obtained by <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.wired.com/story/fbi-section-702-us-person-queries-email/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.wired.com/story/fbi-section-702-us-person-queries-email/" target="_blank" rel="noopener noreferrer">Wired</a></span> dated April 20 was written by FBI Deputy Director Paul Abbate and sent out to employees internally.<br></p><p>“To continue to demonstrate why tools like this are essential to our mission, we need to <em>use</em> them, while also holding ourselves accountable for doing so properly and in compliance with legal requirements,” the email reads, according to Wired, which notes that the italicization on the word “use” was in the original email.</p><p>The FBI email made things even more explicit by encouraging searches for Americans when looking through intercepted communications.<br></p><p>“I urge everyone to continue to look for ways to appropriately use US  person queries to advance the mission, with the added confidence that  this new pre-approval requirement will help ensure that those queries  are fully compliant with the law,” the email reads.</p><p>The FBI’s response to Wired is particularly interesting, making it worth quoting at length. From Wired:<br></p><blockquote data-type="BlockQuote"><p>Following publication, FBI spokesperson Susan McKee provided a statement  from the bureau that mischaracterized WIRED’s reporting, inaccurately  claiming it “alleged that that the FBI instructed its employees to  violate the law or FBI policies.” The statement added that Abbate’s  email “emphasized Congress’ recognition of the vital importance of FISA  Section 702 to protect the American people and was sent to ensure that  FBI personnel were immediately aware of, and in compliance with, the  privacy enhancing changes the law has put in place.”</p></blockquote><p>Obviously, the FBI is going to say everyone at the agency follows the law since they quite literally are the law. But Wired spoke with Rep. Zoe Lofgren, a Democrat from California who notes this newly leaked email “directly contradicts earlier assertions” by the FBI when the agency was trying to get the law reauthorized.</p><p>It’s all a mess. The FBI got exactly what it wanted with the reauthorization of Section 702, something that was never really in doubt, even with pressure from a handful of politicians who opposed it. To paraphrase former president Richard Nixon, it’s <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.nixonlibrary.gov/media/video/excerpt-frost-interview-final&quot;,{&quot;metric25&quot;:1}]]" href="https://www.nixonlibrary.gov/media/video/excerpt-frost-interview-final" target="_blank" rel="noopener noreferrer">not illegal</a></span> when the FBI does it. But what are you going to do in such a <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.vox.com/2014/4/18/5624310/martin-gilens-testing-theories-of-american-politics-explained&quot;,{&quot;metric25&quot;:1}]]" href="https://www.vox.com/2014/4/18/5624310/martin-gilens-testing-theories-of-american-politics-explained" target="_blank" rel="noopener noreferrer">ridiculously rigged system</a></span>? </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Familial Transmission of Personality Is Higher Than Shown in Typical Studies (127 pts)]]></title>
            <link>https://osf.io/preprints/psyarxiv/7ygp6</link>
            <guid>40309840</guid>
            <pubDate>Thu, 09 May 2024 16:24:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://osf.io/preprints/psyarxiv/7ygp6">https://osf.io/preprints/psyarxiv/7ygp6</a>, See on <a href="https://news.ycombinator.com/item?id=40309840">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[ESP32 Drum Synth Machine (213 pts)]]></title>
            <link>https://github.com/zircothc/DRUM_2004_V1</link>
            <guid>40309759</guid>
            <pubDate>Thu, 09 May 2024 16:17:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/zircothc/DRUM_2004_V1">https://github.com/zircothc/DRUM_2004_V1</a>, See on <a href="https://news.ycombinator.com/item?id=40309759">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-turbo-body="">
      


    <div>
      <p><a href="#start-of-content" data-skip-target-assigned="false">Skip to content</a>
      
      <span data-view-component="true">
    <span data-view-component="true"></span>
</span></p><react-partial partial-name="keyboard-shortcuts-dialog" data-ssr="false">
  
  
  
</react-partial>




      

        

            


<header role="banner" data-color-mode="light" data-light-theme="light" data-dark-theme="dark">
  <h2>Navigation Menu</h2>

  

  <div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:zircothc/DRUM_2004_V1" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="Xls1zmfjVRFg9r4Wl7imLC4d7t70EC8VFGEzJ3l8PkSTdyhMRwvLvr6FuGcBXE97nR8Ke0WUSEFhP2Op2rYh0Q" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="zircothc/DRUM_2004_V1" data-current-org="" data-current-owner="zircothc" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=%2BiiCrl8XCZuAbyfAa9SDOHr3qvpevm5qEbQhyJ5E7dgHAE61KDk5rdJcw3r8O2y5EM1VVRGGeCAcnvPZAMPdBvItIhbHV0XYmg%2Fv8CP8RyrNEfe%2FO5azXeP83%2F0HfBzzThpa0pxtmgMeyOyb4XMSLxiL230rkV5xdveUyYtTqNEBGgJlJY5TshB80I2tgtZ6Os3NZL2gmjgXM9vDNSDwHD25huy6KhKPg0NpkNddr0SY6FIkrm2fjLlC3oqfuwpNkEgayvjoI7eDRnt67C1s%2Fz2aEhb9BHhYTqxbEYCpXRNdYPNAFBbjCQPJN9yoDnoEubkElq7AvFFM3NylFzAzSvtZjzOE1yO0JplkVZvZaeOlAUOj2K0dk%2F%2FSOwgbMQHPFoQesHKli8w8R2C3332APP4N2Vnm2xWkH6ctA5FLcp3EBJKNBNVzl4MatYE58pi4SwNAbI21ugU4PfXxFLyWGciBcMvFNnQhpAcYNENsQzIi5ugAkpKIzJQnqtEHdidObAsVK3H6mhqBCyrZrDPYIjfu--YhueA04nZryfZRfM--cAd3gG%2Fp%2FjkDIvZzaBkuUA%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=zircothc%2FDRUM_2004_V1" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/zircothc/DRUM_2004_V1&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="81dd76527504e666ffcf483d0fe30a1f780d08432723a3a9b88f6d261439a7e9" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div>
</header>

      
    </div>

  








    


    
    <include-fragment data-base-src="https://github.com/notifications/beta/shelf"></include-fragment>





  <div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
  





    






  
  

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div id="repo-content-pjax-container">

  

  <include-fragment src="/zircothc/DRUM_2004_V1/spoofed_commit_check/a9e446620f1cd0590298ad68cbce2fedecb34a5c" data-test-selector="spoofed-commit-check"></include-fragment>

  <div data-view-component="true">        


















<react-partial partial-name="repos-overview" data-ssr="true">
  
  
  <div data-target="react-partial.reactRoot"><div><h2>Repository files navigation</h2><nav aria-label="Repository files"><ul role="list"><li><a href="#" aria-current="page"><span data-component="icon"></span><span data-component="text" data-content="README">README</span></a></li></ul></nav></div><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">DRUM_2004_V1</h2><a id="user-content-drum_2004_v1" aria-label="Permalink: DRUM_2004_V1" href="#drum_2004_v1"></a></p>
<p dir="auto">ESP32 DRUM SYNTH MACHINE</p>
<p dir="auto">This is my DRUM SYNTH LOFI MACHINE.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17828930/326164677-c8327dc2-a3f7-4d81-8d82-ebfe2a7c45c3.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUyODg3MDQsIm5iZiI6MTcxNTI4ODQwNCwicGF0aCI6Ii8xNzgyODkzMC8zMjYxNjQ2NzctYzgzMjdkYzItYTNmNy00ZDgxLThkODItZWJmZTJhN2M0NWMzLmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTA5VDIxMDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU1MjAxMzAzNmNiNGJlZWY0Y2RkNDgzZTMxZGU2NGMxYTJiOTYzYjRmMDJiYzgyN2JmZjE3NjExNjQ3ZGFhNDcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.Uyua3Yza2N0QuZGlt3lN_wHPan8EM8u4O6Llrz74cEc"><img src="https://private-user-images.githubusercontent.com/17828930/326164677-c8327dc2-a3f7-4d81-8d82-ebfe2a7c45c3.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUyODg3MDQsIm5iZiI6MTcxNTI4ODQwNCwicGF0aCI6Ii8xNzgyODkzMC8zMjYxNjQ2NzctYzgzMjdkYzItYTNmNy00ZDgxLThkODItZWJmZTJhN2M0NWMzLmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTA5VDIxMDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU1MjAxMzAzNmNiNGJlZWY0Y2RkNDgzZTMxZGU2NGMxYTJiOTYzYjRmMDJiYzgyN2JmZjE3NjExNjQ3ZGFhNDcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.Uyua3Yza2N0QuZGlt3lN_wHPan8EM8u4O6Llrz74cEc" alt="IMG_20240406_150440"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Synth engine:</h2><a id="user-content-synth-engine" aria-label="Permalink: Synth engine:" href="#synth-engine"></a></p>
<ul dir="auto">
<li>Wavetable synthesizer based on DZL Arduino library "The Synth" (<a href="https://github.com/dzlonline/the_synth">https://github.com/dzlonline/the_synth</a>)</li>
<li>16 sound polyphony</li>
<li>Sound parameters: Table, Length, Envelope, Pitch, Modulation, + Volume, Pan and Filter.</li>
<li>Filter (LowPassFilter) comes from Mozzi library (<a href="https://github.com/sensorium/Mozzi">https://github.com/sensorium/Mozzi</a>)</li>
</ul>
<p dir="auto">SEQUENCER:</p>
<ul dir="auto">
<li>16 step/pattern editor and random generators (pattern, sound parameters and notes)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Hardware:</h2><a id="user-content-hardware" aria-label="Permalink: Hardware:" href="#hardware"></a></p>
<ul dir="auto">
<li>Lolin S2 Mini (ESP32 S2)</li>
<li>PCM5102A I2s dac</li>
<li>24 push buttons (8x3)</li>
<li>Rotary encoder</li>
<li>OLED display I2c</li>
<li>32 LED WS2812B</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Software:</h2><a id="user-content-software" aria-label="Permalink: Software:" href="#software"></a></p>
<p dir="auto">IDE:
Arduino 1.8.19</p>
<p dir="auto">Boards:
Expressif Systems 2.0.14</p>
<p dir="auto">Board: Lolin S2 Mini</p>
<p dir="auto">Libraries:</p>
<ul dir="auto">
<li>Sequencer Timer - uClock: <a href="https://github.com/midilab/uClock">https://github.com/midilab/uClock</a></li>
<li>RGB Leds - Adafruit Neopixel: <a href="https://github.com/adafruit/Adafruit_NeoPixel">https://github.com/adafruit/Adafruit_NeoPixel</a></li>
<li>OLED - u8g2: <a href="https://github.com/olikraus/u8g2">https://github.com/olikraus/u8g2</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Notes:</h2><a id="user-content-notes" aria-label="Permalink: Notes:" href="#notes"></a></p>
<p dir="auto">Schematics uploaded.</p>
<p dir="auto">Join solder pads near SCK pin in PCM5102A module.</p>
<p dir="auto">Video demo of the prototype:</p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=rXl1gpWJp-g" rel="nofollow"><img src="https://camo.githubusercontent.com/6859cb54d06b51e0e0690b1ff5f288e2ec91981a74f66c0be1331ed00486f80d/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f72586c316770574a702d672f302e6a7067" alt="IMG_20240406_150231" data-canonical-src="https://img.youtube.com/vi/rXl1gpWJp-g/0.jpg"></a></p>
<p dir="auto">Waiting PCBs to build the first one :)
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17828930/326164735-feb9b928-f76a-4b51-93ea-a7afbd6a5c28.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUyODg3MDQsIm5iZiI6MTcxNTI4ODQwNCwicGF0aCI6Ii8xNzgyODkzMC8zMjYxNjQ3MzUtZmViOWI5MjgtZjc2YS00YjUxLTkzZWEtYTdhZmJkNmE1YzI4LmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTA5VDIxMDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWNlZTFjNjg4YzljOWQyMTUwMjE1NjQ1YmI3MDExYjk2ZDgxZmY5MmJlZDYyNDVmMzEyMDc0YzkyMjI2NDAxZjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.Zq6yD07v-buQ7WaQxTmfWfWiBKceY6Unmnnss2J2fDs"><img src="https://private-user-images.githubusercontent.com/17828930/326164735-feb9b928-f76a-4b51-93ea-a7afbd6a5c28.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUyODg3MDQsIm5iZiI6MTcxNTI4ODQwNCwicGF0aCI6Ii8xNzgyODkzMC8zMjYxNjQ3MzUtZmViOWI5MjgtZjc2YS00YjUxLTkzZWEtYTdhZmJkNmE1YzI4LmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTA5VDIxMDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWNlZTFjNjg4YzljOWQyMTUwMjE1NjQ1YmI3MDExYjk2ZDgxZmY5MmJlZDYyNDVmMzEyMDc0YzkyMjI2NDAxZjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.Zq6yD07v-buQ7WaQxTmfWfWiBKceY6Unmnnss2J2fDs" alt="IMG_20240406_150231"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17828930/326164951-e1001f26-0993-4221-90d1-e9a2f710af0f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUyODg3MDQsIm5iZiI6MTcxNTI4ODQwNCwicGF0aCI6Ii8xNzgyODkzMC8zMjYxNjQ5NTEtZTEwMDFmMjYtMDk5My00MjIxLTkwZDEtZTlhMmY3MTBhZjBmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTA5VDIxMDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA2ZmM0NTAzMDkyM2VmZjBiYzFmODI5MzcyMzBhMTZiNGU4YjFkODk0NzNhM2UwZGY5NjQ2ZGVmNmZmYzc3OTQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.DAz14RYXzspi3g35ofVXaOrf49ivpYcGhtBmBx8F5ZA"><img src="https://private-user-images.githubusercontent.com/17828930/326164951-e1001f26-0993-4221-90d1-e9a2f710af0f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTUyODg3MDQsIm5iZiI6MTcxNTI4ODQwNCwicGF0aCI6Ii8xNzgyODkzMC8zMjYxNjQ5NTEtZTEwMDFmMjYtMDk5My00MjIxLTkwZDEtZTlhMmY3MTBhZjBmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTA5VDIxMDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA2ZmM0NTAzMDkyM2VmZjBiYzFmODI5MzcyMzBhMTZiNGU4YjFkODk0NzNhM2UwZGY5NjQ2ZGVmNmZmYzc3OTQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.DAz14RYXzspi3g35ofVXaOrf49ivpYcGhtBmBx8F5ZA" alt="board"></a></p>
</article></div></div>
</react-partial>

        </div></div>

</turbo-frame>


    </main>
  </div>

          




    <ghcc-consent id="ghcc" data-initial-cookie-consent-allowed="" data-cookie-consent-required="true"></ghcc-consent>


  

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open="">
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog="">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0 tooltipped-no-delay" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Ellipsis – Automated PR reviews and bug fixes (106 pts)]]></title>
            <link>https://www.ellipsis.dev/</link>
            <guid>40309719</guid>
            <pubDate>Thu, 09 May 2024 16:14:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ellipsis.dev/">https://www.ellipsis.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=40309719">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" data-framer-hydrate-v2="{&quot;routeId&quot;:&quot;augiA20Il&quot;,&quot;localeId&quot;:&quot;default&quot;,&quot;breakpoints&quot;:[{&quot;hash&quot;:&quot;72rtr7&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 1440px)&quot;},{&quot;hash&quot;:&quot;103465x&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 1280px) and (max-width: 1439px)&quot;},{&quot;hash&quot;:&quot;142h2bu&quot;,&quot;mediaQuery&quot;:&quot;(min-width: 810px) and (max-width: 1279px)&quot;},{&quot;hash&quot;:&quot;1pkud1z&quot;,&quot;mediaQuery&quot;:&quot;(max-width: 809px)&quot;}]}" data-framer-ssr-released-at="2024-05-06T12:43:44.396Z" data-framer-page-optimized-at="2024-05-09T17:51:33.965Z"><figure data-framer-name="Background" name="Background"></figure><div data-framer-name="cta" name="cta"><div data-framer-name="Content Wrapper" name="Content Wrapper"><a data-border="true" data-framer-name="Main" name="Main" href="https://docs.ellipsis.dev/code#from-a-pr" target="_blank" rel="noopener"></a><div><p data-framer-name="Enhance the way you" data-framer-component-type="RichTextContainer"><h2 data-styles-preset="LdKDZ3RUB"><span data-text-fill="true">Ship faster with AI</span></h2></p></div><p data-styles-preset="ppPqjGXDa">Ellipsis is an AI devtool that reviews pull requests and converts GitHub comments into working, tested code.</p></div><div data-framer-name="Content Wrapper" name="Content Wrapper"><p data-styles-preset="skV12T4aE">Backed by</p><div data-framer-name="YC_logo" name="YC_logo"><p><img decoding="async" sizes="(min-width: 1440px) 150px, (min-width: 1280px) and (max-width: 1439px) 150px, (min-width: 810px) and (max-width: 1279px) 150px, (max-width: 809px) 150px" srcset="https://framerusercontent.com/images/3EGsNY7lyfSWhMVz634fBMRDR4.png?scale-down-to=512 512w,https://framerusercontent.com/images/3EGsNY7lyfSWhMVz634fBMRDR4.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/3EGsNY7lyfSWhMVz634fBMRDR4.png?scale-down-to=2048 2048w,https://framerusercontent.com/images/3EGsNY7lyfSWhMVz634fBMRDR4.png 4096w" src="https://framerusercontent.com/images/3EGsNY7lyfSWhMVz634fBMRDR4.png?scale-down-to=2048" alt="" data-framer-original-sizes="150px"></p></div></div></div><div data-framer-name="FEATURES" name="FEATURES"><div data-framer-name="Headings Wrapper" name="Headings Wrapper"><p><span><strong>But that's only the beginning</strong></span>. Ellipsis is capable of reviewing, writing, and answering questions about your source code.</p></div><div data-framer-name="Features Wrapper" name="Features Wrapper"><div data-framer-name="Feature Block" name="Feature Block" data-border="true"><p data-framer-name="100+ Languages Support" data-framer-component-type="RichTextContainer"><h4>20+ Languages Supported</h4></p></div><div data-framer-name="Feature Block" name="Feature Block"><div><p><img decoding="async" loading="lazy" src="https://framerusercontent.com/images/HlAwD5YbZZw5JczQDnm3WQhEw.png" alt=""></p></div><div data-framer-name="Content Wrapepr" name="Content Wrapepr"><p data-styles-preset="skV12T4aE">Ship faster by converting requirements into working, tested code.</p></div></div><div data-framer-name="Feature Block" name="Feature Block" data-border="true"><p data-framer-name="Modern and easy UI" data-framer-component-type="RichTextContainer"><h4>Free 7 day trial</h4></p><p>Includes unlimited code reviews, summaries, and generations.</p></div></div><div data-framer-name="Content Wrapper" name="Content Wrapper"><p>Ellipsis doesn't store or train on your source code. It will never commit to your default branch, and will only add new commits or open new pull requests when you explicitly request it. </p></div><div data-framer-name="Pricing" name="Pricing"><div><p>License per seat, reassign seats at any time.</p></div><div><div data-border="true"><div data-framer-name="Variant 1" tabindex="0"><p>Install in your repository</p></div><div data-framer-name="Variant 1" tabindex="0"><p>Email us at team@ellipsis.dev</p></div><div data-framer-name="Variant 1" tabindex="0"><p>If approved, get unlimited code reviews</p></div></div><div data-border="true"><div><p data-framer-component-type="RichTextContainer"><h5>per developer-month</h5></p></div><div><div data-framer-name="Variant 1" tabindex="0"><p>Automatic code reviews on every commit</p></div><div data-framer-name="Variant 1" tabindex="0"><p>Bug fixes &amp; code generations</p></div><div data-framer-name="Variant 1" tabindex="0"><p>Question &amp; answer functionality</p></div></div></div><div data-border="true"><div><p data-framer-component-type="RichTextContainer"><h2>Contact us</h2></p></div><div><div data-framer-name="Variant 1" tabindex="0"><p>Weekly code change summaries</p></div><div data-framer-name="Variant 1" tabindex="0"><p>Priority support, with SLA</p></div></div></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Launch HN: Muddy (YC S19) – Multiplayer browser for getting work done (225 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40309342</link>
            <guid>40309342</guid>
            <pubDate>Thu, 09 May 2024 15:38:48 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40309342">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td colspan="2"></td><td><div><p>Hey HN! This is Jimmy, Ron and Austa from Muddy (<a href="https://feelmuddy.com/">https://feelmuddy.com/</a>). Muddy is a browser for work that automatically keeps project files organized in the same place where you use and share them. Here’s a demo: <a href="https://www.youtube.com/watch?v=tZr49aN3sjQ" rel="nofollow">https://www.youtube.com/watch?v=tZr49aN3sjQ</a>. Download and try it out here: <a href="https://feelmuddy.com/">https://feelmuddy.com/</a>.</p><p>Building together in the past, we were incredibly frustrated with how much friction there is to get anything done on our computers. I was losing time everyday digging through chat logs looking for that one important link or breaking others out of flow by asking where something is.</p><p>Web apps promised to help us get more done—and they do, but each in its own silo, so there’s still a ton of redundancy to deal with. Every app has its own way of organizing files, its own notification inbox, its own search system. Conversations live everywhere and there isn’t a single view to see everything about a project. Remember when files simply lived in folders rather than the “cloud”?</p><p>We started dedicating time to organizing our files in shared docs and limiting new apps we used. This helped – but the second we didn’t stay on top of organization, links became stale and things got messy again.</p><p>Muddy started as a hack week project we built for ourselves—a single place to use web apps with others, but personalized for each user automatically. Everyone gets their own view for every project, designed around how they work.</p><p>Muddy users work on projects in spaces, which are like automatic tab groups. Users share apps (any site works—a Github PR, Figma file, Trello board—whatever you want) into the project’s shared timeline and Muddy automatically opens relevant tabs for you. It’s a single click to open up all the apps you need for the project.</p><p>Under the hood, Muddy works in the background to keep track of the timeline and uses a LLM to continuously organize apps and keep everything on to date. It considers signals like the popularity of a file, naming conventions, and conversations to figure out what’s relevant. So everyone is presented with an updated list of important tabs, without anyone lifting a finger. Our actual browser is based on Chromium.</p><p>When you need to revisit something from weeks ago, you can rewind the project timeline to that point in a single click. Apps open up in the timeline so you’ll see your files right away. For sites that don’t have built in collaboration features (like documentation), Muddy lets you do annotations directly on the website.</p><p>Projects sometimes get big and need to be broken up. Across all your spaces, Muddy can answer questions like ChatGPT, cite your files as sources, and return apps directly. This is possible since Muddy’s AI shares your browser and can use your authenticated apps locally (with privacy in mind).</p><p>Other browsers like Chrome and Arc focus on solo productivity with sharing as a bolt-on. We think productivity depends on how well you can work with others, and should be the first class consideration. And doing organizational work manually is unsustainable.</p><p>Muddy will have paid subscriptions for teams with additional features like shared passwords, team organization, custom shortcuts, and SSO management. Those aren’t built out yet and the base product will be free. No part of our revenue will come from data monetization.</p><p>We’d love for you to give Muddy a spin! You can download Muddy for Mac or Windows on our website and add others once inside: <a href="https://feelmuddy.com/">https://feelmuddy.com/</a>. We’ll be around to answer questions and look forward to any and all feedback!</p></div></td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft PlayReady – Complete Client Identity Compromise (181 pts)]]></title>
            <link>https://seclists.org/fulldisclosure/2024/May/5</link>
            <guid>40308261</guid>
            <pubDate>Thu, 09 May 2024 13:53:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://seclists.org/fulldisclosure/2024/May/5">https://seclists.org/fulldisclosure/2024/May/5</a>, See on <a href="https://news.ycombinator.com/item?id=40308261">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="nst-content">

<!--X-Body-Begin-->
<!--X-User-Header-->
<a href="https://seclists.org/fulldisclosure/"><img src="https://seclists.org/images/fulldisclosure-logo.png" width="80" alt="fulldisclosure logo"></a>
<h2><a href="https://seclists.org/fulldisclosure/">Full Disclosure</a>
mailing list archives</h2>
<!--X-User-Header-End-->
<!--X-TopPNI-->


<!--X-TopPNI-End-->
<!--X-MsgBody-->
<!--X-Subject-Header-Begin-->

<hr>
<!--X-Subject-Header-End-->
<!--X-Head-of-Message-->


<em>From</em>: Security Explorations &lt;contact () security-explorations com&gt;<br>

<em>Date</em>: Thu, 9 May 2024 10:02:26 +0200<br>

<!--X-Head-of-Message-End-->
<!--X-Head-Body-Sep-Begin-->
<hr>
<!--X-Head-Body-Sep-End-->
<!--X-Body-of-Message-->
<pre>Hello All,

We have come up with two attack scenarios that make it possible to
extract private ECC keys used by a PlayReady client (Windows SW DRM
scenario) for the communication with a license server and identity
purposes.

More specifically, we successfully demonstrated the extraction of the
following keys:
- private signing key used to digitally sign license requests issued
by PlayReady client,
- private encryption key used to decrypt license responses received by
the client (decrypt license blobs carrying encrypted content keys).

A proof for the above (which Microsoft should be able to confirm) is
available at this link:
<a rel="nofollow" href="https://security-explorations.com/samples/wbpmp_id_compromise_proof.txt">https://security-explorations.com/samples/wbpmp_id_compromise_proof.txt</a>

While PlayReady security is primary about security of content keys,
ECC keys that make up client identity are even more important. Upon
compromise, these keys can be used to mimic a PlayReady client outside
of a Protected Media Path environment and regardless of the imposed
security restrictions.

In that context, extraction of ECC keys used as part of a PlayReady
client identity constitute an ultimate compromise of a PlayReady
client on Windows ("escape" of the PMP environment, ability to request
licenses and decrypt content keys).

Content key extraction from Protected Media Path process (through XOR
key or white-box crypto data structures) in a combination with this
latest identity compromise attack means that there is nothing left to
break when it comes to Windows SW DRM implementation.

Let this serve as a reminder that PlayReady content protection
implemented in software and on a client side has little chances of a
“survival” (understood as a state of not being successfully reverse
engineered and compromised). In that context, this is vendor’s
responsibility to constantly increase the bar and with the use of all
available technological means.

Thank you.

Best Regards,
Adam Gowdiak

----------------------------------
Security Explorations -
AG Security Research Lab
<a rel="nofollow" href="https://security-explorations.com/">https://security-explorations.com</a>
----------------------------------
_______________________________________________
Sent through the Full Disclosure mailing list
<a rel="nofollow" href="https://nmap.org/mailman/listinfo/fulldisclosure">https://nmap.org/mailman/listinfo/fulldisclosure</a>
Web Archives &amp; RSS: <a rel="nofollow" href="https://seclists.org/fulldisclosure/">https://seclists.org/fulldisclosure/</a></pre>
<!--X-Body-of-Message-End-->
<!--X-MsgBody-End-->
<!--X-Follow-Ups-->
<hr>
<!--X-Follow-Ups-End-->
<!--X-References-->
<!--X-References-End-->
<!--X-BotPNI-->

<h3>Current thread:</h3>
<ul>
<li><strong>Microsoft PlayReady - complete client identity compromise</strong> <em>Security Explorations (May 09)</em>
</li></ul>


<!--X-BotPNI-End-->
<!--X-User-Footer-->
<!--X-User-Footer-End-->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VideoPrism: A foundational visual encoder for video understanding (102 pts)]]></title>
            <link>https://research.google/blog/videoprism-a-foundational-visual-encoder-for-video-understanding/</link>
            <guid>40308044</guid>
            <pubDate>Thu, 09 May 2024 13:32:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.google/blog/videoprism-a-foundational-visual-encoder-for-video-understanding/">https://research.google/blog/videoprism-a-foundational-visual-encoder-for-video-understanding/</a>, See on <a href="https://news.ycombinator.com/item?id=40308044">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                <section>
  <h2>Quick links</h2>
  <ul>
    
    
      
    
  </ul>
</section>
                
                


<div>
        <p><span>Posted by Long Zhao, Senior Research Scientist, and Ting Liu, Senior Staff Software Engineer, Google Research</span> </p>
<p>An astounding number of videos are available on the Web, covering a variety of content from everyday moments people share to historical moments to scientific observations, each of which contains a unique record of the world. The right tools could help researchers analyze these videos, transforming how we understand the world around us.</p>

<p>Videos offer dynamic visual content far more rich than static images, capturing movement, changes, and dynamic relationships between entities. Analyzing this complexity, along with the immense diversity of publicly available video data, demands models that go beyond traditional image understanding. Consequently, many of the approaches that best perform on video understanding still rely on specialized models tailor-made for particular tasks. Recently, there has been exciting progress in this area using video foundation models (ViFMs), such as <a href="https://arxiv.org/abs/2109.14084" target="_blank" rel="noopener noreferrer">VideoCLIP</a>, <a href="https://arxiv.org/abs/2212.03191" target="_blank" rel="noopener noreferrer">InternVideo</a>, <a href="https://arxiv.org/abs/2212.04979" target="_blank" rel="noopener noreferrer">VideoCoCa</a>, and <a href="https://arxiv.org/abs/2303.16058" target="_blank" rel="noopener noreferrer">UMT</a>. However, building a ViFM that handles the sheer diversity of video data remains a challenge.</p>
<p>With the goal of building a single model for general-purpose video understanding, we introduce “<a href="https://arxiv.org/abs/2402.13217" target="_blank" rel="noopener noreferrer">VideoPrism: A Foundational Visual Encoder for Video Understanding</a>”. VideoPrism is a ViFM designed to handle a wide spectrum of video understanding tasks, including classification, localization, retrieval, captioning, and question answering (QA). We propose innovations in both the pre-training data as well as the modeling strategy. We pre-train VideoPrism on a massive and diverse dataset: 36 million high-quality video-text pairs and 582 million video clips with noisy or machine-generated parallel text. Our pre-training approach is designed for this hybrid data, to learn both from video-text pairs and the videos themselves. VideoPrism is incredibly easy to adapt to new video understanding challenges, and achieves state-of-the-art performance using a single frozen model.</p>


<p>VideoPrism is a general-purpose video encoder that enables state-of-the-art results over a wide spectrum of video understanding tasks, including classification, localization, retrieval, captioning, and question answering, by producing video representations from a single frozen model.</p>

<h2>Pre-training data</h2>
<p>A powerful ViFM needs a very large collection of videos on which to train — similar to other foundation models (FMs), such as those for large language models (LLMs). Ideally, we would want the pre-training data to be a representative sample of all the videos in the world. While naturally most of these videos do not have perfect captions or descriptions, even imperfect text can provide useful information about the semantic content of the video.</p>
<p>To give our model the best possible starting point, we put together a massive pre-training corpus consisting of several public and private datasets, including <a href="https://rowanzellers.com/merlot/" target="_blank" rel="noopener noreferrer">YT-Temporal-180M</a>, <a href="https://arxiv.org/abs/2307.06942" target="_blank" rel="noopener noreferrer">InternVid</a>, <a href="https://arxiv.org/abs/2204.00679" target="_blank" rel="noopener noreferrer">VideoCC</a>, <a href="https://arxiv.org/abs/2007.14937" target="_blank" rel="noopener noreferrer">WTS-70M</a>, etc. This includes 36 million carefully selected videos with high-quality captions, along with an additional 582 million clips with varying levels of noisy text (like auto-generated transcripts). To our knowledge, this is the largest and most diverse video training corpus of its kind.</p>
<table>
<tbody>
<tr>
<td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrhfnM1Rg_xbS1b3ZtydWc0M7zOchLpi5qdj65UaR3mOYbV8SQQqKhUhltYwmkPNqrULdeVeE1nU3gnRkjR7pE-yFaiVRC1al-BxZecsO0aojXFzSDhfv45oZoOBeYA93IiNeCGdnUryh4HLc3w7Qr2PX0fy6-4qFMTKBORA_PfHspp7Nr1OW0WnAvn-S9/s1999/image18.png" target="_blank" rel="noopener noreferrer"><img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrhfnM1Rg_xbS1b3ZtydWc0M7zOchLpi5qdj65UaR3mOYbV8SQQqKhUhltYwmkPNqrULdeVeE1nU3gnRkjR7pE-yFaiVRC1al-BxZecsO0aojXFzSDhfv45oZoOBeYA93IiNeCGdnUryh4HLc3w7Qr2PX0fy6-4qFMTKBORA_PfHspp7Nr1OW0WnAvn-S9/s16000/image18.png" data-original-height="779" data-original-width="1999"></a></td>
</tr>
<tr>
<td>Statistics on the video-text pre-training data. The large variations of the&nbsp;<a href="https://arxiv.org/abs/2104.14806" target="_blank" rel="noopener noreferrer">CLIP similarity scores</a>&nbsp;(the higher, the better) demonstrate the diverse caption quality of our pre-training data, which is a byproduct of the various ways used to harvest the text.</td>
</tr>
</tbody>
</table>

<h2>Two-stage training</h2>
<p>The VideoPrism model architecture stems from the standard <a href="https://arxiv.org/abs/2010.11929" target="_blank" rel="noopener noreferrer">vision transformer</a> (ViT) with a factorized design that sequentially encodes spatial and temporal information following <a href="https://arxiv.org/abs/2103.15691" target="_blank" rel="noopener noreferrer">ViViT</a>. Our training approach leverages both the high-quality video-text data and the video data with noisy text mentioned above. To start, we use <a href="https://en.wikipedia.org/wiki/Self-supervised_learning#Contrastive_self-supervised_learning" target="_blank" rel="noopener noreferrer">contrastive learning</a> (an approach that minimizes the distance between positive video-text pairs while maximizing the distance between negative video-text pairs) to teach our model to match videos with their own text descriptions, including imperfect ones. This builds a foundation for matching semantic language content to visual content.</p>
<p>After video-text contrastive training, we leverage the collection of videos without text descriptions. Here, we build on the <a href="https://arxiv.org/abs/2212.04500" target="_blank" rel="noopener noreferrer">masked video modeling framework</a> to predict masked patches in a video, with a few improvements. We train the model to predict both the video-level global embedding and token-wise embeddings from the first-stage model to effectively leverage the knowledge acquired in that stage. We then randomly shuffle the predicted tokens to prevent the model from learning shortcuts.</p>
<p>What is unique about VideoPrism’s setup is that we use two complementary pre-training signals: text descriptions and the visual content within a video. Text descriptions often focus on what things look like, while the video content provides information about movement and visual dynamics. This enables VideoPrism to excel in tasks that demand an understanding of both appearance and motion.</p>

<h2>Results</h2>
<p>We conduct extensive evaluation on VideoPrism across four broad categories of video understanding tasks, including video classification and localization, video-text retrieval, video captioning, question answering, and scientific video understanding. VideoPrism achieves state-of-the-art performance on 30 out of 33 video understanding benchmarks — all with minimal adaptation of a single, frozen model.</p>
<table>
<tbody>
<tr>
<td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgiUtXCxgEXrgAZJ2B-Mn8L0DP7VkFUfUbI1yLTgGYSbWtn_Q5AjgGRgi3yQ5PMB3fVFlHLzDP4yhlCeGaPpdXr5I1-TNYelYMUBYiXx16qNYTpqKwAqXX7-EFV-4Asn6qYFWOb6_5p71n5Zzxbt-ZeUy5yIj2aieKXl0LnFOqdhKXa56xm4ZoXbccYDz3H/s1999/image20.png" target="_blank" rel="noopener noreferrer"><img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgiUtXCxgEXrgAZJ2B-Mn8L0DP7VkFUfUbI1yLTgGYSbWtn_Q5AjgGRgi3yQ5PMB3fVFlHLzDP4yhlCeGaPpdXr5I1-TNYelYMUBYiXx16qNYTpqKwAqXX7-EFV-4Asn6qYFWOb6_5p71n5Zzxbt-ZeUy5yIj2aieKXl0LnFOqdhKXa56xm4ZoXbccYDz3H/w628-h640/image20.png" width="628" height="640" data-original-height="1999" data-original-width="1959"></a></td>
</tr>
<tr>
<td>VideoPrism compared to the previous best-performing FMs.</td>
</tr>
</tbody>
</table>

<h3>Classification and localization</h3>
<p>We evaluate VideoPrism on an existing large-scale video understanding benchmark (<a href="https://arxiv.org/abs/2307.03166" target="_blank" rel="noopener noreferrer">VideoGLUE</a>) covering classification and localization tasks. We find that (1) VideoPrism outperforms all of the other state-of-the-art FMs, and (2) no other single model consistently came in second place. This tells us that VideoPrism has learned to effectively pack a variety of video signals into one encoder — from semantics at different granularities to appearance and motion cues — and it works well across a variety of video sources.</p>


<h3>Combining with LLMs</h3>
<p>We further explore combining VideoPrism with LLMs to unlock its ability to handle various video-language tasks. In particular, when paired with a text encoder (following <a href="https://arxiv.org/abs/2111.07991" target="_blank" rel="noopener noreferrer">LiT</a>) or a language decoder (such as <a href="https://arxiv.org/abs/2305.10403" target="_blank" rel="noopener noreferrer">PaLM-2</a>), VideoPrism can be utilized for video-text retrieval, video captioning, and video QA tasks. We compare the combined models on a broad and challenging set of vision-language benchmarks. VideoPrism sets the new state of the art on most benchmarks. From the visual results, we find that VideoPrism is capable of understanding complex motions and appearances in videos (e.g., the model can recognize the different colors of spinning objects on the window in the visual examples below). These results demonstrate that VideoPrism is strongly compatible with language models.</p>


<p>We show qualitative results using VideoPrism with a text encoder for video-text retrieval (first row) and adapted to a language decoder for video QA (second and third row). For video-text retrieval examples, the blue bars indicate the embedding similarities between the videos and the text queries.</p>

<h3>Scientific applications</h3>
<p>Finally, we test VideoPrism on datasets used by scientists across domains, including fields such as ethology, behavioral neuroscience, and ecology. These datasets typically require domain expertise to annotate, for which we leverage existing scientific datasets open-sourced by the community including <a href="https://data.caltech.edu/records/zrznw-w7386" target="_blank" rel="noopener noreferrer">Fly vs. Fly</a>, <a href="https://data.caltech.edu/records/s0vdx-0k302" target="_blank" rel="noopener noreferrer">CalMS21</a>, <a href="https://shirleymaxx.github.io/ChimpACT/" target="_blank" rel="noopener noreferrer">ChimpACT</a>, and <a href="https://dirtmaxim.github.io/kabr/" target="_blank" rel="noopener noreferrer">KABR</a>. VideoPrism not only performs exceptionally well, but actually surpasses models designed specifically for those tasks. This suggests tools like VideoPrism have the potential to transform how scientists analyze video data across different fields.</p>
<table>
<tbody>
<tr>
<td><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3v-C36GWUp8CkaCVqFvaXYKW6-1SvCo99Ogiul-fSTkftyc-t4z5CNUgEWlJkRmzranQrYHldtBvjeJXsqdB4ZbgBkyaZv-_I9QE5U7kus_Z8QWlVqfzX0JfELSDPfGj9V4QqhUMwX_EkyPM-vG7pdYMXN0kj1-s98IZJl3U8CpvqoOHyAsuwXIVt7M4_/s1200/image5.png" target="_blank" rel="noopener noreferrer"><img src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3v-C36GWUp8CkaCVqFvaXYKW6-1SvCo99Ogiul-fSTkftyc-t4z5CNUgEWlJkRmzranQrYHldtBvjeJXsqdB4ZbgBkyaZv-_I9QE5U7kus_Z8QWlVqfzX0JfELSDPfGj9V4QqhUMwX_EkyPM-vG7pdYMXN0kj1-s98IZJl3U8CpvqoOHyAsuwXIVt7M4_/w640-h397/image5.png" width="640" height="397" data-original-height="742" data-original-width="1200"></a></td>
</tr>
<tr>
<td>VideoPrism outperforms the domain experts on various scientific benchmarks. We show the absolute score differences to highlight the relative improvements of VideoPrism. We report mean average precision (mAP) for all datasets, except for KABR which uses class-averaged top-1 accuracy.</td>
</tr>
</tbody>
</table>

<h2>Conclusion</h2>
<p>With VideoPrism, we introduce a powerful and versatile video encoder that sets a new standard for general-purpose video understanding. Our emphasis on both building a massive and varied pre-training dataset and innovative modeling techniques has been validated through our extensive evaluations. Not only does VideoPrism consistently outperform strong baselines, but its unique ability to generalize positions it well for tackling an array of real-world applications. Because of its potential broad use, we are committed to continuing further responsible research in this space, guided by our <a href="http://ai.google/principles" target="_blank" rel="noopener noreferrer">AI Principles</a>. We hope VideoPrism paves the way for future breakthroughs at the intersection of AI and video analysis, helping to realize the potential of ViFMs across domains such as scientific discovery, education, and healthcare.</p>

<h2>Acknowledgements</h2>
<p><em>This blog post is made on behalf of all the VideoPrism authors: Long Zhao, Nitesh B. Gundavarapu, Liangzhe Yuan, Hao Zhou, Shen Yan, Jennifer J. Sun, Luke Friedman, Rui Qian, Tobias Weyand, Yue Zhao, Rachel Hornung, Florian Schroff, Ming-Hsuan Yang, David A. Ross, Huisheng Wang, Hartwig Adam, Mikhail Sirotenko, Ting Liu, and Boqing Gong. We sincerely thank David Hendon for their product management efforts, and Alex Siegman, Ramya Ganeshan, and Victor Gomes for their program and resource management efforts. We also thank Hassan Akbari, Sherry Ben, Yoni Ben-Meshulam, Chun-Te Chu, Sam Clearwater, Yin Cui, Ilya Figotin, Anja Hauth, Sergey Ioffe, Xuhui Jia, Yeqing Li, Lu Jiang, Zu Kim, Dan Kondratyuk, Bill Mark, Arsha Nagrani, Caroline Pantofaru, Sushant Prakash, Cordelia Schmid, Bryan Seybold, Mojtaba Seyedhosseini, Amanda Sadler, Rif A. Saurous, Rachel Stigler, Paul Voigtlaender, Pingmei Xu, Chaochao Yan, Xuan Yang, and Yukun Zhu for the discussions, support, and feedback that greatly contributed to this work. We are grateful to Jay Yagnik, Rahul Sukthankar, and Tomas Izo for their enthusiastic support for this project. Lastly, we thank Tom Small, Jennifer J. Sun, Hao Zhou, Nitesh B. Gundavarapu, Luke Friedman, and Mikhail Sirotenko for the tremendous help with making this blog post.</em></p>

    </div>

                

                


<section aria-label="List of footnotes">
  <ol>
    
  </ol>
</section>

                


            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No "Zero-Shot" Without Exponential Data (175 pts)]]></title>
            <link>https://arxiv.org/abs/2404.04125</link>
            <guid>40307832</guid>
            <pubDate>Thu, 09 May 2024 13:08:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2404.04125">https://arxiv.org/abs/2404.04125</a>, See on <a href="https://news.ycombinator.com/item?id=40307832">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2404.04125">View PDF</a>
    <a href="https://arxiv.org/html/2404.04125v2">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Web-crawled pretraining datasets underlie the impressive "zero-shot" evaluation performance of multimodal models, such as CLIP for classification/retrieval and Stable-Diffusion for image generation. However, it is unclear how meaningful the notion of "zero-shot" generalization is for such multimodal models, as it is not known to what extent their pretraining datasets encompass the downstream concepts targeted for during "zero-shot" evaluation. In this work, we ask: How is the performance of multimodal models on downstream concepts influenced by the frequency of these concepts in their pretraining datasets? We comprehensively investigate this question across 34 models and five standard pretraining datasets (CC-3M, CC-12M, YFCC-15M, LAION-400M, LAION-Aesthetics), generating over 300GB of data artifacts. We consistently find that, far from exhibiting "zero-shot" generalization, multimodal models require exponentially more data to achieve linear improvements in downstream "zero-shot" performance, following a sample inefficient log-linear scaling trend. This trend persists even when controlling for sample-level similarity between pretraining and downstream datasets, and testing on purely synthetic data distributions. Furthermore, upon benchmarking models on long-tailed data sampled based on our analysis, we demonstrate that multimodal models across the board perform poorly. We contribute this long-tail test set as the "Let it Wag!" benchmark to further research in this direction. Taken together, our study reveals an exponential need for training data which implies that the key to "zero-shot" generalization capabilities under large-scale training paradigms remains to be found.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Vishaal Udandarao [<a href="https://arxiv.org/show-email/3ec97a25/2404.04125">view email</a>]      <br>            <strong><a href="https://arxiv.org/abs/2404.04125v1">[v1]</a></strong>
        Thu, 4 Apr 2024 17:58:02 UTC (37,862 KB)<br>
    <strong>[v2]</strong>
        Mon, 8 Apr 2024 21:14:43 UTC (37,863 KB)<br>
</p></div></div>]]></description>
        </item>
    </channel>
</rss>