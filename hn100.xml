<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 05 Feb 2026 01:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[How Jeff Bezos Brought Down the Washington Post (208 pts)]]></title>
            <link>https://www.newyorker.com/news/annals-of-communications/how-jeff-bezos-brought-down-the-washington-post</link>
            <guid>46890034</guid>
            <pubDate>Wed, 04 Feb 2026 18:56:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newyorker.com/news/annals-of-communications/how-jeff-bezos-brought-down-the-washington-post">https://www.newyorker.com/news/annals-of-communications/how-jeff-bezos-brought-down-the-washington-post</a>, See on <a href="https://news.ycombinator.com/item?id=46890034">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content" tabindex="-1"><article lang="en-US"><div><header data-testid="SplitScreenContentHeaderWrapper"><div data-journey-hook="grid-wrapper"><div><p>The Amazon founder bought the paper to save it. Instead, with a mass layoff, he’s forced it into severe decline.</p></div><div><p><span><picture><source media="(max-width: 767px)" srcset="https://media.newyorker.com/photos/69823708afa37297f9cff815/3:4/w_120,c_limit/Marcus-GettyImages-2257983026.jpg 120w, https://media.newyorker.com/photos/69823708afa37297f9cff815/3:4/w_240,c_limit/Marcus-GettyImages-2257983026.jpg 240w, https://media.newyorker.com/photos/69823708afa37297f9cff815/3:4/w_320,c_limit/Marcus-GettyImages-2257983026.jpg 320w, https://media.newyorker.com/photos/69823708afa37297f9cff815/3:4/w_640,c_limit/Marcus-GettyImages-2257983026.jpg 640w, https://media.newyorker.com/photos/69823708afa37297f9cff815/3:4/w_960,c_limit/Marcus-GettyImages-2257983026.jpg 960w" sizes="100vw"><source media="(min-width: 768px)" srcset="https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_120,c_limit/Marcus-GettyImages-2257983026.jpg 120w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_240,c_limit/Marcus-GettyImages-2257983026.jpg 240w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_320,c_limit/Marcus-GettyImages-2257983026.jpg 320w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_640,c_limit/Marcus-GettyImages-2257983026.jpg 640w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_960,c_limit/Marcus-GettyImages-2257983026.jpg 960w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_1280,c_limit/Marcus-GettyImages-2257983026.jpg 1280w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_1600,c_limit/Marcus-GettyImages-2257983026.jpg 1600w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_1920,c_limit/Marcus-GettyImages-2257983026.jpg 1920w, https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_2240,c_limit/Marcus-GettyImages-2257983026.jpg 2240w" sizes="100vw"><img alt="The Washington Post building." loading="eager" src="https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_2560%2Cc_limit/Marcus-GettyImages-2257983026.jpg" data-src="https://media.newyorker.com/photos/69823708afa37297f9cff815/master/w_2560%2Cc_limit/Marcus-GettyImages-2257983026.jpg"></picture></span></p></div></div><div data-journey-hook="grid-wrapper"><p><span>Photograph by Kent Nishimura / Bloomberg / Getty</span></p></div></header></div><div data-testid="ArticlePageChunks" data-attribute-verso-pattern="article-body"><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>On September 4, 2013, the Amazon founder <a href="https://www.newyorker.com/tag/jeff-bezos">Jeff Bezos</a> held his first meeting with the staff of the Washington <em>Post</em>, the newspaper he had agreed to purchase a month earlier from the Graham family, for two hundred and fifty million dollars. It had been a long and unsettling stretch for the paper’s staff. We—I was a deputy editor of the editorial page at the time—had suffered through years of retrenchment. We trusted that Don Graham would place us in capable hands, but we did not know this new owner, and he did not know or love our business in the way that the Graham family had. Bezos’s words at that meeting, about “a new golden era for the Washington <em>Post</em>,” were reassuring. Bob Woodward asked why he had purchased the paper, and Bezos was clear about the commitment he was prepared to make. “I finally concluded that I could provide runway—financial runway—because I don’t think you can keep shrinking the business,” he said. “You can be profitable and shrinking. And that’s a survival strategy, but it ultimately leads to irrelevance, at best. And, at worst, it leads to extinction.”</p><p>To look back on that moment is to wonder: How could it have come to this? The paper had some profitable years under Bezos, sparked by the 2016 election and the first Trump term. But it began losing enormous sums: seventy-seven million dollars in 2023, another hundred million in 2024. The owner who once offered runway was unwilling to tolerate losses of that magnitude. And so, after years of Bezos-fuelled growth, the <em>Post</em> endured two punishing rounds of voluntary buyouts, in 2023 and 2025, that reduced its newsroom from more than a thousand staffers to under eight hundred, and cost the <em>Post</em> some of its best writers and editors. Then, early Wednesday morning, newsroom employees received an e-mail announcing “some significant actions.” They were instructed to stay home and attend a “Zoom webinar at 8:30 <em>a.m.</em>” Everyone knew what was coming—mass layoffs.</p><p>The scale of the demolition, though, was staggering—<a data-offer-url="https://www.nytimes.com/2026/02/04/business/media/washington-post-layoffs.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.nytimes.com/2026/02/04/business/media/washington-post-layoffs.html&quot;}" href="https://www.nytimes.com/2026/02/04/business/media/washington-post-layoffs.html" rel="nofollow noopener" target="_blank">reportedly</a> more than three hundred newsroom staffers. The announcement was left to the executive editor, Matt Murray, and human-relations chief Wayne Connell; the newspaper’s publisher, Will Lewis, was nowhere to be seen as the grim news was unveiled. In what Murray termed a “broad strategic reset,” the <em>Post</em>’s storied sports department was shuttered “in its current form”; several reporters will now cover sports as a “cultural and societal phenomenon.” The metro staff, already cut to about forty staffers during the past five years, has been shrunk to about twelve; the foreign desks will be reduced to approximately twelve locations from more than twenty; Peter Finn, the international editor, told me that he asked to be laid off. The books section and the flagship podcast, “Post Reports,” will end. Shortly after the meeting, staffers received individualized e-mails letting them know whether they would stay or go. Murray said the retrenched <em>Post</em> would “concentrate on areas that demonstrate authority, distinctiveness, and impact,” focussing on areas such as politics and national security. This strategy, a kind of <em>Politico</em>-lite, would be more convincing if so many of the most talented players were not already gone.</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>Graham, who has previously been resolutely silent about changes at the paper, posted a message on Facebook that pulsed with anguish. “It’s a bad day,” he wrote, adding, “I am sad that so many excellent reporters and editors—and old friends—are losing their jobs. My first concern is for them; I will do anything I can to help.” As for himself, Graham, who once edited the sports section, said, “I will have to learn a new way to read the paper, since I have started with the sports page since the late 1940’s.”</p><p>What happened to the Bezos of 2013, a self-proclaimed optimist who seemed to have absorbed the importance of the <em>Post</em> in the nation’s journalistic ecosystem? In 2016, dedicating the paper’s new headquarters, he boasted that it had become “a little more swashbuckling” and had a “little more swagger.” As recently as December, 2024, at the New York <em>Times</em>’ DealBook Summit, Bezos expressed his commitment to nurturing the paper: “The advantage I bring to the <em>Post</em> is when they need financial resources, I’m available. I’m like that. I’m the doting parent in that regard.” Not long ago, he envisioned attracting as many as a hundred million paying subscribers to the <em>Post</em>. With these brutal cuts, he seems content to let the paper limp along, diminished in size and ambition.</p><p>“In the beginning, he was wonderful,” Sally Quinn, the veteran <em>Post</em> contributor and wife of its legendary executive editor, Ben Bradlee, told me of Bezos. “He was smart and funny and kind and interested. He was joyful. He was a person of integrity and conscience. He really meant it when he said this was a sacred trust, to buy the <em>Post</em>. And now I don’t know who this person is.”</p><p>The author David Maraniss was with the <em>Post</em> for forty-eight years. He resigned as an associate editor in 2024, after Bezos killed the editorial page’s planned endorsement of Kamala Harris. “He bought the <em>Post</em> thinking that it would give him some gravitas and grace that he couldn’t get just from billions of dollars, and then the world changed,” Maraniss said of Bezos. “Now I don’t think he gives us—I don’t think he gives a flying fuck.”</p><p>I asked Maraniss what cuts of this magnitude would mean for the institution. “I don’t even want to call it the Washington <em>Post</em>,” he said. “I don’t know what it’ll be without all of that.”</p><p>The first sign of impending layoffs came in late January, when the sports staff was informed that plans to send writers to Italy to cover the Winter Olympics had been cancelled. (Management later agreed to send a smaller crew.) In the following days, as rumors began to spread of severe cuts, the paper’s reporters began posting messages directed at Bezos on X, with the plaintive hashtag #SaveThePost. “Our reporters on the ground drove exclusive coverage during pivotal moments of recent history,” the foreign staff wrote to Bezos. “We have so much left to do.” The local staff noted that it had already been slashed in half in the past five years. “Watergate,” they wrote, “started as a local story.”</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>It did not help the staff’s morale that Lewis and his team were hobnobbing in Davos, or that Bezos and his wife, Lauren Sánchez, were in Paris for Haute Couture Week. More troubling were reminders that Bezos, who once emblazoned “Democracy Dies in Darkness” on the paper’s masthead, appears to be pursuing a policy of appeasement toward the Trump Administration. During the first Trump term, Bezos stood by the <em>Post</em> even when his stewardship threatened to cost him billions in government contracts. Now Bezos had not said a word about a recent F.B.I. raid on the home of the <em>Post</em> federal-government reporter Hannah Natanson, in which the agency seized her phones, laptops, and other devices. As the staff awaited the axe, the President and the First Lady celebrated the première of “<a href="https://www.newyorker.com/culture/critics-notebook/melania-is-a-forty-million-dollar-journey-into-the-void">Melania</a>,” a documentary that Amazon had licensed for forty million dollars and was reported to be spending another thirty-five million to promote. The deal was inked after Bezos had dinner with the Trumps shortly before the Inauguration.</p><p>Martin Baron, who oversaw coverage at the paper that garnered eleven Pulitzer Prizes during his eight years as executive editor, said in a statement, “This ranks among the darkest days in the history of one of the world’s greatest news organizations. The Washington <em>Post</em>’s ambitions will be sharply diminished, its talented and brave staff will be further depleted, and the public will be denied the ground-level, fact-based reporting in our communities and around the world that is needed more than ever.” The news industry is in “a period of head-spinning change,” Baron told me. But the <em>Post’s</em> problems “were made infinitely worse by ill-conceived decisions that came from the very top.” He pointed to Bezos’s decision to kill the Harris endorsement—a “gutless order” that cost the paper more than two hundred fifty thousand subscribers. “Loyal readers, livid as they saw owner Jeff Bezos betraying the values he was supposed to uphold, fled The Post. In truth, they were driven away, by the hundreds of thousands,” Baron said. “Bezos’s sickening efforts to curry favor with President Trump have left an especially ugly stain of their own. This is a case study in near-instant, self-inflicted brand destruction.”</p><p>I spent more than forty years at the <em>Post</em>, as a reporter, an editor, an editorial writer, and a columnist. I <a href="https://www.newyorker.com/news/essay/why-ruth-marcus-left-the-washington-post">resigned</a> last March, after Bezos announced that the Opinions section, where I worked, would henceforth be concentrating on the twin pillars of “personal liberties and free markets.” More alarming, Bezos advised, “Viewpoints opposing those pillars will be left to be published by others.” We had been an opinion section reflecting a wide range of views—which Bezos himself had encouraged. It seemed obvious that this change was deeply misguided.</p><p>I had written a column critical of the non-endorsement decision several months earlier. The paper published it without any substantive changes. But, when I wrote a column disagreeing with the no-dissent-allowed dictum, I was told that Lewis had killed it—it apparently didn’t meet the “high bar” for the <em>Post</em> to write about itself—and declined my request to meet. I submitted my letter of resignation. A new editorial-page editor went on to shift both unsigned editorials and signed opinion columns dramatically to the right, to the point that no liberal columnists remain. One recent <a data-offer-url="https://www.washingtonpost.com/opinions/2025/10/25/ballroom-east-wing-trump-white-house/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.washingtonpost.com/opinions/2025/10/25/ballroom-east-wing-trump-white-house/&quot;}" href="https://www.washingtonpost.com/opinions/2025/10/25/ballroom-east-wing-trump-white-house/" rel="nofollow noopener" target="_blank">editorial</a> praised the President’s plan for a new ballroom and excused his unauthorized bulldozing of the East Wing, saying that “the blueprints would have faced death by a thousand papercuts.” <a data-offer-url="https://www.washingtonpost.com/opinions/2025/09/05/war-department-defense-trump-rebrand/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.washingtonpost.com/opinions/2025/09/05/war-department-defense-trump-rebrand/&quot;}" href="https://www.washingtonpost.com/opinions/2025/09/05/war-department-defense-trump-rebrand/" rel="nofollow noopener" target="_blank">Another</a> endorsed the move to rename the Defense Department the Department of War as “a worthy blow against government euphemism.” There are some editorials critical of Trump, but the inclination to fawning praise is unmistakable. Had I not defenestrated myself, I would, no doubt, have been advised to take my buyout and go.</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>But I am not—at least, I have not been—a Bezos-hater. I am grateful for the resources, financial and technological, that he devoted to the paper in his early years as owner. The surprise of Bezos’s tenure at the <em>Post</em> has been his bad business decisions. Fred Ryan, a former chief of staff to Ronald Reagan and founding president of <em>Politico</em>, was hired as the publisher and C.E.O. in 2014 and oversaw a period of spectacular growth. Buoyed by Bezos-funded expansion and the public’s fixation on the new Trump Administration, the number of digital subscribers soared from thirty-five thousand when he arrived to two and a half million when he left, in the summer of 2023. But Ryan failed to develop an adequate plan for how the newspaper would thrive in a post-Trump environment. As traffic and revenue plunged, Ryan found himself increasingly at odds with the newsroom. He held a year-end town-hall meeting in 2022 at which he announced that layoffs were coming, and then, to the consternation of the staff, left without taking questions. As Clare Malone <a href="https://www.newyorker.com/magazine/2025/05/26/is-jeff-bezos-selling-out-the-washington-post">reported</a> for <em>The New Yorker</em>, Woodward beseeched Bezos to intercede. The owner made a rare visit to the paper in January, 2023, for meetings with key staffers, taking notes on a legal pad as they poured out their anxiety.</p><p>Ryan left that summer, but Lewis, his eventual replacement, accomplished the feat of making the newsroom nostalgic for Ryan. A decade earlier, Lewis, then a senior executive in Rupert Murdoch’s British-tabloid empire, had played a pivotal role in dealing with the fallout from the phone-hacking scandal at some of Murdoch’s papers. Lewis had said that he was acting to protect “journalistic integrity,” when the <em>Post</em> questioned him about his actions during that time, but in 2024 questions arose, fuelled by a civil lawsuit brought against the papers, about whether Lewis had sought to conceal evidence, including by carrying out a plan to delete millions of e-mails. (Lewis has said the allegations against him were “completely untrue.”) At the <em>Post</em>, Lewis clashed with executive editor Sally Buzbee over coverage of the story, reportedly insisting that it was not newsworthy. Shortly afterward, Lewis announced Buzbee’s departure, and his plan to replace her with Robert Winnett, a former colleague of his from London’s <em>Daily Telegraph</em> and <em>Sunday Times</em>. The <em>Post</em> and the <em>Times</em> <a data-offer-url="https://www.washingtonpost.com/investigations/2024/06/16/washington-post-editor-robert-winnett/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.washingtonpost.com/investigations/2024/06/16/washington-post-editor-robert-winnett/&quot;}" href="https://www.washingtonpost.com/investigations/2024/06/16/washington-post-editor-robert-winnett/" rel="nofollow noopener" target="_blank">both</a> <a data-offer-url="https://www.nytimes.com/2024/06/15/world/europe/will-lewis-records-uk-editor.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.nytimes.com/2024/06/15/world/europe/will-lewis-records-uk-editor.html&quot;}" href="https://www.nytimes.com/2024/06/15/world/europe/will-lewis-records-uk-editor.html" rel="nofollow noopener" target="_blank">reported</a> on how Lewis and Winnett had used fraudulently obtained material as the basis for articles. “His ambition outran his ethics,” one of Lewis’s former reporters told the <em>Times</em>. Winnett ended up withdrawing from the position, but the episode poisoned relations between Lewis and the newsroom.</p><p>The staff, meanwhile, became increasingly concerned that Lewis was offering corporate word salad in place of a vision to address the <em>Post</em>’s decline. “Fix it, build it, scale it” was his catchphrase when he arrived, in January, 2024. In June of that year came an amorphous plan for what Lewis called a “third newsroom.” (The second newsroom, we were surprised to learn, was the Opinions section.) First, it was to focus on social media and service journalism. Then it was rechristened WP Ventures and, according to a memo to staff, would “focus entirely on building personality-driven content and franchises around personalities.” By February, 2025, the situation had deteriorated to the point that two former top editors, Leonard Downie and Robert Kaiser, wrote to Bezos about Lewis. “Replacing him is a crucial first step in saving The Washington Post,” they urged in an e-mail. Bezos never responded.</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>Downie, who served as executive editor from 1991 to 2008, contrasted the paths of the <em>Times</em> and the <em>Post</em>. During the past decade, the <em>Times</em> transformed itself into a one-stop-shopping environment that lured readers with games such as Spelling Bee, a cooking app, and a shopping guide. By the end of 2025, it was reporting close to thirteen million digital subscribers and an operating profit of more than a hundred and ninety-two million dollars. The <em>Post</em> does not release information about its digital subscribers, but it was reported to have two and a half million digital subscribers at the time of the non-endorsement decision, in 2024.</p><p>“One of the big differences to me was that they hired a publisher”—Ryan—“who didn’t come up with any ideas,” Downie told me. “And then when he left&nbsp;.&nbsp;.&nbsp;.&nbsp;we knew that Bezos was losing money, and we were encouraged by the fact that they were looking for somebody who could improve the business side of the paper and the circulation side of the paper. And then they chose this guy who we hardly ever heard from, who had a checkered past in British journalism.”</p><p>Writing last month on a private Listserv for former <em>Post</em> employees, Paul Farhi, who as the media reporter for the <em>Post</em> covered Bezos’s acquisition of the paper, shared his “utter mystification and bafflement” about Bezos’s tolerance of Lewis. “Even as a hands-off boss,” he wondered, “could Bezos not see what was obvious to even casual observers within a few months of Will’s arrival—that Will was ill-suited to the Post, that he had alienated the newsroom, that he had an ethically suspect past, and—most important—that none of his big ideas was working or even being implemented?” (Farhi, who took a buyout in 2023, gave me permission to quote his message.)</p><p>Even before these new cuts, a parade of key staffers had left the <em>Post</em>. A beloved managing editor, Matea Gold, went to the <em>Times</em>. The national editor, Philip Rucker, decamped to CNN, and the political reporter Josh Dawsey to the <em>Wall Street</em> <em>Journal</em>. The <em>Atlantic</em> hired, among others, three stars of the paper’s White House team: Ashley Parker, Michael Scherer, and Toluse Olorunnipa. These are losses that would take years to rebuild—if the <em>Post</em> were in a rebuilding mode. The <em>Post</em>, Woodward said, “lives and is doing an extraordinary reporting job on the political crisis that is Donald Trump”—including its scoop on the second strike to kill survivors of an attack on an alleged Venezuelan drug boat. But the print edition is a shadow of its former self, with metro, style, and sports melded into an anemic second section; daily print circulation is now below one hundred thousand. More pressingly, it’s unclear whether a newsroom so stripped of resources can sustain the quality of its work.</p><p>The sports columnist Sally Jenkins, who left the <em>Post</em> in August, 2025, as part of the second wave of buyouts, has been more supportive of management than many other <em>Post</em> veterans. So it was striking that, when we spoke recently, she was both passionate about the work of her newsroom colleagues and unsparing about how the business side had failed them. “When you whack at these sections, you’re whacking at the roots of the tree,” she told me. “We train great journalists in every section of the paper, and we train them to cover every subject on the globe. And when you whack whole sections of people away, you are really, really in danger of killing the whole tree.” When I asked how she felt about the losses, Jenkins said, “My heart is cracked in about five different pieces.”</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>Jenkins, who was in California covering Super Bowl week for the <em>Atlantic</em>, has spent a career studying what accounts for the difference between winning teams and losing ones. Bezos, she said, had been generous with his money and laudable for never interfering in the work of the newsroom. But, she added, “making money at journalism, you have to break rocks with a shovel. You have to love thinking about journalism to the point that it wakes you up at night with an idea, and then you have to be willing to try it. And I don’t see a sense that he loves the business enough to think about it at night. It’s almost like he’s treated it like Pets.com—an interesting experiment that he’s willing to lose some money on until he’s not. But the difference with this business is it’s not Pets.com. It’s not a business that just disappears into the muck of venture capitalism. It’s a business that is essential to the survival of the Republic, for Christ’s sake. So you don’t fuck around with it like that.”</p><p>As <em>Post</em> staffers and alumni braced for the cuts, I called Kaiser, the former managing editor, who spent more than half a century at the paper. “Mr. Bezos’s personal system has failed him in a way I fear he doesn’t grasp,” Kaiser, now eighty-two, told me. “He has no sense of the damage that will be done to his reputation in history if he becomes seen as the man who destroyed the institution that Katharine Graham”—the famed publisher who led the paper from the sixties to the nineties—“and Ben Bradlee built.” Kaiser recalled arriving at the paper’s London bureau in 1964. “If I say, ‘I’m Kaiser from the Washington <em>Post’</em>—what’s that? They never heard of it.” A decade later, he was posted in Moscow, as Woodward and Carl Bernstein were breaking the Watergate story. “Explaining was not necessary,” Kaiser said. “The Russians, in fact, had a gloriously exaggerated impression of the Washington <em>Post</em> as the king-maker and the king-destroyer.”</p><p>Bezos, Kaiser continued, “knew what the role was, acknowledged the role—those words ‘doting parent’—and then he walked away from it. What the hell?” The damage, he predicted, will reverberate beyond the immediate cuts. “What purpose does any honorable, attractive, competent journalist have for remaining at the <em>Post</em>? None.”</p><p>At one point, as we talked about the transformation of the <em>Post</em>, Kaiser stopped himself. “I’m going to cry,” he said, and paused. “Oh, God, it’s killing me.”</p><p>Bezos may be tiring of the <em>Post</em>, but he has not seemed inclined to sell the paper. Nor is it clear that would be a better, or at this point even feasible, outcome. Newspapers across the country are being bought up by private-equity firms that are essentially selling off the valuable parts. But there is another model for Bezos to consider: turning the <em>Post</em> into a nonprofit, endowed by Bezos but operating independently of him. For Bezos, this would reduce the role of the <em>Post</em> as a headache and a threat to other, more favored endeavors, such as his rocket company, Blue Origin. For the <em>Post</em>, assuming the endowment is sufficient, it would provide that continuing runway.</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>There are models for this approach. In Philadelphia, the late cable-television tycoon H.&nbsp;F.&nbsp;“Gerry” Lenfest purchased the <em>Inquirer</em>, the <em>Daily News</em>, and Philly.com in 2015, and the following year donated the publications to a charitable trust. “What would the city be without the <em>Inquirer</em> and the <em>Daily News</em>?” asked Lenfest, whose contribution to the endeavor has been valued at almost a hundred and thirty million dollars. In Utah, the investor Paul Huntsman bought the Salt Lake <em>Tribune</em> from the hedge fund Alden Global Capital in 2016; three years later, he transformed it into a nonprofit, supported in part by tax-deductible contributions from readers.</p><p>Writing in the <em>Columbia Journalism Review</em> in 2024, Steven Waldman <a href="https://www.cjr.org/opinion/waldman-bezos-washington-post-donation-charity-goodwill-endorsements-harris-spiked.php">suggested</a> that Bezos follow a similar course. “&nbsp;‘Nonprofit’ does not mean ‘losing money,’&nbsp;” Waldman wrote. “Nonprofit news organizations can sell ads, offer subscriptions, and take donations. Done well, it is an especially strong business model, because it provides an extra revenue stream (philanthropy) and is deeply embedded in serving the community.” My quibble with Waldman’s pitch is that he asked Bezos to ante up a paltry hundred million. When Bezos purchased the <em>Post,</em> his net worth was about twenty-five billion; it is now an estimated two hundred fifty billion. Why not one per cent of that for the <em>Post</em>, enough to sustain the paper indefinitely? A pipe dream, I know, but this arrangement would make Bezos the savior of the <em>Post</em>, not the man who presided over its demise.</p><p>In the 1941 movie “Citizen Kane,” Charles Foster Kane, a newspaper publisher who, like Bezos, is one of the richest men in the world, is confronted by his legal guardian, Walter Thatcher, about the folly of funding his paper. “Honestly, my boy, don’t you think it’s rather unwise to continue this philanthropic enterprise, this <em>Inquirer</em> that’s costing you a million dollars a year?” Thatcher demands. “You’re right, Mr. Thatcher. I did lose a million dollars last year,” Kane replies. “I expect to lose a million dollars this year. I expect to lose a million dollars next year. You know, Mr. Thatcher, at the rate of a million dollars a year, I’ll have to close this place in sixty years.” Update Kane’s outlays to assume losses of a hundred million annually, in perpetuity. By that math, Bezos would have more than two millennia before needing to turn out the lights.&nbsp;♦</p></div></div></article><div><div data-testid="RowWrapper" data-journey-hook="grid-wrapper"><p><a href="https://www.newyorker.com/contributors/ruth-marcus"><span><picture><source media="(max-width: 767px)" srcset="https://media.newyorker.com/photos/68b85a13ad1f1326c3869e1a/1:1/w_120,c_limit/ruth_marcus.png 120w, https://media.newyorker.com/photos/68b85a13ad1f1326c3869e1a/1:1/w_240,c_limit/ruth_marcus.png 240w" sizes="100vw"><source media="(min-width: 768px)" srcset="https://media.newyorker.com/photos/68b85a13ad1f1326c3869e1a/1:1/w_120,c_limit/ruth_marcus.png 120w, https://media.newyorker.com/photos/68b85a13ad1f1326c3869e1a/1:1/w_240,c_limit/ruth_marcus.png 240w" sizes="100vw"><img alt="" loading="lazy" src="https://media.newyorker.com/photos/68b85a13ad1f1326c3869e1a/1:1/w_270%2Cc_limit/ruth_marcus.png" data-src="https://media.newyorker.com/photos/68b85a13ad1f1326c3869e1a/1:1/w_270%2Cc_limit/ruth_marcus.png"></picture></span></a></p></div><div data-journey-hook="grid-wrapper" data-testid="ContentFooterBottom" data-attr-viewport-monitor=""><p data-testid="SectionTitle"><header>Read More</header></p><div data-testid="SummaryCollectionGridItems"><div data-item="{&quot;dangerousHed&quot;:&quot;What a Viral YouTube Video Says About the Future of Journalism&quot;,&quot;index&quot;:0,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/news/fault-lines/what-a-viral-youtube-video-says-about-the-future-of-journalism#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-1" data-recirc-pattern="summary-item" href="https://www.newyorker.com/news/fault-lines/what-a-viral-youtube-video-says-about-the-future-of-journalism#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>What a Viral YouTube Video Says About the Future of Journalism</p></a><p>A streamer’s investigation of fraud in Minnesota garnered millions of views. His content was questionable, but his methods will likely inspire scores of imitators.</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;The Brilliance and the Badness of “The Sun Also Rises”&quot;,&quot;index&quot;:1,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/books/second-read/the-brilliance-and-the-badness-of-the-sun-also-rises#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-2" data-recirc-pattern="summary-item" href="https://www.newyorker.com/books/second-read/the-brilliance-and-the-badness-of-the-sun-also-rises#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>The Brilliance and the Badness of “The Sun Also Rises”</p></a><p>Although Ernest Hemingway’s novel makes positive claims about what one should be—brave, admiring of nature and grace—its architecture is held up primarily by hatred.</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;Gavin Newsom Is Playing the Long Game&quot;,&quot;index&quot;:2,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/magazine/2026/02/09/gavin-newsom-profile#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-3" data-recirc-pattern="summary-item" href="https://www.newyorker.com/magazine/2026/02/09/gavin-newsom-profile#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>Gavin Newsom Is Playing the Long Game</p></a><p>California’s governor has been touted as the Democrats’ best shot in 2028. But first he’ll need to convince voters that he’s not just a slick establishment politician.</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;J. D. Vance’s Notable Absence on Venezuela&quot;,&quot;index&quot;:3,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/news/the-lede/j-d-vances-notable-absence-on-venezuela#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-4" data-recirc-pattern="summary-item" href="https://www.newyorker.com/news/the-lede/j-d-vances-notable-absence-on-venezuela#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>J. D. Vance’s Notable Absence on Venezuela</p></a><p>Was the Vice-President’s exclusion from the operation in Venezuela an expression of his anti-interventionist ideology—or a political calculation?</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;Why Donald Trump Wants Greenland (and Everything Else)&quot;,&quot;index&quot;:4,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/news/letter-from-trumps-washington/why-donald-trump-wants-greenland-and-everything-else#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><div><p><span><span>Letter from Trump’s Washington</span></span></p></div><a data-component-type="recirc-river" data-recirc-id="item-hed-5" data-recirc-pattern="summary-item" href="https://www.newyorker.com/news/letter-from-trumps-washington/why-donald-trump-wants-greenland-and-everything-else#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>Why Donald Trump Wants Greenland (and Everything Else)</p></a><p>There’s no Trump Doctrine, just a map of the world that the President wants to write his name on in big gold letters.</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;How Colombia’s President Reached an Uneasy Détente with Donald Trump&quot;,&quot;index&quot;:5,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/news/the-lede/how-colombias-president-reached-an-uneasy-detente-with-donald-trump#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-6" data-recirc-pattern="summary-item" href="https://www.newyorker.com/news/the-lede/how-colombias-president-reached-an-uneasy-detente-with-donald-trump#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>How Colombia’s President Reached an Uneasy Détente with Donald Trump</p></a><p>After the attack in Venezuela, its neighbor state reckons with U.S. aggression.</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;Jay Powell, the Prepster Banker Who Is Standing Up to Trump&quot;,&quot;index&quot;:6,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/news/the-lede/jay-powell-the-prepster-banker-who-is-standing-up-to-trump#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-7" data-recirc-pattern="summary-item" href="https://www.newyorker.com/news/the-lede/jay-powell-the-prepster-banker-who-is-standing-up-to-trump#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>Jay Powell, the Prepster Banker Who Is Standing Up to Trump</p></a><p>The seventy-two-year-old Fed chairman put to shame the heads of law firms, universities, and public companies who have caved to the White House.</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;Aaron Rodgers, Football’s Rorschach Quarterback&quot;,&quot;index&quot;:7,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/sports/sporting-scene/aaron-rodgers-footballs-rorschach-quarterback#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-8" data-recirc-pattern="summary-item" href="https://www.newyorker.com/sports/sporting-scene/aaron-rodgers-footballs-rorschach-quarterback#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>Aaron Rodgers, Football’s Rorschach Quarterback</p></a><p>The Pittsburgh Steelers gambled on the forty-two-year-old, one of the N.F.L.’s most polarizing players, to try to end their playoff disappointments. Will it pay off?</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;The Dangerous Paradox of A.I. Abundance&quot;,&quot;index&quot;:8,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/news/the-financial-page/the-dangerous-paradox-of-ai-abundance#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-9" data-recirc-pattern="summary-item" href="https://www.newyorker.com/news/the-financial-page/the-dangerous-paradox-of-ai-abundance#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>The Dangerous Paradox of A.I. Abundance</p></a><p>Silicon Valley envisions artificial intelligence ushering in an era of economic plenty. But what if the benefits are largely confined to corporations and investors that own the technology itself?</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;Denmark Is Sick of Being Bullied by Trump&quot;,&quot;index&quot;:9,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/magazine/2026/01/19/denmark-is-sick-of-being-bullied-by-trump#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-10" data-recirc-pattern="summary-item" href="https://www.newyorker.com/magazine/2026/01/19/denmark-is-sick-of-being-bullied-by-trump#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>Denmark Is Sick of Being Bullied by Trump</p></a><p>The U.S., once Denmark’s closest ally, is threatening to steal Greenland and attacking the country’s wind-power industry. Is this a permanent breakup?</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;Does Every Marriage Need a Prenup?&quot;,&quot;index&quot;:10,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/podcast/the-new-yorker-radio-hour/does-every-marriage-need-a-prenup#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><div><p><span><span>The New Yorker Radio Hour</span></span></p></div><a data-component-type="recirc-river" data-recirc-id="item-hed-11" data-recirc-pattern="summary-item" href="https://www.newyorker.com/podcast/the-new-yorker-radio-hour/does-every-marriage-need-a-prenup#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>Does Every Marriage Need a Prenup?</p></a><p>The staff writer Jennifer Wilson explores why prenuptial agreements have boomed in popularity among millennial and Gen Z couples.</p></div><div data-item="{&quot;dangerousHed&quot;:&quot;Barry Blitt’s “Guzzler”&quot;,&quot;index&quot;:11,&quot;contentType&quot;:&quot;venue&quot;,&quot;hotelLink&quot;:&quot;https://www.newyorker.com/culture/cover-story/cover-story-2026-01-19#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1&quot;,&quot;layout&quot;:&quot;GridFourColumns&quot;}" role="button" tabindex="0"><a data-component-type="recirc-river" data-recirc-id="item-hed-12" data-recirc-pattern="summary-item" href="https://www.newyorker.com/culture/cover-story/cover-story-2026-01-19#intcid=_the-new-yorker-article-bottom-recirc_09f2a729-10bd-45d2-a373-32e3290626c8_roberta-similarity1_fallback_text2vec1" target="_self"><p>Barry Blitt’s “Guzzler”</p></a><p>Trump’s thirst for Venezuela.</p></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Code for Infrastructure (137 pts)]]></title>
            <link>https://www.fluid.sh/</link>
            <guid>46889703</guid>
            <pubDate>Wed, 04 Feb 2026 18:34:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fluid.sh/">https://www.fluid.sh/</a>, See on <a href="https://news.ycombinator.com/item?id=46889703">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-j7pv25f6=""> <header data-astro-cid-j7pv25f6=""> <div data-astro-cid-j7pv25f6="">  <p data-astro-cid-j7pv25f6="">
Claude Code for infrastructure. Debug, act, and audit
                    everything Fluid does on your infrastructure.
</p> <h2 data-astro-cid-j7pv25f6="">What does that mean?</h2> <p data-astro-cid-j7pv25f6="">
Fluid is a terminal agent that do work on production infrastructure like VMs/K8s cluster/etc. by making sandbox clones of the infrastructure for AI agents to work on, allowing the agents to run commands, test connections, edit files, and then generate Infra-as-code like an Ansible Playbook to be applied on production.
</p> <h2 data-astro-cid-j7pv25f6="">
Why not just use an LLM to generate Infrastructure-as-Code (IaC)?
</h2> <p data-astro-cid-j7pv25f6="">
LLMs are great at generating Terraform, OpenTofu, Ansible, etc. but bad at guessing how production systems work. By giving access to a clone of the infrastructure, agents can explore, run commands, test things before writing the IaC, giving them better context and a place to test ideas and changes before deploying.

                I got the idea after seeing how much Claude Code has helped me work on code, I thought "I wish there was something like that for infrastructure", and here we are.
</p> <h2 data-astro-cid-j7pv25f6="">
Why not just provide tools, skills, MCP server to Claude Code?
</h2> <p data-astro-cid-j7pv25f6="">
Safety. I didn't want CC to SSH into a prod machine from where it is running locally (real problem!). I wanted to lock down the tools it can run to be only on sandboxes while also giving it autonomy to create sandboxes and not have access to anything else.

                Fluid gives access to a live output of commands run (it's pretty cool) and does this by ephemeral SSH Certificates. Fluid gives tools for creating IaC and requires human approval for creating sandboxes on hosts with low memory/CPU and for accessing the internet or installing packages.
</p> <!-- <p class="mt-4 text-neutral-400">
                    Create sandboxes from VMs, investigate, plan, execute,
                    generate Ansible playbooks, and audit everything.
                </p> --> <h2 data-astro-cid-j7pv25f6="">
Installation
</h2> <p data-astro-cid-j7pv25f6="">Note: this is a terminal agent (like Claude Code) meant to be installed on your local laptop/workstation</p> <div data-astro-cid-j7pv25f6=""> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6="">$ </span>curl -fsSL https://fluid.sh/install.sh |
                            bash
</p> </div> <p><span data-astro-cid-j7pv25f6="">$ </span>fluid
</p> </div>  </div> </header> <main data-astro-cid-j7pv25f6=""> <div data-astro-cid-j7pv25f6=""> <section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">
Built for where you already work
</h2> <!-- Feature Cards Grid --> <div data-astro-cid-j7pv25f6=""> <!-- Card 1: Sandbox --> <div data-astro-cid-j7pv25f6=""> <p>[~]</p> <div data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">Sandbox Isolation</h3> <p data-astro-cid-j7pv25f6="">Clone VMs instantly. Test changes in isolation before touching production.</p> </div> </div> <!-- Card 2: Explore --> <div data-astro-cid-j7pv25f6=""> <p>ls</p> <div data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">Context-Aware</h3> <p data-astro-cid-j7pv25f6="">Fluid explores your host first - OS, packages, CLI tools - then adapts.</p> </div> </div> <!-- Card 3: Audit --> <div data-astro-cid-j7pv25f6=""> <p>&gt;&gt;&gt;</p> <div data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">Full Audit Trail</h3> <p data-astro-cid-j7pv25f6="">Every command logged. Every change tracked. Review before production.</p> </div> </div> <!-- Card 4: Ansible --> <div data-astro-cid-j7pv25f6=""> <p>.yaml</p> <div data-astro-cid-j7pv25f6=""> <h3 data-astro-cid-j7pv25f6="">Ansible Playbooks</h3> <p data-astro-cid-j7pv25f6="">Auto-generates playbooks from sandbox work. Reproducible infrastructure.</p> </div> </div> </div> <!-- Workflow Steps --> <!-- <div class="relative">
                        <h3 class="text-neutral-400 text-sm font-mono mb-4 uppercase tracking-wider">How it works</h3>


                        <div class="hidden md:block absolute top-18 left-0 right-0 h-px bg-neutral-800"></div>
                        <div id="workflow-progress" class="hidden md:block absolute top-18 left-0 h-px bg-linear-to-r from-blue-500 to-blue-400 transition-all duration-1000 ease-out" style="width: 0%;"></div>

                        <div class="grid grid-cols-2 md:grid-cols-4 gap-4">
                            <div class="workflow-step opacity-0 translate-y-4 transition-all duration-500" data-step="1">
                                <div class="relative flex flex-col items-center text-center">
                                    <div class="w-10 h-10 rounded-full bg-neutral-900 border-2 border-neutral-700 flex items-center justify-center mb-3 transition-all duration-300 workflow-dot">
                                        <span class="text-neutral-500 font-mono text-sm transition-colors duration-300">1</span>
                                    </div>
                                    <span class="text-blue-400 font-mono text-sm mb-1">explore</span>
                                    <span class="text-neutral-600 text-xs">Scan host environment</span>
                                </div>
                            </div>


                            <div class="workflow-step opacity-0 translate-y-4 transition-all duration-500" data-step="2">
                                <div class="relative flex flex-col items-center text-center">
                                    <div class="w-10 h-10 rounded-full bg-neutral-900 border-2 border-neutral-700 flex items-center justify-center mb-3 transition-all duration-300 workflow-dot">
                                        <span class="text-neutral-500 font-mono text-sm transition-colors duration-300">2</span>
                                    </div>
                                    <span class="text-blue-400 font-mono text-sm mb-1">plan</span>
                                    <span class="text-neutral-600 text-xs">Build execution strategy</span>
                                </div>
                            </div>

                            <div class="workflow-step opacity-0 translate-y-4 transition-all duration-500" data-step="3">
                                <div class="relative flex flex-col items-center text-center">
                                    <div class="w-10 h-10 rounded-full bg-neutral-900 border-2 border-neutral-700 flex items-center justify-center mb-3 transition-all duration-300 workflow-dot">
                                        <span class="text-neutral-500 font-mono text-sm transition-colors duration-300">3</span>
                                    </div>
                                    <span class="text-blue-400 font-mono text-sm mb-1">execute</span>
                                    <span class="text-neutral-600 text-xs">Run in sandbox</span>
                                </div>
                            </div>

                            <div class="workflow-step opacity-0 translate-y-4 transition-all duration-500" data-step="4">
                                <div class="relative flex flex-col items-center text-center">
                                    <div class="w-10 h-10 rounded-full bg-neutral-900 border-2 border-neutral-700 flex items-center justify-center mb-3 transition-all duration-300 workflow-dot">
                                        <span class="text-neutral-500 font-mono text-sm transition-colors duration-300">4</span>
                                    </div>
                                    <span class="text-blue-400 font-mono text-sm mb-1">export</span>
                                    <span class="text-neutral-600 text-xs">Generate playbook</span>
                                </div>
                            </div>
                        </div>
                    </div> -->  </section> <section data-astro-cid-j7pv25f6=""> <h2 data-astro-cid-j7pv25f6="">Usage</h2> <!-- Timeline container --> <div id="usage-timeline" data-astro-cid-j7pv25f6=""> <!-- Vertical timeline line - grows as items appear -->  <!-- User Prompt - Blue accent -->  <!-- Sandbox Info -->  <!-- OS Detection --> <div data-astro-cid-j7pv25f6="" data-color="neutral" data-tool="run_command" data-command="cat /etc/os-release"> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Running: <span data-astro-cid-j7pv25f6="">cat /etc/os-release</span></span> </p>  </div> <!-- Package Update -->  <!-- Install Apache --> <div data-astro-cid-j7pv25f6="" data-color="neutral" data-tool="run_command" data-command="apt install -y apache2"> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Running: <span data-astro-cid-j7pv25f6="">apt install -y apache2</span></span> </p>  </div> <!-- Create HTML file --> <div data-astro-cid-j7pv25f6="" data-color="neutral" data-tool="run_command" data-command="echo '<h1>Hello</h1>' > /var/www/html/index.html"> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Running: <span data-astro-cid-j7pv25f6="">echo '...' &gt; /var/www/html/index.html</span></span> </p>  </div> <!-- Service Status --> <div data-astro-cid-j7pv25f6="" data-color="neutral" data-tool="run_command" data-command="systemctl status apache2"> <p><span data-astro-cid-j7pv25f6=""></span> <span data-astro-cid-j7pv25f6="">Running: <span data-astro-cid-j7pv25f6="">systemctl status apache2</span></span> </p>  </div> <!-- Verification -->  <!-- Playbook Creation -->  <!-- Playbook Tasks -->  <!-- Final Summary --> <div data-astro-cid-j7pv25f6="" data-color="green" data-tool="summary"> <p>Done! Here's what I accomplished:</p> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6="">Sandbox Created</span></p><p>- ID: SBX-demo1234</p> <p>- IP: 192.168.122.50</p> </div> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6="">Apache HTTP Server</span></p><p>- Installed and running</p> <p>- Custom page at /var/www/html/index.html</p> <p>- Verified working with curl</p> </div> <div data-astro-cid-j7pv25f6=""> <p><span data-astro-cid-j7pv25f6="">Ansible Playbook: httpd-setup</span></p><p>The playbook includes 4 tasks:</p> <p>1. Update apt cache</p> <p>2. Install Apache</p> <p>3. Create custom index.html</p> <p>4. Start and enable Apache service</p> </div> <p>
You can run this playbook on any Ubuntu server to reproduce this setup.
</p> </div> </div> </section>   </div> </main> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Great Unwind (225 pts)]]></title>
            <link>https://occupywallst.com/yen</link>
            <guid>46889008</guid>
            <pubDate>Wed, 04 Feb 2026 17:49:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://occupywallst.com/yen">https://occupywallst.com/yen</a>, See on <a href="https://news.ycombinator.com/item?id=46889008">Hacker News</a></p>
<div id="readability-page-1" class="page">





<p>Have you wondered why the stock market has been so choppy since
October and why crypto and gold keep flash crashing? The western media
would have you believe this is due to AI bubble, war in Greenland, and
Trump's tweets. We have a better story to tell.

</p><p>
<strong>Wall Street has lost control of the
Japanese Yen carry trade unwind.</strong>

</p><p>There's been a fair bit of quiet chaos in financial markets recently.
Cryptocurrencies have lost 40% of their value. We saw silver drop 40%
which hasn't happened since 1980. Stocks like Microsoft are getting
picked off one-by-one with 15% drops when positive earnings reports come
out. Meanwhile the broader market chops sideways, so people think things
are fine. Trump and Europe were on the brink of war for control of a
desolate arctic territory. Truth Social has overtaken FOMC as the most
important source of financial news. These things may all appear to the
untrained eye as a series of idiosyncratic, disconnected shocks. The
prevailing media narrative is that the market is reacting negatively to
AI CapEx spending and a hawkish new Fed chair. But our systematic
analysis of cross-asset flows, derivatives positioning, central bank
policy minutes, and institutional balance sheets suggests a singular,
unified causality that binds these disparate anomalies, which is the
covert unwinding of the Japanese Yen carry trade.

</p><p>For nearly thirty years, the Bank of Japan’s (BOJ) Zero Interest Rate
Policy (ZIRP) and subsequent Negative Interest Rate Policy (NIRP)
effectively transformed the Yen into the world’s funding currency. We
would call it the greatest free money printer ever made. By anchoring
borrowing costs at or near zero, the BOJ enabled Wall Street to borrow
Yen cheaply and invest it with leverage into higher yielding instruments
globally, such as U.S. treasuries, equities, and cryptography. For
example, you borrow Yen from Japan at 0% interest, you exchange it for
USD, and then you buy treasury bonds that pay 4%. It's that simple. This
funded government benefits and provided continuous reliable liquidity
for financial markets that made stocks keep going up while suppressing
volatility.

</p><p>Trillions of dollars of free loans from the Bank of Japan were used
by a generation of investors to buy a double digit percentage of the
U.S. economy. Now those loans are being recalled. Wall Street traders
who levered up on the free Japanese money now have to sell trillions of
assets and convert the proceeds back to Yen in order to not be
liquidated. These aren't happy times for them. They get liquidated when
Japan raises interest rates; they get liquidated when the Federal
Reserve lowers interest rates; they get liquidated when the Japanese Yen
increases in value; they get liquidated when tech stocks aren't going up
enough, and all four of these things have been happening at once.

</p><p>Wall Street may be greedy, but they're very intelligent too. They
made many smart choices about where to put the "free" money. Now let's
say you're someone who's also smart, but was wise enough to not use
Sauron's ring. Chances are you invested in the same things as Wall
Street. So by now you've probably seen your whole portfolio move against
you; you're wondering why your hedges don't work; and you feel like
you're being punished for making all the right choices. It's because
other smart people, who got greedy, are being forced to close their
positions, and you're the whipping boy for their avarice.

</p><p>The Japanese Yen is sort of like GameStop ($GME). It's the most
shorted currency on Earth. When you borrow yen to buy American assets,
you're effectively shorting the yen. Currency can be rehypothecated so
that yen-denominated debt ends up exceeding the actual yen supply, the
same way GME's short interest exceeded 100% of its float. When shorts
start covering it compounds tragedy, because they all have to buy yen,
which makes its value increase, forcing more shorts to cover, and Japan
is a small island.

</p><p>This December 2025 rate hike to 0.75%, followed by the explicitly
hawkish signalling from Prime Minister Sanae Takaichi’s administration,
has fundamentally altered the risk-reward calculus of these leveraged
positions. The market disruptions observed in January 2026 bear the
distinct mathematical signature of a forced liquidation event rather
than a fundamental repricing of growth prospects. When correlations
between historically uncorrelated assets (e.g. Gold, Bitcoin, Microsoft,
and Silver) approach 1.0 during a sell-off, it serves as a distinct
indicator that traders are not selling what they <em>want</em> to sell,
but rather what they <em>must</em> sell in order to meet margin calls in
a funding currency that is rapidly appreciating against their
liabilities.

</p><p>We shall investigate the mechanics of this unwind in exhaustive
detail. We analyze the "Greenland Distraction" not as a root cause but
as a volatility trigger that shattered the complacent calm of the "Davos
Consensus." We examine the anomalous liquidation in precious metals
following the nomination of Kevin Warsh to the Federal Reserve
Chairmanship, and we dissect the flow of funds from major Japanese
institutional whales like Norinchukin Bank, whose retreat from foreign
bond markets has left a liquidity vacuum in the U.S. Treasury complex.
The evidence points to a systemic repricing of the global cost of
capital, originating in Tokyo and transmitting violently through the
plumbing of Wall Street, leaving no asset class untouched.

</p><h2 id="pivot">
  Japan's Monetary Normalization
</h2>

<p>To fully comprehend the market chaos of January 2026, one must look
beyond the immediate headlines of the new year and scrutinize the subtle
yet seismic shifts that occurred in Tokyo during the closing months of
2025. The conventional market narrative has long regarded the Bank of
Japan as a passive, almost paralyzed actor, perpetually trapped in a
deflationary mire and unable to normalize policy. This view has always
been demonstratably false. The truth is that Wall Street leaders have
been planning for the next quarter, while the Japanese have been
preparing for the next century. The data confirms a deliberate,
aggressive shift toward normalization that caught global carry traders
offguard.

</p><h3>1.1 The December 2025 Rate Hike: A Regime Change</h3>

<p>In a move that many Western analysts critically underestimated, the
Policy Board of the Bank of Japan voted unanimously to raise the
uncollateralized overnight call rate to <strong>0.75%</strong> during
its policy session on December 18-19, 2025. While a 25 basis point hike
might appear negligible in the context of Federal Reserve or ECB
tightening cycles, in the context of the Japanese financial system,
which has operated near the zero-bound for decades, it represents a
massive tightening of financial conditions.

</p><p>This move was not merely a technical adjustment; it was a fundamental
regime change. Coming from a baseline of -0.1% in early 2024 and 0.50%
in late 2025, the move to 0.75% signaled that the era of "free money"
had definitively ended. The rationale provided by the BOJ was grounded
in shifting inflationary dynamics. Core CPI (excluding fresh food), the
central bank's preferred metric, was tracking near 3% in late 2025,
persistently exceeding the 2% price stability target.Although inflation
eased slightly to 2.4% in December, the BOJ minutes reveal a board
convinced that "wage gains may be durable," thus justifying higher rates
to prevent a wage-price spiral.

</p><p>Crucially, the minutes from the December meeting, which were released
in late January 2026, contain explicit language suggesting that the
tightening cycle is far from complete. The board noted that "real
interest rates are expected to remain negative," implying that a policy
rate of 0.75% is <em>still</em> considered accommodative relative to
inflation.To a bond trader, this is hawkish code. It suggests that the
"neutral rate" is significantly higher, potentially between 1.5% and
2.0%. If the market prices in a terminal rate of 2.0%, the cost of
funding for carry trades effectively triples from previous levels,
turning profitable arbitrage positions into deep losses.

</p><h3>1.2 The Takaichi Factor: "Abrynomics" Redux?</h3>

<p>The political dimension in Japan has exacerbated the monetary
tightness, creating a "double tightening" effect that algorithms have
struggled to price. Prime Minister Sanae Takaichi, preparing for a snap
election on February 8, 2026, has adopted a complex economic stance that
blends fiscal expansion with monetary discipline, a volatile mix for
currency markets.

</p><p>Takaichi advocates for "strategic fiscal spending" and tax cuts to
stimulate the domestic economy. In standard macroeconomic theory, an
expansionary fiscal policy (increased government spending) combined with
a tightening monetary policy (higher rates to combat the resulting
inflation) is the perfect recipe for currency appreciation. While
Takaichi has publicly softened her rhetoric to avoid accusations of
currency manipulation, stating she "did not have a preference for the
yen's direction", her policies speak louder than her soundbites.

</p><p>The market fears that Takaichi’s proposed fiscal largesse will force
the BOJ to hike rates <em>faster</em> than currently projected to
counteract the inflationary effects of government spending. This creates
a two-front war on the Yen carry trade:

</p><ol start="1">
  <li>
    <p><strong>Cost of Funding Rises:</strong> Higher BOJ rates make borrowing Yen expensive.
  </p></li>
  <li>
    <p><strong>Exchange Rate Risk:</strong> If the Yen appreciates due to the fiscal-monetary policy mix, the principal value of the USD-denominated assets held by Japanese investors falls in Yen terms, triggering margin calls.
  </p></li>
</ol>

<p>The tension between the Prime Minister's office and the Ministry of
Finance (MOF) adds another layer of uncertainty. Finance Minister
Satsuki Katayama has been far less tolerant of currency volatility,
repeatedly intervening or threatening intervention when USD/JPY
approaches the 155-160 danger zone.This political friction creates a
"floor" for the Yen, making shorting the currency a perilous endeavor
for global macro funds.

</p><h3>1.3 Institutional Flows: The "Whale" Retreats</h3>

<p>Perhaps the most critical, yet underreported, development is the
behavior of Japan's gargantuan institutional investors,
specifically <strong>Norinchukin Bank</strong> (often referred to as the
"CLO Whale") and <strong>Nippon Life Insurance</strong>. These entities
have historically been the largest buyers of U.S. debt, recycling
Japan's trade surplus into U.S. Treasuries and corporate bonds.

</p><p>The data indicates a massive reversal in these flows. Following
significant losses in 2024 and 2025 due to unhedged exposure to U.S. and
European sovereign bonds, Norinchukin has been actively liquidating
foreign assets. By the end of December 2025, the bank had unloaded
nearly <strong>¥12.8 trillion</strong> (approximately $88 billion) in
foreign government bonds.The bank’s CEO, Taro Kitabayashi, confirmed the
completion of this sell-off, stating the bank would "take its time"
before committing capital to fresh investments.

</p><p>The significance of this cannot be overstated. A major,
price-insensitive buyer of U.S. debt has left the building. When the
U.S. Treasury issues debt to fund its deficit, Norinchukin is no longer
the guaranteed bid. This removal of liquidity support weakens the floor
for U.S. Treasuries, contributing to the yield spikes seen in January.
Similarly, Nippon Life has signaled a rotation back into domestic
Japanese Government Bonds (JGBs), acknowledging that "unrealized losses"
on foreign bonds had swelled to ¥4.7 trillion.The logic is simple: why
take currency risk for a 4.5% U.S. yield when domestic JGB yields are
rising and offer a risk-free return in your home currency?

</p><p>By December 31, 2025, the stage was set. The "free money" era was
over. The largest holders of capital in Tokyo were repatriating funds or
moving into cash. Global markets, however, were still positioned for
"business as usual", long Nvidia, long Bitcoin, short Yen. The dissonance
between Japanese reality and Western positioning created the perfect
conditions for a crash.

</p><h2 id="timeline">
  Timeline of the Crisis
</h2>

<p>To validate the thesis that the Yen unwind is the primary driver of
volatility, we must examine the sequence of events. The crash did not
happen in a vacuum; it followed a precise timeline where geopolitical
shocks acted as triggers for a structural fragility that had been
building since the BOJ's December pivot.

</p><h3>2.1 The Lead-Up: October to December 2025</h3>

<p>The pressure began to build in Q4 2025. As the BOJ signaled its
intention to hike rates, Japanese traders, often the "canary in the coal
mine" for global liquidity, began to reduce risk. This cycle started with
Bitcoin. Bitcoin is a pure
liquidity asset; it has no yield and is often funded via margin. As the
cost of Yen margin rose, Japanese selling pressure on Bitcoin
intensified from October through December.This was the first tremor.

</p><h3>2.2 The Catalyst: The "Greenland Crisis" (January 17-21, 2026)</h3>

<p>Was the "Greenland War" theater? While the military dimensions may have
been performative, the economic consequences were
tangible and acted as the catalyst that exposed the fragility of the Yen
carry trade.

</p><p>On January 17, 2026, President Trump escalated his demand to purchase
Greenland by threatening a <strong>10% tariff</strong> on eight European
nations (including the UK, Germany, and France) and escalating to 25% by
June if the territory was not ceded.This introduced a "tail risk" that
markets had not priced: the fracture of the Atlantic economic
alliance.

</p><p>Following the Martin Luther King Jr. holiday, U.S. markets opened on
January 20 to a bloodbath. The S&amp;P 500 fell 2.1%, the Nasdaq
composite dropped 2.4%, and yields on U.S. Treasuries spiked.The
narrative was "Greenland," but the market mechanics told a different
story. The threat of tariffs on close allies disrupts the "Atlantic
Trade" narrative. For Japanese investors holding U.S. assets, this
introduced a new risk premium. It wasn't just about rates anymore; it
was about the stability of the U.S.-led global order. This geopolitical
volatility forced risk parity funds and algorithmic traders to reduce
gross exposure. When a global portfolio deleverages, it buys back its
funding currency. In this case, it bought Yen.

</p><p>While Trump walked back the <em>military</em> threat on January 21 at
Davos, the <em>economic</em> threat of tariffs remained a live wire. The
volatility persisted, suggesting that the "Greenland" narrative was
merely the match that lit the fuse of a much larger powder keg.

</p><h3>2.3 The "Warsh Shock" and the Liquidity Event (January 30-31, 2026)</h3>

<p>The final and most violent phase of the crash occurred at the end of
the month, triggered by the nomination of Kevin Warsh as Federal Reserve
Chair.Warsh is widely perceived as a hawk, favoring sound money and
skepticism toward quantitative easing. His nomination signaled the
potential end of the "Fed Put", the assumption that the central bank
would always intervene to support asset prices.

</p><p>This announcement triggered a massive repricing of the "Debasement
Trade." Assets that thrive on currency debasement, Gold, Silver, and
Bitcoin, collapsed. Gold fell ~11%, and Silver crashed ~36% in a single
session.This synchronization of losses across uncorrelated assets (Tech
and Gold falling together) is the definitive signature of a liquidity
crisis driven by margin calls.

</p><h2 id="liquidation">
  Anatomy of the Liquidation
</h2>

<p>The unwinding of a carry trade is not a monolithic event; it is a
cascade that ripples outward from the most liquid and speculative assets
to the core holdings of institutional portfolios. The sequence of asset
price collapses observed from October 2025 to January 2026 follows this
classic liquidation hierarchy perfectly.

</p><h3>3.1 The Canary in the Coal Mine: Bitcoin</h3>

<p>As noted, the unwind began in the crypto markets. Japan is home to a
massive retail crypto trading base, and the Yen is a major pair for
Bitcoin trading. Snippets indicate that Japanese traders began selling
off Bitcoin in October 2025.

</p><p>This timing is crucial. It correlates with the period when the BOJ
began signaling the December rate hike. Retail traders, facing higher
mortgage rates and loan costs in Japan, likely liquidated their most
volatile, liquid asset first to raise cash. The selling was exacerbated
by the looming tax reform in Japan. While the proposal to move to a flat
20% tax rate is bullish in the long term, the immediate pressure of
rising funding costs forced traders to sell <em>before</em> the tax cut
could be realized.By January 31, massive outflows from Bitcoin ETFs
($528 million) coincided with the broader market crash, confirming that
crypto was being used as a source of liquidity to cover losses
elsewhere.

</p><h3>3.2 The "Tech Wreck": The Microsoft Anomaly</h3>

<p>Consider the "painful ~3% dump" in the Nasdaq and Microsoft's
staggering 15% drop. On January 29, 2026,
Microsoft reported earnings. Despite beating revenue estimates ($81.27
billion vs. $80.28 billion), the stock plummeted ~11-15% intraday.

</p><p>The street blamed concerns over "AI CapEx", the idea that Microsoft
was spending billions on data centers with slow return on investment.
However, a 15% drop in a $3 trillion company on a "good" earnings beat
is rarely fundamental; it is mechanical. Microsoft is a quintessential
"momentum" stock, heavily held by foreign institutional investors,
including Japanese pension funds. When the Yen strengthens, the value of
these USD-denominated assets falls in JPY terms.

</p><p>If a Japanese insurer holds Microsoft unhedged, a falling USD/JPY
exchange rate hurts their balance sheet. If they hold it <em>hedged</em>
(rolling short USD positions), the rising U.S. rates (driven by the
Warsh nomination) make the hedge prohibitively expensive. The January 29
drop was likely exacerbated by a "stop-loss" cascade from Tokyo desks.
As the price broke key technical levels, algorithms programmed to
protect Yen-denominated returns indiscriminately sold the most liquid
blocks. Microsoft, being one of the most liquid stocks in the world,
became the ATM for the rest of the portfolio.

</p><h3>3.3 The Precious Metals Flash Crash</h3>

<p>The most compelling evidence of a forced liquidation event is the
behavior of Gold and Silver on January 31, 2026. Gold fell ~11-12% and
Silver crashed ~31-36% in a single session. Historically, Gold acts as a
safe haven during equity market turmoil. If the Nasdaq is crashing due
to "Greenland" fears, Gold should rally. Instead, it crashed.

</p><p>This anomaly can be explained by two factors:

</p><ol start="1">
  <li>
    <p><strong>The Warsh Effect:</strong> As discussed, Warsh's nomination strengthened the USD and undermined the thesis for holding anti-fiat assets.
  </p></li>
  <li>
    <p><strong>Margin Call Dynamics:</strong> Snippets reveal that CME Group and the Shanghai Gold Exchange raised margin requirements on gold and silver futures <em>days before</em> the crash.When Japanese traders faced losses on their Microsoft longs and their Yen shorts, they needed cash immediately. They couldn't sell illiquid bonds quickly enough, so they sold their "winners." Gold had rallied to ~$5,400/oz prior to the crash. Traders liquidated their profitable Gold positions to pay for the margin calls on their losing Tech and Yen positions.
  </p></li>
</ol>

<h4>Correlation Convergence: The Signature of a Liquidity Event</h4>

<p><strong>Cross-Asset Correlations (Week Ending Jan 31, 2026)</strong>

</p><figure>
  <img src="https://occupywallst.com/correlations.png" alt="Cross-asset correlations chart showing spike in correlation between Gold, Bitcoin, and Nasdaq 100 on Jan 31, 2026">
  <figcaption>
    <strong>Figure 2:</strong> Cross-asset correlations, Jan 15–Jan 31,
    2026. Note the spike in correlation between Gold, Bitcoin, and
    Nasdaq 100 on Jan 31, indicating a systemic "sell-everything" margin
    call.<br>
    <em>Data sources:
      <a href="https://alexlexington.com/blogs/news/gold-and-silver-crash-january-2026-what-caused-fridays-historic-drop">Alex Lexington</a>,
      <a href="https://www.financemagnates.com/trending/why-gold-is-falling-with-silver-and-why-ron-paul-predicts-a-20k-price/">Finance Magnates</a>,
      <a href="https://global.morningstar.com/en-nd/markets/why-are-gold-silver-plunging">Morningstar</a>,
      <a href="https://www.investing.com/analysis/bitcoins-identity-crisis-in-2026-4-paths-forward-and-the-road-to-150000-200674299">Investing.com</a>,
      <a href="https://seekingalpha.com/article/4865184-gold-silver-and-equities-evidence-positive-volspot-correlation">Seeking Alpha</a></em>
  </figcaption>
</figure>

<p>This correlation breakdown is visualized in Figure 2, where the
correlation between Gold and the Nasdaq 100 spikes to nearly 1.0 during
the crash week, a statistical anomaly that only occurs during severe
liquidity events.

</p><h4>The Liquidation Vice: Margin Hikes vs. Silver Price</h4>

<figure>
  <img src="https://occupywallst.com/liquidations.png" alt="Chart showing impact of CME margin requirement increases on Silver spot prices">
  <figcaption>
    <strong>Figure 3:</strong> Impact of CME margin requirement
    increases on Silver spot prices (Jan 20–Feb 2, 2026). The "Step Up"
    in margin cost precedes the vertical drop in price, characteristic
    of a forced unwind.<br>
    <em>Data sources:
      <a href="https://alexlexington.com/blogs/news/gold-and-silver-crash-january-2026-what-caused-fridays-historic-drop">Alex Lexington</a>,
      <a href="https://www.financemagnates.com/trending/why-gold-is-falling-with-silver-and-why-ron-paul-predicts-a-20k-price/">Finance Magnates</a>,
      <a href="https://evrimagaci.org/gpt/bitcoin-and-gold-plunge-as-margin-calls-roil-markets-526479">Evrim Agaci</a></em>
  </figcaption>
</figure>

<h2 id="plumbing">
  The Plumbing of the Crisis
</h2>

<p>The "Yen Whale" hypothesis is strongly supported by the data on
futures volumes and repo market stress. The "central mystery" is not
just in the price action, but in the unseen flows of the derivatives
market.

</p><h3>4.1 The /6J (Yen Futures) Whale</h3>

<p>About a week ago, some whale kicked off an astronomically large
market order for a /6J long when it hit all-time lows. /6J (CME Yen
Futures) hit a low of ~0.00647 (approximately 154.50 USD/JPY) in late
January. This level has historically been a "line in the sand" for the
Japanese Ministry of Finance (MOF).

</p><figure>
  <a href="https://occupywallst.com/yen.png"><img src="https://occupywallst.com/yen.png" alt="Thinkorswim chart showing massive whale order on /6J yen futures"></a>
  <figcaption><strong>Figure 4:</strong> The whale event that kicked off
  the Japanese Yen unwind. Note the massive spike as /6J hit all-time
  lows, rallying investors worldwide to go long on yen
  futures.</figcaption>
</figure>

<p>CME reported record volumes in FX and Interest Rate products for
January 2026.The aggressive buying off the lows suggests a
massive <em>repatriation</em> flow. Who is the Whale? Two theories
emerge:

</p><ol start="1">
  <li>
    <p><strong>The MOF Thesis:</strong> The Ministry of Finance has a history of stealth intervention. Buying /6J (Long Yen) is functionally equivalent to selling USD reserves. Buying futures allows them to support the currency without immediately depleting cash reserves, squeezing speculators who are short.
  </p></li>
  <li>
    <p><strong>The Carry Unwind:</strong> A massive hedge fund or bank (like Norinchukin) realizing that the "game is up" and closing out short-Yen positions. The size of the order suggests an entity that needed to move billions, not millions.
  </p></li>
</ol>

<p>The subsequent price action, a sharp rally followed by "hammering back
down", represents the battleground. U.S. macro funds are still trying to
short the Yen (betting on U.S. economic exceptionalism and Warsh's
policies), while Japanese domestic accounts are buying it. The
volatility is the result of these tectonic plates grinding against each
other.

</p><h3>4.2 The Repo Market &amp; ON RRP</h3>

<p>The plumbing of the U.S. financial system showed signs of stress that
coincided with the Japanese retreat. The Overnight Reverse Repo facility
(ON RRP) saw a year-end spike to $106 billion but has since drained.

</p><p>Japanese banks are typically huge participants in the U.S. repo
market to fund their dollar assets. As Norinchukin and others retreat
(repatriating funds to Japan), liquidity in the U.S. repo market becomes
thinner. The "air pocket" in Microsoft and Gold prices was likely
exacerbated by a lack of market maker depth in the repo-funded
derivatives market. When market makers cannot access cheap repo funding,
they widen spreads and reduce liquidity provision, leading to "gaps" in
price action during sell-offs.

</p><h3>4.3 Peripheral Currency Volatility</h3>

<p>There have been significant moves in other currency futures as well: /6A
increased 87 basis points, /6L rose 19 basis points, and /6S rose 18
basis points.

</p><ul>
 <li>
   <p><strong>/6A (Australian Dollar):</strong> The 87 basis point rise
     in the Aussie Dollar is notable. AUD is often a proxy for Chinese
     growth and global risk sentiment. A rise here, amidst a tech crash,
     suggests a rotation <em>out</em> of U.S. assets and into
     commodities or Asia-Pacific currencies, further supporting the
     "Sell America" thesis triggered by the Greenland tariff
     threats.
 </p></li>
 <li>
   <p><strong>/6L (Brazilian Real) and /6S (Swiss Franc):</strong> The
   rise in the Swiss Franc (a classic safe haven) aligns with the
   risk-off sentiment. The move in the Brazilian Real suggests that
   emerging markets are also seeing volatile flows as the dollar
   stabilizes.
 </p></li>
</ul>

<h3>4.4 The VIX Anomaly</h3>

<p>Why was the VIX at 16 despite the chaos? The VIX measures implied
volatility of S&amp;P 500 options. Its relatively low level (16)
compared to the violence in individual names (MSFT -15%, Gold -11%)
indicates that the crash is a <strong>de-leveraging event</strong>, not
a panic event.

</p><p>In a panic, investors buy Puts on the index to protect themselves,
spiking the VIX. In a de-leveraging event, investors simply sell the
underlying assets (stocks, gold, crypto) to raise cash. They are not
hedging; they are exiting. This explains why the VIX remained subdued
while prices collapsed, the selling was orderly, algorithmic, and
relentless, rather than emotional and panicked.

</p><h2 id="greenland">
  The Greenland Distraction
</h2>

<p>Skepticism about the "Greenland War" is well-founded. While the
diplomatic row was real, its utility as a <em>financial</em>
narrative was far greater than its geopolitical reality.

</p><h3>5.1 The "Davos Pivot"</h3>

<p>President Trump's threat of military force was retracted on January
21 at Davos.This "de-escalation" should theoretically have calmed
markets. Instead, the volatility <em>worsened</em> into month-end. This
confirms that the <em>real</em> problem wasn't Greenland; it was the
re-pricing of the Yen.

</p><h3>5.2 The Narrative Utility</h3>

<p>The financial media loves a simple cause-and-effect narrative.
"Stocks down because of War" is easy to digest. "Stocks down because the
cross-currency basis swap spread widened due to BOJ minutes" is not. The
"Greenland" narrative provided the perfect cover for sophisticated
actors to liquidate positions in Gold and Tech under the guise of "war
jitters." This allowed them to exit without sparking a broader panic
about <em>liquidity</em> in the banking system. The focus on the Arctic
masked the structural rot in the leverage complex.

</p><h2 id="conclusion">
  Conclusion
</h2>

<p>The evidence suggests a covert, structural unwinding of the Yen carry
trade is the primary driver of the January 2026 market chaos.

</p><p>The interconnectedness of these events is undeniable. The BOJ's rate
hike in December 2025 and the subsequent hawkish signaling from the
Takaichi administration fundamentally altered the cost of capital for
the world's largest carry trade. The "Greenland Crisis" acted as the
initial volatility trigger, forcing a reduction in gross exposure. The
nomination of Kevin Warsh acted as the final catalyst, shattering the
"Debasement Trade" and forcing a liquidation of precious metals and
crypto to cover margin calls on Yen-funded positions.

</p><p>Here are some key takeaways:

</p><ol start="1">
  <li>
    <p><strong>The "Free Money" Era is Over:</strong> BOJ policies have
    fundamentally altered the global cost of capital. The flow of
    liquidity from Tokyo to New York has reversed.
  </p></li>
  <li>
    <p><strong>Geopolitics as Catalyst:</strong> "Greenland" may have
    been the spark, but the Yen leverage was the powder keg. The tariff
    threats disrupted the "Atlantic Trade" narrative, forcing a
    repatriation of capital.
  </p></li>
  <li>
    <p><strong>Liquidity Event:</strong> The synchronized crash of Gold,
    Crypto, and Tech confirms a systemic de-leveraging. The "Whale"
    orders in Yen futures and the breakdown of correlations are the
    smoking guns of a margin-driven event.
  </p></li>
</ol>

<p>With the Japanese election on February 8 and U.S. tariffs looming,
the "hammering" of the Yen is likely temporary. The structural trend is
now toward repatriation. This implies <strong>lower U.S. asset prices,
higher U.S. yields, and a stronger Yen</strong> over the medium term.
The "mystery" of the low VIX is explained by the mechanical nature of
the unwind, a controlled demolition of leverage rather than a chaotic
panic.

</p><h2 id="action">
  Call To Action
</h2>

<p>
This won't just be the big one. This could be the last one. If you've
been preparing your whole life, knowing that something's coming, then
this could be the thing you've been preparing for. One final opportunity
to get the guys who did this.

</p><p>
Longing the Yen is commonly referred to as "The Widowmaker Trade" on
Wall Street, because you have trillions of dollars of monopoly money
working against you. The carry traders have compromised every level of
our government. Their greatest vulnerability is the Yen rising in value.
They will do anything to defend their positions, even if that means
bringing America's economy down with them. Since recent events have made
it obvious they're going to lose, we might as well fight them. Most of
us probably won't make it out of this fight. But if we at least try,
then there's a chance we might prosper when it's over.

</p><p>
The IV on
OTM <a href="https://www.cmegroup.com/markets/fx/g10/japanese-yen.html">CME
/6J futures</a> calls is 11% which is astonishingly low. The same is
true for calls on the
<a href="https://www.invesco.com/us/en/financial-products/etfs/invesco-currencyshares-japanese-yen-trust.html">FXY</a>
ETF. Call options have defined risk. The more Yen we control, the more
its value goes up, and the more crooks on Wall Street get liquidated.
The worst that can happen is you lose your monopoly money, but that's
been happening anyway. Since carry traders own 10% of all U.S.
treasuries, when they get liquidated they'll have to sell a lot of
treasury bonds, which means that
<a href="https://www.cmegroup.com/markets/interest-rates/us-treasury/ultra-t-bond.html">CME
/UB futures</a> and
the <a href="https://www.ishares.com/us/products/239454/ishares-20-year-treasury-bond-etf">TLT</a>
ETF will fall.

</p><hr>

<p>This blog is brought to you by various radicals,
malcontents, and people who think the system is rigged. We're not
affiliated with any organization. Nothing here constitutes financial
advice. Occupy Wall Street is not your financial advisor or your lawyer.
We're retail investors like you. Do your own research. Past performance
does not guarantee future results. We are the 99 percent. The only
solution is world revolution. Wall Street's time has finally come.
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Steve Bannon Proposes Using ICE in Elections (106 pts)]]></title>
            <link>https://www.newsweek.com/steve-bannon-proposes-using-ice-in-elections-11462376</link>
            <guid>46888824</guid>
            <pubDate>Wed, 04 Feb 2026 17:36:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newsweek.com/steve-bannon-proposes-using-ice-in-elections-11462376">https://www.newsweek.com/steve-bannon-proposes-using-ice-in-elections-11462376</a>, See on <a href="https://news.ycombinator.com/item?id=46888824">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Steve Bannon, a former White House adviser to President Donald Trump, has said agents from U.S. Immigration and Customs Enforcement (ICE) will be at the polls during November's midterm elections.</p><p>"You're damn right we're gonna have ICE surround the polls come November," Bannon said on his <em>War Room</em> podcast on Tuesday.</p><ul><li><span><strong><a href="https://www.newsweek.com/russia-just-put-another-taco-on-trumps-plate-11463407">Essential Reading: Russia Just Put Another TACO on Trump’s Plate</a></strong></span></li><li><span><strong><a href="https://www.newsweek.com/shutdown-averted-ice-deal-winners-conventional-wisdom-11462827">Conventional Wisdom: The Shutdown Averted Edition</a></strong></span></li></ul><p>"We're not gonna sit here and allow you to steal the country again. And you can whine and cry and throw your toys out of the pram all you want, but we will never again allow an election to be stolen."</p><p>Federal and state laws prohibit the government from deploying federal agents to any polling place, according to the Brennan Center for Justice. Federal law also prohibits any activity that intimidates voters.</p><p>Bannon's comments come after Trump said in a podcast interview on Monday that <a href="https://www.newsweek.com/donald-trump-nationalize-voting-dan-bongino-show-elections-11455526">Republicans should "take over" elections</a> in as many 15 states, as he continued to baselessly claim that widespread fraud cost him re-election in 2020. His calls come amid <a href="https://www.newsweek.com/major-changes-american-voting-system-congress-11458749">a push among Republicans in Congress</a> to impose stricter voting requirements nationwide.</p><p><em>Newsweek</em> contacted the White House and the Department of Homeland Security (DHS) for comment by email outside of regular business hours.</p><div><p><img id="11462395" alt="" caption="Conservative political strategist Steve Bannon, former advisor to US President Donald Trump, addresses Turning Point's annual AmericaFest conference, in remembrance of late right-wing political activist Charlie Kirk, in Phoenix, Arizona on December 19, 2025.  (Photo by Olivier Touron/AFP via Getty Images)" captionoverride="Steve Bannon speaking at Turning Point's annual AmericaFest conference in Phoenix, Arizona, in December." credit="Olivier Touron/AFP/Getty Images" sourcealt="" sources="[]" fetchpriority="auto" loading="lazy" width="5079" height="3386" decoding="async" data-nimg="1" sizes="(min-width: 1200px) 1536px, (min-width: 768px) 768px, 100vw" srcset="https://assets.newsweek.com/wp-content/uploads/2026/02/GettyImages-2252092393.jpg?w=640&amp;quality=80&amp;webp=1 640w, https://assets.newsweek.com/wp-content/uploads/2026/02/GettyImages-2252092393.jpg?w=750&amp;quality=80&amp;webp=1 750w, https://assets.newsweek.com/wp-content/uploads/2026/02/GettyImages-2252092393.jpg?w=1000&amp;quality=80&amp;webp=1 1000w, https://assets.newsweek.com/wp-content/uploads/2026/02/GettyImages-2252092393.jpg?w=1200&amp;quality=80&amp;webp=1 1200w, https://assets.newsweek.com/wp-content/uploads/2026/02/GettyImages-2252092393.jpg?w=1360&amp;quality=80&amp;webp=1 1360w, https://assets.newsweek.com/wp-content/uploads/2026/02/GettyImages-2252092393.jpg?w=1600&amp;quality=80&amp;webp=1 1600w" src="https://assets.newsweek.com/wp-content/uploads/2026/02/GettyImages-2252092393.jpg?w=1600&amp;quality=80&amp;webp=1"></p></div><h2>Why It Matters</h2><p>Trump has recently intensified his efforts to undermine the results of the 2020 election, which he lost to President Joe Biden. He has repeated disproven theories that ballots were altered or stolen and that illegal migrants were allowed to cast votes in some states that he lost. Those efforts come as the Trump administration is turning its attention to electoral issues before the midterm elections in November, when control of Congress will be at stake.</p><p>Meanwhile, the fatal shootings of two U.S. citizens, <a href="https://www.newsweek.com/renee-good-autopsy-results-released-by-lawyers-11398361">Renee Good</a> and <a href="https://www.newsweek.com/alex-pretti-death-deemed-homicide-by-medical-examiner-11454424">Alex Pretti</a>, by immigration enforcement agents in separate incidents in Minneapolis last month have amplified scrutiny of ICE. On Tuesday, Trump signed a government funding bill&nbsp;that only funds DHS for two weeks at the behest of Democrats, who are demanding more restrictions on immigration enforcement&nbsp;following the fatal shootings.</p><h2><strong>What To Know&nbsp;</strong></h2><p>On the <em>War Room </em>podcast, Bannon said that Democrats rely on voter fraud to win elections, suggesting without evidence that illegal migrants are voting in large numbers in Minnesota and New York City.</p><p>Caroline Wren, a GOP fundraiser, agreed with Bannon, saying that Democrats are seeking to "defund ICE" to keep agents away from polling sites.</p><p>Wren pointed to comments from Democratic Senator Mark Warner, who&nbsp;recently expressed concerns about the possibility of Trump sending ICE agents to polling places.</p><p>"They don't want ICE funded because they don't want ICE at the polling stations to stop illegals from voting," she said.&nbsp;</p><p>Bannon said the proposals in two bills to implement stricter voter requirements were "basic."</p><p>"The ask here on the SAVE Act and&nbsp;Make Elections Great Again Act are pretty basic. A legitimate ID to show who you are to vote. It is to clean up the voter rolls," he said. </p><h2><strong>What People Are Saying&nbsp;</strong></h2><p><strong>Bannon said on the podcast</strong>: "Let's put you on notice again. ICE is going to be around the polls in the 2026 midterm elections."</p><p><strong>Senate Minority Leader Chuck Schumer</strong> <strong>wrote on X on Monday</strong>: "The SAVE Act is nothing more than Jim Crow 2.0. It would disenfranchise millions of Americans. Every single Senate Democrat will vote against any bill that contains it."</p><p><strong>Democratic Senator Mark Warner</strong> <strong>told reporters on Tuesday</strong>: "The idea that the president might send some part of the federal government like ICE into patrol and suddenly people are saying, 'well, we want to make sure that nobody undocumented shows up at any polling station.' Again, pre-Minneapolis occupation, that didn't ring as true as it potentially rings true right now"</p><h2><strong>What Happens Next&nbsp;</strong></h2><p>The midterm elections will take place on November 3.</p><blockquote><article><div><p><img id="11261860" alt="" caption="" credit="" sourcealt="" sources="[]" fetchpriority="auto" loading="lazy" width="1312" height="121" decoding="async" data-nimg="1" sizes="(min-width: 1200px) 1312px, (min-width: 768px) 1024px, 100vw" srcset="https://assets.newsweek.com/wp-content/uploads/2025/12/Top.png?w=640&amp;quality=80&amp;webp=1 640w, https://assets.newsweek.com/wp-content/uploads/2025/12/Top.png?w=750&amp;quality=80&amp;webp=1 750w, https://assets.newsweek.com/wp-content/uploads/2025/12/Top.png?w=1000&amp;quality=80&amp;webp=1 1000w, https://assets.newsweek.com/wp-content/uploads/2025/12/Top.png?w=1200&amp;quality=80&amp;webp=1 1200w, https://assets.newsweek.com/wp-content/uploads/2025/12/Top.png?w=1360&amp;quality=80&amp;webp=1 1360w, https://assets.newsweek.com/wp-content/uploads/2025/12/Top.png?w=1600&amp;quality=80&amp;webp=1 1600w" src="https://assets.newsweek.com/wp-content/uploads/2025/12/Top.png?w=1600&amp;quality=80&amp;webp=1"></p></div><p>In a polarized era, the center is dismissed as bland. At <em>Newsweek</em>, ours is different: The Courageous Center—it's not "both sides," it's sharp, challenging and alive with ideas. We follow facts, not factions. If that sounds like the kind of journalism you want to see thrive, we need you.</p><p>When you <a href="https://www.newsweek.com/subscribe?utm_campaign=inlineCTAv2" target="_blank" rel="noreferrer noopener">become a Newsweek Member</a>, you support a mission to keep the center strong and vibrant.&nbsp;Members enjoy:&nbsp;Ad-free browsing, exclusive content and editor conversations.&nbsp;<a href="https://www.newsweek.com/subscribe" target="_blank" rel="noreferrer noopener">Help keep the center courageous. Join today.</a></p><div><p><a href="https://www.newsweek.com/jennifer-cunningham"><img lightbox="{&quot;enabled&quot;:false}" id="11261873" alt="" caption="" credit="" sourcealt="" sources="[]" fetchpriority="auto" loading="lazy" width="1312" height="136" decoding="async" data-nimg="1" sizes="(min-width: 1200px) 1312px, (min-width: 768px) 1024px, 100vw" srcset="https://assets.newsweek.com/wp-content/uploads/2025/12/Bottom.png?w=640&amp;quality=80&amp;webp=1 640w, https://assets.newsweek.com/wp-content/uploads/2025/12/Bottom.png?w=750&amp;quality=80&amp;webp=1 750w, https://assets.newsweek.com/wp-content/uploads/2025/12/Bottom.png?w=1000&amp;quality=80&amp;webp=1 1000w, https://assets.newsweek.com/wp-content/uploads/2025/12/Bottom.png?w=1200&amp;quality=80&amp;webp=1 1200w, https://assets.newsweek.com/wp-content/uploads/2025/12/Bottom.png?w=1360&amp;quality=80&amp;webp=1 1360w, https://assets.newsweek.com/wp-content/uploads/2025/12/Bottom.png?w=1600&amp;quality=80&amp;webp=1 1600w" src="https://assets.newsweek.com/wp-content/uploads/2025/12/Bottom.png?w=1600&amp;quality=80&amp;webp=1"></a></p></div></article></blockquote></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building a 24-bit arcade CRT display adapter from scratch (120 pts)]]></title>
            <link>https://www.scd31.com/posts/building-an-arcade-display-adapter</link>
            <guid>46888795</guid>
            <pubDate>Wed, 04 Feb 2026 17:35:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scd31.com/posts/building-an-arcade-display-adapter">https://www.scd31.com/posts/building-an-arcade-display-adapter</a>, See on <a href="https://news.ycombinator.com/item?id=46888795">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section><p>In November, my friend and fellow Recurser, <a href="https://www.frankchiarulli.com/">Frank</a>, picked up an arcade machine for the <a href="https://www.recurse.com/">Recurse Center</a>. We call it the RCade. He wanted to leave the original CRT in - which I think is a great choice! - and drove it off of a Raspberry Pi. Eventually we wanted to move to a more powerful computer, but we needed a way to connect it to the display. Off-hand, I mentioned that I could build a CRT display adapter that interfaces with a normal computer over USB. This is that project.</p></section><h2>What the display expects</h2><section><p>The CRT in the RCade has a JAMMA connector, and Frank bought a converter that goes between VGA and JAMMA.</p><p>You might think we could just use an off-the-shelf VGA adapter to drive it at this point, but it's not that simple. The CRT runs at a weird resolution; We started with 320x240 but eventually wanted to target 336x262, which is super non-standard. Even 320x240 is unattainable by most display adapters, which typically can't go below 640x480. A custom solution would allow us to output any arbitrary resolution we wanted.</p><p>The other thing is that the Pi, with the <a href="https://github.com/fenlogic/vga666">VGA board</a> we were using, only supports 18-bit colour, and we wanted to improve this. Even on the RCade's CRT, colour banding was an obvious issue.</p><p>We also wanted to use a laptop, not a desktop, which meant not using a PCI-e card. Instead, a USB interface would be preferable.</p></section><h2>Wait, but what is VGA?</h2><section><p>VGA is a signaling protocol that maps almost exactly 1:1 with what a CRT actually does.</p><p><a href="https://www.scd31.com/img/rcade/crt-diagram.jpg"><img src="https://www.scd31.com/thumb/rcade/crt-diagram.jpg"></a></p><small>Taken from wikimedia.org</small><p>Inside of a CRT, there are 3 electron guns, which correspond to red, green, and blue colour values. Two electromagnets in the neck of the tube are responsible for steering the beam - one steers horizontally and one steers vertically. To draw an image, the beam moves across the screen one horizontal line at a time, and the electron guns are rapidly modulated in order to display the correct colour at each pixel.</p><p>VGA contains analog signals for these R, G, and B electron guns. It also contains an HSYNC and VSYNC signal, which are used so that the driver and the CRT can agree on what pixel is being drawn at a given time. Between the VGA input and the CRT is a very simple circuit which locks onto these HSYNC and VSYNC pulses and synchronizes the sweeping of the beam.</p><p><a href="https://www.scd31.com/img/rcade/vga-timing.png"><img src="https://www.scd31.com/thumb/rcade/vga-timing.png"></a></p><small>Taken from pyroelectro.com</small><p>The HSYNC pulses happen in between horizontal lines, and the VSYNC pulses happen in between frames. There are dead zones around each pulse - referred to as the front and back porch - which give the electron beam time to sweep back across the screen.</p><p>So, all we really need are those R, G, B, HSYNC, and VSYNC signals, running at precise timing, and synced properly relative to each other. Conceptually this is actually pretty simple!</p></section><h2>Attempt 1: Using the RP2040's PIO</h2><section><p>I like the Raspberry Pi RP2040 a lot. It's relatively cheap (around $1 USD) and has tons of on-board RAM - 264 KB in fact! It also has what is called Programmable IO, or PIO.</p><p>I've never used the PIO before, but the basic idea is that you can write assembly programs where every instruction takes exactly one cycle, and has useful primitives for interacting with GPIO. It's a fairly limited instruction set, but it allows for bit-banging precise cycle-accurate custom protocols. It's exactly what I need to modulate a VGA signal.</p><p>The PIO code ended up looking like this:</p><pre><span>  </span><span>// 1. low for 320+16=336 pixels
</span><span>  </span><span>// 2. high for 30 pixels
</span><span>  </span><span>// 3. low for 34 pixels
</span><span>  </span><span>// 4. repeat
</span><span>  </span><span>// runs on sm0
</span><span>  </span><span>// 6 instrs -&gt; can save some with sidesetting
</span><span>  </span><span>let</span><span> hsync = pio::pio_asm!(
</span><span>      "</span><span>.wrap_target</span><span>",
</span><span>      </span><span>/* begin pixels + front porch */
</span><span>      "</span><span>irq set 0 [2]</span><span>",    </span><span>// tell vsync we're doing 1 line
</span><span>      "</span><span>set pins, 1 [31]</span><span>", </span><span>// go low for 32
</span><span>      "</span><span>set X, 8 [15]</span><span>",    </span><span>// +16 = 48
</span><span>      "</span><span>a:</span><span>",
</span><span>      "</span><span>jmp X-- a [31]</span><span>", </span><span>// each loop 32, * 9 = 288, total = 336
</span><span>      </span><span>/* end front porch, being assert hsync */
</span><span>      "</span><span>set pins, 0 [29]</span><span>", </span><span>// assert hsync for 30
</span><span>      </span><span>/* end assert hsync, begin back porch */
</span><span>      "</span><span>set pins, 1 [29]</span><span>", </span><span>// deassert, wait 32 (note there is extra delay after the wrap)
</span><span>      "</span><span>.wrap</span><span>"
</span><span>    );
</span><span>
</span><span>  </span><span>// NOTE - we get irq at *end* of line so we have to time things accordingly
</span><span>  </span><span>// 1. low for 242 lines -&gt; but irq 2 every line for the first 240
</span><span>  </span><span>// 2. high for 3 lines
</span><span>  </span><span>// 3. low for 22 lines
</span><span>  </span><span>// 4. repeat
</span><span>  </span><span>// runs on sm1
</span><span>  </span><span>// 19 instr
</span><span>  </span><span>let</span><span> vsync = pio::pio_asm!(
</span><span>      "</span><span>.side_set 1 opt</span><span>",
</span><span>      "</span><span>.wrap_target</span><span>",
</span><span>      "</span><span>set Y, 6</span><span>",
</span><span>      "</span><span>a_outer:</span><span>",
</span><span>      "</span><span>set X, 31</span><span>",
</span><span>      "</span><span>a:</span><span>",
</span><span>      "</span><span>wait 1 irq 0</span><span>",
</span><span>      "</span><span>irq set 2</span><span>",
</span><span>      "</span><span>jmp X-- a</span><span>", </span><span>// 32 lines per inner loop
</span><span>      "</span><span>jmp Y-- a_outer</span><span>", </span><span>// 7 outer loops = 224
</span><span>
</span><span>      "</span><span>set X, 15</span><span>", </span><span>// 16 more lines = 240
</span><span>      "</span><span>z:</span><span>"
</span><span>      "</span><span>wait 1 irq 0</span><span>",
</span><span>      "</span><span>irq set 2</span><span>",
</span><span>      "</span><span>jmp X-- z</span><span>",
</span><span>
</span><span>      "</span><span>wait 1 irq 0</span><span>", </span><span>// wait for end of last rgb line
</span><span>      "</span><span>wait 1 irq 0</span><span>", </span><span>// 2 more lines for front porch
</span><span>      "</span><span>wait 1 irq 0</span><span>",
</span><span>
</span><span>      "</span><span>set X, 2 side 0</span><span>", </span><span>// assert vsync
</span><span>      "</span><span>b:</span><span>",
</span><span>      "</span><span>wait 1 irq 0</span><span>",
</span><span>      "</span><span>jmp X-- b</span><span>", </span><span>// wait for 3 lines
</span><span>      "</span><span>set X, 20 side 1</span><span>", </span><span>// deassert vsync
</span><span>      "</span><span>c:</span><span>",
</span><span>      "</span><span>wait 1 irq 0</span><span>",
</span><span>      "</span><span>jmp X-- c</span><span>" </span><span>// wait for 21 lines (back porch)
</span><span>      "</span><span>.wrap</span><span>",
</span><span>  );
</span><span>
</span><span>  </span><span>// 2 cycles per pixel so we run at double speed
</span><span>  </span><span>// 6 instr
</span><span>  </span><span>let</span><span> rgb = pio::pio_asm!(
</span><span>      "</span><span>out X, 32</span><span>", </span><span>// holds 319, which we have to read from the FIFO
</span><span>      "</span><span>.wrap_target</span><span>",
</span><span>      "</span><span>mov Y, X</span><span>",
</span><span>      "</span><span>wait 1 irq 2</span><span>", </span><span>// wait until start of line
</span><span>      "</span><span>a:</span><span>",
</span><span>      "</span><span>out pins, 16</span><span>", </span><span>// write to rgb from dma
</span><span>      "</span><span>jmp Y-- a</span><span>",
</span><span>      "</span><span>mov pins, NULL</span><span>", </span><span>// output black
</span><span>      "</span><span>.wrap</span><span>"
</span><span>  );
</span></pre>
<p>The full code lives <a href="https://gitlab.scd31.com/stephen/rp2040-rcade-crt-driver/-/blob/master/src/main.rs">here</a>.</p><p>There are 3 separate PIO programs. <code>hsync</code> is responsible for keeping time and generating HSYNC pulses. At the start of each line, it generates an IRQ event that the other programs use for synchronization. <code>vsync</code> counts these events and generates the VSYNC pulses. Finally, <code>rgb</code> reads pixel data from DMA and outputs to the RGB pins in precise time with the other signals. The <code>out pins, 16</code> signifies that we're only doing 16-bit colour for now.</p><p>There's a lot of weirdness in here to get around the constraints of the PIO. For example, between all 3 programs, only a maximum of 31 instructions are allowed. All of the VGA parameters (resolution, porch length, etc.) are hard-coded, and changing these would require at least a small rewrite. It's pretty brittle in that regard, but for our use-case it's sufficient as a proof-of-concept.</p><p>Here it is running the actual CRT in the RCade:</p><p><a href="https://www.scd31.com/img/rcade/pio-crt.jpg"><img src="https://www.scd31.com/thumb/rcade/pio-crt.jpg"></a></p><p>I wanted to fill the framebuffer with a repeating pattern, but I messed up my code, hence it looking weird. That's fine - it was enough to verify my VGA program worked!</p><p>As an aside, every time I popped off the back of the RCade to work on it was terrifying. Not because of the lethal voltages inside, but because Recursers absolutely <i>love</i> the RCade. I often joke that if I were to break it, I would basically be the anti-Frank!</p><p>Now that I had something that could take a framebuffer and throw it onto the CRT, it was time to get the image from my computer to the RP2040.</p></section><h2>Let's write a kernel module!</h2><section><p>My plan was to write a Linux kernel module that would expose itself as a framebuffer, and then send that framebuffer over USB to the RP2040. On the framebuffer side, this involved interfacing with the <a href="https://www.kernel.org/doc/html/v4.11/gpu/drm-internals.html">DRM layer</a>.</p><p>I actually made decent progress here, although I kernel panicked many, many times. I never bothered to set up a proper development environment (oops), so pretty much any bug would require me to reboot my computer. This was super annoying and tedious, although I did learn a lot. I found cursed things in the official documentation, like <a href="https://www.kernel.org/doc/html/v5.5/gpu/drm-kms.html#c.drm_display_mode">interrobangs!</a></p><p><a href="https://www.scd31.com/img/rcade/interrobangs.png"><img src="https://www.scd31.com/thumb/rcade/interrobangs.png"></a></p><small>Linus pls</small><p>I got as far as getting a framebuffer to show up at the correct resolution and refresh rate. Along this journey though, I discovered the <a href="https://github.com/notro/gud/wiki">GUD kernel module</a>, and quickly realized I should use that instead.</p></section><h2>GUD is... pretty good</h2><section><p>Okay so this GUD thing is sick. It's a USB display adapter protocol - exactly what I need! It was originally designed to send video from a computer to a Pi Zero for use as a secondary display. It consists of an upstreamed (!!!) kernel module that runs on the host, and separate gadget software that runs on the Pi Zero. I decided I would just write my own gadget implementation to run on the RP2040.</p><p>As a protocol, GUD seems decent. It supports compression over the wire, and only sends the deltas of what's changed in the host's framebuffer. It's also pretty robust in terms of allowing the gadget to advertise what features it supports - compression is optional, and there's flexibility in colour depth and resolution. And again, it's upstreamed into the kernel, so anyone on modern Linux could use my display adapter with no software tweaks.</p><p>Unfortunately, GUD has almost no documentation. I figured out what I needed to do by reverse engineering the kernel module, which involved recompiling it to add some debugging statements. The protocol is simple enough that is wasn't too much of a hassle, and it didn't take long before I had developed a gadget implementation in Rust for the RP2040.</p><p>And with that, we saw our first Linux images on the CRT:</p>
<p>I know, I know, it looks terrible. Several years ago, I had built a board that implements the R/G/B DACs out of resistors, and I reused that for this project. It can only do 12 bits of colour maximum, and for this test I only bothered to wire up ~2 bits per channel, which is basically unusable. But it proves the concept works!</p><p><a href="https://www.scd31.com/img/rcade/vga-dac.jpg"><img src="https://www.scd31.com/thumb/rcade/vga-dac.jpg"></a></p><small>The board I built several years ago. It was originally designed to fit an STM32 development board.</small><p>To be honest, it's pretty lucky that this board came with me to New York. I'm surprised I didn't either throw it out or move it to my parent's place. It was probably in some other box of things I deemed worth keeping around.</p><p><a href="https://www.scd31.com/img/rcade/rev0-board.jpg"><img src="https://www.scd31.com/thumb/rcade/rev0-board.jpg"></a></p><small>The VGA board connected to the RP2040.</small><p>You can see from the above picture that I really connected the bare minimum for a proof-of-concept. I find perfboard soldering to be a bit tedious!</p><p>As an aside, you may notice in the video that the entire screen is shifted to the left. The left side has wrapped around and is now on the right side. On initial boot, it would look fine; over time it would gradually get worse and worse. This is a bug in my implementation - I suspect it's some kind of buffer underflow that's happening, such that each time it occurs, the PIO gets progressively more out of sync. But this is just a guess; I didn't look into it too much.</p><p>The colour depth issue is trivial to fix, but this next one isn't. The framerate sucks! You can even see it in the video above, where you can watch the new frame scroll down the screen. The RP2040 can only do USB FS (full-speed), which is capable of 11 Mbps. At the 320x240x16 bpp we were originally targeting, every frame is 153.6 kB. At our maximum USB FS speed, that's less than 10 FPS! Embarrasingly, I had originally done the math with a bandwidth of 11 M<b>B</b>ps, not 11 M<b>b</b>ps, so I was off by a factor of 8. I was hoping to get something at least temporarily usable but had to go back to the drawing board.</p></section><h2>Going on a GUD gadget side quest</h2><section><p>Who even needs microcontrollers anyway? My next idea was to use the normal GUD gadget implementation, running on a Pi Zero, but outputting to VGA over GPIO. Conceptually this is pretty simple, although in practice it was anything but. The canonical GUD gadget software was based on a 2021 version of <a href="https://buildroot.org/">Buildroot</a>, which was too old to output VGA. I tried, and failed, to update the Buildroot version, as well as to backport the VGA overlay. Neither of those really worked, but I didn't really know what I was doing.</p><p>I also played around with generating a custom NixOS image that had a modern kernel and the GUD gadget kernel module. When that didn't work I prepared to run a user space GUD gadget implementation on Raspberry Pi OS. But like, isn't that boring? And then I'll still be stuck at 18 bit colour! And sometimes a girl just wants to tickle her electrons :3</p></section><h2>Attempt... 2? 3? 1+i? Returning to MCU land</h2><section><p>Okay, so my beloved RP2040 doesn't support USB HS (high-speed). My beloved RP2350 (the newer version of the same chip) doesn't either. But some of my beloved STM32s do!</p><p>Initially I was planning to go computer -&gt; USB HS -&gt; STM32 -&gt; SPI bus -&gt; RP2040 -&gt; VGA. But like, that's complicated, and there are 2 microcontrollers to program, and there is so much to go wrong, and the SPI bus protocol is going to need to be robust against lost/extra bits, and AAAAAAAAAA I don't wanna!</p><p>But! STM32! I learned through research that some of the nicer ones have an LTDC peripheral, which, among other things, can drive an LCD display. And guess what? Many LCDs take in an R, G, B, HSYNC, and VSYNC signal. That's right - they pretend they're a CRT, and they pretend they have a cute little electron gun inside of them, and the STM32 is like "ok I got u" and can just like, do this natively. And I realize that this is what VGA is, but it's so, so funny to me that the protocol is literally just the manifestation of a physical design that is largely obsolete.</p><p>Okay so at this point I'm like, is this even a real project anymore? I'm just connecting the USB peripheral to the LTDC peripheral. What part of this is supposed to take effort? I had already written the GUD gadget implementation. Wasn't I basically already done?</p><p>OH BOY.</p><p>Anyway, by now it's Christmas time and I fly back to Canada to hang out with my family, as you would expect. I had none of my hardware with me, so now felt like a good time to design the actual board.</p><p><a href="https://www.scd31.com/img/rcade/rev1-top.jpg"><img src="https://www.scd31.com/thumb/rcade/rev1-top.jpg"></a>
<a href="https://www.scd31.com/img/rcade/rev1-bottom.jpg"><img src="https://www.scd31.com/thumb/rcade/rev1-bottom.jpg"></a></p><p>By Christmas Eve, this is what I had. Conceptually, it's a pretty basic board - there's the USB HS input, the VGA output, 3 8-bit DACs, some RAM for the framebuffer, and supporting components. At the heart of it is the STM32H723, which is a microcontroller that's advertised as supporting USB HS and LTDC.</p><p>It's worth talking about the DACs a bit. They have a few requirements. They need to map the 8-bit binary space uniformly to the analog domain. They also need to act as a resistor divider - my I/O is at 3.3V, but VGA expects a maximum of 0.7 volts for R/G/B. And finally, they need to be impedance-matched to the 75 ohms of the VGA cable, to prevent reflections and ringing that show up in the image. I am... pretty doubtful we need this at our resolution, but it doesn't hurt, and it increases nerd cred (^:</p><p>I encoded all of these requirements into a system of equations, threw it into a SAT solver, and computed all of my resistor values. I checked the output manually and it made sense, so I used these values in my DAC.</p><p>Also worth noting is the length-matched traces between the STM32 and the HyperRAM. Length-matching ensures that all the signals arrive at the same time; if some arrive too early or late it can cause issues. The traces aren't impedance-matched, but I did a bit of math and determined they were short enough that I didn't have to worry about it.</p><p>Also, I want to talk about the USB port. I used Mini-USB. Alright look. I know I know, I should have used USB-C. But I don't like USB-C! It's a dumb standard. We spent decades teaching non-technical users to plug the square wire into the square hole and the round wire into the round hole. And then we made every hole the same shape!! But they don't all support the same things!! Not even every <b>cable</b> supports the same things!! I hate it!! And Mini-USB is so cute. It's not reversible, but who cares? It's more robust than micro USB, while still being small. And it's my board, my rules. So yes, I will keep sending pictures of this board to people, and they will keep complaining it doesn't use USB-C. And I will continue to not care! Mini-USB is CUTE. And by the way, if you read this entire article and <b>this</b> is the section you choose to engage with, then you are boring!!! You will never live up to Mini-USB!!</p><p>Okay okay sorry about that. I am calm now. With all of that out of the way, I placed the order for the boards. I bought 5 of them, 2 of which were partially assembled. I would complete the rest of the assembly myself, but I didn't want to worry about the more finicky stuff. Between taxes, tariffs, and shipping, it came to a little over a hundred dollars USD.</p></section><h2>Disaster strikes</h2><section><p>About a week later, I was back home in NYC. My boards hadn't arrived yet, although I did have access to an STM32H723 development board at this point. To prepare for my boards, I started porting my RP2040 firmware to the STM32H723.</p><p>Things were going well until I tried getting USB set up. For some reason, I could only get it working at USB FS speeds. I figured I was just initializing something wrong - maybe a register I was forgetting about, or that wasn't in the HAL? I did a lot of digging, before finding this hidden in the datasheet (emphasis mine):</p><blockquote><p>The devices embed a USB OTG high-speed (up to 480 Mbit/s) device/host/OTG peripheral
that supports both full-speed and high-speed operations. It integrates the transceivers for
full-speed operation (12 Mbit/s) and a UTMI low-pin interface (ULPI) for high-speed
operation (480 Mbit/s). <b>When using the USB OTG_HS interface in HS mode, an external
PHY device connected to the ULPI is required.</b></p></blockquote><p>My heart sank. Yes, despite this chip very clearly advertising support for USB HS, it can't actually do that without an external PHY. This is super easy to miss - I actually told other people about the problem, and often they would tell me I was incorrect until I showed it to them in the datasheet. I've also found many posts on the ST Community forums from people running into the same thing. So yeah, I need a new board.</p><p>But because boards are expensive, I figure I'll still use the rev 1 board to validate as much as I can.</p></section><h2>Disaster strikes, again</h2><section><p>Once the boards come, I complete assembly of one, plug it into my computer, and nothing happens. I find out that the 3.3V rail is shorted to ground. This is the same on all of my boards, even the 3 that are disassembled. Some debugging later, it turns out I moved a via in KiCad and didn't do a re-pour. My ground plane was connected to my power plane.</p><p>I have a full CI/CD pipeline set up for my PCBs, so I was surprised it didn't catch this. It turns out it has a bit of wiggle-room, and the re-pour was small enough it didn't get picked up. I now know I need to be disciplined and run DRC locally, ensuring there are literally no differences (and if there are, commit them and push them up to my Git forge).</p><p>Although annoying, and quite embarrassing, this wasn't a huge deal. I used a drill bit and very carefully drilled out the offending via by hand. It made a bit of a mess - make sure you use breathing protection - but I got a board that worked.</p><p><a href="https://www.scd31.com/img/rcade/rev1-drilled.jpg"><img src="https://www.scd31.com/thumb/rcade/rev1-drilled.jpg"></a></p><small>The drilled-out via. You can see it directly under the text, near the center-bottom of the image.</small><p>At this point I wrote some code that exercised the HyperRAM and VGA. Everything worked great, so I began work on the new board. Here's what my development setup looked like while I was testing:</p><p><a href="https://www.scd31.com/img/rcade/rev1-ltdc-testing.jpg"><img src="https://www.scd31.com/thumb/rcade/rev1-ltdc-testing.jpg"></a></p><p>Even though the rev 1 board didn't work out, Frank pointed out that the difference between it and the previous revision was stark:</p><p><a href="https://www.scd31.com/img/rcade/rev0-rev1.jpg"><img src="https://www.scd31.com/thumb/rcade/rev0-rev1.jpg"></a></p><p>Not a bad pace of development!</p></section><h2>Attempt 4 - Rev 2</h2><section><p>I needed an STM32 that supported ULPI (used for talking to the USB PHY), LTDC, and some kind of external RAM. I looked at dozens of chips and found all sorts of blockers. Chips that actually supported both (but they had overlapping pins), chips that were advertised as supporting both (but in actuality, could only do one or the other, depending on the specific model number), and chips that actually could do both, with unconflicting pins, but only in a BGA package. I did not particularly want to deal with that, mainly because the tiny vias and traces would balloon the board cost even more.</p><p>I ended up settling on the STM32H750IBT, a massive, 176 pin, LQFP chip. This thing is larger than some New York apartments, and at over $10 USD, it costs about the same! I have bought entire dev boards for a fraction of this.</p><p>Once I picked out the chip, I basically redesigned the entire board from scratch. Sure, I could reuse the DACs, but I needed completely new RAM (the new chip has no HyperBus), as well as the USB PHY and supporting components. Now that my Christmas vacation was over, it took me a solid week to get everything designed. This isn't my most complicated board, but it's certainly my most complex routing:</p><p><a href="https://www.scd31.com/img/rcade/rev2-routing.png"><img src="https://www.scd31.com/thumb/rcade/rev2-routing.png"></a></p><p>I mean, look at those traces. I'm using basically all available space just to get them to be the same length. ST famously has bad pinouts, and because one of the memory controller pins is located on the complete opposite side of the chip, literally all of the rest of the RAM traces had to be lengthened. And the RAM has a 16-bit data bus. I had to route 38 length-matched traces for the memory alone!</p><p>The USB PHY also had a decent number of traces to route, although far less than the RAM. This is probably the part where I'm supposed to say that like, crosstalk is bad and stuff, but we're just gonna ignore that. I had like no space; leave me alone!</p><p>Here's what the board looked like:</p><p><a href="https://www.scd31.com/img/rcade/rev2-top.jpg"><img src="https://www.scd31.com/thumb/rcade/rev2-top.jpg"></a>
<a href="https://www.scd31.com/img/rcade/rev2-bottom.jpg"><img src="https://www.scd31.com/thumb/rcade/rev2-bottom.jpg"></a></p><p>And with that, I ordered the board. Waiting for it to arrive just about killed me, but when it finally did, I got to work.</p></section><h2>Board bring-up</h2><section><p>Board bring-up is a magical thing. One-by-one, you enable each part of the board, and you make sure that everything works the way you expect. Given that USB burned me before, I decided to start there.</p><p>Right out of the gate, I was off to a bumpy start. I got the USB technically working, and I even got it to show up on my computer as USB HS (yay!), but it was super, super flaky. Eventually I worked out that its crystal oscillator was unstable. Going back to the datasheet, I realized I missed a 1M ohm resistor, which was meant to be put in parallel with the crystal. I didn't have one handy, but I know the human body is around that resistance. I put one finger on each terminal of the crystal. It immediately stabilized. I was pretty ecstatic!</p><p>The next day I went to the Recurse Center and stole a 1M ohm resistor to affix to the board. (Faculty, if you're reading this, I owe you about a tenth of a cent. Sorry!)</p><p>With that over, the rest of the bring-up process was pretty smooth. I got the LTDC running and ported over the rest of the code that implemented the GUD protocol. I had written things pretty naively but, to my surprise, it didn't need any optimization for high-speed USB. I guess that's what a microcontroller with a 480 MHz core will get you!</p></section><h2>Running it in the RCade cabinet</h2><section><p>I was already at the Recurse Center at this point, so I popped the back off the RCade, unplugged the VGA from the Pi, and plugged it into my board. It started up immediately - the colours looked great and I got the full 60 Hz framerate. To be honest, I was shocked at how good it looked, and the crowd that had formed was shocked too. I wasn't really a believer that 24 bit colour would be noticeable, but I was totally wrong. The lack of colour banding was striking.</p><p>Next, I plugged the board into the Pi, and Frank reconfigured it to make my display adapter the primary display. We launched the normal RCade software and played some games. They looked truly amazing; nothing like before. <a href="https://rose.hall.ly/">Rose</a>, one of the main people who developed the software, joked that it looked so good that some of the graphical shortcuts she took were no longer sufficient.</p><p><a href="https://www.scd31.com/img/rcade/image-before.jpg"><img src="https://www.scd31.com/thumb/rcade/image-before.jpg"></a>
<a href="https://www.scd31.com/img/rcade/image-after.jpg"><img src="https://www.scd31.com/thumb/rcade/image-after.jpg"></a></p><p>It's hard to tell in the pictures but the difference in person was striking. Where it's most obvious is in the lack of banding around the mountains.</p><p>This felt amazing, but I wasn't quite ready to leave the board installed. It was fragile - especially with the resistor I bodged on - and it was expensive. I took my board back out and Frank reverted the RCade to how it was before.</p></section><h2>Designing a case</h2><section><p>I'll be honest. I don't get that much joy out of 3D modeling. I find it frustrating, tedious, and generally unfulfilling. To get around this, I decided to use <a href="https://github.com/mrWheel/YAPP_Box">YAPP</a> to design the case. YAPP is a parametric box generator written in OpenSCAD. I wrote a few dozen lines of code and ended up with this beauty:</p><p><a href="https://www.scd31.com/img/rcade/case-top.png"><img src="https://www.scd31.com/thumb/rcade/case-top.png"></a>
<a href="https://www.scd31.com/img/rcade/case-bottom.png"><img src="https://www.scd31.com/thumb/rcade/case-bottom.png"></a></p><p>It took barely any time at all and only took 2 physical revisions before I was happy with it. I added the OpenSCAD code to my board repository and CI/CD pipeline. Now, it builds all the files I need to order the boards, as well as the STL files for the case.</p><p><a href="https://www.scd31.com/img/rcade/case-printing.jpg"><img src="https://www.scd31.com/thumb/rcade/case-printing.jpg"></a></p><small>HE'S BEGINNING TO TAKE FORM</small><p>And now, with the board in the case:</p><p><a href="https://www.scd31.com/img/rcade/physical-case-top.jpg"><img src="https://www.scd31.com/thumb/rcade/physical-case-top.jpg"></a>
<a href="https://www.scd31.com/img/rcade/physical-case-bottom.jpg"><img src="https://www.scd31.com/thumb/rcade/physical-case-bottom.jpg"></a></p><p>At this point I was starting to prepare myself to install it in the RCade.</p></section><h2>Disaster strikes, again??</h2><section><p>Everything was done, so I expected I'd just plug it in and be good to go. When I did this, though, nothing happened. After some debugging I realized the USB had completely died on my board. It wasn't showing up on any computer I connected it to, although the STM32 was still chugging along happily (and outputting to VGA).</p><p>I still haven't figured out exactly what happened here. I was having a bit of flakiness with the USB already. I vaguely suspect ESD to either the STM32 or the USB PHY, but am not super confident this is the cause. I'm going to keep looking into this. (inb4: wow maybe you shouldn't have touched the crystal without grounding yourself first!)</p><p>In the meantime, I assembled a second board and got that installed instead. I'm slightly nervous because I don't have a third board to use if this one also dies, and I don't want to order any more until I can figure out what's killing them. That said, it has been a few days now since I installed it, and despite running 24/7, there's no signs of it dying yet.</p><p><a href="https://www.scd31.com/img/rcade/in-cabinet.jpg"><img src="https://www.scd31.com/thumb/rcade/in-cabinet.jpg"></a></p><p>Here's the board in its case, installed in the RCade. We're still running it off the Raspberry Pi for now, but soon we'll have that switched out with a laptop. I can't wait!</p></section><h2>Future improvements</h2><section><p>There are all sorts of things I want to change. I want the board to also support audio, with an integrated amp. Perhaps even a tube amp? I just think it would be funny. And being able to read input from the controls would be cool too.</p><p>On the software side, I want double or triple buffering. I actually got them both working, although they didn't play nice with the deltas that GUD sends over the wire. There are workarounds to this that I haven't implemented yet. It would also be nice to give GUD the ability to disable these deltas; perhaps that would be a good feature for me to add to the kernel module. Writing some documentation on the GUD protocol could be good too!</p><p>This was a really fun project, and it's not over yet, but I think all the hard stuff is pretty much done (although - I've thought that before!). I really wasn't expecting this to take as long as it did, but I learned so much, and I'm a stronger engineer for it.</p></section><h2>Source code</h2><section><p>There's a few repositories of interest:</p><p>The hardware lives <a href="https://gitlab.scd31.com/stephen/stm32-usb-vga-adapter-hardware">here</a>.</p><p>The software lives <a href="https://gitlab.scd31.com/stephen/stm32-usb-vga-rcade-adapter">here</a>.</p><p>If you're interested, the original software for the RP2040 lives <a href="https://gitlab.scd31.com/stephen/rp2040-rcade-crt-driver">here</a>.</p><p>My very messy DAC equations live <a href="https://gitlab.scd31.com/stephen/vga-dac-formula-sage">here</a>.</p><p>My Nix GUD gadget attempt lives <a href="https://gitlab.scd31.com/stephen/rcade-gud-os">here</a>.</p><p>I also wrote a fair bit of scratch code while learning (such as for my kernel module), but I don't think any of it was worth putting it in my Git forge.</p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI is killing B2B SaaS (214 pts)]]></title>
            <link>https://nmn.gl/blog/ai-killing-b2b-saas</link>
            <guid>46888441</guid>
            <pubDate>Wed, 04 Feb 2026 17:09:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nmn.gl/blog/ai-killing-b2b-saas">https://nmn.gl/blog/ai-killing-b2b-saas</a>, See on <a href="https://news.ycombinator.com/item?id=46888441">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    
    
      <p>SaaS is the most profitable business model on Earth.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup> It’s easy to understand why: build once, sell the same thing again ad infinitum, and don’t suffer any marginal costs on more sales.</p>

<p>I have been writing software for more than half my life. In the last year itself, I’ve talked to hundreds of founders and operators in SF, from preseed to Series E companies.</p>

<p>AI is bringing an existential threat to a lot of B2B SaaS executives: How to keep asking customers for renewal, when every customer <em>feels</em> they can get something better built with vibe-coded AI products?</p>

<p>And the market is pricing it in. Morgan Stanley’s SaaS basket has <a href="https://www.bloomberg.com/news/articles/2026-01-18/-no-reasons-to-own-software-stocks-sink-on-fear-of-new-ai-tool">lagged the Nasdaq by 40 points</a> since December. HubSpot and Klaviyo are down ~30%. Analysts are writing notes titled “No Reasons to Own” software stocks.</p>

<figure>
  <img src="https://nmn.gl/blog/assets/saas-stocks.png">
  <figcaption>The market is reflecting our new reality (Source: Bloomberg)</figcaption>
</figure>

<!--more-->

<h2 id="the-relation-between-vibe-coding-and-b2b-saas-sales">The relation between vibe coding and B2B SaaS sales</h2>

<p>The new problem for B2B SaaS is that with AI, customers can get <em>something</em> working with vibe coding. There are tens of vibe coding “internal tool” services that promise to connect to every integration in the world to pump out CRUD and workflow apps.</p>

<p>Whatever they build <em>simply works</em>. It takes some wrangling to get there (one Series C VP listed <strong>eleven different</strong> vibe coding tools they’ve tried and the pros and cons between each on a phone call once), but productivity gains are immediate.</p>

<p>And vibe coding is fun. You feel like a mad wizard using the right incantation <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">2</a></sup> to get this magical new silicon intelligence to do exactly what you want.</p>

<p>What they don’t know, though, is that a poorly architected system will fail, eventually. As every senior programmer (eventually) understands, our job is complex because we have to understand the relationships in the real world, the processes involved, and the workflows needed, and representing it in a robust way to create a stable system. AI can’t do that.</p>

<p>Non-programmers don’t know any of this nuance. One Series E CEO told me that they’re re-evaluating the quarterly renewal of their engineering productivity software because they along with an engineer reimplemented something using Github and Notion APIs. They were paying $30,000 to a popular tool<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">3</a></sup> <strong>and they were not going to renew anymore.</strong></p>

<h2 id="how-does-it-impact-b2b-sales">How does it impact B2B sales?</h2>

<p>If customers feel like they aren’t being served exactly like they want to, they are more likely to churn. The reason behind all this is that customers are demanding more from their B2B vendors, because they know what’s possible.</p>

<p>Previously, you would change <em>your company</em> to fit what your ERP and pay them hundreds of thousands of dollars. Now, everyone can see that agentic coding makes an unprecedented level of flexibility possible. And customers are demanding that flexibility, and if they don’t get it, they’ll leave.</p>

<p>This week itself I was on a phone call with a Series B AE talking about how they’re potentially losing an $X00,000 account just because the customer can’t use a specific failure reporting workflow in the SaaS. They’re now working with me to build what the customer needs and retain them.</p>

<h2 id="how-to-survive">How to survive</h2>

<h3 id="1-be-a-system-of-record">1. Be a System of Record</h3>

<p>If the entire company’s workflows operates on your platform, i.e. you’re a line-of-business SaaS, you are integrated into their existing team already. They know your UI and rely on you on the day to day.</p>

<p>For example, to create a data visualization I won’t seek any SaaS. I’ll just code one myself using many of the popular vibe coding tools <em>(my team actually did that and it’s vastly more flexible than what we’d get off-the-shelf).</em></p>

<p>Being a “System of Record” means you’re embedded so deeply that there’s no choice but to win. My prediction is that we’ll see more SaaS companies go from the application layer to offering their robust SoR as their primary selling point.</p>

<h3 id="2-security-authentication-and-robustness">2. Security, authentication, and robustness</h3>

<p>This is where vibe-coded apps silently fail — and where established SaaS platforms earn their keep.</p>

<p>When a non-technical team vibe-codes an internal tool, they’re not thinking about environment keys, XSS vulnerabilities or API keys hardcoded in client-side JavaScript. They’re not implementing rate limiting, audit logs, or proper session management. They’re definitely not thinking about SOC 2 compliance, GDPR data residency requirements, or HIPAA audit trails.</p>

<p>I’ve seen it firsthand: a finance team built a “quick” expense approval tool that stored unencrypted reports in a public S3 bucket. A sales ops team created a commission calculator that anyone with the URL could access — no auth required. These aren’t edge cases. They’re the norm when software is built without security as a foundational concern.</p>

<p>Enterprise SaaS platforms have spent years (and millions) solving these problems: role-based access control, encryption at rest and in transit, penetration testing, compliance certifications, incident response procedures. Your customers may not consciously value this — until something breaks.</p>

<p>The challenge is that security is invisible when it works. You need to communicate this value proactively: remind customers that the “simple” tool they could vibe-code themselves would require them to also handle auth, permissions, backups, uptime, and compliance.</p>

<h3 id="3-adapt-to-the-customer-not-the-other-way-around">3. Adapt to the customer, not the other way around</h3>

<p>The times of asking customers to change how they work are gone. Now, SaaS vendors that differentiate by being ultra customizable win the hearts of customers.</p>

<p>How? It’s the most powerful secret to increase usage. We’ve all heard the classic SaaS problem where the software is sold at the beginning of the year, but no one actually ends up using it because of how inflexible it is and the amount of training needed.</p>

<p>And if a SaaS is underutilized, it gets noticed. And that leads to churn.</p>

<p>This is the case with one of my customers, they have a complex SaaS for maintenance operations. But turns out, this was not being used at the technician level because they found the UI too complex<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">4</a></sup>.</p>

<p>How I’m solving this is essentially a whitelabelled vibe-coding platform with in-built distribution and secure deployments. When they heard of my solution they were immediately onboard. Their customer success teams quickly coded a very specific mobile webapp for the technicians to use and deployed it in a few days.</p>

<p>Now, the IC technician is exposed to just those parts of the SaaS that they care about i.e. creating maintenance work orders. The executives get what they want too, vibe coding custom reports exactly the way they want vs going through complicated BI config. They are able to build exactly what they want and feel like digital gods while doing it.</p>

<p><strong>Usage for that account was under 35%, and is now over 70%.</strong> They are now working closely with me to vibe code new “micro-apps” that work according to all of their customer workflows. And the best part? This is all on top of their existing SaaS which works as a system of record and handles security, authentication, and supports lock-in by being a data and a UI moat.</p>

<p>This is exactly what I’m building: a way for SaaS companies to let their end-users vibe code on top of their platform (More on that below). My customers tell me it’s the best thing they’ve done for retention, engagement, and expansion in 2026 – because when your users are building on your platform, they’re not evaluating your competitors.</p>

<h2 id="the-real-shift">The Real Shift</h2>

<p>Here’s what I’ve realized after hundreds of conversations with founders and operators: AI isn’t killing B2B SaaS. It’s killing B2B SaaS <strong>that refuses to evolve</strong>.</p>

<p>The SaaS model was built on a simple premise: we build it once, you pay forever. That worked when building software was hard. But now your customers have tasted what’s possible. They’ve seen their finance team whip up a custom dashboard in an afternoon. They’ve watched a non-technical PM build an internal tool that actually fits their workflow.</p>

<p>You can’t unsee that. You can’t go back to paying $X0,000/year for software that almost does what you need.</p>

<p>The survivors won’t be the SaaS companies with the best features. They’ll be the ones who become platforms – who let customers build <em>on top of</em> them instead of <em>instead of</em> them. When I showed a well-known VC what I was building to help SaaS companies do exactly this, he said: “This is the future of marketplaces and software companies.”</p>

<p>Maybe. Or maybe this is just another cycle and traditional SaaS will adapt like it always has. But I know this: the companies I’m talking to aren’t waiting around to find out. They’re already rebuilding their relationship with customers from “use our product” to “build on our platform.”</p>

<p>The question isn’t whether AI will eat your SaaS.</p>

<p>It’s whether you’ll be the one holding the fork.</p>

<hr>

<p><strong>I’m solving exactly this problem with a whitelabelled AI platform for B2B SaaS companies</strong>, so your users can vibe code customized workflows on top of their existing system of record.</p>

<p>My customers tell me this is the <strong>best way to support retention, engagement, and expansion</strong> in 2026. If this sounds interesting to you or someone you know, I can reach out with a custom demo or you can <a target="_blank" href="https://gigamind.dev/catalyst">learn more about Giga Catalyst</a>.</p>

<hr>



    
    
    
    
    
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[French streamer unbanked by Qonto after criticizing Palantir and Peter Thiel (196 pts)]]></title>
            <link>https://twitter.com/Ced_haurus/status/2018716889191498172</link>
            <guid>46888438</guid>
            <pubDate>Wed, 04 Feb 2026 17:09:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Ced_haurus/status/2018716889191498172">https://twitter.com/Ced_haurus/status/2018716889191498172</a>, See on <a href="https://news.ycombinator.com/item?id=46888438">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft's Copilot chatbot is running into problems (111 pts)]]></title>
            <link>https://www.wsj.com/tech/ai/microsofts-pivotal-ai-product-is-running-into-big-problems-ce235b28</link>
            <guid>46887564</guid>
            <pubDate>Wed, 04 Feb 2026 16:08:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/tech/ai/microsofts-pivotal-ai-product-is-running-into-big-problems-ce235b28">https://www.wsj.com/tech/ai/microsofts-pivotal-ai-product-is-running-into-big-problems-ce235b28</a>, See on <a href="https://news.ycombinator.com/item?id=46887564">Hacker News</a></p>
Couldn't get https://www.wsj.com/tech/ai/microsofts-pivotal-ai-product-is-running-into-big-problems-ce235b28: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Voxtral Transcribe 2 (714 pts)]]></title>
            <link>https://mistral.ai/news/voxtral-transcribe-2</link>
            <guid>46886735</guid>
            <pubDate>Wed, 04 Feb 2026 15:08:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/voxtral-transcribe-2">https://mistral.ai/news/voxtral-transcribe-2</a>, See on <a href="https://news.ycombinator.com/item?id=46886735">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p dir="ltr">Today, we're releasing Voxtral Transcribe 2, two next-generation speech-to-text models with state-of-the-art transcription quality, diarization, and ultra-low latency. The family includes Voxtral Mini Transcribe V2 for batch transcription and Voxtral Realtime for live applications. Voxtral Realtime is open-weights under the Apache 2.0 license.</p>
<p dir="ltr">We're also launching an <a href="https://console.mistral.ai/build/audio/speech-to-text">audio playground in Mistral Studio</a> to test transcription instantly, powered by Voxtral Transcribe 2, with diarization and timestamps.</p>
<h2 dir="ltr">Highlights.</h2>
<ul>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Voxtral Mini Transcribe V2: State-of-the-art transcription with speaker diarization, context biasing, and word-level timestamps in 13 languages.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Voxtral Realtime: Purpose-built for live transcription with latency configurable down to sub-200ms, enabling voice agents and real-time applications.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Best-in-class efficiency: Industry-leading accuracy at a fraction of the cost, with Voxtral Mini Transcribe V2 achieving the lowest word error rate, at the lowest price point.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Open weights: Voxtral Realtime ships under Apache 2.0, deployable on edge for privacy-first applications.</p>
</li>
</ul>
<h2 dir="ltr">Voxtral Realtime.</h2>
<p dir="ltr">Voxtral Realtime is purpose-built for applications where latency matters. Unlike approaches that adapt offline models by processing audio in chunks, Realtime uses a novel streaming architecture that transcribes audio as it arrives. The model delivers transcriptions with delay configurable down to sub-200ms, unlocking a new class of voice-first applications.</p>
<p dir="ltr"><img src="https://cms.mistral.ai/assets/a21cafea-208d-4290-b65e-36c0514dc179.png?width=2621&amp;height=1293" alt="Fleur Voxtral 2"></p>
<p dir="ltr"><em>Word error rate (lower is better) across languages in the FLEURS transcription benchmark.</em></p>
<p dir="ltr">At 2.4 seconds delay, ideal for subtitling, Realtime matches Voxtral Mini Transcribe V2, our latest batch model. At 480ms delay, it stays within 1-2% word error rate, enabling voice agents with near-offline accuracy.</p>
<p dir="ltr">The model is natively multilingual, achieving strong transcription performance in 13 languages, including English, Chinese, Hindi, Spanish, Arabic, French, Portuguese, Russian, German, Japanese, Korean, Italian, and Dutch. With a 4B parameter footprint, it runs efficiently on edge devices, ensuring privacy and security for sensitive deployments.</p>
<p dir="ltr">We’re releasing the model weights under Apache 2.0 on the <a href="https://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602" target="_blank" rel="noopener">Hugging Face Hub.</a></p>
<h2 dir="ltr">Voxtral Mini Transcribe V2.</h2>
<p><img src="https://cms.mistral.ai/assets/6b8d07b0-1526-4e94-ac66-a861f092aa41.png?width=1775&amp;height=1103" alt="Voxtral 2.0   Avg Diarization Error Rate   Priceper Min"></p>
<p><em>Average diarization error rate (lower is better) across five English benchmarks (Switchboard, CallHome, AMI-IHM, AMI-SDM, SBCSAE) and the TalkBank multilingual benchmark (German, Spanish, English, Chinese, Japanese).</em></p>
<p><img src="https://cms.mistral.ai/assets/58664549-fe38-420a-86fd-5c7003476689.png?width=1775&amp;height=1111" alt="Voxtral 2.0   Transcription Performance Fleurs   Priceper Min"></p>
<p><em>Average word error rate (lower is better) across the top-10 languages in the FLEURS transcription benchmark.</em></p>
<p>Voxtral Mini Transcribe V2 delivers significant improvements in transcription and diarization quality across languages and domains. At approximately 4% word error rate on FLEURS and $0.003/min, Voxtral offers the best price-performance of any transcription API. It outperforms GPT-4o mini Transcribe, Gemini 2.5 Flash, Assembly Universal, and Deepgram Nova on accuracy, and processes audio approximately 3x faster than ElevenLabs’ Scribe v2 while matching on quality at one-fifth the cost.</p>
<h3 dir="ltr">Enterprise-ready features.</h3>
<p dir="ltr">Voxtral Mini Transcribe V2 introduces key capabilities for enterprise deployments.</p>
<div>
<div><p><img src="https://cms.mistral.ai/assets/4b23530e-23c1-4a58-8296-c61a1d5cff98.png?width=96&amp;height=96" alt="Icon Language"></p><h4>Speaker diarization.</h4>
<p dir="ltr">Generate transcriptions with speaker labels and precise start/end times. Ideal for meeting transcription, interview analysis, and multi-party call processing. Note: with overlapping speech, the model typically transcribes one speaker.</p>
</div>
<div><p><img src="https://cms.mistral.ai/assets/221e1a35-1b56-41a1-b294-6e5a3492e0cd.png?width=72&amp;height=64" alt="Icon Filters"></p><h4>Context biasing.</h4>
<p dir="ltr">Provide up to 100 words or phrases to guide the model toward correct spellings of names, technical terms, or domain-specific vocabulary. Particularly useful for proper nouns or industry terminology that standard models often miss. Context biasing is optimized for English; support for other languages is experimental.</p>
</div>
<div><p><img src="https://cms.mistral.ai/assets/e8c644a8-93bf-49c0-ae96-a859c1cec3ad.svg?width=32&amp;height=32" alt="Word-level timestamps."></p><h4>Word-level timestamps.</h4>
<p dir="ltr">Generate precise start and end timestamps for each word, enabling applications like subtitle generation, audio search, and content alignment.</p>
</div>
</div>
<div>
<div><p><img src="https://cms.mistral.ai/assets/ecdac1ed-522e-4a58-a3cc-23d03c40ba6e.png?width=96&amp;height=96" alt="Icon Earth Black"></p><h4>Expanded language support.</h4>
<p dir="ltr">Like Realtime, this model now supports 13 languages: English, Chinese, Hindi, Spanish, Arabic, French, Portuguese, Russian, German, Japanese, Korean, Italian, and Dutch. Non-English performance significantly outpaces competitors.</p>
</div>
<div><p><img src="https://cms.mistral.ai/assets/ec93c74e-5cdd-4950-b494-0a8f3a43dd74.svg?width=32&amp;height=32" alt="Noise robustness."></p><h4>Noise robustness.</h4>
<p dir="ltr">Maintains transcription accuracy in challenging acoustic environments, such as factory floors, busy call centers, and field recordings.</p>
</div>
<div><p><img src="https://cms.mistral.ai/assets/d18e43b2-1c42-4916-b787-d28739220476.svg?width=32&amp;height=32" alt="Longer audio support."></p><h4>Longer audio support.</h4>
<p dir="ltr">Process recordings up to 3 hours in a single request.</p>
</div>
</div>
<p dir="ltr"><img src="https://cms.mistral.ai/assets/97f4a4ee-7448-4a2f-889e-17409821e503.png?width=2849&amp;height=1358" alt="FlEURS"></p>
<p><em>Word error rate (lower is better) across languages in the FLEURS transcription benchmark.</em></p>
<h2 dir="ltr">Audio playground.</h2>
<p dir="ltr">Test Voxtral Transcribe 2 directly in <a href="https://console.mistral.ai/build/audio/speech-to-text">Mistral Studio</a>. Upload up to 10 audio files, toggle diarization, choose timestamp granularity, and add context bias terms for domain-specific vocabulary. Supports .mp3, .wav, .m4a, .flac, .ogg up to 1GB each.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/93ZAhW3bk8g" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h2 dir="ltr">Transforming voice applications.</h2>
<p dir="ltr">Voxtral powers voice workflows in diverse applications and industries.</p>
<ul>
<li>
<h3 dir="ltr">Meeting intelligence.</h3>
<p dir="ltr">Transcribe multilingual recordings with speaker diarization that clearly attributes who said what and when. At Voxtral's price point, annotate large volumes of meeting content at industry-leading cost efficiency.</p>
</li>
<li>
<h3 dir="ltr">Voice agents and virtual assistants.</h3>
<p dir="ltr">Build conversational AI with sub-200ms transcription latency. Connect Voxtral Realtime to your LLM and TTS pipeline for responsive voice interfaces that feel natural.</p>
</li>
<li>
<h3 dir="ltr">Contact center automation.</h3>
<p dir="ltr">Transcribe calls in real time, enabling AI systems to analyze sentiment, suggest responses, and populate CRM fields while conversations are still happening. Speaker diarization ensures clear attribution between agents and customers.</p>
</li>
<li>
<h3 dir="ltr">Media and broadcast.</h3>
<p dir="ltr">Generate live multilingual subtitles with minimal latency. Context biasing handles proper nouns and technical terminology that trip up generic transcription services.</p>
</li>
<li>
<h3 dir="ltr">Compliance and documentation.</h3>
<p dir="ltr">Monitor and transcribe interactions for regulatory compliance, with diarization providing clear speaker attribution and timestamps enabling precise audit trails.</p>
</li>
</ul>
<p dir="ltr">Both models support GDPR and HIPAA-compliant deployments through secure on-premise or private cloud setups.</p>
<h2 dir="ltr">Get started.</h2>
<p dir="ltr"><a href="https://docs.mistral.ai/models/voxtral-mini-transcribe-26-02">Voxtral Mini Transcribe V2</a> is available now via API at $0.003 per minute. Try it now in the new Mistral Studio <a href="https://console.mistral.ai/build/audio/speech-to-text">audio playground</a> or in <a href="http://chat.mistral.ai/">Le Chat</a>.</p>
<p dir="ltr"><a href="https://docs.mistral.ai/models/voxtral-mini-transcribe-realtime-26-02">Voxtral Realtime</a> is available via API at $0.006 per minute and as open weights on <a href="https://huggingface.co/mistralai/Voxtral-Mini-3B-Realtime-2602">Hugging Face</a>.</p>
<p dir="ltr"><a href="https://docs.mistral.ai/capabilities/audio_transcription">Explore documentation</a> on Mistral’s audio and transcription capabilities.</p>
<h2 dir="ltr">We’re hiring.</h2>
<p dir="ltr">If you're excited about building world-class speech AI and putting frontier models into the hands of developers everywhere, we'd love to hear from you. <a href="https://mistral.ai/careers">Apply to join our team</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A case study in PDF forensics: The Epstein PDFs (244 pts)]]></title>
            <link>https://pdfa.org/a-case-study-in-pdf-forensics-the-epstein-pdfs/</link>
            <guid>46886440</guid>
            <pubDate>Wed, 04 Feb 2026 14:46:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pdfa.org/a-case-study-in-pdf-forensics-the-epstein-pdfs/">https://pdfa.org/a-case-study-in-pdf-forensics-the-epstein-pdfs/</a>, See on <a href="https://news.ycombinator.com/item?id=46886440">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>The recent release of a <a href="https://www.justice.gov/epstein/doj-disclosures" target="_blank" rel="noopener">tranche of files</a> by the US Department of Justice (DoJ) under the “Epstein Files Transparency Act (H.R.4405)” has once again prompted many people to closely examine redacted and sanitized PDF documents. Our previous articles on the <a href="https://pdfa.org/corruption-in-pdf-federal-crimes-edition/">Manafort papers</a> and the <a href="https://pdfa.org/a-technical-and-cultural-assessment-of-the-mueller-report-pdf/">Mueller report</a>, as well as a study by Adhatarao, S. and Lauradoux, C. (2021) “<a href="https://doi.org/10.1145/3437880.3460405" target="_blank" rel="noopener">Exploitation and Sanitization of Hidden Data in PDF Files: Do Security Agencies Sanitize Their PDF files?</a>,” in <em>Proceedings of the 2021 ACM Workshop on Information Hiding and Multimedia Security</em>, illustrate the importance of robust sanitization and redaction workflows when handling sensitive documents prior to release.</p>
<p>This article examines a small random selection of the Epstein PDF files from a purely digital forensic perspective, focusing on the PDF syntax and idioms they contain, any malformations or unusual constructs, and other technical aspects.</p>
<p>PDFs are more challenging to analyze than many other formats because they are binary files that require specialized knowledge, expertise, and software. Please note that we did not analyze the contents of the PDF documents. Not every PDF was examined. Any mention of products (or appearance in screen-shots) does not imply any endorsement or support of any information, products, or providers whatsoever. We are not lawyers; this article does not constitute legal advice</p>
<p>We offer this information, in part, as some of the Epstein PDFs released by DoJ are beginning to appear on malware analysis sites (such as <a href="https://hybrid-analysis.com/sample/d8f6ba273d416f1b3160b94b5646374b218a9ecef9d2cb3ae33cd3788f8f862b/6946599fcca0461fcc056ab2" target="_blank" rel="noopener">Hybrid-Analysis</a>) with various kinds of incorrect analysis and misinformation.</p>
<h2 id="26-december-2025-update">26 December 2025 update</h2>
<p>After we'd completed our analysis the DoJ released a new dataset, <a href="https://www.justice.gov/epstein/files/DataSet%208.zip">DataSet 8.zip</a>. This new ZIP file is 9.95 GB compressed and contains over 11,000 files, including 10,593 new PDFs totaling 1.8 GB and 29,343 pages (the longest document has 1,060 pages). DataSet 8 also contains many large MP4 movies, Excel spreadsheets, and various other files. The first PDF in the set of 10,593 PDFs is VOL00008\IMAGES\0001\EFTA00009676.pdf, and the last file is VOL00008\IMAGES\0011\EFTA00039023.pdf. A cursory analysis shows <span>pdfinfo</span> properties similar to those from the earlier datasets, but we have not otherwise analyzed this new dataset.</p>
<p>Since our original post, various social media and news platforms have also been announcing “recoverable redactions” from the “Epstein Files”. We stand by our analysis; DoJ has correctly redacted the EFTA PDFs in Datasets 01-07, and they <b><i>do not contain</i></b> recoverable text as alleged. As our article states, we did not analyze any other DoJ or Epstein-related documents.</p>
<p>For example, the featured image in <a href="https://www.theguardian.com/us-news/2025/dec/23/epstein-unredacted-files-social-media">this Guardian news article</a> (which was also picked up by the <a href="https://www.nytimes.com/2025/12/23/us/politics/epstein-files-redactions-doj.html">New York Times</a>) corresponds to VOL00004\IMAGES\0001EFTA00005855.pdf, as can be easily determined by searching for the Bates Numbers in the EFTA “.OPT” data files. The information in this EFTA PDF is <b><i>fully and correctly redacted</i></b>; there is <b><i>no hidden information</i></b>. The only extractable text is some garbled text from the poor-quality OCR and, as expected, the Bates Numbers on each page.</p>
<p>In the few reports we investigated (including from <a href="https://www.forbes.com/sites/daveywinder/2025/12/26/epstein-files-hacked---all-you-need-to-know">Forbes</a> and Ed Krassenstein on both <a href="https://x.com/EdKrassen/status/2003222444270661801">X (formerly Twitter)</a> and <a href="https://www.instagram.com/krassensteins?igsh=eGYyc3gwZXA2eW4=">Instagram</a>), these stories misrepresent <strong><i>other</i></strong> DoJ files that were <b><i>not</i></b> part of the major DataSets 01-07 release on December 19 under the EFTA. All PDFs released under EFTA have a Bates Number on every page starting "EFTA". These include “<a href="https://www.justice.gov/multimedia/Court%20Records/Government%20of%20the%20United%20States%20Virgin%20Islands%20v.%20JPMorgan%20Chase%20Bank,%20N.A.,%20No.%20122-cv-10904%20(S.D.N.Y.%202022)/001-01.pdf">Case 1:22-cv-10904-JSR &nbsp; Document 1-1,&nbsp; Exhibit 1 to Government’s Complaint against JPMorgan Chase Bank, N.A.</a>” (see page 41) and “<a href="https://www.justice.gov/multimedia/Court%20Records/Matter%20of%20the%20Estate%20of%20Jeffrey%20E.%20Epstein,%20Deceased,%20No.%20ST-21-RV-00005%20(V.I.%20Super.%20Ct.%202021)/2022.03.17-1%20Exhibit%201.pdf">Case No: ST-20-CV-14 Government Exhibit 1</a>” (see page 19). These PDFs, previously released by the DoJ, do contain incorrect and ineffective redactions, with black boxes that simply obscure text, making “copy &amp; paste” easy to recover the text that's otherwise hidden. Clearly, DoJ processes and systems in the past have inadequately redacted information!</p>
<h2 id="the-files-we-examined">The files we examined</h2>
<p>The tranche released by DoJ on Friday, December 19 is available as seven “data sets”, most easily downloaded as seven ZIP archives totaling just under 2.97 GB. Each ZIP file contains a similar folder structure, with DataSet 6 being the odd one out with an extra top-level folder. Once unzipped, the total size is 2.99 GB. The tranche contains 4,085 PDF files, a single AVI (movie) file (located in the folder VOL00002\NATIVES\0001), and 2 data files (.DAT and .OPT) for each ZIP archive. The “.OPT” files appear to be CSV (<a href="https://en.wikipedia.org/wiki/Comma-separated_values" target="_blank" rel="noopener">Comma-Separated Values</a>) but lack a heading row, while the “.DAT” files contain information about the <a href="https://en.wikipedia.org/wiki/Bates_numbering" target="_blank" rel="noopener">Bates numbering</a>. The analysis we provide here is limited to the PDF files.</p>
<p>The PDF files are named and ordered sequentially within the folder structure, starting with “EFTA00000001.pdf” in VOL00001 and ending with “EFTA00009664.pdf” in VOL00007, indicating that <span><strong>at least 5,879 PDF files remain unreleased</strong></span>.</p>
<p>A random sampling of the PDFs for visual review suggests that they are a mix of single and multi-page full-page photos and scanned content. OCR (Optical Character Recognition) was used to provide some searchable and extractable text in at least some files. “Black box” style redactions (without text reasons) are apparent. When done correctly, this is the appropriate way to redact, far more robust than <a href="https://www.bitdefender.com/en-us/blog/hotforsecurity/stop-pixelating-new-tool-reveals-the-secrets-of-redacted-documents" target="_blank" rel="noopener">pixelating text</a>. The PDFs we sampled did not include any obviously “born digital” documents. Various news sites are reporting <a href="https://www.cbsnews.com/news/epstein-files-redaction-over-500-pages-entirely-blacked-out/" target="_blank" rel="noopener">very heavily redacted documents</a> within this tranche.</p>
<h2 id="file-validity">File validity</h2>
<p>A precursor to most forensic examinations is to establish whether the PDF files are technically valid (that is, conform to the rules of the PDF format), since analyzing malformed files can easily lead to incorrect results or wrong conclusions. Combining tools that use different methods provides the broadest possible information while ensuring that tooling limitations are fully understood. However, if the basic file structure or cross-reference information is incorrect, various software might then draw different conclusions and/or construct different Document Object Models (DOMs).</p>
<p>In addition to basic file structure, incremental updates (if any), and cross-reference information, PDF validity assessments include the objects that comprise the PDF’sDOM as well as the file structure, incremental updates, and cross-reference information. To assess relationships between objects in the PDF DOM, some forensic analysis tools leverage our <a href="https://github.com/pdf-association/arlington-pdf-model" target="_blank" rel="noopener">Arlington PDF Data Model</a>, while others use their own internal methods.</p>
<p>Our analysis of file validity, using a multitude of PDF forensic tools, identified only one minor defect (invalidity); 109 PDFs had a positive FontDescriptor <strong>Descent</strong> value rather than a negative one. This is a relatively common (but minor) error, typically associated with font substitution and font matching, that does not affect the validity of the files overall. One specific forensic tool reported a PDF version issue with some files, related to the document catalog <strong>Version</strong> entry, which prevented the tool from further verifying those specific PDFs.</p>
<h2 id="pdf-versions">PDF versions</h2>
<p>I’ve previously written about the <a href="https://pdfa.org/pdf-versions/">unreliability of PDF version numbers</a>. Still, for forensic purposes, they may provide insight into the DoJ’s software, and whether improved software could have performed better.</p>
<p>I used two different but commonly used PDF command-line <code>pdfinfo</code> utilities on different platforms (Windows and Ubuntu Linux) to summarize information about these PDF files. When run against the full tranche of PDFs, I got two very different sets of answers! Immediately, my <a href="https://en.wiktionary.org/wiki/Spidey_sense#English" target="_blank" rel="noopener">spidey senses</a> started to tingle, and I was once again reminded of a key lesson in digital document forensics – you should <em><span>never</span></em> trust a single tool!</p>
<table>
<tbody>
<tr>
<td><strong>Reported PDF Version</strong></td>
<td><strong>Count Tool A</strong></td>
<td><strong>Count Tool B</strong></td>
</tr>
<tr>
<td>1.3</td>
<td>209</td>
<td>3,817</td>
</tr>
<tr>
<td>1.4</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1.5</td>
<td>3,875</td>
<td>267</td>
</tr>
<tr>
<td><strong>TOTAL</strong> <em>(should be 4,085)</em></td>
<td>4,085</td>
<td>4,085</td>
</tr>
</tbody>
</table>

<p>The PDF version in the file header, “<code>%PDF-<em>x.y</em></code>”, is nominally the first line in every PDF file (based on the not-unreasonable assumption that the PDF files have no “junk bytes” before this PDF file identifier). Using the Linux command line, you can run in Linux “<code>head -n 1 <em>file.pdf</em></code>” to extract the first header line from each PDF and compare it with the reported results from each tool. Or run in Linux “<code>grep -P --text --byte-offset "%PDF-\d\.\d" *.pdf</code>” to confirm that there are no junk bytes prior to the PDF header line.</p>
<p>The reason for the difference reported in the table above is that Tool B is not accounting for the <strong>Version</strong> entry in the document catalog of PDFs with incremental updates. We’ll next investigate whether this is due to malformed files or a programming error. When properly accounting for incremental updates, however, Tool A is correct.</p>
<p>Using the same <code>pdfinfo</code> output (and again comparing results from both tools), we can also quickly establish the following facts:</p>
<ul>
<li>No PDF is tagged</li>
<li>No PDF is encrypted</li>
<li>No PDF is “optimized” (technically, Linearized PDF)</li>
<li>No PDF has any annotations</li>
<li>No PDF has any outlines (bookmarks)</li>
<li>No PDF contains any embedded files</li>
<li>None of the PDFs are forms</li>
<li>None of the PDFs contains JavaScript</li>
</ul>
<p>Page counts range from 1 (in 3,818 PDFs) to 119 pages (in two PDFs), totaling 9,659 pages across all 4,085 PDFs.</p>
<h2 id="incremental-updates">Incremental updates</h2>
<p>PDF’s incremental updates feature allows multiple revisions of a document to be stored in a PDF file. As the name implies, each set of deltas is appended to the original document, forming a chain of edits. When read by conforming PDF software, a PDF is <em><span>always</span></em> processed from the end of the file, effectively applying the deltas to the original document and to any previous incremental updates. Both the original document and each incremental update can be recognized by their respective “<code>xref</code>” and “<code>%%EOF</code>” markers (assuming that the PDF files are structured correctly).</p>
<p>For this investigation, we started by examining the very first PDF in the tranche: VOL00001\IMAGES\0001\EFTA00000001.pdf. This PDF had different PDF versions reported by different versions of <code>pdfinfo</code>. A simple trick to check if a PDF contains incremental updates is to search for these special markers while treating the PDF as a text file (<em>which it isn’t!</em>):</p>
<p><strong><code>$ grep -P --text -–byte-offset "(xref)|(%%EOF)" EFTA00000001.pdf</code></strong><br>
<code>371340:xref<br>
371758:startxref<br>
371775:%%EOF<br>
372977:startxref<br>
372994:%%EOF<br>
373961:startxref<br>
373978:%%EOF</code></p>
<p>These results (sorted by byte offset) indicate that EFTA00000001.pdf contains <em><span>two incremental updates after the original file</span></em>. The lack of an “<code>xref</code>” marker before the last two “<code>startxref</code>” markers indicate that neither incremental updates uses conventional cross-reference data, but may use cross-reference streams (if any objects are changed).</p>
<h2 id="bates-numbering">Bates numbering</h2>
<p>As referenced above, Bates numbering is the process by which every page is assigned a unique identifier. For this tranche of Epstein PDF files, Bates numbers were added to each page via a separate incremental update, as shown below in <a href="https://pdfa.org/resource/vscode-extension-pdf-cos-syntax-support/">Visual Studio Code with my pdf-cos-syntax extension</a>. Note that DoJ’s PDFs are primarily text-based internally, making forensic analysis a lot easier - and the files a lot bigger.</p>
<p><img decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/2984-3037.png" alt="Screenshot of VS Code discussed in the text." width="766" height="1284" srcset="https://pdfa.org/wp-content/uploads/2025/12/2984-3037.png 766w, https://pdfa.org/wp-content/uploads/2025/12/2984-3037-179x300.png 179w, https://pdfa.org/wp-content/uploads/2025/12/2984-3037-611x1024.png 611w, https://pdfa.org/wp-content/uploads/2025/12/2984-3037-600x1006.png 600w" sizes="(max-width: 766px) 100vw, 766px"></p>
<p>Observations:</p>
<ul>
<li>Line 2984 is the end-of-file marker for the file version, and line 2985 starts a new incremental update section.</li>
<li>Lines 2985-2987 define object 26, the unembedded Helvetica font resource used by the Bates number.</li>
<li>Lines 2997-3020 are the modified page object (object 3), replacing the page object in previous revisions of the file.</li>
<li>Line 2999 is the page Contents array, comprising five separate content streams, with the 3rd stream (object 29) being the Bates numbering added in this incremental update. Object 30 is an empty content stream that could have been removed by an optimization process.</li>
<li>Line 3034 sets the Helvetica font to 12 point.</li>
<li>Line 3037 uses a hexadecimal string to paint the Bates number onto the page.</li>
</ul>
<p>The idiom for this final incremental update, which adds the Bates number to every page, appears in all the PDF files we selected at random for investigation. This specific incremental update always uses a cross-reference stream (<code>/Type /XRef</code>) and relies on the previous incremental update, in which the document catalog <strong>Version</strong> entry is set to PDF 1.5.</p>
<h2 id="the-first-incremental-update">The first incremental update</h2>
<p>The VSCode pdf-cos-syntax extension also indicates (correctly!) that the original PDF is missing the required (when the PDF contains binary data, which most do) comment as the second line of the file that indicates to software that the PDF file needs to be treated as binary data (ISO 32000-2:2020, §7.5.2). Although the missing comment does not make the PDF invalid per se, without such a marker close to the top of each PDF, software may think the PDF is a text file, and thus potentially corrupt the PDF by changing line endings, which would break the byte offsets in the cross-reference data. In this PDF, the first incremental update adds this marker comment after a lot of binary data, which is pointless.</p>
<p>As mentioned above, the first incremental update changed the document catalog <strong>Version</strong> entry to PDF 1.5, as we see in this next screenshot:</p>
<p><img decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/2924-3000.png" alt="Screenshot of VS Code discussed in the text." width="766" height="1284" srcset="https://pdfa.org/wp-content/uploads/2025/12/2924-3000.png 766w, https://pdfa.org/wp-content/uploads/2025/12/2924-3000-179x300.png 179w, https://pdfa.org/wp-content/uploads/2025/12/2924-3000-611x1024.png 611w, https://pdfa.org/wp-content/uploads/2025/12/2924-3000-600x1006.png 600w" sizes="(max-width: 766px) 100vw, 766px"></p>
<p><span>Observations:</span></p>
<ul>
<li><span>Lines 2953-2984 are the incremental update section.</span></li>
<li><span>Line 2954 is a PDF comment. PDF comments always start with a PERCENT SIGN (<code>%</code>) and may occur in many places in PDF files. Effective sanitization and redaction workflows typically remove all comments from PDFs because they may inadvertently disclose information, but this exact comment appears in 3,608 other PDF files. The origin or meaning of this comment was not further investigated.</span></li>
<li><span>Line 2964 upgrades the PDF version to 1.5. At first glance, this may appear to be perfectly valid PDF, but it is technically incorrect because the file header is <code>%PDF-1.3</code> yet the <strong>Version</strong> key was only added in PDF 1.4 - this is what the strict file validation tool mentioned above had noticed. As object 24 is a compressed object stream (lines 2966-2973) and object 25 is a compressed cross-reference stream (lines 2974-2981), the indicated version should be PDF 1.5. As a practical matter, however, this level of technical detail does not impact operation or behavior of PDFs.</span></li>
<li><span>Line 2984 is the end-of-section “<code>%%EOF</code>” marker for this incremental update section.</span></li>
</ul>
<p><span>As this section of the PDF uses compressed object streams, specialized PDF forensic tools must be used… simple search methodologies, such as those mentioned above, may not identify everything!</span></p>
<p><span>We know that there are 7 objects (because we find /<code>N 7</code>) inside the object stream:</span></p>
<p><img loading="lazy" decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/pdf-debugger.png" alt="Screenshot of debugger displaying content discussed in the text." width="676" height="443" srcset="https://pdfa.org/wp-content/uploads/2025/12/pdf-debugger.png 676w, https://pdfa.org/wp-content/uploads/2025/12/pdf-debugger-300x197.png 300w, https://pdfa.org/wp-content/uploads/2025/12/pdf-debugger-600x393.png 600w" sizes="auto, (max-width: 676px) 100vw, 676px"></p>
<p><span>As per PDF’s specification, ISO 32000-2:2020, §7.5.7, the first line of integers is interpreted as N pairs, where the first integer is the object number and the second integer is the byte offset relative to the first object in the object stream.</span></p>
<table>
<tbody>
<tr>
<td><strong>N</strong></td>
<td><strong>1st integer (object number)</strong></td>
<td><strong>2nd integer (start offset)</strong></td>
<td><strong>Explanation</strong></td>
<td><strong>Content</strong></td>
</tr>
<tr>
<td>1</td>
<td>19</td>
<td>0</td>
<td>Type1 Font object for OPBaseFont0 (Courier)</td>
<td><span>&lt;&lt;/BaseFont/Courier/Encoding&lt;&lt;/BaseEncoding/WinAnsiEncoding/Type/Encoding&gt;&gt;/Name/OPBaseFont0/Subtype/Type1/Type/Font&gt;&gt;</span></td>
</tr>
<tr>
<td>2</td>
<td>20</td>
<td>118</td>
<td>Type1 Font object for OPBaseFont1 (Helvetica)</td>
<td><span>&lt;&lt;/BaseFont/Helvetica/Encoding&lt;&lt;/BaseEncoding/WinAnsiEncoding/Type/Encoding&gt;&gt;/Name/OPBaseFont1/Subtype/Type1/Type/Font&gt;&gt;</span></td>
</tr>
<tr>
<td>3</td>
<td>17</td>
<td>238</td>
<td>Document information (Info) dictionary</td>
<td><span>&lt;&lt;/CreationDate(D:20251218143205)/Creator(OmniPage CSDK 21.1)/ModDate(D:20251218143205)/Producer(Processing-CLI)&gt;&gt;</span></td>
</tr>
<tr>
<td>4</td>
<td>18</td>
<td>352</td>
<td>ProcSet resources array</td>
<td><span>[/PDF/Text/ImageB/ImageC/ImageI]</span></td>
</tr>
<tr>
<td>5</td>
<td>22</td>
<td>384</td>
<td>Resources dictionary for the page</td>
<td><span>&lt;&lt;/Font&lt;&lt;/OPBaseFont0 19 0 R/OPBaseFont1 20 0 R&gt;&gt;/ProcSet 18 0 R/XObject&lt;&lt;/Im0 8 0 R&gt;&gt;&gt;&gt;</span></td>
</tr>
<tr>
<td>6</td>
<td>23</td>
<td>472</td>
<td>Array of 2 indirect references (to content streams)</td>
<td><span>[21 0 R 4 0 R]</span></td>
</tr>
<tr>
<td>7</td>
<td>3</td>
<td>486</td>
<td>Updated Page object</td>
<td><span>&lt;&lt;/Contents 23 0 R/MediaBox[0 0 864 576.75]/Parent 2 0 R/Resources 22 0 R/Thumb 11 0 R/Type/Page&gt;&gt;</span></td>
</tr>
</tbody>
</table>

<p>What is very interesting here – from a PDF forensics perspective – is the fact of a <strong><em><span>hidden document information dictionary</span></em></strong> that is not referenced from the last (final) incremental update trailer (i.e., there is no <strong>Info</strong> entry in object 31, lines 3050-3063 below). As such, this orphaned dictionary is invisible to PDF software! This oddity occurs in all other PDFs we’d randomly selected for investigation.</p>
<p><img loading="lazy" decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/2985-3067.png" alt="Screenshot of VS Code discussed in the text." width="777" height="1144" srcset="https://pdfa.org/wp-content/uploads/2025/12/2985-3067.png 777w, https://pdfa.org/wp-content/uploads/2025/12/2985-3067-204x300.png 204w, https://pdfa.org/wp-content/uploads/2025/12/2985-3067-695x1024.png 695w, https://pdfa.org/wp-content/uploads/2025/12/2985-3067-768x1131.png 768w, https://pdfa.org/wp-content/uploads/2025/12/2985-3067-600x883.png 600w" sizes="auto, (max-width: 777px) 100vw, 777px"></p>
<p><span>Formatted nicely as an uncompressed object, this hidden document information dictionary inside the compressed object stream contains the following information (the CreationDate and ModDate appear to change in other randomly examined PDFs):</span></p>
<pre>     17 0 obj
     &lt;&lt;
          /CreationDate (D:20251218143205)
          /ModDate      (D:20251218143205)
          /Creator      (OmniPage CSDK 21.1)
          /Producer     (Processing-CLI)
     &gt;&gt;
     endobj</pre>
<p>This metadata clearly indicates the software DoJ used to manipulate these PDF files. Although not relevant to the content, this forensic discovery clearly shows that extra care is required when sanitizing PDFs.</p>
<h2 id="different-incremental-updates">Different incremental updates</h2>
<p>Another randomly selected PDF, VOL00003\IMAGES\0001\EFTA00003939.pdf contains 3 full-page images, and just a single incremental update that applies the Bates numbering. However, in this case the file header is <code>%PDF-1.5</code> yet both the original PDF and incremental update use conventional cross-reference tables! This isn’t problematic, but is certainly unexpected and inefficient since PDF 1.5 introduced compressed cross-reference streams.</p>
<p>By comparing the objects in the incremental cross-reference table to the original cross-reference table we can see that objects 66 to 69 – the 3 Page objects for the 3 page document – were redefined. This is just what is expected in order to add the Bates number to each page’s <strong>Contents</strong> stream as in the previous example.</p>

<p>Our initial examination using pdfinfo utilities did not identify any metadata in any of the PDFs in the tranche, either in the document information dictionary (PDF file trailer Info entry) or as an XMP metadata stream (<strong>Metadata</strong> entry).</p>
<p>However, since we know that (a) the tranche includes PDFs with incremental updates, and (b) that an orphaned document information dictionary exists, all revisions of a document should be thoroughly examined. Incremental updates may have marked other document information dictionaries or XMP metadata streams as free but not deleted the actual data.</p>
<p>XMP metadata is always encoded in PDF as a stream object, and since stream objects cannot be in compressed object streams, using forensic tools to search for keys “<code>/XML</code>” or “<code>/Metadata</code>” should always locate them. All modern office suites and PDF creation applications will generate XMP metadata when exporting to PDF. As XMP is usually uncompressed, searching for XML fragments may also be helpful (see below for an example XMP object fragment).</p>
<pre>     3 0 obj
     &lt;&lt;/Length 36996/Subtype/XML/Type/Metadata&gt;&gt;
     stream
     &lt;?xpacket begin="ï»¿" id="W5M0MpCe … zNTczkc9d"?&gt;
     &lt;x:xmpmeta xmlns:x="adobe:ns:meta/" x:xmptk=" … "&gt;
         &lt;rdf:RDF 
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"&gt;
              &lt;rdf:Description rdf:about=""
                   xmlns:dc="http://purl.org/dc/elements/1.1/"
                   xmlns:xmp="http://ns.adobe.com/xap/1.0/"
     ...</pre>
<p>Not unsurprisingly for properly-redacted files, we did not find any XMP metadata streams or XML in any PDF. As a consequence, none of the PDFs can declare conformance to either PDF/A (ISO 19005 for long-term archiving) or PDF/UA (ISO 14289 for accessibility). Of course, as untagged PDFs, the files cannot conform to accessibility specifications such as PDF/UA or WCAG in any event. Additionally, none of the PDFs appear to include device-independent color spaces.</p>
<p>The presence of an <strong>Info</strong> entry in the trailer dictionary or (in PDFs with cross-reference streams) in the cross-reference stream dictionary indicates the presence of document information dictionaries. “<code>/Info</code>” does indeed occur in many of the PDFs, including multiple times in some PDFs, indicating potential changes via incremental updates. However, as discovered above, in some cases the final incremental update does not include an <strong>Info</strong> entry, thus “orphaning” any existing document information dictionaries.</p>
<p>ISO 32000-2:2020, Table 349 lists the defined entries in PDF’s document information dictionary (<strong>Title</strong>, <strong>Author</strong>, <strong>Subject</strong>, etc). Any vendor may add additional entries (such as <a href="https://developer.apple.com/documentation/coregraphics/kcgpdfcontextkeywords" target="_blank" rel="noopener">Apple does with its <span>/AAPL:Keywords</span> entry</a>), so redaction and sanitization software should be aware of extra entries.</p>
<p>From our random sampling, we identified one PDF with a non-trivial document information dictionary still present: VOL00002\IMAGES\0001\EFTA00003212.pdf. This is shown below in <a href="https://pdfa.org/resource/vscode-extension-pdf-cos-syntax-support/">Visual Studio Code with my pdf-cos-syntax extension</a>:</p>
<p><img loading="lazy" decoding="async" src="https://pdfa.org/wp-content/uploads/2025/12/1-69.png" alt="Screenshot of VS Code discussed in the text." width="766" height="1284" srcset="https://pdfa.org/wp-content/uploads/2025/12/1-69.png 766w, https://pdfa.org/wp-content/uploads/2025/12/1-69-179x300.png 179w, https://pdfa.org/wp-content/uploads/2025/12/1-69-611x1024.png 611w, https://pdfa.org/wp-content/uploads/2025/12/1-69-600x1006.png 600w" sizes="auto, (max-width: 766px) 100vw, 766px"></p>
<p><span>Of additional interest in this specific PDF is that the comment at line 60 has survived DoJ’s sanitization and redaction workflow! Other PDF comments may therefore also be present in other files.</span></p>
<p><span>EFTA00003212.pdf appears to be a redacted image or an error from the DoJ workflow, as it is a single page with the text “No Images Produced”.</span></p>
<p><span>Simple searching of the standardized PDF document information dictionary entries gives the following (note that the technique used will not locate information in compressed object streams, as mentioned above):</span></p>
<table>
<tbody>
<tr>
<td><strong>Key name</strong></td>
<td><strong>Number of PDFs (max. = 4,085)</strong></td>
<td><strong>Comment</strong></td>
</tr>
<tr>
<td><strong>Info</strong></td>
<td>3,823</td>
<td>Some PDFs have empty <strong>Info</strong> dictionaries with no entries</td>
</tr>
<tr>
<td><strong>Title</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Author</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Subject</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Keywords</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Creator</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>Producer</strong></td>
<td>215</td>
<td>Always “pypdf” (denotes <a href="https://pypi.org/project/pypdf/" target="_blank" rel="noopener">https://pypi.org/project/pypdf/</a>)</td>
</tr>
<tr>
<td><strong>CreationDate</strong></td>
<td>3,609</td>
<td>Same PDFs that have <strong>ModDate</strong> with an identical value</td>
</tr>
<tr>
<td><strong>ModDate</strong></td>
<td>3,609</td>
<td>Same PDFs that have <strong>CreationDate</strong> with an identical value</td>
</tr>
<tr>
<td><strong>Trapped</strong></td>
<td>1</td>
<td>Only EFTA00003212.pdf</td>
</tr>
<tr>
<td><strong>APPL:Keywords</strong></td>
<td>0</td>
<td></td>
</tr>
</tbody>
</table>

<h3 id="date-analysis">Date analysis</h3>
<p>Detailed date analysis is a common task in the forensic analysis of potentially fraudulent or modified documents. However, in the case of redacted or sanitized documents, where the document is known to have been modified, this can be less useful.</p>
<p>The creation and modification dates for the 3,609 PDFs range from December 18, 2025, 14:32:05 (2:32 pm) to December 19, 2025, 23:26:13 (almost midnight). For all files, the creation and modification dates are always the same. This may also imply that the DoJ batch processing to prepare this tranche of PDFs took at least 36 hours!</p>
<p>What’s also interesting is that the <strong>CreationDate</strong> and <strong>ModDate</strong> fields in the hidden document information dictionary (inside the object stream of the first increment update – see above) appear to always be an exact match to both the <strong>CreationDate</strong> and <strong>ModDate</strong> of the original document. This implies that all dates across all incremental updates were updated in a single processing pass that applied the Bates numbering.</p>
<h2 id="photographs">Photographs</h2>
<p>There are no JPEG images (<strong>DCTDecode </strong>filter) in any PDF in the tranche, including the full-page photographs. Randomly viewing the photographic images at high magnification (zoom) in PDF viewers clearly shows JPEG “jaggy” <a href="https://en.wikipedia.org/wiki/Compression_artifact" target="_blank" rel="noopener">compression artifacts</a>. All photographic images appear to have been downscaled to 96 DPI (769 x 1152 or 1152 x 769 pixels), making text on random objects in the photos much harder to discern (see the <a href="#ocr">OCR discussion below</a>).</p>
<p>DoJ explicitly avoids JPEG images in the PDFs probably because they appreciate that JPEGs often contain identifiable information, such as EXIF, IPTC, or XMP metadata, as well as <a href="https://exiftool.org/#JPEG" target="_blank" rel="noopener">COM (comment) tags</a> in the JPEG bitstream. This information may disclose the camera model and serial number, GPS location, camera operator details, date/time of the photo, etc., and is more difficult to redact while retaining the JPEG data. The DoJ processing pipeline has therefore explicitly converted all lossy JPEG images to low DPI, FLATE-encoded bitmaps in the PDFs using an indexed device-dependent color space with a palette of 256 unique colors (which reduces the color fidelity compared to the original high-quality digital color photograph).</p>
<h2 id="scanned-documents-or-are-they">Scanned documents – or are they?</h2>
<p>Randomly inspecting the tranche discovers many documents that appear to have been created by a scanning process. On closer inspection, there are documents that have tell-tale artifacts from a physical scanning process, such as visible physical paper edges, punched holes, staple marks, spiral binding, stamps, paper scuff marks, color blotches and inconsistencies, handwritten notes or marginalia, varying paper skew, and platen marks from the physical paper scanning processes. For example, VOL00007\IMAGES\0001\EFTA00009440.pdf shows many of these aspects</p>
<p>There are also other documents that appear to <span><em>simulate</em></span> a scanned document but completely lack the “real-world noise” expected with physical paper-based workflows. The much crisper images appear almost perfect without random artifacts or background noise, and with the exact same amount of image skew across multiple pages. Thanks to the borders around each page of text, page skew can easily be measured, such as with VOL00007\IMAGES\0001\EFTA00009229.pdf. It is highly likely these PDFs were created by rendering original content (from a digital document) to an image (e.g., via print to image or save to image functionality) and then applying image processing such as skew, downscaling, and color reduction.</p>
<p>The use of the timeless monospaced (also known as fixed-width) “Courier” typeface means that the number of characters redacted can be easily determined by vertical alignment with text lines above and below each redaction. In some instances, this may reduce the possible number of options that represent the redacted content, allowing it to be more easily guessed. Although redaction of variable-width typefaces is far more complex, Bland, M., Iyer, A., and Levchenko, K. 2022 paper “<a href="http://arxiv.org/abs/2206.02285" target="_blank" rel="noopener">Story Beyond the Eye: Glyph Positions Break PDF Text Redaction</a>” showed that this is still possible with sufficient computing power and determination.</p>
<h3 id="optical-character-recognition-ocr"><a id="ocr"></a>Optical Character Recognition (OCR)</h3>
<p><a href="https://en.wikipedia.org/wiki/Optical_character_recognition" target="_blank" rel="noopener">OCR</a> is complex image processing that attempts to identify text in bitmap images. In PDF files, OCR-identified text is commonly placed on top of the image using the invisible text render mode. This enables users to then extract the text from the image.</p>
<p>Returning to the very first PDF file in the tranche, VOL00001\IMAGES\0001\EFTA00000001.pdf - this is a full-page photo of a hand-written sign where part of the hand-written information is explicitly redacted. The PDF contains largely inaccurate OCR-ed text, indicating that natural language processing (NLP), machine learning (ML), or even language aware dictionary-based algorithms were not used. This means that there will be more errors in the extracted text than is necessary.</p>
<p>With cloud platforms readily accessible and supporting advanced OCR at low cost, anyone is capable of re-processing the entire tranche of PDFs and comparing the OCR results to those provided by DoJ. Even though the page images are low-resolution (96 DPI), rerunning OCR may bring to light additional or corrected information hidden by the original OCR that failed to recognize everything correctly.</p>
<p>The “black box” redactions we investigated were all correctly applied directly into the image pixel data. They are not separate PDF rectangle objects simply floating above sensitive information that was still present in the image and easily discoverable. Yes, sometimes it is that easy…!</p>
<h2 id="conclusion">Conclusion</h2>
<p>We did not set out to comprehensively analyze every corner of every PDF file in the Epstein PDFs, but to present a basic walk-through of some of the challenges and tricks used to conduct a PDF forensic assessment. Our results above were from a small random sample of documents - there may well be outlier PDFs in the data sets that we did not encounter.</p>
<p>The DoJ has clearly created internal processes, systems, and workflows that can sanitize and redact information prior to publishing as PDF. This includes converting JPEG images to low-resolution pixel-only bitmaps, largely removing metadata, and rendering page images to bitmaps. OCR appears to have been widely applied, but is of variable quality.</p>
<p>Their PDF technology could be improved to vastly reduce file size by removing unnecessary objects (e.g., empty content streams, ProcSets, empty thumbnail references, etc.), simplifying and reducing content streams, applying all incremental updates (i.e., removing all incremental update sections), and always using compressed object streams and compressed cross-reference streams. Information leakage may also be occurring via PDF comments or orphaned objects inside compressed object streams, as I discovered above.</p>
<p>PDF forensics is a highly complex field, where variations in files and tool assumptions can easily yield false results. The PDF Association hosts a PDF Forensic Liaison Working Group to develop industry guidance on forensic examination of PDF files and to educate document examiners and other specialists about many of these aspects.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation (147 pts)]]></title>
            <link>https://arxiv.org/abs/2602.00294</link>
            <guid>46886265</guid>
            <pubDate>Wed, 04 Feb 2026 14:33:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2602.00294">https://arxiv.org/abs/2602.00294</a>, See on <a href="https://news.ycombinator.com/item?id=46886265">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2602.00294">View PDF</a>
    <a href="https://arxiv.org/html/2602.00294v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>The most widely used artificial intelligence (AI) models today are Transformers employing self-attention. In its standard form, self-attention incurs costs that increase with context length, driving demand for storage, compute, and energy that is now outstripping society's ability to provide them. To help address this issue, we show that self-attention is efficiently computable to arbitrary precision with constant cost per token, achieving orders-of-magnitude reductions in memory use and computation. We derive our formulation by decomposing the conventional formulation's Taylor expansion into expressions over symmetric chains of tensor products. We exploit their symmetry to obtain feed-forward transformations that efficiently map queries and keys to coordinates in a minimal polynomial-kernel feature basis. Notably, cost is fixed inversely in proportion to head size, enabling application over a greater number of heads per token than otherwise feasible. We implement our formulation and empirically validate its correctness. Our work enables unbounded token generation at modest fixed cost, substantially reducing the infrastructure and energy demands of large-scale Transformer models. The mathematical techniques we introduce are of independent interest.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Leo Kozachkov [<a href="https://arxiv.org/show-email/aad7e88e/2602.00294" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 30 Jan 2026 20:38:02 UTC (2,756 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FBI couldn't get into WaPo reporter's iPhone because Lockdown Mode enabled (542 pts)]]></title>
            <link>https://www.404media.co/fbi-couldnt-get-into-wapo-reporters-iphone-because-it-had-lockdown-mode-enabled/</link>
            <guid>46886237</guid>
            <pubDate>Wed, 04 Feb 2026 14:31:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/fbi-couldnt-get-into-wapo-reporters-iphone-because-it-had-lockdown-mode-enabled/">https://www.404media.co/fbi-couldnt-get-into-wapo-reporters-iphone-because-it-had-lockdown-mode-enabled/</a>, See on <a href="https://news.ycombinator.com/item?id=46886237">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<p>The FBI has been unable to access a Washington Post reporter’s seized iPhone because it was in Lockdown Mode, a sometimes overlooked feature that makes iPhones broadly more secure, according to recently filed court records.</p><p>The court record shows what devices and data the FBI was able to ultimately access, and which devices it could not, after <a href="https://www.theguardian.com/us-news/2026/jan/14/fbi-raid-washington-post-hannah-natanson?ref=404media.co"><u>raiding the home of the reporter</u></a>, Hannah Natanson, in January as part of an investigation into leaks of classified information. It also provides rare insight into the apparent effectiveness of Lockdown Mode, or at least how effective it might be before the FBI may try other techniques to access the device.</p><div><p>💡</p><p><b><strong>Do you know anything else about phone unlocking technology? I would love to hear from you. Using a non-work device, you can message me securely on Signal at joseph.404 or send me an email at joseph@404media.co.</strong></b></p></div>
</div><div>
  <div>
    <h2>This post is for paid members only</h2>
    <p>Become a paid member for unlimited ad-free access to articles, bonus podcast content, and more.</p>
    <p><a href="https://www.404media.co/membership/">Subscribe</a>
  </p></div>
  <div>
    <h2>Sign up for free access to this post</h2>
    <p>Free members get access to posts like this one along with an email round-up of our week's stories.</p>
    <p><a href="https://www.404media.co/signup/">Subscribe</a>
  </p></div>
  <p>Already have an account? <a href="https://www.404media.co/signin/" data-portal="signin">Sign in</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Guinea worm on track to be 2nd eradicated human disease; only 10 cases in 2025 (259 pts)]]></title>
            <link>https://arstechnica.com/health/2026/02/guinea-worm-on-track-to-be-2nd-eradicated-human-disease-only-10-cases-in-2025/</link>
            <guid>46886191</guid>
            <pubDate>Wed, 04 Feb 2026 14:27:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/health/2026/02/guinea-worm-on-track-to-be-2nd-eradicated-human-disease-only-10-cases-in-2025/">https://arstechnica.com/health/2026/02/guinea-worm-on-track-to-be-2nd-eradicated-human-disease-only-10-cases-in-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=46886191">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>A debilitating infection from the parasitic Guinea worm is inching closer to global eradication, with an all-time low of only 10 human cases reported worldwide in 2025, <a href="https://www.cartercenter.org/news/guinea-worm-announcement/">the Carter Center announced</a>.</p>
<p>If health workers can fully wipe out the worms, it will be only the second human disease to be eradicated, after smallpox.</p>
<p>Guinea worm (<em>Dracunculus medinensis</em>) is a parasitic nematode transmitted in water. More specifically, it’s found in waters that contain small crustacean copepods, which harbor the worm’s larvae. If a person consumes water contaminated with Guinea worm, the parasites burrow through the intestinal tract and migrate through the body. About a year later, a spaghetti noodle-length worm emerges from a painful blister, usually in the feet or legs. It can take up to eight weeks for the adult worm to fully emerge. To ease the searing pain, infected people may put their blistered limbs in water, allowing the parasite to release more larvae and continue the cycle.</p>
<p>In addition to being extremely painful, the disease (dracunculiasis) can lead to complications, such as secondary infections and sepsis, which in turn can lead to temporary or permanent disability.</p>
<p>When the Guinea worm eradication program began in 1986, there were an estimated 3.5 million cases across 21 countries in Africa and Asia. To date, only six countries have not been certified by the World Health Organization as Guinea worm-free. In 2024, there were just 15 cases, and, according to the provisional tally for 2025, the number is down to just 10. It’s considered provisional until each country’s disease reports are confirmed, which occurs in a program meeting usually held in April.</p>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Is a Space to Think (356 pts)]]></title>
            <link>https://www.anthropic.com/news/claude-is-a-space-to-think</link>
            <guid>46884883</guid>
            <pubDate>Wed, 04 Feb 2026 12:08:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/claude-is-a-space-to-think">https://www.anthropic.com/news/claude-is-a-space-to-think</a>, See on <a href="https://news.ycombinator.com/item?id=46884883">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div data-theme="ivory"><p>There are many good places for advertising. A conversation with Claude is not one of them.</p><p>Advertising drives competition, helps people discover new products, and allows services like email and social media to be offered for free. We’ve run our own <a href="https://www.youtube.com/watch?v=FDNkDBNR7AM">ad campaigns</a>, and our AI models have, in turn, helped many of our customers in the advertising industry.</p><p>But including ads in conversations with Claude would be incompatible with what we want Claude to be: a genuinely helpful assistant for work and for deep thinking.</p><p>We want Claude to act unambiguously in our users’ interests. So we’ve made a choice: Claude will remain ad-free. Our users won’t see “sponsored” links adjacent to their conversations with Claude; nor will Claude’s responses be influenced by advertisers or include third-party product placements our users did not ask for.</p><h2 id="the-nature-of-ai-conversations"><strong>The nature of AI conversations</strong></h2><p>When people use search engines or social media, they’ve come to expect a mixture of organic and sponsored content. Filtering signal from noise is part of the interaction.</p><p>Conversations with AI assistants are meaningfully different. The format is open-ended; users often share context and reveal more than they would in a search query. This openness is part of what makes conversations with AI valuable, but it’s also what makes them susceptible to influence in ways that other digital products are not.</p><p>Our <a href="https://www.anthropic.com/news/how-people-use-claude-for-support-advice-and-companionship">analysis of conversations</a> with Claude (conducted in a way that keeps all data <a href="https://www.anthropic.com/research/clio">private and anonymous</a>) shows that an appreciable portion involve topics that are sensitive or deeply personal—the kinds of conversations you might have with a trusted advisor. Many other uses involve complex software engineering tasks, deep work, or thinking through difficult problems. The appearance of ads in these contexts would feel incongruous—and, in many cases, inappropriate.</p><p>We still have much to learn about the impact of AI models on the people who use them. <a href="https://www.jmir.org/2025/1/e67114">Early</a> <a href="https://hai.stanford.edu/news/exploring-the-dangers-of-ai-in-mental-health-care">research</a> suggests both benefits—like people finding support they couldn’t access elsewhere—and risks, including the potential for models to reinforce harmful beliefs in vulnerable users. Introducing advertising incentives at this stage would add another level of complexity. <a href="https://www.anthropic.com/research/tracing-thoughts-language-model">Our understanding</a> of how models translate the goals we set them into specific behaviors is still developing; an ad-based system could therefore have unpredictable results.</p><h2 id="incentive-structures"><strong>Incentive structures</strong></h2><p>Being genuinely helpful is one of the core principles of <a href="https://www.anthropic.com/constitution">Claude’s Constitution</a>, the document that describes our vision for Claude’s character and guides how we train the model. An advertising-based business model would introduce incentives that could work against this principle.</p><p>Consider a concrete example. A user mentions they’re having trouble sleeping. An assistant without advertising incentives would explore the various potential causes—stress, environment, habits, and so on—based on what might be most insightful to the user. An ad-supported assistant has an additional consideration: whether the conversation presents an opportunity to make a transaction. These objectives may often align—but not always. And, unlike a list of search results, ads that influence a model’s responses may make it difficult to tell whether a given recommendation comes with a commercial motive or not. Users shouldn’t have to second-guess whether an AI is genuinely helping them or subtly steering the conversation towards something monetizable.</p><p>Even ads that don’t directly influence an AI model’s responses and instead appear separately within the chat window would compromise what we want Claude to be: a clear space to think and work. Such ads would also introduce an incentive to optimize for engagement—for the amount of time people spend using Claude and how often they return. These metrics aren’t necessarily aligned with being genuinely helpful. The most useful AI interaction might be a short one, or one that resolves the user’s request without prompting further conversation.</p><p>We recognize that not all advertising implementations are equivalent. More transparent or opt-in approaches—where users explicitly choose to see sponsored content—might avoid some of the concerns outlined above. But the history of ad-supported products suggests that advertising incentives, once introduced, tend to expand over time as they become integrated into revenue targets and product development, blurring boundaries that were once more clear-cut. We’ve chosen not to introduce these dynamics into Claude.</p><h2 id="our-approach"><strong>Our approach</strong></h2><p>Anthropic is focused on businesses, developers, and helping our users flourish. Our business model is straightforward: we generate revenue through enterprise contracts and paid subscriptions, and we reinvest that revenue into improving Claude for our users. This is a choice with tradeoffs, and we respect that other AI companies might reasonably reach different conclusions.</p><p>Expanding access to Claude is central to our public benefit mission, and we want to do it without selling our users’ attention or data to advertisers. To that end, we’ve <a href="https://www.anthropic.com/news/anthropic-teach-for-all">brought AI tools and training to educators</a> in over 60 countries, begun national AI education pilots with <a href="https://www.anthropic.com/news/anthropic-and-iceland-announce-one-of-the-world-s-first-national-ai-education-pilots">multiple</a> <a href="https://www.anthropic.com/news/rwandan-government-partnership-ai-education">governments</a>, and made Claude <a href="https://www.anthropic.com/news/claude-for-nonprofits">available to nonprofits</a> at a significant discount. We continue to invest in our smaller models so that our free offering remains at the frontier of intelligence, and we may consider lower-cost subscription tiers and regional pricing where there is clear demand for it. Should we need to revisit this approach, we’ll be transparent about our reasons for doing so.</p><h2 id="supporting-commerce"><strong>Supporting commerce</strong></h2><p>AI will increasingly interact with commerce, and we look forward to supporting this in ways that help our users. We’re particularly interested in the potential of agentic commerce, where Claude acts on a user’s behalf to handle a purchase or booking end to end. And we’ll continue to build features that enable our users to find, compare, or buy products, connect with businesses, and more—when they choose to do so.</p><p>We’re also exploring more ways to make Claude a focused space to be at your most productive. Users can already <a href="https://claude.com/blog/interactive-tools-in-claude">connect third-party tools</a> they use for work—like Figma, Asana, and Canva—and interact with them directly within Claude. We expect to introduce many more useful integrations and expand this toolkit over time.</p><p>All third-party interactions will be grounded in the same overarching design principle: they should be initiated by the <em>user </em>(where the AI is working for them) rather than an <em>advertiser</em> (where the AI is working, at least in part, for someone else). Today, whether someone asks Claude to research running shoes, compare mortgage rates, or recommend a restaurant for a special occasion, Claude’s only incentive is to give a helpful answer. We’d like to preserve that.</p><h2 id="a-trusted-tool-for-thought"><strong>A trusted tool for thought</strong></h2><p>We want our users to trust Claude to help them keep thinking—about their work, their challenges, and their ideas.</p><p>Our experience of using the internet has made it easy to assume that advertising on the products we use is inevitable. But open a notebook, pick up a well-crafted tool, or stand in front of a clean chalkboard, and there are no ads in sight.</p><p>We think Claude should work the same way.</p></div></article></div><div data-theme="ivory"><p><h2>Related content</h2></p><div><div><h3>Apple’s Xcode now supports the Claude Agent SDK</h3><p><a href="https://www.anthropic.com/news/apple-xcode-claude-agent-sdk" referrerpolicy="no-referrer-when-downgrade"><span>Read more</span><span><svg width="20" height="20" viewBox="0 0 21 21"><path d="M4.14585 9.87492L14.4584 9.87492L9.60419 5.04158L10.5 4.14575L16.8542 10.4999L10.5 16.8541L9.60419 15.9583L14.4584 11.1249L4.14585 11.1249L4.14585 9.87492Z" fill="currentColor"></path></svg></span></a></p></div><div><h3>Anthropic partners with Allen Institute and Howard Hughes Medical Institute to accelerate scientific discovery</h3><p><a href="https://www.anthropic.com/news/anthropic-partners-with-allen-institute-and-howard-hughes-medical-institute" referrerpolicy="no-referrer-when-downgrade"><span>Read more</span><span><svg width="20" height="20" viewBox="0 0 21 21"><path d="M4.14585 9.87492L14.4584 9.87492L9.60419 5.04158L10.5 4.14575L16.8542 10.4999L10.5 16.8541L9.60419 15.9583L14.4584 11.1249L4.14585 11.1249L4.14585 9.87492Z" fill="currentColor"></path></svg></span></a></p></div><div><h3>ServiceNow chooses Claude to power customer apps and increase internal productivity</h3><p><a href="https://www.anthropic.com/news/servicenow-anthropic-claude" referrerpolicy="no-referrer-when-downgrade"><span>Read more</span><span><svg width="20" height="20" viewBox="0 0 21 21"><path d="M4.14585 9.87492L14.4584 9.87492L9.60419 5.04158L10.5 4.14575L16.8542 10.4999L10.5 16.8541L9.60419 15.9583L14.4584 11.1249L4.14585 11.1249L4.14585 9.87492Z" fill="currentColor"></path></svg></span></a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Ghidra MCP Server – 110 tools for AI-assisted reverse engineering (271 pts)]]></title>
            <link>https://github.com/bethington/ghidra-mcp</link>
            <guid>46882389</guid>
            <pubDate>Wed, 04 Feb 2026 06:51:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bethington/ghidra-mcp">https://github.com/bethington/ghidra-mcp</a>, See on <a href="https://news.ycombinator.com/item?id=46882389">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Ghidra MCP Server</h2><a id="user-content-ghidra-mcp-server" aria-label="Permalink: Ghidra MCP Server" href="#ghidra-mcp-server"></a></p>
<p dir="auto"><a href="https://opensource.org/licenses/Apache-2.0" rel="nofollow"><img src="https://camo.githubusercontent.com/a549a7a30bacba7bfceebdc207a8e86c3f2c02995a2527640dca30048fd2b64e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d417061636865253230322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache%202.0-blue.svg"></a>
<a href="https://openjdk.java.net/projects/jdk/21/" rel="nofollow"><img src="https://camo.githubusercontent.com/b4a38f2fc33ed2f57cbcfd6988fe6791b914b802842fe66aa164e86cff6534cf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4a6176612d32312532304c54532d6f72616e67652e737667" alt="Java Version" data-canonical-src="https://img.shields.io/badge/Java-21%20LTS-orange.svg"></a>
<a href="https://ghidra-sre.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/f52e0f0fcd3839839366190b582ccf024b8c0246358764859575923205758940/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4768696472612d31322e302e322d677265656e2e737667" alt="Ghidra Version" data-canonical-src="https://img.shields.io/badge/Ghidra-12.0.2-green.svg"></a>
<a href="https://github.com/bethington/ghidra-mcp/blob/main/CHANGELOG.md"><img src="https://camo.githubusercontent.com/df860fb53ded212171a8bb5287d797865dae05df12f96c283ba44aa14f644a5a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f56657273696f6e2d322e302e302d627269676874677265656e2e737667" alt="Version" data-canonical-src="https://img.shields.io/badge/Version-2.0.0-brightgreen.svg"></a></p>
<blockquote>
<p dir="auto">If you find this useful, please ⭐ star the repo — it helps others discover it!</p>
</blockquote>
<p dir="auto">A production-ready Model Context Protocol (MCP) server that bridges Ghidra's powerful reverse engineering capabilities with modern AI tools and automation frameworks.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🌟 Features</h2><a id="user-content--features" aria-label="Permalink: 🌟 Features" href="#-features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Core MCP Integration</h3><a id="user-content-core-mcp-integration" aria-label="Permalink: Core MCP Integration" href="#core-mcp-integration"></a></p>
<ul dir="auto">
<li><strong>Full MCP Compatibility</strong> - Complete implementation of Model Context Protocol</li>
<li><strong>110 MCP Tools Available</strong> - Comprehensive API surface for binary analysis</li>
<li><strong>Production-Ready Reliability</strong> - Tested batch operations and atomic transactions</li>
<li><strong>Real-time Analysis</strong> - Live integration with Ghidra's analysis engine</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Binary Analysis Capabilities</h3><a id="user-content-binary-analysis-capabilities" aria-label="Permalink: Binary Analysis Capabilities" href="#binary-analysis-capabilities"></a></p>
<ul dir="auto">
<li><strong>Function Analysis</strong> - Decompilation, call graphs, cross-references</li>
<li><strong>Data Structure Discovery</strong> - Automatic struct/union/enum creation</li>
<li><strong>String Extraction</strong> - Comprehensive string analysis and categorization</li>
<li><strong>Import/Export Analysis</strong> - Symbol table and library dependency mapping</li>
<li><strong>Memory Mapping</strong> - Complete memory layout documentation</li>
<li><strong>Cross-Binary Documentation</strong> - Function hash matching across binary versions</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Development &amp; Automation</h3><a id="user-content-development--automation" aria-label="Permalink: Development &amp; Automation" href="#development--automation"></a></p>
<ul dir="auto">
<li><strong>Automated Development Cycle</strong> - Complete build-test-deploy-verify pipeline</li>
<li><strong>Ghidra Script Management</strong> - Create, run, and manage Ghidra scripts via MCP</li>
<li><strong>Multi-Program Support</strong> - Switch between and compare multiple open programs</li>
<li><strong>Batch Operations</strong> - Efficient bulk renaming, commenting, and typing</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Quick Start</h2><a id="user-content--quick-start" aria-label="Permalink: 🚀 Quick Start" href="#-quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Prerequisites</h3><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<ul dir="auto">
<li><strong>Java 21 LTS</strong> (OpenJDK recommended)</li>
<li><strong>Apache Maven 3.9+</strong></li>
<li><strong>Ghidra 12.0.2</strong> (or compatible version)</li>
<li><strong>Python 3.8+</strong> with pip</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Clone the repository:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/bethington/ghidra-mcp.git
cd ghidra-mcp"><pre>git clone https://github.com/bethington/ghidra-mcp.git
<span>cd</span> ghidra-mcp</pre></div>
</li>
<li>
<p dir="auto"><strong>Install Python dependencies:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install -r requirements.txt"><pre>pip install -r requirements.txt</pre></div>
</li>
<li>
<p dir="auto"><strong>Copy Ghidra libraries</strong> (see <a href="#library-dependencies">Library Dependencies</a> for full list):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Windows - run the provided batch script
copy-ghidra-libs.bat &quot;C:\path\to\ghidra_12.0.2_PUBLIC&quot;

# Linux/Mac - copy manually from your Ghidra installation
# See Library Dependencies section below for all 14 required JARs"><pre><span><span>#</span> Windows - run the provided batch script</span>
copy-ghidra-libs.bat <span><span>"</span>C:\path\to\ghidra_12.0.2_PUBLIC<span>"</span></span>

<span><span>#</span> Linux/Mac - copy manually from your Ghidra installation</span>
<span><span>#</span> See Library Dependencies section below for all 14 required JARs</span></pre></div>
</li>
<li>
<p dir="auto"><strong>Build the plugin:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="mvn clean package assembly:single -DskipTests"><pre>mvn clean package assembly:single -DskipTests</pre></div>
</li>
<li>
<p dir="auto"><strong>Deploy to Ghidra:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Windows (automated)
.\deploy-to-ghidra.ps1

# Or manually copy to Ghidra Extensions
Copy-Item target\GhidraMCP-2.0.0.zip &quot;C:\ghidra\Extensions\Ghidra\&quot;"><pre><span><span>#</span> Windows (automated)</span>
.<span>\deploy-to</span><span>-</span>ghidra.ps1

<span><span>#</span> Or manually copy to Ghidra Extensions</span>
<span>Copy-Item</span> target\GhidraMCP<span>-</span><span>2.0</span>.<span>0.</span>zip <span><span>"</span>C:\ghidra\Extensions\Ghidra\<span>"</span></span></pre></div>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic Usage</h3><a id="user-content-basic-usage" aria-label="Permalink: Basic Usage" href="#basic-usage"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Option 1: Stdio Transport (Recommended for AI tools)</h4><a id="user-content-option-1-stdio-transport-recommended-for-ai-tools" aria-label="Permalink: Option 1: Stdio Transport (Recommended for AI tools)" href="#option-1-stdio-transport-recommended-for-ai-tools"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="python bridge_mcp_ghidra.py"><pre>python bridge_mcp_ghidra.py</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Option 2: SSE Transport (Web/HTTP clients)</h4><a id="user-content-option-2-sse-transport-webhttp-clients" aria-label="Permalink: Option 2: SSE Transport (Web/HTTP clients)" href="#option-2-sse-transport-webhttp-clients"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="python bridge_mcp_ghidra.py --transport sse --mcp-host 127.0.0.1 --mcp-port 8081"><pre>python bridge_mcp_ghidra.py --transport sse --mcp-host 127.0.0.1 --mcp-port 8081</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">In Ghidra</h4><a id="user-content-in-ghidra" aria-label="Permalink: In Ghidra" href="#in-ghidra"></a></p>
<ol dir="auto">
<li>Start Ghidra and load a binary</li>
<li>Go to <strong>Tools &gt; GhidraMCP &gt; Start MCP Server</strong></li>
<li>The server runs on <code>http://127.0.0.1:8080/</code> by default</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">📊 Production Performance</h2><a id="user-content--production-performance" aria-label="Permalink: 📊 Production Performance" href="#-production-performance"></a></p>
<ul dir="auto">
<li><strong>MCP Tools</strong>: 110 tools fully implemented</li>
<li><strong>Speed</strong>: Sub-second response for most operations</li>
<li><strong>Efficiency</strong>: 93% reduction in API calls via batch operations</li>
<li><strong>Reliability</strong>: Atomic transactions with all-or-nothing semantics</li>
<li><strong>Deployment</strong>: Automated version-aware deployment script</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🛠️ API Reference</h2><a id="user-content-️-api-reference" aria-label="Permalink: 🛠️ API Reference" href="#️-api-reference"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Core Operations</h3><a id="user-content-core-operations" aria-label="Permalink: Core Operations" href="#core-operations"></a></p>
<ul dir="auto">
<li><code>check_connection</code> - Verify MCP connectivity</li>
<li><code>get_metadata</code> - Program metadata and info</li>
<li><code>get_version</code> - Server version information</li>
<li><code>get_entry_points</code> - Binary entry points discovery</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Function Analysis</h3><a id="user-content-function-analysis" aria-label="Permalink: Function Analysis" href="#function-analysis"></a></p>
<ul dir="auto">
<li><code>list_functions</code> - List all functions (paginated)</li>
<li><code>search_functions_by_name</code> - Search functions by name/pattern</li>
<li><code>search_functions_enhanced</code> - Advanced function search with filters</li>
<li><code>decompile_function</code> - Decompile function to C pseudocode</li>
<li><code>get_decompiled_code</code> - Get decompiled code by address</li>
<li><code>get_function_callers</code> - Get function callers</li>
<li><code>get_function_callees</code> - Get function callees</li>
<li><code>get_function_call_graph</code> - Function relationship graph</li>
<li><code>get_full_call_graph</code> - Complete call graph for program</li>
<li><code>analyze_function_complete</code> - Comprehensive function analysis</li>
<li><code>analyze_function_completeness</code> - Documentation completeness score</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Memory &amp; Data</h3><a id="user-content-memory--data" aria-label="Permalink: Memory &amp; Data" href="#memory--data"></a></p>
<ul dir="auto">
<li><code>list_segments</code> - Memory segments and layout</li>
<li><code>get_function_by_address</code> - Function at address</li>
<li><code>disassemble_function</code> - Disassembly listing</li>
<li><code>disassemble_bytes</code> - Raw byte disassembly</li>
<li><code>get_xrefs_to</code> - Cross-references to address</li>
<li><code>get_xrefs_from</code> - Cross-references from address</li>
<li><code>get_bulk_xrefs</code> - Bulk cross-reference lookup</li>
<li><code>analyze_data_region</code> - Analyze memory region structure</li>
<li><code>inspect_memory_content</code> - View raw memory content</li>
<li><code>detect_array_bounds</code> - Detect array boundaries</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cross-Binary Documentation (v1.9.4+)</h3><a id="user-content-cross-binary-documentation-v194" aria-label="Permalink: Cross-Binary Documentation (v1.9.4+)" href="#cross-binary-documentation-v194"></a></p>
<ul dir="auto">
<li><code>get_function_hash</code> - SHA-256 hash of normalized function opcodes</li>
<li><code>get_bulk_function_hashes</code> - Paginated bulk hashing with filter</li>
<li><code>get_function_documentation</code> - Export complete function documentation</li>
<li><code>apply_function_documentation</code> - Import documentation to target function</li>
<li><code>build_function_hash_index</code> - Build persistent JSON index</li>
<li><code>lookup_function_by_hash</code> - Find matching functions in index</li>
<li><code>propagate_documentation</code> - Apply docs to all matching instances</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Data Types &amp; Structures</h3><a id="user-content-data-types--structures" aria-label="Permalink: Data Types &amp; Structures" href="#data-types--structures"></a></p>
<ul dir="auto">
<li><code>list_data_types</code> - Available data types</li>
<li><code>search_data_types</code> - Search for data types</li>
<li><code>create_struct</code> - Create custom structure</li>
<li><code>add_struct_field</code> - Add field to structure</li>
<li><code>modify_struct_field</code> - Modify existing field</li>
<li><code>remove_struct_field</code> - Remove field from structure</li>
<li><code>create_enum</code> - Create enumeration</li>
<li><code>get_enum_values</code> - Get enumeration values</li>
<li><code>create_array_type</code> - Create array data type</li>
<li><code>apply_data_type</code> - Apply type to address</li>
<li><code>delete_data_type</code> - Delete a data type</li>
<li><code>consolidate_duplicate_types</code> - Merge duplicate types</li>
<li><code>get_valid_data_types</code> - Get list of valid Ghidra types</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Symbols &amp; Labels</h3><a id="user-content-symbols--labels" aria-label="Permalink: Symbols &amp; Labels" href="#symbols--labels"></a></p>
<ul dir="auto">
<li><code>list_imports</code> - Imported symbols and libraries</li>
<li><code>list_exports</code> - Exported symbols and functions</li>
<li><code>list_external_locations</code> - External location references</li>
<li><code>list_strings</code> - Extracted strings with analysis</li>
<li><code>list_namespaces</code> - Available namespaces</li>
<li><code>list_globals</code> - Global variables</li>
<li><code>create_label</code> - Create label at address</li>
<li><code>batch_create_labels</code> - Bulk label creation</li>
<li><code>delete_label</code> - Delete label at address</li>
<li><code>batch_delete_labels</code> - Bulk label deletion</li>
<li><code>rename_label</code> - Rename existing label</li>
<li><code>rename_or_label</code> - Rename or create label</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Renaming &amp; Documentation</h3><a id="user-content-renaming--documentation" aria-label="Permalink: Renaming &amp; Documentation" href="#renaming--documentation"></a></p>
<ul dir="auto">
<li><code>rename_function</code> - Rename function by name</li>
<li><code>rename_function_by_address</code> - Rename function by address</li>
<li><code>rename_data</code> - Rename data item</li>
<li><code>rename_variables</code> - Rename function variables</li>
<li><code>rename_global_variable</code> - Rename global variable</li>
<li><code>rename_external_location</code> - Rename external reference</li>
<li><code>batch_rename_function_components</code> - Bulk renaming</li>
<li><code>set_decompiler_comment</code> - Set decompiler comment</li>
<li><code>set_disassembly_comment</code> - Set disassembly comment</li>
<li><code>set_plate_comment</code> - Set function plate comment</li>
<li><code>get_plate_comment</code> - Get function plate comment</li>
<li><code>batch_set_comments</code> - Bulk comment setting</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Type System</h3><a id="user-content-type-system" aria-label="Permalink: Type System" href="#type-system"></a></p>
<ul dir="auto">
<li><code>set_function_prototype</code> - Set function signature</li>
<li><code>set_local_variable_type</code> - Set variable type</li>
<li><code>set_parameter_type</code> - Set parameter type</li>
<li><code>batch_set_variable_types</code> - Bulk type setting</li>
<li><code>set_variable_storage</code> - Control variable storage location</li>
<li><code>set_function_no_return</code> - Mark function as non-returning</li>
<li><code>list_calling_conventions</code> - Available calling conventions</li>
<li><code>get_function_variables</code> - Get all function variables</li>
<li><code>get_function_labels</code> - Get labels in function</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ghidra Script Management</h3><a id="user-content-ghidra-script-management" aria-label="Permalink: Ghidra Script Management" href="#ghidra-script-management"></a></p>
<ul dir="auto">
<li><code>list_scripts</code> - List available scripts</li>
<li><code>run_script</code> - Run a script</li>
<li><code>list_ghidra_scripts</code> - List custom Ghidra scripts</li>
<li><code>save_ghidra_script</code> - Save new script</li>
<li><code>get_ghidra_script</code> - Get script contents</li>
<li><code>run_ghidra_script</code> - Execute Ghidra script</li>
<li><code>update_ghidra_script</code> - Update existing script</li>
<li><code>delete_ghidra_script</code> - Delete script</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Multi-Program Support</h3><a id="user-content-multi-program-support" aria-label="Permalink: Multi-Program Support" href="#multi-program-support"></a></p>
<ul dir="auto">
<li><code>list_open_programs</code> - List all open programs</li>
<li><code>get_current_program_info</code> - Current program details</li>
<li><code>switch_program</code> - Switch active program</li>
<li><code>list_project_files</code> - List project files</li>
<li><code>open_program</code> - Open program from project</li>
<li><code>compare_programs_documentation</code> - Compare documentation between programs</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Analysis Tools</h3><a id="user-content-analysis-tools" aria-label="Permalink: Analysis Tools" href="#analysis-tools"></a></p>
<ul dir="auto">
<li><code>find_next_undefined_function</code> - Find undefined functions</li>
<li><code>find_undocumented_by_string</code> - Find functions by string reference</li>
<li><code>batch_string_anchor_report</code> - String anchor analysis</li>
<li><code>search_byte_patterns</code> - Search for byte patterns</li>
<li><code>get_assembly_context</code> - Get assembly context</li>
<li><code>analyze_struct_field_usage</code> - Analyze structure field access</li>
<li><code>get_field_access_context</code> - Get field access patterns</li>
<li><code>create_function</code> - Create function at address</li>
<li><code>get_function_jump_target_addresses</code> - Get jump targets</li>
</ul>
<p dir="auto">See <a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/README.md">docs/README.md</a> for complete documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🏗️ Architecture</h2><a id="user-content-️-architecture" aria-label="Permalink: 🏗️ Architecture" href="#️-architecture"></a></p>
<div data-snippet-clipboard-copy-content="┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   AI/Automation │◄──►│   MCP Bridge    │◄──►│  Ghidra Plugin  │
│     Tools       │    │ (bridge_mcp_    │    │ (GhidraMCP.jar) │
│  (Claude, etc.) │    │  ghidra.py)     │    │                 │
└─────────────────┘    └─────────────────┘    └─────────────────┘
        │                       │                       │
   MCP Protocol            HTTP REST              Ghidra API
   (stdio/SSE)          (localhost:8080)      (Program, Listing)"><pre><code>┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   AI/Automation │◄──►│   MCP Bridge    │◄──►│  Ghidra Plugin  │
│     Tools       │    │ (bridge_mcp_    │    │ (GhidraMCP.jar) │
│  (Claude, etc.) │    │  ghidra.py)     │    │                 │
└─────────────────┘    └─────────────────┘    └─────────────────┘
        │                       │                       │
   MCP Protocol            HTTP REST              Ghidra API
   (stdio/SSE)          (localhost:8080)      (Program, Listing)
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Components</h3><a id="user-content-components" aria-label="Permalink: Components" href="#components"></a></p>
<ul dir="auto">
<li><strong>bridge_mcp_ghidra.py</strong> - Python MCP server that translates MCP protocol to HTTP calls</li>
<li><strong>GhidraMCP.jar</strong> - Ghidra plugin that exposes analysis capabilities via HTTP</li>
<li><strong>ghidra_scripts/</strong> - Collection of 70+ automation scripts for common tasks</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔧 Development</h2><a id="user-content--development" aria-label="Permalink: 🔧 Development" href="#-development"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Building from Source</h3><a id="user-content-building-from-source" aria-label="Permalink: Building from Source" href="#building-from-source"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Build the plugin (skip integration tests)
mvn clean package assembly:single -DskipTests

# Deploy to Ghidra
.\deploy-to-ghidra.ps1"><pre><span><span>#</span> Build the plugin (skip integration tests)</span>
mvn clean package assembly:single -DskipTests

<span><span>#</span> Deploy to Ghidra</span>
.<span>\d</span>eploy-to-ghidra.ps1</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Project Structure</h3><a id="user-content-project-structure" aria-label="Permalink: Project Structure" href="#project-structure"></a></p>
<div data-snippet-clipboard-copy-content="ghidra-mcp/
├── bridge_mcp_ghidra.py     # MCP server (Python)
├── src/main/java/           # Ghidra plugin (Java)
├── lib/                     # Ghidra library dependencies
├── ghidra_scripts/          # 70+ automation scripts
├── docs/                    # Documentation
│   ├── prompts/            # AI workflow prompts
│   ├── releases/           # Version release notes
│   └── project-management/ # Project docs
├── examples/                # Example usage
└── scripts/                 # Build/utility scripts"><pre><code>ghidra-mcp/
├── bridge_mcp_ghidra.py     # MCP server (Python)
├── src/main/java/           # Ghidra plugin (Java)
├── lib/                     # Ghidra library dependencies
├── ghidra_scripts/          # 70+ automation scripts
├── docs/                    # Documentation
│   ├── prompts/            # AI workflow prompts
│   ├── releases/           # Version release notes
│   └── project-management/ # Project docs
├── examples/                # Example usage
└── scripts/                 # Build/utility scripts
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Library Dependencies</h3><a id="user-content-library-dependencies" aria-label="Permalink: Library Dependencies" href="#library-dependencies"></a></p>
<p dir="auto">The <code>lib/</code> folder must contain Ghidra JAR files for compilation. Run the provided script to copy them from your Ghidra installation:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Windows
copy-ghidra-libs.bat &quot;C:\path\to\ghidra_12.0.2_PUBLIC&quot;

# Or manually copy from your Ghidra installation"><pre><span><span>#</span> Windows</span>
copy-ghidra-libs.bat <span><span>"</span>C:\path\to\ghidra_12.0.2_PUBLIC<span>"</span></span>

<span><span>#</span> Or manually copy from your Ghidra installation</span></pre></div>
<p dir="auto"><strong>Required Libraries (14 JARs, ~37MB):</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Library</th>
<th>Source Path</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Base.jar</strong></td>
<td><code>Features/Base/lib/</code></td>
<td>Core Ghidra functionality</td>
</tr>
<tr>
<td><strong>Decompiler.jar</strong></td>
<td><code>Features/Decompiler/lib/</code></td>
<td>Decompilation engine</td>
</tr>
<tr>
<td><strong>PDB.jar</strong></td>
<td><code>Features/PDB/lib/</code></td>
<td>Microsoft PDB symbol support</td>
</tr>
<tr>
<td><strong>FunctionID.jar</strong></td>
<td><code>Features/FunctionID/lib/</code></td>
<td>Function identification</td>
</tr>
<tr>
<td><strong>SoftwareModeling.jar</strong></td>
<td><code>Framework/SoftwareModeling/lib/</code></td>
<td>Program model API</td>
</tr>
<tr>
<td><strong>Project.jar</strong></td>
<td><code>Framework/Project/lib/</code></td>
<td>Project management</td>
</tr>
<tr>
<td><strong>Docking.jar</strong></td>
<td><code>Framework/Docking/lib/</code></td>
<td>UI docking framework</td>
</tr>
<tr>
<td><strong>Generic.jar</strong></td>
<td><code>Framework/Generic/lib/</code></td>
<td>Generic utilities</td>
</tr>
<tr>
<td><strong>Utility.jar</strong></td>
<td><code>Framework/Utility/lib/</code></td>
<td>Core utilities</td>
</tr>
<tr>
<td><strong>Gui.jar</strong></td>
<td><code>Framework/Gui/lib/</code></td>
<td>GUI components</td>
</tr>
<tr>
<td><strong>FileSystem.jar</strong></td>
<td><code>Framework/FileSystem/lib/</code></td>
<td>File system support</td>
</tr>
<tr>
<td><strong>Graph.jar</strong></td>
<td><code>Framework/Graph/lib/</code></td>
<td>Graph/call graph analysis</td>
</tr>
<tr>
<td><strong>DB.jar</strong></td>
<td><code>Framework/DB/lib/</code></td>
<td>Database operations</td>
</tr>
<tr>
<td><strong>Emulation.jar</strong></td>
<td><code>Framework/Emulation/lib/</code></td>
<td>P-code emulation</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<blockquote>
<p dir="auto"><strong>Note</strong>: Libraries are NOT included in the repository (see <code>.gitignore</code>). You must copy them from your Ghidra installation before building.</p>
</blockquote>
<p dir="auto"><h3 tabindex="-1" dir="auto">Development Features</h3><a id="user-content-development-features" aria-label="Permalink: Development Features" href="#development-features"></a></p>
<ul dir="auto">
<li><strong>Automated Deployment</strong>: Version-aware deployment script</li>
<li><strong>Batch Operations</strong>: Reduces API calls by 93%</li>
<li><strong>Atomic Transactions</strong>: All-or-nothing semantics</li>
<li><strong>Comprehensive Logging</strong>: Debug and trace capabilities</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">📚 Documentation</h2><a id="user-content--documentation" aria-label="Permalink: 📚 Documentation" href="#-documentation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Core Documentation</h3><a id="user-content-core-documentation" aria-label="Permalink: Core Documentation" href="#core-documentation"></a></p>
<ul dir="auto">
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/README.md">Documentation Index</a> - Complete documentation navigation</li>
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/PROJECT_STRUCTURE.md">Project Structure</a> - Project organization guide</li>
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/NAMING_CONVENTIONS.md">Naming Conventions</a> - Code naming standards</li>
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/HUNGARIAN_NOTATION.md">Hungarian Notation</a> - Variable naming guide</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">AI Workflow Prompts</h3><a id="user-content-ai-workflow-prompts" aria-label="Permalink: AI Workflow Prompts" href="#ai-workflow-prompts"></a></p>
<ul dir="auto">
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/prompts/README.md">Prompts Overview</a> - AI prompting system guide</li>
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/prompts/FUNCTION_DOC_WORKFLOW_V4.md">Function Documentation Workflow</a> - Complete workflow</li>
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/prompts/QUICK_START_PROMPT.md">Quick Start Prompt</a> - Simplified beginner workflow</li>
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/prompts/CROSS_VERSION_MATCHING_COMPREHENSIVE.md">Cross-Version Matching</a> - Hash-based matching</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Release History</h3><a id="user-content-release-history" aria-label="Permalink: Release History" href="#release-history"></a></p>
<ul dir="auto">
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/CHANGELOG.md">Complete Changelog</a> - All version release notes</li>
<li><a href="https://github.com/bethington/ghidra-mcp/blob/main/docs/releases">Release Notes</a> - Detailed release documentation</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🤝 Contributing</h2><a id="user-content--contributing" aria-label="Permalink: 🤝 Contributing" href="#-contributing"></a></p>
<p dir="auto">See <a href="https://github.com/bethington/ghidra-mcp/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for detailed contribution guidelines.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Quick Start</h3><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<ol dir="auto">
<li>Fork the repository</li>
<li>Create a feature branch (<code>git checkout -b feature/amazing-feature</code>)</li>
<li>Build and test your changes (<code>mvn clean package assembly:single -DskipTests</code>)</li>
<li>Update documentation as needed</li>
<li>Commit your changes (<code>git commit -m 'Add amazing feature'</code>)</li>
<li>Push to the branch (<code>git push origin feature/amazing-feature</code>)</li>
<li>Open a Pull Request</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">📄 License</h2><a id="user-content--license" aria-label="Permalink: 📄 License" href="#-license"></a></p>
<p dir="auto">This project is licensed under the Apache License 2.0 - see the <a href="https://github.com/bethington/ghidra-mcp/blob/main/LICENSE">LICENSE</a> file for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🏆 Production Status</h2><a id="user-content--production-status" aria-label="Permalink: 🏆 Production Status" href="#-production-status"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Metric</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Version</strong></td>
<td>2.0.0</td>
</tr>
<tr>
<td><strong>MCP Tools</strong></td>
<td>110 fully implemented</td>
</tr>
<tr>
<td><strong>Compilation</strong></td>
<td>✅ 100% success</td>
</tr>
<tr>
<td><strong>Batch Efficiency</strong></td>
<td>93% API call reduction</td>
</tr>
<tr>
<td><strong>Ghidra Scripts</strong></td>
<td>70+ automation scripts</td>
</tr>
<tr>
<td><strong>Documentation</strong></td>
<td>Comprehensive with AI prompts</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">See <a href="https://github.com/bethington/ghidra-mcp/blob/main/CHANGELOG.md">CHANGELOG.md</a> for version history and release notes.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🙏 Acknowledgments</h2><a id="user-content--acknowledgments" aria-label="Permalink: 🙏 Acknowledgments" href="#-acknowledgments"></a></p>
<ul dir="auto">
<li><strong>Ghidra Team</strong> - For the incredible reverse engineering platform</li>
<li><strong>Model Context Protocol</strong> - For the standardized AI integration framework</li>
<li><strong>Contributors</strong> - For testing, feedback, and improvements</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔗 Related Projects</h2><a id="user-content--related-projects" aria-label="Permalink: 🔗 Related Projects" href="#-related-projects"></a></p>
<ul dir="auto">
<li><a href="https://github.com/bethington/re-universe">re-universe</a> — Ghidra BSim PostgreSQL platform for large-scale binary similarity analysis. Pairs perfectly with GhidraMCP for AI-driven reverse engineering workflows.</li>
<li><a href="https://github.com/bethington/cheat-engine-server-python">cheat-engine-server-python</a> — MCP server for dynamic memory analysis and debugging.</li>
</ul>
<hr>
<p dir="auto"><strong>Ready for production deployment with enterprise-grade reliability and comprehensive binary analysis capabilities.</strong></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Petition for Recognition of Work on Open-Source as Volunteering in Germany (207 pts)]]></title>
            <link>https://www.openpetition.de/petition/online/recognition-of-work-on-open-source-as-volunteering-in-germany</link>
            <guid>46881568</guid>
            <pubDate>Wed, 04 Feb 2026 04:46:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openpetition.de/petition/online/recognition-of-work-on-open-source-as-volunteering-in-germany">https://www.openpetition.de/petition/online/recognition-of-work-on-open-source-as-volunteering-in-germany</a>, See on <a href="https://news.ycombinator.com/item?id=46881568">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<div dir="ltr" lang="en">
			<p>
				<strong>Petition richtet sich an:</strong>
									German Bundestag, Petition Committee							</p>

			<!--marker--><p>Open-Source-Software builds the foundations of digital infrastructure in big parts - in administration, economy, science and daily life. Even the current <b>coalition agreement</b> of the <b>Federal Government</b> mentions Open-Source-Software as a fundamental building block for the achievement of <b>digital sovereignty</b>.</p><p>However, the work done by thousands of volunteers for this goal is <b>not recognised as volunteering</b>, neither fiscally nor in terms of funding. This imbalance between societal importance and legal status has to be corrected.</p><p>Therefore, as an active contributor to Open-Source-Projects, I call for work on Open-Source to be recognised as <b>volunteering for the common good</b> – of equal rank as volunteer work for associations, youth work or ambulance service.</p>		</div>

					<h4>Begründung</h4>

			<div dir="ltr" lang="en">
				<!--marker--><p><b>1. Open-Source contributes evidently to the common good</b></p><ul><li>It is creating <b>free, transparent and auditable software</b> that is available for everyone.</li><li>Critical systems like <b>internet protocols, security libraries, health IT, AI frameworks, energy management, education technologies </b>and<b> communication tools</b> are based significantly on volunteer contributions.</li><li>Without this work, Germany would be <b>digitally more dependent, less secure </b>and<b> less inventive.</b></li></ul><p>Orientation on the common good is a central criterion for volunteering – and Open-Source fulfils it to the highest degree.</p><p><b>2. This work predominantly happens unpaid – and is voluntary civilian commitment</b></p><ul><li>The majority of all work on development, maintenance and documentation happens voluntarily in leisure time.</li><li>Contributors take responsibility for security, stability and advancement of central software components, without getting paid and often recognised.</li><li>The commitment is <b>comparable to work in associations for the public good</b>, but digitally.</li></ul><p>The legal equalisation with traditional volunteering is therefore coherent.</p><p><b>3. Societal dependence without appreciation</b></p><ul><li>State facilities, town councils, schools and enterprises <b>profit directly</b> from Open-Source libraries, frameworks and tools.</li><li>Security vulnerabilities like "Heartbleed" or "Log4Shell" have shown the importance of work by maintainers for the <b>protection of the public</b>.</li><li>Concurrently, resources and structures are lacking, as the work is <b>not formally recognised as volunteering</b> – and does therefore <i>not receive taxable or organisational benefits</i>.</li></ul><p>This creates an <b>imbalance of responsibilities</b> that lies on few volunteers, while millions of users are profiting.</p><p><b>4. Recognition as volunteering would create legal clarity</b><br>Possible results of formal recognition:</p><ul><li><b>Compensations </b>could be <b>paid tax-exempt </b>(Ehrenamtspauschale/Übungsleiterpauschale).</li><li><b>Open-Source projects for the common good</b> could more easily receive a classification as per §52 AO.</li><li>Contributors could get a better position in issues of liability (similar to §31a BGB for an Association's Board).</li><li>Projects could legally reimburse expenses and issue donation receipts.</li></ul><p>This creates <b>transparency, legal clarity and sustainability</b> in digital volunteer work.</p><p><b>5. Digitalisation needs competent volunteers – and those deserve funding</b></p><ul><li>Open-Source commitment requires high technical competence</li><li>Volunteer developers perform work, that companies would otherwise need to buy for high hourly rates.</li><li>The state invests billions in digitalisation, but ignores the people who maintain the technological foundation <b>voluntarily</b>.</li></ul><p>Recognition as volunteer work would be a <b>cost-efficient contribution to digital sovereignty</b> in Germany.</p><p><b>6. Germany limps behind internationally</b><br>Other countries are already funding commitment to Open-Source through: </p><ul><li>Taxable benefits</li><li>Institutional support</li><li>Recognition of software development for the public good</li></ul><p>Germany is risking to fall behind in international competition, if volunteers in the digital realm are <b>structurally disadvantaged</b> further.</p>			</div>
		
					
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I miss thinking hard (1202 pts)]]></title>
            <link>https://www.jernesto.com/articles/thinking_hard</link>
            <guid>46881264</guid>
            <pubDate>Wed, 04 Feb 2026 03:54:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jernesto.com/articles/thinking_hard">https://www.jernesto.com/articles/thinking_hard</a>, See on <a href="https://news.ycombinator.com/item?id=46881264">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>Before you read this post, ask yourself a question: <strong>When was the last time you truly thought hard?</strong></p>

<p>By “thinking hard,” I mean encountering a specific, difficult problem and spending multiple days just sitting with it to overcome it. </p>

<p>a) All the time. 
b) Never. 
c) Somewhere in between.</p>

<p>If your answer is (a) or (b), this post isn't for you. But if, like me, your response is (c), you might get something out of this, if only the feeling that you aren't alone.</p>

<p>First, a disclaimer: this post has no answers, not even suggestions. It is simply a way to vent something I've been feeling for the last few months.</p>

<h3 id="the-builder-and-the-thinker">The Builder and The Thinker</h3>

<p>I believe my personality is built on two primary traits:</p>

<ol>
<li><p><strong>The Builder</strong> (The desire to create, ship, and be pragmatic).</p></li>
<li><p><strong>The Thinker</strong> (The need for deep, prolonged mental struggle).</p></li>
</ol>

<p>The builder is pretty self explanatory, it’s motivated by velocity and utility. It is the part of me that craves the transition from “idea” to “reality.” It loves the dopamine hit of a successful deploy, the satisfaction of building systems to solve real problems, and the knowledge that someone, somewhere, is using my tool.</p>

<p>To explain the Thinker , I need to go back to my university days studying physics. Every now and then, we would get homework problems that were significantly harder than average. Even if you had a decent grasp of the subject, just coming up with an approach was difficult.</p>

<p>I observed that students fell into three categories when facing these problems (well, four, if you count the 1% of geniuses for whom no problem was too hard).</p>

<ul>
<li><p><strong>Type 1:</strong> The majority. After a few tries, they gave up and went to the professor or a TA for help.</p></li>
<li><p><strong>Type 2:</strong> The Researchers. They went to the library to look for similar problems or insights to make the problem approachable. They usually succeeded.</p></li>
<li><p><strong>Type 3:</strong> The Thinkers.</p></li>
</ul>

<p>I fell into the third category, which, in my experience, was almost as rare as the genius 1%. My method was simply to think. To think hard and long. Often for several days or weeks, all my non-I/O brain time was relentlessly chewing on possible ways to solve the problem, even while I was asleep.</p>

<p>This method never failed me. I always felt that deep prolonged thinking was my superpower. I might not be as fast or naturally gifted as the top 1%, but given enough time, I was confident I could solve anything. I felt a deep satisfaction in that process.</p>

<h3 id="the-conflict-with-ai">The Conflict with AI</h3>

<p>That satisfaction is why software engineering was initially so gratifying. It hit the right balance. It satisfied <strong>The Builder</strong> (feeling productive and pragmatic by creating useful things) and <strong>The Thinker</strong> (solving really hard problems). Thinking back, the projects where I grew the most as an engineer were always the ones with a good number of really hard problems that needed creative solutions.</p>

<p>But recently, the number of times I truly ponder a problem for more than a couple of hours has decreased tremendously.</p>

<p>Yes, <strong>I blame AI for this</strong>.</p>

<p>I am currently writing much more, and more complicated software than ever, yet I feel I am not growing as an engineer at all. When I started meditating on why I felt “stuck,” I realized I am starving <strong>The Thinker</strong>.</p>

<p>“Vibe coding” satisfies the Builder. It feels great to see to pass from idea to reality in a fraction of a time that would take otherwise. But it has drastically cut the times I need to came up with creative solutions for technical problems. I know many people who are purely Builders, for them this era is the best thing that ever happened. But for me, something is missing.</p>

<h3 id="the-trap-of-pragmatism">The Trap of Pragmatism</h3>

<p>I know what you might be thinking: "If you can ‘vibe code’ your way through it, the problem wasn’t actually hard."</p>

<p>I think that misses the point.  It’s not that AI is good for hard problems, it’s not even that good for easy problems. I’m confident that my third manual rewrite of a module would be much better than anything the AI can output. But I am also a pragmatist.</p>

<p>If I can get a solution that is “close enough” in a fraction of the time and effort, it is irrational not to take the AI route. And that is the real problem: <strong>I cannot simply turn off my pragmatism.</strong></p>

<p>At the end of the day, I am a Builder. I like building things. The faster I build, the better. Even if I wanted to reject AI and go back to the days where the Thinker's needs were met by coding, the Builder in me would struggle with the inefficiency.</p>

<p>Even though the AI almost certainly won't come up with a 100% satisfying solution, the 70% solution it achieves usually hits the “good enough” mark.</p>

<h3 id="so-what-now">So, what now?</h3>

<p>To be honest, I don’t know. I am still figuring it out.</p>

<p>I'm not sure if my two halves can be satisfied by coding anymore. You can always aim for harder projects, hoping to find problems where AI fails completely. I still encounter those occasionally, but the number of problems requiring deep creative solutions feels like it is diminishing rapidly.</p>

<p>I have tried to get that feeling of mental growth outside of coding. I tried getting back in touch with physics, reading old textbooks. But that wasn’t successful either. It is hard to justify spending time and mental effort solving physics problems that aren’t relevant or state-of-the-art when I know I could be building things.</p>

<p>My Builder side won’t let me just sit and think about unsolved problems, and my Thinker side is starving while I vibe-code. I am not sure if there will ever be a time again when both needs can be met at once.  </p>

<p> "Now we have the right to give this being the well-known name that always designates what no power of imagination, no flight of the boldest fantasy, no intently devout heart, no abstract thinking however profound, no enraptured and transported spirit has ever attained: God. But this basic unity is of the past; it no longer is. It has, by changing its being, totally and completely shattered itself. God has died and his death was the life of the world." <br>
-  Philipp Mainländer </p>

			</div></div>]]></description>
        </item>
    </channel>
</rss>