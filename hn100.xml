<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 03 Jul 2023 09:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[55 GiB/s FizzBuzz (2021) (256 pts)]]></title>
            <link>https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/236630#236630</link>
            <guid>36568192</guid>
            <pubDate>Mon, 03 Jul 2023 02:54:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/236630#236630">https://codegolf.stackexchange.com/questions/215216/high-throughput-fizz-buzz/236630#236630</a>, See on <a href="https://news.ycombinator.com/item?id=36568192">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<h2>x86-64+AVX2 assembly language (Linux, <code>gcc</code>+<code>gas</code>)</h2>

<h3>Build and usage instructions</h3>
<p>This program is most conveniently built using <code>gcc</code>. Save it as <code>fizzbuzz.S</code> (that's a capital <code>S</code> as the extension), and build using the commands</p>
<pre><code>gcc -mavx2 -c fizzbuzz.S
ld -o fizzbuzz fizzbuzz.o
</code></pre>
<p>Run as <code>./fizzbuzz</code> piped into one command, e.g. <code>./fizzbuzz | pv &gt; /dev/null</code> (as suggested in the question), <code>./fizzbuzz | cat</code>, or <code>./fizzbuzz | less</code>. To simplify the I/O, this will not work (producing an error on startup) if you try to output to a file/terminal/device rather than a pipe. Additionally, this program may produce incorrect output if piped into two commands (e.g. <code>./fizzbuzz | pv | cat &gt; fizzbuzz.txt</code>), but only in the case where the middle command uses the <code>splice</code> system call; this is either a bug in Linux (very possible with system calls this obscure!) or a mistake in the documentation of the system calls in question (also possible). However, it should work correctly for the use case in the question, which is all that matters on CGCC.</p>
<p>This program is somewhat system-specific; it requires the operating system to be a non-ancient version of Linux, and the processor to be an x86-64 implementation that supports AVX2. (Most moderately recent processors by Intel and AMD have AVX2 support, including the Ryzen 9 mentioned in the question, and almost all use the x86-64 instruction set.) However, it avoids assumptions about the system it's running on beyond those mentioned in the header, so there's a decent chance that if you can run Linux, you can run this.</p>
<p>The program outputs a quintillion lines of FizzBuzz and then exits (going further runs into problems related to the sizes of registers). This would take tens of years to accomplish, so hopefully counts as "a very high astronomical number" (although it astonishes me that it's a small enough timespan that it might be theoretically possible to reach a number as large as a quintillion without the computer breaking).</p>
<p>As a note: this program's performance is dependent on whether it and the program it outputs to are running on sibling CPUs or not, something which will be determined arbitrarily by the kernel when you start it. If you want to compare the two possible timings, use <code>taskset</code> to force the programs onto particular CPUs:
<code>taskset 1 ./fizzbuzz | taskset 2 pv &gt; /dev/null</code> versus <code>taskset 1 ./fizzbuzz | taskset 4 pv &gt; /dev/null</code>. (The former will probably run faster, but might be slower on some CPU configurations.)</p>
<h3>Discussion</h3>
<p>I've spent months working on this program. I've long thought that "how fast can you make a FizzBuzz" would be a really interesting question for learning about high-performance programming, and when I subsequently saw this question posted on CGCC, I pretty much had to try.</p>
<p>This program aims for the maximum possible single-threaded performance. In terms of the FizzBuzz calculation itself, it is intended to sustain a performance of 64 bytes of FizzBuzz per 4 clock cycles (and is future-proofed where possible to be able to run faster if the relevant processor bottleneck – L2 cache write speed – is ever removed). This is faster than a number of standard functions. In particular, it's faster than <code>memcpy</code>, which presents interesting challenges when it comes to I/O (if you try to output using <code>write</code> then the copies in <code>write</code> will take up almost all the runtime – replacing the I/O routine here with <code>write</code> causes the performance on my CPU to drop by a factor of 5). As such, I needed to use much more obscure system calls to keep I/O-related copies to a minimum (in particular, the generated FizzBuzz text is only sent to main memory if absolutely necessary; most of the time it's stored in the processor's L2 cache and piped into the target program from there, which is why reading it from a sibling CPU can boost performance – the physical connection to the L2 cache is shorter and higher bandwidth than it would be to a more distant CPU).</p>
<p>On my computer (which has a fairly recent, but not particularly powerful, Intel processor), this program generates around 31GiB of FizzBuzz per second. I'll be interested to see how it does on the OP's computer.</p>
<p>I did experiment with multithreaded versions of the program, but was unable to gain any speed. Experiments with simpler programs show that it could be possible, but any gains may be small; the cost of communication between CPUs is sufficiently high to negate most of the gains you could get by doing work in parallel, assuming that you only have one program reading the resulting FizzBuzz (and anything that writes to memory will be limited by the write speed of main memory, which is slower than the speed with which the FizzBuzz can be generated).</p>
<h3>The program</h3>
<p>This isn't <a href="https://codegolf.stackexchange.com/questions/tagged/code-golf" title="show questions tagged 'code-golf'" rel="tag">code-golf</a>, so my explanation of the program and its algorithm are given as comments in the program itself. (I still had to lightly golf the program, and especially the explanation, to fit this post within the 65536 byte size limit.)</p>
<p>The program is written in a "literate" assembly style; it will be easiest to understand if you read it in order, from start to end. (I also added a number of otherwise useless line labels to separate the program into logical groups of instructions, in order to make the disassembly easier to read, if you're one of the people who prefers to read assembly code like that.)</p>
<pre><code>.intel_syntax prefix

// Header files.
#include &lt;asm/errno.h&gt;
#include &lt;asm/mman.h&gt;
#include &lt;asm/unistd.h&gt;
#define F_SETPIPE_SZ 1031 // not in asm headers, define it manually

// The Linux system call API (limited to 4 arguments, the most this
// program uses). 64-bit registers are unsuffixed; 32-bit have an "e"
// suffix.
#define ARG1 %rdi
#define ARG1e %edi
#define ARG2 %rsi
#define ARG2e %esi
#define ARG3 %rdx
#define ARG3e %edx
#define ARG4 %r10
#define ARG4e %r10d
#define SYSCALL_RETURN %rax
#define SYSCALL_RETURNe %eax
#define SYSCALL_NUMBER %eax

// %rax, %rcx, %rdx, %ymm0-3 are general-purpose temporaries. Every
// other register is used for just one or two defined purposes; define
// symbolic names for them for readability. (Bear in mind that some of
// these will be clobbered sometimes, e.g. OUTPUT_LIMIT is clobbered
// by `syscall` because it's %r11.)
#define OUTPUT_PTR %rbx
#define BYTECODE_IP %rbp
#define SPILL %rsi
#define BYTECODE_GEN_PTR %rdi
#define REGEN_TRIGGER %r8
#define REGEN_TRIGGERe %r8d
#define YMMS_AT_WIDTH %r9
#define YMMS_AT_WIDTHe %r9d
#define BUZZ %r10
#define BYTECODE_NEG_LEN %r10
#define FIZZ %r11
#define FIZZe %r11d
#define OUTPUT_LIMIT %r11
#define BYTECODE_END %r12
#define BYTECODE_START %r13
#define BYTECODE_STARTe %r13d
#define PIPE_SIZE %r13
#define LINENO_WIDTH %r14
#define LINENO_WIDTHe %r14d
#define GROUPS_OF_15 %r15
#define GROUPS_OF_15e %r15d
#define LINENO_LOW %ymm4
#define LINENO_MID %ymm5
#define LINENO_MIDx %xmm5
#define LINENO_TOP %ymm6
#define LINENO_TOPx %xmm6
#define LINENO_MID_TEMP %ymm7
#define ENDIAN_SHUFFLE %ymm8
#define ENDIAN_SHUFFLEx %xmm8
#define LINENO_LOW_INCR %ymm9
#define LINENO_LOW_INCRx %xmm9

// The last six vector registers are used to store constants, to avoid
// polluting the cache by loading their values from memory.
#define LINENO_LOW_INIT %ymm10
#define LINENO_MID_BASE %ymm11
#define LINENO_TOP_MAX %ymm12
#define ASCII_OFFSET %ymm13
#define ASCII_OFFSETx %xmm13
#define BIASCII_OFFSET %ymm14
#define BASCII_OFFSET %ymm15


// Global variables.
.bss
.align 4 &lt;&lt; 20
// The most important global variables are the IO buffers. There are
// two of these, each with 2MiB of memory allocated (not all of it is
// used, but putting them 2MiB apart allows us to simplify the page
// table; this gives a 30% speedup because page table contention is
// one of the main limiting factors on the performance).
io_buffers:
.zero 2 * (2 &lt;&lt; 20)
// The remaining 2MiB of memory stores everything else:
iovec_base:          // I/O config buffer for vmsplice(2) system call
.zero 16
error_write_buffer:  // I/O data buffer for write(2) system call
.zero 1
.p2align 9,0
bytecode_storage:    // the rest is a buffer for storing bytecode
.zero (2 &lt;&lt; 20) - 512


// The program starts here. It doesn't use the standard library (or
// indeed any libraries), so the start point is _start, not main.
.text
.globl _start
_start:

// This is an AVX2 program, so check for AVX2 support by running an
// AVX2 command. This is a no-op, but generates SIGILL if AVX2 isn't
// supported.
vpand %ymm0, %ymm0, %ymm0

// Initialize constant registers to their constant values.
vmovdqa LINENO_LOW_INIT, [%rip + lineno_low_init]
vmovdqa LINENO_MID_BASE, [%rip + lineno_mid_base]
vmovdqa LINENO_TOP_MAX, [%rip + lineno_top_max]
vmovdqa ASCII_OFFSET, [%rip + ascii_offset]
vmovdqa BIASCII_OFFSET, [%rip + biascii_offset]
vmovdqa BASCII_OFFSET, [%rip + bascii_offset]

// Initialize global variables to their initial values.
vmovdqa ENDIAN_SHUFFLE, [%rip + endian_shuffle_init]
vmovdqa LINENO_TOP, [%rip + lineno_top_init]

// Check the size of the L2 cache.
//
// This uses the CPUID interface. To use it safely, check what range
// of command numbers is legal; commands above the legal range have
// undefined behaviour, commands within the range might not be
// implemented but will return all-zeros rather than undefined values.
// CPUID clobbers a lot of registers, including some that are normally
// call-preserved, so this must be done first.
mov %eax, 0x80000000 // asks which CPUID extended commands exist
cpuid                // returns the highest supported command in %eax
cmp %eax, 0x80000006 // does 0x80000006 give defined results?
jb bad_cpuid_error

mov %eax, 0x80000006 // asks about the L2 cache size
cpuid                // returns size in KiB in the top half of %ecx
shr %ecx, 16
jz bad_cpuid_error   // unsupported commands return all-0s

// Calculate the desired pipe size, half the size of the L2 cache.
// This value is chosen so that the processor can hold a pipeful of
// data being output, plus a pipeful of data being calculated, without
// needing to resort to slow L3 memory operations.
shl %ecx, 10 - 1     // convert KiB to bytes, then halve
mov PIPE_SIZE, %rcx

// Ask the kernel to resize the pipe on standard output.
mov ARG1e, 1
mov ARG2e, F_SETPIPE_SZ
mov ARG3e, %ecx
mov SYSCALL_NUMBER, __NR_fcntl
syscall
cmp SYSCALL_RETURNe, -EBADF
je pipe_error
cmp SYSCALL_RETURNe, -EPERM
je pipe_perm_error
call exit_on_error
cmp SYSCALL_RETURN, PIPE_SIZE
jne pipe_size_mismatch_error

// Ask the kernel to defragment the physical memory backing the BSS
// (read-write data) segment. This simplifies the calculations needed
// to find physical memory addresses, something that both the kernel
// and processor would otherwise spend a lot of time doing, and
// speeding the program up by 30%.
lea ARG1, [%rip + io_buffers]
mov ARG2e, 3 * (2 &lt;&lt; 20)
mov ARG3e, MADV_HUGEPAGE
mov SYSCALL_NUMBER, __NR_madvise
syscall
call exit_on_error

// From now on, OUTPUT_PTR is permanently set to the memory location
// where the output is being written. This starts at the start of the
// first I/O buffer.
lea OUTPUT_PTR, [%rip + io_buffers]


///// First phase of output
//
// The FizzBuzz output is produced in three distinct phases. The first
// phase is trivial; just a hardcoded string, that's left in the
// output buffer, to be output at the end of the second phase.

first_phase:

.section .rodata
fizzbuzz_intro:
.ascii "1\n2\nFizz\n4\nBuzz\nFizz\n7\n8\nFizz\n"
.text
vmovdqu %ymm0, [%rip + fizzbuzz_intro]
vmovdqu [OUTPUT_PTR], %ymm0
add OUTPUT_PTR, 30


///// Second phase of output
//
// This is a routine implementing FizzBuzz in x86-64+AVX2 assembler in
// a fairly straightforward and efficient way. This isn't as fast as
// the third-phase algorithm, and can't handle large numbers, but will
// introduce some of the basic techniques this program uses.

second_phase_init:

// The outer loop of the whole program breaks the FizzBuzz output into
// sections where all the line numbers contain the same number of
// digits. From now on, LINENO_WIDTH tracks the number of digits in
// the line number. This is currently 2; it ranges from 2-digit
// numbers to 18-digit numbers, and then the program ends.
mov LINENO_WIDTHe, 2

// GROUPS_OF_15 is permanently set to the number of groups of 15 lines
// that exist at this line number width; it's multiplied by 10 whenever
// LINENO_WIDTH is incremented.
//
// A general note about style: often the program uses numbers that are
// statically known to fit into 32 bits, even in a register that's
// conceptually 64 bits wide (like this one). In such cases, the
// 32-bit and 64-bit versions of a command will be equivalent (as the
// 32-bit version zero-extends to 64-bits on a 64-bit processor); this
// program generally uses the 32-bit version, both because it
// sometimes encodes to fewer bytes (saving cache pressure), and
// because some processors recognise zeroing idioms only if they're 32
// bits wide.
mov GROUPS_OF_15e, 6

// Some constants used throughout the second phase, which permanently
// stay in their registers. Note that short string literals can be
// stored in normal integer registers - the processor doesn't care.
mov FIZZ, 0x0a7a7a6946  // "Fizz\n"
mov BUZZ, 0x0a7a7a7542  // "Buzz\n"

.section .rodata
.p2align 5, 0
second_phase_constants:
.byte 0, 0, 0, 0, 0, 0, 0, 0
.byte 1, 0, 0, 0, 0, 0, 0, 0
.text
vmovdqa %xmm3, [%rip + second_phase_constants]

// This program makes extensive use of a number format that I call
// "high-decimal". This is a version of decimal where the digit 0 is
// encoded as the byte 246, the digit 1 as the byte 247, ..., the
// digit 9 as the byte 255. The bytes are stored in the normal
// endianness for the processor (i.e. least significant first), and
// padded to a known length (typically 8 digits) with leading zeroes.
//
// The point of high-decimal is that it allows us to use arithmetic
// operators intended for binary on high-decimal numbers, and the
// carries will work the same way (i.e. the same digits will carry,
// although carries will be 0-based rather than 246-based); all that's
// required is to identify the digits that carried and add 246 to
// them. That means that the processor's binary ALU can be used to do
// additions directly in decimal - there's no need for loops or
// anything like that, and no need to do binary/decimal conversions.
//
// The first use for high-decimal is to store the line number during
// the second phase (it's stored differently in the third phase).
// It's stored it in the top half of %xmm1 (although it's only 64 bits
// wide, it needs to be in a vector register so that it can be
// interpreted as 8 x 8 bits when necessary; general-purpose
// registers can't do that). The bottom half of %xmm1 is unused, and
// frequently overwritten with arbitrary data.
.section .rodata
line_number_init:
#define REP8(x) x,x,x,x,x,x,x,x
.byte REP8(0)
.byte 246, 247, 246, 246, 246, 246, 246, 246
.text
vmovdqa %xmm1, [%rip + line_number_init]

// Writing line numbers is nontrivial because x86-64 is little-endian
// but FizzBuzz output is big-endian; also, leading zeroes aren't
// allowed. ENDIAN_SHUFFLE is used to fix both these problems; when
// used to control the vector shuffler, it reverses the order of a
// vector register, and rotates the elements to put the first digit
// (based on LINENO_WIDTH) into the first byte. (This method is used
// by both the second and third phases; the second phase uses only the
// bottom half, with the top half used by the third phase, but they
// are both initialized together.)
.section .rodata
endian_shuffle_init:
.byte 9, 8, 7, 6, 5, 4, 3, 2
.byte 1, 0, 255, 254, 253, 252, 251, 250
.byte 3, 2, 1, 0, 255, 254, 253, 252
.byte 251, 250, 249, 248, 247, 246, 245, 244
.text


second_phase_per_width_init:

// The second phase writing routines are macros.
//
// Fizz and Buzz are trivial. (This writes a little beyond the end of
// the string, but that's OK; the next line will overwrite them.)
#define WRITE_FIZZ   mov [OUTPUT_PTR], FIZZ; add OUTPUT_PTR, 5
#define WRITE_BUZZ   mov [OUTPUT_PTR], BUZZ; add OUTPUT_PTR, 5

// For FizzBuzz, output 32 bits of FIZZ to write "Fizz" with no
// newline, then write a "Buzz" after that.
#define WRITE_FIZZBUZZ \
  mov [OUTPUT_PTR], FIZZe; mov [OUTPUT_PTR + 4], BUZZ; \
  add OUTPUT_PTR, 9

// To write a line number, add 58 to each byte of the line number
// %xmm1, fix the endianness and width with a shuffle, and write a
// final newline.
.section .rodata
ascii_offset:
.byte REP8(58), REP8(58), REP8(58), REP8(58)
.text
#define WRITE_LINENO \
  vpaddb %xmm0, ASCII_OFFSETx, %xmm1; \
  vpshufb %xmm0, %xmm0, ENDIAN_SHUFFLEx; \
  vmovdqu [OUTPUT_PTR], %xmm0; \
  lea OUTPUT_PTR, [OUTPUT_PTR + LINENO_WIDTH + 1]; \
  mov byte ptr [OUTPUT_PTR - 1], 10  // 10 = newline

// Incrementing the line number is fairly easy: add 1 (in the usual
// binary notation, taken from %xmm3) to the high-decimal number, then
// convert any bytes that produced a carry to high-decimal 0s by
// max-ing with 246.
//
// Normally I'd use a separate constant for this, but there randomly
// happens to be an %xmm register with 246s in its top half already
// (it's intended for an entirely different purpose, but it'll do for
// this one too).
#define INC_LINENO \
  vpaddq %xmm1, %xmm3, %xmm1; vpmaxub %xmm1, LINENO_TOPx, %xmm1

// Avoid modulus tests by unrolling the FizzBuzz by 15. (Bear in mind
// that this starts at 10, not 0, so the pattern will have a different
// phase than usual.)
mov %ecx, GROUPS_OF_15e
fifteen_second_phase_fizzbuzz_lines:
WRITE_BUZZ; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_FIZZ; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_FIZZBUZZ; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_FIZZ; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_BUZZ; INC_LINENO
WRITE_FIZZ; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_LINENO; INC_LINENO
WRITE_FIZZ; INC_LINENO
dec %ecx
jnz fifteen_second_phase_fizzbuzz_lines

second_phase_increment_width:

lea GROUPS_OF_15e, [GROUPS_OF_15 + GROUPS_OF_15 * 4]
add GROUPS_OF_15e, GROUPS_OF_15e
inc LINENO_WIDTHe

// Increment every element of the low half of ENDIAN_SHUFFLE to
// adjust it for the new width, while leaving the top half unchanged.
vpcmpeqb %xmm0, %xmm0, %xmm0
vpsubb ENDIAN_SHUFFLE, ENDIAN_SHUFFLE, %ymm0

// The second phase handles line numbers with 2 to 5 digits.
cmp LINENO_WIDTHe, 6
jne second_phase_per_width_init

///// The output routine
//
// Most FizzBuzz routines produce output with `write` or a similar
// system call, but these have the disadvantage that they need to copy
// the data being output from userspace into kernelspace. It turns out
// that when running full speed (as seen in the third phase), FizzBuzz
// actually runs faster than `memcpy` does, so `write` and friends are
// unusable when aiming for performance - this program runs five times
// faster than an equivalent that uses `write`-like system calls.
//
// To produce output without losing speed, the program therefore needs
// to avoid copies, or at least do them in parallel with calculating
// the next block of output. This can be accomplished with the
// `vmsplice` system call, which tells the kernel to place a reference
// to a buffer into a pipe (as opposed to copying the data into the
// pipe); the program at the other end of this pipe will then be able
// to read the output directly out of this program's memory, with no
// need to copy the data into kernelspace and then back into
// userspace. In fact, it will be reading out of this program's
// processor's L2 cache, without main memory being touched at all;
// this is the secret to high-performance programming, because the
// cache is much faster than main memory is.
//
// Of course, it's therefore important to avoid changing the output
// buffer until the program connected to standard output has actually
// read it all. This is why the pipe size needed to be set earlier; as
// long as the amount of output is always at least as large as the
// pipe size, successfully outputting one buffer will ensure that none
// of the other buffer is left in the pipe, and thus it's safe to
// overwrite the memory that was previously output. There is some need
// to jump through hoops later on to make sure that `swap_buffers` is
// never called with less than one pipeful of data, but it's worth it
// to get the huge performance boost.

mov %rdx, OUTPUT_PTR
and %edx, (2 &lt;&lt; 20) - 1

call swap_buffers
jmp third_phase_init

// Takes the amount of data to output in %rdx, and outputs from the
// buffer containing OUTPUT_PTR.
swap_buffers:
and OUTPUT_PTR, -(2 &lt;&lt; 20)  // rewind to the start of the buffer
mov [%rip + iovec_base], OUTPUT_PTR
mov [%rip + iovec_base + 8], %rdx
mov ARG1e, 1
lea ARG2, [%rip + iovec_base]
mov ARG3e, 1
xor ARG4e, ARG4e

// As with most output commands, vmsplice can do a short write
// sometimes, so it needs to be called in a loop in order to ensure
// that all the output is actually sent.
1: mov SYSCALL_NUMBER, __NR_vmsplice
syscall
call exit_on_error
add [ARG2], SYSCALL_RETURN
sub [ARG2 + 8], SYSCALL_RETURN
jnz 1b

xor OUTPUT_PTR, (2 &lt;&lt; 20)  // swap to the other buffer
ret


///// Third phase of output
//
// This is the heart of this program. It aims to be able to produce a
// sustained output rate of 64 bytes of FizzBuzz per four clock cycles
// in its main loop (with frequent breaks to do I/O, and rare breaks
// to do more expensive calculations).
//
// The third phase operates primarily using a bytecode interpreter; it
// generates a program in "FizzBuzz bytecode", for which each byte of
// bytecode generates one byte of output. The bytecode language is
// designed so that it can be interpreted using SIMD instructions; 32
// bytes of bytecode can be loaded from memory, interpreted, and have
// its output stored back into memory using just four machine
// instructions. This makes it possible to speed up the FizzBuzz
// calculations by hardcoding some of the calculations into the
// bytecode (this is similar to how JIT compilers can create a version
// of the program with some variables hardcoded, and throw it away on
// the rare occasions that those variables' values change).

third_phase_init:

// Reinitialize ENDIAN_SHUFFLE by copying the initializer stored in
// its high half to both halves. This works in the same way as in the
// second phase.
vpermq ENDIAN_SHUFFLE, ENDIAN_SHUFFLE, 0xEE

// Up to this point, PIPE_SIZE has held the size of the pipe. In order
// to save on registers, the pipe size is from now on encoded via the
// location in which the bytecode program is stored; the bytecode is
// started at iovec_base + PIPE_SIZE (which will be somewhere within
// bytecode_storage), so the same register can be used to find the
// bytecode and to remember the pipe size.
lea %rax, [%rip + iovec_base]
add BYTECODE_START, %rax  // BYTECODE_START is a synonym for PIPE_SIZE

// The bytecode program always holds instructions to produce exactly
// 600 lines of FizzBuzz. At width 6, those come to 3800 bytes long.
lea BYTECODE_END, [BYTECODE_START + 3800]

mov REGEN_TRIGGER, -1  // irrelevant until much later, explained there


third_phase_per_width_init:

// Calculate the amount of output at this LINENO_WIDTH. The result
// will always be divisible by 32, and thus is stored as the number of
// 32-byte units at this width; storing it in bytes would be more
// convenient, but sadly would overflow a 64-bit integer towards the
// end of the program.
lea %ecx, [LINENO_WIDTH * 8 + 47]   // bytes per 15 lines
mov YMMS_AT_WIDTH, GROUPS_OF_15
shr YMMS_AT_WIDTH, 5   // to avoid overflow, divide by 32 first
imul YMMS_AT_WIDTH, %rcx

// This program aims to output 64 bytes of output per four clock
// cycles, which it achieves via a continuous stream of 32-byte writes
// calculated by the bytecode program. One major complication here is
// that the 32-byte writes won't correspond to lines of FizzBuzz; a
// single processor instruction may end up outputting multiple
// different line numbers. So it's no longer possible to have a simple
// line number register, like it was in the second phase.
//
// Instead, the program stores an *approximation* of the line number,
// which is never allowed to differ by 100 or more from the "actual"
// line number; the bytecode program is responsible for fixing up the
// approximation to work out the correct line number to output (this
// allows the same CPU instruction to output digits from multiple
// different line numbers, because the bytecode is being interpreted
// in a SIMD way and thus different parts of the bytecode can fix the
// line number up differently within a single instruction.
//
// The line number is split over three processor registers:
// - LINENO_LOW: stores the line number modulo 200
// - LINENO_MID: stores the hundreds to billions digits
// - LINENO_TOP: stores the ten-billions and more significant digits
// (The parity of the 100s digit is duplicated between LINENO_MID and
// LINENO_LOW; this allows a faster algorithm for LINENO_MID updates.)
//
// Because there's only a need to be within 100 of the real line
// number, the algorithm for updating the line numbers doesn't need to
// run all that often (saving processor cycles); it runs once every
// 512 bytes of output, by simply adding a precalculated value
// (LINENO_LOW_INCR) to LINENO_LOW, then processing the carry to
// LINENO_MID (see later for LINENO_TOP). The amount by which the line
// number increases per 512 bytes of output is not normally going to
// be an integer; LINENO_LOW is therefore stored as a 64-bit fixpoint
// number (in which 2**64 represents "200", e.g. 2**63 would be the
// representation of "the line number is 100 mod 200"), in order to
// delay the accumulation of rounding errors as long as possible. It's
// being stored in a vector register, so there are four copies of its
// value; two of them have 50 (i.e 2**62) added, and two of them have
// 50 subtracted, in order to allow for more efficient code to handle
// the carry to LINENO_MID. Additionally, LINENO_LOW is interpreted as
// a signed number (an older version of this program was better at
// checking for signed than unsigned overflow and I had no reason to
// change).
//
// LINENO_LOW and LINENO_MID are reset every LINENO_WIDTH increase
// (this is because the program can calculate "past" the width
// increase due to not being able to break out of every instruction of
// the main loop, which may cause unwanted carries into LINENO_MID and
// force a reset).

.section .rodata
lineno_low_init:
.byte 0, 0, 0, 0, 0, 0, 0, 192
.byte 0, 0, 0, 0, 0, 0, 0, 64
.byte 0, 0, 0, 0, 0, 0, 0, 192
.byte 0, 0, 0, 0, 0, 0, 0, 64
.text
vmovdqa LINENO_LOW, LINENO_LOW_INIT

// %ecx is the number of bytes in 15 lines. That means that the number
// of 200-line units in 512 bytes is 38.4/%ecx, i.e. 384/(%ecx*10).
// Multiply by 2**64 (i.e. 384*2**64/(%ecx*10) to get LINENO_LOW_INCR.
lea %ecx, [%rcx + %rcx * 4]
add %ecx, %ecx
mov %edx, 384
xor %eax, %eax
div %rcx  // 128-bit divide, %rax = %rdx%rax / %rcx
vpxor LINENO_LOW_INCR, LINENO_LOW_INCR, LINENO_LOW_INCR
vpinsrq LINENO_LOW_INCRx, LINENO_LOW_INCRx, %rax, 0
vpermq LINENO_LOW_INCR, LINENO_LOW_INCR, 0

// LINENO_MID is almost stored in high-decimal, as four eight-digit
// numbers. However, the number represented is the closest line number
// that's 50 mod 100, stored as the two closest multiples of 100 (e.g.
// if the true line number is 235, it's approximated as 250 and then
// stored using the representations for 200 and 300), which is why
// LINENO_LOW needs the offsets of 50 and -50 to easily do a carry. A
// ymm vector holds four 64-bit numbers, two of which hold the value
// that's 0 mod 200, two which hold the value that's 100 mod 200. So
// carries on it are handled using a vector of mostly 246s, with 247s
// in the two locations which are always odd.
.section .rodata
lineno_mid_base:
.byte 246, 246, 246, 246, 246, 246, 246, 246
.byte 247, 246, 246, 246, 246, 246, 246, 246
.byte 246, 246, 246, 246, 246, 246, 246, 246
.byte 247, 246, 246, 246, 246, 246, 246, 246
.text

// This code is some fairly complex vector manipulation to initialise
// LINENO_MID to a power of 10 (handling the case where LINENO_WIDTH
// is so high that the hundreds to billions digits are all zeroes).
mov %edx, 1
mov %eax, 11
sub %eax, LINENO_WIDTHe
cmovbe %eax, %edx
shl %eax, 3
vpxor %xmm0, %xmm0, %xmm0
vpinsrq %xmm0, %xmm0, %rax, 0
vpermq %ymm0, %ymm0, 0
vpcmpeqb LINENO_MID, LINENO_MID, LINENO_MID
vpsrlq LINENO_MID, LINENO_MID, %xmm0
vpmaxub LINENO_MID, LINENO_MID_BASE, LINENO_MID
vpermq %ymm0, LINENO_MID_BASE, 0x55
vpsubb %ymm0, %ymm0, LINENO_MID_BASE
vpaddq LINENO_MID, LINENO_MID, %ymm0
vpmaxub LINENO_MID, LINENO_MID_BASE, LINENO_MID

// LINENO_TOP doesn't need to be initialized for new widths, because
// an overrun by 100 lines is possible, but by 10 billion lines isn't.
// The format consists of two 64-bit sections that hold high-decimal
// numbers (these are always the same as each other), and two that
// hold constants that are used by the bytecode generator.
.section .rodata
lineno_top_init:
.byte 198, 197, 196, 195, 194, 193, 192, 191
.byte 246, 246, 246, 246, 246, 246, 246, 246
.byte 190, 189, 188, 187, 186, 185, 184, 183
.byte 246, 246, 246, 246, 246, 246, 246, 246
.text

// When moving onto a new width, start at the start of the bytecode
// program.
mov BYTECODE_IP, BYTECODE_START


// Generating the bytecode program
//
// The bytecode format is very simple (in order to allow it to be
// interpreted in just a couple of machine instructions):
// - A negative byte represents a literal character (e.g. to produce
//   a literal 'F', you use the bytecode -'F', i.e. -70 = 0xba)
// - A byte 0..7 represents the hundreds..billions digit of the line
//   number respectively, and asserts that the hundreds digit of the
//   line number is even
// - A byte 8..15 represents the hundreds..billions digit of the line
//   number respectively, and asserts that the hundreds digit of the
//   line number is odd
//
// In other words, the bytecode program only ever needs to read from
// LINENO_MID; the information stored in LINENO_LOW and LINENO_TOP
// therefore has to be hardcoded into it. The program therefore needs
// to be able to generate 600 lines of output (as the smallest number
// that's divisible by 100 to be able to hardcode the two low digits,
// 200 to be able to get the assertions about the hundreds digits
// correct, and 3 and 5 to get the Fizzes and Buzzes in the right
// place).

generate_bytecode:

mov BYTECODE_GEN_PTR, BYTECODE_START

// FIZZ and BUZZ work just like in the second phase, except that they
// are now bytecode programs rather than ASCII.
mov FIZZ, 0xf6868697ba  // -"Fizz\n"
mov BUZZ, 0xf686868bbe  // -"Buzz\n"

// %ymm2 holds the bytecode for outputting the hundreds and more
// significant digits of a line number. The most significant digits of
// this can be obtained by converting LINENO_TOP from high-decimal to
// the corresponding bytecode, which is accomplished by subtracting
// from 198 (i.e. 256 - 10 - '0'). The constant parts of LINENO_TOP
// are 198 minus the bytecode for outputting the hundreds to billions
// digit of a number; this makes it possible for a single endian
// shuffle to deal with all 16 of the mid and high digits at once.
.section .rodata
bascii_offset:
.byte REP8(198), REP8(198), REP8(198), REP8(198)
.text
vpsubb %ymm2, BASCII_OFFSET, LINENO_TOP
vpshufb %ymm2, %ymm2, ENDIAN_SHUFFLE

#define GEN_FIZZ  mov [BYTECODE_GEN_PTR], FIZZ; add BYTECODE_GEN_PTR, 5
#define GEN_BUZZ  mov [BYTECODE_GEN_PTR], BUZZ; add BYTECODE_GEN_PTR, 5
#define GEN_FIZZBUZZ \
  mov [BYTECODE_GEN_PTR], FIZZe; \
  mov [BYTECODE_GEN_PTR + 4], BUZZ; add BYTECODE_GEN_PTR, 9
#define GEN_LINENO(units_digit) \
  vmovdqu [BYTECODE_GEN_PTR], %xmm2; \
  lea BYTECODE_GEN_PTR, [BYTECODE_GEN_PTR + LINENO_WIDTH + 1]; \
  mov [BYTECODE_GEN_PTR - 3], %al; \
  mov word ptr [BYTECODE_GEN_PTR - 2], 0xf6d0 - units_digit

// The bytecode generation loop is unrolled to depth 30, allowing the
// units digits to be hardcoded. The tens digit is stored in %al, and
// incremented every ten lines of output. The parity of the hundreds
// digit is stored in %ymm2: one half predicts the hundreds digit to
// be even, the other to be odd, and the halves are swapped every time
// the tens digit carries (ensuring the predictions are correct).
mov %eax, 0xd0
jmp 2f
inc_tens_digit:
cmp %al, 0xc7
je 1f  // jumps every 10th execution, therefore predicts perfectly
dec %eax
ret
1: mov %eax, 0xd0
vpermq %ymm2, %ymm2, 0x4e
ret

2: mov %ecx, 20
thirty_bytecode_lines:
GEN_BUZZ
GEN_LINENO(1)
GEN_FIZZ
GEN_LINENO(3)
GEN_LINENO(4)
GEN_FIZZBUZZ
GEN_LINENO(6)
GEN_LINENO(7)
GEN_FIZZ
GEN_LINENO(9)
call inc_tens_digit
GEN_BUZZ
GEN_FIZZ
GEN_LINENO(2)
GEN_LINENO(3)
GEN_FIZZ
GEN_BUZZ
GEN_LINENO(6)
GEN_FIZZ
GEN_LINENO(8)
GEN_LINENO(9)
call inc_tens_digit
GEN_FIZZBUZZ
GEN_LINENO(1)
GEN_LINENO(2)
GEN_FIZZ
GEN_LINENO(4)
GEN_BUZZ
GEN_FIZZ
GEN_LINENO(7)
GEN_LINENO(8)
GEN_FIZZ
call inc_tens_digit
dec %ecx
jnz thirty_bytecode_lines

generate_bytecode_overrun_area:

// Duplicate the first 512 bytes of the bytecode program at the end,
// so that there's no need to check to see whether BYTECODE_IP needs
// to be looped back to the start of the program any more than once
// per 512 bytes
mov %rax, BYTECODE_START
#define COPY_64_BYTECODE_BYTES(offset) \
  vmovdqa %ymm0, [%rax + offset]; \
  vmovdqa %ymm3, [%rax + (offset + 32)]; \
  vmovdqu [BYTECODE_GEN_PTR + offset], %ymm0; \
  vmovdqu [BYTECODE_GEN_PTR + (offset + 32)], %ymm3
COPY_64_BYTECODE_BYTES(0)
COPY_64_BYTECODE_BYTES(64)
COPY_64_BYTECODE_BYTES(128)
COPY_64_BYTECODE_BYTES(192)
COPY_64_BYTECODE_BYTES(256)
COPY_64_BYTECODE_BYTES(320)
COPY_64_BYTECODE_BYTES(384)
COPY_64_BYTECODE_BYTES(448)


// Preparing for the main loop
//
// Work out how long the main loop is going to iterate for.
// OUTPUT_LIMIT holds the address just beyond the end of the output
// that the main loop should produce. The aim here is to produce
// exactly one pipeful of data if possible, but to stop earlier if
// there's a change in digit width (because any output beyond that
// point will be useless: the bytecode will give it the wrong number
// of digits).
calculate_main_loop_iterations:

// Extract the pipe size from BYTECODE_START, in 32-byte units.
// During this calculation, OUTPUT_LIMIT holds the amount of output
// produced, rather than an address like normal.
mov OUTPUT_LIMIT, BYTECODE_START
lea %rdx, [%rip + iovec_base]
sub OUTPUT_LIMIT, %rdx
shr OUTPUT_LIMIT, 5

// Reduce the output limit to the end of this width, if it would be
// higher than that.
cmp OUTPUT_LIMIT, YMMS_AT_WIDTH
cmovae OUTPUT_LIMIT, YMMS_AT_WIDTH

// If there's already some output in the buffer, reduce the amount
// of additional output produced accordingly (whilst ensuring that
// a multiple of 512 bytes of output is produced).
//
// This would be buggy if the YMMS_AT_WIDTH limit were hit at the
// same time, but that never occurs as it would require two width
// changes within one pipeful of each other, and 9000000 lines of
// FizzBuzz is much more than a pipeful in size.
mov %rax, OUTPUT_PTR
and %eax, ((2 &lt;&lt; 20) - 1) &amp; -512
shr %eax, 5
sub OUTPUT_LIMIT, %rax

// The amount of output to produce is available now, and won't be
// later, so subtract it from the amount of output that needs to
// be produced now.
sub YMMS_AT_WIDTH, OUTPUT_LIMIT

// Return OUTPUT_LIMIT back to being a pointer, not an amount.
shl OUTPUT_LIMIT, 5
add OUTPUT_LIMIT, OUTPUT_PTR

prepare_main_loop_invariants:

// To save one instruction in the bytecode interpreter (which is very
// valuable, as it runs every second CPU cycle), LINENO_MID_TEMP is
// used to store a reformatted version of LINENO_MID, in which each
// byte is translated from high-decimal to ASCII, and the bytecode
// command that would access that byte is added to the result (e.g.
// the thousands digit for the hundreds-digits-odd version has 10
// added to convert from high-decimal to a pure number, '0' added to
// convert to ASCII, then 9 added because that's the bytecode command
// to access the thousands digit when the hundreds digit is odd, so
// the amount added is 10 + '0' + 9 = 57).
//
// LINENO_MID_TEMP is updated within the main loop, immediately after
// updating LINENO_MID, but because the bytecode interpreter reads
// from it it needs a valid value at the start of the loop.
.section .rodata
biascii_offset:
.byte 58, 59, 60, 61, 62, 63, 64, 65
.byte 66, 67, 68, 69, 70, 71, 72, 73
.byte 58, 59, 60, 61, 62, 63, 64, 65
.byte 66, 67, 68, 69, 70, 71, 72, 73
.text
vpaddb LINENO_MID_TEMP, BIASCII_OFFSET, LINENO_MID

// To save an instruction, precalculate minus the length of the
// bytecode. (Although the value of this is determined entirely by
// LINENO_WIDTH, the register it's stored in gets clobbered by
// system calls and thus needs to be recalculated each time.)
mov BYTECODE_NEG_LEN, BYTECODE_START
sub BYTECODE_NEG_LEN, BYTECODE_END


// The main loop

// The bytecode interpreter consists of four instructions:
// 1. Load the bytecode from memory into %ymm2;
// 2. Use it as a shuffle mask to shuffle LINENO_MID_TEMP;
// 3. Subtract the bytecode from the shuffle result;
// 4. Output the result of the subtraction.
//
// To see why this works, consider two cases. If the bytecode wants to
// output a literal character, then the shuffle will produce 0 for
// that byte (in AVX2, a shuffle with a a negative index produces an
// output of 0), and subtracting the bytecode from 0 then produces the
// character (because the bytecode encoded minus the character). If
// the bytecode instead wants to output a digit, then the shuffle will
// fetch the relevant digit from LINENO_MID_TEMP (which is the desired
// ASCII character plus the bytecode instruction that produces it),
// and subtract the bytecode instruction to just produce the character
// on its own.
//
// This produces an exactly correct line number as long as the line
// number approximation is within 100 of the true value: it will be
// correct as long as the relevant part of LINENO_MID is correct, and
// the worst case is for LINENO_MID to be storing, say, 200 and 300
// (the representation of 250) when the true line number is 400. The
// value in LINENO_MID specifically can be up to 50 away from the
// value of the line number as recorded by LINENO_MID and LINENO_LOW
// together, so as long as the line number registers are within 100,
// LINENO_MID will be within 150 (which is what is required).
//
// This doesn't update the bytecode instruction pointer or the pointer
// into the output buffer; those are updated once every 512 bytes (and
// to "advance the instruction pointer" the rest of the time, the main
// loop is unrolled, using hardcoded offsets with the pointer updates
// baked in).
//
// The bytecode instruction pointer itself is read from %rdx, not
// BYTECODE_IP, so that mid-loop arithmetic on BYTECODE_IP won't cause
// the interpreter to break.
//
// It's important to note one potential performance issue with this
// code: the read of the bytecode from memory is not only misalignable
// (`vmovdqu`); it splits a cache line 3/8 of the time. This causes L1
// split-load penalties on the 3/8 cycles where it occurs. I am not
// sure whether this actually reduces the program's performance in
// practice, or whether the split loads can be absorbed while waiting
// for writes to go through to the L2 cache. However, even if it does
// have a genuine performance cost, it seems like the least costly way
// to read the bytecode; structuring the bytecode to avoid split loads
// makes it take up substantially more memory, and the less cache that
// is used for the bytecode, the more that can be used for the output
// buffers. (In particular, increasing the bytecode to 2400 lines so
// that it's available at all four of the alignments required of it
// does not gain, because it then becomes so large that the processor
// struggles to keep it in L1 cache - it only just fits, and there
// isn't any way for it to know which parts of the cache are meant to
// stay in L1 and which are meant to leave to L2, so there's a large
// slowdown when it guesses wrong.)
#define INTERPRET_BYTECODE(bc_offset, buf_offset) \
  vmovdqu %ymm2, [%rdx + bc_offset]; \
  vpshufb %ymm0, LINENO_MID_TEMP, %ymm2; \
  vpsubb %ymm0, %ymm0, %ymm2; \
  vmovdqa [OUTPUT_PTR + buf_offset], %ymm0

// The main loop itself consists of sixteen uses of the bytecode
// interpreter, interleaved (to give the reorder buffer maximum
// flexibility) with all the other logic needed in the main loop.
// (Most modern processors can handle 4-6 instructions per clock cycle
// as long as they don't step on each others' toes; thus this loop's
// performance will be limited by the throughput of the L2 cache, with
// all the other work (bytecode interpretation, instruction decoding,
// miscellaneous other instructions, etc.) fitting into the gaps while
// the processor is waiting for the L2 cache to do its work.)

.p2align 5
main_loop:
// %rdx caches BYTECODE_IP's value at the start of the loop
mov %rdx, BYTECODE_IP
INTERPRET_BYTECODE(0, 0)

// %ymm1 caches LINENO_LOW's value at the start of the loop
vmovdqa %ymm1, LINENO_LOW
INTERPRET_BYTECODE(32, 32)

// Add LINENO_LOW_INCR to LINENO_LOW, checking for carry; it carried
// if the sign bit changed from 0 to 1. (vpandn is unintuitive; this
// is ~%ymm1 &amp; LINENO_LOW, not %ymm1 &amp; ~LINENO_LOW like the name
// suggests.)
vpaddq LINENO_LOW, LINENO_LOW_INCR, LINENO_LOW
INTERPRET_BYTECODE(64, 64)

vpandn %ymm3, %ymm1, LINENO_LOW
INTERPRET_BYTECODE(96, 96)

vpsrlq %ymm3, %ymm3, 63
INTERPRET_BYTECODE(128, 128)

// Add the carry to LINENO_MID (doubling it; LINENO_MID counts in
// units of 100 but a LINENO_LOW carry means 200).
vpaddb %ymm3, %ymm3, %ymm3
INTERPRET_BYTECODE(160, 160)

vpaddq LINENO_MID, LINENO_MID, %ymm3
INTERPRET_BYTECODE(192, 192)

vpmaxub LINENO_MID, LINENO_MID_BASE, LINENO_MID
INTERPRET_BYTECODE(224, 224)

// Update LINENO_MID_TEMP with the new value from LINENO_MID; this is
// the point at which the new value takes effect. This is done at the
// exact midpoint of the loop, in order to reduce the errors from
// updating once every 512 bytes as far as possible.
vpaddb LINENO_MID_TEMP, BIASCII_OFFSET, LINENO_MID
INTERPRET_BYTECODE(256, 256)

// Update the output and bytecode instruction pointers. The change to
// the output pointer kicks in immediately, but is cancelled out via
// the use of a negative offset until the end of the loop.
add OUTPUT_PTR, 512
INTERPRET_BYTECODE(288, -224)

add BYTECODE_IP, 512
INTERPRET_BYTECODE(320, -192)

// The change to the bytecode instruction pointer doesn't kick in
// immediately, because it might need to wrap back to the start (this
// can be done by adding BYTECODE_NEG_LEN to it); this is why the
// interpreter has a cached copy of it in %rdx.
lea %rax, [BYTECODE_IP + BYTECODE_NEG_LEN]
INTERPRET_BYTECODE(352, -160)

INTERPRET_BYTECODE(384, -128)
// Some modern processors can optimise `cmp` better if it appears
// immediately before the command that uses the comparison result, so
// a couple of commands have been moved slightly to put the `cmp` next
// to the use of its result. With modern out-of-order processors,
// there is only a marginal advantage to manually interleaving the
// instructions being used, and the `cmp` advantage outweighs that.
cmp BYTECODE_IP, BYTECODE_END

cmovae BYTECODE_IP, %rax
INTERPRET_BYTECODE(416, -96)

INTERPRET_BYTECODE(448, -64)

INTERPRET_BYTECODE(480, -32)
cmp OUTPUT_PTR, OUTPUT_LIMIT
jb main_loop

after_main_loop:
// There are two reasons the main loop might terminate: either there's
// a pipeful of output, or the line number has increased in width
// (forcing the generaion of new bytecode to put more digits in the
// numbers being printed). In the latter case, a) the output may have
// overrun slightly, and OUTPUT_PTR needs to be moved back to
// OUTPUT_LIMIT:
mov OUTPUT_PTR, OUTPUT_LIMIT
// and b) there may be less than a pipeful of output, in which case it
// wouldn't be safe to output it and the swap_buffers call needs to be
// skipped. Calculate the pipe size into %rax, the amount of output
// into %rdx (swap_buffers needs it there anyway), and compare.
lea %rax, [%rip + iovec_base]
sub %rax, BYTECODE_START
neg %eax
mov %rdx, OUTPUT_PTR
and %edx, (2 &lt;&lt; 20) - 1
cmp %edx, %eax
jb 1f
call swap_buffers

// If all the lines at this width have been exhausted, move to the
// next width.
1: test YMMS_AT_WIDTH, YMMS_AT_WIDTH
jnz check_lineno_top_carry

cmp LINENO_WIDTHe, 18  // third phase handles at most 18 digits
je fourth_phase

inc LINENO_WIDTHe
vpcmpeqb %ymm0, %ymm0, %ymm0
vpsubb ENDIAN_SHUFFLE, ENDIAN_SHUFFLE, %ymm0

lea GROUPS_OF_15, [GROUPS_OF_15 + GROUPS_OF_15 * 4]
add GROUPS_OF_15, GROUPS_OF_15

add BYTECODE_END, 320

jmp third_phase_per_width_init

// So far, the code has kept LINENO_MID and LINENO_LOW updated, but
// not LINENO_TOP. Because 10 billion lines of FizzBuzz don't normally
// have a length that's divisible by 512 (and indeed, vary in size a
// little because 10 billion isn't divisible by 15), it's possible for
// the 10-billions and higher digits to need to change in the middle
// of a main loop iteration - indeed, even in the middle of a single
// CPU instruction!
//
// It turns out that when discussing the line number registers above,
// I lied a little about the format. The bottom seven bytes of
// LINENO_MID do indeed represent the hundreds to hundred millions
// digits. However, the eighth changes in meaning over the course of
// the program. It does indeed represent the billions digit most of
// the time; but when the line number is getting close to a multiple
// of 10 billion, the billions and hundred-millions digits will always
// be the same as each other (either both 9s or both 0s). When this
// happens, the format changes: the hundred-millions digit of
// LINENO_MID represents *both* the hundred-millions and billions
// digits of the line number, and the top byte then represents the
// ten-billions digit. Because incrementing a number causes a row of
// consecutive 9s to either stay untouched, or all roll over to 0s at
// once, this effectively lets us do maths on more than 8 digits,
// meaning that the normal arithmetic code within the main loop can
// handle the ten-billions digit in addition to the digits below.
//
// Of course, the number printing code also needs to handle the new
// representation, but the number printing is done by a bytecode
// program, which can be made to output some of the digits being
// printed multiple times by repeating "print digit from LINENO_MID"
// commands within it. Those commands are generated from COUNTER_TOP
// anyway, so the program just changes the constant portion of
// COUNTER_TOP (and moves print-digit commands into the top half) in
// order to produce the appropriate bytecode changes.
//
// A similar method is used to handle carries in the hundred-billions,
// trillions, etc. digits.
//
// Incidentally, did you notice the apparent off-by-one in the
// initialisation of LINENO_MID within third_phase_per_width_init? It
// causes the "billions" digit to be initialised to 1 (not 0) when the
// line number width is 11 or higher. That's because the alternate
// representation will be in use during a line number width change (as
// higher powers of 10 are close to multiples of 10 billion), so the
// digit that's represented by that byte of LINENO_MID genuinely is a
// 1 rather than a 0.
check_lineno_top_carry:

// The condition to change line number format is:
// a) The line number is in normal format, and the hundred-millions
//    and billions digits are both 9; or
// b) The line number is in alternate format, and the hundred-millions
//    digit is 0.
// To avoid branchy code in the common case (when no format change is
// needed), REGEN_TRIGGER is used to store the specific values of the
// hundred-millions and billions digits that mean a change is needed,
// formatted as two repeats of billions, hundred-millions, 9, 9 in
// high-decimal (thus, when using normal format, REGEN_TRIGGER is
// high-decimal 99999999, i.e. -1 when interpreted as binary). The 9s
// are because vpshufd doesn't have very good resolution: the millions
// and ten-millions digits get read too, but can simply just be masked
// out. The two repeats are to ensure that both halves of LINENO_MID
// (the even-hundreds-digit and odd-hundreds-digit halves) have the
// correct value while changing (changing the format while half the
// register still ended ...98999999 would produce incorrect output).
vpshufd %xmm0, LINENO_MIDx, 0xED
vpextrq %rax, %xmm0, 0
mov %rdx, 0x0000ffff0000ffff
or %rax, %rdx
cmp %rax, REGEN_TRIGGER
jne calculate_main_loop_iterations

cmp REGEN_TRIGGER, -1
jne switch_to_normal_representation


switch_to_alternate_representation:
// Count the number of 9s at the end of LINENO_TOP. To fix an edge
// case, the top bit of LINENO_TOP is interpreted as a 0, preventing
// a 9 being recognised there (this causes 10**18-1 to increment to
// 10**17 rather than 10**18, but the program immediately exits
// before this can become a problem).
vpextrq %rdx, LINENO_TOPx, 1
mov SPILL, %rdx
shl %rdx, 1
shr %rdx, 1
not %rdx
bsf %rcx, %rdx
and %rcx, -8

// Change the format of LINENO_TOP so that the digit above the
// consecutive 9s becomes a reference to the top byte of LINENO_MID,
// and the 9s themselves references to the hundred-millions digit.
// This is done via a lookup table that specifies how to move the
// bytes around.
.section .rodata
alternate_representation_lookup_table:
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 7, 9, 10, 11, 12, 13, 14, 15
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 7, 9, 10, 11, 12, 13, 14, 15

.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 7, 10, 11, 12, 13, 14, 15
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 7, 10, 11, 12, 13, 14, 15

.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 7, 11, 12, 13, 14, 15
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 7, 11, 12, 13, 14, 15

.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 7, 12, 13, 14, 15
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 7, 12, 13, 14, 15

.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 7, 13, 14, 15
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 7, 13, 14, 15

.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 6, 7, 14, 15
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 6, 7, 14, 15

.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 6, 6, 7, 15
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 6, 6, 7, 15

.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 6, 6, 6, 7
.byte 0, 1, 2, 3, 4, 5, 6, 6
.byte 6, 6, 6, 6, 6, 6, 6, 7
.text

lea %rax, [%rip + alternate_representation_lookup_table]
vpshufb LINENO_TOP, LINENO_TOP, [%rax + 4 * %rcx]

// The top byte of LINENO_MID also needs the appropriate digit of
// LINENO_TOP placed there.
mov %rdx, SPILL
shr %rdx, %cl
vpinsrb LINENO_MIDx, LINENO_MIDx, %edx, 7
vpinsrb LINENO_MIDx, LINENO_MIDx, %edx, 15
vpermq LINENO_MID, LINENO_MID, 0x44

// Finally, REGEN_TRIGGER needs to store the pattern of digits that
// will prompt a shift back to the normal representation (the hundred-
// millions digit must be 0, and the value of the billions digit will
// be predictable).
inc %edx
shl %edx, 24
or %edx, 0xF6FFFF
mov REGEN_TRIGGERe, %edx
shl %rdx, 32
or REGEN_TRIGGER, %rdx
jmp generate_bytecode


switch_to_normal_representation:
// Switching back is fairly easy: LINENO_TOP can almost be converted
// back into its usual format by running the bytecode program stored
// there to remove any unusual references into LINENO_MID, then
// restoring the usual references manually. Running the program will
// unfortunately convert high-decimal to ASCII (or in this case zeroes
// because there's no need to do the subtraction), but that can be
// worked around by taking the bytewise maximum of the converted and
// original LINENO_TOP values (high-decimal is higher than bytecode
// references and much higher than zero).
vpsubb %ymm2, BASCII_OFFSET, LINENO_TOP
vpshufb %ymm0, LINENO_MID, %ymm2
vpmaxub LINENO_TOP, LINENO_TOP, %ymm0

// Manually fix the constant parts of lineno_top to contain their
// usual constant values
.section .rodata
lineno_top_max:
.byte 198, 197, 196, 195, 194, 193, 192, 191
.byte 255, 255, 255, 255, 255, 255, 255, 255
.byte 190, 189, 188, 187, 186, 185, 184, 183
.byte 255, 255, 255, 255, 255, 255, 255, 255
.text
vpminub LINENO_TOP, LINENO_TOP_MAX, LINENO_TOP

// The billions digit of LINENO_MID needs to be set back to 0 (which
// is its true value at this point: the same as the hundred-thousands
// digit, which is also 0).
vpsllq LINENO_MID, LINENO_MID, 8
vpsrlq LINENO_MID, LINENO_MID, 8
vpmaxub LINENO_MID, LINENO_MID_BASE, LINENO_MID

mov REGEN_TRIGGER, -1

jmp generate_bytecode


///// Fourth phase
//
// Ending at 999999999999999999 lines would be a little unsatisfying,
// so here's a routine to write the quintillionth line and exit.
//
// It's a "Buzz", which we can steal from the first phase's constant.

fourth_phase:

mov ARG1e, 1
lea ARG2, [%rip + fizzbuzz_intro + 11]
mov ARG3, 5
mov SYSCALL_NUMBER, __NR_write
syscall
call exit_on_error
xor ARG1e, ARG1e
jmp exit


///// Error handling code
//
// This doesn't run in a normal execution of the program, and isn't
// particularly optimised; I didn't comment it much because it isn't
// very interesting and also is fairly self-explanatory.

write_stderr:
mov ARG1e, 2
mov SYSCALL_NUMBER, __NR_write
syscall
ret

inefficiently_write_as_hex:
push %rax
push %rcx
shr %rax, %cl
and %rax, 0xF
.section .rodata
hexdigits: .ascii "0123456789ABCDEF"
.text
lea %rcx, [%rip + hexdigits]
movzx %rax, byte ptr [%rcx + %rax]
mov [%rip + error_write_buffer], %al
lea ARG2, [%rip + error_write_buffer]
mov ARG3e, 1
call write_stderr
pop %rcx
pop %rax
sub %ecx, 4
jns inefficiently_write_as_hex
ret

exit_on_error:
test SYSCALL_RETURN, SYSCALL_RETURN
js 1f
ret

.section .rodata
error_message_part_1: .ascii "Encountered OS error 0x"
error_message_part_2: .ascii " at RIP 0x"
error_message_part_3: .ascii ", exiting program.\n"
.text

1: push SYSCALL_RETURN
lea ARG2, [%rip + error_message_part_1]
mov ARG3e, 23
call write_stderr
pop SYSCALL_RETURN
neg SYSCALL_RETURN
mov %rcx, 8
call inefficiently_write_as_hex
lea ARG2, [%rip + error_message_part_2]
mov ARG3e, 10
call write_stderr
pop %rax  // find the caller's %rip from the stack
sub %rax, 5  // `call exit_on_error` compiles to 5 bytes
mov %rcx, 60
call inefficiently_write_as_hex
lea ARG2, [%rip + error_message_part_3]
mov ARG3e, 19
call write_stderr
mov ARG1e, 74
// fall through

exit:
mov SYSCALL_NUMBER, __NR_exit_group
syscall
ud2

.section .rodata
cpuid_error_message:
.ascii "Error: your CPUID command does not support command "
.ascii "0x80000006 (AMD-style L2 cache information).\n"
.text
bad_cpuid_error:
lea ARG2, [%rip + cpuid_error_message]
mov ARG3e, 96
call write_stderr
mov ARG1e, 59
jmp exit

.section .rodata
pipe_error_message:
.ascii "This program can only output to a pipe "
.ascii "(try piping into `cat`?)\n"
.text
pipe_error:
lea ARG2, [%rip + pipe_error_message]
mov ARG3e, 64
call write_stderr
mov ARG1e, 73
jmp exit

.section .rodata
pipe_perm_error_message_part_1:
.ascii "Cannot allocate a sufficiently large kernel buffer.\n"
.ascii "Try setting /proc/sys/fs/pipe-max-size to 0x"
pipe_perm_error_message_part_2: .ascii ".\n"
.text
pipe_perm_error:
lea ARG2, [%rip + pipe_perm_error_message_part_1]
mov ARG3e, 96
call write_stderr
mov %rax, PIPE_SIZE
mov %ecx, 28
call inefficiently_write_as_hex
lea ARG2, [%rip + pipe_perm_error_message_part_2]
mov ARG3e, 2
call write_stderr
mov ARG1e, 77
jmp exit

.section .rodata
pipe_size_error_message_part_1:
.ascii "Failed to resize the kernel pipe buffer.\n"
.ascii "Requested size: 0x"
pipe_size_error_message_part_2: .ascii "\nActual size: 0x"
pipe_size_error_message_part_3:
.ascii "\n(If the buffer is too large, this may cause errors;"
.ascii "\nthe program could run too far ahead and overwrite"
.ascii "\nmemory before it had been read from.)\n"
.text
pipe_size_mismatch_error:
push SYSCALL_RETURN
lea ARG2, [%rip + pipe_size_error_message_part_1]
mov ARG3e, 59
call write_stderr
mov %rax, PIPE_SIZE
mov %ecx, 28
call inefficiently_write_as_hex
lea ARG2, [%rip + pipe_size_error_message_part_2]
mov ARG3e, 16
call write_stderr
pop %rax
mov %ecx, 28
call inefficiently_write_as_hex
lea ARG2, [%rip + pipe_size_error_message_part_3]
mov ARG3e, 141
call write_stderr
mov ARG1e, 73
jmp exit
</code></pre>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla on track to smash targets after producing almost a million EVs in 6 months (136 pts)]]></title>
            <link>https://thedriven.io/2023/07/03/tesla-on-track-to-smash-targets-after-producing-almost-a-million-evs-in-first-6-months/</link>
            <guid>36567725</guid>
            <pubDate>Mon, 03 Jul 2023 01:43:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thedriven.io/2023/07/03/tesla-on-track-to-smash-targets-after-producing-almost-a-million-evs-in-first-6-months/">https://thedriven.io/2023/07/03/tesla-on-track-to-smash-targets-after-producing-almost-a-million-evs-in-first-6-months/</a>, See on <a href="https://news.ycombinator.com/item?id=36567725">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

		
		<main id="main" role="main">

			
			
				
				<article id="post-170072">
				

							
			<section>
		<figure>
			<a href="https://thedriven.io/wp-content/uploads/2023/07/Tesla-Q2-results_03.jpg">
				<img width="800" height="437" src="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-800x437.jpg?lossy=1&amp;strip=0&amp;webp=1" alt="Tesla Model 3" decoding="async" loading="lazy" data-srcset="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-90x49.jpg?lossy=1&amp;strip=0&amp;webp=1 90w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-120x66.jpg?lossy=1&amp;strip=0&amp;webp=1 120w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-150x82.jpg?lossy=1&amp;strip=0&amp;webp=1 150w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-180x98.jpg?lossy=1&amp;strip=0&amp;webp=1 180w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-240x131.jpg?lossy=1&amp;strip=0&amp;webp=1 240w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-300x164.jpg?lossy=1&amp;strip=0&amp;webp=1 300w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-320x175.jpg?lossy=1&amp;strip=0&amp;webp=1 320w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-388x212.jpg?lossy=1&amp;strip=0&amp;webp=1 388w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03.jpg?size=464x253&amp;lossy=1&amp;strip=0&amp;webp=1 464w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-560x306.jpg?lossy=1&amp;strip=0&amp;webp=1 560w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-640x350.jpg?lossy=1&amp;strip=0&amp;webp=1 640w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03.jpg?size=696x380&amp;lossy=1&amp;strip=0&amp;webp=1 696w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-800x437.jpg?lossy=1&amp;strip=0&amp;webp=1 800w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-1120x612.jpg?lossy=1&amp;strip=0&amp;webp=1 1120w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-1160x634.jpg?lossy=1&amp;strip=0&amp;webp=1 1160w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03.jpg?lossy=1&amp;strip=0&amp;webp=1 1200w" data-sizes="(max-width: 800px) 100vw, 800px" data-src="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_03-800x437.jpg?lossy=1&amp;strip=0&amp;webp=1">			</a>
						<figcaption>Tesla Model 3. Source: Unsplash – Vlad Tchompalov</figcaption>
					</figure>
	</section>

					<div>

										
			
							<section>

								<p>Tesla produced 479,700 electric vehicles in the second quarter of 2023 and delivered 466,140, smashing both quarterly production and sales records.</p>
<p>For the first half of the year Tesla has produced 920,508 EVs meaning the company is well placed to achieve its target of producing 2 million in 2023.</p>
<p>As expected, the Model 3 and Model Y made up 96% of Tesla’s production, with the Model S and X flagship cars accounting for just 4%.</p>
<p>Tesla’s Q2 sales were up 10% quarter-on-quarter from Q1’s previous record of 422,875. Year-on-year Q2 sales were up a staggering 83% over Q2 2022, as shown in the graph below from <a href="https://twitter.com/piloly/status/1675535815164805121">Roland Pircher.</a></p>

<figure id="attachment_170076" aria-describedby="caption-attachment-170076"><a href="https://thedriven.io/wp-content/uploads/2023/07/Tesla-Q2-results_01.jpg"><img loading="lazy" decoding="async" src="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01.jpg?lossy=1&amp;strip=0&amp;webp=1" alt="Tesla global quarterly sales" width="1200" height="675" srcset="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-90x51.jpg?lossy=1&amp;strip=0&amp;webp=1 90w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-120x68.jpg?lossy=1&amp;strip=0&amp;webp=1 120w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-150x84.jpg?lossy=1&amp;strip=0&amp;webp=1 150w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-180x101.jpg?lossy=1&amp;strip=0&amp;webp=1 180w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-240x135.jpg?lossy=1&amp;strip=0&amp;webp=1 240w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-300x169.jpg?lossy=1&amp;strip=0&amp;webp=1 300w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-320x180.jpg?lossy=1&amp;strip=0&amp;webp=1 320w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-388x218.jpg?lossy=1&amp;strip=0&amp;webp=1 388w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01.jpg?size=464x261&amp;lossy=1&amp;strip=0&amp;webp=1 464w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-560x315.jpg?lossy=1&amp;strip=0&amp;webp=1 560w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-640x360.jpg?lossy=1&amp;strip=0&amp;webp=1 640w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01.jpg?size=696x392&amp;lossy=1&amp;strip=0&amp;webp=1 696w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-800x450.jpg?lossy=1&amp;strip=0&amp;webp=1 800w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01.jpg?size=928x522&amp;lossy=1&amp;strip=0&amp;webp=1 928w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-1120x630.jpg?lossy=1&amp;strip=0&amp;webp=1 1120w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-1160x653.jpg?lossy=1&amp;strip=0&amp;webp=1 1160w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01.jpg?lossy=1&amp;strip=0&amp;webp=1 1200w" sizes="(max-width: 1160px) 100vw, 1160px" data-old-src="https://thedriven.io/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-srcset="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-90x51.jpg?lossy=1&amp;strip=0&amp;webp=1 90w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-120x68.jpg?lossy=1&amp;strip=0&amp;webp=1 120w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-150x84.jpg?lossy=1&amp;strip=0&amp;webp=1 150w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-180x101.jpg?lossy=1&amp;strip=0&amp;webp=1 180w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-240x135.jpg?lossy=1&amp;strip=0&amp;webp=1 240w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-300x169.jpg?lossy=1&amp;strip=0&amp;webp=1 300w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-320x180.jpg?lossy=1&amp;strip=0&amp;webp=1 320w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-388x218.jpg?lossy=1&amp;strip=0&amp;webp=1 388w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01.jpg?size=464x261&amp;lossy=1&amp;strip=0&amp;webp=1 464w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-560x315.jpg?lossy=1&amp;strip=0&amp;webp=1 560w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-640x360.jpg?lossy=1&amp;strip=0&amp;webp=1 640w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01.jpg?size=696x392&amp;lossy=1&amp;strip=0&amp;webp=1 696w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-800x450.jpg?lossy=1&amp;strip=0&amp;webp=1 800w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01.jpg?size=928x522&amp;lossy=1&amp;strip=0&amp;webp=1 928w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-1120x630.jpg?lossy=1&amp;strip=0&amp;webp=1 1120w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01-1160x653.jpg?lossy=1&amp;strip=0&amp;webp=1 1160w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01.jpg?lossy=1&amp;strip=0&amp;webp=1 1200w" data-src="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_01.jpg?lossy=1&amp;strip=0&amp;webp=1"></a><figcaption id="caption-attachment-170076">Tesla global quarterly sales. Source: <a href="https://twitter.com/piloly/status/1675535815164805121">@piloly</a></figcaption></figure>
<p>Looking at production in Q2, Tesla produced 479,700 EVs, up 13% on Q1’s figure of 440,808. If Tesla can maintain that level of quarter-on-quarter production growth for the rest of this year, it will hit around 542,000 for Q3 and 612,500 for Q4.</p>
<p>This will put total 2023 production numbers at around 2.1 million, exceeding Tesla’s stated goal of 1.8 to 2 million.</p>
<p>If Tesla does manage to produce 2.1 million EVs for 2023, it will represent an annualised growth rate of around 60%, which is also above Tesla’s long-term target of 50% annualised production growth.</p>
<p>To get a sense of Tesla’s exponential sales growth, James Stephenson graphed Q2 trailing 12-month global deliveries over the past 10 years.</p>
<p>Based the Q2 trailing 12-month figures, Tesla sales grew 47% in 2022-23, 58% in 2021-22 and 82% in 2020-21.</p>

<figure id="attachment_170078" aria-describedby="caption-attachment-170078"><a href="https://thedriven.io/wp-content/uploads/2023/07/Tesla-Q2-results_02.jpg"><img loading="lazy" decoding="async" src="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02.jpg?lossy=1&amp;strip=0&amp;webp=1" alt="Trailing 12-month global Tesla deliveries Q2 2013 to Q2 2023" width="1047" height="1408" srcset="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-90x120.jpg?lossy=1&amp;strip=0&amp;webp=1 90w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-120x160.jpg?lossy=1&amp;strip=0&amp;webp=1 120w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-150x202.jpg?lossy=1&amp;strip=0&amp;webp=1 150w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-180x242.jpg?lossy=1&amp;strip=0&amp;webp=1 180w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-240x323.jpg?lossy=1&amp;strip=0&amp;webp=1 240w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-297x400.jpg?lossy=1&amp;strip=0&amp;webp=1 297w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-300x403.jpg?lossy=1&amp;strip=0&amp;webp=1 300w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-320x430.jpg?lossy=1&amp;strip=0&amp;webp=1 320w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02.jpg?size=464x624&amp;lossy=1&amp;strip=0&amp;webp=1 464w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-560x753.jpg?lossy=1&amp;strip=0&amp;webp=1 560w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-640x861.jpg?lossy=1&amp;strip=0&amp;webp=1 640w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02.jpg?size=696x936&amp;lossy=1&amp;strip=0&amp;webp=1 696w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-800x1076.jpg?lossy=1&amp;strip=0&amp;webp=1 800w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02.jpg?size=928x1248&amp;lossy=1&amp;strip=0&amp;webp=1 928w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02.jpg?lossy=1&amp;strip=0&amp;webp=1 1047w" sizes="(max-width: 1047px) 100vw, 1047px" data-old-src="https://thedriven.io/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-srcset="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-90x120.jpg?lossy=1&amp;strip=0&amp;webp=1 90w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-120x160.jpg?lossy=1&amp;strip=0&amp;webp=1 120w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-150x202.jpg?lossy=1&amp;strip=0&amp;webp=1 150w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-180x242.jpg?lossy=1&amp;strip=0&amp;webp=1 180w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-240x323.jpg?lossy=1&amp;strip=0&amp;webp=1 240w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-297x400.jpg?lossy=1&amp;strip=0&amp;webp=1 297w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-300x403.jpg?lossy=1&amp;strip=0&amp;webp=1 300w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-320x430.jpg?lossy=1&amp;strip=0&amp;webp=1 320w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02.jpg?size=464x624&amp;lossy=1&amp;strip=0&amp;webp=1 464w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-560x753.jpg?lossy=1&amp;strip=0&amp;webp=1 560w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-640x861.jpg?lossy=1&amp;strip=0&amp;webp=1 640w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02.jpg?size=696x936&amp;lossy=1&amp;strip=0&amp;webp=1 696w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02-800x1076.jpg?lossy=1&amp;strip=0&amp;webp=1 800w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02.jpg?size=928x1248&amp;lossy=1&amp;strip=0&amp;webp=1 928w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02.jpg?lossy=1&amp;strip=0&amp;webp=1 1047w" data-src="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/07/Tesla-Q2-results_02.jpg?lossy=1&amp;strip=0&amp;webp=1"></a><figcaption id="caption-attachment-170078">Trailing 12-month global Tesla deliveries Q2 2013 to Q2 2023. Source: <a href="https://twitter.com/ICannot_Enough/status/1675543214638465026">@ICannot_Enough</a></figcaption></figure>

<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img loading="lazy" src="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442.jpeg?lossy=1&amp;strip=0&amp;webp=1" width="100" height="100" alt="Daniel Bleakley Profile Picture" itemprop="image" srcset="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442-80x80.jpeg?lossy=1&amp;strip=0&amp;webp=1 80w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442-90x90.jpeg?lossy=1&amp;strip=0&amp;webp=1 90w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442-120x120.jpeg?lossy=1&amp;strip=0&amp;webp=1 120w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442-160x160.jpeg?lossy=1&amp;strip=0&amp;webp=1 160w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442-180x180.jpeg?lossy=1&amp;strip=0&amp;webp=1 180w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442-240x240.jpeg?lossy=1&amp;strip=0&amp;webp=1 240w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442-320x320.jpeg?lossy=1&amp;strip=0&amp;webp=1 320w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442-388x388.jpeg?lossy=1&amp;strip=0&amp;webp=1 388w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442.jpeg?size=464x464&amp;lossy=1&amp;strip=0&amp;webp=1 464w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442-560x560.jpeg?lossy=1&amp;strip=0&amp;webp=1 560w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442-640x640.jpeg?lossy=1&amp;strip=0&amp;webp=1 640w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442.jpeg?size=696x696&amp;lossy=1&amp;strip=0&amp;webp=1 696w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442.jpeg?lossy=1&amp;strip=0&amp;webp=1 800w" sizes="(max-width: 800px) 100vw, 800px" data-old-src="https://thedriven.io/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2023/01/1667258499442.jpeg?size=100x100&amp;lossy=1&amp;strip=0&amp;webp=1"></p><div><p>Daniel Bleakley is a clean technology researcher and advocate with a background in engineering and business. He has a strong interest in electric vehicles, renewable energy, manufacturing and public policy.</p></div></div><!-- AI CONTENT END 1 -->

								
							</section>

										
			
						</div><!-- .entry-wrap -->

					


				</article>

				
				
			
		</main>

		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lumia WOA Project – Windows 10 or Windows 11 Desktop OS for Lumia 950/XL (117 pts)]]></title>
            <link>https://woa-project.github.io/LumiaWOA/</link>
            <guid>36566999</guid>
            <pubDate>Sun, 02 Jul 2023 23:42:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://woa-project.github.io/LumiaWOA/">https://woa-project.github.io/LumiaWOA/</a>, See on <a href="https://news.ycombinator.com/item?id=36566999">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-role="main">
        <div id="hero">
            <p>
                
                <h4>Full Windows for Lumia</h4>
            </p>
        </div>
        <div>
                <h3>Caution</h3>
                <h6>Experimental firmware ahead</h6>
                <p>The firmware provided is for testing purposes only. We aren't responsible for any data loss caused by
                    the firmware images. Make backups of your data prior to installing.</p>
                <p><strong>This software has not been approved for use with emergency services. By installing this
                        software, you agree to not use it as your primary phone device due to possible disruption in
                        emergency service access.</strong></p>
            </div>
        <div>
            <r-grid columns="2">
                <r-cell span-s="row">
                    
                    <h2>The Windows You Know and Love</h2>
                    <p>This project brings the Windows 10 or Windows 11 desktop operating system to your Lumia 950 and Lumia 950 XL.
                    </p>
                    <p>It's the same edition of Windows you're used to on your traditional laptop or desktop
                        computer, but it's the version for ARM64 (armv8a) processors.</p>
                    <p>It can run ARM64, ARM, x86 and x64 applications (the last two via emulation) just fine.<sup>1</sup></p>
                </r-cell>
                <r-cell span-s="row">
                    <figure>
                        <div>
                            <picture>
                                <source srcset="https://woa-project.github.io/LumiaWOA/img/Desktop.webp" type="image/webp">
                                <img loading="lazy" src="https://woa-project.github.io/LumiaWOA/img/Desktop.png" alt="A Lumia 950">
                            </picture>
                            
                        </div>
                    </figure>
                </r-cell>
            </r-grid>
        </div>
        <div>
            <figure>
                <div>
                    <picture>
                        <source srcset="https://woa-project.github.io/LumiaWOA/img/phone_continuum.webp" type="image/webp">
                        <img loading="lazy" src="https://woa-project.github.io/LumiaWOA/img/phone_continuum.png" alt="A Lumia 950">
                    </picture>
                    
                </div>
            </figure>
            <div>
                <h2></h2>
                <h2>With Continuum<sup>2</sup></h2>
                <figure>
                    <p><img src="https://woa-project.github.io/LumiaWOA/img/desktop_continuum.png">
                        
                    </p>
                </figure>
            </div>
        </div>
        <r-grid columns="2">
            <r-cell span="1" span-s="row">
                <h2></h2>
                <h2>A Mobile Twist</h2>
                <div>
                    <p>MobileShell is a fully-featured adaptive shell aiming to mimic the appearance of Windows
                        Mobile.</p>
                    <p>MobileShell brings back the navigation bar, status bar, puts your notification toasts at the top,
                        status icons at a glance, and activates only when your phone is in tablet mode.</p>
                        
                </div>
            </r-cell>
            <r-cell span="1" span-s="row">
                <figure>
                    <div>
                        <picture>
                            <source srcset="https://woa-project.github.io/LumiaWOA/img/MobilePortrait.webp" type="image/webp">
                            <img loading="lazy" src="https://woa-project.github.io/LumiaWOA/img/MobilePortrait.png" alt="A Lumia 950">
                        </picture>
                        
                    </div>
                </figure>
            </r-cell>
            <r-cell span="1" span-s="row">
                <figure>
                    <p><img src="https://woa-project.github.io/LumiaWOA/img/MobileLandscape.png">
                        
                    </p>
                </figure>
            </r-cell>
            <r-cell span="1" span-s="row">
                <p>MobileShell also supports landscape mode, adjusting perfectly to the phone's current state. Mobile
                    Shell is made by @ADeltaX and is included by default! You can also download it from the Microsoft
                    Store:</p>
                
            </r-cell>
        </r-grid>
        <div>
            <r-grid columns="2">
                <r-cell span-s="row">
                    <h2></h2>
                    <h2>Say Hello...<sup>3</sup></h2>
                    <div>
                        <p>This project backports the cellular stack from Windows 10 Mobile to Windows desktop. On
                            supported versions of Windows, you can make calls, texts, and browse the internet using a
                            cellular connection.</p>
                        <p>Dialer (previously WOA Dialer) is our custom app that allows you to make and manage calls on your device. 
                            Dialer is bundled with the project by default, along with the classic Microsoft Phone app.</p>
                    </div>
                    
                </r-cell>
                <r-cell span-s="row">
                    <figure>
                        <div>
                            <picture>
                                <source srcset="https://woa-project.github.io/LumiaWOA/img/Dialer.webp" type="image/webp">
                                <img loading="lazy" src="https://woa-project.github.io/LumiaWOA/img/Dialer.png" alt="A Lumia 950">
                            </picture>
                            
                        </div>
                    </figure>
                </r-cell>
            </r-grid>
        </div>
        <div>
            <r-grid columns="2">
                <r-cell span-s="row">
                    <figure>
                        <div>
                            <picture>
                                <source srcset="https://woa-project.github.io/LumiaWOA/img/Chat.webp" type="image/webp">
                                <img loading="lazy" src="https://woa-project.github.io/LumiaWOA/img/Chat.png" alt="A Lumia 950">
                            </picture>
                            
                        </div>
                    </figure>
                </r-cell>
                <r-cell span-s="row">
                    <h2></h2>
                    <h2>...Or Send a Message<sup>3</sup></h2>
                    <p>With the Chat application, you can recieve and send SMS messages. MMS messages remain unsupported
                        as of now.</p>
                    
                </r-cell>
            </r-grid>
        </div>
        <r-grid columns="2">
            <r-cell span="1-2" span-s="row">
                <h2>And Much More!</h2>
            </r-cell>
            <r-cell span-s="row">
                <h4>WOA Deployer</h4>
                <p>WOA Deployer allows you to deploy with ease Windows Desktop to your device, and enabling Dual Boot
                    with 2 clicks. You can pick the windows release you want, the language you want.</p>
                <a href="https://github.com/WOA-Project/WOA-Deployer-Lumia">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>BootShim</h4>
                <p>BootShim is the UEFI bootstraper. It escalates the SoC to AArch64 and starts our UEFI.</p>
                <a href="https://github.com/imbushuo/boot-shim">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>Lumia950XlPkg</h4>
                <p>Lumia950XlPkg is our EDK2 port for the Lumia 950 and Lumia 950 XL. It enables us to bootstrap Windows
                    10/11 Desktop for ARM64 processors on the Lumia.</p>
                <a href="https://github.com/WOA-Project/Lumia950XLPkg">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>Lumia Drivers</h4>
                <p>Lumia Drivers is the repository hosting all driver files for Windows, and INF files which had to be
                    recreated. Some additional driver patching is also done here to make things work the way they
                    should.</p>
                <a href="https://github.com/WOA-Project/Lumia-Drivers">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>Lumia USB-C</h4>
                <p>Lumia USB-C is the recreation of the USB C driver for Lumia devices. The Lumia 950 USB-C solution is
                    proprietary and personalized, thus the need for a custom driver.</p>
                <a href="https://github.com/WOA-Project/LumiaUSBC">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>Color Profile</h4>
                <p>Color Profile is the stack managing the personalization of the display color tint, saturation and
                    contrast.</p>
                <a href="https://github.com/WOA-Project/ColorProfile">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>Advanced Info</h4>
                <p>Advanced Info displays information about your device, within the settings app.</p>
                <a href="https://github.com/WOA-Project/AdvancedInfo">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>Airwaves</h4>
                <p>Airwaves allows you to listen to FM radio, right from your phone.</p>
                <a href="https://github.com/tigerw/FM-Radio-Frontend">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>RIL Init Service</h4>
                <p>RIL Init Service allows you to have the Radio Interface Layer initialized on newer versions of
                    Windows 10/11.</p>
                <a href="https://github.com/WOA-Project/RILServiceInit">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>Auto Brightness Service</h4>
                <p>The auto brightness service allows you to have automatic brightness on your device.</p>
                <a href="https://github.com/WOA-Project/AutoBrightnessSvc">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>Auto Rotation Service</h4>
                <p>The auto rotation service allows you to have automatic rotation on your device.</p>
                <a href="https://github.com/WOA-Project/AutoRotate">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>Vibrations</h4>
                <p>The vibration stack allows you to have haptic vibrations once you get a notification, and control the
                    intensity of the vibration via a settings application.</p>
                <a href="https://github.com/WOA-Project/VibrationSettings">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>USB Function Mode Switcher</h4>
                <p>USB Function Mode Switcher allows you to switch USB function modes.</p>
                <a href="https://github.com/WOA-Project/USBFunctionModeSwitcher">View on
                    GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>Data Management Service</h4>
                <p>The data management service enables cellular data connections automatically.</p>
                <a href="https://github.com/WOA-Project/DataManagementSvc">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>Power Supply Notifier</h4>
                <p>Power Supply Notifier plays a sound when your device starts charging.</p>
                <a href="https://github.com/WOA-Project/PowerSupplyNotifier">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>SynapticsTouch</h4>
                <p>The Synaptics Touch driver enables touch on your device</p>
                <a href="https://github.com/imbushuo/SynapticsTouch">View on GitHub</a>
            </r-cell>
            <r-cell span-s="row">
                <h4>Display Dock Flyout</h4>
                <p>The Display Dock Flyout displays information about a connected Display Dock (HD-500)</p>
                <a href="https://github.com/WOA-Project/DisplayDockFlyout">View on GitHub</a>
            </r-cell>
        </r-grid>
        <div>
            <p><sup>1</sup> Applications compiled for the AMD64/x86-64 architecture are 
                supported only on build 21277+.</p>
            <p><sup>2</sup> Continuum currently only works wirelessly over Miracast.</p>
            <p><sup>3</sup> Cellular support is still unfinished and might be broken in some
                areas. Cellular calls are automatically enabled in up to Windows 10 November 2019 Update (version 19H2, build
                18363). Versions higher than this will <strong>only</strong> support cellular data. You can manually enable 
                calls on builds higher than 18363 by using <a href="https://woa-project.github.io/LumiaWOA/guides/ican0/">this guide</a>. SMS are supported up to Windows 10 November 2019 Update 
                (version 19H2, build 18363). Dual SIM devices may have issues fetching the default Carrier APN settings, a provisioning 
                package for APN may be required. The advanced settings page for Cellular in the Windows Settings app may crash. 
                Your experience will vary between carriers and devices. This software stack has not been approved for use with emergency services.
                As a consequence <strong>it should not be used as your primary way of communication</strong>. VoLTE (IMS) stack while
                present is not functional.</p>
        </div>
    </div><div>
            <p>© 2017-2021 The Lumia WOA Authors</p>
            <p>Snapdragon is a registered trademark of Qualcomm Incorporated. Microsoft, the Microsoft Corporate Logo,
                Windows, Lumia, Windows Hello, Continuum, Hyper-V, and DirectX are registered trademarks of Microsoft
                Corporation in the United States. Miracast is a registered trademark of the Wi-Fi Alliance. Other
                binaries may be copyright Qualcomm Incorporated and Microsoft Mobile.</p>
            <p>Hello from San Francisco (US), France, Italy, Germany, Spain, Hungary. Site built by @itsmichaelwest.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Illegal Life Pro Tip: Want to ruin your competitors business? (225 pts)]]></title>
            <link>https://oppositeinvictus.com/illegal-life-pro-tip-want-to-ruin-your-competitors-business</link>
            <guid>36566634</guid>
            <pubDate>Sun, 02 Jul 2023 22:51:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://oppositeinvictus.com/illegal-life-pro-tip-want-to-ruin-your-competitors-business">https://oppositeinvictus.com/illegal-life-pro-tip-want-to-ruin-your-competitors-business</a>, See on <a href="https://news.ycombinator.com/item?id=36566634">Hacker News</a></p>
Couldn't get https://oppositeinvictus.com/illegal-life-pro-tip-want-to-ruin-your-competitors-business: Error: incorrect header check]]></description>
        </item>
        <item>
            <title><![CDATA[Ericsson to WhatsApp: The Story of Erlang (135 pts)]]></title>
            <link>https://thechipletter.substack.com/p/ericsson-to-whatsapp-the-story-of</link>
            <guid>36566167</guid>
            <pubDate>Sun, 02 Jul 2023 21:51:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thechipletter.substack.com/p/ericsson-to-whatsapp-the-story-of">https://thechipletter.substack.com/p/ericsson-to-whatsapp-the-story-of</a>, See on <a href="https://news.ycombinator.com/item?id=36566167">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84d7445f-4d93-4120-b226-de74c97b6d63_2292x1536.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84d7445f-4d93-4120-b226-de74c97b6d63_2292x1536.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84d7445f-4d93-4120-b226-de74c97b6d63_2292x1536.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84d7445f-4d93-4120-b226-de74c97b6d63_2292x1536.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84d7445f-4d93-4120-b226-de74c97b6d63_2292x1536.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84d7445f-4d93-4120-b226-de74c97b6d63_2292x1536.jpeg" width="1456" height="976" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/84d7445f-4d93-4120-b226-de74c97b6d63_2292x1536.jpeg&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:976,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:135418,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84d7445f-4d93-4120-b226-de74c97b6d63_2292x1536.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84d7445f-4d93-4120-b226-de74c97b6d63_2292x1536.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84d7445f-4d93-4120-b226-de74c97b6d63_2292x1536.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84d7445f-4d93-4120-b226-de74c97b6d63_2292x1536.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>In this post, we’re going to look at a piece of technology that was banned by the company that created it. It was kept alive by a small team of enthusiasts. Then, almost thirty years after its first development, it became the core technology underpinning one of the most important and lucrative startups of the 2010s.</p><p>Today, it plays a key role in services that are used by billions across the world.</p><p>We’re talking about the Erlang programming language.</p><p>Why is Erlang interesting? Well, one of the themes of this newsletter is that old technology can be incredibly valuable and useful. Erlang was often seen as an esoteric curiosity, until a small group of entrepreneurial engineers used it to create a start-up that they sold for billions of dollars.</p><p>Erlang’s history also has a number of lessons. The spread of general purpose hardware and software into specialist areas like telecoms. The power of individuals and small teams using the right software tools. The resilience of open source software. And more.</p><p>This is our first post on a programming language. Except it isn’t entirely about software, it’s about how software can make the most of the hardware resources available and the links between the hardware of computing and that of telephony.</p><p>So, what is Erlang, how did it come into being, and why has it had a renaissance recently?</p><p>We’re going to start at the place where Erlang was born. In Stockholm in Sweden.</p><p>If you’re old enough, you may remember Ericsson mobile phone handsets which were a popular choice in the pre-smartphone era. Today, Ericsson’s business is focused on telecommunications equipment.</p><p>Ericsson was founded by Lars Magnus Ericsson in Stockholm, Sweden in 1876. In 1878, it started making and selling telephones and switchboards.  Over the following decades, Ericsson had mixed fortunes and, after a period of financial difficulties, it was rescued by banks controlled by the Wallenberg family. By the 1960s, the Wallenbergs had full control of Ericsson.</p><p><span>We’ve previously met Ericsson in recounting the </span><a href="https://thechipletter.substack.com/p/the-first-risc-john-cocke-and-the" rel="">story</a><span> of the first RISC computer, the IBM 801. IBM wanted to to enter the telecoms equipment market and considered joining forces with Ericsson, with the development of a new computer at the center of a possible joint venture. After a series of secretive meetings at London’s Claridges Hotel, that came to nothing.</span></p><p>But telephony in general, and Ericsson in particular, needed computing.</p><p>In 1980, a small group of Ericsson engineers - Bjarne Däcker, Mike Williams, Göran Båge and Seved Torsten-dahl - proposed creating a Computer Science Laboratory (CSL) within the company. Their objectives were to create software technology for future telecoms systems and to help introduce that technology into existing Ericsson systems.</p><p><span>Their hardware mixed industry standard computers with specialised telecoms hardware, with a </span><a href="https://en.wikipedia.org/wiki/VAX-11" rel="">DEC VAX 11/750</a><span> minicomputer linked to an Ericsson telephone exchange.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc09f58-e02f-4ec2-8730-9a3fb48b4c16_1016x1312.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc09f58-e02f-4ec2-8730-9a3fb48b4c16_1016x1312.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc09f58-e02f-4ec2-8730-9a3fb48b4c16_1016x1312.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc09f58-e02f-4ec2-8730-9a3fb48b4c16_1016x1312.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc09f58-e02f-4ec2-8730-9a3fb48b4c16_1016x1312.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc09f58-e02f-4ec2-8730-9a3fb48b4c16_1016x1312.png" width="1016" height="1312" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9fc09f58-e02f-4ec2-8730-9a3fb48b4c16_1016x1312.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1312,&quot;width&quot;:1016,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:363474,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc09f58-e02f-4ec2-8730-9a3fb48b4c16_1016x1312.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc09f58-e02f-4ec2-8730-9a3fb48b4c16_1016x1312.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc09f58-e02f-4ec2-8730-9a3fb48b4c16_1016x1312.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9fc09f58-e02f-4ec2-8730-9a3fb48b4c16_1016x1312.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The original setup used to develop Erlang with a VAX 11/750 minicomputer running Unix connected to an Ericsson telephone exchange</figcaption></figure></div><p>Earlier work to program telecom systems at Ericsson had used a range of languages including PL163, CHILL and modified versions of the Pascal programming language. </p><p>Now the team started to look at a range of existing programming languages, each of which brought its own approach. These languages included then mainstream languages like Ada and lesser known ones such as Concurrent Euclid, PFL, LPL, OPS4, Frames and CLU.</p><p>As the team's work progressed, it became clear that none of these individual languages by itself would meet all the team’s requirements.</p><p>In 1985, the group was joined by Joe Armstrong and Robert Virding.</p><p>Then in 1988, the Lab moved from Ericsson to Ellemtel, a joint venture between Ericsson and the Swedish national telecoms provider Televerket.</p><p>The focus now was on building software to program AXE, Ericsson’s telephone exchange, which was programmed in a language called PLEX. The motivation was to “to make something like PLEX, to run on ordinary hardware, only better.”</p><p>Carrying forward some properties of PLEX was considered essential. In particular, according to Armstrong:</p><blockquote><p>Firstly, it should be possible to change code “on the fly;” in other words, code change operations should be possible without stopping the system.</p></blockquote><p>Software systems need to be updated and maintained with new code replacing old. A telephone system can’t be taken down completely whilst a set of code updates are introduced. Customers would not be happy if they can’t make their calls!</p><p>The language also needed to support many simultaneous activities, as calls were routed between users, and it had to be able to do this efficiently. Again, according to Armstrong, the language had to take replicate this property of telecoms switching systems:</p><blockquote><p>A switching system is made from a number of individual switches. Individual switches typically handle tens to hundreds of thousands of simultaneous calls. The switching system must be capable of handling millions of calls and must tolerate the failure of individual switches, providing uninterrupted services to the user. </p></blockquote><p>To this was added the conclusions of the earlier work to test a variety of languages. In particular:</p><ul><li><p>Small languages were thought desirable.</p></li><li><p>Functional programming was liked.</p></li><li><p>Logic programming was best in terms of elegance.</p></li><li><p>Concurrency was viewed as essential for this type of problem.</p></li></ul><p>Armstrong experimented with Smalltalk, but his attention was drawn to Prolog. Experimenting with building a system in Prolog soon led to something distinct:</p><blockquote><p>What started as an experiment in “adding concurrency to Prolog” became more of a language in its own right and this language acquired a name “Erlang,” which was probably coined by Bjarne Dacker. What did the name Erlang mean? Some said it meant “Ericsson Language,” while others claimed it was named after Agner Krarup Erlang (1878 – 1929), while we deliberately encouraged this ambiguity.</p></blockquote><p>Naming Erlang after Agner Krarup Erlang the Danish Mathematician who worked in the fields of traffic engineering and queuing theory, was surely appropriate for a language used to route telephone calls!</p><p>Robert Virding was now working with Armstrong on Erlang and by the end of 1988 most of the key ideas in Erlang had been implemented. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F508ca2bc-a5fa-44d8-9e4a-d76ddec36f92_664x592.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F508ca2bc-a5fa-44d8-9e4a-d76ddec36f92_664x592.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F508ca2bc-a5fa-44d8-9e4a-d76ddec36f92_664x592.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F508ca2bc-a5fa-44d8-9e4a-d76ddec36f92_664x592.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F508ca2bc-a5fa-44d8-9e4a-d76ddec36f92_664x592.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F508ca2bc-a5fa-44d8-9e4a-d76ddec36f92_664x592.png" width="664" height="592" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/508ca2bc-a5fa-44d8-9e4a-d76ddec36f92_664x592.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:592,&quot;width&quot;:664,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:37564,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F508ca2bc-a5fa-44d8-9e4a-d76ddec36f92_664x592.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F508ca2bc-a5fa-44d8-9e4a-d76ddec36f92_664x592.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F508ca2bc-a5fa-44d8-9e4a-d76ddec36f92_664x592.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F508ca2bc-a5fa-44d8-9e4a-d76ddec36f92_664x592.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>So what made Erlang different, and how did it support the Ericsson team’s requirements?</p><p>At the centre of Erlang was the idea of thousands and thousands of ‘processes’. These are separate pieces of code that run largely independently of each other. Each process communicates with other processes using ‘messages’, small amounts of data that are sent and received by each process.</p><p>Each process has a ‘mailbox’ which it can check from time to time and take action depending on the contents.</p><p>Furthermore, each process is extremely ‘lightweight’ in that it uses a very small proportion of the resources of the computer. A modern server can support millions of Erlang processes running at the same time.</p><p>The team built resilience into the language, allowing processes to fail, either due to bugs or to hardware failures, without bringing down the whole system – which of course would be a disaster for a telephony switching system.</p><p>They also built in the ability to scale. Processes can run on multiple physical machines, sending messages to other processes either running on the same machine or on other machines. So, an Erlang program can easily grow by just adding more physical machines.</p><p>Word of the development of Erlang spread, and Ericsson engineers wanted to try it out:</p><blockquote><p>The team wanted to prototype a new software architecture called ACS3 designed for programming telephony services on the Ericsson MD110 PABX4 and were looking for a suitable language for the project, which is how they got to hear about Erlang. A project called ACS / Dunder was started to build the prototype.</p></blockquote><p>When the work on ACS / Dunder was evaluated, there was a striking conclusion: development in Erlang was a lot faster than the alternatives.</p><p>Erlang was revealed to the world at a conference in 1989. Work continued inside Ericsson on to develop and improve Erlang over the following years. Then in 1992 there was a seemingly small, but in fact immensely significant, step forward for Erlang. A book was published on the language.</p><p>PLEX had been proprietary to Ericsson, as it was presumed that it gave the company a commercial advantage. For Erlang, it was decided to follow the example of AT&amp;T and the C language.</p><blockquote><p>The decision to publish an Erlang book and to be fairly open about what we did was therefore to avoid isolation and follow the AT&amp;T/C path rather than the Ericsson/PLEX path. Also in 1992 we ported Erlang to MS-DOS windows, the Mac, QNX and VxWorks.</p></blockquote><p>So the Erlang team started to promote the language. Including on video. We can see some of the original designers of Erlang, showcasing the system, in ‘Erlang: The Movie’. In it Bjarne Decker, Joe Armstrong, Mike Williams and Robert Virding show off the capabilities of their new language.</p><p><strong> ‘Declarative Real Time Programming Now!’, ‘Try It, You’ll like it!’</strong></p><div id="youtube2-xrIjfIjssLE" data-attrs="{&quot;videoId&quot;:&quot;xrIjfIjssLE&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/xrIjfIjssLE?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p>In December 1995, a large project at Ellemtel, called AXE-N, collapsed. According to Armstrong:</p><blockquote><p>AXE-N was a project aimed at developing a new generation of switching products ultimately to replace the AXE10 system. The AXE-N project had developed a new hardware platform and system software that was developed in C++.</p></blockquote><p>It was decided to replace the C++ software with code written in Erlang.</p><p>Again, according to Armstrong:</p><blockquote><p>This new project was to be the largest-ever Erlang project so far, with over 60 Erlang programmers. At the start of the AXD project, the entire Erlang system was the responsibility of half a dozen people in the Lab. This number was viewed as inadequate to support the needs of a large development project and so plans were immediately enacted to build a product unit, called OTP, to officially support the Erlang system.</p></blockquote><p>OTP or the  ‘Open Telecoms Platform’ provided capabilities such as ‘hot code reloading’, databases (he ‘Mnesia’ package) and many other facilities. Despite the use of the word ‘telecom’ in the name OTP is really a general purpose set of programs and doesn’t really have anything that is peculiar to telecoms systems.</p><p>So with increasing adoption Erlang’s future within Ericsson looked bright.</p><p>Then suddenly, in 1998, Erlang was banned within the Ericsson. The reason? To avoid the costs of development of a language that was unique to Ericsson, and instead to access the shared effort being put into the development of other languages.</p><blockquote><p>The selection of an implementation language implies a more long-term commitment than the selection of a processor and OS, due to the longer life cycle of implemented products. Use of a proprietary language implies a continued effort to maintain and further develop the support and the development environment. It further implies that we cannot easily benefit from, and find synergy with, the evolution following the large-scale deployment of globally used languages.</p></blockquote><p>In other words, Erlang was almost killed by the success of open-source languages.</p><p>But all was not over for Erlang.</p><p>The language continued to be maintained within Ericsson, as it was needed to support existing products.</p><p>And the efforts of the Erlang team outside Erlang would bear fruit. According to Armstrong:</p><blockquote><p>For some time, we had been distributing Erlang to interested parties outside Ericsson, although in the form of a free evaluation system subject to a non-disclosure agreement. By 1998, about 40 evaluation systems had been distributed to external users and by now the idea of releasing Erlang subject to an open-source license was formed. Recall that at the start of the Erlang era, in 1986, “open source” was unheard of, so in 1986 everything we did was secret.</p></blockquote><p>Following the ban, the Erlang team lobbied for Erlang, no longer seen as a sensitive commercial secret for Ericsson, to be released as open source. On 2 December 1998, “Open-Source Erlang” was announced.</p><p>The original members of the Erlang team soon left Ericsson to form their own company, Bluetail, to work on Erlang. It was natural for the team to turn to internet services, as this was just at the end of the era of the internet bubble.</p><blockquote><p>Given that the Bluetail system was programmed by most of the people who had designed and implemented the Erlang and OTP systems, the project was rapidly completed and had sold its first system within six months of the formation of the company. This was one of the first products built using the OTP technology for a non-telecoms application.</p></blockquote><p>Erlang had broken away from its telecoms roots and made its way onto the internet.</p><p>Other uses for the language started to appear. It found a niche in finance, helping firms that rely on ultra-fast trading to ensure that their systems were robust. Illustrious Wall Street firm Goldman Sachs used Erlang to implement their messaging system, with its robustness and reliability again key.</p><p><span>Open-source Erlang-based projects started to appear.  One of these was </span><a href="https://en.wikipedia.org/wiki/Ejabberd" rel="">ejabberd</a><span>, originally developed by Alexey Shchepin starting in 2003, which provided high-quality software to implement a system that allowed chat messages to be sent between a large number of users.</span></p><p>Then in 2009, Jan Koum came up with an idea. What about an internet-based messaging system for the iPhone?</p><p>The iPhone was launched in 2007 and the App Store in July 2008. The first version of Android was released in September 2008.</p><p>iPhone and Android users could send text messages to each other, but doing so was costly, with charges on a per-text basis. By contrast, the amount of data used for each message was tiny, even in the context of the small data transfer allowances granted to users at the time.</p><p><span>Koum was joined by Brian Acton, who he’d met whilst working at Yahoo!</span></p><p>Koum and Acton set out to build a system where users could send each other messages using their data allowances. This would dramatically undercut the pricing of the telecoms operators. With dedicated apps on each of the new mobile platforms, they could also build in more features to make using the application more useful and fun.</p><p>The underlying software base to power the ‘back end’ of this system was already available in the form of ejabberd. Koum and Acton took the open-source messaging system and adapted it to provide the underpinnings of the product that they envisaged.</p><p><span>So, </span><a href="https://en.wikipedia.org/wiki/WhatsApp" rel="">WhatsApp</a><span> was born in January 2009.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F904669ad-127a-45f9-9eeb-e2f8d14f1b0c_1508x1338.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F904669ad-127a-45f9-9eeb-e2f8d14f1b0c_1508x1338.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F904669ad-127a-45f9-9eeb-e2f8d14f1b0c_1508x1338.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F904669ad-127a-45f9-9eeb-e2f8d14f1b0c_1508x1338.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F904669ad-127a-45f9-9eeb-e2f8d14f1b0c_1508x1338.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F904669ad-127a-45f9-9eeb-e2f8d14f1b0c_1508x1338.png" width="1456" height="1292" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/904669ad-127a-45f9-9eeb-e2f8d14f1b0c_1508x1338.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1292,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:467063,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F904669ad-127a-45f9-9eeb-e2f8d14f1b0c_1508x1338.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F904669ad-127a-45f9-9eeb-e2f8d14f1b0c_1508x1338.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F904669ad-127a-45f9-9eeb-e2f8d14f1b0c_1508x1338.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F904669ad-127a-45f9-9eeb-e2f8d14f1b0c_1508x1338.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>WhatsApp Logo</figcaption></figure></div><p>WhatsApp’s growth was spectacular. From 10 million users in 2010 it grew to 100 million at the end of 2012. Thanks to the efficiency of Erlang and their careful refinement of both ejabberd, the FreeBSD operating system and Erlang itself, they were able to scale quickly whilst keeping growth of both their hardware and engineering resources down.</p><p>Their ability to scale at low cost also underpinned their business strategy. They avoided showing ads to users, instead charging each user $1 each year after the first year. $1 per user may not sound much, but with their growing user base, it would soon represent significant income. It was also affordable for users even in lower income countries, and users liked the ad-free WhatsApp user experience.</p><p>By 2013, Facebook’s Mark Zuckerberg started to see WhatsApp as a threat to his own business. Facebook had its own messaging application, Facebook Messenger, but WhatsApp was winning the messaging battle.</p><p>Critically, Zuckerberg would have seen how fast WhatsApp was scaling and presumed that it would be able to continue to scale. All thanks to Erlang.</p><p>So Facebook bought WhatsApp in 2014 for $16 billion, making Koum and Acton billionaires overnight. In the previous year, WhatsApp had revenues of only $10.2 million had incurred losses of $138 million (still small for a company with 400 million users at the end of the year – and with much of this stock-based compensation rather than underlying costs). Immediately after the acquisition, Facebook dropped what had been WhatsApp’s major revenue source, by removing the $1 per year fee. At the time of the acquisition Erlang employed only 35 engineers.</p><p>Under Facebook’s ownership, WhatsApp has continued to grow, with more than 2 billion users worldwide, all supported by Erlang.</p><p>WhatsApp wasn’t the only messaging system to use Erlang. Like WhatsApp, Facebook Messenger had used Erlang and ejabberd but moved away from it after finding it difficult to recruit engineers. WeChat in China also used Erlang for a messaging system operating with billions of users.</p><p>But messaging wasn't the only area where Erlang could be built on.</p><p>Jose Valim had been a core member of the group developing the Open-Source Ruby on Rails (commonly known as ‘Rails’) web framework. Rails was started by David Heinemeier Hansson in 2003 a part of the Basecamp project management web application.</p><p>Rails provides much of the software infrastructure  that is needed to build a modern web application: the ability to create web pages, access a database with user data and so on. Rails is built using the Ruby programming language.</p><p>Valim saw the advantages of Erlang and how useful they would be to someone developing a modern web application. In particular, its scalability made it suited to applications where users need to communicate frequently with web servers.</p><p>He also saw that Erlang had some major limitations in this context, including an unfamiliar syntax. So het set out to create a language that dealt with these issues whilst retaining the core advantages of Erlang and OTP.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F080d62f2-69e6-4e78-a028-c9a5a88bfffe_1000x418.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F080d62f2-69e6-4e78-a028-c9a5a88bfffe_1000x418.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F080d62f2-69e6-4e78-a028-c9a5a88bfffe_1000x418.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F080d62f2-69e6-4e78-a028-c9a5a88bfffe_1000x418.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F080d62f2-69e6-4e78-a028-c9a5a88bfffe_1000x418.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F080d62f2-69e6-4e78-a028-c9a5a88bfffe_1000x418.png" width="1000" height="418" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/080d62f2-69e6-4e78-a028-c9a5a88bfffe_1000x418.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:418,&quot;width&quot;:1000,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:62250,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F080d62f2-69e6-4e78-a028-c9a5a88bfffe_1000x418.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F080d62f2-69e6-4e78-a028-c9a5a88bfffe_1000x418.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F080d62f2-69e6-4e78-a028-c9a5a88bfffe_1000x418.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F080d62f2-69e6-4e78-a028-c9a5a88bfffe_1000x418.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>So </span><a href="https://en.wikipedia.org/wiki/Elixir_(programming_language)" rel="">Elixir</a><span> was born in 2013. Elixir provides the capabilities of Erlang (in fact, the language ‘cross compiles’ to Erlang) in a syntax that is largely familiar to Ruby programmers.</span></p><p>Just as Rails on Rails built on Ruby, Elixir soon formed the base for a new ‘web framework’, developed by Chris McCord, Jose Valim and others, Phoenix, provides open-source software that is broadly equivalent to Ruby on Rails in its capabilities whilst being less resource intensive and making it more straightforward to build web applications, such as chat, that need frequent connection to a web server.</p><p>Innovation on top of Elixir and Phoenix has continued to this day. Two notable examples are LiveView, that removes the need for the user to write JavaScript running in the browser, and Nx which adds the base capabilities required for machine learning applications.</p><p>Today, many companies are using Elixir as the basis for their web applications, including large companies such as Twitch and a number of smaller start-ups. Elixir and Phoenix provide everything that is needed for even a small team to build an application that can be rapidly scaled.</p><p>Erlang continues to be developed and supported by individuals and teams both inside and outside Ericsson. In 2022, it received a notable update that speeded up the execution of Erlang programs significantly through the introduction of an updated ‘just in time’ compiler.</p><p>Elixir and Phoenix have both reached maturity. They have both attracted a small but dedicated and enthusiastic group of supporters. The ecosystem around both continues to expand, although it still can’t match that around a framework such as Ruby on Rails.</p><p>But Elixir and Phoenix haven’t taken over the world and are still relatively niche. We’ll discuss why this is and some of the lessons that can be learned from the history of Erlang, WhatsApp, and Elixir in the paid supplement to this post coming on Tuesday. This post also contains loads of links to sources and supplementary material, including the briefest introductions to programming in Erlang and Elixir.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI and the Automation of Work (155 pts)]]></title>
            <link>https://www.ben-evans.com/benedictevans/2023/7/2/working-with-ai</link>
            <guid>36565854</guid>
            <pubDate>Sun, 02 Jul 2023 21:16:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ben-evans.com/benedictevans/2023/7/2/working-with-ai">https://www.ben-evans.com/benedictevans/2023/7/2/working-with-ai</a>, See on <a href="https://news.ycombinator.com/item?id=36565854">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-6492ff3078695b7b2d072912" data-item-id="6492ff3078695b7b2d072912">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1687355241466" id="item-6492ff3078695b7b2d072912"><div data-block-type="2" id="block-yui_3_17_2_1_1687355242158_5623">
  <p>Pretty much everyone in tech agrees that generative AI, Large Language Models and ChatGPT are a generational change in what we can do with software, and in what we can automate with software. There isn’t much agreement on anything else about LLMs - indeed, we’re still working out what the arguments are - but everyone agrees there’s a lot more automation coming, and entirely new kinds of automation. Automation means jobs, and people. </p><p>This is also happening very fast: ChatGPT has (apparently) over 100m users after just six months, and this data from <a href="https://productiv.com/state-of-saas-trends/">Productiv</a> suggests it’s already a top-dozen ‘shadow IT’ app. So, how many jobs is this going to take, how fast, and can there be new jobs to replace them?</p>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1688229104156_55683">

<p>We should start by remembering that we’ve been automating work for 200 years. Every time we go through a wave of automation, whole classes of jobs go away, but new classes of jobs get created. There is frictional pain and dislocation in that process, and sometimes the new jobs go to different people in different places, but over time the total number of jobs doesn’t go down, and we have all become more prosperous. </p>



</div><div data-block-type="2" id="block-yui_3_17_2_1_1688084473363_14341">
  <p>When this is happening to your own generation, it seems natural and intuitive to worry that this time, there aren’t going to be those new jobs. We can <em>see</em> the jobs that are going away, but we can’t predict what the new jobs will be, and often they don’t exist yet. We know (or should know), empirically, that there always have been those new jobs in the past, and that they weren’t predictable either: no-one in 1800 would have predicted that in 1900 a million Americans would work on ‘railways’ and no-one in 1900 would have predicted ‘video post-production’ or ‘software engineer’ as employment categories. But it seems insufficient to take it on faith that this will happen now just because it always has in the past. How do you know it will happen this time? Is this different?</p><p>At this point, any first-year economics student will tell us that this is answered by, amongst other things, the ‘Lump of Labour’ fallacy. </p><p>The Lump of Labour fallacy is the misconception that there is a fixed amount of work to be done, and that if some work is taken by a machine then there will be less work for people. But if it becomes cheaper to use a machine to make, say, a pair of shoes, then the shoes are cheaper, more people can buy shoes and they have more money to spend on other things besides, and we discover new things we need or want, and new jobs. The efficient gain isn’t confined to the shoe: generally, it ripples outward through the economy and creates new prosperity and new jobs. So, we don’t know what the new jobs will be, but we have a model that says, not just that there always have been new jobs, but why that is inherent in the process. Don’t worry about AI!</p><p>The most fundamental challenge to this model today, I think, is to say that no, what’s really been happening for the last 200 years of automation is that we’ve been moving up the scale of human capability. </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1688084473363_58771">

      

      
        <figure>
          
        
        

        
          
            
          
        

        
          
          <figcaption>
            <p>‘Barge haulers on the Volga’, Ilya Repin, 1870-73. (Note the steam boat on the horizon.)</p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1688084473363_59132">
  <p>We began with humans as beasts of burden, pulling barges up the river, and moved up: we automated legs, then arms, then fingers, and now brains. We went from farm work to blue collar work to white collar work, and now we’ll automate the white-collar work as well and there’ll be nothing left. Factories were replaced by call centres, but if we automate the call centres, what else is there? </p><p>Here, I think it’s useful to look at another piece of economic and tech history: the Jevons Paradox. </p><p>In the 19th century the British navy ran on coal. Britain had a lot of coal (it was the Saudi Arabia of the steam age) but people worried what would happen when the coal ran out. Ah, said the engineers: don’t worry, because the steam engines keep getting more efficient, so we’ll use less coal. No, said Jevons: if we make steam engines more efficient, then they will be cheaper to run, and we will use more of them and use them for new and different things, and so we will use <em>mor</em>e coal. </p><p>We’ve been applying the Jevons Paradox to white collar work for 150 years. </p>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1688069358241_3998">
  <p>It’s hard to imagine jobs of the future that don’t exist yet, but it’s also hard to imagine some of the jobs of the past that have already been automated away. Gogol’s <a href="https://en.wikipedia.org/wiki/The_Overcoat">downtrodden clerks</a> in 1830s St Petersburg spent their entire adult lives copying out documents, one at a time, by hand. They were human Xeroxes. By the 1880s, typewriters produced perfectly legible text at twice the words-per-minute, and carbons gave half a dozen free copies as well. Typewriters meant a clerk could produce more than 10 times the output. A few decades later, adding machines from companies like Burroughs did the same for book-keeping and accounting: instead of adding up columns with a pen, the machine does it for you, in 20% of the time, with no mistakes. </p><p>What did that do to clerical employment? People hired far more clerks. Automation plus the Jevons Paradox meant more jobs. </p><p>If one clerk with a machine can do the work of 10, then you might have fewer clerks, but you might also you might do far more with them. If, Jevons tells us, it becomes much cheaper and more efficient to do something, you might do more of it - you might do more analysis or manage more inventory. You might build a different and more efficient business that is only possible because you can automate their administration with typewriters and adding machines. </p><p>This process keeps repeating. This is Jack Lemon as CC Baxter in <a href="https://en.wikipedia.org/wiki/The_Apartment">The Apartment</a> in 1960, using an electro-mechanical adding machine from <a href="https://en.wikipedia.org/wiki/Friden,_Inc.">Friden</a> fifty years after adding machines were new and exciting. </p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1688069358241_18109">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/50363cf324ac8e905e7df861/2d3a670a-28cf-4dd9-a07e-c37c9f9861c8/featured.png" data-image="https://images.squarespace-cdn.com/content/v1/50363cf324ac8e905e7df861/2d3a670a-28cf-4dd9-a07e-c37c9f9861c8/featured.png" data-image-dimensions="1200x894" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="649de7e7206ef75742274813" data-type="image" src="https://images.squarespace-cdn.com/content/v1/50363cf324ac8e905e7df861/2d3a670a-28cf-4dd9-a07e-c37c9f9861c8/featured.png">
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1688069358241_18464">

<p>Everyone in that shot is a cell in a spreadsheet, and the whole building is a spreadsheet. Once a week someone on the top floor presses F9 and they recalculate. But they already had computers, and in 1965 or 1970 they bought a mainframe, and scrapped all the adding machines. Did white collar employment collapse? Or, as IBM advertised, did a computer give you 150 extra engineers? 25 years later, what did the PC revolution, and the accounting department in a box, do to accounting?</p>



</div><div data-block-type="2" id="block-yui_3_17_2_1_1688084473363_92506">
  <p>Dan Bricklin invented the computer spreadsheet in 1979: until then, ‘spreadsheets’ were paper (you can still buy them <a href="https://www.amazon.com/s?crid=J5T9EM16AQN4&amp;i=office-products&amp;k=spreadsheet%20paper&amp;ref=nb_sb_ss_ts-doa-p_1_11&amp;sprefix=spreadsheet%2Coffice-products%2C56">on Amazon</a>). He has <a href="https://qz.com/578661/dan-bricklin-invented-the-spreadsheet-but-dont-hold-that-against-him">some entertaining stories</a> about early use: ‘<em>People would tell me, “I was doing all this work, and coworkers thought I was amazing. But I was really goofing off because it only took an hour and then I took the the rest of the day off. People thought I was a wunderkind but I was using this tool.”’</em></p><p> So, what did Excel and the PC do to accounting employment? <a href="https://us.aicpa.org/interestareas/accountingeducation/newsandpublications/aicpa-trends-report">It went up</a>. </p>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1688069358241_21167">

<p>40 years later, do spreadsheets mean you can goof off early? Not really.  </p>



</div><div data-block-json="{&quot;width&quot;:550,&quot;height&quot;:null,&quot;hSize&quot;:null,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p lang=\&quot;en\&quot; dir=\&quot;ltr\&quot;>Younger people may not believe this but before spreadsheets investment bankers worked really long hours. It&amp;#39;s only thanks to Excel that Goldman Sachs associates can get everything done and leave the office at 3pm on Fridays. Now LLMs mean they&amp;#39;ll only have to work one day a week!</p>&amp;mdash; Benedict Evans (@benedictevans) <a href=\&quot;https://twitter.com/benedictevans/status/1654514832765329411?ref_src=twsrc%5Etfw\&quot;>May 5, 2023</a></blockquote>\n<script async src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;url&quot;:&quot;https://twitter.com/benedictevans/status/1654514832765329411&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;floatDir&quot;:null,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;customThumbEnabled&quot;:false}" data-block-type="22" id="block-yui_3_17_2_1_1688219853387_28970"><blockquote><p lang="en" dir="ltr">Younger people may not believe this but before spreadsheets investment bankers worked really long hours. It's only thanks to Excel that Goldman Sachs associates can get everything done and leave the office at 3pm on Fridays. Now LLMs mean they'll only have to work one day a week!</p>— Benedict Evans (@benedictevans) <a href="https://twitter.com/benedictevans/status/1654514832765329411?ref_src=twsrc%5Etfw">May 5, 2023</a></blockquote>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1688219853387_29036">
  <p>New technology generally makes it cheaper and easier to do something, but that might mean you do the same with fewer people, or you might do much more with the same people. It also tends to mean that you change what you do. To begin with, we make the new tool fit the old way of working, but over time, we change how we work to fit the tool. When CC Baxter’s company bought a mainframe, they began by automating the way they already did things, but over time, new ways to run the business became possible. The machine lets a person do 10x the work, but you need the person. </p><p>So, all of this is to say that by default, we should expect LLMs to destroy, displace, create, accelerate and multiple jobs just as SAP, Excel, Mainframes or typewriters did. It’s just more automation.  </p><p>I think there are two counter-arguments to this. </p><p>The first is to say that yes, perhaps this is indeed just more of the same kind of change that we saw with the internet, PCs or computers, and perhaps again it will have no long-term effect on net employment, but this time it will happen much faster, and so that frictional pain will be much greater and it will be much harder to adjust. </p><p>LLMs and ChatGPT certainly are happening a lot faster than things like iPhones or the Internet, or indeed PCs. The Apple II shipped in 1977, the IBM PC in 1981 and the Mac in 1984, but it took until the early 1990s before  there were 100m PCs in use: there are 100m ChatGPT users today after just six months. You don’t need to wait for telcos to build broadband networks, or consumers to buy new devices, and generative AI sits on top of the whole existing stack of cloud, distributed computing and indeed a lot of the machine learning stack itself that was built over the last decade. To a user, it’s just a website.</p><p>However, your expectations might be different if you think about the implications of these charts, from <a href="https://productiv.com/state-of-saas-trends/">Productiv</a> again and from <a href="https://www.okta.com/uk/resources/whitepaper-businesses-at-work-2021/">Okta</a> (with a different methodology). They report that their typical customer now has hundreds of different software applications. </p>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1688331732417_68266">

<p>And yet, enterprise cloud adoption is still barely a quarter of workflows.  </p>



</div><div data-block-type="2" id="block-yui_3_17_2_1_1688219853387_71837">
  <p>What does that mean for generative AI in the workplace? Whatever you think will happen, it will take years, not weeks. </p><p>First, the tools that people use for work, and the tasks that might now get a new layer of automation, are complicated and very specialised, and embody a lot of work and institutional knowledge. A lot of people are <em>experimenting </em>with ChatGPT, and seeing what it will do. If you’re reading this, you probably have too. That doesn’t mean that ChatGPT has replaced their existing workflows <em>yet</em>, and replacing or automating any of those tools and tasks is not trivial. </p><p>There’s a huge difference between an amazing demo of a transformative technology and something that a big complicated company holding other people’s business can use. You can rarely go to a law firm and sell them an API key to GCP’s translation or sentiment analysis: you need to wrap it in control, security, versioning, management, client privilege and a whole bunch of other things that only legal software companies know about (there’s a graveyard of machine learning companies that learnt this in the last decade). Companies generally can’t buy ‘technology’.  <a href="https://www.everlaw.com/">Everlaw</a> doesn’t sell translation and <a href="https://www.people.ai/">People.ai</a> doesn’t sell sentiment analysis - they sell tools and products, and often the AI is only one part of that. I don’t think a text prompt, a ‘go’ button and a black-box, general purpose text generation engine make up a product, and product takes time.  </p><p>Second, buying tools that manage big complicated things takes time even once the tool is built and has product-market fit. One of the most basic challenges in building an enterprise software startup is that startups run on an 18 month funding cycle and a lot of enterprises run on an 18 month decision cycle. SaaS itself accelerated this because you don’t need to get into the enterprise datacenter deployment schedule, but you still need purchase, integration and training, and companies with millions of customers and tens or hundreds of thousands of employees have very good reasons not to change things suddenly. The future takes a while, and the world outside Silicon Valley is complicated. </p><p>The second objection is that part of the paradigm shift of ChatGPT and LLMs is a shift in the layer of abstraction: this looks like a much more general purpose technology. Indeed, that’s why it’s exciting. It can answer <em>anything,</em> we are told. So, you could look at that chart of 473 enterprise SaaS apps and say that ChatGPT will disrupt that and collapse many those vertical apps into one prompt box. That would mean it would move faster, and also automate much more. </p><p>I think that misunderstands the problem. If a partner at a law firm wants a first draft of a paper, they want to be able to shape the parameters in completely different ways to a salesperson at an insurance company challenging a claim, probably with a different training set and certainly with a bunch of different tooling. Excel is ‘general purpose’ too, and so is SQL, but how many different kinds of ‘database’ are there? This is one reason I think the future of LLMs is to move from prompt boxes to GUIs and buttons - I think ‘prompt engineering’ and natural language’ are mutually contradictory. But either way, even if you can run everything as a thin wrapper on top of one giant foundational model (and there is very little agreement or clarity about this yet), even those wrappers will take time.</p><p>Meanwhile, while one could suggest that LLMs will subsume many apps on one axis, I think it’s equally likely that they will enable a whole new wave of unbundling on other axes, as startups peel off dozens more use cases from Word, Salesforce and SAP, and build a whole bunch more big companies by solving problems that no-one had realised were problems until LLMs let you solve them. That’s the process that explains why big companies already have 400 SaaS apps today, after all. </p><p>More fundamental, of course, there is the error rate. ChatGPT can <em>try </em>to answer ‘anything’ but the answer might be wrong. People call this hallucinations, making things up, lying or bullshitting - it’s the ‘overconfident undergraduate’ problem. I think these are all unhelpful framings: I think the best way to understand this is that when you type something into a prompt, you’re not actually asking it to answer a question at all. Rather, you’re asking it “what sort of answers would be people be likely to produce to questions that look like this?” You’re asking it to match a pattern. </p><p>Hence, if I ask ChatGPT4 to write a biography of myself, and then ask it again, it gives different answers. It suggests I went to Cambridge, Oxford or the LSE; my first job was in equity research, consulting or financial journalism. These are always the right pattern: it’s the right kind of university and the right kind of job (it never says Anglia Poly and then catering management). It is giving 100% correct answers to the question “what <strong>kinds</strong> of degrees and jobs are people <strong>like</strong> Benedict <strong>likely</strong> to have done?” It’s not doing a database lookup: it’s making a pattern. </p><p>You can see something similar in this image I got from MidJourney. The prompt was “A photograph of advertising people discussing creativity on stage in a panel on a beach at Cannes Lions.”</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1688228900463_18067">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/50363cf324ac8e905e7df861/f8965b47-137b-4dc8-9fe7-eec10e13781f/0_3.png" data-image="https://images.squarespace-cdn.com/content/v1/50363cf324ac8e905e7df861/f8965b47-137b-4dc8-9fe7-eec10e13781f/0_3.png" data-image-dimensions="1024x1024" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="64a05493b8d18000902a981a" data-type="image" src="https://images.squarespace-cdn.com/content/v1/50363cf324ac8e905e7df861/f8965b47-137b-4dc8-9fe7-eec10e13781f/0_3.png">
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1688228900463_18432">
  <p>It’s matched the pattern almost perfectly - that looks like the beach at Cannes, these people are dressed like advertising people, and they even have the right haircuts. But it doesn’t <em>know</em> anything, and so it doesn’t know that people <em>never </em>have three legs, only that it’s unlikely. This isn’t ‘lying’ or ‘making things up’ - it’s matching a pattern, imperfectly. </p><p>Whatever you call it, if you don’t understand this, you can get into trouble, as happened to <a href="https://www.nytimes.com/2023/06/08/nyregion/lawyer-chatgpt-sanctions.html">this unfortunate lawyer</a>, who did not understand that when he asked for precedents, he was actually asking for things that looked like precedents. He duly got things that looked like precedents, but weren’t. It’s not a database. </p><p>If you do understand this, then you have to ask, well, where are LLMs useful? Where is it useful to have automated undergraduates, or automated interns, who can repeat a pattern, that you might have to check? The last wave of machine learning gave you infinite interns who could read anything for you, but you had to check, and now we have infinite interns that can write anything for you, but you have to check. So where is it useful to have infinite interns? Ask Dan Bricklin - we’re back to the Jevons Paradox. </p><p>This takes me, obviously, to AGI. The really fundamental objection to everything I’ve just said is to ask what would happen if we had a system that didn’t have an error rate, didn’t hallucinate, and really could do anything that people can do. If we had that, then you might not have one accountant using Excel to get the output of ten accountants: you might just have the machine. This time, it really would be be different. Where previous waves of automation meant one person could do more, now you don’t need the person.  </p><p>Like a lot of AGI questions, though, this can become circular if you’re not careful. ‘If we had a machine that could do anything people do, without any of these limitations, could it do anything people can do, without these limitations?’</p><p>Well, indeed, and if so we might have bigger problems than middle-class employment, but is that close? You can spend weeks of your life watching three hour YouTube videos of computer scientists arguing about this, and conclude only that they don’t really know either. You might also suggest that the idea this one magic piece of software will change everything, and override all the complexity of real people, real companies and the real economy, and can now be deployed in weeks instead of years, sounds like classic tech solutionism, but turned from utopia to dystopia. </p><p>As an analyst, though, I tend to prefer Hume’s empiricism over Decartes - I can only analyse what we can know. We don’t have AGI, and without that, we have only another wave of automation, and we don’t seem to have any <em>a priori</em> reason why this must be more or less painful than all the others. </p>
</div></div>

    

    

    

  </article>





  
              </section>
            
          </main>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Disabled at 22 million commits (103 pts)]]></title>
            <link>https://programming.dev/post/355447</link>
            <guid>36565842</guid>
            <pubDate>Sun, 02 Jul 2023 21:15:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://programming.dev/post/355447">https://programming.dev/post/355447</a>, See on <a href="https://news.ycombinator.com/item?id=36565842">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="postContent"><div><p>Hey folks,</p>
<p>This is an update to: <a href="https://sh.itjust.works/post/580838">https://sh.itjust.works/post/580838</a></p>
<p>On <a href="https://github.com/csm10495/commit-ment">https://github.com/csm10495/commit-ment</a>, I made it to somewhere around 22 million commits. I can’t imagine this is not a world record for commits to a single branch. In the middle of the night, I got an email from GitHub support saying:</p>
<p><img src="https://sh.itjust.works/pictrs/image/e706b3af-9157-4d97-a5c2-0b4e3725b452.png" alt=""></p>
<p>A few minutes later, I got another email like so:</p>
<p><img src="https://sh.itjust.works/pictrs/image/96f57e50-0567-4913-a8cf-e9c4773ba45f.png" alt=""></p>
<p>I’ve asked them if the two emails are related (and I guess if the first one is some sort of error since there was no personal info in that repo). I’ve also asked if they can give any information about what triggered the email and if they can give me more info about what it looks look on their side.</p>
<p>I’ve also asked if they can re-enable it so I can give one more commit to say the final results on the readme then (public) archive it.</p>
<p>We’ll see what they say.</p>
<p>Doing a pull is interesting at the moment, it shows:</p>
<pre><code>git pull origin master --no-rebase -vvv
ERROR: Access to this repository has been disabled by GitHub staff due to
excessive resource use. Please contact support via
https://support.github.com/contact to restore access to this repository.
Read about how to decrease the size of your repository:
  https://docs.github.com/articles/what-is-my-disk-quota

fatal: Could not read from remote repository.

Please make sure you have the correct access rights
and the repository exists.
</code></pre>
<p>Similar thing happens if you try to clone: <a href="https://programming.dev/cdn-cgi/l/email-protection#46212f3206212f322e33246825292b"><span data-cfemail="caada3be8aada3bea2bfa8e4a9a5a7">[email&nbsp;protected]</span></a>:csm10495/commit-ment.git</p>
<p>So yeah, I figured this would happen sooner or later. I just hope they can tell me a bit more about what it looks like on their side since managing this repo on my box is a pain, I can’t imagine what it could look like on theirs. I’m also curious how pull requests could merge at such a rate given that just doing a pull on my end could take minutes. So many questions!</p>
<p>This whole project was really just for curiosity on my end, so anything I can learn/find out is much appreciated on all ends.</p>
<p>Anyways, just figured I’d update y’all.</p>
</div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WebAuthn Is Great and It Sucks (2020) (115 pts)]]></title>
            <link>https://sec.okta.com/articles/2020/04/webauthn-great-and-it-sucks/</link>
            <guid>36565405</guid>
            <pubDate>Sun, 02 Jul 2023 20:35:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sec.okta.com/articles/2020/04/webauthn-great-and-it-sucks/">https://sec.okta.com/articles/2020/04/webauthn-great-and-it-sucks/</a>, See on <a href="https://news.ycombinator.com/item?id=36565405">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>What is WebAuthn again?</h2><p>First things first, let’s all agree that passwords suck, OK?&nbsp;</p><p>Good, glad we’re on the same page. Passwords are hard to remember, leading people to pick weak ones and reuse them over and over. Passwords are also easy to phish, with ever more subtle and believable attacks happening <a href="https://threatpost.com/clever-phishing-attack-enlists-google-translate-to-spoof-facebook-login-page/141571/">all the time</a>.&nbsp;</p><p>WebAuthn—short for Web Authentication—promises to fix passwords on the web with a strong, simple, and un-phishable standard for secure authentication. WebAuthn at its heart is a credential management API built into modern web browsers allowing web applications to strongly authenticate users, and it’s now a World Wide Web Consortium standard.</p><p>How does WebAuthn do this? Public key cryptography, which allows you to strongly authenticate without a password. Using WebAuthn, you're able to use a single authenticator (like a Yubikey, for example) on any site that supports the standard. This way, as a user, you don't need to have passwords for every site you visit, just a strong authenticator that works with WebAuthn.</p><p>In addition to offering convenience, WebAuthn provides privacy, as one site can’t figure out from the authenticator what other sites you’ve used it for. Attackers also can’t capture and successfully replay the authentication request, so malicious sites can’t use it to attack the genuine sites, eliminating <a href="https://breakdev.org/evilginx-2-next-generation-of-phishing-2fa-tokens/">man-in-the-middle attacks</a>. WebAuthn also allows you to choose your own authenticator, a device you already have (like a smartphone or computer) or an external authenticator like a USB security key.&nbsp;</p><h3>Wow, sounds great!</h3><p>Sure does!</p><h3>OK, so I looked up WebAuthn and it’s full of acronyms!</h3><p>You bet, let’s look at what they mean!</p><p><strong>FIDO</strong> is short for Fast IDentity Online. The FIDO Alliance is an open industry association with <a href="https://fidoalliance.org/members/">hundreds of member companies</a>, working to create authentication standards to help reduce the world’s over-reliance on passwords.&nbsp;</p><p><strong>FIDO2</strong> is the overarching term for the <a href="https://fidoalliance.org/specifications/download/">specifications</a> from the World Wide Web Consortium (W3C) and the FIDO Alliance. It includes both WebAuthentication (web APIs for passwordless authentication in browsers) and CTAP protocols.</p><p><strong>CTAP</strong> stands for <a href="https://fidoalliance.org/specs/fido-v2.0-ps-20190130/fido-client-to-authenticator-protocol-v2.0-ps-20190130.html">Client To Authenticator Protocol</a>. It describes how authenticators can implement second-factor and passwordless authentication. These authenticators can be built-in to devices like phones and laptops (on-device or platform authenticators), or they can be external ones (roaming authenticators or security keys) connecting over NFC, USB, and/or BLE.</p><p><strong>CTAP2</strong> is the new hotness. It enables you to use the new authenticators <strong>not only for second-factor authentication</strong>, but also for <strong><a href="https://www.w3.org/TR/webauthn/#sctn-authenticator-taxonomy">passwordless and multi-factor authentication</a></strong>.&nbsp;</p><p><strong>CTAP1</strong> is what used to be called FIDO U2F. It allows older U2F authenticators like security keys to continue to be used for second-factor authentication, i.e. as an extra step after a password.&nbsp;</p><p><img src="https://lh5.googleusercontent.com/ZO0LpBNwZXtNU7BcMFv0G97IFjEWKNGScAsD1vOBjs36YhTysbpL91AghbbSAy0QorZEHb78cLcBIvtzbuFXecY4Gaw__Re5qlWJYuORpb3KscqBv34EcVcaIX71ZD1CX_JyK7nf"><br>
Image copyright FIDO Alliance</p><p>Easy, right? Well, it could be a lot worse—just look at the <a href="https://tools.ietf.org/html/rfc6749">OAuth 2.0 specifications!</a></p><p><img src="https://lh5.googleusercontent.com/M3i3S_QJPUvtfkFRLsC17sgw2Ha_UbkgG-ULfwKu8n9vk_HDnLL4U4R0ZcPBGnBUG99uqn21abXnAEQAHBh0LofdZ7wurV2JxOpTty36qR0BYRtYFz16XDInI-YH1tu-u1CPKdHV"></p><p>If you want to see how WebAuthn works behind the scenes, watch this <a href="https://www.okta.com/resources/oktane-content/developer/#does-webauthn-signal">great video by James Fang and Payal Pan from Oktane 19</a>.</p><h2>Wait, why do I care again?</h2><p>Great question! The key promise is …. *drum roll* <strong>strong passwordless authentication</strong>!</p><p>The older FIDO U2F protocols and security keys allow for strong and phishing-resistant second-factor experiences, but now we’re talking passwordless! Just think of how smooth and seamless that will be!</p><p>These new protocols make it possible to require even stronger authentication than the user presence test of U2F protocol, where you tap the security key to authenticate. With FIDO2, <a href="https://www.w3.org/TR/webauthn/#user-verification">sites can require user verification</a> at different levels from password or PIN tied to the security key all the way to on-device biometrics, such as fingerprint readers, Face ID, or Windows Hello. This can enable single-device <a href="https://en.wikipedia.org/wiki/Multi-factor_authentication#Authentication_factors">multi-factor authentication</a>, combining the possession factor (you have the authenticator) with a knowledge factor (you know the PIN) and/or inherent factors (your biometric, like fingerprint or faceprint matches).</p><p>Now, the biggest challenge in moving past passwords is the simple fact that it has been the lowest common denominator—the easiest and cheapest thing to implement. Passwords like we know them date back 59 years (!!) going back to <a href="https://www.wired.com/2012/01/computer-password/">MIT in 1961 with the CTSS</a> operating system. Passwords are literally everywhere.&nbsp;</p><p>Every gizmo that has come since with a promise to eliminate the password has failed. There’s always been a platform, service, or system that didn’t support the latest new passwordless idea, and very few were ready to pay the cost of changing the servers, the operating systems, the applications, everything, just to get a non-compatible point solution. Passwords are cheap. Everything else is expensive.</p><p>Except now, with WebAuthn!</p><h2>Everything supports WebAuthn! Great!</h2><p>We are at a cusp of having universal support for WebAuthn!&nbsp; All major operating systems and browsers have now implemented WebAuthn.&nbsp;</p><p>As I write this in April 2020, a full <strong>83% of all the browsers in use</strong> around the world support it, as you can see in this <a href="https://caniuse.com/#search=webauthn">CanIUse</a> report.</p><p><img src="https://lh3.googleusercontent.com/2wLQQsRTDLUv1OT-jPovHPioCZpyU5XlY_-WlSa7Mb5eoDlYJ2WntAakBxKIUfSlivfmpXvp-V2IUeQS4O_8q7dIOPV4TCc5EFsPM_eiuTPYxM8S0F1ar0Eeg0icjWqCypE9NTxU"></p><p>There are dozens of different FIDO2-compatible security keys available from companies like Yubico, Feitian, Google, Kensington, and others. And developers have built support into operating systems (iOS, Android, Windows, macOS) so you can use platform authenticators like Touch ID sensors on MacBooks and facial recognition and fingerprint sensors on PCs.</p><p>Victory, hooray! Let’s go and get a FIDO2 Security Key so we can use it everywhere!</p><h2>Nothing supports WebAuthn! What?!</h2><p>Except when you go to set it up, you will find that basically <strong>no major web application</strong> supports WebAuthn the way we envisioned here as replacement for the password! D’oh!</p><p>Web applications support WebAuthn fairly well as a <strong>second factor</strong>, backward compatible to FIDO U2F, but even that support remains far from universal.</p><p>Story time! I’ve always been more than a little paranoid, an occupational hazard having worked around web security for 20+ years. Outside of work, I already had a unique, complex, and <a href="https://haveibeenpwned.com/Passwords">non-Pwned password</a> for each of the 562 websites and apps I have a login for (not counting the work apps behind Okta SSO of course). Yes, I use a <a href="https://1password.com/">password manager</a>—I’m not an animal.</p><p>Let me recount my experience when I went to set up WebAuthn on every account whose security really matters to me! Passwords begone! Here are the results!</p><h3>Let’s see the scoreboard</h3><ul><li>GMail: Yes! But alas only as a U2F security key after password.</li><li>Another email: No, but at least they support generic <a href="https://en.wikipedia.org/wiki/Time-based_One-time_Password_algorithm">TOTP second factors</a>.</li><li>Apple iCloud: Proprietary multi-factor authentication, but that’s a different story.&nbsp;</li><li>Cellular provider: LOL NOPE! Security PIN only and SMS, which they helpfully are willing to send to my kids’ phone numbers too in case they ever guess my password!</li><li>Top modern robo advisor: No, but at least they support generic TOTP.</li><li>Top online brokerage: No, but at least they support a proprietary third-party TOTP app.</li><li>Top retirement account: LOL NOPE! SMS!</li><li>Top-three credit card issuer: LOL NOPE! SMS!</li><li>Another top-three credit card issuer: LOL NOPE! No strong authentication of ANY kind.</li><li>Top-five bank: LOL NOPE! SMS! Or they’ll sell you a 90’s-style hardware TOTP token!</li><li>Local credit union: LOL NOPE! They got nothing, but the last time I tried to log in my account was locked out, so good to know that somebody’s trying to brute-force my complex, globally unique password :)</li><li>Online crypto currency wallet: Yes! But alas only as a U2F security key after password. Also, they block my FIDO2 platform authenticator and only allow USB security keys. And once you add a security key, you lose your TOTP! It’s one or the other!&nbsp;&nbsp;</li><li>My DNS / hosting provider: Yes! But alas only as a U2F security key after password.</li><li>Facebook: Yes, but just as a second factor, U2F mode.</li><li>Twitter: Yes, but just as a second factor, U2F mode, and the settings are buried deep.</li><li>Zoom: Nope. Just a well-hidden option to add a generic TOTP second factor.</li><li>Dropbox: Yes, but just as a second factor, U2F mode.</li></ul><p>So, the <strong>score is 0 (zero) out of 17 for going passwordless</strong> with WebAuthn. Sigh.</p><p>Or we could say the score is 6 out of 17, if we accept U2F mode using WebAuthn as a second factor.</p><h3>Don’t banks want better security?</h3><p>Well, they do, but they are not pushing end-user-visible and end-user-operated security tools, because today even the best ones like WebAuthn add friction in the form of inconsistencies and confusion. And as I’ll show you shortly, even with WebAuthn that friction is unfortunately real.&nbsp;</p><p>Any friction translates to confused and angry customers, which translates to millions of dollars in call-center cost and customer churn. Remember that even small banks have tens of thousands of users, large ones tens of millions! This is why banking security professionals focus so heavily on the invisible, back-end fraud detection and risk management tools. And if an attacker compromises an account and takes money, the bank can make the account holder whole again and treat it as a cost of doing business. Corporate banking portals dealing with big money transfers typically use strong authentication, as the user population is much smaller and more receptive to adopting security measures.</p><p>So, don’t look for consumer financial services to adopt passwordless WebAuthn first. That won’t happen until browsers and operating systems universally support it and <strong>not until the user experience is consistent and great</strong>.</p><h2>Why can’t we have nice things?</h2><p>So are WebAuthn and FIDO2 doomed to fail? And can it ever get us to passwordless?&nbsp;</p><p>Well, the technology doesn’t suck, the protocols work, the basic tech is kind of great, and you can and should use WebAuthn as a second-factor authenticator everywhere that matters! Security keys are one of the <a href="https://krebsonsecurity.com/2018/07/google-security-keys-neutralized-employee-phishing/">strongest practical authenticators</a> available today, and they are useful for anyone who would ever get this far into a blog post like this.</p><p>The problem is, while they technically work, the <a href="https://blog.silverorange.com/web-authn-ux-89a61ba7b555">user experience is broken</a>.&nbsp;</p><p>Every website has a different path for setting things up. What the security settings are called and where they are found are wildly inconsistent from one website to the next.&nbsp;</p><p>Every browser and operating system presents the experience in a different-looking pane or slide-over. The terminology different browsers use is inconsistent and confusing.&nbsp;</p><p>Even the very few sites that support the full passwordless WebAuthn experience have to provide other options, so you have to click on a separate link for the passwordless path. And if you make a mistake during setup, the error messages can be less than helpful.</p><p><img src="https://lh6.googleusercontent.com/b1qcKPRRquGHsuNgvomjLj1p0e9fsSTy605x88BVKynqrnKiV5bI8kU_yznvCRgHLAq_mDE20nnApEsPK9Ob5zzbah_w3l-Zcau-x8EHQ5i6i0-78NWCks5JhbcYbnU-O8Xxhmwj"></p><p>Therefore it is hard to recommend WebAuthn to the people we most want to help—our friends and family, children and parents. The way websites, browsers and OSs implement WebAuthn today does not pass my will-my-spouse-murder-me-in-my-sleep standard of deployability.&nbsp;</p><h2>Can I get passwordless WebAuthn?</h2><p>In short, probably not today. But it’s not hopeless!</p><p>Frankly, you might get passwordless first at work. Modern single sign-on providers make it possible to use WebAuthn and other modern authenticators in combination with risk scoring, device management, and other tools in the corporate IT tool box to enable end-to-end passwordless experiences. These corporate solutions, like <a href="https://www.okta.com/fastpass/">Okta FastPass</a>, combine on-device biometrics and device management solutions to get there. At work, we are <a href="https://www.okta.com/blog/2019/10/the-dogfooding-chronicles-webauthn-the-path-to-passwordless/">eating our own dogfood</a> with WebAuthn!</p><p>Outside of the workplace, across the 17 sites I looked to secure, I found none that yet supported a bona-fide WebAuthn passwordless experience.&nbsp;</p><h2>So what should I do?</h2><p>Don’t give up!</p><p>Even if we can’t have true passwordless today, <strong>adding WebAuthn as a strong second-factor authentication is absolutely worth it</strong>. I can use WebAuthn as a second factor at 6 of my 17 sites I checked. <a href="https://youtu.be/w-YDV6vC2qo">Not great, not terrible!</a> Another 4 of the 17 support adding TOTP one-time passwords. Although technically these one-time passwords are phishable, the risk is vastly reduced if you’re using a password manager app as your TOTP authenticator as well, as the password manager won’t autofill your credentials to the phishing site.&nbsp;</p><p>So using WebAuthn as a second-factor authenticator is definitely worth it and user experience is fairly seamless when combined with password managers.</p><p>But how do we ever get to the promised WebAuthn passwordless world?!</p><p>Let’s keep the pressure on the browser and operating system vendors and ask for consistency. Ask <a href="https://support.google.com/chrome/answer/95315">Chrome</a>, <a href="https://qsurvey.mozilla.com/s3/FirefoxInput/">Firefox</a>, and <a href="https://www.apple.com/feedback/safari.html">Safari</a> to standardize their naming conventions for a better user experience!</p><p>And on the other hand, let’s keep the pressure on the <a href="https://twofactorauth.org/">websites that don’t support strong authentication</a> at all and more specifically, let’s push <a href="https://www.dongleauth.info/">websites that don’t support security keys</a> to add that support.</p><p>If you’re an IT administrator and want to support WebAuthn for your employee access, it’s easy to do with modern SSO providers like <a href="https://www.okta.com/resources/whitepaper-how-webauthn-works-oad">Okta</a>.&nbsp;</p><p>And if you’re one of the people who builds these websites, consider adding WebAuthn support to it! The frameworks are there and ready for you to use, see <a href="https://developers.yubico.com/WebAuthn/WebAuthn_Developer_Guide/Overview.html">Yubico’s WebAuthn developer guide</a> and <a href="https://2018.pycon-au.org/talks/44258-webauthn-multifactor-auth-for-everyone/">this talk</a> for examples. With just a little more design and usability polish, we can all win!</p><p>Thanks for reading and stay safe!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Commuters prefer origin to destination transfers (128 pts)]]></title>
            <link>https://pedestrianobservations.com/2023/06/30/why-commuters-prefer-origin-to-destination-transfers/</link>
            <guid>36564608</guid>
            <pubDate>Sun, 02 Jul 2023 19:07:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pedestrianobservations.com/2023/06/30/why-commuters-prefer-origin-to-destination-transfers/">https://pedestrianobservations.com/2023/06/30/why-commuters-prefer-origin-to-destination-transfers/</a>, See on <a href="https://news.ycombinator.com/item?id=36564608">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
<p>It’s an empirical observation that rail riders who are faced with a transfer are much more likely to make the trip if it’s near their home than near their destination. Reinhard Clever’s since-linkrotted work gives an example from Toronto, and American commuter rail rider behavior in general; <a href="https://pedestrianobservations.com/2011/10/28/why-the-7-to-secaucus-wont-work/">I was discussing it from the earliest days of this blog</a>. He points out that American and Canadian commuter rail riders drive long distances just to get to a cheaper or faster park-and-ride stations, but are reluctant to take the train if they have any transfer at the city center end.</p>



<p>This pattern is especially relevant as, due to continued job sprawl, American rail reformers keep looking for new markets for commuter rail to serve and set their eyes on commutes to the suburbs. <a href="https://blog.bimajority.org/2018/11/12/a-further-examination-of-the-agricultural-branch-for-regional-rail/">Garrett Wollman is giving an example</a>, in the context of the Agricultural Branch, a low-usage freight line linking to the Boston-Worcester commuter line that could be used for local passenger rail service. Garrett talks about the potential ridership of the line, counting people living near it and people working near it. And inadvertently, his post makes it clear why the pattern Clever saw in Toronto is as it is.</p>



<p><strong>Residential and job sprawl</strong></p>



<p>The issue at hand is that residential sprawl and job sprawl both require riders to spend some time connecting to the train. The more typical example of residential sprawl involves isotropic single-family density in a suburban region, with commuters driving to the train station to get on a train to city center; they could be parking there or being dropped off by family, but in either case, the interface to the train for them is in their own car.</p>



<p>Job sprawl is different. Garrett points out that there are 79,000 jobs within two miles of a potential station on the Ag Branch, within the range of corporate shuttles. With current development pattern, rail service on the branch could follow the best practices there are and I doubt it would get 5% of those workers as riders, for all of the following reasons:</p>



<ul>
<li>The corporate shuttle is a bus, with all the discomfort that implies; it usually is also restricted in hours even more than traditional North American commuter rail – the frequency on the LIRR or even Caltrain is low off-peak but the trains do run all day, whereas corporate shuttles have a tendency to only run at peak. There is no own-car interface involved.</li>



<li>The traditional car-commuter train interface is to jobs in areas with traffic congestion and difficult parking. The jobs in the suburbs face neither constraint. Of note, Long Islanders working in Manhattan do transfer to the subway, because driving to the East Side to avoid the transfer from Penn Station is not a realistic option.</li>



<li>The traditional car-commuter train interface is to jobs in a city center served from all directions by commuter rail. In contrast, the jobs in the suburbs are only served by commuter rail along a single axis. There is a fair amount of reverse-peak ridership from San Francisco to Silicon Valley jobs or from New York to White Plains and Stamford jobs, even if at far lower rates than the traditional peak direction – but most people working at a suburban job center live in another suburb, own a car, and either commute in a different direction from that of the train or don’t live and work close enough to a station that the car-train-shuttle trip is faster than an all-car trip. </li>
</ul>



<p>Those features are immutable without further changes in urban design. Then there are other features that interact with the current timetables and fares. North American commuter rail has so many features designed to appeal to the type of person who drives everywhere and uses the train as a shuttle  extending their car-oriented lifestyle into the city – premium fares, heavy marketing as different from normal public transit, poor integration with said normal public transit – that interface with one’s own car is especially valuable, and interface with public transit is especially unvalued.</p>



<p>And yet, it’s clearly possible to make it work. How?</p>



<p><strong>How Europe makes it work</strong></p>



<p>Commuter trains in Europe (nobody calls them regional rail here – <a href="https://pedestrianobservations.com/2019/08/20/s-bahn-and-regionalbahn/">that term is reserved for hourly long-range trains</a>) get a lot of off-peak ridership and are not at all used exclusively by 9-to-5 commuters who drive for all other purposes. Some of this is to suburban job centers. How does this work, besides timetables and other operating practices that American reformers recognize as superior to what’s available in the US and Canada?</p>



<p>The primary answer is near-center jobs. Paris and La Défense have, between them, about 37% of the total jobs of Ile-de-France. Within the same land area, 100 km^2, both New York and Boston have a similar proportion of the jobs in their respective metro areas, about 35% each, as does San Francisco within the smaller definition of the metro area, excluding Silicon Valley. Ile-de-France’s work trip modal split is about 43%, metro New York’s is 33%, metro San Francisco’s is 17%, metro Boston’s is 12%.</p>



<p>So where Boston specifically fails is not so much office park jobs, such as those on Route 128, but near-center jobs. Its urban and suburban transit networks do a poor job of getting people to job centers like Longwood, the airport, Cambridge, and the Seaport. The same is true of San Francisco. New York’s network does a better but still mediocre job at connecting to Long Island City and Downtown Brooklyn, and a rather bad job at connecting to inner-suburban New Jersey jobs, but so many of those 35% jobs in the central 100 km^2 are in fact in the central 23 km^2 of the Manhattan core, and nearly half are in the central 4 km^2 comprising Midtown, that the poor service to the other 77 km^2 can be overlooked.</p>



<p>As far as commuter rail is concerned, the main difference in ridership between the main European networks – the Paris RER, the Berlin S-Bahn, and so on – and the American ones is how useful they are for plain urban service. Nearly all Berlin S-Bahn traffic is within the city, not the suburbs; the RER’s workhorse stations are mostly in dense inner suburbs that in most other countries would have been amalgamated into the city already.</p>



<p>To the extent that this relates to American commuter rail reforms, it’s about coverage within the city: multiple city stations, good (free, frequent) connections to local urban rail, high frequency all day to encourage urban travel (a train within the city that runs every half an hour might as well not run).</p>



<p>Suburban ridership is better here as well, but this piggybacks on very strong urban service, giving strong service from the suburbs to the city. Suburb-to-suburb commutes are done largely by car – Ile-de-France’s modal split is 43%, not 80%; there are fewer of them than in most of the US, but not fewer than in New York, Boston, or San Francisco.</p>



<p>But, well, Paris’s modal split is noticeably higher than the job share within the city – a job share that does include drivers. What gives?</p>



<p><strong>Suburban transit-oriented development</strong></p>



<p>TOD in the suburbs can create a pleasant enough rail commute that the modal split is respectable, if nothing like what is seen for jobs in Paris or Manhattan. However, for this to work, planners must eliminate the expression “corporate shuttle” from their lexicon.</p>



<p>Instead, suburban job sites must be placed right on top of the train station, or within walking distance along streets that are decently walkable. I can’t think of good Berlin examples – Berlin maintains high modal split through a strong center – but I can think of several Parisian ones: Marne-la-Vallée (including Disneyland), Noisy, Evry, Cergy. Those were often built simultaneously with greenfield suburban lines that were then connected to the RER, rather than on top of preexisting commuter lines.</p>



<p>They look nothing like American job sprawl. Here, for example, is Cergy:</p>



<figure><a href="https://pedestrianobservations.files.wordpress.com/2023/06/cergy.png"><img data-attachment-id="9549" data-permalink="https://pedestrianobservations.com/2023/06/30/why-commuters-prefer-origin-to-destination-transfers/cergy/" data-orig-file="https://pedestrianobservations.files.wordpress.com/2023/06/cergy.png" data-orig-size="1412,876" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="cergy" data-image-description="" data-image-caption="" data-medium-file="https://pedestrianobservations.files.wordpress.com/2023/06/cergy.png?w=300" data-large-file="https://pedestrianobservations.files.wordpress.com/2023/06/cergy.png?w=830" src="https://pedestrianobservations.files.wordpress.com/2023/06/cergy.png?w=1024" alt="" srcset="https://pedestrianobservations.files.wordpress.com/2023/06/cergy.png?w=1024 1024w, https://pedestrianobservations.files.wordpress.com/2023/06/cergy.png?w=150 150w, https://pedestrianobservations.files.wordpress.com/2023/06/cergy.png?w=300 300w, https://pedestrianobservations.files.wordpress.com/2023/06/cergy.png?w=768 768w, https://pedestrianobservations.files.wordpress.com/2023/06/cergy.png 1412w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>There are parking garages visible near the train stations, but also a massing of mid-rise residential and commercial buildings.</p>



<p>But speaking of residential, the issue is that employers looking for sites to locate to have no real reason to build offices on top of most suburban train stations – the likeliest highest and best usage is residential. In the case of American TOD, even the secondary-urban centers, like Worcester, probably have much more demand for residential than commercial TOD within walking distance of the train station – employers who are willing to pay near-train station premium rent might as well pay the higher premium of locating within the primary city, where the commuter shed is much larger.</p>



<p>In effect, the suburban TOD model does not counter the traditional monocentric urban layout. It instead extends it to a much larger scale. In this schema, the entirety of the city, and not just its central few square kilometers, is the monocenter, served by different lines with many stations on them. Berlin is ahead of the curve by virtue of its having multiple close-by centers as a Cold War legacy, but Paris is similar (its highest-intensity commercial TOD is in La Défense and in in-city sites like Bercy, on top of former railyards attached to Gare de Lyon).</p>



<p>At no point does this model include destination-end transfers in the suburbs. In the city, it does: a single line cannot cover all urban job sites; but the transfer is within the rapid transit system. But in the suburbs, the jobs that are serviceable by public transportation are within walking distance of the station. Shuttles may exist, but are secondary, and job sites that require them are and will always be auto-centric.</p>
			
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google search's death by a thousand cuts (132 pts)]]></title>
            <link>https://matt-rickard.com/google-searchs-death-by-a-thousand-cuts</link>
            <guid>36564042</guid>
            <pubDate>Sun, 02 Jul 2023 18:14:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matt-rickard.com/google-searchs-death-by-a-thousand-cuts">https://matt-rickard.com/google-searchs-death-by-a-thousand-cuts</a>, See on <a href="https://news.ycombinator.com/item?id=36564042">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>Reddit communities are still private in protest of new API rules. Twitter moved beyond a login wall and is rate-limiting users. Users are frustrated but still using these sites.</p><p>But — what will happen to the Google Index? Millions of search results are effectively dead links. Users that refined Reddit search results via Google are now out of luck (Reddit’s search is inferior). Tweets in the search engine results page (SERP) now lead to a login wall for many users.</p><p>Advancements in <a href="https://matt-rickard.com/will-llms-disrupt-google" rel="noopener noreferrer nofollow">AI might disrupt Google Search</a> in a roundabout way:</p><p>Large models are trained on public data scraped via API. Content-heavy sites are most likely to be disrupted (why post on StackOverflow?) by models trained on their own data. Naturally, they want to restrict access and either (1) sell the data or (2) train their own models. This restriction prevents (or complicates) Google’ automatic scraping of the data for Search (and probably for training models, too).</p><p>Google will lose results, site by site — it will be Google Search’s death by a thousand cuts.</p><p>It’s estimated that Wikipedia shows up on the first page of 99% of searches on Google. What if Wikipedia started charging or restricting API access? It’s a dataset found in almost every large language model corpus. The Wikimedia Foundation is constantly looking for financial assistance (“please donate” banners) and has already launched an enterprise API product (Wikimedia Enterprise, 2021).</p><p>One by one, search results become dead links and are removed from the index. Users will start to rely on site-specific searches behind walled gardens. The first page of search results will not only be filled with ads but will be missing key results. Google may try to augment results with AI-generated answers, but (1) not all of these answers will be good enough, and (2) the data needed to train these answers will increasingly be found behind login or paywalls. Search might progressively get worse over the years until a new alternative arises.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[JavaScript Gom Jabbar (406 pts)]]></title>
            <link>https://frantic.im/javascript-gom-jabbar/</link>
            <guid>36564010</guid>
            <pubDate>Sun, 02 Jul 2023 18:12:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://frantic.im/javascript-gom-jabbar/">https://frantic.im/javascript-gom-jabbar/</a>, See on <a href="https://news.ycombinator.com/item?id=36564010">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <header>
    
    
  </header>
  <p>You have been using JavaScript for 10 years. It’s time for your test. You are sitting in front of a computer. The test is simple: you have to open a package.json file and read it. The <code>package.json</code> is full of pain. You have to read it all.</p>
<p>You look at <code>version</code>, you haven’t reached 1.0 yet. Semver causes unpleasant memories, but you’ve learned to ignore them for so long that you don’t even notice the tickling sensation in your skull.</p>
<p>You wish you used a different <code>name</code> for your package, but some random internet person has squatted that name 7 years ago and never updated their package since. It’s only mildly discomforting. Maybe the test isn’t so bad after all?</p>
<p>Both <code>main</code> and <code>browser</code> fields are present, you sense traces of Isomorphic JavaScript. In a flash, you remember requiring <code>fs</code> module from your browser bundle. These memories are very unpleasant. The hacks you had to do to make it work were even more unpleasant.</p>
<p>The <code>type</code> is set to <code>module</code>. This has something to do with the migration from <code>requires</code> to <code>imports</code>. Why do we have to care about this, again? The extensive pain you’ve experienced trying to importing ES5 modules from ESM modules and vice versa overwhelms you again.</p>
<p>You make your way to <code>scripts</code>. What a hot, painful mess it is. You can’t look at them without your heart rate going to 150. lint, lintall, lintfast, lintdiff. Parallel runs, obscure arguments, double-escaping JSON-formatted arguments. Subcommands calling npm even through you switched to yarn and then pnpm. Thousands of variations, premutations and details make you shiver. Why do these things have to be here? Why do they need to be so complicated?</p>
<p>Some scripts still use <code>watchman</code>. Gotta remember to not use symlinks because it doesn’t support them (and the issue has been open since 2015). There’s also this gulp-based script that nobody has the guts to replace with anything else that’s considered more modern. You think that there’s actually no modern version of gulp but it feels outdated and you definitely want to get rid of it. The pains spreads from your head into your neck and shoulders.</p>
<p>The pain is barely tolerable when you reach <code>dependencies</code>. So, so many of them. There’s <code>left-pad</code>, the legendary tiny package that broke all internet, collectively causing the amount of pain and drama comparable to the destruction of Alderaan.</p>
<p>Every time you modify dependency list, some of the dependencies print out screens-worth of messages to your console, asking for donations, warning about breaking changes. You gave up trying to understand these. You only hope none of them are malicious enough to steal your secrets or ruin your computer. The threat of potential pain of that magnitute is frighting.</p>
<p>There’s also moment.js. You love that library, it has a really pleasent API. But the internet decided it’s too “mutable”, too fat, it doesn’t support treeshaking and now you have to migrate to date-fns. You haven’t started yet, but you already feel the painful refactoring in your bones.</p>
<p>Looking at every package in that list causes some amount of trauma recall. But what’s even more concerning is that the version of these packages are way behind what’s considered “current”. You know that you should upgrade them. But you also have tried that before and you know how much suffering it brings. Things will break in so many ways, big and loud ways, small and subtle ways.</p>
<p>The next thing in this damn file is <code>resolutions</code>. Yes, you remember this one. It’s a suffering you choose to avoid dealing with package upgrades.</p>
<p>You scroll down to <code>devDependencies</code>. You can’t remember the time when you only needed non-dev dependencies. Why do we have this split? Yes, right, to cause more pain.</p>
<p><code>eslint</code>. Its configuration got so strict that you can’t even write code anymore. Any small misstep and you get an angry red underline. Your CI is configured to treat any lint problem as the end of the world. It gives a false sense of security to your junior engineers on the team. You survived serveral holy wars on which rules to enable. The pain is proportional to the amount of <code>eslint-ignore</code>s you have all over your codebase. There’s a lot.</p>
<p>You also notice <code>postcss</code> hiding there. This package is a mystery to you. You don’t use it directly, it’s a requirement of a dependency of a dependency. But it’s the package that’s constantly causing you pain by throwing obscure C++ compilation errors on any new platform you try to <code>npm install</code> on. If CSS itself wasn’t painful enough.</p>
<p>Oh, dear <code>jest</code>. It started as a fast test runner. But now it’s big and fat, it depends on some babel packages while the rest of your app is transpiled by a mix of esbuild and swc. Properly configuring it with ESM and TypeScript was a PhD science project.</p>
<p>You stop to count how many tools and parsers work on your codebase: TypeScript, esbuild, swc, babel, eslint, prettier, jest, webpack, rollup, terser. You are not sure if you missed any. You are not sure if you want to know. The level of pain is so high you forget about anything else.</p>
<p><code>engines</code> prominently lists <code>node</code>. And while you hate it with the depth of your soul, you are not going to Bun or Deno because you know this will not stop the pain. This will only make the pain worse.</p>
<p>It’s the end of the file now. Final closing curly brace. You close the tab and take a breath. Look around. You are still alive, your hands and your brain intact. You survived. For now.</p>

  
  






  <div>
    <p>Hello! This text lives here to convince you to subscribe. If you are reading this, consider clicking that subscribe button for more details.</p>
    <p>I write about programming, software design and side projects <a href="https://frantic.im/subscribe/" target="_blank"><svg viewBox="0 0 800 800"><path d="M493 652H392c0-134-111-244-244-244V307c189 0 345 156 345 345zm71 0c0-228-188-416-416-416V132c285 0 520 235 520 520z"></path><circle cx="219" cy="581" r="71"></circle></svg> Subscribe</a></p>
  </div>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AMD CPU Use Among Linux Gamers Approaching 70% Marketshare (305 pts)]]></title>
            <link>https://www.phoronix.com/news/AMD-CPU-Linux-Gaming-67p</link>
            <guid>36563979</guid>
            <pubDate>Sun, 02 Jul 2023 18:09:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phoronix.com/news/AMD-CPU-Linux-Gaming-67p">https://www.phoronix.com/news/AMD-CPU-Linux-Gaming-67p</a>, See on <a href="https://news.ycombinator.com/item?id=36563979">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="AMD" src="https://www.phoronix.com/assets/categories/amd.webp" width="100" height="100"></p><p>
Besides being curious about the Steam Survey results for indicating the size of the Linux gaming marketshare as an overall percentage, one of the interesting metrics we are curious about each month is the AMD vs. Intel CPU marketshare for Linux gaming. AMD has been on quite an upward trajectory among Linux gamers/enthusiasts in recent years not only for their Radeon graphics cards with their popular open-source driver stack but their Ryzen CPUs have become extremely popular with Linux users. With <a href="https://www.phoronix.com/news/Steam-June-2023-Statistics">the new Steam Survey results for June</a>, AMD CPUs are found on nearly 70% of Linux gaming systems polled by Steam.
</p><p>
The June results put the AMD CPU marketshare for Linux users at 67%, a remarkable 7% increase month-over-month. In part that's due to the Steam Deck being powered by an AMD SoC but it's been a trend building for some time of AMD's increasing Ryzen CPU popularity among Linux users to their open-source driver work and continuing to build more good will with the community.
</p><p><img src="https://www.phoronix.net/image.php?id=2023&amp;image=steam_june_4"></p>
<p>In comparison, last June the AMD CPU Linux gaming marketshare <a href="https://www.phoronix.com/news/Steam-Linux-June-2022">came in at 45%</a> while Intel was at 54%. Or at the start of 2023, <a href="https://www.phoronix.com/news/Steam-Survey-January-2023">AMD CPUs were at a 55% marketshare</a> among Linux gamers. Or if going back six years, <a href="https://www.phoronix.com/news/Steam-Survey-July-2017">AMD CPU use among Linux gamers was a mere 18%</a> during the early Ryzen days.
</p><p><img src="https://www.phoronix.net/image.php?id=2023&amp;image=windows_cpu_gamers_june" alt="Windows CPU stats for June"></p>
<p>It's also the direct opposite on the Windows side. When looking at the Steam Survey results for June limited to Windows, there Intel has a 68% marketshare to AMD at 32%.
</p><p><a href="https://www.phoronix.com/image-viewer.php?id=2023&amp;image=amd_gaming_cpus_june_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=2023&amp;image=amd_gaming_cpus_june_med" alt="AMD Ryzen boxes, cheers"></a></p>
<p>Beyond the Steam Deck, it's looking like AMD's efforts around open-source drivers, <a href="https://www.phoronix.com/news/Dell-Mario-On-AMD-Linux-Team">AMD expanding their Linux client (Ryzen) development efforts</a> over the past two years, promises around <a href="https://www.phoronix.com/search/OpenSIL">OpenSIL</a>, and other efforts commonly covered on Phoronix are paying off for AMD in wooing over their Linux gaming customer base.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chinese Tech Terms Explained in English (166 pts)]]></title>
            <link>https://16x.engineer/2022/10/18/chinese-tech-terms.html</link>
            <guid>36563956</guid>
            <pubDate>Sun, 02 Jul 2023 18:06:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://16x.engineer/2022/10/18/chinese-tech-terms.html">https://16x.engineer/2022/10/18/chinese-tech-terms.html</a>, See on <a href="https://news.ycombinator.com/item?id=36563956">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
            <p>
              Chinese tech companies like ByteDance and Tencent are setting up
              engineering offices outside China. Local hires in these global
              offices are becoming a norm.
            </p>
            <p>
              These locally hired engineers typically have limited Chinese
              language proficiency. It is a challenge for them to understand the
              Chinese tech terms used in their daily work, and to communicate
              with their Chinese colleagues.
            </p>
            <p>
              Here are 5 common Chinese tech terms, along with explanations and
              examples of usage in a sentence.
            </p>
            <h2 id="huidu">Huidu</h2>
            <blockquote>
              <p>灰度 <span>huī dù</span></p>
            </blockquote>
            <p>
              <img src="https://16x.engineer/public/post-images/optimized/chinese-huidu.webp" alt="Huidu in English example screenshot">
            </p>
            <p>
              Huidu is a widely used Chinese technical term in companies like
              Tencent and Alibaba. Huidu means rolling out experimental new
              features to a small subset of users for testing.
            </p>
            <p>
              The implication of huidu is that the new feature may be launched
              officially (at a later date), or scrapped if it did not have the
              desired outcome.
            </p>
            <h2 id="huidu-in-english">Huidu in English</h2>
            <p>
              The literal translation of huidu is “grayscale”. Intuitively,
              huidu represents the transition state between black and white.
            </p>
            <p>
              Note that huidu can be used to describe product features,
              functionalities, or code deployment.
            </p>
            <p>
              When describing a product feature, the close equivalent would be
              <strong>beta release</strong> or
              <strong>phased rollout</strong> in English.
            </p>
            <p>
              When used for describe code deployment,
              <strong>canary release</strong> is also an accurate translation.
            </p>
            <h2 id="examples-of-huidu-in-a-sentence">
              Examples of huidu in a sentence
            </h2>
            <ul>
              <li>
                <p>
                  <em>WeChat is <strong>huidu</strong> testing a new feature that
                    allows users to register an additional WeChat account with
                    an existing phone number.</em>
                </p>
              </li>
              <li>
                <p>
                  <em>Lenovo started <strong>huiduing</strong> new version of
                    operating system for its tablets.</em>
                </p>
              </li>
            </ul>
            <h2 id="lunzi">Lunzi</h2>
            <blockquote><p>轮子 lún zi</p></blockquote>
            <p>
              <img src="https://16x.engineer/public/post-images/optimized/chinese-lunzi.webp" alt="Lunzi in English example screenshot">
            </p>
            <p>
              Lunzi describes tools, libraries or frameworks that have been
              invented or reinvented multiple times.
            </p>
            <p>
              Typically it is used for new things that are created to solve a
              specific problem, but bear resemblance to something existing.
            </p>
            <h2 id="lunzi-in-english">Lunzi in English</h2>
            <p>
              The literal translation for lunzi is “wheel”, and the origin of
              the word is likely from the English phrase “reinvent the wheel”.
            </p>
            <p>
              Despite the apparent origin from English, lunzi as a word has no
              equivalent translation in English.
            </p>
            <p>
              The literal translation “<strong>wheel</strong>” might be the best
              candidate.
            </p>
            <h2 id="example-of-lunzi-in-a-sentence">
              Example of lunzi in a sentence
            </h2>
            <ul>
              <li>
                <p>
                  <em>Engineers need create <strong>lunzi</strong> to fulfill
                    KPIs or get promoted.</em>
                </p>
              </li>
              <li>
                <p>
                  <em><strong>Lunzi</strong> created by others do not fulfil our
                    specific needs.</em>
                </p>
              </li>
            </ul>
            <h2 id="chendian">Chendian</h2>
            <blockquote><p>沉淀 chén diàn</p></blockquote>
            <p>
              <img src="https://16x.engineer/public/post-images/optimized/chinese-chendian.webp" alt="Chendian in English example screenshot">
            </p>
            <p>
              Chendian is not a technical term, but it is commonly used in
              Chinese tech companies. It means consolidating learnings from past
              experience.
            </p>
            <p>
              It also implies coming up with a systematic solution to a
              recurring problem.
            </p>
            <h2 id="chendian-in-english">Chendian in English</h2>
            <p>
              The literal translation for chendian is “chemical precipitation”,
              drawing from the intuition that things are consolidated from
              liquid form to solid state.
            </p>
            <p>
              At the beginning, things are messy and fluid. But as you learn and
              progress, they because more clear and structured.
            </p>
            <p>
              There seems to be no equivalent term in English to describe this
              concept.
            </p>
            <h2 id="example-of-chendian-in-a-sentence">
              Example of chendian in a sentence
            </h2>
            <ul>
              <li>
                <p>
                  <em>Team lead has some expectations for new interns, such as
                    critical thinking, <strong>chendian</strong> and knowledge
                    sharing.</em>
                </p>
              </li>
              <li>
                <p>
                  <em>Our team managed to <strong>chendian</strong> tools and
                    organizational capabilities from the double 11 sale.</em>
                </p>
              </li>
            </ul>
            <h2 id="dapan">Dapan</h2>
            <blockquote><p>大盘 dà pán</p></blockquote>
            <p>
              <img src="https://16x.engineer/public/post-images/optimized/chinese-dapan.webp" alt="Dapan in English example screenshot">
            </p>
            <p>
              In Chinese tech companies, dapan is used to describe dashboards
              with various charts, where you can monitor key system metrics or
              business metrics in real time.
            </p>
            <p>
              It is especially important for e-commerce companies like Alibaba
              and JD who run big sales events like double 11.
            </p>
            <h2 id="dapan-in-english">Dapan in English</h2>
            <p>
              Dapan originally refers to the big screens in stock exchanges
              showing market data.
            </p>
            <p>
              The close equivalent of dapan in English would be “<strong>monitoring dashboard</strong>”.
            </p>
            <h2 id="examples-of-dapan-in-a-sentence">
              Examples of dapan in a sentence
            </h2>
            <ul>
              <li>
                <p>
                  <em>Remember to monitor <strong>dapan</strong> closely when
                    performing production deployment.</em>
                </p>
              </li>
              <li>
                <p>
                  <em>Popular <strong>dapan</strong> products usually come with
                    WYSIWYG editors.</em>
                </p>
              </li>
            </ul>
            <h2 id="maidian">Maidian</h2>
            <blockquote>
              <p>埋点 <span>mái diǎn</span></p>
            </blockquote>
            <p>
              <img src="https://16x.engineer/public/post-images/optimized/chinese-maidian.webp" alt="Maidian in English example screenshot">
            </p>
            <p>
              In Chinese companies, maidian refers to embedding of tracking code
              to monitor and analyse user behaviour.
            </p>
            <p>
              This is typically required by product and data analytics teams,
              and the tracking code is embedded in the product by front-end
              engineers.
            </p>
            <h2 id="maidian-in-english">Maidian in English</h2>
            <p>
              As individual characters, “mai” means burying, and “dian” means
              points. The phrase “maidian” literally means “embedding points” or
              “burying seeds”.
            </p>
            <p>
              The intuition is that by “embedding” the “seed” in the product,
              the user journey can be mapped out later.
            </p>
            <p>
              It can be translated into <strong>tracking</strong>,
              <strong>tagging</strong> or
              <strong>user data analytics</strong> depending on the context.
            </p>
            <h2 id="examples-of-maidian-in-a-sentence">
              Examples of maidian in a sentence
            </h2>
            <ul>
              <li>
                <p>
                  <em>Data analytics team need to design a rigorous
                    <strong>maidian</strong> system and produce
                    <strong>maidian</strong> document to support subsequent user
                    behaviour analysis.</em>
                </p>
              </li>
              <li>
                <p>
                  <em>The cost of <strong>maidian</strong> is high because every
                    widget with user interactions needs to embed
                    <strong>maidian</strong> code.</em>
                </p>
              </li>
            </ul>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Economic inequality cannot be explained by individual bad choices, study finds (129 pts)]]></title>
            <link>https://phys.org/news/2023-06-economic-inequality-individual-bad-choices.html</link>
            <guid>36563815</guid>
            <pubDate>Sun, 02 Jul 2023 17:53:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2023-06-economic-inequality-individual-bad-choices.html">https://phys.org/news/2023-06-economic-inequality-individual-bad-choices.html</a>, See on <a href="https://news.ycombinator.com/item?id=36563815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2023/economic-inequality-ca.jpg" data-src="https://scx2.b-cdn.net/gfx/news/2023/economic-inequality-ca.jpg" data-sub-html="Correlation between ten biases within 3346 participants showed each bias was largely unique and not collinear with other biases assessed, with the exception of overplacement&nbsp;and overestimation (which rely on the presence of some biases). Credit: <i>Scientific Reports</i> (2023). DOI: 10.1038/s41598-023-36339-2">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2023/economic-inequality-ca.jpg" alt="Economic inequality cannot be explained by individual bad choices" title="Correlation between ten biases within 3346 participants showed each bias was largely unique and not collinear with other biases assessed, with the exception of overplacement&nbsp;and overestimation (which rely on the presence of some biases). Credit: Scientific Reports (2023). DOI: 10.1038/s41598-023-36339-2" width="685" height="530">
             <figcaption>
                Correlation between ten biases within 3346 participants showed each bias was largely unique and not collinear with other biases assessed, with the exception of overplacement&nbsp;and overestimation (which rely on the presence of some biases). Credit: <i>Scientific Reports</i> (2023). DOI: 10.1038/s41598-023-36339-2
            </figcaption>        </figure>
    </div>
<p>A global study led by a researcher at Columbia University Mailman School of Public Health and published in the journal <i>Scientific Reports</i> finds that economic inequality on a social level cannot be explained by bad choices among the poor nor by good decisions among the rich. Poor decisions were the same across all income groups, including for people who have overcome poverty.

										  
											        </p>
										 
										 											  
<p>While <a href="https://phys.org/tags/economic+inequality/" rel="tag">economic inequality</a> continues to rise within countries, efforts to address it have been largely ineffective, particularly those involving behavioral approaches. It has been often implied, but until now not tested, that choice patterns among low-income individuals may be a factor impeding behavioral interventions aimed at improving upward economic mobility.
</p><p>The study is based on online surveys in 22 languages with close to 5,000 participants from 27 countries in Asia, Europe, North America, and South America. Decision-making ability was measured through 10 individual biases, including (1) temporal discounting, not preferring immediate funds over larger future gains; (2) overestimation, or thinking you are better than you are at making decisions; (3) over-placement, or thinking you are better than the <a href="https://phys.org/tags/average+person/" rel="tag">average person</a> at making decisions; and (4) extremeness aversion, or taking the "middle option" simply because it seems safer than the highest or lowest.
</p><p>Taken along with <a href="https://phys.org/news/2022-07-economic-inequality-instability-impacts-long-term.html">related work</a> showing that temporal discounting is tied more to the broader societal economic environment rather than individual financial circumstances, the new findings are a major validation of arguments stating that poorer individuals are not uniquely prone to <a href="https://phys.org/tags/cognitive+biases/" rel="tag">cognitive biases</a> that alone explain protracted poverty.
</p><p>"Our research does not reject the notion that individual behavior and decision-making may directly relate to upward economic mobility. Instead, we narrowly conclude that biased decision-making does not alone explain a significant proportion of population-level economic inequality," says first author Kai Ruggeri, Ph.D., assistant professor in the Department of Health Policy and Management at Columbia Public Health.
</p><p>"Low-income individuals are not uniquely prone to cognitive biases linked to bad financial decisions. Instead, scarcity is more likely a greater driver of these decisions," Ruggeri adds.
										 																				
																				</p><div>
																						<p><strong>More information:</strong>
												Kai Ruggeri et al, The persistence of cognitive biases in financial decisions across economic groups, <i>Scientific Reports</i> (2023).  <a data-doi="1" href="https://dx.doi.org/10.1038/s41598-023-36339-2" target="_blank">DOI: 10.1038/s41598-023-36339-2</a>
																						
																						</p>
																					</div>
                               											
																					
                              										                                        
										<!-- print only -->
										<div>
											 <p><strong>Citation</strong>:
												Economic inequality cannot be explained by individual bad choices, study finds (2023, June 29)
												retrieved 2 July 2023
												from https://phys.org/news/2023-06-economic-inequality-individual-bad-choices.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AMIGAlive – Play Amiga games online with people across the world (123 pts)]]></title>
            <link>https://www.amigalive.com/</link>
            <guid>36563780</guid>
            <pubDate>Sun, 02 Jul 2023 17:50:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.amigalive.com/">https://www.amigalive.com/</a>, See on <a href="https://news.ycombinator.com/item?id=36563780">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
		<main id="main" role="main">

			
				
<article id="post-65" class="page">
	
	<div>
		

		
<h2><strong>Welcome to the AmigaLive project!</strong></h2>



<h4>AmigaLive is a front-end application which utilizes the  netplay capabilities of the FS-UAE emulator. AmigaLive makes it more simple than ever before to have 2 or more people from around the world, connect and play the same game, or even use the same software, as if sharing the same Amiga computer hardware and peripherals<strong>.</strong></h4>



<div><figure><img decoding="async" width="820" height="462" src="https://www.amigalive.com/wp-content/uploads/Amiga-Facebook-2.jpg" alt="" srcset="https://www.amigalive.com/wp-content/uploads/Amiga-Facebook-2.jpg 820w, https://www.amigalive.com/wp-content/uploads/Amiga-Facebook-2-300x169.jpg 300w, https://www.amigalive.com/wp-content/uploads/Amiga-Facebook-2-768x433.jpg 768w, https://www.amigalive.com/wp-content/uploads/Amiga-Facebook-2-128x72.jpg 128w, https://www.amigalive.com/wp-content/uploads/Amiga-Facebook-2-32x18.jpg 32w" sizes="(max-width: 820px) 100vw, 820px"></figure></div>



<h4>FS-UAE  is the friendliest Amiga emulator which integrates Amiga emulation code from WinUAE and is available for all major platforms, such as Windows, Mac OS-X and Linux.</h4>



<p><strong>*This project offers an unofficial distribution of the&nbsp;FS-UAE&nbsp;software which may not be up to date, therefore please do not send any bug reports to the developer (Frode Solheim) regarding AmigaLive issues.</strong></p>



<h2><strong>Requirements:</strong></h2>



<ul><li><a href="https://www.amigalive.com/download/"><strong>Download</strong></a><b><strong> </strong>the latest version of the AmigaLive bundle</b><br><b>(Everyone needs to have the same major version)</b></li><li><strong>A modern computer running a 64-bit OS </strong><br><strong>(Linux, Mac OS-X or Windows)</strong></li><li><strong>High speed internet<br>(Wi-Fi works but a wired LAN connection is recommended)</strong></li><li><strong>Any input device:&nbsp;Joystick, GamePad, Keyboard or Mouse.&nbsp;<br>A joystick can also be emulated by using different keyboard layouts, the default keys are: cursor keys and right Ctrl as fire 1 button<br>(A digital&nbsp;2 button Joystick/GamePad is recommended)</strong></li><li><strong><strong>You need people ready to play with you, but if you don’t know many that are interested or support Amiga emulation, w<strong><strong>e welcome you to join </strong></strong></strong>us on the <a href="https://discord.gg/r8pZTyV">AmigaLive Discord</a> and give us a shout. You can notify whoever is available by using the @here command in the Discord channels 🙂</strong></li></ul>




	</div><!-- .entry-content -->
</article><!-- #post-## -->

			
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First 'tooth regrowth' medicine moves toward clinical trials in Japan (782 pts)]]></title>
            <link>https://mainichi.jp/english/articles/20230609/p2a/00m/0sc/026000c</link>
            <guid>36563590</guid>
            <pubDate>Sun, 02 Jul 2023 17:33:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mainichi.jp/english/articles/20230609/p2a/00m/0sc/026000c">https://mainichi.jp/english/articles/20230609/p2a/00m/0sc/026000c</a>, See on <a href="https://news.ycombinator.com/item?id=36563590">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<!-- cxenseparse_start -->

<div>
<figure>
<div>
<a data-href="https://cdn.mainichi.jp/vol1/2023/06/09/20230609p2a00m0na021000p/9.jpg?1" data-lightbox="photos" data-title="(Getty)">
<span>
<img src="https://cdn.mainichi.jp/vol1/2023/06/09/20230609p2a00m0na021000p/6.jpg?1" alt="">

</span>

</a>
</div>
<figcaption>(Getty)</figcaption>
</figure>
</div>

<div>
<figure>
<div>
<a data-href="https://cdn.mainichi.jp/vol1/2023/06/09/20230609p2a00m0na022000p/9.jpg?1" data-lightbox="photos" data-title="Katsu Takahashi, head of the dentistry and oral surgery department at the Medical Research Institute Kitano Hospital, is seen in the city of Osaka's Kita Ward on May 16, 2023. (Mainichi/Mirai Nagira)">
<span>
<img src="https://cdn.mainichi.jp/vol1/2023/06/09/20230609p2a00m0na022000p/7.jpg?1" alt="">

</span>

</a>
</div>
<figcaption>Katsu Takahashi, head of the dentistry and oral surgery department at the Medical Research Institute Kitano Hospital, is seen in the city of Osaka's Kita Ward on May 16, 2023. (Mainichi/Mirai Nagira)</figcaption>
</figure>
</div>
<p>
    TOKYO -- A Japanese research team is making progress on the development of a groundbreaking medication that may allow people to grow new teeth, with clinical trials set to begin in July 2024.
</p>
<!-- cxenseparse_end -->

<!-- cxenseparse_start -->
<p>
    The tooth regrowth medicine is intended for people who lack a full set of adult teeth due to congenital factors. The team is aiming to have it ready for general use in 2030.
</p>
<p>
    In prior animal experiments, the medicine prompted the growth of "third-generation" teeth following baby teeth and then permanent adult teeth.
</p>
<p>
    "The idea of growing new teeth is every dentist's dream. I've been working on this since I was a graduate student. I was confident I'd be able to make it happen," said Katsu Takahashi, lead researcher and head of the dentistry and oral surgery department at the Medical Research Institute Kitano Hospital in the city of Osaka.
</p>

<div>
<figure>
<div>
<a data-href="https://cdn.mainichi.jp/vol1/2023/06/09/20230609p2a00m0na023000p/7.jpg?1" data-lightbox="photos" data-title="A new tooth is seen growing in a mouse treated with the tooth regrowth medicine. (Photo provided by Katsu Takahashi, head of the dentistry and oral surgery department at the Medical Research Institute Kitano Hospital)">
<span>
<img src="https://cdn.mainichi.jp/vol1/2023/06/09/20230609p2a00m0na023000p/6.jpg?1" alt="">

</span>

</a>
</div>
<figcaption>A new tooth is seen growing in a mouse treated with the tooth regrowth medicine. (Photo provided by Katsu Takahashi, head of the dentistry and oral surgery department at the Medical Research Institute Kitano Hospital)</figcaption>
</figure>
</div>
<p>
    Anodontia is a congenital condition that causes the growth of fewer than a full set of teeth, present in around 1% of the population. Genetic factors are thought to be the major cause for the one-tenth of anodontia patients who lack six or more teeth, a condition categorized as oligodontia. These conditions are also known as tooth agenesis. People who grow up with tooth agenesis struggle with basic abilities like chewing, swallowing and speaking from a young age, which can negatively impact their development.
</p>
<p>
    After completing a dentistry degree, Takahashi went on to graduate studies in molecular biology at Kyoto University in 1991. Afterwards, he studied in the U.S.
</p>
<p>
    Around that time, research around the world had begun to pinpoint genes that, when deleted, would cause genetically modified mice to grow fewer teeth. "The number of teeth varied through the mutation of just one gene. If we make that the target of our research, there should be a way to change the number of teeth (people have)," Takahashi said of his thoughts at the time.
</p>
<p>
    <b>Global attention</b>
</p>

<div>
<figure>
<div>
<a data-href="https://cdn.mainichi.jp/vol1/2023/06/09/20230609p2a00m0na024000p/6.jpg?1" data-lightbox="photos" data-title="The front teeth of a ferret treated with tooth regrowth medicine are seen in a photo provided by Katsu Takahashi, head of the dentistry and oral surgery department at the Medical Research Institute Kitano Hospital. The medicine induced the growth of an additional seventh tooth (center).">
<span>
<img src="https://cdn.mainichi.jp/vol1/2023/06/09/20230609p2a00m0na024000p/6.jpg?1" alt="">

</span>

</a>
</div>
<figcaption>The front teeth of a ferret treated with tooth regrowth medicine are seen in a photo provided by Katsu Takahashi, head of the dentistry and oral surgery department at the Medical Research Institute Kitano Hospital. The medicine induced the growth of an additional seventh tooth (center).</figcaption>
</figure>
</div>
<p>
    It was around 2005, when he delved further into the subject at Kyoto University after returning to Japan, that he began to see a bright path for his continued research. The researchers found that mice lacking a certain gene had an increased number of teeth. A protein called USAG-1, synthesized by the gene, was found to limit the growth of teeth. In other words, blocking the action of that protein could allow more teeth to grow.
</p>
<p>
    Takahashi's research team narrowed their focus onto USAG-1, and developed a neutralizing antibody medicine able to block the protein's function. In experiments in 2018, mice with a congenitally low number of teeth were given medicine that resulted in new teeth coming through. The research results were published in a U.S. scientific paper in 2021, and gained much attention as the beginnings of the world's first tooth regeneration medicine.
</p>
<p>
    Work is now underway to get the drug ready for human use. Once confirmed to have no ill effects on the human body, it will be aimed at treating children aged 2 to 6 who exhibit anodontia. "We hope to pave the way for the medicine's clinical use," Takahashi said.
</p>
<p>
    <b> Medicine could be game-changer</b>
</p>
<p>
    If successful, a drug to regenerate teeth may be a game-changer for the entire field of dentistry.
</p>
<p>
    Animals including sharks and some reptile species can continuously regrow teeth. It's been assumed that humans only grow two sets of teeth in their lifetime, but in fact, there is evidence that we also have the "buds" for a third set.
</p>
<p>
    Around 1% of the population exhibits the converse of anodontia: hyperdontia, a congenital condition causing a higher-than-normal number of teeth. According to research by Takahashi's team, one in three such cases manifests as the growth of a third set of teeth. Takahashi believes that in most cases, humans' ability to grow a third set was lost over time.
</p>
<p>
    When the researchers applied the drug to ferrets, they grew an additional seventh front tooth. As the new teeth grew in between the existing front teeth and were of the same shape, the medicine is thought to have induced the generation of third-set teeth in the animals.
</p>
<p>
    When treatment of teeth is no longer possible due to severe cavities or erosion of the dental sockets, known as pyorrhea, people lose them and need to rely on dental appliances such as dentures. The ability to grow third-generation teeth could change that. "In any case, we're hoping to see a time when tooth-regrowth medicine is a third choice alongside dentures and implants," Takahashi said.
</p>
<p>
    For further information or inquiries about Takahashi's research, please visit https://www.kitano-hp.or.jp/toothreg/ (in Japanese).
</p>
<p>
    (Japanese original by Mirai Nagira, Science &amp; Environment News Department)
</p>
<!-- cxenseparse_end -->

<!--| tools BGN |-->

<!--| tools END |-->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Are You Sure You Want to Use MMAP in Your Database Management System? (2022) (164 pts)]]></title>
            <link>https://db.cs.cmu.edu/mmap-cidr2022/</link>
            <guid>36563187</guid>
            <pubDate>Sun, 02 Jul 2023 16:48:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://db.cs.cmu.edu/mmap-cidr2022/">https://db.cs.cmu.edu/mmap-cidr2022/</a>, See on <a href="https://news.ycombinator.com/item?id=36563187">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>
                <i>Memory-mapped</i> (<tt>MMAP</tt>) file I/O is an OS-provided feature that
                maps the contents of a file on secondary storage into a program’s
                address space. The program then accesses pages via pointers as if
                the file resided entirely in memory. The OS transparently loads
                pages only when the program references them and automatically evicts
                pages if memory fills up.
            </p>
            <p>
                <tt>MMAP</tt>‘s perceived ease of use has seduced <i>database management system</i>
                (DBMS) developers for decades as a viable alternative to
                implementing a buffer pool. There are, however, severe correctness
                and performance issues with <tt>MMAP</tt> that are not immediately apparent.
                Such problems make it difficult, if not impossible, to use <tt>MMAP</tt>
                correctly and efficiently in a modern DBMS. In fact, several popular
                DBMSs initially used <tt>MMAP</tt> to support larger-than-memory databases
                but soon encountered these hidden perils, forcing them to switch to
                managing file I/O themselves after significant engineering costs.
            </p>
            <p>
                In this way, <tt>MMAP</tt> and DBMSs are like coffee and spicy food: an
                unfortunate combination that becomes obvious after the fact.
            </p>
            <p>
                Since developers keep trying to use <tt>MMAP</tt> in new DBMSs, we wrote this
                paper to provide a warning to others that <tt>MMAP</tt> is not a suitable
                replacement for a traditional buffer pool. We discuss the main
                shortcomings of <tt>MMAP</tt> in detail, and our experimental analysis
                demonstrates clear performance limitations. Based on these findings,
                we conclude with a prescription for when DBMS developers might
                consider using <tt>MMAP</tt> for file I/O.
            </p>
            <p><small><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16"> <path d="M14.5.5a.5.5 0 0 0-1 0V2H1a1 1 0 0 0-1 1v2h16V3a1 1 0 0 0-1-1h-.5V.5ZM2.5 4a.5.5 0 1 1 0-1 .5.5 0 0 1 0 1Zm2 0a.5.5 0 1 1 0-1 .5.5 0 0 1 0 1Zm7.5-.5a.5.5 0 1 1-1 0 .5.5 0 0 1 1 0Zm1.5.5a.5.5 0 1 1 0-1 .5.5 0 0 1 0 1Zm-7-1h3a.5.5 0 0 1 0 1h-3a.5.5 0 0 1 0-1Zm-2 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm.5-1.5a.5.5 0 1 1-1 0 .5.5 0 0 1 1 0Zm6.5 1.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm0-1a.5.5 0 1 0 0-1 .5.5 0 0 0 0 1Z"></path> <path d="M16 6H0v8a1 1 0 0 0 1 1h14a1 1 0 0 0 1-1V6ZM4.5 13a2.5 2.5 0 1 1 0-5 2.5 2.5 0 0 1 0 5Zm7 0a2.5 2.5 0 1 1 0-5 2.5 2.5 0 0 1 0 5Z"></path> </svg> Recommended Music for this Paper:<br><a href="https://youtu.be/JW8mwaw2-xc" target="_youtube" rel="noopener">Dr. Dre – High Powered (featuring RBX)</a></small></p>
          </div><div>
                <h3>Citation</h3>
                <pre>@inproceedings{crotty22-mmap💩,
  author = {Crotty, Andrew and Leis, Viktor and Pavlo, Andrew},
  title = {Are You Sure You Want to Use MMAP in Your Database Management System?},
  booktitle = {{CIDR} 2022, Conference on Innovative Data Systems Research},
  year = {2022},
}</pre>
            </div><div>
            <h3>Acknowledgments</h3>
            <p>
                This paper is the culmination of an unhealthy, years-long obsession with the idea of developers incorrectly using mmap in their DBMSs. The authors would like to thank everyone who contributed and provided helpful feedback: <a href="https://lcy.im/">Chenyao Lou</a> (PKU), <a href="https://en.wikipedia.org/wiki/File:David_Andersen_-_Professor_Street_Urchin.jpg">David “Greasy” Andersen</a> (CMU), <a href="https://www.cs.cmu.edu/~kaminsky/">Michael Kaminsky</a> (BrdgAI), <a href="https://db.in.tum.de/~neumann/">Thomas Neumann</a> (TUM), <a href="https://osg.tuhh.de/People/dietrich/">Christian Dietrich</a> (TUHH), <a href="https://www.linkedin.com/in/toddlipcon/">Todd Lipcon</a> (<a href="https://lipcon.org/">lipcon.org</a>), and <a href="https://people.ece.ubc.ca/sasha/">Sasha Fedorova</a> (UBC).
            </p>
            <p>
                This work was supported (in part) by the NSF (<a href="http://www.nsf.gov/awardsearch/showAward?AWD_ID=1846158">IIS-1846158</a>, <a href="http://www.nsf.gov/awardsearch/showAward?AWD_ID=1423210">III-1423210</a>, <a href="http://www.nsf.gov/awardsearch/showAward?AWD_ID=1252522">DGE-1252522</a>), research grants from Google and Snowflake, and the <a href="https://sloan.org/grant-detail/8638">Alfred P. Sloan Research Fellowship</a> program.
            </p>
            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Designing the First Apple Macintosh: The Engineers’ Story (1984) (110 pts)]]></title>
            <link>https://spectrum.ieee.org/apple-macintosh</link>
            <guid>36562958</guid>
            <pubDate>Sun, 02 Jul 2023 16:25:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/apple-macintosh">https://spectrum.ieee.org/apple-macintosh</a>, See on <a href="https://news.ycombinator.com/item?id=36562958">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-elid="2661376756" data-post-url="https://spectrum.ieee.org/apple-macintosh" data-authors="Fred Guterl" data-headline="Designing the First Apple Macintosh: The Engineers’ Story" data-page-title="Designing the First Apple Macintosh: The Engineers’ Story - IEEE Spectrum"><p><strong></strong><strong>In 1979 the Macintosh</strong> personal computer existed only as the pet idea of Jef Raskin, a veteran of the Apple II team, who had proposed that <a href="https://www.apple.com/" rel="noopener noreferrer" target="_blank">Apple Computer Inc.</a> make a low-cost “appliance”-type computer that would be as easy to use as a toaster. Mr. Raskin believed the computer he envisioned, which he called Macintosh, could sell for US $1000 if it was manufactured in high volume and used a powerful microprocessor executing tightly written software.</p><p>Mr. Raskin’s proposal did not impress anyone at Apple Computer enough to bring much money from the board of directors or much respect from Apple engineers. The company had more pressing concerns at the time: <a href="https://spectrum.ieee.org/apple-lisa" target="_self">the major Lisa workstation project</a> was getting under way, and there were problems with the reliability of the Apple III, the revamped version of the highly successful Apple II.</p><div id="rebelltitem2" data-id="2" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-2" data-basename="particle-2" data-post-id="2661376756" data-published-at="1686938434" data-use-pagination="False"><p>Although the odds seemed against it in 1979, the Macintosh, designed by a handful of inexperienced engineers and programmers, is now recognized as a technical milestone in personal computing. Essentially a slimmed-down version of the Lisa workstation with many of its software features, the Macintosh sold for $2495 at its introduction in early 1984; the Lisa initially sold for $10,000. Despite criticism of the Macintosh—that it lacks networking capabilities adequate for business applications and is awkward to use for some tasks—the computer is considered by Apple to be its most important weapon in the war with IBM for survival in the personal-computer business.</p><p>From the beginning, the Macintosh project was powered by the dedicated drive of two key players on the project team. For Burrell Smith, who designed the Macintosh digital hardware, the project represented an opportunity for a relative unknown to demonstrate outstanding technical talents. For Steven Jobs, the 29-year-old chairman of Apple and the Macintosh project’s director, it offered a chance to prove himself in the corporate world after a temporary setback: although he cofounded Apple Computer, the company had declined to let him manage the Lisa project. Mr. Jobs contributed relatively little to the technical design of the Macintosh, but he had a clear vision of the product from the beginning. He challenged the project team to design the best product possible and encouraged the team by shielding them from bureaucratic pressures within the company.</p><h2>Burrell Smith and the Early Mac Design<em></em></h2><p>Mr. Smith, who was a repairman in the Apple II maintenance department in 1979, had become hooked on microprocessors several years earlier during a visit to the electronics-industry area south of San Francisco known as Silicon Valley. He dropped out of liberal-arts studies at the Junior College of Albany, New York, to pursue the possibilities of microprocessors—there isn’t anything you can’t do with those things, he thought. Mr. Smith later became a repairman in Cupertino, Calif., where he spent much time studying the cryptic logic circuitry of the Apple II, designed by company cofounder Steven Wozniak.</p><p>Mr. Smith’s dexterity in the shop impressed Bill Atkinson, one of the Lisa designers, who introduced him to Mr. Raskin as “the man who’s going to design your Macintosh.” Mr. Raskin replied noncommittally, “We’ll see about that.”</p><p>However, Mr. Smith managed to learn enough about Mr. Raskin ‘s conception of the Macintosh to whip up a makeshift prototype using a Motorola 6809 microprocessor, a television monitor, and an Apple II. He showed it to Mr. Raskin, who was impressed enough to make him the second member of the Macintosh team.</p><p>But the fledgling Macintosh project was in trouble. The Apple board of directors wanted to cancel the project in September 1980 to concentrate on more important projects, but Mr. Raskin was able to win a three-month reprieve.</p><p>Meanwhile Steve Jobs, then vice president of Apple, was having trouble with his own credibility within the company. Though he had sought to manage the Lisa computer project, the other Apple executives saw him as too inexperienced and eccentric to entrust him with such a major undertaking, and he had no formal business education. After this rejection, “he didn’t like the lack of control he had,” noted one Apple executive. “He was looking for his niche.”</p><p>Mr. Jobs became interested in the Macintosh project, and, possibly because few in the company thought the project had a future, Mr. Jobs was made its manager. Under his direction, the design team became as compact and efficient as the Macintosh was to<em></em>be—a group of engineers working at a distance from all the meetings and paper-pushing of the corporate mainstream. Mr. Jobs, in recruiting the other members of the Macintosh team, lured some from other companies with promises of potentially lucrative stock options.</p></div><p>The Macintosh project “was known in the company as ‘Steve’s folly.’”</p><div id="rebelltitem4" data-id="4" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-4" data-basename="particle-4" data-post-id="2661376756" data-published-at="1686938434" data-use-pagination="False"><p>With Mr. Jobs at the helm, the project gained some credibility among the board of directors—but not much. According to one team member, it was known in the company as “Steve’s folly.” But Mr. Jobs lobbied for a bigger budget for the project and got it. The Macintosh team grew to 20 by early 1981.</p><p>The decision on what form the Macintosh would take was left largely to the design group. At first the members had only the basic principles set forth by Mr. Raskin and Mr. Jobs to guide them, as well as the example set by the Lisa project. The new machine was to be easy to use and inexpensive to manufacture. Mr. Jobs wanted to commit enough money to build an automated factory that would produce about 300 000 computers a year. So one key challenge for the design group was to use inexpensive parts and to keep the parts count low.</p><p>Making the computer easy to use required considerable software for the user-computer interface. The model was, of course, the Lisa workstation with its graphic “windows” to display simultaneously many different programs. “Icons,” or little pictures, were used instead of cryptic computer terms to represent a selection of programs on the screen; by moving a “mouse,’’ a box the size of a pack of cigarettes, the user manipulated a cursor on the screen. The Macintosh team redesigned the software of the Lisa from scratch to make it operate more efficiently, since the Macintosh was to have far less memory than the 1 million bytes of the Lisa. But the Macintosh software was also required to operate quicker than the Lisa software, which had been criticized for being slow.</p><h2>Defining the Mac as the Project Progressed</h2><p>The lack of a precise definition for the Macintosh project was not a problem. Many of the designers preferred to define the computer as they went along. “Steve allowed us to crystallize the problem and the solution simultaneously,” recalled Mr. Smith. The method put strain on the design team, since they were continually evaluating design alternatives. “We were swamped in detail,” Mr. Smith said. But this way of working also led to a better product, the designers said, because they had the freedom to seize opportunities during the design stage to enhance the product.</p><p>Such freedom would not have been possible had the Macintosh project been structured in the conventional way at Apple, according to several of the designers. “No one tried to control us,” said one. “Some managers like to take control, and though that may be good for mundane engineers, it isn’t good if you are self-motivated.”</p></div><p><img id="95050" data-rm-shortcode-id="3321510644ca62def7dd22030ec28f21" data-rm-shortcode-name="rebelmouse-image" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-table-detailing-differences-between-star-lisa-and-mac-computers.jpg?id=34133796&amp;width=980" data-runner-src="https://spectrum.ieee.org/media-library/a-table-detailing-differences-between-star-lisa-and-mac-computers.jpg?id=34133796&amp;width=980" width="1240" height="502" alt="A table detailing differences between Star, Lisa, and Mac computers"></p><div id="rebelltitem6" data-id="6" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-6" data-basename="particle-6" data-post-id="2661376756" data-published-at="1686938961" data-use-pagination="False"><p>Central to the success of this method was the small, closely knit nature of the design group, with each member being responsible for a relatively large portion of the total design and free to consult other members of the team when considering alternatives. For example, Mr. Smith, who was well acquainted with the price of electronic components from his early work on reducing the cost of the Apple II, made many decisions about the economics of Macintosh hardware without time-consuming consultations with purchasing agents. Because communication among team members was good, the designers shared their areas of expertise by advising each other in the working stages, rather than waiting for a final evaluation from a group of manufacturing engineers. Housing all members of the design team in one small office made communicating easier. For example, it was simple for Mr. Smith to consult a purchasing agent about the price of parts if he needed to, because the purchasing agent worked in the same building.</p><p>Andy Hertzfeld, who transferred from the Apple II software group to design the Macintosh operating software, noted, “In lots of other projects at Apple, people argue about ideas. But sometimes bright people think a little differently. Somebody like Burrell Smith would design a computer on paper and people would say. ‘It’ll never work.’ So instead Burell builds it lightning fast and has it working before the guy can say anything.”</p></div><p>“When you have one person designing the whole computer, he knows that a little leftover gate in one part may be used in another part.”<br>—Andy Herzfeld</p><div id="rebelltitem8" data-id="8" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-8" data-basename="particle-8" data-post-id="2661376756" data-published-at="1686938961" data-use-pagination="False"><p>The closeness of the Macintosh group enabled it to make design tradeoffs that would not have been possible in a large organization, the team members contended. The interplay between hardware and software was crucial to the success of the Macintosh design, using a limited memory and few electronic parts to perform complex operations. Mr. Smith, who was in charge of the computer’s entire digital hardware design, and Mr. Herzfeld became close friends and often collaborated. “When you have one person designing the whole computer,” Mr. Hertzfeld observed, “he knows that a little leftover gate in one part may be used in another part.”</p><p>To promote interaction among the designers, one of the first things that Mr. Jobs did in taking over the Macintosh project was to arrange special office space for the team. In contrast to Apple’s corporate headquarters, identified by the company logo on a sign on its well-trimmed lawn, the team’s new quarters, behind a Texaco service station, had no sign to identify them and no listing in the company telephone directory. The office, dubbed Texaco Towers, was an upstairs, low-rent, plasterboard-walled, “tacky-carpeted” place, “the kind you’d find at a small law outfit,’’ according to Chris Espinosa, a veteran of the original Apple design team and an early Macintosh draftee. It resembled a house more than an office, having a communal area much like a living room, with smaller rooms off to the side for more privacy in working or talking. The decor was part college dormitory, part electronics repair shop: art posters, beanbag chairs, coffee machines, stereo systems, and electronic equipment of all sorts scattered about.</p></div><p>“Whenever a competitor came out with a product, we would buy and dismantle it, and it would kick around the office.”<br>—Chris Espinosa</p><div id="rebelltitem10" data-id="10" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-10" data-basename="particle-10" data-post-id="2661376756" data-published-at="1686938961" data-use-pagination="False"><p>There were no set work hours and initially not even a schedule for the development of the Macintosh. Each week, if Mr. Jobs was in town (often he was not), he would hold a meeting at which the team members would report what they had done the previous week. One of the designers’ sidelines was to dissect the products of their competitors. “Whenever a competitor came out with a product, we would buy and dismantle it, and it would kick around the office,” recalled Mr. Espinosa.</p><p>In this way, they learned what they did not want their product to be. In their competitors’ products, Mr. Smith saw a propensity for using connectors and slots for inserting printed-circuit boards—a slot for the video circuitry, a slot for the keyboard circuitry, a slot for the disk drives, and memory slots. Behind each slot were buffers to allow signals to pass onto and off the printed-circuit board properly. The buffers meant delays in the computers’ operations, since several boards shared a backplane, and the huge capacitance required for multiple PC boards slowed the backplane. The number of parts required made the competitors’ computers hard to manufacture, costly, and less reliable. The Macintosh team resolved that their PC would have but two printed-circuit boards and no slots, buffers, or backplane.</p></div><p><img id="fe15a" data-rm-shortcode-id="fa433347b51dd81951de454cbc4d9e73" data-rm-shortcode-name="rebelmouse-image" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/looking-into-the-open-back-of-a-computer-with-metal-enclosures-and-wires-and-the-back-of-a-cathode-ray-tube.jpg?id=34133831&amp;width=980" data-runner-src="https://spectrum.ieee.org/media-library/looking-into-the-open-back-of-a-computer-with-metal-enclosures-and-wires-and-the-back-of-a-cathode-ray-tube.jpg?id=34133831&amp;width=980" width="975" height="999" alt="Looking into the open back of a computer, with metal enclosures and wires, and the back of a cathode ray tube."><small><p>A challenge in building the Macintosh was to offer sophisticated software using the fewest and least-expensive parts.</p></small></p><div id="rebelltitem12" data-id="12" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-12" data-basename="particle-12" data-post-id="2661376756" data-published-at="1686939853" data-use-pagination="False"><p>
	To squeeze the needed components onto the board, Mr. Smith planned the Macintosh to perform specific functions rather than operate as a flexible computer that could be tailored by programmers for a wide variety of applications. By rigidly defining the configuration of the Macintosh and the functions it would perform, he eliminated much circuitry. Instead of providing slots into which the user could insert printed-circuit boards with such hardware as memory or coprocessors, the designers decided to incorporate many of the basic functions of the computer in read-only memory, which is more reliable. The computer would be expanded not by slots, but through a high-speed serial port.
</p><h2>Writing the Mac’s Software</h2><p>
	The software designers were faced in the beginning with often-unrealistic schedules. “We looked for any place where we could beg, borrow, or steal code,” Mr. Herzfeld recalled. The obvious place for them to look was the Lisa workstation. The Macintosh team wanted to borrow some of the Lisa’s software for drawing graphics on the bit-mapped display. In 1981, Bill Atkinson was refining the Lisa graphics software, called <a href="https://computerhistory.org/blog/macpaint-and-quickdraw-source-code/" target="_blank">Quickdraw</a>, and began to work part-time implementing it for the Macintosh.
</p><p>
	Quickdraw was a scheme for manipulating bit maps to enable applications programmers to construct images easily on the Macintosh bit-mapped display. The Quickdraw program allows the programmer to define and manipulate a region—a software representation of an arbitrarily shaped area of the screen. One such region is a rectangular window with rounded comers, used throughout the Macintosh software. Quickdraw also allows the programmer to keep images within defined boundaries, which make the windows in the Macintosh software appear to hold data. The programmer can unite two regions, subtract one from the other, or intersect them.
</p><p>
	In Macintosh, the Quickdraw program was to be tightly written in assembly-level code and etched permanently in ROM. It would serve as a foundation for higher-level software to make use of graphics.
</p><p>
	Quickdraw was “an amazing graphics package,” Mr. Hertzfeld noted, but it would have strained the capabilities of the 6809 microprocessor, the heart of the early Macintosh prototype. <a href="https://www.motorola.com/us/" rel="noopener noreferrer" target="_blank">Motorola Corp.</a> announced in late 1980 that the 68000 microprocessor was available, but that chip was new and unproven in the field, and at $200 apiece it was also expensive. Reasoning that the price of the chip would come down before Apple was ready to start mass-producing the Macintosh, the Macintosh designers decided to gamble on the Motorola chip.
</p><p>
	Another early design question for the Macintosh was whether to use the Lisa operating system. Since the Lisa was still in the early stages of design, considerable development would have been required to tailor its operating system for the Macintosh. Even if the Lisa had been completed, rewriting its software in assembly code would have been required for the far smaller memory of the Macintosh. In addition, the Lisa was to have a multitasking operating system, using complex circuitry and software to run more than one computer program at the same time, which would have been too expensive for the Macintosh. Thus the decision was made to write a Macintosh operating system from scratch, working from the basic concepts of the Lisa. Simplifying the Macintosh operating system posed the delicate problem of restricting the computer’s memory capacity enough to keep it inexpensive but not so much as to make it inflexible.
</p><p>
	The Macintosh would have no multitasking capability but would execute only one applications program at a time. Generally, a multitasking operating system tracks the progress of each of the programs it is running and then stores the entire state of each program—the values of its variables, the location of the program counter, and so on. This complex operation requires more memory and hardware than the Macintosh designers could afford. However, the illusion of multitasking was created by small programs built into the Macintosh system software. Since these small programs—such as one that creates the images of a calculator on the screen and does simple arithmetic—operate in areas of memory separate from applications, they can run simultaneously with applications programs.
</p></div><p><img id="636d6" data-rm-shortcode-id="205c2e1d605fa7662334de56f1f600c0" data-rm-shortcode-name="rebelmouse-image" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-flow-chart-with-a-screen-shot-of-windows-on-a-computer.jpg?id=34133849&amp;width=980" data-runner-src="https://spectrum.ieee.org/media-library/a-flow-chart-with-a-screen-shot-of-windows-on-a-computer.jpg?id=34133849&amp;width=980" width="2163" height="2948" alt="A flow chart with a screen shot of windows on a computer"><small><p>Embedding Macintosh software in 64 kilobytes of read-only memory increased the reliability of the computer and simplified the hardware [A]. About one third of the ROM software is the operating system. One third is taken up by Quickdraw, a program for representing shapes and images for the bit-mapped display. The remaining third is devoted to the user ­interface toolbox, which handles the display of windows, text editing, menus, and the like. The user interface of the Macintosh includes pull-down menus, which appear only when the cursor is placed over the menu name and a button on the mouse is pressed. Above, a user examining the ‘file’ menu selects the open command, which causes the computer to load the file (indicated by darkened icon) from disk into internal memory. The Macintosh software was designed to make the toolbox routines optional for programmers; the applications program offers the choice of whether or not to handle an event [B].</p></small></p><div id="rebelltitem14" data-id="14" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-14" data-basename="particle-14" data-post-id="2661376756" data-published-at="1686939853" data-use-pagination="False"><p>Since the Macintosh used a memory-mapped scheme, the 68000 microprocessor required no memory management, simplifying both the hardware and the software. For example, the 68000 has two modes of operation: a user mode, which is restricted so that a programmer cannot inadvertently upset the memory-management scheme; and a supervisor mode, which allows unrestricted access to all of the 68000’s commands. Each mode uses its own stack of pointers to blocks of memory. The 68000 was rigged to run only in the supervisor mode, eliminating the need for the additional stack. Although seven levels of interrupts were available for the 68000, only three were used.</p><p>Another simplification was made in the Macintosh’s file structure, exploiting the small disk space with only one or two floppy disk drives. In the Lisa and most other operating systems, two indexes access a program on floppy disk, using up precious random-access memory and increasing the delay in fetching programs from a disk. The designers decided to use only one index for the Macintosh—a block map, located in RAM, to indicate the location of a program on a disk. Each block map represented one volume of disk space.</p><p>This scheme ran into unexpected difficulties and may be modified in future versions of the Macintosh, Mr. Hertzfeld said. Initially, the Macintosh was not intended for business users, but as the design progressed and it became apparent that the Macintosh would cost more than expected, Apple shifted its marketing plan to target business users. Many of them add hard disk drives to the Macintosh, making the block-map scheme unwieldy.</p><p>By January 1982, Mr. Hertzfeld began working on software for the Macintosh, perhaps the computer’s most distinctive feature, which he called the user-interface toolbox.</p><p>The toolbox was envisioned as a set of software routines for constructing the windows, pull-down menus, scroll bars, icons, and other graphic objects in the Macintosh operating system. Since RAM space would be scarce on the Macintosh (it initially was to have only 64 kilobytes), the toolbox routines were to be a part of the Macintosh’s operating software; they would use the Quickdraw routines and operate in ROM.</p><p>It was important however, not to handicap applications programmers—who could boost sales of the Macintosh by writing programs for it—by restricting them to only a few toolbox routines in ROM. So the toolbox code was designed to fetch definition functions—routines that use Quickdraw to create a graphic image such as a window—from either the systems disk or an applications disk. In this way, an applications programmer could add definition functions for a program, which Apple could incorporate in later versions the Macintosh by modifying the system disk. “We were nervous about putting (the toolbox) in ROM,” recalled Mr. Hertzfeld, “We knew that after the Macintosh was out, programmers would want to add to the toolbox routines.”</p><p>Although the user could operate only one applications program at a time, he could transfer text or graphics from one applications program to another with a toolbox routine called scrapbook. Since the scrapbook and the rest of the toolbox routines were located in ROM, they could run along with applications programs, giving the illusion of multitasking. The user would cut text from one program into the scrapbook, close the program, open another, and paste the text from the scrapbook. Other routines in the toolbox, such as the calculator, could also operate simultaneously with applications programs.</p><p>Late in the design of the Macintosh software, the designers realized that, to market the Macintosh in non-English-speaking countries, an easy way of translating text in programs into foreign languages was needed. Thus computer code and data were separated in the software to allow translation without unraveling a complex computer program, by scanning the data portion of a program. No programmer would be needed for translation.</p><h2>Placing an Early Bet on the 68000 Chip</h2><p><a href="https://spectrum.ieee.org/chip-hall-of-fame-motorola-mc68000-microprocessor" target="_self">The 68000</a>, with a 16-bit data bus and 32-bit internal registers and a 7.83-megahertz clock, could grab data in relatively large chunks. Mr. Smith dispensed with separate controllers for the mouse, the disk drives, and other peripheral functions. “We were able to leverage off slave devices,” Mr. Smith explained, “and we had enough throughput to deal with those devices in a way that appeared concurrent to the user.”</p><p>When Mr. Smith suggested implementing the mouse without a separate controller, several members of the design team argued that if the main microprocessor was interrupted each time the mouse was moved, the movement of the cursor on the screen would always lag. Only when Mr. Smith got the prototype up and running were they convinced it would work.</p></div><p><img id="30420" data-rm-shortcode-id="f28ef5693cbdbda7a8717d5ff74cdc5a" data-rm-shortcode-name="rebelmouse-image" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-table-listing-macintosh-prototypes-and-their-features.jpg?id=34133860&amp;width=980" data-runner-src="https://spectrum.ieee.org/media-library/a-table-listing-macintosh-prototypes-and-their-features.jpg?id=34133860&amp;width=980" width="1240" height="931" alt="A table listing Macintosh prototypes and their features"></p><div id="rebelltitem16" data-id="16" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-16" data-basename="particle-16" data-post-id="2661376756" data-published-at="1686939853" data-use-pagination="False"><p>Likewise, in the second prototype, the disk drives were controlled by the main microprocessor. “In other computers,” Mr. Smith noted, “the disk controller is a brick wall between the disk and the CPU, and you end up with a poor-performance, expensive disk that you can lose control of. It’s like buying a brand-new car complete with a chauffeur who insists on driving everywhere.</p><p>The 68000 was assigned many duties of the disk controller and was linked with a disk-controller circuit built by Mr. Wozniak for the Apple II. “Instead of a wimpy little 8-bit microprocessor out there, we have this incredible 68000—it’s the world’s best disk controller,” Mr. Smith said.</p><p>Direct-memory-access circuitry was designed to allow the video screen to share RAM with the 68000. Thus the 68000 would have access to RAM at half speed during the live portion of the horizontal line of the video screen and at full speed during the horizontal and vertical retrace. [See diagram, below.]</p></div><p><img id="3ed14" data-rm-shortcode-id="9e1db1aa3f5f379aa73cc5af021c87c5" data-rm-shortcode-name="rebelmouse-image" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-block-diagram-ending-in-line-drawings-of-a-speaker-and-a-cathode-ray-tube.jpg?id=34133917&amp;width=980" data-runner-src="https://spectrum.ieee.org/media-library/a-block-diagram-ending-in-line-drawings-of-a-speaker-and-a-cathode-ray-tube.jpg?id=34133917&amp;width=980" width="2155" height="2676" alt="A block diagram ending in line drawings of a speaker and a cathode ray tube"><small><p>The 68000 microprocessor, which has exclusive access to the read-only memory of the Macintosh, fetches commands from ROM at full speed—.83 megahertz. The 68000 shares the random-access memory with the video and sound circuitry, having access to RAM only part of the time [A]; it fetches instructions from RAM at an average speed of about 6 megahertz. The video and sound instructions are loaded directly into the video-shift register or the sound-counter, respectively. Much of the “glue” circuitry of the Macintosh is contained in eight programmable-array-logic chips. The Macintosh’s ability to play four independent voices was added relatively late in the design, when it was realized that most of the circuitry needed already existed in the video circuitry [B]. The four voices are added in software and the digital samples stored in memory. During the video retrace, sound data is fed into the sound buffer.</p></small></p><div id="rebelltitem18" data-id="18" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-18" data-basename="particle-18" data-post-id="2661376756" data-published-at="1686939853" data-use-pagination="False"><p>While building the next prototype, Mr. Smith saw several ways to save on digital circuitry and increase the execution speed of the Macintosh. The 68000 instruction set allowed Mr. Smith to embed subroutines in ROM. Since the 68000 has exclusive use of the address and data buses of the ROM, it has access to the ROM routines at up to the full clock speed. The ROM serves somewhat as a high-speed cache memory. While building the next prototype, Mr. Smith saw several ways to save on digital circuitry and increase the execution speed of the Macintosh. The 68000 instruction set allowed Mr. Smith to embed subroutines in ROM. Since the 68000 has exclusive use of the address and data buses of the ROM, it has access to the ROM routines at up to the full clock speed. The ROM serves somewhat as a high-speed cache memory.</p><p>The next major revision in the original concept of the Macintosh was made in the computer’s display. Mr. Raskin had proposed a computer that could be hooked up to a standard television set. However, it became clear early on that the resolution of television display was too coarse for the Macintosh. After a bit of research, the designers found they could increase the display resolution from 256 by 256 dots to 384 by 256 dots by including a display with the computer. This added to the estimated price of the Macintosh, but the designers considered it a reasonable tradeoff.</p><p>To keep the parts count low, the two input/output ports of the Macintosh were to be serial. The decision to go with this was a serious one, since the future usefulness of the computer depended largely on its efficiency when hooked up to printers, local-area networks, and other peripherals. In the early stages of development, the Macintosh was not intended to be a business product, which would have made networking a high priority.</p></div><p>“We had an image problem. We wore T-shirts and blue jeans with holes in the knees, and we had a maniacal conviction that we were right about the Macintosh, and that put some people off.”<br>—Chris Espinosa</p><div id="rebelltitem20" data-id="20" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-20" data-basename="particle-20" data-post-id="2661376756" data-published-at="1686939853" data-use-pagination="False"><p>The key factor in the decision to use one high-speed serial port was the introduction in the spring of 1981 of the Zilog Corp.’s 85530 serial-communications controller, a single chip to replace two less expensive conventional parts—” vanilla” chips—in the Macintosh. The risks in using the Zilog chip were that it had not been proven in the field and it was expensive, almost $9 apiece. In addition, Apple had a hard time convincing Zilog that it seriously intended to order the part in high volumes for the Macintosh.</p><p>“We had an image problem,” explained Mr. Espinosa. “We wore T-shirts and blue jeans with holes in the knees, and we had a maniacal conviction that we were right about the Macintosh, and that put some people off. Also, Apple hadn’t yet sold a million Apple IIs. How were we to convince them that we would sell a million Macs?”</p><p>In the end, Apple got a commitment from Zilog to supply the part, which Mr. Espinosa attributes to the negotiating talents of Mr. Jobs. The serial input/output ports “gave us essentially the same bandwidth that a memory-mapped parallel port would,” Mr. Smith said. Peripherals were connected to serial ports in a daisy-chain configuration with the Apple bus network.</p><h2>Designing the Mac’s Factory Without the Product</h2><p>In the fall of 1981, as Mr. Smith worked on the fourth Macintosh prototype, the design for the Macintosh factory was getting under way. Mr. Jobs hired <a href="https://spectrum.ieee.org/steve-jobs-realworld-leading-ladies-gather" target="_self">Debi Coleman</a>, who was then working as financial manager at <a href="https://www.hp.com/us-en/home.html" target="_blank">Hewlett-Packard Co.</a> in Cupertino, Calif., to handle the finances of the Macintosh project. A graduate of Stanford University with a master’s degree in business ad­ministration, Ms. Coleman was a member of a task force at HP that was studying factories, quality management, and inventory management. This was good training for Apple, for Mr. Jobs was intent on using such concepts to build a highly automated manufacturing plant for the Macintosh in the United States.</p><p>Briefly he considered building the plant in Texas, but since the designers were to work closely with the manufacturing team in the later stages of the Macintosh design, he decided to locate the plant at Fremont, Calif., less than a half-hour’s drive from Apple’s Cupertino headquarters.</p><p>Mr. Jobs and other members of the Macintosh team made frequent tours of automated plants in various industries, particularly in Japan. At long meetings held after the visits, the manufacturing group discussed whether to borrow certain methods they had observed.</p></div><p><img id="32edd" data-rm-shortcode-id="b1e99327cd193c63c5d6c7a5f5a830aa" data-rm-shortcode-name="rebelmouse-image" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/hands-hold-a-round-cone-like-object-up-to-the-front-of-a-macintosh-computer-display.jpg?id=34133930&amp;width=980" data-runner-src="https://spectrum.ieee.org/media-library/hands-hold-a-round-cone-like-object-up-to-the-front-of-a-macintosh-computer-display.jpg?id=34133930&amp;width=980" width="1619" height="1301" alt="Hands hold a round cone-like object up to the front of a Macintosh computer display"><small><p>The Macintosh factory borrowed assembly ideas from other computer plants and other industries. A method of testing the brightness of cathode-ray tubes was borrowed from television manufacturers.</p></small></p><div id="rebelltitem23" data-id="23" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-23" data-basename="particle-23" data-post-id="2661376756" data-published-at="1686939853" data-use-pagination="False"><p>The Macintosh factory design was based on two major concepts. The first was “just-in-time” inventory, calling for vendors to deliver parts for the Macintosh frequently, in small lots, to avoid excessive handling of components at the factory and reduce damage and storage costs. The second concept was zero-defect parts, with any defect on the manufacturing line immediately traced to its source and rectified to prevent recurrence of the error.</p><p>The factory, which was to churn out about a half million Macintosh computers a year (the number kept increasing), was designed to be built in three stages: first, equipped with stations for workers to insert some Macintosh components, delivered to them by simple robots; second, with robots to insert components instead of workers; and third, many years in the future, with “integrated” automation, requiring virtually no human operators. In building the factory, “Steve was willing to chuck all the traditional ideas about manufacturing and the relationship between design and manufacturing,” Ms. Coleman noted. “He was willing to spend whatever it cost to experiment in this factory. We planned to have a major revision every two years.”</p><p>By late 1982, before Mr. Smith had designed the final Macintosh prototype, the designs of most of the factory’s major subassemblies were frozen, and the assembly stations could be designed. About 85 percent of the components on the digital-logic printed-circuit board were to be inserted automatically, and the remaining 15 percent were to be surface-mounted devices inserted manually at first and by robots in the second stage of the factory. The production lines for automatic insertion were laid out to be flexible; the number of stations was not defined until trial runs were made. The materials-delivery system, designed with the help of engineers recruited from Texas Instruments in Dallas, Texas, divided small and large parts between receiving doors at the materials distribution center. The finished Macintoshes coming down the conveyor belt were to be wrapped in plastic and stuffed into boxes using equipment adapted from machines used in the wine industry for packaging bottles.</p></div><p><img id="3b9b2" data-rm-shortcode-id="001bc2cbe2fca207d4d093a4fed3b94a" data-rm-shortcode-name="rebelmouse-image" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-closeup-of-gears-and-rollers-with-strips-of-electronic-components-feeding-through-them.jpg?id=34133981&amp;width=980" data-runner-src="https://spectrum.ieee.org/media-library/a-closeup-of-gears-and-rollers-with-strips-of-electronic-components-feeding-through-them.jpg?id=34133981&amp;width=980" width="979" height="1001" alt="A closeup of gears and rollers with strips of electronic components feeding through them"><small><p>Most of the discrete components in the Macintosh are inserted automatically into the printed-circuit boards.</p></small></p><div id="rebelltitem22" data-id="22" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-22" data-basename="particle-22" data-post-id="2661376756" data-published-at="1686939853" data-use-pagination="False"><p>As factory construction progressed, pressure built on the Macintosh design team to deliver a final prototype. The designers had been working long hours but with no deadline set for the computer’s introduction. That changed in the middle of 1981, after Mr. Jobs imposed a tough and sometimes unrealistic schedule, reminding the team repeatedly that “real artists ship” a finished product. In late 1981, when IBM announced its personal computer, the Macintosh marketing staff began to refer to a “window of opportunity” that made it urgent to get the Macintosh to customers.</p><p>“We had been saying, ‘We’re going to finish in six months’ for two years,” Mr. Hertzfeld recalled.</p><p>The new urgency led to a series of design problems that seemed to threaten the Macintosh dream.</p><h2>The Mac Team Faces Impossible Deadlines</h2><p>The computer’s circuit density was one bottleneck. Mr. Smith had trouble paring enough circuitry off his first two prototypes to squeeze them onto one logic board. In addition, he needed faster circuitry for the Macintosh display. The horizontal resolution was only 384 dots—not enough room for the 80 characters of text needed for the Macintosh to compete as a word processor. One suggested solution was to use the word-processing software to allow an 80-character line to be seen by horizontal scrolling. However, most standard computer displays were capable of holding 80 characters, and the portable computers with less capability were very inconvenient to use.</p><p>Another problem with the Macintosh display was its limited dot density. Although the analog circuitry, which was being designed by Apple engineer George Crow, accommodated 512 dots on the horizontal axis, Mr. Smith’s digital circuitry—which consisted of bipolar logic arrays—did not operate fast enough to generate the dots. Faster bipolar circuitry was considered but rejected because of its high-power dissipation and its cost. Mr. Smith could think of but one alternative: combine the video and other miscellaneous circuitry on a single custom n-channel MOS chip.</p><p>Mr. Smith began designing such a chip in February 1982. During the next six months the size of the hypothetical chip kept growing. Mr. Jobs set a shipping target of May 1983 for the Macintosh but, with a backlog of other design problems, Burrell Smith still had not finished designing the custom chip, which was named after him: the IBM (Integrated Burrell Machine) chip.</p></div><div id="rebelltitem27" data-id="27" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-27" data-basename="particle-27" data-post-id="2661376756" data-published-at="1686942238" data-use-pagination="False"><p>Meanwhile, the Macintosh offices were moved from Texaco Towers to more spacious quarters at the Apple headquarters, since the Macintosh staff had swelled to about 40. One of the new employees was Robert Belleville, whose previous employer was <a href="https://spectrum.ieee.org/xerox-parc" target="_self">the Xerox Palo Alto Research Corp</a>. At Xerox he had designed the hardware for the Star workstation—which, with its windows, icons. and mouse, might be considered an early prototype of the Macintosh. When Mr. Jobs offered him a spot on the Macintosh team, Mr. Belleville was impatiently waiting for authorization from Xerox to proceed on a project he had proposed that was similar to the Macintosh—a low-cost version of the Star.</p><p>As<em></em>the new head of the Macintosh engineering, Mr. Belleville faced the task of directing Mr. Smith, who was proceeding on what looked more and more like a dead-end course. Despite the looming deadlines, Mr. Belleville tried a soft-sell approach.</p><p>“I asked Burrell if he really needed the custom chip,” Mr. Belleville recalled. “He said yes. I told him to think about trying something else.”</p><p>After thinking about the problem for three months, Mr. Smith concluded in July 1982 that “the difference in size between this chip and the state of Rhode Island is not very great.” He then set out to design the circuitry with higher-speed programmable-array logic—as he had started to do six months earlier. He had assumed that higher resolution in the horizontal video required a faster clock speed. But he realized that he could achieve the same effect with clever use of faster bipolar-logic chips that had become available only a few months earlier. By adding several high­-speed logic circuits and a few ordinary circuits, he pushed the resolution up to 512 dots.</p><p>Another advantage was that the PALs were a mature technology and their electrical parameters could tolerate large variations from the specified values, making the Macintosh more stable and more reliable—important characteristics for a so-called appliance product. Since the electrical characteristics of each integrated circuit may vary from those of other ICs made in different batches, the sum of the variances of 50<em></em>or so components in a computer may be large enough to threaten the system’s integrity.</p></div><p>“It became an intense and almost religious argument about the purity of the system’s design versus the user’s freedom to configure the system as he liked. We had weeks of argument over whether to add a few pennies to the cost of the machine.”<br>—Chris Espinosa</p><div id="rebelltitem29" data-id="29" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-29" data-basename="particle-29" data-post-id="2661376756" data-published-at="1686942238" data-use-pagination="False"><p>Even as late as the summer of 1982, with one deadline after another blown, the Macintosh designers were finding ways of adding features to the computer. After the team disagreed over the choice of a white background for the video with black characters or the more typical white-on-black, it was suggested that both options be made available to the user through a switch on the back of the Macintosh. But this compromise led to debates about other questions.</p><p>“It became an intense and almost religious argument,” recalled Mr. Espinosa, “about the purity of the system’s design versus the user’s freedom to configure the system as he liked. We had weeks of argument over whether to add a few pennies to the cost of the machine.”</p><p>The designers, being committed to the Macintosh, often worked long hours to refine the system. A programmer might spend many night hours to reduce the time needed to format a disk from three minutes to one. The reasoning was that expenditure of a Macintosh programmer’s time amounted to little in comparison with a reduction of two minutes in the formatting time. “If you take two extra minutes per user, times a million people, times 50 disks to format, that’s a lot of the world’s time,” Mr. Espinosa explained.</p><p>But if the group’s commitment to refinements often kept them from meeting deadlines, it paid off in tangible design improvements. “There was a lot of competition for doing something very bright and creative and amazing,” said Mr. Espinosa. “People were so bright that it became a contest to astonish them.”</p><p>The Macintosh team’s approach to working—“like a Chautauqua, with daylong affairs where people would sit and talk about how they were going to do this or that’”—sparked creative thinking about the Macintosh’s capabilities. When a programmer and a hardware designer started to discuss how to implement the sound generator, for instance, they were joined by one of several nontechnical members of the team—marketing staff, finance specialists, secretaries—who remarked how much fun it would be if the Macintosh could sound four distinct voices at once so the user could program it to play music. That possibility excited the programmer and the hardware engineer enough to spend extra hours in designing a sound generator with four voices.</p><p>The payoff of such discussions with nontechnical team members, Mr. Espinosa said, “was coming up with all those glaringly evident things that only somebody completely ignorant could come up with. If you immerse yourself in a group that doesn’t know the technical limitations, then you get a group mania to try and deny those limitations. You start trying to do the impossible—and once in a while succeeding.”</p></div><p>Nobody had even considered designing a four-voice [sound] generator—that is, not until “group mania” set in.</p><div id="rebelltitem31" data-id="31" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-31" data-basename="particle-31" data-post-id="2661376756" data-published-at="1686942238" data-use-pagination="False"><p>The sound generator in the original Macintosh was quite simple—a one-bit register connected to a speaker. To vibrate the speaker, the programmer wrote a software loop that changed the value of the register from one to zero repeatedly. Nobody had even considered designing a four-voice generator—that is, not until “group mania” set in.</p><p>Mr. Smith was pondering this problem when he noticed that the video circuitry was very similar to the sound-generator circuitry. Since the video was bit-mapped, a bit of memory represented one dot on the video screen. The bits that made up a complete video image were held in a block of RAM and fetched by a scanning circuit to generate the image. Sound circuitry required similar scanning, with data in memory corresponding to the amplitude and frequency of the sound emanating from the speaker. Mr. Smith reasoned that by adding a pulse-width-modulator circuit, the video circuitry could be used to generate sound during the last microsecond of the horizontal retrace—the time it took the electron beam in the cathode-ray tube of the display to move from the last dot on each line to the first dot of the next line. During the retrace the video-scanning circuitry jumped to a block of memory earmarked for the amplitude value of the sound wave, fetched bytes, deposited them in a buffer that fed the sound generator, and then jumped back to the video memory in time for the next trace. The sound generator was simply a digital-to-analog converter connected to a linear amplifier.</p><p>To enable the sound generator to produce four distinct voices, software routines were written and embedded in ROM to accept values representing four separate sound waves and convert them into one complex wave. Thus a programmer writing applications programs for the Macintosh could specify separately each voice without being concerned about the nature of the complex wave.</p><h2>Gearing up to Build Macs</h2><p>In the fall of 1982, as the factory was being built and the design of the Macintosh was approaching its final form, Mr. Jobs began to play a greater role in the day-to-day activities of the designers. Although the hardware for the sound generator had been designed, the software to enable the computer to make sounds had not yet been written by Mr. Hertzfeld, who considered other parts of the Macintosh software more urgent. Mr. Jobs had been told that the sound generator would be impressive, with the analog circuitry and the speaker having been upgraded to accommodate four voices. But since this was an additional hardware expense, with no audible results at that point, one Friday Mr. Jobs issued an ultimatum: “If I don’t hear sound out of this thing by Monday morning, we’re ripping out the amplifier.”</p><p>That motivation sent Mr. Hertzfeld to the office during the weekend to write the software. By Sunday afternoon only three voices were working. He telephoned his colleague Mr. Smith and asked him to stop by and help optimize the software.</p></div><p>“Do you mean to tell me you’re using subroutines!” Burrell Smith exclaimed after examining the problem. “No wonder you can’t get four voices. Subroutines are much too slow.”</p><div id="rebelltitem33" data-id="33" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-33" data-basename="particle-33" data-post-id="2661376756" data-published-at="1686942238" data-use-pagination="False"><p>“Do you mean to tell me you’re using subroutines!” Mr. Smith exclaimed after examining the problem. “No wonder you can’t get four voices. Subroutines are much too slow.”</p><p>By Monday morning, the pair had written the microcode programs to produce results that satisfied Mr. Jobs.</p><p>Although Mr. Jobs’s input was sometimes hard to define, his instinct for defining the Macintosh as a product was important to its success, according to the designers. “He would say, ‘This isn’t what I want. I don’t know what I want, but this isn’t it.’” Mr. Smith said.</p><p>“He knows what great products are,” noted Mr. Hertzfeld. “He intuitively knows what people want.’’</p><p>One example was the design of the Macintosh casing, when clay models were made to demonstrate various possibilities. “I could hardly tell the difference between two models,” Mr. Hertzfeld said. “Steve would walk in and say, ‘This one stinks and this one is great.’ And he was usually right.”</p><p>Because Mr. Jobs placed great emphasis on packaging the Macintosh to occupy little space on a desk, a vertical design was used, with the disk drive placed underneath the CRT.</p><p>Mr. Jobs also decreed that the Macintosh contain no fans, which he had tried to eliminate from the original Apple computer. A vent was added to the Macintosh casing to allow cool air to enter and absorb heat from the vertical power supply, with hot air escaping at the top. The logic board was horizontally positioned.</p></div><p>[Steve] Jobs at times gave unworkable orders. When he demanded that the designers reposition the RAM chips on an early printed-circuit board because they were too close together, “most people chortled.”</p><div id="rebelltitem35" data-id="35" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-35" data-basename="particle-35" data-post-id="2661376756" data-published-at="1686942238" data-use-pagination="False"><p>Mr. Jobs, however, at times gave unworkable orders. When he demanded that the designers reposition the RAM chips on an early printed-circuit board because they were too close together, “most people chortled,” one designer said. The board was redesigned with the chips farther apart, but it did not work because the signals from the chips took too long to propagate over the increased distance. The board was redesigned again to move the chips back to their original position.</p><h2>Stopping the Radiation Leaks</h2><p>When the design group started to concentrate on manufacturing, the most imposing task was preventing radiation from leaking from the Macintosh’s plastic casing. At one time the fate of the Apple II had hung in the balance as its designers tried unsuccessfully to meet the emissions standards of the Federal Communications Commission. “I quickly saw the number of Apple II components double when several inductors and about 50 capacitors were added to the printed-circuit boards,” Mr. Smith recalled. With the Macintosh, however, he continued, “we eliminated all of the discrete electronics by going to a connector-less and solder-less design; we had had our noses rubbed in the FCC regulations, and we knew how important that was.’’ The high­speed serial I/O ports caused little interference because they were easy to shield.</p><p>Another question that arose toward the end of the design was the means of testing the Macintosh. In line with the zero-defect concept, the Macintosh team devised software for factory workers to use in debugging faults in the printed-circuit boards, as well as self-testing routines for the Macintosh itself.</p><p>The disk controller is tested with the video circuits. Video signals sent into the disk controller are read by the microprocessor. “We can display on the screen the pattern we were supposed to receive and the pattern we did receive when reading off the disk,” Mr. Smith explained, “and other kinds of prepared information about errors and where they occurred on the disk.’’</p><p>To test the printed-circuit boards in the factory, the Macintosh engineers designed software for a custom bed-of-nails tester that checks each computer in only a few seconds, faster than off-the-­shelf testers. If a board fails when a factory worker places it on the tester, the board is handed to another worker who runs a diagnostic test on it. A third worker repairs the board and returns it to the production line.</p></div><p><img id="3679b" data-rm-shortcode-id="56bbeced2e6f5852f115e5e65e31f2b8" data-rm-shortcode-name="rebelmouse-image" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/rows-of-macintosh-computers-on-racks.jpg?id=34133989&amp;width=980" data-runner-src="https://spectrum.ieee.org/media-library/rows-of-macintosh-computers-on-racks.jpg?id=34133989&amp;width=980" width="1143" height="869" alt="Rows of Macintosh computers on racks"><small><p>Each Macintosh is burned in—that is, turned on and heated—to detect the potential for early failures before shipping, thus increasing the reliability of the computers that are in fact shipped.</p></small></p><div id="rebelltitem36" data-id="36" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-36" data-basename="particle-36" data-post-id="2661376756" data-published-at="1686942238" data-use-pagination="False"><p>When Apple completed building the Macintosh factory, at an investment of $20 million, the design team spent most of its time there, helping the manufacturing engineers get the production lines moving. Problems with the disk drives in the middle of 1983 required Mr. Smith to redesign his final prototype twice.</p><p>Some of the plans for the factory proved troublesome, according to Ms. Coleman. The automatic insertion scheme for discrete components was unexpectedly difficult to implement. Many of the precise specifications for the geometric and electrical properties of the parts had to be reworked several times. Machines proved to be needed to align many of the parts before they were inserted. Although the machines, at $2000 apiece, were not expensive, they were a last-minute requirement.</p><p>The factory had few major difficulties with its first experimental run in December 1983, although the project had slipped from its May 1983 deadline. Often the factory would stop completely while engineers busily traced the faults to the sources—part of the zero-defect approach. Mr. Smith and the other design engineers virtually lived in the factory that December.</p><p>In January 1984 the first salable Macintosh computer rolled off the line. Although the production rate was erratic at first, it has since settled at one Macintosh every 27 seconds—about a half million a year.</p><h2>An Unheard of $30 Million Marketing Budget</h2><p>The marketing of the Macintosh shaped up much like the marketing of a new shampoo or soft drink, according to Mike Murray, who was hired in 1982 as the third member of the Macintosh marketing staff. “If Pepsi has two times more shelf space than Coke,” he explained, “you will sell more Pepsi. We want to create shelf space in your mind for the Macintosh.’’</p><p>To create that space on a shelf already crowded by IBM, Tandy, and other computer companies, Apple launched an aggressive advertising campaign—its most expensive ever.</p><p>Mr. Murray proposed the first formal marketing budget for the Macintosh in late 1983: he asked for $40 million. “People literally laughed at me,” he recalled. “They said, ‘What kind of a yo-yo is this guy?’ “He didn’t get his $40 million budget, but he got close to it—$30 million.</p></div><p>“We’ve established a beachhead with the Macintosh. If IBM knew in their heart of hearts how aggressive and driven we are, they would push us off the beach right now.”<br>—Mike Murray</p><div id="rebelltitem38" data-id="38" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/apple-macintosh/particle-38" data-basename="particle-38" data-post-id="2661376756" data-published-at="1686944251" data-use-pagination="False"><p>
	The marketing campaign started before the Macintosh was introduced. Television viewers watching the Super Bowl football game in January 1984 saw <a href="https://www.youtube.com/watch?v=VtvjbmoDx-I" rel="noopener noreferrer" target="_blank">a commercial</a> with the Macintosh overcoming Orwell’s nightmare vision of 1984.
</p><p>
	Other television advertisements, as well as magazine and billboard ads, depicted the Macintosh as being easy to learn to use. In some ads, the Mac was positioned directly alongside IBM’s personal computer. Elaborate color foldouts in major magazines pictured the Macintosh and members of the design team.</p><p>
	“The interesting thing about this business,” mused Mr. Murray, “is that there is no history. The best way is to come in really smart, really understand the fundamentals of the technology and how the software dealers work, and then run as fast as you can.’’
</p><h2>The Mac Team Disperses</h2><p>
	“We’ve established a beachhead with the Macintosh,” explained Mr. Murray. “We’re on the beach. If IBM knew in their heart of hearts how aggressive and driven we are, they would push us off the beach right now, and I think they’re trying. The next 18 to 24 months is do-or-die time for us.”
</p><p>
	With sales of the Lisa workstation disappointing, Apple is counting on the Macintosh to survive. The ability to bring out a successful family of products is seen as a key to that goal, and the company is working on a series of Macintosh peripherals—printers, local-area networks, and the like. This, too, is proving both a technical and organizational challenge.
</p><p>
	“Once you go from a stand-alone system to a networked one, the complexity increases enormously,” noted Mr. Murray. “We cannot throw it all out into the market and let people tell us what is wrong with it. We have to walk before we can run.”
</p><p>
	Only two software programs were written by Apple for the Macintosh—Macpaint, which allows users to draw pictures with the mouse, and Macwrite, a word-processing program. Apple is counting on independent software vendors to write and market applications programs for the Macintosh that will make it a more attractive product for potential customers. The company is also modifying some Lisa software for use on Macintosh and making versions of the Macintosh software to run on the Lisa.
</p><p>
	Meanwhile the small, coherent Macintosh design team is no longer. “Nowadays we’re a large company,” Mr. Smith remarked.
</p><p><span></span>“The pendulum of the project swings,” explained Mr. Hertzfeld, who has taken a leave of absence from Apple. “Now the company is a more mainstream organization, with managers who have managers working for them. That’s why I’m not there, because I got spoiled” working on the Macintosh design team.<span></span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Do We Owe Our Teams? (112 pts)]]></title>
            <link>https://www.mironov.com/owe/</link>
            <guid>36562868</guid>
            <pubDate>Sun, 02 Jul 2023 16:15:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mironov.com/owe/">https://www.mironov.com/owe/</a>, See on <a href="https://news.ycombinator.com/item?id=36562868">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
          <div>
            
            <p>Many of my discussions with product leaders (CPOs, VPs and others who manage teams of product folks) are about the substance of product management: portfolios, competing stakeholders, pricing &amp; packaging, tarot cards as a revenue forecasting model. &nbsp;Last week, though, in my <a href="https://maven.com/richmironov/pmleaders/?ref=mironov.com">product leadership workshop</a>, we had an extended discussion about the <strong>core people-and-organizational obligations we have toward those who work for us</strong>.<br>(If you’re running some other department, these should sound familiar.)</p><h2 id="1-be-umbrellas-not-funnels">1. &nbsp;Be Umbrellas, Not Funnels</h2><p>Companies, especially executive teams, can generate a lot of chaos: “<a href="https://www.mironov.com/cake/">small</a>” interrupts, sudden shifts, cross-functional blame, budget jousting. &nbsp;In the colorful MBA vernacular, we’re either <a href="https://www.urbandictionary.com/define.php?term=Shit+Umbrella&amp;ref=mironov.com">poop umbrellas</a> or poop funnels: buffering our teams from the noise and confusion as best we can, or letting it all fall on their heads.</p><p>Umbrella-wielding is a skill: anticipating politics; de-escalating &nbsp;drama; being ready with in-the-moment analysis and insights about whether a problem is actually important; articulating which department is best equipped to handle today’s small crisis; practicing organizational <em>jiu jitsu</em>.</p><p>Examples:</p><ul><li>A Fortune 50 financial company light-years away from our core manufacturing market expresses interest. &nbsp;Sales (inevitably) wants to expand our European SMB tech manufacturing <a href="https://www.portent.com/blog/cro/ideal-customer-profiles-beginners-guide.htm?ref=mironov.com">ICP</a> to include US-based global banks. Product fit will probably be catastrophic. &nbsp;This requires a quick-but-urgent review of the opportunity with Product and Engineering before it’s committed to the revenue pipeline.</li><li>Our CEO thinks that a new product manager is doing a poor job because her product has falling revenue and poor customer feedback. &nbsp;But she’s newly assigned to a decrepit old widget that’s in a shrinking segment and hasn’t been maintained for years. &nbsp;In your opinion, she’s very talented and just inherited a mess. &nbsp;Best to walk back the CEO’s misimpression quickly, before the discussion turns to firings.</li><li>A competitor announces ChatGPT-based retirement investment advice. &nbsp;<em>(Probably doesn't work yet, or gives generically bad advice 100x faster than humans.) </em> With generative AI at the very top of its hype cycle, the Board wants a 90-day meet-the-competition development plan, and says they are willing to sacrifice everything on the roadmap to staff it. &nbsp;You’ll need to spend some political capital to slow this down just a little – then sell the idea of a prototype, so we can find out whether it makes any sense.</li></ul><p>Also, when there’s a hot issue with unclear ownership, &nbsp;we don’t throw our subordinates under the bus. &nbsp;So <a href="https://www.mironov.com/pronouns/">pronouns</a> matter: “<em><strong>I </strong></em>think this tax calculation issue crosses products and departments: give <em><strong>me</strong></em> a day to chase down which group can fix it” is much better than “Sandeep screwed up again – let me pull <em><strong>him</strong></em> into the meeting” or “those losers in BizOps were supposed to keep the pricing database 100% accurate.”</p><h2 id="2-merchandize-good-work">2. &nbsp;Merchandize Good Work</h2><p>People who are invisible – or whose work is invisible – miss out on raises and promotions and invitations to do cool stuff. &nbsp;And most of the good things our product (and engineering and design and research and documentation and test automation and support) teams do isn’t very visible. &nbsp;So it’s incumbent on us as leaders to gently – but relentlessly – <a href="https://www.mironov.com/merchandizing/">merchandize</a> our teams’ good work and accomplishments and business-relevant wins.</p><ul><li>If we’ve fixed some poor UX in our sign-up funnel, consider a 90-second video where the product manager introduces the problem, the designer who fixed it <a href="https://www.mironov.com/show-tell/">shows</a> a brief before-and-after, and the product manager recaps with outcome/impact. <em> (“1.1% higher top-of-funnel conversion means $3-4M more per quarter in top-line revenue.”)</em></li><li>Shortening onboarding time/effort lets us add more customers faster, at lower cost. &nbsp;Maybe in our monthly All-Hands we call out the Customer Success person who suggested the fix, the content creator whose “onboard yourself faster” checklist sped up onboarding by 11%, and the product manager overseeing new customer tools.</li><li>I love having my teams identify unappreciated heroes in other departments, so I can <a href="https://www.mironov.com/ty/">send their VPs a thank-you note</a> on behalf of Product. &nbsp;Recognizing good work can be habit-forming.</li></ul><p>BTW, there’s a reverse halo effect here. &nbsp;If my extended team is seen as successful and hardworking and smart, I get some of the reflected glow. &nbsp;Other leaders give us the benefit of the doubt, and talented folks want to move into our group.</p><h2 id="3-provide-honest-career-pathing">3. Provide Honest Career Pathing</h2><p>At scale, product managers might be 2-3% of a company’s employees. &nbsp;The role is vaguely defined, challenging, and demands an unusual mix of skills. People come in all shapes, sizes, styles, and talents – that mostly fit <em><strong>other</strong></em> roles. So we owe our team gentle-but-clear-and-frequent communication about how they are doing and where we see them going next. &nbsp;(When I’ve parachuted into companies as interim CPO, my first order of business has been to quickly evaluate the team I’ve inherited.) &nbsp;Examples:</p><ul><li>Someone<strong> green but smart, humble, curious, and coachable</strong>... we might map out 4-6 areas for intense mentoring through the year. &nbsp;Talk through the theory of <a href="https://www.mironov.com/moneystories/">thumbnail business cases</a>, work the first 3 or 4 together with lots of coaching, then move down the skills list.</li><li>A <strong>deeply opinionated subject expert </strong>with visible disdain for average users will focus on rarely used expert features and tend to ignore opinions from the bottom 95% of customers. &nbsp;Maybe an evangelist or implementation architect role is a better match: worth a frank talk about fit and attitudes and where to make the biggest contributions to the company.</li><li>A<strong> product veteran</strong> who is effortlessly juggling a maker team, represents product management on a strategy task force, and coaches the newbies may need a bigger challenge. &nbsp;Are there open slots for directors? &nbsp;Can we create one? Is there a juicy assignment coming up? &nbsp;A win for the company even if they move out of my team.</li></ul><h2 id="4-play-the-long-game">4. Play the Long Game</h2><p>The half-life of any particular job is short, and most companies don’t last. &nbsp;So the great people we nurture will eventually be somewhere else. &nbsp;In the long game, we’re investing in the larger product community and relationships that span years and organizations. &nbsp;Ideally, you have a portfolio of trusted peers<em> (for moral support, shared challenges)</em> and a few mentors <em>(for career advice, realistic POV)</em> and up-and-comers <em>(<a href="https://www.mironov.com/pif/">paying it forward</a>)</em>. &nbsp;As we move up through organizations, our informal external networks get more and more valuable. &nbsp;</p><p>Which raises a “what do we owe them” quandary: what if your best player signals that she wants to leave? &nbsp;I see competing obligations to my company <em>(keep the best talent)</em> and myself <em>(run a strong department)</em> and to her <em>(support new opportunities and challenges)</em>. &nbsp;It might go this way:</p><ul><li>First, an honest closed-door conversation about her real concerns or goals. &nbsp;Is she unhappy with the company? &nbsp;Frustrated by my management style? Needing flexibility or some recharge/refresh time? &nbsp;Bored and ready to move onto greener pastures? &nbsp;Different issues, different answers. &nbsp;(As product folks, we should never offer solutions until we’re clear on the underlying problem.)</li><li>If there are some reasonable solutions or accommodations, explore and sell them – but don’t oversell or promise something you can’t deliver. &nbsp;Product folks have pretty good BS detectors. &nbsp;I’d rather have her be my peer or lead a peer organization in my company than lose her.</li><li>But if not, I usually feel the obligation to help her reach/find her next adventure. &nbsp;<strong>To play the long game.</strong> &nbsp;To continue being a coach/mentor outside the company. &nbsp;To value the person, not just the work. &nbsp;That might include <a href="https://www.mironov.com/exiting/">talking about outside opportunities, exit timelines and career implications</a>; being a (quiet, careful) job reference; voicing honest opinions about trends or industries; sharing contacts at a few non-competing companies; offering to be a sounding board for her inevitable next challenges.</li></ul><p>If we cherish our people as much as our products and end users, we should be supporting their goals and dreams as much as our own.</p><h2 id="sound-byte">Sound Byte</h2><p>Leading an organization and managing people carries a substantial responsibility to those who work for us. &nbsp; We need to support and protect them so that they can do their best work; build recognition for them; and help them look ahead to what’s next. &nbsp;Not that different from building a product or <a href="https://www.mironov.com/parenting_and_pm/">raising a child</a>.</p>
          </div>
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Make Your Renders Unnecessarily Complicated by Modeling a Film Camera in Blender [video] (241 pts)]]></title>
            <link>https://www.youtube.com/watch?v=YE9rEQAGpLw</link>
            <guid>36562757</guid>
            <pubDate>Sun, 02 Jul 2023 16:03:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=YE9rEQAGpLw">https://www.youtube.com/watch?v=YE9rEQAGpLw</a>, See on <a href="https://news.ycombinator.com/item?id=36562757">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Aspartame: Once More Unto the Breach (166 pts)]]></title>
            <link>https://dynomight.net/aspartame/</link>
            <guid>36562739</guid>
            <pubDate>Sun, 02 Jul 2023 16:02:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dynomight.net/aspartame/">https://dynomight.net/aspartame/</a>, See on <a href="https://news.ycombinator.com/item?id=36562739">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <p>Look, I get it. Diet Coke tastes sweet because it has aspartame in it. Aspartame is a weird synthetic molecule that’s 200 times sweeter than sucrose. Half of the world’s aspartame is made by Ajinomoto of Tokyo—the same company that first brought us MSG back in 1909.</p>

<p><img src="https://dynomight.net/img/aspartame/ajinomoto-headquarters.jpg" alt="ajinomoto headquarters"></p>

<p>If you look on <a href="https://en.wikipedia.org/wiki/Aspartame">Wikipedia</a>, you’ll see that aspartame is a <em>methyl ester of the aspartic acid phenylalanine dipeptide</em>, which isn’t, like, comforting.</p>

<p>It’s normal to have a prior that aspartame might be bad for you. Certainly, that was <em>my</em> prior. Without looking at any evidence, any reasonable person would think like this:</p>

<table>
  <thead>
    <tr>
      <th>aspartame is…</th>
      <th>odds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>…good for you</td>
      <td>very unlikely</td>
    </tr>
    <tr>
      <td>…harmless</td>
      <td>plausible</td>
    </tr>
    <tr>
      <td>…bad for you</td>
      <td>plausible</td>
    </tr>
  </tbody>
</table>

<p>This makes the decision theory pretty simple: Consuming aspartame has little upside, but substantial downside.</p>

<p>The thing is, we do have evidence. We have a lot of evidence. The FDA calls aspartame “one of the most exhaustively studied substances in the human food supply”.</p>

<p>The other thing is, the alternative to aspartame often isn’t <em>no aspartame</em> but rather <em>sugar</em> or <a href="https://dynomight.net/cola/#mexican-coke"><em>corn syrup</em></a> or even perhaps even <a href="https://dynomight.net/alcohol/"><em>alcohol</em></a>.</p>

<p>I don’t want to convince anyone to consume aspartame. But if we’re choosing between aspartame and other risky things, we should evaluate the relative risks.</p>

<h2 id="what-happens-to-aspartame-after-it-goes-into-your-body">What happens to aspartame after it goes into your body</h2>

<p>Let’s forget about safety for a second, and just look at the causal chain. Say you drink a Diet Coke. What happens next?</p>

<h3 id="fact-1-aspartame-is-quickly-broken-down-in-the-gut">Fact 1: Aspartame is quickly broken down in the gut.</h3>

<p>After you drink a Diet Coke, the aspartame goes to your guts. After that, it’s very quickly broken down into 50% phenylalanine, 40% aspartic acid, and 10% methanol. For example, a can of Diet Coke contains 184 mg of aspartame. This becomes:</p>

<ul>
  <li>92 mg of phenylalanine</li>
  <li>73.6 mg aspartic acid</li>
  <li>18.4 mg methanol</li>
</ul>

<details>
  <summary>This happens quickly and completely. No aspartame ever enters your bloodstream. The rest of your body only ever sees these three other chemicals. (<u>click here or on any paragraph with a triangle for more details</u>)</summary>

  <p>The European Food Safety Authority Report (EFSA) report: <a href="https://www.efsa.europa.eu/en/efsajournal/pub/3496">Scientific Opinion on the re-evaluation of aspartame as a food additive</a> gives this figure (slightly modified):</p>

  <p><img src="https://dynomight.net/img/aspartame/metabolism-bigger2.svg" alt="metabolism"></p>

  <p>The same report gives this discussion:</p>

  <p><img src="https://dynomight.net/img/aspartame/EFSA-breakdown.svg" alt="EFSA breakdown"></p>

</details>

<h3 id="fact-2-phenylalanine-is-a-standard-amino-acid-you-consume-all-the-time">Fact 2: Phenylalanine is a standard amino acid you consume all the time.</h3>

<p>We recently talked about <a href="https://dynomight.net/diet-coke-nootropic/">phenylalanine</a>. It is an essential amino acid. If you didn’t consume any of it then when your body tried to make certain proteins those proteins would get truncated, and then they wouldn’t do what they are supposed to do, and then you would die.</p>

<p>Fortunately, that’s almost impossible. From 2% to 5% of all protein in food is phenylalanine. The recommended dietary allowance for a 70 kg (154 lb) person is at least 2130 mg. Meat-eating men in the UK average 3500 mg per day, while vegetarians and vegans get slightly less.</p>

<p>Here are the amounts of phenylalanine in a few foods:</p>

<table>
  <tbody>
    <tr>
      <td>potato</td>
      <td>170 mg</td>
    </tr>
    <tr>
      <td>large egg</td>
      <td>340 mg</td>
    </tr>
    <tr>
      <td>8 oz (235 ml) glass of milk</td>
      <td>430 mg</td>
    </tr>
    <tr>
      <td>400g box of tofu</td>
      <td>3300 mg</td>
    </tr>
  </tbody>
</table>

<details>
  <summary>The 92 mg of phenylalanine you get from a Diet Coke is much less than what virtually everyone already gets from other sources.</summary>

  <p><a href="https://doi.org/10.1186/s13023-020-01391-y">MacDonald et al. (2020)</a>:</p>

  <p><img src="https://dynomight.net/img/aspartame/macdonald.svg" alt="macdonald"></p>

  <p>RDA guidelines are <a href="https://globalrph.com/rda-and-ear-recommendations-for-essential-amino-acids/">here</a>. For adults, the recommendation is at least 33 m/kg of phenylalanine (or tyrosine, a metabolite of phenylalanine). For a 70 kg (154 lb) person, that would be 2130 mg.</p>

  <p><a href="https://doi.org/10.1038/ejcn.2015.144">Schmidt et al. (2015)</a>:</p>

  <p><img src="https://dynomight.net/img/aspartame/schmidt.svg" alt="schmidt"></p>

</details>

<p>Around 1 in 12,000 babies is born with <a href="https://www.nichd.nih.gov/health/topics/factsheets/pku">phenylketonuria</a>, a serious genetic disorder that results in low levels of <a href="https://en.wikipedia.org/wiki/Phenylalanine_hydroxylase">phenylalanine hydroxylase</a>, making it difficult to metabolize phenylalanine. People with phenylketonuria need to carefully monitor their consumption of phenylalanine (from all sources). This is why there’s this scary <strong>ALL-BOLD WARNING</strong>.</p>

<!-- ![phenylketonurics warning](/img/aspartame/phenylketonurics.jpg) -->

<p><img alt="phenylketonurics warning" src="https://dynomight.net/img/aspartame/phenylketonurics.jpg"></p>

<p>If you had phenylketonuria you would know it already.</p>

<h3 id="fact-3-aspartic-acid-is-a-standard-amino-acid-you-consume-all-the-time">Fact 3: Aspartic acid is a standard amino acid you consume all the time.</h3>

<p>Here’s <a href="https://commons.wikimedia.org/wiki/File:ProteinogenicAminoAcids.svg">a chart from Wikimedia</a> with our friends circled:</p>

<!-- ![amino-acids](/img/aspartame/amino-acids.png) -->

<p><img alt="amino acids" src="https://dynomight.net/img/aspartame/amino-acids.png"></p>

<p>Aspartic acid is not essential in humans, meaning that if you don’t eat it, your body can make it (usually from <a href="https://en.wikipedia.org/wiki/Oxaloacetic_acid">oxaloacetic acid</a>). But that’s not likely, since almost everything with protein has aspartic acid including meat, grains, dairy, vegetables, and eggs. Men in the UK average 6600 mg of aspartic acid per day.</p>

<details>
  <summary>The 74 mg of aspartic acid you get from a Diet Coke is two orders of magnitude less than what most people get already.</summary>

  <p>Here’s <a href="https://doi.org/10.1038/ejcn.2015.144">Schmidt et al. (2015)</a> again:</p>

  <p><img src="https://dynomight.net/img/aspartame/schmidt.svg" alt="schmidt"></p>

</details>

<h3 id="fact-4-methanol-is-a-simple-alcohol-you-consume-all-the-time">Fact 4: Methanol is a simple alcohol you consume all the time.</h3>

<p>Methanol (CH₃OH) is the simplest alcohol molecule. It’s in lots of food. Here are some foods with larger average amounts.</p>

<table>
  <thead>
    <tr>
      <th>food</th>
      <th>mg/kg methanol</th>
      <th>typical serving</th>
      <th>methanol</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>wine</td>
      <td>115.0</td>
      <td>150 ml glass</td>
      <td>17 mg</td>
    </tr>
    <tr>
      <td>tomatoes</td>
      <td>281.4</td>
      <td>medium 125g tomato</td>
      <td>35 mg</td>
    </tr>
    <tr>
      <td>citrus fruit</td>
      <td>106.5</td>
      <td>medium 140g orange</td>
      <td>15 mg</td>
    </tr>
  </tbody>
</table>

<p>This vastly underestimates how much methanol you get. In land plants, the primary component of cells walls is <a href="https://en.wikipedia.org/wiki/Pectin">pectin</a>. Once in the body, pectin degrades into methanol. Here are some estimates of the <em>indirect</em> increase in methanol various fruits and vegetables cause in this way.</p>

<table>
  <thead>
    <tr>
      <th>food</th>
      <th>mg/kg methanol</th>
      <th>typical serving</th>
      <th>methanol</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>root vegetables</td>
      <td>774</td>
      <td>medium 200 g potato</td>
      <td>155 mg</td>
    </tr>
    <tr>
      <td>apples</td>
      <td>508.5</td>
      <td>medium 170 g apple</td>
      <td>132 mg</td>
    </tr>
    <tr>
      <td>oranges</td>
      <td>531</td>
      <td>medium 140g orange</td>
      <td>74 mg</td>
    </tr>
    <tr>
      <td>bananas</td>
      <td>657</td>
      <td>120g without skin</td>
      <td>79 mg</td>
    </tr>
    <tr>
      <td>avocados</td>
      <td>486</td>
      <td>100g (flesh only)</td>
      <td>59 mg</td>
    </tr>
  </tbody>
</table>

<p>You get the idea. We eat things that contain methanol or metabolize into methanol all the time. It’s estimated that most people get between 130 and 1030 mg of methanol from food per day, much more than the 18 mg in a Diet Coke.</p>

<p>Now isn’t methanol toxic? Sure, if you consume enough of it. The <a href="https://en.wikipedia.org/wiki/Median_lethal_dose">LD₅₀</a> in rats is around 5600 mg/kg, as compared to 7300 mg/kg for <a href="https://dynomight.net/alcohol-trial/">good-old ethanol</a>.</p>

<details>
  <summary>One "conspiracy theory" you hear about aspartame is that it becomes formaldehyde once it's in the body. This is <em>absolutely true</em>: When metabolizing methanol, formaldehyde is created. But small amounts of formaldehyde are <em>completely normal</em>. The half-life of formaldehyde in human blood is around 1 minute, meaning it disappears almost immediately. You get more formaldehyde (via methanol) by eating an apple than by drinking a Diet Coke. Formaldehyde itself is also present in lots of foods, like meat, seafood, fruits, vegetables, and coffee.</summary>

  <p>The EFSA report:</p>

  <p><img src="https://dynomight.net/img/aspartame/EFSA-methanol.svg" alt="ESFA methanol"></p>

  <p>Also the ESFA report:</p>

  <p><img src="https://dynomight.net/img/aspartame/EFSA-methanol-2.svg" alt="ESFA methanol"></p>

  <p><a href="https://doi.org/10.1002/jps.21319">Dhareshwar and Stella (2008)</a></p>

  <p><img src="https://dynomight.net/img/aspartame/dhareshwar-1.svg" alt="dhareshwar 1"></p>

  <p>Also <a href="https://doi.org/10.1002/jps.21319">Dhareshwar and Stella (2008)</a>:</p>

  <p><img src="https://dynomight.net/img/aspartame/dhareshwar-2.svg" alt="dhareshwar 1"></p>

  <p>The EFSA report again:</p>

  <p><img src="https://dynomight.net/img/aspartame/EFSA-formaldehyde.svg" alt="ESFA formaldehyde"></p>

</details>

<h3 id="fact-5-this-doesnt-prove-aspartame-is-safe">Fact 5: This doesn’t prove aspartame is safe.</h3>

<p>To summarize the above:</p>

<ol>
  <li>Aspartame is quickly broken down in the gut into phenylalanine, aspartic acid, and methanol. Aspartame itself never enters your bloodstream or touches any other part of your body.</li>
  <li>Phenylalanine is normal.</li>
  <li>Aspartic acid is normal.</li>
  <li>Methanol is normal.</li>
</ol>

<p>(Incidentally, this same logic does not apply to other artificial sweeteners which mostly aren’t broken down at all.)</p>

<p>While <em>informative</em>, this does not <em>prove</em> aspartame is safe. Biology is crazy. But it should inform our priors. Speaking for myself, my previous model was that consuming aspartame would result in a crazy unknown synthetic chemical circulating around my body and doing god-knows-what. My updated model is that consuming aspartame results in slightly larger amounts of some totally normal chemicals.</p>

<p>This is reassuring. But even if they’re normal, could these chemicals still cause harm? Sure. Fortunately for us, aspartame was invented a long time ago, so we have lots of evidence.</p>

<h2 id="the-scientific-consensus">The scientific consensus</h2>

<h3 id="how-to-think-about-this-situation">How to think about this situation</h3>

<p>Aspartame was first made in 1965 and was approved by the FDA in 1981. In the decades since, there have been hundreds of studies.</p>

<p>Given so many studies, focusing on individual papers is a mistake. With enough <strike>monkeys pounding away at enough typewriters</strike> scientists pounding away at enough science, lots of weirdness is expected.</p>

<p>The right strategy is to look at the entire pool of evidence. Some tiny number of people have the time and expertise to comb through the entire literature and synthesize everything. For the rest of us, the only sane thing is to read other people who have done that synthesis.</p>

<h3 id="the-us-food-and-drug-administration-fda">The US Food and Drug Administration (FDA)</h3>

<p>In typical US government fashion, the FDA doesn’t go to great lengths to explain its reasoning to the public. The best you can find is this <a href="https://www.fda.gov/food/food-additives-petitions/additional-information-about-high-intensity-sweeteners-permitted-use-food-united-states">rather lame page</a>:</p>

<p><img src="https://dynomight.net/img/aspartame/FDA.svg" alt="FDA info"></p>

<p>The history of aspartame and the FDA is contentious and sort of infuriating. For the scientific question of “is aspartame safe?” the main thing to know is that the FDA approved it a long time ago, and continues to stand by those decisions.</p>

<details>
  <summary>
But it must be said that the history and public communication of the FDA on this issue is kind of a train wreck, and if I wanted to optimize it to serve as conspiracy theory fuel, I could scarcely do any better. The FDA says it continues to monitor new studies and remains confident aspartame is safe. So why doesn't it explain its reasoning to a skeptical public? The newest document the FDA can point people to is from 26 years ago. When a concerned citizen writes in, the FDA does things like respond 12 years later, while acting like that's perfectly normal.
</summary>

  <p>The FDA first approved aspartame for dry foods in 1974. However, there was a lot of controversy about the studies performed by <a href="https://en.wikipedia.org/wiki/G.D._Searle,_LLC">G.D. Searle</a>, the company that discovered aspartame in 1965 (and that Donald Rumsfeld would become CEO of in 1977). The FDA commissioner agreed with these criticisms and placed a stay on aspartame’s approval.</p>

  <p>After more debate, the FDA finally approved aspartame in 1981 in a <a href="https://www.fda.gov/media/89219/download">26-page report</a> with this summary:</p>

  <p><img src="https://dynomight.net/img/aspartame/FDA-1981.svg" alt="FDA 1981 report"></p>

  <p>In 1983 the FDA added approval for carbonated beverages. <a href="https://www.fda.gov/media/89189/download">The report</a> is mostly boring but this part is fun:</p>

  <p><img src="https://dynomight.net/img/aspartame/FDA-1983.svg" alt="FDA 1983 report"></p>

  <p>There was controversy about US Attorney General <a href="https://en.wikipedia.org/wiki/Samuel_K._Skinner">Samuel Skinner</a> who was involved in the case and then went on to take a job at a law firm that Searle used. This led <a href="https://en.wikipedia.org/wiki/Howard_Metzenbaum">Senator Metzenbaum</a> to request an investigation by the Government Accountability Office (GAO). They reported in 1987 that the process had been followed correctly. They also got responses from 69 researchers, 43 of whom worked in aspartame research.</p>

  <p><img src="https://dynomight.net/img/aspartame/image-20220614162208248.png" alt="image-20220614162208248"></p>

  <p>Finally in 1996, the FDA <a href="http://www.gpo.gov/fdsys/pkg/FR-1996-06-28/pdf/96-16522.pdf">approved</a> aspartame as a “general sweetener”.</p>

  <p><img src="https://dynomight.net/img/aspartame/FDA-1996.svg" alt="FDA 1996 report"></p>

  <p>Also in 1996, Roger Walton, a psychiatrist at Northeastern Ohio Universities College of Medicine, wrote a <a href="https://www.lightenyourtoxicload.com/wp-content/uploads/2014/07/Dr-Walton-survey-of-aspartame-studies.pdf">survey</a> that claimed that 74 out of 74 industry-funded studies confirmed aspartame’s safety whereas 84 out of 91 independent studies identified health concerns. Walton went appeared in a <a href="https://www.youtube.com/watch?v=BK_u7DG9DY8"><em>60 Minutes</em> special</a> on aspartame. It later turned out that Walton had missed at least 50 peer-reviewed studies  and most of the independent “studies” he did cite were really just letters to the editor or similar, many weren’t negative, and some didn’t involve aspartame at all.</p>

  <p>For example, Walton cites <a href="https://doi.org/10.1016/S0140-6736(85)90920-1">Wurtman (1985)</a>. This appeared in the Lancet, which is a very good journal. But it’s just a 5-paragraph letter to the editor that points out that aspartame creates phenylalanine without other amino acids, which might do something in the brain—an idea we’ve <a href="https://dynomight.net/diet-coke-nootropic">looked at recently</a>—and gives some anecdotes about people getting seizures. Real studies do not confirm these anecdotes. <a href="https://doi.org/10.1093/ajcn/68.3.531">Wurtman himself</a> did a real study in 1998 that found “Large daily doses of aspartame had no effect on neuropsychologic, neurophysiologic, or behavioral functioning in healthy young adults”. But the Walton report remains discussed to this day. Just a few months ago, Walton published a book called “Double Blind”. I’ll let you judge the credibility for yourself:</p>

  <p><img src="https://dynomight.net/img/aspartame/double-blind.png" alt="Double Blind"></p>

  <p>Since 1996, the FDA doesn’t appear to have published any systematic argument that the current science supports the idea that aspartame is safe. If you look <em>really</em> hard, you can find a few places where the FDA has recently been forced to justify the idea that aspartame is safe. For example, a concerned citizen wrote to the FDA in 2002 and sent this <a href="https://www.regulations.gov/document/FDA-2002-P-0247-0023">response</a> in 2014:</p>

  <p><img src="https://dynomight.net/img/aspartame/FDA-2014-response.svg" alt="FDA 2014 response"></p>

  

</details>



<p>Fortunately, other countries exist. The EFSA has a nice <a href="https://www.efsa.europa.eu/en/topics/topic/aspartame">page</a> that summarizes things this way:</p>

<p><img src="https://dynomight.net/img/aspartame/EFSA-webpage.svg" alt="EFSA webpage"></p>

<p>The bottom of the page has a timeline that clearly presents all past activities, and clearly links to all ongoing studies and reports. (The fact that I’m impressed by such basic things drives home just how low the FDA sets the bar.)</p>

<p>There’s also an <em>extremely</em> nice-263 page <a href="https://www.efsa.europa.eu/en/press/news/131210">risk assessment</a>. This document is the single best (most clear, credible, thorough, and up-to-date) source of information I could find on the safety of aspartame. Here are some quotes from the summary:</p>

<blockquote>
  <p>there was no epidemiological evidence for possible associations of aspartame with various cancers in the human population.</p>
</blockquote>

<blockquote>
  <p>The Panel considered the database on the genotoxicity of methanol and concluded that the data set was limited but that the available reliable <em>in vitro</em> and <em>in vivo</em> data did not indicate a genotoxic potential for methanol.</p>
</blockquote>

<blockquote>
  <p>the calculated [No Observed Adverse Effect Level]s for methanol by oral exposure are 140 and 515-fold higher than the maximum amount of methanol that could be released when aspartame is consumed at the [Acceptable Daily Intake].</p>
</blockquote>

<blockquote>
  <p>the data on reproductive and developmental toxicity did not suggest that there was a risk from methanol derived from aspartame at the current exposure estimates or at the [Acceptable Daily Intake] of 40 mg/kg bw/day.</p>
</blockquote>

<blockquote>
  <p>based on recent measurements of basal levels of formaldehyde in blood and on the modelling of its biological turnover and steady state concentration in cells, formaldehyde formed from aspartame-derived methanol was not of safety concern at the current exposure estimates or at the ADI of 40 mg/kg bw/day.</p>
</blockquote>

<p>It ends this way:</p>

<p><img src="https://dynomight.net/img/aspartame/EFSA-report.svg" alt="EFSA report"></p>

<h3 id="health-canada">Health Canada</h3>

<p>Canada is one of the <a href="https://www.canada.ca/en/health-canada/services/food-nutrition/food-safety/food-additives/sugar-substitutes/aspartame-artificial-sweeteners.html">clearer communicators</a>:</p>

<p><img src="https://dynomight.net/img/aspartame/canada.svg" alt="canada"></p>

<p>Here are their conclusions in a handy table:</p>

<table>
  <thead>
    <tr>
      <th>Allegation</th>
      <th>Conclusion</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>The methanol in aspartame is toxic and is linked to numerous health  problems including lupus and blindness, and also mimics multiple  sclerosis</td>
      <td>Not supported</td>
    </tr>
    <tr>
      <td>Aspartame is especially dangerous for person with diabetes</td>
      <td>Not supported</td>
    </tr>
    <tr>
      <td>Aspartame causes cancer and brain tumours</td>
      <td>Not supported</td>
    </tr>
    <tr>
      <td>Aspartame causes seizures</td>
      <td>Not supported</td>
    </tr>
    <tr>
      <td>Aspartame causes allergic reactions</td>
      <td>Not supported</td>
    </tr>
  </tbody>
</table>

<h3 id="new-zealand-food-safety-authority">New Zealand Food Safety Authority</h3>

<p>From an <a href="https://web.archive.org/web/20081216093929/http://www.nzfsa.govt.nz/consumers/chemicals-nutrients-additives-and-toxins/aspartame/">archived page</a>:</p>

<p><img src="https://dynomight.net/img/aspartame/nz.svg" alt="new zealand"></p>

<h3 id="joint-expert-committee-on-food-additives-jecfa">Joint Expert Committee on Food Additives (JECFA)</h3>

<p>The UN and WHO “jointly” run the JECFA. The only public reports I can find from them are really old, like <a href="https://inchem.org/documents/jecfa/jecmono/v15je03.htm">1980</a>. For what it’s worth, this was the conclusion:</p>

<p><img src="https://dynomight.net/img/aspartame/JECFA.svg" alt="JECFA"></p>

<p>As far as I can tell, this <a href="https://inchem.org/documents/jecfa/jecmono/v16je01.htm">1981</a> update is the last word on aspartame from the JECFA. However, the JECFA currently has aspartame on the <a href="https://www.fao.org/fao-who-codexalimentarius/sh-proxy/fr/?lnk=1&amp;url=https%253A%252F%252Fworkspace.fao.org%252Fsites%252Fcodex%252FCircular%252520Letters%252FCL%2525202021-81%252Fcl21_81e.pdf">priority list of substances proposed for evaluation</a>, as requested by Columbia, Costa Rica, and—somehow—the United States of America. (<em>Update</em>: This report is due to finally come out July 14, 2023. I’ll write about it when it does.)</p>

<h3 id="the-academy-of-nutrition-and-dietetics">The Academy of Nutrition and Dietetics</h3>

<p>This is a <a href="https://en.wikipedia.org/wiki/Academy_of_Nutrition_and_Dietetics">seemingly respectable</a> organization of more than 100 thousand food and nutrition professionals, albeit one funded by food industry lobbying groups. Their <a href="https://doi.org/10.1016/j.jand.2012.03.009">position report</a> states:</p>

<p><img src="https://dynomight.net/img/aspartame/academy.svg" alt="academy"></p>

<h2 id="literature-reviews">Literature reviews</h2>

<p>Again, I don’t think it’s productive to look at individual papers. But we can look at <em>reviews</em> of all the evidence.</p>

<p>Here, some judgment is required. If I type “review aspartame safety” into Google scholar, many of the papers that come up have several of the following features:</p>

<ol>
  <li>Paper is published in an obscure journal</li>
  <li>Authors are from obscure institutions</li>
  <li>Paper only engages with a tiny slice of the literature</li>
  <li>Paper just “doesn’t look right” (e.g. has a serious grammatical error in the title)</li>
</ol>

<p>For full transparency, here are the papers I found less credible for the above reasons, given as hopefully-offense-minimizing numbers: <a href="https://doi.org/10.1007/s10616-013-9681-0">1</a> <a href="https://doi.org/10.3923/pjbs.2018.127.134">2</a> <a href="https://doi.org/10.4103%2F0976-500X.85936">3</a> <a href="https://doi.org/10.1080/1028415X.2017.1288340">4</a> <a href="https://pubmed.ncbi.nlm.nih.gov/29038387/">5</a> <a href="https://www.researchgate.net/profile/Ab-Naik/publication/360642412_Aspartame_Effects_and_Awareness/links/62949ea76886635d5cae8511/Aspartame-Effects-and-Awareness.pdf">6</a> <a href="https://doi.org/10.3390/nu13061957">7</a> <a href="https://doi.org/10.1093/nutrit/nux035">8</a>. Note that many of these <em>do</em> suggest health concerns with aspartame, but I am discounting their conclusions because I don’t think they are credible. If <em>you</em> don’t trust <em>me</em>, you should look at those papers yourself. I have linked (here or below) everything I found that was published after the year 2000 and claimed to be a review of aspartame.</p>

<p><strong>Butchko et al. <a href="https://doi.org/10.1006/rtph.2002.1542"><em>Aspartame: Review of Safety</em></a>. Regulatory Toxicology and Pharmacology, 2002.</strong></p>

<p>Our first is a 93-page monster from a team of 24 scientists (three of whom, note, are employed by The NutraSweet Company). As I write this, it’s been cited 344 times. In their summary, you can feel the frustration:</p>

<p><img src="https://dynomight.net/img/aspartame/butchko-1.svg" alt="butchko 1"></p>

<p>Here’s a table from this paper:</p>

<p><img src="https://dynomight.net/img/aspartame/butchko-2.svg" alt="butchko 2"></p>

<p>This is helpful to put things in perspective. If you drink a Diet Coke, you get 2.6 mg/kg of aspartame, assuming you weight 70 kg. That’s around 20 times less than the government recommended limits. It’s also around <em>1000 times</em> less than doses that do not show harms in animals.</p>

<p><strong>Magnuson et al. <a href="https://doi.org/10.1080/10408440701516184"><em>Aspartame: A Safety Evaluation Based on Current Use Levels, Regulations, and Toxicological and Epidemiological Studies</em></a>. Critical Reviews in Toxicology, 2007.</strong></p>

<p>This is a 99-page paper that’s been cited 430 times so far. The conclusions are kind of feisty.</p>

<p><img src="https://dynomight.net/img/aspartame/magnuson.svg" alt="magnuson"></p>

<details>
  <summary>Note that this study was funded by Ajinomoto via some kind of blind-trust arrangement.</summary>

  <p>The paper describes it this way:</p>

  <p><img src="https://dynomight.net/img/aspartame/magnuson-sponsor.svg" alt="magnuson sponsor"></p>

  <p>I still mostly trust this paper, but <a href="https://dynomight.net/alcohol-trial/">we all know how these things can go</a>.</p>

</details>

<p><strong>Rogers et al. <a href="https://doi.org/10.1038/ijo.2015.177"><em>Does low-energy  sweetener consumption affect energy intake and body weight? A systematic review, including meta-analyses, of the evidence from human and animal studies</em></a>. International Journal of Obesity, 2016.</strong></p>

<p>This paper has 320 citations and 11 authors (four of whom—sigh—have gotten grants from or worked at sweetener companies). It focuses on metabolism and weight. Here is their conclusion, where LES = Low-Energy Sweeteners, EI = Energy Intake, and BW = Body Weight.</p>

<p><img src="https://dynomight.net/img/aspartame/rogers-1.svg" alt="rogers 1"></p>

<p><img src="https://dynomight.net/img/aspartame/rogers-2.svg" alt="rogers 2"></p>

<h3 id="other-reviews">Other reviews</h3>

<p>There are many other reviews that seem scientifically solid, but aren’t as comprehensive as those above. Here’s a representative snippet from each:</p>

<table>
  <thead>
    <tr>
      <th>paper</th>
      <th>snippet</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://doi.org/10.1111/j.1541-4337.2006.tb00081.x">Kroger et al. (2006)</a></td>
      <td>“within the range of variation caused by day-to-day differences in food intake and are clearly not harmful”</td>
    </tr>
    <tr>
      <td><a href="https://doi.org/10.1016/j.fct.2013.07.040">Marinovich et al. (2009)</a></td>
      <td>“not consistently related to vascular events and preterm deliveries.”</td>
    </tr>
    <tr>
      <td><a href="https://doi.org/10.1080/19338244.2013.828674">Mallikarjun and Sieburth (2013)</a></td>
      <td>“suggest that [aspartame] consumption has no significant carcinogenic effect in rodents.”</td>
    </tr>
    <tr>
      <td><a href="https://doi.org/10.1080/10408398.2017.1304358">Santos et al. (2018)</a></td>
      <td>“no found deleterious effects associated with aspartame consumption on variables studied”</td>
    </tr>
    <tr>
      <td><a href="https://doi.org/10.1016/j.yrtph.2018.01.009">Haighton et al. (2018)</a></td>
      <td>“a conclusion that aspartame is not carcinogenic is supported”</td>
    </tr>
    <tr>
      <td><a href="https://doi.org/10.1016/j.yrtph.2019.01.033">Haighton et al. (2019)</a></td>
      <td>“do not support that [low calories sweeteners and] aspartame, are associated with an increased risk of cancer in humans.”</td>
    </tr>
    <tr>
      <td><a href="https://doi.org/10.1001/jamanetworkopen.2022.2092">McGlynn et al. (2022)</a></td>
      <td>“small improvements in body weight and cardiometabolic risk factors without evidence of harm”</td>
    </tr>
  </tbody>
</table>

<h2 id="why-write-this">Why write this?</h2>

<p>I write all this with some trepidation, as my <a href="https://dynomight.net/cola/#ps">previous</a> <a href="https://dynomight.net/thanks/">mentions</a> of aspartame caused a surprising amount of rancor.</p>

<p>But whatever, I’ll die on this hill: After aspartame is consumed, it immediately breaks down into three naturally occurring chemicals. Even large amounts of aspartame cause smaller fluctuations in those chemicals than normal food. The current science says that the health impact of aspartame is essentially zero. Every credible body that has studied this question has reached the same conclusion.</p>

<p>Is it possible that some harms have been missed? Of course! That’s how science works: Evidence accumulates slowly. It never becomes a <em>sure thing</em>, we just eventually decide it’s sure <em>enough</em> and move on with our lives.</p>

<p>So why are we still talking about aspartame? Why worry about it rather than, say, <em>sugar</em> or <em>alcohol</em>? I know many people who avoid diet soda but drink sugar-sweetened soda or large amounts of alcohol. That’s choosing a known harm over something that appears harmless.</p>

<p>Or, why not worry about:</p>

<ul>
  <li><a href="https://www.weather.gov/safety/lightning-odds">Lightning</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Cotton_swab#Medical_risks">Q-tips</a></li>
  <li><a href="https://dynomight.net/air/#things-that-create-particles-indoors">Fireplaces</a></li>
  <li><a href="https://doi.org/10.1097/PAF.0b013e31828d68c7">Bathtubs</a></li>
  <li><a href="https://www.cdc.gov/pictureofamerica/pdfs/Picture_of_America_Poisoning.pdf">Generators</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Lawn_mower#Safety_issues">Lawn mowers</a></li>
  <li><a href="https://www.bbc.com/news/world-us-canada-48360832">Umbrellas</a></li>
  <li><a href="https://wwwnc.cdc.gov/travel/yellowbook/2020/travel-by-air-land-sea/cruise-ship-travel">Cruise ships</a></li>
  <li><a href="https://dynomight.net/air/#particles-while-commuting">Air in subways</a></li>
  <li><a href="https://doi.org/10.1371/journal.pmed.0040290">Blood clots in planes</a></li>
  <li><a href="https://www.cdc.gov/nceh/radiation/air_travel.html">Cosmic rays in planes</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Heterocyclic_amine_formation_in_meat">Charred meat</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Anticholinergic#Side_effects">Anticholinergics</a></li>
  <li><a href="https://doi.org/10.1093/fqsafe/fyy025">Cocoa</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Perfluorooctanoic_acid#Health_concerns">Perfluorooctanoic acid</a></li>
  <li><a href="https://doi.org/10.1128/CMR.00011-10">Helicobacter pylori</a></li>
</ul>

<p>All of these present some real danger but mostly no one cares.</p>

<p>To me, most skepticism of aspartame looks like an <a href="https://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/">isolated demand for rigor</a>—an impossibly high standard of evidence that isn’t applied to other things. We all have finite bandwidth for things to worry about, and the evidence places aspartame very low on the list of sensible worries.</p>

<p>Many of the same people who claim aspartame is risky exhort to Follow the Science in other domains. I wonder: What evidence would be convincing proof of aspartame’s safety, but doesn’t already exist? Is it even possible? If not, then OK! But if you only follow the science when the conclusions are intuitive, it’s not science that chooses your destination.</p>

  


  

  

  
  
  
  

</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It's 2023 and memory overwrite bugs are not just a thing theyre still number one (109 pts)]]></title>
            <link>https://www.theregister.com/2023/06/29/cwe_top_25_2023/</link>
            <guid>36562727</guid>
            <pubDate>Sun, 02 Jul 2023 16:01:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/06/29/cwe_top_25_2023/">https://www.theregister.com/2023/06/29/cwe_top_25_2023/</a>, See on <a href="https://news.ycombinator.com/item?id=36562727">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>The most dangerous type of software bug is the out-of-bounds write, according to MITRE this week. This type of flaw is responsible for 70 CVE-tagged holes in the US government's list of known vulnerabilities that are under active attack and need to be patched, we note.</p>
<p>Out-of-bounds write, sometimes labeled <a target="_blank" rel="nofollow" href="https://cwe.mitre.org/data/definitions/787.html">CWE-787</a>, also took the top spot in 2022, showing a distinct lack of improvement.</p>
<p>An out-of-bounds write happens when software (and sometimes hardware) alters memory it's not supposed to, such as by writing data to a memory buffer and overshooting the end of that buffer, causing it to unexpectedly change other variables and information and/or just crash. That kind of bug can be triggered accidentally through normal operation, or it can be triggered deliberately by exploit code.</p>

    

<p>Typically, exploit code will induce an out-of-bounds write to alter data structures so that the flow of execution is hijacked and diverted in a way the attacker chooses, allowing them to take control of the software, be it an application, a remote service, or part of an operating system. Ideally, software should be written to prevent this kind of overwrite, and using memory-safe languages like Rust <a target="_blank" href="https://www.theregister.com/2022/11/11/nsa_urges_orgs_to_use/">can help here</a>.</p>

        


        

<p>Number two on MITRE's list is the less complex but still annoying cross-site scripting bug (<a target="_blank" rel="nofollow" href="https://cwe.mitre.org/data/definitions/79.html">CWE-79</a>), which was key in four CVEs in the known exploited vulnerabilities <a target="_blank" rel="nofollow" href="https://www.cisa.gov/known-exploited-vulnerabilities-catalog">catalog</a> maintained by Uncle Sam's CISA. This bug type is a fancy form of a failure to sanitize user input.</p>
<p>Number three — SQL injection flaws (<a target="_blank" rel="nofollow" href="https://cwe.mitre.org/data/definitions/89.html">CWE-89</a>) — account for four known exploited bugs in the CISA catalog. Again, another form of input sanitization failure. Clean and neutralize your inputs, people. You can't assume all your users are nice.</p>

        

<p>MITRE compiles the annual <a target="_blank" rel="nofollow" href="https://cwe.mitre.org/top25/archive/2023/2023_top25_list.html">CWE Top 25 list</a> by analyzing public vulnerability data in America's <a target="_blank" rel="nofollow" href="https://nvd.nist.gov/">National Vulnerability Database</a>. This year's list is based on 43,996 CVE records for vulnerabilities in 2021 and 2022, and was issued in hand with US Homeland Security and CISA.</p>
<p>"These weaknesses lead to serious vulnerabilities in software," the cybersecurity agency <a target="_blank" rel="nofollow" href="https://www.cisa.gov/news-events/alerts/2023/06/29/2023-cwe-top-25-most-dangerous-software-weaknesses">warned</a> today. "An attacker can often exploit these vulnerabilities to take control of an affected system, steal data, or prevent applications from working."&nbsp;</p>
<p>In fact, the top three most dangerous software weaknesses for 2023 were also the most dangerous, and in the same order, in the 2022 list. Progress is slow, it seems.</p>
<div>
<h3>Time to get patching</h3>

<p>Also today, CISA added eight more flaws to its <a target="_blank" rel="nofollow" href="https://www.cisa.gov/known-exploited-vulnerabilities-catalog">Known Exploited Vulnerabilities Catalog</a>. These affect D-Link and Samsung devices and they are tracked as:</p>

<ul>
<li>CVSS 9.8 — <a target="_blank" rel="nofollow" href="https://nvd.nist.gov/vuln/detail/CVE-2023-25717">CVE-2019-17621</a> D-Link DIR-859 router contains a command execution vulnerability.</li>

<li>CVSS 7.8 — <a target="_blank" rel="nofollow" href="https://nvd.nist.gov/vuln/detail/CVE-2019-20500">CVE-2019-20500</a> D-Link DWL-2600AP access points are vulnerable to command injection attacks.</li>

<li>CVSS 7.8 — <a target="_blank" rel="nofollow" href="https://nvd.nist.gov/vuln/detail/CVE-2021-25487">CVE-2021-25487</a> Samsung mobile devices are vulnerable to out-of-bounds read.&nbsp;</li>

<li>CVSS 5.5 — <a target="_blank" rel="nofollow" href="https://nvd.nist.gov/vuln/detail/CVE-2021-25489">CVE-2021-25489</a> Samsung mobile devices contain an improper input validation flaw.</li>

<li>CVSS 6.4 — <a target="_blank" rel="nofollow" href="https://nvd.nist.gov/vuln/detail/CVE-2021-25394">CVE-2021-25394</a> Samsung mobile devices are susceptible to a race condition vulnerability.</li>

<li>CVSS 9.0 — <a target="_blank" rel="nofollow" href="https://nvd.nist.gov/vuln/detail/CVE-2016-3427">CVE-2021-25395</a> another race condition bug in Samsung mobile devices, but this one's critical.&nbsp;</li>

<li>CVSS 6.7 — <a target="_blank" rel="nofollow" href="https://nvd.nist.gov/vuln/detail/CVE-2021-25371">CVE-2021-25371</a> an unspecified flaw in Samsung mobile devices.</li>

<li>CVSS 6.7 — <a target="_blank" rel="nofollow" href="https://nvd.nist.gov/vuln/detail/CVE-2021-25372">CVE-2021-25372</a> Samsung mobile devices contain an improper boundary check vulnerability.</li>
</ul>
</div>
<p>Number four, however, was one of the "biggest movers" on the list, jumping from the seventh spot last year to the fourth-ranked most dangerous issue this year. It's <a target="_blank" rel="nofollow" href="https://cwe.mitre.org/data/definitions/416.html">CWE-416</a>, or use-after-free. This type of exploitable bug is when a program, remote service, or operating system component releases memory that's no longer needed, and then continues to use it anyway. At that point, it's relying on memory that could be, say, manipulated by some other code, and can lead to crashes or hijacking of execution.</p>
<p>Again, memory-safe languages are useful here as they abstract away this fiddly memory management, or ensure insecure memory use is blocked.</p>

        

<p>Some of the other biggest movers up the list, according to MITRE, include <a target="_blank" rel="nofollow" href="https://cwe.mitre.org/data/definitions/862.html">CWE-862</a>, which covers missing authorization bugs. This weakness jumped from sixteenth position last year to number 11 in 2023.&nbsp;&nbsp;</p>
<p>Additionally, <a target="_blank" rel="nofollow" href="https://cwe.mitre.org/data/definitions/269.html">CWE-269</a> (improper privilege management) moved up seven places to 22 on the list, and <a target="_blank" rel="nofollow" href="https://cwe.mitre.org/data/definitions/863.html">CWE-863</a> (incorrect authorization) went from rose four ranks to number 24.</p>
<ul>

<li><a href="https://www.theregister.com/2023/06/21/vmware_bug_under_exploit/">A (cautionary) tale of two patched bugs, both exploited in the wild</a></li>

<li><a href="https://www.theregister.com/2023/06/21/apple_patches_triangledb_spyware/">Apple squashes kernel bug used by TriangleDB spyware</a></li>

<li><a href="https://www.theregister.com/2023/06/16/third_moveit_bug_fixed/">Third MOVEit bug fixed a day after PoC exploit made public</a></li>

<li><a href="https://www.theregister.com/2023/06/13/june_patch_tuesday_vmware_vuln/">June Patch Tuesday: VMware vuln under attack by Chinese spies, Microsoft kinda meh</a></li>
</ul>
<p>There's also a couple new entries to this year's list: <a target="_blank" rel="nofollow" href="https://cwe.mitre.org/data/definitions/269.html">CWE-269</a> (improper privilege management), in 22nd place, and <a target="_blank" rel="nofollow" href="https://cwe.mitre.org/data/definitions/863.html">CWE-863</a> (incorrect authorization) as a newcomer in 24th.</p>
<p>"CWEs are becoming more and more prevalent in vulnerability exposure conversations as the community looks to avoid the root causes that can become vulnerabilities," according to <a target="_blank" rel="nofollow" href="https://cwe.mitre.org/top25/index.html">MITRE</a>.&nbsp;</p>
<p>To this end, the nonprofit will publish a series of reports over the next few months that aim to help organizations "more effectively" use the Top 25 list. These will cover a range of topics including weaknesses that didn't quite make the Top 25 —&nbsp;but orgs should still be aware of them.&nbsp;</p>
<p>It will also publish a report on trends in CWEs over the last four years, and a report on actively exploited weaknesses based on CISA's catalog.&nbsp; ®</p>                                


                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stanford A.I. Courses (425 pts)]]></title>
            <link>https://ai.stanford.edu/courses/</link>
            <guid>36562502</guid>
            <pubDate>Sun, 02 Jul 2023 15:40:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.stanford.edu/courses/">https://ai.stanford.edu/courses/</a>, See on <a href="https://news.ycombinator.com/item?id=36562502">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							
							<p><label>Sort by: </label>
							</p>
							
						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A toy programming language in 137 lines of Python code (108 pts)]]></title>
            <link>https://blog.miguelgrinberg.com/post/building-a-toy-programming-language-in-python</link>
            <guid>36562432</guid>
            <pubDate>Sun, 02 Jul 2023 15:36:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.miguelgrinberg.com/post/building-a-toy-programming-language-in-python">https://blog.miguelgrinberg.com/post/building-a-toy-programming-language-in-python</a>, See on <a href="https://news.ycombinator.com/item?id=36562432">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I thought it would be fun to go outside of my comfort zone of web development topics and write about something completely different and new, something I have never written about before. So today, I'm going to show you how to implement a programming language!</p>
<p>The project will parse and execute programs written in a simple language I called <code>my</code> (I know it's a lame name, but hey, it is "my" language). The implementation is going to be in Python, without any external dependencies. The <code>my</code> language is simple enough to make this project reasonably short, but also complex enough to make it interesting. If you are only interested in the complete code, you can find it in <a href="https://github.com/miguelgrinberg/mylang">this GitHub repository</a>. If you want to learn, then read on!</p>
<p>In this first installment of this series, I'll show you how to build a very basic programming language that implements a print statement. Then in the <a href="https://blog.miguelgrinberg.com/post/building-a-toy-programming-language-in-python-part-2">second part</a> I'll extend the language to support variables and mathematical expressions. The end goal is a programming language implementation that can execute programs such as this one:</p>
<pre><code>a = 3
b = 4 + a * 2
print b + 1
</code></pre>
<p>Once you learn the techniques involved in bringing <code>my</code> to life, you will be able to extend the language in any way you like and make it yours too. Sounds interesting? Let's get started!</p>
<h2>The Components of a Programming Language</h2>
<p>It is not the point of this article to bore you with a discussion of compiler theory, but at the same time I feel it is important to begin with a basic idea of the project structure. It is certainly possible to start coding away and figure things out intuitively as you go, but given that this is a topic that has been well studied it does not make sense to ignore all the research and knowledge that is available.</p>
<p>So, in very general terms, a programming language implementation is composed of the following phases:</p>
<ul>
<li>Lexical analysis, where the program's source code is read and divided up into individual units called <em>tokens</em>.</li>
<li>Syntax analysis, where the sequence of tokens provided by the lexical analyzer (or <em>lexer</em>) is checked against the grammar of the language. The module that performs this task is called the <em>parser</em>.</li>
<li>Code generation, where an intermediate code is generated as a lower-level representation of the sequence of tokens parsed from the source file. The module that performs this task is sometimes called the <em>compiler</em>, though this term is often used to refer to this and the previous two phases combined.</li>
<li>Execution, where the intermediate code produced by the compiler is read and executed. The module that performs this task is called the <em>interpreter</em>.</li>
</ul>
<p>Some languages have a more complex structure, which for example includes one or more code optimization phases after the compiler phase, leading to more efficient code. Others have simplifications, such as having a single phase that merges code generation and execution together, which means that code is executed on the fly as it is parsed.</p>
<p>Regardless of the exact structure of a language implementation, the important point to remember is that using a well defined structure based on the above phases will help keep the complexity of the project under control.</p>
<h2>The "My" Programming Language, Version 0.1</h2>
<p>If you are familiar with my tutorials, you know that I like to build projects in small steps. For that reason, the first version of the <code>my</code> language is going to be extremely simple, with just a <code>print</code> statement that prints numbers. Here is an example program written in the first version of <code>my</code>:</p>
<pre><code>print 1
print 52
</code></pre>
<p>The <code>print</code> keyword is a reserved word of the language. Numbers in this language are integers. When this program is executed, the expected output should be:</p>
<pre><code>1
52
</code></pre>
<p>The documentation that describes the syntax of a language is called the language <em>grammar</em>. This is very important to have, as it serves as a reference when implementing the language. The grammar for this first version of the <code>my</code> language is:</p>
<pre><code>&lt;program&gt; = &lt;statement&gt; [ &lt;statement&gt; ... ]
&lt;statement&gt; = &lt;print_statement&gt; "\n"
&lt;print_statement&gt; = "print" &lt;expression&gt;
&lt;expression&gt; = number
</code></pre>
<p>To make sense of this notation you can start from top to bottom. The first rule says that a program in this language is defined  as a statement optionally followed by more statements.</p>
<p>In the second rule, a statement is defined as a print statement, followed by an end of line. The third rule states that a print statement must have the literal word "print" followed by an expression. The fourth and final rule defines an expression as a number. Remember that this is a first attempt, expressions will later be expanded.</p>
<p>The <code>"\n"</code>, <code>"print"</code> and <code>number</code> elements used in this grammar are terminal symbols, or <em>tokens</em>. These do not require grammar rules because they are tokens directly produced by the lexer. The remaining symbols, which are shown enclosed in <code>&lt;</code> and <code>&gt;</code>, are defined in terms of other symbols or tokens.</p>
<h2>The Lexer</h2>
<p>The function of the lexical analyzer (or lexer) is to read the source code of the language and produce a sequence of tokens. In this section I'll show you how to build a lexer for the <code>my</code> language.</p>
<p>Consider once again the example <code>my</code> program:</p>
<pre><code>print 1
print 52
</code></pre>
<p>With this input, the lexer should produce the following list of tokens:</p>
<ul>
<li><code>"print"</code></li>
<li><code>"number"</code>, 1</li>
<li><code>"\n"</code></li>
<li><code>"print"</code></li>
<li><code>"number"</code>, 52</li>
<li><code>"\n"</code></li>
</ul>
<p>The <code>My</code> class shown below accepts the source code of a <code>my</code> program as a string, and in accordance with the grammar I shared above. Its <code>tokens()</code> method returns an iterator that produces tokens from this code.</p>
<pre><code>class My:
    def __init__(self, code):
        self.code = code
        self.line_nr = 0

    def raise_error(self, message):
        raise ValueError(f'{self.line_nr}: {message}')

    def tokens(self):
        for line in self.code.strip().split('\n'):
            self.line_nr += 1
            for token in line.strip().split(' '):
                if token == 'print':
                    yield (token,)
                elif token.isnumeric():
                    yield ('number', int(token))
                else:
                    self.raise_error(f'Syntax Error: Invalid token {token}')
            yield ('\n',)
</code></pre>
<p>Copy the above code to a file named <em>my.py</em>. Before I explain some the interesting details in this implementation, let's give this lexer a try. Try the following in a Python prompt:</p>
<pre><code>&gt;&gt;&gt; from my import My
&gt;&gt;&gt; p = My('''print 1
... print 52
... ''')
&gt;&gt;&gt; list(p.tokens())
[('print',), ('number', 1), ('\n',), ('print',), ('number', 52), ('\n',)]
</code></pre>
<p>This is pretty cool, right? Each token is returned as a tuple. For the <code>"print"</code> and <code>"\n"</code> tokens, the tuples have a single element with the token itself. For the <code>number</code> token, a second element is added with the actual value of the number.</p>
<p>The <code>tokens()</code> method is built as a <a href="https://docs.python.org/3/glossary.html#term-generator">generator</a>, a special kind of Python function that returns an iterator. The elements returned by the iterator are produced with the <code>yield</code> keyword, inside the body of the function. You can see that the method splits the source code into lines and iterates over them, then for each line it splits on the spaces. Inside this double for-loop, each part is checked to see if it matches the <code>"print"</code> or <code>number</code> tokens. The <code>"\n"</code> token is treated as a special case because it is only valid at the end of the line, so it is added automatically after each outer loop iteration.</p>
<p>What happens when a token does not match the <code>"print"</code> or <code>number</code> tokens defined in the language grammar? That is an error, so for that case the <code>raise_error()</code> method is called. This method raises a <code>ValueError</code> exception with an the error message, which would be the equivalent to having a syntax error reported in a Python script. Here is another console example where an error is raised due to an invalid token:</p>
<pre><code>&gt;&gt;&gt; p = My('''print 1
... print "foo"
... ''')
&gt;&gt;&gt; list(p.tokens())
Traceback (most recent call last):
...
ValueError: 2: Syntax Error: Invalid token "foo"
</code></pre>
<p>Notice the <code>2:</code> in the error message. This is the line number of the error! The <code>line_nr</code> attribute of the <code>My</code> class counts the line as they are being analyzed, and this makes it possible to report a line number when an error occurs. A more sophisticated lexer could also keep track of column numbers and accurately show the position of the error within the line as well.</p>
<p>Because the <code>tokens()</code> method returns an iterable, it can be printed by transforming it to a list, as I did in the Python prompt examples shown above. Another way to use this method that is more practical for a language parser is to use it along with the <code>next()</code> function from Python. Here is how that works, still in the Python console:</p>
<pre><code>&gt;&gt;&gt; p = My('''print 1
... print 52
... ''')
&gt;&gt;&gt; token_feed = p.tokens()
&gt;&gt;&gt; next(token_feed)
('print',)
&gt;&gt;&gt; next(token_feed)
('number', 1)
&gt;&gt;&gt; next(token_feed)
('\n',)
&gt;&gt;&gt; next(token_feed)
('print',)
&gt;&gt;&gt; next(token_feed)
('number', 52)
&gt;&gt;&gt; next(token_feed)
('\n',)
&gt;&gt;&gt; next(token_feed)
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
StopIteration
</code></pre>
<p>Here the <code>token_feed</code> variable is assigned the iterator returned by the <code>tokens()</code> method. Then each time the <code>next()</code> function is called with this iterator as an argument, another token is returned. When all the tokens have been returned, the <code>StopIteration</code> exception is raised. This is going to be the basis of how the parser will communicate with the lexer to ask for tokens. The <code>next_token()</code> method of the <code>My</code> class, shown below, will be used for this task:</p>
<pre><code>class My:
    def __init__(self, code):
        self.code = code
        self.line_nr = 0
        self.token_feed = self.tokens()

    # ...

    def next_token(self):
        try:
            token = next(self.token_feed)
        except StopIteration:
            token = None
        return token
</code></pre>
<p>In the constructor, the <code>token_feed</code> attribute is initialized with the token iterator. The <code>next_token()</code> method then returns tokens from this iterator one by one. When the end of the token stream is reached, the method catches the <code>StopIteration</code> exception and returns <code>None</code> instead, which the parser will interpret as having reached the end of the code.</p>
<p>To evaluate if the token stream matches a certain rule, it is often useful for the parser to "look ahead" for the next token, before it is certain if the rule under consideration is a match or not. The <code>next_token()</code> method shown above returns the next token, but at the same time it consumes it, meaning that once a token has been returned it has to be used or else it is lost. What would be most useful is if the parser could change its mind with regards to a token and return it to the stream, so that then another rule in the parser can get it when it calls <code>next_token()</code>.</p>
<p>The idea of being able to take the next token and optionally returning it to the stream is implemented below in the <code>return_token()</code> method:</p>
<pre><code>class My:
    def __init__(self, code):
        self.code = code
        self.line_nr = 0
        self.token_feed = self.tokens()
        self.returned_token = None

    # ...

    def next_token(self):
        if self.returned_token:
            token = self.returned_token
            self.returned_token = None
        else:
            try:
                token = next(self.token_feed)
            except StopIteration:
                token = None
        return token

    def return_token(self, token):
        if self.returned_token is not None:
            raise RuntimeError('Cannot return more than one token at a time')
        self.returned_token = token
</code></pre>
<p>In this version of the <code>My</code> class, a <code>returned_token</code> attribute is initialized to <code>None</code>. If a token provided by <code>next_token()</code> cannot be used, the parser can give it back with a call to <code>return_token()</code>, so that the same token is returned the next time <code>next_token()</code> is called. This creates a complication, because there is no easy way to return an item to an iterator. My implementation puts the returned token in the new <code>returned_token</code> attribute. The <code>next_time()</code> implementation is now expanded to return this token instead of the next one from the iterator. With this little trick the parser can retrieve a token, do some work with it and then change its mind and return it. One side effect of this implementation is that it is only possible to return one token, so a <code>RuntimeError</code> is raised if two tokens are returned in a row.</p>
<p>Save the above changes to the <em>my.py</em> file, and then start a new Python session to play with the new token methods:</p>
<pre><code>&gt;&gt;&gt; from my import My
&gt;&gt;&gt; p = My('''print 1
... print 52
... ''')
&gt;&gt;&gt; p.next_token()
('print',)
&gt;&gt;&gt; p.next_token()
('number', 1)
&gt;&gt;&gt; p.return_token(('number', 1))
&gt;&gt;&gt; p.next_token()
('number', 1)
&gt;&gt;&gt; p.next_token()
('\n',)
</code></pre>
<p>Hopefully this example clarifies how the parser is going to manage the token stream.</p>
<h2>The Parser</h2>
<p>The task of the parser is to match the sequence of tokens to the language grammar. For each rule in the grammar, there is going to be a method that determines if the token stream matches the rule or not.</p>
<p>Here is the first rule in the language grammar:</p>
<pre><code>&lt;program&gt; = &lt;statement&gt; [ &lt;statement&gt; ... ]
</code></pre>
<p>As a naming convention, I'm going to use the rule names in the parsing methods. The rule is named <code>&lt;program&gt;</code>, so I'm going to call the method that parses it <code>parse_program()</code>. Another convention is that all the methods that parse rules will return <code>True</code> if they were able to match the rule to the incoming tokens, or <code>False</code> if not. A return of <code>False</code> would tell the caller that this rule isn't present in the stream.</p>
<p>The <code>&lt;program&gt;</code> rule is a high-level rule that is defined in terms of other rules, and while this may appear to complicate things, in fact it is all the contrary, because any references to other rules are addressed by calling the methods of the other rules.</p>
<p>I think the best way to understand what I mean here is to look at the definition of the <code>parse_program()</code> method:</p>
<pre><code>class My:
    # ...

    def parse_program(self):
        if not self.parse_statement():
            self.raise_error('Expected: statement')
        token = self.next_token()
        while token is not None:
            self.return_token(token)
            if not self.parse_statement():
               self.raise_error('Expected: statement')
            token = self.next_token()
        return True
</code></pre>
<p>The <code>&lt;program&gt;</code> rule says that the very first thing to look for is something that matches the <code>&lt;statement&gt;</code> rule. This is implemented by calling a <code>parse_statement()</code> method (which does not exist yet). Like all the methods that implement the parsing of a rule, the return value of the call indicates if the parsing was successful or not. When parsing the <code>&lt;program&gt;</code> rule, a failure to parse a first statement indicates that the program is incorrect, as there are no alternative rules that can be considered instead. For that reason, if the initial statement cannot be parsed, that is considered an error that halts the parsing.</p>
<p>After the first statement, a <code>&lt;program&gt;</code> rule allows one or more optional statements, until the end of the program is reached. This means that after parsing the first statement, the parser for <code>&lt;program&gt;</code> needs to consider one of two possible paths, both valid:</p>
<ol>
<li>There is another statement in the token stream</li>
<li>There are no more tokens, meaning that the end of the program was reached</li>
</ol>
<p>To decide which of the two paths is the one that matches the input stream of tokens, the next token is obtained. If this token is not <code>None</code>, that means that there are more statements in the program. In that case, the token is returned to the stream and another call to <code>parse_statement()</code> is made to parse the next statement. Returning the token to the stream is important, because this token needs to be available to the <code>parse_statement()</code> method.</p>
<p>When the end of the program is reached, the next token is going to be <code>None</code>, and this will cause the while-loop to exit. At this point the program has been completely parsed!</p>
<p>But of course, the parser is still incomplete, as there are three more rules that need to be implemented. Let's look at the second rule:</p>
<pre><code>&lt;statement&gt; = &lt;print_statement&gt; "\n"
</code></pre>
<p>Here is the <code>parse_statement()</code> method that implements this rule:</p>
<pre><code>class My:
    # ...

    def parse_statement(self):
        if not self.parse_print_statement():
            self.raise_error('Expected: print statement')
        token = self.next_token()
        if token[0] != '\n':
            self.raise_error('Expected: end of line')
        return True
</code></pre>
<p>This actually makes sense, right? A statement is composed of a print statement followed by an end-of-line token. If either of them aren't present, then errors are reported. To check for the <code>&lt;print_statement&gt;</code> rule, a call to the <code>parse_print_statement()</code> is made. The check for the end-of-line token does not require any method calls because it can be done with a simple comparison.</p>
<p>There are two rules left to implement:</p>
<pre><code>&lt;print_statement&gt; = "print" &lt;expression&gt;
&lt;expression&gt; = number
</code></pre>
<p>Here are the corresponding parsing methods:</p>
<pre><code>class My:
    # ...

    def parse_print_statement(self):
        token = self.next_token()
        if token[0] != 'print':
            self.return_token(token)
            return False
        if not self.parse_expression():
            self.raise_error('Expected: expression')
        return True

    def parse_expression(self):
        token = self.next_token()
        if token[0] != 'number':
            self.return_token(token)
            return False
        return True
</code></pre>
<p>A difference in these two parsing methods is that when they don't recognize the first token they put the token back on the stream and then return <code>False</code>, whereas the previous two rules raised errors. When a rule returns <code>False</code>, it is giving the parent rule the option to attempt to call other rules before giving up with an error. This is a sensible thing to do in lower level rules, because they do not have the context to know if there are other alternatives that the parent rule can explore.</p>
<p>It may sound hard to believe, but this is all there is to the parser module of the <code>my</code> language. To tie the collection of rules together, let's add a <code>run()</code> method that runs the program through the parser:</p>
<pre><code>class My:
    # ...

    def run(self):
        try:
            return self.parse_program()
        except ValueError as exc:
            print(str(exc))
            return False
</code></pre>
<p>This method catches the <code>ValueError</code> exception that is raised for various error conditions when the <code>raise_error()</code> method is invoked. When an error occurs, the error message is printed, and then the <code>run()</code> method returns <code>False</code>, to indicate that the program failed.</p>
<p>You can try parsing some simple programs in the Python prompt:</p>
<pre><code>&gt;&gt;&gt; from my import My
&gt;&gt;&gt; p = My('''print 1
... print 52
... ''')
&gt;&gt;&gt; p.run()
True
</code></pre>
<p>This returns a simple <code>True</code>, but that means a lot. It means that all the tokens found in this program were found to comply with the rules of the grammar of the language. Let's try some invalid programs to see how the output changes:</p>
<pre><code>&gt;&gt;&gt; p = My('''print 1
... print
... ''')
&gt;&gt;&gt; p.run()
2: Expected: expression
False
</code></pre>
<p>In this example, I have omitted the argument to <code>print</code> in line 2. The error reports this mistake, and the top-level <code>run()</code> method returns <code>False</code>, to indicate that the program did not parse.</p>
<p>Let's try another one:</p>
<pre><code>&gt;&gt;&gt; p = My('''print 1 2
... ''')
&gt;&gt;&gt; p.run()
1: Expected: end of line
False
</code></pre>
<p>For this second error, I added an extra number at the end of the print statement in line 1, and the parser indicates that an end-of-line was expected there. Fantastic!</p>
<h2>The Interpreter</h2>
<p>The parser for the first version of the language is now complete, so now it is time to evaluate the options for the remaining work:</p>
<ul>
<li>One option is to define a set of low-level coding instructions and then add code generation of these instructions to the parsing methods. Then separately from that, build an interpreter the runs these instructions.</li>
<li>A second option is to directly implement the code execution logic within the parsing methods, without generating intermediate instructions.</li>
</ul>
<p>To keep things simple, I'm going to go with the second option, which is a good option for smaller languages.</p>
<p>In terms of implementing the program execution for this language, the secret technique that makes it possible is the <a href="https://en.wikipedia.org/wiki/Stack_(abstract_data_type)">stack</a>. A stack is a primitive data structure that supports two main operations, <em>push</em> and <em>pop</em>, to add and remove elements respectively. The interesting aspect is that elements are removed in reverse order to how they were added, which is the same as saying that the last element in is the first element out (LIFO). The stack is at the core of pretty much all execution environments for programming languages.</p>
<p>Here is a very simple execution stack implementation for the <code>my</code> language:</p>
<pre><code>class My:
    def __init__(self, code):
        self.code = code
        self.line_nr = 0
        self.token_feed = self.tokens()
        self.returned_token = None
        self.stack = []

    # ...

    def stack_push(self, arg):
        self.stack.append(arg)

    def stack_pop(self):
        return self.stack.pop()
</code></pre>
<p>How is the stack used? It's simple. Rules such as <code>&lt;expression&gt;</code>, which have a resulting value after they are parsed, push this result to the stack. Rules such as <code>&lt;print_statement&gt;</code>, which consume a value, pop a value from the stack. Let's implement the stack in these two rules:</p>
<pre><code>class My:
    # ...

    def parse_print_statement(self):
        token = self.next_token()
        if token != ('print',):
            self.return_token(token)
            return False
        if not self.parse_expression():
            self.raise_error('Expected expression')

        value = self.stack_pop()
        print(value)
        return True

    def parse_expression(self):
        token = self.next_token()
        if token[0] != 'number':
            self.return_token(token)
            return False

        self.stack_push(token[1])
        return True

    # ...
</code></pre>
<p>After a successful parse of the <code>&lt;expression&gt;</code> rule, and before returning <code>True</code>, the value associated with the expression is pushed to the stack. For the simplistic expressions in the current version of the language, the number to push is given as the second value in the <code>number</code> token tuple.</p>
<p>The <code>&lt;print_statement&gt;</code> rule, which needs a value to print, pops a value from the stack and prints it. This is all it takes to execute the print statement!</p>
<p>In case you are wondering, the LIFO property of the stack prevents values from different statements from ever getting mixed up. Even with complicated mathematical expressions, the stack is able to maintain the running state of the application, with every expression being consumed by the proper owner.</p>
<h2>Running Programs Stored on Files</h2>
<p>The <code>my</code> language is somewhat useless as it can only print numbers, but it is a very good base to continue building from. Before I end this first part, it would be convenient to make the <code>my</code> language work with programs stored in files on disk. This can be implemented at the bottom of <em>my.py</em>:</p>
<pre><code>import sys

class My:
    # ...

if __name__ == '__main__':
    with open(sys.argv[1], 'rt') as f:
        code = f.read()
    program = My(code)
    program.run()
</code></pre>
<p>Now you can create silly programs that print numbers, store them in a file and execute them. For example, write the following program in a file called <em>test.my</em>:</p>
<pre><code>print 1
print 52
</code></pre>
<p>Then run the program as follows:</p>
<pre><code>$ python my.py test.my
1
52
</code></pre>
<p>Very cool!</p>
<p>In the <a href="https://blog.miguelgrinberg.com/post/building-a-toy-programming-language-in-python-part-2">second part</a> of this tutorial, I'll show you how to extend the <code>my</code> language to support variables and mathematical expressions.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My Meeting with David Bohm (109 pts)]]></title>
            <link>https://johnhorgan.org/cross-check/my-meeting-with-david-bohm-tormented-quantum-visionary</link>
            <guid>36561991</guid>
            <pubDate>Sun, 02 Jul 2023 14:52:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://johnhorgan.org/cross-check/my-meeting-with-david-bohm-tormented-quantum-visionary">https://johnhorgan.org/cross-check/my-meeting-with-david-bohm-tormented-quantum-visionary</a>, See on <a href="https://news.ycombinator.com/item?id=36561991">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" id="block-e52f82f2667c20f5a522">
  <p><em>Some scientists seek to clarify reality, others to mystify it. Physicist David Bohm seemed driven by both impulses. He is renowned for promoting a sensible (according to experts like Einstein, John Bell and philosopher Tim Maudlin) interpretation of quantum mechanics. But Bohm also asserted that science can never fully explain the world, and his 1980 book Wholeness and the Implicate Order veers into spirituality. Bohm’s interpretation of quantum mechanics has attracted increasing attention lately. He is the hero, for example, of Adam Becker’s book What Is Real: The Unfinished Quest for the Meaning of Quantum Mechanics. In </em><a href="https://www.amazon.com/End-Science-Knowledge-Twilight-Scientific/dp/0465065929/"><em>The End of Science</em></a><em>, I tried to make sense of this paradoxical truth-seeker, who died in 1992 at the age of 74. Below is an edited version of my take on Bohm. –John Horgan</em></p><p>In August 1992, when I visit David Bohm at his home outside London, his skin is alarmingly pale, especially in contrast to his purplish lips and dark, wiry hair. His frame, sinking into a large armchair, seems limp, languorous, and yet suffused with nervous energy. One hand cups the top of his head, the other grips an armrest. His fingers, long and blue-veined, with tapered, yellow nails, are splayed. He is recovering, he says, from a heart attack. </p><p>Bohm’s wife brings us tea and biscuits and vanishes. Bohm speaks haltingly at first, then faster and faster, in a low monotone, with ancient-Mariner urgency. His mouth must be dry, because he keeps smacking his lips. Occasionally, he pulls his lips back from his teeth in a grimace-smile. He has the disconcerting habit of pausing every few sentences and asking, “Is that clear?” or simply, “Hmmm?” I am often so hopelessly befuddled that I just smile and nod. But Bohm can be bracingly clear, too. He oscillates in and out of focus, like an exotic quantum particle.</p><p>Born (in 1917) and raised in the U.S., Bohm left in 1951, the height of anti-communist hysteria, after refusing to answer a Congressional committee’s questions about his ties to communism. After stays in Brazil and Israel, he settled in England. Bohm was a scientific dissident too. He rebelled against the so-called Copenhagen interpretation of quantum mechanics promulgated by Danish physicist Niels Bohr.</p><p>According to the Copenhagen interpretation, a quantum entity such as an electron has no definite existence apart from our observation of it. We cannot say with certainty whether it is a wave or particle. The interpretation also rejects the possibility that the seemingly probabilistic behavior of quantum systems stems from underlying, deterministic mechanisms. </p><p>Bohm rejected that view. “The whole idea of science so far has been to say that underlying the phenomenon is some reality which explains things,” he explains to me. “It was not that Bohr denied reality, but he said quantum mechanics implied there was nothing more that could be said about it.” Such a view reduces quantum mechanics to “a system of formulas that we use to make predictions or to control things technologically. I said that's not enough. I don’t think I would be very interested in science if that were all there was.”</p><p>In 1952 Bohm proposed a model that builds upon one invented by Louis de Broglie in the 1920s. Particles are particles at all times, not just when observed in a certain way, and their behavior is determined by a force called the “pilot wave.” Any effort to observe a particle alters its behavior by disturbing the pilot wave. Bohm thus gave the uncertainty principle a purely physical rather than metaphysical meaning. Niels Bohr had interpreted the uncertainty principle as meaning “not that there is uncertainty, but that there is an inherent ambiguity” in a quantum system, Bohm says.</p><p>Bohm’s interpretation gets rid of one quantum paradox, wave/particle duality, while doubling down on another, nonlocality, the capacity of one particle to influence another instantaneously across vast distances. Einstein drew attention to nonlocality in 1935 in an effort to show that quantum mechanics must be flawed. Together with Boris Podolsky and Nathan Rosen, Einstein proposed a thought experiment involving two particles that spring from a common source and fly in opposite directions.</p><p>According to the standard model of quantum mechanics, neither particle has fixed properties, such as spin, before it is measured. Upon measuring one particle’s spin, the physicist instantaneously determines the spin of the other particle, no matter how distant. Deriding this effect as “spooky action at a distance,” Einstein argued that quantum mechanics must be flawed or incomplete. But in 1980 French physicists demonstrated spooky action in a laboratory. Bohm never doubted the experiment’s outcome. “It would have been a terrific surprise to find out otherwise,” he says.</p><p>But here is the paradox of Bohm: Although he tries to make the world more sensible with his pilot-wave model, he also argues that complete clarity is impossible. He reached this conclusion after seeing an experiment on television, in which a drop of ink is squeezed onto a cylinder of glycerin. When the cylinder is rotated, the ink diffuses through the glycerin in an apparently irreversible fashion. Its order seems to have disintegrated. But when the direction of rotation is reversed, the ink gathers into a drop again.</p><p>The experiment inspired Bohm to write <em>Wholeness and the Implicate Order</em>, published in 1980. Beneath physical appearances, the “explicate order,” he argues in the book, there lies a hidden “implicate order.” Applying this concept to the quantum realm, Bohm conjectures that the implicate order is a field consisting of infinite fluctuating pilot waves. The overlapping of these waves generates what appear to us as particles, which constitute the explicate order. Even space and time might be manifestations of a deeper, implicate order, according to Bohm.</p><p>To plumb the implicate order, Bohm says, physicists might need to jettison basic assumptions about nature. During the Enlightenment, thinkers such as Newton and Descartes replaced the ancients’ organic concept of order with a mechanistic view. Even after the advent of relativity and quantum mechanics, “the basic idea is still the same,” Bohm tells me, "a mechanical order described by coordinates.”</p><p>Bohm hopes scientists will eventually move beyond mechanistic and even mathematical paradigms. “We have an assumption now that’s getting stronger and stronger that mathematics is the only way to deal with reality,” Bohm says. “Because it’s worked so well for a while, we’ve assumed that it has to be that way.”</p><p>Someday, science and art will merge, Bohm predicts. “This division of art and science is temporary,” he observes. “It didn't exist in the past, and there’s no reason why it should go on in the future.” Just as art consists not simply of works of art but of an “attitude, the artistic spirit,” so does science consist not in the accumulation of knowledge but in the creation of fresh modes of perception. “The ability to perceive or think differently is more important than the knowledge gained.”</p><p>Bohm rejects the claim of Stephen Hawking and others that physics can achieve a final theory, or “theory of everything,” that explains the world. Science is an infinite, “inexhaustible process,” Bohm says. “The form of knowledge is to have at any moment something essential, and the appearance can be explained. But then when we look deeper at these essential things, they turn out to have some feature of appearances. We're not ever going to get a final essence which isn't also the appearance of something.”</p><p>Bohm fears belief in a final theory might become self-fulfilling. “If you have fish in a tank and you put a glass barrier in there, the fish keep away from it,” he says. “And then if you take away the glass barrier, they never cross the barrier, and they think the whole world is that.” He chuckles and shows me his smile-grimace. “So your thought that this is the end could be the barrier to looking further.” Trying to convince me that final knowledge is unattainable, Bohm says the following:</p><p><em>Anything known has to be determined by its limits. And that’s not just quantitative but qualitative. The theory is this and not that. Now it’s consistent to propose that there is the unlimited. You have to notice that if you say there is the unlimited, it cannot be different, because then the unlimited will limit the limited, by saying that the limited is not the unlimited, right? The unlimited must include the limited. We have to say, from the unlimited the limited arises, in a creative process. That’s consistent. Therefore we say that no matter how far we go there is the unlimited. It seems that no matter how far you go, somebody will come up with another point you have to answer. And I don’t see how you could ever settle that.</em></p><p>To my relief, Bohm’s wife enters the room and asks if we want more tea. As she refills my cup, I spot a book on Buddhism in a bookcase and ask if Bohm is interested in spirituality. He nods. He was close to Jiddu Krishnamurti, an Indian sage who taught westerners how to achieve the supreme spiritual state called enlightenment. Was Krishnamurti enlightened? “In some ways, yes,” Bohm replies. “His basic thing was to go into thought, to get to the end of it, completely, and thought would become a different kind of consciousness.”</p><p>Of course, Bohm says, you can never truly plumb your own mind; any attempt to examine your thought changes it--just as the measurement of an electron alters its course. We cannot achieve final self-knowledge, Bohm seems to imply, any more we can achieve a final theory of physics.</p><p>Was Krishnamurti a happy person? Bohm seems puzzled by my question. “That's hard to say,” he replies. “He was unhappy at times, but I think he was pretty happy overall. The thing is not about happiness, really.” Bohm frowns, as if realizing the import of what he has just said.</p><p>I say goodbye to Bohm and his wife and depart. Outside, a light rain is falling. I walk up the path to the street and glance back at Bohm's house, a modest white-painted cottage on a street of modest white-painted cottages.</p><p>In <em>Wholeness and the Implicate Order</em>, Bohm insists on the importance of “playfulness” in science, and in life, but Bohm, in his writings and in person, was anything but playful. For him, truth-seeking was not a game, it was a dreadful, impossible, necessary task. Bohm was desperate to know, to discover the secret of everything, but he knew it wasn’t attainable, not for any mortal being. No one leaves the fish tank alive.</p><p>Two months after our meeting, Bohm died of a heart attack.</p><p><em>Further Reading</em>:</p><p>See my free online book <a href="https://johnhorgan.org/books/my-quantum-experiment"><em>My Quantum Experiment</em></a> as well as my profile of <a href="https://blogs.scientificamerican.com/cross-check/do-our-questions-create-the-world/">another quantum visionary, John Wheeler</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Parsing time stamps faster with SIMD instructions (204 pts)]]></title>
            <link>https://lemire.me/blog/2023/07/01/parsing-time-stamps-faster-with-simd-instructions/</link>
            <guid>36561974</guid>
            <pubDate>Sun, 02 Jul 2023 14:50:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lemire.me/blog/2023/07/01/parsing-time-stamps-faster-with-simd-instructions/">https://lemire.me/blog/2023/07/01/parsing-time-stamps-faster-with-simd-instructions/</a>, See on <a href="https://news.ycombinator.com/item?id=36561974">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>In software, it is common to represent time as a time-stamp string. It is usually specified by a time format string. <a href="https://datatracker.ietf.org/doc/html/rfc4034#section-3.2">Some standards</a> use the format <tt>%Y%m%d%H%M%S</tt> meaning that we print the year, the month, the day, the hours, the minutes and the seconds. The current time as I write this blog post would be <tt>20230701205436</tt> as a time stamp in this format. It is convenient because it is short, easy to read and if you sort the strings lexicographically, you also sort them chronologically.</p>
<p>You can generate time stamps using any programming language. In C, the following program will print the current time (universal, not local time):</p>
<pre><span>#</span><span>include </span><span>&lt;</span><span>time.h</span><span>&gt;</span>
<span>#</span><span>include </span><span>&lt;</span><span>stdio.h</span><span>&gt;</span>
<span>int</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
<span>  char</span> buffer<span>[</span><span>15</span><span>]</span><span>;</span>
<span>  struct</span> <span>tm</span> timeinfo<span>;</span>
<span>  time_t</span> rawtime<span>;</span>
<span>  time</span><span>(</span><span>&amp;</span>rawtime<span>)</span><span>;</span>
  gmtime_r<span>(</span><span>&amp;</span>rawtime<span>,</span> <span>&amp;</span>timeinfo<span>)</span><span>;</span>
<span>  size_t</span> len <span>=</span> <span>strftime</span><span>(</span>buffer<span>,</span> <span>15</span><span>,</span> <span>"</span><span>%Y%m</span><span>%d</span><span>%H%M</span><span>%S</span><span>"</span><span>,</span> <span>&amp;</span>timeinfo<span>)</span><span>;</span>
  buffer<span>[</span><span>14</span><span>]</span> <span>=</span> <span>'\0'</span><span>;</span>
<span>  puts</span><span>(</span>buffer<span>)</span><span>;</span>
<span>}</span>
</pre>
<p>We are interested in the problem of parsing these strings. In practice, this means that we want to convert them to an integer presenting the number of seconds since the Unix epoch. The Unix epoch is January 1st 1970. For my purposes, I will consider the time to be an unsigned 32-bit integer so we can represent time between 1970 and 2106. It is not difficult to switch over to a 64-bit integer or to signed integers.</p>
<p>The way you typically solve this problem is to use something like the C function <tt>strptime</tt>. Can we do better?</p>
<p>Modern processors have fast instructions that operate on several words at once, called SIMD instructions. We have a block of 14 characters. Let us assume that we can read 16 characters safely, ignoring the content of the leftover characters.</p>
<p>We load the block of digits in a SIMD register. We subtract 0x30 (the code point value of the character ‘0’), and all bytes values should be between 0 and 9, inclusively. We know that some character must be smaller than 9, for example, we cannot have more than 59 seconds and never 60 seconds, in the time stamp string. So one character must be between 0 and 5. Similarly, we start the hours at 00 and end at 23, so one character must be between 0 and 2. We do a saturating subtraction of the maximum: the result of such a subtraction should be zero if the value is no larger. We then use a special instruction to multiply one byte by 10, and sum it up with the next byte, getting a 16-bit value. We then repeat the same approach as before, checking that the result is not too large.</p>
<p>The code might look as follow using Intel intrinsic functions:</p>
<pre> __m128i v <span>=</span> _mm_loadu_si128<span>(</span><span>(</span><span>const</span> __m128i <span>*</span><span>)</span>date_string<span>)</span><span>;</span>
v <span>=</span> _mm_sub_epi8<span>(</span>v<span>,</span> _mm_set1_epi8<span>(</span><span>0x30</span><span>)</span><span>)</span><span>;</span>
__m128i limit <span>=</span>
_mm_setr_epi8<span>(</span><span>9</span><span>,</span> <span>9</span><span>,</span> <span>9</span><span>,</span> <span>9</span><span>,</span> <span>1</span><span>,</span> <span>9</span><span>,</span> <span>3</span><span>,</span> <span>9</span><span>,</span> <span>2</span><span>,</span> <span>9</span><span>,</span> <span>5</span><span>,</span> <span>9</span><span>,</span> <span>5</span><span>,</span> <span>9</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>-</span><span>1</span><span>)</span><span>;</span>
__m128i abide_by_limits <span>=</span> _mm_subs_epu8<span>(</span>v<span>,</span> limit<span>)</span><span>;</span> <span>// must be all zero</span>
<span>const</span> __m128i weights <span>=</span> _mm_setr_epi8<span>(</span>
<span>10</span><span>,</span> <span>1</span><span>,</span> <span>10</span><span>,</span> <span>1</span><span>,</span> <span>10</span><span>,</span> <span>1</span><span>,</span> <span>10</span><span>,</span> <span>1</span><span>,</span> <span>10</span><span>,</span> <span>1</span><span>,</span> <span>10</span><span>,</span> <span>1</span><span>,</span> <span>10</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>)</span><span>;</span>
v <span>=</span> _mm_maddubs_epi16<span>(</span>v<span>,</span> weights<span>)</span><span>;</span>
__m128i limit16 <span>=</span>
_mm_setr_epi16<span>(</span><span>99</span><span>,</span><span>99</span><span>,</span> <span>12</span><span>,</span> <span>31</span><span>,</span> <span>23</span><span>,</span> <span>59</span><span>,</span> <span>59</span><span>,</span> <span>-</span><span>1</span><span>)</span><span>;</span>
__m128i abide_by_limits16 <span>=</span> _mm_subs_epu16<span>(</span>v<span>,</span> limit16<span>)</span><span>;</span>
__m128i limits <span>=</span> _mm_or_si128<span>(</span>abide_by_limits16<span>,</span>abide_by_limits<span>)</span><span>;</span>
<span>if</span> <span>(</span><span>!</span>_mm_test_all_zeros<span>(</span>limits<span>,</span> limits<span>)</span><span>)</span> <span>{</span>
<span>  return</span> false<span>;</span>
<span>}</span>

</pre>
<p>It does not get all the parsing done, but at this point, you have the months, days, hours, minutes and seconds as valid binary integer values. The year is parsed in two components (the first two digits, and the next two digits).</p>
<p>We can just use standard C code for the result.</p>
<p>Is it fast? I wrote a benchmark that I compile using GCC 12 on an Intel Ice Lake Linux server.</p>
<table>
<tbody>
<tr>
<th></th>
<th>instructions per stamp</th>
<th>time per stamp</th>
</tr>
<tr>
<td>standard C with <tt>strptime</tt></td>
<td>700</td>
<td>46</td>
</tr>
<tr>
<td>SIMD approach</td>
<td>65</td>
<td>7.9</td>
</tr>
</tbody>
</table>
<p>We use about 10 times fewer instructions, and we go 6 times faster. That is not bad, but I suspect it is not nearly optimal.</p>
<p><a href="https://github.com/lemire/Code-used-on-Daniel-Lemire-s-blog/tree/master/2023/07/01">The source code is available</a>.</p>
<p><strong>Credit</strong>: Thanks to Jeroen Koekkoek from NLnetLabs for initial work and for proposing the problem, and to @aqrit for sketching the current code.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A curated list of Emacs Lisp development resources (112 pts)]]></title>
            <link>https://github.com/p3r7/awesome-elisp</link>
            <guid>36561897</guid>
            <pubDate>Sun, 02 Jul 2023 14:41:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/p3r7/awesome-elisp">https://github.com/p3r7/awesome-elisp</a>, See on <a href="https://news.ycombinator.com/item?id=36561897">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><div dir="auto"><p><a href="https://github.com/p3r7/awesome-elisp"><img alt="Emacs Logo" width="240" height="240" src="https://camo.githubusercontent.com/1a6b6ba74a3a29246f56caf18a3a758ac6f6735cac2f0baf5737cd2962550386/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f302f30382f456d61637349636f6e2e737667" data-canonical-src="https://upload.wikimedia.org/wikipedia/commons/0/08/EmacsIcon.svg"></a></p><h2 tabindex="-1" dir="auto">Awesome Elisp</h2>
</div>
<p dir="auto">Welcome to <i>Awesome Elisp</i>, a list of resources linked to Emacs Lisp (Elisp) development.</p>
<p dir="auto">Its aim is to not be a simple index but a <i>compendium</i>: resources are not only listed but also commented.</p>
<p dir="auto">It tries to be as exhaustive as possible.</p>
<p dir="auto">For a more general index related to all-things Emacs, use <a href="https://github.com/emacs-tw/awesome-emacs">Awesome Emacs</a>.</p>
<h2 tabindex="-1" dir="auto">Table of Contents</h2>
<blockquote>
  <ul dir="auto">
    <li><a href="#what-is-elisp">What is Elisp?</a></li>
    <li><a href="#iconography">Iconography</a></li>
    <li><a href="#resources">Resources</a>
      <ul dir="auto">
        <li><a href="#entry-level">Entry-level</a></li>
        <li><a href="#advanced">Advanced</a></li>
        <li><a href="#cookbooks">Cookbooks</a></li>
        <li><a href="#on-package-authoring">On Package Authoring</a></li>
        <li><a href="#contributing-to-emacs">Contributing to Emacs</a></li>
      </ul>
    </li>
    <li><a href="#development-tools">Development Tools</a>
      <ul dir="auto">
        <li><a href="#interactive-development--debugging">Interactive Development &amp; Debugging</a></li>
        <li><a href="#documentation--introspection">Documentation &amp; Introspection</a></li>
        <li><a href="#code-editing">Code Editing</a>
          <ul dir="auto">
            <li><a href="#jump-to-definition">Jump to definition</a></li>
            <li><a href="#search--replace">Search &amp; Replace</a></li>
            <li><a href="#editing">Editing</a></li>
            <li><a href="#editing-s-exps">Editing S-exps</a></li>
            <li><a href="#refactoring">Refactoring</a></li>
            <li><a href="#formatting">Formatting</a></li>
          </ul>
        </li>
        <li><a href="#testing">Testing</a></li>
        <li><a href="#profiling">Profiling</a></li>
        <li><a href="#validation">Validation</a></li>
        <li><a href="#building">Building</a></li>
        <li><a href="#syntax-highlighting--visual-enhancements">Syntax Highlighting &amp; Visual Enhancements</a></li>
        <li><a href="#pretty-printing">Pretty Printing</a></li>
      </ul>
    </li>
    <li><a href="#libraries">Libraries</a>
      <ul dir="auto">
        <li><a href="#core--general-purpose">Core / General Purpose</a></li>
        <li><a href="#data-structures">Data Structures</a>
          <ul dir="auto">
            <li><a href="#strings">Strings</a></li>
            <li><a href="#sequences">Sequences</a></li>
            <li><a href="#maps">Maps</a></li>
            <li><a href="#custom-types--oop">Custom Types &amp; OOP</a></li>
            <li><a href="#date--time">Date &amp; Time</a></li>
            <li><a href="#tables">Tables</a></li>
            <li><a href="#queues">Queues</a></li>
            <li><a href="#rings">Rings</a></li>
            <li><a href="#trees">Trees</a></li>
            <li><a href="#parsers--parse-trees">Parsers &amp; Parse Trees</a></li>
            <li><a href="#xmlhtml">XML/HTML</a></li>
            <li><a href="#org-mode-outlines">Org-mode outlines</a></li>
            <li><a href="#color-codes">Color Codes</a></li>
          </ul>
        </li>
        <li><a href="#concurrency--asynchronicity">Concurrency / Asynchronicity</a>
          <ul dir="auto">
            <li><a href="#timers">Timers</a></li>
            <li><a href="#promises--delays">Promises &amp; Delays</a></li>
            <li><a href="#async-elisp-function-calls">Async Elisp function calls</a></li>
            <li><a href="#async-sub-processes">Async sub-processes</a></li>
            <li><a href="#async-interpreter-commands">Async interpreter commands</a></li>
          </ul>
        </li>
        <li><a href="#buffer-manipulation">Buffer Manipulation</a></li>
        <li><a href="#filesystem-interactions">Filesystem Interactions</a></li>
        <li><a href="#networking">Networking</a>
          <ul dir="auto">
            <li><a href="#http-client">HTTP client</a></li>
            <li><a href="#http-server">HTTP server</a></li>
            <li><a href="#rpc-server">RPC server</a></li>
            <li><a href="#d-bus">D-Bus</a></li>
          </ul>
        </li>
        <li><a href="#database-access">Database Access</a></li>
        <li><a href="#gui">GUI</a>
          <ul dir="auto">
            <li><a href="#popups">Popups</a></li>
            <li><a href="#overlays">Overlays</a></li>
            <li><a href="#charts--diagrams">Charts &amp; diagrams</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#heroes">Heroes</a></li>
    <li><a href="#contributing">Contributing</a></li>
    <li><a href="#license">License</a></li>
  </ul>
</blockquote>
<h2 tabindex="-1" dir="auto">What is Elisp?</h2>
<p dir="auto">Elisp is short for <i>Emacs Lisp</i>, a dialect of <a href="https://en.wikipedia.org/wiki/Lisp_programming_language" rel="nofollow">Lisp</a> specific to Emacs.</p>
<p dir="auto">If you’re a fresh Emacs user, you’ve certainly practiced it a bit by editing your <code>init.el</code> (i.e. configuration).</p>
<p dir="auto">You may also have spotted that most <i>packages</i> (i.e. plugins) available to Emacs are written in pure Elisp.</p>
<p dir="auto">In fact, Elisp is not limited to extending Emacs functionalities: a good chunk (and <a href="https://archive.fosdem.org/2020/schedule/event/emacsthoughts/" rel="nofollow">admittedly not enough</a>) of Emacs is written in it.</p>
<p dir="auto">This means that any user can browse, extend or even override core Emacs functionalities at runtime.</p>
<p dir="auto">As such, in essence, Emacs is <a href="https://www.eigenbahn.com/2020/01/12/emacs-is-no-editor" rel="nofollow">not an editor</a> but more a platform allowing users to write text-based apps.</p>
<p dir="auto">Being an editor is not its intrinsic nature but merely a feature.</p>
<p dir="auto">Learning Elisp will up your Emacs game tremendously, unlocking its full potential by writing functionalities either for your personal needs or to share with the world.</p>
<p dir="auto">As an added bonus, it’s great fun.</p>
<h2 tabindex="-1" dir="auto">Iconography</h2>

<h2 tabindex="-1" dir="auto">Resources</h2>
<h2 tabindex="-1" dir="auto">Entry-level</h2>
<h3 tabindex="-1" dir="auto">An Introduction to Programming in Emacs Lisp</h3>
<p dir="auto"><a href="https://www.gnu.org/software/emacs/manual/html_node/eintr/index.html" rel="nofollow">read online</a></p>
<p dir="auto">Also comes bundled with Emacs.
  Just <code>C-h i</code> (or <code>M-x info</code>) and open <code>Emacs Lisp Intro</code>.</p>
<p dir="auto">A bit scholarly. Not the easiest read.</p>
<h3 tabindex="-1" dir="auto">Emacs In A Box - Elisp Programming</h3>
<p dir="auto"><a href="http://caiorss.github.io/Emacs-Elisp-Programming/Elisp_Programming.html" rel="nofollow">read online</a>, <a href="https://github.com/caiorss/Emacs-Elisp-Programming/blob/master/Elisp_Programming.org">source</a></p>
<p dir="auto">Very complete and gentle introduction.</p>
<p dir="auto">Written by <a href="#caio-rordrigues-caiorss">Caio Rordrigues (@caiorss)</a>.</p>
<h3 tabindex="-1" dir="auto">(Almost) All You Need to Know About Variables</h3>
<p dir="auto"><a href="https://with-emacs.com/posts/tutorials/almost-all-you-need-to-know-about-variables/" rel="nofollow">read online</a></p>
<p dir="auto">A must read!</p>
<h3 tabindex="-1" dir="auto">elisp-guide</h3>
<p dir="auto"><a href="https://github.com/chrisdone/elisp-guide">read online</a></p>
<p dir="auto">Focused on introducing general concepts and terminology.</p>
<h3 tabindex="-1" dir="auto">Emergency Elisp</h3>
<p dir="auto"><a href="http://steve-yegge.blogspot.com/2008/01/emergency-elisp.html" rel="nofollow">read online</a></p>
<p dir="auto">Focused around data structures.
  More like a cheat sheet.</p>
<h3 tabindex="-1" dir="auto">ergoemacs - Practical Emacs Lisp</h3>
<p dir="auto"><a href="http://ergoemacs.org/emacs/elisp.html" rel="nofollow">read online</a></p>
<p dir="auto">Not super up to date but generally well put together.</p>
<p dir="auto">One of the first resources on the web introducing Elisp in a concise and comprehensible way.</p>
<p dir="auto">Please note that the more complex examples follow a coding style regarded as not so great: big monolithic functions instead of multiple small functional ones.</p>
<p dir="auto">To Xah’s defense, some packages now considered standard are also written this way (we’re looking at you <code>ediff</code>).</p>
<h3 tabindex="-1" dir="auto">ElispCheatSheet</h3>
<p dir="auto"><a href="https://alhassy.github.io/ElispCheatSheet/" rel="nofollow">read online</a>, <a href="https://github.com/alhassy/ElispCheatSheet">source</a></p>
<p dir="auto">Focused around data structures.</p>
<p dir="auto">Author’s Common Lisp background can be felt.</p>
<h2 tabindex="-1" dir="auto">Advanced</h2>
<h3 tabindex="-1" dir="auto">Emacs Lisp Reference Manual</h3>
<p dir="auto"><a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/index.html" rel="nofollow">read online</a></p>
<p dir="auto">Also comes bundled with Emacs.
  Just <code>C-h i</code> (or <code>M-x info</code>) and open <code>Elisp</code>.</p>
<p dir="auto">Comprehensive guide of core Elisp APIs.</p>
<p dir="auto">Generally well written but needs you to understand its logic and be familiar with Emacs terminology.</p>
<h3 tabindex="-1" dir="auto">The Emacs Lisp Style Guide</h3>
<p dir="auto"><a href="https://github.com/bbatsov/emacs-lisp-style-guide">read online</a></p>
<p dir="auto">Provides solid guidelines on the dos and don’ts for quality Elisp code.</p>
<h3 tabindex="-1" dir="auto">The Emacs Package Developer’s Handbook</h3>
<p dir="auto"><a href="https://alphapapa.github.io/emacs-package-dev-handbook/" rel="nofollow">read online</a>, <a href="https://github.com/alphapapa/emacs-package-dev-handbook">source</a></p>
<p dir="auto"><a href="#alphapapa">@alphapapa</a>’s organized notes about Elisp development.</p>
<p dir="auto">List bunch of tools and libraries for helping package developers.</p>
<p dir="auto">Also provides various snippets and best practices.</p>
<p dir="auto">Lots of good insights.</p>
<h3 tabindex="-1" dir="auto">nullprogram.com</h3>
<p dir="auto"><a href="#chris-wellons-skeeto">Chris Wellons (@skeeto)</a>’s blog, especially the posts tagged <a href="https://nullprogram.com/tags/elisp/" rel="nofollow">#elisp</a>.</p>
<p dir="auto">A few highlights:</p>
<ul dir="auto">
  <li><a href="https://nullprogram.com/blog/2018/02/14/" rel="nofollow">Options for Structured Data in Emacs Lisp</a></li>
  <li><a href="https://nullprogram.com/blog/2010/07/26/" rel="nofollow">Elisp Memoize</a></li>
  <li><a href="https://nullprogram.com/blog/2017/10/27/" rel="nofollow">Make Flet Great Again</a></li>
  <li><a href="https://nullprogram.com/blog/2013/01/22/" rel="nofollow">The Limits of Emacs Advice</a></li>
  <li><a href="https://nullprogram.com/blog/2017/01/30/" rel="nofollow">How to Write Fast(er) Emacs Lisp</a></li>
</ul>
<h3 tabindex="-1" dir="auto">Emacs Lisp Programming Thoughts</h3>
<p dir="auto"><a href="https://www.nongnu.org/emacs-tiny-tools/elisp-coding/" rel="nofollow">read online</a></p>
<p dir="auto">Pretty old but has very good insights, guidelines and real-world examples.</p>
<p dir="auto">Byte compiler section is outdated but general coding style recommendations and sections about macros and profiling are still relevant to this day.</p>
<h2 tabindex="-1" dir="auto">Cookbooks</h2>
<h3 tabindex="-1" dir="auto">elisp-demos</h3>
<p dir="auto"><a href="https://github.com/xuchunyang/elisp-demos/blob/master/elisp-demos.org">read online</a>, <a href="https://github.com/xuchunyang/elisp-demos">source</a></p>
<p dir="auto">Very good and beginner-friendly.</p>
<p dir="auto">Almost complete list of single-liner examples of standard function.
  Also packs examples for <code>dash</code> and <code>s</code>.</p>
<h3 tabindex="-1" dir="auto">Emacs In A Box - Elisp Snippets</h3>
<p dir="auto"><a href="http://caiorss.github.io/Emacs-Elisp-Programming/Elisp_Snippets.html" rel="nofollow">read online</a>, <a href="https://github.com/caiorss/Emacs-Elisp-Programming/blob/master/Elisp_Snippets.org">source</a></p>
<p dir="auto">Really nice selection of snippets with real-world use-cases.</p>
<h3 tabindex="-1" dir="auto">EmacsWiki’s Cookbook</h3>
<p dir="auto"><a href="https://www.emacswiki.org/emacs/ElispCookbook" rel="nofollow">read online</a></p>
<p dir="auto">Community-driven snippets, beginner-friendly.</p>
<h3 tabindex="-1" dir="auto">@alphapapa’s unpackaged.el</h3>
<p dir="auto"><a href="https://alphapapa.github.io/unpackaged.el/" rel="nofollow">read online</a>, <a href="https://github.com/alphapapa/unpackaged.el">source</a></p>
<p dir="auto">Real-world selection of snippets, not beginner-friendly.</p>
<h2 tabindex="-1" dir="auto">On Package Authoring</h2>
<p dir="auto"><a href="#the-emacs-lisp-styleguide">The Emacs Lisp Style Guide</a> applies all the more in this context.</p>
<h3 tabindex="-1" dir="auto">Article: Take Your Emacs to the Next Level by Writing Custom Packages</h3>
<p dir="auto"><a href="https://spin.atomicobject.com/2016/05/27/write-emacs-package/" rel="nofollow">read online</a></p>
<p dir="auto">Real world experience of a user writing and submitting his first package.</p>
<h3 tabindex="-1" dir="auto">MELPA recommandations</h3>
<p dir="auto"><a href="https://github.com/melpa/melpa/blob/master/CONTRIBUTING.org#making-your-package-ready-for-inclusion">read online</a></p>
<p dir="auto">There’s a high chance that you’ll be uploading your package on <a href="https://melpa.org/" rel="nofollow">MELPA</a>.</p>
<p dir="auto">They have clear recommandations.</p>
<p dir="auto">Don’t worry, for your first submissions, they will be very comprehensive and will help you fixing what’s wrong.</p>
<h2 tabindex="-1" dir="auto">Contributing to Emacs</h2>
<p dir="auto">The <a href="https://www.gnu.org/software/emacs/CONTRIBUTE" rel="nofollow">CONTRIBUTE</a> file is the official document describing the process.
  Additional development tips and coding conventions can be found in the <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Tips.html#Tips" rel="nofollow">Elisp Manual</a>.</p>
<p dir="auto"><code>M-x view-emacs-todo</code> shows a lists of TODO items you might want to work on.
  You can also browse the bug archive using <code>M-x debbugs-gnu</code> using the <a href="https://elpa.gnu.org/packages/debbugs.html" rel="nofollow">debbugs</a> package.</p>
<p dir="auto"><a href="https://archive.casouri.cat/note/2020/contributing-to-emacs/" rel="nofollow">Contributing to Emacs</a> gives some helpful background information and overview about the contribution workflow for newcomers.</p>
<h2 tabindex="-1" dir="auto">Development Tools</h2>
<p dir="auto">By default, Emacs is already pretty well set up for Elisp development.</p>
<p dir="auto">But some features can be hard to learn and some stuff can be improved with additinal packages.</p>
<p dir="auto">See also those talks <a href="https://github.com/p3r7/awesome-elisp#john-wiegley-jwiegley">John Wiegley</a> gave about his setup for Elisp development:</p>
<ul dir="auto">
  <li><a href="https://www.youtube.com/watch?v=QFClYrhV1z4" rel="nofollow">Emacs Lisp Development - @ Emacs Conference 2013</a></li>
  <li><a href="https://sachachua.com/blog/2015/04/2015-04-08-emacs-lisp-development-tips-with-john-wiegley/" rel="nofollow">Emacs Lisp Development Tips - Sacha Chua Emacs Chat 2015-04-08</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Interactive Development &amp; Debugging</h2>
<p dir="auto">Emacs is built with interactive development in mind.</p>
<p dir="auto">You could spend days developing Elisp code without ever having to restart Emacs.</p>
<p dir="auto">Standard <i>commands</i> used are:</p>
<ul dir="auto">
  <li><code>eval-last-sexp</code> (<code>C-x C-e</code>)</li>
  <li><code>eval-defun</code> (<code>C-M-x</code>)</li>
  <li><code>eval-buffer</code></li>
  <li><code>eval-region</code></li>
</ul>
<p dir="auto">The <code>*scratch*</code> buffer also provides a temporary zone to try and test ideas.
  In it can be used <code>eval-print-last-sexp</code> (<code>C-j</code>) which acts like <code>eval-last-sexp</code> but also prints the result after the <i>s-exp</i> in the buffer.</p>
<p dir="auto"><code>eval-expression</code> (<code>M-:</code>) allows quickly evaluating a <i>s-exp</i> from anywhere by entering it in the <i>minibuffer</i>.</p>
<p dir="auto">For logging, function <code>(message "&lt;text&gt;")</code> allows printing into the <code>*Messages*</code> buffer.</p>
<p dir="auto">For debugging, the most basic command is <code>toggle-debug-on-error</code> to get a stacktrace.</p>
<p dir="auto">See also:</p>
<ul dir="auto">
  <li><a href="https://www.masteringemacs.org/article/evaluating-elisp-emacs" rel="nofollow">Mastering Emacs - Evaluating Elisp in Emacs</a></li>
</ul>
<h4 tabindex="-1" dir="auto">IELM</h4>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Stands for Inferior Emacs Lisp Mode.</p>
<p dir="auto">Provides a <a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop" rel="nofollow">REPL</a> for evaluating Elisp code.</p>
<h4 tabindex="-1" dir="auto">edebug</h4>
<p dir="auto"><a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/emacs-lisp/edebug.el">source</a>, <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Edebug.html" rel="nofollow">doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">edebug is the interactive Elisp debugger.</p>
<p dir="auto">The documentation is a bit rough to get started.
  I recommend reading this series of posts:</p>
<ul dir="auto">
  <li><a href="https://endlessparentheses.com/debugging-emacs-lisp-part-1-earn-your-independence.html" rel="nofollow">Endless Parentheses - Debugging Elisp Part 1: Earn your independence</a></li>
  <li><a href="https://endlessparentheses.com/debugging-elisp-part-2-advanced-topics.html" rel="nofollow">Endless Parentheses - Debugging Elisp Part 2: Advanced topics</a></li>
</ul>
<p dir="auto">You can also read the dedicated <a href="https://www.gnu.org/software/emacs/manual/html_node/eintr/Debugging.html" rel="nofollow">chapter in book An Introduction to Programming in Emacs Lisp</a>.</p>
<h4 tabindex="-1" dir="auto">trace</h4>
<p dir="auto"><a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/emacs-lisp/trace.el">source</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Provides a simple facility to output a trace of function calls into a buffer (<code>*trace-buffer*</code>).</p>
<p dir="auto">Please note that this trace is very basic and has no performance data. For more advanced tracing see <a href="#profiling">Profiling</a>.</p>
<p dir="auto">Tracing is switched on / off with <i>commands</i> <code>trace-function</code>, <code>untrace-function</code> and <code>untrace-all</code>.</p>
<h4 tabindex="-1" dir="auto">macrostep</h4>
<p dir="auto"><a href="https://github.com/joddie/macrostep">source &amp; doc</a></p>
<p dir="auto">Interactive macro expander.</p>
<p dir="auto">Expand nested macros one by one.</p>
<p dir="auto">Way better than using default <code>macroexpand</code>.</p>
<h4 tabindex="-1" dir="auto">eval-expr</h4>
<p dir="auto"><a href="https://github.com/jwiegley/eval-expr">source</a></p>
<p dir="auto">Provides <code>eval-expr</code>, an enhanced <code>eval-expression</code> command.</p>
<p dir="auto">Some highlights:</p>
<ul dir="auto">
  <li>automatic display of output in temp buffer if too big</li>
  <li>allows pretty printing of results (with <code>pp</code>)</li>
  <li>invalid <i>s-expr</i> don’t have to be retyped on 2nd try</li>
</ul>
<h4 tabindex="-1" dir="auto">eval-sexp-fu</h4>
<p dir="auto"><a href="https://github.com/emacsmirror/eval-sexp-fu">source</a></p>
<p dir="auto">Visual improvment.</p>
<p dir="auto">Flashes the sexps during the evaluation.</p>
<h4 tabindex="-1" dir="auto">eros</h4>
<p dir="auto"><a href="https://github.com/xiongtx/eros">source</a></p>
<p dir="auto">Show evaluation results inline.</p>
<h2 tabindex="-1" dir="auto">Documentation &amp; Introspection</h2>
<p dir="auto">To get the documentation of a symbol, you could use one of the built-in:</p>
<ul dir="auto">
  <li><code>describe-symbol</code>: get documentation of symbol</li>
  <li><code>describe-function</code>: get documentation of function</li>
  <li><code>describe-variable</code>: get documentation of variable</li>
  <li><code>describe-key</code>: get documentation of <i>command</i> associated with keybinding</li>
</ul>
<p dir="auto">These would spawn a <code>*Help*</code> buffer. Hence documentation in Emacs is often referred to as the <i>help</i>.
  For searching through symbols Emacs also comes with various <code>apropos-*</code> commands which populate a buffer with your search results.</p>
<p dir="auto">Some packages improve on these.</p>
<h3 tabindex="-1" dir="auto">helpful</h3>
<p dir="auto"><a href="https://github.com/Wilfred/helpful">source &amp; doc</a></p>
<p dir="auto">Provides more contextual information.</p>
<table>
  <tbody><tr><th>helpful command</th><th>default command</th><th>comment</th></tr>
  <tr><td><code>helpful-at-point</code></td><td><code>describe-symbol</code></td><td></td></tr>
  <tr><td><code>helpful-callable</code></td><td>no equivalent</td><td>like <code>helpful-function</code> but also works on macros and special forms</td></tr>
  <tr><td><code>helpful-function</code></td><td><code>describe-function</code></td><td></td></tr>
  <tr><td><code>helpful-macro</code></td><td>no equivalent</td><td></td></tr>
  <tr><td><code>helpful-variable</code></td><td><code>describe-variable</code></td><td></td></tr>
  <tr><td><code>helpful-key</code></td><td><code>describe-key</code></td><td></td></tr>
</tbody></table>
<h3 tabindex="-1" dir="auto">elisp-demos</h3>
<p dir="auto"><a href="https://github.com/xuchunyang/elisp-demos">source</a></p>
<p dir="auto">Provides usage examples in the <code>*Help*</code> buffer.</p>
<h3 tabindex="-1" dir="auto">which-key</h3>
<p dir="auto"><a href="https://github.com/justbur/emacs-which-key">source &amp; doc</a></p>
<p dir="auto"><code>which-key</code> is like an always-on <code>describe-key</code>.</p>
<p dir="auto">It displays automatically all the possible keybindings following a key prefix.</p>
<h3 tabindex="-1" dir="auto">suggest</h3>
<p dir="auto"><a href="https://github.com/Wilfred/suggest.el">source</a></p>
<p dir="auto">Discover elisp functions by specifying input and the desired output.</p>
<h2 tabindex="-1" dir="auto">Code Editing</h2>
<h3 tabindex="-1" dir="auto">Jump to definition</h3>
<p dir="auto">To jump to the definition of a symbol Emacs provides <code>xref-find-definitions</code>. In practice it works with nicely with functions but is kind of hit-or-miss with variables.</p>
<p dir="auto">In addition, the following more specialised functions exist:</p>
<ul dir="auto">
  <li><code>find-function</code>: go to the definition of function</li>
  <li><code>find-variable</code>: go to the definition of variable</li>
  <li><code>find-library</code>: go to the definition of <i>feature</i> (i.e. module, package)</li>
</ul>
<p dir="auto">Better options exists so that you don’t have to remember all of these.</p>
<p dir="auto">Honorable mention: <a href="https://github.com/purcell/elisp-slime-nav">elisp-slime-nav</a>, that can be seen as an ancestor to <code>elisp-def</code>.
  If you want to jump to symbols in files which aren’t loaded in your Emacs you can fallback to the more general <a href="https://github.com/jacktasia/dumb-jump">dumb-jump</a> package.</p>
<h4 tabindex="-1" dir="auto">elisp-def</h4>
<p dir="auto"><a href="https://github.com/Wilfred/elisp-def">source &amp; doc</a></p>
<p dir="auto">Provides <code>elisp-def</code> that allows jumping to the definition of function / variable / feature.</p>
<p dir="auto">Like a better <code>xref-find-definitions</code>.</p>
<p dir="auto">Is able to distinguish between functions / variables / features depending on the context.</p>
<p dir="auto">Also handles macros, functions defined through macros and let-bound variables.</p>
<h3 tabindex="-1" dir="auto">Search &amp; Replace</h3>
<p dir="auto">In Emacs regular expressions can make use of syntax information provided by the major-mode. This means that to some extend semantic searches are possible with <code>isearch</code> and <code>occur</code>.
  To search and jump to toplevel definitions of a buffer you can use the built-in <code>imenu</code>. The <a href="https://github.com/vspinu/imenu-anywhere">imenu-anywhere</a> package allows to extend the scope to buffers of the same project or mode.</p>
<h4 tabindex="-1" dir="auto">elisp-refs</h4>
<p dir="auto"><a href="https://github.com/Wilfred/elisp-refs">source</a></p>
<p dir="auto">Semantic code search for Elisp which parses the code instead of doing dump text searches.</p>
<h4 tabindex="-1" dir="auto">el-search</h4>
<p dir="auto"><a href="https://elpa.gnu.org/packages/el-search.html" rel="nofollow">source</a></p>
<p dir="auto">Lets you execute search and replace operations on symbolic expressions. For example you can search for things like defvars which don’t specify an init value using the pattern `(defvar ,_)`.</p>
<h3 tabindex="-1" dir="auto">Editing</h3>
<p dir="auto">Honorable mentions:</p>
<ul dir="auto">
  <li><a href="https://github.com/joaotavora/yasnippet">YASnippet</a>: generic (not Elisp-specific) powerful abreviation-based snippet expander.  Even though it could be used in the place of <code>speed-of-thought-lisp</code>, it is less context-aware and requires a specific key combination to trigger. It offers other features, though, and can be used complementarily.</li>
</ul>
<h4 tabindex="-1" dir="auto">speed-of-thought-lisp</h4>
<p dir="auto"><a href="https://github.com/Malabarba/speed-of-thought-lisp">source</a></p>
<p dir="auto">Allows writting Elisp blazingly fast with the use of context-aware abbreviations triggered after <code>&lt;SPACE&gt;</code> keypress.</p>
<h4 tabindex="-1" dir="auto">elisp-docstring</h4>
<p dir="auto"><a href="https://github.com/Fuco1/elisp-docstring-mode">source</a></p>
<p dir="auto">Enriched syntax highlighting for docstring contents. Together with <a href="https://github.com/magnars/string-edit.el">string-edit</a> you can edit docstrings in a temporary buffer and get automated special character escaping.</p>
<h3 tabindex="-1" dir="auto">Editing S-exps</h3>
<p dir="auto">Elisp is a Lisp and Lisps are written using a structure of nested lists called <a href="https://en.wikipedia.org/wiki/S-expression" rel="nofollow">S-expressions</a>.</p>
<p dir="auto">Mastering how to navigate and manipulate this structure with ease is essential.</p>
<p dir="auto">By default Emacs doesn’t offer much apart from <code>forward-list</code> / <code>backward-list</code> and <code>forward-sexp</code> / <code>backward-sexp</code>.</p>
<p dir="auto">Luckily, powerful minor-modes are available to give you the power you deserve.</p>
<h4 tabindex="-1" dir="auto">lispy</h4>
<p dir="auto"><a href="https://github.com/abo-abo/lispy">source &amp; doc</a>, <a href="http://oremacs.com/lispy/" rel="nofollow">cheat sheet</a>, <a href="https://www.youtube.com/user/abo5abo/videos" rel="nofollow">video demos</a></p>
<p dir="auto">Easiest to learn yet most powerful solution in that list.</p>
<p dir="auto">Like <code>paxedit</code>, <i>commands</i> are context-aware.</p>
<p dir="auto">The killing feature is that shortcuts are single characters and not key combinations.</p>
<p dir="auto">The trick is that commands get triggered only when the point is at a delimiter (e.g. a parenthesis) or the region is active.</p>
<p dir="auto">Provides a powerful <i>command</i> combination system and refactoring commands.</p>
<h4 tabindex="-1" dir="auto">paxedit</h4>
<p dir="auto"><a href="https://github.com/promethial/paxedit">source &amp; doc</a></p>
<p dir="auto">Heavily inspired by <code>paredit</code>.</p>
<p dir="auto">The major difference with the latter is that <i>commands</i> are context-aware, they behave differently depending on what the cursor is hovering on.</p>
<p dir="auto">The direct consequence is that fewer <i>commands</i> / shortcuts needs to be learned to perform the same amount of things.</p>
<h4 tabindex="-1" dir="auto">paredit</h4>
<p dir="auto"><a href="http://danmidwood.com/content/2014/11/21/animated-paredit.html" rel="nofollow">tutorial</a>, <a href="https://github.com/emacsmirror/paredit">source</a></p>
<p dir="auto">The first powerful S-exp editing mode for Emacs.</p>
<p dir="auto">Learning curve is a bit steep.</p>
<p dir="auto">Still actively maintained and very popular.</p>
<h3 tabindex="-1" dir="auto">Refactoring</h3>
<h4 tabindex="-1" dir="auto">elisp-depmap</h4>
<p dir="auto"><a href="https://github.com/mtekman/elisp-depmap.el">source &amp; doc</a></p>
<p dir="auto">Aids the refactoring process by presenting a graphical visualization of project dependencies.</p>
<h4 tabindex="-1" dir="auto">emacs-refactor</h4>
<p dir="auto"><a href="https://github.com/Wilfred/emacs-refactor">source &amp; doc</a></p>
<p dir="auto">Contains various refactoring commands for Elisp.</p>
<h3 tabindex="-1" dir="auto">Formatting</h3>
<h4 tabindex="-1" dir="auto">aggressive-indent-mode</h4>
<p dir="auto"><a href="https://github.com/Malabarba/aggressive-indent-mode">source &amp; doc</a></p>
<p dir="auto">Auto-indents code as you type.</p>
<h4 tabindex="-1" dir="auto">elfmt</h4>
<p dir="auto"><a href="https://github.com/riscy/elfmt">source</a></p>
<p dir="auto">Focuses on placement of lists and tries to break lines at <code>fill-column</code></p>
<h2 tabindex="-1" dir="auto">Testing</h2>
<p dir="auto">For simulating interactive user input, consider using libraries such as <a href="#with-simulated-input">with-simulated-input</a> (launch <i>commands</i>) and <a href="#dokey">dokey</a> (simulated keyboard shortcut presses).
  To test behavior and interactive usage in a clean and temporary environment <a href="https://github.com/alphapapa/emacs-sandbox.sh">emacs-sandbox.sh</a> is useful.</p>
<h4 tabindex="-1" dir="auto">ERT</h4>
<p dir="auto"><a href="https://www.gnu.org/software/emacs/manual/html_node/ert/index.html" rel="nofollow">doc</a>, <a href="https://nullprogram.com/blog/2012/08/15/" rel="nofollow">blog post on nullprogram.com</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Stands for /”Emacs Lisp Regression Testing”/.</p>
<p dir="auto">Featureful and easy to use.</p>
<p dir="auto">Suitable for <a href="https://en.wikipedia.org/wiki/Unit_testing" rel="nofollow">unit tests</a> with <i>mocking</i>.</p>
<h4 tabindex="-1" dir="auto">Buttercup</h4>
<p dir="auto"><a href="https://github.com/jorgenschaefer/emacs-buttercup">source &amp; doc</a></p>
<p dir="auto"><i>Behavior-Driven Emacs Lisp Testing</i></p>
<p dir="auto">Especially suitable for <a href="https://en.wikipedia.org/wiki/Integration_testing" rel="nofollow">integration tests</a>.</p>
<p dir="auto">Allows defining test suites (i.e. goups of related tests) with a shared context (through <i>set-up</i> and <i>tear-down</i> phases).</p>
<p dir="auto">Also provides mocking capabilities.</p>
<p dir="auto">For a complete example of integration w/ <code>undercover</code> and <code>coverage</code>:</p>
<ul dir="auto">
  <li><a href="https://sachachua.com/blog/2022/01/coverage-reporting-in-emacs-with-buttercup-undercover-coverage-and-a-makefile/" rel="nofollow">Sacha Chua - Coverage reporting in Emacs with Buttercup, Undercover, Coverage, and a Makefile</a></li>
</ul>
<h4 tabindex="-1" dir="auto">director</h4>
<p dir="auto"><a href="https://github.com/bard/emacs-director">source &amp; doc</a></p>
<p dir="auto">Program sequence of user interactions. Useful for end-to-end testing.</p>
<p dir="auto">Inspired by Selenium Webdriver.</p>
<h4 tabindex="-1" dir="auto">undercover</h4>
<p dir="auto"><a href="https://github.com/undercover-el/undercover.el">source &amp; doc</a></p>
<p dir="auto">Track test coverage and integrate w/ coverage reporting solutions.</p>
<p dir="auto">For in-Emacs reporting, use the <a href="https://github.com/trezona-lecomte/coverage">coverage</a> package.</p>
<h2 tabindex="-1" dir="auto">Profiling</h2>
<p dir="auto">Emacs provides 2 Elips profilers:</p>
<ul dir="auto">
  <li><code>profiler.el</code>: profile a whole call stack, easier to use</li>
  <li><code>elp.el</code>: profile only selected functions</li>
</ul>
<p dir="auto">Both are briefly mentioned in the <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Profiling.html" rel="nofollow">profiling section</a> of the <i>Emacs Lisp Reference Manual</i>.</p>
<p dir="auto">Either one is of a great help to debug slow Elisp code, most noticeable during user interactions (Emacs seems to freeze).</p>
<p dir="auto"><code>profiler.el</code> is easily toggled using <code>profiler-start</code>, <code>profiler-stop</code>. To obtain a result report call <code>profiler-report</code>.</p>
<p dir="auto"><code>elp.el</code> can target individual functions with <code>elp-instrument-function</code> or a whole package with <code>elp-instrument-package</code>.</p>
<p dir="auto">To profile individual forms Emacs also comes with the <code>benchmark</code> library. The <i>Emacs Package Developer’s Handbook</i> has a <a href="https://github.com/alphapapa/emacs-package-dev-handbook#profiling--optimization">whole section</a> dedicated to this with thorough examples and helper macros.</p>
<h3 tabindex="-1" dir="auto">etrace</h3>
<p dir="auto"><a href="https://github.com/aspiers/etrace">source &amp; doc</a></p>
<p dir="auto">Wrapper around <code>elp.el</code> outputting a report in the <i>Chromium Catapult Trace Event Format</i>.</p>
<p dir="auto">This allows opening them in external applications to explore them as <i>flame graphs</i>.</p>
<h2 tabindex="-1" dir="auto">Validation</h2>
<p dir="auto">Emacs provides various functions to validate an Elisp file / project:</p>
<ul dir="auto">
  <li><code>byte-compile-file</code>: validate the file compiles cleanly</li>
  <li><code>checkdoc</code>: validate the documentation</li>
  <li><code>check-declare-file</code> / <code>check-declare-directory</code>: validate the declaration of symbols</li>
  <li><code>package-lint-current-buffer</code>: validate format for submitting as a package</li>
</ul>
<p dir="auto">It’s tedious to run manually each and every of those commands. Thankfully projects aim at making this process easier.</p>
<p dir="auto">For maximum efficiency, they can be integrated into a <a href="https://en.wikipedia.org/wiki/Continuous_integration" rel="nofollow">CI</a> chain (<i>GitHub actions</i> or <i>Travis</i>).</p>
<h4 tabindex="-1" dir="auto">melpazoid</h4>
<p dir="auto"><a href="https://github.com/riscy/melpazoid">source &amp; doc</a></p>
<p dir="auto">In addition to standard validation, it adds a license checker and some <a href="https://github.com/riscy/melpazoid/blob/master/melpazoid/melpazoid.el">additional checks</a>.</p>
<p dir="auto">Created by MELPA member <a href="https://github.com/riscy">@riscy</a> to validate submissions.</p>
<p dir="auto">Does not run tests.</p>
<p dir="auto">Provides recipes for integration with <i>GitHub actions</i> or <i>Travis</i>.</p>
<h4 tabindex="-1" dir="auto">makem.sh</h4>
<p dir="auto"><a href="https://github.com/alphapapa/makem.sh">source &amp; doc</a></p>
<p dir="auto">Very straightforward way to validate an Emacs package folder / repository.</p>
<p dir="auto">Provides a makefile with different targets to run.</p>
<p dir="auto">Implemented in bash with a makefile wrapper.</p>
<p dir="auto">Performs linting (<code>make lint</code>), tests (<code>make test</code>) or everything (<code>make all</code>).</p>
<p dir="auto">In addition to standard checks, also validates indentation and optionally <a href="#elsa">elsa</a> checks.</p>
<p dir="auto">Supports both ERT and buttercup tests.</p>
<p dir="auto">One drawback is that this makem.sh sources have to be dropped in each of your package source repository.</p>
<p dir="auto">Provides recipes for integration with <i>GitHub actions</i>.</p>
<h4 tabindex="-1" dir="auto">makel</h4>
<p dir="auto"><a href="https://gitea.petton.fr/DamienCassou/makel" rel="nofollow">source &amp; doc</a></p>
<p dir="auto">Provides a makefile with different targets to run.</p>
<p dir="auto">Implemented completely as a makefile.</p>
<p dir="auto">Requires a bit of configuration for each package.</p>
<p dir="auto">One drawback is that this makel sources have to be dropped in each of your package source repository.</p>
<p dir="auto">No CI integration recipes.</p>
<h4 tabindex="-1" dir="auto">elisp-check</h4>
<p dir="auto"><a href="https://github.com/leotaku/elisp-check">source</a></p>
<p dir="auto">A zero config github action to validate packages.</p>
<h4 tabindex="-1" dir="auto">auto-compile</h4>
<p dir="auto"><a href="https://github.com/emacscollective/auto-compile">source</a></p>
<p dir="auto">Compiles current file on save and display compile errors/warnings in the mode-line.</p>
<h4 tabindex="-1" dir="auto">elisp-lint</h4>
<p dir="auto"><a href="https://github.com/gonewest818/elisp-lint">elisp-lint</a></p>
<p dir="auto">Performs standard validation of specified file. Also checks for indentation.</p>
<p dir="auto">No CI integration recipes.</p>
<h4 tabindex="-1" dir="auto">elsa</h4>
<p dir="auto"><a href="https://github.com/emacs-elsa/Elsa">source</a></p>
<p dir="auto">Static Elisp code analyzer providing helpful hints.</p>
<p dir="auto">Can be launched directly from <a href="#makem.sh">makem.sh</a>.</p>
<h4 tabindex="-1" dir="auto">package-lint</h4>
<p dir="auto"><a href="https://github.com/purcell/package-lint">source</a></p>
<p dir="auto">Lints Elisp files for requirements of packages. Can be integrated with flycheck (a general linter framework) by installing <a href="https://github.com/purcell/flycheck-package">flyspell-package</a>.</p>
<h2 tabindex="-1" dir="auto">Building</h2>
<p dir="auto">Those tools, in addition to what those in the <a href="#validation">Validation</a> section provide, are full-fledged build-definition tools, allowing to make complex CI/CD chains.</p>
<p dir="auto">They require a fair amount of configuration and are not for the faint of heart.</p>
<p dir="auto">They only seem necessary when building larger packages with exotic dependencies.</p>
<h4 tabindex="-1" dir="auto">Eldev</h4>
<p dir="auto"><a href="https://github.com/doublep/eldev">source &amp; doc</a></p>
<p dir="auto">Stands for /”Elisp Development Tool”/.</p>
<p dir="auto">Certainly the most modern of the lot.</p>
<p dir="auto">100% written in Elisp.</p>
<p dir="auto">One small drawback is that it does not run in a dedicated isolated Emacs process.</p>
<h4 tabindex="-1" dir="auto">cask</h4>
<p dir="auto"><a href="https://cask.readthedocs.io/en/latest/" rel="nofollow">doc</a>, <a href="https://github.com/cask/cask">source</a></p>
<p dir="auto">Pretty advanced and hard to get into.</p>
<p dir="auto">Implemented in python.</p>
<p dir="auto">Runs in a dedicated isolated Emacs process</p>
<h4 tabindex="-1" dir="auto">emake</h4>
<p dir="auto"><a href="https://github.com/vermiculus/emake.el">source &amp; doc</a></p>
<p dir="auto">The most simple to use from this list.</p>
<p dir="auto">Implemented in Elisp with a makefile wrapper.</p>
<p dir="auto">Easier to integrate with CI tools such as <i>Travis</i>.</p>
<h2 tabindex="-1" dir="auto">Syntax Highlighting &amp; Visual Enhancements</h2>
<p dir="auto">Several packages provide visual improvements and extend default syntax highlighting (<i>font locking</i> in Emacs lingo).</p>
<p dir="auto">All those listed bellow are complementary.</p>
<p dir="auto">Honorable mentions:</p>
<ul dir="auto">
  <li><a href="https://github.com/Fanael/highlight-defined">highlight-defined</a> which is superseded by <code>lisp-extra-font-lock</code> functionalities</li>
</ul>
<p dir="auto">Not Elisp-specific but commonly used in the context of Elisp development:</p>
<ul dir="auto">
  <li>traditionally, <i>form feed</i> characters (<code>^L</code>) are used in Elisp source as a section delimiters. Either <a href="https://github.com/purcell/page-break-lines">page-break-lines</a> or <a href="https://depp.brause.cc/form-feed/" rel="nofollow">form-feed</a> can be used to display them as intended.</li>
  <li>for those that can barely stand parentheses, <a href="https://github.com/tarsius/paren-face">paren-face</a> can be used to dim them in Lisp-based modes</li>
  <li>for those that love parentheses, <a href="https://github.com/Fanael/rainbow-delimiters">rainbow-delimiters</a> allows displaying them in different colors depending on their nesting depth</li>
</ul>
<h3 tabindex="-1" dir="auto">lisp-extra-font-lock</h3>
<p dir="auto"><a href="https://github.com/Lindydancer/lisp-extra-font-lock">source &amp; doc</a></p>
<p dir="auto">Various additional syntax highlightings.</p>
<p dir="auto">Killer feature is having different faces for <i>special</i> vars (global) VS <i>normal</i> ones (local).</p>
<h3 tabindex="-1" dir="auto">highlight-function-calls</h3>
<p dir="auto"><a href="https://github.com/alphapapa/highlight-function-calls">source &amp; doc</a></p>
<p dir="auto">Make functions calls stand out with a specific face.</p>
<h3 tabindex="-1" dir="auto">cl-lib-highlight</h3>
<p dir="auto"><a href="https://github.com/skeeto/cl-lib-highlight">source &amp; doc</a></p>
<p dir="auto">Provides additional / alternative font-locking for <code>cl-lib</code> symbols, to make them stand out in your code.</p>
<p dir="auto">Also highlights deprecated <code>cl</code> symbols with a different face. Useful when reading legacy code.</p>
<h3 tabindex="-1" dir="auto">easy-escape</h3>
<p dir="auto"><a href="https://github.com/cpitclaudel/easy-escape">source &amp; doc</a></p>
<p dir="auto">Make regular expression strings more readable.</p>
<h3 tabindex="-1" dir="auto">nameless</h3>
<p dir="auto"><a href="https://github.com/Malabarba/Nameless">source &amp; doc</a></p>
<p dir="auto">Hide prefix in symbols of a package.</p>
<h2 tabindex="-1" dir="auto">Pretty Printing</h2>
<h4 tabindex="-1" dir="auto">pp</h4>
<p dir="auto"><a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/emacs-lisp/pp.el">source</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Standard Emacs pretty-printing util.</p>
<h4 tabindex="-1" dir="auto">ppp</h4>
<p dir="auto"><a href="https://github.com/conao3/ppp.el">source &amp; doc</a></p>
<p dir="auto">Advanced pretty-printing utils.</p>
<h2 tabindex="-1" dir="auto">Libraries</h2>
<p dir="auto">Traditionally, it was recommended to not use external libs/dependencies and prefer using standard APIs bundled with Emacs.</p>
<p dir="auto">These recommendation are still mostly valid but predated the advent of <code>package.el</code>.</p>
<p dir="auto">Some external libs are now considered “standard”, as lots of popular packages use them and they can outperform standard implementations while still being simpler to use (e.g. <code>dash</code>).</p>
<p dir="auto">Some libraries might be listed several times, as they fit in several categories (e.g. <code>subr-x</code>, <code>dash</code>).</p>
<h2 tabindex="-1" dir="auto">Core / General Purpose</h2>
<h4 tabindex="-1" dir="auto">cl-lib</h4>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Lib extending Elisp with functionalities inherited from Common Lisp. Replaces the deprecated <code>cl</code> package which did not use name prefixes. To help with updating the code from <code>cl</code> to <code>cl-lib</code> there is <a href="https://github.com/purcell/cl-libify">cl-libify</a>.</p>
<p dir="auto">Just do a <code>(require 'cl-lib)</code> to use it.</p>
<h4 tabindex="-1" dir="auto">subr-x</h4>
<p dir="auto"><a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/emacs-lisp/subr-x.el">source</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Intended as an extension to <a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/subr.el">subr.el</a>, the core library of basic functions written in Elisp.</p>
<p dir="auto">Provides:</p>
<ul dir="auto">
  <li>threading macros (<i>a la</i> Clojure, <code>thread-first</code> and <code>thread-last</code>)</li>
  <li>additional binding helpers (<code>if-let</code>, <code>if-let*</code>, <code>when-let</code>, <code>when-let*</code> and <code>and-let*</code>)    - hash-table manipulation helper (<code>hash-table-empty-p</code>, <code>hash-table-keys</code> and <code>hash-table-values</code>)</li>
  <li>string manipulation helper (<code>string-empty-p</code>, <code>string-blank-p</code>, <code>string-join</code>, <code>string-trim</code>, <code>string-trim-left</code>, <code>string-trim-right</code>, <code>string-remove-prefix</code> and <code>string-remove-suffix</code>)</li>
  <li>region manipulation helpers (<code>replace-region-contents</code>)</li>
</ul>
<h4 tabindex="-1" dir="auto">dash</h4>
<p dir="auto"><a href="https://github.com/magnars/dash.el">source &amp; doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/informal-standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/informal-standard.png" alt="./rsc/icon/informal-standard.png"></a></p>
<p dir="auto">Even though this lib revolves primarily around list manipulation, it also offers for general purpose utils.</p>
<p dir="auto">Those are:</p>
<ul dir="auto">
  <li><a href="https://github.com/magnars/dash.el#threading-macros">threading macros</a></li>
  <li><a href="https://github.com/magnars/dash.el#function-combinators">function combinators</a></li>
  <li><a href="https://github.com/magnars/dash.el#binding">additional binding helpers</a></li>
</ul>
<p dir="auto">They all seem to be heavily inspired by Clojure.</p>
<h4 tabindex="-1" dir="auto">el-patch</h4>
<p dir="auto"><a href="https://github.com/raxod502/el-patch">source and doc</a></p>
<p dir="auto">More perene advices, get notified when they break.</p>
<h4 tabindex="-1" dir="auto">anaphora</h4>
<p dir="auto"><a href="https://github.com/rolandwalker/anaphora">source &amp; doc</a></p>
<p dir="auto">Allows the definition of anaphoric functions (as can be found in Common Lisp, Clojure…).</p>
<h4 tabindex="-1" dir="auto">with-simulated-input</h4>
<p dir="auto"><a href="https://github.com/DarwinAwardWinner/with-simulated-input">source &amp; doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/informal-standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/informal-standard.png" alt="./rsc/icon/informal-standard.png"></a></p>
<p dir="auto">Simulate user interactions (i.e. launch <i>commands</i>).</p>
<p dir="auto">Mostly usefull for writing tests.</p>
<h4 tabindex="-1" dir="auto">dokey</h4>
<p dir="auto"><a href="https://github.com/ernstvanderlinden/emacs-dokey">source &amp; doc</a></p>
<p dir="auto">Trigger keyboard events.</p>
<h4 tabindex="-1" dir="auto">contract</h4>
<p dir="auto"><a href="https://github.com/langston-barrett/contract.el">source &amp; doc</a></p>
<p dir="auto">Provides data structure defintions as contracts (essentially interface description).</p>
<p dir="auto">Port of <a href="https://docs.racket-lang.org/reference/contracts.html" rel="nofollow">Racket’s contract</a> to Elisp.</p>
<p dir="auto">Akin to <a href="https://clojure.org/about/spec" rel="nofollow">Clojure’s spec</a>.</p>
<h4 tabindex="-1" dir="auto">signal</h4>
<p dir="auto"><a href="https://github.com/Mola-T/signal">source &amp; doc</a></p>
<p dir="auto">Reimplementation of hooks, with more advanced features.</p>
<h4 tabindex="-1" dir="auto">weak-ref</h4>
<p dir="auto"><a href="https://github.com/skeeto/elisp-weak-ref">source &amp; doc</a></p>
<p dir="auto">Allows creating weak reference to vars.
  Weak reference offer better performance but can be garbage collected.</p>
<h4 tabindex="-1" dir="auto">predd</h4>
<p dir="auto"><a href="https://github.com/skeeto/predd">source &amp; doc</a>, <a href="https://nullprogram.com/blog/2013/12/18/" rel="nofollow">blog post</a></p>
<p dir="auto">Provides Clojure-style <i>multimethods</i> (multiple dispatch over an ad hoc type hierarchy).</p>
<h4 tabindex="-1" dir="auto">cats</h4>
<p dir="auto"><a href="https://github.com/Fuco1/emacs-cats">source &amp; doc</a></p>
<p dir="auto">Provices Haskell-inspired Category Theory abstractions.</p>
<h4 tabindex="-1" dir="auto">fn</h4>
<p dir="auto"><a href="https://github.com/troyp/fn.el">source &amp; doc</a></p>
<p dir="auto">Provides macros for a more concise lambda syntax, <i>a la</i> Clojure.</p>
<h2 tabindex="-1" dir="auto">Data Structures</h2>
<h3 tabindex="-1" dir="auto">Strings</h3>
<h4 tabindex="-1" dir="auto">subr-x</h4>
<p dir="auto"><a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/emacs-lisp/subr-x.el">source</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Provide the following helpers: <code>string-empty-p</code>, <code>string-blank-p</code>, <code>string-join</code>, <code>string-trim</code>, <code>string-trim-left</code>, <code>string-trim-right</code>, <code>string-remove-prefix</code> and <code>string-remove-suffix</code>.</p>
<h4 tabindex="-1" dir="auto">s</h4>
<p dir="auto"><a href="https://github.com/magnars/s.el">source &amp; doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/informal-standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/informal-standard.png" alt="./rsc/icon/informal-standard.png"></a></p>
<p dir="auto">Advanced yet easy to use string manipulation helpers.</p>
<h4 tabindex="-1" dir="auto">rx</h4>
<p dir="auto"><a href="https://francismurillo.github.io/2017-03-30-Exploring-Emacs-rx-Macro/" rel="nofollow">tutorial</a>, <a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/emacs-lisp/rx.el">source</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Macro for helping writing Elisp regexp.</p>
<h4 tabindex="-1" dir="auto">xr</h4>
<p dir="auto"><a href="https://github.com/mattiase/xr">source &amp; doc</a></p>
<p dir="auto">Convert regexp to their more human-readable <code>rx</code> macro form.</p>
<p dir="auto">Also provides regexp linting, detecting mistakes and bad practices.</p>
<p dir="auto">Relies on its own internal <a href="#parsers--parse-trees">parser</a>.</p>
<h3 tabindex="-1" dir="auto">Sequences</h3>
<h4 tabindex="-1" dir="auto">seq</h4>
<p dir="auto"><a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/emacs-lisp/seq.el">source</a>, <a href="https://github.com/NicolasPetton/seq.el">doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a> (since version 25)</p>
<h4 tabindex="-1" dir="auto">dash</h4>
<p dir="auto"><a href="https://github.com/magnars/dash.el">source &amp; doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/informal-standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/informal-standard.png" alt="./rsc/icon/informal-standard.png"></a></p>
<p dir="auto">Advanced yet easy to use list manipulation helpers.
  Lots of them also have alternative anaphoric forms.</p>
<h4 tabindex="-1" dir="auto">stream</h4>
<p dir="auto"><a href="https://github.com/NicolasPetton/stream">source &amp; doc</a></p>
<p dir="auto">Allows defining streams of data as data sequences.
  Compatible w/ seq.el.</p>
<h4 tabindex="-1" dir="auto">trie</h4>
<p dir="auto"><a href="http://www.dr-qubit.org/predictive/trie.el" rel="nofollow">source</a></p>
<p dir="auto">Provides APIs for building and manipulating <i>tries</i>, sequence-like data structures where both storage and retrieval are space- and time-efficient.</p>
<p dir="auto">Stored elements must be ordered sequences, i.e. strings (most common use-case), lists or vectors.</p>
<h4 tabindex="-1" dir="auto">lister</h4>
<p dir="auto"><a href="https://github.com/publicimageltd/lister">source &amp; doc</a></p>
<p dir="auto">Provides <code>lister-mode</code>, major mode for building and manipulating list-based user-interfaces.</p>
<p dir="auto">Inspired by <code>tablist</code> (for tables) and <code>hierarchy</code> (for trees).</p>
<h3 tabindex="-1" dir="auto">Maps</h3>
<p dir="auto">(Hash)maps are a special type of sequences that allow representing a list of key / value pairs.
  In other languages they can also be called associative arrays or dictionaries.</p>
<p dir="auto">In Elisp, a map can be represented as:</p>
<ul dir="auto">
  <li>an <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Association-Lists.html" rel="nofollow">alist</a> (association list, preserving element order)</li>
  <li>a <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Property-Lists.html" rel="nofollow">plist</a> (property list, more human-readable)</li>
  <li>an <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Hash-Tables.html" rel="nofollow">hash-table</a></li>
</ul>
<table>
  <tbody><tr><th>data structure</th><th>human-readability</th><th>insert speed</th><th>lookup speed</th><th>ordered?</th></tr>
  <tr><td>alist</td><td>meh</td><td>fastest</td><td>slower as data grows</td><td>yes</td></tr>
  <tr><td>plist</td><td>very good</td><td>ok</td><td>fast</td><td>no</td></tr>
  <tr><td>hash-table</td><td>ok</td><td>ok</td><td>very fast</td><td>no</td></tr>
</tbody></table>
<p dir="auto">The official doc also has <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Plists-and-Alists.html" rel="nofollow">a nice section comparing plists and alists</a>.</p>
<p dir="auto">tl;dr:</p>
<ul dir="auto">
  <li>planning on doing lots of inserts and a few lookups (or mostly on recent elements), use an alist</li>
  <li>planning on having a big number of elements and lookup speed is critical, use an hash-map</li>
  <li>every other case, use a plist</li>
</ul>
<p dir="auto">Older Emacs packages tend to rely mostly on alists, sometimes for no good reason.</p>
<p dir="auto">Each data structure has its own APIs to get/insert/update.</p>
<p dir="auto">Thankfully, some libraries provide an abstraction layer that allows having a single API for multiple data structures.</p>
<p dir="auto">I would recommend sticking with the default <code>map.el</code> library, unless you really enjoy the Clojure syntax in which case <code>a.el</code> is also a nice choice.
  If you know for sure that you want to stick with an alist or a hash-table,  <code>asoc.el</code> and <code>ht</code> are high quality choices.</p>
<h4 tabindex="-1" dir="auto">map</h4>
<p dir="auto"><a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/emacs-lisp/map.el">source</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a> (since version 25)</p>
<p dir="auto">supports: alists, plists and hash-tables.</p>
<p dir="auto">Shared API for all 3 Elisp map objects (+ <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Arrays.html" rel="nofollow">arrays</a>).</p>
<p dir="auto">No documentation other than what is inlined in source.</p>
<h4 tabindex="-1" dir="auto">asoc</h4>
<p dir="auto"><a href="https://github.com/troyp/asoc.el">source &amp; doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/informal-standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/informal-standard.png" alt="./rsc/icon/informal-standard.png"></a></p>
<p dir="auto">supports: only alists.</p>
<p dir="auto">Nice set of additional APIs for alists.</p>
<h4 tabindex="-1" dir="auto">ht</h4>
<p dir="auto"><a href="https://github.com/Wilfred/ht.el">source &amp; doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/informal-standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/informal-standard.png" alt="./rsc/icon/informal-standard.png"></a></p>
<p dir="auto">supports: only hash-tables, but allow converting from/to alists and plists.</p>
<p dir="auto">Nice set of additional APIs for hash-tables.</p>
<h4 tabindex="-1" dir="auto">a</h4>
<p dir="auto"><a href="https://github.com/plexus/a.el">source &amp; doc</a></p>
<p dir="auto">supports: alists and hash-tables.</p>
<p dir="auto">Shared API for alists and hash-tables.
  Like <code>map.el</code>, but in a more “Clojurey” syntax.</p>
<h4 tabindex="-1" dir="auto">kv</h4>
<p dir="auto"><a href="https://github.com/nicferrier/emacs-kv">source &amp; doc</a></p>
<p dir="auto">support: mostly alists, but allow converting from/to alists and plists.</p>
<h4 tabindex="-1" dir="auto">dict-tree</h4>
<p dir="auto"><a href="http://www.dr-qubit.org/predictive/dict-tree.el" rel="nofollow">source</a></p>
<p dir="auto">Provides APIs for building and manipulating <i>Dictionary trees</i>, hybrid between <a href="#trie">tries</a> and hash tables.</p>
<p dir="auto">Think about it as a more storage-efficient hash tables.</p>
<h3 tabindex="-1" dir="auto">Custom Types &amp; OOP</h3>
<p dir="auto">Can be done natively using <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Records.html#Records" rel="nofollow">records</a>, additional custom user-defined types.</p>
<h4 tabindex="-1" dir="auto">cl-lib (defstruct API)</h4>
<p dir="auto"><a href="https://www.gnu.org/software/emacs/manual/html_node/cl/Structures.html" rel="nofollow">API documentation</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">One part of <code>cl-lib</code> is APIs to define and manipulate C-like data structures, strongly typed.</p>
<p dir="auto">Provides the <code>cl-defstruct</code> macro.</p>
<p dir="auto">Built on top of the native <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Records.html#Records" rel="nofollow">records</a> system.</p>
<p dir="auto">See also this blog post from @skeeto: <a href="https://nullprogram.com/blog/2018/02/14/" rel="nofollow">Options for Structured Data in Emacs Lisp</a></p>
<h4 tabindex="-1" dir="auto">EIEIO</h4>
<p dir="auto"><a href="https://www.gnu.org/software/emacs/manual/html_mono/eieio.html" rel="nofollow">doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Stands for <i>Enhanced Implementation of Emacs Interpreted Objects</i>.</p>
<p dir="auto">Brings an OOP layer to Elisp, based upon the <i>Common Lisp Object System</i> (CLOS).</p>
<p dir="auto">Provides the <code>defclass</code> macro.</p>
<p dir="auto">Built on top of the native <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Records.html#Records" rel="nofollow">records</a> system.</p>
<h3 tabindex="-1" dir="auto">Date &amp; Time</h3>
<h4 tabindex="-1" dir="auto">ts</h4>
<p dir="auto"><a href="https://github.com/alphapapa/ts.el">source &amp; doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/informal-standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/informal-standard.png" alt="./rsc/icon/informal-standard.png"></a></p>
<p dir="auto">Advanced yet easy to use datetime / timestamp library.</p>
<h4 tabindex="-1" dir="auto">datetime</h4>
<p dir="auto"><a href="https://github.com/doublep/datetime">source &amp; doc</a></p>
<p dir="auto">Library for parsing, formatting, matching and recoding timestamps and date-time format strings.</p>
<h4 tabindex="-1" dir="auto">datetime-format</h4>
<p dir="auto"><a href="https://github.com/emacs-php/emacs-datetime">source &amp; doc</a></p>
<p dir="auto">Provides <code>datetime-format</code>, inspired by PHP’s <code>Datetime::format</code> method.</p>
<h3 tabindex="-1" dir="auto">Tables</h3>
<h4 tabindex="-1" dir="auto">tabulated-list</h4>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Library for defining, manipulating and displaying tables.</p>
<h4 tabindex="-1" dir="auto">tablist</h4>
<p dir="auto"><a href="https://github.com/politza/tablist">source &amp; doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/informal-standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/informal-standard.png" alt="./rsc/icon/informal-standard.png"></a></p>
<p dir="auto">Extension to <code>tabulated-list</code>, adding possibility to mark and filter items.</p>
<h4 tabindex="-1" dir="auto">navigel</h4>
<p dir="auto"><a href="https://github.com/DamienCassou/navigel">source</a></p>
<p dir="auto">Facilitate the creation of <code>tabulated-list</code>-based UIs.</p>
<p dir="auto">Also relies on <code>tablist</code>.</p>
<h4 tabindex="-1" dir="auto">gridlock</h4>
<p dir="auto"><a href="https://github.com/articuluxe/gridlock">source &amp; doc</a></p>
<p dir="auto">Provides <code>gridlock-mode</code>, major mode for building and manipulating spreadsheet-based user-interfaces</p>
<p dir="auto">Also provides <code>gridlock-csv-mode</code> and <code>gridlock-fix-mode</code> minor modes, backporting the API to CSV and FIX files.</p>
<h4 tabindex="-1" dir="auto">cell</h4>
<p dir="auto"><a href="http://xelf.me/cell.html" rel="nofollow">doc</a>, <a href="https://gitlab.com/dto/mosaic-el/blob/master/cell.el" rel="nofollow">source</a></p>
<p dir="auto">Provides <code>cell-mode</code>, major mode for building and manipulating spreadsheet-based user-interfaces.</p>
<h4 tabindex="-1" dir="auto">ctable</h4>
<p dir="auto"><a href="https://github.com/kiwanami/emacs-ctable">source &amp; doc</a></p>
<p dir="auto">Library for defining, manipulating and displaying tables.</p>
<h3 tabindex="-1" dir="auto">Queues</h3>
<h4 tabindex="-1" dir="auto">queue</h4>
<p dir="auto"><a href="http://www.dr-qubit.org/predictive/queue.el" rel="nofollow">source</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Provides FIFO / FILO queue APIs.</p>
<h4 tabindex="-1" dir="auto">fifo-class</h4>
<p dir="auto"><a href="https://github.com/mola-T/fifo-class">source &amp; doc</a></p>
<p dir="auto">An EIEIO abstract class class to provide FIFO methods to <i><a href="https://www.gnu.org/software/emacs/manual/html_node/eieio/Slot-Options.html" rel="nofollow">slots</a></i>.</p>
<h3 tabindex="-1" dir="auto">Rings</h3>
<p dir="auto">Even though <code>ring</code> is the standard implementation, some core libs use their own internal implementation (e.g. the <a href="https://www.gnu.org/software/emacs/manual/html_node/eintr/ring-file.html" rel="nofollow">kill-ring</a>).</p>
<h4 tabindex="-1" dir="auto">ring</h4>
<p dir="auto"><a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/emacs-lisp/ring.el">source</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Provides APIs to create and manipulate a ring data structure.</p>
<p dir="auto">Used by: <code>ERC</code></p>
<h4 tabindex="-1" dir="auto">dynaring</h4>
<p dir="auto"><a href="https://github.com/countvajhula/dynaring">source</a></p>
<p dir="auto">Similar to <code>ring</code>, but w/ a dynamic size.</p>
<h3 tabindex="-1" dir="auto">Trees</h3>
<p dir="auto">Escaped and nested S-exps is the most straightforward way to encode a tree in (E)lisp.</p>
<p dir="auto">Some libraries deliver higherèlevel data structure with manipulation functions for improved performance and convenience.</p>
<h4 tabindex="-1" dir="auto">heap</h4>
<p dir="auto"><a href="http://www.dr-qubit.org/predictive/heap.el" rel="nofollow">source</a></p>
<p dir="auto">Provides APIs to build and manipulate a <i>ternary</i> (at most 3 children per node) <i>heap</i> (self-sorting tree).</p>
<h4 tabindex="-1" dir="auto">avl-tree</h4>
<p dir="auto"><a href="http://www.dr-qubit.org/predictive/avl-tree.el" rel="nofollow">source</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Provides APIs to build and manipulate a self-balancing binary tree.</p>
<h4 tabindex="-1" dir="auto">hierarchy</h4>
<p dir="auto"><a href="https://github.com/DamienCassou/hierarchy">source &amp; doc</a>, <a href="https://emacs.cafe/emacs/guest-post/2017/06/26/hierarchy.html" rel="nofollow">blog post</a></p>
<p dir="auto">Allows defining trees as well as building user interfaces displaying them.</p>
<h4 tabindex="-1" dir="auto">treepy</h4>
<p dir="auto"><a href="https://github.com/volrath/treepy.el">source &amp; doc</a></p>
<p dir="auto">Allows defining and traversing trees.</p>
<h4 tabindex="-1" dir="auto">taxy</h4>
<p dir="auto"><a href="https://github.com/alphapapa/taxy.el">source &amp; doc</a></p>
<p dir="auto">Allows defining hierarchical taxonomies, i.e. trees w/ automatic classification based on (nested) rules.</p>
<h4 tabindex="-1" dir="auto">rbit</h4>
<p dir="auto"><a href="http://elpa.gnu.org/packages/rbit.html" rel="nofollow">source</a></p>
<p dir="auto">Self-balancing interval trees.</p>
<p dir="auto">Implementation of Chris Okasaki’s algorithm from <a href="https://dl.acm.org/citation.cfm?id=968578.968583&amp;coll=DL&amp;dl=GUIDE" rel="nofollow">“Red-black trees in a functional setting”, JFP’99</a>.</p>
<h4 tabindex="-1" dir="auto">pair-tree</h4>
<p dir="auto"><a href="https://github.com/zainab-ali/pair-tree.el">source &amp; doc</a></p>
<p dir="auto">Visualize and explore nested S-exps as a tree.</p>
<h3 tabindex="-1" dir="auto">Parsers &amp; Parse Trees</h3>
<p dir="auto">Those libraries allow parsing a document in a format / language and converting it to an tree, called an an <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree" rel="nofollow">AST</a>.</p>
<h4 tabindex="-1" dir="auto">parse-it</h4>
<p dir="auto"><a href="https://github.com/jcs-elpa/parse-it">source &amp; doc</a></p>
<p dir="auto">Regexp-based parser, supporting a bunch of languages.</p>
<h4 tabindex="-1" dir="auto">tree-sitter</h4>
<p dir="auto"><a href="https://ubolonton.github.io/emacs-tree-sitter/" rel="nofollow">doc</a>, <a href="https://github.com/ubolonton/emacs-tree-sitter/">source</a>, <a href="https://www.reddit.com/r/emacs/comments/chnxzm/dynamic_module_binding_for_treesitter_an/" rel="nofollow">reddit post</a>, <a href="https://blog.meain.io/2022/more-treesitter-emacs/" rel="nofollow">example usage article</a></p>
<p dir="auto">Implemented as a module, binding with the <a href="https://tree-sitter.github.io/tree-sitter/" rel="nofollow">tree-sitter</a> parser (written in Rust).</p>
<p dir="auto">For a concrete use-case, have a look at <a href="https://github.com/ethan-leba/tree-edit">tree-edit</a>.</p>
<p dir="auto">For a better sitter grammar for elisp (distinguishing between var, functions and macros), use <a href="https://github.com/Wilfred/tree-sitter-elisp">tree-sitter-elisp</a>.</p>
<h4 tabindex="-1" dir="auto">moldable-emacs</h4>
<p dir="auto"><a href="https://github.com/ag91/moldable-emacs">source &amp; doc</a>, <a href="https://github.com/p3r7/awesome-elisp/blob/master/Moldable%20Emacs,%20a%20step%20towards%20sustainable%20software">presentation @ EmacsConf21</a></p>
<p dir="auto">Powerful parser and transformer library, relying on the concept of composable functional <b>molds</b>.</p>
<p dir="auto">Also support asynchronous processing (relying on <a href="#async">async</a>).</p>
<h4 tabindex="-1" dir="auto">tNFA</h4>
<p dir="auto"><a href="http://www.dr-qubit.org/predictive/tNFA.el" rel="nofollow">source</a></p>
<p dir="auto">Provides APIs to build and manipulate NFA (<i>Nondeterministic Finite Automaton</i>), i.e. a state machine / decision tree.</p>
<p dir="auto">It was built manily with regexp parsing in mind.</p>
<h4 tabindex="-1" dir="auto">parsec</h4>
<p dir="auto"><a href="https://github.com/cute-jumper/parsec.el">source &amp; doc</a></p>
<p dir="auto">Parsing library in the spirit of Haskell’s parsec.</p>
<h4 tabindex="-1" dir="auto">pl</h4>
<p dir="auto"><a href="https://github.com/jwiegley/emacs-pl">source &amp; doc</a></p>
<p dir="auto">Parsing library in the spirit of Haskell’s parsec. Somewhat limited.</p>
<h3 tabindex="-1" dir="auto">XML/HTML</h3>
<h4 tabindex="-1" dir="auto">dom</h4>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">DOM manipulation and searching functions.</p>
<h4 tabindex="-1" dir="auto">xml-query</h4>
<p dir="auto"><a href="https://github.com/skeeto/elfeed/blob/master/xml-query.el">source</a></p>
<p dir="auto">List-based XML selectors. Part of the elfeed package.</p>
<h3 tabindex="-1" dir="auto">Org-mode outlines</h3>
<p dir="auto"><code>org-mode</code> outlines (<a href="https://orgmode.org/worg/dev/org-syntax.html" rel="nofollow">spec</a>) can be considered both a file format and a tree format.</p>
<h4 tabindex="-1" dir="auto">org-element</h4>
<p dir="auto"><a href="https://code.orgmode.org/bzg/org-mode/src/master/lisp/org-element.el" rel="nofollow">source</a>, <a href="https://orgmode.org/worg/dev/org-element-api.html" rel="nofollow">doc</a>, <a href="http://ergoemacs.org/emacs/elisp_parse_org_mode.html" rel="nofollow">tutorial on ergoemacs</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto"><code>org-mode</code>’s internal parser, used to convert a text buffer into a tree structure (<i>parse-tree</i>).</p>
<h4 tabindex="-1" dir="auto">org-ml</h4>
<p dir="auto"><a href="https://github.com/ndwarshuis/org-ml">source &amp; doc</a></p>
<p dir="auto">Functional manipulation of an org parse-tree.</p>
<h4 tabindex="-1" dir="auto">org-ql</h4>
<p dir="auto"><a href="https://github.com/alphapapa/org-ql">source &amp; doc</a></p>
<p dir="auto">Query language (<a href="https://en.wikipedia.org/wiki/Domain-specific_language" rel="nofollow">DSL</a>) for parsing, searching and filtering an org outline.</p>
<h4 tabindex="-1" dir="auto">org-ba</h4>
<p dir="auto"><a href="https://github.com/Fuco1/orgba">source &amp; doc</a></p>
<p dir="auto">More user-friendly APIs for writting code for interacting with org documents.</p>
<h3 tabindex="-1" dir="auto">Faces</h3>
<p dir="auto"><i>Faces</i> are a group of attributes controlling the formatting of text in Emacs.</p>
<p dir="auto">It’s akin to CSS for HTML or styling <a href="https://en.wikipedia.org/wiki/ANSI_escape_code" rel="nofollow">ANSI escape sequences</a> for terminal text.</p>
<p dir="auto">You can read more about <i>faces</i> in the <a href="https://www.gnu.org/software/emacs/manual/html_node/emacs/Faces.html" rel="nofollow">Emacs manual</a> or the <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Faces.html" rel="nofollow">Emacs Lisp Reference Manual</a>.</p>
<h4 tabindex="-1" dir="auto">engrave-faces</h4>
<p dir="auto"><a href="https://github.com/tecosaur/engrave-faces">source &amp; doc</a></p>
<p dir="auto">Convert faces to other formats.</p>
<p dir="auto">Currently, only LaTeX is supported.</p>
<h3 tabindex="-1" dir="auto">Color Codes</h3>
<h4 tabindex="-1" dir="auto">color</h4>
<p dir="auto"><a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/color.el">source</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<h4 tabindex="-1" dir="auto">color-tools</h4>
<p dir="auto"><a href="https://github.com/neeasade/color-tools.el">source &amp; doc</a>, <a href="https://notes.neeasade.net/color-spaces.html" rel="nofollow">blog post</a></p>
<p dir="auto">Color codes manipulation, with support for various color spaces.</p>
<h4 tabindex="-1" dir="auto">yk-color</h4>
<p dir="auto"><a href="https://github.com/yurikhan/yk-color">source</a></p>
<p dir="auto">Color codes manipulation.</p>
<h2 tabindex="-1" dir="auto">Concurrency / Asynchronicity</h2>
<p dir="auto">Concurrency in Elisp / Emacs is a hot topic.</p>
<p dir="auto">Due to its single-threaded nature, we can’t do parallel processing unless using some dirty tricks (see <a href="#async">async</a>).</p>
<p dir="auto">But that doesn’t prevent us from doing concurrent processing, with say <i>timers</i>.</p>
<p dir="auto">Emacs recently extended this support with <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Generators.html" rel="nofollow">generators</a> (since 25.1) and <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Threads.html" rel="nofollow">native threads</a> (not what you might be thinking of, since 26.1).</p>
<p dir="auto">For more info on those subject, read:</p>
<ul dir="auto">
  <li><a href="https://www.emacswiki.org/emacs/NoThreading" rel="nofollow">emacswiki/No Threading</a></li>
  <li><a href="https://www.emacswiki.org/emacs/NoThreading" rel="nofollow">emacswiki/Concurrent Emacs</a></li>
  <li>blog post from @skeeto: <a href="https://nullprogram.com/blog/2018/05/31/" rel="nofollow">Emacs 26 Brings Generators and Threads</a></li>
</ul>
<h3 tabindex="-1" dir="auto">Timers</h3>
<h4 tabindex="-1" dir="auto">timer</h4>
<p dir="auto"><a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/emacs-lisp/timer.el">source</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Default timer lib.</p>
<h4 tabindex="-1" dir="auto">named-timer</h4>
<p dir="auto"><a href="https://github.com/DarwinAwardWinner/emacs-named-timer">source &amp; doc</a></p>
<p dir="auto">Easier to use timer lib.</p>
<h3 tabindex="-1" dir="auto">Promises &amp; Delays</h3>
<h4 tabindex="-1" dir="auto">thunk.el</h4>
<p dir="auto"><a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/emacs-lisp/thunk.el">source</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Provides an API for creating and dereferencing / evaluating <i>delays</i>.</p>
<h4 tabindex="-1" dir="auto">promise.el</h4>
<p dir="auto"><a href="https://github.com/chuntaro/emacs-promise">source &amp; doc</a></p>
<p dir="auto">Reimplementation of the <a href="https://promisesaplus.com/" rel="nofollow">Promises/A+</a> open standard (originally targeting Javascript).</p>
<h4 tabindex="-1" dir="auto">aio</h4>
<p dir="auto"><a href="https://github.com/skeeto/emacs-aio">source &amp; doc</a>, <a href="https://nullprogram.com/blog/2019/03/10/" rel="nofollow">blog post</a></p>
<p dir="auto">Mostly an async/await lib but implements its own promise system internally.</p>
<h3 tabindex="-1" dir="auto">Async Elisp function calls</h3>
<h4 tabindex="-1" dir="auto">deferred</h4>
<p dir="auto"><a href="https://github.com/kiwanami/emacs-deferred">source &amp; doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/informal-standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/informal-standard.png" alt="./rsc/icon/informal-standard.png"></a></p>
<p dir="auto">Not super-actively maintained, but quite stable and featureful.</p>
<p dir="auto">Achieves concurrency through the use of timers.</p>
<p dir="auto">Also allows handling async (sub-)processes and HTTP calls with <a href="https://github.com/tkf/emacs-request">request.el bindings</a>.</p>
<h4 tabindex="-1" dir="auto">concurrent</h4>
<p dir="auto"><a href="https://github.com/kiwanami/emacs-deferred/blob/master/concurrent.el">source</a>, <a href="https://github.com/kiwanami/emacs-deferred/blob/master/README-concurrent.markdown">doc</a></p>
<p dir="auto">Higher-level wrapper around <code>deferred</code>.</p>
<p dir="auto">Provides various syntaxes inspired by those of other programming languages, such as:</p>
<ul dir="auto">
  <li>Clojure / Java / Lua’s coroutines (<code>threads</code>)</li>
  <li>Python’s asyncio coroutines (<code>generators</code>)</li>
  <li>Clojure’s <a href="https://github.com/clojure/core.async">core.async</a> pipelines (<code>signals</code> / <code>channels</code>).</li>
</ul>
<h4 tabindex="-1" dir="auto">async</h4>
<p dir="auto"><a href="https://github.com/jwiegley/emacs-async">source &amp; doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/informal-standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/informal-standard.png" alt="./rsc/icon/informal-standard.png"></a></p>
<p dir="auto">Achieves true parallel processing by spawning a child Emacs sub-process.
  As such, necessary context needs to be passed w/ <code>async-inject-variables</code>.</p>
<p dir="auto">Supports defining callbacks.</p>
<p dir="auto">Offers bindings w/ <code>dired</code>, <code>bytecomp</code> and <code>smtp-mail</code>.</p>
<h4 tabindex="-1" dir="auto">timp</h4>
<p dir="auto"><a href="https://github.com/mola-T/timp">source &amp; doc</a></p>
<p dir="auto">Multithreading through sub-processes with over-the-wire payload capabilities.</p>
<p dir="auto">Achieves true parallel processing by spawning a child Emacs sub-process for each thread.</p>
<h4 tabindex="-1" dir="auto">aio</h4>
<p dir="auto"><a href="https://github.com/skeeto/emacs-aio">source &amp; doc</a>, <a href="https://nullprogram.com/blog/2019/03/10/" rel="nofollow">blog post</a></p>
<p dir="auto">Short for <code>async-io</code>.</p>
<p dir="auto">Allows writing coroutines with the async/await syntax found in Python’s <a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow">asyncio</a>.</p>
<p dir="auto">Internal representation relies on its own promise implementation and <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Generators.html" rel="nofollow">generators</a>.</p>
<h4 tabindex="-1" dir="auto">async-await</h4>
<p dir="auto"><a href="https://github.com/chuntaro/emacs-async-await">source &amp; doc</a></p>
<p dir="auto">Simple implementation of Async/Await, based on the TypeScript syntax.</p>
<p dir="auto">Relies on <code>promise.el</code> and <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Generators.html" rel="nofollow">generators</a>.</p>
<h4 tabindex="-1" dir="auto">lcr</h4>
<p dir="auto"><a href="https://github.com/jyp/lcr">source</a></p>
<p dir="auto">lcr stands for Lightweight CoRoutines.</p>
<p dir="auto">Seems to rely on timers.</p>
<h3 tabindex="-1" dir="auto">Async sub-processes</h3>
<p dir="auto">These libs only allow to run asynchronously command processes (as opposed to Elisp function calls).</p>
<p dir="auto">It can be done in standard with low-level function <code>make-process</code> or derivatives <code>start-process</code>, <code>make-pipe-process</code> and <code>start-process-shell-command</code>.</p>
<p dir="auto">Some advanced behaviours are hard to program, that’s why wrapper libraries can help you.</p>
<p dir="auto">Notably:</p>
<ul dir="auto">
  <li>ensuring the process is launched asynchronously (not blocking Emacs)</li>
  <li>configuring callbacks (by binding a <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Sentinels.html" rel="nofollow">sentinel</a> to the process)</li>
</ul>
<h4 tabindex="-1" dir="auto">deferred</h4>
<p dir="auto"><a href="https://github.com/kiwanami/emacs-deferred">source &amp; doc</a></p>
<p dir="auto">Not super-actively maintained, but featureful.</p>
<p dir="auto">Also allows handling async Elisp function calls and HTTP calls with <a href="https://github.com/tkf/emacs-request">request.el bindings</a>.</p>
<h4 tabindex="-1" dir="auto">bpr</h4>
<p dir="auto"><a href="https://github.com/ilya-babanov/emacs-bpr">source &amp; doc</a></p>
<p dir="auto">Stands for Background Process Runner.
  Allows running a command process in the background.</p>
<p dir="auto">Allows advanced callback behaviours.</p>
<p dir="auto">It relies on <code>start-process-shell-command</code>.</p>
<h4 tabindex="-1" dir="auto">pfuture</h4>
<p dir="auto"><a href="https://github.com/Alexander-Miller/pfuture">source &amp; doc</a></p>
<p dir="auto">Allows running a command process in the background.</p>
<p dir="auto">Result can be handled either with a future (<code>pfuture-new</code>, <code>pfuture-result</code>) or a callback (<code>pfuture-callback</code>).</p>
<p dir="auto">It relies on <code>make-pipe-process</code> for the future-based implementation and <code>make-process</code> for the callback one.</p>
<h3 tabindex="-1" dir="auto">Async interpreter commands</h3>
<p dir="auto">Emacs provides a layer on top of <code>make-process</code> for spawning commands from a shell interpreter (i.e. <code>bash</code> or <code>zsh</code>).</p>
<p dir="auto">These are provided by <code>simple.el</code> (<a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/simple.el">source</a>).</p>
<p dir="auto">The async version of these command is <code>async-shell-command</code>.</p>
<p dir="auto">Some advanced behaviours are hard to program, that’s why wrapper libraries can help you.</p>
<h4 tabindex="-1" dir="auto">dtache</h4>
<p dir="auto"><a href="https://gitlab.com/niklaseklund/dtache" rel="nofollow">source &amp; doc</a></p>
<p dir="auto">Provides <code>dtache-shell-command</code>, a drop-in replacement for <code>async-shell-command</code> that allows command execution to persist even after the Emacs process exits.</p>
<p dir="auto">Also works on remote hosts.</p>
<p dir="auto">Relies on <a href="https://github.com/crigler/dtach">dtach</a> to create a persistent session.</p>
<h4 tabindex="-1" dir="auto">friendly-shell-command</h4>
<p dir="auto"><a href="https://github.com/p3r7/friendly-shell">source &amp; doc</a></p>
<p dir="auto"><code>friendly-shell-command</code> provides <code>friendly-shell-command-async</code>, a wrapper around <code>async-shell-command</code> with easier access to advanced behaviours thanks to optional keyword arguments.</p>
<p dir="auto">It notably eases associating a callback to the end of the execution, running on remote hosts and launching with alternative interpreters.</p>
<h2 tabindex="-1" dir="auto">Buffer Manipulation</h2>
<h4 tabindex="-1" dir="auto">b</h4>
<p dir="auto"><a href="https://github.com/emacs-php/b.el">source &amp; doc</a></p>
<p dir="auto">Utility functions for buffer manipulation.</p>
<h4 tabindex="-1" dir="auto">tp</h4>
<p dir="auto"><a href="https://github.com/alphapapa/tp.el">source</a></p>
<p dir="auto">Utilities for helping with manipulating a buffer’s <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Text-Properties.html" rel="nofollow">text properties</a>.</p>
<h4 tabindex="-1" dir="auto">m-buffer</h4>
<p dir="auto"><a href="http://phillord.github.io/m-buffer-el/" rel="nofollow">doc</a>, <a href="https://github.com/phillord/m-buffer-el">source</a></p>
<p dir="auto">List-oriented functions for accessing and manipulating the contents of Emacs buffers.</p>
<h2 tabindex="-1" dir="auto">Filesystem Interactions</h2>
<h3 tabindex="-1" dir="auto">f</h3>
<p dir="auto"><a href="https://github.com/rejeep/f.el">source &amp; doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/informal-standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/informal-standard.png" alt="./rsc/icon/informal-standard.png"></a></p>
<p dir="auto">Modern API for working with files and directories.</p>
<h2 tabindex="-1" dir="auto">Networking</h2>
<h3 tabindex="-1" dir="auto">HTTP client</h3>
<p dir="auto">Emacs comes already with an HTTP client, <code>url.el</code>, written in pure Elisp (<a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/url/url.el">source</a>), which has a few limitations.
  It exposes functions <code>url-retrieve-synchronously</code> and <code>url-retrieve</code> (async).</p>
<h4 tabindex="-1" dir="auto">request</h4>
<p dir="auto"><a href="https://github.com/tkf/emacs-request">source &amp; doc</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/informal-standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/informal-standard.png" alt="./rsc/icon/informal-standard.png"></a></p>
<p dir="auto">If found on the system, uses the <i>cURL</i> binary instead of <code>url.el</code>.
  Can be customized with <code>request-backend</code>.</p>
<p dir="auto">Supports a bunch of options exposed clearly with keyword arguments.</p>
<p dir="auto">Advanced asynchronicity via bindings with <code>deferred</code>.</p>
<h4 tabindex="-1" dir="auto">plz</h4>
<p dir="auto"><a href="https://github.com/alphapapa/plz.el">source &amp; doc</a></p>
<p dir="auto">Uses the <i>cURL</i> binary (<code>curl</code>) instead of <code>url.el</code>.</p>
<p dir="auto">Supports a bunch of options exposed clearly with keyword arguments.</p>
<p dir="auto">Supports both synchronous &amp; asynchronous calls, as well as queuing.</p>
<p dir="auto">When doing async request, the returned handler is a <code>curl</code> process object.</p>
<p dir="auto">Strong contender for a lightweight alternative to <code>request</code>.</p>
<h4 tabindex="-1" dir="auto">mb-url</h4>
<p dir="auto"><a href="https://github.com/dochang/mb-url">source &amp; doc</a></p>
<p dir="auto">Stands for “Multiple Backends for URL package”.</p>
<p dir="auto">Provides API-compatible replacements to <code>url-retrieve</code> and <code>url-retrieve-synchronously</code> using <i>cURL</i> and <i>HTTPie</i>.</p>
<h4 tabindex="-1" dir="auto">websocket</h4>
<p dir="auto"><a href="https://github.com/ahyatt/emacs-websocket">source</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/informal-standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/informal-standard.png" alt="./rsc/icon/informal-standard.png"></a></p>
<p dir="auto">Websocket (peristent HTTP connection) client for Emacs.</p>
<h4 tabindex="-1" dir="auto">apiwrap</h4>
<p dir="auto"><a href="https://github.com/vermiculus/apiwrap.el">source &amp; doc</a></p>
<p dir="auto">Macros to ease the definition of binding functions to HTTP APIs.</p>
<h4 tabindex="-1" dir="auto">with-proxy</h4>
<p dir="auto"><a href="https://github.com/twlz0ne/with-proxy.el">source &amp; doc</a></p>
<p dir="auto">Wrapper for let-binding HTTP proxies.</p>
<h3 tabindex="-1" dir="auto">HTTP server</h3>
<h4 tabindex="-1" dir="auto">simple-httpd</h4>
<p dir="auto"><a href="https://github.com/skeeto/emacs-web-server">source &amp; doc</a></p>
<p dir="auto">A web server written in pure Elisp, serving HTTP.</p>
<h4 tabindex="-1" dir="auto">web-server</h4>
<p dir="auto"><a href="https://github.com/eschulte/emacs-web-server">source &amp; doc</a></p>
<p dir="auto">A web server written in pure Elisp, serving HTTP APIs bound to Elisp functions (<i>handlers</i>).</p>
<h3 tabindex="-1" dir="auto">RPC server</h3>
<p dir="auto">A <a href="https://en.wikipedia.org/wiki/Remote_procedure_call" rel="nofollow">Remote Procedure Call</a> server allows Emacs to receive commands from a remote process through a messaging system.</p>
<p dir="auto">It’s a common strategy of <a href="https://en.wikipedia.org/wiki/Inter-process_communication" rel="nofollow">inter-process communication</a> (IPC).</p>
<h4 tabindex="-1" dir="auto">porthole</h4>
<p dir="auto"><a href="https://github.com/jcaw/porthole">source &amp; doc</a></p>
<p dir="auto">Start a HTTP-based RPC server under Emacs.</p>
<p dir="auto">Commands are direct Elisp code to be executed. They can (by default) only be called synchronously.</p>
<p dir="auto">Messages are encoded in JSON (following the <a href="https://www.jsonrpc.org/specification" rel="nofollow">JSON-RPC 2.0 Specification</a>) which makes it support client libraries of almost any language.</p>
<p dir="auto">Relies on <code>web-server</code>.</p>
<h4 tabindex="-1" dir="auto">EPC</h4>
<p dir="auto"><a href="https://github.com/kiwanami/emacs-epc">source &amp; doc</a></p>
<p dir="auto">Start a RPC client &amp; server under Emacs.</p>
<p dir="auto">It implements its own protocol (over TCP) and support both synchronous &amp; asynchronous execution (via bindings with <code>deferred</code>).</p>
<p dir="auto">Commands are explicitly defined (akin to handlers bound to <i>routes</i> in an HTTP API).</p>
<p dir="auto">Messages are encoded as Lisp / S-exprs, which makes it more challenging to implement client libraries in non-Lisp languages.</p>
<h3 tabindex="-1" dir="auto">D-Bus</h3>
<p dir="auto">D-Bus is the most popular <a href="https://en.wikipedia.org/wiki/Inter-process_communication" rel="nofollow">inter-process communication</a> (IPC) protocol under Linux.</p>
<p dir="auto">Emacs supports it by default.</p>
<h4 tabindex="-1" dir="auto">dbus</h4>
<p dir="auto"><a href="https://www.gnu.org/software/emacs/manual/html_mono/dbus.html" rel="nofollow">doc</a>, <a href="https://github.com/emacs-mirror/emacs/blob/master/lisp/net/dbus.el">source</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto">Very boilerplate-y to use.</p>
<h4 tabindex="-1" dir="auto">debase</h4>
<p dir="auto"><a href="https://github.com/ieure/debase">source &amp; doc</a></p>
<p dir="auto">EIEIO abstractions over <code>dbus</code> for writting easier interaction code.</p>
<h2 tabindex="-1" dir="auto">Database Access</h2>
<h3 tabindex="-1" dir="auto">SQL</h3>
<h4 tabindex="-1" dir="auto">sql</h4>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<p dir="auto"><a href="https://repo.or.cz/w/emacs.git/blob/HEAD:/lisp/progmodes/sql.el" rel="nofollow">source</a>, <a href="https://www.emacswiki.org/emacs/SqlMode" rel="nofollow">emacswiki</a></p>
<p dir="auto">Not a client <i>per se</i>.</p>
<p dir="auto">Provides <code>sql-mode</code>, a comint-based REPL wrapper supporting various CLI client interpreters.</p>
<h4 tabindex="-1" dir="auto">sqlite</h4>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a> (since version 29)</p>
<p dir="auto">Recent Emacs now embbeds a native SQLite3 database &amp; the accompagnying client.</p>
<h4 tabindex="-1" dir="auto">emacsql</h4>
<p dir="auto"><a href="https://github.com/skeeto/emacsql">source &amp; doc</a></p>
<p dir="auto">High-level client to SQLite, PostgreSQL &amp; MySQL.</p>
<p dir="auto">Queries and schema definitions are written in specific tree-based DSLs, allowing easy programmatic manipulation.</p>
<h4 tabindex="-1" dir="auto">closql</h4>
<p dir="auto"><a href="https://github.com/emacscollective/closql">source</a></p>
<p dir="auto"><a href="https://en.wikipedia.org/wiki/Object%E2%80%93relational_mapping" rel="nofollow">ORM</a> providing mapping between <a href="#eieio">EIEIO</a> and SQLite tables.</p>
<p dir="auto">Relies on <code>emacsql</code>.</p>
<h4 tabindex="-1" dir="auto">edbi</h4>
<p dir="auto"><a href="https://github.com/kiwanami/emacs-edbi">source &amp; doc</a></p>
<p dir="auto">Client to SQL dialects, using <a href="https://dbi.perl.org/" rel="nofollow">Perl’s Database Interface</a> (<i>DBI</i>) as a connection interface.</p>
<p dir="auto">In addition to programmatic querying capabilities, provides several major modes for user interactions with database instances.</p>
<h4 tabindex="-1" dir="auto">triples</h4>
<p dir="auto"><a href="https://github.com/ahyatt/triples">source &amp; doc</a></p>
<p dir="auto">Abstraction on top of SQL clients (either <code>emacsql</code> or <code>sqlite</code>) to represent &amp; store a graph database.</p>
<h2 tabindex="-1" dir="auto">GUI</h2>
<p dir="auto">Honorable mention: <a href="https://github.com/sabof/magic-buffer">magic-buffer</a>, an executable cookbook on how to use &amp; abuse Emacs’ buffer display engine.</p>
<h3 tabindex="-1" dir="auto">Popups</h3>
<h4 tabindex="-1" dir="auto">frog-menu</h4>
<p dir="auto"><a href="https://github.com/clemera/frog-menu">source &amp; doc</a></p>
<p dir="auto">User selection menu in the form of a popup.</p>
<h3 tabindex="-1" dir="auto">Overlays</h3>
<h4 tabindex="-1" dir="auto">ov</h4>
<p dir="auto"><a href="https://github.com/emacsorphanage/ov">source &amp; doc</a></p>
<p dir="auto">Helpers to manipulate overlays.
  Originally authored by <a href="https://github.com/ShingoFukuyama">@ShingoFukuyama</a>. Unmaintained.</p>
<h3 tabindex="-1" dir="auto">Charts &amp; diagrams</h3>
<h4 tabindex="-1" dir="auto">chart</h4>
<p dir="auto"><a href="https://francismurillo.github.io/2017-04-15-Exploring-Emacs-chart-Library/" rel="nofollow">tutorial</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/p3r7/awesome-elisp/blob/master/rsc/icon/standard.png"><img src="https://github.com/p3r7/awesome-elisp/raw/master/rsc/icon/standard.png" alt="./rsc/icon/standard.png"></a></p>
<h2 tabindex="-1" dir="auto">Heroes</h2>
<p dir="auto">Emacs has too many heroes to really list.</p>
<p dir="auto">In this section, we list some users who have significantly contributed with libraries and resources that improve the Emacs development experience.</p>
<p dir="auto">They are listed in alphabetical order.</p>
<p dir="auto">Another complementary list is <a href="https://github.com/tarsius/elisp-maintainers">elisp-maintainers</a>.</p>
<h2 tabindex="-1" dir="auto">@alphapapa</h2>
<p dir="auto"><a href="https://github.com/alphapapa">github</a></p>
<p dir="auto">Contributed to Elisp development with:</p>
<ul dir="auto">
  <li><a href="https://github.com/alphapapa/emacs-package-dev-handbook">The Emacs Package Developer’s Handbook</a></li>
  <li><code>makem.sh</code></li>
  <li><code>ts</code></li>
  <li><code>plz</code></li>
  <li><code>org-ql</code></li>
</ul>
<h2 tabindex="-1" dir="auto">Bozhidar Batsov (@bbatsov)</h2>
<p dir="auto"><a href="https://github.com/bbatsov">github</a>, <a href="https://emacsredux.com/" rel="nofollow">Emacs-related blog</a>, <a href="https://github.com/sponsors/bbatsov">open to sponsoring</a></p>
<p dir="auto">Known for:</p>
<ul dir="auto">
  <li><a href="https://github.com/bbatsov/projectile">projectile</a>: the best project management package for Emacs</li>
  <li><a href="https://cider.mx/" rel="nofollow">CIDER</a>: the interactive Clojure development environment for Emacs</li>
</ul>
<p dir="auto">Contributed to Elisp development with:</p>
<ul dir="auto">
  <li><a href="https://github.com/bbatsov/emacs-lisp-style-guide">The Emacs Lisp Style Guide</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Caio Rordrigues (@caiorss)</h2>
<p dir="auto"><a href="https://github.com/caiorss">github</a></p>
<p dir="auto">Contributed to Elisp development with:</p>
<ul dir="auto">
  <li>his book <a href="http://caiorss.github.io/Emacs-Elisp-Programming/" rel="nofollow">Emacs In a Box</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Chris Wellons (@skeeto)</h2>
<p dir="auto"><a href="https://github.com/skeeto">github</a>, <a href="https://nullprogram.com/" rel="nofollow">blog</a></p>
<p dir="auto">Known for:</p>
<ul dir="auto">
  <li><a href="https://github.com/skeeto/elfeed">elfeed</a>, the popular Emacs RSS reader</li>
  <li><a href="https://github.com/skeeto/skewer-mode">skewer-mode</a>, interactive web development with auto-reload on edit</li>
</ul>
<p dir="auto">Contributed to Elisp development with:</p>
<ul dir="auto">
  <li>his blog, <i>nullprogram.com</i></li>
  <li><code>aio</code></li>
  <li><code>emacsql</code></li>
  <li><code>simple-httpd</code></li>
  <li><code>week-ref</code></li>
</ul>
<h2 tabindex="-1" dir="auto">John Wiegley (@jwiegley)</h2>
<p dir="auto"><a href="http://newartisans.com/" rel="nofollow">blog</a>, <a href="https://github.com/jwiegley">github</a>, <a href="https://github.com/jwiegley/dot-emacs/blob/master/init.el">dot emacs</a></p>
<p dir="auto">Known for:</p>
<ul dir="auto">
  <li>being the head of the Emacs project maintainers</li>
  <li>authoring <code>use-package</code></li>
</ul>
<p dir="auto">Contributed to Elisp development with:</p>
<ul dir="auto">
  <li><code>async.el</code></li>
  <li>talks on how to setup Emacs to ease Elisp development:
    <ul dir="auto">
      <li><a href="https://www.youtube.com/watch?v=QFClYrhV1z4" rel="nofollow">Emacs Lisp Development - @ Emacs Conference 2013</a></li>
      <li><a href="https://sachachua.com/blog/2015/04/2015-04-08-emacs-lisp-development-tips-with-john-wiegley/" rel="nofollow">Emacs Lisp Development Tips - Sacha Chua Emacs Chat 2015-04-08</a>.</li>
    </ul>
  </li>
</ul>
<h2 tabindex="-1" dir="auto">Jonas Bernoulli (@tarsius)</h2>
<p dir="auto"><a href="https://emacsair.me/" rel="nofollow">blog</a>, <a href="https://github.com/tarsius">github</a>, <a href="https://magit.vc/donate/" rel="nofollow">open to sponsoring</a></p>
<p dir="auto">Known for:</p>
<ul dir="auto">
  <li>authoring <a href="https://github.com/magit/magit">magit</a></li>
  <li>lots of high quality smaller packages (<a href="https://github.com/tarsius/orglink">orglink</a>, <a href="https://github.com/tarsius/keycast">keycast</a>…)</li>
</ul>
<p dir="auto">Contributed to Elisp development with:</p>
<ul dir="auto">
  <li><a href="https://github.com/magit/transient">transient</a></li>
  <li><code>closql</code></li>
</ul>
<h2 tabindex="-1" dir="auto">Magnar Sveen (@magnars)</h2>
<p dir="auto"><a href="https://github.com/magnars">github</a>, <a href="http://twitter.com/magnars" rel="nofollow">twitter</a></p>
<p dir="auto">Contributed to Elisp development with:</p>
<ul dir="auto">
  <li><a href="https://github.com/magnars/s.el">s</a> (strings)</li>
  <li><a href="https://github.com/magnars/dash.el">dash</a> (lists)</li>
</ul>
<h2 tabindex="-1" dir="auto">Nicolas Petton</h2>
<p dir="auto"><a href="https://nicolas.petton.fr/" rel="nofollow">portfolio</a>, <a href="https://emacs.cafe/" rel="nofollow">blog</a>, <a href="https://github.com/NicolasPetton">github</a></p>
<p dir="auto">Known for:</p>
<ul dir="auto">
  <li>creating the popular <a href="https://github.com/NicolasPetton/Indium">Indium</a> interactive Javascript development environment</li>
</ul>
<p dir="auto">Contributed to Elisp development with:</p>
<ul dir="auto">
  <li>creating the now standard <code>seq.el</code> and <code>map.el</code></li>
  <li><code>stream.el</code></li>
</ul>
<h2 tabindex="-1" dir="auto">Oleh Krehel (@abo-abo)</h2>
<p dir="auto"><a href="https://oremacs.com/" rel="nofollow">blog</a>, <a href="https://github.com/abo-abo">github</a>, <a href="https://github.com/sponsors/abo-abo">open to sponsoring</a></p>
<p dir="auto">Author of many high-quality packages such as <a href="https://github.com/abo-abo/swiper">ivy</a>, <a href="https://github.com/abo-abo/hydra">hydra</a>, <a href="https://github.com/abo-abo/lispy">lispy</a>…</p>
<h2 tabindex="-1" dir="auto">Toby ‘qubit’ Cubitt</h2>
<p dir="auto"><a href="http://www.dr-qubit.org/" rel="nofollow">website</a></p>
<p dir="auto">Known for:</p>
<ul dir="auto">
  <li><a href="http://www.dr-qubit.org/undo-tree/undo-tree.el" rel="nofollow">undo-tree</a></li>
</ul>
<p dir="auto">Contributed to Elisp development with <a href="http://www.dr-qubit.org/emacs_data-structures.html" rel="nofollow">his implementation of basic and more complex data structures</a>: <code>queue</code>, <code>heap</code>, <code>avl-tree</code>, <code>trie</code>, <code>dict-tree</code>, <code>tNFA</code>.</p>
<h2 tabindex="-1" dir="auto">Xah Lee</h2>
<p dir="auto"><a href="http://ergoemacs.org/emacs/emacs.html" rel="nofollow">website</a>, <a href="https://www.patreon.com/xahlee" rel="nofollow">open to sponsoring</a></p>
<p dir="auto">A controversial figure in the Emacs community (he is <a href="http://ergoemacs.org/emacs/_p/KickbanXahLeeFromEmacsChannel.htm" rel="nofollow">notorious for trolling</a>), Xah nethertheless created the first online digestible resource for learning Elisp.</p>
<p dir="auto">His contribution to the Emacs world is unquestionable and as such he deserves his place in this list.</p>
<h2 tabindex="-1" dir="auto">Contributing</h2>
<p dir="auto">Contributions and suggestions are always welcome!</p>
<p dir="auto">The <a href="https://github.com/p3r7">original author</a> made this document available as he felt something like it was missing.</p>
<p dir="auto">The idea is to have this evolve into a community effort, the initial version being only a baseline.</p>
<h2 tabindex="-1" dir="auto">Guidelines</h2>
<h3 tabindex="-1" dir="auto">PR and Issues</h3>
<p dir="auto">Open one issue or PR / subject matter.</p>
<p dir="auto">Don’t go submit a gazillion unrelated changes that would conflict with other’s submitted PRs.</p>
<h3 tabindex="-1" dir="auto">Opinions</h3>
<p dir="auto">Try to not be too opinionated.</p>
<p dir="auto">Some solutions are objectively better in some regards than others and that can be stated but don’t go launch a flame war.</p>
<p dir="auto">Descriptions of libraries and tools expressed in this document are always subject to change. If a description feels too negative, don’t hesitate to open an issue to discuss it.</p>
<h3 tabindex="-1" dir="auto">Scope</h3>
<p dir="auto">The aim of this document is to (loosely) follow the style of other <a href="https://github.com/sindresorhus/awesome">awesome lists</a>.</p>
<p dir="auto">Content should be concise and always follow the same format.</p>
<p dir="auto">In this spirit, no block quotes, no code snippets and no in-depth explanation of concepts should appear here.</p>
<p dir="auto">This is no cookbook, no manual, no article.</p>
<p dir="auto">Section can have small introduction to contextualize things (e.g. built-in libs) but should remain succinct, instead favoring links to external articles.</p>
<p dir="auto">The introduction of the <a href="#concurrency--asynchronicity">Concurrency / Asynchronicity</a> is a good example of concisely presenting the necessary information and linking to external resources.</p>
<p dir="auto">On the contrary, the <a href="#maps">Maps</a> section goes into too much details and should instead link to an article.</p>
<h4 tabindex="-1" dir="auto">Relevant Content: Development Tools</h4>
<p dir="auto">In <a href="#development-tools">Development Tools</a>, only list tools and package that are specific to Elisp development.</p>
<p dir="auto">It’s very tempting to list stuff such as <code>projectile</code> or <code>treemacs</code> but those packages apply not only to Elisp development and should not be listed.</p>
<p dir="auto">Don’t create a sub-section for tools that have modern counterpart and are deprecated / no more maintained. You could eventually mention them like it’s done for <code>highlight-defined</code> in <a href="#syntax-highlighting--visual-enhancements">Syntax Highlighting &amp; Visual Enhancements</a>.</p>
<h4 tabindex="-1" dir="auto">Relevant Content: Libraries</h4>
<p dir="auto">In <a href="#libraries">Libraries</a>, only list packages that were created to be used as libraries and generic enough to target a broad range of applications.</p>
<p dir="auto">E.g. HTTP client libs such as <code>request</code> have their place, wrappers targeting a specific API (such as <code>ghub</code> or <code>pocket-lib</code>) don’t.</p>
<h3 tabindex="-1" dir="auto">Comments</h3>
<p dir="auto">Each linked resource / tool / library should be commented.</p>
<p dir="auto">This comment is a short intro and analysis and must not be copy-pasted directly from the linked resource page.</p>
<p dir="auto">Instead it should provide insights as to how it compares to other links in a similar category: what are the differences, advantages, drawbacks.</p>
<p dir="auto">This description should be short and ideally not exceed a few lines.</p>
<h3 tabindex="-1" dir="auto">Order of Tools &amp; Libraries</h3>
<p dir="auto">Try to put the most “standard” entries first.</p>
<p dir="auto">By standard we mean, in order: embedded in Emacs, most sane or used by the most people / projects.</p>
<h3 tabindex="-1" dir="auto">Order of Categories</h3>
<p dir="auto">Don’t submit a PR single-handedly deciding to reorganize the whole document structure.</p>
<p dir="auto">Open an issue and provoke conversation.</p>
<p dir="auto">What can feel natural to you can be counter-intuitive to others.</p>
<h2 tabindex="-1" dir="auto">License &amp; Acknowledgments</h2>
<p dir="auto"><a href="https://creativecommons.org/publicdomain/zero/1.0/" rel="nofollow"><img src="https://camo.githubusercontent.com/9e918e1e7cd28a73246cf1c8d2c9903da3e487a65931c823a2391afe4b4a0d04/68747470733a2f2f6c6963656e7365627574746f6e732e6e65742f702f7a65726f2f312e302f38387833312e706e67" alt="https://licensebuttons.net/p/zero/1.0/88x31.png" data-canonical-src="https://licensebuttons.net/p/zero/1.0/88x31.png"></a></p>
<p dir="auto">Ribbon icons courtesy of <a href="https://icons8.com/" rel="nofollow">icons8</a>.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Alt-F4 #65 – Factorio visualizer in Unreal Engine 5 (401 pts)]]></title>
            <link>https://alt-f4.blog/ALTF4-65/</link>
            <guid>36561847</guid>
            <pubDate>Sun, 02 Jul 2023 14:34:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alt-f4.blog/ALTF4-65/">https://alt-f4.blog/ALTF4-65/</a>, See on <a href="https://news.ycombinator.com/item?id=36561847">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
Written by <em>Hurricane</em>,
edited by <em>Nanogamer7, stringweasel, Conor_, Therenas, MyNameIsTrez, Firerazer</em>
</p><div>

<p>Today we’ve got a very fun project to talk about: The FUE5 project, explained in this article by <em>Hurricane</em>. It’s Factorio, but <em>3D</em>! Dreams do come true sometimes. It’s not quite a game, but more of a stunning re-imagining of its visuals. There’s lots of technical details on how this was achieved, so let’s jump in.</p>
<h2 id="what-is-fue5">
<a href="#what-is-fue5">What is FUE5?</a>
</h2>
<p>FUE5 (short for <strong>F</strong>actorio in <strong>U</strong>nreal <strong>E</strong>ngine <strong>5</strong>) is an experimental project with a simple goal: to visualize the 2D world of Factorio in 3D space. It was created by 3D artist Hurricane and Factorio modder Nuke during a five month period, starting on January 10th 2023.
While many creative people in the Factorio modding community create awesome large-scale mods like Space Exploration, Bob’s mods or Angel’s, we decided to take a slightly different approach. To put it simply, this project is a 3D visualization environment which can import bases from the Factorio game and visually replicate their behavior. It contains no gameplay, however you can fly around and visit your base in 3D.</p>
<p>
<iframe src="https://www.youtube.com/embed/01qux-5Qx_Y" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>


<div>
<figure>
<img src="https://media.alt-f4.blog/ALTF4/65/snap.jpg" alt="3D view of large scale factory with a variety of machines and structures.">
<figcaption>Example of a large-scale factory in the trailer. Don’t mind the missing power poles.</figcaption>
</figure>
</div>


<h2 id="how-was-it-done">
<a href="#how-was-it-done">How was it done?</a>
</h2>
<p>To even start thinking about a project such as this, it was necessary to model and animate each Factorio asset, be it assembling machine or inserter, from scratch based on the sprites from the game. We’ve used Cinema4D for 3D modelling and Adobe Photoshop for creating the textures. Once the model and textures are done, the entire structure is exported from Cinema4D to FBX format, which is then imported into Unreal Engine 5, where proper shaders are applied - such shaders are usually materials like glass, metal, or even smoke from a chimney.</p>


<div>
<figure>
<img src="https://media.alt-f4.blog/ALTF4/65/structures.jpg" alt="3 Way split depicting chemical plant. Left: Factorio Sprite. Middle: Wireframe remodel. Right: Textured remodel.">
<figcaption>The remodelling process was a lot of fun, but next time we should really ask for the original Factorio models to preserve what’s left of our sanity.</figcaption>
</figure>
</div>


<p>It was also necessary to replicate several key systems like belts, trains, and the logistic system. These were created via the native UE5 blueprint node system. We decided to create all the logic for these system after the 3D modelling was mostly finished, since it was necessary to have the correctly sized 3D models placed in 3D space for proper alignment of moving elements such as trains and items on belts. One major step which helped push the project forward was the ingenious idea to export Factorio bases from the game directly, and to then import them into the Unreal Engine environment. This solution saved a lot of time on base building, which would be tedious and wouldn’t look correct if done in Unreal Engine alone.</p>


<div>
<figure>
<img src="https://media.alt-f4.blog/ALTF4/65/nodes.jpg" alt="Node graph within Unity.">
<figcaption>When you don’t know how to code, you just put these nodes together, and if it doesn’t work you just keep adding more and more and become increasingly confused. Suspiciously similar to this factory game I’ve been playing recently.</figcaption>
</figure>
</div>


<h3 id="1-structure-system">
<a href="#1-structure-system">1. Structure System</a>
</h3>
<p>The first major component of FUE5 is the ability to spawn structures in an identical manner to how you’d find them in Factorio. By reading in-game data, we can get building types, their orientation and cable connections. This information is exported as a JSON file via a FUE5 exporter mod directly from inside the game. This file is then read by the FUE5 project, which is enough to visually replicate all structural and vehicular behavior of the actual base.</p>
<h3 id="2-transport-belt-system">
<a href="#2-transport-belt-system">2. Transport Belt System</a>
</h3>
<p>Apart from spawning the actual 3D models of individual transport belts, we had to figure out the item movement mechanic. This was achieved by representing transport belts as splines. When exporting a Factorio base via the FUE5 exporter, each continuous transport belt segment (a segment of transport belts which are connected and end in a tunnel, end on their own, or are looped) is treated as its own individual system. Once FUE5 reads this data, it constructs a spline for each of these individual systems. These splines then guide the items through the same path they follow in the actual game.</p>
<h3 id="3-train-system">
<a href="#3-train-system">3. Train System</a>
</h3>
<p>The train system is quite different to the transport belt system, since replicating train scheduling, signals and locomotive pathing would be very hard to do. Instead, we opted to use the native Factorio system for finding routes the trains should take. For a train to spawn and drive in FUE5, one has to set its destination and give it the green light prior to exporting the base. At this point we can read the train’s pre-calculated path and use it to construct a spline which then dictates the train’s movement in FUE5.</p>
<h3 id="4-logistic-system">
<a href="#4-logistic-system">4. Logistic System</a>
</h3>
<p>Right off the bat we skipped construction robots, since we’re currently spawning buildings via the native UE5 Construction Script system, and that’s the way it’s gonna stay for a while. What we focused on instead was getting logistic robots to work properly, since they’re the lifeline of any semi-advanced Factorio base and they add a lot of visual interest to the whole picture. Each roboport has a chance to randomly spawn a cluster of logistic robots, where each robot has its own simple brain to search for logistic chests in the vicinity and fly between them to visually replicate resource transportation. After this task of resource transportation is done, the robot will determine the location of the closest roboport and head to it to despawn.</p>
<h2 id="problems-and-optimization">
<a href="#problems-and-optimization">Problems and Optimization</a>
</h2>
<p>The first major issues became apparent once bigger bases were imported into FUE5 in the early days of the project. The FPS would drop significantly and blueprint events started to produce unreliable results, which is why a lot of optimization work was necessary to even run the project at 30 to 60 FPS.</p>
<p>Key optimization decisions revolved around poly count, texture resolution, particles, and the amount of on-tick updates. These had to be drastically reduced by optimizing the transport belt system, which caused a lot of stuttering in the early days of the project. We’ve also gained a lot of FPS by tweaking and optimizing the level of detail (LOD) of the animated parts of structures - such parts include things like the spinning cylinders on centrifuges, or all the gears and pistons on the roof of the assembling machines.</p>


<div>
<figure>
<img src="https://media.alt-f4.blog/ALTF4/65/array.jpg" alt="Array of 3D texture electric furnaces.">
<figcaption>You can never have enough iron plates.</figcaption>
</figure>
</div>


<p>There was also the need for approval from the Factorio developer Wube Software. When asked about the legality of this whole endeavour, they showed great understanding and allowed the project to be released, provided it won’t be used for commercial purposes.</p>
<h2 id="the-fun-part">
<a href="#the-fun-part">The Fun Part</a>
</h2>
<p>Once the general idea and most of the prototyping was figured out during the first two months of production, it became quite easy to replicate various Factorio assets and systems. That’s when the time came to really focus on the beauty of the whole thing and creation of the <a href="https://www.youtube.com/watch?v=01qux-5Qx_Y&amp;feature=youtu.be&amp;ab_channel=Hurricane">main release trailer</a>, which showcases large-scale bases built using the FUE5 exporter, and a lot of other cool stuff one can do within the FUE5 environment.</p>
<p>It was necessary to build a lot of custom stuff for the large-scale factories showcased in the trailer. Just the ability to export Factorio in-game bases doesn’t result in very clean and cinematic results, so there were a lot of tweaks done by hand to make it nice for the camera! It also turned out that spaghetti bases are much more fun visually than the long strips of single buildings optimized for high science per minute (SPM).</p>


<div>
<figure>
<img src="https://media.alt-f4.blog/ALTF4/65/fun.jpg" alt="Cube with machines and structures on all sides.">
<figcaption>Is this the Skyblock I’ve been hearing so much about?</figcaption>
</figure>
</div>


<h2 id="how-to-use-fue5">
<a href="#how-to-use-fue5">How to use FUE5</a>
</h2>
<p>This project is not a game, doesn’t have any user interface, and requires basic knowledge of UE5 to use. That being said, you can find a full description of the process on our <a href="https://github.com/FUE5BASE/FUE5">GitHub page</a>. Apart from installing UE5 and running the downloaded project, the process really comes down to simply selecting the chunk of your base you wish to export, and exporting it to FUE5 as described in the detailed <a href="https://github.com/FUE5BASE/FUE5/blob/main/BaseImportGuide.md">how-to guide</a>. Once you go through the process once, it becomes really easy to repeat.</p>
<h2 id="the-future">
<a href="#the-future">The Future</a>
</h2>
<p>We wanted to share this project as open source via GitHub, because the Factorio community is an extremely dedicated group of very creative people, and having access to such a project might allow some of them to experience the world they love in a new dimension. Plus, it might give the more creative ones the ability to create things which were not possible before.</p>
<p>Myself and Nuke are currently working on polishing the existing systems so they’re easy to use and perform well even with larger bases. We also started toying around with the idea of adding modded content in the future.</p>
<p>The factory must grow!</p>


<div>
<figure>
<img src="https://media.alt-f4.blog/ALTF4/65/se.jpg" alt="3D space elevator base surrounded by belts and machines.">
<figcaption>No joke here. Go play Space Exploration.</figcaption>
</figure>
</div>


<h2 id="contributing">
<a href="#contributing">Contributing</a>
</h2>
<p>As always, we’re looking for people that want to contribute to Alt-F4, be it by submitting an article or by helping with translation. If you have something interesting in mind that you want to share with the community in a polished way, this is the place to do it. If you’re not too sure about it we’ll gladly help by discussing content ideas and structure questions. If that sounds like something that’s up your alley, join the <a href="https://alt-f4.blog/discord">Discord</a> to get started!</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[/u/spez is right about feudalism and that's why Reddit is doomed (142 pts)]]></title>
            <link>https://maya.land/monologues/2023/07/01/spez-feudalism-reddit.html</link>
            <guid>36561166</guid>
            <pubDate>Sun, 02 Jul 2023 13:11:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maya.land/monologues/2023/07/01/spez-feudalism-reddit.html">https://maya.land/monologues/2023/07/01/spez-feudalism-reddit.html</a>, See on <a href="https://news.ycombinator.com/item?id=36561166">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Since Elon Musk bought Twitter, people have been making a lot of comparisons between internet institutions – particularly various social media things – and premodern political forms and figures.</p>

<p>These comparisons typically rely on the level of understanding of antiquity or of medieval life you’d expect to get from <a href="https://www.dk.com/us/book/9781465481542-dkfindout-castles/">DKfindout! Castles</a>. I am not a historian, but I know, like, just about enough to be embarrassed for the speakers.</p>

<p>So in this post, I want to talk a bit about how the relevant historical phenomena worked, a bit about why feudalism tends to be a pretty bad comparison to internet stuff, and a bit about why Reddit CEO Steve Huffman is – still! – maybe more correct than he knows when he compares moderators to landed gentry… in a way that suggests the end coming for Reddit as-we-know-it<sup id="fnref:medieval" role="doc-noteref"><a href="#fn:medieval">1</a></sup>.</p>

<h2 id="medieval-sociopolitics-in-my-blog-its-more-likely-than-you-think">Medieval sociopolitics? In <em>my</em> blog? It’s more likely than you think</h2>

<p>Feudalism is such a shit concept to work with that if you look it up in the Encyclopedia Britannica, instead of getting a history of feudalism, you get <a href="https://www.britannica.com/topic/feudalism">a history of the term’s use in history, how it has always been an awkward oversimplification, and how it only got muddier over time</a>. Everything I can find goes to great pains to explain that any summary you can give will erase a lot of very important variance over time and place, and that even within one state at one time <a href="https://en.wikipedia.org/wiki/Feudalism_in_the_Holy_Roman_Empire#Types">shit could get stupid complicated</a>.</p>

<p>However! If I am to claim that internet comparisons to feudalism are bad, then I need to evaluate charitably what they might best mean, squinted at under flattering light.</p>

<p>To that end, let’s try and disentangle two parts. <a href="https://acoup.blog/2022/09/23/collections-teaching-paradox-crusader-kings-iii-part-iia-rascally-vassals/">Bret Devereaux, actual historian</a><sup id="fnref:bret" role="doc-noteref"><a href="#fn:bret">2</a></sup>:</p>

<blockquote>
  <p>Veteran readers of the blog will already know that I generally avoid the terms ‘feudal’ and ‘feudalism,’ as do many medievalists these days. The problem is that ‘feudalism’ comes to conflate two very different systems: manorialism, the economic system which structured the relations between peasant farmers (mostly serfs) and their elite landlords, and vassalage, the political system which structured relations between elites. But these systems and the relationships they structured were very different and their conflation together as a single system is a modern, not medieval, construction.</p>
</blockquote>

<p>Okay. Manorialism and vassalage. This sounds doable, right?</p>

<p>Here follows sketched-out summary.</p>

<h2 id="manorialism">Manorialism</h2>

<ul>
  <li><a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">Premodern subsistence farmers, on their own, don’t optimize for producing a surplus, but instead on increasing their resiliency.</a><sup id="fnref:europe" role="doc-noteref"><a href="#fn:europe">3</a></sup> This is because having a surplus – whether in goods or money – is, in their context, both more difficult and less useful than you might expect. To increase resiliency, they can employ less facially efficient farming methods that will diversify their risks, and when times are good, they can invest any small surplus in social relations.</li>
  <li><a href="https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/">Large landholders rely on the desperation of the little people to make it possible for them to secure enough borrowed/bought/forced labor to make those larger holdings produce</a>.</li>
  <li>The relationship between the small farmers and the elites is the exchange of “labor, deference and some support” for “[military or political] protection […], some access to farming capital and most importantly the implied promise that in a catastrophe the big landholder would come to the ‘rescue’.”-</li>
  <li>This relationship is largely exploitative. In many places and times, it relies on a lot of “non-free labor”. The non-free-ness of it all is enforced with violence or the threat of violence, whether state violence or not.</li>
  <li>The manorial relationship also “[serves] to reorient production away from subsistence and towards surplus” to support elite lifestyles. “[Doing] anything that isn’t farming means somehow forcing subsistence farmers to work more and harder in order to generate the surplus to provide for those people who do the activities which in turn the subsistence farmers might benefit from not at all.”</li>
</ul>

<h2 id="vassalage">Vassalage</h2>

<p>It is with some trepidation that I will point to non-popular-history<sup id="fnref:pop" role="doc-noteref"><a href="#fn:pop">4</a></sup>, “Fiefs and vassals : the medieval evidence reinterpreted”, by Susan Reynolds<sup id="fnref:admit" role="doc-noteref"><a href="#fn:admit">5</a></sup>. If anyone with a relevant degree wants to tell me I’m wrong in my summary or choice of source, they are welcome<sup id="fnref:google" role="doc-noteref"><a href="#fn:google">6</a></sup>.</p>

<p>She reiterates the thing about feudalism being a blob of concept that confuses more than it elucidates. She extends that to vassalage and fiefs, saying that, well, we might have hoped they would be more dependable concepts since they’re smaller in scope, but that was wrong. To the extent that we can pin down little bits of them with adequate definition, she says they aren’t as generally useful as they’ve been made out to be.</p>

<p>So in as far as we are here to make a comparison between vassalage and anything internet, it is probably fair to say that we are making it to a kind of 16th-century historical myth-narrative rather than a usefully abstracted description of real social relations.</p>

<p>Of this vassalage narrative, then:</p>

<ul>
  <li>Vassalage denotes the relation between a lord and his free or noble follower. This was undertaken with oath and ceremony. It obligated the lord to “protect and maintain his vassal”, and obligated the vassal to provide military aid and attend at the lord’s court. (The latter obligations were also sort of implied outside of vassalage relationships if you were otherwise propertied enough to be <em>able</em> to provide demanded knights, for instance.)</li>
  <li>It hacked a state structure into existence through personal relations when “there was [supposedly] no idea of the state and very little idea of impersonal, public obligations at all”<sup id="fnref:publica" role="doc-noteref"><a href="#fn:publica">7</a></sup>.</li>
  <li>In the modern mind, there are nice crisp distinctions between “rent” and “tax”. This is because we like to imagine we have a crisp concept of “ownership” of land distinct from jurisdiction. In fief-holding Europe, it’s more accurate to say that the <em>classic</em> ideological structure dictates that the land belongs to God, and God says kings have charge of bits of it, and the kings say lords have charge of bits of those bits, and the lords may say various non-lords have charge of bits… Rent-y-tax-y obligations are owed back up chain, and rights-like obligations exist along it. However, this <em>idea</em> obscures that folks down the chain may often feel that their land is more meaningfully theirs by <em>custom</em> than by the higher layers’ authority, and the language in primary sources doesn’t dictate clean lines.</li>
  <li>“[In] an age of low literacy, few records, and poor communications, great men needed to use personal loyalties, ceremonies, and <em>ad hominem</em> rewards to maintain and extend their power over the land; and that, since rulers, nobles, and most free men lived off the work of a dependent peasantry, rulers could maintain, control, and reward their followers by delegating control over land and peasants to them. It also seems clear that, as collective activity became more organized, as bureaucracy developed, and as literacy increased the range and power of propaganda, so government relied less on direct interpersonal relations.”</li>
</ul>

<h2 id="one-more-thing-state-capacity">One more thing: state capacity</h2>

<p>There’s this book called <a href="https://en.wikipedia.org/wiki/Seeing_Like_a_State">Seeing Like A State</a> by James C. Scott. If you’re not in the mood to read it, read <a href="https://www.ribbonfarm.com/2010/07/26/a-big-little-idea-called-legibility/">the first chunk of this blog post</a>, but mentally credit it with a bunch of examples Rao doesn’t include in the summary. This section is kind of cribbed from parts of it.</p>

<p>So – why did our mythically-feudal king need vassals, if other states didn’t always have them?</p>

<p>A state needs revenue, and in the premodern era, that’s got to come “mainly from levies on commerce and land, the major sources of wealth.” This turns out to be at least as complicated as taxes today, if for very different reasons. Knowing <em>from a distance</em> what taxes you should demand is hard. Take too little, and your state is feeble. Take too much, and you’ll have a whole new set of problems: flight, resistance, etc.</p>

<p>The local systems of measurement may vary from tiny place to tiny place – and even if you have more abstract ones to hand, local practices and land quality may mean that “two acres” in one place might acceptably be taxed far more highly than in another. So you can see why there was so much pressure to standardize the measures in the early modern era, right?</p>

<p>But it wasn’t <em>just</em> the measures getting standardized – it was also the rights people had.</p>

<p>Scott gives an example amalgamated from Southeast Asian practices. You might have land that’s parceled out among families during the main growing season, but reparceled out every seven years. After the main-season crop is harvested, then everything is common land, so anybody in the village gets to graze their animals and plant dry-season crops. But you might only be allowed to graze a certain number of animals, and that right might be transferable among the villagers, but not to outsiders. You might get to gather firewood for your own use but not for commercial sale – customs where fruit belongs to the family who planted a tree, even if not on their current parcel, but <em>fallen</em> fruit is fair game for anyone – rules about who gets branches that broke off of trees in storms… Rules “riven with inequalities based on gender, status, and lineage.”…</p>

<p>And <em>all</em> of this varying wildly from place to place.</p>

<p>Now: how could you as the king figure out how much rent-tax to demand directly from each of these people? Maybe you can figure out to some approximation the overall productivity of the overall land associated with the community, but actually extracting resources has to come from these households, right? And none of the inequalities are clear to you as an outsider – and <em>everyone will lie to you</em> and to your representatives because <em><a href="https://www.youtube.com/watch?v=ICUwC-f8iYg">fuck tha rent</a></em>.</p>

<p>And do you have the <em>capacity</em> to go around enforcing all this? To send people from your royal court out to each little hamlet, figure out how much to demand, and punish those who don’t meet the demand?</p>

<p>This points to an important function of the local feudal hierarchy, looked at from the perspective of <a href="https://en.wikipedia.org/wiki/State_capacity">state capacity</a>. If the vassal is around in the community to be able to figure out the local practices and maximize the rent-tax he can extract from the little people, then the king can extract value from the vassal and thus indirectly the region, even without having a bureaucracy under his own control that knows every town’s Local Fruit-Gathering Rules.</p>

<p>One of the main themes of Scott’s book is that throughout history, it is infeasible for states to build the Local Fruit-Gathering Rulebook at scale if they want to increase their centralized power and do Bigger Things. So what they actually do is come through and force people to stop measuring things the ways they have and to use standard measures, to stop thinking about property rights the ways they have and to use standard property rights, to stop using names the ways they have and to use patronyms… and while everyone hitting the pointy end of it <em>hates</em> this stuff, it makes it so much easier for the top-level state to do its state business that it can expand its state aspirations and be Bigger<sup id="fnref:scott" role="doc-noteref"><a href="#fn:scott">8</a></sup>. The capacity of the state isn’t just a function of the kind of bureaucracy you can build if you can force people to become more governable.</p>

<h2 id="why-this-stuff-doesnt-map-well-onto-the-internet">Why this stuff doesn’t map well onto the internet</h2>

<p>I would hope that everything I’m about to write is self-evident – so self-evident that you might as well skip this section. However, I would also have hoped that “people who want to sign up for an account on a new web service instead of using an old web service they don’t like as much anymore” would not consider it appropriate to term themselves “refugees”, so forgive me some obvious points.</p>

<ul>
  <li>The business at scale in social media is advertising. I haven’t given up hope on <a href="https://en.wikipedia.org/wiki/The_Long_Tail_(book)">the long tail</a>, <a href="https://www.honest-broker.com/p/where-did-the-long-tail-go">Gioiaian jeremiads notwithstanding</a>, but at scale, today, direct monetization pales in comparison to advertising’s revenues. This means that the economic productivity of social media use is indirect and highly mediated. Also, the business models are often opaque. This is a lot harder to track than wheat farms in medieval France somewhere. <strong>Comparisons risk implying we understand more than we accurately do</strong> about just who’s generating value and just how. (…more on this.)</li>
  <li>In the settled medieval context, there are subsistence farmers, and there are people eating surplus that subsistence farmers were squeezed into producing. Other food sources do not exist at the scale needed for the population. Reliable sources assure me the eventual consequence of going without food is death. Social media – the whole user-content internet – is only one of a whole host of entertainments, information sources, and communication options available to the kind of person who has internet access. Breaking one’s e.g. YouTube habit may be unpleasant or difficult, but it is not inherently life-or-death. <strong>When we make comparisons between our info-luxuries and survival necessities, we ratchet up the stakes in these conversations way too high</strong>, way too fast… and we also distract from <a href="https://apnews.com/article/technology-health-eating-disorders-center-government-and-politics-0c8ae73f44926fa3daf66bd7caf3ad43">actual life-or-death issues at play</a>.</li>
  <li>Over my lifetime, there have been a number of attempts at manufacturing digital scarcity. They have been pretty embarrassing and not made too much of a dent. That doesn’t mean that there are <em>no</em> relevant scarcities to bear in mind – money on offer for advertising, eyeball-hours monetizable on the other end – but <strong>naive analogies between, like, namespaces and <em>arable land holdings</em> often get pretty silly</strong>.</li>
  <li>I am not in debt bondage to Instagram. You are not a LinkedIn serf. Yes, there are relevant “<a href="https://doctorow.medium.com/facebooks-war-on-switching-costs-27fa4aeb7978">switching costs</a>” to this stuff. Those are notable because they operate in contrast to the general idea of businesses offering freely substitutable goods and services, not because <em>someone will come recapture you if you try to leave</em>. When someone writes a “Why I’m Leaving Twitter” post, they do not then have to go defend their violation of an oath of homage on the battlefield! <strong>If we pretend that we’re less free to leave than we are, we distort reality in ways that only benefit the big platforms.</strong></li>
  <li>If you are a premodern small farmer, you are subject to the varying jurisdictions that cover the land you live on and farm<sup id="fnref:transhumance" role="doc-noteref"><a href="#fn:transhumance">9</a></sup>. The social ties associated with your local community are essential to your survival. If you are an internet user today, you <a href="https://xkcd.com/1810/">have clicked through more terms of service than you can count</a>, migrated through more dead sites than you remember, and your ability to feed yourself is extraordinarily unlikely to be truly predicated on the particular group of otherwise-strangers with whom you interact on any given app<sup id="fnref:networking" role="doc-noteref"><a href="#fn:networking">10</a></sup>. <strong>There are a lot more options to the modern internet user than acquiescence or revolt-in-place.</strong></li>
  <li>The jurisdiction associated with lords’ enfiefed land is a burden, not a perk. <strong>Having to deal with little people problems is not a longed-for opportunity to get to tell people what to do – it is part of the trade-off necessary to get to extract rents/taxes from them.</strong> Remember: these are <em>actually</em> inherited positions, not first-mover-benefits-maintained-over-time. I am sure you can find an example of some medieval baron getting petty about dumb shit (send it to me!), but for the most part, everything I’ve read suggests they are trying to further delegate this work to <em>their</em> retainers so they have more time for… you know, falconry. Fulfilling their other obligations. Flexing on other rich people. 1% problems.</li>
</ul>

<h2 id="so-if-its-that-bad-why-do-people-keep-making-the-comparison">So if it’s that bad, why do people keep making the comparison?</h2>

<p>Reynolds’ book begins:</p>

<blockquote>
  <p>Feudalism, to any members of the general public who ever refer to it, stands for any hierarchical and oppressive system. Bosses or landlords who bully their employees or tenants are being feudal. If they bully them fiercely they are worse: they are positively medieval.</p>
</blockquote>

<p>To some extent, that’s the long and the short of it. The kind of person who imagines that the Dark Ages are called that because they weren’t yet Enlightened is not trying to make a historically-grounded point about political theory. They’re trying to say that something <em>sucks</em>. Anyone who grew up in a liberal democracy absorbed quite a lot of civic ideology about what makes governments legitimate; therefore, any authority that the speaker had no hand in appointing is a likely target of this condemnation. “Someone who isn’t me has power and control and I don’t like it”. That’s a fair thing to want to express, even if I’m salty about inaccuracy of comparison.</p>

<p>So… okay, so what? I didn’t get thousands of words into this just because <a href="https://xkcd.com/386/">someone said something obviously wrong about a medieval thing on the internet</a>.</p>

<p>Can we redeem this desire to compare the two?</p>

<p>How far can we get with a comparison if we try to say <code>/u/spez</code> is right?</p>

<h2 id="steve-my-liege-a-word">Steve, my liege, a word</h2>

<p>Steve Huffman (<a href="https://old.reddit.com/user/spez"><code>/u/spez</code></a>) is the CEO of Reddit. Reddit is a social media site that is somewhat unlike its competitor social media sites in form, but which is trying to have its business become publicly traded. It therefore needs to become more like those other sites – at least in profitability narrative. Reddit makes <a href="https://www.theverge.com/2021/8/12/22621445/reddit-valuation-revenue-funding-round">most of its revenue from advertising</a>. It relies on a vast amount of unpaid volunteer moderation labor – <a href="https://clivethompson.medium.com/reddit-moderators-do-over-3-4-million-in-free-labor-every-year-d3571235c32c">$3.4 million’s worth a year</a>, by one estimate. Some of Huffman’s IPO-minded moves have proven <a href="https://health.wusf.usf.edu/npr-health/2023-07-01/reddit-says-new-accessibility-tools-for-moderators-are-coming-mods-are-skeptical">very hostile</a> to the moderators, who have been protesting by taking subreddits dark – restricting access or posting or otherwise <a href="https://www.cnn.com/2023/06/23/tech/reddit-john-oliver-protest/index.html">creatively disrupting their function</a>.</p>

<p>And then Steve forces my hand, <em>makes</em> me write all this, by <a href="https://www.nbcnews.com/tech/tech-news/reddit-protest-blackout-ceo-steve-huffman-moderators-rcna89544">saying the following</a>:</p>

<blockquote>
  <p>If you’re a politician or a business owner, you are accountable to your constituents. So a politician needs to be elected, and a business owner can be fired by its shareholders.</p>
</blockquote>

<blockquote>
  <p>And I think, on Reddit, the analogy is closer to the landed gentry: The people who get there first get to stay there and pass it down to their descendants, and that is not democratic.</p>
</blockquote>

<p>There is obviously a lot about this that immediately sounds alarms, right?</p>

<ul>
  <li>Look, I’m even less of a lawyer than I am a historian, but if “a business owner can be fired by its shareholders” then they weren’t actually the <em>owner</em> of the business, no? They were, like, a CEO or something?</li>
  <li>Conflating citizens and shareholders is a classic American thought disease. Polysyllabic cringe.</li>
  <li>It sounds like Steve thinks that “gentry” operated on <a href="https://www.history.com/this-day-in-history/settlers-race-to-claim-land">Oklahoma land grab rules</a>.</li>
  <li>While <em>I</em> am willing to get hype about the general idea of property inheritance being so anti-democratic in nature that a democratic society must expropriate that property to function, I am guessing Steve Huffman, <a href="https://duckduckgo.com/?t=ffab&amp;q=steve+huffman+net+worth&amp;ia=web">estimated net worth in the millions</a> Steve Huffman, is not too married to what that implies, and really intends only to speak of inherited <em>authority</em>.</li>
</ul>

<p>But… fine. Come at me, Huffman.</p>

<h3 id="what-can-we-get-from-comparing-moderators-to-feudal-lords">What can we get from comparing moderators to feudal lords?</h3>

<h4 id="you-need-manorialism-to-make-little-farmers-produce-surplus-and-you-need-moderation-to-make-openly-hosted-user-generated-content-ad-monetizable">You need manorialism to make little farmers produce surplus, and you need moderation to make openly hosted user-generated content ad-monetizable</h4>

<p>Our subsistence farming household does not really want to produce the kind of surplus that can then be rent-taxed away, so the feudal structure has to force that to happen to exist. There’s real production, valuable activity, going on no matter what – but to make your state a Thing you need to beat that production into a useful shape.</p>

<p>Small, closed groups of internet users often function on top of internet infrastructure without explicit internal moderation. You, the reader, are probably in a number of group texts from which you have never formally banned a member for spam.</p>

<p>The openness of a platform can create a lot <em>more</em> monetizable engagement than the group chats. There are many of you who will never get to snigger at the jokes in my group chats, and <a href="https://en.wikipedia.org/wiki/Homo_economicus">Homo economicus</a> might see that as lost opportunity to engage-and-advertise-and-monetize, if he squints. A missed opportunity for extractable surplus – because, like the subsistence farmers trying to maximize resilience instead of production, my friends are not sharing bad puns with an eye toward anyone’s ad revenue.</p>

<p>However, open, public internet infrastructure has its own downward tendencies. Whenever a truly unmoderated hosting service opens on the internet, there is a clock ticking down until that service is first used to host <a href="https://www.techdirt.com/2022/11/02/hey-elon-let-me-help-you-speed-run-the-content-moderation-learning-curve/">content related to child sexual abuse.</a> The openness can create an economic opportunity, but you need moderation to make that hold together – even just on the legal front.</p>

<p>Or just imagine an ad equilibrium. You, a user, are probably willing to tolerate a certain amount of promotional stuff in a Web Thing before you go off and find another Web Thing; call it an ad-viewing threshold. Variable by individual, but probably measurable in aggregate. Promotional material that is posted by a user and shown to you counts against your threshold, and any ad space bought with the platform on your feed also counts against your threshold, but only the latter makes the platform money. If the platform has enough would-be paid-advertisers to max out whatever it estimates its users’ ad-viewing threshold to be, then it has a strong incentive to go and hunt down any user content on its platform that has even a hint of promotion and hide it from sight. Maybe it’ll get those users to give up and pay them, but even if it doesn’t, it stops them from displacing monetizable ads under your threshold<sup id="fnref:unicode" role="doc-noteref"><a href="#fn:unicode">11</a></sup>.</p>

<p>So even if a moderator isn’t engaging with the ad infrastructure of a site, and <em>even if they’re not explicitly dealing with maintaining a high bar of “advertiser-friendliness”</em>, their role functions to make the thing stick together in the open way that produces the engagement-surplus that attracts ad money.</p>

<h4 id="local-variance-in-custom-makes-it-really-hard-to-moderate-from-outside-the-community">Local variance in custom makes it really hard to moderate from outside the community…</h4>

<p>If you ask heavy-use Redditors about their use of the site, many will, unprompted, bring up that the main big subreddits are trash and, while they might <em>also</em> subscribe to <code>/r/gifs</code> or whatever, they’re really <em>there</em> for the niche communities that are quite different – in both tone and content. Yes, it’s impressive that the recommendation algorithms on short-form video platforms can deduce my susceptibility to <a href="https://www.instagram.com/nicole_coenen/">thirst-trappy woodcutter lady content</a>, but the level of specificity in which such content is arranged on Reddit is far more impressive (sometimes horrifying in its specificity, if we’re being honest). These are far more diverse in intent and effect than the “communities” of shared engagement that arise around algorithmically recommended topics.</p>

<p>Maintaining engagement on <code>/r/AskHistorians</code> requires a very different standard of post and comment moderation than e.g. <code>/r/circlejerkaustralia</code>; they are trying to be different things, people <em>go</em> to them for different things, and the rules that will best encourage posters to post and consumers to consume are different.</p>

<p>How would you do that in a scalable way from the outside? Hell, set aside trying to keep things on-topic – from the outside, how can you keep up with the ever-shifting dog whistles and coded signifiers of bigotry that accompany the first encroachments of <a href="https://en.wiktionary.org/wiki/Nazi_bar">Nazis into your bar</a>? Maybe advertisers won’t understand either to care about the first wave, but you better believe they won’t like the media coverage of the later ones…</p>

<p>In an environment as heterogeneous and nichey as Reddit has been: you can’t. It works about as well as compiling the Local Fruit-Gathering Rules with the Firewood Addenda for every village in your nation. So if you’re going to have heterogeneous and nichey social media, you need moderation to be heterogeneous and nichey, enacted by the kind of person Scott calls a “local tracker”. <strong>Reddit as it has existed does not have the “state capacity” to do this any other way.</strong> Maybe, at least for the high-engagement subreddits that it considers most important, it can <em>replace</em> the local trackers with more compliant ones – but it can’t go without them. The king of Reddit, today, needs somebody to go be baron. If he couldn’t get them for free, he’d have to pay them.</p>

<h4 id="but-if-you-can-rent-tax-from-outside-the-community-you-can-shift-the-balance-of-power">…but if you can rent-tax from outside the community, you can shift the balance of power</h4>

<p>Reddit does not pay its moderators. It is not fully accurate to say that Reddit even confers the status and control that moderators possess, because that status and control is scoped to their moderated communities, and thus principally a function of community prominence. Anyone can be <em>a</em> mod; being a moderator of something that <em>matters</em> is something different entirely, and it’s Reddit’s userbase that makes <em>that</em> happen. On Reddit, many communities are extremely fungible; use the site long enough and you’ll observe schisms and migrations to new bits of namespace. We can argue that there is <em>some</em> extent to which community prominence is driven by the desirability of the community name, which is a bit conferred by Reddit – if I’m looking for an X subreddit, I’m going to look for <code>/r/X</code> before <code>/r/originalX</code>, <code>/r/seriousX</code>, <code>/r/XUncensored</code> etc., so there’s <em>something</em> meaningful to who gets to keep running <code>/r/X</code> – but in practice this is moderately fluid, as genres of content merge and divide even without explicit mod drama.</p>

<p>So if I were going to pin down what Reddit “gives” its mods, I would probably put it something like this: The ability to create and grow an online community with a bunch of useful (and not free-to-operate!) infrastructure and with intercommunity discovery among a large existing userbase.</p>

<p>What Reddit <em>gets</em> from its mods is – following the above – the ability to make the money that it makes from ads.</p>

<p>So how do you know whether that’s a fair trade?</p>

<p>It isn’t disqualifying to our comparison that the mods/lords don’t get paid in the same kind of thing that the company/king gets. For example, it was fairly common for the king to principally extract <em>military</em> support from the lords, rather than the same kind of rent-taxes the lords extracted from the commoners. However, this dynamic was always a bit in flux; making your vassals mad by giving them a shitty trade-off posed risks the king had to deal with in much the same way that the lords had to contend with the risk of overtaxing the populace. No one involved was <em>stupid</em>, and all the weird ideological language about divine right of kings shouldn’t make you think that people weren’t looking out for their own interests.</p>

<p>But crucially – the lords knew what kind of revenues they were getting from their lands, and they knew what the king was getting from them in turn. Maybe they’d lie to the king about the exact surpluses they’d extracted, just like the farmers would lie as much as possible about how much surplus there <em>was</em> – but their local control meant they had the local knowledge necessary to piece together the situation themselves.</p>

<p>So you can <em>imagine</em> that maybe the status quo <em>is</em> a fair trade – maybe the costs of running Reddit (data centers, engineers, lawyers), minus the ad revenue pretty much balance what Reddit gets from the mods in return for the chance to run their little communities. But how do you <em>know</em>?</p>

<p>A mod might be able to estimate how replaceable the job they do is, how replaceable their <em>community</em> is, and start trying to figure out what their leverage is…</p>

<p>But how do they estimate Reddit’s end of the deal?</p>

<p>Let’s talk about online advertising platforms for a second. (Sorry.)</p>

<p>YouTube does some revenue-sharing with video creators, so the amount of information exposed illustrates some interesting dynamics. First, remember: <em>many videos lose YouTube money, possibly even most.</em> They don’t ever get enough monetizable engagement to pay for their own (secret) marginal contributions to operating costs. Video hosting is expensive! But where there <em>is</em> monetizable engagement, the fact that we have <em>some</em> numbers doesn’t clear as much up as you might think.</p>

<p>Let’s say there’s some genre of enterprise software that’s hugely profitable to sell, but niche in potential customers; to advertise products of this kind, you need to reach people who work at companies who have jobs where they can influence buying decisions. Let’s say you are trying to sell one of these products. You know that the kind of person with the kind of job that makes them useful to influence likely uses some <em>other</em> kind of software – <a href="https://en.wikipedia.org/wiki/Tableau_Software">Tableau</a>, maybe. Now let’s say that <em>I</em> run a YouTube channel with Tableau tutorials. You and your competitors want to advertise on my channel <em>so bad</em>. Maybe you don’t specifically know about my channel, and you’re letting YouTube figure out the eligibility of where to put your ads – but that’s the advertising opportunity that might <em>work</em> for your business, so if YouTube is willing to offer you that specificity, it’s gonna be valuable to you, and that means it’s gonna be <em>pricey</em>. If YouTube is revenue-sharing <em>honestly</em>, then <em>that</em> means that <em>I</em> am gonna get a way bigger cut per video than the creator of a <em>equally watched</em> channel that doesn’t imply some super-valuable advertising opportunity. And indeed, we see some amount of that: “best short term insurance plans” as keywords gets a <a href="https://en.wikipedia.org/wiki/Cost_per_impression">CPM</a> about <a href="https://vloggerpro.com/youtube-niches-with-high-cpm/">50 times higher than “best USB mic”</a>, and some of that trickles down to the actual video creators.</p>

<p>But this can be alienated in ways that give the advertising platform a leg up. Let’s say that there’s a Norwegian law news channel that, like, <em>every</em> Norwegian lawyer watches religiously. It doesn’t post much, maybe, so it doesn’t get a ton of traffic, but the correlation is flawless. Norway has a high CPM, law has a high CPM, so let’s just say that intersection is a super valuable advertising target. Furthermore, though, this channel is so <em>boring</em> and <em>specific</em> that probably anyone who watches it much <em>is</em> a Norwegian lawyer. YouTube keeps track of those accounts. Let’s say there’s a <em>second</em> channel that’s all about… I dunno, drama commentary about the <a href="https://en.wikipedia.org/wiki/Norwegian_National_Opera_and_Ballet">Norwegian National Opera and Ballet</a>, and it just so happens that – unbeknownst to either the law news channel or the opera drama channel – Norwegian lawyers eat this opera drama shit up. This second channel might not have any high-CPM topics associated with it – but <em>if</em> YouTube lets advertisers target by “likely to be a Norwegian lawyer” rather than keywords associated with the actual opera video, then the <em>signal</em> about target demographics gathered from the law news channel combined with the <em>engagement</em> generated by the opera drama channel creates very profitable advertising opportunities for YouTube. Should the law news channel get a cut of the law-targeted ads on the opera drama channel because its content provided the signal that let that targeting happen<sup id="fnref:targeting" role="doc-noteref"><a href="#fn:targeting">12</a></sup>? Should the opera drama channel be paid better for desirability of the eyeball-hours it attracts, independently of opera drama keyword CPM? Does either channel have accurate information on how competitive its market is? If neither channel knows about the correlation, how incentivized is YouTube to remunerate them for the profitability of the intersection?</p>

<p>Maybe YouTube has the data it could crunch to figure out the marginal contributions there, but this begins to <em>sound</em> a bit like… parcels of land that maybe you can farm on <em>some</em> of the year, but during the <em>dry</em> season your <em>neighbors</em> can graze their <em>animals</em> on, but then with <em>trees</em> that the <em>old</em> tenants get to harvest… Right?</p>

<p>Substitute “subreddit” for “YouTube channel” and mix in that Reddit doesn’t have to share its detailed ad numbers, and you start to see how <strong>any given moderator of any given community can’t know whether they’re being exploited or how badly</strong>, even if as a whole it seems like mods produce way more value for Reddit than they benefit from. <em>Your</em> subreddit might marginally make Reddit a ton of money or might <em>lose</em> Reddit money, and you have no visibility into which.</p>

<p>The real dynamics of online advertising are fundamentally hidden from the creators of content and from volunteer moderators, and this means that no one can negotiate from their own actual value in the market. The illegibility of local variation may have meant that feudal lords were necessary to the feudal state, and the illegibility of local custom may similarly have meant that community-embedded moderators are necessary to Reddit as it exists today, but <strong>these platforms have information asymmetry</strong> that weights the balance of power heavily toward them. That’s kinda wild, and I can’t think of a parallel that real landed gentry had to put up with.</p>

<h4 id="the-tension-between-custom-and-putative-authority-seems-important-for-understanding-feudalism-and-moderator-revolt">The tension between custom and putative authority seems important for understanding feudalism and moderator revolt</h4>

<p>Let’s say the king comes to you, a feudal lord, and tells you that <a href="https://daily.jstor.org/peter-the-greats-beard-tax/">you’ve got to shave your beard</a>. Maybe he bothers justifying it, whatever. You don’t <em>want</em> to shave your beard. “You know, your Majesty,” you say, “this new law seems pretty risky. Obviously <em>I</em> would never, but, uh, what if the rest of the lords tell you to, you know. Fuck off?”</p>

<p>One thing the king <em>might</em> say is “Well, my good man, who would <em>definitely</em> never say such a thing himself, they only matter because <em>I</em> say they do. Because God says <em>I</em> matter, and <em>I</em> delegated authority <em>to</em> them. And they know that, so they know that it would be both inherently ridiculous and self-defeating to go against me. Like, what would they be without me? Nothing. Peasants in violation of <a href="https://en.wikipedia.org/wiki/Sumptuary_law#Scotland">sumptuary law</a>.”</p>

<p>You are not totally confident in this description of affairs. It sort of seems to you that the tenant farmers under you are mostly under your control because everyone’s used to it and because you pay men with pointy metal things to tidy up the exceptions, not because you have a royal stamp of officialdom. Sure, <em>technically</em> you are <em>under</em> this king, but is that really relevant to how the yearly harvest gets brought in and taxed? If that royal stamp were revoked, wouldn’t you still be able to exploit the local farmers all the same?</p>

<p>But it’s a little ambiguous. Even if the king’s authority seems like a fiction, if he has the military power to come in, squash you, and give your fief to the neighboring Baron Dogface, then… well, the little people would probably shrug and pay rent-tax to Dogface and try to get on with their own lives.</p>

<p>So who does a subreddit belong to?</p>

<p>Imagine starting one, hyping it up, patiently providing four-fifths of the content until people show up, moderating spam, moderating jerks, growing it gradually over time. Setting rules, establishing tone, running the weekly topical threads. Would you feel like that <code>/r/whateverItWas</code> existed because of <em>Reddit the company</em>? Would you feel like it fundamentally belonged to his Royal Highness Steve, and Steve was just delegating it to you to run? No! You started it! You shaped it! You collaborated with the people it attracted to make it what it is! Even those users – they could switch <em>tomorrow</em> to <code>/r/whateverItWasTwo</code> and you couldn’t do a thing about it – if they decided they didn’t like your vision for <code>/r/whateverItWas</code>, they <em>would</em>, so the fact that they’re still here is a kind of voting with your feet, it <em>validates</em> what you’re doing… To the extent that <code>/r/whateverItWas</code> exists as a <em>thing</em> within Reddit as a whole, to be run or misrun, managed or mismanaged? It feels like <em>yours</em>.</p>

<p>But at the same time, to an external observer – you can see how they would feel that this is pretty silly, right? The thing that’s “yours” is nothing but rows and columns in Reddit’s databases<sup id="fnref:rdbms" role="doc-noteref"><a href="#fn:rdbms">13</a></sup>, a series of flags giving you the power to moderate. The only thing you have is set in Reddit’s systems, a permission to edit stuff under a certain scope a bit differently than other users, wo<em>wee</em> aren’t you important. It’s not you who has a license to the user posts, it’s not you who controls anything but a tiny little square of grass Reddit let you mow. You’re gonna <em>protest</em> over that? The world at large already doesn’t understand why you might volunteer for this work, why you might care enough to do it unpaid – you seem like a schmuck to them, a victim.</p>

<p><strong>But not to Steve.</strong></p>

<p>Steve is calling you landed gentry not because he’s <em>really</em> proposing to make things more <em>democratic.</em> Plenty of the protesting subreddits <em>voted</em> to protest – and even if Reddit vomits some PR about how that only reflects, like, <a href="https://en.wikipedia.org/wiki/1%25_rule">the 9% rather than the 90%</a> that never vote, it’s not really a convincing argument, is it? Steve is calling you landed gentry because <strong>he knows you work for him, making him money, and he wishes that you understood your authority to be delegated from him as your liege lord</strong>. Steve is annoyed that you feel like you have your own thing by local custom when what he sees is a bunch of flags in tables that are getting in the way of his business decisions<sup id="fnref:annoyed" role="doc-noteref"><a href="#fn:annoyed">14</a></sup>.</p>

<p>And I’m pretty sure Steve would like to modernize this whole feudal mess and remove the locality of your control.</p>

<h3 id="the-early-modern-state-comes-to-reddit">The early modern state comes to Reddit</h3>

<p>If we go back to Seeing Like A State for a minute… Technologies and practices that enabled central control were critical in the progression of the early modern state. Get rid of all that local variation in law and standardize it. Get rid of all those confusing local measurements. Bulldoze weird little windy streets and create boulevards that will make it easier to subdue local resistance. Propagandize to center your own importance. Use new media to extend your influence and control. Now you don’t need those local trackers like you once did, now you can administer your state more effectively centrally.</p>

<p>You know who’s managed this beautifully?</p>

<p>TikTok.</p>

<p>TikTok is really good at making people <em>feel</em> like they are seeing hyper-individualized content, but never allowing any explicit division of spaces within it. Without that division, no local norms can be established, no real preference expressed, and thus the tone of content is often uncannily homogeneous across wildly variant topics. This is what you’d expect: the unsteerable algorithmic recommendation feed feels like the final form of <a href="https://www.roughtype.com/?p=8724">content collapse</a>.</p>

<p>If I were a profit-maximizing social media company trying to expand my “state capacity”, I would be throwing money at every feature I could that took explicit navigation away from users, instead offering them frictionless spoon-feeding. Why? Social media that is homogenized (standard language!) is easier to moderate at scale. Moderation that is opaque (downweighting within hidden rankings) is easier to enact without objection, and tunably toward my engagement goals. Without even a sense of search keywords, I would increase the opacity of my advertising even further, obscuring from content creators the value I extract from them. These moves parallel the ones that Scott outlines early modern states taking to pull themselves out of dependency on local trackers. Remember: you don’t have to come up with a bureaucracy that can better handle the nation you have <em>if you can change the nation itself</em> to make it more governable.</p>

<p>And don’t you see those moves coming to Reddit?</p>

<p>I mean, maybe you <em>don’t</em> – Reddit has been pretty clever in allowing power users to maintain the old view characterized by explicit control even while it funnels new eyeballs toward recsys pablum. Part of Reddit’s whole IPO story <em>has</em> to be proving that it can provide a beautifully monetizable spoon-fed Infinite Recommended Content Feed just like Instagram or TikTok or Twitter or whatever – that’s just how social media companies are structured now. But especially if you’re used to using <code>https://old.reddit.com/</code> or one of the very good third party apps that has existed – pop open a private window and navigate to the normal home page. Doesn’t that look a <em>bit</em> like they’re trying to navigate away from how Reddit has always been and towards e.g. Twitter?</p>

<p>So maybe Reddit moderators <em>are</em> like feudal lords in that they have been the necessary structure that allowed Reddit communities to be so <em>wildly</em> different all this time.</p>

<p>And maybe we need to lean into those metaphorical comparisons to imagine what’s coming next. Bloggers invoking the high-level “enclosure of the commons” are phoning it in. Let’s talk <a href="https://en.wikipedia.org/wiki/Enclosure#The_end_of_the_Open_Field_system">conversion of copyholders into leaseholders to remove customary rights</a>.</p>

<p>And maybe we need to look at the ways those metaphorical comparisons <em>don’t</em> hold to imagine our ways <em>out</em>. Premodern subsistence farmers and early modern state subjects didn’t have all the options we do. You can’t bootstrap an alternate state by, like, automating crossposting, but on the internet all <em>kinds</em> of things are possible. (Hell, reminds one a bit of <a href="https://www.vice.com/en/article/z4444w/how-reddit-got-huge-tons-of-fake-accounts--2">Reddit’s own fakery</a>, dunnit?)</p>

<p>So as a non-moderator, as a <em>peasant</em>, as an <em>un-titled pleb</em>, I’d like to thank Steve for issuing the most CEO-flavored version of the age-old phpBB “the mods are mad with power!” complaint I’ve ever heard in my goddamn life.</p>

<p>Long live the King.</p>

<hr>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Sidewiki (127 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Google_Sidewiki</link>
            <guid>36560937</guid>
            <pubDate>Sun, 02 Jul 2023 12:41:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Google_Sidewiki">https://en.wikipedia.org/wiki/Google_Sidewiki</a>, See on <a href="https://news.ycombinator.com/item?id=36560937">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div id="mw-content-text" lang="en" dir="ltr">

<table><caption>Google Sidewiki</caption><tbody><tr><td colspan="2"><a href="https://en.wikipedia.org/wiki/File:Sidewiki_logo.png"><img alt="Sidewiki logo.png" src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/54/Sidewiki_logo.png/120px-Sidewiki_logo.png" decoding="async" width="120" height="24" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/5/54/Sidewiki_logo.png/180px-Sidewiki_logo.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/5/54/Sidewiki_logo.png 2x" data-file-width="200" data-file-height="40"></a></td></tr><tr><td colspan="2"><a href="https://en.wikipedia.org/wiki/File:Google_Sidewiki_Screenshot.png"><img alt="Google Sidewiki Screenshot.png" src="https://upload.wikimedia.org/wikipedia/en/thumb/0/03/Google_Sidewiki_Screenshot.png/100px-Google_Sidewiki_Screenshot.png" decoding="async" width="100" height="192" srcset="https://upload.wikimedia.org/wikipedia/en/thumb/0/03/Google_Sidewiki_Screenshot.png/150px-Google_Sidewiki_Screenshot.png 1.5x, https://upload.wikimedia.org/wikipedia/en/thumb/0/03/Google_Sidewiki_Screenshot.png/200px-Google_Sidewiki_Screenshot.png 2x" data-file-width="228" data-file-height="437"></a><p>Screenshot of the entries for the Wikipedia portal page.</p></td></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/Programmer" title="Programmer">Original author(s)</a></th><td><a href="https://en.wikipedia.org/wiki/Google" title="Google">Google</a></td></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/Programmer" title="Programmer">Developer(s)</a></th><td><a href="https://en.wikipedia.org/wiki/Google" title="Google">Google</a></td></tr><tr><th scope="row">Initial release</th><td>September&nbsp;23,&nbsp;2009<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup></td></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/Operating_system" title="Operating system">Operating system</a></th><td><a href="https://en.wikipedia.org/wiki/Windows_XP" title="Windows XP">Windows XP</a>, <a href="https://en.wikipedia.org/wiki/Windows_Vista" title="Windows Vista">Windows Vista</a>, <a href="https://en.wikipedia.org/wiki/Windows_7" title="Windows 7">Windows 7</a>, <a href="https://en.wikipedia.org/wiki/Linux" title="Linux">Linux</a>, <a href="https://en.wikipedia.org/wiki/Mac_OS_X" title="Mac OS X">Mac OS X</a></td></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/Computing_platform" title="Computing platform">Platform</a></th><td><a href="https://en.wikipedia.org/wiki/Google_Chrome_Extensions_Gallery" title="Google Chrome Extensions Gallery">Google Chrome Extension</a>, <a href="https://en.wikipedia.org/wiki/Google_Toolbar" title="Google Toolbar">Google Toolbar</a>, <a href="https://en.wikipedia.org/wiki/Bookmarklet" title="Bookmarklet">bookmarklet</a> (<a href="https://en.wikipedia.org/wiki/Firefox" title="Firefox">Firefox</a>, <a href="https://en.wikipedia.org/wiki/Internet_Explorer" title="Internet Explorer">Internet Explorer</a>, <a href="https://en.wikipedia.org/wiki/Opera_(web_browser)" title="Opera (web browser)">Opera</a>, <a href="https://en.wikipedia.org/wiki/Apple_Safari" title="Apple Safari">Safari</a>)</td></tr><tr><th scope="row">Available in</th><td>English</td></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/Software_categories#Categorization_approaches" title="Software categories">Type</a></th><td><a href="https://en.wikipedia.org/wiki/Web_annotation" title="Web annotation">Web annotation</a></td></tr><tr><th scope="row">Website</th><td><a rel="nofollow" href="http://www.google.com/sidewiki/">google.com/sidewiki</a></td></tr></tbody></table>
<p><b>Google Sidewiki</b> was a <a href="https://en.wikipedia.org/wiki/Web_annotation" title="Web annotation">web annotation</a> tool from <a href="https://en.wikipedia.org/wiki/Google" title="Google">Google</a>, launched in September 2009 and discontinued in December 2011. Sidewiki was a <a href="https://en.wikipedia.org/wiki/Browser_extension" title="Browser extension">browser extension</a> that allowed anyone logged into a <a href="https://en.wikipedia.org/wiki/Google_Account" title="Google Account">Google Account</a> to make and view comments about a given website in a <a href="https://en.wikipedia.org/wiki/Sidebar_(computing)" title="Sidebar (computing)">sidebar</a>. Despite the name, the tool was not a collaborative <a href="https://en.wikipedia.org/wiki/Wiki" title="Wiki">wiki</a>, though the comments were editable by the author.<sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup><sup id="cite_ref-arstech_4-0"><a href="#cite_note-arstech-4">[4]</a></sup>
</p>
<meta property="mw:PageProp/toc">
<h2><span id="Function">Function</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Google_Sidewiki&amp;action=edit&amp;section=1" title="Edit section: Function">edit</a><span>]</span></span></h2>
<p>Google used ranking algorithms to determine comment <a href="https://en.wikipedia.org/wiki/Relevancy" title="Relevancy">relevancy</a> and usefulness, using criteria such as users voting up and down a comment and past user contributions. Anyone could look up a contributor's <a href="https://en.wikipedia.org/wiki/Google_profile" title="Google profile">Google profile</a> and assess their credibility. Caesar Sengupta of Google argued that the link to Google Profiles would help increase comment quality, because "People stop making trivial comments when it ties back to them."<sup id="cite_ref-paid_5-0"><a href="#cite_note-paid-5">[5]</a></sup> Website owners could "claim" their site, giving them the right to the first comment on the Sidewiki for that site.<sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup> Sidewiki also linked to "relevant posts from blogs and other sources", a feature that was potentially gameable.<sup id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup> Sidewiki was available for <a href="https://en.wikipedia.org/wiki/Internet_Explorer" title="Internet Explorer">Internet Explorer</a> and <a href="https://en.wikipedia.org/wiki/Firefox" title="Firefox">Firefox</a> through <a href="https://en.wikipedia.org/wiki/Google_Toolbar" title="Google Toolbar">Google Toolbar</a>, and on the <a href="https://en.wikipedia.org/wiki/Google_Chrome" title="Google Chrome">Google Chrome</a> browser through an add-on.<sup id="cite_ref-pcmag_8-0"><a href="#cite_note-pcmag-8">[8]</a></sup> For other browsers like <a href="https://en.wikipedia.org/wiki/Safari_(web_browser)" title="Safari (web browser)">Safari</a>, it was available as a third-party <a href="https://en.wikipedia.org/wiki/Bookmarklet" title="Bookmarklet">bookmarklet</a>.<sup id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup><sup id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup> Comments could be shared via a link, email, Twitter, or Facebook,<sup id="cite_ref-pcmag_8-1"><a href="#cite_note-pcmag-8">[8]</a></sup> and an <a href="https://en.wikipedia.org/wiki/API" title="API">API</a> was available for developers.<sup id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup>
</p>
<h2><span id="Shutdown">Shutdown</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Google_Sidewiki&amp;action=edit&amp;section=2" title="Edit section: Shutdown">edit</a><span>]</span></span></h2>
<p>In September 2011, Google announced it would discontinue a number of its products, including Google Sidewiki.<sup id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup>
</p>
<h2><span id="Reception">Reception</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Google_Sidewiki&amp;action=edit&amp;section=3" title="Edit section: Reception">edit</a><span>]</span></span></h2>
<p>Sidewiki allowed users to interact with a website in ways that the site owner could not control, which upset some website owners. <a href="https://en.wikipedia.org/wiki/Jeff_Jarvis" title="Jeff Jarvis">Jeff Jarvis</a> complained that Sidewiki "takes comments away from my blog and puts them on Google. That sets up Google in channel conflict vs me. It robs my site of much of its value",<sup id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup> and PaidContent noted that "Google is walking a fine line in its efforts to innovate in some areas that have long been the domain of traditional publishers, while not alienating them."<sup id="cite_ref-paid_5-1"><a href="#cite_note-paid-5">[5]</a></sup> PC Magazine commented that Sidewiki could "push site owners to make their forums more appealing on their own, and to enhance sites with no comment area with a space for reader participation."<sup id="cite_ref-pcmag_8-2"><a href="#cite_note-pcmag-8">[8]</a></sup> <a href="https://en.wikipedia.org/wiki/Public_relations" title="Public relations">Public relations</a> professionals saw Sidewiki as another venue that will need managing, but which offered an opportunity to engage with complaints and spot 'hot issues'.<sup id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup> <a href="https://en.wikipedia.org/wiki/Mark_Borkowski" title="Mark Borkowski">Mark Borkowski</a> predicted that "SideWiki is going to challenge PR by providing the masses with the tool for the ultimate expression of people power, something uncontainable that will need constant monitoring... SideWiki will make it impossible to promote one message and not be held to account."<sup id="cite_ref-15"><a href="#cite_note-15">[15]</a></sup> ArsTechnica argued that the comments were of similar value to those on existing sites such as <a href="https://en.wikipedia.org/wiki/Digg" title="Digg">Digg</a> and <a href="https://en.wikipedia.org/wiki/Reddit" title="Reddit">Reddit</a>, and suggested that without the ability found in Wikipedia to delete and restructure material, it was a "glorified comment system".<sup id="cite_ref-arstech_4-1"><a href="#cite_note-arstech-4">[4]</a></sup>
</p>
<h2><span id="See_also">See also</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Google_Sidewiki&amp;action=edit&amp;section=4" title="Edit section: See also">edit</a><span>]</span></span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/Google_SearchWiki" title="Google SearchWiki">Google SearchWiki</a></li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Google_Sidewiki&amp;action=edit&amp;section=5" title="Edit section: References">edit</a><span>]</span></span></h2>
<div>
<ol>
<li id="cite_note-1"><span><b><a href="#cite_ref-1">^</a></b></span> <span><cite id="CITEREFMalik2009">Malik, Om (September 23, 2009). <a rel="nofollow" href="https://gigaom.com/2009/09/23/google-launches-sidewiki-more-like-universal-commenting-system/">"Google Launches Sidewiki — More Like a Universal Commenting System"</a>. <i>gigaom.com</i><span>. Retrieved <span>March 3,</span> 2019</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=gigaom.com&amp;rft.atitle=Google+Launches+Sidewiki+%E2%80%94+More+Like+a+Universal+Commenting+System&amp;rft.date=2009-09-23&amp;rft.aulast=Malik&amp;rft.aufirst=Om&amp;rft_id=https%3A%2F%2Fgigaom.com%2F2009%2F09%2F23%2Fgoogle-launches-sidewiki-more-like-universal-commenting-system%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></span>
</li>
<li id="cite_note-2"><span><b><a href="#cite_ref-2">^</a></b></span> <span>Eustace, Alan. (2011-09-02) <a rel="nofollow" href="http://googleblog.blogspot.com/2011/09/fall-spring-clean.html">Official Blog: A fall spring-clean</a>. Googleblog.blogspot.com. Retrieved on 2013-09-04.</span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><cite><a rel="nofollow" href="http://googleblog.blogspot.com/2009/09/help-and-learn-from-others-as-you.html">"Help and learn from others as you browse the web: Google Sidewiki"</a>. September 23, 2009<span>. Retrieved <span>September 23,</span> 2009</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Help+and+learn+from+others+as+you+browse+the+web%3A+Google+Sidewiki&amp;rft.date=2009-09-23&amp;rft_id=http%3A%2F%2Fgoogleblog.blogspot.com%2F2009%2F09%2Fhelp-and-learn-from-others-as-you.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></span>
</li>
<li id="cite_note-arstech-4"><span>^ <a href="#cite_ref-arstech_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-arstech_4-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFPaul2009">Paul, Ryan (September 23, 2009). <a rel="nofollow" href="https://arstechnica.com/web/news/2009/09/google-introduces-sidewiki-invites-users-to-annotate-web.ars">"Google Sidewiki interesting, but real utility unclear"</a>. <i>ArsTechnica</i><span>. Retrieved <span>September 9,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ArsTechnica&amp;rft.atitle=Google+Sidewiki+interesting%2C+but+real+utility+unclear&amp;rft.date=2009-09-23&amp;rft.aulast=Paul&amp;rft.aufirst=Ryan&amp;rft_id=https%3A%2F%2Farstechnica.com%2Fweb%2Fnews%2F2009%2F09%2Fgoogle-introduces-sidewiki-invites-users-to-annotate-web.ars&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></span>
</li>
<li id="cite_note-paid-5"><span>^ <a href="#cite_ref-paid_5-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-paid_5-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFTartakoff2009">Tartakoff, Joseph (September 23, 2009). <a rel="nofollow" href="https://web.archive.org/web/20120325201729/http://paidcontent.org/article/419-googles-latest-ambition-a-universal-commenting-system-for-the-web/">"Google's Latest Ambition: A Universal Commenting System For The Web"</a>. <i>PaidContent</i>. Archived from <a rel="nofollow" href="http://paidcontent.org/article/419-googles-latest-ambition-a-universal-commenting-system-for-the-web/">the original</a> on March 25, 2012<span>. Retrieved <span>September 9,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=PaidContent&amp;rft.atitle=Google%27s+Latest+Ambition%3A+A+Universal+Commenting+System+For+The+Web&amp;rft.date=2009-09-23&amp;rft.aulast=Tartakoff&amp;rft.aufirst=Joseph&amp;rft_id=http%3A%2F%2Fpaidcontent.org%2Farticle%2F419-googles-latest-ambition-a-universal-commenting-system-for-the-web%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></span>
</li>
<li id="cite_note-6"><span><b><a href="#cite_ref-6">^</a></b></span> <span><cite id="CITEREFArrington2009">Arrington, Michael (September 23, 2009). <a rel="nofollow" href="https://techcrunch.com/2009/09/23/google-steps-where-many-have-stumbled-sidewiki/">"Google Steps Where Many Have Stumbled: Sidewiki"</a>. <i>TechCrunch</i><span>. Retrieved <span>September 9,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=TechCrunch&amp;rft.atitle=Google+Steps+Where+Many+Have+Stumbled%3A+Sidewiki&amp;rft.date=2009-09-23&amp;rft.aulast=Arrington&amp;rft.aufirst=Michael&amp;rft_id=https%3A%2F%2Ftechcrunch.com%2F2009%2F09%2F23%2Fgoogle-steps-where-many-have-stumbled-sidewiki%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></span>
</li>
<li id="cite_note-7"><span><b><a href="#cite_ref-7">^</a></b></span> <span><cite id="CITEREFTurner2009">Turner, Adam (October 2, 2009). <a rel="nofollow" href="http://www.itwire.com/opinion-and-analysis/seeking-nerdvana/28166-wave-hello-to-google-sidewiki-bombing">"Wave hello to Google Sidewiki bombing"</a>. <i>iTWire</i><span>. Retrieved <span>September 9,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=iTWire&amp;rft.atitle=Wave+hello+to+Google+Sidewiki+bombing&amp;rft.date=2009-10-02&amp;rft.aulast=Turner&amp;rft.aufirst=Adam&amp;rft_id=http%3A%2F%2Fwww.itwire.com%2Fopinion-and-analysis%2Fseeking-nerdvana%2F28166-wave-hello-to-google-sidewiki-bombing&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></span>
</li>
<li id="cite_note-pcmag-8"><span>^ <a href="#cite_ref-pcmag_8-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-pcmag_8-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-pcmag_8-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFMuchmore2009">Muchmore, Michael (September 25, 2009). <a rel="nofollow" href="https://www.pcmag.com/article2/0,2817,2353282,00.asp">"Hands On with Google Sidewiki: Comments for All"</a>. <i>PC Magazine</i><span>. Retrieved <span>September 9,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=PC+Magazine&amp;rft.atitle=Hands+On+with+Google+Sidewiki%3A+Comments+for+All&amp;rft.date=2009-09-25&amp;rft.aulast=Muchmore&amp;rft.aufirst=Michael&amp;rft_id=https%3A%2F%2Fwww.pcmag.com%2Farticle2%2F0%2C2817%2C2353282%2C00.asp&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><cite id="CITEREFAgarwal2009">Agarwal, Amit (September 24, 2009). <a rel="nofollow" href="http://www.labnol.org/internet/google-sidewiki-without-google-toolbar/9959/">"Use Google Sidewiki without the Google Toolbar"</a>. <i>Digital Inspiration</i>. Labnol<span>. Retrieved <span>September 9,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Digital+Inspiration&amp;rft.atitle=Use+Google+Sidewiki+without+the+Google+Toolbar&amp;rft.date=2009-09-24&amp;rft.aulast=Agarwal&amp;rft.aufirst=Amit&amp;rft_id=http%3A%2F%2Fwww.labnol.org%2Finternet%2Fgoogle-sidewiki-without-google-toolbar%2F9959%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></span>
</li>
<li id="cite_note-10"><span><b><a href="#cite_ref-10">^</a></b></span> <span><cite id="CITEREFAdaikin2009">Adaikin, Andrey (October 29, 2009). <a rel="nofollow" href="http://chrome.blogspot.com/2009/10/bringing-google-sidewiki-goodness-to.html">"Bringing Google Sidewiki goodness to Google Chrome, Part I"</a>. <i>Google Chrome Blog</i><span>. Retrieved <span>September 9,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Google+Chrome+Blog&amp;rft.atitle=Bringing+Google+Sidewiki+goodness+to+Google+Chrome%2C+Part+I&amp;rft.date=2009-10-29&amp;rft.aulast=Adaikin&amp;rft.aufirst=Andrey&amp;rft_id=http%3A%2F%2Fchrome.blogspot.com%2F2009%2F10%2Fbringing-google-sidewiki-goodness-to.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></span>
</li>
<li id="cite_note-11"><span><b><a href="#cite_ref-11">^</a></b></span> <span><cite id="CITEREFLardinois2009">Lardinois, Frederic (September 23, 2009). <a rel="nofollow" href="https://web.archive.org/web/20100828045821/http://www.readwriteweb.com/archives/google_launches_sidewiki_lets_you_annotate_the_web.php">"Annotate the Web: Google Launches Sidewiki"</a>. <i>ReadWriteWeb</i>. Archived from <a rel="nofollow" href="http://www.readwriteweb.com/archives/google_launches_sidewiki_lets_you_annotate_the_web.php">the original</a> on August 28, 2010<span>. Retrieved <span>September 9,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ReadWriteWeb&amp;rft.atitle=Annotate+the+Web%3A+Google+Launches+Sidewiki&amp;rft.date=2009-09-23&amp;rft.aulast=Lardinois&amp;rft.aufirst=Frederic&amp;rft_id=http%3A%2F%2Fwww.readwriteweb.com%2Farchives%2Fgoogle_launches_sidewiki_lets_you_annotate_the_web.php&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></span>
</li>
<li id="cite_note-12"><span><b><a href="#cite_ref-12">^</a></b></span> <span>
<cite id="CITEREFAlan_Eustace2011">Alan Eustace (September 2, 2011). <a rel="nofollow" href="http://googleblog.blogspot.com/2011/09/fall-spring-clean.html">"A fall spring-clean"</a><span>. Retrieved <span>September 2,</span> 2011</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=A+fall+spring-clean&amp;rft.date=2011-09-02&amp;rft.au=Alan+Eustace&amp;rft_id=http%3A%2F%2Fgoogleblog.blogspot.com%2F2011%2F09%2Ffall-spring-clean.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></span>
</li>
<li id="cite_note-13"><span><b><a href="#cite_ref-13">^</a></b></span> <span><cite id="CITEREFIrvine2009">Irvine, Chris (September 24, 2009). <a rel="nofollow" href="https://www.telegraph.co.uk/technology/google/6224801/Google-Sidewiki-new-tool-lets-anyone-comment-on-webpages.html">"Google Sidewiki: new tool lets anyone comment on webpages"</a>. <i>Daily Telegraph</i><span>. Retrieved <span>September 9,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Daily+Telegraph&amp;rft.atitle=Google+Sidewiki%3A+new+tool+lets+anyone+comment+on+webpages&amp;rft.date=2009-09-24&amp;rft.aulast=Irvine&amp;rft.aufirst=Chris&amp;rft_id=https%3A%2F%2Fwww.telegraph.co.uk%2Ftechnology%2Fgoogle%2F6224801%2FGoogle-Sidewiki-new-tool-lets-anyone-comment-on-webpages.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></span>
</li>
<li id="cite_note-14"><span><b><a href="#cite_ref-14">^</a></b></span> <span><cite id="CITEREFLee2009">Lee, Julian (November 13, 2009). <a rel="nofollow" href="http://www.smh.com.au/technology/biz-tech/sidewiki-causes-a-pr-headache-20091113-idlp.html">"Sidewiki causes a PR headache"</a>. <i>Sydney Morning Herald</i><span>. Retrieved <span>September 9,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Sydney+Morning+Herald&amp;rft.atitle=Sidewiki+causes+a+PR+headache&amp;rft.date=2009-11-13&amp;rft.aulast=Lee&amp;rft.aufirst=Julian&amp;rft_id=http%3A%2F%2Fwww.smh.com.au%2Ftechnology%2Fbiz-tech%2Fsidewiki-causes-a-pr-headache-20091113-idlp.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></span>
</li>
<li id="cite_note-15"><span><b><a href="#cite_ref-15">^</a></b></span> <span><cite id="CITEREFBorkowski2009">Borkowski, Mark (November 9, 2009). <a rel="nofollow" href="https://www.theguardian.com/media/2009/nov/09/sidewiki-danger-to-pr">"SideWiki changes everything"</a>. <i>The Guardian</i>. PDA – The Digital Content Blog<span>. Retrieved <span>September 9,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Guardian&amp;rft.atitle=SideWiki+changes+everything&amp;rft.date=2009-11-09&amp;rft.aulast=Borkowski&amp;rft.aufirst=Mark&amp;rft_id=https%3A%2F%2Fwww.theguardian.com%2Fmedia%2F2009%2Fnov%2F09%2Fsidewiki-danger-to-pr&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></span>
</li>
</ol></div>
<h2><span id="External_links">External links</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Google_Sidewiki&amp;action=edit&amp;section=6" title="Edit section: External links">edit</a><span>]</span></span></h2>
<ul><li><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=Dgl6k_k5uwg">"Google Sidewiki for Google Toolbar"</a>. <i>Google Toolbar Help</i>. YouTube. September 22, 2009. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/Dgl6k_k5uwg">Archived</a> from the original on December 21, 2021<span>. Retrieved <span>September 9,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Google+Toolbar+Help&amp;rft.atitle=Google+Sidewiki+for+Google+Toolbar&amp;rft.date=2009-09-22&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DDgl6k_k5uwg&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AGoogle+Sidewiki"></span></li></ul>

<!-- 
NewPP limit report
Parsed by mw1380
Cached time: 20230625173037
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.689 seconds
Real time usage: 0.820 seconds
Preprocessor visited node count: 2125/1000000
Post‐expand include size: 158770/2097152 bytes
Template argument size: 1806/2097152 bytes
Highest expansion depth: 19/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 53716/5000000 bytes
Lua time usage: 0.329/10.000 seconds
Lua memory usage: 6920016/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  540.342      1 -total
 38.93%  210.380      1 Template:Reflist
 26.66%  144.082      1 Template:Google_Inc.
 21.09%  113.966      5 Template:Cite_web
 15.09%   81.519      1 Template:Infobox_software
 13.20%   71.346      1 Template:Infobox
 13.03%   70.416      1 Template:Short_description
 12.71%   68.689     10 Template:Cite_news
  7.27%   39.291      2 Template:Pagetype
  7.01%   37.880      1 Template:Hlist
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:24447456-0!canonical and timestamp 20230625173036 and revision id 1151201688. Rendering was triggered because: api-parse
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing as a form of thinking (148 pts)]]></title>
            <link>https://lopespm.com/notes/2023/07/02/writing-as-a-form-of-thinking.html</link>
            <guid>36560254</guid>
            <pubDate>Sun, 02 Jul 2023 10:56:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lopespm.com/notes/2023/07/02/writing-as-a-form-of-thinking.html">https://lopespm.com/notes/2023/07/02/writing-as-a-form-of-thinking.html</a>, See on <a href="https://news.ycombinator.com/item?id=36560254">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Large language models (LLM) like ChatGPT triggered a remarkable societal and computational shift that feels comparable to the impact from the initial internet era with its first impressive search engines like Google. LLMs are the toast of the town.</p>

<p>Writing emails, reports, school homework, analysis, code, summaries. The list goes on.</p>

<p>Save from when you would delegate this task to another fellow human, long hours would be passed in the past trying to conjure a piece of text that could communicate something to another entity. Now this can be made at scale, at low cost, with low effort.</p>

<p>Since we are still liable for the results of this tool, i.e. it’s still our name on the email sender, so instead of just sending that email, we might first read that LLM output, interpret it, understand it, and then send it.</p>

<h2 id="more-than-just-text">More than just text</h2>

<p>Text is a form of communication. If something, or someone wrote it for us, certain decisions were made along the way to convey the goal that we gave. Out of the many paths possible to crystallize that piece of knowledge into a piece text, one of them was chosen.</p>

<p>I would claim that something gets lost on that delegation.</p>

<p>The writing process is more than just the production of text. Many time it requires the exploration of different perspectives, thinking deeply and coming to terms that we don’t know enough about a subject and need to learn more about it.</p>

<p>For example, it’s essential for me to have a notebook at hand to take notes during meetings and formal discussions. I write phrases, loose words, make small diagrams, jot down some reminders. Some of them are never to be re-read again, others I revisit to structure them down into a concise structure. Most of all, they help me think about a problem.</p>

<p>Same holds for notes and articles. I start with a cloud of loosely held ideas that are related, which I attempt to refine into a structured form. Similar to the <a href="https://en.wikipedia.org/wiki/Double_Diamond_(design_process_model)">double diamond</a> process.</p>

<p>Same for books. Several times I’ve come to terms that I learned close to nothing about a book read one month before. Or conversations. Or movies. Or experiences.</p>

<p>This is, <a href="https://www.youtube.com/watch?v=otazg3TuPWM">except</a> if I reflected or acted about them. Except if I wrote down my conclusions about them.</p>

<blockquote>
  <p>For me, taking notes helps make sure that I’m really thinking hard about what’s in there. If I disagree with the book, sometimes it takes a long time to read the books because I’m writing so much in the margin</p>

  <p><em>― <a href="https://youtu.be/eTFy8RnUkoU?t=11">Bill Gates</a></em></p>
</blockquote>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[64bit computing on a budget (163 pts)]]></title>
            <link>https://virtuallyfun.com/2023/07/01/64bit-computing-on-a-budget/</link>
            <guid>36560242</guid>
            <pubDate>Sun, 02 Jul 2023 10:54:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://virtuallyfun.com/2023/07/01/64bit-computing-on-a-budget/">https://virtuallyfun.com/2023/07/01/64bit-computing-on-a-budget/</a>, See on <a href="https://news.ycombinator.com/item?id=36560242">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>With all that <a href="https://virtuallyfun.com/2023/05/15/windows-2000-64-bit-for-alpha-axp/">Dec Alpha talk</a>, and how hard it is to get hardware, and how seemingly exclusionary it is, I thought I would try to touch on a more available 64bit ‘risc’ platform, for the masses!</p>
<p>While a couple years ago I had touched on running <a rel="noreferrer noopener" href="https://virtuallyfun.com/2020/07/24/windows-10-on-the-raspberry-pi-4/" data-type="URL" data-id="/2020/07/24/windows-10-on-the-raspberry-pi-4/" target="_blank">Windows 10 on the Raspberry Pi 4</a>, in the brave new world of 2023 getting ahold of a pi4 is expensive, hard to find, and kind of depressive, which lead me to this (old) but exciting project, the <a href="https://renegade-project.tech/en/home" target="_blank" rel="noreferrer noopener">Renegade Project</a>!</p>
<p>Long story short, there exists enough drivers &amp; information to facilitate a port to the Snapdragon 845, a 64bit System On a Chip( SOAC!), meaning that if you have a device with this chip it *can* be slightly possible to install Windows 10 onto it.</p>
<figure><a href="https://renegade-project.tech/en/state"><img decoding="async" width="921" height="428" src="https://virtuallyfun.com/wp-content/uploads/2023/07/renegade-system-matrix.png" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/07/renegade-system-matrix.png 921w, http://virtuallyfun.com/wp-content/uploads/2023/07/renegade-system-matrix-300x139.png 300w, http://virtuallyfun.com/wp-content/uploads/2023/07/renegade-system-matrix-768x357.png 768w, http://virtuallyfun.com/wp-content/uploads/2023/07/renegade-system-matrix-500x232.png 500w" sizes="(max-width: 921px) 100vw, 921px"></a><figcaption>system compatibility matrix, for ants.</figcaption></figure>
<p>Glancing at the system matrix, to me the glaring hole is Charging. 3 systems outright support it, all of them from Xiaomi, the <a href="https://renegade-project.tech/en/devices/xiaomi/polaris">Xiaomi Mix 2s</a>, Xiaomi Mix 3 &amp; the <a href="https://renegade-project.tech/en/devices/xiaomi/beryllium">Xiaomi PocoPhone F1</a>. Looking around eBay to start this adventure I found a PocoPhone F1!</p>
<h2>Getting the Phone</h2>
<figure><a href="https://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-f1-ebay-listing.png"><img decoding="async" loading="lazy" width="901" height="431" src="https://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-f1-ebay-listing.png" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-f1-ebay-listing.png 901w, http://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-f1-ebay-listing-300x144.png 300w, http://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-f1-ebay-listing-768x367.png 768w, http://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-f1-ebay-listing-500x239.png 500w" sizes="(max-width: 901px) 100vw, 901px"></a></figure>
<p>This seemed like a good start, 29.99, 128GB of flash storage, and I’d later learn 6GB of RAM. The first problem came from Xiaomi. Turns out that the phone was still locked, the seller had neglected to logout from his Xiaomi account. Even worse though he had forgotten his login and password. Calling Xiaomi support was basically worthless. Without unlocking the phone on a reset to root the phone lead me to this:</p>
<div>
<figure><a href="https://virtuallyfun.com/wp-content/uploads/2023/07/locked-pocophone2.jpg"><img decoding="async" loading="lazy" width="384" height="512" src="https://virtuallyfun.com/wp-content/uploads/2023/07/locked-pocophone2.jpg" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/07/locked-pocophone2.jpg 384w, http://virtuallyfun.com/wp-content/uploads/2023/07/locked-pocophone2-225x300.jpg 225w" sizes="(max-width: 384px) 100vw, 384px"></a><figcaption>Locked!</figcaption></figure></div>
<p>I got lucky however after talking to the seller, he agreed to go above and beyond and we were able to unlock the phone together. So everything went well. If you do buy one of these phones used, MAKE SURE TO CHECK THE XIOAMI login id! It has to be unlocked and blank so you can register it and get the unlock. It will require a valid email &amp; phone number + sim for it to send/receive SMS codes.</p>
<p>Access to the site is very up &amp; down, so I archived what <a rel="noreferrer noopener" href="https://archive.org/details/miflash_unlock_en_7.6.602.42" target="_blank">I had downloaded to unlock the phone here</a>. <a href="https://archive.org/details/miflash_unlock_en_7.6.602.42" target="_blank" rel="noreferrer noopener">miflash_unlock_en_7.6.602.42.7z</a></p>
<p>I should add that we’ve cleared the first few hurdles of precuring the device and unlocking it. And I’m glossing over stuff. Getting to this point was not easy and took a week. The unlock process is not intuitive, and I’m sure many phones are sold out there that have their google access wiped, but have not been logged out all the way, or the flash erased. I can’t show you mine as I ended up erasing Android but be aware of this!</p>
<h2>Getting ready for Windows</h2>
<p>Basically on the Android side there is three main modes, the boot, the recovery and the ‘fastboot’ mode. Holding power &amp; down brings you to fastboot, where using the fastboot tool you can load an image from your PC into ram and execute it. <a href="https://github.com/edk2-porting/edk2-msm" target="_blank" rel="noreferrer noopener">EDK2 UEFI firmware</a>, is the first part or the renegade project you’ll encouter. It’s really powerful, allowing you to not only boot into Windows, but it also supports a linux disk target mode, allowing you to partition and access the flash directly from a PC. Naturally this is SUPER dangerous, and <a href="https://archive.org/details/pocophone-f1-modem-files" target="_blank" rel="noreferrer noopener">backup your modem files</a>!</p>
<p>With the phone unlocked softbooting E2DK you can put it into a target disk mode, connect it to a pc and partition away!</p>
<div>
<figure><a href="https://virtuallyfun.com/wp-content/uploads/2023/07/disk-host-mode-reduced.jpg"><img decoding="async" loading="lazy" width="467" height="865" src="https://virtuallyfun.com/wp-content/uploads/2023/07/disk-host-mode-reduced.jpg" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/07/disk-host-mode-reduced.jpg 467w, http://virtuallyfun.com/wp-content/uploads/2023/07/disk-host-mode-reduced-162x300.jpg 162w" sizes="(max-width: 467px) 100vw, 467px"></a><figcaption>disk mode… for ants!</figcaption></figure></div>
<p><a rel="noreferrer noopener" href="https://renegade-project.tech/en/install" target="_blank">The guide</a> (section 1.2) advices pushing the disk tools to the phone booted up in <a rel="noreferrer noopener" href="https://archive.org/download/miflash_unlock_en_7.6.602.42/twrp-3.7.0_9-0-beryllium.img" target="_blank">twrp-3.7.0_9-0-beryllium.img</a>. Honestly its easier to just partition it on your computer. HOWEVER if you were to use Windows, there is a slight issue:</p>
<p><strong><span>The device may no longer be able to boot into fastboot mode</span></strong></p>
<p>I ran into this issue and thought I had bricked my phone. I was actually in the middle of researching how to do a physical hard reset, <a href="https://www.youtube.com/watch?v=IlAaRQBtHKw" target="_blank" rel="noreferrer noopener">and place it into EDL mode</a> (taking it apart and finding which pads to short, when I found this section of the troubleshooting guide, where it’s the partition names. So instead, I ended up doing the partitioning on a Virtual Machine using VMware and Ubuntu.</p>
<pre><code>(parted) print
print
Model: SAMSUNG KLUDG4U1EA-B0C1 (scsi)
Disk /dev/block/sda: 123GB
Sector size (logical/physical): 4096B/4096B
Partition Table: gpt
Disk Flags:

Number  Start   End     Size    File system  Name        Flags
 1      24.6kB  41.0kB  16.4kB               switch
 2      41.0kB  73.7kB  32.8kB               ssd
 3      73.7kB  524kB   451kB                bk01
 4      524kB   786kB   262kB                bk02
 5      786kB   1049kB  262kB                bk03
 6      1049kB  1573kB  524kB                keystore
 7      1573kB  2097kB  524kB                frp
 8      2097kB  4194kB  2097kB               bk04
 9      4194kB  8389kB  4194kB               misc
10      8389kB  16.8MB  8389kB               logfs
11      16.8MB  33.6MB  16.8MB               oops
12      33.6MB  50.3MB  16.8MB               devinfo
13      50.3MB  67.1MB  16.8MB               bk05
14      67.1MB  134MB   67.1MB  ext4         persist
15      134MB   201MB   67.1MB  ext4         persistbak
16      201MB   268MB   67.1MB               logdump
17      268MB   403MB   134MB                minidump
18      403MB   1275MB  872MB   ext4         cust
19      1275MB  1342MB  67.1MB               recovery
20      1342MB  1611MB  268MB   ext4         cache
21      1611MB  123GB   121GB                userdata</code></pre>
<p>Before I did anything, this is what the phone partition table looked like. It’s an exceptional amount. The new parted v 3.0 that is recommended to use, doesn’t support the resize command so I had to manually do the numbers after destroying partition 21.</p>
<p>Originally, I had made a 32Gb partition to keep some Android functionality but somewhere it just stopped booting. But I didn’t care.</p>
<pre><code>rm 21
mkpart userdata ext4 1611MB 32G
mkpart esp fat32 32G 32.5G
set 22 esp on
mkpart win ntfs 32.5GB 123G

21      1611MB  32.0GB  30.4GB  ext4         userdata
22      32.0GB  32.5GB  499MB   fat32        esp         boot, esp
23      32.5GB  123GB   90.5GB  ntfs         win         msftdata</code></pre>
<p>Obviously dont follow this. I’m only providing output as an example.</p>
<p>If I were more patient, I guess I would have dd’d the entire phone to get a full entire backup. But I didn’t get this phone to run Android, so I really don’t care.</p>
<p>There is a LOT of disks being presented to Windows, in case you ever wondered how those 128GB flash devices get sold with only 114GB of user space. </p>
<figure><a href="https://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-f1-disk-partitions.png"><img decoding="async" loading="lazy" width="887" height="108" src="https://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-f1-disk-partitions.png" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-f1-disk-partitions.png 887w, http://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-f1-disk-partitions-300x37.png 300w, http://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-f1-disk-partitions-768x94.png 768w, http://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-f1-disk-partitions-500x61.png 500w" sizes="(max-width: 887px) 100vw, 887px"></a><figcaption>So many partitions!</figcaption></figure>
<p>And even that 112GB is actually usable!</p>
<p>Remember the system partition needs the boot,esp flags, and the windows partition is msftdata. Also make sure the partition names are either single words, or NO words. Spaces will kill the fastboot mode.</p>
<p>I put all the disks that are presented in offline mode, so I don’t get confused. Make sure you are going to mess with the right volumes when formatting after the partitioning. This is NOT for the novice, it would be easy to not only brick the phone but screw up your existing install. If you have physical disks attached you don’t absolutely need, remove them or put them offline to make sure you don’t screw up.</p>
<p>I used diskpart to select the appropriate volumes and format them.</p>
<pre><code>select disk 8
select volume 5
format quick fs=fat32 label="System"
assign letter="S"
select volume 6
format quick fs=ntfs label="Windows"
assign letter="W"</code></pre>
<p>This isn’t a guide, just a reflection of what I went through.</p>
<p>With the disk now formatted, it’s a matter of selecting an OS to install.</p>
<p>I had really bad luck picking random versions of Windows, so I looked until I could find a confirmed working version in this video, <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=t81-Ji17fGM" target="_blank">Rodando o Windows 10 ARM nativamente em um Dispositivo Android (Pocophone F1 + UEFI)</a>. Long story short, it’s Windows build 210521-1658 with version <a rel="noreferrer noopener" href="https://github.com/edk2-porting/edk2-msm/releases/tag/v0.4" target="_blank">0.4 of the bootloader</a>. Long story short I messed with LOTS of Windows on ARM driver sets, before I finally had the brave idea to just load it with no drivers:</p>
<div>
<figure><a href="https://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-booted-to-windows.jpg"><img decoding="async" loading="lazy" width="491" height="945" src="https://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-booted-to-windows.jpg" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-booted-to-windows.jpg 491w, http://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-booted-to-windows-156x300.jpg 156w" sizes="(max-width: 491px) 100vw, 491px"></a><figcaption>booted</figcaption></figure></div>
<p>But that image is far too stale, and expires out very quickly, reducing any useful functionality once it’s connected to the internet. So it’s something that probably could be fixed, but it’s far easier to just grab an image that’s newer.</p>
<p>The x86_64 image I’m using now is 19045.3031, so I guessed to pick something comparable on ARM64. I used something called <a href="https://archive.org/details/19045.3031_arm64_en-us_professional" target="_blank" rel="noreferrer noopener">19045.3031_arm64_en-us_professional</a>, although it too was out of date, but Windows update brought it up to 22H2 19045.3086 . I had tried the downloader tool and apply all the updates offline, but I had issues. I suspect now in retrospect it was drivers.</p>
<p>Another thing I learned the hard way is that some of these images have multiple OS images installed. I guess it’s de-duplication, along with compression, but be sure to index the image first! I accidentally installed a Home version. Yuck.</p>
<pre><code>dism /Get-ImageInfo /imagefile:install.wim

Index : 1
Name : Windows 10 Home
Description : Windows 10 Home
Size : 17,706,743,995 bytes

Index : 4
Name : Windows 10 Pro
Description : Windows 10 Pro
Size : 17,836,320,420 bytes</code></pre>
<p>So just don’t go wildly apply image #1. I wasted too much time on that one.</p>
<p>But in the release I’m using it’s image #1. I checked. Trust me.</p>
<pre><code>dism /apply-image /ImageFile:10.0.21390.1.co_release.210521-1658_arm64fre\install.wim /index:4 /ApplyDir:W:\</code></pre>
<p>The S volume needs to be populated with the UEFI boot files. I had foolishly thought the boot.wim file would include the boot files, but instead bcdboot can set it up based on the location of a Windows install.</p>
<pre><code>bcdboot W:\Windows /s S: /f UEFI</code></pre>
<p>The next thing to do is install the drivers.</p>
<p>I was lucky enough to get some insight into some driver combination to work, and I came up with this much:</p>
<pre>minimal 2210.1-fix
USB beryllium v2.0rc2
FG beryllium v2.0rc2</pre>
<p>The key of course is that there is a minimal set in 2210.1-fix that will bring the system up with working USB. The FG package brings in enough of the power management to know the battery status.</p>
<pre><code>dism /Image:W: /Add-Driver /Driver:drivers /Recurse</code></pre>
<p>The drivers are not signed, so that means we need to change a bunch of boot flags. I also turned on debugging so have Windows dump core files, so you can run analysts on them with <a href="https://learn.microsoft.com/en-us/windows-hardware/drivers/debugger/debugger-download-tools" target="_blank" rel="noreferrer noopener">Windgb</a>.</p>
<pre><code>S:
cd S:\EFI\Microsoft\Boot
bcdedit /store BCD /set "{default}" testsigning on
bcdedit /store BCD /set "{default}" nointegritychecks on
bcdedit /store BCD /set "{default}" recoveryenabled no
bcdedit /store BCD /set "{default}" debug on</code></pre>
<p>Of course the catch being that with no drivers loaded it’s in a super basic mode, with no USB, no touch screen, no power management, no wifi no nothing. So it’s a brick. But at least we’ve reproduced enough to show that you can boot Windows.</p>
<p>Sadly, loading all the drives from <a href="https://github.com/edk2-porting/WOA-Drivers/releases/tag/2210.1-fix" target="_blank" rel="noreferrer noopener">2210.1-fix</a> or beryllium <a href="https://github.com/edk2-porting/WOA-Drivers/releases/tag/v2.0rc2" target="_blank" rel="noreferrer noopener">v2.0rc2</a> lead to this:</p>
<figure><a href="https://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-crashed.jpg"><img decoding="async" loading="lazy" width="567" height="408" src="https://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-crashed.jpg" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-crashed.jpg 567w, http://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-crashed-300x216.jpg 300w, http://virtuallyfun.com/wp-content/uploads/2023/07/pocophone-crashed-417x300.jpg 417w" sizes="(max-width: 567px) 100vw, 567px"></a><figcaption>the cracked glass adds to the feeling.</figcaption></figure>
<p>Add in a much needed OTG adapter and a mouse or keyboard, and you can complete the installation. </p>
<figure><a href="https://virtuallyfun.com/wp-content/uploads/2023/07/Windows-10-on-Surface-scaled-1.jpg"><img decoding="async" loading="lazy" width="592" height="546" src="https://virtuallyfun.com/wp-content/uploads/2023/07/Windows-10-on-Surface-scaled-1.jpg" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/07/Windows-10-on-Surface-scaled-1.jpg 592w, http://virtuallyfun.com/wp-content/uploads/2023/07/Windows-10-on-Surface-scaled-1-300x277.jpg 300w, http://virtuallyfun.com/wp-content/uploads/2023/07/Windows-10-on-Surface-scaled-1-325x300.jpg 325w" sizes="(max-width: 592px) 100vw, 592px"></a></figure>
<p>However, since I left off the majority of the device drivers as I didn’t want to spend forever trying to track it down, I used a random USB to Ethernet adapter and thankfully It just worked!</p>
<figure><a href="https://virtuallyfun.com/wp-content/uploads/2023/07/Windows-10-on-pocophone.png"><img decoding="async" loading="lazy" width="1024" height="597" src="https://virtuallyfun.com/wp-content/uploads/2023/07/Windows-10-on-pocophone-1024x597.png" alt="" srcset="http://virtuallyfun.com/wp-content/uploads/2023/07/Windows-10-on-pocophone-1024x597.png 1024w, http://virtuallyfun.com/wp-content/uploads/2023/07/Windows-10-on-pocophone-300x175.png 300w, http://virtuallyfun.com/wp-content/uploads/2023/07/Windows-10-on-pocophone-768x448.png 768w, http://virtuallyfun.com/wp-content/uploads/2023/07/Windows-10-on-pocophone-500x292.png 500w, http://virtuallyfun.com/wp-content/uploads/2023/07/Windows-10-on-pocophone.png 1282w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>Accessing the phone over RDP.</figcaption></figure>
<p>I added a fancy USB 3.0 ‘dock’ with USB-C connector that you can plug a charger into, so that not only can the phone stay connected to power, but there is room for the Ethernet. It also has HDMI, perhaps is the drivers were more stable, it could be a viable desktop? And I have what I wanted, which was a non Intel/AMD 64bit platform that is hopefully more reliable than the Alpha64 platform, and maybe something to do some kind of contrast of the past vs future</p>
<p>This was NOT a simple thing to go through. I would be extremely hesitant to advise other people to follow suit. But in the off chance anyone who wants to do it, might have a better idea of what is involved.</p>
<p>Read the <a rel="noreferrer noopener" href="https://renegade-project.tech/en/Troubleshooting" target="_blank">Troubleshooting guide</a> &amp; the <a rel="noreferrer noopener" href="https://renegade-project.tech/en/install" target="_blank">Installation guide</a>. Keep notes! I would have absolutely given up, without keeping notes.</p>
<p>Even simple tracking of disasters like this at least helped me along:</p>
<pre><code>210521-1658<br>10.0.21390.1.co_release.210521-1658_arm64fre</code></pre>
<div>
<div>
<pre><code>boot-beryllium Version 0.4.1.img</code></pre>
<pre><code>boot-beryllium-ebbg Release - 2210.1.img</code></pre>
<pre><code>boot-beryllium-ebbg Release - 2210.1.img

boot-beryllium-ebbg Release - 2210.1.img

boot-beryllium-ebbg Release - 2210.1.img

boot-beryllium-ebbg Release - 2210.1.img</code></pre>
</div>
<div>
<pre><code>no drivers</code></pre>
<pre><code>
no drivers</code></pre>
<pre><code>
v1.1.1


v1.1


FocalTechTouch v2.0rc1


v2.0rc1</code></pre>
</div>
<div>
<pre><code>INTERNAL_POWER_ERROR</code></pre>
<pre><code>
installer


SYSTEM THREAD EXCEPTION NOT HANDLED


SYSTEM THREAD EXCEPTION NOT HANDLED

installer


SYSTEM THREAD EXCEPTION NOT HANDLED</code></pre>
</div>
</div>
<p>Sorry the table doesn’t format well.</p>
<p>TL;DR don’t do it, unless you don’t mind spending too much time on this. Get a used Surface X instead.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Drastic increase in Tor clients from Germany (257 pts)]]></title>
            <link>https://metrics.torproject.org/userstats-relay-country.html?start=2019-01-01&amp;end=2023-07-02&amp;country=de&amp;events=off</link>
            <guid>36560136</guid>
            <pubDate>Sun, 02 Jul 2023 10:29:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://metrics.torproject.org/userstats-relay-country.html?start=2019-01-01&#x26;end=2023-07-02&#x26;country=de&#x26;events=off">https://metrics.torproject.org/userstats-relay-country.html?start=2019-01-01&#x26;end=2023-07-02&#x26;country=de&#x26;events=off</a>, See on <a href="https://news.ycombinator.com/item?id=36560136">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Kokuhaku: Japan’s Love Confessing Culture (2013) (118 pts)]]></title>
            <link>https://www.tofugu.com/japan/kokuhaku-love-confessing-japan/</link>
            <guid>36560114</guid>
            <pubDate>Sun, 02 Jul 2023 10:25:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tofugu.com/japan/kokuhaku-love-confessing-japan/">https://www.tofugu.com/japan/kokuhaku-love-confessing-japan/</a>, See on <a href="https://news.ycombinator.com/item?id=36560114">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img width="100%" src="https://files.tofugu.com/articles/japan/2013-10-23-kokuhaku-love-confessing-japan/header-640x.jpg" alt="Header 640x">
</p>
<h2>
<span>
Kokuhaku: Japan's Love Confessing Culture
</span>
<small>
<span>
If you're going to say I Love You, do it right!
</span>
</small>
</h2>
<p>
<span>
<time datetime="2013-10-23T00:00:00Z">October 23, 2013</time>
•
<span></span>
words written by

•
Art by
<a href="https://www.tofugu.com/about/people/aya-francisco/">Aya Francisco</a>
<a href="https://files.tofugu.com/articles/japan/2013-10-23-kokuhaku-love-confessing-japan/header-5120x.jpg" title="Download header wallpaper" target="_blank"><i></i>
</a></span>
</p>
</div><div>
<article>
<div>
<p>As I mentioned in a previous article, I ran into a bit of trouble when I said 'I love you' at the very beginning of my relationship with my boyfriend (now husband). In Western culture, if someone suddenly and unexpectedly confessed this to you so quickly you would start running, I think. In English, the word "Love" is a big one, and some would say it should not be used so freely or haphazardly. It's possible to date and like somebody while not being in love with them, just as it is possible to be in love with someone you aren't dating. I'm sure we all know that feeling (Ah hemm! …Brad Pitt…Excuse me!).</p>

<p>However, things are quite different in Japan. Everything starts from the act of <i>kokuhaku</i> <ruby>告白<rp>（</rp><rt></rt><rp>）</rp></ruby>, which is confessing your love and asking them to go out with you. Now, let's learn more about <em>kokuhaku!</em></p>

<h2 id="the-art-of-kokuhaku">The Art Of Kokuhaku</h2>

<figure><img alt="japanese confession love" src="https://files.tofugu.com/articles/japan/2013-10-23-kokuhaku-love-confessing-japan/guy-girl-confession.jpg"></figure>

<p><i>kokuhaku</i> <ruby>告白<rp>（</rp><rt>こくはく</rt><rp>）</rp></ruby>, literally means "confession", and it is done when a man or a woman declares their love to another, and hopes to begin dating that person. The most basic way of confessing this is to say:</p>

<ul>
  <li>好きです。付き合ってください。</li>
  <li>I love you. Can we start seeing each other?</li>
</ul>

<p>The <i>tsukiau</i> <ruby>付き合う<rp>（</rp><rt>つきあう</rt><rp>）</rp></ruby> part means "dating", "seeing each other", or "having a relationship" in English. This is a very common phrase used for this kind of confession and you may have heard it, or a phrase similar to it, once or twice in Japanese movies or anime. If accepted, it marks the beginning of a "serious" boyfriend/girlfriend relationship. Like real grown-up stuff.</p>

<p>You may go out with the person a few times or go out on a group date, but your relationship hasn't technically started until this love confession, aka <em>kokuhaku,</em> occurs. The prospect of entering into this kind of relationship is sometimes so overwhelming that people even "confess their love" before the first date, followed by a sheepish invitation to an event with just the two of you. As you might guess, professing your love to someone as a precursor to saying hello for the first time might not be the most logical way of getting hitched, but as you'll see, it often appears to some men as be the best overall option.</p>

<p>And after this confession, if you go out with another woman or man, it may be called "cheating" because after the kokuhaku you two have officially started being exclusive. At this point, it's the same as any serious boyfriend/girlfriend relationship in Western culture. So, when I started seeing my Canadian husband, I met some other girls who were also dating foreigners. One of them warned me that I should be aware of their cheating. She even told me 'Mami, you know, they are all cheaters!'. Maybe some of them are but I doubt that all of them are cheating. I believe that she thought so because she misunderstood the differences in the initial stages of dating between the two cultures.</p>

<p>Speaking of misunderstanding foreigners often say that they don't understand what Japanese girls or boys are thinking because when they go out on dates they aren't even allowed to touch their hands. But, when the foreigner asks about the possibility of another date and they answer: "Sure! What is it?" … in that case they may be waiting for your <em>kokuhaku.</em> The love confession is like a switch. Once the switch is flipped, they can get into relationship mode. In other words, they usually don't act like a boyfriend or a girlfriend when they are not officially dating, although it is not very common to touch, hug, or kiss in public in Japan anyway.</p>

<h3 id="is-it-like-or-is-it-love">Is It Like Or Is It Love?</h3>

<figure><img alt="city art love park" src="https://files.tofugu.com/articles/japan/2013-10-23-kokuhaku-love-confessing-japan/love-sculpture-in-front-of-building.jpg"><figcaption>  </figcaption> Source: <a href="https://www.flickr.com/photos/ecos/2331960166/" title="Visit source's website" target="_blank">Matt Harris</a></figure>

<p>The concept of "like" and "love" in Japanese may be a little difficult for you to gauge because the word <em>"suki"</em> could mean both/either "like" or "love."</p>

<p>Although we have a word for "to love" or "I love you" <i>aishiteru</i> <ruby>愛している<rp>（</rp><rt>あいしてる</rt><rp>）</rp></ruby>, we barely use it. Granted, if you throw enough beer into the stomachs of two dudes who have been friends since childhood, you'll inevitably hear the "I love you man!" "No way, I love you!" argument. But, aishiteru is just the equivalent of the words we reserve for those truly special in our lives. This is when the words aren't just said, but felt as well.</p>

<p>More simply, <em>aishiteru</em> has a completely different weight to it than than the words <em>suki</em> or even <em>daisuki</em> (really like). In many ways, it holds more gravity than when English speakers say "I love you" because people can "love" donuts or movies or even use it the hashtag #love to describe a picture of something they took on their phones. <em>Aishiteru,</em> however, is used for only one purpose.</p>

<p>So, I think the confusion comes from the translation and how the words are perceived in the various cultures. You might say "I love you" in English and we might say <em>"suki"</em> in Japanese. To us, <em>suki</em> can mean "love" but it isn't the same kind of love as <em>aishiteru,</em> which is when you're actually feeling love for another person. That's why when you're confessing your "love" for someone in Japanese, it isn't as big of a deal because you're saying you love them, but in the same way you might say you love a donut. So, you know, you say "love" and we say <em>"suki"</em> and you say "love" and we say <em>"aishiteru."</em> Keep that in mind while we talk about <em>kokuhaku</em> so you don't get the wrong impression.</p>

<p>Anyways, a Japanese man and woman's relationship usually starts from this big "confession" event. If you were in Japan, your Japanese friends would probably ask you whether person X has confessed to you yet, even after a couple of dates. You may be wondering why Japanese people let their love interests known and that they intend to date them, in a committed way, even before the first date. Sometimes adults make their love confessions in this way:</p>

<ul>
  <li>結婚を前提にお付き合いさせてください</li>
  <li>I would like to have a relationship with you with the objective of an eventual marriage.</li>
</ul>

<p>Some people think it's a waste of time to date someone who doesn't plan on getting married at any point in the near future, if at all. Actually, it's a rather practical way of starting a relationship if you are looking to tie the knot.</p>

<h2 id="you-need-courage-to-kokuhaku">You Need Courage To Kokuhaku</h2>

<figure><img alt="kokuhaku confession courage cartoon" src="https://files.tofugu.com/articles/japan/2013-10-23-kokuhaku-love-confessing-japan/kokuhaku-superhero.jpg"></figure>

<p>Now, if you really like a Japanese person and want to start a serious relationship with them, then the next step is to confess your love. Although you may not be afraid of telling the one you love that you love them, things are quite different in Japan. According to research about "love confessions" conducted by Unilever Japan in 2011, out of 300 Japanese women and men (high school students, university students and another group of people in their 20's), 79% of them answered that they can't perform the act of confessing. The top two reasons for it were:</p>

<ol>
  <li>Because I don't know what he/she thinks of me.</li>
  <li>Because I don't have enough confidence in myself.</li>
</ol>

<p>25% of them also answered that they would confess if they were more than 90% certain that their kokuhaku would be accepted, 43% of them said they would take a shot with 70% odds, and 22% of them would try if the possibility is 50-50.</p>

<p>However, in the same journal, people who regretted confessing was only 21% whereas people who regretted not confessing was a much larger 52%. Moreover, 55% of people answered that they may start liking someone if they were confessed to, even though they had never thought of the confessor as a girlfriend or boyfriend. So, why don't you head out there and profess how you truly feel! No regrets! 告白しよう!</p>

<h2 id="lame-ways-men-confess-their-love-to-women">Lame Ways Men Confess Their Love To Women</h2>

<p>So now you've heard basically all there is to know about Japanese "love" confession culture… that is, except for its failures. According to research conducted by My-navi-woman from July 27, 2013 to August 2, 2013, 124 out of 476 women have actually turned the confessor down because of how lame, or even scary, their confession came off as. So, what kind of confessions turned them away? Let's have a look so you won't make the same mistake that these men made.</p>

<figure><img alt="don't confess by text" src="https://files.tofugu.com/articles/japan/2013-10-23-kokuhaku-love-confessing-japan/confession-by-text.jpg"></figure>

<ul>
  <li>メールで告白された。しかも朝の5時に。（33歳／女性）</li>
  <li>He confessed that he loved me via text. On top of that, it was 5am. (33 year-old female)</li>
</ul>

<p>Maybe there was a time difference he didn't account for? If not, it was kind of rude to send a text to people while they are probably sleeping. Although the number of people that confess their love (or even break up) by texting is increasing, I personally don't like it either. It's like you are telling them that you aren't serious about the relationship.</p>

<ul>
  <li>「俺、ヒモになりたい」と言ってきた人がいた。あり得ない。（32歳／女性）</li>
  <li>One guy told me, "I wanna be your string." Unbelievable! (32 year-old female)</li>
</ul>

<p>You may be wondering why saying "I wanna be your string" is so bad. String,
<i>aka</i> <ruby>紐<rp>（</rp><rt></rt><rp>）</rp></ruby> <i>himo</i> <ruby>ひも<rp>（</rp><rt></rt><rp>）</rp></ruby> in Japanese is used for guys that are like pimps, mostly in that they depend on their wife or girlfriend's income. They also are often associated with abusive relationships. It's really strange and doesn't sound like a love confession at all. At least he's being honest-ish?</p>

<ul>
  <li>「俺と両親を養ってくれ」と言われた。ドン引きした。（28歳／女性）</li>
  <li>I was asked, "Can you financially support me and my parents?" I was totally turned off. (28 years-old female)</li>
</ul>

<p>Now, I have a little more faith in men than this, so I prefer to believe that this was actually a marriage proposal. Let me explain. I imagine a situation in which the woman really wanted to get married, but the guy didn't. He contemplated a nice way to break up with her for a long time and realized that this proposal would end the relationship and make her not feel so badly about splitting… And he succeeded! Yay! Good for them. I don't know, it's all just a part of my imagination, but I can't imagine anything else going on here.</p>

<ul>
  <li>同じ職場の人から、長い手紙で告白された。何となく見かけたことがある程度なのに長々と文章が書かれていた。あまりにもいろんなことが書かれていて怖かった。（26歳／女性）</li>
  <li>I was confessed to in a long letter from my co-worker. Although I'd never talked to him before and only knew his face, the letter was so long and mentioned so many things. It actually creeped me out. (26-years-old female)</li>
</ul>

<p>It's pretty scary that somebody who you don't know at all actually knows you quite well. Although you may fall in love with a girl at first sight and follow her around for a while, long enough to learn a lot about her, you would be much better off not disclosing all the things you've learned while stalking her when you talk to her (or write to her) for the first time. I'm sorry I have to state the obvious here because apparently some people need to know.</p>

<ul>
  <li>電車内で見知らぬ男性から「ずっと片思いしてました、友達からでいいのでお付き合いしてください！」と、車両中に響く声で告白された。怖くて、結婚しているとうそをついて断ってしまったが、当分その電車に一人で乗れなかった。（31歳／女性）</li>
  <li>On the train, I was confessed to by a stranger who very loudly said, "I've unrequitedly loved you for a long time. It's okay for me to start being friends, but could we start our relationship, instead?" I was scared and lied to him that I was married. I stopped riding the train for a while. (31-year-old female)</li>
</ul>

<p>This isn't the only public blunder as it seems that many other public confessions fail in their attempts as well.</p>

<ul>
  <li>告白と同時にいきなり後ろから抱きつかれた。告白だと理解する前に恐怖を感じてしまった。（29歳／女性）</li>
  <li>He hugged me from behind my back and then confessed his love. Before realizing that it was his confession, I felt really threatened. (29-year-old female)</li>
</ul>

<p>Maybe he couldn't restrain his feelings, but it's seriously scary, especially for Japanese people who don't have a hugging culture. He definitely jumped the gun.</p>

<figure><img alt="shall I compare thee to an anime girl?" src="https://files.tofugu.com/articles/japan/2013-10-23-kokuhaku-love-confessing-japan/anime-girl-comparison.jpg"></figure>

<ul>
  <li>漫画のキャラクターの名前を挙げて、それよりもかわいいから付き合ってと言われた。（25歳／女性）</li>
  <li>He listed off some female anime characters names and told me that I'm cuter than they are and that's why he wanted to date me. (25-year-old female)</li>
</ul>

<p>Although he probably just thought it was an adorable way to tell her that she was attractive, it sounds kind of nerdy and I assume most women would be turned off from hearing a confession of that sort.</p>

<ul>
  <li>相手の人が履歴書を持参して、延々と説明をして、すでに結婚モードになっていたことが昔あります。（40歳／女性）</li>
  <li>He gave me his resume and explained what kind of person he is and that he was thinking about marrying me. This happened a long time ago though. (40-year-old female)</li>
</ul>

<p>Like I mentioned above, some Japanese people want to start a relationship when marriage is the goal. He may have done it this way just to show that he is serious about marriage and would be faithful, but I think it was a bit too much.</p>

<ul>
  <li>高校生のとき、朝学校にいったら黒板に私宛てに愛の告白文が書かれていた。他の友達にもバレて、恥ずかしかった。（29歳／女性）</li>
  <li>When I was a high school student, there was a confession written on the blackboard when I arrived at school one morning. It was embarrassing because it was revealed to all my friends. (29-year-old woman)</li>
</ul>

<p>This happens sometimes when you're young. Your feelings overcome reason and you don't realize that this potentially embarrassing event will be known to everyone in school. I think this also happened once when I was in junior high, although I was just an onlooker wearing a huge grin.</p>

<ul>
  <li>年賀状で告白された。親にも見られて恥ずかしかった。（31歳／女性）</li>
  <li>I was confessed to on a New Years card. It was embarrassing because my parents saw it. (31-year-old woman)</li>
</ul>

<p>One tradition in Japan is to exchange Happy New Year cards, but those postcards are not enclosed in envelopes like Western Christmas cards, so his confession was right there for anyone to see.</p>

<ul>
  <li>いきなり小さなバラの花束を持ってきての告白。同じ学校の人でしたが、話したことはなく、一度目が合っただけだそうです。（32歳／女性）</li>
  <li>He suddenly approached me with a bouquet of roses and confessed his love for me. He went to the same school as me, but I'd never talked to him before. In fact, I had only ever seen him one time before this. (32-year-old woman)</li>
</ul>

<p>Women like flowers but not from strangers. Although, this might be different if you are a foreigner. If a foreigner approached me with flowers, I'd accept it as it his culture.</p>

<figure><img alt="impress her with his income" src="https://files.tofugu.com/articles/japan/2013-10-23-kokuhaku-love-confessing-japan/pay-slip-cartoon.jpg"></figure>

<ul>
  <li>いきなり給与明細を見せてきた。（26歳／女性）</li>
  <li>He suddenly showed me his pay slip. (26 years old woman)</li>
</ul>

<p>Whether his payment was a little or a lot, this would definitely turn most women away, not just Japanese women.</p>

<hr>

<p>All in all, you may have found this system of "love confessions" to be a bit weird compared to your culture, but I personally think that this system helps to make relationships clear from the beginning and also makes it easier to start dating. Because of this, we don't usually need to have that awkward moment of asking "Are we serious about each other?" or "Are we exclusive?" or even "Do you love me?" Men know what is to be expected of them upon doing their <em>kokuhaku</em> and women know what is expected of them upon accepting.</p>



</div>
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Entropy: A little understood concept in physics [video] (195 pts)]]></title>
            <link>https://www.youtube.com/watch?v=DxL2HoqLbyA</link>
            <guid>36560104</guid>
            <pubDate>Sun, 02 Jul 2023 10:23:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=DxL2HoqLbyA">https://www.youtube.com/watch?v=DxL2HoqLbyA</a>, See on <a href="https://news.ycombinator.com/item?id=36560104">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>