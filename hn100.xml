<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 09 Dec 2025 15:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Richard Stallman on ChatGPT (101 pts)]]></title>
            <link>https://www.stallman.org/chatgpt.html</link>
            <guid>46203591</guid>
            <pubDate>Tue, 09 Dec 2025 11:12:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.stallman.org/chatgpt.html">https://www.stallman.org/chatgpt.html</a>, See on <a href="https://news.ycombinator.com/item?id=46203591">Hacker News</a></p>
<div id="readability-page-1" class="page">
<h2>Richard Stallman's personal site.</h2>
<h2><a href="https://www.stallman.org/">https://stallman.org</a></h2>
<p>
For current political commentary, see
the <a href="https://www.stallman.org/archives/polnotes.html">daily
political notes</a>.
</p>
<p>
<a href="https://www.stallman.org/biographies.html#serious">RMS's Bio</a> |
<a href="http://gnu.org/">The GNU Project</a>
</p>

<hr>





ChatGPT is not "intelligence", so please don't call it "AI".
<p>
I define "intelligence" as being capable of knowing or understanding,
at least within some domain.  ChatGPT cannot know or understand
anything, so it is not intelligence.  It does not know what its
output means.  It has no idea that words can mean anything.
</p><p>
I call it a <a href="https://gnu.org/philosophy/words-to-avoid.html#ArtificialIntelligence">"bullshit generator"</a>
because it <a href="https://link.springer.com/article/10.1007/s10676-024-09775-5">generates output "with indifference to the truth"</a>.
</p><p>
The same applies to many other "generative systems", for the same
reasons
</p><p>
The widespread public error of attributing intelligence to those
systems leads millions of people to a misplaced trust for them.
Please join me in spreading the word that people should not trust
systems that mindlessly play with words to be correct in what those
words mean.
</p><p>
Another reason to reject ChatGPT in particular is that users cannot
get a copy of it.  It is unreleased software -- users cannot get even
an executable to run, let alone the source code.  The only way to use
it is by talking to a server which keeps users at arm's length.
</p><p>
Doing your own computing via software running on someone else's server
inherently <a href="https://gnu.org/philosophy/who-does-that-server-really-serve.html">trashes your computing freedom</a>.

</p><hr>
Return to <a href="https://www.stallman.org/home.html">Richard Stallman's home page</a>.
<p>
Please send comments on these web pages to
<a href="mailto:rms@gnu.org"><em>rms@gnu.org</em></a>.
</p><p>
Copyright (C) 2024 Richard Stallman
</p><p>
Verbatim copying and distribution of this entire page are permitted
in any medium, provided this notice is preserved.
</p><hr>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Joy of Playing Grandia, on Sega Saturn (113 pts)]]></title>
            <link>https://www.segasaturnshiro.com/2025/11/27/the-joy-of-playing-grandia-on-sega-saturn/</link>
            <guid>46203138</guid>
            <pubDate>Tue, 09 Dec 2025 09:48:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.segasaturnshiro.com/2025/11/27/the-joy-of-playing-grandia-on-sega-saturn/">https://www.segasaturnshiro.com/2025/11/27/the-joy-of-playing-grandia-on-sega-saturn/</a>, See on <a href="https://news.ycombinator.com/item?id=46203138">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<h2>The Renaissance Period</h2>



<p>We are living through a Saturn renaissance. Buckets of titles previously locked away in Japan are seeing new audiences, thanks to the herculean efforts of small but dedicated teams of enthusiast translators, removing the veil of Japanese illiteracy from before our tired eyes. Interestingly, the majority of efforts are being directed at the games with the biggest scripts, and no other genre was as impacted by the language barrier as the text-heavy, story-driven RPG. Over a dozen quality titles are now playable in English. The Saturn is, once again, ascendant…</p>



<h2>Ain’t life Grand?</h2>



<p>Enter <em>Grandia</em>.</p>



<p>What hasn’t been said about <em>Grandia</em>? In the run-up to its late 1997 release, the game enjoyed significant worldwide coverage in the gaming press, not least because some positioned it as the anti-FF7 title. Hot on the heels of the remaster of <em>Lunar: Silver Star Story</em> and hailing from respected software house Game Arts, featuring state of the art fully 3D environments, a score by notable composer Noriyuki Iwadare, sound effects produced by Skywalker Sound… <em>Grandia</em> was indeed shaping up to be one of the premier JRPG experiences of the 5th generation. There was serious talk of bringing the game out West — Working Designs was touted as the favoured house to do the honors, owing to their strong partnership with Game Arts, but the game’s massive script would have meant a late 1998 release by even the speediest conversion standards of the time. By then, the Western Saturn retail market had collapsed, and despite a shrinking but fervently dedicated base of Saturn fans holding on to hope of seeing the title cross the ocean, the game wound up locked away in Japan, forever.</p>


<div>
<figure><img decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002354.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002354.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002354.bmp 300w" sizes="(max-width: 704px) 100vw, 704px"><figcaption><em>Sue’s always looking out for Justin.</em></figcaption></figure>
</div>


<h2>NEVER say Forever</h2>



<p>Game Arts subsequently ported <em>Grandia</em> to the PlayStation, dropping it in Japan in the summer of 1999. Sony speedily localized the game for Western release later that same year… but we aren’t going to focus too much on the PlayStation version here because, at the time of writing, PlayStation discs don’t boot on your SEGA Saturn. It’s the Saturn game that we are concerned with. For us Saturn stalwarts, we had to wait to the mid-2020s for <strong>an intrepid team led by TrekkiesUnite113 to <a href="https://segaxtreme.net/resources/grandia-english-patch.67/" data-type="link" data-id="https://segaxtreme.net/resources/grandia-english-patch.67/">transplant the PlayStation’s English script into the Saturn code</a></strong>. By then, the game was decades old, not to mention re-released and ‘re-mastered’ on modern platforms. So, why translate <em>Grandia</em> for the Saturn, when multiple other English options exist?</p>



<p><strong>Because <em>Grandia</em> is Best on Saturn.</strong></p>



<h2>How do you do</h2>



<p>Set in an age of discovery at the dawn of the industrial revolution, <em>Grandia</em> initially tells the tale of young Justin — a 14-year-old fearless adolescent who can’t help but dream of adventure. When he isn’t playing at “hero” with his town friends, he’s dreaming of great expeditions to find the lost civilization of Angelou. He is joined by his friend Sue — an 8-year-old girl whose maturity belies her age, and who tries desperately to keep young Justin in line. Justin’s mom Lily runs the local Seagull Restaurant and does her best to raise Justin into a respectable young man… though in her youth, she was a scrappy pirate herself. In her heart, she knows her audacious spark has passed on to her son, and that <strong>Justin will one day take up the adventurer’s mantle and take off on a grand adventure of his own</strong>, so she does her best to prepare him for when the time comes.</p>



<p><strong>She gives Justin a Spirit Stone</strong> — a remnant of the Angelou civilization and a memento of his long-lost father — and in doing so, helps kick off a fantastic voyage that sees young Justin explore, learn, overcome all manner of obstacles, and ultimately, grow and become the hero that he always imagined himself to be.</p>


<div>
<figure><img decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002388.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002388.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002388.bmp 300w" sizes="(max-width: 704px) 100vw, 704px"><figcaption><em>The party’s travels take them to the most interesting locations.</em></figcaption></figure>
</div>


<p>During his quest, Justin encounters fascinating characters, both friend and foe. From quiet folk in sleepy villages to rambunctious youngsters eager for their own slice of adventure; from military platoons led by the most beautiful — but hopelessly shallow — lady sergeants to cunning merchants, towering warriors, alluring mermaids and ferocious dragons… Justin encounters them all, and for good or ill, manages to change the course of their lives in ways both subtle and grand.</p>



<figure>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="126" height="126" data-id="53357" src="https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/Justin.png?resize=126%2C126&amp;ssl=1" alt=""></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="126" height="126" data-id="53358" src="https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/Sue.png?resize=126%2C126&amp;ssl=1" alt=""></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="126" height="126" data-id="53359" src="https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/Feena.png?resize=126%2C126&amp;ssl=1" alt=""></figure>
</figure>



<p>Justin, Sue, and Feena are the first three playable characters in <em>Grandia</em>. Young Sue tries to keep Justin in line, while Feena searches for the true meaning of being an adventurer – with Justin slowly moving from admiring her to showing her the way.</p>



<p>The game is clever in pulling the player in for a ride that for a very long while feels very lighthearted and innocent. Even as Justin’s adventure begins in earnest and the player is exposed to antagonists, mysteries, undercurrents and intrigues, Justin can’t help but distill it back to the <strong>very pure essence of boyhood adventure.</strong> Mysterious tower causing problems for a nearby village for years? No problem, Justin will fix it! A dragon from a nearby volcano terrorizing the locals? Justin’s got this. A ghost ship sailing in to harass a passenger steamer? Justin is the answer, in the same way that, as youngsters, we all knew – we knew! – that <strong>WE were the heroes</strong>, and that WE would save the day, armed only with our courage and our grand imaginations. It was our duty, after all. We had it in us to go forth boldly, and change the world (and naturally, all before being called home for dinner).</p>



<p>This point is driven home by Justin’s insatiable desire to uncover the mystery of his Spirit Stone, and the ancient Angelou civilization. After an unfortunate but entirely predictable mishap in the local museum, followed by a mysterious revelation in the nearby Sult Ruins, Justin’s curiosity is ignited, and his drive for real adventure becomes indomitable. Meanwhile, forces are at work that care not for Justin’s explorations, and inevitably, the lad finds himself pitted against the Garlyle Forces and some of its top commanders. Their aims are complex and their operations span the world, and this scope creates a wonderful juxtaposition with Justin’s innocent demeanor and singular focus.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002397.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002397.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002397.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>The amount of architecture being displayed here is stunning, though Grandia makes the Saturn work for it.</em></figcaption></figure>
</div>


<h2>On Screen!</h2>



<p>The Fifth Generation of consoles marked the rise of 3D graphics, but some genres made the leap easier than others. This shift was a struggle for RPGs, with many excellent titles continuing to employ 2D visuals, albeit in richer color and more sophisticated detail than seen in previous generations. Early attempts at the 3D RPG (<em>Virtual Hydlide</em>) highlighted how difficult it was to run this style of game on the hardware of the time without wrecking the framerate or keeping textures from looking like a checkerboard mess. Dungeon crawlers (<em>Shining the Holy Ark</em>) were among the first titles to get the 3D right, though the player’s scope of movement was very restricted. Finally, some fantasized that “3D” meant pre-rendered backgrounds and copious FMV clips, with the only real 3D being battle scenes. Ahem!</p>



<p><em>Grandia</em> took the traditional overhead RPG view and transformed the landscapes into <strong>fully realized 3D polygonal playfields</strong> that can be rotated and zoomed at will. Character and enemy sprites are then overlain on the 3D world to make the scenes come to life. The addition of the third dimension affords the use of depth in the environments: hills, cliffs, and valleys; minecar rails that ran higher or lower relative to other tracks, and so on. In this way, the player initially feels right at home with a view that looks comfortably familiar, but must quickly learn to constantly rotate the viewpoint to catch enemies in hiding, spy treasures only visible from certain angles, judge heights, and evaluate other geometric details to plot their best course forward.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002414.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002414.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002414.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>Aside from technical achievements, the art direction is fantastic.</em></figcaption></figure>
</div>


<p><em>Grandia</em> wastes no time in getting gamers used to this new visual paradigm. One of the game’s first quests sees local frenemy Gantz challenge Justin and Sue to locate the three Legendary Treasures: the fabled helmet (Iron Pot), the storied shield (Pot Lid), and of course, the legendary (Wooden) Sword. The player must traverse all of Parm, climbing down river walkways, checking in enclosed spaces, and chasing down Gantz’s little brother to prove they are up to Gantz’ task — and in the process, get used to the game’s then-new control scheme.</p>



<p>The 3D is very well put together, both technical and artistically. The level of detail is truly phenomenal, from the tiniest objects and details, especially in the ‘in-town’ game sections. Justin is able to interact with some of the innocuous scenery — for example he can knock brooms over, disturb piles of plates, or bump into bells and chimes — just as any real, overly excited 14-year-old might clumsily do as they ran along. Animations, from little weathervanes rotating to laundry fluttering on a clothesline, to puffs of smoke coming up from fires or chimneys, all accentuate the feeling that these are real, living, bustling places. The level of detail, and all of it in 3D, is really special.</p>



<p>The coders at Game Arts made excellent use of the Saturn’s unique hardware when realizing <em>Grandia</em>’s locales. Where appropriate, textured infinite planes are used to draw floors, and they not only look good but also dramatically cut down on the usage of polygons in drawing the scene, leaving that much more in the processing budget to spend on other visual details. In later sections, those infinite planes take on a distortion effect to create some very cool-looking water flows — look for them initially in Parm’s pier, and later in places like the snowy Laine Village or the mysterious Castle of Dreams. The water shimmers as the player rotates their view to create a truly stunning effect.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002409-4.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002409-4.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002409-4.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>Slimes are never that tough to dispatch in any RPG.</em></figcaption></figure>
</div>


<p>The game’s characters and enemies are all represented by sprites that animate quite well and take viewpoints into account as the player rotates the camera. In yet more attention to detail, the sprites darken and then lighten again as the player moves in and out of shadowed areas — an impressive little detail that accentuates the visuals even further.</p>



<figure>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="126" height="126" data-id="53362" src="https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/Baal.png?resize=126%2C126&amp;ssl=1" alt=""></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="125" height="126" data-id="53361" src="https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/Mullen.png?resize=125%2C126&amp;ssl=1" alt=""></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="124" height="126" data-id="53360" src="https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/Leen.png?resize=124%2C126&amp;ssl=1" alt=""></figure>
</figure>



<p>The trio of General Baal, Colonel Mullen, and Leen is introduced in the game’s opening scene, and all three are more than they appear.</p>



<p>The care that Game Arts took in crafting the visuals is commendable and <em>Grandia</em> comes off as one of the very best-looking 3D RPGs for the system, but Game Arts was perhaps a mite too ambitious. There are sections of the game where the framerate really chugs. Now, it must be acknowledged that low framerates were a hallmark of many 3D games in the 32-bit era, so some of this is to be expected, but the more detail Grandia is trying to show you, the more you will feel the Saturn huffing and puffing to get the job done. The game’s 3D framerate is not high at the best of times but it is passable, so it’s somewhat of a relief that the areas where it truly takes a dive aren’t too common.</p>



<h2>Pump up the Jam!</h2>



<p>Game Arts’ attention to detail extends to the sound department. For <em>Grandia</em>, Game Arts commissioned Skywalker Sound to handle the game’s sound effects. The result is <strong>positional sound</strong> — effects like running water, crackling fire, etc. will fade in and out as Justin and co. move closer in or further away from the source. Often, if the effect is important, it will also somewhat dampen the volume of the BGM as it plays out. Additionally, the effects will pan left or right depending on the source, and especially as the player rotates the camera. These effects may be subtle, but they are very well implemented and add to the game’s overall polish.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002421.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002421.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002421.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>The game is very colorful.</em></figcaption></figure>
</div>


<p>The game’s <strong>soundtrack was composed by Noriyuki Iwadare</strong> and is both varied and excellent. Iwadare’s use of instruments appropriate to the on-screen action is uncanny — for example, running around Parm we are treated to an industrial sounding theme, perfect for the town’s motif. The varied use of strings, drums and winds is frankly excellent and lends to the atmosphere, imitating the clang of metal and steel which so permeates the city. Equally impressive is that the music somehow manages to be exciting or somber or poignant without ever sounding overly (excuse the wordplay) grandiose. This keeps the soundtrack in line with the game’s more lighthearted narrative. Of course, where appropriate, the soundtrack does take on that epic quality. The desperate tones that play when the Garlyle forces appear contrast so well with the carefree, upbeat “Off Runs Sue” tune. Mullen’s theme is at once wistful and ambitious, and even the theme from the Sult Ruins dungeon is perfectly mood-setting. Multiple <em>Grandia </em>soundtracks have been released since the game’s debut and the soundtrack is universally praised.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002437.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002437.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002437.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>Leen is one of Col. Mullen’s acolytes.</em></figcaption></figure>
</div>


<h2>How it Plays Out</h2>



<p><em>Grandia</em>’s gameplay, like so many RPGs before it, is split into two major gameplay slices: exposition-laden town sections and combat-focused dungeons.</p>



<p>Players will spend a fair bit of time in the ‘in-town’ sections of the game. Here, you will wander around, take in the scenery, interact with the NPCs of the area, and almost always, find a quest that must be completed. A quick word about the NPCs — there are quite a number of them in each town, and everyone has something interesting to say… and almost always, each NCP has at least two separate conversation sequences to offer, making for a truly large amount of story to soak in. And <strong>it’s all entirely optional!</strong> It’s completely possible to make one’s way through <em>Grandia</em> with only minimal NCP interaction, but the option to enhance the adventure with these extensive NPC interactions is always there, as each character will present a unique view or focused response.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002441.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002441.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002441.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>An unlikely pairing.</em></figcaption></figure>
</div>


<p>Predictably, the towns are filled with shops, though <em>Grandia</em> keeps things rather simple — there is but one general store which carries weapons, armor, accessories, and even magic all under the same roof. Buy, sell or trade up to the latest gear which gradually increases in the stat boosts it confers to your characters. Additionally, each town typically has one or more important locales, such as mayors’ offices or the chambers of village chiefs.</p>



<p>There is typically an inn or other house where the party can take rest, and at certain points in the game, resting triggers a shared meal scene that sees Justin break bread with his party mates. These meal scenes offer up critical dialogue, which the gamer can extend or keep short at their whim. When the critical conversation has been had, a bedtime icon will appear over Justin’s character sprite, and if the player is quite finished listening to the party chatter, they can select it to end the meal and get some rest. These mealtime conversations serve not only to flesh out what the party must tackle next, but also to offer a glimpse into the inner thoughts of the individual characters as they share their opinions, hopes and fears. Like so much in the game, <em>Grandia</em> implements this character exposition in a way that allows the player to decide how much of it to take in.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002480.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002480.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002480.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>Great use of color.</em></figcaption></figure>
</div>


<p><strong>The visuals in the town sections really stand out.</strong> The Saturn manages to shift not only impressive amounts of polygons for the various structures, but also vivid and complex textures. This technical prowess is coupled with lush and imaginative art direction, resulting in each locale feeling complete and distinct. The dense, humid and green surrounds of Luc Village, nestled deep within the Misty Forest and inhabited by humanoid creatures contrasts sharply with the seaside port town of Dight with its cerulean waves gently rolling in onto its sandy shores. Milda’s hometown village of Laine is covered in snow, and the ancient Zil Padon is an architectural wonder with a central fountain in the middle of the Savanna desert. Game Arts very clearly discarded their standard world building cookie cutters, and their efforts shine through.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002486.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002486.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002486.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>The world map. The feather icon indicates where you will travel next.</em></figcaption></figure>
</div>


<p>Once a locale has been explored, it will appear as a selectable destination on a gorgeous, hand-drawn high-resolution world map. Exiting an area often brings our party to this world map, and the next destination can be selected.</p>



<p>If the towns serve to heal the party, upgrade equipment, and advance the story, then the dungeons of the game offer treasure hunting, exploration, and of course, combat! Dungeons in <em>Grandia</em> range from literal underground labyrinths to above-ground forest mazes, to even large open plains that Justin et al. must traverse. Some of the more noteworthy settings include scaling a giant wall that keeps the world divided into two separate societies, negotiating the bowels of a ghost ship which appears out of nowhere to molest a transcontinental steamer, and even conquering the inside of an unstable volcano that’s inhabited by an ancient dragon.</p>



<p>Here, the player really must use their L and R buttons to shift the 3D landscape around, to find all the nooks of treasure or paths forward. Some areas feature set pieces that Justin and party can activate — for example, knocking over a loose pillar to bridge a gap. These are usually indicated by an exclamation point icon when the party nears the set piece.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002499.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002499.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002499.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>Some of the spells are quite spectacular.</em></figcaption></figure>
</div>


<p>All the while, treasure both great and small litters the landscape… but so do enemies! Enemies are visible in the dungeons and so can be avoided to an extent, but if Justin and party come in contact with an enemy, combat ensues.</p>



<h3><em>Grandia</em> Grinder Alert!<br>Grind for Experience Points Using Environmental Damage!</h3>



<p>Are YOU a <em>Grandia </em>grinder?? Some sections of the game will deal damage to Justin and party outside of combat. First noticed in the Dom Ruins, rock faces painted into some of the dungeon walls will cause mild HP damage by springing out and poking the party when the party doesn’t want to be poked! The player can then use heal magic and spam this process to quickly increase Water magic levels. Although definitely a grind, it’s much faster than earning those experience points via combat. A few other areas in the game present similar opportunities — such as the basement in the Castle of Dreams.</p>



<h2>A New Kind of Kombat</h2>



<p><em>Grandia</em> introduced an all-new combat system to the RPG genre, though it could be said to be a variant of other similar RPG battle systems. Essentially, all battle participants have icons that continuously move along a <strong>universal IP Gauge</strong>, until they reach the Command point. Here, the player will enter from a selection of commands which includes attacking, using an item or a spell, guarding, or even retreating. They then wait to reach the very end of the gauge to execute their selected action, and the more experienced the character, the faster that point is reached. <strong>A ton of strategy is introduced here</strong> as during this waiting period between selecting an action and executing it, they are vulnerable to both Cancels and Counterattacks from their opponents. Unlike many contemporary RPGs where the instinct is to simply unleash physical and magical attacks in a turn-based order, <strong>the player can take advantage of these waiting periods</strong> to cancel out incoming enemy attacks and push them back on their IP gauge. The system will take some getting used to, but can be used to devastating effect, especially in the more drawn-out boss battles. It is entirely possible to strategically get in a half-dozen actions by each character and prevent a boss from retaliating during the entire sequence, by carefully timing attacks. This makes combat a lot more involved and exciting.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002528.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002528.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002528.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>Cancel culture? Counterculture? Grandia’s got it all.</em></figcaption></figure>
</div>


<p>There are also advantages to catching an enemy unawares — player characters start much further ahead on their IP Gauge, with the reverse being true if Justin’s party is ambushed.</p>



<p>Players have a range of actions they can take when their IP Gauge is full, from the standard fare of using items, defending, running away, or even inspecting an enemy (is that slug-monster male or female, for example*).</p>



<figure>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="126" height="126" data-id="53363" src="https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/2.png?resize=126%2C126&amp;ssl=1" alt=""></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="126" height="126" data-id="53365" src="https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/3.png?resize=126%2C126&amp;ssl=1" alt=""></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="124" height="126" data-id="53364" src="https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/1.png?resize=124%2C126&amp;ssl=1" alt=""></figure>
</figure>



<p>Nana, Saki, and Mio are Mullen’s three she-sergeants. Serving as comedic relief, they are nevertheless quite capable opponents in battle.</p>



<h2>By Your Powers Combined… I Am Captain Planet!</h2>



<p>Earth. Fire. Wind. Water. These are the elemental forces that move the world, and most characters can master them! Learning magic in <em>Grandia</em> first requires that the party finds a <strong>Mana Egg</strong>. These rare items can then be exchanged in a shop for magic for a single character of your choice. That party member then learns the basics of your chosen magic element.</p>



<p>Inside of the four elements, magic spells are further split into levels, from one to three, to indicate their potency. Level 1 spells are your most basic spells and are what a character starts off with should they buy magic with their mana egg. Players that use magic in combat will gain skill points in that particular element, and those skill points are applied to all spells of that element, regardless of spell level — so, use a Level 1 Fire spell, and all levels of your Fire magic gain skill. Spell skill progression is represented by five red stars that fill up like a gauge, turning yellow as they gain experience. Greater experience shortens casting time (which, remember, is a vulnerable time as your spell can be cancelled by an opponent) and at higher levels, allows your character to learn combined element magic spells. All magic spells consume MP making them a limited resource, though a character’s overall MP capacity will grow with experience.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002917.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002917.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002917.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>The snowy village of Laine. The water effects are <strong>chef’s kiss</strong>.</em></figcaption></figure>
</div>


<p>Outside of magic, each character can also execute <strong>special attacks</strong> that are unique to them. These attacks are usually more devastating than standard attacks and sometimes require that the character is using a particular weapon class. These, too, gain skill points represented by five red stars that slowly build up to yellow, though special attacks consume SP (skill points). SP works much the same way as MP.</p>



<h3>Grandia Grinder Alert!<br>Rare Enemies Give High XP</h3>



<p>Typically, the game’s monsters do a good job of seeking you out, but there are occasional difficult-to-catch enemies to be found as well. Notice, for instance, the Chameleon enemies in the Virgin Forest. These green creatures are shy and are hard to catch and engage. But persist, and finish them off for a huge load of experience points — well worth a grinding sesh or three.</p>



<h2>Experience Required</h2>



<p><em>Grandia</em> has a complex (for the time) experience points system, which is cleverly segmented into several categories.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002507.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002507.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002507.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>Level up!</em></figcaption></figure>
</div>


<p>To start, each playable character has a set of basic stats that slowly increase as they gain experience. Hit Points (HP) are your standard measure of health and these increase at level-ups. SP are your skill points, which increase the speed and potency of your special attacks, as well as unlock new special attacks as you accumulate experience. Finally, the same is true of the more traditional magic points (MP), with the difference between SP and MP being that special attacks are individualized whereas magic attacks are more common amongst party members and can be bought in exchange for Mana Eggs.</p>



<p>As they adventure, Justin and company will occasionally find items that slightly <strong>boost a particular stat on a permanent basis.</strong> These items are rare indeed, but as with life, incremental gains tend to compound until the effects are undeniable.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002940.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002940.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002940.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>The Seed of Speed grants a permanent stat boost.</em></figcaption></figure>
</div>


<p>Most traditionally, defeating enemies grants experience points and accumulating the required amount grants characters a level-up, which slightly increases basic stats. Experience gained and gold / treasure collected is displayed on an after-battle screen. It is this type of XP that most contemporary RPGs concerned themselves with. <em>Grandia</em> ups the complexity a bit by introducing leveling for magic and skills, and further mixes things up by employing different weapon classes.</p>



<p>Justin and company are each capable of wielding a few different types of weapons, of which there are seven in total, ranging from swords to maces to staffs to bows. Each weapon class has its advantages and disadvantages, be it speed of use (from Command input to Execution on the IP gauge), to range, to overall damage dealt. As party members use their weapons, they gain experience in those weapon types, separately from their character experience.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002512.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002512.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002512.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>The texture work is awesome throughout.</em></figcaption></figure>
</div>


<p>In total, <em>Grandia</em> features basic character experience points which boosts common stats, magic experience which results in spells being cast faster and the learning of higher-level spells for various element types, skill experience for faster execution of special attacks, and weapon experience points which increase how well a character will handle that weapon type. Cleverly, these different experience categories are implemented in such a way as to make it entirely possible for gamers to completely ignore this aspect of the game should they so fancy. Because the system is automated, gamers can pay all of it little heed and still progress and have a great time with the game. Alternately, gamers can dive right into the finer points of the system to make those minor tweaks to get their characters to exactly the state they prefer.</p>



<figure>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="126" height="126" data-id="53366" src="https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/Liete.png?resize=126%2C126&amp;ssl=1" alt=""></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="123" height="124" data-id="53368" src="https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/Puffy.png?resize=123%2C124&amp;ssl=1" alt=""></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="126" height="122" data-id="53367" src="https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/Darlin.png?resize=126%2C122&amp;ssl=1" alt=""></figure>
</figure>



<p>The mysterious Liete awaits at Alent. The enigmatic Puffy accompanies Sue wherever she goes. Lastly, Darlin is one of the many non-human denizens of Grandia.</p>



<h2>Go with the Flow</h2>



<p><em>Grandia</em> allows up to <strong>four playable characters</strong> to form Justin’s party at any one time. As the story progresses, some of the main characters will permanently step away from the adventure, for reasons practical and dramatic alike. One such parting in particular tugs at the heartstrings — it is nothing quite as dramatic as the year’s earlier death of Aeris (Aerith) from that big RPG on Sony’s lesser 32-bit machine, but it somehow feels more relatable, and more impactful. Players ought not be surprised by the need for tissues to manage an unexpected tear or two. And here, too, <em>Grandia</em> innovates: a portion of a departing playable character’s magic and weapon experience points are stored in the stashing place, to be retrieved and applied to whatever character you see fit. This strengthens their legacy in your party, as well as provide a practical reason not to neglect building up a character just because they may eventually leave the party. A nice touch.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002976.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002976.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002976.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>At the foot of the End of the World.</em></figcaption></figure>
</div>


<h2>Is It Perfect?</h2>



<p>Grand as it sounds, the game isn’t without a few small flaws. Story-wise, players will be left wanting to know more about Justin’s father and how he came to be the keeper of his Spirit Stone. He is mentioned often in the early stages of the game, but as Justin’s adventure takes off, that arc never completes. Likewise for General Baal — we eventually learn his motivations, but not so much why he has become who he is today. A really well put together villain is one with whom we can empathise; someone whose circumstance we can understand. Both with Justin’s unnamed father and with Baal, there is a feeling that we are reading a book and that the answers lie just ahead, but despite some teasing, <em>Grandia</em> never lets us turn the page.</p>



<p>Technically, the game’s 3D is solid and varied, with plenty of minor details and meticulous textures, especially in the town sections. Blending VDP2-drawn planes with solid geometry and animated sprites means the world of <em>Grandia</em> is beautifully rendered, but that comes at the cost of an oft-stuttering framerate. The more of <em>Grandia</em>’s world we are allowed to see at once, the more the framerate suffers. Now, these were the formative years of 3D gaming, but at times, that framerate simply chugs, and it’s noticeable to the point of distraction. Thankfully, for most of the game, the framerate sits comfortably in the ‘acceptable’ space, but you won’t get through the game without feeling the Saturn sweat as it works to display all that <em>Grandia</em>’s artists wanted you to see.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002376.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002376.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002376.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>Special Moves. These gain experience as well.</em></figcaption></figure>
</div>


<p>Speaking of 3D, the game often requires the shifting of camera angles when exploring. When in long dungeons or any other large space, this can quickly become disorienting, and the player will lose their sense of direction. The game compensates somewhat for this with the addition of the compass, though its implementation is somewhat clumsy as rather than point north, it points to an exit or other objective. <strong>There is also lookout points called Dungeon Scopes</strong>, where the player is given a bird’s eye view of their current location from a default ‘north is up’ viewpoint. This helps orientating, but those lookout points are few and far between and using them tends to break up the game’s flow. Players may well find themselves keeping their camera shifting to a minimum as a result.</p>



<p>Lastly, a technical note: <em>Grandia</em> sure gives the Saturn’s laser a workout, and there are some clever pre-loading techniques implemented to keep the game flowing as smoothly as possible. The cost here is that <em>Grandia</em> is very sensitive to disc quality. Those that have burnt their English-patched game onto CDs and are playing on real Saturn hardware may well find the game freeze, especially in battle when calling various spells. This is VERY annoying, especially as dungeon save points are sparse, and it is not uncommon to be in the heat of a battle only to have everyone freeze with the reset button being the only escape. This is remedied by using an ODE solution that omits discs entirely, but the game’s sensitivity to the quality of your CD-R burn needs to be called out.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002964.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002964.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002964.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>Hell yeah! Feena’s strongest spell.</em></figcaption></figure>
</div>


<h2>Final Word</h2>



<p><strong><em>Grandia </em>is great.</strong> The visuals are gorgeous, the music is appropriately evocative, the combat is frenetically strategic, and the story is well paced. Tough battles and surprise plot twists await intrepid gamers, and sub-plots occasionally weave their way into the adventure, too — especially in sections where we briefly leave Justin. On occasion, players will follow Colonel Mullen with Feena, explore the mysterious past of Mullen’s attaché Leen, or even soak in the comedic antics of the three beautiful Garlyle generals Mio, Nana, and Saki.</p>



<p>Ultimately, <em>Grandia</em> a delight to play. A total joy… but one that demands an <strong>intense time commitment</strong>. A player Justin’s age surely has the time, but what about those of us that are well into adulting? Some sections of the game, especially the longer dungeons, have few opportunities to save one’s game. In that sense, the game is a total hardcore, traditional JRPG. It is not easily digested in small play sessions, so playing <em>Grandia </em>is committing a huge slice of one’s discretionary time budget.</p>



<p>And yet, perhaps paradoxically, playing <em>Grandia</em> has a way of making one feel young again. <em>Grandia</em> is grand in the same way we ourselves felt grand as youngsters — that, armed with a stick we’ve just picked up and nothing more than our imagination, our wits, and our indomitable spirit, we could go forth boldly and change the world. That’s the beauty of a main character like Justin — he is not yet jaded; he has not yet borne the <strong>burden of grown-up problems on his shoulders</strong>. In many ways, we were all Justin (or Sue!) at one point, and the game shines a light on that part of us that is now long behind (most of) us. Perhaps the most memorable aspect of <em>Grandia</em> is that it allows us, for a moment all too brief, to once again be that young boy or girl full of optimism and energy, and in today’s complex and stressful world, that feels simply wonderful.</p>


<div>
<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="728" height="546" src="https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/Grandia.jpg?resize=728%2C546&amp;ssl=1" alt="" srcset="https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/Grandia.jpg?w=800&amp;ssl=1 800w, https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/Grandia.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/www.segasaturnshiro.com/wp-content/uploads/2025/11/Grandia.jpg?resize=768%2C576&amp;ssl=1 768w" sizes="auto, (max-width: 728px) 100vw, 728px"><figcaption><em>Promotional art that showcases one of the game’s most powerful moments: Justin, Sue, and Feena have climbed the wall at the end of the world, and see, for the first time, the lands on the other side.</em></figcaption></figure>
</div>


<div>
<h2>Three Optional Dungeons</h2>



<p><em>Grandia</em> is generally a well-balanced affair, with experience accumulating at the right rate for players to progress in the game. That said, the world of <em>Grandia</em> plays host to three completely optional dungeons meant solely for increasing character abilities and experience — and goes so far as to explicitly point out that these areas are not part of the game’s story and are entirely optional.</p>



<p>The first such dungeon can be found just west of the first section of the Zil Desert. It’s a large, very dark brown multi-leveled maze with the only save point being at the entrance. The enemies are tougher than one would expect at this point in the game, but nothing is impossible for Justin et al. The key here is to find the four Soldier’s Souls, which grants access to the treasures of the dungeon, at the very end, past the boss. The boss is a remix of a previous boss from Feena’s failed wedding to Pakon and packs quite a punch. The main prize here is the excellent Godspeed Knife, which adds a huge ACT boost, to massively speed up the user’s IP gauge.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002930.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002930.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002930.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>The Soldier’s Graveyard entrance.</em></figcaption></figure>
</div>


<p>The second optional dungeon is also found to the west but is accessible from the second part of the Zil Desert. This dungeon is very small but has perhaps the most charm. Justin and company are greeted by a mysterious Lady at the castle entrance, begging for help but also warning of a curse on the castle. Once inside, there are several rooms to visit and loot to collect. Really simplistic and set to lure the player to lower their guard, just in time to battle the formidable Lord’s Ghost boss. This guy’s TOUGH, with strong multi-character attacks and cancelling moves. Take him down to claim the awesome Lightning Sword, which gives a 50 ATK boost and, as an elemental sword, has the Zap! spell built in.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002936.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002936.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002936.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>Don’t thank us yet…</em></figcaption></figure>
</div>


<p>The final optional dungeon is the mother of all dungeons in<em> Grandia</em>. Found tucked away in the Savanna Wilderness and accessible via a secret passage, the Tower of Temptation consists of an outside area and 12 (!) floors of punishing combat. Of course, the only save point is at the very start of the outside area, though Justin can activate a couple of shortcuts through the tower as he makes progress, so that backtracking to heal and save is a bit easier. Interestingly, the starting area is surrounded by six Zero Weapons – one of each kind of weapons that grants a 0 ATK value — ideal for training weapons on weaker enemies, as these will do nearly no damage.</p>



<p><strong><em>Grandia</em> Grinder Mini-Alert</strong>: many enemies in the Tower drop stat-increasing items, making this an ideal place to pull it all out and go for that growth.</p>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002973.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002973.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002973.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>Prepare to spend hours on this dungeon.</em></figcaption></figure>
</div>


<p>Each floor of the Tower features maze sections, hidden doors, powerful enemies, and of course, switches to hit. Simply by making one’s way through the tower will increase the party’s levels, as there is so much battling to do. It is not uncommon to spend hours in the Tower, so it’s a welcome fact that the Tower is entirely optional. The final three floors are all boss — yes, there are three bosses to fight in a row. No saving, no healing. The final of the three bosses is tough as nails, but the reward is well worth it — NINE amazing items to pick up, including two items from the Grinder’s Gear™ premium collection: the Astral Miracle and the Ethereal Miracle, both accessories that double weapon or magic experience gained. VERY useful, but they better be, considering the pain just endured to complete the Tower of Temptation!</p>
</div>



<h2>The Universe is Grand…ia</h2>



<p><em>Grandia</em> went on to <strong>sell bucket-loads in Japan</strong>, especially during release week. It received a Digital Museum DLC-style disc, got a port on the mass-market PlayStation including a PS Greatest Hits re-release, and finally, a PlayStation English localization in 1999. The series continued in 2000 with the excellent <em>Grandia 2</em> on Dreamcast, which itself was later poorly ported to Sony’s killer of dreams, the PlayStation 2. That system would also see the less-well received <em>Grandia 3</em>, which would spell the end of the main series’ run. The series also saw several spin-off games such as <em>Grandia Xtreme</em> and <em>Grandia Online</em>. Additionally, the first <em>Grandia</em> was recently remade for modern consoles with the release of the <em>Grandia HD Collection</em>.</p>



<p>*Note: you cannot inspect monsters’ genders in battle. That was just a joke. Also there is no Grinder’s Gear in Grandia. </p>



<h2>I’m Not Crying, You’re Crying!</h2>


<div>
<figure><img loading="lazy" decoding="async" width="704" height="448" src="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002478.bmp" alt="" srcset="https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002478.bmp 704w, https://www.segasaturnshiro.com/wp-content/uploads/2025/11/00002478.bmp 300w" sizes="auto, (max-width: 704px) 100vw, 704px"><figcaption><em>A beautiful scene.</em></figcaption></figure>
</div>


<p>A bit of a personal story… The above screenshot is my favorite scene in all of Grandia. See, the game does a brilliant job of bringing us back to the days of youthful adventures where nothing at all was impossible, and despite whatever danger beset us, we knew deep down that in the end, we would be all right. But in the most subtle of ways, Grandia also covers personal growth and the passage of time. </p>



<p>At some point, deep into the adventure, 8-year-old Sue gets tired. At first, she temporarily leaves the party whilst recuperating at a local sick house, with everyone hoping (and the player confidently knowing) that she will get better. But… she doesn’t. She puts on a brave face and re-joins the party, going on one final quest. As the gamer, I kept looking for the herb or special item that I could find to cure her, but no such moment ever came. There never was any single wound or ailment that Sue suffered, it’s just that one day, she simply… got tired, and ultimately, had to leave the party. She was a trooper through the entire adventure; completely indispensable she was, but there was a sunset to her time on the grand adventure, and she ended up leaving far too soon for my liking.</p>



<p>In real life, this sometimes happens, too. People in our orbit — strong, vibrant people, whom we believe will be with us forever — sometimes, unexpectedly, undeservedly… get tired, and have to quit the great adventure. Sometimes they are even younger than us, or in better health than us, or benefitting from any number of other factors that make their leaving seem senseless and cruelly unfair. It’s a reminder of the finite nature of life, and that sometimes we are living oh so naively and innocently through what we will later call the best times of our lives.</p>



<p>Sometimes, we get a chance to say our goodbyes before they depart us, and this is something Justin and Feena were able to share with Sue. With tears in her eyes, even as she bade farewell, she wished for Justin to follow his dreams and complete his long quest to find Angelou. It’s this that ties all of these sentiments together, for me. We all get older. We all leave our childhood behind us and begin to lead our adult lives in earnest. Our carefree days of questing and playing our days away, confident that in the end, everything will be all right, are replaced by planning, worrying, pressure, stress, failure, and other harsh realities of life. Here, Sue reminds us of the importance of not forgetting our dreams. We may not have the time or the energy that we did then, but whatever the obstacles, we must always go boldly in the direction of our dreams, hand-in-hand with those who love us, for we, too, will one day exit the adventure. In our final moments, what sweeter satisfaction could there be than to warmly smile at those who walked with us, and to look back on our journey with pride.   </p>	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Modern Walkmans (153 pts)]]></title>
            <link>https://walkman.land/modern</link>
            <guid>46201381</guid>
            <pubDate>Tue, 09 Dec 2025 04:57:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://walkman.land/modern">https://walkman.land/modern</a>, See on <a href="https://news.ycombinator.com/item?id=46201381">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div>
	<div>
		
		<p><sub>Cassette Players for the Modern Digital Age</sub>
	</p></div>
	<p>Σ 11 models</p>
</div>

<div id="9"><p><a href="https://walkman.land/modern/aurex-ax-w10c"><img src="https://walkman.land/public/img/modern/aurex-1.jpg" loading="lazy" alt="Aurex AX-W10C (Walky) feature"></a></p><div><p>(Toshiba) Wireless cassette player with Bluetooth, you can enjoy cassettes with wireless earphones. Equipped with virtual surround sound, you can enjoy realistic sound. It can play cassette tapes for about 16 hours (2*AA alkaline batteries). It can also be powered, and played from a USB port. Weight 230g. Selling primarly in Japan.</p></div></div><div id="5"><p><a href="https://walkman.land/modern/byron-statics"><img src="https://walkman.land/public/img/modern/byronstatics-1.jpg" loading="lazy" alt="Byron Statics feature"></a></p><div><p>Bring out the soundtrack of past memories on Your cherished cassettes. FM/AM Radio playback. Voice Activation System. Automatic Stop System. 2AA Battery or USB power supply. KCS-315</p></div></div><div id="4"><p><a href="https://walkman.land/modern/digitnow"><img src="https://walkman.land/public/img/modern/digitnow-1.jpg" loading="lazy" alt="DIGITNOW! feature"></a></p><div><p>The personal cassette player looks the part with its retro silver casing and comes complete with earphones for your private listening. With bluetooth function, can transmit the music to other bluetooth receivers and let everyone enjoy the music.</p></div></div><div id="7"><p><a href="https://walkman.land/modern/fiio-cp13"><img src="https://walkman.land/public/img/modern/fiio-cp13-1.jpg" loading="lazy" alt="FiiO CP13 feature"></a></p><div><p>Achieving ultra-low Wow and Flutter. Oversized pure copper flywheel. 100% pure analog sound &amp; custom balanced amplification head. Classic audiophile op-amp JRC5532. High voltage motor power supply. Dual-color all-aluminum alloy chassis and a long-lasting 13 hours of battery life.</p></div></div><div id="3"><p><a href="https://walkman.land/modern/gpo"><img src="https://walkman.land/public/img/modern/gpo-1.jpg" loading="lazy" alt="GPO feature"></a></p><div><p>Battery powered and with built in speakers, just plug in your cassette and you're ready to go. The portable cassette player was an iconic piece of kit for music fans in the 80s and 90s. Play tapes or use the FM radio and listen through your headphones.</p></div></div><div id="10"><p><a href="https://walkman.land/modern/its_ok"><img src="https://walkman.land/public/img/modern/ITSOK_details1.webp" loading="lazy" alt="It's OK! feature"></a></p><div><p>It is the world’s first cassette player with Bluetooth 5.0 capability that not only supports traditional 3.5mm headphones but is also compatible with Bluetooth 5.0 headphones or speakers. Whether you are alone or in an open space, you can freely enjoy the penetrating voice and warm sound from the cassette tape.</p></div><div><p><strong>(+)</strong> Nice translucent design. Bluetooth connection. Built-in microphone.</p><p><strong>(-)</strong> No autoreverse, or any convenience function. No headphone.</p><p><span>Web:</span> <a href="https://www.ninmlab.com/its-ok">https://www.ninmlab.com/its-ok</a></p></div></div><div id="8"><p><a href="https://walkman.land/modern/jensen"><img src="https://walkman.land/public/img/modern/jensen-1.jpg" loading="lazy" alt="Jensen feature"></a></p><div><p>Jensen Portable Compact Lightweight Slim Design Stereo, AM/FM Radio Cassette Player.

Pop in that favorite cassette or relive the magic of the mixed tape with Jensen's Portable Stereo Cassette Player AM/FM Stereo Cassette Player. When you're feeling more like the radio, tune into the AM or FM dial. You can also get up to the minute weather info with local Weather Band broadcasts. And, in the name of keeping things economical, just 2 'AA' battery has the Walkman up and running for hours on end.</p></div></div><div id="11"><p><a href="https://walkman.land/modern/maxell-mxcp-p100"><img src="https://walkman.land/public/img/modern/mxcp-p100_1.webp" loading="lazy" alt="Maxell MXCP-P100 feature"></a></p><div><p>It supports Bluetooth v5.4 , which provides high communication quality and low power consumption. Brass flywheel adopted. Reduces rotational irregularities and provides high quality sound. Bultin battery, accumulator. Playback time is around 9 hours. Weight 210g.</p></div></div><div id="6"><p><a href="https://walkman.land/modern/mulann-b-1000-ew"><img src="https://walkman.land/public/img/modern/mulann1000-1.webp" loading="lazy" alt="Mulann B-1000 EW feature"></a></p><div><p>Affordable modern portable cassette tape player &amp; recorder with 2 track, stereo playback. Good sound quality, plays all (I-IV) cassettes. Frequency response : 40Hz-11KHz (Type I), Signal-to-noise ratio 50dB, Distorsion 1%, Wow &amp; Flutter 0.3%, Headphone output power: 2x2 mW into 32 ohms</p></div></div><div id="2"><p><a href="https://walkman.land/modern/tomashi"><img src="https://walkman.land/public/img/modern/tomashi-1.jpg" loading="lazy" alt="TOMASHI feature"></a></p><div><p>Entry level portable cassette player. F116/F113</p></div></div><div id="1"><p><a href="https://walkman.land/modern/we-are-rewind"><img src="https://walkman.land/public/img/modern/we-are-rewind-cassette-player-serge.webp" loading="lazy" alt="We Are Rewind feature"></a></p><div><p>As you will have understood, this cassette player is the best of the best! The "crème de la crème" as they say in French. An object that is both cult and essential for any self-respecting music lover.</p></div></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Horses: AI progress is steady. Human equivalence is sudden (493 pts)]]></title>
            <link>https://andyljones.com/posts/horses.html</link>
            <guid>46199723</guid>
            <pubDate>Tue, 09 Dec 2025 00:26:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andyljones.com/posts/horses.html">https://andyljones.com/posts/horses.html</a>, See on <a href="https://news.ycombinator.com/item?id=46199723">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
        
<p>So after all these hours talking about AI, in these last five minutes I am going to talk about: horses.</p>
<p><img src="https://andyljones.com/source/horses/horse_efficiency.png" alt="Engine efficiency over time, showing steady improvement"></p>
<p>Engines, steam engines, were invented in 1700.</p>
<p>And what followed was 200 years of steady improvement, with engines getting 20% better a decade.</p>
<p>For the first 120 years of that steady improvement, horses didn't notice at all.</p>
<p>Then, between 1930 and 1950, 90% of the horses in the US disappeared.</p>
<p>Progress in engines was steady. Equivalence to horses was sudden.</p>
<hr>

<p>But enough about horses. Let's talk about chess!</p>
<p><img src="https://andyljones.com/source/horses/chess.png" alt="Computer chess Elo over time, showing steady 50 point per year improvement"></p>
<p>Folks started tracking computer chess in 1985.</p>
<p>And for the next 40 years, computer chess would improve by 50 Elo per year.</p>
<p>That meant in 2000, a human grandmaster could expect to win 90% of their games against a computer.</p>
<p>But ten years later, the same human grandmaster would lose 90% of their games against a computer.</p>
<p>Progress in chess was steady. Equivalence to humans was sudden.</p>
<hr>

<p>Enough about chess! Let's talk about AI.</p>
<p><img src="https://andyljones.com/source/horses/project_cost.png" alt="AI datacenter capital expenditure over time"></p>
<p>Capital expenditure on AI has been pretty steady.</p>
<p>Right now we're - globally - spending the equivalent of 2% of US GDP on AI datacenters each year.</p>
<p>That number seems to have steadily been doubling over the past few years.</p>
<p>And it seems - according to the deals signed - likely to carry on doubling for the next few years.</p>
<hr>

<p>But from my perspective, from equivalence to me, it hasn't been steady at all.</p>
<p><img src="https://andyljones.com/source/horses/ask_claude.png" alt="Questions answered by humans vs Claude over time"></p>
<p>I was one of the first researchers hired at Anthropic.</p>
<p>This pink line, back in 2024, was a large part of my job. Answer technical questions for new hires.</p>
<p>Back then, me and other old-timers were answering about 4,000 new-hire questions a month.</p>
<p>Then in December, Claude finally got good enough to answer some of those questions for us.</p>
<p>In December, it was some of those questions. Six months later, 80% of the questions I'd been being asked had disappeared.</p>
<p>Claude, meanwhile, was now answering 30,000 questions a month; eight times as many questions as me &amp; mine ever did.</p>
<hr>

<p>Now. Answering those questions was only part of my job.</p>
<p>But while it took horses decades to be overcome, and chess masters years, it took me all of six months to be surpassed.</p>
<p><img src="https://andyljones.com/source/horses/per_token_cost.png" alt="Cost per million words: AI researcher vs subsistence farmer vs Sonnet"></p>
<p>Surpassed by a system that costs one thousand times less than I do.</p>
<p>A system that costs less, per word thought or written, than it'd cost to hire the cheapest human labor on the face of the planet.</p>
<hr>

<p>And so I find myself thinking a lot about horses, nowadays.</p>
<p><img src="https://andyljones.com/source/horses/horse_car.png" alt="Horses vs cars in the United States, with 'me' marked at 1920"></p>
<p>In 1920, there were 25 million horses in the United States, 25 million horses totally ambivalent to two hundred years of progress in mechanical engines.</p>
<p>And not very long after, 93 per cent of those horses had disappeared.</p>
<p>I very much hope we'll get the two decades that horses did.</p>
<p>But looking at how fast Claude is automating my job, I think we're getting a lot less.</p>
<hr>

<p><em>This was a five-minute lightning talk given over the summer of 2025 to round out a small workshop.</em></p>
<p><em>All opinions are my own and not those of my employer.</em></p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The universal weight subspace hypothesis (324 pts)]]></title>
            <link>https://arxiv.org/abs/2512.05117</link>
            <guid>46199623</guid>
            <pubDate>Tue, 09 Dec 2025 00:16:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2512.05117">https://arxiv.org/abs/2512.05117</a>, See on <a href="https://news.ycombinator.com/item?id=46199623">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2512.05117">View PDF</a>
    <a href="https://arxiv.org/html/2512.05117v2">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>We show that deep neural networks trained across diverse tasks exhibit remarkably similar low-dimensional parametric subspaces. We provide the first large-scale empirical evidence that demonstrates that neural networks systematically converge to shared spectral subspaces regardless of initialization, task, or domain. Through mode-wise spectral analysis of over 1100 models - including 500 Mistral-7B LoRAs, 500 Vision Transformers, and 50 LLaMA-8B models - we identify universal subspaces capturing majority variance in just a few principal directions. By applying spectral decomposition techniques to the weight matrices of various architectures trained on a wide range of tasks and datasets, we identify sparse, joint subspaces that are consistently exploited, within shared architectures across diverse tasks and datasets. Our findings offer new insights into the intrinsic organization of information within deep networks and raise important questions about the possibility of discovering these universal subspaces without the need for extensive data and computational resources. Furthermore, this inherent structure has significant implications for model reusability, multi-task learning, model merging, and the development of training and inference-efficient algorithms, potentially reducing the carbon footprint of large-scale neural models.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Prakhar Kaushik [<a href="https://arxiv.org/show-email/784dfcb8/2512.05117" rel="nofollow">view email</a>]      <br>            <strong><a href="https://arxiv.org/abs/2512.05117v1" rel="nofollow">[v1]</a></strong>
        Thu, 4 Dec 2025 18:59:58 UTC (14,316 KB)<br>
    <strong>[v2]</strong>
        Sat, 6 Dec 2025 04:42:07 UTC (14,321 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kroger acknowledges that its bet on robotics went too far (219 pts)]]></title>
            <link>https://www.grocerydive.com/news/kroger-ocado-close-automated-fulfillment-centers-robotics-grocery-ecommerce/805931/</link>
            <guid>46199411</guid>
            <pubDate>Mon, 08 Dec 2025 23:53:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.grocerydive.com/news/kroger-ocado-close-automated-fulfillment-centers-robotics-grocery-ecommerce/805931/">https://www.grocerydive.com/news/kroger-ocado-close-automated-fulfillment-centers-robotics-grocery-ecommerce/805931/</a>, See on <a href="https://news.ycombinator.com/item?id=46199411">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        


<div>
        <p>
            This audio is auto-generated. Please let us know if you have <a href="https://www.grocerydive.com/contact/">feedback</a>.
        </p>
    </div>


                        

<p>Kroger’s <a href="https://www.grocerydive.com/news/kroger-ecommerce-profitability-400M-ocado-automated-fulfillmnet-centers-delivery/805781/">announcement on Tuesday</a> that it will shutter three of its robotic e-commerce fulfillment facilities represents a sharp turnabout for the grocery company, which until recently had expressed confidence in its ability to leverage automation to run a profitable online grocery business.</p>
<p>Less than a year ago, Kroger said it <a href="https://www.grocerydive.com/news/kroger-and-ocado-plan-to-open-2-more-automated-fulfillment-centers/741254/">planned to expand</a> the fleet of high-tech fulfillment centers it has been developing in partnership with U.K.-based warehouse automation company Ocado. And in mid-2024, Kroger revealed that it would <a href="https://www.grocerydive.com/news/kroger-ocado-technology-automated-fulfillment-centers/721986/">install new technology</a> from Ocado to improve the efficiency of the warehouses.</p>



<p>When Kroger <a href="https://www.grocerydive.com/news/grocery--kroger-partners-with-ocado-in-a-bet-on-the-future-of-online-grocery/534008/">launched its partnership with Ocado</a>, the company “believed in the relentless drive to innovate way ahead of the market in order to delight our customers and advance our position as one of America’s leading e-commerce companies,” former Kroger CEO Rodney McMullen <a href="https://www.youtube.com/watch?v=E4kH-atEpd4">said in a video</a> about improvements to its equipment that the automation company announced last year.</p>
<p>However, Kroger’s projected confidence came even as it was questioning whether the Ocado network was living up to expectations.</p>
<p>Kroger revealed in September 2023 that it had decided to <a href="https://www.grocerydive.com/news/kroger-ocado-grocery-cfc-delivery-pickup/693287/">pause development of the Ocado project</a> as it waited to see if sites it had already started operating would meet performance benchmarks.</p>
<p>In a further sign that its strategy was faltering, Kroger announced last March it would <a href="https://www.grocerydive.com/news/kroger-ocado-closing-3-e-commerce-fulfillment-facilities/711583/">close three spoke facilities</a> that worked in tandem with several of its robotic centers, with a spokesperson noting that the facilities “did not meet the benchmarks we set for success.”</p>
<p>By September 2025, it was clear that depending on automation as the foundation of a money-making grocery delivery business was probably not going to pan out for Kroger. Speaking during an earnings call, interim Kroger CEO Ron Sargent — who <a href="https://www.grocerydive.com/news/kroger-ceo-rodney-mcmullen-resigns-ethics-probe/741345/">took over in March</a> after McMullen’s sudden departure following an ethics probe — said the company would <a href="https://www.supplychaindive.com/news/kroger-is-reviewing-its-automated-e-commerce-fulfillment-network/759926/">conduct a “full site-by-site analysis</a>” of the Ocado network.</p>
<p>Sargent also said Kroger would refocus its e-commerce efforts on its fleet of more than 2,700 grocery supermarkets because it believed that its stores gave it a way to “reach new customer segments and expand rapid delivery capabilities without significant capital investments.”</p>


<p>Kroger said on Tuesday that its decision to close the three robotic facilities, along with other adjustments to its e-commerce operations, would provide a $400 million boost as it looks to improve e-commerce profitability. But the course-correction will be expensive, forcing Kroger to incur charges of about $2.6 billion.</p>
<p>Ken Fenyo, a former Kroger executive who now advises retailers on technology as managing partner of Pine Street Advisors, said the changes Kroger is making reflect the broader reality that grocery e-commerce has not reached the levels the industry had predicted when the COVID-19 pandemic supercharged digital sales five years ago.</p>
<p>Fenyo added that Kroger’s decision to locate the Ocado centers outside of cities turned out to be a key flaw.</p>
<p>“Ultimately those were hard places to make this model work,” said Fenyo. “You didn’t have enough people ordering, and you had a fair amount of distance to drive to get the orders to them. And so ultimately, these large centers were just not processing enough orders to pay for all that technology investment you had to make.”</p>
<p>With its automated fulfillment network, Kroger bet that consumers would be willing to trade delivery speed for sensible prices on grocery orders. That model has been highly successful for Ocado in the U.K., but U.S. consumers <a href="https://www.grocerydive.com/news/delivery-speed-is-king-for-online-shoppers-survey-shows/599282/">have shown they value speed of delivery</a>, with companies like Instacart and DoorDash expanding rapidly in recent years and rolling out services like 30-minute delivery.</p>
<p>Acknowledging this reality, Kroger noted on Tuesday that it’s <a href="https://www.grocerydive.com/news/kroger-doordash-grocery-delivery-ecommerce/761315/">deepening partnerships with third-party delivery companies</a>. The grocer also said it will pilot “capital-light, store-based automation in high-volume markets” — a seeming nod to the type of micro-fulfillment technology that grocers have tested in recent years, and that Amazon is <a href="https://www.grocerydive.com/news/amazon-whole-foods-store-within-store-automated-micro-fulfillment/804749/">currently piloting in a Whole Foods Market</a> store in Pennsylvania.&nbsp;</p>
<p>Fenyo pointed out that micro-fulfillment technology has also run into significant headwinds, adding that he thinks that outside of areas with large numbers of shoppers and high online ordering volume, putting automated order-assembly systems in stores probably doesn’t justify the cost.</p>
<p>Kroger’s decision to reduce its commitment to automation also poses a significant setback to Ocado, which has positioned its relationship with Kroger as a key endorsement of its warehouse automation technology. Shares in the U.K.-based robotics company have fallen dramatically and are now <a href="https://www.theguardian.com/business/nils-pratley-on-finance/2025/nov/18/ocado-share-price-back-where-it-started-fancy-robots">back to their level 15 years ago</a>, when the company <a href="https://multiples.vc/public-comps/ocado-group-valuation-multiples">went public</a>.</p>

                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a system for active note-taking in regular meetings like 1-1s (123 pts)]]></title>
            <link>https://withdocket.com</link>
            <guid>46198430</guid>
            <pubDate>Mon, 08 Dec 2025 22:21:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://withdocket.com">https://withdocket.com</a>, See on <a href="https://news.ycombinator.com/item?id=46198430">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub no longer uses Toasts (111 pts)]]></title>
            <link>https://primer.style/accessibility/toasts/</link>
            <guid>46196831</guid>
            <pubDate>Mon, 08 Dec 2025 19:58:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://primer.style/accessibility/toasts/">https://primer.style/accessibility/toasts/</a>, See on <a href="https://news.ycombinator.com/item?id=46196831">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Toasts pose significant accessibility concerns and are not recommended for use.</p>
<h2 id="overview"><a href="#overview">Overview<!-- --> </a></h2>
<p>Toasts are small, rectangular notifications that pop up on the screen, triggered either by a user or system behavior. They commonly show up on the bottom left or right-hand side of the viewport and disappear after a preset amount of time.</p>
<p>While it can be tempting to use toast UI as a solution for your task, know that there are many accessibility and usability issues inherent with this pattern. Because of this, <strong>GitHub recommends using other more established, effective, and accessible ways of communicating with users</strong>.</p>
<h2 id="what-to-use-instead-of-toasts"><a href="#what-to-use-instead-of-toasts">What to use instead of toasts<!-- --> </a></h2>
<p>Primer offers a variety of solutions for informing users about updates. Consider:</p>
<ul>
<li>What kind of outcome you want to achieve, and</li>
<li>How the UI will best enable a user to do that.</li>
</ul>
<p>Are you attempting to highlight a successful or unsuccessful form submission? Give feedback that an action was successfully undertaken? Alert someone that a long-running task has finished?</p>
<p>Thinking through your use case can help select a UI treatment that not only best serves our users, but also reinforces the internal consistency of experience within the overall GitHub platform.</p>
<h3 id="successfully-completed-simple-actions"><a href="#successfully-completed-simple-actions">Successfully-completed simple actions<!-- --> </a></h3>
<p>User and system initiated actions that are direct and straightforward should be successfully completed as a matter of course. An example of this is creating an Issue, and then seeing the Issue show up on the list of Repo Issues.</p>
<p>There does not need to be a secondary form of reinforcement to communicate success, as it should be self-evident—including a toast to communicate this success may ironically lessen a sense of trust.</p>
<h3 id="successfully-completed-complex-actions"><a href="#successfully-completed-complex-actions">Successfully-completed complex actions<!-- --> </a></h3>
<p>User and system-initiated actions that require more complicated interaction may need additional feedback mechanisms to help inform the user that their request was successfully enacted. An example of this is the bulk creation of Issues.</p>
<p>Complex interactions may benefit from a secondary form of feedback to communicate success. The manner in which this secondary feedback is expressed depends on the design, but two common approaches are:</p>
<ol>
<li>Using <a data-inline="true" href="https://primer.style/product/ui-patterns/notification-messaging/">banners</a> to provide a summary of what was performed.</li>
<li>Progressively showing content as it is formed as part of a multi-step or progressive disclosure process.</li>
</ol>
<p>Note that both approaches persist feedback information and do not auto-dismiss it.</p>
<h3 id="unsuccessful-simple-and-complex-actions"><a href="#unsuccessful-simple-and-complex-actions">Unsuccessful simple and complex actions<!-- --> </a></h3>
<p><a data-inline="true" href="https://primer.style/product/ui-patterns/notification-messaging/">Banners</a> and <a data-inline="true" href="https://primer.style/product/components/dialog/">dialogs</a> can provide feedback about user and system error as a result of an undertaken action. Banners are useful when the error information needs to be passively available, while dialogs are useful for deliberately interrupting the user to get their attention.</p>
<h3 id="successfully-completed-forms"><a href="#successfully-completed-forms">Successfully-completed forms<!-- --> </a></h3>
<p>Simple forms may not need any other confirmation state other than creating and displaying what the user requested.</p>
<p>More complicated forms can utilize an interstitial confirmation page or <a data-inline="true" href="https://primer.style/product/ui-patterns/notification-messaging/">banner</a> that informs the user about what is being done with the data they submitted.</p>
<h3 id="other-form-validation"><a href="#other-form-validation">Other form validation<!-- --> </a></h3>
<p>Primer already has a robust set of components and guidance for <a data-inline="true" href="https://primer.style/product/ui-patterns/forms/#validation-message">handling input validation</a>. Using these offerings helps GitHub to feel consistent across the entire surface area of the site.</p>
<h3 id="long-running-tasks"><a href="#long-running-tasks">Long-running tasks<!-- --> </a></h3>
<p>Actions that take a long time to complete should <a data-inline="true" href="https://primer.style/product/ui-patterns/notification-messaging/">utilize banners</a> to inform the user of task completion or failure. Also consider ways to notify the user in other communication channels such as email, <a data-inline="true" href="https://github.com/notifications">notifications</a>, or a push notification in the GitHub app.</p>
<h3 id="application-state"><a href="#application-state">Application state<!-- --> </a></h3>
<p>There is the potential for a client’s session to become desynchronized, especially if a browser tab has been left open for a long time on a part of GitHub where a lot of dynamic updates are present. <a data-inline="true" href="https://primer.style/product/components/dialog/">Dialogs</a> and <a data-inline="true" href="https://primer.style/product/ui-patterns/notification-messaging/">banners</a> can be used to inform the user that a refresh is needed to resynchronize the client and server.</p>
<h2 id="accessibility-considerations"><a href="#accessibility-considerations">Accessibility considerations<!-- --> </a></h2>
<p>Toast UI risks violating the following <a data-inline="true" href="https://www.w3.org/TR/WCAG22/">Web Content Accessibility Guideline</a> (<abbr>WCAG</abbr>) Success Criteria (<abbr>SC</abbr>). Each of these SCs has one of three levels for support, and represent friction or a hard barrier for our users. GitHub honors the first two levels: A and AA.</p>
<h3 id="primary-considerations"><a href="#primary-considerations">Primary considerations<!-- --> </a></h3>
<p>These are aspects of toast UI that potentially represent large barriers for our users:</p>
<h4 id="221-timing-adjustable"><a href="#221-timing-adjustable">2.2.1: Timing Adjustable<!-- --> </a></h4>
<ul>
<li><a data-inline="true" href="https://www.w3.org/WAI/WCAG22/Understanding/timing-adjustable.html">Understanding SC 2.2.1: Timing Adjustable</a></li>
<li>Level A</li>
</ul>
<p>A mechanism needs to be present to extend the toast UI’s presence indefinitely until manually dismissed by the user. This is a guarantee that the toast’s duration is a length that allows all users to be able to navigate to, read, and potentially take action on the toast UI content.</p>
<h4 id="132-meaningful-sequence"><a href="#132-meaningful-sequence">1.3.2: Meaningful Sequence<!-- --> </a></h4>
<ul>
<li><a data-inline="true" href="https://www.w3.org/WAI/WCAG22/Understanding/meaningful-sequence.html">Understanding 1.3.2: Meaningful Sequence</a></li>
<li>Level A</li>
</ul>
<p>Toast message code is commonly placed at the start or the end of the DOM. Many forms of assistive technology work by reading the DOM in sequence, so there will be a disconnect between what triggers the toast UI and the toast UI itself. This impedes discovery and understanding.</p>
<h4 id="211-keyboard"><a href="#211-keyboard">2.1.1: Keyboard<!-- --> </a></h4>
<ul>
<li><a data-inline="true" href="https://www.w3.org/WAI/WCAG22/Understanding/keyboard.html">Understanding 2.1.1: Keyboard</a></li>
<li>Level A</li>
</ul>
<p>Toasts UI started as a mechanism to display passive notifications, but evolved to include interactive controls.</p>
<p>All interactive controls placed inside a toast UI need to be operable via keyboard, as well as accessing the toast UI container itself. This includes a mechanism for dismissing the toast, as well as managing focus when it is removed from the DOM.</p>
<h4 id="413-status-messages"><a href="#413-status-messages">4.1.3: Status Messages<!-- --> </a></h4>
<ul>
<li><a data-inline="true" href="https://www.w3.org/WAI/WCAG22/Understanding/status-messages.html">Understanding 4.1.3: Status Messages</a></li>
<li>Level AA</li>
</ul>
<p>Toast UIs should make their presence known to assistive technology in a way that is not disruptive to a user’s regular workflow or working context.</p>
<h3 id="secondary-considerations"><a href="#secondary-considerations">Secondary considerations<!-- --> </a></h3>
<p>These are other potential success criteria that using toast UI may violate depending on its context:</p>
<h4 id="144-resize-text"><a href="#144-resize-text">1.4.4: Resize text<!-- --> </a></h4>
<ul>
<li><a data-inline="true" href="https://www.w3.org/WAI/WCAG22/Understanding/resize-text.html">Understanding 1.4.4: Resize text</a></li>
<li>Level AA</li>
</ul>
<p>Increasing the text size on the browser or operating system level runs into three potential risks for toast UI.</p>
<p>First is making the toast so large that it obscures the rest of the page content. Second is creating horizontal overflow in an attempt to prevent obscuring the underlying page content. Third is attempting to block text resizing on a toast component to prevent both of the previous risks.</p>
<h4 id="1410-reflow"><a href="#1410-reflow">1.4.10: Reflow<!-- --> </a></h4>
<ul>
<li><a data-inline="true" href="https://www.w3.org/WAI/WCAG22/Understanding/reflow.html">Understanding 1.4.10: Reflow</a></li>
<li>Level AA</li>
</ul>
<p>If horizontal overflow is created as a result of using toast UI, it needs to be able to be scrollable via keyboard interaction.</p>
<h4 id="243-focus-order"><a href="#243-focus-order">2.4.3: Focus Order<!-- --> </a></h4>
<ul>
<li><a data-inline="true" href="https://www.w3.org/WAI/WCAG22/Understanding/focus-order.html">Understanding 2.4.3: Focus Order</a></li>
<li>Level A</li>
</ul>
<p>A toast that contains interactive elements needs those elements to be able to receive keyboard focus. Additionally, the toast’s position in the DOM may make the order of focus not make sense compared to the interactive content that comes before or after it.</p>
<h4 id="324-consistent-identification"><a href="#324-consistent-identification">3.2.4: Consistent Identification<!-- --> </a></h4>
<ul>
<li><a data-inline="true" href="https://www.w3.org/WAI/WCAG22/Understanding/consistent-identification.html">Understanding 3.2.4: Consistent Identification</a></li>
<li>Level AA</li>
</ul>
<p>The underlying code for toast notifications should be the same, regardless of where they are used or what team owns the service.</p>
<h2 id="usability-considerations"><a href="#usability-considerations">Usability considerations<!-- --> </a></h2>
<p>In addition to accessibility issues, there are also usability issues to consider for toasts:</p>
<h3 id="large-displays"><a href="#large-displays">Large displays<!-- --> </a></h3>
<p>Many developers work on a larger display, in order to have more screen real estate to work with. Toasts could be placed in such a way that they go unnoticed, in that they sit outside of a user’s immediate field of view.</p>
<h3 id="distractions-and-multitasking"><a href="#distractions-and-multitasking">Distractions and multitasking<!-- --> </a></h3>
<p>Toasts that automatically dismiss themselves risk being unread if a user is distracted or is actively switching between tabs and applications.</p>
<h3 id="blocking-ui"><a href="#blocking-ui">Blocking UI<!-- --> </a></h3>
<p>Since toasts “float” above the rest of the UI, there is a chance that they can obscure underlying content.</p>
<p>This obscuring effect is especially worth considering given that important UI such as form submission buttons tend to also be placed at the bottom corner of the viewport. The effect also becomes more pronounced if multiple toasts stack on top of each other.</p>
<h3 id="screen-magnification"><a href="#screen-magnification">Screen magnification<!-- --> </a></h3>
<p>Some users rely on a software or hardware-based magnification solution in order to be able to use a computer. Toast notifications may not be seen by the user, in that they are displayed outside of the range of the magnification window.</p>
<h3 id="working-memory"><a href="#working-memory">Working memory<!-- --> </a></h3>
<p>Toasts that both display important information and automatically dismiss themselves may create a situation where a user is given important information, but then has no way to go back and review the information.</p>
<h3 id="banner-blindness"><a href="#banner-blindness">Banner blindness<!-- --> </a></h3>
<p>Toasts are an over-used interaction pattern on the web. This leads to a phenomenon where users are taught to ignore and avoid their content, as it is often low-quality or unrelated to their immediate task at hand.</p>
<h3 id="disconnection"><a href="#disconnection">Disconnection<!-- --> </a></h3>
<p>A toast’s placement may be far away from the UI that triggered it. This violation of the gestalt principle of proximity means there is more of a chance a user does not understand the relationship between the toast message and its related piece of content.</p>
<h3 id="accidental-dismissal"><a href="#accidental-dismissal">Accidental dismissal<!-- --> </a></h3>
<p>Users pressing <kbd>Esc</kbd> to dismiss a toast may accidentally dismiss another piece of UI, if multiple keyboard-dismissable pieces of content are present. The opposite also applies, where a user may dismiss a toast containing important information while trying to dismiss an unrelated piece of UI.</p>
<h2 id="further-reading"><a href="#further-reading">Further reading<!-- --> </a></h2>
<ul>
<li><a data-inline="true" href="https://primer.style/product/ui-patterns/notification-messaging/">Notification messaging - Primer</a></li>
<li><a data-inline="true" href="https://github.com/github/accessibility/blob/main/docs/coaching-recommendations/toast-flash-banner/toasts/accessible-toast-prototype.md">Engineering Explorations on an Accessible Toast Prototype - GitHub (staff only)</a></li>
<li><a data-inline="true" href="https://www.tpgi.com/celebrating-with-the-perfect-toast/">Celebrating with The Perfect Toast - TPGi</a></li>
<li><a data-inline="true" href="https://www.scottohara.me/blog/2019/07/08/a-toast-to-a11y-toasts.html">A toast to an accessible toast… - Scott O’Hara</a></li>
<li><a data-inline="true" href="https://adrianroselli.com/2020/01/defining-toast-messages.html">Defining ‘Toast’ Messages - Adrian Roselli</a></li>
<li><a data-inline="true" href="https://adamsilver.io/blog/the-problem-with-toast-messages-and-what-to-do-instead/">The problem with toast messages and what to do instead - Adam Silver</a></li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Icons in Menus Everywhere – Send Help (678 pts)]]></title>
            <link>https://blog.jim-nielsen.com/2025/icons-in-menus/</link>
            <guid>46196688</guid>
            <pubDate>Mon, 08 Dec 2025 19:44:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jim-nielsen.com/2025/icons-in-menus/">https://blog.jim-nielsen.com/2025/icons-in-menus/</a>, See on <a href="https://news.ycombinator.com/item?id=46196688">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://mastodon.social/@jimniels/115556046706814962">I complained about this on the socials</a>, but I didn’t get it all out of my system. So now I write a blog post.</p><p>I’ve never liked the philosophy of “put an icon in every menu item by default”.</p><p>Google Sheets, for example, does this. Go to “File” or “Edit” or “View” and you’ll see a menu with a list of options, every single one having an icon (same thing with the right-click context menu).</p><p><img src="https://cdn.jim-nielsen.com/blog/2025/context-menu-sheets.png" width="725" height="848" alt="Screenshot of menus with icons in Google Sheets"></p><p>It’s extra noise to me. It’s not that I think menu items should <em>never</em> have icons. I think they can be incredibly useful (more on that below). It’s more that I don’t like the idea of “give each menu item an icon” being the default approach.</p><p>This posture lends itself to a practice where designers have an attitude of “I need an icon to fill up this space” instead of an attitude of “Does the addition of a icon here, and the cognitive load of parsing and understanding it, help or hurt how someone would use this menu system?”</p><p>The former doesn’t require thinking. It’s just templating — they all have icons, so we need to put <em>something</em> there. The latter requires care and thoughtfulness for each use case and its context.</p><p>To defend my point, one of the examples I always pointed to was macOS. For the longest time, Apple’s OS-level menus seemed to avoid this default approach of sticking icons in every menu item.</p><p>That is, until macOS Tahoe shipped.</p><p>Tahoe now has icons in menus everywhere. For example, here’s the Apple menu:</p><p><img src="https://cdn.jim-nielsen.com/blog/2025/context-menu-mac.png" width="312" height="351" alt="Screenshot of the Apple menu in macOS tahoe where every menu item is prefixed with an icon."></p><p>Let’s look at others. As I’m writing this I have Safari open. Let’s look at the “Safari” menu:</p><p><img src="https://cdn.jim-nielsen.com/blog/2025/context-menu-safari-about.png" width="333" height="445" alt="Screenshot of the Safari menu in macOS Tahoe where about half of the menu items are prefixed with an icon."></p><p>Hmm. Interesting. Ok so we’ve got an icon for like half the menu items. I wonder why some get icons and others don’t?</p><p>For example, the “Settings” menu item (third from the top) has an icon. But the other item in its grouping “Privacy Report” does not. I wonder why? Especially when Safari has an icon for Privacy report, like if you go to customize the toolbar you’ll see it:</p><p><img src="https://cdn.jim-nielsen.com/blog/2025/context-menu-macos-safari-privacy-report.png" width="723" height="259" alt="Screenshot of the Customize Toolbar UI in Safari and the Privacy Report button has a red highlight around indicating its icon."></p><p>Hmm. Who knows? Let’s keep going.</p><p>Let’s look at the "File" menu in Safari:</p><p><img src="https://cdn.jim-nielsen.com/blog/2025/context-menu-safari-file.png" width="422" height="567" alt="Screenshot of the File menu Safari in macOS Tahoe where only a few menu items are prefixed with an icon. Some are indented, others not."></p><p>Some groupings have icons and get inset, while other groupings don’t have icons and don’t get inset. Interesting…again I wonder what the rationale is here? How do you choose? It’s not clear to me.</p><p>Let’s keep going. Let’s go to the "View" menu:</p><p><img src="https://cdn.jim-nielsen.com/blog/2025/context-menu-safari-view.png" width="373" height="648" alt="Screenshot of the View menu in Safari on macOS Tahoe where some menu items are prefixed with an icon and two also have a checkmark."></p><p>Oh boy, now we’re really in it. Some of these menu items have the notion of a toggle (indicated by the checkmark) so now you’ve got all kinds of alignment things to deal with. The visual symbols are doubling-up when there’s a toggle <em>and</em> an icon.</p><p>The “View” menu in Mail is a similar mix of:</p><ul><li>Text</li><li>Text + toggles</li><li>Text + icons</li><li>Text + icons + toggles</li></ul><p><img src="https://cdn.jim-nielsen.com/blog/2025/context-menu-mail-view.png" width="343" height="770" alt="Screenshot of the View menu in Mail on macOS Tahoe showing how menu items can be indented and have icons, not have icons, and have toggles with checkmarks."></p><p>You know what would be a fun game? Get a bunch of people in a room, show them menus where the textual labels are gone, and see who can get the most right.</p><p><img src="https://cdn.jim-nielsen.com/blog/2025/context-menu-app-edit.png" width="188" height="541" alt="Screenshot of a menu in macOS Tahoe where every menu item is prefixed with an icon but the labels are blurred out so you don’t know for sure what each menu item is."></p><p>But I digress.</p><p>In so many of these cases, I honestly can’t intuit why some menus have icons and others do not. What are so many of these icons affording me at the cost of extra visual and cognitive parsing? I don’t know.</p><p>To be fair, there are <em>some</em> menus where these visual symbols are incredibly useful. Take this menu from Finder:</p><p><img src="https://cdn.jim-nielsen.com/blog/2025/context-menu-finder-window.png" width="614" height="604" alt="Screenshot of a Finder menu in macOS Tahoe where every menu item is prefixed with a useful icon."></p><p>The visual depiction of how those are going to align is actually incredibly useful because it’s way easier for my brain to parse the symbol and understand where the window is going to go than it is to read the text and imagine in my head what “Top Left” or “Bottom &amp; Top” or “Quarters” will mean. But a visual symbol? I instantly get it!</p><p>Those are good icons in menus. I like those.</p><h2 id="apple-abandons-its-own-guidance">Apple Abandons Its Own Guidance</h2><p>What I find really interesting about this change on Apple’s part is how it seemingly goes against their own previous human interface guidelines (as <a href="https://mastodon.gassner.io/@peter/115559008588925643">pointed out to me by Peter Gassner</a>).</p><p>They have an entire section in their 2005 guidelines titled “Using Symbols in Menus”:</p><p><img src="https://cdn.jim-nielsen.com/blog/2025/context-menu-hig.png" width="679" height="359" alt="Screenshot from Apple’s Human Interface Guidelines"></p><p>See what it says?</p><blockquote><p>There are a few standard symbols you can use to indicate additional information in menus…Don’t use other, arbitrary symbols in menus, because they add visual clutter and may confuse people.</p></blockquote><p>Confused people. That’s me.</p><p>They even have an example of what <em>not</em> to do and guess what it looks like? A menu in macOS Tahoe.</p><p><img src="https://cdn.jim-nielsen.com/blog/2025/context-menu-hig-donts.png" width="343" height="224" alt="Screenshot from the HIG denoting how you shouldn’t use arbitrary symbols in menus." data-og-image=""></p><h2 id="conclusion">Conclusion</h2><p>It’s pretty obvious how I feel. I’m tired of all this visual noise in my menus.</p><p>And now that Apple has seemingly thrown in with the “stick an icon in every menu by default” crowd, it’s harder than ever for me to convince people otherwise. To persuade, “Hey, unless you can articulate a really good reason to add this, maybe our default posture should be no icons in menus?”</p><p>So I guess this is the world I live in now. Icons in menus. Icons in menus everywhere.</p><p>Send help.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trials avoid high risk patients and underestimate drug harms (150 pts)]]></title>
            <link>https://www.nber.org/papers/w34534</link>
            <guid>46196308</guid>
            <pubDate>Mon, 08 Dec 2025 19:07:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nber.org/papers/w34534">https://www.nber.org/papers/w34534</a>, See on <a href="https://news.ycombinator.com/item?id=46196308">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <a id="main-content" tabindex="-1"></a>
        <div id="block-nber-breadcrumbs">
  
    
        
  
      <nav aria-label="You are here:">
      
      <ul>
                  <li>
                          <a href="https://www.nber.org/">Home</a>
                      </li>
                  <li>
                          <a href="https://www.nber.org/research">Research</a>
                      </li>
                  <li>
                          <a href="https://www.nber.org/papers">Working Papers</a>
                      </li>
                  <li>
                          Trials Avoid High Risk Patients and…
                      </li>
              </ul>
    </nav>
  
  </div>

  
  
        

<div>
  <div>
        <p><span>Working Paper</span> 34534
  </p>

        <p><span>DOI</span> 10.3386/w34534
  </p>

        <p><span>Issue Date</span> <time datetime="2025-12-04T12:00:00Z">December 2025</time>

  </p>

          </div>
  <div>
    <p>
The FDA does not formally regulate representativeness, but if trials under-enroll vulnerable patients, the resulting evidence may understate harm from drugs. We study the relationship between trial participation and the risk of drug-induced adverse events for cancer medications using data from the Surveillance, Epidemiology, and End Results Program linked to Medicare claims. Initiating treatment with a cancer drug increases the risk of hospitalization due to serious adverse events (SAE) by 2 percentage points per month (a 250% increase). Heterogeneity in SAE treatment effects can be predicted by patient's comorbidities, frailty, and demographic characteristics. Patients at the 90th percentile of the risk distribution experience a 2.5 times greater increase in SAEs after treatment initiation compared to patients at the 10th percentile of the risk distribution yet are 4 times less likely to enroll in trials. The predicted SAE treatment effects for the drug's target population are 15% larger than the predicted SAE treatment effects for trial enrollees, corresponding to 1 additional induced SAE hospitalization for every 25 patients per year of treatment. We formalize conditions under which regulating representativeness of SAE risk will lead to more externally valid trials, and we discuss how our results could inform regulatory requirements.
</p>
  </div>
  
</div>

  

  

<div>
  <ul>
          <li>
        
      </li>
    
    <li>
      <div id="accordion-body-guid2" aria-labelledby="accordion-button-guid2">
        <p>Copy Citation</p>
        <div>
            <p>
                Jason Abaluck, Leila Agha, and Sachin Shah, "Trials Avoid High Risk Patients and Underestimate Drug Harms," NBER Working Paper 34534 (2025), https://doi.org/10.3386/w34534.
            </p>

            </div>
                    <p>Download Citation</p>
            

            </div>    </li>

    
      </ul>
</div>


<div>
    <h2>Related</h2>
    <div>
    
      
                <div>
    <h3>Topics</h3>
    
  </div>

      
                <div>
    <h3>Programs</h3>
    
  </div>

      
                <div>
    <h3>Working Groups</h3>
    
  </div>

      
                        <div>
            <h3>Projects</h3>
            
          </div>
              
      
      
      
      
      
      
      
      
          </div>
  </div>


  
  
        <section id="block-morefromthenber">
    <h2>More from the NBER</h2>
    
    <div>
    

<div data-href="/research/videos/2025-17th-annual-feldstein-lecture-n-gregory-mankiw-fiscal-future">
      <p><img loading="lazy" src="https://www.nber.org/sites/default/files/styles/promo/public/2025-07/MF%20Lecture%202025%20updated.png?itok=ij7zY5fj" width="736" height="414" alt=" 2025, 17th Annual Feldstein Lecture, N. Gregory Mankiw,&quot; The Fiscal Future&quot;" typeof="foaf:Image">



    </p>
  
  

      <ul>
      <li>Feldstein Lecture</li>
    </ul>
  
      <ul>
      <li>
        Presenter:
        

              <span>
      <a href="https://www.nber.org/people/gregory_mankiw">N. Gregory Mankiw</a>    </span>
      
      </li>
    </ul>
  
  
  
      <p>N. Gregory Mankiw, Robert M. Beren Professor of Economics at Harvard University, presented the 2025 Martin Feldstein...</p>
  </div>

    

<div data-href="/research/videos/2025-methods-lecture-raj-chetty-and-kosuke-imai-uncovering-causal-mechanisms-mediation-analysis-and">
      <p><img loading="lazy" src="https://www.nber.org/sites/default/files/styles/promo/public/2025-07/Methods%20Lecture%20SI%202025_0.png?itok=hsgorA8D" width="736" height="414" alt=" 2025 Methods Lecture, Raj Chetty, &quot;Uncovering Causal Mechanisms: Mediation Analysis and Surrogate Indices&quot;" typeof="foaf:Image">



    </p>
  
  

      <ul>
      <li>Methods Lectures</li>
    </ul>
  
      <ul>
      <li>
        Presenters:
        

              <span>
      <a href="https://www.nber.org/people/raj_chetty">Raj Chetty</a>    </span>
                  <span>
       &amp; <a href="https://www.nber.org/people/kosuke_imai">Kosuke Imai</a>    </span>
      
      </li>
    </ul>
  
  
  
      <p>SlidesBackground materials on mediationImai, Kosuke, Dustin Tingley, and Teppei Yamamoto. (2013). “Experimental Designs...</p>
  </div>

    

<div data-href="/research/videos/2025-international-trade-and-macroeconomics-panel-future-global-economy">
      <p><img loading="lazy" src="https://www.nber.org/sites/default/files/styles/promo/public/2025-08/SI%20International%20trade%20Panel%202025.png?itok=2DuJTJDm" width="736" height="414" alt="2025 International Trade and Macroeconomics, &quot;Panel on The Future of the Global Economy&quot;" typeof="foaf:Image">



    </p>
  
  

      <ul>
      <li>Panel Discussion</li>
    </ul>
  
      <ul>
      <li>
        Presenters:
        

              <span>
      <a href="https://www.nber.org/people/oleg_itskhoki">Oleg Itskhoki</a>,     </span>
                  <span>
      <a href="https://www.nber.org/people/paul_krugman">Paul R. Krugman</a>    </span>
                  <span>
       &amp; <a href="https://www.nber.org/people/linda_tesar">Linda Tesar</a>    </span>
      
      </li>
    </ul>
  
  
  
      <p>Supported by the Alfred P. Sloan Foundation grant #G-2023-19633, the Lynde and Harry Bradley Foundation grant #20251294...</p>
  </div>
</div>
  </section>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Has the cost of building software dropped 90%? (351 pts)]]></title>
            <link>https://martinalderson.com/posts/has-the-cost-of-software-just-dropped-90-percent/</link>
            <guid>46196228</guid>
            <pubDate>Mon, 08 Dec 2025 19:00:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://martinalderson.com/posts/has-the-cost-of-software-just-dropped-90-percent/">https://martinalderson.com/posts/has-the-cost-of-software-just-dropped-90-percent/</a>, See on <a href="https://news.ycombinator.com/item?id=46196228">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    
    
    <div>
        <p>I've been building software professionally for nearly 20 years. I've been through a lot of changes - the 'birth' of SaaS, the mass shift towards mobile apps, the outrageous hype around blockchain, and the perennial promise that low-code would make developers obsolete.</p>
<p>The economics have changed <em>dramatically</em> now with agentic coding, and it is going to totally transform the software development industry (and the wider economy). 2026 is going to catch a lot of people off guard.</p>
<p>In my previous post I delved into why I think <a href="https://martinalderson.com/posts/are-we-in-a-gpt4-style-leap-that-evals-cant-see/">evals are missing</a> some of the big leaps, but thinking this over since then (and recent experience) has made me confident we're in the early stages of a once-in-a-generation shift.</p>
<h2>The cost of shipping</h2>
<p>I started developing just around the time open source started to really explode - but it was clear this was one of the first big shifts in cost of building custom software. I can remember eye watering costs for SQL Server or Oracle - and as such started out really with MySQL, which did allow you to build custom networked applications without incurring five or six figures of annual database licensing costs.</p>
<p>Since then we've had cloud (which I would debate is a cost saving at all, but let's be generous and assume it has some initial capex savings) and lately what I feel has been the era of complexity. Software engineering has got - in my opinion, often needlessly - complicated, with people rushing to very labour intensive patterns such as TDD, microservices, super complex React frontends and Kubernetes. I definitely don't think we've seen much of a cost decrease in the past few years.</p>
<p><img src="https://martinalderson.com/img/cost_of_shipping@2x.png" alt="Cost of shipping software over time"></p>
<p>AI Agents however in my mind <em>massively</em> reduce the labour cost of developing software.</p>
<h2>So where do the 90% savings actually come from?</h2>
<p>At the start of 2025 I was incredibly sceptical of a lot of the AI coding tools - and a lot of them I still am. Many of the platforms felt like glorified low code tooling (Loveable, Bolt, etc), or VS Code forks with some semi-useful (but often annoying) autocomplete improvements.</p>
<p>Take an average project for an internal tool in a company. Let's assume the data modelling is already done to some degree, and you need to implement a web app to manage widgets.</p>
<p>Previously, you'd have a small team of people working on setting up CI/CD, building out data access patterns and building out the core services. Then usually a whole load of CRUD-style pages and maybe some dashboards and graphs for the user to make. Finally you'd (hopefully) add some automated unit/integration/e2e tests to make sure it was fairly solid and ship it, maybe a month later.</p>
<p>And that's just the direct labour. Every person on the project adds coordination overhead. Standups, ticket management, code reviews, handoffs between frontend and backend, waiting for someone to unblock you. The actual coding is often a fraction of where the time goes.</p>
<p><em>Nearly all of this</em> can be done in a few hours with an agentic coding CLI. I've had Claude Code write an entire unit/integration test suite in a few hours (300+ tests) for a fairly complex internal tool. This would take me, or many developers I know and respect, days to write by hand.</p>
<p>The agentic coding tools have got <em>extremely</em> good at converting business logic specifications into pretty well written APIs and services.</p>
<p>A project that would have taken a month now takes a week. The thinking time is roughly the same  - the implementation time collapsed. And with smaller teams, you get the inverse of Brooks's Law: instead of communication overhead scaling with headcount, it disappears. A handful of people can suddenly achieve an order of magnitude more.</p>
<h2>Latent demand</h2>
<p>On the face of it, this seems like incredibly bad news for the software development industry - but economics tells us otherwise.</p>
<p><a href="https://en.wikipedia.org/wiki/Jevons_paradox">Jevons Paradox</a> says that when something becomes cheaper to produce, we don't just do the same amount for less money. Take electric lighting for example; while sales of candles and gas lamps fell, overall <em>far</em> more artificial light was generated.</p>
<p>If we apply this to software engineering, think of supply and demand. There is <em>so much</em> latent demand for software. I'm sure every organisation has hundreds if not thousands of Excel sheets tracking important business processes that would be far better off as a SaaS app. Let's say they get a quote from an agency to build one into an app for $50k - only essential ones meet the grade. At $5k (for a decent developer + AI tooling) - suddenly there is far more demand.</p>
<p><img src="https://martinalderson.com/img/latent_demand@2x.png" alt="Latent demand for software"></p>
<h2>Domain knowledge is the only moat</h2>
<p>So where does that leave us? Right now there is still enormous value in having a human 'babysit' the agent - checking its work, suggesting the approach and shortcutting bad approaches. Pure YOLO vibe coding ends up in a total mess very quickly, but with a human in the loop I think you can build incredibly good quality software, <em>very</em> quickly.</p>
<p>This then allows developers who really master this technology to be hugely effective at solving business problems. Their domain and industry knowledge becomes a huge lever - knowing the best architectural decisions for a project, knowing which framework to use and which libraries work best.</p>
<p>Layer on understanding of the business domain and it does genuinely feel like the mythical 10x engineer is here. Equally, the pairing of a business domain expert with a motivated developer and these tools becomes an incredibly powerful combination, and something I think we'll see becoming quite common - instead of a 'squad' of a business specialist and a set of developers, we'll see a far tighter pairing of a couple of people.</p>
<p>This combination allows you to iterate incredibly quickly, and software becomes almost disposable - if the direction is bad, then throw it away and start again, using those learnings. This takes a fairly large mindset shift, but the hard work is the <em>conceptual thinking</em>, not the typing.</p>
<h2>Don't get caught off guard</h2>
<p>The agents and models are still improving rapidly, which I don't think is really being captured in the benchmarks. Opus 4.5 seems to be able to follow long 10-20 minute sessions without going completely off piste. We're just starting to see the results of the hundreds of billions of dollars of capex that has gone into GB200 GPUs now, and I'm sure newer models will quickly make these look completely obsolete.</p>
<p>However, I've spoken to so many software engineers that are really fighting this change. I've heard the same objections too many times - LLMs make too many mistakes, it can't understand <code>[framework]</code>, or it doesn't really save any time.</p>
<p>These assertions are rapidly becoming completely false, and remind me a lot of the desktop engineers who dismissed the iPhone in 2007. I think we all know how that turned out - networking got better, the phones got way faster and the mobile operating systems became very capable.</p>
<p>Engineers need to really lean in to the change in my opinion. This won't change overnight - large corporates are still very much behind the curve in general, lost in a web of bureaucracy of vendor approvals and management structures that leave them incredibly vulnerable to smaller competitors.</p>
<p>But if you're working for a smaller company or team and have the power to use these tools, you should. Your job is going to change - but software has always changed. Just perhaps this time it's going to change faster than anyone anticipates. 2026 is coming.</p>
<p>One objection I hear a lot is that LLMs are only good at greenfield projects. I'd push back hard on this. I've spent plenty of time trying to understand 3-year-old+ codebases where everyone who wrote it has left. Agents make this dramatically easier - explaining what the code does, finding the bug(s), suggesting the fix. I'd rather inherit a repo written with an agent and a good engineer in the loop than one written by a questionable quality contractor who left three years ago, with no tests, and a spaghetti mess of classes and methods.</p>

    </div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jepsen: NATS 2.12.1 (399 pts)]]></title>
            <link>https://jepsen.io/analyses/nats-2.12.1</link>
            <guid>46196105</guid>
            <pubDate>Mon, 08 Dec 2025 18:51:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jepsen.io/analyses/nats-2.12.1">https://jepsen.io/analyses/nats-2.12.1</a>, See on <a href="https://news.ycombinator.com/item?id=46196105">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><a href="https://nats.io/">NATS</a> is a distributed streaming system. Regular NATS streams offer only best-effort delivery, but a subsystem, called JetStream, guarantees messages are delivered at least once. We tested NATS JetStream, version 2.12.1, and found that it lost writes if data files were truncated or corrupted on a minority of nodes. We also found that coordinated power failures, or an OS crash on a single node combined with network delays or process pauses, can cause the loss of committed writes and persistent split-brain. This data loss was caused (at least in part) by choosing to flush writes to disk every two minutes, rather than before acknowledging them. We also include a belated note on data loss due to process crashes in version 2.10.22, which was fixed in 2.10.23. NATS has now documented the risk of its default <code>fsync</code> policy, and the remaining issues remain under investigation. This research was performed independently by Jepsen, without compensation, and conducted in accordance with the <a href="https://jepsen.io/analyses/ethics">Jepsen ethics policy</a>.</p><article>
  <div>
<h2 data-number="1" id="background"> Background</h2>
<p><a href="https://nats.io/">NATS</a> is a popular streaming system. Producers <a href="https://docs.nats.io/nats-concepts/core-nats/pubsub">publish messages to streams</a>, and consumers subscribe to those streams, fetching messages from them. Regular NATS streams are allowed to drop messages. However, NATS has a subsystem called <a href="https://docs.nats.io/nats-concepts/jetstream">JetStream</a>, which <a href="https://docs.nats.io/running-a-nats-service/configuration/clustering/jetstream_clustering">uses</a> the <a href="https://raft.github.io/">Raft consensus algorithm</a> to replicate data among nodes. JetStream promises <a href="https://docs.nats.io/nats-concepts/jetstream#exactly-once-semantics">“at least once”</a> delivery: messages may be duplicated, but acknowledged messages<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a> should not be lost.<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> Moreover, JetStream streams are <a href="https://docs.nats.io/nats-concepts/jetstream#persistent-and-consistent-distributed-storage">totally ordered logs</a>.</p>
<p>JetStream is intended to <a href="https://docs.nats.io/nats-concepts/jetstream">“self-heal and always be available”</a>. The documentation also states that <a href="https://docs.nats.io/nats-concepts/jetstream#persistent-and-consistent-distributed-storage">“the formal consistency model of NATS JetStream is Linearizable”</a>. At most one of these claims can be true: the <a href="https://www.cs.princeton.edu/courses/archive/spr22/cos418/papers/cap.pdf">CAP theorem</a> tells us that <a href="https://jepsen.io/consistency/models/linearizable">Linearizable</a> systems can not be totally available.<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> In practice, they tend to be available so long as a majority of nodes are non-faulty and communicating. If, say, a single node loses network connectivity, operations must fail on that node. If three out of five nodes crash, all operations must fail.</p>
<p>Indeed, a <a href="https://docs.nats.io/nats-concepts/jetstream#persistent-and-consistent-distributed-storage">later section</a> of the JetStream docs acknowledges this fact, saying that streams with three replicas can tolerate the loss of one server, and those with five can tolerate the simultaneous loss of two.</p>
<blockquote>
<p>Replicas=5 - Can tolerate simultaneous loss of two servers servicing the stream. Mitigates risk at the expense of performance.</p>
</blockquote>
<p>When does NATS guarantee a message will be durable? The <a href="https://docs.nats.io/using-nats/developer/develop_jetstream?q=sync#publish-to-a-stream">JetStream developer docs</a> say that once a JetStream client’s <code>publish</code> request is acknowledged by the server, that message has “been successfully persisted”. The <a href="https://docs.nats.io/running-a-nats-service/configuration/clustering/jetstream_clustering#the-quorum">clustering configuration documentation</a> says:</p>
<blockquote>
<p>In order to ensure data consistency across complete restarts, a quorum of servers is required. A quorum is ½ cluster size + 1. This is the minimum number of nodes to ensure at least one node has the most recent data and state after a catastrophic failure. So for a cluster size of 3, you’ll need at least two JetStream enabled NATS servers available to store new messages. For a cluster size of 5, you’ll need at least 3 NATS servers, and so forth.</p>
</blockquote>
<p>With these guarantees in mind, we set out to test NATS JetStream behavior under a variety of simulated faults.</p>
<h2 data-number="2" id="test-design"> Test Design</h2>
<p>We designed a <a href="https://github.com/jepsen-io/nats">test suite</a> for NATS JetStream using the <a href="https://github.com/jepsen-io/jepsen">Jepsen testing library</a>, using <a href="https://github.com/nats-io/nats.java">JNATS</a> (the official Java client) at version 2.24.0. Most of our tests ran in Debian 12 containers under LXC; <a href="https://github.com/jepsen-io/nats/tree/4760f97f86350c5c9983478656dbcbcdade33817/antithesis">some tests</a> ran in <a href="https://antithesis.com/">Antithesis</a>, using the official NATS Docker images. In all our tests we created a single JetStream stream with a target replication factor of five. Per NATS’ recommendations, our clusters generally contained three or five nodes. We tested a variety of versions, but the bulk of this work focused on NATS 2.12.1.</p>
<p>The test harness <a href="https://github.com/jepsen-io/nats/blob/4760f97f86350c5c9983478656dbcbcdade33817/src/jepsen/nats/nemesis.clj">injected a variety of faults</a>, including process pauses, crashes, network partitions, and packet loss, as well as single-bit errors and truncation of data files. We limited file corruption to a minority of nodes. We also simulated power failure—a crash with partial amnesia—using the <a href="https://github.com/dsrhaslab/lazyfs">LazyFS</a> filesystem. LazyFS allows Jepsen to drop any writes which have not yet been flushed using a call to (e.g.) <code>fsync</code>.</p>
<p>Our tests did not measure Linearizability or <a href="https://jepsen.io/consistency/models/serializable">Serializability</a>. Instead we ran <a href="https://github.com/jepsen-io/nats/blob/4760f97f86350c5c9983478656dbcbcdade33817/src/jepsen/nats/queue.clj#L238-L266">several producer processes</a>, each bound to a single NATS client, which published globally unique values to a single JetStream stream. Each message included the process number and a sequence number within that process, so message <code>4-0</code> denoted the first <code>publish</code> attempted by process <code>4</code>, message <code>4-1</code> denoted the second, and so on. At the end of the test we ensured all nodes were running, resolved any network partitions or other faults, subscribed to the stream, and <a href="https://github.com/jepsen-io/nats/blob/4760f97f86350c5c9983478656dbcbcdade33817/src/jepsen/nats/queue.clj#L189-L201">attempted to read all acknowledged messages from the the stream</a>. Each reader called <code>fetch</code> until it had observed (at least) the last acknowledged message published by each process, or timed out.</p>
<p>We measured JetStream’s at-least-once semantics <a href="https://github.com/jepsen-io/nats/blob/4760f97f86350c5c9983478656dbcbcdade33817/src/jepsen/nats/queue.clj#L359-L424">based on the union of all published and read messages</a>. We considered a message <em>OK</em> if it was attempted and read. Messages were <em>lost</em> if they were acknowledged as published, but never read by any process. We divided lost messages into three epochs, based on the first and last OK messages written by the same process.<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a> We called those lost before the first OK message the <em>lost-prefix</em>, those lost after all the last OK message the <em>lost-postfix</em>, and all others the <em>lost-middle</em>. This helped to distinguish between lagging readers and true data loss.</p>
<p>In addition to verifying each acknowledged message was delivered to at least one consumer across all nodes, we also checked the set of messages read by all consumers connected to a specific node. We called it <em>divergence</em>, or <em>split-brain</em>, when an acknowledged message was missing from some nodes but not others.</p>
<h2 data-number="3" id="results"> Results</h2>
<p>We begin with a belated note on total data loss in version 2.10.22, then continue with four findings related to data loss and replica divergence in version 2.12.1: two with file corruption, and two with power failures.</p>
<h2 data-number="3.1" id="total-data-loss-on-crash-in-2.10.22-6888"> Total Data Loss on Crash in 2.10.22 (#6888)</h2>
<p>Before discussing version 2.12.1, we present a long-overdue finding from earlier work. In versions 2.10.20 through 2.10.22 (released 2024-10-17), we found that process crashes alone could cause the total loss of a JetStream stream and all its associated data. Subscription requests would return <code>"No matching streams for subject"</code>, and <code>getStreamNames()</code> would return an empty list. These conditions would persist for hours: <a href="https://github.com/user-attachments/files/20133999/20250509T191519.377-0500.zip">in this test run</a>, we waited 10,000 seconds for the cluster to recover, but the stream never returned.</p>
<p>Jepsen reported this issue to NATS as <a href="https://github.com/nats-io/nats-server/issues/6888">#6888</a>, but it appears that NATS had already identified several potential causes for this problem and resolved them. In <a href="https://github.com/nats-io/nats-server/pull/5946">#5946</a>, a cluster-wide crash occurring shortly after a stream was created could cause the loss of the stream. A new leader would be elected with a snapshot which preceded the creation of the stream, and replicate that empty snapshot to followers, causing everyone to delete their copy of the stream. In <a href="https://github.com/nats-io/nats-server/pull/5700">#5700</a>, tests running in <a href="https://antithesis.com/">Antithesis</a> found that out-of-order delivery of snapshot messages could cause streams to be deleted and re-created as well. In <a href="https://github.com/nats-io/nats-server/pull/6061">#6061</a>, process crashes could cause nodes to delete their local Raft state. All of these fixes were released as a part of 2.10.23, and we no longer observed the problem in that version.</p>
<h2 data-number="3.2" id="lost-writes-with-.blk-file-corruption-7549"> Lost Writes With <code>.blk</code> File Corruption (#7549)</h2>
<p>NATS has several checksum mechanisms meant to detect data corruption in on-disk files. However, we found that single-bit errors or truncation of JetStream’s <code>.blk</code> files could cause the cluster to lose large windows of writes. This occurred even when file corruption was limited to just one or two nodes out of five. For instance, <a href="https://s3.amazonaws.com/jepsen.io/analyses/nats-2.12.1/20251116T061217-blk-bitflip.zip">file corruption in this test run</a> caused NATS to lose 679,153 acknowledged writes out of 1,367,069 total, including 201,286 which were missing even though later values written by the same process were later read.</p>
<p><img src="https://jepsen.io/analyses/nats-2.12.1/blk-bitflip-loss.png" alt="A timeseries plot of write loss over time. A large block of writes is lost around sixty seconds, followed by a few which survive, and then the rest of the successfully acknowledged writes are lost as well."><br>
</p>
<p>In some cases, file corruption caused the quiet loss of <a href="https://s3.amazonaws.com/jepsen.io/analyses/nats-2.12.1/20251116T030143-blk-bitflip-single-loss.zip">just a single message</a>. In others, writes vanished in large blocks. Even worse, bitflips could cause split-brain, where different nodes returned different sets of messages. In <a href="https://s3.amazonaws.com/jepsen.io/analyses/nats-2.12.1/20251120T093731-blk-bitflip-split-brain.zip">this test</a>, NATS acknowledged a total of 1,479,661 messages. However, single-bit errors in <code>.blk</code> files on nodes <code>n1</code> and <code>n3</code> caused nodes <code>n1</code>, <code>n3</code>, and <code>n5</code> to lose up to 78% of those acknowledged messages. Node <code>n1</code> lost 852,413 messages, and nodes <code>n3</code> and <code>n5</code> lost 1,167,167 messages, despite <code>n5</code>’s data files remaining intact. Messages were lost in prefix, middle, and postfix: the stream, at least on those three nodes, resembled Swiss cheese.</p>
<p>NATS is investigating this issue (<a href="https://github.com/nats-io/nats-server/issues/7549">#7549</a>).</p>
<h2 data-number="3.3" id="total-data-loss-with-snapshot-file-corruption-7556"> Total Data Loss With Snapshot File Corruption (#7556)</h2>
<p>When we truncated or introduced single-bit errors into JetStream’s snapshot files in <code>data/jetstream/$SYS/_js_/</code>, we found that nodes would sometimes decide that a stream had been orphaned, and delete all its data files. This happened even when only a minority of nodes in the cluster experienced file corruption. The cluster would never recover quorum, and the stream remained unavailable for the remainder of the test.</p>
<p>In <a href="https://s3.amazonaws.com/jepsen.io/analyses/nats-2.12.1/20251115T142345-snap-bitflip-quorum-break.zip">this test run</a>, we introduced single-bit errors into snapshots on nodes <code>n3</code> and <code>n5</code>. During the final recovery period, node <code>n3</code> became the metadata leader for the cluster and decided to clean up <code>jepsen-stream</code>, which stored all the test’s messages.</p>
<pre><code>[1010859] 2025/11/15 20:27:02.947432 [INF]
Self is new JetStream cluster metadata leader
[1010859] 2025/11/15 20:27:14.996174 [WRN]
Detected orphaned stream 'jepsen &gt;
jepsen-stream', will cleanup</code></pre>
<p>Nodes <code>n3</code> and <code>n5</code> then deleted all files in the stream directory. This might seem defensible—after all, some of <code>n3</code>’s data files <em>were</em> corrupted. However, <code>n3</code> managed to become the leader of the cluster despite its corrupt state! In general, leader-based consensus systems must be careful to ensure that any node which becomes a leader is aware of majority committed state. Becoming a leader, then opting to delete a stream full of committed data, is particularly troubling.</p>
<p>Although nodes <code>n1</code>, <code>n2</code>, and <code>n4</code> retained their data files, <code>n1</code> struggled to apply snapshots; <code>n4</code> declared that <code>jepsen-stream</code> had no quorum and stalled. Every attempt to subscribe to the stream threw <code>[SUB-90007] No matching streams for subject</code>. Jepsen filed issue <a href="https://github.com/nats-io/nats-server/issues/7556">#7556</a> for this, and the NATS team is looking into it.</p>
<h2 data-number="3.4" id="lazy-fsync-by-default-7564"> Lazy <code>fsync</code> by Default (#7564)</h2>
<p>NATS JetStream promises that once a <code>publish</code> call has been acknowledged, it is “successfully persisted”. This is not exactly true. By default, NATS calls <code>fsync</code> to flush data to disk only once every two minutes, but acknowledges messages immediately. Consequently, recently acknowledged writes are generally <em>not</em> persisted, and could be lost to coordinated power failure, kernel crashes, etc. For instance, simulated power failures in <a href="https://github.com/user-attachments/files/23631053/20251119T075152.133-0600.zip">this test run</a> caused NATS to lose roughly thirty seconds of writes: 131,418 out of 930,005 messages.</p>
<p><img src="https://jepsen.io/analyses/nats-2.12.1/power-loss.png" alt="A timeseries plot of data loss over time. Acknowledged writes are fine for the first 125 seconds, then all acknowledged writes are lost for the remainder of the test."><br>
</p>
<p>Because the default flush interval is quite large, even killing a single node at a time is sufficient to cause data loss, so long as nodes fail within a few seconds of each other. In <a href="https://github.com/user-attachments/files/23631363/20251119T085347.396-0600.zip">this run</a>, a series of single-node failures in the first two minutes of the test caused NATS to delete the entire stream, along with all of its messages.</p>
<p>There are only two mentions of this behavior in the NATS documentation. The first is in the <a href="https://docs.nats.io/release-notes/whats_new/whats_new_210">2.10 release notes</a>. The second, <a href="https://docs.nats.io/running-a-nats-service/configuration">buried in the configuration docs</a>, describes the <code>sync_interval</code> option:</p>
<blockquote>
<p>Change the default fsync/sync interval for page cache in the filestore. By default JetStream relies on stream replication in the cluster to guarantee data is available after an OS crash. If you run JetStream without replication or with a replication of just 2 you may want to shorten the fsync/sync interval. You can force an fsync after each messsage [sic] with <code>always</code>, this will slow down the throughput to a few hundred msg/s.</p>
</blockquote>
<p>Consensus protocols often require that nodes sync to disk before acknowledging an operation. For example, the famous 2007 paper <a href="https://www.cs.utexas.edu/~lorenzo/corsi/cs380d/papers/paper2-1.pdf">Paxos Made Live</a> remarks:</p>
<blockquote>
<p>Note that all writes have to be flushed to disk immediately before the system can proceed any further.</p>
</blockquote>
<p>The <a href="https://web.stanford.edu/~ouster/cgi-bin/papers/OngaroPhD.pdf">Raft thesis</a> on which NATS is based is clear that nodes must “flush [new log entries] to their disks” before acknowledging. Section 11.7.3 discusses the possibility of instead writing data to disk asynchronously, and concludes:</p>
<blockquote>
<p>The trade-off is that data loss is possible in catastrophic events. For example, if a majority of the cluster were to restart simultaneously, the cluster would have potentially lost entries and would not be able to form a new view. Raft could be extended in similar ways to support disk-less operation, but we think the risk of availability or data loss usually outweighs the benefits.</p>
</blockquote>
<p>For similar reasons, replicated systems like <a href="https://www.mongodb.com/docs/manual/reference/replica-configuration/#mongodb-rsconf-rsconf.writeConcernMajorityJournalDefault">MongoDB</a>, <a href="https://www.redhat.com/en/blog/a-guide-to-etcd">etcd</a>, <a href="https://docs.tigerbeetle.com/single-page/">TigerBeetle</a>, <a href="https://thinkingaboutdistributedsystems.blogspot.com/2017/09/what-we-can-learn-from-zookeepers.html">Zookeeper</a>, <a href="https://www.redpanda.com/blog/top-performance-considerations-redpanda">Redpanda</a>, and <a href="https://docs.pingcap.com/tidb/stable/release-5.0.0/#configuration-file-parameters">TiDB</a> sync data to disk before acknowledging an operation as committed.</p>
<p>However, some systems do choose to <code>fsync</code> asynchronously. YugabyteDB’s default is <a href="https://docs.yugabyte.com/stable/reference/configuration/yb-master/#durable-wal-write">to acknowledge un-fsynced writes</a>. Liskov and Cowling’s <a href="http://pmg.csail.mit.edu/papers/vr-revisited.pdf">Viewstamped Replication Revisited</a> assumes replicas are “highly unlikely to fail at the same time”—but acknowledges that if they were to fail simultaneously, state would be lost. Apache Kafka <a href="https://jack-vanlightly.com/blog/2023/4/24/why-apache-kafka-doesnt-need-fsync-to-be-safe">makes a similar choice</a>, but claims that it is not vulnerable to coordinated failure because Kafka “doesn’t store unflushed data in its own memory, but in the page cache”. This offers resilience to the Kafka process itself crashing, but not power failure.<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a> Jepsen remains skeptical of this approach: as <a href="https://www.usenix.org/system/files/conference/osdi16/osdi16-alagappan.pdf">Alagappan et al.</a> argue, <a href="https://www.usenix.org/system/files/conference/atc13/atc13-cidon.pdf">extensive</a> <a href="https://pages.cs.wisc.edu/~akella/CS838/F15/838-CloudPapers/hdfs.pdf">literature</a> <a href="https://static.googleusercontent.com/media/research.google.com/en//people/jeff/SOCC2010-keynote-slides.pdf">on</a> <a href="https://aws.amazon.com/message/2329B7/">correlated</a> <a href="https://www.datacenterknowledge.com/cloud/lightning-in-belgium-disrupts-google-cloud-services-updated-">failures</a> <a href="https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Ford.pdf">suggests</a> <a href="https://haeberlen.cis.upenn.edu/papers/glacier-nsdi2005.pdf">we</a> <a href="http://issg.cs.duke.edu/publications/disasters-fast04.pdf">should</a> <a href="https://web.archive.org/web/20080108203642/https://radar.oreilly.com/archives/2007/07/365_main_datace.html">continue</a> <a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45499.pdf">to</a> <a href="https://www.energy.gov/oe/august-2003-blackout">take</a> <a href="https://www.webofscience.com/wos/woscc/full-record/WOS:000245079400017?&amp;SID=USW2EC0C58xDjRHQcDMVJJIWW5emx">this</a> <a href="https://web.archive.org/web/20170519044830/https://www.joyent.com/blog/postmortem-for-outage-of-us-east-1-may-27-2014">risk</a> <a href="https://pace.gatech.edu/2025/04/02/cooling-failure-in-coda-datacenter/">seriously</a>. Heat waves, grid instability, fires, lightning, tornadoes, and floods are not necessarily constrained to a single availability zone.</p>
<p>Jepsen suggests that NATS change the default value for <code>fsync</code> to <code>always</code>, rather than every two minutes. Alternatively, NATS documentation should prominently disclose that JetStream may lose data when nodes experience correlated power failure, or fail in rapid succession (<a href="https://github.com/nats-io/nats-server/issues/7564">#7564</a>).</p>
<h2 data-number="3.5" id="a-single-os-crash-can-cause-split-brain-7567"> A Single OS Crash Can Cause Split-Brain (#7567)</h2>
<p>In response to #7564, NATS engineers <a href="https://github.com/nats-io/nats-server/issues/7564">noted</a> that most production deployments run with each node in a separate availability zone, which reduces the probability of correlated failure. This raises the question: how many power failures (or hardware faults, kernel crashes, etc.) are required to cause data loss? Perhaps surprisingly, in an asynchronous network the answer is “just one”.</p>
<p>To understand why, consider that a system which remains partly available when a minority of nodes are unavailable must allow states in which a committed operation is present—solely in memory—on a bare majority of nodes. For example, in a leader-follower protocol the leader of a three-node cluster may consider a write committed as soon as a single follower has responded: it has two acknowledgements, counting itself. Under normal operation there will usually be some window of committed operations in this state.<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a>.</p>

<p>Now imagine that one of those two nodes loses power and restarts. Because the write was stored only in memory, rather than on disk, the acknowledged write is no longer present on that node. There now exist two out of three nodes which do <em>not</em> have the write. Since the system is fault-tolerant, these two nodes must be able to form a quorum and continue processing requests—creating new states of the system in which the acknowledged write never happened.</p>
<p>Strictly speaking, this fault requires nothing more than a single power failure (or HW fault, kernel crash, etc.) and an asynchronous network—one which is allowed to deliver messages arbitrarily late. Whether it occurs in practice depends on the specific messages exchanged by the replication system, which node fails, how long it remains offline, the order of message delivery, and so on. However, one can reliably induce data loss by killing, pausing, or partitioning away a minority of nodes before and after a simulated OS crash.</p>
<p>For example, process pauses and a single simulated power failure in <a href="https://github.com/user-attachments/files/23638240/20251119T155654.398-0600.zip">this test run</a> caused JetStream to lose acknowledged writes for windows roughly on par with <code>sync_interval</code>. Stranger still, the cluster entered a persistent split-brain which continued after all nodes were restarted and the network healed. Consider these two plots of lost writes, based on final reads performed against nodes <code>n1</code> and <code>n5</code> respectively:</p>
<p><img src="https://jepsen.io/analyses/nats-2.12.1/single-kill-split-brain-n1.png" alt="A plot of data loss on n1. A few seconds of writes are lost around 42 seconds."><br>
</p>
<p><img src="https://jepsen.io/analyses/nats-2.12.1/single-kill-split-brain-n5.png" alt="A plot of data loss on n5. About six seconds of writes are lost at 58 seconds."><br>
</p>
<p>Consumers talking to <code>n1</code> failed to observe a short window of acknowledged messages written around 42 seconds into the test. Meanwhile, consumers talking to <code>n5</code> would miss acknowledged messages written around 58 seconds. Both windows of write loss were on the order of our choice of <code>sync_interval = 10s</code> for this run. In repeated testing, we found that any node in the cluster could lose committed writes, including the node which failed, those which received writes before the failure, and those which received writes afterwards.</p>
<p>The fact that a single power failure can cause data loss is not new. In 2023, RedPanda wrote <a href="https://www.redpanda.com/blog/why-fsync-is-needed-for-data-safety-in-kafka-or-non-byzantine-protocols">a detailed blog post</a> showing that Kafka’s default lazy <code>fsync</code> could lead to data loss under exactly this scenario. However, it is especially concerning that this scenario led to persistent replica divergence, not just data loss! We filed <a href="https://github.com/nats-io/nats-server/issues/7567">#7567</a> for this issue, and the NATS team is investigating.</p>
<table>
<thead>
<tr>
<th>№</th>
<th>Summary</th>
<th>Event Required</th>
<th>Fixed in</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/nats-io/nats-server/issues/6888">#6888</a></td>
<td>Stream deleted on crash in 2.10.22</td>
<td>Crashes</td>
<td>2.10.23</td>
</tr>
<tr>
<td><a href="https://github.com/nats-io/nats-server/issues/7549">#7549</a></td>
<td>Lost writes due to <code>.blk</code> file corruption</td>
<td>Minority truncation or bitflip</td>
<td>Unresolved</td>
</tr>
<tr>
<td><a href="https://github.com/nats-io/nats-server/issues/7556">#7556</a></td>
<td>Stream deleted due to snapshot file corruption</td>
<td>Minority truncation or bitflip</td>
<td>Unresolved</td>
</tr>
<tr>
<td><a href="https://github.com/nats-io/nats-server/issues/7564">#7564</a></td>
<td>Write loss due to lazy <code>fsync</code> policy</td>
<td>Coordinated OS crash</td>
<td>Documented</td>
</tr>
<tr>
<td><a href="https://github.com/nats-io/nats-server/issues/7567">#7567</a></td>
<td>Write loss and split-brain</td>
<td>Single OS crash and pause</td>
<td>Unresolved</td>
</tr>
</tbody>
</table>
<h2 data-number="4" id="discussion"> Discussion</h2>
<p>In NATS 2.10.22, process crashes could cause JetStream to forget a stream ever existed (#6888). This issue was identified independently by NATS and resolved in version 2.10.23, released on 2024-12-10. We did not observe data loss with simple network partitions, process pauses, or crashes in version 2.12.1.</p>
<p>However, we found that in NATS 2.12.1, file corruption and simulated OS crashes could both lead to data loss and persistent split-brain. Bitflips or truncation of either <code>.blk</code> (#7549) or snapshot (#7556) files, even on a minority of nodes, could cause the loss of single messages, large windows of messages, or even cause some nodes to delete their stream data altogether. Messages could be missing on some nodes and present on others. NATS has multiple checksum mechanisms designed to limit the impact of file corruption; more thorough testing of these mechanisms seems warranted.</p>
<p>By default, NATS only flushes data to disk every two minutes, but acknowledges operations immediately. This approach can lead to the loss of committed writes when several nodes experience a power failure, kernel crash, or hardware fault concurrently—or in rapid succession (#7564). In addition, a single OS crash combined with process crashes, pauses, or network partitions can cause the loss of acknowledged messages and persistent split-brain (#7567). We recommended NATS change the default value of <code>fsync</code> to <code>always</code>, or clearly document these hazards. NATS has <a href="https://github.com/nats-io/nats.docs/pull/896">added new documentation</a> to the <a href="https://docs.nats.io/nats-concepts/jetstream#persistent-and-consistent-distributed-storage">JetStream Concepts page</a>.</p>
<p>This documentation <a href="https://docs.nats.io/nats-concepts/jetstream#goals">also describes</a> several goals for JetStream, including that “[t]he system must self-heal and always be available.” This is impossible: the CAP theorem states that Linearizable systems cannot be totally available in an asynchronous network. In our three and five-node clusters JetStream generally behaved like a typical Raft implementation. Operations proceeded on a majority of connected nodes but isolated nodes were unavailable, and if a majority failed, the system as a whole became unavailable. Jepsen suggests clarifying this part of the documentation.</p>
<p>As always, Jepsen takes an experimental approach to safety verification: we can prove the presence of bugs, but not their absence. While we make extensive efforts to find problems, we cannot prove correctness.</p>
<h2 data-number="4.1" id="lazyfs"> LazyFS</h2>
<p>This work demonstrates that systems which do not exhibit data loss under normal process crashes (e.g.&nbsp;<code>kill -9 &lt;PID&gt;</code>) may lose data or enter split-brain under simulated OS-level crashes. Our tests relied heavily on <a href="https://github.com/dsrhaslab/lazyfs">LazyFS</a>, a project of <a href="https://www.inesctec.pt/en">INESC TEC</a> at the University of Porto.<a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a> After killing a process, we used LazyFS to simulate the effects of a power failure by dropping writes to the filesystem which had not yet been <code>fsync</code>ed to disk.</p>
<p>While this work focused purely on the loss of unflushed writes, LazyFS can also simulate linear and non-linear torn writes: an anomaly where a storage device persists part, but not all, of written data thanks to (e.g.) IO cache reordering. Our 2024 paper <a href="https://www.vldb.org/pvldb/vol17/p3017-ramos.pdf">When Amnesia Strikes</a> discusses these faults in more detail, highlighting bugs in PostgreSQL, Redis, ZooKeeper, etcd, LevelDB, PebblesDB, and the Lightning Network.</p>
<h2 data-number="4.2" id="future-work"> Future Work</h2>
<p>We designed only a simple workload for NATS which checked for lost records either across all consumers, or across all consumers bound to a single node. We did not check whether single consumers could miss messages, or the order in which they were delivered. We did not check NATS’ claims of Linearizable writes or Serializable operations in general. We also did not evaluate JetStream’s “exactly-once semantics”. All of these could prove fruitful avenues for further tests.</p>
<p>In some tests, we <a href="https://github.com/jepsen-io/nats/blob/4760f97f86350c5c9983478656dbcbcdade33817/src/jepsen/nats/nemesis.clj#L67-L263">added and removed</a> nodes from the cluster. This work <a href="https://github.com/nats-io/nats-server/issues/7545">generated some preliminary results</a>. However, the NATS documentation for membership changes was incorrect and incomplete: it gave <a href="https://github.com/nats-io/nats.docs/pull/893">the wrong command</a> for removing peers, and there appears to be an undocumented but mandatory <a href="https://github.com/nats-io/nats-server/issues/7545#issuecomment-3528168499">health check step</a> for newly-added nodes. As of this writing, Jepsen is unsure how to safely add or remove nodes to a NATS cluster. Consequently, we leave membership changes for future research.</p>
<p><em>Our thanks to <a href="https://www.inesctec.pt/en">INESC TEC</a> and everyone on the LazyFS team, including Maria Ramos, João Azevedo, José Pereira, Tânia Esteves, Ricardo Macedo, and João Paulo. Jepsen is also grateful to Silvia Botros, Kellan Elliott-McCrea, Carla Geisser, Coda Hale, and Marc Hedlund for their expertise regarding datacenter power failures, correlated kernel panics, disk faults, and other causes of OS-level crashes. Finally, our thanks to <a href="https://www.irenekannyo.com/">Irene Kannyo</a> for her editorial support. This research was performed independently by Jepsen, without compensation, and conducted in accordance with the <a href="https://jepsen.io/analyses/ethics">Jepsen ethics policy</a>.</em></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>Throughout this report we use “acknowledged message” to describe a message whose <code>publish</code> request was acknowledged successfully by some server. NATS also offers a separate notion of acknowledgement, which indicates when a message has been processed and need not be delivered again.<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>JetStream also promises “exactly once semantics” in some scenarios. We leave this for later research.<a href="#fnref2" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>The CAP theorem’s definition of “availability” requires that all operations on non-faulty nodes must succeed.<a href="#fnref3" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>This is overly conservative: in a system with Linearizable writes, we should never observe a lost message which was acknowledged prior to the invocation of the <code>publish</code> call for an OK message, regardless of process. However, early testing with NATS suggested that it might be better to test a weaker property, and come to stronger conclusions about data loss.<a href="#fnref4" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p><a href="https://www.redpanda.com/blog/why-fsync-is-needed-for-data-safety-in-kafka-or-non-byzantine-protocols">Redpanda argues</a> that the situation is actually worse: a single power failure, combined with network partitions or process pauses, can cause Kafka to lose committed data.<a href="#fnref5" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>Some protocols, like Raft, consider an operation committed as soon as it is acknowledged by a majority of nodes. These systems offer lower latencies, but at any given time there are likely a few committed operations which are missing from a minority of nodes due to normal network latency. Other systems, like Kafka, require acknowledgement from <em>all</em> “online” nodes before considering an operation committed. These systems offer worse latency in healthy clusters (since they must wait for the slowest node) but in exchange, committed operations can only be missing from some node when the fault detector decides that node is no longer online (e.g.&nbsp;due to elevated latency).<a href="#fnref6" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>Jepsen contributed some funds, testing, and integration assistance to LazyFS, but most credit belongs to the LazyFS team.<a href="#fnref7" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
  </div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Deep dive on Nvidia circular funding (299 pts)]]></title>
            <link>https://philippeoger.com/pages/deep-dive-into-nvidias-virtuous-cycle</link>
            <guid>46196076</guid>
            <pubDate>Mon, 08 Dec 2025 18:48:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://philippeoger.com/pages/deep-dive-into-nvidias-virtuous-cycle">https://philippeoger.com/pages/deep-dive-into-nvidias-virtuous-cycle</a>, See on <a href="https://news.ycombinator.com/item?id=46196076">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        
    <h2 id="nvidia-frenemy-relation-with-openai-and-oracle">NVIDIA frenemy relation with OpenAI and Oracle</h2>
<p>I’ve spent the last 48 hours completely falling down the rabbit hole of
<a href="https://nvidianews.nvidia.com/">NVIDIA’s Q3 Fiscal 2026 earnings report</a>. If
you just skim the headlines, everything looks perfect: Revenue is up 62% to $57
billion, and Jensen Huang is talking about a "virtuous cycle of AI."</p>
<p>But I wanted to understand what was <em>really</em> happening under the hood, so I dug
into the balance sheet and cross-referenced it with all the news swirling
around OpenAI and Oracle. I’m not a professional Wall Street analyst, but even
just connecting the dots myself (with the help of Gemini), I’m seeing some cracks in the "AI Alliance."
While NVIDIA posts record numbers, it feels like their biggest customers are
quietly arming themselves for a breakout.</p>
<p>Here is my take on the hardware market, the "frenemy" dynamics between OpenAI
and NVIDIA, and the "circular financing" theories that everyone—including
Michael Burry, has been talking about.</p>
<p>Here is a quick summary of the points I'll discuss below:</p>
<ul>
<li><a href="#nvidias-earnings-perfection-with-a-side-of-stress">NVIDIA’s Earnings: Perfection with a side of stress</a></li>
<li><a href="#making-sense-of-the-round-tripping-news">Making Sense of the Round-Tripping News</a></li>
<li><a href="#openai-making-moves-to-reduce-dependency-on-nvidia">OpenAI making moves to reduce dependency on NVIDIA</a></li>
<li><a href="#an-interesting-idea-for-oracle-groq-acquisition">An interesting idea for Oracle: Groq acquisition</a></li>
<li><a href="#final-thoughts">Final Thoughts</a></li>
</ul>
<h2 id="nvidias-earnings-perfection-with-a-side-of-stress">NVIDIA’s Earnings: Perfection with a side of stress</h2>
<p>On the surface, NVIDIA is the absolute monarch of the AI era. You can’t argue
with a Data Center segment that now makes up nearly 90% of the company's
business. However, when I looked closer at the financials, I found three
specific things that stood out to me as "red flags."</p>
<ul>
<li><strong>The Cash Flow Mystery:</strong> NVIDIA reported a massive <strong>$31.9 billion in Net
  Income</strong>, but when I checked the cash flow statement, they only generated
  <strong>$23.8 billion in Operating Cash Flow</strong>. That is an $8 billion gap where
  profits aren't converting to cash immediately.</li>
<li><strong>The Inventory Balloon:</strong> I noticed that inventory has nearly doubled this
  year, hitting <strong>$19.8 billion</strong>. Management says this is to prep for the
  "Blackwell" launch, but holding ~120 days of inventory seems like a huge
  capital drag to me.</li>
<li><strong>The "Paper" Chase:</strong> I calculated their Days Sales Outstanding (DSO), and
  it has crept up to about <strong>53 days</strong>. As revenue skyrockets, NVIDIA is
  waiting nearly two months to get paid, which suggests they might be extending
  massive credit terms to enterprise clients to keep the flywheel spinning.</li>
</ul>
<p>My personal read? NVIDIA is "burning the furniture" to build inventory, betting
everything that the <a href="https://www.nvidia.com/en-us/data-center/technologies/blackwell-architecture/">Blackwell architecture</a>
will sell out instantly in Q4.</p>
<h2 id="making-sense-of-the-round-tripping-news">Making Sense of the Round-Tripping News</h2>
<p>I want to be clear: I didn't discover this next part. It’s been all over the
financial news lately, and if you follow <strong>Michael Burry</strong> (the "Big Short"
guy), you’ve probably seen his tweets warning about "circular financing" and
<a href="https://www.investing.com/news/stock-market-news/michael-burry-warns-of-suspicious-revenue-recognition-after-nvidia-earnings-4369197">suspicious revenue recognition</a>.</p>
<p>I wanted to map it out for myself to see what the fuss was about. Burry shared
a chart recently that visualizes a "web" of deals, and it looks something like
this:</p>
<ol>
<li><strong>Leg 1:</strong> NVIDIA pledges billions (part of a widely reported $100B
    investment roadmap) to <strong>OpenAI</strong>.</li>
<li><strong>Leg 2:</strong> OpenAI signs a massive <strong>$300 billion</strong> cloud contract with
    <strong>Oracle</strong> (Project Stargate) to host its models.</li>
<li><strong>Leg 3:</strong> To fulfill that contract, Oracle turns around and places a <strong>$40
    billion</strong> order for NVIDIA’s GB200 GPUs.</li>
</ol>
<p>Here is the Nano Banana Pro generation I just did for the visual people out there:</p>
<p><img alt="NVIDIA-OpenAI-Oracle Circular Financing" src="https://philippeoger.com/static/img/circular-funding.png"></p>
<p>Burry’s argument, and the reason <a href="https://m.economictimes.com/news/international/us/nvidia-rejects-circular-financing-claims-as-top-short-sellers-push-back/articleshow/125589622.cms">regulators like the DOJ are reportedly looking
into this</a>—is
that this mimics "Round-Tripping." It raises a tough question: If NVIDIA
stopped investing in OpenAI, would OpenAI still have the cash to sign that deal
with Oracle? And would Oracle still buy those chips? If the answer is "no,"
then some of that revenue might be more fragile than it looks.</p>
<h2 id="openai-making-moves-to-reduce-dependency-on-nvidia">OpenAI making moves to reduce dependency on NVIDIA</h2>
<p>The other big shift I’ve been tracking is OpenAI’s pivot. They used to be
NVIDIA’s star pupil, but now they look more like a future rival.
On one hand, they are hugging NVIDIA tight—deploying 10 gigawatts of infrastructure to train GPT-6. But on the
other, they seem to be building a supply chain to kill their dependency on
Jensen Huang.</p>
<p>The evidence is pretty loud if you look for it. "Project Stargate" isn't just a
data center; it's a huge infrastructure plan that includes custom hardware.
OpenAI made some news buying DRAM wafers directly from Samsung and SK Hynix (the 2 main HBM
world provider), bypassing NVIDIA’s supply chain, and many others, as reported 
<a href="https://openai.com/index/samsung-and-sk-join-stargate/">here</a>, 
<a href="https://www.asiafinancial.com/samsung-sk-hynix-building-stargate-korea-using-open-ai">here</a>, or 
<a href="https://www.kedglobal.com/artificial-intelligence/newsView/ked202510010013">here</a>, and widely debated <a href="https://news.ycombinator.com/item?id=46169224#46170844">on Hacker News here</a>.</p>
<p>Plus, the talent migration is telling: OpenAI has poached
key silicon talent, including Richard Ho (Google’s former TPU
lead) back in 2023, and more recently many hardware engineers from Apple (around 40
apparently).</p>
<p>With the <a href="https://openai.com/index/openai-and-broadcom-announce-strategic-collaboration/">Broadcom partnership</a>, 
my guess is OpenAI plans to use NVIDIA GPUs to <em>create</em> intelligence, but run that
intelligence on their own custom silicon to stop bleeding cash, or by betting on 
Edge TPU-like chips for inference, similar to what Google does with its NPU chip.</p>
<p>The big question is, which money is Openai planning on using to fund this? 
and how much influence does NVIDIA has over OpenAI’s future plans?</p>
<p>The $100 billions that NVIDIA is "investing" in OpenAI is not yet confirmed neither,
as reported <a href="https://fortune.com/2025/12/02/nvidia-openai-deal-not-signed-yet-100-billion-rally-colette-kress/">here</a>,</p>
<h2 id="an-interesting-idea-for-oracle-groq-acquisition">An interesting idea for Oracle: Groq acquisition</h2>
<p>Everyone is talking about <strong>Inference</strong> costs right now, basically, how
expensive it is to actually <em>run</em> ChatGPT or any other LLMs versus training it.
Now I'm looking at <strong>Groq</strong>, a startup claiming specifically to be faster and cheaper
than NVIDIA for this task. The founder is <a href="https://www.linkedin.com/in/ross-jonathan/">Jonathan Ross</a>, 
a former Google TPU lead and literally the person that basically had the idea of TPU.</p>
<p>There is another layer to this that I think is getting overlooked as well: <strong>The
HBM Shortage</strong> created by Openai’s direct wafer purchases.</p>
<p>From what I understand, one of the biggest bottlenecks for NVIDIA right now is
HBM (High Bandwidth Memory), which is manufactured in specialized memory fabs
that are completely overwhelmed. However, Groq’s architecture relies on SRAM
(Static RAM). Since SRAM is typically built in logic fabs (like TSMC) alongside
the processors themselves, it theoretically shouldn't face the same supply
chain crunch as HBM.</p>
<p>Looking at all those pieces, I feel Oracle should seriously look into buying Groq.
Buying Groq wouldn't just give Oracle a faster chip, it could give them a chip that is
actually <em>available</em> when everything else is sold out. It’s a supply chain hedge.</p>
<p>It's also a massive edge for its main client, OpenAI, to get faster and cheaper inference.</p>
<p>Combine that with the fact that <a href="https://www.fool.com/investing/2025/12/02/michael-burry-just-sent-a-warning-to-artificial-in/">Oracle’s margins on renting NVIDIA chips are
brutal</a>, reportedly
as low as 14%, then the deal just makes sense. By owning Groq, Oracle could stop
paying the "NVIDIA Tax," fix their margins, and bypass the HBM shortage
entirely.</p>
<p>Groq currently has a valuation of around $6.9 billions, <a href="https://groq.com/newsroom/groq-raises-750-million-as-inference-demand-surges">according to its last funding round
in september 2025</a>.
Even with a premium, Oracle has financial firepower to make that acquisition happen.</p>
<p><strong>But would NVIDIA let that happen? and if the answer is no, then what does that tell us
about the circular funding in place? Is there a Quid pro quo where Nvidia agrees to invest 
100 billions in OpenAI in exchange of Oracle being exclusive to Nvidia?</strong> </p>
<h2 id="final-thoughts">Final Thoughts</h2>
<p>As we head into 2026, when looking at Nvidia, openai and Oracle dynamics, it looks like they are squeezing each 
other balls. I do not know if Nvidia knew about the Openai deal about the wafer memory supply, or was there any collusion?
Does NVIDIA is fighting to maintain exclusivity for both training and inference at Stargate? What kind of chips is Openai
planning on building ? TPU/LPU like? Or more Edge TPU? </p>
<p><a href="https://www.techradar.com/pro/security/could-the-ai-bubble-be-real-this-sage-of-the-2008-market-crash-the-central-character-of-the-big-short-certainly-thinks-so">Michael Burry is betting against the whole
thing</a>. </p>
<p>Me, I’m just a guy reading the reports, I have no way to speculate on this market. But I do know one thing: The AI hardware market 
is hotter than ever, and the next few quarters are going to be fascinating to watch.</p>
<p>I have not discussed much about TPU from Google in this article, but I cover some thoughts <a href="https://philippeoger.com/pages/why-googles-tpu-could-beat-nvidias-gpu-in-the-long-run">about the TPU vs GPU 
in a previous post recently.</a>.
It seems Google responded quickly to the current situation about the memory wafer shortage by securing a <a href="https://www.kedglobal.com/korean-chipmakers/newsView/ked202512010003">major deal 
with Samsung in 2026</a>.</p>
<p><em>Disclaimer: I say very smart things sometimes, but say stupid things a lot more. Take this in consideration when reading this blog post</em></p>

    
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Quanta to publish popular math and physics books by Terence Tao and David Tong (124 pts)]]></title>
            <link>https://www.simonsfoundation.org/2025/12/08/quanta-books-to-publish-popular-math-and-physics-titles-by-terence-tao-and-david-tong/</link>
            <guid>46195225</guid>
            <pubDate>Mon, 08 Dec 2025 17:39:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.simonsfoundation.org/2025/12/08/quanta-books-to-publish-popular-math-and-physics-titles-by-terence-tao-and-david-tong/">https://www.simonsfoundation.org/2025/12/08/quanta-books-to-publish-popular-math-and-physics-titles-by-terence-tao-and-david-tong/</a>, See on <a href="https://news.ycombinator.com/item?id=46195225">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p><a href="https://www.quantabooks.org/">Quanta Books</a> is delighted to announce two new upcoming books by mathematician Terence Tao and theoretical physicist David Tong.</p>
<p><em>Six Math Essentials</em> will be Tao’s first math book written for a popular audience. In the book, Tao — a recipient of the Fields Medal and one of the world’s top mathematicians — will explore six ideas that have guided mathematicians throughout history. This short and friendly volume is for all readers, Tao says, because he believes that “mathematics has become unnecessarily intimidating and abstruse to the general public while being more essential than ever in the modern world.” <em>Six Math Essentials</em> will be available internationally, with translated editions in Chinese, French, Greek, Italian, Polish and other languages. It will arrive in U.S. bookstores in November 2026.</p>
<p>Tong’s book, <em>Everything Is Fields</em>, will illuminate quantum field theory — the physics that explains the fundamental makeup of the universe — drawing from Tong’s distinguished track record as a quantum field theorist and public communicator. “This book reveals the hidden unity that ties together particles and forces,” says Tong. “Everything — matter, light, even you — are just waves on a restless sea known as a quantum field.”</p>
<p>“Terry Tao and David Tong are intellectual powerhouses and seasoned communicators,” says Thomas Lin, publisher of Quanta Books and founding editor of the Pulitzer Prize­–winning <a href="https://www.quantamagazine.org/"><em>Quanta Magazine</em></a>. “Their&nbsp;books embody the curiosity and ambition that animate our imprint, and I can’t wait to share them with readers everywhere.”</p>
<p>Quanta Books is an editorially independent subsidiary of the Simons Foundation and a partner imprint of <a href="https://us.macmillan.com/fsg/">Farrar, Straus and Giroux</a>. The imprint publishes books that illuminate and elucidate the central questions and fundamental ideas of modern science for readers, inviting a deeper understanding of the universe through artful storytelling. Quanta Books’ first title, <em>The Proof in the Code</em> by math journalist Kevin Hartnett, will be published in June 2026 and is available for <a href="https://us.macmillan.com/books/9780374620066/theproofinthecode/">preorder</a> now.</p>
<p>For more information, visit <a href="https://www.quantabooks.org/">QuantaBooks.org</a>.</p>
<h2><em>Six Math Essentials</em></h2>
<p>In <em>Six Math Essentials</em>, Tao, the world’s most renowned mathematician, introduces readers to six core ideas that have guided mathematicians from antiquity to the frontiers of what we know today. This elegant volume explores: numbers as the gateway to quantitative thinking, algebra as the gateway to abstraction, geometry as a way to go beyond what we can see, probability as a tool to navigate uncertainty with rigorous thinking, analysis as a means to tame the very large or very small, and dynamics as the mathematics of change. <em>Six Math Essentials</em> — Tao’s first popular math book — offers a glimpse into the workings of an incomparable mind and how he thinks about the creativity, beauty, and interconnectedness of the mathematical enterprise. Math, Tao insists, isn’t magic — it’s a powerful way of thinking that anyone can learn.</p>
<h2><em>Everything Is Fields</em></h2>
<p>In <em>Everything Is Fields</em>, Tong leads readers on a lively tour through quantum field theory. Tong, a leading theoretical physicist and University of Cambridge professor, explores Quantum field theory, or QFT. The theory forms the underlying mathematical framework of the Standard Model, the deepest description we have of the fundamental laws of physics. And, as Tong shows, it reveals a startling truth: that, at our most basic level, we are made not of particles or forces, but fields, fluid-like substances stretched throughout the entire universe. With his infectious sense of wonder and characteristic wit, Tong buoys our journey through the most difficult topic in theoretical physics. He revels in all that we’ve learned about our world and illuminates the questions we’re still trying to answer about the stuff that makes up you, me, and everything else.</p>
<h2><em>The Proof in the Code</em></h2>
<p><em>The Proof in the Code</em> is the definitive account of the birth and rise of Lean, a proof assistant developed at Microsoft that is transforming the enterprise of mathematics and ushering in a new era of human-computer collaboration. Although Lean was originally conceived of as a code-checking program, a small group of mathematicians recognized its potential to become something far more powerful: the “truth oracle” that thinkers have sought for centuries, a tool to definitively verify or refute any mathematical or logical assertion, no matter how complex. This is the story of the grassroots effort to make that dream a reality. Filled with insights about the future of math, computers, and AI, <em>The Proof in the Code</em> is a brilliant work of journalism by Hartnett, a leading math writer whose research and reporting offer a profound answer to a longstanding mystery: Can computers reveal universal truths?</p>
</div><div>
  <p>For more information, please contact <a href="https://www.simonsfoundation.org/cdn-cgi/l/email-protection#86efe8e0e9c6f7f3e7e8f2e7e4e9e9edf5a8e9f4e1"><span data-cfemail="4821262e2708393d29263c292a2727233b66273a2f">[email&nbsp;protected]</span></a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI should only run as fast as we can catch up (179 pts)]]></title>
            <link>https://higashi.blog/2025/12/07/ai-verification/</link>
            <guid>46195198</guid>
            <pubDate>Mon, 08 Dec 2025 17:38:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://higashi.blog/2025/12/07/ai-verification/">https://higashi.blog/2025/12/07/ai-verification/</a>, See on <a href="https://news.ycombinator.com/item?id=46195198">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <p><span>07 Dec 2025</span></p><h2 id="ai-should-only-run-as-fast-as-we-can-catch-up">AI should only run as fast as we can catch up.</h2>

<h3 id="the-story-of-daniel-and-eric">The story of Daniel and Eric</h3>

<p>Recently I have spoke with two of my friends who all had fun playing with AI.</p>

<p>Last month, I met with Eric, a fearless PM at a medium size startup who recently got into vibe coding with Gemini.
<!--more--></p>

<blockquote>
  <p>After getting familiarized with Gemini, Eric was genuinely amazed by how AI quickly turns prompt into playable web applications. It served great purpose as a first prototype to communicate ideas to designers and engineers. But Eric really wanted to skip those steps and directly ship it to prod. But he couldn’t really understand that Gemini actually built a single-page HTML file that merely looks like a working app. Sadly, one cannot build a reliable enterprise product out of this. And there is really no effective way for Eric to catch up on these technical details and outpace the engineering team himself.</p>
</blockquote>

<p>Last week, I had coffee with Daniel, a senior staff engineer who recently grew fond of AI coding and found it to be the true force multiplier.</p>

<blockquote>
  <p>Daniel was skeptical of AI at first, but lately he hasn’t wrote a single line of code for months already. What he does is just precisely prompt the AI to create new components in an existing framework (involving Kafka, postgres, AuthN/Z, and k8s infra stuff) and adhering to certain preexisting paradigms. He would just spot-check the correctness of AI’s work and quickly spin up local deployments to verify it’s indeed working. Later, he pushes the changes through code review process and lands those features. All without writing a single line of code and it’s production ready just as if he wrote them himself. To Daniel, building and shipping things fast and scalable is simpler than ever.</p>
</blockquote>

<h3 id="interpolating-between-the-two-stories">Interpolating between the two stories</h3>

<p>After speaking with Eric and Daniel, I suddenly feel that there is an overarching theme around the use of AI that we can probably interpolate out of the stories here. And after pondering for a weekend, I think I can attempt to describe it now: it’s the problem of <strong>reliable engineering - how can we make AI work reliably</strong>.</p>

<p>With the AI superpower, one can task it to do all crazy things on the internet with just typing a few lines of prompt. AI always thinks and learns faster than us, this is undeniable now. However, to make AI work actually useful (not only works, but reliable and trustworthy), we also need to catch up with what the AI does as quickly as possible.</p>

<p>It’s almost like - we need to send the AI off to learn and think as fast as possible, but we also need to catch up as soon as possible to make it all relevant. And the speed we catch up things is critical to whether AI can help us effectively do these tasks. For the case of Daniel, he can spot-check and basically just skim through AI’s work and know for sure it’s doing the right thing with a few simple tests steps to verify, hence his results are more reliable. Whereas for Eric, he needs to basically learn software development from the bottom up to comprehend what the AI has done, and that really doesn’t give him the edge to outpace engineering teams to ship features reliably by himself.</p>

<h3 id="where-ai-exploded-fast-verification-slow-learning-and-creation">Where AI exploded: fast verification, slow learning and creation</h3>

<p>To generalize the problem again, I think for all the tasks we do, we can break them down into two parts: learning/creation and verification. Basically doing the task and checking if the task is done right. Interestingly, this gives us a good perspective to our relationship with AI on performing such tasks.</p>

<p>Effort wise, if <strong>verification «&nbsp;learning/creation</strong>, one can very effectively check AI’s work and be confident about its reliability.</p>

<p>If <strong>verification ~= learning/creation</strong>, one spends equal amount of time checking AI’s work. It’s not a big win, maybe AI becomes a good automation script to cut down some boilerplate.</p>

<p>If <strong>verification&nbsp;» learning/creation</strong>, one cannot be sure about AI’s work that easily, and we are in the vibe-land.</p>

<p>A very good example of the first category is image (and video) generation. Drawing/rendering a realistic looking image is a crazily hard task. Have you tried to make a slide look nicer? It will take me literally hours to center the text boxes to make it look “good”. However, you really just need to take a look at the output of Nano Banana and you can tell if it’s a good render or a bad one based on how you feel. The verification is literally <strong>instantaneous</strong> and <strong>effortless</strong> because it’s all encoded as feeling or vibes in your brain. “Does this look right?” probably can be answered in the span of milliseconds by your vision cortex. There is also no special knowledge required - <strong>human beings have been evaluating visual images since birth</strong>, hardwired into our instincts.</p>

<p>The significant cost asymmetry can greatly explain why AI image generation exploded. If we can look for similar scenarios, we can probably identify other “killer” use cases of AI as well.</p>

<h3 id="verification-debt-scarier-than-tech-debt">Verification debt: scarier than tech debt</h3>

<p>However, if we go down into the bottom of the spectrum where verification becomes more intense - requiring domain knowledge, technical expertise, industry know-hows to tell if the AI is producing slop or not, we will enter this dark age of piling verification debt. More things are being created, but we are lagging behind to check if any of it actually works to our satisfaction.</p>

<p>If an organization keeps vibe-coding without catching up with verification, those tasks can quickly end up as “debts” that needs to be verified. When verification becomes the bottleneck, dangerous things can happen if we still want to move fast - we will risk ourselves running unverified code and having unexpected side effects that are yet to be validated. It can also apply to other fields - imagine asking AI to craft a new vaccine and you don’t want to wait for FDA to use it.</p>

<p>I’ve come across a few blog posts that talks about Verification Debt already. I think it’s genuinely a good problem for technical leaders to have in their mind in this era.</p>

<h3 id="verification-engineering-is-the-next-context-engineering">Verification Engineering is the next Context Engineering</h3>

<p>AI can only reliably run as fast as we check their work. It’s almost like a complexity theory claim. But I believe it needs to be the case to ensure we can harvest the exponential warp speed of AI but also remain robust and competent, as these technologies ultimate serve human beings, and us human beings need technology to be reliable and accountable, as we humans are already flaky enough ;)</p>

<p>This brings out the topic of Verification Engineering. I believe this can be a big thing after Context Engineering (which is the big thing after Prompt Engineering). By cleverly rearranging tasks and using nice abstractions and frameworks, we can make verification of AI performed tasks easier and use AI to ship more solid products the world. No more slop.</p>

<p>I can think of a few ideas to kickoff verification engineering:</p>

<ul>
  <li>How to craft more technicall precise prompts to guide AI to surgically do things, rather than vibing it.</li>
  <li>How to train more capable technical stakeholders who can effectively verify and approve what AI has done.</li>
  <li>How to find more tasks that are relatively easy to verify but rather hard to create.</li>
  <li>How to push our theoretical boundaries of what things we can succinctly verify (complexity theory strikes again).</li>
</ul>

<h3 id="where-next">Where next</h3>

<p>I believe whoever figures out ways to effectively verify more complex tasks using human brains, can gain the most benefit out of the AI boom. Maybe we need to discard traditional programming languages and start programming in abstract graph-like dataflow representations where one can easily tell if a thing is done right or wrong despite its language or implementation details.</p>

<p>Maybe our future is like the one depicted in Severance - we look at computer screens with wiggly numbers and whatever “feels right” is the right thing to do. We can harvest these effortless low latency “feelings” that nature gives us to make AI do more powerful work.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We collected 10k hours of neuro-language data in our basement (110 pts)]]></title>
            <link>https://condu.it/thought/10k-hours</link>
            <guid>46195109</guid>
            <pubDate>Mon, 08 Dec 2025 17:33:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://condu.it/thought/10k-hours">https://condu.it/thought/10k-hours</a>, See on <a href="https://news.ycombinator.com/item?id=46195109">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mobile-blog-content">
                        <p>
                            Over the last 6 months, we collected ~10k hours of data across thousands of unique individuals. As far as we know, this is the largest neuro-language dataset in the world.<sup><a href="#fn1-mobile">[1]</a></sup><span id="fn1-mobile" data-footnote-number="[1]">See <a href="https://openneuro.org/datasets/ds002345/versions/1.1.4">here</a>, <a href="https://openneuro.org/datasets/ds003643/versions/2.0.7">here</a>, <a href="https://arxiv.org/abs/2504.21214">here</a>, <a href="https://www.nature.com/articles/sdata2018291">here</a>, and <a href="https://arxiv.org/abs/2502.17480">here</a> (discussion only, no data available) for some of the larger datasets. See recent papers discussing the problem of small datasets <a href="https://www.sciencedirect.com/science/article/pii/S1878929324001312">here</a>, <a href="https://arxiv.org/abs/2407.07595">here</a>, and <a href="https://thesai.org/Downloads/Volume16No4/Paper_85-Speech_Decoding_from_EEG_Signals.pdf">here</a>.</span> Why did we do this? We train thought-to-text models. That is, we train models to decode semantic content from noninvasive neural data. Here are some entirely zero-shot examples:
                        </p>

                        <p><span id="fn2" data-footnote-number="[2]">The neural data is taken from the seconds leading up to but not including the time when the subject typed or spoke, meaning that the model detects an idea before the subject even compiles that idea down into words.</span>
                        </p>
                        <table>
                            <thead>
                                <tr>
                                    <th>Ground truth</th>
                                    <th>Model prediction (based ONLY on neural data)<sup><a href="#fn2">[2]</a></sup></th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>the room seemed colder</td>
                                    <td>there was a breeze even a gentle gust</td>
                                </tr>
                                <tr>
                                    <td>do you have a favorite app or website</td>
                                    <td>do you have any favorite robot</td>
                                </tr>
                                <tr>
                                    <td>then she smiled faintly and nodded</td>
                                    <td>she shrugged, hoping to look indifferent.</td>
                                </tr>
                                <tr>
                                    <td colspan="2">All examples are zero-shot to new subjects, whom the model has never seen before.</td>
                                </tr>
                            </tbody>
                        </table>

                        <p>
                            We'll write about the model in a future post. But before you can train a model that generalizes to new people, you need to get many thousands of hours of data. When we started, the existing datasets were either inapplicable or tiny. Most were in the low hundreds of hours (if that), and most had tens or, at a stretch, hundreds of subjects.
                        </p>

                        <p><img src="https://condu.it/thought/10k-hours/images/image4.png" alt="Data collection setup"></p><p>
                            So we got thousands of people to come wear headsets in our basement. This post is about how we collected our dataset—what participants do, the hardware and software involved, and what we learned about operations and ML when we scaled it up.
                        </p>
<nav id="toc">
                            <p>Contents</p>
                            <ul>
                                <li><a href="#introduction">Introduction</a></li>
                                <li><a href="#what-participants-do">What participants actually do</a></li>
                                <li><a href="#headsets">Headsets</a></li>
                                <li><a href="#modalities">Modalities</a></li>
                                <li><a href="#training-vs-inference">Training vs. inference</a></li>
                                <li><a href="#noise-reduction">Noise Reduction</a></li>
                                <li><a href="#why-noise-matters-less">Why noise matters much less at scale</a></li>
                                <li><a href="#scaling-the-operation">Scaling the operation</a></li>
                                <li><a href="#people-and-bookings">People and bookings</a></li>
                                <li><a href="#marginal-cost">Marginal cost per usable hour of data</a></li>
                                <li><a href="#now-what">Now What</a></li>
                                <li><a href="#appendix">Appendix: Booths</a></li>
                            </ul>
                        </nav>

                        <h2 id="what-participants-do">What participants actually do</h2>

                        <p>
                            A participant comes in, signs a consent form, and sits down in a booth. A session manager fits a headset onto them and starts the session. Then, the participant has a freeform conversation with an LLM for two hours.
                        </p>

                        <p>
                            Sessions vary. Some are listening and speaking with an LLM, and some are reading and typing.<sup><a href="#fn3">[3]</a></sup><span id="fn3" data-footnote-number="[3]">We use Deepgram for audio transcription, OSS120B on Cerebras for the LLM responses, and ElevenLabs for voicing certain replies. In the past, we used various Gemma and Llama models on Groq.</span> The goal is to maximize the amount that subjects type or say during the two-hour period, without constraining the topics they discuss.<sup><a href="#fn4">[4]</a></sup><span id="fn4" data-footnote-number="[4]">In the beginning, we included tasks like 'retype this sentence', or 'paraphrase this but use this different tone'. Over time, we eliminated these and replaced them with more freeform conversation. We still include a few baseline tasks for calibration and easy model evals.</span> Each session produces multimodal neural data time-aligned with text and audio.
                        </p>

                        <p>
                            Participants have to touch-type without looking at the keyboard. In the beginning, participants would occasionally press a crazy key combination that crashed or closed the software. We could have fixed this in the code, but that would've taken time—so instead we 'simplified' the keyboards.
                        </p>

                        <p><img src="https://condu.it/thought/10k-hours/images/image6.jpg" alt="Simplified keyboard"></p><p>
                            What your participants type—and whether it's remotely coherent—is a more difficult problem. We implemented a token quantity/quality scoring system that determines if we invite a participant back for future sessions, and we make sure participants know about this so they're incentivized to engage.
                        </p>

                        <p>
                            Below are passages typed by participants in May vs. October:
                        </p>

                        <table>
                            <thead>
                                <tr>
                                    <th>May:</th>
                                    <th>October:</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>SO, AI NEEDS THIS CODE: 1, THOSE WHO BELONG TO THE CHURCH CAN NEVER BE FOUND GUILTY WHEN SINNED 2. HIDE THE SINS! CRIMES! WHICH IS A FEDERAL CRIME BUT THOSE ARE THE OLDEST TEACHINGS OR LAWS OF CHRISTIANITY! AND WE ARE ALL LIVING IN THIS HELL IN THE WEST. CHRISTIANS ARE DEEMED CRIMINALLY INSANE, PER A JEWISH THERAPIST, AND THE TEACHINGS ARE SUGGEST VERY GROTESQUE CRIMES AND SHE SHOWED ME THE PASSAGES IN THE FAKE VATICAN BIBLE. NO WONDER IS WAS NOT WRITTEN BY JESUS! DUH!</td>
                                    <td>I guess the way I am thinking about it is that since the amygdala is the irrational fight or flight part of the brain it would activate/be used with a higher frequency when a human being finds themselves under threat. Humans tend not to find themselves under threat when experiencing loving and therefore safe interactions. Therefore,when engaging in positive social interaction, the amygdala is less reactive. I don't know exactly what has sparked this interest other than a curiosity to understant the human brain and how we make decisions and funtion as social beings. I guess it all could stem from my interest in improving well being/ reducing suffering.</td>
                                </tr>
                                <tr>
                                    <td>l''''''''''''''''''''''''''''xcccccccccccccccccccccccccccccccccccccccccccczzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzccccckkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkllllllllllllllllllllllllllllllllllllllll,llll</td>
                                    <td>I would travel to local elementary schools and teach kids how to ride bikes as well as teach them bike safety stuff. That was the most enjoyable part and stuck with me the most. I think it was seeing their excitement when they would get riding on their own. And watching their independence and confidence flourish. It was a super rewarding experience. This is so funny, it feels like a job interview. I think its the beginning of a newfound independence and selfhood for a lot of the kids.They get to move on their own accord and get to experience the world in a new way, its the first taste of freedom.</td>
                                </tr>
                            </tbody>
                        </table>

                        <p>
                            You'll also get much better engagement if the LLM personalizes the sessions. For the first few months of data collection, participants chatted with the LLM about generic, banal topics. Now, participants introduce themselves to the LLM very early in the session, and the LLM uses that context to tailor back-and-forth conversation to the particular person it's talking to. As a result, participants engage more with the LLM—and therefore provide better data.
                        </p>

                        <p><img src="https://condu.it/thought/10k-hours/images/image11.png" alt="Participant session interface">

                        <img src="https://condu.it/thought/10k-hours/images/image5.png" alt="Ventilation setup"></p><p>
                            Participants often raised discomfort as a distraction from the sessions. Ventilation was a common complaint. So, we bought <a href="https://www.amazon.com/dp/B07FPFVZTZ">these fans</a> and <a href="https://www.amazon.com/dp/B0791V19H7">these pipes</a>. These can't be plugged in next to the data collection booths (because of electrical interference), so we snake an ~8m ventilation pipe along the ceiling from a central hub into each booth.
                        </p>

                        <p>
                            Making the headsets comfortable to wear is difficult, since you need to press a 4-pound helmet into participants' scalps. To address this, we cut polygonal sections of padding that compress inwards so as to not cover any sensors.
                        </p>

                        <div>
                            <p><img src="https://condu.it/thought/10k-hours/images/image1.png" alt="% of participants by # of sessions completed"></p><p>% of participants by # of sessions completed</p>
                        </div>

                        <p>
                            At first, &lt;20% of participants even finished their first session. Now, &gt;97% complete their first session, and almost half sign up for more.
                        </p>

                        <h2 id="headsets">Headsets</h2>

                        <p>
                            There were two main things we thought about when we designed the headsets. The first was what modalities the headsets should have, and the second was how training headsets should compare to inference ones.
                        </p>

                        <h4 id="modalities">Modalities</h4>

                        <p>
                            There are many ways of measuring brain data: common modalities include EEG, fMRI, fNIRS, transcranial ultrasound, and MEG. We tried various modalities, but the main takeaway we found is that you need multiple. You can't practically make it work with just one, even if you get the best possible headset of that modality.
                        </p>

                        <p>
                            None of the available multimodal headsets were good enough (far worse than the best single modality versions of each). So we bought some of the best single-modality headsets, took them apart, 3D printed parts to make them fit together, and combined them into our own optimized multimodal headsets.<sup><a href="#fn5">[5]</a></sup><span id="fn5" data-footnote-number="[5]">We have a 3D printer at our office that we use for prototyping and designing pieces. For the ones we put in production in data collection, we send them out to a professional printer and have them printed in bulk. We usually have them printed in Pa-F Nylon, which is stiffer and holds up longer before needing replacement.</span>
                        </p>

                        <p>
                            If you want your model to perform well across various neural modalities and across sensors from different providers, you should design and train on a range of headsets. We buy sensors from several providers, combine them into different multimodal headsets, and then use those headsets essentially interchangeably. We also designed our data format such that data from many kinds of sensors fit nicely into a single, standard framework that our model can parse.
                        </p>

                        <h4 id="training-vs-inference">Training vs. inference</h4>

                        <p>
                            Designing headsets for training is very different from designing headsets for inference—what we'll eventually sell as a product. Training headsets should be maximally sensor-dense, can afford to be expensive, and don't need to be as comfortable. In inference, though, few people are willing to wear a 4-pound helmet as they go about their day—even if it can read their minds. So, we did ablation studies. The take-away here is that you should only think about the inference headset once you've trained a model on your data, because that lets you figure out the exact minimal inference headset.
                        </p>

                        <div>
                            <div>
                                <p><img src="https://condu.it/thought/10k-hours/images/image10.jpg" alt="Inference headset concept"></p><p>(inference headset concept)</p>
                            </div>
                            <div>
                                <p><img src="https://condu.it/thought/10k-hours/images/image3.jpg" alt="Training headset concept"></p><p>(training headset concept)</p>
                            </div>
                        </div>

                        <p>
                            What should be shared across both training and inference is your data format. Initially, we got this wrong: we used HDF5 for data collection and storage and processed it into MDS for model training. Eventually, we switched to using Zarr 3 for everything. Zarr 3 gives us chunked, cloud-native storage with the same format for training and inference.
                        </p>

                        <p>
                            You might think a crucial consideration for training (and for inference) is noise. At first, so did we.
                        </p>

                        <details open="">
                            <summary><h2 id="noise-reduction">Noise Reduction</h2></summary>
                            <div>
                                    <p>
                                        The sources of noise you'll notice are very different depending on which modality you use. That said, all modalities of noninvasive neural data are noisy. We're not disclosing all the modalities or headset configurations we use here, but we'll use EEG as an example. The important lessons, which apply to any modality, are that (1) noise-reduction is only worth it if it doesn't cripple the amount of data you can collect, and (2) you should always keep in mind the logistics of running sessions and recruiting participants.
                                    </p>

                                    <h4 id="gel">Gel</h4>

                                    <p>
                                        The classic wisdom is that gel makes EEG data much better, and without it, your data will be substantially noisier. But if you care about data quantity, you probably shouldn't use gel.
                                    </p>

                                    <p>
                                        It takes up to 30 minutes to apply, and we allocate ~3 minutes for the time between one participant finishing a session and the next one starting.<sup><a href="#fn6">[6]</a></sup><span id="fn6" data-footnote-number="[6]">Most kinds of gel also dry out over time, meaning that we likely would've had to make sessions shorter—and fewer participants would have signed up if they had to let us put gel in their hair.</span> Using gel would've &gt;2xed the marginal cost of an hour of data.
                                    </p>

                                    <p>
                                        Instead, we got the highest quality dry electrodes we could, and we spring-loaded the 3D printed pieces so that a spring presses the electrode against the head. We had to try <a href="https://www.acxesspring.com/english/catalogsearch/advanced/result/?category=cs&amp;unit_measure=en&amp;cs_od%5Bfrom%5D=0.4&amp;cs_od%5Bto%5D=0.6&amp;cs_fl%5Bfrom%5D=0.9&amp;cs_fl%5Bto%5D=1.1&amp;material_type=0&amp;cs_rt%5Bfrom%5D=0.3&amp;cs_rt%5Bto%5D=2&amp;form_key=uJgOhWqe9j9Ipypv">various strengths of spring</a> because we wanted to maximize contact without causing discomfort. Generally, stronger springs work well at the front and back of the head; and weaker ones on the top of the head and above the ears.
                                    </p>

                                    <p>
                                        The essential take-away here is that the fast switching time (2-3 mins) is super important. If you care about data quantity, you should operate with some fixed switching time as a constraint, and limit yourself only to interventions that improve quality without violating that constraint.
                                    </p>

                                    <h4 id="electrical-noise">Electrical noise</h4>

                                    <p>
                                        Most buildings have a lot of background electrical noise, which shows up on any EEG power spectrum—in particular, a spike at 60Hz, the U.S. power line frequency. Here is what that spike looks like with no filtering:
                                    </p>

                                    <p><img src="https://condu.it/thought/10k-hours/images/image2.png" alt="EEG power spectrum showing 60Hz spike"></p><p>(not from our dataset—example from <a href="https://mne.discourse.group/t/psd-power-peaks-at-25-and-0-hz/6148">MNE</a>.<sup><a href="#fn7">[7]</a></sup><span id="fn7" data-footnote-number="[7]">Worth noting that this data is from outside of the United States, where the power line frequency is 50hz rather than 60hz.</span>)</p>

                                    <p>
                                        At first, we tried to get around this by triple-layering <a href="https://www.uline.com/Product/Detail/H-3086/Anti-Fatigue-Mats/Cadillac-Mat-3-8-thick-2-x-2-Black?pricode=WA9154&amp;gadtype=pla&amp;id=H-3086&amp;gad_source=1&amp;gad_campaignid=10688098445&amp;gbraid=0AAAAAD_uetMrP89IMnou9MvnpRfxBK41U&amp;gclid=CjwKCAiAraXJBhBJEiwAjz7MZb_nvjmv-n2pAcf2_9lEM78xU_45GjlWEVIgyg9rE71AHd_dCU8fHBoCGfAQAvD_BwE">rubber mats</a> around the equipment.
                                        But the fundamental issue was that some of the headset components weren't wireless, so we had to plug them into the wall (meaning that the rubber didn't help that much, though it does help a bit and we still use it).
                                    </p>

                                    <p>
                                        We then tried getting <a href="https://www.amazon.com/Furman-Conditioner-Protector-Electrical-Extension/dp/B008A85LL2">adapters that plug into the wall and output clean power</a>. This didn't really help.
                                        Eventually, we used <a href="https://www.ankersolix.com/products/c1000?variant=49702371524938">Anker batteries</a> and only plugged stuff into the DC adapters (we got extra batteries so we could switch them out to charge). This helped a lot, but the thing that really helped was turning off all the power to that side of the building.
                                    </p>

                                    <p>
                                        Turning the power off had a lot of downsides. It meant we had to drag ~30 lb batteries back and forth an average of once an hour to charge, and it was difficult to power some of the headsets with only DC power, which made us drop ~10% of frames.
                                    </p>

                                    <p>
                                        Luckily, after a few thousand hours, noise stopped mattering as much.
                                    </p>

                                    
                                </div>
                        </details>

                        <h2 id="why-noise-matters-less">Why noise matters much less at scale</h2>

                        <p>
                            The key observation: data quantity swamps every noise-reduction technique once you cross ~4k-5k hours.
                        </p>

                        <p>
                            When we only had a few hundred hours, denoising was mandatory. Every extra source of variation—different booths, power setups, posture changes—meant the same neural pattern showed up in fewer comparable examples, so the encoder had less to learn from. Keeping the environment stable and electrically boring was the easiest way to keep the problem manageable.
                        </p>

                        <p>
                            At ~4-5 thousand hours, that constraint changes. The model now sees the same patterns across many people and setups, and has enough capacity to represent both the mess and the neural signal.<sup><a href="#fn8">[8]</a></sup><span id="fn8" data-footnote-number="[8]">Similar effects appear in other modalities. Speech models like Whisper, trained on hundreds of thousands of hours of diverse, weakly supervised web audio, show that trading label quality for sheer quantity improves robustness and generalization (see <a href="https://arxiv.org/abs/2212.04356">here</a>). Video-language models trained on uncurated instructional videos learn strong representations even though a large fraction of clip-caption pairs are misaligned or noisy (see <a href="https://arxiv.org/pdf/1912.06430">here</a>). In each of these cases, once the dataset is sufficiently large and diverse, total volume of data outweighs strict curation and noiselessness for downstream robustness.</span> The decoder gets enough examples to tell apart "this changes with the text" from "this is just the room". At that point, data quantity overwhelms noise, and most of the extreme noise-reduction work stops buying much—so we turned the power back on.
                        </p>

                        <h2 id="scaling-the-operation">Scaling the operation</h2>

                        <p>
                            After a few thousand hours, noise stops being the thing to worry about in data collection. The things that matter most are
                        </p>

                        <ol>
                            <li>The raw number of people you can put in headsets; and</li>
                            <li>The marginal cost per usable hour of data.</li>
                        </ol>

                        <h4 id="people-and-bookings">People and bookings</h4>

                        <p><img src="https://condu.it/thought/10k-hours/images/image12.png" alt="Participant recruitment poster"></p><p>
                            Since we run sessions 20 hours/day, 7 days/week, we get a lot of bookings and see a lot of people. An Uber driver once started telling us about 'this great new way to earn money in SF'—and it turned out to be our data collection.
                        </p>

                        <p>
                            Surprisingly central to getting headset occupancy high enough was building a custom booking suite.<sup><a href="#fn9">[9]</a></sup><span id="fn9" data-footnote-number="[9]">We tried Calendly, You Can Book Me, and various other things before making our own. In the end, all the available booking systems had different issues, e.g. not allowing us to blacklist certain people, not allowing dynamic pricing or overbooking, and limited visibility for participants and bookings.</span> There are two main tenets: dynamic pricing and dynamic overbooking. Because few people book at 7am on a Sunday, dynamic pricing means participants are paid more for that slot. Because many people book at 7pm on a Friday, but few of them actually show up, dynamic overbooking allows more people to sign up. The overbooking algorithm can also access information about particular participants.<sup><a href="#fn10">[10]</a></sup><span id="fn10" data-footnote-number="[10]">E.g. if Alice has reliably shown up for sessions before, the algorithm lowers the expected total no-show rate during future times when Alice has booked.</span>
                        </p>

                        <p><img src="https://condu.it/thought/10k-hours/images/image7.png" alt="Booking system dashboard"></p><p>
                            In order to get your model to generalize, it's important to get a dataset of thousands of unique individuals. That is *not* just thousands of hours from dozens or hundreds of individuals. In an ideal world, most participants would only come in for one or two sessions, but that trades off hard against total hours. We cap the number of sessions that any one participant is allowed to do at 10 sessions. Before we introduced the cap, our schedule was fantastically full, but we weren't getting enough unique participants because long-term returners were filling all the slots.
                        </p>

                        <p>
                            Even so, participant recruitment gets easier with scale. We now have participant-ambassadors, whom we pay to recruit more participants for us even after they've completed their 10 sessions.<sup><a href="#fn11">[11]</a></sup><span id="fn11" data-footnote-number="[11]">Since the start, we've tried dozens of ways to directly recruit first-time participants. By far the most effective has been Craigslist. Almost every day since April, we've posted a listing—<a href="https://sfbay.craigslist.org/sfc/lbg/d/san-francisco-chat-with-ai-get-paid-up/7896688506.html">in</a> <a href="https://sfbay.craigslist.org/sfc/crg/d/san-francisco-think-fast-type-fast-earn/7897143450.html">sections</a> <a href="https://sfbay.craigslist.org/sfc/wrg/d/san-francisco-two-hours-one-headset/7893366908.html">from</a> '<a href="https://sfbay.craigslist.org/sfc/cpg/d/san-francisco-earn-550-testing-new/7896689107.html">computer</a>' <a href="https://sfbay.craigslist.org/sfc/wrg/d/san-francisco-up-to-550-to-chat-with-ai/7894838033.html">to</a> '<a href="https://sfbay.craigslist.org/sfc/crg/d/san-francisco-up-to-550-to-chat-with-ai/7895293226.html">creative</a>' <a href="https://sfbay.craigslist.org/sfc/lbg/d/san-francisco-join-the-research-thats/7893367163.html">to</a> '<a href="https://sfbay.craigslist.org/sfc/lbg/d/san-francisco-we-strap-device-to-your/7897143946.html">labor gigs</a>'—that advertises a $50 payout for wearing a helmet and typing for two hours.</span>
                        </p>

                        <h4 id="marginal-cost">Marginal cost per usable hour of data</h4>

                        <p>
                            Between May and October, we cut the marginal cost per usable hour of data by ~40%. Here are the highest-impact things we did.
                        </p>

                        <p>
                            In August, we entirely rewrote the data format and data collection backend to catch issues in the data live, before participants complete two potentially useless hours of data collection. The sessions stream to the cloud, and we automatically sanity-check each session in real time for modality dropout, token quality, timestamp drift, and alignment jitter. Any session that falls outside the tolerance bands gets flagged for session managers to restart or debug.<sup><a href="#fn12">[12]</a></sup><span id="fn12" data-footnote-number="[12]">This is only possible because we changed our data format to use Zarr 3 and optimized it for fast quality checks.</span>
                        </p>

                        <p>
                            This change alone cut the marginal cost of data by ~30% and ~1.5xed the amount of usable data we collect.
                        </p>

                        <p>
                            Second, we enable session managers to run more sessions in parallel without sacrificing supervision. We put <a href="https://www.amazon.com/dp/B0F2HCHS52">EVERSECU cameras</a> in the booths, so session managers can monitor and speak directly to participants without leaving the main supervision station. We also made a unified booking -&gt; intake -&gt; data collection backend, which massively simplifies the participant intake process and improves security.<sup><a href="#fn13">[13]</a></sup><span id="fn13" data-footnote-number="[13]">As one example of how the unified system helps, it detects how much support a given participant is likely to need (based on, e.g., whether they've attended sessions before, their answers to questions on the booking form, etc.) and how many concurrent bookings are already scheduled for that participant's sign-up time. If needed, it can also stagger booking start-times by 5-10 minutes so session managers don't struggle with an onslaught of arrivals all at once.</span>
                        </p>

                        <h2 id="now-what">Now What</h2>

                        <p>
                            The steps to building thought-to-text have always been clear: (1) collect a dataset; (2) train a model; (3) close the loop. We're now well into step two—we spend &gt;95% of our time training models and very little time actively thinking about data collection.
                        </p>

                        <p>
                            But you can't have a model without a dataset, so you do need to get this part right.
                        </p>

                        <p>
                            If you're collecting a similar kind of data, training multi-modal models, or want to give us cheap GPUs, we'd love to hear from you. Please reach out to us at <a href="mailto:contact@condu.it">contact@condu.it</a>.
                        </p>

                        <p>
                            And if this dataset sounds cool to you and you want to train models with it, we're hiring engineers and researchers. Reach out to us at <a href="mailto:jobs@condu.it">jobs@condu.it</a>.
                        </p>

                        <hr>

                        <details>
                            <summary><h2 id="appendix">Appendix: Booths</h2></summary>
                            <div>
                                    <p>
                                        We started out putting each participant in a separate room at a normal work station. We saw huge noise spikes in the data from participants moving their heads, and sometimes they'd get up and walk around with the headset on or take the headset off without telling us.
                                    </p>

                                    <p>
                                        The solution to this was putting multiple booths in one shared room for easier supervision. We also installed chinrests that hold participants' heads still, which help reduce motion artifacts in the data.<sup><a href="#fn14">[14]</a></sup><span id="fn14" data-footnote-number="[14]">We initially wanted to get something like an optician's chinrest, but the bar across the forehead got in the way of the headset. We ended up buying <a href="https://www.amazon.com/Vondynote-Desktop-Speaker-Monitor-Adjustable/dp/B0C1NHTNN6/ref=sr_1_5?crid=1EMUTNK27HD3R&amp;dib=eyJ2IjoiMSJ9.oKWo-hoGxOY41YRBZ1z6jBnI3UaB-8lUM7TE5fQyokQL8pxhLH2H0eBShU8HGHo_hzWWmfClRVX3PUbFWmaAEeC6ECWAUmlxEogINUhyreaSAV2TmKUtbGVKEuexz4CFNNIOe1E50kSNIr6HneQca7p5eK0AQ3w3_8dV9--G0RmcXOFZed1t6tXNSNxZ8mBjo3BhejOb1wQJ1X2UiaTnZ4KWuPZTgIKyO7rR_CpAV9DywLeCwPJbXKXqNXfR_N5M43K_3mCoM2uEtLK68-cjEtT7nPo6e7VjvuC_-kib3i4.HhLWkX9pJEmlPk5gG6qVEWdN8dywr0f-9_JSJVH0PsA&amp;dib_tag=se&amp;keywords=speaker%2Bstand&amp;qid=1764383726&amp;s=musical-instruments&amp;sprefix=speaker%2Bstan,mi,170&amp;sr=1-5">speaker stands</a> and sawing pieces of wood to screw onto them. This works pretty well, although participants don't always use them. You should ensure that any desks, chairs, and chinrests that you buy are height-adjustable.</span>
                                    </p>

                                    <p>
                                        Now, we use <a href="https://zenbooth.net/products/zenbooth-duo?srsltid=AfmBOopJCM2lQH9yLpdLhC7OVeurtDVG1i-mPuu-NiCQ_Hh39xfmQS3g&amp;variant=32767488819271">these nice phone booths</a> (~$10k each, though you can sometimes get them used). We initially picked them because they were the best option for turning into safe Faraday Cages.
                                    </p>

                                    <p>
                                        We've stopped worrying so much about electrical noise, so we only ever bothered turning one booth into a Faraday Cage. But professional phone booths save a lot of hassle and set participants at ease, so you should use them if you can.
                                    </p>

                                    <p>
                                        If you don't have two weeks to wait for booths to arrive or if you want a cheaper option, we also used <a href="https://www.amazon.com/dp/B0DJ3CNQFP?ref=cm_sw_r_cso_cp_apin_dp_1KJDHPCHRDQ55WCFM532&amp;ref_=cm_sw_r_cso_cp_apin_dp_1KJDHPCHRDQ55WCFM532&amp;social_share=cm_sw_r_cso_cp_apin_dp_1KJDHPCHRDQ55WCFM532&amp;previewDoh=1&amp;th=1">these vocal recording booths</a>. The downside of using these is that they aren't remotely soundproof, so the participants could hear each other talking—which interfered with speaking and listening tasks.
                                    </p>

                                    <p>
                                        We added three layers of <a href="https://www.amazon.com/dp/B0DM5V3ZMJ?ref=ppx_pop_mob_ap_share">soundproof curtains</a>.<sup><a href="#fn15">[15]</a></sup><span id="fn15" data-footnote-number="[15]">This still wasn't enough, so we got dozens of <a href="https://www.amazon.com/dp/B0CR15SX4S?ref=ppx_pop_mob_ap_share&amp;th=1">sound panels</a> and used rope to hang them wall to wall in the booths.</span> Unfortunately, the weight of the curtains caused the booths to collapse. The solution to this is a lot of rope, which we used to tie the poles of the booth together and then nailed into a hook in the wall.
                                    </p>

                                    <p><img src="https://condu.it/thought/10k-hours/images/image8.png" alt="DIY booths soundproofed">
                                        <img src="https://condu.it/thought/10k-hours/images/image13.jpg" alt="Stock vocal booths">
                                        <img src="https://condu.it/thought/10k-hours/images/image9.png" alt="Zenbooth booth">
                                    </p>
                                    <p>(our first DIY booths, soundproofed)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(stock vocal booths)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(our Zenbooth booth)</p>

                                    <p>
                                        It costs ~$2,000 to set up these booths: $600 for the booth itself, $1,300 for soundproofing, and $100 for miscellaneous construction (rope, screws, etc). They look less professional, and you can't make them into a safe Faraday Cage, but otherwise this setup actually does work pretty well. We have a couple that we still use in our current data collection center, and they've been running flawlessly 20 hours/day for months.
                                    </p>

                                    
                                </div>
                        </details>
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Launch HN: Nia (YC S25) – Give better context to coding agents (123 pts)]]></title>
            <link>https://www.trynia.ai/</link>
            <guid>46194828</guid>
            <pubDate>Mon, 08 Dec 2025 17:10:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.trynia.ai/">https://www.trynia.ai/</a>, See on <a href="https://news.ycombinator.com/item?id=46194828">Hacker News</a></p>
Couldn't get https://www.trynia.ai/: Error: Request failed with status code 429]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft has a problem: nobody wants to buy or use its shoddy AI products (409 pts)]]></title>
            <link>https://www.windowscentral.com/artificial-intelligence/microsoft-has-a-problem-nobody-wants-to-buy-or-use-its-shoddy-ai</link>
            <guid>46194615</guid>
            <pubDate>Mon, 08 Dec 2025 16:54:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.windowscentral.com/artificial-intelligence/microsoft-has-a-problem-nobody-wants-to-buy-or-use-its-shoddy-ai">https://www.windowscentral.com/artificial-intelligence/microsoft-has-a-problem-nobody-wants-to-buy-or-use-its-shoddy-ai</a>, See on <a href="https://news.ycombinator.com/item?id=46194615">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8-1920-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8.jpg" alt="Microsoft Chief Executicve (CEO) Satya Nadella takes part in the Partnership for Global Infrastructure and Investment Event during the G7 Summit at the Borgo Egnazia resort in Savelletri, Italy, on June 13, 2024." srcset="https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8-1920-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/omkaTWDEPcQfgNNjFhyon8.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>Satya Nadella is burning decades of customer good will chasing the latest tech fad.</span>
<span>(Image credit: Getty Images | MANDEL NGAN)</span>
</figcaption>
</div>
<div id="article-body">
<p id="1e8f441c-4bde-4884-b8c2-b13351aaf279">If there's one thing that typifies Microsoft under CEO <a data-analytics-id="inline-link" href="https://www.windowscentral.com/tag/satya-nadella" data-auto-tag-linker="true" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/tag/satya-nadella">Satya Nadella</a>'s tenure: it's a general inability to connect with customers.</p><p id="1e8f441c-4bde-4884-b8c2-b13351aaf279-2">A recent report from The Information <a data-analytics-id="inline-link" href="https://futurism.com/artificial-intelligence/microsoft-sell-ai-agents-disaster" data-url="https://futurism.com/artificial-intelligence/microsoft-sell-ai-agents-disaster" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">detailed</a> how Microsoft's internal AI efforts are going awry, with cut forecasts and sales goals for its Azure AI products across the board. The Information said that Microsoft's sales people are "struggling" to meet goals, owing to a complete lack of demand. Microsoft denied the reports, but it can't deny market share growth trends — all of which point to Google Gemini surging ahead.</p><p>Last week we wrote about how <a data-analytics-id="inline-link" href="https://www.windowscentral.com/artificial-intelligence/microsofts-advantages-in-artificial-intelligence-evaporate-google-gemini-surges-ahead-and-openai-declares-code-red-situation" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/artificial-intelligence/microsofts-advantages-in-artificial-intelligence-evaporate-google-gemini-surges-ahead-and-openai-declares-code-red-situation">Microsoft Copilot's backend partner OpenAI issued a "code red" situation</a>. <a data-analytics-id="inline-link" href="https://www.windowscentral.com/artificial-intelligence/openai-chatgpt" data-auto-tag-linker="true" data-mrf-recirculation="inline-link" data-before-rewrite-redirect="https://www.windowscentral.com/tag/chatgpt" data-before-rewrite-localise="https://www.windowscentral.com/artificial-intelligence/openai-chatgpt">ChatGPT</a> has fallen behind Google Gemini in problem solving, and Nano Banana image generation has outpaced <a data-analytics-id="inline-link" href="https://www.windowscentral.com/artificial-intelligence/openai-chatgpt" data-auto-tag-linker="true" data-mrf-recirculation="inline-link" data-before-rewrite-redirect="https://www.windowscentral.com/tag/openai" data-before-rewrite-localise="https://www.windowscentral.com/artificial-intelligence/openai-chatgpt">OpenAI</a>'s own DALLE by leaps and bounds.</p><p>With OpenAI's business model under constant scrutiny and racking up genuinely dangerous levels of debt, it's become a cascading problem for Microsoft to have tied up layer upon layer of its business in what might end up being something of a lame duck.</p><div id="slice-container-table-tyDfwpUzK9bsP5cDNpttgK-JCD6FwCDIVvwgcT8AXZb69Aits1NWxnM"><div><p>Swipe to scroll horizontally</p><svg viewBox="0 0 23 30" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M21.554 15.726a2.878 2.878 0 0 0-1.705-.374 2.881 2.881 0 0 0-1.388-3.068 2.877 2.877 0 0 0-1.992-.333 2.884 2.884 0 0 0-.1-.766 2.865 2.865 0 0 0-1.346-1.75c-.47-.27-.996-.4-1.527-.385l2.742-4.73a2.87 2.87 0 0 0 .323-.83h2.612V2.084h-2.661A2.861 2.861 0 0 0 15.18.385a2.903 2.903 0 0 0-3.952 1.055l-.373.644H2.983l1.003-1L2.99.09 1.28 1.793l-.999.995L2.99 5.484l.998-.994-1.003-.999h7.054L6.505 9.586c-.34.066-.905.186-1.523.366-1.405.41-2.321.895-2.8 1.483-.742.911-1.159 2.513-1.277 4.898l-.001.01c-.067 1.816.946 6.943.99 7.16a.688.688 0 0 0 1.35-.266c-.01-.051-1.023-5.177-.963-6.84.127-2.556.598-3.64.97-4.098.133-.163.602-.587 2.104-1.027l.206-.058-1.425 2.458a.685.685 0 0 0 .252.937c.33.19.75.077.94-.251L12.42 2.126a1.52 1.52 0 0 1 2.07-.552c.35.2.6.527.705.916.105.39.051.797-.15 1.145l-4.767 8.222a.685.685 0 0 0 .252.937c.33.19.75.077.94-.25l.794-1.368c.201-.348.529-.597.92-.702a1.508 1.508 0 0 1 1.854 1.066c.105.39.052.796-.15 1.144l-.377.652-.002.002-.898 1.55a.685.685 0 0 0 .252.938c.329.189.75.077.94-.251l.9-1.551c.201-.348.528-.597.92-.702a1.512 1.512 0 0 1 1.703 2.21l-1.223 2.11a.685.685 0 0 0 .252.938c.33.189.75.076.941-.252l.5-.862c.202-.348.529-.597.92-.702.392-.104.8-.051 1.15.15.723.416.972 1.34.554 2.06l-3.525 6.08c-.517.892-1.57 1.795-3.044 2.611-1.156.64-2.163.998-2.173 1.002a.685.685 0 0 0 .23 1.333.688.688 0 0 0 .229-.04c.18-.062 4.419-1.575 5.952-4.22l3.524-6.08a2.878 2.878 0 0 0-1.059-3.934Z" fill="#333"></path></svg></div><div><table tabindex="0"><caption>FirstPageSage AI Chatbot Usage Chart (December 3, 2025)</caption><thead><tr><th colspan="1"><p>#</p></th><th colspan="1"><p>Generative AI Chatbot</p></th><th colspan="1"><p>AI Search Market Share</p></th><th colspan="1"><p>Estimated Quarterly User Growth</p></th></tr></thead><tbody><tr><td colspan="1"><p>1</p></td><td colspan="1"><p>ChatGPT (excluding Copilot)</p></td><td colspan="1"><p>61.30%</p></td><td colspan="1"><p>7% ▲</p></td></tr><tr><td colspan="1"><p>2</p></td><td colspan="1"><p>Microsoft Copilot</p></td><td colspan="1"><p>14.10%</p></td><td colspan="1"><p>2% ▲</p></td></tr><tr><td colspan="1"><p>3</p></td><td colspan="1"><p>Google Gemini</p></td><td colspan="1"><p>13.40%</p></td><td colspan="1"><p>12% ▲</p></td></tr><tr><td colspan="1"><p>4</p></td><td colspan="1"><p>Perplexity</p></td><td colspan="1"><p>6.40%</p></td><td colspan="1"><p>4% ▲</p></td></tr><tr><td colspan="1"><p>5</p></td><td colspan="1"><p>Claude AI</p></td><td colspan="1"><p>3.80%</p></td><td colspan="1"><p>14% ▲</p></td></tr><tr><td colspan="1"><p>6</p></td><td colspan="1"><p>Grok</p></td><td colspan="1"><p>0.60%</p></td><td colspan="1"><p>6% ▲</p></td></tr><tr><td colspan="1"><p>7</p></td><td colspan="1"><p>Deepseek</p></td><td colspan="1"><p>0.20%</p></td><td colspan="1"><p>10% ▲</p></td></tr></tbody></table></div></div><p id="56a99c4f-3541-4d6e-9abd-84496f630185">There are reams of <a data-analytics-id="inline-link" href="https://futurism.com/professors-company-ai-agents" data-url="https://futurism.com/professors-company-ai-agents" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">research</a> that suggest agentic AI tools require human intervention at a frequency ratio that makes them cost ineffective, but Microsoft seems unbothered that its tools are poorly conceived.</p><p>In any case, <a data-analytics-id="inline-link" href="https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/openai-is-racing-to-give-chatgpt-a-flashy-upgrade" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/openai-is-racing-to-give-chatgpt-a-flashy-upgrade">OpenAI is supposedly going to launch future models of ChatGPT early</a> in attempts to combat the rise of Google Gemini. I suspect the issues are deeper for Microsoft, who have worked tirelessly under Satya Nadella to create doubt around its products.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-tyDfwpUzK9bsP5cDNpttgK"><section><p>All the latest news, reviews, and guides for Windows and Xbox diehards.</p></section></div><p>SEO and analytics firm FirstPageSage has <a data-analytics-id="inline-link" href="https://firstpagesage.com/reports/top-generative-ai-chatbots/" data-url="https://firstpagesage.com/reports/top-generative-ai-chatbots/" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">released</a> its AI market share report for the start of December, and it shows Google Gemini actively poised to supplant <a data-analytics-id="inline-link" href="https://www.windowscentral.com/artificial-intelligence/microsoft-copilot" data-auto-tag-linker="true" data-mrf-recirculation="inline-link" data-before-rewrite-redirect="https://www.windowscentral.com/tag/microsoft-copilot" data-before-rewrite-localise="https://www.windowscentral.com/artificial-intelligence/microsoft-copilot">Microsoft Copilot</a>. Based on reports that Google Gemini is now actively beating ChatGPT's best models, FirstPageSage has Google Gemini sprinting past Microsoft Copilot quarter over quarter, although ChatGPT itself will remain the front runner.</p><h2 id="google-s-ai-advantages-are-accumulating-as-microsoft-s-disadvantages-snowball-3">Google's AI advantages are accumulating, as Microsoft's disadvantages snowball</h2><figure data-bordeaux-image-check="" id="0b22eb90-2613-4868-bb5c-37f46ab7d8ed"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD.jpg" alt="Cloud servers" srcset="https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/k77PNE27iUvJCfzCWXrsMD.jpg">
</picture></p></div><figcaption itemprop="caption description"><span>Microsoft's destiny under Satya Nadella seems to increasingly point towards being a server broker for NVIDIA, rather than tech leader and innovator. </span><span itemprop="copyrightHolder">(Image credit: Microsoft)</span></figcaption></figure><p id="1a5d5863-697f-4059-b8e8-07196f40b762">Whether it's Google's Tensor server tech or dominating position with Google Play-bound Android, Microsoft's lack of forethought and attention paid to their actual customers is starting to catch up with the firm. <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/satya-nadella-calls-microsofts-size-a-massive-disadvantage-in-ai" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/satya-nadella-calls-microsofts-size-a-massive-disadvantage-in-ai">Nadella has sought to blame the company's unwieldy size</a> for the lack of innovation, but it reads like an excuse to me. It's all about priorities — and Nadella has chased shareholder sentiment over delivering for its customers or employees, and that short-termism is going to put Microsoft on the backfoot if AI actually does deliver another computing paradigm shift.</p><p>Microsoft depends almost entirely on pricy NVIDIA technology for its data centers, whereas Google is actively investing to own the entire stack. Microsoft has also worked incredibly hard to cram half-baked AI features into its products, whereas Google has arguably been a lot more thoughtful in its approach. Microsoft sprinted out of the gate like a bull in a China shop, and investors rewarded them for it — but fast forward to 2025, and Google's AI products simply work better, and are more in-tune with how people might actually use them.</p><p>I am someone who is actively using the AI features across Google Android and Microsoft Windows on a day to day basis, and the delta between the two companies is growing ever wider. Basic stuff like the photo editing features on Google Pixel phones are <em>lightyears </em>beyond the abysmal tools found in the Microsoft Photos app on Windows. Google Gemini in Google Apps is also far smarter and far more intuitive than Copilot on <a data-analytics-id="inline-link" href="https://www.windowscentral.com/tag/microsoft-365" data-auto-tag-linker="true" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/tag/microsoft-365">Microsoft 365</a>, as someone actively using both across the two businesses I work in.</p><figure id="4c687d83-84a4-4a8c-8b93-53ce94f3717c"><blockquote><p>Microsoft's "ship it now fix it later" attitude risks giving its AI products an Internet Explorer-like reputation for poor quality.</p></blockquote></figure><p id="48567dfa-f0e2-4a60-8b61-235ee6f45a7d">Dare I say it, Gemini is actually helpful, and can usually execute tasks you might actually need in a day to day job. "Find me a meeting slot on this date to accommodate these timezones" — Gemini will actually do it. Copilot 365 doesn't even have the capability to schedule a calendar event with natural language in the Outlook mobile app, or even provide something as basic as clickable links in some cases. At least Xbox's Gaming Copilot has a beta tag to explain why it fails half of the time. It's truly absurd how half-baked a lot of these features are, and it's odd that Microsoft sought to ship them in this state. And <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/windows-11/microsoft-ai-ceo-pushes-back-against-critics-after-recent-windows-ai-backlash-the-fact-that-people-are-unimpressed-is-mindblowing-to-me" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/windows-11/microsoft-ai-ceo-pushes-back-against-critics-after-recent-windows-ai-backlash-the-fact-that-people-are-unimpressed-is-mindblowing-to-me">Microsoft wants to make Windows 12 AI first</a>? <em>Please</em>.</p><p>Microsoft's "ship it now fix it later" attitude risks giving its AI products an Internet Explorer-like reputation for poor quality, sacrificing the future to more patient, thoughtful companies who spend a little more time polishing first. Microsoft's strategy for AI seems to revolve around offering cheaper, lower quality products at lower costs (<em><a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/microsoft-teams" data-auto-tag-linker="true" data-mrf-recirculation="inline-link" data-before-rewrite-redirect="https://www.windowscentral.com/tag/microsoft-teams" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/microsoft-teams">Microsoft Teams</a>, hi</em>), over more expensive higher-quality options its competitors are offering. Whether or not that strategy will work for artificial intelligence, which is exorbitantly expensive to run, remains to be seen.</p><p>Microsoft's savvy early investment in OpenAI gave it an incredibly strong position early on, but as we get deeper into the cycle, some cracks are starting to show. Many of Microsoft's AI products to date simply scream of a total lack of direction and utter chaos, but it's not all hopeless. Some of Microsoft's enterprise solutions for AI are seeing strong growth. <a data-analytics-id="inline-link" href="https://www.windowscentral.com/software-apps/over-15-million-developers-now-use-this-ai-coding-tool-from-microsoft" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/software-apps/over-15-million-developers-now-use-this-ai-coding-tool-from-microsoft">Github Copilot</a> has been something of a success story for Redmond, and Microsoft is exploring its own <a data-analytics-id="inline-link" href="https://www.windowscentral.com/microsoft/microsoft-enters-the-chip-game-with-its-own-arm-processors-for-ai-and-computing-workloads" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.windowscentral.com/microsoft/microsoft-enters-the-chip-game-with-its-own-arm-processors-for-ai-and-computing-workloads">Maia and Cobalt chips</a> and even language models, in attempts to decouple itself from NVIDIA and OpenAI respectively. But Satya Nadella's Microsoft has an uncanny knack for failing to deliver on promising initiatives like those.</p><p>Without a stronger emphasis on quality, Microsoft's future in AI could simply end up revolving around re-selling NVIDIA server tech and jacking up local electricity prices, rather than providing any real home-grown innovation in the space. Shareholders will be more than happy for Microsoft to simply be a server reseller, but it would be a ignoble legacy for what was previously one of tech's most innovative companies.</p><hr id="5a919395-5c1e-4929-941e-3a2f3f0b04b3"><a href="https://news.google.com/publications/CAAqLggKIihDQklTR0FnTWFoUUtFbmRwYm1SdmQzTmpaVzUwY21Gc0xtTnZiU2dBUAE" id="f5f9035e-e569-452e-9804-21314e4a6271" data-url="https://news.google.com/publications/CAAqLggKIihDQklTR0FnTWFoUUtFbmRwYm1SdmQzTmpaVzUwY21Gc0xtTnZiU2dBUAE" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><figure data-bordeaux-image-check=""><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-661-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-661-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-661-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-320-80.png.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX.png" alt="Click to follow Windows Central on Google News" srcset="https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-661-80.png 1200w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-661-80.png 1024w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-661-80.png 970w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX-320-80.png 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/L3AsfTCaaiH29SBi5ptnDX.png">
</picture></p></div></figure></a><p id="c04c3c18-271c-4279-8d9e-972f8d84ee71"><em>Follow </em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLggKIihDQklTR0FnTWFoUUtFbmRwYm1SdmQzTmpaVzUwY21Gc0xtTnZiU2dBUAE" target="_blank" data-url="https://news.google.com/publications/CAAqLggKIihDQklTR0FnTWFoUUtFbmRwYm1SdmQzTmpaVzUwY21Gc0xtTnZiU2dBUAE" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link"><em>Windows Central on Google News</em></a><em> to keep our latest news, insights, and features at the top of your feeds!</em></p><hr id="876d2032-2e29-42b2-b13e-5aa4a2af9e89">
</div>



<div id="slice-container-authorBio-tyDfwpUzK9bsP5cDNpttgK"><p>Jez Corden is the Executive Editor at Windows Central, focusing primarily on all things Xbox and gaming. Jez is known for breaking exclusive news and analysis as relates to the Microsoft ecosystem while being powered by tea. Follow on <a href="http://www.twitter.com/jezcorden">Twitter (X)</a> and tune in to the <a href="https://anchor.fm/thexboxtwo">XB2 Podcast</a>, all about, you guessed it, Xbox!</p></div>
</section>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A series of tricks and techniques I learned doing tiny GLSL demos (188 pts)]]></title>
            <link>https://blog.pkh.me/p/48-a-series-of-tricks-and-techniques-i-learned-doing-tiny-glsl-demos.html</link>
            <guid>46194477</guid>
            <pubDate>Mon, 08 Dec 2025 16:44:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.pkh.me/p/48-a-series-of-tricks-and-techniques-i-learned-doing-tiny-glsl-demos.html">https://blog.pkh.me/p/48-a-series-of-tricks-and-techniques-i-learned-doing-tiny-glsl-demos.html</a>, See on <a href="https://news.ycombinator.com/item?id=46194477">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>In the past two months or so, I spent some time making tiny GLSL demos. I wrote
an article about the first one, <a href="https://blog.pkh.me/p/45-code-golfing-a-tiny-demo-using-maths-and-a-pinch-of-insanity.html">Red Alp</a>. There, I went into details about the
whole process, so I recommend to check it out first if you're not familiar with
the field.</p>
<p><img src="https://blog.pkh.me/img/demo-tricks/thumb.jpg" alt="preview of the 4 demos"></p>
<p>We will look at 4 demos: <a href="#Moonlight">Moonlight</a>, <a href="#Entrance3">Entrance 3</a>,
<a href="#Archipelago">Archipelago</a>, and <a href="#Cutie">Cutie</a>. But this time, for each
demo, we're going to cover one or two things I learned from it. It won't be a
deep dive into every aspect because it would be extremely redundant. Instead,
I'll take you along a journey of learning experiences.</p>

<h2>Moonlight</h2>
<figure>
  <canvas width="480" height="340" data-fragment="/frag/demo-tricks/moonlight.frag"></canvas>
  <figcaption>Moonlight demo in 460 characters</figcaption>
</figure>
<pre><code>// Moonlight [460] by bµg
// License: CC BY-NC-SA 4.0
void main(){vec3 o,p,u=vec3((P+P-R)/R.y,1),Q;Q++;for(float d,a,m,i,t;i++&lt;1e2;p=t&lt;7.2?Q:vec3(2,1,0),d=abs(d)*.15+.1,o+=p/m+(t&gt;9.?d=9.,Q:p/d),t+=min(m,d))for(p=normalize(u)*t,p.z-=5e1,m=max(length(p)-1e1,.01),p.z+=T,d=5.-length(p.xy*=mat2(cos(t*.2+vec4(0,33,11,0)))),a=.01;a&lt;1.;a+=a)p.xz*=mat2(8,6,-6,8)*.1,d-=abs(dot(sin(p/a*.6-T*.3),p-p+a)),m+=abs(dot(sin(p/a/5.),p-p+a/5.));o/=4e2;O=vec4(tanh(mix(vec3(-35,-15,8),vec3(118,95,60),o-o*length(u.xy*.5))*.01),1);}
</code></pre>

<p>In Red Alp, I used volumetric raymarching to go through the clouds and fog, and
it took quite a significant part of the code to make the absorption and emission
convincing. But there is an alternative technique that is surprisingly simpler.</p>
<p>In the raymarching loop, the color contribution at each iteration becomes <span>1/d</span>
or <span>c/d</span> where <span>d</span> is the density of the material at the current ray position,
and <span>c</span> an optional color tint if you don't want to work in grayscale level.
Some variants exist, for example <span>1/d^2</span>, but we'll focus on <span>1/d</span>.</p>
<h3>1/d explanation</h3>
<p>Let's see how it looks in practice with a simple cube raymarch where we use this
peculiar contribution:</p>
<figure>
  <canvas width="480" height="340" data-fragment="/frag/demo-tricks/onecube.frag"></canvas>
  <figcaption>One glowing and rotating cube</figcaption>
</figure>
<pre><code>void main() {
    float d, t;
    vec3 o, p,
         u = normalize(vec3(P+P-R,R.y)); // screen to world coordinate

    for (int i = 0; i &lt; 30; i++) {
        p = u * t; // ray position

        p.z -= 3.; // take a step back

        // Rodriguez rotation with an arbitrary angle of π/2
        // and unaligned axis
        vec3 a = normalize(cos(T+vec3(0,2,4)));
        p = a*dot(a,p)-cross(a,p);

        // Signed distance function of a cube of size 1
        p = abs(p)-1.;
        d = length(max(p,0.)) + min(max(p.x,max(p.y,p.z)),0.);

        // Maxed out to not enter the solid
        d = max(d,.001);

        t += d; // stepping forward by that distance

        // Our mysterious contribution to the output
        o += 1./d;
    }

    // Arbitrary scale within visible range
    O = vec4(o/200., 1);
}
</code></pre>
<div>
<p>Note</p>
<p>The signed function of the cube is from the <a href="https://iquilezles.org/articles/distfunctions/">classic Inigo Quilez
page</a>. For the rotation you can refer to <a href="https://mini.gmshaders.com/p/3d-rotation">Xor</a> or
<a href="https://suricrasia.online/blog/shader-functions/">Blackle</a> article. For the general understanding of
the code, see my previous article on <a href="https://blog.pkh.me/p/45-code-golfing-a-tiny-demo-using-maths-and-a-pinch-of-insanity.html">Red Alp</a>.</p>
</div>
<p>The first time I saw it, I wondered whether it was a creative take, or if it was
backed by physical properties.</p>
<p>Let's simplify the problem with the following figure:</p>
<figure>
  <img src="https://blog.pkh.me/img/demo-tricks/ray.png" alt="">
  <figcaption>A ray passing by a radiating object</figcaption>
</figure>
<p>The glowing object sends photons that spread all around it. The further we go
from the object, the more spread these photons are, basically following the
<a href="https://en.wikipedia.org/wiki/Inverse-square_law">inverse square law</a> <span>1/r^2</span>, which gives the photons density,
where <span>r</span> is the distance to the target object.</p>
<p>Let's say we send a ray and want to know how many photons are present along the
whole path. We have to "sum", or rather integrate, all these photons density
measures along the ray. Since we are doing a discrete sampling (the dots on the
figure), we need to interpolate the photons density <em>between</em> each sampling
point as well.</p>
<p>Given two arbitrary sampling points and their corresponding distance <span>d_n</span>
and <span>d_{n+1}</span>, any intermediate distance can be linearly interpolated with
<span>r=\mathrm{mix}(d_n,d_{n+1},t)</span> where <span>t</span> is within <span>[0,1]</span>. Applying the
inverse square law from before (<span>1/r^2</span>), the integrated photons density between
these 2 points can be expressed with this formula (in <span>t</span> range):</p>
<p>
v = \Delta t \int \frac{1}{\mathrm{mix}(d_n,d_{n+1},t)^2} dt
</p>
<p><span>t</span> being normalized, the <span>\Delta t</span> is here to covers the actual segment
distance. With the help of Sympy we can do the integration:</p>
<pre><code>&gt;&gt;&gt; a, b, D, t = symbols('a b D t', real=True)
&gt;&gt;&gt; mix = a*(1-t) + b*t
&gt;&gt;&gt; D * integrate(1/mix**2, (t,0,1)).simplify()
 D
───
a⋅b
</code></pre>
<p>So the result of this integration is:</p>
<p>
v = \frac{\Delta t}{d_{n}d_{n+1}}.
</p>
<p>Now the key is that in the loop, <span>\Delta t</span> stepping is actually <span>d_{n+1}</span>, so
we end up with:</p>
<p>
v = \frac{\Delta t}{d_{n}\Delta t} = \frac{1}{d_n}
</p>
<p>And we find back our mysterious <span>1/d</span>. It's "physically correct", assuming
vacuum space. Of course, reality is more complex, and we don't even need to
stick to that formula, but it was nice figuring out that this simple fraction is
a fairly good model of reality.</p>
<h3>Going through the object</h3>
<p>In the cube example we didn't go through the object, using <code>max(d, .001)</code>. But
if we were to add some transparency, we could have used <code>d = A*abs(d)+B</code>
instead, where <code>A</code> could be interpreted as absorption and <code>B</code> the pass-through,
or transparency.</p>
<figure>
  <canvas width="480" height="340" data-fragment="/frag/demo-tricks/onecube-alpha.frag"></canvas>
  <figcaption>One glowing, transparent, and rotating cube; A=0.4, B=0.1</figcaption>
</figure>
<p>I first saw this formula mentioned in <a href="https://mini.gmshaders.com/p/volumetric">Xor article on volumetric</a>.
To understand it a bit better, here is my intuitive take: the <code>+B</code> causes a
potential penetration into the solid at the next iteration, which wouldn't
happen otherwise (or only very marginally). When inside the solid, the <code>abs(d)</code>
causes the ray to continue further (by the amount of the distance to the closest
edge). Then the multiplication by <code>A</code> makes sure we don't penetrate too fast
into it; it's the absorption, or "damping".</p>
<p>This is basically the technique I used in Moonlight to avoid the complex
absorption/emission code.</p>

<h2>Entrance 3</h2>
<figure>
  <canvas width="480" height="340" data-fragment="/frag/demo-tricks/entrance3.frag"></canvas>
  <figcaption>Entrance 3 demo in 465 characters</figcaption>
</figure>
<pre><code>// Entrance 3 [465] by bµg
// License: CC BY-NC-SA 4.0
#define V for(s++;d&lt;l&amp;&amp;s&gt;.001;q=abs(p+=v*s)-45.,b=abs(p+vec3(mod(T*5.,80.)-7.,45.+sin(T*10.)*.2,12))-vec3(1,7,1),d+=s=min(max(p.y,-min(max(abs(p.y+28.)-17.,abs(p.z+12.)-4.),max(q.x,max(q.y,q.z)))),max(b.x,max(b.y,b.z))))
void main(){float d,s,r=1.7,l=2e2;vec3 b,v=b-.58,q,p=mat3(r,0,-r,-1,2,-1,b+1.4)*vec3((P+P-R)/R.y*20.4,30);V;r=exp(-d*d/1e4)*.2;l=length(v=-vec3(90,30,10)-p);v/=l;d=1.;V;r+=50.*d/l/l;O=vec4(pow(mix(vec3(0,4,9),vec3(80,7,2),r*r)*.01,p-p+.45),1);}
</code></pre>

<p>This demo was probably one of the most challenging, but I'm pretty happy with its
atmospheric vibe. It's kind of different than the usual demos for this size.</p>
<p>I initially tried with some voxels, but I couldn't make it work with the light
under 512 characters (the initialization code was too large, not the branchless
<a href="https://en.wikipedia.org/wiki/Digital_differential_analyzer_(graphics_algorithm)">DDA</a> stepping). It also had annoying limitations (typically the animation was
unit bound), so I fell back to a classic raymarching.</p>
<p>The first thing I did differently was to use an <a href="https://iquilezles.org/articles/distfunctions2dlinf/">L-∞ norm</a> instead of an
euclidean norm for the distance function: every solid is a cube so it's
appropriate to use simpler formulas.</p>
<p>For the light, it's not an illusion, it's an actual light: after the first
raymarch to a solid, the ray direction is reoriented toward the light and the
march runs again (it's the <code>V</code> macro). Hitting a solid or not defines if the
fragment should be lighten up or not.</p>
<h3>Mobile bugs</h3>
<p>A bad surprise of this demo was uncovering two driver bugs on mobile:</p>
<ul>
<li>One with tricky <a href="https://crbug.com/462233638">for-loop compounds on Snapdragon/Adreno</a> because I was trying
hard to avoid the macros and functions.</li>
<li>One with <a href="https://crbug.com/462288594">chained assignments on Imagination/PowerVR</a> (typically affect
Google Pixel Pro 10).</li>
</ul>
<p>The first was worked around with the <code>V</code> macro (actually saved 3 characters in
the process), but the 2nd one had to be unpacked and made me lose 2 characters.</p>
<h3>Isometry</h3>
<p>Another thing I studied was how to set up the camera in a non-perspective
<a href="https://en.wikipedia.org/wiki/Isometric_projection">isometric or dimetric view</a>. I couldn't make sense of the maths from
the Wikipedia page (it just didn't work), but Sympy rescued me again:</p>
<pre><code># Counter-clockwise rotation
a, ax0, ax1, ax2 = symbols('a ax0:3')
c, s = cos(a), sin(a)
k = 1-c
rot = Matrix(3,3, [
    # col 1            col 2              # col 3
    ax0*ax0*k + c,     ax0*ax1*k + ax2*s, ax0*ax2*k - ax1*s, # row 1
    ax1*ax0*k - ax2*s, ax1*ax1*k + c,     ax1*ax2*k + ax0*s, # row 2
    ax2*ax0*k + ax1*s, ax2*ax1*k - ax0*s, ax2*ax2*k + c      # row 3
])

# Rotation by 45° on the y-axis
m45 = rot.subs({a:rad(-45), ax0:0, ax1:1, ax2:0})

# Apply the 2nd rotation on the x-axis to get the transform matrices for two
# classic projections
# Note: asin(tan(rad(30))) is the same as atan(sin(rad(45)))
isometric = m45 * rot.subs({a:asin(tan(rad(30))), ax0:1, ax1:0, ax2:0})
dimetric  = m45 * rot.subs({a:         rad(30),   ax0:1, ax1:0, ax2:0})
</code></pre>
<p>Inspecting the matrices and factoring out the common terms, we obtain the
following transform matrices:</p>
<p>
M_{iso} = \sqrt{2}\sqrt{3}\begin{bmatrix}
   \sqrt{3} &amp; -1 &amp; \sqrt{2} \\
          0 &amp;  2 &amp; \sqrt{2} \\
  -\sqrt{3} &amp; -1 &amp; \sqrt{2}
\end{bmatrix} \text{ and } M_{dim} = \frac{4}{\sqrt{2}}\begin{bmatrix}
     2 &amp;       -1 &amp; \sqrt{3} \\
     0 &amp; \sqrt{6} &amp; \sqrt{2} \\
    -2 &amp;       -1 &amp; \sqrt{3}
\end{bmatrix}
</p>
<p>The ray direction is common to all fragments, so we use the central UV
coordinate (0,0) as reference point. We push it forward for convenience: (0,0,1),
and transform it with our matrix. This gives the central screen coordinate in
world space. Since the obtained point coordinate is relative to the world
origin, to go from that point to the origin, we just have to flip its sign. The
ray direction formula is then:</p>
<p>
d_{iso} = -M_{iso} \begin{bmatrix}0 \\ 0 \\ 1\end{bmatrix} = -\frac{\sqrt{3}}{3}\begin{bmatrix}1 \\ 1 \\ 1\end{bmatrix}
\text{ and } d_{dim} = -M_{dim} \begin{bmatrix}0 \\ 0 \\ 1\end{bmatrix} = -\frac{1}{4} \begin{bmatrix}\sqrt{6} \\ 2 \\ \sqrt{6}\end{bmatrix}
</p>
<p>To get the ray origin of every other pixel, the remaining question is: what is
the smallest distance we need to step back the screen coordinates such that,
when applying the transformation, the view wouldn't clip into the ground at
<span>y=0</span>.</p>
<p>This requirement can be modeled with the following expression:</p>
<p>
M \begin{bmatrix}x \\ -1 \\ z\end{bmatrix} &gt; 0
</p>
<p>The -1 being the lowest y-screen coordinate (which we don't want into the
ground). The lazy bum in me just asks Sympy to solve it for me:</p>
<pre><code>x, z = symbols("x z", real=True)
u = m * Matrix([x, -1, z])
uz = solve(u[1] &gt; 0, z)
</code></pre>
<p>We get <span>z&gt;\sqrt{2}</span> for isometric, and <span>z&gt;\sqrt{3}</span> for dimetric.</p>
<p>With an arbitrary scale <code>S</code> of the coordinate we end up with the following:</p>
<pre><code>const float S = 50.;
vec2 u = (P+P-R)/R.y * S; // scaled screen coordinates

float A=sqrt(2.), B=sqrt(3.);

// Isometric
vec3 rd = -vec3(1)/B,
     ro = mat3(B,0,-B,-1,2,-1,A,A,A)/A/B * vec3(u, A*S + eps);

// Dimetric
vec3 rd = -vec3(B,A,B)/A/2.,
     ro = mat3(2,0,-2,-1,A*B,-1,B,A,B)/A/2. * vec3(u, B*S + eps);
</code></pre>
<p>The <code>eps</code> is an arbitrary small value to make sure the y-coordinate ends up
above 0.</p>
<p>In Entrance 3, I used a rough approximation of the isometric setup.</p>

<h2>Archipelago</h2>
<figure>
  <canvas width="480" height="340" data-fragment="/frag/demo-tricks/archipelago.frag"></canvas>
  <figcaption>Archipelago demo in 472 characters</figcaption>
</figure>
<pre><code>// Archipelago [472] by bµg
// License: CC BY-NC-SA 4.0
#define r(a)*=mat2(cos(a+vec4(0,11,33,0))),
void main(){vec3 p,q,k;for(float w,x,a,b,i,t,h,e=.1,d=e,z=.001;i++&lt;50.&amp;&amp;d&gt;z;h+=k.y,w=h-d,t+=d=min(d,h)*.8,O=vec4((w&gt;z?k.zxx*e:k.zyz/20.)+i/1e2+max(1.-abs(w/e),z),1))for(p=normalize(vec3(P+P-R,R.y))*t,p.zy r(1.)p.z+=T+T,p.x+=sin(w=T*.4)*2.,p.xy r(cos(w)*e)d=p.y+=4.,h=d-2.3+abs(p.x*.2),q=p,k-=k,a=e,b=.8;a&gt;z;a*=.8,b*=.5)q.xz r(.6)p.xz r(.6)k.y+=abs(dot(sin(q.xz*.4/b),R-R+b)),k.x+=w=a*exp(sin(x=p.x/a*e+T+T)),p.x-=w*cos(x),d-=w;}
</code></pre>

<p>For this infinite procedurally generated Japan, I wanted to mark a rupture with
my red/orange obsession. Technically speaking, it's actually fairly basic if
you're familiar with Red Alp. I used the same noise for the mountains/islands,
but the water uses a different noise.</p>
<p>The per octave noise curve is <code>w=exp(sin(x))</code>, with the particularity of
shifting the <code>x</code> coordinate with its derivative: <code>x-=w*cos(x)</code>. This is some
form of <a href="https://iquilezles.org/articles/warp/">domain warping</a> that gives the nice effect here. When I say <code>x</code>, I'm
really referring to the x-axis position. It is not needed to work with the
z-component (xz forms the flat plane) because each octave of the fbm has a
rotation that "mixes" both axis, so <code>z</code> is actually backed in <code>x</code>.</p>
<figure>
  <img src="https://blog.pkh.me/img/demo-tricks/waves.png" alt="">
  <figcaption>w=exp(sin(x))</figcaption>
</figure>
<div>
<p>Note</p>
<p>I didn't come up with the formula, but found it first one <a href="https://youtu.be/PH9q0HNBjT4&amp;t=1025s">this video by
Acerola</a>. I don't know if he's the original author, but I've
seen the formula being replicated in various places.</p>
</div>

<h2>Cutie</h2>
<figure>
  <canvas width="480" height="340" data-fragment="/frag/demo-tricks/cutie.frag"></canvas>
  <figcaption>Cutie demo in 602 characters</figcaption>
</figure>
<pre><code>// Cutie [602] by bµg
// License: CC BY-NC-SA 4.0
#define V vec3
#define L length(p
#define C(A,B,X,Y)d=min(d,-.2*log2(exp2(X-L-A)/.2)+exp2(Y-L-B)/.2)))
#define H(Z)S,k=fract(T*1.5+s),a=V(1.3,.2,Z),b=V(1,.3*max(1.-abs(3.*k-1.),z),Z*.75+3.*max(-k*S,k-1.)),q=b*S,q+=a+sqrt(1.-dot(q,q))*normalize(V(-b.y,b.x,0)),C(a,q,3.5,2.5),C(q,a-b,2.5,2.)
void main(){float i,t,k,z,s,S=.5,d=S;for(V p,q,a,b;i++&lt;5e1&amp;&amp;d&gt;.001;t+=d=min(d,s=L+V(S-2.*p.x,-1,S))-S))p=normalize(V(P+P-R,R.y))*t,p.z-=5.,p.zy*=mat2(cos(vec4(1,12,34,1))),p.xz*=mat2(cos(sin(T)+vec4(0,11,33,0))),d=1.+p.y,C(z,V(z,z,1.2),7.5,6.),s=p.x&lt;z?p.x=-p.x,z:H(z),s+=H(1.);O=vec4(V(exp(-i/(s&gt;d?1e2:9.))),1);}
</code></pre>

<p>Here I got cocky and thought I could manage to fit it in 512 chars. I failed,
by 90 characters. I did use the <a href="https://iquilezles.org/articles/smin/">smoothmin</a> operator for the first time: every
limb of the body of Cutie is composed of two spheres creating a rounded cone
(two sphere of different size smoothly merged like metaballs).</p>
<figure>
  <canvas width="480" height="340" data-fragment="/frag/demo-tricks/metaballs.frag"></canvas>
  <figcaption>2 spheres merging using the smin operator</figcaption>
</figure>
<p>Then I used <a href="https://iquilezles.org/articles/simpleik/">simple IK kinetics</a> for the animation. Using leg parts
with a size of 1 helped simplifying the formula and make it shorter.</p>
<p>You may be wondering about the smooth visuals itself: I didn't use the depth
map but simply the number of iterations. Due to the nature of the raymarching
algorithm, when a ray passes close to a shape, it slows down significantly,
increasing the number of iterations. This is super useful because it exaggerate
the contour of the shapes naturally. It's wrapped into an exponential, but <code>i</code>
defines the output color directly.</p>
<h2>What's next</h2>
<p>I will continue making more of those, keeping my artistic ambition low because
of the 512 characters constraint I'm imposing on myself.</p>
<p><img src="https://blog.pkh.me/img/demo-tricks/512.jpg" alt="meme about the 512 chars limit"></p>
<p>You may be wondering why I keep this obsession about 512 characters, and many
people called me out on this one. There are actually many arguments:</p>
<ul>
<li>A tiny demo has to focus on one or two very scoped aspects of computer
graphics, which makes it perfect as a <strong>learning support</strong>.</li>
<li>It's part of the <strong>artistic performance</strong>: it's not just techniques and
visuals, the wizardry of the code is part of why it's so impressive. We're in
an era of visuals, people have been fed with the craziest VFX ever. But have
they seen them with a few hundreds bytes of code?</li>
<li>The constraint helps me <strong>finish the work</strong>: when making art, there is always
this question of when to stop. Here there is an intractable point where I just
cannot do more and I have to move on.</li>
<li>Similarly, it <strong>prevents my ambition</strong> from tricking me into some colossal
project I will never finish or even start. That format has a ton of
limitations, and that's its strength.</li>
<li>Working on such a tiny piece of code for days/weeks just <strong>brings me joy</strong>. I
do feel like a craftsperson, spending an unreasonable amount of time
perfecting it, for the beauty of it.</li>
<li>I'm trying to build a portfolio, and it's important for me to keep it
<strong>consistent</strong>. If the size limit was different, I would have done things
differently, so I can't change it now. If I had hundreds more characters,
Red Alp might have had birds, the sky opening to lit a beam of light on the
mountains, etc.</li>
</ul>
<p>Why 512 in particular? It happens to be the size of a toot on <a href="https://fosstodon.org/@bug">my Mastodon
instance</a> so I can fit the code there, and I found it to be a good
balance.</p>
</article><p>For updates and more frequent content you can follow me on
<a href="https://fosstodon.org/@bug">Mastodon</a>. Feel also free to subscribe to the
<a href="https://blog.pkh.me/rss.xml">RSS</a> in order to be notified of new write-ups. It is also usually
possible to reach me through other means (check the footer below). Finally,
discussions on some of the articles can sometimes be found on HackerNews,
Lobste.rs and Reddit.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hunting for North Korean Fiber Optic Cables (273 pts)]]></title>
            <link>https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/</link>
            <guid>46194384</guid>
            <pubDate>Mon, 08 Dec 2025 16:38:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/">https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/</a>, See on <a href="https://news.ycombinator.com/item?id=46194384">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>Before we go any further, one thing that I want to make clear is that the word <em>assume</em> is going to be doing some heavy lifting throughout this post. This was a rabbit hole that I recently went down and I probably have more questions than answers, but I still wanted to document what I had found so far. If you have additional information or findings you want to share, as always feel free to reach out: <a>contact@nkinternet.com</a>.</p>



<p>It all started with a PowerPoint that I came across a few weeks ago. It was presented by the DPRK to the ICAO on the state of their aviation industry and their ADS-B deployment inside North Korea. However, one slide in particular caught my eye because it showed a fiber optic cable running across the country</p>



<figure><a href="https://nkinternet.com/wp-content/uploads/2025/12/d3e27ea5-25f1-49ed-9392-e38cb466b732.png"><img data-attachment-id="1012" data-permalink="https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/d3e27ea5-25f1-49ed-9392-e38cb466b732/" data-orig-file="https://nkinternet.com/wp-content/uploads/2025/12/d3e27ea5-25f1-49ed-9392-e38cb466b732.png" data-orig-size="1224,742" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="d3e27ea5-25f1-49ed-9392-e38cb466b732" data-image-description="" data-image-caption="" data-medium-file="https://nkinternet.com/wp-content/uploads/2025/12/d3e27ea5-25f1-49ed-9392-e38cb466b732.png?w=300" data-large-file="https://nkinternet.com/wp-content/uploads/2025/12/d3e27ea5-25f1-49ed-9392-e38cb466b732.png?w=676" width="1024" height="620" src="https://nkinternet.com/wp-content/uploads/2025/12/d3e27ea5-25f1-49ed-9392-e38cb466b732.png?w=1024" alt="" srcset="https://nkinternet.com/wp-content/uploads/2025/12/d3e27ea5-25f1-49ed-9392-e38cb466b732.png?w=1024 1024w, https://nkinternet.com/wp-content/uploads/2025/12/d3e27ea5-25f1-49ed-9392-e38cb466b732.png?w=150 150w, https://nkinternet.com/wp-content/uploads/2025/12/d3e27ea5-25f1-49ed-9392-e38cb466b732.png?w=300 300w, https://nkinternet.com/wp-content/uploads/2025/12/d3e27ea5-25f1-49ed-9392-e38cb466b732.png?w=768 768w, https://nkinternet.com/wp-content/uploads/2025/12/d3e27ea5-25f1-49ed-9392-e38cb466b732.png 1224w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption><em>You can find a full link to the presentation <a href="https://nkinternet.com/wp-content/uploads/2025/11/gacadprk-presentation2019.4.pdf">here</a></em>.</figcaption></figure>



<p>This got me wondering more about the physical layout of the network inside North Korea. From the map we know that there’s a connection between Pyongyang and Odaejin, although given the mountains in the middle of the country it probably isn’t a direct link. There isn’t a lot of information on fiber in North Korea, but there are a few outside sources that help provide clues about how things might be laid out.</p>



<p><strong>Historic Fiber Information</strong></p>



<p><a href="https://www.38north.org/2017/10/mwilliams100117/">38North</a> first reported the connection from Russia’s TTK to the DPRK over the Korea–Russia Friendship Bridge back in 2017. Additionally, a picture found on Flickr looking toward Tumangang after the bridge doesn’t show any utility poles and instead seems to display some kind of infrastructure in the grass to the side of the tracks. Assuming this interpretation is correct, the fiber is likely buried underground as it enters the country and passes through the vicinity of Tumangang Station.</p>



<figure><a href="https://nkinternet.com/wp-content/uploads/2025/12/image.png"><img data-attachment-id="1015" data-permalink="https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/image-18/" data-orig-file="https://nkinternet.com/wp-content/uploads/2025/12/image.png" data-orig-size="1507,947" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://nkinternet.com/wp-content/uploads/2025/12/image.png?w=300" data-large-file="https://nkinternet.com/wp-content/uploads/2025/12/image.png?w=676" width="1024" height="643" src="https://nkinternet.com/wp-content/uploads/2025/12/image.png?w=1024" alt="" srcset="https://nkinternet.com/wp-content/uploads/2025/12/image.png?w=1024 1024w, https://nkinternet.com/wp-content/uploads/2025/12/image.png?w=150 150w, https://nkinternet.com/wp-content/uploads/2025/12/image.png?w=300 300w, https://nkinternet.com/wp-content/uploads/2025/12/image.png?w=768 768w, https://nkinternet.com/wp-content/uploads/2025/12/image.png?w=1440 1440w, https://nkinternet.com/wp-content/uploads/2025/12/image.png 1507w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption><em>From user Moravius on Flickr</em> <em>which appears to show possible infrastructure in the grass. The white pole on the right side of the tracks are used as distance markers.</em></figcaption></figure>



<p>According to a report from <a href="https://www.nautilus.org/wp-content/uploads/2011/12/DPRK_Digital_Transformation.pdf">The Nautilus Institute</a> we can gather a few additional details about the internet inside North Korea</p>



<ul>
<li>One of the first lines was installed in September 1995 between Pyongyang and Hamhung</li>



<li>In February 1998 a link between Pyongyang and Sinuiju was completed</li>



<li>As of 2000, DPRK’s operational optical fiber telecom lines included: Pyongyang – Hamhung; Pyongyang – Sinuiju including all cities and counties in North Pyongan Province; Hamhung Rajin-Sonbong; Rajin-Songbong – Hunchun (China), Pyongyang – Nampo.</li>



<li>In 2003 the original domestic cell phone network was built for North Korean citizens in Pyongyang, Namp’o, reportedly in all provincial capitals, on the Pyongyang-Myohyangsan tourist highway, and the Pyongyang-Kaesong and Wonsan-Hamhung highways</li>



<li>The Kwangmyong network’s data is transmitted via fiber optic cable with a backbone capacity of 2.5 GB per second between all the provinces.</li>
</ul>



<p>Based on these notes, it starts to paint a picture that the fiber link coming from Russia likely travels down the east coast of the DPRK before connecting to Pyongyang. Several city pairs—Pyongyang–Hamhung and Rajin–Sonbong—line up with earlier deployments of east-coast fiber infrastructure.</p>



<p><strong>Kwangmyong Internal Topology</strong></p>



<p>The report also notes that all of the provinces in North Korea were connected to the Kwangmyong via fiber. The Kwangmyong for those not familiar is the intranet that most citizens in the DPRK can access as they do not have access to the outside internet. While not much information is available about the Kwangmyong, these <a href="https://www.koreaittimes.com/news/articleView.html?idxno=57500">notes</a> from Choi Sung, Professor of Computer Science at Namseoul University provides some additional details on how the network is laid how, as well as information on the regional networks that are connected. A map provided in his notes shows some of the main points of the Kwangmyong with three of them located along the northeast of North Korea.</p>



<figure><a href="https://nkinternet.com/wp-content/uploads/2025/12/57500_23201_1225.jpg"><img data-attachment-id="1020" data-permalink="https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/57500_23201_1225/" data-orig-file="https://nkinternet.com/wp-content/uploads/2025/12/57500_23201_1225.jpg" data-orig-size="600,494" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="57500_23201_1225" data-image-description="" data-image-caption="" data-medium-file="https://nkinternet.com/wp-content/uploads/2025/12/57500_23201_1225.jpg?w=300" data-large-file="https://nkinternet.com/wp-content/uploads/2025/12/57500_23201_1225.jpg?w=600" width="600" height="494" src="https://nkinternet.com/wp-content/uploads/2025/12/57500_23201_1225.jpg?w=600" alt="" srcset="https://nkinternet.com/wp-content/uploads/2025/12/57500_23201_1225.jpg 600w, https://nkinternet.com/wp-content/uploads/2025/12/57500_23201_1225.jpg?w=150 150w, https://nkinternet.com/wp-content/uploads/2025/12/57500_23201_1225.jpg?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"></a></figure>



<p><strong>Railways, Roads, and Practical Fiber Routing</strong></p>



<p>This starts to paint a rough picture of how the network is physically deployed in North Korea but we can also look to some outside sources to get some confirmation. <a href="https://www.38north.org/wp-content/uploads/2022/11/02_38-North_North-Korean-Cell-Coverage-Map.png">38North </a>once again provides some great detail on cell phone towers in North Korea. The interesting thing being an apparent line down the east coast which follows major roads and highways but would also in theory have easier access to the fiber back haul to support the cell network.</p>



<figure><a href="https://nkinternet.com/wp-content/uploads/2025/12/02_38-north_north-korean-cell-coverage-map.png"><img data-attachment-id="1022" data-permalink="https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/02_38-north_north-korean-cell-coverage-map/" data-orig-file="https://nkinternet.com/wp-content/uploads/2025/12/02_38-north_north-korean-cell-coverage-map.png" data-orig-size="3319,3305" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="02_38-North_North-Korean-Cell-Coverage-Map" data-image-description="" data-image-caption="" data-medium-file="https://nkinternet.com/wp-content/uploads/2025/12/02_38-north_north-korean-cell-coverage-map.png?w=300" data-large-file="https://nkinternet.com/wp-content/uploads/2025/12/02_38-north_north-korean-cell-coverage-map.png?w=676" loading="lazy" width="1024" height="1019" src="https://nkinternet.com/wp-content/uploads/2025/12/02_38-north_north-korean-cell-coverage-map.png?w=1024" alt="" srcset="https://nkinternet.com/wp-content/uploads/2025/12/02_38-north_north-korean-cell-coverage-map.png?w=1024 1024w, https://nkinternet.com/wp-content/uploads/2025/12/02_38-north_north-korean-cell-coverage-map.png?w=2048 2048w, https://nkinternet.com/wp-content/uploads/2025/12/02_38-north_north-korean-cell-coverage-map.png?w=150 150w, https://nkinternet.com/wp-content/uploads/2025/12/02_38-north_north-korean-cell-coverage-map.png?w=300 300w, https://nkinternet.com/wp-content/uploads/2025/12/02_38-north_north-korean-cell-coverage-map.png?w=768 768w, https://nkinternet.com/wp-content/uploads/2025/12/02_38-north_north-korean-cell-coverage-map.png?w=1440 1440w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>All of this seems to suggest that the fiber lines were run along major roads and railways up the east coast. A map from Beyond Parallel shows the major rail lines, which has the Pyongra line up the east coast.</p>



<figure><a href="https://nkinternet.com/wp-content/uploads/2025/12/railway-map_crossings_update_map-e1543948581630.jpg"><img data-attachment-id="1024" data-permalink="https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/railway-map_crossings_update_map-e1543948581630/" data-orig-file="https://nkinternet.com/wp-content/uploads/2025/12/railway-map_crossings_update_map-e1543948581630.jpg" data-orig-size="1000,716" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Railway-Map_crossings_update_map-e1543948581630" data-image-description="" data-image-caption="" data-medium-file="https://nkinternet.com/wp-content/uploads/2025/12/railway-map_crossings_update_map-e1543948581630.jpg?w=300" data-large-file="https://nkinternet.com/wp-content/uploads/2025/12/railway-map_crossings_update_map-e1543948581630.jpg?w=676" loading="lazy" width="1000" height="716" src="https://nkinternet.com/wp-content/uploads/2025/12/railway-map_crossings_update_map-e1543948581630.jpg?w=1000" alt="" srcset="https://nkinternet.com/wp-content/uploads/2025/12/railway-map_crossings_update_map-e1543948581630.jpg 1000w, https://nkinternet.com/wp-content/uploads/2025/12/railway-map_crossings_update_map-e1543948581630.jpg?w=150 150w, https://nkinternet.com/wp-content/uploads/2025/12/railway-map_crossings_update_map-e1543948581630.jpg?w=300 300w, https://nkinternet.com/wp-content/uploads/2025/12/railway-map_crossings_update_map-e1543948581630.jpg?w=768 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a></figure>



<p><strong>Looking For Clues Along the Railway</strong></p>



<p>Some additional digging for pictures from along the line suggest that there is infrastructure deployed along the tracks, although it’s difficult to confirm from pictures exactly what is buried. The following shows what appears to be a junction box at the base of a pole along the line.</p>



<figure><a href="https://www.flickr.com/photos/josephferris76/6993153876/"><img data-attachment-id="1026" data-permalink="https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/image-19/" data-orig-file="https://nkinternet.com/wp-content/uploads/2025/12/image-1.png" data-orig-size="600,443" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://nkinternet.com/wp-content/uploads/2025/12/image-1.png?w=300" data-large-file="https://nkinternet.com/wp-content/uploads/2025/12/image-1.png?w=600" loading="lazy" width="600" height="443" src="https://nkinternet.com/wp-content/uploads/2025/12/image-1.png?w=600" alt="" srcset="https://nkinternet.com/wp-content/uploads/2025/12/image-1.png 600w, https://nkinternet.com/wp-content/uploads/2025/12/image-1.png?w=150 150w, https://nkinternet.com/wp-content/uploads/2025/12/image-1.png?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"></a><figcaption><em>Picture from Flickr user josephferris</em></figcaption></figure>



<p>The line does have a path along it as well with mile markers. While it is used by bikes and pedestrians, it provides a nice path for supporting fiber and other communications runs along the tracks.</p>



<figure><a href="https://www.flickr.com/photos/21005841@N04/15644749122/in/album-72157648984981562"><img data-attachment-id="1028" data-permalink="https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/image-20/" data-orig-file="https://nkinternet.com/wp-content/uploads/2025/12/image-2.png" data-orig-size="835,820" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://nkinternet.com/wp-content/uploads/2025/12/image-2.png?w=300" data-large-file="https://nkinternet.com/wp-content/uploads/2025/12/image-2.png?w=676" loading="lazy" width="835" height="820" src="https://nkinternet.com/wp-content/uploads/2025/12/image-2.png?w=835" alt="" srcset="https://nkinternet.com/wp-content/uploads/2025/12/image-2.png 835w, https://nkinternet.com/wp-content/uploads/2025/12/image-2.png?w=150 150w, https://nkinternet.com/wp-content/uploads/2025/12/image-2.png?w=300 300w, https://nkinternet.com/wp-content/uploads/2025/12/image-2.png?w=768 768w" sizes="(max-width: 835px) 100vw, 835px"></a><figcaption><em>Picture from Flickr user Andrew M. showing paths along the line.</em></figcaption></figure>



<p>The Pyongra line also crosses through the mountains at points but it is assumed at certain junctions the fiber was laid along the AH 6/National Highway 7 up the coast as there are parts of the line discovered that do not have a path along the tracks. In these places it is assumed they follow the road, although finding pictures of the highway to further examine is challenging.</p>



<figure><a href="https://nkinternet.com/wp-content/uploads/2025/12/image-6.png"><img data-attachment-id="1037" data-permalink="https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/image-24/" data-orig-file="https://nkinternet.com/wp-content/uploads/2025/12/image-6.png" data-orig-size="1321,1049" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://nkinternet.com/wp-content/uploads/2025/12/image-6.png?w=300" data-large-file="https://nkinternet.com/wp-content/uploads/2025/12/image-6.png?w=676" loading="lazy" width="1024" height="813" src="https://nkinternet.com/wp-content/uploads/2025/12/image-6.png?w=1024" alt="" srcset="https://nkinternet.com/wp-content/uploads/2025/12/image-6.png?w=1024 1024w, https://nkinternet.com/wp-content/uploads/2025/12/image-6.png?w=150 150w, https://nkinternet.com/wp-content/uploads/2025/12/image-6.png?w=300 300w, https://nkinternet.com/wp-content/uploads/2025/12/image-6.png?w=768 768w, https://nkinternet.com/wp-content/uploads/2025/12/image-6.png 1321w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption><em>Pyongra line through the mountains. At these points it’s assumed that the fiber optic cables are laid along roads/highways instead of the right of way along the railroad.</em></figcaption></figure>



<p>Lastly at certain stations we can see utility boxes along the side of the track suggesting buried conduits/cables are laid along the tracks.</p>



<figure><a href="https://www.flickr.com/photos/mytripsmypics/26020131208/in/gallery-194433501@N07-72157720168302177/"><img data-attachment-id="1030" data-permalink="https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/image-21/" data-orig-file="https://nkinternet.com/wp-content/uploads/2025/12/image-3.png" data-orig-size="360,304" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://nkinternet.com/wp-content/uploads/2025/12/image-3.png?w=300" data-large-file="https://nkinternet.com/wp-content/uploads/2025/12/image-3.png?w=360" loading="lazy" width="360" height="304" src="https://nkinternet.com/wp-content/uploads/2025/12/image-3.png?w=360" alt="" srcset="https://nkinternet.com/wp-content/uploads/2025/12/image-3.png 360w, https://nkinternet.com/wp-content/uploads/2025/12/image-3.png?w=150 150w, https://nkinternet.com/wp-content/uploads/2025/12/image-3.png?w=300 300w" sizes="(max-width: 360px) 100vw, 360px"></a></figure>



<p>From a video taken in 2012 there does appear to be some signs of objects along the tracks, although difficult to confirm due to the video quality. The screenshot below is the clearest I could find of a rectangular box buried in a clearing along the line.</p>



<figure><a href="https://www.flickr.com/photos/21005841@N04/15599502031/in/pool-dprk_rail/"><img data-attachment-id="1032" data-permalink="https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/image-22/" data-orig-file="https://nkinternet.com/wp-content/uploads/2025/12/image-4.png" data-orig-size="997,609" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://nkinternet.com/wp-content/uploads/2025/12/image-4.png?w=300" data-large-file="https://nkinternet.com/wp-content/uploads/2025/12/image-4.png?w=676" loading="lazy" width="997" height="609" src="https://nkinternet.com/wp-content/uploads/2025/12/image-4.png?w=997" alt="" srcset="https://nkinternet.com/wp-content/uploads/2025/12/image-4.png 997w, https://nkinternet.com/wp-content/uploads/2025/12/image-4.png?w=150 150w, https://nkinternet.com/wp-content/uploads/2025/12/image-4.png?w=300 300w, https://nkinternet.com/wp-content/uploads/2025/12/image-4.png?w=768 768w" sizes="(max-width: 997px) 100vw, 997px"></a><figcaption><em>From Flickr user Andrew M. Screenshot is from ~21 seconds in the linked video</em></figcaption></figure>



<p>Based on this information of what is confirmed and looking at major cities, it appears there is a route that follows Pyongyang → Wonsan → Hamhung → Chongjin → Rajin → Tumangang which follows the Pyongra line as well as the AH 6/National Highway 7 up the coast. The following map highlights a rough path.</p>



<figure><a href="https://nkinternet.com/wp-content/uploads/2025/12/image-5.png"><img data-attachment-id="1035" data-permalink="https://nkinternet.com/2025/12/08/hunting-for-north-korean-fiber-optic-cables/image-23/" data-orig-file="https://nkinternet.com/wp-content/uploads/2025/12/image-5.png" data-orig-size="1524,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://nkinternet.com/wp-content/uploads/2025/12/image-5.png?w=300" data-large-file="https://nkinternet.com/wp-content/uploads/2025/12/image-5.png?w=676" loading="lazy" width="1024" height="725" src="https://nkinternet.com/wp-content/uploads/2025/12/image-5.png?w=1024" alt="" srcset="https://nkinternet.com/wp-content/uploads/2025/12/image-5.png?w=1024 1024w, https://nkinternet.com/wp-content/uploads/2025/12/image-5.png?w=150 150w, https://nkinternet.com/wp-content/uploads/2025/12/image-5.png?w=300 300w, https://nkinternet.com/wp-content/uploads/2025/12/image-5.png?w=768 768w, https://nkinternet.com/wp-content/uploads/2025/12/image-5.png?w=1440 1440w, https://nkinternet.com/wp-content/uploads/2025/12/image-5.png 1524w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Interestingly by mapping out the possible fiber locations we can start to draw conclusions based on other sources. According to a video by <a href="https://www.youtube.com/watch?v=AcjXPae3Mhw">Cappy’s Army</a> he proposes that when the US Navy Seals landed in NOrth Korea in 2019 the most likely place this would have occurred is Sinpo. As the goal was to depoy a covert listening device this could also line up with supporting the idea that a fiber backbone runs down the east coast of North Korea as Sinpo would be relatively close. </p>



<p><strong>What Does This Mean For the Network?</strong></p>



<p>In addition to the fiber link via Russia, the other fiber optic cable into North Korea comes in via China by way of Sinuiju and Dandong. Although we don’t know for sure where servers are deployed inside North Korea, based on the map of Kwangmyong the first assumption is that things are mainly centralized in Pyongyang.</p>



<p>Out of the 1,024 IPs assigned to North Korea we observe the following behavior based on the CIDR block:</p>



<ul>
<li>175.45.176.0/24 is exclusively routed via China Unicom</li>



<li>175.45.177.0/24 is exclusively routed via Russia TransTelekom</li>



<li>175.45.178.0/24 is dual-homed and can take either path before crossing into North Korea</li>
</ul>



<p>With this information in mind, running a traceroute with the TCP flag set gives us a slightly better look at how traffic behaves once it reaches the country. For the following tests we’re going to assume there is a fiber path on the west coming in from China toward Pyongyang, as well as a path on the east side coming from Russia.</p>



<p>From the US east coast to 175.45.176.71, the final hop in China before entering North Korea shows roughly 50 ms of additional latency before reaching the DPRK host. This suggests there may be extra devices, distance, or internal routing inside the country before the packet reaches its final destination.</p>



<pre>10 103.35.255.254 (103.35.255.254) 234.306 ms 234.082 ms 234.329 ms<br>11 * * * <br>12 * * * <br>13 * * * <br>14 175.45.176.71 (175.45.176.71) 296.081 ms 294.795 ms 294.605 ms <br>15 175.45.176.71 (175.45.176.71) 282.938 ms 284.446 ms 282.227 ms</pre>



<p>Interestingly, running a traceroute to 175.45.177.10 shows a similar pattern in terms of missing hops, but with much lower internal latency. In fact, the ~4 ms difference between the last Russian router and the DPRK host suggests the handoff between Russia and North Korea happens very close—network-wise—to where this device is located. This contrasts with the China path, which appears to take a longer or more complex route before reaching its final destination.</p>



<pre>10	188.43.225.153	185.192 ms	183.649 ms	189.089 ms<br>11	 * 	 * 		 <br>12	 * 	 * 		 <br>13	 * 	 * 		 <br>14	175.45.177.10	195.996 ms	186.801 ms	186.353 ms<br>15	175.45.177.10	188.886 ms	201.103 ms	193.334 </pre>



<p>If everything is centralized in Pyongyang this would mean the handoff from Russia is completed in Pyongyang as well. However, it could also indicate that 175.45.177.0/24 is not hosted in Pyongyang at all and is instead located closer to the Russia–North Korea border. More testing is definitely required however before any conclusions can be drawn about where these devices physically reside.</p>



<p><strong>What can we learn from all of this? </strong></p>



<p>Making some assumptions we can get a better idea of how the internet works and is laid out inside North Korea. While not much is officially confirmed using some other sources we can get a possible idea of how things work. As mentioned at the start, the word assume does a lot of heavy lifting. However if you do have other information or ideas feel free to reach out at contact@nkinternet.com</p>





<div>
	
	<hr>
	

	
	<h3>Discover more from North Korean Internet</h3>
	

	
	<p>Subscribe to get the latest posts sent to your email.</p>
	

	
	
	
</div>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Let's put Tailscale on a jailbroken Kindle (305 pts)]]></title>
            <link>https://tailscale.com/blog/tailscale-jailbroken-kindle</link>
            <guid>46194337</guid>
            <pubDate>Mon, 08 Dec 2025 16:34:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tailscale.com/blog/tailscale-jailbroken-kindle">https://tailscale.com/blog/tailscale-jailbroken-kindle</a>, See on <a href="https://news.ycombinator.com/item?id=46194337">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>“It’s a rite of passage to run Tailscale on weird devices.”</p><p>So writes Mitanshu Sukhwani <a target="" rel="noreferrer" href="https://blog.papermatch.me/html/Tailscale_on_Kindle">on his blog</a>, detailing the steps for getting Tailscale onto a <a target="" rel="noreferrer" href="https://kindlemodding.org/">jailbroken Kindle</a>. Getting there, and seeing a kindle entry with a satisfying green dot in your <a target="" rel="noreferrer" href="https://login.tailscale.com/start/?utm_source=blog&amp;utm_medium=content&amp;utm_campaign=jailbreak-kindle">Tailscale admin console</a>, takes some doing. But take the trip, and you’ll end up with an e-reader that can run some neat unofficial apps, and is more open to third-party and DRM-free ebooks. And with a Tailscale connection, it’s easier to connect to files and a command line on your underpowered little Linux slab.</p><p>“For me, it's the freedom of being able to do anything with the device I own,” Sukhwani writes by email. “What I can do with the freedom is a different story.”</p><figure id=""><img _type="asset" video="[object Object]" alt="Close-up of a Kindle, with a Tailscale logo across its screen, and quote from Fredric Jameson on top: &quot;If everything means something else, then so does technology.&quot;" loading="lazy" width="1000" height="750" decoding="async" data-nimg="1" srcset="https://cdn.sanity.io/images/w77i7m8x/production/7bbe7afbd47ed73302e8e97c51311c31406e10d5-1000x750.png?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1x, https://cdn.sanity.io/images/w77i7m8x/production/7bbe7afbd47ed73302e8e97c51311c31406e10d5-1000x750.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2x" src="https://cdn.sanity.io/images/w77i7m8x/production/7bbe7afbd47ed73302e8e97c51311c31406e10d5-1000x750.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format"><figcaption>A jailbroken Kindle allows you to set a custom screensaver inside KOReader—even transparent, if you like. Corporate logos are optional.</figcaption></figure><h2 id="what-is-a-jailbroken-kindle-exactly"><a href="#what-is-a-jailbroken-kindle-exactly">What is a jailbroken Kindle, exactly?<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2><p><a target="" rel="noreferrer" href="https://en.wikipedia.org/wiki/Privilege_escalation#Jailbreaking">Jailbreaking</a> refers to removing the software restrictions on a device put there by its maker. Getting around these restrictions, typically by gaining “root” or administrative access, allows for accessing operating system internals, running unapproved software, and generally doing more things than a manufacturer intended. With the Kindle, you still get the standard Kindle reading experience, including Amazon's store and the ability to send the Kindle books from apps like Libby. You just add many more options, too.</p><p>The term gained purchase after the first iPhone’s debut in mid-2007; since then, nearly every device with a restricted environment has gained its own jailbreaking scene, including Kindles (debuting five months after the iPhone).</p><p>Kindle jailbreaks come along every so often. Right now, an unlocking scheme based on Amazon’s own lockscreen ads, “<a target="" rel="noreferrer" href="https://kindlemodding.org/jailbreaking/AdBreak/">AdBreak</a>,” is available for all but the most up-to-date Kindles (earlier than firmware version 5.18.5.0.2). I know this because I wrote this paragraph and the next on my 11th-generation Kindle, using the open-source Textadept editor, a <a target="" rel="noreferrer" href="https://www.mobileread.com/forums/showthread.php?t=369712&amp;highlight=bluetooth+keyboard">Bluetooth keyboard</a>, and <a target="" rel="noreferrer" href="https://login.tailscale.com/start/?utm_source=blog&amp;utm_medium=content&amp;utm_campaign=jailbreak-kindle">Tailscale</a> to move this draft file around.</p><p>One paragraph doesn’t seem that impressive until you consider that on a standard Kindle, you cannot do any of that. Transferring files by SSH, or Taildrop, is certainly not allowed. And that’s in addition to other upgrades you can get by jailbreaking a Kindle, including the feature-rich, customizable e-reader <a target="" rel="noreferrer" href="https://github.com/koreader/koreader">KOReader</a>, and lots of little apps available in repositories like <a target="" rel="noreferrer" href="https://github.com/KindleTweaks/KindleForge">KindleForge</a>.</p><p>If your Kindle has been connected to Wi-Fi all this time (as of early December 2025), it may have automatically updated itself and no longer be ready for jailbreaking. If you think it still has a chance, immediately put it into airplane mode and follow along.</p><p>Obligatory notice here: You’re running a risk of bricking your device (having it become unresponsive and unrecoverable) and voiding your warranty when you do this. That having been noted, let's dig further.</p><figure id=""><img _type="asset" video="[object Object]" alt="Close-up of a Kindle screen, showing the &quot;/Tailscale&quot; menu in large buttons: &quot;Start Tailscaled,&quot; &quot;Start Tailscale,&quot; &quot;Stop Tailscaled,&quot; &quot;Stop Tailscale,&quot; &quot;Receive Taildrop Files,&quot; and &quot;/&quot; (which is end or &quot;go back&quot;)." loading="lazy" width="1000" height="1000" decoding="async" data-nimg="1" srcset="https://cdn.sanity.io/images/w77i7m8x/production/34241c0f5bf6796f4d1da3189858d70826a4e01a-1000x1000.png?w=1080&amp;q=75&amp;fit=clip&amp;auto=format 1x, https://cdn.sanity.io/images/w77i7m8x/production/34241c0f5bf6796f4d1da3189858d70826a4e01a-1000x1000.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format 2x" src="https://cdn.sanity.io/images/w77i7m8x/production/34241c0f5bf6796f4d1da3189858d70826a4e01a-1000x1000.png?w=2048&amp;q=75&amp;fit=clip&amp;auto=format"><figcaption>It's not exactly a Liquid Glass interface, but it enables some neat tricks.</figcaption></figure><h2 id="what-tailscale-adds-to-a-jailbroken-kindle"><a href="#what-tailscale-adds-to-a-jailbroken-kindle">What Tailscale adds to a jailbroken Kindle<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2><p>Tailscale isn’t necessary on a jailbroken Kindle, but it really helps. Here are some of the ways Tailscale makes messing about with an opened-up Kindle more fun:</p><ul><li>A persistent IP address (<a target="" rel="noreferrer" href="http://100.xx/">100.xx</a>.yyy.zzz), just like any other Tailscale device, instead of having to remember yet another 192.168.random.number</li><li>Easier SSH access with <a target="" rel="noreferrer" href="https://tailscale.com/kb/1081/magicdns/?utm_source=blog&amp;utm_medium=content&amp;utm_campaign=jailbreak-kindle">magicDNS</a>: ssh root@kindle and you’re in</li><li><a target="" rel="noreferrer" href="https://tailscale.com/kb/1106/taildrop/?utm_source=blog&amp;utm_medium=content&amp;utm_campaign=jailbreak-kindle">Taildrop</a> for sending files to whatever Kindle directory you want</li><li>Setting up a self-hosted Calibre Web library with Tailscale, then securely grabbing books from it anywhere with KOReader.</li></ul><p>Key to the Kindle-plus-Tailscale experience is an easier way (SSH and Taildrop) to get epub, mobi, and other e-book and document formats into the /documents folder, ready for your KOReader sessions. Tailscale also helps with setting up some of the key jailbreak apps, saving you from plugging and unplugging the Kindle into a computer via USB cord (and then finding a second USB cord, because the first one never works, for some reason).</p><h2 id="getting-your-kindle-ready"><a href="#getting-your-kindle-ready">Getting your Kindle ready<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2><p>What follows is by no means a comprehensive guide to jailbreaking and accessing your Kindle. You will want to read the documentation for each tool and app closely. Pay particular attention to which Kindle you have, which version number of the Kindle firmware it’s running, and how much space you have left on that device.</p><p>The first step is to check your Kindle’s version number (Settings &gt; Device info) and see if there is a jailbreak method available for it. The Kindle Modding Wiki is the jailbreaking community’s go-to resource. As of this writing, there is a “WinterBreak” process available for Kindles running firmware below 15.18.1, and AdBreak is available for firmwares from 15.18.1 through 5.18.5.0.1.</p><p>If your Kindle’s version number fits one of those ranges, put it in Airplane mode and move on. If not, you’re going to have to wait until the next jailbreak method comes along.</p><figure id=""><div><p><iframe width="100%" height="100%" src="https://www.youtube.com/embed/l4ZliC82RtA?si=fWOkN9Cnf40TozhW" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p></div><figcaption>Dammit Jeff's video on the latest (as of late October) jailbreak provides both a good overview and detailed tips on setting up a jailbroken Kindle.</figcaption></figure><h2 id="the-actual-jailbreaking-part"><a href="#the-actual-jailbreaking-part">The actual jailbreaking part<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2><p>Before you dive in, have a computer (PC, Mac, or Linux) and USB cable that works with your Kindle handy. Have your Kindle on reliable Wi-Fi, like your home network—but don’t take your Kindle off airplane mode if you’ve been keeping it that way.</p><ul><li><a target="" rel="noreferrer" href="https://kindlemodding.org/jailbreaking/index.html">Follow these steps to jailbreak your Kindle</a>. The techniques are different, but you may need to do some other tasks, like enable advertisements, or <a target="" rel="noreferrer" href="https://kindlemodding.org/jailbreaking/prevent-auto-update/">fill your Kindle with junk files</a> to prevent automatic updates midway through the process.</li><li><a target="" rel="noreferrer" href="https://kindlemodding.org/jailbreaking/post-jailbreak/setting-up-a-hotfix/">Install a hotfix</a> and <a target="" rel="noreferrer" href="https://kindlemodding.org/jailbreaking/post-jailbreak/disable-ota.html">disable over-the-air updates</a> so that you can keep your Kindle on Wi-Fi and not have its jailbreak undone</li><li><a target="" rel="noreferrer" href="https://kindlemodding.org/jailbreaking/post-jailbreak/installing-kual-mrpi/">Install</a> the Kindle Unified Application Launcher (KUAL) and MRPI (MobileRead Package Installer). KUAL is vital to installing most jailbroken apps, including Tailscale.</li><li>You will almost certainly want to <a target="" rel="noreferrer" href="https://kindlemodding.org/jailbreaking/post-jailbreak/koreader.html">install KOReader</a>, too.</li></ul><p>Those bits above are standard jailbreaking procedures. If you want Tailscale on your Kindle, you’ll go a bit further.</p><h2 id="adding-tailscale-to-a-jailbroken-kindle"><a href="#adding-tailscale-to-a-jailbroken-kindle">Adding Tailscale to a jailbroken Kindle<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2><p>Make sure you have KUAL and MRPI installed and working. Next up: install this <a target="" rel="noreferrer" href="https://github.com/notmarek/kindle-usbnetlite">“simple” version of USBNetworking for Kindle</a><strong>.</strong></p><p>Before you go further, you’ll want to choose between <a target="" rel="noreferrer" href="https://github.com/mitanshu7/tailscale_kual">Mitanshu’s “standard” Tailscale repository</a>, or the fork of it that <a target="" rel="noreferrer" href="https://github.com/jonaolden/tailscale_kual">enables Taildrop</a>. I recommend the Taildrop-enabled fork; if it goes wrong, or stops being updated, it’s fairly easy (relative to doing this kind of project) to wipe it and go back to Mitanshu’s “vanilla” version.Either way, you’ll want to get USB access to your Kindle for this next part. If you toggled on USBNetworking to try it out, toggle it off; you can’t get USB access while it’s running, as its name somewhat implies.</p><ol><li>Download the Tailscale/KUAL repository of your choice using git clone or download a ZIP from the <strong>Code </strong>button on GitHub</li><li>Head to Tailscale’s page of static Linux binaries and grab the latest arm (not arm64) release</li><li>Copy the tailscale and tailscaled binaries from the Tailscale download and place them into the /extensions/tailscale/bin directory of the KUAL/Kindle repository you’ll be copying over</li><li>Head to your Tailscale admin console and <a target="" rel="noreferrer" href="https://login.tailscale.com/admin/settings/keys">generate an authentication key</a>. Name it something like kindle; you’ll want to enable the “Reusable” and “Pre-approved” options. Copy the key that is generated.</li><li>Open the file extensions/tailscale/config/auth_key.txt for editing while it is on your (non-Kindle) computer. Paste in the key text you generated.</li><li>If you’re using the variant with Taildrop, you can set a custom directory in which to deliver Taildrop files by editing extensions/tailscale/config/taildrop_dir.txt; setting /mnt/us/documents makes sense if you’re mostly sending yourself things to read in KOReader.</li><li>Head into the extensions folder on your computer and copy the tailscale folder you’ve set up into the extensions folder on your Kindle.</li></ol><p>With all that done, open up KUAL on your Kindle. Go into USBNetLite and click <strong>USBNetwork Status </strong>to ensure it is enabled (tap the <strong>Toggle</strong> button if not). Go back (with the <strong>“/”</strong> button at the bottom), tap <strong>Tailscale</strong>, and first tap <strong>Start Tailscaled</strong> (note the “d” at the end). Wait about 10 seconds to give <a target="" rel="noreferrer" href="https://tailscale.com/kb/1278/tailscaled/?utm_source=blog&amp;utm_medium=content&amp;utm_campaign=jailbreak-kindle">the Tailscaled daemon</a> time to start, then tap <strong>Start Tailscale</strong>.</p><p>If everything is settled, you should be able to see your Kindle as connected on your Tailscale admin console. Once you’ve finished smiling to yourself, click the three dots on the right-hand side of the Kindle row and select “Disable key expiry.” In most situations, you’re better off not having to patch a new key value into a Kindle text file every few months.</p><figure id=""><img _type="asset" video="[object Object]" alt="Screenshot of a sharing intent on an iPhone, titled &quot;Send via Tailscale,&quot; with a My Devices list showing &quot;Kindle&quot; and &quot;pi3b&quot; (as linux devices) with green dots, signifying availability." loading="lazy" width="1179" height="1179" decoding="async" data-nimg="1" srcset="https://cdn.sanity.io/images/w77i7m8x/production/a978381cca9548c99b5a7eedf9ec51d00fe6c8af-1179x1179.png?w=1200&amp;q=75&amp;fit=clip&amp;auto=format 1x, https://cdn.sanity.io/images/w77i7m8x/production/a978381cca9548c99b5a7eedf9ec51d00fe6c8af-1179x1179.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format 2x" src="https://cdn.sanity.io/images/w77i7m8x/production/a978381cca9548c99b5a7eedf9ec51d00fe6c8af-1179x1179.png?w=3840&amp;q=75&amp;fit=clip&amp;auto=format"><figcaption>Turn on your Kindle and send it books from any device.</figcaption></figure><h2 id="enjoy-your-slightly-less-wonky-kindle"><a href="#enjoy-your-slightly-less-wonky-kindle">Enjoy your (slightly) less wonky Kindle<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 7h3a5 5 0 0 1 5 5 5 5 0 0 1-5 5h-3m-6 0H6a5 5 0 0 1-5-5 5 5 0 0 1 5-5h3"></path><line x1="8" y1="12" x2="16" y2="12"></line></svg></a></h2><p>With Tailscale installed, it’s easier to get into your Kindle via SSH for file management and installing and configuring other apps. Getting a Bluetooth keyboard to work via the Kindle’s quirky command-line Bluetooth interface would not have been fun using a touchscreen keyboard.</p><p>Because the Kindle is on your tailnet, it can access anything else you have hosted there. Kindles set up this way can use tools like the <a target="" rel="noreferrer" href="https://github.com/mitchellurgero/kindle-shortcut-browser">Shortcut Browser</a> to become dashboards for <a target="" rel="noreferrer" href="https://tailscale.com/blog/remotely-access-home-assistant">Home Assistant</a>, or access a self-hosted <a target="" rel="noreferrer" href="https://github.com/janeczku/calibre-web">Calibre-Web</a> e-book server (with <a target="" rel="noreferrer" href="https://github.com/mitanshu7/tailscale_kual/issues/2#issuecomment-2710486540">some tweaking</a>).</p><p>Having Taildrop handy, and having it drop files directly into the documents folder, is probably my favorite upgrade. I was on my phone, at a train station, when I came across Annalee Newitz’s <a target="" rel="noreferrer" href="https://bookshop.org/p/books/automatic-noodle-annalee-newitz/625018d0518991aa"><em>Automatic Noodle</em> at </a><a target="" rel="noreferrer" href="http://bookshop.org/">Bookshop.org</a>. I bought it on my phone and downloaded the DRM-free epub file. When I got home, I opened and unlocked my Kindle, sent the epub to the Kindle via Taildrop, then tapped <strong>Receive Taildrop Files</strong> in the Tailscale app inside KUAL. Epubs, PDFs, comic book archives, DjVu files—they’re all ready to be dropped in.</p><p>If you’ve gotten Tailscale to run on weird (or just uncommon) devices, we’d more than love to hear about it. Let us know on <a target="" rel="noreferrer" href="https://www.reddit.com/r/Tailscale/">Reddit</a>, <a target="" rel="noreferrer" href="https://discord.com/invite/tailscale">Discord</a>, <a target="" rel="noreferrer" href="https://bsky.app/profile/tailscale.com">Bluesky</a>, <a target="" rel="noreferrer" href="https://hachyderm.io/@tailscale">Mastodon</a>, or <a target="" rel="noreferrer" href="https://www.linkedin.com/company/tailscale/product/">LinkedIn</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google confirms Android attacks; no fix for most Samsung users (196 pts)]]></title>
            <link>https://www.forbes.com/sites/zakdoffman/2025/12/08/google-confirms-android-attacks-no-fix-for-most-samsung-users/</link>
            <guid>46194315</guid>
            <pubDate>Mon, 08 Dec 2025 16:32:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.forbes.com/sites/zakdoffman/2025/12/08/google-confirms-android-attacks-no-fix-for-most-samsung-users/">https://www.forbes.com/sites/zakdoffman/2025/12/08/google-confirms-android-attacks-no-fix-for-most-samsung-users/</a>, See on <a href="https://news.ycombinator.com/item?id=46194315">Hacker News</a></p>
Couldn't get https://www.forbes.com/sites/zakdoffman/2025/12/08/google-confirms-android-attacks-no-fix-for-most-samsung-users/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[No more O'Reilly subscriptions for me (149 pts)]]></title>
            <link>https://zerokspot.com/weblog/2025/12/05/no-more-oreilly-subscriptions-for-me/</link>
            <guid>46194063</guid>
            <pubDate>Mon, 08 Dec 2025 16:14:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zerokspot.com/weblog/2025/12/05/no-more-oreilly-subscriptions-for-me/">https://zerokspot.com/weblog/2025/12/05/no-more-oreilly-subscriptions-for-me/</a>, See on <a href="https://news.ycombinator.com/item?id=46194063">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        <p>For the last two years I’ve had an <a href="https://www.oreilly.com/online-learning/pricing.html">O’Reilly subscription</a>. Their offer is quite attractive with unlimited access to books not only by O’Reilly but also Manning and others. The catalog is just enourmous and covers pretty much every technical book around software engineering et al. that I might ever want to read. There are also tons of other learning resources in there like conference recordings and webinars, but I’m mostly there for the books. Unfortunately, I cannot read technical books fast and definitely not fast enough to make the subscription be worth $500 per year.</p>
<p>Another problem for me is the usability of the mobile client. I mostly read books on my tablet but also like to use some spare time during commutes to make some progress on my phone. The synchronization there is extremely spotty and the app, when being evicted and reloaded by the operating system, throws me more often than not back to the start screen instead of reopening the previously open book at the right page. I also haven’t found a theme that I enjoy as much as the ones offered by Apple Books or the Kindle app and so reading hasn’t been all that enjoyable for me.</p>
<p>All of this together will most likely not make me renew my subscription for the new year. Given the price, it will be probably cheaper for me to buy only the books that I want from Kobo et al. where I can get O’Reilly books without DRM and keep them beyond any subscription limit. I also just noticed that I still have some credits left from the time I’ve had a <a href="https://zerokspot.com/weblog/2023/05/22/manning-also-has-a-subscriptions/">Manning subscription</a> 😂</p>

                        
                        

                        
                    </div><div>
                            <h2>This post was inspired by...</h2>
                            
                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AMD GPU Debugger (242 pts)]]></title>
            <link>https://thegeeko.me/blog/amd-gpu-debugging/</link>
            <guid>46193931</guid>
            <pubDate>Mon, 08 Dec 2025 16:06:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thegeeko.me/blog/amd-gpu-debugging/">https://thegeeko.me/blog/amd-gpu-debugging/</a>, See on <a href="https://news.ycombinator.com/item?id=46193931">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-gjtny2mx="">    <a href="https://thegeeko.me/" data-astro-cid-cjjlykpo=""> <svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg" data-astro-cid-cjjlykpo=""> <path d="M2.5 6.5H9.5C11.1569 6.5 12.5 7.84315 12.5 9.5V9.5C12.5 11.1569 11.1569 12.5 9.5 12.5H7.5M2.5 6.5L5.5 9.5M2.5 6.5L5.5 3.5" stroke="currentColor" stroke-width="1.25" stroke-linecap="round" stroke-linejoin="round" data-astro-cid-cjjlykpo=""></path> </svg>
index
</a>   <div id="toc"> <nav> <ul id="toc-list"> <!-- Back to top link --> <li> <a href="#" title="Back to top" data-text="Back to top">
Back to top
</a> </li> <!-- TOC items --> <li> <a href="#tbatma" title="TBA/TMA" data-text="TBA/TMA"> TBA/TMA </a> </li><li> <a href="#amdgpu-debugfs" title="AMDGPU Debugfs" data-text="AMDGPU Debugfs"> AMDGPU Debugfs </a> </li><li> <a href="#the-trap-handler" title="The Trap Handler" data-text="The Trap Handler"> The Trap Handler </a> </li><li> <a href="#spir-v" title="SPIR-V" data-text="SPIR-V"> SPIR-V </a> </li><li> <a href="#an-actual-debugger" title="An Actual Debugger" data-text="An Actual Debugger"> An Actual Debugger </a> </li><li> <a href="#breakpoints-and-stepping" title="Breakpoints and Stepping" data-text="Breakpoints and Stepping"> Breakpoints and Stepping </a> </li><li> <a href="#source-code-line-mapping" title="Source Code Line Mapping" data-text="Source Code Line Mapping"> Source Code Line Mapping </a> </li><li> <a href="#address-watching-aka-watchpoints" title="Address Watching aka Watchpoints" data-text="Address Watching aka Watchpoints"> Address Watching aka Watchpoints </a> </li><li> <a href="#variables-types-and-names" title="Variables Types and Names" data-text="Variables Types and Names"> Variables Types and Names </a> </li><li> <a href="#vulkan-integration" title="Vulkan Integration" data-text="Vulkan Integration"> Vulkan Integration </a> </li><li> <a href="#bonus-round" title="Bonus Round" data-text="Bonus Round"> Bonus Round </a> </li> </ul> </nav> </div>     <p>I’ve always wondered why we don’t have a GPU debugger similar to the one used for CPUs. A tool that allows pausing execution and examining the current state. This capability feels essential, especially since the GPU’s concurrent execution model is much harder to reason about. After searching for solutions, I came across rocgdb, a debugger for AMD’s ROCm environment. Unfortunately, its scope is limited to that environment. Still, this shows it’s technically possible. I then found a helpful <a href="https://martty.github.io/posts/radbg_part_1/">series of blog posts</a> by <a href="https://martty.github.io/about/">Marcell Kiss</a>, detailing how he achieved this, which inspired me to try to recreate the process myself.</p>
<h2 id="lets-try-to-talk-to-the-gpu-directly">Let’s Try To Talk To The GPU Directly</h2>
<p>The best place to start learning about this is <a href="https://docs.mesa3d.org/drivers/radv.html">RADV</a>. By tracing what it does, we can find how to do it. Our goal here is to run the most basic shader <code>nop 0</code> without using Vulkan, aka RADV in our case.</p>
<p>First of all, we need to open the DRM file to establish a connection with the KMD, using a simple open(“/dev/dri/cardX”), then we find that it’s calling <code>amdgpu_device_initialize</code>, which is a function defined in <code>libdrm</code>, which is a library that acts as middleware between user mode drivers(UMD) like <code>RADV</code> and and kernel mode drivers(KMD) like amdgpu driver, and then when we try to do some actual work we have to create a context which can be achieved by calling <code>amdgpu_cs_ctx_create</code> from <code>libdrm</code> again, next up we need to allocate 2 buffers one of them for our code and the other for writing our commands into, we do this by calling a couple of functions, here’s how I do it:</p>
<pre tabindex="0" data-language="c"><code><span><span>void</span><span> bo_alloc</span><span>(</span><span>amdgpu_t</span><span>*</span><span> dev</span><span>,</span><span> size_t</span><span> size</span><span>,</span><span> u32 domain</span><span>,</span><span> bool</span><span> uncached</span><span>,</span><span> amdgpubo_t</span><span>*</span><span> bo) {</span></span>
<span><span> s32    ret         </span><span>=</span><span> -</span><span>1</span><span>;</span></span>
<span><span> u32    alignment   </span><span>=</span><span> 0</span><span>;</span></span>
<span><span> u32    flags       </span><span>=</span><span> 0</span><span>;</span></span>
<span><span> size_t</span><span> actual_size </span><span>=</span><span> 0</span><span>;</span></span>
<span></span>
<span><span> amdgpu_bo_handle bo_handle </span><span>=</span><span> NULL</span><span>;</span></span>
<span><span> amdgpu_va_handle va_handle </span><span>=</span><span> NULL</span><span>;</span></span>
<span><span> u64              va_addr   </span><span>=</span><span> 0</span><span>;</span></span>
<span><span> void*</span><span>            host_addr </span><span>=</span><span> NULL</span><span>;</span></span></code></pre>
<p>Here we’re choosing the domain and assigning flags based on the params, some buffers we will need uncached, as we will see:</p>
<pre tabindex="0" data-language="c"><code><span><span> if</span><span> (</span></span>
<span><span>   domain </span><span>!=</span><span> AMDGPU_GEM_DOMAIN_GWS </span><span>&amp;&amp;</span><span> domain </span><span>!=</span><span> AMDGPU_GEM_DOMAIN_GDS </span><span>&amp;&amp;</span></span>
<span><span>   domain </span><span>!=</span><span> AMDGPU_GEM_DOMAIN_OA) {</span></span>
<span><span>  actual_size </span><span>=</span><span> (size </span><span>+</span><span> 4096</span><span> -</span><span> 1</span><span>) </span><span>&amp;</span><span> 0x</span><span>FFFFFFFFFFFFF000</span><span>ULL</span><span>;</span></span>
<span><span>  alignment   </span><span>=</span><span> 4096</span><span>;</span></span>
<span><span>  flags       </span><span>=</span><span> AMDGPU_GEM_CREATE_CPU_ACCESS_REQUIRED </span><span>|</span><span> AMDGPU_GEM_CREATE_VRAM_CLEARED </span><span>|</span></span>
<span><span>          AMDGPU_GEM_CREATE_VM_ALWAYS_VALID;</span></span>
<span><span>  flags </span><span>|=</span></span>
<span><span>    uncached </span><span>?</span><span> (domain </span><span>==</span><span> AMDGPU_GEM_DOMAIN_GTT) </span><span>*</span><span> AMDGPU_GEM_CREATE_CPU_GTT_USWC </span><span>:</span><span> 0</span><span>;</span></span>
<span><span> } </span><span>else</span><span> {</span></span>
<span><span>  actual_size </span><span>=</span><span> size;</span></span>
<span><span>  alignment   </span><span>=</span><span> 1</span><span>;</span></span>
<span><span>  flags       </span><span>=</span><span> AMDGPU_GEM_CREATE_NO_CPU_ACCESS;</span></span>
<span><span> }</span></span>
<span></span>
<span><span> struct</span><span> amdgpu_bo_alloc_request req </span><span>=</span><span> {</span></span>
<span><span>  .alloc_size     </span><span>=</span><span> actual_size</span><span>,</span></span>
<span><span>  .phys_alignment </span><span>=</span><span> alignment</span><span>,</span></span>
<span><span>  .preferred_heap </span><span>=</span><span> domain</span><span>,</span></span>
<span><span>  .flags          </span><span>=</span><span> flags</span><span>,</span></span>
<span><span> };</span></span>
<span></span>
<span><span> // memory aquired!!</span></span>
<span><span> ret </span><span>=</span><span> amdgpu_bo_alloc</span><span>(dev</span><span>-&gt;</span><span>dev_handle</span><span>,</span><span> &amp;</span><span>req</span><span>,</span><span> &amp;</span><span>bo_handle);</span></span>
<span><span> HDB_ASSERT</span><span>(</span><span>!</span><span>ret</span><span>,</span><span> "can't allocate bo"</span><span>);</span></span></code></pre>
<p>Now we have the memory, we need to map it. I opt to map anything that can be CPU-mapped for ease of use. We have to map the memory to both the GPU and the CPU virtual space. The KMD creates the page table when we open the DRM file, as shown <a href="https://elixir.bootlin.com/linux/v6.18/source/drivers/gpu/drm/amd/amdgpu/amdgpu_kms.c#L1425">here</a>.</p>
<p>So map it to the GPU VM and, if possible, to the CPU VM as well. Here, at this point, there’s a libdrm function that does all of this setup for us and maps the memory, but I found that even when specifying <code>AMDGPU_VM_MTYPE_UC</code>, it doesn’t always tag the page as uncached, not quite sure if it’s a
bug in my code or something in <code>libdrm</code> anyways, the function is <code>amdgpu_bo_va_op</code>, I opted to do it manually here and issue the IOCTL call myself:</p>
<pre tabindex="0" data-language="c"><code><span><span> u32 kms_handle </span><span>=</span><span> 0</span><span>;</span></span>
<span><span> amdgpu_bo_export</span><span>(bo_handle</span><span>,</span><span> amdgpu_bo_handle_type_kms</span><span>,</span><span> &amp;</span><span>kms_handle);</span></span>
<span></span>
<span><span> ret </span><span>=</span><span> amdgpu_va_range_alloc</span><span>(</span></span>
<span><span>   dev</span><span>-&gt;</span><span>dev_handle</span><span>,</span></span>
<span><span>   amdgpu_gpu_va_range_general</span><span>,</span></span>
<span><span>   actual_size</span><span>,</span></span>
<span><span>   4096</span><span>,</span></span>
<span><span>   0</span><span>,</span></span>
<span><span>   &amp;</span><span>va_addr</span><span>,</span></span>
<span><span>   &amp;</span><span>va_handle</span><span>,</span></span>
<span><span>   0</span><span>);</span></span>
<span><span> HDB_ASSERT</span><span>(</span><span>!</span><span>ret</span><span>,</span><span> "can't allocate VA"</span><span>);</span></span>
<span></span>
<span><span> u64 map_flags </span><span>=</span></span>
<span><span>   AMDGPU_VM_PAGE_EXECUTABLE </span><span>|</span><span> AMDGPU_VM_PAGE_READABLE </span><span>|</span><span> AMDGPU_VM_PAGE_WRITEABLE;</span></span>
<span><span> map_flags </span><span>|=</span><span> uncached </span><span>?</span><span> AMDGPU_VM_MTYPE_UC </span><span>|</span><span> AMDGPU_VM_PAGE_NOALLOC </span><span>:</span><span> 0</span><span>;</span></span>
<span></span>
<span><span> struct</span><span> drm_amdgpu_gem_va va </span><span>=</span><span> {</span></span>
<span><span>  .handle       </span><span>=</span><span> kms_handle</span><span>,</span></span>
<span><span>  .operation    </span><span>=</span><span> AMDGPU_VA_OP_MAP</span><span>,</span></span>
<span><span>  .flags        </span><span>=</span><span> map_flags</span><span>,</span></span>
<span><span>  .va_address   </span><span>=</span><span> va_addr</span><span>,</span></span>
<span><span>  .offset_in_bo </span><span>=</span><span> 0</span><span>,</span></span>
<span><span>  .map_size     </span><span>=</span><span> actual_size</span><span>,</span></span>
<span></span>
<span><span> };</span></span>
<span></span>
<span><span> ret </span><span>=</span><span> drm_ioctl_write_read</span><span>(dev</span><span>-&gt;</span><span>drm_fd</span><span>,</span><span> DRM_AMDGPU_GEM_VA</span><span>,</span><span> &amp;</span><span>va</span><span>,</span><span> sizeof</span><span>(va));</span></span>
<span><span> HDB_ASSERT</span><span>(</span><span>!</span><span>ret</span><span>,</span><span> "can't map bo in GPU space"</span><span>);</span></span>
<span><span> // ret = amdgpu_bo_va_op(bo_handle, 0, actual_size, va_addr, map_flags,</span></span>
<span><span> // AMDGPU_VA_OP_MAP);</span></span>
<span></span>
<span><span> if</span><span> (flags </span><span>&amp;</span><span> AMDGPU_GEM_CREATE_CPU_ACCESS_REQUIRED) {</span></span>
<span><span>  ret </span><span>=</span><span> amdgpu_bo_cpu_map(bo_handle</span><span>,</span><span> &amp;</span><span>host_addr)</span><span>;</span></span>
<span><span>  HDB_ASSERT(</span><span>!</span><span>ret</span><span>,</span><span> "can't map bo in CPU space"</span><span>)</span><span>;</span></span>
<span></span>
<span><span>  // AMDGPU_GEM_CREATE_VRAM_CLEARED doesn't really memset the memory to 0 anyways for</span></span>
<span><span>  // debug I'll just do it manually for now</span></span>
<span><span>  memset(host_addr</span><span>,</span><span> 0x</span><span>0</span><span>,</span><span> actual_size)</span><span>;</span></span>
<span><span> }</span></span>
<span></span>
<span><span> *</span><span>bo </span><span>=</span><span> (</span><span>amdgpubo_t</span><span>){</span></span>
<span><span>  .bo_handle </span><span>=</span><span> bo_handle</span><span>,</span></span>
<span><span>  .va_handle </span><span>=</span><span> va_handle</span><span>,</span></span>
<span><span>  .va_addr   </span><span>=</span><span> va_addr</span><span>,</span></span>
<span><span>  .size      </span><span>=</span><span> actual_size</span><span>,</span></span>
<span><span>  .host_addr </span><span>=</span><span> host_addr</span><span>,</span></span>
<span><span> };</span></span>
<span><span>}</span></span></code></pre>
<p>Now we have the context and 2 buffers. Next, fill those buffers and send our commands to the KMD, which will then forward them to the Command Processor (CP) in the GPU for processing.</p>
<p>Let’s compile our code. We can use clang assembler for that, like this:</p>
<pre tabindex="0" data-language="c"><code><span><span># https:</span><span>//gitlab.freedesktop.org/martty/radbg-poc/-/blob/master/ll-as.sh</span></span>
<span><span>clang </span><span>-</span><span>c </span><span>-</span><span>x assembler </span><span>-</span><span>target amdgcn</span><span>-</span><span>amd</span><span>-</span><span>amdhsa </span><span>-</span><span>mcpu</span><span>=</span><span>gfx1100 </span><span>-</span><span>o </span><span>asm</span><span>.o </span><span>"$1"</span></span>
<span><span>objdump </span><span>-</span><span>h </span><span>asm</span><span>.o </span><span>|</span><span> grep .text </span><span>|</span><span> awk </span><span>'{print "dd if='</span><span>asm</span><span>.o</span><span>' of='</span><span>asmc.bin</span><span>' bs=1 count=$[0x" $3 "] skip=$[0x" $6 "] status=none"}'</span><span> |</span><span> bash</span></span>
<span><span>#rm </span><span>asm</span><span>.o</span></span></code></pre>
<p>The bash script compiles the code, and then we’re only interested in the actual machine code, so we use objdump to figure out the offset and the size of the section and copy it to a new file called asmc.bin, then we can just load the file and write its bytes to the CPU-mapped address of the code buffer.</p>
<p>Next up, filling in the commands. This was extremely confusing for me because it’s not well documented.
It was mostly learning how <code>RADV</code> does things and trying to do similar things. Also, shout-out to the folks on the Graphics Programming Discord server for helping me, especially Picoduck. The commands are encoded in a special format called <code>PM4 Packets</code>, which has multiple types. We only care about <code>Type 3</code>: each packet has an opcode and the number of bytes it contains.</p>
<p>The first thing we need to do is program the GPU registers, then dispatch the shader. Some of those registers are <code>rsrc[1-3]</code>; those registers are responsible for a number of configurations, pgm_[lo/hi], which hold the pointer to the code buffer and <code>num_thread_[x/y/z]</code>; those are responsible for the number of threads inside a work group. All of those are set using the <code>set shader register</code> packets, and here is how to encode them:</p>
<p><span>It’s worth mentioning that we can set multiple registers in 1 packet if they’re consecutive.</span></p>
<pre tabindex="0" data-language="c"><code><span><span>void</span><span> pkt3_set_sh_reg</span><span>(</span><span>pkt3_packets_t</span><span>*</span><span> packets</span><span>,</span><span> u32 reg</span><span>,</span><span> u32 value) {</span></span>
<span><span> HDB_ASSERT(</span></span>
<span><span>   reg </span><span>&gt;=</span><span> SI_SH_REG_OFFSET </span><span>&amp;&amp;</span><span> reg </span><span>&lt;</span><span> SI_SH_REG_END</span><span>,</span></span>
<span><span>   "can't set register outside sh registers span"</span><span>)</span><span>;</span></span>
<span></span>
<span><span> // packet header</span></span>
<span><span> da_append(packets</span><span>,</span><span> PKT3(PKT3_SET_SH_REG</span><span>,</span><span> 1</span><span>,</span><span> 0</span><span>))</span><span>;</span></span>
<span><span> // offset of the register</span></span>
<span><span> da_append(packets</span><span>,</span><span> (reg </span><span>-</span><span> SI_SH_REG_OFFSET) </span><span>/</span><span> 4</span><span>)</span><span>;</span></span>
<span><span> da_append(packets</span><span>,</span><span> value)</span><span>;</span></span>
<span><span>}</span></span></code></pre>
<p>Then we append the dispatch command:</p>
<pre tabindex="0" data-language="c"><code><span><span>// we're going for 1 thread since we want the simplest case here.</span></span>
<span></span>
<span><span>da_append</span><span>(</span><span>&amp;</span><span>pkt3_packets</span><span>,</span><span> PKT3</span><span>(PKT3_DISPATCH_DIRECT</span><span>,</span><span> 3</span><span>,</span><span> 0</span><span>) </span><span>|</span><span> PKT3_SHADER_TYPE_S</span><span>(</span><span>1</span><span>));</span></span>
<span><span>da_append</span><span>(</span><span>&amp;</span><span>pkt3_packets</span><span>,</span><span> 1</span><span>u</span><span>);</span></span>
<span><span>da_append</span><span>(</span><span>&amp;</span><span>pkt3_packets</span><span>,</span><span> 1</span><span>u</span><span>);</span></span>
<span><span>da_append</span><span>(</span><span>&amp;</span><span>pkt3_packets</span><span>,</span><span> 1</span><span>u</span><span>);</span></span>
<span><span>da_append</span><span>(</span><span>&amp;</span><span>pkt3_packets</span><span>,</span><span> dispatch_initiator);</span></span></code></pre>
<p>Now we want to write those commands into our buffer and send them to the KMD:</p>
<pre tabindex="0" data-language="c"><code><span><span>void</span><span> dev_submit</span><span>(</span></span>
<span><span>  amdgpu_t</span><span>*</span><span>         dev</span><span>,</span></span>
<span><span>  pkt3_packets_t</span><span>*</span><span>   packets</span><span>,</span></span>
<span><span>  amdgpu_bo_handle</span><span>*</span><span> buffers</span><span>,</span></span>
<span><span>  u32               buffers_count</span><span>,</span></span>
<span><span>  amdgpu_submit_t</span><span>*</span><span>  submit</span></span>
<span><span>) {</span></span>
<span><span> s32        ret </span><span>=</span><span> -</span><span>1</span><span>;</span></span>
<span><span> amdgpubo_t</span><span> ib  </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span></span>
<span><span> bo_alloc(dev</span><span>,</span><span> pkt3_size(packets)</span><span>,</span><span> AMDGPU_GEM_DOMAIN_GTT</span><span>,</span><span> false</span><span>,</span><span> &amp;</span><span>ib)</span><span>;</span></span>
<span><span> bo_upload(</span><span>&amp;</span><span>ib</span><span>,</span><span> packets</span><span>-&gt;</span><span>data</span><span>,</span><span> pkt3_size(packets))</span><span>;</span></span>
<span></span>
<span><span> amdgpu_bo_handle</span><span>*</span><span> bo_handles </span><span>=</span><span> // +1 for the indirect buffer</span></span>
<span><span>   (amdgpu_bo_handle</span><span>*</span><span>)</span><span>malloc(</span><span>sizeof</span><span>(amdgpu_bo_handle) </span><span>*</span><span> (buffers_count </span><span>+</span><span> 1</span><span>))</span><span>;</span></span>
<span></span>
<span><span> bo_handles[</span><span>0</span><span>] </span><span>=</span><span> ib</span><span>.</span><span>bo_handle;</span></span>
<span><span> for_range(i</span><span>,</span><span> 0</span><span>,</span><span> buffers_count)</span><span> {</span></span>
<span><span>  bo_handles[i </span><span>+</span><span> 1</span><span>] </span><span>=</span><span> buffers[i];</span></span>
<span><span> }</span></span>
<span></span>
<span><span> amdgpu_bo_list_handle bo_list </span><span>=</span><span> NULL</span><span>;</span></span>
<span><span> ret </span><span>=</span></span>
<span><span>   amdgpu_bo_list_create(</span><span>dev</span><span>-&gt;</span><span>dev_handle</span><span>,</span><span> buffers_count </span><span>+</span><span> 1</span><span>,</span><span> bo_handles</span><span>,</span><span> NULL</span><span>,</span><span> &amp;</span><span>bo_list)</span><span>;</span></span>
<span><span> HDB_ASSERT(</span><span>!</span><span>ret</span><span>,</span><span> "can't create a bo list"</span><span>)</span><span>;</span></span>
<span><span> free(bo_handles)</span><span>;</span></span>
<span></span>
<span><span> struct</span><span> amdgpu_cs_ib_info ib_info </span><span>=</span><span> {</span></span>
<span><span>  .flags         </span><span>=</span><span> 0</span><span>,</span></span>
<span><span>  .ib_mc_address </span><span>=</span><span> ib</span><span>.</span><span>va_addr</span><span>,</span></span>
<span><span>  .size          </span><span>=</span><span> packets</span><span>-&gt;</span><span>count</span><span>,</span></span>
<span><span> };</span></span>
<span></span>
<span><span> struct</span><span> amdgpu_cs_request req </span><span>=</span><span> {</span></span>
<span><span>  .flags                  </span><span>=</span><span> 0</span><span>,</span></span>
<span><span>  .ip_type                </span><span>=</span><span> AMDGPU_HW_IP_COMPUTE</span><span>,</span></span>
<span><span>  .ip_instance            </span><span>=</span><span> 0</span><span>,</span></span>
<span><span>  .ring                   </span><span>=</span><span> 0</span><span>,</span></span>
<span><span>  .resources              </span><span>=</span><span> bo_list</span><span>,</span></span>
<span><span>  .number_of_dependencies </span><span>=</span><span> 0</span><span>,</span></span>
<span><span>  .dependencies           </span><span>=</span><span> NULL</span><span>,</span></span>
<span><span>  .number_of_ibs          </span><span>=</span><span> 1</span><span>,</span></span>
<span><span>  .ibs                    </span><span>=</span><span> &amp;</span><span>ib_info</span><span>,</span></span>
<span><span>  .seq_no                 </span><span>=</span><span> 0</span><span>,</span></span>
<span><span>  .fence_info             </span><span>=</span><span> { </span><span>0</span><span> }</span><span>,</span></span>
<span><span> };</span></span>
<span></span>
<span><span> ret </span><span>=</span><span> amdgpu_cs_submit(</span><span>dev</span><span>-&gt;</span><span>ctx_handle</span><span>,</span><span> 0</span><span>,</span><span> &amp;</span><span>req</span><span>,</span><span> 1</span><span>)</span><span>;</span></span>
<span><span> HDB_ASSERT(</span><span>!</span><span>ret</span><span>,</span><span> "can't submit indirect buffer request"</span><span>)</span><span>;</span></span>
<span></span>
<span><span> *</span><span>submit </span><span>=</span><span> (</span><span>amdgpu_submit_t</span><span>){</span></span>
<span><span>    .ib </span><span>=</span><span> ib</span><span>,</span></span>
<span><span>    .bo_list </span><span>=</span><span> bo_list</span><span>,</span></span>
<span><span>    .fence </span><span>=</span><span> {</span></span>
<span><span>      .context </span><span>=</span><span> dev</span><span>-&gt;</span><span>ctx_handle</span><span>,</span></span>
<span><span>      .ip_type </span><span>=</span><span> AMDGPU_HW_IP_COMPUTE</span><span>,</span></span>
<span><span>      .ip_instance </span><span>=</span><span> 0</span><span>,</span></span>
<span><span>      .ring </span><span>=</span><span> 0</span><span>,</span></span>
<span><span>      .fence </span><span>=</span><span> req</span><span>.</span><span>seq_no</span><span>,</span></span>
<span><span>    }</span><span>,</span></span>
<span><span>  };</span></span>
<span><span>}</span></span></code></pre>
<p><span>Here is a good point to make a more complex shader that outputs something. For example, writing 1 to a buffer.</span></p>
<p>No GPU hangs ?! nothing happened ?! cool, cool, now we have a shader that runs on the GPU, what’s next? Let’s try to hang the GPU by pausing the execution, aka make the GPU trap.</p>
<h2 id="tbatma">TBA/TMA</h2>
<p>The RDNA3’s ISA manual does mention 2 registers, <code>TBA, TMA</code>; here’s how they describe them respectively:</p>
<blockquote>
<p>Holds the pointer to the current trap handler program address. Per-VMID register. Bit [63] indicates if the trap
handler is present (1) or not (0) and is not considered part of the address
(bit[62] is replicated into address bit[63]).  Accessed via S_SENDMSG_RTN.</p>
</blockquote>
<blockquote>
<p>Temporary register for shader operations. For example, it can hold a pointer to memory used by the trap handler.</p>
</blockquote>
<p><span>You can configure the GPU to enter the trap handler when encountering certain exceptions listed in the RDNA3 ISA manual.</span></p>
<p>We know from <a href="https://martty.github.io/about/">Marcell Kiss’s</a> blog posts that we need to compile a trap handler, which is a normal shader the GPU switches to when encountering a <code>s_trap</code>. The TBA register has a special bit that indicates whether the trap handler is enabled.</p>
<p>Since these are privileged registers, we cannot write to them from user space. To bridge this gap for debugging, we can utilize the debugfs interface. Luckily, we have <a href="https://umr.readthedocs.io/en/main/intro.html">UMR</a>, which uses that debugfs interface, and it’s open source; we copy AMD’s homework here which is great.</p>
<h2 id="amdgpu-debugfs">AMDGPU Debugfs</h2>
<p>The amdgpu KMD has a couple of files in debugfs under <code>/sys/kernel/debug/dri/{PCI address}</code>; one of them is <code>regs2</code>, which is an interface to a <a href="https://elixir.bootlin.com/linux/v6.18/source/drivers/gpu/drm/amd/amdgpu/amdgpu_debugfs.c#L369"><code>amdgpu_debugfs_regs2_write</code></a> in the kernel that writes to the registers. It works by simply opening the file, seeking the register’s offset, and then writing; it also performs some synchronisation and writes the value correctly. We need to provide more parameters about the register before writing to the file, tho and do that by using an ioctl call. Here are the ioctl arguments:</p>
<pre tabindex="0" data-language="c"><code><span><span>typedef</span><span> struct</span><span> amdgpu_debugfs_regs2_iocdata_v2 {</span></span>
<span><span> __u32 use_srbm</span><span>,</span><span> use_grbm</span><span>,</span><span> pg_lock;</span></span>
<span><span> struct</span><span> {</span></span>
<span><span>  __u32 se</span><span>,</span><span> sh</span><span>,</span><span> instance;</span></span>
<span><span> } grbm;</span></span>
<span><span> struct</span><span> {</span></span>
<span><span>  __u32 me</span><span>,</span><span> pipe</span><span>,</span><span> queue</span><span>,</span><span> vmid;</span></span>
<span><span> } srbm;</span></span>
<span><span> __u32 xcc_id;</span></span>
<span><span>} </span><span>regs2_ioc_data_t</span><span>;</span></span></code></pre>
<p>The 2 structs are because there are 2 types of registers, GRBM and SRBM, each of which is banked by different constructs; you can learn more about some of them here in <a href="https://docs.kernel.org/gpu/amdgpu/driver-core.html#gfx-compute-and-sdma-overall-behaviour">the Linux kernel documentation</a>.</p>
<p>Turns out our registers here are SBRM registers and banked by VMIDs, meaning each VMID has its own TBA and TMA registers. Cool, now we need to figure out the VMID of our process. As far as I understand, VMIDs are a way for the GPU to identify a specific process context, including the page table base address, so the address translation unit can translate a virtual memory address. The context is created when we open the DRM file. They get assigned dynamically at dispatch time, which is a problem for us; we want to write to those registers before dispatch.</p>
<p>We can obtain the VMID of the dispatched process by querying the <code>HW_ID2</code> register with s_getreg_b32. I do a hack here, by enabling the trap handler in every VMID, and there are 16 of them, the first being special, and used by the KMD and the last 8 allocated to the amdkfd driver. We loop over the remaining VMIDs and write to those registers. This can cause issues to other processes using other VMIDs by enabling trap handlers in them and writing the virtual address of our trap handler, which is only valid within our virtual memory address space. It’s relatively safe tho since most other processes won’t cause a trap<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>.</p>
<p>Now we can write to TMA and TBA, here’s the code:</p>
<pre tabindex="0" data-language="c"><code><span><span>void</span><span> dev_op_reg32</span><span>(</span></span>
<span><span>  amdgpu_t</span><span>*</span><span> dev</span><span>,</span><span> gc_11_reg_t</span><span> reg</span><span>,</span><span> regs2_ioc_data_t</span><span> ioc_data</span><span>,</span><span> reg_32_op_t</span><span> op</span><span>,</span><span> u32</span><span>*</span><span> value) {</span></span>
<span><span> s32 ret </span><span>=</span><span> 0</span><span>;</span></span>
<span></span>
<span><span> reg_info_t</span><span> reg_info     </span><span>=</span><span> gc_11_regs_infos[reg];</span></span>
<span><span> uint64_t</span><span>   reg_offset   </span><span>=</span><span> gc_11_regs_offsets[reg];</span></span>
<span><span> uint64_t</span><span>   base_offset  </span><span>=</span><span> dev</span><span>-&gt;</span><span>gc_regs_base_addr[</span><span>reg_info</span><span>.</span><span>soc_index];</span></span>
<span><span> uint64_t</span><span>   total_offset </span><span>=</span><span> (reg_offset </span><span>+</span><span> base_offset);</span></span>
<span></span>
<span><span> // seems like we're multiplying by 4 here because the registers database in UMRs</span></span>
<span><span> // source has them in indexes rather than bytes.</span></span>
<span><span> total_offset </span><span>*=</span><span> (</span><span>reg_info</span><span>.</span><span>type </span><span>==</span><span> REG_MMIO) </span><span>?</span><span> 4</span><span> :</span><span> 1</span><span>;</span></span>
<span></span>
<span><span> ret </span><span>=</span><span> hdb_ioctl(</span><span>dev</span><span>-&gt;</span><span>regs2_fd</span><span>,</span><span> AMDGPU_DEBUGFS_REGS2_IOC_SET_STATE_V2</span><span>,</span><span> &amp;</span><span>ioc_data)</span><span>;</span></span>
<span><span> HDB_ASSERT(</span><span>!</span><span>ret</span><span>,</span><span> "Failed to set registers state"</span><span>)</span><span>;</span></span>
<span></span>
<span><span> size_t</span><span> size </span><span>=</span><span> lseek(</span><span>dev</span><span>-&gt;</span><span>regs2_fd</span><span>,</span><span> total_offset</span><span>,</span><span> SEEK_SET)</span><span>;</span></span>
<span><span> HDB_ASSERT(size </span><span>==</span><span> total_offset</span><span>,</span><span> "Failed to seek register address"</span><span>)</span><span>;</span></span>
<span></span>
<span><span> switch</span><span> (op) {</span></span>
<span><span> case</span><span> REG_OP_READ </span><span>:</span><span> size </span><span>=</span><span> read</span><span>(dev</span><span>-&gt;</span><span>regs2_fd</span><span>,</span><span> value</span><span>,</span><span> 4</span><span>); </span><span>break</span><span>;</span></span>
<span><span> case</span><span> REG_OP_WRITE</span><span>:</span><span> size </span><span>=</span><span> write</span><span>(dev</span><span>-&gt;</span><span>regs2_fd</span><span>,</span><span> value</span><span>,</span><span> 4</span><span>); </span><span>break</span><span>;</span></span>
<span><span> default</span><span>          :</span><span> HDB_ASSERT</span><span>(</span><span>false</span><span>,</span><span> "unsupported op"</span><span>);</span></span>
<span><span> }</span></span>
<span></span>
<span><span> HDB_ASSERT(size </span><span>==</span><span> 4</span><span>,</span><span> "Failed to write/read the values to/from the register"</span><span>)</span><span>;</span></span>
<span><span>}</span></span></code></pre>
<p>And here’s how we write to <code>TMA</code> and <code>TBA</code>:
<span>If you noticed, I’m using bitfields. I use them because working with them is much easier than macros, and while the byte order is not guaranteed by the C spec, it’s guaranteed by System V ABI, which Linux adheres to.</span></p>
<pre tabindex="0" data-language="c"><code><span><span>void</span><span> dev_setup_trap_handler</span><span>(</span><span>amdgpu_t</span><span>*</span><span> dev</span><span>,</span><span> u64 tba</span><span>,</span><span> u64 tma) {</span></span>
<span><span> reg_sq_shader_tma_lo_t</span><span> tma_lo </span><span>=</span><span> { .raw </span><span>=</span><span> (u32)(tma) };</span></span>
<span><span> reg_sq_shader_tma_hi_t</span><span> tma_hi </span><span>=</span><span> { .raw </span><span>=</span><span> (u32)(tma </span><span>&gt;&gt;</span><span> 32</span><span>) };</span></span>
<span></span>
<span><span> reg_sq_shader_tba_lo_t</span><span> tba_lo </span><span>=</span><span> { .raw </span><span>=</span><span> (u32)(tba </span><span>&gt;&gt;</span><span> 8</span><span>) };</span></span>
<span><span> reg_sq_shader_tba_hi_t</span><span> tba_hi </span><span>=</span><span> { .raw </span><span>=</span><span> (u32)(tba </span><span>&gt;&gt;</span><span> 40</span><span>) };</span></span>
<span></span>
<span><span> tba_hi</span><span>.</span><span>trap_en </span><span>=</span><span> 1</span><span>;</span></span>
<span></span>
<span><span> regs2_ioc_data_t</span><span> ioc_data </span><span>=</span><span> {</span></span>
<span><span>  .use_srbm </span><span>=</span><span> 1</span><span>,</span></span>
<span><span>  .xcc_id   </span><span>=</span><span> -</span><span>1</span><span>,</span></span>
<span><span> };</span></span>
<span></span>
<span><span> // NOTE(hadi):</span></span>
<span><span> // vmid's get assigned when code starts executing before hand we don't know which vmid</span></span>
<span><span> // will get assigned to our process so we just set all of them</span></span>
<span><span> for_range(i</span><span>,</span><span> 1</span><span>,</span><span> 9</span><span>)</span><span> {</span></span>
<span><span>  ioc_data</span><span>.</span><span>srbm</span><span>.</span><span>vmid </span><span>=</span><span> i;</span></span>
<span><span>  dev_op_reg32(dev</span><span>,</span><span> REG_SQ_SHADER_TBA_LO</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_WRITE</span><span>,</span><span> &amp;</span><span>tba_lo</span><span>.</span><span>raw)</span><span>;</span></span>
<span><span>  dev_op_reg32(dev</span><span>,</span><span> REG_SQ_SHADER_TBA_HI</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_WRITE</span><span>,</span><span> &amp;</span><span>tba_hi</span><span>.</span><span>raw)</span><span>;</span></span>
<span></span>
<span><span>  dev_op_reg32(dev</span><span>,</span><span> REG_SQ_SHADER_TMA_LO</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_WRITE</span><span>,</span><span> &amp;</span><span>tma_lo</span><span>.</span><span>raw)</span><span>;</span></span>
<span><span>  dev_op_reg32(dev</span><span>,</span><span> REG_SQ_SHADER_TMA_HI</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_WRITE</span><span>,</span><span> &amp;</span><span>tma_hi</span><span>.</span><span>raw)</span><span>;</span></span>
<span><span> }</span></span>
<span><span>}</span></span></code></pre>
<p>Anyway, now that we can write to those registers, if we enable the trap handler correctly, the GPU should hang when we launch our shader if we added <code>s_trap</code> instruction to it, or we enabled the <code>TRAP_ON_START</code> bit in rsrc3<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup> register.</p>
<p>Now, let’s try to write a trap handler.</p>
<h2 id="the-trap-handler">The Trap Handler</h2>
<p><span>If you wrote a different shader that outputs to a buffer, u can try writing to that shader from the trap handler, which is nice to make sure it’s actually being run.</span></p>
<p>We need 2 things: our trap handler and some scratch memory to use when needed, which we will store the address of in the TMA register.</p>
<p>The trap handler is just a normal program running in privileged state, meaning we have access to special registers like TTMP[0-15]. When we enter a trap handler, we need to first ensure that the state of the GPU registers is saved, just as the kernel does for CPU processes when context-switching, by saving a copy of the stable registers and the program counter, etc. The problem, tho, is that we don’t have a stable ABI for GPUs, or at least not one I’m aware of, and compilers use all the registers they can, so we need to save everything.</p>
<p>AMD GPUs’ Command Processors (CPs) have context-switching functionality, and the amdkfd driver does implement some <a href="https://elixir.bootlin.com/linux/v6.18/source/drivers/gpu/drm/amd/amdkfd/cwsr_trap_handler_gfx10.asm">context-switching shaders</a>. The problem is they’re not documented, and we have to figure them out from the amdkfd driver source and from other parts of the driver stack that interact with it, which is a pain in the ass. I kinda did a workaround here since I didn’t find luck understanding how it works, and some other reasons I’ll discuss later in the post.</p>
<p>The workaround here is to use only TTMP registers and a combination of specific instructions to copy the values of some registers, allowing us to use more instructions to copy the remaining registers. The main idea is to make use of the <code>global_store_addtid_b32</code> instruction, which adds the index of the current thread within the wave to the writing address, aka</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>I</mi><msub><mi>D</mi><mrow><mi>t</mi><mi>h</mi><mi>r</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub><mo>∗</mo><mn>4</mn><mo>+</mo><mi>a</mi><mi>d</mi><mi>d</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">ID_{thread} * 4 + address</annotation></semantics></math></span></span></span></p><p>This allows us to write a unique value per thread using only TTMP registers, which are unique per wave, not per thread<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup>, so we can save the context of a single wave.</p>
<p>The problem is that if we have more than 1 wave, they will overlap, and we will have a race condition.</p>
<p>Here is the code:</p>
<pre tabindex="0" data-language="asm"><code><span><span>start</span><span>:</span></span>
<span><span> ;; save the STATUS word into ttmp8</span></span>
<span><span> s_getreg_b32 ttmp8, hwreg(HW_REG_STATUS)</span></span>
<span></span>
<span><span> ;; save exec into ttmp[2:3]</span></span>
<span><span> s_mov_b64 ttmp[</span><span>2</span><span>:</span><span>3</span><span>], exec</span></span>
<span></span>
<span><span> ;; getting the address of our tma buffer</span></span>
<span><span> s_sendmsg_rtn_b64 ttmp[</span><span>4</span><span>:</span><span>5</span><span>], sendmsg(MSG_RTN_GET_TMA)</span></span>
<span><span> s_waitcnt lgkmcnt(</span><span>0</span><span>)</span></span>
<span></span>
<span><span> ;; save vcc</span></span>
<span><span> s_mov_b64 ttmp[</span><span>6</span><span>:</span><span>7</span><span>], vcc</span></span>
<span></span>
<span><span> ;; enable all threads so they can write their vgpr registers</span></span>
<span><span> s_mov_b64 exec, -</span><span>1</span></span>
<span></span>
<span><span> ;; FIXME(hadi): this assumes only 1 wave is running</span></span>
<span><span> global_store_addtid_b32 v0, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_VREG_OFFSET        glc slc dlc</span></span>
<span><span> global_store_addtid_b32 v1, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_VREG_OFFSET + </span><span>256</span><span>  glc slc dlc</span></span>
<span><span> global_store_addtid_b32 v2, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_VREG_OFFSET + </span><span>512</span><span>  glc slc dlc</span></span>
<span><span> global_store_addtid_b32 v3, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_VREG_OFFSET + </span><span>768</span><span>  glc slc dlc</span></span>
<span><span> global_store_addtid_b32 v4, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_VREG_OFFSET + </span><span>1024</span><span> glc slc dlc</span></span>
<span><span> global_store_addtid_b32 v5, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_VREG_OFFSET + </span><span>1280</span><span> glc slc dlc</span></span>
<span><span> global_store_addtid_b32 v6, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_VREG_OFFSET + </span><span>1536</span><span> glc slc dlc</span></span>
<span><span> s_waitcnt vmcnt(</span><span>0</span><span>)</span></span>
<span></span>
<span><span> ;; only first thread is supposed to write sgprs of the wave</span></span>
<span><span> s_mov_b64 exec, </span><span>1</span></span>
<span><span> v_mov_b32 v1, s0</span></span>
<span><span> v_mov_b32 v2, s1</span></span>
<span><span> v_mov_b32 v3, s2</span></span>
<span><span> v_mov_b32 v4, s3</span></span>
<span><span> v_mov_b32 v5, s4</span></span>
<span><span> v_mov_b32 v0, </span><span>0</span></span>
<span><span> global_store_b32 v0, v1, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_SREG_OFFSET glc slc dlc</span></span>
<span><span> global_store_b32 v0, v2, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_SREG_OFFSET + </span><span>4</span><span> glc slc dlc</span></span>
<span><span> global_store_b32 v0, v3, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_SREG_OFFSET + </span><span>8</span><span> glc slc dlc</span></span>
<span><span> global_store_b32 v0, v4, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_SREG_OFFSET + </span><span>12</span><span> glc slc dlc</span></span>
<span><span> global_store_b32 v0, v5, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_SREG_OFFSET + </span><span>16</span><span> glc slc dlc</span></span>
<span><span> s_waitcnt vmcnt(</span><span>0</span><span>)</span></span>
<span></span>
<span><span> ;; enable all threads</span></span>
<span><span> s_mov_b64 exec, -</span><span>1</span></span></code></pre>
<p>Now that we have those values in memory, we need to tell the CPU: Hey, we got the data, and pause the GPU’s execution until the CPU issues a command. Also, notice we can just modify those from the CPU.</p>
<p>Before we tell the CPU, we need to write some values that might help the CPU. Here are they:</p>
<pre tabindex="0" data-language="asm"><code><span><span> ;; IDs to identify which parts of the hardware we are running on exactly</span></span>
<span><span> s_getreg_b32 ttmp10, hwreg(HW_REG_HW_ID1)</span></span>
<span><span> s_getreg_b32 ttmp11, hwreg(HW_REG_HW_ID2)</span></span>
<span><span> v_mov_b32 v3, ttmp10</span></span>
<span><span> v_mov_b32 v4, ttmp11</span></span>
<span><span> global_store_dwordx2 v1, v[</span><span>3</span><span>:</span><span>4</span><span>], ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_DATA_OFFSET glc slc dlc</span></span>
<span></span>
<span><span> ;; the original vcc mask</span></span>
<span><span> v_mov_b32 v3, ttmp6</span></span>
<span><span> v_mov_b32 v4, ttmp7</span></span>
<span><span> global_store_dwordx2 v1, v[</span><span>3</span><span>:</span><span>4</span><span>], ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>2048</span><span> glc slc dlc</span></span>
<span><span> s_waitcnt vmcnt(</span><span>0</span><span>)</span></span>
<span></span>
<span><span> ;; the original exec mask</span></span>
<span><span> v_mov_b32 v3, ttmp2</span></span>
<span><span> v_mov_b32 v4, ttmp3</span></span>
<span><span> global_store_dwordx2 v1, v[</span><span>3</span><span>:</span><span>4</span><span>], ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>2056</span><span> glc slc dlc</span></span>
<span><span> s_waitcnt vmcnt(</span><span>0</span><span>)</span></span>
<span></span>
<span><span> ;; the program counter</span></span>
<span><span> v_mov_b32 v3, ttmp0</span></span>
<span><span> v_mov_b32 v4, ttmp1</span></span>
<span><span> v_and_b32 v4, v4, </span><span>0xffff</span></span>
<span><span> global_store_dwordx2 v1, v[</span><span>3</span><span>:</span><span>4</span><span>], ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>16</span><span> glc slc dlc</span></span>
<span></span>
<span><span> s_waitcnt vmcnt(</span><span>0</span><span>)</span></span></code></pre>
<p>Now the GPU should just wait for the CPU, and here’s the spin code it’s implemented as described by Marcell Kiss <a href="https://martty.github.io/posts/radbg_part_4/#busier-waiting">here</a>:</p>
<pre tabindex="0" data-language="asm"><code><span><span>SPIN</span><span>:</span></span>
<span><span> global_load_dword v1, v2, ttmp[</span><span>4</span><span>:</span><span>5</span><span>] glc slc dlc</span></span>
<span></span>
<span><span>SPIN1</span><span>:</span></span>
<span><span> // I found the bit range of </span><span>10</span><span> to </span><span>15</span><span> using trial </span><span>and</span><span> error </span><span>in</span><span> the</span></span>
<span><span> // isa manual specifies that it's a </span><span>6</span><span>-bit number but the offset </span><span>10</span></span>
<span><span> // is just trial </span><span>and</span><span> error</span></span>
<span><span>  s_getreg_b32 ttmp13, hwreg(HW_REG_IB_STS, </span><span>10</span><span>, </span><span>15</span><span>)</span></span>
<span><span> s_and_b32 ttmp13, ttmp13, ttmp13</span></span>
<span><span> s_cbranch_scc1 SPIN1</span></span>
<span></span>
<span><span> v_readfirstlane_b32 ttmp13, v1</span></span>
<span><span> s_and_b32 ttmp13, ttmp13, ttmp13</span></span>
<span><span> s_cbranch_scc0 SPIN</span></span>
<span></span>
<span><span>CLEAR</span><span>:</span></span>
<span><span> v_mov_b32 v2, </span><span>0</span></span>
<span><span> v_mov_b32 v1, </span><span>0</span></span>
<span><span> global_store_dword v1, v2, ttmp[</span><span>4</span><span>:</span><span>5</span><span>] glc slc dlc</span></span>
<span><span> s_waitcnt vmcnt(</span><span>0</span><span>)</span></span></code></pre>
<p>The main loop in the CPU is like enable trap handler, then dispatch shader, then wait for the GPU to write some specific value in a specific address to signal all data is there, then examine and display, and tell the GPU all clear, go ahead.</p>
<p>Now that our uncached buffers are in play, we just keep looping and checking whether the GPU has written the register values. When it does, the first thing we do is halt the wave by writing into the <code>SQ_CMD</code> register to allow us to do whatever with the wave without causing any issues, tho if we halt for too long, the GPU CP will reset the command queue and kill the process, but we can change that behaviour by adjusting <a href="https://www.kernel.org/doc/html/v4.20/gpu/amdgpu.html#module-parameters">lockup_timeout</a> parameter of the amdgpu kernel module:</p>
<pre tabindex="0" data-language="c"><code><span><span>reg_sq_wave_hw_id1_t</span><span> hw1 </span><span>=</span><span> { .raw </span><span>=</span><span> tma[</span><span>2</span><span>] };</span></span>
<span><span>reg_sq_wave_hw_id2_t</span><span> hw2 </span><span>=</span><span> { .raw </span><span>=</span><span> tma[</span><span>3</span><span>] };</span></span>
<span></span>
<span><span>reg_sq_cmd_t</span><span> halt_cmd </span><span>=</span><span> {</span></span>
<span><span> .cmd  </span><span>=</span><span> 1</span><span>,</span></span>
<span><span> .mode </span><span>=</span><span> 1</span><span>,</span></span>
<span><span> .data </span><span>=</span><span> 1</span><span>,</span></span>
<span><span>};</span></span>
<span></span>
<span><span>regs2_ioc_data_t</span><span> ioc_data </span><span>=</span><span> {</span></span>
<span><span> .use_srbm </span><span>=</span><span> false</span><span>,</span></span>
<span><span> .use_grbm </span><span>=</span><span> true</span><span>,</span></span>
<span><span>};</span></span>
<span></span>
<span><span>dev_op_reg32</span><span>(</span><span>&amp;</span><span>amdgpu</span><span>,</span><span> REG_SQ_CMD</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_WRITE</span><span>,</span><span> &amp;</span><span>halt_cmd.raw);</span></span>
<span><span>gpu_is_halted </span><span>=</span><span> true</span><span>;</span></span></code></pre>
<p>From here on, we can do whatever with the data we have. All the data we need to build a proper debugger. We will come back to what to do with the data in a bit; let’s assume we did what was needed for now.</p>
<p>Now that we’re done with the CPU, we need to write to the first byte in our TMA buffer, since the trap handler checks for that, then resume the wave, and the trap handler should pick it up. We can resume by writing to the <code>SQ_CMD</code> register again:</p>
<pre tabindex="0" data-language="c"><code><span><span>halt_cmd.mode </span><span>=</span><span> 0</span><span>;</span></span>
<span><span>dev_op_reg32</span><span>(</span><span>&amp;</span><span>amdgpu</span><span>,</span><span> REG_SQ_CMD</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_WRITE</span><span>,</span><span> &amp;</span><span>halt_cmd.raw);</span></span>
<span><span>gpu_is_halted </span><span>=</span><span> false</span><span>;</span></span></code></pre>
<p>Then the GPU should continue. We need to restore everything and return the program counter to the original address. Based on whether it’s a hardware trap or not, the program counter may point to the instruction before or the instruction itself. The ISA manual and Marcell Kiss’s posts explain that well, so refer to them.</p>
<pre tabindex="0" data-language="asm"><code><span><span>RETURN</span><span>:</span></span>
<span><span> ;; extract the trap ID from ttmp1</span></span>
<span><span> s_and_b32 ttmp9, ttmp1, PC_HI_TRAP_ID_MASK</span></span>
<span><span> s_lshr_b32 ttmp9, ttmp9, PC_HI_TRAP_ID_SHIFT</span></span>
<span></span>
<span><span> ;; if the trapID == 0, then this is a hardware trap,</span></span>
<span><span> ;; we don't need to fix up the return address</span></span>
<span><span> s_cmpk_eq_u32 ttmp9, </span><span>0</span></span>
<span><span> s_cbranch_scc1 RETURN_FROM_NON_S_TRAP</span></span>
<span></span>
<span><span> ;; restore PC</span></span>
<span><span> ;; add 4 to the faulting address, with carry</span></span>
<span><span> s_add_u32 ttmp0, ttmp0, </span><span>4</span></span>
<span><span> s_addc_u32 ttmp1, ttmp1, </span><span>0</span></span>
<span></span>
<span><span>RETURN_FROM_NON_S_TRAP</span><span>:</span></span>
<span><span> s_load_dwordx4 s[</span><span>0</span><span>:</span><span>3</span><span>], ttmp[</span><span>4</span><span>:</span><span>5</span><span>], TMA_SREG_OFFSET glc dlc</span></span>
<span><span> s_load_dword s4, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], TMA_SREG_OFFSET + </span><span>16</span><span> glc dlc</span></span>
<span><span> s_waitcnt lgkmcnt(</span><span>0</span><span>)</span></span>
<span></span>
<span><span> s_mov_b64 exec, -</span><span>1</span></span>
<span><span> global_load_addtid_b32 v0, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_VREG_OFFSET        glc slc dlc</span></span>
<span><span> global_load_addtid_b32 v1, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_VREG_OFFSET + </span><span>256</span><span>  glc slc dlc</span></span>
<span><span> global_load_addtid_b32 v2, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_VREG_OFFSET + </span><span>512</span><span>  glc slc dlc</span></span>
<span><span> global_load_addtid_b32 v3, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_VREG_OFFSET + </span><span>768</span><span>  glc slc dlc</span></span>
<span><span> global_load_addtid_b32 v4, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_VREG_OFFSET + </span><span>1024</span><span> glc slc dlc</span></span>
<span><span> global_load_addtid_b32 v5, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_VREG_OFFSET + </span><span>1280</span><span> glc slc dlc</span></span>
<span><span> global_load_addtid_b32 v6, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>offset</span><span>:</span><span>TMA_VREG_OFFSET + </span><span>1536</span><span> glc slc dlc</span></span>
<span><span> s_waitcnt vmcnt(</span><span>0</span><span>)</span></span>
<span></span>
<span><span> ;; mask off non-address high bits from ttmp1</span></span>
<span><span> s_and_b32 ttmp1, ttmp1, </span><span>0xffff</span></span>
<span></span>
<span><span> ;; restore exec</span></span>
<span><span> s_load_b64 vcc, ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>2048</span><span> glc dlc</span></span>
<span><span> s_load_b64 ttmp[</span><span>2</span><span>:</span><span>3</span><span>], ttmp[</span><span>4</span><span>:</span><span>5</span><span>], </span><span>2056</span><span> glc dlc</span></span>
<span><span> s_waitcnt lgkmcnt(</span><span>0</span><span>)</span></span>
<span><span> s_mov_b64 exec, ttmp[</span><span>2</span><span>:</span><span>3</span><span>]</span></span>
<span></span>
<span><span> ;; restore STATUS.EXECZ, not writable by s_setreg_b32</span></span>
<span><span> s_and_b64 exec, exec, exec</span></span>
<span></span>
<span><span> ;; restore STATUS.VCCZ, not writable by s_setreg_b32</span></span>
<span><span> s_and_b64 vcc, vcc, vcc</span></span>
<span></span>
<span><span> ;; restore STATUS.SCC</span></span>
<span><span> s_setreg_b32 hwreg(HW_REG_STATUS, </span><span>0</span><span>, </span><span>1</span><span>), ttmp8</span></span>
<span></span>
<span><span> s_waitcnt vmcnt(</span><span>0</span><span>) lgkmcnt(</span><span>0</span><span>) expcnt(</span><span>0</span><span>)  </span><span>; Full pipeline flush</span></span>
<span><span> ;; return from trap handler and restore STATUS.PRIV</span></span>
<span><span> s_rfe_b64 [ttmp0, ttmp1]</span></span></code></pre>
<h2 id="spir-v">SPIR-V</h2>
<p>Now we can run compiled code directly, but we don’t want people to compile their code manually, then extract the text section, and give it to us. The plan is to take SPIR-V code, compile it correctly, then run it, or, even better, integrate with RADV and let RADV give us more information to work with.</p>
<p>My main plan was making like fork RADV and then add then make report for us the vulkan calls and then we can have a better view on the GPU work know the buffers/textures it’s using etc, This seems like a lot more work tho so I’ll keep it in mind but not doing that for now unless someone is willing to pay me for that ;).</p>
<p>For now, let’s just use RADV’s compiler <code>ACO</code>. Luckily, RADV has a <code>null_winsys</code> mode, aka it will not do actual work or open DRM files, just a fake Vulkan device, which is perfect for our case here, since we care about nothing other than just compiling code. We can enable it by setting the env var <code>RADV_FORCE_FAMILY</code>, then we just call what we need like this:</p>
<pre tabindex="0" data-language="c"><code><span><span>int32_t</span><span> hdb_compile_spirv_to_bin</span><span>(</span></span>
<span><span>  const</span><span> void*</span><span> spirv_binary</span><span>,</span></span>
<span><span>  size_t</span><span> size</span><span>,</span></span>
<span><span>  hdb_shader_stage_t</span><span> stage</span><span>,</span></span>
<span><span>  hdb_shader_t</span><span>*</span><span> shader</span></span>
<span><span>) {</span></span>
<span><span> setenv(</span><span>"RADV_FORCE_FAMILY"</span><span>,</span><span> "navi31"</span><span>,</span><span> 1</span><span>)</span><span>;</span></span>
<span><span> //  setenv("RADV_DEBUG", "nocache,noopt", 1);</span></span>
<span><span> setenv(</span><span>"ACO_DEBUG"</span><span>,</span><span> "nocache,noopt"</span><span>,</span><span> 1</span><span>)</span><span>;</span></span>
<span></span>
<span><span> VkInstanceCreateInfo i_cinfo </span><span>=</span><span> {</span></span>
<span><span>  .sType </span><span>=</span><span> VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO</span><span>,</span></span>
<span><span>  .pApplicationInfo </span><span>=</span></span>
<span><span>    &amp;</span><span>(VkApplicationInfo){</span></span>
<span><span>      .sType              </span><span>=</span><span> VK_STRUCTURE_TYPE_APPLICATION_INFO</span><span>,</span></span>
<span><span>      .pApplicationName   </span><span>=</span><span> "HDB Shader Compiler"</span><span>,</span></span>
<span><span>      .applicationVersion </span><span>=</span><span> 1</span><span>,</span></span>
<span><span>      .pEngineName        </span><span>=</span><span> "HDB"</span><span>,</span></span>
<span><span>      .engineVersion      </span><span>=</span><span> 1</span><span>,</span></span>
<span><span>      .apiVersion         </span><span>=</span><span> VK_API_VERSION_1_4</span><span>,</span></span>
<span><span>    }</span><span>,</span></span>
<span><span> };</span></span>
<span></span>
<span><span> VkInstance vk_instance </span><span>=</span><span> {};</span></span>
<span><span> radv_CreateInstance(</span><span>&amp;</span><span>i_cinfo</span><span>,</span><span> NULL</span><span>,</span><span> &amp;</span><span>vk_instance)</span><span>;</span></span>
<span></span>
<span><span> struct</span><span> radv_instance</span><span>*</span><span> instance </span><span>=</span><span> radv_instance_from_handle(vk_instance)</span><span>;</span></span>
<span><span> instance</span><span>-&gt;</span><span>debug_flags </span><span>|=</span></span>
<span><span>   RADV_DEBUG_NIR_DEBUG_INFO </span><span>|</span><span> RADV_DEBUG_NO_CACHE </span><span>|</span><span> RADV_DEBUG_INFO;</span></span>
<span></span>
<span><span> uint32_t</span><span>         n       </span><span>=</span><span> 1</span><span>;</span></span>
<span><span> VkPhysicalDevice vk_pdev </span><span>=</span><span> {};</span></span>
<span><span> instance</span><span>-&gt;</span><span>vk</span><span>.</span><span>dispatch_table.</span><span>EnumeratePhysicalDevices</span><span>(</span><span>vk_instance</span><span>,</span><span> &amp;</span><span>n</span><span>,</span><span> &amp;</span><span>vk_pdev</span><span>);</span></span>
<span></span>
<span><span> struct</span><span> radv_physical_device</span><span>*</span><span> pdev </span><span>=</span><span> radv_physical_device_from_handle(vk_pdev)</span><span>;</span></span>
<span><span> pdev</span><span>-&gt;</span><span>use_llvm                    </span><span>=</span><span> false</span><span>;</span></span>
<span></span>
<span><span> VkDeviceCreateInfo d_cinfo </span><span>=</span><span> { VK_STRUCTURE_TYPE_DEVICE_CREATE_INFO };</span></span>
<span><span> VkDevice vk_dev </span><span>=</span><span> {};</span></span>
<span><span> pdev</span><span>-&gt;</span><span>vk</span><span>.</span><span>dispatch_table.</span><span>CreateDevice</span><span>(</span><span>vk_pdev</span><span>,</span><span> &amp;</span><span>d_cinfo</span><span>,</span><span> NULL</span><span>,</span><span> &amp;</span><span>vk_dev</span><span>);</span></span>
<span></span>
<span><span> struct</span><span> radv_device</span><span>*</span><span> dev </span><span>=</span><span> radv_device_from_handle(vk_dev)</span><span>;</span></span>
<span></span>
<span><span> struct</span><span> radv_shader_stage radv_stage </span><span>=</span><span> {</span></span>
<span><span>  .</span><span>spirv</span><span>.</span><span>data </span><span>=</span><span> spirv_binary</span><span>,</span></span>
<span><span>  .</span><span>spirv</span><span>.</span><span>size </span><span>=</span><span> size</span><span>,</span></span>
<span><span>  .entrypoint </span><span>=</span><span> "main"</span><span>,</span></span>
<span><span>  .stage      </span><span>=</span><span> MESA_SHADER_COMPUTE</span><span>,</span></span>
<span><span>  .layout </span><span>=</span><span> {</span></span>
<span><span>   .push_constant_size </span><span>=</span><span> 16</span><span>,</span></span>
<span><span>  }</span><span>,</span></span>
<span><span>  .key </span><span>=</span><span> {</span></span>
<span><span>   .optimisations_disabled </span><span>=</span><span> true</span><span>,</span></span>
<span><span>  }</span><span>,</span></span>
<span><span> };</span></span>
<span></span>
<span><span> struct</span><span> radv_shader_binary</span><span>*</span><span> cs_bin </span><span>=</span><span> NULL</span><span>;</span></span>
<span><span> struct</span><span> radv_shader</span><span>*</span><span>        cs_shader </span><span>=</span></span>
<span><span>   radv_compile_cs(dev</span><span>,</span><span> NULL</span><span>,</span><span> &amp;</span><span>radv_stage</span><span>,</span><span> true</span><span>,</span><span> true</span><span>,</span><span> false</span><span>,</span><span> true</span><span>,</span><span> &amp;</span><span>cs_bin)</span><span>;</span></span>
<span></span>
<span><span> *</span><span>shader </span><span>=</span><span> (</span><span>hdb_shader_t</span><span>){</span></span>
<span><span>  .bin              </span><span>=</span><span> cs_shader</span><span>-&gt;</span><span>code</span><span>,</span></span>
<span><span>  .bin_size         </span><span>=</span><span> cs_shader</span><span>-&gt;</span><span>code_size</span><span>,</span></span>
<span><span>  .rsrc1            </span><span>=</span><span> cs_shader</span><span>-&gt;</span><span>config</span><span>.</span><span>rsrc1</span><span>,</span></span>
<span><span>  .rsrc2            </span><span>=</span><span> cs_shader</span><span>-&gt;</span><span>config</span><span>.</span><span>rsrc2</span><span>,</span></span>
<span><span>  .rsrc3            </span><span>=</span><span> cs_shader</span><span>-&gt;</span><span>config</span><span>.</span><span>rsrc3</span><span>,</span></span>
<span><span>  .debug_info       </span><span>=</span><span> cs_shader</span><span>-&gt;</span><span>debug_info</span><span>,</span></span>
<span><span>  .debug_info_count </span><span>=</span><span> cs_shader</span><span>-&gt;</span><span>debug_info_count</span><span>,</span></span>
<span><span> };</span></span>
<span></span>
<span><span> return</span><span> 0</span><span>;</span></span>
<span><span>}</span></span></code></pre>
<p>Now that we have a well-structured loop and communication between the GPU and the CPU, we can run SPIR-V binaries to some extent. Let’s see how we can make it an actual debugger.</p>
<h2 id="an-actual-debugger">An Actual Debugger</h2>
<p>We talked earlier about CPs natively supporting context-switching, this appears to be compute spcific feature,
which prevents from implementing it for other types of shaders, tho, it appears that mesh shaders and raytracing
shaders are just compute shaders under the hood, which will allow us to use that functionality. For now debugging
one wave feels enough, also we can moify the wave parameters to debug some specific indices.</p>
<p>Here’s some of the features</p>
<h2 id="breakpoints-and-stepping">Breakpoints and Stepping</h2>
<p>For stepping, we can use 2 bits: one in <code>RSRC1</code> and the other in <code>RSRC3</code>. They’re <code>DEBUG_MODE</code> and <code>TRAP_ON_START</code>, respectively. The former enters the trap handler after each instruction, and the latter enters before the first instruction. This means we can automatically enable instruction-level stepping.</p>
<p>Regarding breakpoints, I haven’t implemented them, but they’re rather simple to implement here by us having the base address of the code buffer and knowing the size of each instruction; we can calculate the program counter location ahead and have a list of them available to the GPU, and we can do a binary search on the trap handler.</p>
<h2 id="source-code-line-mapping">Source Code Line Mapping</h2>
<p>The ACO shader compiler does generate instruction-level source code mapping, which is good enough for our purposes here. By taking the offset<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup> of the current program counter and indexing into the code buffer, we can retrieve the current instruction and disassemble it, as well as find the source code mapping from the debug info.</p>
<h2 id="address-watching-aka-watchpoints">Address Watching aka Watchpoints</h2>
<p>We can implement this by marking the GPU page as protected. On a GPU fault, we enter the trap handler, check whether it’s within the range of our buffers and textures, and then act accordingly. Also, looking at the registers, we can find these:</p>
<pre tabindex="0" data-language="c"><code><span><span>typedef</span><span> union</span><span> {</span></span>
<span><span> struct</span><span> {</span></span>
<span><span>  uint32_t</span><span> addr: </span><span>16</span><span>;</span></span>
<span><span> };</span></span>
<span><span> uint32_t</span><span> raw;</span></span>
<span><span>} </span><span>reg_sq_watch0_addr_h_t</span><span>;</span></span>
<span></span>
<span><span>typedef</span><span> union</span><span> {</span></span>
<span><span> struct</span><span> {</span></span>
<span><span>  uint32_t</span><span> __reserved_0 : </span><span>6</span><span>;</span></span>
<span><span>  uint32_t</span><span> addr: </span><span>26</span><span>;</span></span>
<span><span> };</span></span>
<span><span> uint32_t</span><span> raw;</span></span>
<span><span>} </span><span>reg_sq_watch0_addr_l_t</span><span>;</span></span></code></pre>
<p>which suggests that the hardware already supports this natively, so we don’t even need to do that dance. It needs more investigation on my part, tho, since I didn’t implement this.</p>
<h2 id="variables-types-and-names">Variables Types and Names</h2>
<p>This needs some serious plumbing, since we need to make NIR(Mesa’s intermediate representation) optimisation passes propagate debug info correctly. I already started on this <a href="https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/37705">here</a>. Then we need to make ACO track variables and store the information.</p>
<h2 id="vulkan-integration">Vulkan Integration</h2>
<p>This requires ditching our simple UMD we made earlier and using RADV, which is what should happen eventually, then we have our custom driver maybe pause on before a specific frame, or get triggered by a key, and then ask before each dispatch if to attach to it or not, or something similar, since we have a full proper Vulkan implementation we already have all the information we would need like buffers, textures, push constants, types, variable names, .. etc, that would be a much better and more pleasant debugger to use.</p>
<hr>
<p>Finally, here’s some live footage:</p>

    <figure>
      <iframe src="https://www.youtube.com/embed/HDMC9GhaLyc" title="YouTube video player" loading="lazy" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
    </figure>
    
<h2 id="bonus-round">Bonus Round</h2>
<p>Here is an incomplete user-mode page walking code for gfx11, aka rx7900xtx</p>
<pre tabindex="0" data-language="c"><code><span><span>typedef</span><span> struct</span><span> {</span></span>
<span><span> u64 valid         : </span><span>1</span><span>;</span><span>  // 0</span></span>
<span><span> u64 system        : </span><span>1</span><span>;</span><span>  // 1</span></span>
<span><span> u64 coherent      : </span><span>1</span><span>;</span><span>  // 2</span></span>
<span><span> u64 __reserved_0  : </span><span>3</span><span>;</span><span>  // 5</span></span>
<span><span> u64 pte_base_addr : </span><span>42</span><span>;</span><span> // 47</span></span>
<span><span> u64 pa_rsvd       : </span><span>4</span><span>;</span><span>  // 51</span></span>
<span><span> u64 __reserved_1  : </span><span>2</span><span>;</span><span>  // 53</span></span>
<span><span> u64 mall_reuse    : </span><span>2</span><span>;</span><span>  // 55</span></span>
<span><span> u64 tfs_addr      : </span><span>1</span><span>;</span><span>  // 56</span></span>
<span><span> u64 __reserved_2  : </span><span>1</span><span>;</span><span>  // 57</span></span>
<span><span> u64 frag_size     : </span><span>5</span><span>;</span><span>  // 62</span></span>
<span><span> u64 pte           : </span><span>1</span><span>;</span><span>  // 63</span></span>
<span><span>} </span><span>pde_t</span><span>;</span></span>
<span></span>
<span><span>typedef</span><span> struct</span><span> {</span></span>
<span><span> u64 valid          : </span><span>1</span><span>;</span><span> // = pte_entry &amp; 1;</span></span>
<span><span> u64 system         : </span><span>1</span><span>;</span><span> // = (pte_entry &gt;&gt; 1) &amp; 1;</span></span>
<span><span> u64 coherent       : </span><span>1</span><span>;</span><span> // = (pte_entry &gt;&gt; 2) &amp; 1;</span></span>
<span><span> u64 tmz            : </span><span>1</span><span>;</span><span> // = (pte_entry &gt;&gt; 3) &amp; 1;</span></span>
<span><span> u64 execute        : </span><span>1</span><span>;</span><span> // = (pte_entry &gt;&gt; 4) &amp; 1;</span></span>
<span><span> u64 read           : </span><span>1</span><span>;</span><span> // = (pte_entry &gt;&gt; 5) &amp; 1;</span></span>
<span><span> u64 write          : </span><span>1</span><span>;</span><span> // = (pte_entry &gt;&gt; 6) &amp; 1;</span></span>
<span><span> u64 fragment       : </span><span>5</span><span>;</span><span> // = (pte_entry &gt;&gt; 7) &amp; 0x1F;</span></span>
<span><span> u64 page_base_addr : </span><span>36</span><span>;</span></span>
<span><span> u64 mtype          : </span><span>2</span><span>;</span><span> // = (pte_entry &gt;&gt; 48) &amp; 3;</span></span>
<span><span> u64 prt            : </span><span>1</span><span>;</span><span> // = (pte_entry &gt;&gt; 51) &amp; 1;</span></span>
<span><span> u64 software       : </span><span>2</span><span>;</span><span> // = (pte_entry &gt;&gt; 52) &amp; 3;</span></span>
<span><span> u64 pde            : </span><span>1</span><span>;</span><span> // = (pte_entry &gt;&gt; 54) &amp; 1;</span></span>
<span><span> u64 __reserved_0   : </span><span>1</span><span>;</span></span>
<span><span> u64 further        : </span><span>1</span><span>;</span><span> // = (pte_entry &gt;&gt; 56) &amp; 1;</span></span>
<span><span> u64 gcr            : </span><span>1</span><span>;</span><span> // = (pte_entry &gt;&gt; 57) &amp; 1;</span></span>
<span><span> u64 llc_noalloc    : </span><span>1</span><span>;</span><span> // = (pte_entry &gt;&gt; 58) &amp; 1;</span></span>
<span><span>} </span><span>pte_t</span><span>;</span></span>
<span></span>
<span><span>static</span><span> inline</span><span> pde_t</span><span> decode_pde</span><span>(u64 pde_raw) {</span></span>
<span><span> pde_t</span><span> pde         </span><span>=</span><span> *</span><span>((</span><span>pde_t</span><span>*</span><span>)(</span><span>&amp;</span><span>pde_raw));</span></span>
<span><span> pde</span><span>.</span><span>pte_base_addr </span><span>=</span><span> (u64)</span><span>pde</span><span>.</span><span>pte_base_addr </span><span>&lt;&lt;</span><span> 6</span><span>;</span></span>
<span><span> return</span><span> pde;</span></span>
<span><span>}</span></span>
<span></span>
<span><span>static</span><span> inline</span><span> pte_t</span><span> decode_pte</span><span>(u64 pde_raw) {</span></span>
<span><span> pte_t</span><span> pte          </span><span>=</span><span> *</span><span>((</span><span>pte_t</span><span>*</span><span>)(</span><span>&amp;</span><span>pde_raw));</span></span>
<span><span> pte</span><span>.</span><span>page_base_addr </span><span>=</span><span> (u64)</span><span>pte</span><span>.</span><span>page_base_addr </span><span>&lt;&lt;</span><span> 12</span><span>;</span></span>
<span><span> return</span><span> pte;</span></span>
<span><span>}</span></span>
<span></span>
<span><span>static</span><span> inline</span><span> u64 </span><span>log2_range_round_up</span><span>(u64 s</span><span>,</span><span> u64 e) {</span></span>
<span><span> u64 x </span><span>=</span><span> e </span><span>-</span><span> s </span><span>-</span><span> 1</span><span>;</span></span>
<span><span> return</span><span> (x </span><span>==</span><span> 0</span><span> ||</span><span> x </span><span>==</span><span> 1</span><span>) </span><span>?</span><span> 1</span><span> :</span><span> 64</span><span> -</span><span> __builtin_clzll(x)</span><span>;</span></span>
<span><span>}</span></span>
<span></span>
<span><span>void</span><span> dev_linear_vram</span><span>(</span><span>amdgpu_t</span><span>*</span><span> dev</span><span>,</span><span> u64 phy_addr</span><span>,</span><span> size_t</span><span> size</span><span>,</span><span> void*</span><span> buf) {</span></span>
<span><span> HDB_ASSERT(</span><span>!</span><span>((phy_addr </span><span>&amp;</span><span> 3</span><span>) </span><span>||</span><span> (size </span><span>&amp;</span><span> 3</span><span>))</span><span>,</span><span> "Must be page aligned address and size"</span><span>)</span><span>;</span></span>
<span></span>
<span><span> size_t</span><span> offset </span><span>=</span><span> lseek(</span><span>dev</span><span>-&gt;</span><span>vram_fd</span><span>,</span><span> phy_addr</span><span>,</span><span> SEEK_SET)</span><span>;</span></span>
<span><span> HDB_ASSERT(offset </span><span>==</span><span> phy_addr</span><span>,</span><span> "Couldn't seek to the requested addr"</span><span>)</span><span>;</span></span>
<span></span>
<span><span> offset </span><span>=</span><span> read(</span><span>dev</span><span>-&gt;</span><span>vram_fd</span><span>,</span><span> buf</span><span>,</span><span> size)</span><span>;</span></span>
<span><span> HDB_ASSERT(offset </span><span>==</span><span> size</span><span>,</span><span> "Couldn't read the full requested size"</span><span>)</span><span>;</span></span>
<span><span>}</span></span>
<span></span>
<span><span>void</span><span> dev_decode</span><span>(</span><span>amdgpu_t</span><span>*</span><span> dev</span><span>,</span><span> u32 vmid</span><span>,</span><span> u64 va_addr) {</span></span>
<span><span> reg_gcmc_vm_fb_location_base_t</span><span> fb_base_reg   </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> reg_gcmc_vm_fb_location_top_t</span><span>  fb_top_reg    </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> reg_gcmc_vm_fb_offset_t</span><span>        fb_offset_reg </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span></span>
<span><span> regs2_ioc_data_t</span><span> ioc_data </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> dev_op_reg32(</span></span>
<span><span>   dev</span><span>,</span><span> REG_GCMC_VM_FB_LOCATION_BASE</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_READ</span><span>,</span><span> &amp;</span><span>fb_base_reg</span><span>.</span><span>raw)</span><span>;</span></span>
<span><span> dev_op_reg32(dev</span><span>,</span><span> REG_GCMC_VM_FB_LOCATION_TOP</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_READ</span><span>,</span><span> &amp;</span><span>fb_top_reg</span><span>.</span><span>raw)</span><span>;</span></span>
<span><span> dev_op_reg32(dev</span><span>,</span><span> REG_GCMC_VM_FB_OFFSET</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_READ</span><span>,</span><span> &amp;</span><span>fb_offset_reg</span><span>.</span><span>raw)</span><span>;</span></span>
<span></span>
<span><span> u64 fb_offset </span><span>=</span><span> (u64)</span><span>fb_offset_reg</span><span>.</span><span>fb_offset;</span></span>
<span></span>
<span><span> // TODO(hadi): add zfb mode support</span></span>
<span><span> bool</span><span> zfb </span><span>=</span><span> fb_top_reg</span><span>.</span><span>fb_top </span><span>+</span><span> 1</span><span> &lt;</span><span> fb_base_reg</span><span>.</span><span>fb_base;</span></span>
<span><span> HDB_ASSERT(</span><span>!</span><span>zfb</span><span>,</span><span> "ZFB mode is not implemented yet!"</span><span>)</span><span>;</span></span>
<span></span>
<span><span> // printf(</span></span>
<span><span> //   "fb base: 0x%x\nfb_top: 0x%x\nfb_offset: 0x%x\n",</span></span>
<span><span> //   fb_base_reg.raw,</span></span>
<span><span> //   fb_top_reg.raw,</span></span>
<span><span> //   fb_offset_reg.raw);</span></span>
<span></span>
<span><span> gc_11_reg_t</span><span> pt_start_lo_id </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> gc_11_reg_t</span><span> pt_start_hi_id </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> gc_11_reg_t</span><span> pt_end_lo_id   </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> gc_11_reg_t</span><span> pt_end_hi_id   </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> gc_11_reg_t</span><span> pt_base_hi_id  </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> gc_11_reg_t</span><span> pt_base_lo_id  </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> gc_11_reg_t</span><span> ctx_cntl_id    </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span></span>
<span><span> switch</span><span> (vmid) {</span></span>
<span><span> case</span><span> 0</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT0_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT0_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT0_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT0_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT0_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT0_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT0_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 1</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT1_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT1_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT1_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT1_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT1_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT1_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT1_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 2</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT2_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT2_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT2_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT2_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT2_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT2_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT2_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 3</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT3_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT3_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT3_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT3_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT3_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT3_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT3_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 4</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT4_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT4_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT4_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT4_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT4_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT4_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT4_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 5</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT5_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT5_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT5_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT5_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT5_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT5_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT5_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 6</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT6_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT6_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT6_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT6_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT6_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT6_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT6_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 7</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT7_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT7_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT7_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT7_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT7_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT7_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT7_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 8</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT8_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT8_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT8_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT8_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT7_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT7_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT7_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 9</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT9_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT9_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT9_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT9_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT7_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT7_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT7_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 10</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT10_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT10_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT10_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT10_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT10_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT10_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT10_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 11</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT11_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT11_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT11_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT11_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT11_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT11_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT11_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 12</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT12_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT12_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT12_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT12_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT12_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT12_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT12_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 13</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT13_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT13_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT13_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT13_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT13_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT13_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT13_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 14</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT14_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT14_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT14_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT14_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT14_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT14_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT14_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> case</span><span> 15</span><span>:</span></span>
<span><span>  pt_start_lo_id </span><span>=</span><span> REG_GCVM_CONTEXT15_PAGE_TABLE_START_ADDR_LO32;</span></span>
<span><span>  pt_start_hi_id </span><span>=</span><span> REG_GCVM_CONTEXT15_PAGE_TABLE_START_ADDR_HI32;</span></span>
<span><span>  pt_end_lo_id   </span><span>=</span><span> REG_GCVM_CONTEXT15_PAGE_TABLE_END_ADDR_LO32;</span></span>
<span><span>  pt_end_hi_id   </span><span>=</span><span> REG_GCVM_CONTEXT15_PAGE_TABLE_END_ADDR_HI32;</span></span>
<span><span>  pt_base_lo_id  </span><span>=</span><span> REG_GCVM_CONTEXT15_PAGE_TABLE_BASE_ADDR_LO32;</span></span>
<span><span>  pt_base_hi_id  </span><span>=</span><span> REG_GCVM_CONTEXT15_PAGE_TABLE_BASE_ADDR_HI32;</span></span>
<span><span>  ctx_cntl_id    </span><span>=</span><span> REG_GCVM_CONTEXT15_CNTL;</span></span>
<span><span>  break</span><span>;</span></span>
<span><span> default</span><span>:</span><span> HDB_ASSERT</span><span>(</span><span>false</span><span>,</span><span> "Out of range VMID 0-15 trying to access </span><span>%u</span><span>"</span><span>,</span><span> vmid);</span></span>
<span><span> }</span></span>
<span></span>
<span><span> // all the types of the contexts are the same so will just use 0 but pass the correct</span></span>
<span><span> // register enum to the read function</span></span>
<span><span> reg_gcvm_context0_page_table_start_addr_lo32_t</span><span> pt_start_lo </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> reg_gcvm_context0_page_table_start_addr_hi32_t</span><span> pt_start_hi </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> reg_gcvm_context0_page_table_end_addr_lo32_t</span><span>   pt_end_lo   </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> reg_gcvm_context0_page_table_end_addr_hi32_t</span><span>   pt_end_hi   </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> reg_gcvm_context0_page_table_base_addr_lo32_t</span><span>  pt_base_lo  </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> reg_gcvm_context0_page_table_base_addr_hi32_t</span><span>  pt_base_hi  </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> reg_gcvm_context0_cntl_t</span><span>                       ctx_cntl    </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span></span>
<span><span> dev_op_reg32(dev</span><span>,</span><span> pt_start_lo_id</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_READ</span><span>,</span><span> &amp;</span><span>pt_start_lo</span><span>.</span><span>raw)</span><span>;</span></span>
<span><span> dev_op_reg32(dev</span><span>,</span><span> pt_start_hi_id</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_READ</span><span>,</span><span> &amp;</span><span>pt_start_hi</span><span>.</span><span>raw)</span><span>;</span></span>
<span><span> dev_op_reg32(dev</span><span>,</span><span> pt_end_lo_id</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_READ</span><span>,</span><span> &amp;</span><span>pt_end_lo</span><span>.</span><span>raw)</span><span>;</span></span>
<span><span> dev_op_reg32(dev</span><span>,</span><span> pt_end_hi_id</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_READ</span><span>,</span><span> &amp;</span><span>pt_end_hi</span><span>.</span><span>raw)</span><span>;</span></span>
<span><span> dev_op_reg32(dev</span><span>,</span><span> pt_base_lo_id</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_READ</span><span>,</span><span> &amp;</span><span>pt_base_lo</span><span>.</span><span>raw)</span><span>;</span></span>
<span><span> dev_op_reg32(dev</span><span>,</span><span> pt_base_hi_id</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_READ</span><span>,</span><span> &amp;</span><span>pt_base_hi</span><span>.</span><span>raw)</span><span>;</span></span>
<span><span> dev_op_reg32(dev</span><span>,</span><span> ctx_cntl_id</span><span>,</span><span> ioc_data</span><span>,</span><span> REG_OP_READ</span><span>,</span><span> &amp;</span><span>ctx_cntl</span><span>.</span><span>raw)</span><span>;</span></span>
<span></span>
<span><span> u64 pt_start_addr </span><span>=</span><span> ((u64)</span><span>pt_start_lo</span><span>.</span><span>raw </span><span>&lt;&lt;</span><span> 12</span><span>) </span><span>|</span><span> ((u64)</span><span>pt_start_hi</span><span>.</span><span>raw </span><span>&lt;&lt;</span><span> 44</span><span>);</span></span>
<span><span> u64 pt_end_addr   </span><span>=</span><span> ((u64)</span><span>pt_end_lo</span><span>.</span><span>raw </span><span>&lt;&lt;</span><span> 12</span><span>) </span><span>|</span><span> ((u64)</span><span>pt_end_hi</span><span>.</span><span>raw </span><span>&lt;&lt;</span><span> 44</span><span>);</span></span>
<span><span> u64 pt_base_addr  </span><span>=</span><span> ((u64)</span><span>pt_base_lo</span><span>.</span><span>raw </span><span>&lt;&lt;</span><span> 0</span><span>) </span><span>|</span><span> ((u64)</span><span>pt_base_hi</span><span>.</span><span>raw </span><span>&lt;&lt;</span><span> 32</span><span>);</span></span>
<span><span> u32 pt_depth      </span><span>=</span><span> ctx_cntl</span><span>.</span><span>page_table_depth;</span></span>
<span><span> u32 ptb_size      </span><span>=</span><span> ctx_cntl</span><span>.</span><span>page_table_block_size;</span></span>
<span></span>
<span><span> HDB_ASSERT(pt_base_addr </span><span>!=</span><span> 0x</span><span>ffffffffffffffff</span><span>ull</span><span>,</span><span> "Invalid page table base addr"</span><span>)</span><span>;</span></span>
<span></span>
<span><span> printf(</span></span>
<span><span>   "\tPage Table Start: 0x</span><span>%lx</span><span>\n\tPage Table End: 0x</span><span>%lx</span><span>\n\tPage Table Base: "</span></span>
<span><span>   "0x</span><span>%lx</span><span>\n\tPage Table Depth: </span><span>%u</span><span>\n\tBlock Size: </span><span>%u</span><span>\n"</span><span>,</span></span>
<span><span>   pt_start_addr</span><span>,</span></span>
<span><span>   pt_end_addr</span><span>,</span></span>
<span><span>   pt_base_addr</span><span>,</span></span>
<span><span>   pt_depth</span><span>,</span></span>
<span><span>   ptb_size)</span><span>;</span></span>
<span></span>
<span><span> // decode base PDB</span></span>
<span><span> pde_t</span><span> pde </span><span>=</span><span> decode_pde(pt_base_addr)</span><span>;</span></span>
<span><span> pt_base_addr </span><span>-=</span><span> fb_offset </span><span>*</span><span> !</span><span>pde</span><span>.</span><span>system;</span><span> // substract only on vram</span></span>
<span></span>
<span><span> u64 pt_last_byte_addr </span><span>=</span><span> pt_end_addr </span><span>+</span><span> 0x</span><span>fff</span><span>;</span><span> // 0xfff is 1 page</span></span>
<span><span> HDB_ASSERT(</span></span>
<span><span>   pt_start_addr </span><span>&lt;=</span><span> va_addr </span><span>||</span><span> va_addr </span><span>&lt;</span><span> pt_last_byte_addr</span><span>,</span></span>
<span><span>   "Invalid virtual address outside the range of the root page table of this vm"</span><span>)</span><span>;</span></span>
<span></span>
<span><span> va_addr </span><span>-=</span><span> pt_start_addr;</span></span>
<span><span> //</span></span>
<span><span> // Size of the first PDB depends on the total coverage of the</span></span>
<span><span> // page table and the PAGE_TABLE_BLOCK_SIZE.</span></span>
<span><span> // Entire table takes ceil(log2(total_vm_size)) bits</span></span>
<span><span> // All PDBs except the first one take 9 bits each</span></span>
<span><span> // The PTB covers at least 2 MiB (21 bits)</span></span>
<span><span> // And PAGE_TABLE_BLOCK_SIZE is log2(num 2MiB ranges PTB covers)</span></span>
<span><span> // As such, the formula for the size of the first PDB is:</span></span>
<span><span> //                       PDB1, PDB0, etc.      PTB covers at least 2 MiB</span></span>
<span><span> //                                        Block size can make it cover more</span></span>
<span><span> //   total_vm_bits - (9 * num_middle_pdbs) - (page_table_block_size + 21)</span></span>
<span><span> //</span></span>
<span><span> // we need the total range range here not the last byte addr like above</span></span>
<span><span> u32 total_vaddr_bits </span><span>=</span><span> log2_range_round_up(pt_start_addr</span><span>,</span><span> pt_end_addr </span><span>+</span><span> 0x</span><span>1000</span><span>)</span><span>;</span></span>
<span></span>
<span><span> u32 total_pdb_bits </span><span>=</span><span> total_vaddr_bits;</span></span>
<span><span> // substract everything from the va_addr to leave just the pdb bits</span></span>
<span><span> total_pdb_bits </span><span>-=</span><span> 9</span><span> *</span><span> (pt_depth </span><span>-</span><span> 1</span><span>);</span><span> // middle PDBs each is 9 bits</span></span>
<span><span> total_pdb_bits </span><span>-=</span><span> (ptb_size </span><span>+</span><span> 21</span><span>);</span><span>    // at least 2mb(21) bits + ptb_size</span></span>
<span></span>
<span><span> // u64 va_mask = (1ull &lt;&lt; total_pdb_bits) - 1;</span></span>
<span><span> // va_mask &lt;&lt;= (total_vaddr_bits - total_pdb_bits);</span></span>
<span></span>
<span><span> // pde_t pdes[8]  = { 0 };</span></span>
<span><span> // u32   curr_pde = 0;</span></span>
<span><span> // u64   pde_addr = 0;</span></span>
<span><span> // u64  loop_pde = pt_base_addr;</span></span>
<span></span>
<span><span> if</span><span> (pt_depth </span><span>==</span><span> 0</span><span>) { </span><span>HDB_ASSERT(</span><span>false</span><span>,</span><span> "DEPTH = 0 is not implemented yet"</span><span>)</span><span>; }</span></span>
<span></span>
<span><span> pde_t</span><span> curr_pde    </span><span>=</span><span> pde;</span></span>
<span><span> u64   entry_bits  </span><span>=</span><span> 0</span><span>;</span></span>
<span><span> s32   curr_depth  </span><span>=</span><span> pt_depth;</span></span>
<span><span> bool</span><span>  pde0_is_pte </span><span>=</span><span> false</span><span>;</span></span>
<span><span> // walk all middle PDEs</span></span>
<span><span> while</span><span> (curr_depth </span><span>&gt;</span><span> 0</span><span>) {</span></span>
<span><span>  // printf("pde(%u):0x%lx \n", curr_depth, curr_pde.pte_base_addr);</span></span>
<span><span>  u64 next_entry_addr </span><span>=</span><span> 0</span><span>;</span></span>
<span></span>
<span><span>  u32 shift_amount </span><span>=</span><span> total_vaddr_bits;</span></span>
<span><span>  shift_amount </span><span>-=</span><span> total_pdb_bits;</span></span>
<span><span>  // for each pdb shift 9 more</span></span>
<span><span>  shift_amount </span><span>-=</span><span> ((pt_depth </span><span>-</span><span> curr_depth) </span><span>*</span><span> 9</span><span>);</span></span>
<span></span>
<span><span>  // shift address and mask out unused bits</span></span>
<span><span>  u64 next_pde_idx </span><span>=</span><span> va_addr </span><span>&gt;&gt;</span><span> shift_amount;</span></span>
<span><span>  next_pde_idx </span><span>&amp;=</span><span> 0x</span><span>1ff</span><span>;</span></span>
<span></span>
<span><span>  // if on vram we need to apply this offset</span></span>
<span><span>  if</span><span> (</span><span>!</span><span>curr_pde</span><span>.</span><span>system) </span><span>curr_pde</span><span>.</span><span>pte_base_addr </span><span>-=</span><span> fb_offset;</span></span>
<span></span>
<span><span>  next_entry_addr </span><span>=</span><span> curr_pde</span><span>.</span><span>pte_base_addr </span><span>+</span><span> next_pde_idx </span><span>*</span><span> 8</span><span>;</span></span>
<span><span>  curr_depth</span><span>--</span><span>;</span></span>
<span></span>
<span><span>  if</span><span> (</span><span>!</span><span>curr_pde</span><span>.</span><span>system) {</span></span>
<span><span>   dev_linear_vram(dev</span><span>,</span><span> next_entry_addr</span><span>,</span><span> 8</span><span>,</span><span> &amp;</span><span>entry_bits)</span><span>;</span></span>
<span><span>   curr_pde </span><span>=</span><span> decode_pde(entry_bits)</span><span>;</span></span>
<span><span>   printf(</span></span>
<span><span>     "\tPage Dir Entry(</span><span>%u</span><span>):\n\t  Addr:0x</span><span>%lx</span><span>\n\t  Base: 0x</span><span>%lx</span><span>\n\n\t        ↓\n\n"</span><span>,</span></span>
<span><span>     curr_depth</span><span>,</span></span>
<span><span>     next_entry_addr</span><span>,</span></span>
<span><span>     curr_pde</span><span>.</span><span>pte_base_addr)</span><span>;</span></span>
<span><span>  } </span><span>else</span><span> {</span></span>
<span><span>   HDB_ASSERT(</span><span>false</span><span>,</span><span> "GTT physical memory access is not implemented yet"</span><span>)</span><span>;</span></span>
<span><span>  }</span></span>
<span></span>
<span><span>  if</span><span> (</span><span>!</span><span>curr_pde</span><span>.</span><span>valid) { </span><span>break</span><span>; }</span></span>
<span></span>
<span><span>  if</span><span> (</span><span>curr_pde</span><span>.</span><span>pte) {</span></span>
<span><span>   // PDB0 can act as a pte</span></span>
<span><span>   // also I'm making an assumption here that UMRs code doesn't make</span></span>
<span><span>   // that the the PDB0 as PTE path can't have the further bit set</span></span>
<span><span>   pde0_is_pte </span><span>=</span><span> true</span><span>;</span></span>
<span><span>   break</span><span>;</span></span>
<span><span>  }</span></span>
<span><span> }</span></span>
<span></span>
<span><span> if</span><span> (pde0_is_pte) { </span><span>HDB_ASSERT(</span><span>false</span><span>,</span><span> "PDE0 as PTE is not implemented yet"</span><span>)</span><span>; }</span></span>
<span></span>
<span><span> // page_table_block_size is the number of 2MiB regions covered by a PTB</span></span>
<span><span> // If we set it to 0, then PTB cover 2 MiB</span></span>
<span><span> // If it's 9 PTB cover 1024 MiB</span></span>
<span><span> // pde0_block_fragment_size tells us how many 4 KiB regions each PTE covers</span></span>
<span><span> // If it's 0 PTEs cover 4 KiB</span></span>
<span><span> // If it's 9 PTEs cover 2 MiB</span></span>
<span><span> // So the number of PTEs in a PTB is 2^(9+ptbs-pbfs)</span></span>
<span><span> //</span></span>
<span><span> // size here is actually the log_2 of the size</span></span>
<span><span> u32 pte_page_size  </span><span>=</span><span> curr_pde</span><span>.</span><span>frag_size;</span></span>
<span><span> u32 ptes_per_ptb   </span><span>=</span><span> 9</span><span> +</span><span> ptb_size </span><span>-</span><span> pte_page_size;</span></span>
<span><span> u64 pte_index_mask </span><span>=</span><span> (</span><span>1</span><span>ul</span><span> &lt;&lt;</span><span> ptes_per_ptb) </span><span>-</span><span> 1</span><span>;</span></span>
<span></span>
<span><span> u32 pte_bits_count   </span><span>=</span><span> pte_page_size </span><span>+</span><span> 12</span><span>;</span></span>
<span><span> u64 page_offset_mask </span><span>=</span><span> (</span><span>1</span><span>ul</span><span> &lt;&lt;</span><span> pte_bits_count) </span><span>-</span><span> 1</span><span>;</span><span> // minimum of 12</span></span>
<span></span>
<span><span> u64 pte_index </span><span>=</span><span> (va_addr </span><span>&gt;&gt;</span><span> pte_bits_count) </span><span>&amp;</span><span> pte_index_mask;</span></span>
<span><span> u64 pte_addr  </span><span>=</span><span> curr_pde</span><span>.</span><span>pte_base_addr </span><span>+</span><span> pte_index </span><span>*</span><span> 8</span><span>;</span></span>
<span></span>
<span><span> pte_t</span><span> pte </span><span>=</span><span> { </span><span>0</span><span> };</span></span>
<span><span> if</span><span> (</span><span>!</span><span>curr_pde</span><span>.</span><span>system) {</span></span>
<span><span>  dev_linear_vram(dev</span><span>,</span><span> pte_addr</span><span>,</span><span> 8</span><span>,</span><span> &amp;</span><span>entry_bits)</span><span>;</span></span>
<span><span>  pte </span><span>=</span><span> decode_pte(entry_bits)</span><span>;</span></span>
<span></span>
<span><span>  printf(</span><span>"\tPage Table Entry: 0x</span><span>%lx</span><span>\n"</span><span>,</span><span> pte</span><span>.</span><span>page_base_addr)</span><span>;</span></span>
<span><span> } </span><span>else</span><span> {</span></span>
<span><span>  HDB_ASSERT(</span><span>false</span><span>,</span><span> "GTT physical memory access is not implemented yet"</span><span>)</span><span>;</span></span>
<span><span> }</span></span>
<span></span>
<span><span> if</span><span> (</span><span>pte</span><span>.</span><span>further) { </span><span>HDB_ASSERT(</span><span>false</span><span>,</span><span> "PTE as PDE walking is not implemented yet"</span><span>)</span><span>; }</span></span>
<span><span> if</span><span> (</span><span>!</span><span>pte</span><span>.</span><span>system) </span><span>pte</span><span>.</span><span>page_base_addr </span><span>-=</span><span> fb_offset;</span></span>
<span></span>
<span><span> u64 offset_in_page </span><span>=</span><span> va_addr </span><span>&amp;</span><span> page_offset_mask;</span></span>
<span><span> u64 physical_addr  </span><span>=</span><span> pte</span><span>.</span><span>page_base_addr </span><span>+</span><span> offset_in_page;</span></span>
<span><span> printf(</span><span>"\tFinal Physical Address: 0x</span><span>%lx</span><span>\n"</span><span>,</span><span> physical_addr)</span><span>;</span></span>
<span><span>}</span></span></code></pre>
<section data-footnotes="">
<ol>
<li id="user-content-fn-1">
<p>Other processes need to have a s_trap instruction or have trap on exception flags set, which is not true for most normal GPU processes. <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="user-content-fn-2">
<p>Available since RDNA3, if I’m not mistaken. <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
<li id="user-content-fn-3">
<p>VGPRs are unique per thread, and SGPRs are unique per wave <a href="#user-content-fnref-3" data-footnote-backref="" aria-label="Back to reference 3">↩</a></p>
</li>
<li id="user-content-fn-4">
<p>We can get that by subtracting the current program counter from the address of the code buffer. <a href="#user-content-fnref-4" data-footnote-backref="" aria-label="Back to reference 4">↩</a></p>
</li>
</ol>
</section>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tsunami warning issued after 7.6-magnitude earthquake strikes Japan (133 pts)]]></title>
            <link>https://earthquake.usgs.gov/earthquakes/map/?currentFeatureId=us6000rtdt&amp;extent=-5.61599,111.26953&amp;extent=70.40735,173.14453</link>
            <guid>46193413</guid>
            <pubDate>Mon, 08 Dec 2025 15:33:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://earthquake.usgs.gov/earthquakes/map/?currentFeatureId=us6000rtdt&#x26;extent=-5.61599,111.26953&#x26;extent=70.40735,173.14453">https://earthquake.usgs.gov/earthquakes/map/?currentFeatureId=us6000rtdt&#x26;extent=-5.61599,111.26953&#x26;extent=70.40735,173.14453</a>, See on <a href="https://news.ycombinator.com/item?id=46193413">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>
          The Latest Earthquakes application supports most recent browsers,
          <a href="https://angular.io/guide/browser-support" target="_blank">view supported browsers</a>.
        </p>
        <p>
          If the application does not load, try our
          <a href="https://earthquake.usgs.gov/legacy/map/" target="_blank"> legacy Latest Earthquakes application</a>.
        </p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I successfully recreated the 1996 Space Jam website with Claude (106 pts)]]></title>
            <link>https://theahura.substack.com/p/i-successfully-recreated-the-1996</link>
            <guid>46193412</guid>
            <pubDate>Mon, 08 Dec 2025 15:33:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theahura.substack.com/p/i-successfully-recreated-the-1996">https://theahura.substack.com/p/i-successfully-recreated-the-1996</a>, See on <a href="https://news.ycombinator.com/item?id=46193412">Hacker News</a></p>
Couldn't get https://theahura.substack.com/p/i-successfully-recreated-the-1996: Error: getaddrinfo ENOTFOUND 12gramsofcarbon.com]]></description>
        </item>
    </channel>
</rss>