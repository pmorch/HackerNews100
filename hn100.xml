<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 28 Jan 2025 00:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[I trusted an LLM, now I'm on day 4 of an afternoon project (134 pts)]]></title>
            <link>https://nemo.foo/blog/day-4-of-an-afternoon-project</link>
            <guid>42845933</guid>
            <pubDate>Mon, 27 Jan 2025 21:37:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nemo.foo/blog/day-4-of-an-afternoon-project">https://nemo.foo/blog/day-4-of-an-afternoon-project</a>, See on <a href="https://news.ycombinator.com/item?id=42845933">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>TLDR - AI isn’t a co-pilot; it’s a junior dev faking competence. Trust it at your own risk.</strong></p>
<p>I’m 4 days into an afternoon project. I was so sure I’d crush this one. I had a good plan and the stoke was high. Let me introduce <em>Deskthang</em>. It’s a thang for your desk. When I work, I want to put my phone in the other room, and only get the important notifications (thangs) in a different way. If my deployment pipeline fails, I want a globe on my desk to turn red and show me a gitlab logo. I do not want to check my phone or email or anywhere a distraction might find me.</p>
<blockquote>
<p>Quick backstory: I work full time++ doing boring enterprise software dev and rarely get to flex my engineering skills. While my title says engineer, I’d disagree.</p>
</blockquote>
<h2>The Problem I’m Trying to Solve</h2>
<p>I always try to align multiple interests for a side project. I wanted to pull my electronics hardware box out of storage, I wanted to solve the notifications and focus issue for myself, and I wanted to see how scared I should be about AI taking my job. As they say, I was trying to get a few birds stoned at once.</p>
<p><img src="https://nemo.foo/blog-content/deskthang/two_birds_stoned.gif" alt=""></p>
<h3>1. I miss working with hardware.</h3>
<p>During COVID lock-downs I landed an R&amp;D contract for a IoT Prototype. That R&amp;D job was the most fulfilling work of my career. I worked with a small, scrappy team with some of my best friends. I was 3D printing models, soldering components, writing embedded C, and field-testing with mechanical engineers… Real engineers. We worked hard, often late into the night, and the collaboration felt more like playing StarCraft with the boiz than a 9-to-5. I’ve missed that deeply ever since. Recently, I’ve been inspired recently by <a href="https://x.com/_MaxBlade">@_MaxBlade and DeskHub</a> and wanted to brush the dust off my electronics skills.</p>
<h3>2. I hate the UX of MFA (Multi Factor Authentication).</h3>
<p>I use GitLab heavily for CI/CD with my personal Kubernetes projects. Knowing the status of my pipelines is crucial… broken builds could disrupt all 7 of my users! Logging into GitLab feels like getting stabbed in the spleen. Every time I log in (multiple times a day), I face captchas, authenticator apps, or waiting for email codes, followed by yet another captcha. I’ve tried pipeline notifications through Slack, Discord, and Telegram, but those apps are like productivity black holes. I don’t want my phone near me while working, or to open chat apps that derail my focus. Removing these distractions keeps me locked in.</p>
<h3>3. I want to see how good these AI tools are.</h3>
<p>I want to figure out if AI is going to take my job. I’m skeptical it can replace what I do, but I like testing my assumptions. Sometimes AI surprises me; other times, it’s just a rabbit hole of wasted hours when I avoid doing real thinking.</p>
<p>Recently, I used Claude Sonnet 3.5 to brute-force hundreds of React compile errors while upgrading a project from React 15 to 18. I threw <code>package.json</code> updates, deleted <code>node_modules</code>, and burned through a small fortune in AI tokens. To my surprise, we had a passing build by the end of the day. Work has been encouraging us to adopt an AI-first workflow and giving us unlimited tokens. It’s a wild experiment.</p>
<p>This happened on a Friday. I wiped the sweat off my brow after a hard day’s prompting, and headed home early to start on my side project…</p>
<h2>The Plan</h2>
<p>Unlike me, my wife likes to leave the house and do things. I’ve spent a few years turning my garage into my favorite place to be. My wife and I have a deal where 1 day a month, She takes the kiddo and I am absolved of all responsibilities. I get a full day to lock in and build projects. From her perspective, I order doordash and turn into a degen who is unfit to father. From my perspective, I get to enjoy my favorite place and just tinker or play games or do whatever. These are the days I get to play mad scientist and feel most like myself. I look forward to it every month. My plan was to learn zig, brush off my hardware skills, build this project, write a blog post and make a video about it. Totally achievable.</p>
<p>I wanted to wire up a Raspberry Pi Pico, a small 240x240 LCD display and some RGB LEDs. I was going to learn Zig and use it to send image data over USB to the pico which will put an image on the screen and change the LED color. I would set up webhooks from GitLab to call an API in my Kube cluster and setup my host Zig app to poll that same API for changes and send updates to the Pico. I really wanted to transmit the data over USB because I’ve never done that before. I’ve already used Bluetooth, LTE and Wifi and just wanted to do something new.</p>
<p>The wiring is simple. Common patterns I was familiar with like <a href="https://en.wikipedia.org/wiki/Serial_Peripheral_Interface">SPI (Serial Peripheral Interface)</a> for the display + some RGB leds. The <a href="https://itsfoss.com/what-is-tty-in-linux/?utm_source=chatgpt.com">TTY (TeleTYpewriter)</a> serial data port on Linux <code>/dev/ttyACM0</code> for USB communication with the Pico felt familiar because of how I had setup debug logging in the past. It looked like I had enough example repos collected that I could stitch a solution together. I did a little research each day and felt a little more sure each time. I’ve been using ChatGPT and Claude more and more to do initial research. I was at an AI hype peak and was bold enough to trust it…</p>
<p><img src="https://nemo.foo/blog-content/deskthang/excalidraw.png" alt=""></p>
<p>Since I do full stack web stuff on the daily, the api, webhooks and postgres are out of scope for the degen day. I was scoping the day’s work to Zig -&gt; Pico image transfer.</p>
<h3>1. Setup Pico</h3>
<ul>
<li>Organize the workspace</li>
<li>Find a micro usb cable that supports data and not just charging… really why are they all power only?!</li>
<li>Wire up a breadboard with Pico &amp; display and LED</li>
<li>Setup the C SDK for the raspi pico and a repo <a href="https://gitlab.com/nemofoo/deskthang">gitlab</a>, <a href="https://github.com/nemofoo/deskthang">gihub-mirror</a></li>
<li>Push a build and see logs on <code>cat /dev/ttyACM0</code></li>
</ul>
<p><img src="https://nemo.foo/blog-content/deskthang/first_assembly.jpg" alt=""></p>
<h3>2. Setup Pico Display</h3>
<ul>
<li>Put something on the screen during the boot loop.</li>
</ul>
<p><img src="https://nemo.foo/blog-content/deskthang/first_test_pattern.jpg" alt=""></p>
<p><a href="https://youtube.com/shorts/H6b64PJI40o">youtube link (12 sec)</a></p>
<h3>3. Setup Host Zig Project</h3>
<ul>
<li>Setup a host directory in repo</li>
<li>Init zig project</li>
<li>Send a message and see something on the screen</li>
</ul>
<p><a href="https://youtu.be/Y0wkzbwGWJc">youtube link (9 sec)</a></p>
<h3>4. Image Transfer</h3>
<ul>
<li>Yeet the raw rgb image data over USB</li>
<li>It’s bidirectional safe right</li>
<li>USB CDC is bidirectional safe
<ul>
<li>TTY interface is built on top of USB CDC
<ul>
<li>TTY is bidirectional safe because CDC is (no it’s not… thanks gpt)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://nemo.foo/blog-content/deskthang/gptlies.png" alt=""></p>
<blockquote>
<p>In the above image you can see the outright lie that broke me… USB CDC has separate TX (Transmit) and RX (Receive) buffers so it’s bidirectional safe. The same is not true for TTY which is bidirectional but less safe with a single buffer for TX and RX data.</p>
</blockquote>
<h2>Timeline of Actuality (AI Woes)</h2>
<p>After a dozen duds, I found a data capable usb micro cable and everything went smoothly until the image transfer. I used Claude, Cline, and ChatGPT to AI-max my way to a buggy but working implementation. I sent commands from my terminal with Zig over USB to the Pico which read them and changed the screen. This only took a few hours and I was excited that the AI assisted dream was real. It’s not complex but I think it was faster than I could have done alone. I have no experience with zig besides hearing ThePrimeagen yap about it. I haven’t even read the docs.</p>
<p>Multiple times, I found myself stopping Cline from starting completely new implementations of already solved issues. I didn’t catch everything though. When Cline blew through my API limits, I added Claude to my harem and ran both in parallel when possible.</p>
<blockquote>
<p>As I look through the code now, I realize that I’m lousy at multitasking and was gaslighting myself.</p>
</blockquote>
<h3>The Image Transfer Disaster</h3>
<p>This is where my hubris came into play. In my mind, I pictured sending all the image data in one go, like an S3 upload. I imagined clean, raw data streaming over <code>/dev/ttyACM0</code>. It wasn’t clean. It wasn’t raw. It was chaos.</p>
<p>I expected to see:</p>
<pre><code>pico - heartbeat
zig - start image transfer
zig - [240x240 COLOR PIXELS]
zig - end image transfer
pico - heartbeat
</code></pre>
<p>What I actually saw looked like this, but worse:</p>
<pre><code>pico - heartbeat
zig - start ima%
pico - heage transfert
pico - heartbeat
zig - [240x240 COL
pico - heartbea
OR PIXELtS]
pico - heartbeat
zig - end image transfer
pico - heartbeat
</code></pre>
<p><a href="https://youtu.be/jnmqlsdD6oU">It’s just like that interrupting cow knock knock joke.</a> Completely unfunny and day ruining.</p>
<p><strong>Key Problems:</strong></p>
<p><strong>1. Buffer Conflicts:</strong> <code>/dev/ttyACM0</code> was the battlefield. The same buffer was used for both logging and image transfer. If a log slipped in during the data stream… well good luck figuring out what the hell just happened.</p>
<p><strong>2. Noise:</strong> Some weird corruption was happening. Maybe I wasn’t clearing buffers properly. Maybe the gods of USB communication just hate me.</p>
<p>The bottom line? Neither the Pico nor my laptop could trust the data. Each system needed to learn to yield, and I needed to build the round-a-bout to force them to be polite and wait their turn.</p>
<h3>Packets, Protocols &amp; State Machines, Oh my…</h3>
<p>I needed to get serious. So, naturally, I let Claude write some docs:</p>
<ul>
<li>Detailed a packet shape.</li>
<li>Documented a checksum verification plan.</li>
<li>Described data format for transfer.</li>
<li>Denoted how to chunk and rebuild the image.</li>
<li>Depicted the state machine transitions.</li>
<li>Demonstrated command system.</li>
<li>Designed a logging system that doesn’t break incoming commands.</li>
</ul>
<p>After delving down dem docs, I let AI run with the actual implementations. At this point, my “degen hat” came off, and I resumed my dad duties while letting Cursor and Cline play StarCraft with my codebase. This is the dream use case for AI, right? Just let it rip and come back to a perfectly functioning system. Let’s see just how close we get to the sun.</p>
<p>Reality Check: AI tools are like interns who know how to Google really fast but don’t understand context. Cursor started changing core implementations for unrelated edits. Cline would randomly rewrite half the system without asking. By the time I noticed, my codebase looked like the aftermath of a spaghetti fight at a junior developer convention. Most of the codebase was actually unreachable.</p>
<h2>What did I learn?</h2>
<p>Like Icarus, my codebase is irrecoverable. A tangled heap of wing fragments and melted wax, dripping with half-baked ideas and unsupervised AI chaos. My grand vision of outsourcing grunt work to AI had sent me soaring, but the sun of reality burned away any hope of landing gracefully. Here’s what I’m taking away from this flaming descent.</p>
<h3>1. AI is a tool, not a co-pilot</h3>
<p>AI is great for generating ideas or drafting code, but it doesn’t understand. It’s like giving a junior developer a chainsaw instead of a scalpel—it might finish the job, but you’ll spend twice as long cleaning up the mess. I learned that I need to stay firmly in the driver’s seat when tackling new tech.</p>
<h3>2. Friction forces focus</h3>
<p>Having AI directly in my editor felt like playing with infinite cheat codes. It was too easy to let it run wild and harder to maintain control. Moving forward, I’m introducing deliberate friction. I will be using AI only in web interfaces or as a brainstorming tool. If I have to paste its suggestions into my code manually, I’ll be more mindful of the process and less likely to reach for it.</p>
<h3>3. Mistakes teach better than shortcuts</h3>
<p>When I make mistakes, I learn. Debugging my own failures has always been one of the best ways to understand a new language or concept. Relying on AI to “fix” things for me short-circuited that learning process. As a result, I’m left with no deeper understanding of Zig than when I started.</p>
<h3>4. Patience beats hubris</h3>
<p>Building something new, with unfamiliar tools takes time. The idea that I could fully implement my vision in a single “degen day” was overly optimistic, bordering on foolish. Sometimes, you have to respect the complexity of what you’re trying to achieve.</p>
<h2>Moving Forward</h2>
<p>Deskthang has grown from a casual afternoon project into a saga of overconfidence, AI misadventures, and lessons learned the hard way. For now, I’m shelving the AI driven shortcuts and committing to a rewrite on my next no-responsibilities day.</p>
<p>I’ve picked up a pen and started writing docs by hand like it’s the stone age. I plan to work through some Advent of Code problems in Zig to actually learn the language before taking another crack at this project.</p>
<p>Want to see if Deskthang ever works, or just enjoy the chaos as I fail forward? Subscribe below for a monthly email drop of my latest misadventures and skill issues. Together, we’ll learn how to coexist with AI, relearn the lessons I forget, and hopefully build something worthwhile in the process.</p>
<p>LFG 🚀</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nvidia sheds almost $600B in market cap, biggest one-day loss in US history (221 pts)]]></title>
            <link>https://www.cnbc.com/2025/01/27/nvidia-sheds-almost-600-billion-in-market-cap-biggest-drop-ever.html</link>
            <guid>42845681</guid>
            <pubDate>Mon, 27 Jan 2025 21:13:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/01/27/nvidia-sheds-almost-600-billion-in-market-cap-biggest-drop-ever.html">https://www.cnbc.com/2025/01/27/nvidia-sheds-almost-600-billion-in-market-cap-biggest-drop-ever.html</a>, See on <a href="https://news.ycombinator.com/item?id=42845681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="SpecialReportArticle-ArticleBody-6" data-module="ArticleBody" data-test="articleBody-2" data-analytics="SpecialReportArticle-articleBody-6-2"><div id="ArticleBody-InlineImage-108082997" data-test="InlineImage"><p>Nvidia CEO Jensen Huang holds a Blackwell GeForce RTX 50 Series GPU (L) and a RTX 5000 laptop as he delivers a keynote address at the Consumer Electronics Show (CES) in Las Vegas, Nevada on January 6, 2025.&nbsp;</p><p>Patrick T. Fallon | Afp | Getty Images</p></div><div><p><span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/NVDA/">Nvidia</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> lost close to $600 billion in market cap on Monday, the biggest drop for any company on a single day in U.S. history.</p><p>The chipmaker's stock price plummeted 17% to close at $118.58. It was Nvidia's worst day on the market since March 16, 2020, which was early in the Covid pandemic. After <a href="https://www.cnbc.com/2025/01/21/nvidia-passes-apple-again-to-become-worlds-most-valuable-company-.html">Nvidia surpassed</a> <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-3"><a href="https://www.cnbc.com/quotes/AAPL/">Apple</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> last week to become the most valuable publicly traded company, the stock's drop Monday led a 3.1% slide in the tech-heavy Nasdaq.</p><p>The sell-off was <a href="https://www.cnbc.com/2025/01/27/nvidia-falls-10percent-in-premarket-trading-as-chinas-deepseek-triggers-global-tech-sell-off.html">sparked</a> by concerns that Chinese <a href="https://www.cnbc.com/ai-artificial-intelligence/">artificial intelligence</a> lab DeepSeek is presenting increased competition in the global AI battle. In late December, <a href="https://www.cnbc.com/2025/01/24/how-chinas-new-ai-model-deepseek-is-threatening-us-dominance.html">DeepSeek unveiled</a> a free, open-source large language model that <a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf" target="_blank">it&nbsp;said</a>&nbsp;took only two months and less than $6 million to build, using reduced-capability chips from&nbsp;<a href="https://www.cnbc.com/quotes/NVDA/">Nvidia</a>&nbsp;called H800s.&nbsp;</p><p>Nvidia's graphics processing units, or GPUs, dominate the market for AI data center chips in the U.S., with tech giants such as <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-9"><a href="https://www.cnbc.com/quotes/GOOGL/">Alphabet</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>, <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-10"><a href="https://www.cnbc.com/quotes/META/">Meta</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> and <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-11"><a href="https://www.cnbc.com/quotes/AMZN/">Amazon</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> spending billions of dollars on the processors to train and run their AI models. </p><p>Analysts at Cantor wrote in a report Monday that the release of DeepSeek's latest technology has caused "great angst as to the impact for compute demand, and therefore, fears of peak spending on GPUs."</p></div><div id="SpecialReportArticle-RelatedContent-1"><h2>Read more DeepSeek coverage</h2><div><ul><li><a href="https://www.cnbc.com/2025/01/27/chinas-deepseek-ai-tops-chatgpt-app-store-what-you-should-know.html">China's DeepSeek AI dethrones ChatGPT on App Store</a></li><li><a href="https://www.cnbc.com/2025/01/27/deepseek-hit-with-large-scale-cyberattack-says-its-limiting-registrations.html">DeepSeek hit with large-scale cyberattack, says it's limiting registrations</a></li><li><a href="https://www.cnbc.com/2025/01/24/how-chinas-new-ai-model-deepseek-is-threatening-us-dominance.html">How China's new AI model DeepSeek is threatening U.S. dominance</a></li><li><a href="https://www.cnbc.com/2025/01/27/nvidia-falls-10percent-in-premarket-trading-as-chinas-deepseek-triggers-global-tech-sell-off.html">Nvidia hits new low for session on threat from DeepSeek AI model</a></li><li><a href="https://www.cnbc.com/2025/01/27/how-the-buzz-around-chinese-ai-model-deepseek-sparked-a-massive-nasdaq-sell-off.html">Buzz around Chinese AI model DeepSeek sparks massive Nasdaq sell-off</a></li><li><a href="https://www.cnbc.com/2025/01/27/the-key-chart-levels-to-watch-on-nvidia-tech-stocks-on-deepseek-fear.html">Pro: The key chart levels to watch on Nvidia and other tech stocks amid DeepSeek rout</a></li></ul></div></div><div><p>The analysts said they "think this view is farthest from the truth" and that advancements in AI will most likely lead to "the AI industry wanting more compute, not less." They recommend buying Nvidia shares.</p><p>But after Nvidia's huge run-up — the stock soared 239% in <a href="https://www.cnbc.com/2023/05/30/nvidia-on-track-to-hit-1-trillion-market-cap-when-market-opens.html">2023</a> and 171% in <a href="https://www.cnbc.com/2024/12/25/ai-crypto-top-tech-stocks-applovin-microstrategy-palantir-nvidia.html">2024</a> — the market is on edge about any possible pullback in spending. <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-14"><a href="https://www.cnbc.com/quotes/AVGO/">Broadcom</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>, the other big U.S. chipmaker to see giant valuation gains from AI, fell 17% on Monday, pulling its market cap down by $200 billion.</p><p>Data center companies reliant on Nvidia's GPUs for their hardware sales saw big sell-offs as well. <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-15"><a href="https://www.cnbc.com/quotes/DELL/">Dell</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>, <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-16"><a href="https://www.cnbc.com/quotes/HPE/">Hewlett Packard Enterprise</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> and <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-17"><a href="https://www.cnbc.com/quotes/SMCI/">Super Micro Computer</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> dropped at least 5.8%. <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-18"><a href="https://www.cnbc.com/quotes/ORCL/">Oracle</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>, a part of President<a href="https://www.cnbc.com/donald-trump/"> Donald Trump's</a> latest AI initiative, fell 14%.</p><p>For Nvidia, the loss was more than <a href="https://www.cnbc.com/2024/09/04/asian-chip-stocks-fall-after-nvidia-sell-off-on-wall-street-overnight.html">double the $279 billion drop</a> the company saw in September, which was the biggest one-day market value loss in history at the time, unseating Meta's <a href="https://www.cnbc.com/2022/02/03/facebooks-232billion-drop-in-value-sets-all-time-record.html">$232 billion loss</a> in 2022. Before that, the steepest drop was $182 billion by Apple in 2020.</p><p>Nvidia's decline is more than double the market cap of <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-22"><a href="https://www.cnbc.com/quotes/KO/">Coca-Cola</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> and <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-23"><a href="https://www.cnbc.com/quotes/CVX/">Chevron</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> and exceeds the market value of both Oracle and <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-24"><a href="https://www.cnbc.com/quotes/NFLX/">Netflix</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>.</p><p>CEO Jensen Huang's net worth also took a massive hit, declining roughly $21 billion, according to <a href="https://www.forbes.com/real-time-billionaires/#458f33ab3d78" target="_blank">Forbes' real-time billionaires list</a>. The move demoted Huang to 17th on the richest-person list.</p><p>The sudden excitement around DeepSeek over the weekend pushed its app <a href="https://www.cnbc.com/2025/01/27/chinas-deepseek-ai-tops-chatgpt-app-store-what-you-should-know.html">past OpenAI's ChatGPT</a> as the most-downloaded free app in the U.S. on Apple's app store. The model's development comes despite a slew of recent curbs on U.S. chip exports to China.</p><p>Venture capitalist David Sacks, who was <a href="https://www.cnbc.com/2024/12/05/trump-david-sacks-billionaire-ai-crypto.html">tapped</a> by Trump to be the White House's AI and crypto czar, <a href="https://x.com/DavidSacks/status/1883935713877782884" target="_blank">wrote on X</a> that DeepSeek's model "shows that the AI race will be very competitive" and that Trump was right to rescind President <a href="https://www.cnbc.com/video/2019/04/25/joe-biden-enters-2020-presidential-race.html">Joe Biden</a>'s executive order last week on AI safety.</p><p>"I'm confident in the U.S. but we can't be complacent," Sacks wrote.</p><p>Nvidia is now the third most-valuable public company, behind Apple and <span data-test="QuoteInBody" id="SpecialReportArticle-QuoteInBody-30"><a href="https://www.cnbc.com/quotes/MSFT/">Microsoft</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>.</p><p><strong>WATCH:</strong> <a href="https://www.cnbc.com/video/2025/01/27/pro-watch-cnbcas-full-interview-with-bernsteins-stacy-rasgon-trivariateas-adam-parker-and-payne-capitalas-courtney-garcia.html">CNBC's full interview with Bernstein's Stacy Rasgon</a></p></div><div id="Placeholder-ArticleBody-Video-108093000" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000364746" aria-labelledby="Placeholder-ArticleBody-Video-108093000"><p><img src="https://image.cnbcfm.com/api/v1/image/108093001-17380094731738009466-38180086461-1080pnbcnews.jpg?v=1738009472&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Watch CNBC’s full interview with Bernstein's Stacy Rasgon, Trivariate’s Adam Parker and Payne Capital’s Courtney Garcia"></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Illustrated DeepSeek-R1 (163 pts)]]></title>
            <link>https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1</link>
            <guid>42845488</guid>
            <pubDate>Mon, 27 Jan 2025 20:51:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1">https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1</a>, See on <a href="https://news.ycombinator.com/item?id=42845488">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em><span>[Draft post, updates to come, please let me know if you have any suggestions or feedback here or on </span><a href="https://bsky.app/profile/jayalammar.bsky.social" rel="">Bluesky</a><span> or </span><a href="https://x.com/JayAlammar" rel="">X/Twitter</a><span>]</span></em></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98138856-a4de-45e3-ad08-1434378127c2_1130x408.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98138856-a4de-45e3-ad08-1434378127c2_1130x408.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98138856-a4de-45e3-ad08-1434378127c2_1130x408.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98138856-a4de-45e3-ad08-1434378127c2_1130x408.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98138856-a4de-45e3-ad08-1434378127c2_1130x408.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98138856-a4de-45e3-ad08-1434378127c2_1130x408.png" width="1130" height="408" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/98138856-a4de-45e3-ad08-1434378127c2_1130x408.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:408,&quot;width&quot;:1130,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98138856-a4de-45e3-ad08-1434378127c2_1130x408.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98138856-a4de-45e3-ad08-1434378127c2_1130x408.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98138856-a4de-45e3-ad08-1434378127c2_1130x408.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F98138856-a4de-45e3-ad08-1434378127c2_1130x408.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>DeepSeek-R1 is the latest resounding beat in the steady drumroll of AI progress. For the ML R&amp;D community, it is a major release for reasons including: </p><ol><li><p>It is an open weights model with smaller, distilled versions and </p></li><li><p>It shares and reflects upon a training method to reproduce a reasoning model like OpenAI O1. </p></li></ol><p>In this post, we’ll see how it was built.</p><p>Contents:</p><ul><li><p>Recap: How LLMs are trained</p></li><li><p>DeepSeek-R1 Training Recipe</p></li><li><p>1- Long chains of reasoning SFT Data</p></li><li><p>2- An interim high-quality reasoning LLM (but worse at non-reasoning tasks).</p></li><li><p>3- Creating reasoning models with large-scale reinforcement learning (RL) </p><ul><li><p>3.1- Large-Scale Reasoning-Oriented Reinforcement Learning (R1-Zero)</p></li><li><p>3.2- Creating SFT reasoning data with the interim reasoning model</p></li><li><p>3.3- General RL training phase </p></li></ul></li><li><p>Architecture</p></li></ul><p><span>Most of the foundational knowledge you need to understand how such a model works is available in our book, </span><a href="https://github.com/handsOnLLM/Hands-On-Large-Language-Models" rel="">Hands-On Large Language Models</a><span>.</span></p><p>Just like most existing LLMs, DeepSeek-R1 generates one token at a time, except it excels at solving math and reasoning problems because it is able to spend more time processing a problem through the process of generating thinking tokens that explain its chain of thought.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5280089e-8989-45d7-8194-93396b25557d_613x152.gif" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5280089e-8989-45d7-8194-93396b25557d_613x152.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5280089e-8989-45d7-8194-93396b25557d_613x152.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5280089e-8989-45d7-8194-93396b25557d_613x152.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5280089e-8989-45d7-8194-93396b25557d_613x152.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5280089e-8989-45d7-8194-93396b25557d_613x152.gif" width="613" height="152" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5280089e-8989-45d7-8194-93396b25557d_613x152.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:152,&quot;width&quot;:613,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3441758,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/gif&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5280089e-8989-45d7-8194-93396b25557d_613x152.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5280089e-8989-45d7-8194-93396b25557d_613x152.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5280089e-8989-45d7-8194-93396b25557d_613x152.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5280089e-8989-45d7-8194-93396b25557d_613x152.gif 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The following figure, from Chapter 12 of our book shows the general recipe of creating a high-quality LLM over three steps:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa354473-6ae0-4ae7-a20c-e858c804d6c4_1600x477.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa354473-6ae0-4ae7-a20c-e858c804d6c4_1600x477.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa354473-6ae0-4ae7-a20c-e858c804d6c4_1600x477.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa354473-6ae0-4ae7-a20c-e858c804d6c4_1600x477.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa354473-6ae0-4ae7-a20c-e858c804d6c4_1600x477.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa354473-6ae0-4ae7-a20c-e858c804d6c4_1600x477.png" width="1456" height="434" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/aa354473-6ae0-4ae7-a20c-e858c804d6c4_1600x477.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:434,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa354473-6ae0-4ae7-a20c-e858c804d6c4_1600x477.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa354473-6ae0-4ae7-a20c-e858c804d6c4_1600x477.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa354473-6ae0-4ae7-a20c-e858c804d6c4_1600x477.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faa354473-6ae0-4ae7-a20c-e858c804d6c4_1600x477.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>1) The language modeling step where we train the model to predict the next word using a massive amount of web data. This step results in a base model.</p><p>2) a supervised fine-tuning step that makes the model more useful in following instructions and answering questions. This step results in an instruction tuned model or a supervised fine -tuning / SFT model.</p><p>3) and finally a preference tuning step which further polishes its behaviors and aligns to human preferences, resulting in the final preference-tuned LLM which you interact with on playgrounds and apps.</p><p><span>DeepSeek-R1 follows this general recipe. The details of that first step come from a </span><a href="https://arxiv.org/pdf/2412.19437v1" rel="">previous paper for the DeepSeek-V3 model</a><span>. R1 uses the </span><em>base</em><span> model (not the final DeepSeek-v3 model) from that previous paper, and still goes through an SFT and preference tuning steps, but the details of how it does them are what's different.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc66dff5b-8332-4696-b484-b2ddb029b78c_854x234.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc66dff5b-8332-4696-b484-b2ddb029b78c_854x234.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc66dff5b-8332-4696-b484-b2ddb029b78c_854x234.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc66dff5b-8332-4696-b484-b2ddb029b78c_854x234.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc66dff5b-8332-4696-b484-b2ddb029b78c_854x234.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc66dff5b-8332-4696-b484-b2ddb029b78c_854x234.png" width="854" height="234" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c66dff5b-8332-4696-b484-b2ddb029b78c_854x234.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:234,&quot;width&quot;:854,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:30102,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc66dff5b-8332-4696-b484-b2ddb029b78c_854x234.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc66dff5b-8332-4696-b484-b2ddb029b78c_854x234.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc66dff5b-8332-4696-b484-b2ddb029b78c_854x234.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc66dff5b-8332-4696-b484-b2ddb029b78c_854x234.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>There are three special things to highlight in the R1 creation process.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26136780-897d-4f64-b1e5-45936b6078dd_854x434.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26136780-897d-4f64-b1e5-45936b6078dd_854x434.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26136780-897d-4f64-b1e5-45936b6078dd_854x434.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26136780-897d-4f64-b1e5-45936b6078dd_854x434.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26136780-897d-4f64-b1e5-45936b6078dd_854x434.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26136780-897d-4f64-b1e5-45936b6078dd_854x434.png" width="854" height="434" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/26136780-897d-4f64-b1e5-45936b6078dd_854x434.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:434,&quot;width&quot;:854,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:43757,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26136780-897d-4f64-b1e5-45936b6078dd_854x434.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26136780-897d-4f64-b1e5-45936b6078dd_854x434.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26136780-897d-4f64-b1e5-45936b6078dd_854x434.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26136780-897d-4f64-b1e5-45936b6078dd_854x434.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This is a large number of long chain-of-thought reasoning examples (600,000 of them). These are very hard to come by and very expensive to label with humans at this scale. Which is why the process to create them is the second special thing to highlight</p><p><span>This data is created by a precursor to R1, an unnamed sibling which specializes in reasoning. This sibling is inspired by a third model called </span><em>R1-Zero </em><span>(that we’ll discuss shortly). It is significant not because it’s a great LLM to use, but because creating it required so little labeled data alongside large-scale reinforcement learning resulting in a model that excels at solving reasoning problems. </span></p><p>The outputs of this unnamed specialist reasoning model can then be used to train a more general model that can also do other, non-reasoning tasks, to the level users expect from an LLM.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4caea6a5-52a1-4651-8c71-4586c0637f3e_924x427.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4caea6a5-52a1-4651-8c71-4586c0637f3e_924x427.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4caea6a5-52a1-4651-8c71-4586c0637f3e_924x427.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4caea6a5-52a1-4651-8c71-4586c0637f3e_924x427.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4caea6a5-52a1-4651-8c71-4586c0637f3e_924x427.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4caea6a5-52a1-4651-8c71-4586c0637f3e_924x427.png" width="924" height="427" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4caea6a5-52a1-4651-8c71-4586c0637f3e_924x427.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:427,&quot;width&quot;:924,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:50317,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4caea6a5-52a1-4651-8c71-4586c0637f3e_924x427.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4caea6a5-52a1-4651-8c71-4586c0637f3e_924x427.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4caea6a5-52a1-4651-8c71-4586c0637f3e_924x427.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4caea6a5-52a1-4651-8c71-4586c0637f3e_924x427.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This happens in two steps:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png" width="1456" height="629" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:629,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:176092,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Here, RL is used to create the interim reasoning model. The model is then used to  generate the SFT reasoning examples. But what makes creating this model possible is an earlier experiment creating an earlier model called </span><em>DeepSeek-R1-Zero</em><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b9f117-caa3-42fd-a949-dc6433990d26_1526x506.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b9f117-caa3-42fd-a949-dc6433990d26_1526x506.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b9f117-caa3-42fd-a949-dc6433990d26_1526x506.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b9f117-caa3-42fd-a949-dc6433990d26_1526x506.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b9f117-caa3-42fd-a949-dc6433990d26_1526x506.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b9f117-caa3-42fd-a949-dc6433990d26_1526x506.png" width="1456" height="483" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/69b9f117-caa3-42fd-a949-dc6433990d26_1526x506.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:483,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:103072,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b9f117-caa3-42fd-a949-dc6433990d26_1526x506.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b9f117-caa3-42fd-a949-dc6433990d26_1526x506.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b9f117-caa3-42fd-a949-dc6433990d26_1526x506.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F69b9f117-caa3-42fd-a949-dc6433990d26_1526x506.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>R1-Zero is special because it is able to excel at reasoning tasks without having a labeled SFT training set. Its training goes directly from a pre-trained base model through a RL training process (no SFT step). It does this so well that it’s competitive with o1.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5c964f-b654-49b2-ab5a-5618b256ef99_1588x418.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5c964f-b654-49b2-ab5a-5618b256ef99_1588x418.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5c964f-b654-49b2-ab5a-5618b256ef99_1588x418.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5c964f-b654-49b2-ab5a-5618b256ef99_1588x418.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5c964f-b654-49b2-ab5a-5618b256ef99_1588x418.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5c964f-b654-49b2-ab5a-5618b256ef99_1588x418.png" width="1456" height="383" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7b5c964f-b654-49b2-ab5a-5618b256ef99_1588x418.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:383,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:106577,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5c964f-b654-49b2-ab5a-5618b256ef99_1588x418.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5c964f-b654-49b2-ab5a-5618b256ef99_1588x418.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5c964f-b654-49b2-ab5a-5618b256ef99_1588x418.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7b5c964f-b654-49b2-ab5a-5618b256ef99_1588x418.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This is significant because data has always been the fuel for ML model capability. How can this model depart from that history? This points to two things:</p><p>1- Modern base models have crossed a certain threshold of quality and capability (this base model was trained on 14.8 trillion high-quality tokens).</p><p>2- Reasoning problems, in contrast to general chat or writing requests, can be automatically verified or labeled. Let’s show this with an example. This can be a prompt/question that is a part of this RL training step:</p><blockquote><p>Write python code that takes a list of numbers, returns them in a sorted order, but also adds 42 at the start.</p></blockquote><p>A question like this lends itself to many ways of automatic verification. Say we present this this to the model being trained, and it generates a completion:</p><ul><li><p>A software linter can check if the completion is proper python code or not</p></li><li><p>We can execute the python code to see if it even runs</p></li><li><p>Other modern coding LLMs can create unit tests to verify the desired behavior (without being reasoning experts themselves). </p></li><li><p>We can go even one step further and measure execution time and make the training process prefer more performant solutions over other solutions — even if they’re correct python programs that solve the issue.</p></li></ul><p>We can present a question like this to the model in a training step, and generate multiple possible solutions.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8edd9db2-a071-4bba-9d14-bbdb076d6355_798x444.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8edd9db2-a071-4bba-9d14-bbdb076d6355_798x444.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8edd9db2-a071-4bba-9d14-bbdb076d6355_798x444.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8edd9db2-a071-4bba-9d14-bbdb076d6355_798x444.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8edd9db2-a071-4bba-9d14-bbdb076d6355_798x444.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8edd9db2-a071-4bba-9d14-bbdb076d6355_798x444.png" width="798" height="444" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8edd9db2-a071-4bba-9d14-bbdb076d6355_798x444.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:444,&quot;width&quot;:798,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:60456,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8edd9db2-a071-4bba-9d14-bbdb076d6355_798x444.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8edd9db2-a071-4bba-9d14-bbdb076d6355_798x444.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8edd9db2-a071-4bba-9d14-bbdb076d6355_798x444.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8edd9db2-a071-4bba-9d14-bbdb076d6355_798x444.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>We can automatically check (with no human intervention) and see that the first completion is not even code. The second one is indeed python code but does not solve the problem. The third is a possible solution, but fails the unit tests, and the forth is a correct solution.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f9645a0-b1fb-4753-942c-583504297c25_972x517.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f9645a0-b1fb-4753-942c-583504297c25_972x517.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f9645a0-b1fb-4753-942c-583504297c25_972x517.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f9645a0-b1fb-4753-942c-583504297c25_972x517.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f9645a0-b1fb-4753-942c-583504297c25_972x517.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f9645a0-b1fb-4753-942c-583504297c25_972x517.png" width="972" height="517" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1f9645a0-b1fb-4753-942c-583504297c25_972x517.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:517,&quot;width&quot;:972,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:74268,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f9645a0-b1fb-4753-942c-583504297c25_972x517.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f9645a0-b1fb-4753-942c-583504297c25_972x517.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f9645a0-b1fb-4753-942c-583504297c25_972x517.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1f9645a0-b1fb-4753-942c-583504297c25_972x517.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>These are all signals that can be directly use to improve the model. This is of course done over many examples (in mini-batches) and over successive training steps.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b595e04-bd57-4f78-8c9b-ab37797e9b66_955x543.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b595e04-bd57-4f78-8c9b-ab37797e9b66_955x543.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b595e04-bd57-4f78-8c9b-ab37797e9b66_955x543.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b595e04-bd57-4f78-8c9b-ab37797e9b66_955x543.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b595e04-bd57-4f78-8c9b-ab37797e9b66_955x543.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b595e04-bd57-4f78-8c9b-ab37797e9b66_955x543.png" width="955" height="543" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5b595e04-bd57-4f78-8c9b-ab37797e9b66_955x543.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:543,&quot;width&quot;:955,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:92262,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b595e04-bd57-4f78-8c9b-ab37797e9b66_955x543.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b595e04-bd57-4f78-8c9b-ab37797e9b66_955x543.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b595e04-bd57-4f78-8c9b-ab37797e9b66_955x543.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5b595e04-bd57-4f78-8c9b-ab37797e9b66_955x543.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>These reward signals and model updates are how the model continues improving on tasks over the RL training process as seen in Figure 2 from the paper.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe48af6fa-8956-44b0-84cf-915e607f3b5e_1546x884.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe48af6fa-8956-44b0-84cf-915e607f3b5e_1546x884.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe48af6fa-8956-44b0-84cf-915e607f3b5e_1546x884.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe48af6fa-8956-44b0-84cf-915e607f3b5e_1546x884.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe48af6fa-8956-44b0-84cf-915e607f3b5e_1546x884.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe48af6fa-8956-44b0-84cf-915e607f3b5e_1546x884.png" width="1456" height="833" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e48af6fa-8956-44b0-84cf-915e607f3b5e_1546x884.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:833,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:211203,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe48af6fa-8956-44b0-84cf-915e607f3b5e_1546x884.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe48af6fa-8956-44b0-84cf-915e607f3b5e_1546x884.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe48af6fa-8956-44b0-84cf-915e607f3b5e_1546x884.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe48af6fa-8956-44b0-84cf-915e607f3b5e_1546x884.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Corresponding with the improvement of this capability is the length of the generated response, where the model generates more thinking tokens to process the problem.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png" width="1456" height="875" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:875,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:250596,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This process is useful, but the R1-Zero model, despite scoring high on these reasoning problems, confronts other issues that make it less usable than desired. </p><blockquote><p>Although DeepSeek-R1-Zero exhibits strong reasoning capabilities and autonomously develops unexpected and powerful reasoning behaviors, it faces several issues. For instance, DeepSeek-R1-Zero struggles with challenges like poor readability, and language mixing.</p></blockquote><p>R1 is meant to be a more usable model. So instead of relying completely on the RL process, it is used in two places as we’ve mentioned earlier in this section:</p><p>1- creating an interim reasoning model to generate SFT data points</p><p>2- Training the R1 model to improve on reasoning and non-reasoning problems (using other types of verifiers)</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png" width="1456" height="629" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:629,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45ca8c84-6eb6-4879-ab53-035174b17ce1_1620x700.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>To make the interim reasoning model more useful, it goes through an supervised fine-tuning (SFT) training step on a few thousand examples of reasoning problems (some of which are generated and filtered from R1-Zero). The paper refers to this as cold start data”</p><blockquote><p><strong>2.3.1. Cold Start</strong><br><span>Unlike DeepSeek-R1-Zero, to prevent the early unstable cold start phase of RL training from the base model, for DeepSeek-R1 we construct and collect a small amount of long CoT data to fine-tune the model as the initial RL actor. To collect such data, we have explored several approaches: using few-shot prompting with a long CoT as an example, directly prompting models to generate detailed answers with reflection and verification, gathering DeepSeek-R1- Zero outputs in a readable format, and refining the results through post-processing by human annotators.</span></p></blockquote><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a89a9a0-c08f-430d-b135-7f012c2810ba_1824x586.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a89a9a0-c08f-430d-b135-7f012c2810ba_1824x586.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a89a9a0-c08f-430d-b135-7f012c2810ba_1824x586.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a89a9a0-c08f-430d-b135-7f012c2810ba_1824x586.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a89a9a0-c08f-430d-b135-7f012c2810ba_1824x586.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a89a9a0-c08f-430d-b135-7f012c2810ba_1824x586.png" width="1456" height="468" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1a89a9a0-c08f-430d-b135-7f012c2810ba_1824x586.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:468,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:160514,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a89a9a0-c08f-430d-b135-7f012c2810ba_1824x586.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a89a9a0-c08f-430d-b135-7f012c2810ba_1824x586.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a89a9a0-c08f-430d-b135-7f012c2810ba_1824x586.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a89a9a0-c08f-430d-b135-7f012c2810ba_1824x586.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>But wait, if we have this data, then why are we relying on the RL process? It’s because of the scale of the data. This dataset might be 5,000 examples (which is possible to source), but to train R1, 600,000 examples were needed. This interim model bridges that gap and allows to synthetically generate that extremely valuable data.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F857e61c8-03e7-4bc7-bcbe-ca182f60a70e_3300x1170.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F857e61c8-03e7-4bc7-bcbe-ca182f60a70e_3300x1170.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F857e61c8-03e7-4bc7-bcbe-ca182f60a70e_3300x1170.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F857e61c8-03e7-4bc7-bcbe-ca182f60a70e_3300x1170.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F857e61c8-03e7-4bc7-bcbe-ca182f60a70e_3300x1170.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F857e61c8-03e7-4bc7-bcbe-ca182f60a70e_3300x1170.png" width="1456" height="516" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/857e61c8-03e7-4bc7-bcbe-ca182f60a70e_3300x1170.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:516,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:244148,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F857e61c8-03e7-4bc7-bcbe-ca182f60a70e_3300x1170.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F857e61c8-03e7-4bc7-bcbe-ca182f60a70e_3300x1170.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F857e61c8-03e7-4bc7-bcbe-ca182f60a70e_3300x1170.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F857e61c8-03e7-4bc7-bcbe-ca182f60a70e_3300x1170.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>If you’re new to the concept of Supervised Fine-Tuning (SFT), that is the process that presents the model with training examples in the form of prompt and correct completion. This figure from chapter 12 shows a couple of SFT training examples:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b630dbc-aaa4-4c27-804b-542055b0f298_2264x1324.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b630dbc-aaa4-4c27-804b-542055b0f298_2264x1324.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b630dbc-aaa4-4c27-804b-542055b0f298_2264x1324.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b630dbc-aaa4-4c27-804b-542055b0f298_2264x1324.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b630dbc-aaa4-4c27-804b-542055b0f298_2264x1324.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b630dbc-aaa4-4c27-804b-542055b0f298_2264x1324.png" width="1456" height="851" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8b630dbc-aaa4-4c27-804b-542055b0f298_2264x1324.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:851,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:575809,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b630dbc-aaa4-4c27-804b-542055b0f298_2264x1324.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b630dbc-aaa4-4c27-804b-542055b0f298_2264x1324.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b630dbc-aaa4-4c27-804b-542055b0f298_2264x1324.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b630dbc-aaa4-4c27-804b-542055b0f298_2264x1324.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This enables R1 to excel at reasoning as well as other non-reasoning tasks. The process is similar to the the RL process we’ve seen before. But since it extends to non-reasoning applications, it utilizes a helpfulnes and a safety reward model (not unlike the Llama models) for prompts that belong to these applications.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e5f9acf-b4ca-4ec4-9731-4845c8fc5515_902x394.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e5f9acf-b4ca-4ec4-9731-4845c8fc5515_902x394.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e5f9acf-b4ca-4ec4-9731-4845c8fc5515_902x394.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e5f9acf-b4ca-4ec4-9731-4845c8fc5515_902x394.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e5f9acf-b4ca-4ec4-9731-4845c8fc5515_902x394.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e5f9acf-b4ca-4ec4-9731-4845c8fc5515_902x394.png" width="902" height="394" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0e5f9acf-b4ca-4ec4-9731-4845c8fc5515_902x394.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:394,&quot;width&quot;:902,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:72511,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e5f9acf-b4ca-4ec4-9731-4845c8fc5515_902x394.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e5f9acf-b4ca-4ec4-9731-4845c8fc5515_902x394.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e5f9acf-b4ca-4ec4-9731-4845c8fc5515_902x394.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0e5f9acf-b4ca-4ec4-9731-4845c8fc5515_902x394.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Just like previous models from the dawn of </span><a href="https://jalammar.github.io/illustrated-gpt2/" rel="">GPT2</a><span> and </span><a href="https://jalammar.github.io/how-gpt3-works-visualizations-animations/" rel="">GPT 3</a><span>, DeepSeek-R1 is a stack of </span><a href="https://jalammar.github.io/illustrated-transformer/" rel="">Transformer</a><span> decoder blocks. It’s made up 61 of them. The first three are dense, but the rest are mixture-of-experts layers (See my co-author Maarten’s incredible intro guide here: </span><a href="https://substack.com/home/post/p-148217245" rel="">A Visual Guide to Mixture of Experts (MoE)</a><span>).</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F199f326e-9a8d-4a95-8574-4778d5b7657b_538x413.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F199f326e-9a8d-4a95-8574-4778d5b7657b_538x413.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F199f326e-9a8d-4a95-8574-4778d5b7657b_538x413.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F199f326e-9a8d-4a95-8574-4778d5b7657b_538x413.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F199f326e-9a8d-4a95-8574-4778d5b7657b_538x413.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F199f326e-9a8d-4a95-8574-4778d5b7657b_538x413.png" width="538" height="413" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/199f326e-9a8d-4a95-8574-4778d5b7657b_538x413.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:413,&quot;width&quot;:538,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:39245,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F199f326e-9a8d-4a95-8574-4778d5b7657b_538x413.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F199f326e-9a8d-4a95-8574-4778d5b7657b_538x413.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F199f326e-9a8d-4a95-8574-4778d5b7657b_538x413.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F199f326e-9a8d-4a95-8574-4778d5b7657b_538x413.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In terms of model dimension size and other hyperparameters, they look like this:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ee664ae-a544-4e19-a145-0ae87acc43fa_916x481.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ee664ae-a544-4e19-a145-0ae87acc43fa_916x481.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ee664ae-a544-4e19-a145-0ae87acc43fa_916x481.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ee664ae-a544-4e19-a145-0ae87acc43fa_916x481.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ee664ae-a544-4e19-a145-0ae87acc43fa_916x481.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ee664ae-a544-4e19-a145-0ae87acc43fa_916x481.png" width="916" height="481" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2ee664ae-a544-4e19-a145-0ae87acc43fa_916x481.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:481,&quot;width&quot;:916,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:63869,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ee664ae-a544-4e19-a145-0ae87acc43fa_916x481.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ee664ae-a544-4e19-a145-0ae87acc43fa_916x481.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ee664ae-a544-4e19-a145-0ae87acc43fa_916x481.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ee664ae-a544-4e19-a145-0ae87acc43fa_916x481.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>More details about the model architecture are presented in their two earlier papers:</p><ul><li><p><a href="https://arxiv.org/pdf/2412.19437v1" rel="">DeepSeek-V3 Technical Report</a></p></li><li><p><a href="https://arxiv.org/pdf/2401.06066" rel="">DeepSeekMoE: Towards Ultimate Expert Specialization in</a></p><p><a href="https://arxiv.org/pdf/2401.06066" rel="">Mixture-of-Experts Language Models</a></p></li></ul><p>With this, you should now have the main intuitions to wrap your head around the DeepSeek-R1 model. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png" width="1456" height="634" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:634,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:341594,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>If you felt needed a little more foundational information to understand this post, I’d suggest you pick up a copy of </span><a href="https://www.llm-book.com/" rel="">Hands-On Large Language Models</a><span> or read it online on </span><a href="https://learning.oreilly.com/library/view/hands-on-large-language/9781098150952/" rel="">O’Reilly</a><span> and check it out on </span><a href="https://github.com/handsOnLLM/Hands-On-Large-Language-Models" rel="">Github</a><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7beb5f-e943-4d2d-8b4c-eb1e80231670_582x768.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7beb5f-e943-4d2d-8b4c-eb1e80231670_582x768.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7beb5f-e943-4d2d-8b4c-eb1e80231670_582x768.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7beb5f-e943-4d2d-8b4c-eb1e80231670_582x768.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7beb5f-e943-4d2d-8b4c-eb1e80231670_582x768.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7beb5f-e943-4d2d-8b4c-eb1e80231670_582x768.png" width="158" height="208.49484536082474" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bd7beb5f-e943-4d2d-8b4c-eb1e80231670_582x768.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:768,&quot;width&quot;:582,&quot;resizeWidth&quot;:158,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Book Cover&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Book Cover" title="Book Cover" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7beb5f-e943-4d2d-8b4c-eb1e80231670_582x768.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7beb5f-e943-4d2d-8b4c-eb1e80231670_582x768.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7beb5f-e943-4d2d-8b4c-eb1e80231670_582x768.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd7beb5f-e943-4d2d-8b4c-eb1e80231670_582x768.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Other suggested resources are:</p><ul><li><p><a href="https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1" rel="">DeepSeek R1's recipe to replicate o1 and the future of reasoning LMs</a><span> by </span></p><span> </span></li><li><p><a href="https://substack.com/home/post/p-148217245" rel="">A Visual Guide to Mixture of Experts (MoE)</a><span> by </span></p><span> </span></li><li><p><span>Sasha Rush’s YouTube video </span><a href="https://www.youtube.com/watch?v=6PEJ96k1kiw" rel="">Speculations on Test-Time Scaling (o1)</a><span> </span></p></li><li><p><span>Yannis Kilcher’s </span><a href="https://www.youtube.com/watch?v=bAWV_yrqx4w" rel="">DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models (Paper Explained)</a></p></li><li><p><a href="https://github.com/huggingface/open-r1" rel="">Open R1</a><span> is the HuggingFace project to openly reproduce DeepSeek-R1</span></p></li><li><p><a href="https://huggingface.co/blog/putting_rl_back_in_rlhf_with_rloo" rel="">Putting RL back in RLHF</a></p></li></ul></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Go 1.24's go tool is one of the best additions to the ecosystem in years (111 pts)]]></title>
            <link>https://www.jvt.me/posts/2025/01/27/go-tools-124/</link>
            <guid>42845323</guid>
            <pubDate>Mon, 27 Jan 2025 20:33:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jvt.me/posts/2025/01/27/go-tools-124/">https://www.jvt.me/posts/2025/01/27/go-tools-124/</a>, See on <a href="https://news.ycombinator.com/item?id=42845323">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>For those that aren't aware, one of the big changes in February's upcoming Go 1.24 release is the new <a href="https://tip.golang.org/doc/go1.24#tools"><code>go tool</code></a> command, and <code>tool</code> directive in the <code>go.mod</code> to manage any tools your project uses. I'm <em>incredibly excited</em> about this, and in my opinion, this is one of the best changes we've had in recent years in the ecosystem as a whole.</p><p>I've been meaning to write this post since the first release candidate for Go 1.24 landed, but after reading Howard John's <a href="https://blog.howardjohn.info/posts/go-tools-command/">Exploring the new "go tool" support in Go 1.24</a> this morning, I thought I should write my thoughts up.</p><h2 id="what-is-it">What is it?</h2><p>Within your Go codebases, there's often some additional tools that you need to have installed to be able to build/test/deploy the project.</p><p>Sometimes this will a dependency that's needed for <code>go generate</code>ing, or it may be that you want to pipe your <code>go test</code> output into a JUnit-compatible format, so your CI platform can provide more useful metadata.</p><p>For each of these, you have two choices:</p><ul><li>require that the user knows how to install them, i.e. by knowing to run <code>make deps</code> or <code>just setup</code> before building anything on the project (which will then i.e. <code>go install</code> the commands)</li><li>use the <a href="https://www.jvt.me/posts/2022/06/15/go-tools-dependency-management/"><code>tools.go</code> pattern</a> to make it so you can <em>just</em> run <code>go generate</code>, and that'll call the right dependency via <code>go run</code></li></ul><p>My preference is <a href="https://www.jvt.me/posts/2022/06/15/go-tools-dependency-management/"><code>tools.go</code> pattern</a>, but there are two key problems with this approach.</p><p>Firstly, there's a performance hit of using a <code>tools.go</code>. It's something that is <em>slightly</em> noticeable, moreso if your project relies upon a lot of <code>go run</code> i.e. with lots of <code>go generate</code>s, because prior to Go 1.24, the <code>go run</code> invocations were not cached.</p><p>Secondly, it also leads to dependency tree bloat, because you have to record your dependency on i.e. <code>github.com/sqlc-dev/sqlc/cmd/sqlc</code> which then gets recorded in your <code>go.mod</code>, and then anyone using <em>your module</em> will then see that as an indirect (transitive) dependency.</p><p>This was something we <a href="https://www.jvt.me/posts/2023/10/23/oapi-codegen-v2-decrease/">worked on for <code>oapi-codegen</code>'s v2 release</a> to further reduce unnecessary dependencies, and make things a bit cleaner for our consumers. This is somewhat mitigated by Go's <a href="https://go.dev/ref/mod#graph-pruning">module graph pruning</a> which won't download dependencies that aren't used, but consumers may still see the dependencies coming in as an indirect dependency, which may not be ideal (especially as it can then bloat their indirect dependencies, which then gets passed on to their consumers and so on .</p><p>Dependency tree bloat can also be further mitigated by splitting your <a href="https://www.jvt.me/posts/2024/09/30/go-tools-module/"><code>tools.go</code> into a separate module</a>, which makes it more awkward to invoke dependencies but makes sure that none of your consumers will be seeing any tool-related dependencies.</p><p>For those who know me as co-maintainer of <a href="https://github.com/oapi-codegen/oapi-codegen">oapi-codegen</a>, you'll know that the <code>tools.go</code> pattern is our <a href="https://github.com/oapi-codegen/oapi-codegen#install">explicit recommendation</a> and we believe is better than installing it as a binary, so it's probably unsurprising that I'm very excited about this as an option to manage dependencies.</p><h2 id="how-does-it-work">How does it work?</h2><p>I've started playing around with this <a href="https://gitlab.com/tanna.dev/dependency-management-data/-/commits/spike/go-tools-124">on a branch</a> of the <a href="https://dmd.tanna.dev/">dependency-management-data</a> project, where I've got a mix of different tools that need to be installed and used.</p><p>Let's take a worked example of how we'd move over calls to <code>oapi-codegen</code> to the new <code>go tool</code> pattern.</p><h3 id="existing-state">Existing state</h3><p>For instance let's say that we have the following <code>tools.go</code> in its own module:</p><pre tabindex="0"><code data-lang="gomod"># tools/go.mod
module dmd.tanna.dev/tools

go 1.22.0

require (
	github.com/99designs/gqlgen v0.17.49
	github.com/oapi-codegen/oapi-codegen/v2 v2.4.1
	github.com/sqlc-dev/sqlc v1.26.0
)
</code></pre><p>We can then see that we invoke this via <code>go run</code>:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>// internal/ecosystems/generate.go
</span></span></span><span><span><span>//go:generate go run -modfile=../../tools/go.mod github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen --config=config.yaml openapi.yaml
</span></span></span></code></pre></div><h3 id="migrating">Migrating</h3><p>To start migrating over to <code>go tool</code>, we need to make sure that we've first pulled in the new version of Go in our top-level Go module:</p><div><pre tabindex="0"><code data-lang="diff"><span><span> module dmd.tanna.dev
</span></span><span><span>
</span></span><span><span><span>-go 1.22.7
</span></span></span><span><span><span></span><span>+go 1.24
</span></span></span><span><span><span></span>
</span></span><span><span><span>-toolchain go1.23.2
</span></span></span><span><span><span></span><span>+toolchain go1.24rc2
</span></span></span></code></pre></div><p>Next, we need to pull in a <code>tool</code> dependency on <code>oapi-codegen</code>'s CLI tool - notice that you need <strong>the full path</strong> to the command that's being invoked:</p><div><pre tabindex="0"><code data-lang="sh"><span><span><span># NOTE the full import path</span>
</span></span><span><span>% go get -tool github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen@v2.4.1
</span></span></code></pre></div><p>We could also do this by hand, but doing it via <code>go get</code> simplifies this a little.</p><p>From here, we'll notice that our <code>go.mod</code> has a few other changes:</p><div><pre tabindex="0"><code data-lang="diff"><span><span><span>@@ -57,12 +57,16 @@ require (
</span></span></span><span><span><span></span>        github.com/cenkalti/backoff/v4 v4.3.0 // indirect
</span></span><span><span>        github.com/cespare/xxhash/v2 v2.3.0 // indirect
</span></span><span><span>        github.com/charmbracelet/lipgloss v0.10.0 // indirect
</span></span><span><span><span>+       github.com/dprotaso/go-yit v0.0.0-20220510233725-9ba8df137936 // indirect
</span></span></span><span><span><span></span>        github.com/dustin/go-humanize v1.0.1 // indirect
</span></span><span><span>        github.com/felixge/httpsnoop v1.0.4 // indirect
</span></span><span><span><span>+       github.com/getkin/kin-openapi v0.127.0 // indirect
</span></span></span><span><span><span></span>        github.com/go-ini/ini v1.67.0 // indirect
</span></span><span><span>        github.com/go-logfmt/logfmt v0.6.0 // indirect
</span></span><span><span>        github.com/go-logr/logr v1.4.2 // indirect
</span></span><span><span>        github.com/go-logr/stdr v1.2.2 // indirect
</span></span><span><span><span>+       github.com/go-openapi/jsonpointer v0.21.0 // indirect
</span></span></span><span><span><span>+       github.com/go-openapi/swag v0.23.0 // indirect
</span></span></span><span><span><span></span>        github.com/gobwas/glob v0.2.3 // indirect
</span></span><span><span>        github.com/google/go-querystring v1.1.0 // indirect
</span></span><span><span>        github.com/gorilla/mux v1.8.1 // indirect
</span></span><span><span><span>@@ -72,16 +76,22 @@ require (
</span></span></span><span><span><span></span>        github.com/hashicorp/go-retryablehttp v0.7.5 // indirect
</span></span><span><span>        github.com/hashicorp/golang-lru/v2 v2.0.7 // indirect
</span></span><span><span>        github.com/inconshreveable/mousetrap v1.1.0 // indirect
</span></span><span><span><span>+       github.com/invopop/yaml v0.3.1 // indirect
</span></span></span><span><span><span>+       github.com/josharian/intern v1.0.0 // indirect
</span></span></span><span><span><span></span>        github.com/klauspost/compress v1.17.11 // indirect
</span></span><span><span>        github.com/lucasb-eyer/go-colorful v1.2.0 // indirect
</span></span><span><span><span>+       github.com/mailru/easyjson v0.7.7 // indirect
</span></span></span><span><span><span></span>        github.com/mattn/go-isatty v0.0.20 // indirect
</span></span><span><span>        github.com/mattn/go-runewidth v0.0.15 // indirect
</span></span><span><span>        github.com/mitchellh/mapstructure v1.5.0 // indirect
</span></span><span><span><span>+       github.com/mohae/deepcopy v0.0.0-20170929034955-c48cc78d4826 // indirect
</span></span></span><span><span><span></span>        github.com/muesli/reflow v0.3.0 // indirect
</span></span><span><span>        github.com/muesli/termenv v0.15.2 // indirect
</span></span><span><span>        github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect
</span></span><span><span>        github.com/ncruces/go-strftime v0.1.9 // indirect
</span></span><span><span><span>+       github.com/oapi-codegen/oapi-codegen/v2 v2.4.1 // indirect
</span></span></span><span><span><span></span>        github.com/olekukonko/tablewriter v0.0.5 // indirect
</span></span><span><span><span>+       github.com/perimeterx/marshmallow v1.1.5 // indirect
</span></span></span><span><span><span></span>        github.com/prometheus/client_golang v1.20.5 // indirect
</span></span><span><span>        github.com/prometheus/client_model v0.6.1 // indirect
</span></span><span><span>        github.com/prometheus/common v0.60.1 // indirect
</span></span><span><span><span>@@ -91,8 +101,10 @@ require (
</span></span></span><span><span><span></span>        github.com/rivo/uniseg v0.4.7 // indirect
</span></span><span><span>        github.com/sirupsen/logrus v1.9.4-0.20230606125235-dd1b4c2e81af // indirect
</span></span><span><span>        github.com/sosodev/duration v1.3.1 // indirect
</span></span><span><span><span>+       github.com/speakeasy-api/openapi-overlay v0.9.0 // indirect
</span></span></span><span><span><span></span>        github.com/spf13/pflag v1.0.5 // indirect
</span></span><span><span>        github.com/tchap/go-patricia/v2 v2.3.1 // indirect
</span></span><span><span><span>+       github.com/vmware-labs/yaml-jsonpath v0.3.2 // indirect
</span></span></span><span><span><span></span>        github.com/xeipuuv/gojsonpointer v0.0.0-20190905194746-02993c407bfb // indirect
</span></span><span><span>        github.com/xeipuuv/gojsonreference v0.0.0-20180127040603-bd5ef7bd5415 // indirect
</span></span><span><span>        github.com/yashtewari/glob-intersection v0.2.0 // indirect
</span></span><span><span><span>@@ -110,11 +122,13 @@ require (
</span></span></span><span><span><span></span>        go.opentelemetry.io/otel/metric v1.32.0 // indirect
</span></span><span><span>        go.opentelemetry.io/proto/otlp v1.3.1 // indirect
</span></span><span><span>        golang.org/x/exp v0.0.0-20231108232855-2478ac86f678 // indirect
</span></span><span><span><span>+       golang.org/x/mod v0.18.0 // indirect
</span></span></span><span><span><span></span>        golang.org/x/net v0.30.0 // indirect
</span></span><span><span>        golang.org/x/oauth2 v0.23.0 // indirect
</span></span><span><span>        golang.org/x/sys v0.27.0 // indirect
</span></span><span><span>        golang.org/x/term v0.25.0 // indirect
</span></span><span><span>        golang.org/x/time v0.5.0 // indirect
</span></span><span><span><span>+       golang.org/x/tools v0.22.0 // indirect
</span></span></span><span><span><span></span>        google.golang.org/genproto/googleapis/api v0.0.0-20241104194629-dd2ea8efbc28 // indirect
</span></span><span><span>        google.golang.org/genproto/googleapis/rpc v0.0.0-20241104194629-dd2ea8efbc28 // indirect
</span></span><span><span>        google.golang.org/grpc v1.68.0 // indirect
</span></span><span><span><span>@@ -128,3 +142,5 @@ require (
</span></span></span><span><span><span></span>        modernc.org/token v1.1.0 // indirect
</span></span><span><span>        sigs.k8s.io/yaml v1.4.0 // indirect
</span></span><span><span> )
</span></span><span><span><span>+
</span></span></span><span><span><span>+tool github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen
</span></span></span></code></pre></div><p>From here, we can see:</p><ul><li>there is a <code>tool</code> directive for <code>github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen</code></li><li>the containing Go module for the CLI, <code>github.com/oapi-codegen/oapi-codegen/v2</code>, is now an <code>indirect</code> dependency</li><li>any other required dependencies of <code>github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen</code> are now <code>indirect</code> dependencies</li></ul><p>Now we've done this, we could run:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>% go tool github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen --help
</span></span><span><span>Usage of /home/jamie/.cache/go-build/0e/0e04736601c8bbef785d372de02859bf8f39405aae9ccbf371477b0f2d8df755-d/oapi-codegen:
</span></span><span><span><span># ...</span>
</span></span></code></pre></div><p>With this tool set up, we can now modify i.e. <code>internal/ecosystems/generate.go</code> like so to use the new <code>go tool</code>:</p><div><pre tabindex="0"><code data-lang="diff"><span><span> package ecosystems
</span></span><span><span>
</span></span><span><span><span>-//go:generate go run -modfile=../../tools/go.mod github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen --config=config.yaml openapi.yaml
</span></span></span><span><span><span></span><span>+//go:generate go tool github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen --config=config.yaml openapi.yaml
</span></span></span></code></pre></div><p>Then running <code>go generate ./internal/ecosystems</code> works as it did before 🚀</p><h2 id="performance-implications">Performance implications</h2><p>A less scientific view than Howard John's article above, but we can see a slight improvement in performance:</p><div><pre tabindex="0"><code data-lang="sh"><span><span><span># first time using `go tool`, from a fresh cache directory</span>
</span></span><span><span>% <span>time</span> go generate ./internal/ecosystems
</span></span><span><span>go generate ./internal/ecosystems  55.05s user 4.57s system 531% cpu 11.220 total
</span></span><span><span><span># a subsequent call</span>
</span></span><span><span>% <span>time</span> go generate ./internal/ecosystems
</span></span><span><span>go generate ./internal/ecosystems  0.59s user 0.18s system 424% cpu 0.181 total
</span></span><span><span><span># another just to see</span>
</span></span><span><span>% <span>time</span> go generate ./internal/ecosystems
</span></span><span><span>go generate ./internal/ecosystems  0.57s user 0.25s system 404% cpu 0.202 total
</span></span></code></pre></div><p>Compare this to the previous implementation:</p><div><pre tabindex="0"><code data-lang="sh"><span><span><span># first time using `go run`, from a fresh cache directory</span>
</span></span><span><span>% <span>time</span> go generate ./internal/ecosystems
</span></span><span><span>go generate ./internal/ecosystems  50.29s user 3.67s system 536% cpu 10.063 total
</span></span><span><span><span># a subsequent call</span>
</span></span><span><span>% <span>time</span> go generate ./internal/ecosystems
</span></span><span><span>go generate ./internal/ecosystems  1.04s user 0.21s system 185% cpu 0.677 total
</span></span><span><span><span># another just to see</span>
</span></span><span><span>% <span>time</span> go generate ./internal/ecosystems
</span></span><span><span>go generate ./internal/ecosystems  1.02s user 0.26s system 191% cpu 0.669 total
</span></span></code></pre></div><p>Notice that the first call is similar in speed, but the use of <code>go tool</code>'s subsequent calls are still faster.</p><p>I'm a big fan of the fact that as of Go 1.24+ the <code>go run</code>s will be cached, so even if you don't move over to <code>go tool</code>, you'll get a performance boost!</p><h2 id="concerns">Concerns</h2><p>Now, there are still a few things I've noticed while doing the migration that aren't necessarily what I expected.</p><h3 id="gomod-implications"><code>go.mod</code> implications</h3><p>Something interesting is that the usage of the <code>tool</code> dependencies being treated as an <code>indirect</code> dependency is that they're present in the dependency tree, and treated like any other <code>indirect</code> dependency.</p><p>I'd also have preferred that we had just used <code>// tool</code> instead of <code>// indirect</code>, but I can see why this is likely the choice that's made - so they're treated like any other dependency - but making them less clear as only being required for tools could lead to issues with clashing dependencies, or where you upgrade an <code>indirect</code> dependency and then that breaks other things.</p><p>This means that tools such as Renovate need to be a little more involved in how to do the updates, but <a href="https://github.com/renovatebot/renovate/discussions/33867">that's all in hand</a>.</p><h2 id="gqlgen-fails-to-run-with-go-124rc2"><code>gqlgen</code> fails to run with Go 1.24rc2</h2><p>Something I've noticed while playing around with this is that <a href="https://github.com/99designs/gqlgen/issues/3505"><code>gqlgen</code> struggles to run with Go 1.24rc2</a>, which <a href="https://github.com/golang/go/issues/71448">feels like an upstream Go issue</a>, but it looks like that may be related to the use of <code>/x/tools</code> 🤔</p><p>It may be interesting to find out what else gets affected by this - please give the RC a test!</p><h2 id="closing">Closing</h2><p>Overall, I'm feeling very positive about it, and improving the way that dependencies get installed <em>if they should be built from source</em>, but there are dependencies such as <code>golangci-lint</code> which <a href="https://golangci-lint.run/welcome/install/#install-from-sources">don't recommend building from source</a> and instead using their pre-built binaries, which is fair, and is unlikely to change here.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We're bringing Pebble back (1043 pts)]]></title>
            <link>https://repebble.com/</link>
            <guid>42845091</guid>
            <pubDate>Mon, 27 Jan 2025 20:11:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://repebble.com/">https://repebble.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42845091">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="text-container">
            
            
            
            <div>
                <div>
                    <h2>We're making new Pebble watches</h2>
                    <p>I've tried pretty much every other smartwatch on Earth, yet I still wear my Pebble every day—nothing else matches its features and long battery life. I really, <em>really</em>, <strong><em>really</em></strong> hoped someone else would create a proper replacement, but no one has stepped up, and my stash of old Pebbles is dwindling!</p>
                    <p>It's time to take matters into my own hands. A small team and I are working on a new Pebble-like smartwatch that runs open source PebbleOS, has the same beloved features (plus some fun new stuff), and stays true to the core Pebble vision. If enough people are interested, we'll build it. <a href="https://repebble.com/signup.html">Sign up</a> to get one!</p>
                    <a href="https://ericmigi.com/blog/why-were-bringing-pebble-back" target="_blank">
                        <h3>Read the full blog post</h3>
                        <p>Why We're Bringing Pebble Back</p>
                    </a>
                </div>

                <div>
                    <h2>PebbleOS is now open source</h2>
                    <p>Google (which purchased Fitbit, which had bought Pebble) still owns PebbleOS. Over the last year, a team inside Google (including some amazing ex-Pebblers turned Googlers) has been working on open sourcing the OS! The source code for PebbleOS is now available at <a href="https://github.com/google/pebble" target="_blank">github.com/google/pebble</a>. Read more on their <a href="https://opensource.googleblog.com/2025/01/see-code-that-powered-pebble-smartwatches.html" target="_blank">blog</a>.</p>
                    <p>Thank you so much, Google! I can't stress how thankful I am to the individuals who did the heavy lifting. This was also made possible by the <a href="https://rebble.io/" target="_blank">Rebble</a> team and community, who have supported Pebble since it shut down. Check out the vibrant <a href="https://reddit.com/r/pebble" target="_blank">r/Pebble</a> and <a href="https://discordapp.com/invite/aRUAYFN" target="_blank">Discord</a>.</p>
                </div>
                
                <div>
                    <h2>What happens now?</h2>
                    <p>The source code that powers each Pebble smartwatch is now freely available to download, modify and improve on <a href="https://github.com/google/pebble" target="_blank">Github</a>. Want a reminder of how awesome Pebble OS is? Dive back into the <a href="https://ericmigi.com/blog/pebbleos-is-awesome" target="_blank">beautiful, retro, pixelated world</a> of Pebble.</p>
                    <p>Anyone can use PebbleOS in any way they want. You can get it working on existing Pebble watches, emulate it, run it on other embedded devices, or create new hardware specifically for it. <a href="https://github.com/pebble-dev/pebbleos" target="_blank">Learn more</a> about PebbleOS.</p>
                    <p>We're setting out to bring Pebble back, we'd love for you to join the fun!</p>
                </div>
            </div>

            <h2 id="do-you-want-one">Do you want a new Pebble?</h2>
            
            <div>
                <p>Eric Migicovsky<br>Founder of Pebble</p>
                <div>
                    <h3>Wait, what is Pebble again?</h3>
                    <p>Pebble is an e-paper smartwatch with simple functionality, long battery life, and fun, quirky design. It first launched on <a href="https://www.kickstarter.com/projects/getpebble/pebble-e-paper-watch-for-iphone-and-android" target="_blank">Kickstarter</a> in 2012 and sold over 2 million watches before the company's IP was sold to Fitbit in 2016.</p>
                </div>
                <p id="smallText">© Copyright <span id="year">----</span> Core Devices LLC. All Rights Reserved.<br><a href="https://repebble.com/privacy.html">Privacy</a> · <a href="https://repebble.com/terms.html">Terms</a> · <a href="https://twitter.com/pebble" target="_blank">Twitter</a></p>
            </div>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google open-sources the Pebble OS (602 pts)]]></title>
            <link>https://opensource.googleblog.com/2025/01/see-code-that-powered-pebble-smartwatches.html</link>
            <guid>42845070</guid>
            <pubDate>Mon, 27 Jan 2025 20:09:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opensource.googleblog.com/2025/01/see-code-that-powered-pebble-smartwatches.html">https://opensource.googleblog.com/2025/01/see-code-that-powered-pebble-smartwatches.html</a>, See on <a href="https://news.ycombinator.com/item?id=42845070">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-5561126018697023258" itemprop="articleBody">
<meta name="twitter:image" content="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHCX-mb_DqHgkNn1By45jRl-t4yGY82D79aFivyvhLIjiW9oglYr2fu7qOXFTEPj4sg-18anq6Aydli437ogx_AfTNI4V8Kq9Wjm1pPpOpqsSG1aiTwNLURTHgzFTeND8VuCxmndTLxT48Hr5RQgWvilKyeI9ORfoRNE40ZyqV49xuxTNarCAIoErsYbw/s1600/Pebble-Smartwatch%20%281%29.png">
<p>

<a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHCX-mb_DqHgkNn1By45jRl-t4yGY82D79aFivyvhLIjiW9oglYr2fu7qOXFTEPj4sg-18anq6Aydli437ogx_AfTNI4V8Kq9Wjm1pPpOpqsSG1aiTwNLURTHgzFTeND8VuCxmndTLxT48Hr5RQgWvilKyeI9ORfoRNE40ZyqV49xuxTNarCAIoErsYbw/s1600/Pebble-Smartwatch%20%281%29.png" imageanchor="1"><img data-original-height="800" data-original-width="100%" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHCX-mb_DqHgkNn1By45jRl-t4yGY82D79aFivyvhLIjiW9oglYr2fu7qOXFTEPj4sg-18anq6Aydli437ogx_AfTNI4V8Kq9Wjm1pPpOpqsSG1aiTwNLURTHgzFTeND8VuCxmndTLxT48Hr5RQgWvilKyeI9ORfoRNE40ZyqV49xuxTNarCAIoErsYbw/s1600/Pebble-Smartwatch%20%281%29.png"></a></p><p>We are excited to announce that the source code that powered Pebble smartwatches is now <a href="https://github.com/google/pebble" target="_blank">available for download</a>.</p>

<p>This is part of an effort from Google to help and support the <a href="https://rebble.io/" target="_blank">volunteers</a> who have come together to maintain functionality for Pebble watches after the original company ceased operations in 2016.</p><br>

<h3><b>A quick look back</b></h3>

<p>Pebble was initially launched through a very successful <a href="https://www.kickstarter.com/projects/getpebble/pebble-e-paper-watch-for-iphone-and-android" target="_blank">Kickstarter project</a>. Pebble’s first Kickstarter was the single most funded at the time, and its successor Kickstarter for the <a href="https://www.kickstarter.com/projects/getpebble/pebble-time-awesome-smartwatch-no-compromises" target="_blank">Pebble Time</a> repeated that feat – and remains the second most funded today! Over the course of four years, Pebble sold over two million smartwatches, cultivating a thriving community of thousands of developers who created over ten thousand Pebble apps and watchfaces.</p>

<p>In 2016, Fitbit acquired Pebble, including Pebble’s intellectual property. Later on, Fitbit itself was acquired by Google, taking the Pebble OS with it.</p>

<p>Despite the Pebble hardware and software support being discontinued eight years ago, Pebble still has thousands of dedicated fans.</p><br>

<h3><b>What is being released</b></h3>

<p>We are releasing most of the source code for the Pebble operating system. This repository contains the entire OS, which provides all the standard smartwatch functionality – notifications, media controls, fitness tracking, and support for custom apps and watchfaces – on tiny ARM Cortex-M microcontrollers. Built with <a href="https://www.freertos.org/" target="_blank">FreeRTOS</a>, it contains multiple modules for memory management, graphics, and timekeeping, as well as an extensive framework to load and run custom applications written in C, as well as in Javascript via the <a href="https://jerryscript.net/" target="_blank">Jerryscript</a> Javascript engine. The Pebble architecture allowed for a lightweight system delivering a rich user experience as well as a very long battery life.</p>

<p>It's important to note that some proprietary code was removed from this codebase, particularly for chipset support and the Bluetooth stack. This means the code being released contains all the build system files (using the <a href="https://waf.io/" target="_blank">waf</a> build system), but it will not compile or link as released.</p><br>

<h3><b>The path forward</b></h3>

<p>From here, we are hoping this release will assist the dedicated community and volunteers from the <a href="https://rebble.io/" target="_blank">Rebble project</a> to carry forward the support for Pebble watches that users still love. For someone to build a new firmware update, there is a non-trivial amount of work to do in finding replacements for the pieces that were stripped out of this code, as well as updating this source code that has not been maintained for a few years.</p>

<p><i>By Matthieu Jeanson, Katharine Berry, and Liam McLoughlin</i></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google has open-sourced the Pebble smartwatch operating system (335 pts)]]></title>
            <link>https://rebble.io/2025/01/27/the-future-of-rebble.html</link>
            <guid>42845017</guid>
            <pubDate>Mon, 27 Jan 2025 20:03:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rebble.io/2025/01/27/the-future-of-rebble.html">https://rebble.io/2025/01/27/the-future-of-rebble.html</a>, See on <a href="https://news.ycombinator.com/item?id=42845017">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    <div>
	    <p>Jan 27, 2025 • by <a href="https://rebble.io/team#person-Will%20Murphy">Will Murphy</a></p>
        
        <p>Today we’re excited to announce several developments which will affect the future of Rebble. Let’s get straight into it, starting with the big one…</p>

<h2 id="-google-open-sources-tintin">🎉 Google Open Sources Tintin</h2>

<p><img src="https://rebble.io/images/tintin-blog-post/the-loop.png" alt=""></p>

<p>Today Google <a href="https://github.com/google/pebble">announced that they have released the source code to PebbleOS</a>. This is massive for Rebble, 
and will accelerate our efforts to produce new hardware.</p>

<p>Previously, we have been working on our own replacement firmware: <a href="https://github.com/pebble-dev/RebbleOS">RebbleOS</a>. As you can see by the commit history though, progress was slow.
Building a production-ready realtime OS for the Pebble is no small feat, and although we were confident we’d get there given enough time, it was never our ideal path.
Thanks to the hard work of many people both within Google and not, we finally have our hands on the original source code for PebbleOS. You can read <a href="https://opensource.googleblog.com/2025/01/see-code-that-powered-pebble-smartwatches.html">Google’s blog post on this for even more information.</a></p>

<p>This does <em>not</em> mean we instantly have the ability to start developing updates for PebbleOS though, we first will need to spend some concentrated time getting it to build. 
But before we talk about that, let’s talk about Rebble itself.</p>

<!--more-->



<p>With a long term plan for the Rebble community starting to coalesce, the
longevity of Rebble is more important than ever.  We’re excited to say that
Rebble is transforming into a non-profit to formalize what we’ve all always
hoped for: the community (that’s you!) are the owners of Rebble!  Rebble has
always been about preserving these humble little smartwatches as a little
oasis of user-respectful technology in a desert of big corporations trying
to sell your attention, and we’re excited to have a legal framework that
lets us codify our missions of: educating people about why these are
important; using them as a platform to teach embedded systems; preserving
the history of this quirky little platform; and building open source
software for the public good to keep the dream going long into the future.</p>

<p>It’s still early days, but more information will be available at <a href="https://rebble.foundation/">rebble.foundation</a> as soon<img title=":tm:" alt=":tm:" src="https://github.githubassets.com/images/icons/emoji/unicode/2122.png" height="20" width="20"> as we have it. 
In the mean time, expect more hackathons from us, now that we have a
framework to run them!  Oh, and speaking of which…</p>

<h2 id="-the-rebbleos-hackathon">💻 The RebbleOS Hackathon</h2>

<p><img src="https://rebble.io/images/tintin-blog-post/hackathon-002.gif" alt=""></p>

<p>The <a href="https://rebble.io/2023/05/12/a-look-back-at-the-rebble-hackathon.html">last Rebble hackathon</a> was so much fun, and we’ve been wanting to do another for some time. 
The Rebble project is a fantastic example of what community can achieve, and we intend to build on this in 2025 and beyond.</p>

<p>Writing Pebble apps is a fantastic way to delve into the world of embedded systems, and what better way to do that than with a hackathon?</p>

<p>Mark your calendars for the <strong>1st - 8th of March</strong> as we work on RebbleOS and other apps, and encourage you to do the same!</p>

<p>For more information see <a href="https://rebble.io/hackathon-002">/hackathon-002</a></p>

<h2 id="-old-dog-new-tricks">🐶 Old Dog, New Tricks</h2>

<p><img src="https://rebble.io/images/tintin-blog-post/snowy.png" alt=""></p>

<p>We’re also happy to announce that we’ve acquired the <a href="https://github.com/pebble-dev/snowy">source code for Snowy</a>! 
<a href="https://apps.rebble.io/en_US/application/561960c8a1dd2652af00000d">Snowy</a> was one of the most popular assistants for the Pebble, and is still a useful companion today.
However, given the current landscape of LLMs and voice assistants it is definitely due an upgrade, so expect to see this old dog appear in the hackathon.</p>

<h2 id="️-thats-all-for-now">🗒️ That’s all for now</h2>

<p>Between everything above, and the fact that progress continues on our replacement mobile app, the future of Rebble has never looked so bright. We are committed to an open-source community-owned smartwatch, and these announcements bring that reality even closer.
A huge thank you to everyone in the Pebble-verse who made this happen, especially those internal to Google who have helped ensure PebbleOS’s future. We’d like to especially thank Liam McLoughlin and Matthieu Jeanson, as well as Rebble superstar Katharine Berry. Thank you also to the many other Googlers who made this possible – and a massive shout out to Eric Migicovsky for ensuring this happened (and for creating Pebble in the first place).</p>

<p>One more shoutout: we would like to thank, of course, you!  Without all of you Rebblers who have been entrusting us for the past 8 years to keep the dream of an open-platform user-respectful smartwatch alive, PebbleOS wouldn’t be relevant at all today.  Your cumulative $3s a month have reminded the world that Pebble is worth preserving, and worth building on.  We love this platform, and we’re glad that you do too.  Thank you so much.</p>

<p>Stay tuned for more updates as the Hackathon launches, and when we have the first working versions of the new RebbleOS!</p>

<p>- Will ❤️</p>

<h3 id="clarifications">Clarifications:</h3>

<h4 id="how-can-i-get-involved-with-the-hackathon">How can I get involved with the hackathon?</h4>
<p>See <a href="https://rebble.io/hackathon-002/">here.</a></p>

<h4 id="did-google-gift-pebbleos-to-rebble-specifically">Did Google gift PebbleOS to Rebble specifically?</h4>
<p>No, Google have open sourced the PebbleOS to everyone, Rebble plans to make good use of this.</p>


<p>No. If you’re reading about another PebbleOS project somewhere other than this blog, it does not involve us.</p>

<h4 id="what-if-i-have-more-questions">What if I have more questions?</h4>
<p>Reach out to us at support@rebble.io, or drop a message <a href="https://rebble.io/discord">on Discord.</a></p>

    </div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Alpha Myth: How captive wolves led us astray (132 pts)]]></title>
            <link>https://anthonydavidadams.substack.com/p/the-alpha-myth-how-captive-wolves</link>
            <guid>42844619</guid>
            <pubDate>Mon, 27 Jan 2025 19:21:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://anthonydavidadams.substack.com/p/the-alpha-myth-how-captive-wolves">https://anthonydavidadams.substack.com/p/the-alpha-myth-how-captive-wolves</a>, See on <a href="https://news.ycombinator.com/item?id=42844619">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>In 1947, at Switzerland's Basel Zoo, animal behaviorist Rudolf Schenkel peered into an enclosure of captive wolves, meticulously documenting their interactions. What he witnessed – aggressive displays of dominance, rigid hierarchies, the emergence of an "alpha" male – would spawn decades of misunderstanding about power, leadership, and masculinity. His observations were later popularized by biologist L. David Mech in his influential 1970 book, "The Wolf: Ecology and Behavior of an Endangered Species," cementing the alpha wolf concept in both scientific literature and popular imagination.</p><div><figure><a target="_blank" href="https://images.unsplash.com/photo-1511561415413-c643d4969838?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxfHx3b2xmfGVufDB8fHx8MTczNzk5OTg0M3ww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://images.unsplash.com/photo-1511561415413-c643d4969838?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxfHx3b2xmfGVufDB8fHx8MTczNzk5OTg0M3ww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 424w, https://images.unsplash.com/photo-1511561415413-c643d4969838?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxfHx3b2xmfGVufDB8fHx8MTczNzk5OTg0M3ww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 848w, https://images.unsplash.com/photo-1511561415413-c643d4969838?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxfHx3b2xmfGVufDB8fHx8MTczNzk5OTg0M3ww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1272w, https://images.unsplash.com/photo-1511561415413-c643d4969838?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxfHx3b2xmfGVufDB8fHx8MTczNzk5OTg0M3ww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1456w" sizes="100vw"><img src="https://images.unsplash.com/photo-1511561415413-c643d4969838?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxfHx3b2xmfGVufDB8fHx8MTczNzk5OTg0M3ww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080" width="6000" height="4000" data-attrs="{&quot;src&quot;:&quot;https://images.unsplash.com/photo-1511561415413-c643d4969838?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxfHx3b2xmfGVufDB8fHx8MTczNzk5OTg0M3ww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:4000,&quot;width&quot;:6000,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;silhouette of dog&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="silhouette of dog" title="silhouette of dog" srcset="https://images.unsplash.com/photo-1511561415413-c643d4969838?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxfHx3b2xmfGVufDB8fHx8MTczNzk5OTg0M3ww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 424w, https://images.unsplash.com/photo-1511561415413-c643d4969838?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxfHx3b2xmfGVufDB8fHx8MTczNzk5OTg0M3ww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 848w, https://images.unsplash.com/photo-1511561415413-c643d4969838?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxfHx3b2xmfGVufDB8fHx8MTczNzk5OTg0M3ww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1272w, https://images.unsplash.com/photo-1511561415413-c643d4969838?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wzMDAzMzh8MHwxfHNlYXJjaHwxfHx3b2xmfGVufDB8fHx8MTczNzk5OTg0M3ww&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1080 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>Years later, studying wolves in the wilderness of Minnesota, Mech discovered something striking. </span><strong>In their natural habitat, wolf packs operated nothing like the prison-yard dynamics he'd observed in the zoo.</strong><span> Instead of hierarchies maintained through aggression, he found family units guided by experienced parents. Leadership wasn't seized through dominance – it was earned through nurturing, teaching, and protecting the collective good.</span></p><blockquote><p>"I felt responsible for unleashing this monster," Mech would later write about his initial research. "The concept of the alpha wolf as a 'top dog' fighting for dominance had become ingrained in our culture, but it was based on artificial conditions. Unfortunately, we've built much of our understanding of power and leadership on a foundation of captive behavior."</p></blockquote><p> This revelation would come too late – the captive wolf model had already escaped into human culture, shaping everything from executive leadership to dating advice, and creating what we might now recognize as a profound misunderstanding of power itself.</p><p><span>The irony is that in attempting to model human behavior on what we thought was "natural" wolf psychology, we instead normalized the very behaviors that emerge from unnatural confinement. Just as captive wolves exhibit exaggerated aggression and dominance, humans operating within rigid hierarchies and crushing social expectations often adopt similarly distorted patterns – what we might call </span><strong>"captive male syndrome."</strong></p><p>Consider how these dynamics manifest in Silicon Valley, where Facebook's infamous "move fast and break things" mantra shaped a generation of tech culture. This emphasis on speed and disruption at any cost has created work environments that mirror the artificial pressures of captivity, where displaying dominance often takes precedence over fostering sustainable innovation.</p><p>The toll is measurable. According to a recent survey by Blind, an anonymous professional network, 57% of tech employees report experiencing burnout – a stark indicator of an industry grappling with unsustainable expectations. </p><p><span>The parallels to captive wolf behavior are striking. Just as confined wolves display exaggerated aggression and dominance to cope with their unnatural environment, tech founders often find themselves performing an amplified version of leadership – one that prioritizes the appearance of unwavering strength over authentic collaboration and sustainable innovation. This culture of </span><strong>performative dominance</strong><span>, according to workplace researchers at Pluralsight, directly contributes to chronic exhaustion, disengagement, and a diminished sense of accomplishment among workers.</span></p><p>The costs are steep. Research from the American Psychological Association shows that men who strongly adhere to traditional "alpha" masculine norms are:</p><ul><li><p>More likely to suffer from depression and anxiety</p></li><li><p>Less likely to seek help</p></li><li><p>Report lower relationship satisfaction</p></li><li><p>Struggle to maintain close friendships</p></li></ul><p>The very traits we've coded as strength – emotional stoicism, aggressive competition, rejection of vulnerability – turn out to be profound weaknesses.</p><p><span>But there's hope in the wilderness. Just as Mech's later research revealed the true nature of wolf leadership, innovative organizations are discovering the power of what we might call </span><strong>"wild leadership"</strong><span> – approaches that embrace our natural capacities for cooperation and care.</span></p><p>Take Patagonia, where founder Yvon Chouinard deliberately rejected the alpha CEO model. Instead of ruling from above, he built a flat structure where decisions emerge from collaboration. The company's "let my people go surfing" philosophy – which encourages employees to step away from work to pursue passion and maintain balance – seems radical only because we've normalized captive behavior. The results speak for themselves: Patagonia enjoys employee turnover rates 25% lower than industry averages and consistently outperforms more traditionally structured competitors.</p><p>The path forward requires more than just rejecting the alpha male myth. We need to redesign the structures that created captive behavior in the first place. This means rethinking everything from how we raise boys to how we run companies. It means creating space for a masculinity that draws strength from connection rather than competition, from nurturing rather than dominating.</p><p><em>In the end, we might learn our most important leadership lessons not from wolves in cages, but from those running free – where strength flows not from who can dominate, but from who can best ensure the pack's survival and flourishing. The question isn't whether you're alpha enough to lead. It's whether you're wise enough to leave the cage behind.</em></p><p>To join our next “Wild Leadership” men’s event or to explore deeper work for you or your organization, reach out. </p><p><em><strong>Anthony David Adams</strong><span> created one of the “Top 25 Blogs Worldwide” according to TIME / CNN; is known as the “unicorn whisperer” for his </span><a href="http://earthpilot.org/" rel="nofollow ugc noopener">high-stakes performance advisory work</a><span> with once-in-a generation talent from founders to surgeons to broadway legends; was </span><a href="https://www.thirteen.org/programs/mysteries-of-mental-illness/episode-4-preview-new-frontiers-8ssere/" rel="nofollow ugc noopener">the first person to openly administer underground MDMA on national TV with PBS</a><span>; and is the founder of </span><a href="http://earthpilot.ai/" rel="nofollow ugc noopener">EarthPilot : Mission Support for Spaceship Earth</a><span>. </span></em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Taylorator – All Your Frequencies Are Belong to Us (214 pts)]]></title>
            <link>https://www.scd31.com/posts/taylorator</link>
            <guid>42843623</guid>
            <pubDate>Mon, 27 Jan 2025 17:42:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scd31.com/posts/taylorator">https://www.scd31.com/posts/taylorator</a>, See on <a href="https://news.ycombinator.com/item?id=42843623">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section><p>For the past two weeks or so, I've been working on constructing the Taylorator. The Taylorator is a piece of software which allows me to flood the FM broadcast band with Taylor Swift's music. No matter where you tune your radio, you will only be able to listen to her!</p>
<p>Okay, I admit that you could technically use the Taylorator to broadcast whatever music you want, so maybe it's a bit of a misnomer. But for some reason I figured this would be funnier.</p><p>What do I mean by flooding the FM broadcast band? Well, in Canada and the US (and maybe other places too), the FM broadcast band spans 88 MHz - 108 MHz. You can't broadcast wherever, though. Stations will only appear on odd-numbered frequencies, like 88.1 MHz, 94.5 MHz, 107.3 MHz, etc. There's a technical reason for this - every FM broadcast takes up about 150 KHz of bandwidth, and spacing the broadcasts like this allows for an extra 50 KHz of wiggle room.</p><p>This also works out to 100 different frequencies that we need to populate (with 100 different songs). So, how can we accomplish this?</p></section><h2>Software Defined Radio</h2><section><p>SDR, or Software Defined Radio, is a paradigm where you do most of your signal processing in software, and then a relatively dumb piece of hardware creates a real-world signal from this virtual signal. It works similarly to a sound card. It takes in a series of samples, and spits out a waveform that matches these samples.</p><p><a href="https://www.scd31.com/img/taylorator/limesdr.png"><img src="https://www.scd31.com/thumb/taylorator/limesdr.png"></a></p><p>They make SDRs that can transmit, receive, or do both. For this project we don't care about receive, and only need to be able to transmit. I chose to use a LimeSDR mini, because it can transmit, has a wide enough bandwidth, and I already had it lying around.</p><p>One important difference between a sound card and an SDR is that a sound card takes real-valued samples, and an SDR takes complex-valued samples. That is to say, each SDR sample can be presented as a single number <code>a + bi</code>, where <code>a</code> and <code>b</code> are real numbers. This is primarily done because it cuts the required sample rate in half, as it allows for negative frequencies. On the hardware side, this results in a simpler design, which lowers cost.</p></section><h2>Audio preparation</h2><section><p>There are a few things we need to do to our raw audio to prepare it for modulation. First of all, we want the sample rate of all of our different songs to be the same. I chose 44.1 KHz as the target sample rate, but 48 KHz would also be a sane value (or anything else, really). I wrote a rational resampler which does this by upsampling, linear interpolating, and decimating to the target sample rate.</p><p>Next, we need to run our audio through a low-pass filter and perform FM-preemphasis. I won't touch on low-pass filtering much, but FM-preemphasis is basically just a high-pass filter. The idea is that random atmospheric noise, when demoulated by an FM receiver, is biased towards high frequencies. We can get around this by boosting our high frequencies on transmit (pre-emphasis) and having the receiver attenuate the same frequencies (de-emphasis).</p><p>This is all done before the modulation actually starts. Modulation takes a ton of CPU power so we want to pre-compute whatever we can.</p></section><h2>FM modulation in software</h2><section><p>FM modulation follows a pretty simple formula. Basically, <code>y_n = e^(i*pi*sum(x))</code>, where <code>y_n</code> is the output sample, and <code>x</code> is the input audio stream up until this point. (Sorry, my blog doesn't support LaTeX! Maybe I should add that...) In other words, we're rotating around a circle, and the speed at which we rotate around this circle is dictated by the sum of all the audio samples we've seen up until this point. In the complex world, rotation speed is analogous to frequency, so this is all we need to build an FM modulator!</p><p>In practice, though, this is actually pretty difficult for our use-case. We need to modulate 100 audio streams at once. Each one needs to be offset by up to +/- 10 MHz, so we need to sample at 20MSPS. Performance was the name of the game, and I spent probably a week banging my head against my computer in order to get it to an acceptable level. Huge thanks to my friend Won, who gave me a ton of different ideas to try.</p><p>The current architecture modulates all audio channels at once, so we only need to write to our output array once (instead of reading/writing 100 times). The modulator is also responsible for "biasing" each channel to be centered around a different frequency. This used to be done as a separate stage but doing it as part of modulation sped things up significantly. Finally, rather than computing trig operations, a lookup table is generated which converts between phase angle and its complex number representation. This lookup table is also gain-compensated, so that when we add up the 100 outputs, we don't end up clipping.</p><p>I'm not convinced that I'm operating anywhere close to peak efficiency. There may be some huge DSP-specific shortcut that I'm overlooking - I'm certainly no expert. But the current code works well enough.</p></section><h2>Performance</h2><section><p>Due to the increase in required sample rate, as well as the increase in number of channels, required processing power grows at O(n^2), where n represents the amount of bandwidth we're covering.</p><p>On my laptop, which has a 10th-gen i5 CPU, I can only get to about 0.5x real-time performance if I target the entire FM broadcast band (88 MHz - 108 MHz). However, if I decrease that slightly to 88 - 104 MHz, then my laptop is able to handle it at slightly better than real-time.</p><p>My desktop, with a Ryzen 2700x CPU, fares better. Even only using a few cores, it can easily manage 2x real-time performance or more. This is a 7-year-old CPU, so the bar isn't actually too high here.</p><p>Memory usage is also pretty high. Since we're loading all songs into memory and pre-computing beforehand, it can take a few gigabytes to hold everything. With my music, I've noticed around 3.5 GB of RAM usage. On top of this, there's also per-thread RAM usage, though it should be less significant. There's certainly room for improvement here. Just changing how audio is stored could cut this usage in half, or more.</p></section><h2>Legality</h2><section><p>Whenever I told someone about the Taylorator during its development, the question I'd consistently get asked is, "is this legal?". This is going to depend on exactly where you live and exactly how you're using the Taylorator, but in general, I think the answer is... probably not.</p><p>There are generally cut-outs for very low power FM transmitters, like the ones people use in their car. Usually, though, this requires the transmitter itself to be licensed, and of course, the software I have written has no such license.</p><p>In practice, it's probably not a huge deal? A few mW spread over 20 MHz of bandwidth results in a pretty weak signal. Obviously, don't do illegal things (and if you do, don't tell me about it)! If you connected your SDR up to an amplifier you would almost certainly get in a bunch of trouble. So, uh, don't do that.</p></section><h2>Source Code</h2><section><p>As always, this project is <a href="https://gitlab.scd31.com/stephen/taylorator">open source</a>!</p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DeepSeek releases Janus Pro, a text-to-image generator [pdf] (564 pts)]]></title>
            <link>https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf</link>
            <guid>42843131</guid>
            <pubDate>Mon, 27 Jan 2025 16:57:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf">https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=42843131">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>GitHub Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;security_link_product_navbar&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code Review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_product_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
        <p>Code Search</p><p>
        Find more, search less
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>

                  <li>
      
      
</li>

                    <li>
      
      <div>
                    <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;white_papers_ebooks_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;white_papers_ebooks_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      White papers, Ebooks, Webinars

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      
      <div>
              <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

                </ul>
              </div>
              <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

                </ul>
              </div>
              
          </div>
</li>


                <li>
      
      <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>Enterprise platform</p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:deepseek-ai/Janus" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="AZh1BsnuYrMa8XYwSsvEvprN4QiDVKK9Ro9Izb5bgtAX9c5eSNLKzgF8xQC0Ip3REUpceX9BJ3f5srJV0VDakQ" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="deepseek-ai/Janus" data-current-org="deepseek-ai" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=deepseek-ai%2FJanus" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="4a0f27a000a78e9a4f92df59b03c3d2e1143bca405fcd75da8c4841105eecdae" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a>
          
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Operation Leg: When the RAF airdropped a prosthetic leg into a German POW castle (159 pts)]]></title>
            <link>https://www.rafbf.org/news-and-stories/raf-history/operation-leg-pilot-unlike-any-other</link>
            <guid>42842257</guid>
            <pubDate>Mon, 27 Jan 2025 15:41:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rafbf.org/news-and-stories/raf-history/operation-leg-pilot-unlike-any-other">https://www.rafbf.org/news-and-stories/raf-history/operation-leg-pilot-unlike-any-other</a>, See on <a href="https://news.ycombinator.com/item?id=42842257">Hacker News</a></p>
Couldn't get https://www.rafbf.org/news-and-stories/raf-history/operation-leg-pilot-unlike-any-other: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[My failed attempt to shrink all NPM packages by 5% (282 pts)]]></title>
            <link>https://evanhahn.com/my-failed-attempt-to-shrink-all-npm-packages-by-5-percent/</link>
            <guid>42840548</guid>
            <pubDate>Mon, 27 Jan 2025 12:44:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://evanhahn.com/my-failed-attempt-to-shrink-all-npm-packages-by-5-percent/">https://evanhahn.com/my-failed-attempt-to-shrink-all-npm-packages-by-5-percent/</a>, See on <a href="https://news.ycombinator.com/item?id=42840548">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In 2022, I had an idea that could decrease the size of all newly-published npm packages by about 5%, and it was completely backwards compatible. This would have improved performance and reduced storage costs.</p><p>I eagerly pitched this idea to the npm maintainers, convinced it was a clear win. But after a few months, my proposal was rejected. To be clear: <em>I think this was the right call!</em></p><p>Here’s what happened. I hope this story will be useful to others.</p><h2 id="technical-background">Technical background</h2><p>Two things to know before diving in: how npm packages are distributed, and about the Zopfli compressor.</p><h3 id="npm-packages-are-just-gzipped-tarballs">npm packages are just gzipped tarballs</h3><p>First thing to know: npm packages are distributed as tar archives compressed with gzip. In other words, they’re just <code>.tar.gz</code> or <code>.tgz</code> files.</p><p>You can download these archives using <code>npm pack $PACKAGE_NAME</code>:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>npm pack express &amp;&amp; ls
</span></span><span><span><span># =&gt; express-4.21.2.tgz</span>
</span></span></code></pre></div><p>If you <a href="https://evanhahn.com/mnemonic-to-remember-tar-commands/">extract this tarball</a>, you’ll see all of the package’s files, such as <code>package.json</code>.</p><h3 id="zopfli-a-gzip-compatible-compressor">Zopfli, a gzip-compatible compressor</h3><p>The second thing to know about: <a href="https://github.com/google/zopfli">Zopfli</a>.</p><p>Zopfli can create gzip-compatible data that’s smaller than other tools can. For example, compare the <code>zopfli</code> command to the <code>gzip</code> command:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>gzip -9 romeo_and_juliet.txt
</span></span><span><span>du -h romeo_and_juliet.txt.gz
</span></span><span><span><span># =&gt; 64K     romeo_and_juliet.txt.gz</span>
</span></span><span><span>
</span></span><span><span>zopfli romeo_and_juliet.txt
</span></span><span><span>du -h romeo_and_juliet.txt.gz
</span></span><span><span><span># =&gt; 60K     romeo_and_juliet.txt.gz</span>
</span></span></code></pre></div><p>As you can see, <code>zopfli</code> produces smaller files than <code>gzip</code>.</p><p>If Zopfli produces smaller sizes than gzip, why not use it everywhere? Unfortunately, Zopfli is great but it’s <em>much</em> slower than regular gzip.</p><div><pre tabindex="0"><code data-lang="sh"><span><span>time gzip -9 romeo_and_juliet.txt
</span></span><span><span><span># =&gt; real   0m0.016s</span>
</span></span><span><span>
</span></span><span><span>time zopfli romeo_and_juliet.txt
</span></span><span><span><span># =&gt; real   0m0.462s</span>
</span></span></code></pre></div><p>In this simple test, Zopfli is about <em>28 times slower</em>! That means it’s bad for content that changes a lot, but good for content that doesn’t.</p><p>In my opinion, Zopfli’s killer feature is that it creates files that are backwards compatible with existing decompressors. Other compression algorithms, like LZMA, can be better than gzip, but you can’t decompress their results with <code>gunzip</code> or equivalent. With Zopfli, you can!</p><div><pre tabindex="0"><code data-lang="sh"><span><span>cat my_file.txt
</span></span><span><span><span># =&gt; Hello world</span>
</span></span><span><span>
</span></span><span><span>lzma -c my_file.txt | gunzip -c
</span></span><span><span><span># =&gt; gunzip: unknown compression format</span>
</span></span><span><span>
</span></span><span><span>zopfli -c my_file.txt | gunzip -c
</span></span><span><span><span># =&gt; Hello world</span>
</span></span></code></pre></div><p>So I wondered: if npm packages are compressed with gzip, <strong>could npm packages be compressed better with Zopfli?</strong> The answer is “yes”.</p><h2 id="proof-of-concept">Proof of concept</h2><p>To see if this would work, I tried it on one of my own npm packages.</p><p>I did something like this:</p><ol><li><p>Get the file that is published by default. I used <a href="https://www.npmjs.com/package/humanize-duration">HumanizeDuration.js</a>, one of my more popular packages, as a test.</p><div><pre tabindex="0"><code data-lang="sh"><span><span>cd HumanizeDuration.js
</span></span><span><span>npm pack
</span></span><span><span><span># ...</span>
</span></span><span><span><span># =&gt; humanize-duration-3.32.1.tgz</span>
</span></span></code></pre></div><p>This created <code>humanize-duration-3.32.1.tgz</code>, which was ~17 kibibytes large. I could <code>npm publish</code> this right now, but let’s try shrinking it.</p></li><li><p>Decompress (but don’t unarchive) the file.</p><div><pre tabindex="0"><code data-lang="sh"><span><span>gunzip humanize-duration-3.32.1.tgz
</span></span></code></pre></div><p>This leaves us with an uncompressed tarball, <code>humanize-duration-3.32.1.tar</code>.</p></li><li><p>Re-compress it with Zopfli.</p><div><pre tabindex="0"><code data-lang="sh"><span><span>zopfli humanize-duration-3.32.1.tar
</span></span></code></pre></div><p>As expected, this produced a slightly smaller file by over a kilobyte. That’s promising!</p></li><li><p>Make sure I could still install it. I installed the tarball, and tried to use it.</p><div><pre tabindex="0"><code data-lang="sh"><span><span>cd <span>"</span><span>$(</span>mktemp -d<span>)</span><span>"</span>
</span></span><span><span>
</span></span><span><span>npm install /path/to/recompressed/humanize-duration-3.32.1.tar.gz
</span></span><span><span><span># =&gt; added 1 package in 123ms</span>
</span></span><span><span>
</span></span><span><span>node -p <span>'require("humanize-duration")(1234)'</span>
</span></span><span><span><span># =&gt; 1.234 seconds</span>
</span></span></code></pre></div><p>It worked!</p></li></ol><p>This saved 1114 bytes for a ~6.2% reduction. And this is completely backwards-compatible. That made sense; this is what Zopfli is supposed to do!</p><p>I also tried it on a few of my other packages. Everything seemed to work and offered a ~5% size reduction. Great!</p><p>I published one of my modules this way, and nobody complained. I later did this for <a href="https://helmetjs.github.io/">Helmet</a>, my <a href="https://evanhahn.com/lessons-learned-maintaining-a-sorta-popular-open-source-package/">most popular module</a>—again, without issue.</p><p>This was, and still is, a minor success. This is a small optimization that saves about 2 gigabytes of bandwidth per year across all installations. I doubt many individual installs were perceptibly faster after this change…but it’s nice to do a tiny amount of work for a 5% improvement!</p><p>Now that I’d proved it’d work for my modules, I wondered: <em>could this be done on a wider scale?</em></p><h2 id="2022-05-27-asking-for-feedback">2022-05-27: asking for feedback</h2><p>Given that this worked fine for my packages, could this be done for the <em>entire npm registry</em>?</p><p>On May 27, I asked my <a href="https://signal.org/">Signal</a> colleagues for feedback on an idea. Here’s what I asked (reformatted slightly):</p><blockquote><p>Here is something I would like feedback on:</p><p>npm packages are just gzipped tarballs (try it yourself with <code>npm pack $PACKAGE_NAME</code>).</p><p>Zopfli does a better job at gzipping files than <code>gzip -9</code>.</p><p>Therefore, the npm registry and developers could save bandwidth if they compressed new (or re-compressed existing) packages with Zopfli.</p><p>With React as an example:</p><ul><li>The latest version of React is 81,166 bytes, compressed with the equivalent of <code>gzip -9</code></li><li>Re-compressing it with Zopfli saves 4019 bytes; about a 5% reduction</li><li>React was downloaded ~562M times last year</li><li>That would save ~2 TiB of bandwidth just for React</li></ul><p>To be clear, this is completely backwards compatible as far as I understand.</p></blockquote><p>I got two important pieces of feedback:</p><ul><li><a href="https://belkadan.com/about">Jordan Rose</a> pointed out that decompression time could be significant. I hadn’t checked this! I ran some quick tests and found that this wasn’t an issue.</li><li><a href="https://fosstodon.org/@indutny">Fedor Indutny</a> pointed out that npm’s lockfile, <code>package-lock.json</code>, contains a checksum of the package file. The npm people couldn’t easily re-compress existing packages without breaking things. It would only work for newly-published files; new packages or new versions of existing ones.</li></ul><p>Armed with that feedback, I brought the idea to the npm folks.</p><h2 id="2022-05-29-rfc-time">2022-05-29: RFC time</h2><p>I learned that the npm CLI people have <a href="#TODO">a formal proposal process</a> where you write up a document and submit a patch.</p><p>I spent a few days writing and editing my proposal, <a href="https://github.com/npm/rfcs/pull/595">“Improving tarball compression while maintaining backwards compatibility”</a>. It was 708 words. I tried to make it sound compelling with things like this:</p><blockquote><p>Even a small savings, like 5%, would reduce the registry’s bandwidth usage by multiple terabytes. For example: React&nbsp;<a href="https://npm-stat.com/charts.html?package=react&amp;from=2021-01-01&amp;to=2021-12-31">was downloaded 561,743,096 times in 2021</a>. If we assume that each of these downloads shrunk from 81,166 bytes to 77,147 bytes, the registry would have saved more than 2 terabytes in bandwidth for React alone.</p></blockquote><p>On May 29, I finally submitted my RFC. I was nervous!</p><h2 id="2022-06-01-they-discussed-it">2022-06-01: they discussed it</h2><p>A few days later, the npm CLI people had <a href="https://github.com/npm/rfcs/issues/596">a meeting where they discussed a bunch of stuff, including my RFC</a>. I wasn’t able to attend but watched the recording. Overall, they felt it was worth evaluating further but were cautious. From their notes:</p><blockquote><p>Overall sentiment is that the compression improvement is welcome but it looks like it would take a proof of concept and challenge some of the edge cases to see if there are any unintended consequences, etc</p></blockquote><p>I built a <a href="https://evanhahn.github.io/npm-repack-with-zopfli-proof-of-concept/">little proof of concept web app</a> that used a WebAssembly port of Zopfli to recompress npm packages and <a href="https://github.com/npm/rfcs/pull/595#issuecomment-1145168973">posted about it on the RFC</a>.</p><p>I attended the next meeting a couple of weeks later.</p><h2 id="2022-06-15-the-meeting">2022-06-15: the meeting</h2><p>I attended a call on June 15.</p><p>I did the bad thing where I wasn’t really listening until it was my turn because I was thinking about what I was going to say. When it was finally my turn, I stammered.</p><p>Watching it back, I cringe a bit. I was wordy, unclear, and unconvincing. But I think I did an <em>okay</em> job making my point: npm packages could become ~5% smaller if we could figure out how to run Zopfli at publish time.</p><p>You can <a href="https://www.youtube.com/live/l8ob4j_KOR4?t=853">watch my mumbling in the recording</a>, as well as the npm maintainers’ feedback.</p><p><em>“Who benefits from this?”</em> was probably the biggest question. It was discussed that the npm registry folks, paying storage costs, might care about this. But “literally no one’s noticed” some other recent performance improvements, so they wanted to see more data. Was this just something I thought was neat (a “performance romantic”, as one person called it), or did this solve a real problem for users?</p><p>There were also concerns about including WebAssembly, the performance implications at install time, and Zopfli licensing issues.</p><p>I was tasked with some investigation on the topics above, and I got digging.</p><h2 id="2022-07-31-giving-up">2022-07-31: giving up</h2><p>After a bunch of thinking and feedback, what once seemed like an obviously great idea now seemed…well, less great.</p><p>On July 31, after doing a bunch of research, I posted <a href="https://github.com/npm/rfcs/pull/595#issuecomment-1200480148">a comment on the RFC</a>.</p><p>I wrote up some pros and cons. The pros:</p><ul><li>The top 250 npm packages would shrink by about 4.5% with this change.</li><li>This compression would be backwards compatible, and would require no changes from anyone else.</li></ul><p>But the cons were substantial:</p><ul><li>Integrating Zopfli into the npm CLI would be difficult.</li><li>Publishing would be slower—in some cases, <em>much</em> slower.</li><li>This wouldn’t retroactively apply to existing packages.</li></ul><p>After this discussion and thinking about the tradeoffs, I felt that it was not worth it, and I closed my RFC.</p><p>And that was that!</p><h2 id="lessons-learned">Lessons learned</h2><p>I learned a lot during this process.</p><p>It was a bit nerve-wracking, but I learned how to make proposals like this. I’d written internal proposals at work, but I’d never made a semi-official RFC like this before.</p><p>I also think I did a pretty bad job in my verbal communication during the meeting. Perhaps it was because I was nervous. I could have done a better job communicating about the tradeoffs—good and bad—of the proposal. And I could have been less wordy!</p><p>I also learned that things that seem like obvious wins aren’t always obvious wins, either because the motivation isn’t there or because there are trade-offs I minimized.</p><p>Overall, even though my proposal was denied, I’m glad I did this. I think I’m a better engineer for it! I hope this story was interesting and useful to you, dear reader.</p><p>(Oh, and I’m still <a href="https://github.com/helmetjs/helmet/blob/632e629b08de04bbd7188934641f3535af21685d/build/build-package.ts#L341">compressing my own modules with Zopfli</a>.)</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oliver Heaviside and the theory of transmission lines (2021) (219 pts)]]></title>
            <link>https://www.pa3fwm.nl/technotes/tn28-heaviside-transmission-lines.html</link>
            <guid>42840352</guid>
            <pubDate>Mon, 27 Jan 2025 12:18:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pa3fwm.nl/technotes/tn28-heaviside-transmission-lines.html">https://www.pa3fwm.nl/technotes/tn28-heaviside-transmission-lines.html</a>, See on <a href="https://news.ycombinator.com/item?id=42840352">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p><em>Pieter-Tjerk de Boer, PA3FWM <a href="mailto:web@pa3fwm.nl">web@pa3fwm.nl</a></em></p><p>
(This is an adapted version of an article I wrote for the Dutch
amateur radio magazine <em>Electron</em>, November 2021.)
</p><p>

<img src="https://www.pa3fwm.nl/technotes/tn28fig1.jpg" alt="Oliver Heaviside">

An antenna cable is not just a piece of wire.
Technically, it's called a "transmission line",
with special properties such as its characteristic impedance.
But transmission lines are quite a bit older than radio technology: they date back to the
second half of the 19th century, in the form of (mostly submarine) telegraph cables.
In this article we look at the principles and properties of transmission lines,
with special emphasis on Oliver Heaviside's contribution to our knowledge of them.

</p><h2>Oliver Heaviside</h2><p>

After secondary school, Oliver Heaviside (1850-1925) started working at the company
which operated the submarine telegraph cable between Newcastle (UK) and Denmark.
At first he worked as a telegraph operator, but soon he also got involved with the
(electro)technical side of the telegraph systems.
One of the things he noticed, was that when water leaked into a submarine cable and
progressively short-circuited it, the signals did not just become weaker (as expected),
but also clearer, less distorted.

</p><p>
In those days, electrical engineering was still in its infancy.
Thanks to the work of physicists like Volta, Ampère, Ørsted and Faraday, there was a decent
understanding of generating electrical currents and moving compass needles using an electromagnet.
Together, that is enough for building a telegraph, at least in principle.
But if one uses as very long cable, and tries to send dots and dashes at a high rate,
it turned out to not work so well.
There was little theoretical understanding of this,
particularly among the more practically minded people who cobbled together telegraph systems.

</p><p>
Heaviside studied physics by himself, and stumbled on the books by James Clerk Maxwell.
Maxwell's ideas about electromagnetism were, at that time, rather speculative and not widely accepted,
but Heaviside got enthousiastic, studied them, and succesfully applied this theory to telegraph lines.

</p><p>
Thus, Heaviside, who never had studied at a university, rose from being a humble telegraph operator
to a respected physicist.
After quitting his job at the telegraph company at the age of 24, he never had another job.
The rest of his life he lived in relative poverty while working on the theory.
He became one of the so-called Maxwellians: a group of physicists who enhanced Maxwell's
theory after his untimely death (in 1879 at the age of 48) and popularised it.
One of Heaviside's achievements is that he converted Maxwell's twenty mathematical formulas
into a more accessible set of just four, which nowadays are taught at all universities
as "Maxwell's equations".
If you want to learn more about this remarkable person, I recommend his biography [1].

</p><h2>Thomson's model</h2>
<p><img src="https://www.pa3fwm.nl/technotes/tn28fig2.png" alt="Thomson's model">

William Thomson (later Lord Kelvin) 
attempted to describe what happens in a long telegraph cable.
His model is sketched in the figure.
He mentally chopped the cable into short pieces, each of which has some resistance and some capacitance.
Next, he calculated what happens if at the left end one suddenly applies a voltage of say 1 volt.
The graphs show the result, for a 4 km long cable having 0.1 ohm of resistance per meter,
and 10 pF of capacitance per meter.
The cable has been divided into 4 pieces of 1 km each, so each having 100 ohm and 10 nF.
We see that the voltage on the first capacitor gradually increases to 1 volt: that's logical,
as the capacitor gets charged via the first resistor.
The voltage on the second capacitor also gradually increases to 1 volt, but slower:
that makes sense, as it is charged from the first capacitor.
And so on.
At the right end of the cable, the voltage increases only very gradually,
and this slow increases puts a limit on how quickly Morse code signs can be sent.

</p><p>
However, Thomson's model is wrong.


</p><h2>Heaviside's model</h2>
<p><img src="https://www.pa3fwm.nl/technotes/tn28fig3.png" alt="Heaviside's model">

Heaviside realised that the inductance of the cable is also important.
See the next figure: here we have replaced Thomson's resistors by inductors, of 1 µH per meter of cable length.

</p><p>
First have a look at the first set of graphs, marked as "4 sections".
We see that the voltage on the first capacitor reaches the full 1 volt much earlier
than in Thomson's model, and even overshoots.
This is because once there is current flowing in an inductor, this current doesn't
just stop when the voltage across the coil becomes lower.
This faster increase of the voltage, and the fact that the current doesn't just stop,
also causes the second capacitor to be charged earlier and faster than in Thomson's model,
and so on.

</p><p>
Of course, modelling a 4 km long cable in just 4 pieces is not very realistic.
For a better model, we could e.g. model it using 10 times as many pieces,
each 10 times shorter (i.e., 40 pieces of 100 m each),
each with 10 times less capacitance and inductance.
The result is shown in the second set of graphs.
The third set of graphs is for a yet 10 times finer modelling of the cable.
The graphs now show the voltage at every 10th and every 100th capacitor, respectively;
i.e., still at distances of 1, 2, 3 and 4 km from the start of the cable,
like in the first set of graphs.
We see that with the more refined model, the voltages increase faster and the overshoot takes less long.

</p><p>
The schematic with all those coils and capacitors resembles a low-pass filter,
and indeed, we see that the voltages increase only gradually,
hinting at the absence of high frequencies.
When one partitions the model in ever smaller pieces, the inductances and capacitances
become smaller and the filter's cut-off frequency becomes higher.
If one mathematically takes the limit, eventually modelling the cable as consisting
of infinitely many pieces, each having infinitely little inductance and capacitance,
one gets an ever more accurate model.
While doing so, the low-pass effect disappears, and the voltage jump from 0 to 1 volt
is transmitted without distortion.



</p><h2>Impedance</h2><p>

Heaviside's model also helps us to understand what the "impedance" of a cable is.
At the left, suddenly a voltage of 1 volt is applied to the cable.
The capacitors are as yet uncharged, so there's 1 volt across the first inductor,
causing a gradually increasing current to flow.
How large will that current become?
That depends on the inductance: the more inductance, the slower the current increases.
And it also depends on the capacitance: the more capacitance, the more charge needs to be supplied
to charge it to 1 volt.
When the capacitor has been charged to 1 volt (ignoring the overshoot),
there will be 0 volts across the inductor, so the current through it will no longer change.
The current doesn't become 0, but remains constant, flows into the second inductor,
charges the second capacitor, and so on.

</p><p>
And what happens when also the last capacitor has been charged?
As noted above, the current through those inductors cannot just stop.
If we "terminate" the cable in a resistor, as shown in the figure, then the
current will flow through the resistor and cause a voltage drop across it.
If the resistor has exactly the right value, then that voltage drop is exactly 1 volt.
Then we reach a stable state: all capacitors are charged to 1 volt, across the coils
there's no voltage, and a constant current flows from the source through the cable
and the termination resistor.

</p><p>
If the termination resistor is too large, the voltage drop across it will be more than 1 volt,
so the last capacitor will be charged to more than 1 volt.
Via the last inductor a part of that charge will then flow back from the last to the
second-to-last capacitor, from there to the third-last capacitor, and so on:
we get a <i>reflected</i> wave.
Something similar happens if the termination resistor is too small.

</p><p>
The value of the termination resistor which does <i>not</i> cause a reflection,
is called the impedance of the cable.
It turns out that this equals <math><msqrt><mi><i>L/C</i></mi></msqrt></math>,
where <i>L</i> and <i>C</i> are the inductance and capacitance per meter of cable length.
Note that this formula matches what we already observed earlier: more <i>L</i> means less current
and thus higher termination resistor needed to still drop 1 volt;
similarly, more <i>C</i> means more current and thus lower termination resistor.


</p><h2>Speed</h2><p>

In the previous figure, we effectively saw a <i>wave</i> move from left to right through the cable;
the farther from the source, the later the voltage change arrives.
How fast does this wave move?
That also depends on the values of <i>L</i> and <i>C</i>.
The larger the inductance <i>L</i>, the slower the current increases (at given voltage),
so the longer it takes to charge the next capacitor.
And the larger <i>C</i>, the longer it takes (at given current) to charge the capacitance.
Heaviside showed that the speed equals </p><mathml>1/<msqrt><mi><i>LC</i></mi></msqrt>.

<p>
Does this mean that we can make a cable with any desired speed,
simply by choosing <i>L</i> and <i>C</i> appropriately?
Perhaps even faster than light? (Einstein already starts turning over in his grave.)
No: it turns out that we have only limited freedom in choosing <i>L</i> and <i>C</i>.
Changing the shape and size of the cable affects both <i>L</i> and <i>C</i>, and always
such that the speed of light is never exceeded.

</p><p>
<img src="https://www.pa3fwm.nl/technotes/tn28fig4.png" alt="[properties of coaxial cable]">
As an example, consider a coaxial cable.
If one makes the center conductor thinner, the capacitance between center conductor and
shield decreases, so by the formula one would expect the speed to increase.
Unfortunately, at the same time the inductance increases!
That's (among others) because making the center conductor thinner causes the currents
inside that center conductor to be closer together, and thus sense more of each other's
magnetic field (which, after all, is what causes (self)-inductance).

<o>
The figure shows, for a coaxial cable with air as isolation,
the theorectical dependence of the capacitance and inductance (both per meter) on the ratio of the
diameters of the center conductor and the shield.
Furthermore, the resulting impedance and wave velocity are indicated.
The solid lines are based on the assumption that the current spreads itself equally
over the entire cross-section of the center conductor.
We see that in this case the velocity increases when the center conductor is made thinner,
but does not exceed the speed of light (300 × 10<sup>6</sup> m/s).
At higher frequencies the skin-effect kicks in, forcing the current to only flow on the outside
of the center conductor.
That case is indicated with dotted lines, and the speed exactly equals the speed of light,
regardless of the diameters.

</o></p><p>
If we fill the cable with e.g. some plastic material, the capacitance increases while the
inductance remains the same. Then the speed decreases; this is generally described
as the "velocity factor" being less than 1.

</p><h2>Loss and distortion</h2>
<img src="https://www.pa3fwm.nl/technotes/tn28fig5.png" alt="[Heaviside's model with loss]">

So far, we haven't included loss in the model, but a real cable does have loss due to resistances,
and Heaviside included this in his model, as sketched at the right.
There are two kinds of loss.
The first one is the resistance of the copper wire itself; to model this,
Heaviside included a resistance of <i>R</i> ohms per meter in series with each inductance.
The second one is the leakage of the capacitor's isolation, modelled as a parallel resistance 1/<i>G</i>.
(We write this as 1/<i>G</i> because this resistance is inversely proportional to the length;
the shorter the cable section, the less leakage, so the larger the leakage resistance.
Thus <i>G</i> itself, being the inverse of the resistance, is again directly proportional
to the length; it is expressed in Ω<sup>-1</sup> per meter, also called Siemens per meter.)

<p>
Heaviside showed that losses do not just attenuate the signal, but also cause distortion.
In fact we already saw this in Thomson's model in the first figure:
the sudden increase of the voltage at the input of the cable, is distorted to something
that only rises slowsly, as it travels down the cable.

</p><p>
However, Heaviside also found out that this distortion disappears if the following
condition is satisfied: <i>L</i>/<i>R</i> = <i>C</i>/<i>G</i>.
If there is no loss, then <i>R</i> and <i>G</i> are both 0, so the condition is satisfied.
But a realistic cable usually has <i>L</i>/<i>R</i>  much smaller than <i>C</i>/<i>G</i>,
because <i>G</i>, the leakage of the isolation, is almost zero (good isolation material),
and particularly in submarine cables, the capacitance is rather high.
In principle, we can improve such a cable in four ways to satisfy the condition:
</p><ul>
<li> decrease <i>R</i>: use thicker copper wire, that's expensive.
</li><li> decrease <i>C</i>, i.e., increase the distance between the wires: that may be feasible
on telegraph poles on land, but making a coaxial submarine cable thicker is hard (expensive).
</li><li> increase <i>G</i>, so use a not-so-good isolation material: this is what happens when
water seeps into a sea-cable (recall that Heaviside as a telegraph operator had already noticed that
then the distortion is reduced), but the obvious disadvantage is that the signals
become weaker.
</li><li> what remains: increase <i>L</i>.
</li></ul>

<img src="https://www.pa3fwm.nl/technotes/tn28fig6.jpg" alt="[a Pupin coil]">
Indeed, special cables have been manufactured in which the center conductor has extra
inductance, by covering it in a suitable magnetic material.
But the most commonly used way to increase <i>L</i>, is by connecting a coil in series
every couple of kilometers.
Heaviside invented this idea, but William Preece, the British telegraph service's 
engineer-in-chief didn't believe it, and in fact thought that one should avoid inductance.
As a consequence, the technique initially was not tried in England (and this was not the
only conflict between Heaviside and Preece [1]).
But Michael Pupin patented the idea a few years later in America.
It turned out to work very well and has been used for decades in the telephone industry,
until it became possible to amplify signals electronically.
And radio amateurs have, particularly in the 1970s and 1980s, used such Pupin coils
for making audio filters.
The picture shows a typical Pupin coil. It had two windings, with red and green wires,
for both wires of the telephone line. Separately the windings usually were 22 mH,
in series 88 mH.

<p>
Should we now also insert coils into our antenna cables to prevent distortion of our
radio signals?
No: firstly the distortion is negligible for relatively narrow-band signals;
and secondly, such coils would work as a low-pass filter, so our (high) frequencies
wouldn't get through anymore.



</p><h2>References</h2>
[1] Basil Mahon: The forgotten genius of Oliver Heaviside -- A maverick of electrical science. 2017.

</mathml></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nvidia, ASML Plunge as DeepSeek Triggers Tech Stock Selloff (232 pts)]]></title>
            <link>https://finance.yahoo.com/news/asml-sinks-china-ai-startup-081823609.html</link>
            <guid>42839650</guid>
            <pubDate>Mon, 27 Jan 2025 10:57:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://finance.yahoo.com/news/asml-sinks-china-ai-startup-081823609.html">https://finance.yahoo.com/news/asml-sinks-china-ai-startup-081823609.html</a>, See on <a href="https://news.ycombinator.com/item?id=42839650">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>    <p><!-- HTML_TAG_START -->(Bloomberg) -- ASML Holding NV shares tanked along with global technology stocks on Monday as Chinese artificial intelligence startup DeepSeek sparked fear over Western technological dominance.<!-- HTML_TAG_END --></p> <p><!-- HTML_TAG_START -->Most Read from Bloomberg<!-- HTML_TAG_END --></p> <ul><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-01-23/us-pedestrian-study-we-re-walking-faster-hanging-out-less?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:What Happened to Hanging Out on the Street?;elm:context_link;itc:0;sec:content-canvas">What Happened to Hanging Out on the Street?</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/features/2025-01-24/vienna-bets-on-heat-pumps-to-decouple-it-from-russian-gas?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Vienna Embraces Heat Pumps to Ditch Russian Gas;elm:context_link;itc:0;sec:content-canvas">Vienna Embraces Heat Pumps to Ditch Russian Gas</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-01-23/billionaire-developer-slams-la-leadership-over-deadly-wildfires?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Billionaire Developer Caruso Slams LA Leadership Over Wildfires;elm:context_link;itc:0;sec:content-canvas">Billionaire Developer Caruso Slams LA Leadership Over Wildfires</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-01-19/how-sanctuary-cities-are-preparing-for-another-showdown-with-trump?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:How Sanctuary Cities Are Preparing for Another Showdown With Trump;elm:context_link;itc:0;sec:content-canvas">How Sanctuary Cities Are Preparing for Another Showdown With Trump</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-01-23/hoboken-path-station-will-close-for-almost-a-month-on-jan-30?utm_campaign=bn&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Hoboken PATH Station Will Close for Almost a Month on Jan. 30;elm:context_link;itc:0;sec:content-canvas">Hoboken PATH Station Will Close for Almost a Month on Jan. 30</a><!-- HTML_TAG_END --></p> </li> </ul> <p><!-- HTML_TAG_START -->ASML’s shares dropped as much as 9.4% to €634.70 apiece in early Amsterdam trading on Monday, the biggest intraday drop since Oct. 15. The technology heavy Nasdaq 100 futures index slumped 3%.<!-- HTML_TAG_END --></p> <p><!-- HTML_TAG_START -->The Dutch company makes machines needed to produce high-end chips that power everything from electric vehicles to military gear, and it’s benefited from a surge in AI spending.<!-- HTML_TAG_END --></p> <p><!-- HTML_TAG_START -->Most Read from Bloomberg Businessweek<!-- HTML_TAG_END --></p> <ul><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-01-23/southern-towns-in-the-us-want-more-buc-ee-s-gas-stations?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Forget Factories, Small US Towns Want Buc-ee’s Gas Stations;elm:context_link;itc:0;sec:content-canvas">Forget Factories, Small US Towns Want Buc-ee’s Gas Stations</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/features/2025-01-24/fertility-treatment-risks-what-information-the-cdc-holds-back?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:The CDC Won’t Give the Public a Full Picture of Fertility Treatment Risks;elm:context_link;itc:0;sec:content-canvas">The CDC Won’t Give the Public a Full Picture of Fertility Treatment Risks</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-01-21/elon-musk-s-inaugural-highs-and-lows?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Elon Musk’s Inaugural Highs (and Lows);elm:context_link;itc:0;sec:content-canvas">Elon Musk’s Inaugural Highs (and Lows)</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-01-21/kendrick-lamar-the-business-of-being-super-bowl-2025-headliner?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:How Kendrick Lamar Turned Beef With Drake Into Music Superstardom;elm:context_link;itc:0;sec:content-canvas">How Kendrick Lamar Turned Beef With Drake Into Music Superstardom</a><!-- HTML_TAG_END --></p> </li><li> <p><!-- HTML_TAG_START --><a href="https://www.bloomberg.com/news/articles/2025-01-21/greek-police-say-eggs-were-stolen-from-ivf-clinic-patients?utm_campaign=bw&amp;utm_medium=distro&amp;utm_source=yahooUS" rel="nofollow noopener" target="_blank" data-ylk="slk:Greek Police Say Eggs Were Stolen from IVF Clinic Patients;elm:context_link;itc:0;sec:content-canvas">Greek Police Say Eggs Were Stolen from IVF Clinic Patients</a><!-- HTML_TAG_END --></p> </li> </ul> <p><!-- HTML_TAG_START -->©2025 Bloomberg L.P.<!-- HTML_TAG_END --></p>      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Facebook ban on discussing Linux? (395 pts)]]></title>
            <link>https://distrowatch.com/weekly-mobile.php?issue=20250127#sitenews</link>
            <guid>42839502</guid>
            <pubDate>Mon, 27 Jan 2025 10:32:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://distrowatch.com/weekly-mobile.php?issue=20250127#sitenews">https://distrowatch.com/weekly-mobile.php?issue=20250127#sitenews</a>, See on <a href="https://news.ycombinator.com/item?id=42839502">Hacker News</a></p>
Couldn't get https://distrowatch.com/weekly-mobile.php?issue=20250127#sitenews: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[SiFive's P550 Microarchitecture (135 pts)]]></title>
            <link>https://chipsandcheese.com/p/inside-sifives-p550-microarchitecture</link>
            <guid>42839501</guid>
            <pubDate>Mon, 27 Jan 2025 10:32:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/p/inside-sifives-p550-microarchitecture">https://chipsandcheese.com/p/inside-sifives-p550-microarchitecture</a>, See on <a href="https://news.ycombinator.com/item?id=42839501">Hacker News</a></p>
Couldn't get https://chipsandcheese.com/p/inside-sifives-p550-microarchitecture: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Sweden Seizes Ship Suspected of Baltic Sea 'Sabotage' (141 pts)]]></title>
            <link>https://www.barrons.com/news/sweden-says-has-seized-ship-suspected-of-baltic-sea-sabotage-13ff82f2</link>
            <guid>42839348</guid>
            <pubDate>Mon, 27 Jan 2025 10:05:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.barrons.com/news/sweden-says-has-seized-ship-suspected-of-baltic-sea-sabotage-13ff82f2">https://www.barrons.com/news/sweden-says-has-seized-ship-suspected-of-baltic-sea-sabotage-13ff82f2</a>, See on <a href="https://news.ycombinator.com/item?id=42839348">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <div>
          <p><img src="https://www.barrons.com/asset/barrons/images/barrons-logo.png"></p><p>This copy is for your personal, non-commercial use only. To order presentation-ready copies for distribution to your colleagues, clients or customers visit http://www.djreprints.com.</p>
          <p>https://www.barrons.com/news/sweden-says-has-seized-ship-suspected-of-baltic-sea-sabotage-13ff82f2</p>
        </div>

        <!-- cxenseparse_start -->
        <div id="article_sector">
          <article id="article-contents" maincontentofpage="">
            <header>
              
              
              <hr>

              <div>


                  <div>

<p><span>By AFP - Agence France Presse</span>


</p>

<p><time>
  January 26, 2025
</time>
                  </p></div>
                  <div>
<ul>
    <li tabindex="0" onclick="window.open('//s100.copyright.com/Clients/wsj_com/FairUse.jsp?PublisherName=barrons.com&amp;PublicationDate=2025-01-26&amp;Author=AFP%20-%20Agence%20France%20Presse&amp;orderReset=true&amp;orderSource=barrons.com&amp;publication=barrons.com&amp;Title=Sweden%20Says%20Has%20Seized%20Ship%20Suspected%20Of%20Baltic%20Sea%20'Sabotage'&amp;ContentID=AFP6114440072959283523876703099927818386300.djm&amp;ArticleType=AFP%2520News&amp;DJType=true&amp;mod=article_reprintsHead', '_blank', 'left=20,top=20,width=500,height=500,toolbar=0,resizable=0')" onkeypress="window.open('//s100.copyright.com/Clients/wsj_com/FairUse.jsp?PublisherName=barrons.com&amp;PublicationDate=2025-01-26&amp;Author=AFP%20-%20Agence%20France%20Presse&amp;orderReset=true&amp;orderSource=barrons.com&amp;publication=barrons.com&amp;Title=Sweden%20Says%20Has%20Seized%20Ship%20Suspected%20Of%20Baltic%20Sea%20'Sabotage'&amp;ContentID=AFP6114440072959283523876703099927818386300.djm&amp;ArticleType=AFP%2520News&amp;DJType=true&amp;mod=article_reprintsHead', '_blank', 'left=20,top=20,width=500,height=500,toolbar=0,resizable=0')">
      Order Reprints
      <span>
      </span>
    </li>

  <li tabindex="0">
    Print Article
    <span data-id="AFP6114440072959283523876703099927818386300" data-headline="Sweden Says Has Seized Ship Suspected Of Baltic Sea 'Sabotage'" data-url="https://www.barrons.com/articles/sweden-says-has-seized-ship-suspected-of-baltic-sea-sabotage-13ff82f2" data-authors="AFP - Agence France Presse" data-date="January 26, 2025" data-summary=""></span>
  </li>
</ul>
                  </div>
              </div>
            </header>

            

<div id="js-article__body" itemprop="articleBody" data-sbid="AFP6114440072959283523876703099927818386300">
  



    <p><span>Text size</span>
      
      
    </p>
  

   <p>Swedish authorities on Sunday seized a ship suspected of having sabotaged a fibre-optic cable in the Baltic Sea, the prosecutors' office announced.</p> <p>Prosecutors have opened an investigation for "aggravated sabotage" after the undersea cable running between Sweden and Latvia was damaged, said the statement.</p> <p>nzg/jj/sbk</p>

</div>

 <!-- data-module-name="article.app/lib/module/barrons/TopStories" -->


<div data-module-id="29" data-module-name="article.app/lib/module/barrons/articleDisclaimer" data-module-zone="article_disclaimer">
  <p>
    The Barron's news department was not involved in the creation of the content above. This article was produced by AFP. For more information go to <a href="https://www.afp.com/" target="_blank">AFP.com</a>.<br>© Agence France-Presse 
  </p>

</div> <!-- data-module-name="article.app/lib/module/barrons/articleDisclaimer" -->


            

 <!-- data-module-name="article.app/lib/module/dynamicContentByArticleType" -->


              

            <!-- Div for the Unruly Ad -->
            

            
            <!-- Div for the Native Ad -->
            
            
            
            
            
            
            
            
            
            
            

            

<div id="recirc" data-module-id="14" data-module-name="article.app/lib/module/barrons/Recirc" data-module-zone="recirc"><h2>READ MORE FROM BARRON’S</h2></div> <!-- data-module-name="article.app/lib/module/barrons/Recirc" -->


          </article>
        </div>
        <!-- cxenseparse_end -->

        


 <!-- data-module-name="article.app/lib/module/barrons/dianomiJs" -->

            

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I Made an iOS Podcast Player with Racket (168 pts)]]></title>
            <link>https://defn.io/2024/11/16/podcatcher/</link>
            <guid>42838875</guid>
            <pubDate>Mon, 27 Jan 2025 08:56:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://defn.io/2024/11/16/podcatcher/">https://defn.io/2024/11/16/podcatcher/</a>, See on <a href="https://news.ycombinator.com/item?id=42838875">Hacker News</a></p>
Couldn't get https://defn.io/2024/11/16/podcatcher/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[One in four 2020 Tesla Model 3 failed the Danish periodic inspection in 2024 (164 pts)]]></title>
            <link>https://fdm.dk/nyheder/bilist/2025-01-populaer-tesla-model-dumper-med-et-brag-til-syn</link>
            <guid>42838855</guid>
            <pubDate>Mon, 27 Jan 2025 08:52:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fdm.dk/nyheder/bilist/2025-01-populaer-tesla-model-dumper-med-et-brag-til-syn">https://fdm.dk/nyheder/bilist/2025-01-populaer-tesla-model-dumper-med-et-brag-til-syn</a>, See on <a href="https://news.ycombinator.com/item?id=42838855">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  

<p><span><span><span><span>Elbilernes salgskurve er de seneste år gået stejlt opad, og mere end hver anden solgte nye bil er nu en elbil. Det mærker man nu også ude i landets synshaller, hvor elbiler ikke længere er et særsyn. Lige Godt 28.000 elbiler var i de første 11 måneder af 2024 til periodisk syn. </span></span></span></span></p>

<p><span><span><span><span>Det er dog langtfra alle elbiler, der klarer turen på liften lige godt. Især én model falder igennem: Tesla Model 3. Den populære elbil, som der kører i alt 35.000 af på de danske veje, blev lanceret i 2019, og dermed har den første store årgang været til sit første periodiske bilsyn i det forgangne år.</span></span></span></span></p>





<h2><span><span><span><span>Rasende høj dumpeprocent</span></span></span></span></h2>

<p><span><span><span>Af de 4.668 Tesla Model 3 årgang 2020, som mellem 1. januar og 21. november sidste år var til syn, dumpede de 1.051. Det svarer til 23 procent. Til sammenligning dumpede ’kun’ 9 procent af de øvrige elbiler, der var til syn i 2024, viser tal fra Færdselsstyrelsen, som FDM Test &amp; Bilsyn har analyseret. </span></span></span></p>

<p><span><span><span>– Det er en rasende høj dumpeprocent for Tesla Model 3, som Færdselsstyrelsens synsdata afslører, men det er desværre ikke noget, som overrasker os. Tallene indikerer, at kvaliteten og holdbarheden af Tesla Model 3, i hvert fald de første årgange, ikke er på niveau med andre bilmærker. Det er noget, vi også oplever, og som vi holder øje med, siger områdechef i FDMs tekniske rådgivning Lone Otto. </span></span></span></p>

<h2>Tesla har mere end hver 3. af alle fejl</h2>

<p><span><span><span>I</span></span></span><span><span><span>&nbsp;alt blev der fundet 1.392 fejl på de Tesla Model 3 årgang 2020, svarende til 0,3 fejl pr. synet model. Dermed blev der fundet tre gange så mange fejl i forhold til de øvrige elbiler, som blev synet sidste år. </span></span></span></p>



<p><span><span><span><span>Billedet fra de danske synshaller af Tesla Model 3 stemmer overens med synstal fra Tyskland. Også her faldt bilmodellen igennem i den årlige synsrapport fra tyske TÜV, der bl.a. syner biler. </span></span></span></span></p>

<p><span><span><span><span>Det er særligt fejlgrupperne „bremseudstyr“, „lygteudstyr“, „aksler, hjul og dæk“ samt „styretøj“, som bilerne dumper på. Noget man i FDMs tekniske rådgivning kan nikke genkendende til. </span></span></span></span></p>

<p><span><span><span>– Elbiler bremser på en anden måde, og derfor er problemer med bremserne velkendt. Men det er kritisk, at problemer med hjulophæng og ratslør er så udtalt på en bil, der ikke er ældre end Tesla Model 3. Det ser vi ikke på andre biler. Det samme gælder Teslas overrepræsentation af fejl på lygter, som ofte enten er løse, eller som blænder, siger Lone Otto</span></span></span></p>
<figure role="group">
<picture>
                  <source srcset="https://fdm.dk/sites/default/files/styles/ckeditor_textwidth_large/public/inline-images/Tesla%20Model%203_hjuloph%C3%A6ng_300dpi.jpg?itok=RdrIkHr9 1x" media="all and (min-width: 1440px)" type="image/jpeg" width="700" height="467">
              <source srcset="https://fdm.dk/sites/default/files/styles/ckeditor_textwidth_large/public/inline-images/Tesla%20Model%203_hjuloph%C3%A6ng_300dpi.jpg?itok=RdrIkHr9 1x" media="all and (min-width: 1200px) and (max-width: 1439px)" type="image/jpeg" width="700" height="467">
              <source srcset="https://fdm.dk/sites/default/files/styles/ckeditor_textwidth_large/public/inline-images/Tesla%20Model%203_hjuloph%C3%A6ng_300dpi.jpg?itok=RdrIkHr9 1x" media="all and (min-width: 992px) and (max-width: 1199px)" type="image/jpeg" width="700" height="467">
              <source srcset="https://fdm.dk/sites/default/files/styles/ckeditor_textwidth_large/public/inline-images/Tesla%20Model%203_hjuloph%C3%A6ng_300dpi.jpg?itok=RdrIkHr9 1x" media="all and (min-width: 768px) and (max-width: 991px)" type="image/jpeg" width="700" height="467">
              <source srcset="https://fdm.dk/sites/default/files/styles/ckeditor_textwidth_medium/public/inline-images/Tesla%20Model%203_hjuloph%C3%A6ng_300dpi.jpg?itok=6miTp5XF 1x" type="image/jpeg" width="500" height="334">
                  <img data-entity-type="file" data-entity-uuid="986dacef-e2f5-40ab-ae45-ea88e1364e59" data-responsive-image-style="ckeditor_contentwidth" src="https://fdm.dk/sites/default/files/styles/ckeditor_textwidth_small/public/inline-images/Tesla%20Model%203_hjuloph%C3%A6ng_300dpi.jpg?itok=04A14CHE" width="320" height="214" alt="Synsmand tester hjulophæng på Tesla Model 3" loading="lazy" typeof="foaf:Image">

  </picture>
<figcaption>Problemer med hjulophænget på tidligere årgange Tesla Model 3 er velkendt i FDMs tekniske rådgivning, og også noget, der ses ved syn. (Foto: FDM)</figcaption>
</figure>

<h2><span><span><span>62.000 elbiler skal til syn i år</span></span></span></h2>

<p><span><span><span>Det kommende år skal 62.000 elbiler til syn herhjemme – de 45.000 for første gang. Heriblandt Tesla Model 3 årgang 2021 og ikke mindst den første årgang af Tesla Model Y, der er den mest solgte elbil i Danmark. </span></span></span></p>

<p><span><span><span>– Vi har ingen grund til at tro, at yngre årgange af Tesla Model 3 vil adskille sig væsentligt fra årgang 2020, når det gælder fejl og dermed også dumpeprocent. Mere spændende bliver det at se, hvordan Tesla Model Y vil klare sig, siger Lone Otto og tilføjer:</span></span></span></p>

<p><span><span><span>– Tesla har fire års garanti på sine biler. Det passer med deres første syn. Et godt råd er derfor at få bilen gennemgået af en uvildig, inden man når skæringsdatoen. I det hele taget anbefaler vi, at man løbende servicerer sin bil og får gennemgået bilens bremser og generelle stand. Gerne en gang om året. Det gælder uanset bilmærke, eller om bilen overhovedet har et fast serviceinterval.</span></span></span></p>

<p>Opdateret 24. januar:</p>

<p><span><span>FDM har bedt Tesla om en kommentar til dels synstallene for deres Model 3 dels kritikken af bilens kvalitet. Det er ikke lykkedes at få. I en mail til FDM gør Tesla dog opmærksom på, at Tesla Model 3 fik et større facelift i 2021, og at modellen i 2023 kom i en ny og markant forbedret udgave. </span></span></p>

<div>
<h2><span><span><span><strong>Har du brug for hjælp?</strong></span></span></span></h2>

<p><span><span><span>Husk, som medlem af FDM kan du altid få hjælp af eksperter, der har den nyeste viden om elbiler.</span></span></span></p>

<p><a href="https://fdm.dk/vi-tilbyder/elbil-plugin-hybrid-fdms-raadgivning-kan-hjaelpe"><span><span><span>Kontakt rådgivningen</span></span></span></a></p>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Once You're Laid Off, You'll Never Be the Same Again (859 pts)]]></title>
            <link>https://mertbulan.com/2025/01/26/once-you-are-laid-off-you-will-never-be-the-same-again/</link>
            <guid>42838700</guid>
            <pubDate>Mon, 27 Jan 2025 08:22:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mertbulan.com/2025/01/26/once-you-are-laid-off-you-will-never-be-the-same-again/">https://mertbulan.com/2025/01/26/once-you-are-laid-off-you-will-never-be-the-same-again/</a>, See on <a href="https://news.ycombinator.com/item?id=42838700">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <article>
    <p>It happened on the afternoon of May 4th. A message from a colleague—who has since become a good friend—popped up on my screen, urging me to check my emails. When I opened my inbox, there it was: an email from the COO. The email announced an impending company-wide layoff and mentioned that, within a few minutes, I’d receive another email letting me know whether I was impacted. A short while later, the second email arrived. I was among those affected—along with most of my team.</p>

<p>The situation felt surreal. One by one, my colleagues posted in our team chat, confirming they’d been impacted too. Before our accounts were locked, we quickly jumped on a call. We had just 30 minutes to have one final conversation as a team, to say our goodbyes. It was a bittersweet moment, sharing those last words with people I’d worked so closely with.</p>

<p>It was difficult to process what was happening. Just ten months earlier, the company had gone through another round of layoffs. And at the beginning of the year, during the company’s kick-off event, the president assured us there wouldn’t be any more layoffs. They even said the company was performing well financially. So, why was this happening?</p>

<h2 id="signs-of-a-layoff">Signs of a Layoff</h2>

<p>Looking back, my colleagues and I were not entirely surprised by the layoff. There were several warning signs that hinted something was coming. I want to share these signs so you can be better prepared if you ever face a similar situation.</p>

<h3 id="1-cancellation-of-team-events">1. Cancellation of Team Events</h3>
<p>One of the earliest indicators was the sudden cancellation of team events. When I heard from other teams that their off-site events were canceled without any clear explanation, it immediately raised red flags. These cancellations often signal that the company is going to announce something about the team structure and doesn’t want you to be with your team in the same place. This is because one of your teammates—or you—might be impacted, and you’d need to cancel flights, hotels, etc. To avoid dealing with these logistical issues, the company preemptively cancels the event.</p>

<h3 id="2-unexpected-notifications-about-packages">2. Unexpected Notifications About Packages</h3>
<p>Some employees at the company received notifications about packages scheduled to arrive at their homes. This happens because services like DHL notify you through their app when a package is on the way. If your company requires you to return your work equipment, like a laptop, after being laid off, they often arrange for these shipping boxes to be delivered in advance. If you unexpectedly see a notification about a package from your company’s IT provider, it’s a strong sign that a layoff is imminent—and you may be impacted.</p>

<h3 id="3-lack-of-vision-from-leadership">3. Lack of Vision from Leadership</h3>
<p>The absence of a clear vision from leadership is one of the most common signs of an impending layoff. During off-site or kick-off events, you might notice that leaders seem unsure of the company’s direction. When this lack of clarity is followed by team restructuring, and then another restructuring just a few months later, it becomes evident that the leadership is struggling to find focus. Ultimately, this cycle often ends with a layoff, accompanied by yet another round of restructuring for those who remain.</p>

<h3 id="4-sudden-vague-meetings">4. Sudden, Vague Meetings</h3>
<p>Another sign is the appearance of unexpected, vague meetings on your calendar. These meetings are marked as “important” with no clear agenda, and attendance is mandatory. If this happens, it’s often a precursor to a layoff announcement. Public companies, in particular, may choose to send layoff notices via email to align the timing with when they notify investors.</p>

<h3 id="5-timing-around-quarterly-results">5. Timing Around Quarterly Results</h3>

<p>If your company is publicly traded, layoffs are frequently announced in conjunction with quarterly earnings reports. This can be especially stressful because, leading up to every financial results announcement, employees may anxiously wait to see if layoffs will accompany the news. If no layoffs are announced, you know you’re safe—for at least one more quarter.</p>

<h2 id="youre-just-a-row-in-an-excel-table">You’re Just a Row in an Excel Table</h2>

<p>When I looked back on my time at the company and all the things I had accomplished, I was surprised to be impacted by the layoffs. It wasn’t because I thought I was better than others—it was because I believed I was doing more than what was expected of me. However, during a layoff, it seems that who you are and what you do doesn’t matter. In most cases, the decision is made by people who don’t even know you. This realization made me question the concept of work, which is part of the reason I’m writing this blog post.</p>

<p>I was hired as a Backend Developer. When I joined my team, I noticed a project that needed a developer to implement the client-side feature in React Native. Although I had no prior experience with React Native, I had worked with React before, so I volunteered for the task. I shipped the feature without any issues, received positive feedback from my team and lead, and eventually, my title was changed to Developer, making me a full-stack developer.</p>

<p>In some instances, I worked on projects independently, always aligning with my team and ensuring my work was reviewed. I would implement the backend first and then move on to the client-side. This was my expected role, and in performance reviews, I was consistently rated as a high performer. Yet, I was always doing more than what was expected of me.</p>

<p>Sometimes, I worked on small features I thought would enhance the app. These features might not have been used by many, but they provided significant value to heavy users. Occasionally, I shipped these under the radar. I created dashboards to measure the impact of my team’s work, helping us focus on features that would bring the most value to users. I also built proof-of-concept features based on user requests to show leadership how easily they could be implemented, advocating for their prioritization. Additionally, I participated in hackdays, creating projects to showcase innovative ideas.</p>

<p>On several occasions, I was selected for special projects outside my team. These projects often came directly from the CEO, and I was chosen because I constantly wanted to do more for the company and our users. For some of these projects, I worked more than eight hours a day, including weekends. A few of these initiatives were mentioned in financial reports, praised by the CEO during all-hands meetings, or retweeted multiple times by the CEO on Twitter.</p>

<p>Over time, I gained the attention of senior management in my business unit, which consisted of about 400 people. I began directly interacting with the VP of Product and the VP of Engineering, both of whom were four or five levels above me. Occasionally, the VP of Product would message me directly to ask if a feature was feasible to implement. Later, the VP of Engineering started scheduling regular one-on-one meetings with me, which was highly uncommon. During these calls, he told me multiple times that if I continued working at this level, I could quickly climb the ladder to become a Staff Developer. He wasn’t the only one saying this to me.</p>

<p>Beyond my immediate role, I also sought ways to contribute to the broader company. Whenever a new tool was introduced, I would explore it, write detailed articles about my findings, and share them to help other teams use the tool more effectively.</p>

<p>I referred many friends and former colleagues to the company because I believed in its mission. If I recall correctly, I referred over ten people, four of whom received offers, and three were ultimately hired. I also encouraged many others to consider joining the company.</p>

<p>I even initiated discussions about translating our website into Turkish to support the many customers we had in Turkey. A few weeks before the layoff announcement, I was helping a team working on this project find a Turkish-speaking content designer because they noticed my willingness to assist.</p>

<p>Additionally, I tried to convince friends who were CTOs at major e-commerce companies to migrate their websites to our platform. Whenever I received job offers from e-commerce companies on LinkedIn, I used those opportunities to promote our platform instead. I passed along leads to the sales team and later noticed that one of those companies had indeed moved to our platform.</p>

<p>I’m not sharing all of this to brag but to highlight that, in the end, none of it mattered. On the day I announced I had been laid off, I received numerous messages from colleagues, even those I hadn’t worked with directly, telling me that I had inspired and motivated them. While those messages were heartwarming, they didn’t change the reality: to the company, I was just a row in an Excel sheet.</p>

<h2 id="the-broken-trust-of-modern-work">The Broken Trust of Modern Work</h2>

<p>Layoffs were uncommon when I started working, and being a developer felt like an incredibly safe job. In most professions, the unspoken rule was simple: if you performed well and the company was financially stable, your job was secure.</p>

<p>But today, companies are announcing layoffs alongside record-breaking financial results. You work hard, focus on impactful projects, and receive praise from your lead—only to find yourself let go by someone who likely doesn’t even know you exist. It feels as though the trust between companies and employees is now broken. Companies, it seems, are either unaware of this shift or unwilling to address it. And frankly, I’m not sure how they could fix it.</p>

<p>What’s particularly strange is that the layoffs predominantly affect individual contributors—the people who have little say in deciding the company’s direction. These are the team members closest to the users, the ones who spend hours planning how to improve the product. But after those plans are made, leadership often swoops in and redirects efforts toward entirely different goals. You trust their judgment, work on their priorities, and deliver on time. Then, when the arbitrary goals they set aren’t met, the company decides to cut staff. Those who made the poor decisions remain, and some are even promoted, while the people carrying out the work are let go. It feels surreal—like <a rel="nofollow noopener" target="_blank" href="https://www.youtube.com/watch?v=u48vYSLvKNQ">an episode from Silicon Valley</a>—but this is how big companies operate.</p>

<p>I’m not alone in feeling this way. Many friends and ex-colleagues who’ve been laid off in recent years share similar experiences. They’ve lost trust in their employers. They believe their efforts won’t matter in the long run and anticipate being part of the next layoff cycle. As a result, they only do what’s strictly required to avoid a performance improvement plan. No one goes above and beyond anymore; no one takes initiative to improve things. Why? Because it doesn’t matter. They’ve seen firsthand that it changes nothing.</p>

<p>For those like me who’ve experienced layoffs, work has become just that—work. You do what’s assigned, and if your company squanders your potential or forces you to waste time on unnecessary projects, you simply stop caring. You collect your paycheck at the end of the month, and that’s it. This is the new modern work: no more striving to be 40% better every year.</p>

<h2 id="the-myth-of-job-security-in-germany">The Myth of Job Security in Germany</h2>

<p>Since I was working for a German entity of a company, I want to address a common myth about job security in Germany. Many people believe that it’s nearly impossible to be fired in Germany. While this is partially true for individuals who have completed their probation period, it doesn’t hold up in the context of layoffs. If a company decides to lay off, for instance, 40 employees, German law doesn’t prevent this. Instead, the law enforces a social scoring system to determine who is affected, prioritizing the protection of the most vulnerable employees, such as those with children. In this sense, when it comes to layoffs, the difference between Germany and the US is minimal.</p>

<h2 id="suggestions-for-those-who-havent-been-laid-off-yet">Suggestions for Those Who Haven’t Been Laid Off (Yet)</h2>

<p>When I talk to friends who were laid off in recent years, we often reflect on what we could have done differently. Here are some of the lessons we’ve learned:</p>

<ul>
  <li><strong>Stick to your contract hours.</strong> If your contract says 40 hours, work 40 hours—no more, no less. Protect your personal time and well-being.</li>
  <li><strong>Avoid going above and beyond with initiatives.</strong> Many companies encourage impactful work to earn promotions, but instead of chasing internal advancements, focus on switching companies to achieve your next career step.</li>
  <li><strong>Always keep interviewing.</strong> One of the biggest mistakes I’ve seen is stopping interviews after starting a new job, trusting in the company. Instead, continuously explore opportunities so that if a layoff happens, you already have other options lined up.</li>
  <li><strong>Leverage external offers for salary growth.</strong> Companies often resist giving substantial raises to existing employees but pay top dollar for new hires. Regularly interview elsewhere, and if you get an offer with a 20% or higher salary increase, consider taking it. Many people have seen their compensation triple or quadruple this way in just a few years.</li>
  <li><strong>Don’t overthink your résumé.</strong> Worrying about short experiences on your CV isn’t worth it. You can always tailor your résumé—leave out brief roles, or consolidate short-term jobs as freelance experience. Ultimately, your résumé is just a starting point; your skills will be assessed during the interview process.</li>
</ul>

<hr>

<p>You’ve probably noticed that I didn’t mention the name of the company I was laid off from. That’s because I believe it’s irrelevant. Everything I’ve shared reflects the current state of the tech industry. It might differ at very small companies, but once you work at a company with more than 100 employees, you’ll likely encounter many of the same patterns I’ve described.</p>

<p>I’ve wanted to write about this topic for a long time, but it’s been difficult to find the energy. The subject itself is a deep disappointment for me, and every time I reflect on layoffs, it makes me profoundly sad. It’s a stark reminder of how companies treat workers as disposable. Before you join, they go to great lengths to make you feel valued and excited to accept their offer. You meet multiple people, and some even offer signing bonuses. But when layoffs come, you’re reduced to a name on a list. During the exit interview, a random person from the company reads a prepared script and can’t answer your questions. The HR team that once worked to make you feel valued doesn’t even conduct an actual conversation with you. That random person becomes the last connection you have to a company you spent years at.</p>

<p>The layoff fundamentally changed how I perceive work now. I don’t think that I’ll be the same person again.</p>

  </article>
</div><div>
      <p><a href="https://mertbulan.com/2024/05/05/how-to-retire-early-in-germany/">
        <img data-src="/images/posts/retire-early-germany.webp" alt="Once You're Laid Off, You'll Never Be the Same Again" src="https://mertbulan.com/images/posts/retire-early-germany.webp">
      </a></p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Making AR experiences is still painful – had to make my own editor (147 pts)]]></title>
            <link>https://ordinary.space/</link>
            <guid>42838355</guid>
            <pubDate>Mon, 27 Jan 2025 07:32:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ordinary.space/">https://ordinary.space/</a>, See on <a href="https://news.ycombinator.com/item?id=42838355">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="pabmky5I8QL"><main><vev id="eS5k201GAkr"><div><w id="eS5k201GAkrc"></w><div><vev id="e1-wKGNYP1x"><div id="e1-wKGNYP1xc"><vev id="eSi_hnsRzhu"></vev><vev id="eXWw6ZEMOuc"><div id="eXWw6ZEMOucc"><vev id="enMAzuvD0W8"><div><w id="enMAzuvD0W8c"><img alt="Graphics software, Operating system, Blue, Technology, Screenshot" loading="lazy" src="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=1280/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/z7vQZZROKA" srcset="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=320/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/z7vQZZROKA 320w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=640/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/z7vQZZROKA 640w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=960/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/z7vQZZROKA 960w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=1280/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/z7vQZZROKA 1280w"></w></div></vev><vev id="ekn0cQhYw55"></vev></div></vev></div></vev><vev id="eRphUPqt0cL"><div id="eRphUPqt0cLc"><vev id="e9epbWqYQdH"><div id="e9epbWqYQdHc"><vev id="etYK-JU5gzk"><div><w id="etYK-JU5gzkc"><p><video aria-label="Comp 1_2.mp4" disableremoteplayback="" muted="" playsinline="" poster="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/os6HaeVXmI/thumbnail0000000000.jpeg" preload="auto" autoplay=""><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/os6HaeVXmI/hd-h264.mp4" type="video/mp4"><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/os6HaeVXmI/hd-vp9.mp4" type="video/mp4">Your browser does not support this video</video></p></w></div></vev><vev id="eOkWdJn6zH5"></vev></div></vev><vev id="eeMGofkM575"><div id="eeMGofkM575c"><vev id="eIzgaXOQiR2"><div><w id="eIzgaXOQiR2c"><img alt="Graphics software, Operating system, Technology, Screenshot" loading="lazy" src="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=1920/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/4Z9FGGZh8L_2il2go.png" srcset="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=320/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/4Z9FGGZh8L_2il2go.png 320w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=640/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/4Z9FGGZh8L_2il2go.png 640w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=960/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/4Z9FGGZh8L_2il2go.png 960w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=1280/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/4Z9FGGZh8L_2il2go.png 1280w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/4Z9FGGZh8L_2il2go.png 2048w"></w></div></vev></div></vev><vev id="eXweg8Ev3iz"><div id="eXweg8Ev3izc"><vev id="eVRJ7v9InIv"><div><w id="eVRJ7v9InIvc"><img alt="Audio equipment, Technology, Loudspeaker" loading="lazy" src="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,h=1920/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/kSNfpwKRM6_2il2ip.png" srcset="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,h=320/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/kSNfpwKRM6_2il2ip.png 320w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,h=640/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/kSNfpwKRM6_2il2ip.png 640w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,h=960/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/kSNfpwKRM6_2il2ip.png 960w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,h=1280/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/kSNfpwKRM6_2il2ip.png 1280w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/kSNfpwKRM6_2il2ip.png 2038w"></w></div></vev><vev id="eUvk_AL_Au9"></vev></div></vev><vev id="eR3P4Caj2Qy"></vev><vev id="e6zobiEV3gy"></vev><vev id="etLab1VNXjU"><div id="etLab1VNXjUc"><vev id="eOZcytwYwX0"><div id="eOZcytwYwX0c"><vev id="eBlNf4uewnn"><div><w id="eBlNf4uewnnc"><p id=""><h2>Prototype high fidelity spatial apps.</h2></p></w></div></vev><vev id="e0mWgMde1zc"><div><w id="e0mWgMde1zcc"><p id=""><h3>Ordinary Objects helps designers ideate and build intuitive and delightful mixed reality projects.</h3></p></w></div></vev><vev id="euTuieJXt2P"><p><w id="euTuieJXt2Pc"><a href="https://app.ordinary.space/sign-up" data-tween="false">Try the beta - it's free</a></w></p></vev></div></vev></div></vev></div></vev></div></div></vev><vev id="eFByiatr4rI"><div><w id="eFByiatr4rIc"></w><div><vev id="evjHakPdmhw"><div id="evjHakPdmhwc"><vev id="eaW96F8iZB-"><div id="eaW96F8iZB-c"><vev id="e3zb7m8tGmI"><div><w id="e3zb7m8tGmIc"><p id=""><h2>Create rich human centric experiences.</h2></p></w></div></vev></div></vev><vev id="eeEoj7iXXan"><div id="eeEoj7iXXanc"><vev id="eL7ZWvfxxQS"><div><w id="eL7ZWvfxxQSc"><p>Powerful authoring features and a unique workflow to prototype spatial user flows and interactions.</p></w></div></vev></div></vev><vev id="eOOMCnCW8JB"><div id="eOOMCnCW8JBc"><vev id="esE5NXjw_Ks"><div id="esE5NXjw_Ksc"><vev id="eVIn1M-HGqR"><div><w id="eVIn1M-HGqRc"><p><video aria-label="States-Board.mp4" disableremoteplayback="" muted="" playsinline="" poster="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/fQJsihX4vn/thumbnail0000000000.jpeg" preload="auto"><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/fQJsihX4vn/hd-h264.mp4" type="video/mp4"><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/fQJsihX4vn/hd-vp9.mp4" type="video/mp4">Your browser does not support this video</video></p></w></div></vev><vev id="ezpcVO-x-S6"><div><w id="ezpcVO-x-S6c"><p><video aria-label="Real-Time-Feedback.mp4" disableremoteplayback="" muted="" playsinline="" poster="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/Ltr7lvGxMj/thumbnail0000000000.jpeg" preload="auto"><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/Ltr7lvGxMj/hd-h264.mp4" type="video/mp4"><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/Ltr7lvGxMj/hd-vp9.mp4" type="video/mp4">Your browser does not support this video</video></p></w></div></vev><vev id="elWnfCp-a9h"><div><w id="elWnfCp-a9hc"><p><video aria-label="Triggers-Actions-v1.mp4" disableremoteplayback="" muted="" playsinline="" poster="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/AOPDMUPNfY/thumbnail0000000000.jpeg" preload="auto"><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/AOPDMUPNfY/hd-h264.mp4" type="video/mp4"><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/AOPDMUPNfY/hd-vp9.mp4" type="video/mp4">Your browser does not support this video</video></p></w></div></vev><vev id="e-i6FnTVf1E"><div><w id="e-i6FnTVf1Ec"><p><video aria-label="Smart-States-1.mp4" disableremoteplayback="" muted="" playsinline="" poster="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/jEBTM7qCpn/thumbnail0000000000.jpeg" preload="auto"><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/jEBTM7qCpn/hd-h264.mp4" type="video/mp4"><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/jEBTM7qCpn/hd-vp9.mp4" type="video/mp4">Your browser does not support this video</video></p></w></div></vev></div></vev><vev id="eF4EKhFVV3J"><div id="eF4EKhFVV3Jc"><vev id="egPuU6ceM-D"><div id="egPuU6ceM-Dc"><vev id="e9_dRGRsq3t"><div id="e9_dRGRsq3tc"><vev id="eCYU1gXDx45"><div id="eCYU1gXDx45c" role="button" tabindex="0"><vev id="eznwlgP6ooj"><div id="eznwlgP6oojc"><vev id="egM4U8qGXjR"><div id="egM4U8qGXjRc"><vev id="eF6VdoKCQNn"><div><w id="eF6VdoKCQNnc"><img alt="" loading="lazy" src="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/MzoGP7YiN8" srcset=""></w></div></vev></div></vev><vev id="ehIN_7PkWOz"><div id="ehIN_7PkWOzc"><vev id="e9misgZ6p-S"></vev><vev id="eZdG0kPG-Lw"><div><w id="eZdG0kPG-Lwc"><p>Ensuring graceful transitions throughout the prototype and a consistent look and feel.</p></w></div></vev></div></vev></div></vev></div></vev><vev id="eM9d-Wv8tpo"><div><w id="eM9d-Wv8tpoc"><img alt="" loading="lazy" src="https://cdn.vev.design/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/PdOlAP60j_" srcset=""></w></div></vev><vev id="eu7UCNO8bHJ"><div id="eu7UCNO8bHJc" role="button" tabindex="0"><vev id="eXFe1U5CVot"><div id="eXFe1U5CVotc"><vev id="e-Xc2aC4hZ_"><div id="e-Xc2aC4hZ_c"><vev id="eSZlQYBu0hU"><div><w id="eSZlQYBu0hUc"><img alt="" loading="lazy" src="https://cdn.vev.design/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/a3mv33KPdS.svg" srcset=""></w></div></vev></div></vev><vev id="e7gxuXvZM50"><div id="e7gxuXvZM50c"><vev id="eVUOv0-7UrQ"><div><w id="eVUOv0-7UrQc"><p>Powerful Triggers and Actions</p></w></div></vev><vev id="ehn9Ctvulfk"><div><w id="ehn9Ctvulfkc"><p>Enabling rich behaviours and interactions, alone and in combination.</p></w></div></vev></div></vev></div></vev></div></vev><vev id="eELmKXwNfjs"><div><w id="eELmKXwNfjsc"><img alt="" loading="lazy" src="https://cdn.vev.design/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/jLAvLQPA6D" srcset=""></w></div></vev><vev id="elHYNn99H-z"><div id="elHYNn99H-zc" role="button" tabindex="0"><vev id="eRIldnMbPu4"><div id="eRIldnMbPu4c"><vev id="ePfmxoXYYmo"><div id="ePfmxoXYYmoc"><vev id="eN1RqagmvZc"><div><w id="eN1RqagmvZcc"><img alt="" loading="lazy" src="https://cdn.vev.design/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/eOmIsLWTSi.svg" srcset=""></w></div></vev></div></vev><vev id="eQJHQzmYjXc"><div id="eQJHQzmYjXcc"><vev id="eRdqERYmJ3c"></vev><vev id="e31SL3o5Tgb"><div><w id="e31SL3o5Tgbc"><p>No play mode, testing interactions just like that.</p></w></div></vev></div></vev></div></vev></div></vev><vev id="e0nOFa7LhBI"><div><w id="e0nOFa7LhBIc"><img alt="" loading="lazy" src="https://cdn.vev.design/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/jLAvLQPA6D" srcset=""></w></div></vev><vev id="eK2ZC58UMEp"><div id="eK2ZC58UMEpc" role="button" tabindex="0"><vev id="et5K1XKQJg1"><div id="et5K1XKQJg1c"><vev id="ezG40x1C08U"><div id="ezG40x1C08Uc"><vev id="eZp771VuXIs"><div><w id="eZp771VuXIsc"><img alt="" loading="lazy" src="https://cdn.vev.design/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/NeJMZvuAcD.svg" srcset=""></w></div></vev></div></vev><vev id="eAQxJg2dl_z"><div id="eAQxJg2dl_zc"><vev id="ezA-E8xcHBK"></vev><vev id="eLHfTGXzrPH"><div><w id="eLHfTGXzrPHc"><p>An always up to date overview of the flow, quickly jump between states.</p></w></div></vev></div></vev></div></vev></div></vev></div></vev></div></vev></div></vev></div></vev><vev id="eTXu9IE0irb"><div id="eTXu9IE0irbc"><vev id="eBx8ltJyn2H"><div><w id="eBx8ltJyn2Hc"><p>Ordinary Objects runs natively on major platforms</p></w></div></vev><vev id="eB9xMBESAJT"></vev></div></vev></div></vev></div></div></vev><vev id="ekXL1Vk3MOk"><div><w id="ekXL1Vk3MOkc"></w><div><vev id="eMwYTJl8wQ1"><div id="eMwYTJl8wQ1c"><vev id="eBO4yKSTtUA"><div id="eBO4yKSTtUAc"><vev id="e18qqhZG-te"><div><w id="e18qqhZG-tec"><p id=""><h2>Unlock space as a creative medium.</h2></p></w></div></vev><vev id="e_Qqe4o9ZRb"><div><w id="e_Qqe4o9ZRbc"><img alt="" loading="lazy" src="https://cdn.vev.design/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/nOj78YuQA4.svg" srcset=""></w></div></vev></div></vev><vev id="eRVPL8ybml4"><div id="eRVPL8ybml4c"><vev id="eNRmx-JbR3H"><div><w id="eNRmx-JbR3Hc"><p id=""><h3>Express your XR vision with beautiful prototypes to remove the guesswork for stakeholders and developers about how an experience should look and feel.</h3></p></w></div></vev><vev id="ev3MDvD_1L7"><div><w id="ev3MDvD_1L7c"><p id=""><h3>Ordinary Objects is designed from the ground up to ensure creative freedom while playfully surfacing the limitations and benefits of spatial experiences.</h3></p></w></div></vev></div></vev></div></vev></div></div></vev><vev id="eldnpBBgl8F"><div><w id="eldnpBBgl8Fc"></w><div><vev id="eXEJ_ghP0gP"><div id="eXEJ_ghP0gPc"><vev id="eXck89l-OJG"><div id="eXck89l-OJGc"><vev id="esxL098G1fe"><div><w id="esxL098G1fec"><p id=""><h2>Made to design spatial experiences</h2></p></w></div></vev></div></vev><vev id="e6XeA1gofmp"><div id="e6XeA1gofmpc"><vev id="eXNmKcP76jE"><div id="eXNmKcP76jEc"><vev id="e9HggUlbmDn"><div id="e9HggUlbmDnc"><vev id="eoH7-6Rz6NU"><div id="eoH7-6Rz6NUc"><vev id="eDBaSNsQmQA"><div><w id="eDBaSNsQmQAc"><img alt="Font" loading="lazy" src="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/lCR4L8Qwi8.png" srcset="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,h=320/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/lCR4L8Qwi8.png 320w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/lCR4L8Qwi8.png 616w"></w></div></vev></div></vev><vev id="eEM1pbkN9x7"><div id="eEM1pbkN9x7c"><vev id="eD4lwFhnFnL"><div id="eD4lwFhnFnLc"><vev id="eMZnHHc9MSb"><div><w id="eMZnHHc9MSbc"><p>Human centric interactions</p></w></div></vev><vev id="ezFPbxjMzem"><div><w id="ezFPbxjMzemc"><p>Essential events to sketch out interactive flows instantly.</p></w></div></vev></div></vev></div></vev></div></vev><vev id="eOdHmOqEaYe"><div id="eOdHmOqEaYec"><vev id="ebM69-_c2og"><div id="ebM69-_c2ogc"><vev id="eOTOw22askv"><div><w id="eOTOw22askvc"><img alt="Font" loading="lazy" src="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/NL-NSUWzaE.png" srcset="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,h=320/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/NL-NSUWzaE.png 320w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/NL-NSUWzaE.png 540w"></w></div></vev></div></vev><vev id="eFBUsUQjjHo"><div id="eFBUsUQjjHoc"><vev id="e_oR3je7qt4"><div id="e_oR3je7qt4c"><vev id="ewGG6DZEndP"><div><w id="ewGG6DZEndPc"><p>Authoring features for spatial computing</p></w></div></vev><vev id="ePOlpfZ-YA-"><div><w id="ePOlpfZ-YA-c"><p>Bring spatial prototypes to life with simple and graceful actions.</p></w></div></vev></div></vev></div></vev></div></vev></div></vev><vev id="eOWxXPhCcb_"><div id="eOWxXPhCcb_c"><vev id="eyGS4LhhZUq"><div id="eyGS4LhhZUqc"><vev id="ekeC9U2ynBC"><div id="ekeC9U2ynBCc"><vev id="eA95AGe1xxe"><div><w id="eA95AGe1xxec"><p><video aria-label="Spatial-audio-s.mov" disableremoteplayback="" muted="" playsinline="" poster="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/8ghTcNuUu8/thumbnail0000000000.jpeg" preload="auto" autoplay=""><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/8ghTcNuUu8/hd-h264.mp4" type="video/mp4"><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/8ghTcNuUu8/hd-vp9.mp4" type="video/mp4">Your browser does not support this video</video></p></w></div></vev></div></vev><vev id="eIN7V2kY1s8"><div id="eIN7V2kY1s8c"><vev id="eblKmv9fjHQ"><div id="eblKmv9fjHQc"><vev id="eDUevS4Rs3W"></vev><vev id="ewomc9jODww"><div><w id="ewomc9jODwwc"><p>Add audio to create truly immersive and intuitive experiences</p></w></div></vev></div></vev></div></vev></div></vev><vev id="eJURSgj_WuS"><div id="eJURSgj_WuSc"><vev id="eu_J7GRx-My"><div id="eu_J7GRx-Myc"><vev id="eHa1VcrSfxP"><div><w id="eHa1VcrSfxPc"><p><video aria-label="GLB-Animation-s_2.mp4" disableremoteplayback="" muted="" playsinline="" poster="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/XmqXBHrnCW/thumbnail0000000000.jpeg" preload="auto" autoplay=""><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/XmqXBHrnCW/hd-h264.mp4" type="video/mp4"><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/XmqXBHrnCW/hd-vp9.mp4" type="video/mp4">Your browser does not support this video</video></p></w></div></vev></div></vev><vev id="eZRxtoBXLCJ"><div id="eZRxtoBXLCJc"><vev id="eIPN6gIyF_H"><div id="eIPN6gIyF_Hc"><vev id="eje6wmwkA9g"></vev><vev id="eOt3vq44FC0"><div><w id="eOt3vq44FC0c"><p>Import 3D assets with animations to add finesse and fun</p></w></div></vev></div></vev></div></vev></div></vev><vev id="e9sRSnvVPlO"><div id="e9sRSnvVPlOc"><vev id="eVIUw5LNGYH"><div id="eVIUw5LNGYHc"><vev id="e2GjubL-Bit"><div><w id="e2GjubL-Bitc"><p><video aria-label="PNG animations.mov" disableremoteplayback="" muted="" playsinline="" poster="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/xDsza3gj9j/thumbnail0000000000.jpeg" preload="auto" autoplay=""><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/xDsza3gj9j/hd-h264.mp4" type="video/mp4"><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/xDsza3gj9j/hd-vp9.mp4" type="video/mp4">Your browser does not support this video</video></p></w></div></vev></div></vev><vev id="eyVcOFV1PZZ"><div id="eyVcOFV1PZZc"><vev id="eqI5cU08f6P"><div id="eqI5cU08f6Pc"><vev id="eL2zsN1y0ul"></vev><vev id="eOpMOsJspPY"><div><w id="eOpMOsJspPYc"><p>Quickly mock up spatial UIs with images.</p></w></div></vev></div></vev></div></vev></div></vev></div></vev></div></vev><vev id="ebe2wMbAYiD"></vev></div></vev></div></div></vev><vev id="eD0L2Izs4fP"><div><w id="eD0L2Izs4fPc"></w><div><vev id="e5aF1sUPe8g"><div id="e5aF1sUPe8gc"><vev id="e6I7f44faNV"></vev><vev id="eA5PMVXXDZA"><div><w id="eA5PMVXXDZAc"><p id=""><h2>A workflow to go fast, go far and discover.</h2></p></w></div></vev><vev id="egU12XeRbfH"><div id="egU12XeRbfHc"><vev id="efGzSf3U2Oz"></vev><vev id="emi_4MttdDJ"><div id="emi_4MttdDJc"><vev id="e5othl-kiRV"><div><w id="e5othl-kiRVc"><p><video aria-label="Screen Recording 2024-11-26 at 15.48.09.mov" disableremoteplayback="" muted="" playsinline="" poster="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,h=1280/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/H6QPVVBFNO" preload="auto" autoplay=""><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/kG2Lluougd/hd-h264.mp4" type="video/mp4"><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/kG2Lluougd/hd-vp9.mp4" type="video/mp4">Your browser does not support this video</video></p></w></div></vev></div></vev></div></vev><vev id="eCTaEb4XssM"><div><w id="eCTaEb4XssMc"><p id=""><h3>With Ordinary Objects, ideating, designing and testing <em>true spatial</em> experiences is faster and more fun than ever before. Discover novel use-cases, create variants and fine tune prototypes until they excite and are intuitive to use.</h3></p></w></div></vev><vev id="egIU6bMrvl3"></vev></div></vev></div></div></vev><vev id="eZDYLy159zL"><div><w id="eZDYLy159zLc"></w><div><vev id="em18a4xf610"><div id="em18a4xf610c"><vev id="erGLJ86-Egk"><div id="erGLJ86-Egkc"><vev id="egMayGHHHgv"><div><w id="egMayGHHHgvc"><img alt="" loading="lazy" src="https://cdn.vev.design/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/qLlzZcOOk1.svg" srcset=""></w></div></vev></div></vev><vev id="ekEOO0G9StJ"><div><w id="ekEOO0G9StJc"><p id=""><h2>We are on a mission to merge our physical world with the synthetic reality we live in.</h2><h2>We believe in a world where we are free of screens and floating panels.</h2><h2>Present in the moment, connected by <em>ordinary objects</em>.</h2></p></w></div></vev><vev id="eYHDiYcN5UN"></vev><vev id="e5WDH2yvbm8"></vev></div></vev></div></div></vev><vev id="eXaexRh8dOH"><div><w id="eXaexRh8dOHc"></w><div><vev id="eVCfJUwoo7H"><div id="eVCfJUwoo7Hc"><vev id="e7lhOVXITGa"></vev><vev id="ejJzOVEJZLM"><div id="ejJzOVEJZLMc"><vev id="ebWF-I5tvoM"><div id="ebWF-I5tvoMc"><vev id="eKApWwZDQ4q"><div><w id="eKApWwZDQ4qc"><p id=""><h2>Go above and beyond.</h2></p></w></div></vev><vev id="eTxU-6Vs4_o"><div id="eTxU-6Vs4_oc"><vev id="ecU0iahm1nt"><div role="button" tabindex="0"><w id="ecU0iahm1ntc"><p>Ordinary Objects is the first mixed reality prototyping platform that elevates plane and spatial anchors to the design process.</p></w></div></vev></div></vev></div></vev><vev id="ewYGIYNu6mE"><div id="ewYGIYNu6mEc"><vev id="e_QI4PURFJ5"><div id="e_QI4PURFJ5c"><vev id="ehp3Ng_53wP"><div id="ehp3Ng_53wPc"><vev id="earFzaFt7Dg"></vev><vev id="elxPYYlk9yW"><div><w id="elxPYYlk9yWc"><p><video aria-label="Spatial Canvas - Anchors.mov" disableremoteplayback="" muted="" playsinline="" poster="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/hzlOIf34Sg/thumbnail0000000000.jpeg" preload="auto" autoplay=""><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/hzlOIf34Sg/hd-h264.mp4" type="video/mp4"><source src="https://cdn.vev.design/a/c1uZR8BI8TkpmJHZsLDg/p/wyPaPGvlZ-/v/hzlOIf34Sg/hd-vp9.mp4" type="video/mp4">Your browser does not support this video</video></p></w></div></vev></div></vev><vev id="e_-BvFn9pQu"><div id="e_-BvFn9pQuc"><vev id="eAViVlXVp0k"><div id="eAViVlXVp0kc"><vev id="eLGJWV5UnQ5"><div id="eLGJWV5UnQ5c"><vev id="eW8roZljJ3w"><div id="eW8roZljJ3wc"><vev id="eEb75ZiUpoT"><div id="eEb75ZiUpoTc"><vev id="epODTmfdquZ"><div><w id="epODTmfdquZc"><img alt="" loading="lazy" src="https://cdn.vev.design/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/350hA44uhp.svg" srcset=""></w></div></vev></div></vev><vev id="exYc8k2Zxdg"><div id="exYc8k2Zxdgc"><vev id="e4IyA5URQTO"></vev><vev id="eQdzCQBNw0L"><div><w id="eQdzCQBNw0Lc"><p>Interact with physical surfaces.</p></w></div></vev></div></vev></div></vev></div></vev></div></vev></div></vev></div></vev><vev id="eOlYSGQmSBu"><div id="eOlYSGQmSBuc"><vev id="e9b9gWAj3jP"><div id="e9b9gWAj3jPc"><vev id="eLZX3WtXHsZ"><div id="eLZX3WtXHsZc"><vev id="eD_1rpie7w6"><div id="eD_1rpie7w6c"><vev id="eIkNjGJvF8g"><div id="eIkNjGJvF8gc"><vev id="er0CLHoYkes"><div id="er0CLHoYkesc"><vev id="eJHCRHjKAHn"><div><w id="eJHCRHjKAHnc"><img alt="" loading="lazy" src="https://cdn.vev.design/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/7wtW_VEhNY.svg" srcset=""></w></div></vev></div></vev><vev id="eT3My_B_btn"></vev></div></vev></div></vev></div></vev></div></vev><vev id="elrUu_FrA6j"></vev></div></vev></div></vev><vev id="eSdHfs8KMJU"><div id="eSdHfs8KMJUc"><vev id="ehMDiNCX5j0"><div role="button" tabindex="0"><w id="ehMDiNCX5j0c"><p>Next-level creative freedom that sets a new standard for interaction design. Ordinary Objects allows full control over the first crucial touchpoints of entering a spatial app.</p></w></div></vev></div></vev></div></vev><vev id="eOrLRuYktFf"></vev></div></vev></div></div></vev><vev id="exFllCXsl_Y"><div><w id="exFllCXsl_Yc"></w><div><vev id="eiZ9Cy2PGRt"><div id="eiZ9Cy2PGRtc"><vev id="eAJG5yC-qKj"><div id="eAJG5yC-qKjc"><vev id="eU52efa6E9_"><div id="eU52efa6E9_c"><vev id="ezbZLf4Fcsg"><div><w id="ezbZLf4Fcsgc"><p id=""><h2>Start prototyping.</h2></p></w></div></vev><vev id="e-g73oX4AUE"><div><w id="e-g73oX4AUEc"><p>Download the native editor for macOS or windows.</p></w></div></vev><vev id="eRcUOAxtisb"><div id="eRcUOAxtisbc"><vev id="eP53_IsjWTN"></vev><vev id="eUCF8wAX9_q"><div><w id="eUCF8wAX9_qc"><img alt="Rectangle, Font" loading="lazy" src="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=1280/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/Ri_p3Hwb_d" srcset="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=320/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/Ri_p3Hwb_d 320w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=640/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/Ri_p3Hwb_d 640w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=960/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/Ri_p3Hwb_d 960w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=1280/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/Ri_p3Hwb_d 1280w"></w></div></vev></div></vev></div></vev><vev id="ec24unks_Lc"><div id="ec24unks_Lcc"><vev id="e_DOTeLgsy8"><div><w id="e_DOTeLgsy8c"><p id=""><h2>Test prototypes.</h2></p></w></div></vev><vev id="eizMBfpdQ7V"><div><w id="eizMBfpdQ7Vc"><p>Get the mirror apps for Quest 3 and iOS.</p></w></div></vev><vev id="ekw6ljqcFHy"><div id="ekw6ljqcFHyc"><vev id="eQLE0mbqhtL"></vev><vev id="ewuZ2l8QKc1"><div id="ewuZ2l8QKc1c"><vev id="ePAUkA4jV6N"><div><w id="ePAUkA4jV6Nc"><img alt="Rectangle" loading="lazy" src="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/xqEAfnnKJr" srcset="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=320/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/xqEAfnnKJr 320w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=640/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/xqEAfnnKJr 640w"></w></div></vev></div></vev></div></vev></div></vev></div></vev></div></vev></div></div></vev><vev id="e_bjFwbHGUF"><div><w id="e_bjFwbHGUFc"></w><div><vev id="ewavDeIhYX-"><div id="ewavDeIhYX-c"><vev id="eHkI_90X9lv"></vev><vev id="eF9cP7CYnLy"><div id="eF9cP7CYnLyc"><vev id="eE9TYAQ69bp"><div id="eE9TYAQ69bpc"><vev id="epRHIX90fl8"><div><w id="epRHIX90fl8c"><p id=""><h2>Collaboration, in hyperspace</h2></p></w></div></vev><vev id="egr9I-_H-IN"><div id="egr9I-_H-INc"><vev id="e_uF316dJhg"><div role="button" tabindex="0"><w id="e_uF316dJhgc"><p>Everything up to date, everywhere, instantly.</p></w></div></vev></div></vev></div></vev><vev id="epHzmJY2tQg"><div id="epHzmJY2tQgc"><vev id="e_8CIUJjOgj"><div id="e_8CIUJjOgjc"><vev id="eYQe-QSHPSD"><div><w id="eYQe-QSHPSDc"><img alt="Product, Font, Screenshot, Rectangle" loading="lazy" src="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=1920/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/ShQ2FyzBm2.png" srcset="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=320/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/ShQ2FyzBm2.png 320w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=640/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/ShQ2FyzBm2.png 640w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=960/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/ShQ2FyzBm2.png 960w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82,w=1280/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/ShQ2FyzBm2.png 1280w,https://cdn.vev.design/cdn-cgi/image/f=auto,q=82/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/ShQ2FyzBm2.png 2048w"></w></div></vev></div></vev><vev id="eer6SlPFYHw"><div id="eer6SlPFYHwc"><vev id="eo4tgWaYXv6"><div id="eo4tgWaYXv6c"><vev id="e23AUK13sno"><div id="e23AUK13snoc"><vev id="edgLsN6Dfzv"><div id="edgLsN6Dfzvc"><vev id="eBHynb_2rxC"><div id="eBHynb_2rxCc"><vev id="ezMV5dbzIW1"><div><w id="ezMV5dbzIW1c"><img alt="" loading="lazy" src="https://cdn.vev.design/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/_jmheJ5k-d.svg" srcset=""></w></div></vev></div></vev><vev id="eFoqKk4fM7-"><div id="eFoqKk4fM7-c"><vev id="eolHrgyVmCY"><div><w id="eolHrgyVmCYc"><p>Changes in the editor get synchronised automatically so your collaborators are always up to date, in the editor and mirror.</p></w></div></vev><vev id="e5F778cT7SG"><div><w id="e5F778cT7SGc"><p>Collaborating never felt so smooth.</p></w></div></vev></div></vev></div></vev></div></vev></div></vev></div></vev></div></vev><vev id="eINbji20eJR"></vev></div></vev><vev id="edEhEtDUddv"></vev></div></vev></div></div></vev><vev id="enhBtcyHCHE"><div><w id="enhBtcyHCHEc"></w><div><vev id="erZAFmUvcW6"><div id="erZAFmUvcW6c"><vev id="e-QlUGs0HEU"></vev><vev id="eBhM4IRrZXH"><div><w id="eBhM4IRrZXHc"><p id=""><h2>Collaboration, in hyperspace.</h2></p></w></div></vev><vev id="egoZ3a8Y1vl"><div id="egoZ3a8Y1vlc"><vev id="e79SksDL_SB"><div><w id="e79SksDL_SBc"><div id=""><p>In Ordinary Objects, collaboration feels like a super power.</p><p>Riff on ideas or refine a prototype.</p></div></w></div></vev><vev id="eBxlWDONw4m"></vev><vev id="e00A_augfuS"></vev></div></vev></div></vev></div></div></vev><vev id="eU4x_3RAjtD"><div><w id="eU4x_3RAjtDc"></w><div><vev id="ecTeJE0VLSA"><div id="ecTeJE0VLSAc"><vev id="e5zh0xbtNLF"><div id="e5zh0xbtNLFc"><vev id="e-8LzwI_6F3"><div id="e-8LzwI_6F3c"><vev id="e2LLXXRMvAw"><div><w id="e2LLXXRMvAwc"><img alt="" loading="lazy" src="https://cdn.vev.design/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/nOj78YuQA4.svg" srcset=""></w></div></vev></div></vev><vev id="eyQyGxvO1In"><div id="eyQyGxvO1Inc"><vev id="eUsXn8KtotY"><div><w id="eUsXn8KtotYc"><p id=""><h2>Delightful spatial apps.</h2></p></w></div></vev><vev id="eaoSXKM3zD-"></vev></div></vev><vev id="eH2JhE09Miu"><div id="eH2JhE09Miuc"><vev id="eo-03kxry0Q"><div id="eo-03kxry0Qc"><vev id="e8x3zxTy16z"></vev><vev id="eWSl6Ew3cxY"></vev><vev id="eoS0KnspT8-"></vev><vev id="euuHTZ0okLV"></vev><vev id="ec84MO0EycP"><a href="https://www.linkedin.com/company/ordinaryobjectsdesign" data-tween="false" target="_blank"><div id="ec84MO0EycPc"><vev id="euEBHjJ_nA0"><div><w id="euEBHjJ_nA0c"><img alt="" loading="lazy" src="https://cdn.vev.design/cdn-cgi/image/f=auto,q=82/private/Q7R509Ho9MZy0VuJiZbVOMS2HmR2/image/-yCLMprD0J" srcset=""></w></div></vev></div></a></vev></div></vev><vev id="elQBxy9940L"></vev></div></vev></div></vev></div></vev></div></div></vev></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hedy: Textual programming made easy (197 pts)]]></title>
            <link>https://www.hedy.org/</link>
            <guid>42837636</guid>
            <pubDate>Mon, 27 Jan 2025 05:11:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hedy.org/">https://www.hedy.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42837636">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main_page_content">
        
        <div>
                    <h2>Textual programming made easy!</h2>
                    
                    <p>Many schools and teachers around the world want to teach their students programming. Initially this is often done with playful tools, ranging from the Beebot robot to
Scratch Junior or Scratch. After using such tools, kids often want to move to more powerful, textual programming languages, like Python.</p>
<p>Python however is hard, because it is only available in English, and requires learners to learn complex programming concepts and syntax at once.
Hedy is the easy way to get started with textual programming languages! Hedy is free to use, open source, and unlike any other textual programming language in three ways.</p>
<ol>
<li>Hedy is multi-lingual, you can use Hedy in your own language</li>
<li>Hedy is gradual, so you can learn one concept and its syntax a time</li>
<li>Hedy is built for the classroom, allowing teachers to fully customize their student's experience</li>
</ol>

                </div>
        
        <div>
                    <div>
                        <h3>Multi-lingual programming</h3>
                        <p>While almost all textual programming language have keywords in English, such as <code>for</code> or <code>repeat</code>, Hedy can be used in any language! We currently support 47 different languages, including Dutch, Spanish, Arabic, Turkish, Chinese and Hindi. If your language is not available you can always start a new translation.</p>

                    </div>
                    <p><img src="https://d1xliaqnpftsm2.cloudfront.net/static-bdbbcc20a24ec0b311573119d46d08f324f0eb99/images/hedy-multilang.png">
                </p></div>
        
        <div>
                    <p><img src="https://d1xliaqnpftsm2.cloudfront.net/static-bdbbcc20a24ec0b311573119d46d08f324f0eb99/images/hedy-grows.png"></p><div>
                        <h3>Step by step learning</h3>
                        <p>Learning a programming language can be overwhelming, since learners have to learn concepts (for example if-else or loops) and syntax (like quotation marks or round brackets) at the same time. In Hedy, concepts are first introduced with little syntax and then refined. A scientifically proven way to learn!</p>

                    </div>
                </div>
        
        <div>
                    <div>
                        <h3>Built for the classroom</h3>
                        <p>Hedy is suitable for kids aged 10 and up and designed for classroom use.
Teachers can use our free, built-in lesson plans, but can also author their own lessons and load these into the Hedy user interface.</p>

                    </div>
                    <p><img src="https://d1xliaqnpftsm2.cloudfront.net/static-bdbbcc20a24ec0b311573119d46d08f324f0eb99/images/hedy-classroom.png">
                </p></div>
        
        <div>
                    <h2>Programming in context</h2>
                    
                    <p>Hedy shows programming in the broadest way possible, and can be used in variety of exciting ways. Hedy allows for the creation of digital and interactive stories, colorful drawings that can be shown on the screen but also drawn with a pen plotter or embroidered on a shirt, and can be used to create games or apps with buttons and keyboard actions.</p>

                </div>
        
        <div>
                    
                    <div>
                        <h3>Is Hedy free?</h3>
                        <p>Yes! Hedy is 'Open source', which means that everyone can help us make Hedy better.
You can find our code on <a href="https://github.com/hedyorg/hedy" target="_blank">Github</a>.
If you like Hedy and want to contribute, we accept (and are very grateful for) <a href="https://github.com/sponsors/hedyorg" target="_blank">donations</a>!</p>

                    </div>
                    
                    <div>
                        <h3>Do I need to install anything?</h3>
                        <p>No. Hedy works in the browser, which is the program you are using to look at this page. Probably Chrome or Edge or Firefox. Hedy also works on phones and tablets.</p>

                    </div>
                    
                    <div>
                        <h3>Do I need programming experience to teach with Hedy?</h3>
                        <p>No, that is not needed. All concepts are explained in the slides and in the interface for learners.
If you create a free teacher's account, you also get access to the teacher's manual with information on how to teach
and frequently made mistakes.</p>

                    </div>
                    
                </div>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[If OpenSSL were a GUI (2022) (181 pts)]]></title>
            <link>https://smallstep.com/blog/if-openssl-were-a-gui/</link>
            <guid>42837462</guid>
            <pubDate>Mon, 27 Jan 2025 04:34:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://smallstep.com/blog/if-openssl-were-a-gui/">https://smallstep.com/blog/if-openssl-were-a-gui/</a>, See on <a href="https://news.ycombinator.com/item?id=42837462">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p> Get your self-service free hosted private certificate authority today</p></div><div><div><article><time datetime="{updatedAt}">Updated on: <!-- -->May 20, 2024</time><blockquote>
<p>"When something exceeds your ability to understand how it works,<br>
it sort of becomes magical." - Jony Ive</p>
</blockquote>
<p><img src="https://smallstep.imgix.net/openssl_83b5f638ef.png?auto=format%2Ccompress&amp;fit=max&amp;q=50" alt="openssl.png"></p>
<p>*This is incomplete. It covers about 80% of one corner of OpenSSL's functionality. The certificate policy options have a lot more knobs that I didn't include.</p>
<div><p>Carl Tashian (<a href="https://tashian.com/">Website</a>, <a href="https://www.linkedin.com/in/tashian/">LinkedIn</a>) is an engineer, writer, exec coach, and startup all-rounder. He's currently an Offroad Engineer at Smallstep. He co-founded and built the engineering team at Trove, and he wrote the code that opens your Zipcar. He lives in San Francisco with his wife Siobhan and he loves to play the modular synthesizer 🎛️🎚️</p></div></article></div><div><h2>Further Reading</h2></div></div></div><div><div><p><img alt="Smallstep Icon Logo" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" srcset="https://smallstep.imgix.net/images/smallstep-icon-logo-white.svg?auto=format%2Ccompress&amp;fit=max&amp;w=48&amp;q=50 1x, https://smallstep.imgix.net/images/smallstep-icon-logo-white.svg?auto=format%2Ccompress&amp;fit=max&amp;w=96&amp;q=50 2x" src="https://smallstep.imgix.net/images/smallstep-icon-logo-white.svg?auto=format%2Ccompress&amp;fit=max&amp;w=96&amp;q=50"></p><div><p>Subscribe to updates</p><p>Unsubscribe anytime, see Privacy Policy</p></div></div><nav></nav><div><p>© </p><!-- --><p>2025</p><!-- --><p> Smallstep Labs, Inc. All rights reserved</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Purelymail: Cheap, no-nonsense email (287 pts)]]></title>
            <link>https://purelymail.com/</link>
            <guid>42836818</guid>
            <pubDate>Mon, 27 Jan 2025 02:38:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://purelymail.com/">https://purelymail.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42836818">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Cheap, no-nonsense email</h2><p>Let's get straight to the point:</p><ul><li>We host your email address.</li><li>We're IMAP and POP3 compatible, so we work with most mail apps.</li><ul><li>Or you can use our webmail, powered by <a href="https://roundcube.net/" target="_blank" rel="noopener">Roundcube</a>.</li></ul><li>No arbitrary limits. Have as many users and store as much mail as you want.</li><li>Bring as many of your own domains as you want, or use one of ours. No extra charges.</li><li>It's cheap. Really, really cheap.</li></ul><h2>How cheap?</h2><p>Let's say you only need one email address, and have 3 GB of data to store. For one year of use, this will cost:</p><table><tbody><tr><td><a href="https://protonmail.com/" target="_blank" rel="noopener">Protonmail</a></td><td>$48.00</td></tr><tr><td><a href="https://fastmail.com/" target="_blank" rel="noopener">Fastmail</a></td><td>$60.00</td></tr><tr><td><a href="https://workspace.google.com/" target="_blank" rel="noopener">Google Workspace</a></td><td>$72.00</td></tr><tr><td><a href="https://zoho.com/mail" target="_blank" rel="noopener">Zoho</a></td><td>$12.00</td></tr><tr><td><a href="https://hushmail.com/" target="_blank" rel="noopener">Hushmail</a></td><td>$49.98</td></tr><tr><td>Purelymail</td><td>$10.00</td></tr></tbody></table><p>For most use cases, Purelymail is the cheapest option available. <b>Especially</b> if you need more than one user. All of the plans above charge per user, but we don't. Check out our <a href="https://purelymail.com/pricing">pricing page</a> for more information. (For an in-depth explanation of this particular comparison, <a href="https://purelymail.com/pricingcomparisonindepth" target="_blank" rel="noopener">see here.</a>)</p><h2>What's the catch?</h2><p>What you get here is  <i>purely</i> mail. </p><p>We're not trying to bamboozle you with glossy images, or sell you a lofty ideal. If we have a gimmick, it's that we offer a known service at a low price. What you do with it is up to you.</p><h3>An honest list of drawbacks</h3><p>Based on our experience, here are our weak points:</p><ul><li>Occasionally, obscure email servers will block emails sent through us. Usually this can be resolved within a day or two.</li><li>We don't have a 24/7 support staff, although we do try to get back to any inquiries within a day.</li><li>Some features other providers have, such as calendar syncing, are not yet implemented.</li><li>We're not for sending any type of unsolicited or marketing emails (you should use a dedicated marketing platform anyway).</li><li>Our UI can be a little unpolished and unglamorous, if that bothers you.</li></ul><h3>Also, we're in beta</h3><p>That means there might be a few hiccups along the way. If you run across any problems you can always <a href="https://purelymail.com/support">let us know,</a> and we'll do our best to fix them.</p><p>If you're interested in Purelymail but want to wait until we're out of beta, check out <a href="https://purelymail.com/betamailinglist">our mailing list.</a></p><h2>Is this for me?</h2><b>Do you want email?</b><p>Then yes, probably.</p><b>What about security and reliability?</b><p><a href="https://purelymail.com/docs/security">We do take security seriously.</a></p><p>As for reliability, we're in beta, but our architecture has proven itself robust so far, our infrastructure runs on the highly reliable AWS cloud, and even if we do have an outage the email protocols are pretty forgiving. (See our <a href="https://news.purelymail.com/status.html">status page</a> for our historical issues- there aren't that many.)</p><b>Do you sell user data or ads?</b><p>Absolutely not. Check out our <a href="https://purelymail.com/privacy">privacy policy.</a></p><b>What features do you support?</b><p>See our full <a href="https://purelymail.com/docs/features">features list</a>.</p><h2>Still can't decide if we're right for you?</h2><p>Come take a look around!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Knowing less about AI makes people more open to using it (101 pts)]]></title>
            <link>https://theconversation.com/knowing-less-about-ai-makes-people-more-open-to-having-it-in-their-lives-new-research-247372</link>
            <guid>42836517</guid>
            <pubDate>Mon, 27 Jan 2025 01:54:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/knowing-less-about-ai-makes-people-more-open-to-having-it-in-their-lives-new-research-247372">https://theconversation.com/knowing-less-about-ai-makes-people-more-open-to-having-it-in-their-lives-new-research-247372</a>, See on <a href="https://news.ycombinator.com/item?id=42836517">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article" data-id="247372" itemscope="" itemtype="http://schema.org/Article">
  

    
<figure>
  <div>
    <p><img alt="Brain - AI." src="https://images.theconversation.com/files/642582/original/file-20250115-15-vekshv.jpg?ixlib=rb-4.1.0&amp;rect=0%2C0%2C2683%2C1786&amp;q=20&amp;auto=format&amp;w=320&amp;fit=clip&amp;dpr=2&amp;usm=12&amp;cs=strip" data-id="642582" itemprop="image"></p>
  </div>

    <p>
      <figcaption>
        
        <span><a href="https://www.shutterstock.com/image-photo/ai-brain-motif-centered-on-circular-2500501245">Anggalih Prasetya / Shutterstock</a></span>
      </figcaption>
    </p>

  <div>
      
  <header>
    

    <p><time datetime="2025-01-20T13:00:45Z" itemprop="datePublished" content="2025-01-20T13:00:45Z">Published: January 20, 2025 2.00pm CET</time>
    </p>
  </header>

    </div>
</figure>


  <div>
    <div>

      
        <div>
      <h3>Authors</h3>
      <ol>
        <li id="author-622246" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
    <a rel="author" itemprop="url" href="https://theconversation.com/profiles/chiara-longoni-1510254">
      <img alt="" data-src="https://cdn.theconversation.com/avatars/1510254/width170/image-20240208-26-1fxzgt.jpg" src="https://cdn.theconversation.com/avatars/1510254/width170/image-20240208-26-1fxzgt.jpg" itemprop="image">
      <span itemprop="name">
        Chiara Longoni
      </span>
</a>
    

    <p>
      Associate Professor, Marketing and Social Science, Bocconi University
    </p>

</li>
<li id="author-622249" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
    <a rel="author" itemprop="url" href="https://theconversation.com/profiles/gil-appel-2298003">
      <img alt="" data-src="https://cdn.theconversation.com/avatars/2298003/width170/image-20250116-17-9jfb48.jpg" src="https://cdn.theconversation.com/avatars/2298003/width170/image-20250116-17-9jfb48.jpg" itemprop="image">
      <span itemprop="name">
        Gil Appel
      </span>
</a>
    

    <p>
      Assistant Professor of Marketing, School of Business, George Washington University
    </p>

</li>
<li id="author-622248" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
    <a rel="author" itemprop="url" href="https://theconversation.com/profiles/stephanie-tully-2298001">
      <img alt="" data-src="https://cdn.theconversation.com/avatars/2298001/width170/file-20250115-15-610b82.jpg" src="https://cdn.theconversation.com/avatars/2298001/width170/file-20250115-15-610b82.jpg" itemprop="image">
      <span itemprop="name">
        Stephanie Tully
      </span>
</a>
    

    <p>
      Associate Professor of Marketing, USC Marshall School of Business, University of Southern California
    </p>

</li>

      </ol>
    </div>


      
    <section>
      <h3>Disclosure statement</h3>
        <p><span>The authors do not work for, consult, own shares in or receive funding from any company or organisation that would benefit from this article, and have disclosed no relevant affiliations beyond their academic appointment.</span></p>
    </section>

      

  <section>
    <h3>Partners</h3>

    <p><a href="https://theconversation.com/institutions/bocconi-university-3019"><picture><source srcset="https://images.theconversation.com/partners/1602/logos/logo-1651682222.png?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=170&amp;h=170" media="(min-width:600px)"><img alt="Bocconi University" src="data:image/gif;base64,R0lGODlhAQABAAD/ACwAAAAAAQABAAACADs%3D"></picture></a></p><p><a href="https://theconversation.com/institutions/university-of-southern-california-1265"><picture><source srcset="https://images.theconversation.com/partners/1267/logos/logo-1551380060.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=170&amp;h=170" media="(min-width:600px)"><img alt="University of Southern California" src="data:image/gif;base64,R0lGODlhAQABAAD/ACwAAAAAAQABAAACADs%3D"></picture></a></p>

    <p><a href="https://theconversation.com/institutions/bocconi-university-3019">Bocconi University</a> provides funding as a member of The Conversation UK.</p><p><a href="https://theconversation.com/institutions/university-of-southern-california-1265">University of Southern California</a> provides funding as a member of The Conversation US.</p>


    <p><a href="https://theconversation.com/europe/partners">View all partners</a></p>
  </section>

      

      
    </div>

    <div itemprop="articleBody">
    <p>The rapid spread of artificial intelligence has people wondering: who’s most likely to embrace AI in their daily lives? Many assume it’s the tech-savvy – those who understand how AI works – who are most eager to adopt it. </p>

<p>Surprisingly, our new research (published in the <a href="https://journals.sagepub.com/doi/10.1177/00222429251314491">Journal of Marketing</a>) finds the opposite. People with less knowledge about AI are actually more open to using the technology. We call this difference in adoption propensity the “lower literacy-higher receptivity” link.</p>

<p>This link shows up across different groups, settings and even countries. For instance, our analysis of <a href="https://www.ipsos.com/sites/default/files/ct/news/documents/2022-01/Global-opinions-and-expectations-about-AI-2022.pdf">data from market research company Ipsos</a> spanning 27 countries reveals that people in nations with lower average AI literacy are more receptive towards AI adoption than those in nations with higher literacy. </p>

<p>Similarly, our survey of US undergraduate students finds that those with less understanding of AI are more likely to indicate using it for tasks like academic assignments. </p>

<p>The reason behind this link lies in how AI now performs tasks we once thought only humans could do. When AI creates a piece of art, writes a heartfelt response or plays a musical instrument, it can feel almost magical – like it’s crossing into human territory. </p>

<p>Of course, AI <a href="https://online.hull.ac.uk/blog/what-is-artificial-intelligence-and-how-is-it-different-from-human-intelligence">doesn’t actually possess</a> human qualities. A chatbot might generate an empathetic response, but it doesn’t feel empathy. People with more technical knowledge about AI understand this. </p>

<p>They know how algorithms (sets of mathematical rules used by computers to carry out particular tasks), training data (used to improve how an AI system works) and computational models operate. This makes the technology less mysterious.</p>

<p>On the other hand, those with less understanding may see AI as magical and awe inspiring. We suggest this sense of magic makes them more open to using AI tools.</p>

<p>Our studies show this lower literacy-higher receptivity link is strongest for using AI tools in areas people associate with human traits, like providing emotional support or counselling. When it comes to tasks that don’t evoke the same sense of human-like qualities – such as analysing test results – the pattern flips. People with higher AI literacy are more receptive to these uses because they focus on AI’s efficiency, rather than any “magical” qualities.</p>

<figure>
            <p><img alt="Typing." data-src="https://images.theconversation.com/files/643186/original/file-20250117-15-eswebz.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip" data-srcset="https://images.theconversation.com/files/643186/original/file-20250117-15-eswebz.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=600&amp;h=400&amp;fit=crop&amp;dpr=1 600w, https://images.theconversation.com/files/643186/original/file-20250117-15-eswebz.jpg?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=600&amp;h=400&amp;fit=crop&amp;dpr=2 1200w, https://images.theconversation.com/files/643186/original/file-20250117-15-eswebz.jpg?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=600&amp;h=400&amp;fit=crop&amp;dpr=3 1800w, https://images.theconversation.com/files/643186/original/file-20250117-15-eswebz.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;h=503&amp;fit=crop&amp;dpr=1 754w, https://images.theconversation.com/files/643186/original/file-20250117-15-eswebz.jpg?ixlib=rb-4.1.0&amp;q=30&amp;auto=format&amp;w=754&amp;h=503&amp;fit=crop&amp;dpr=2 1508w, https://images.theconversation.com/files/643186/original/file-20250117-15-eswebz.jpg?ixlib=rb-4.1.0&amp;q=15&amp;auto=format&amp;w=754&amp;h=503&amp;fit=crop&amp;dpr=3 2262w" sizes="(min-width: 1466px) 754px, (max-width: 599px) 100vw, (min-width: 600px) 600px, 237px" src="https://images.theconversation.com/files/643186/original/file-20250117-15-eswebz.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip"></p>
            <figcaption>
              <span>The researchers carried out surveys with a number of different groups, including undergraduates.</span>
              <span><a href="https://www.shutterstock.com/image-photo/human-interact-ai-artificial-intelligence-virtual-2459700141">Owlie Productions / Shutterstock</a></span>
            </figcaption>
          </figure>

<h2>It’s not about capability, fear or ethics</h2>

<p>Interestingly, this link between lower literacy and higher receptivity persists even though people with lower AI literacy are more likely to view AI as less capable, less ethical, and even a bit scary. Their openness to AI seems to stem from their sense of wonder about what it can do, despite these perceived drawbacks. </p>

<p>This finding offers new insights into <a href="https://journals.sagepub.com/doi/full/10.1177/0022243719851788?casa_token=TCasUPe0eDgAAAAA%3AxYiVq00BSj6fmxbhnc_wFboqbpHOPqIV11GqnXJHGJiO6ArnO1hD0cFMJMzPr2n6q2xUM9tgrNw">why people respond so differently to emerging technologies</a>. Some studies suggest <a href="https://www.sciencedirect.com/science/article/abs/pii/S0749597818303388">consumers favour new tech</a>, a phenomenon called “algorithm appreciation”, while others show scepticism, or “algorithm aversion”. Our research points to perceptions of AI’s “magicalness” as a key factor shaping these reactions.</p>

<p>These insights pose a challenge for policymakers and educators. <a href="https://www.weforum.org/stories/2022/03/without-universal-ai-literacy-ai-will-fail-us/">Efforts to boost AI literacy</a> might unintentionally dampen people’s enthusiasm for using AI by making it seem less magical. This creates a tricky balance between helping people understand AI and keeping them open to its adoption. </p>

<p>To make the most of AI’s potential, businesses, educators and policymakers need to strike this balance. By understanding how perceptions of “magicalness” shape people’s openness to AI, we can help develop and deploy new AI-based products and services that take the way people view AI into account, and help them understand the benefits and risks of AI.</p>

<p>And ideally, this will happen without causing a loss of the awe that inspires many people to embrace this new technology.</p>
  </div>

    

  </div>
  
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Marginalia – A search engine that prioritizes non-commercial content (524 pts)]]></title>
            <link>https://marginalia-search.com/</link>
            <guid>42836405</guid>
            <pubDate>Mon, 27 Jan 2025 01:39:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marginalia-search.com/">https://marginalia-search.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42836405">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><i></i>Policies</p>
        <p><span>
        This website complies with the GDPR by not collecting any personal information,
        and with the EU Cookie Directive by not using cookies for any purpose other than
        to provide service functionality.
        </span>
        <span>
        Access logs containing IP-addresses are retained for up to 24 hours,
        anonymized logs with source addresses removed are sometimes kept longer
        for to help diagnosing bugs.
        </span>
    </p></div></div>]]></description>
        </item>
    </channel>
</rss>