<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 21 May 2025 20:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Collaborative Text Editing Without CRDTs or OT (114 pts)]]></title>
            <link>https://mattweidner.com/2025/05/21/text-without-crdts.html</link>
            <guid>44053560</guid>
            <pubDate>Wed, 21 May 2025 17:05:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mattweidner.com/2025/05/21/text-without-crdts.html">https://mattweidner.com/2025/05/21/text-without-crdts.html</a>, See on <a href="https://news.ycombinator.com/item?id=44053560">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    

    <p><i>
    Matthew Weidner |
    
    May 21st, 2025
    
    <br>
    <a href="https://mattweidner.com/">Home</a> | <a href="https://mattweidner.com/feed.xml">RSS Feed</a>
    <br>
    Keywords: text editing, server reconciliation, Articulated
    </i></p>

    <p>Collaborative text editing is arguably the hardest feature to implement in a collaborative app. Even if you use a central server and a fully general solution to optimistic local updates (<a href="https://mattweidner.com/2024/06/04/server-architectures.html#1-server-reconciliation">server reconciliation</a>), text editing in particular requires fancy algorithms - specifically, the <a href="https://mattweidner.com/2024/06/04/server-architectures.html#challenge-text-and-lists">core of a text-editing CRDT or OT</a>.</p>

<p>Or rather, that’s what I thought until recently. This blog post describes an alternative, straightforward approach to collaborative text editing, without Conflict-free Replicated Data Types (CRDTs) or Operational Transformation (OT). By making text editing flexible and easy to DIY, I hope that the approach will let you create rich collaborative apps that are challenging to build on top of a black-box CRDT/OT library.</p>

<p>This post builds off of my previous post, <a href="https://mattweidner.com/2024/06/04/server-architectures.html">Architectures for Central Server Collaboration</a>, though I’ll recap ideas as needed to keep it self-contained. In particular, I’ll generally assume that your collaborative app has a central server. A <a href="#decentralized-variants">later section</a> extends the approach to decentralized/server-optional collaboration, revealing surprising links to several text-editing CRDTs.</p>

<p>As usual for collaborative text editing, any technique in this post can also be applied to general collaborative lists: ingredients in a recipe, a powerpoint filmstrip, spreadsheet rows and columns, etc.</p>

<p><strong>Sources:</strong> I learned the main idea of this approach from a <a href="https://news.ycombinator.com/item?id=41100477">Hacker News comment</a> by <a href="https://x.com/wcools/">Wim Cools</a> from Thymer. It is also used by <a href="https://jazz.tools/docs/react/using-covalues/colists">Jazz’s CoLists</a>. I do not know of an existing public description of the approach - in particular, I have not found it in any paper on <a href="https://crdt.tech/papers.html">crdt.tech</a> - but given its simplicity, others have likely used the approach as well.
The extension to decentralized collaboration is based on <a href="https://arxiv.org/abs/1805.04263">OpSets: Sequential Specifications for Replicated Datatypes</a> by Martin Kleppmann, Victor B. F. Gomes, Dominic P. Mulligan, and Alastair R. Beresford (2018).</p>

<ul id="toc"></ul>
<!-- Filled in by script at end. -->

<h2 id="core-problem">Core Problem</h2>

<p><em>Recap of <a href="https://mattweidner.com/2024/06/04/server-architectures.html#challenge-text-and-lists">Architectures for Central Server Collaboration - Challenge: Text and Lists</a></em></p>

<p>Let’s start by focusing on one part of the collaborative text editing problem: submitting operations to the server. When a user types a word on their client device, we need to communicate this operation to the server, so that the server can update its own (authoritative) state.</p>

<p>It’s tempting to model the text as an array of characters and send operations to the server that operate on the array representation, like “insert ‘ the’ at index 17”. However, this fails when there are multiple concurrent editors, as shown in Figure 1:</p>

<p><a id="figure-1"></a>
<img src="https://mattweidner.com/assets/img/server-architectures/index_rebasing.png" alt="See caption"></p>
<p><i><b>Figure 1.</b> Bob submits the operation "insert ‘ the’ at index 17" to the central server. But before his edit arrives, the server applies Alice's concurrent operation "insert ‘ gray’ at index 3". So it no longer makes sense to apply Bob's operation at index 17; the server must "rebase" it to index 22.</i></p>

<p>The core problem we must solve is: <strong>What operations should clients send to the server, and how should the server interpret them, so that the server updates its own text in the “obvious” correct way?</strong></p>

<blockquote>
  <p>This “index rebasing” challenge is best known for real-time collaborative apps like Google Docs, but technically, it can also affect non-real-time apps—e.g., a web form that inserts items into a list. The problem can even appear in single-threaded local apps, which need to transform text/list indices for features like inline comments and edit histories.</p>
</blockquote>

<h2 id="issues-with-existing-solutions">Issues with Existing Solutions</h2>

<p>Existing solutions to this core problem fall into two camps, Conflict-free Replicated Data Types (CRDTs) and Operational Transformation (OT). Roughly:</p>

<ul>
  <li><a href="https://crdt.tech/">CRDTs</a> (2005+) assign an immutable ID (<a href="https://mattweidner.com/2022/02/10/collaborative-data-design.html#position-def">“position”</a>) to each character and sort these IDs using a mathematical total order - often a tree traversal over a special kind of tree.</li>
  <li><a href="https://en.wikipedia.org/wiki/Operational_transformation">OT</a> (1989+) directly “transforms” operations to account for concurrent edits. In the above example, the server’s OT subroutine would transform “insert ‘ the’ at index 17” against “insert ‘ gray’ at index 3”, yielding “insert ‘ the’ at index 22”.</li>
</ul>

<p>Both CRDT and OT algorithms are used in practice. OT is used by Google Docs; the <a href="https://docs.yjs.dev/">Yjs</a> CRDT library is used by numerous apps. I’ve personally spent several years thinking and writing about text-editing <a href="https://mattweidner.com/2022/02/10/collaborative-data-design.html#list-crdt">CRDTs</a> <a href="https://mattweidner.com/2022/10/21/basic-list-crdt.html">and</a> <a href="https://mattweidner.com/2023/04/13/position-strings.html">closely</a> <a href="https://mattweidner.com/2024/04/29/list-positions.html">related</a> algorithms. So why does this blog post introduce a different approach, and what makes it better?</p>

<p>The main issue with both CRDTs and OT is their <em>conceptual complexity</em>. Text-editing CRDTs’ total orders are subtle algorithms defined in academic papers, often challenging to read. OT algorithms must satisfy algebraic “transformation properties” that have quadratically many cases and are <a href="https://hal.inria.fr/inria-00071213/">frequently flawed</a> without formal verification.</p>

<p>Complicated algorithms lead to even more complicated implementations, and CRDT/OT implementations are notoriously difficult. Thus you often use them through libraries, implemented by experts, which you can’t customize without a similar level of expertise. Because collaboration is a full-stack concern, the libraries are also full-stack, taking over core parts of your application: they present as a networked black box that inputs operations and outputs state.</p>

<p>This monolithic, unmodifiable approach becomes a liability when your app requires features that the library author did not anticipate. For example, I would struggle to do any of the following with an existing text-editing CRDT or OT library:</p>

<ol>
  <li>Divide the state between disk and memory, only loading the necessary parts of a large document.</li>
  <li>Enforce sub-document permissions on the server, e.g., some users are only allowed to edit certain paragraphs or use specific formatting.</li>
  <li>Allow “suggested changes” in the style of Google Docs, either inline or next to the text. (I <a href="https://github.com/mweidner037/list-positions-demos/tree/master/suggested-changes">tried to implement this</a> with my own CRDT library, but got stuck because suggestions could migrate away from their target text - precisely because I had no control over the CRDT’s total order.)</li>
  <li>Store the text in a key-value representation that is easy to sync over an existing key-value store (e.g. Replicache), without merely storing the entire text as a blob or the entire operation history as an array.</li>
  <li>Support operations beyond insert/delete: moving text, document tree manipulations, paragraph splitting/merging, etc.</li>
</ol>

<p>In contrast, the approach described in this blog post is dead simple. I hope that you will soon understand it well enough to do-it-yourself if you desire. Once that’s done, you can modify the internals and add features at will.</p>

<h2 id="the-approach">The Approach</h2>

<h2 id="main-idea">Main Idea</h2>

<p>The main idea of our approach is straightforward:</p>

<ul>
  <li>Label each text character with a globally unique ID (e.g., a UUID), so that we can refer to it in a consistent way across time - instead of using an array index that changes constantly. That is, our core data structure has type <code>Array&lt;{ id: ID; char: string }&gt;</code>.</li>
  <li>Clients send the server “insert after” operations that reference an existing ID. E.g., in <a href="#figure-1">Figure 1</a> above, Bob’s operation would be “insert ‘ the’ after <code>f1bdb70a</code>”, where <code>f1bdb70a</code> is the ID of ‘n’ in ‘on’.</li>
  <li>The server interprets “insert after” operations literally: it looks up the target ID and inserts the new characters immediately after it.</li>
</ul>

<p>Verify for yourself that this approach would handle both of Figure 1’s edits in the “obvious” correct way.</p>

<h2 id="some-corrections">Some Corrections</h2>

<p>You may have noticed two small issues with the above description. Luckily, they are both easy to correct.</p>

<p>First, when Bob sends his operation to the server, he also needs to specify the new elements’ IDs: “insert ‘ the’ after <code>f1bdb70a</code> with ids […]”. In other words, he must tell the server what pairs <code>{ id, char }</code> to add to its internal list, instead of just the new characters. (Having Bob generate the IDs, instead of waiting for the server to assign them, lets him reference those IDs in subsequent “insert after” operations before receiving a response to his first operation.)</p>

<p>Second, it’s possible for Bob to send an operation like “insert ‘foo’ after <code>26085702</code>”, but before his operation reaches the server, another user concurrently deletes the character with ID <code>26085702</code>. If the server literally deletes its pair <code>{ id: "26085702", char: "x" }</code> in response to the concurrent operation, then it won’t know where to insert Bob’s text anymore. The server can work around this by storing IDs in its internal list even after the corresponding characters are deleted: the server’s state becomes a list</p>

<div><pre><code><span>Array</span><span>&lt;</span><span>{</span> <span>id</span><span>:</span> <span>ID</span><span>;</span> <span>char</span><span>?:</span> <span>string</span><span>;</span> <span>isDeleted</span><span>:</span> <span>boolean</span> <span>}</span><span>&gt;</span><span>.</span>
</code></pre></div>

<p>Of course, deleted entries don’t show up in the user-visible text.</p>

<p>In summary, our corrected approach for client -&gt; server communication is as follows:</p>

<div><pre><code>Client &amp; server text state: Each stores a list of characters labeled by IDs, including deleted IDs.
- Type: `Array&lt;{ id: ID; char?: string; isDeleted: boolean }&gt;`
- Corresponding text: `list.filter(elt =&gt; !elt.isDeleted).map(elt =&gt; elt.char).join('')`

Typing a character `char`:
1. Client looks up the ID of the character just before the insertion point, `before`.
2. Client generates a globally unique ID for the new character (e.g., a UUID): `id`.
3. Client sends the server the operation: "insert ${char} after ${before} with id ${id}".
4. Server applies this operation to its own state literally:
  a. Looks up `before` in its own list, including deleted entries.
  b. Inserts `{ id, char, isDeleted: false }` immediately after `before`'s entry in the list.

Deleting a character:
1. Client looks up the ID of the deleted character, `id`.
2. Client sends the server the operation: "delete the entry with id ${id}".
3. Server looks up the entry for `id` and sets `entry.isDeleted = true` if not already.
</code></pre></div>

<p>You probably still have practical concerns with the above approach: e.g., it’s inefficient to store a UUID for every character. I’ll discuss optimizations <a href="#helper-library-articulated">later</a>.</p>

<h2 id="client-side">Client Side</h2>

<p><em>Recap of <a href="https://mattweidner.com/2024/06/04/server-architectures.html#1-server-reconciliation">Architectures for Central Server Collaboration - Server Reconciliation</a></em></p>

<p>The approach described so far lets us send operations from clients to the server, updating the server’s state. We managed to solve the <a href="#core-problem">core problem</a> in a straightforward way, without combing through any CRDT or OT papers.</p>

<p>For true Google-Docs style collaborative text editing, we also want to let users see the effects of their own operations immediately, without waiting for a response from the server. That is, clients should be allowed to perform optimistic local updates.</p>

<p>Optimistic local updates cause trouble when:</p>

<ul>
  <li>A client possesses pending local operations - operations that it performed locally but were not yet acknowledged by the server.</li>
  <li>Before receiving an acknowledgment for those operations, the client receives a new remote operation from the server, necessarily concurrent to its pending local operations.</li>
</ul>

<p><a id="figure-2"></a>
<img src="https://mattweidner.com/assets/img/text-without-crdts/text_pending_local_operation.png" alt="See caption"></p>
<p><i><b>Figure 2.</b> Bob submits the operation "insert ‘ the’ after &lt;n's ID&gt;" to the central server. But before the server acknowledges his operation, he receives the remote operation "insert ‘ gray’ after &lt;e's ID&gt;". What state should Bob's client display, incorporating both the remote operation and Bob's pending local operation?</i></p>

<p>At this point, you might say: We have concurrent operations, received in different orders by the client and the server, who must ultimately end up in the same state. Doesn’t that mean we need a CRDT?</p>

<p>Luckily, the answer is no! There is a fully general solution to optimistic local updates, <a href="https://mattweidner.com/2024/06/04/server-architectures.html#1-server-reconciliation">server reconciliation</a>, which is in particular compatible with our “insert after” operations. Briefly, the way you update a client in response to a new remote operation <code>R</code> is:</p>

<ol>
  <li>Undo all pending local operations. This rewinds the state to the client’s previous view of the server’s state.</li>
  <li>Apply the remote operation(s). This brings the client up-to-date with the server’s state.</li>
  <li>Redo any pending local operations that are still pending, i.e., they were not acknowledged as part of the remote batch.</li>
</ol>

<p><img src="https://mattweidner.com/assets/img/server-architectures/server_reconciliation.png" alt="Starting in optimistic local state S+L1+L2+L3, Step 1 leads to state S, Step 2 leads to state S+R, and Step 3 leads to state S+R+L1+L2+L3."></p>

<p><i>The Server Reconciliation way to process a remote operation <code>R</code> in the presence of pending local operations <code>L1, L2, L3</code>.</i></p>

<!-- Step 1 could involve literal undo commands, using a local stack that records how to undo each pending local mutation. Or, you could store the app state as a persistent data structure and directly restore the state before the first pending local mutation. Or, the server could tell you the exact new state to use (= its own latest state), which you use directly as the result of step 2.

Either way, server reconciliation completes our straightforward approach to collaborative text editing. -->

<blockquote>
  <p>There is another strategy that is even simpler than server reconciliation: forbid clients from processing remote operations whenever they possess pending local operations. I learned of this strategy from <a href="https://docs.powersync.com/architecture/consistency">PowerSync</a>.</p>

  <p>For example, in <a href="#figure-2">Figure 2</a>, Bob’s client would ignore the first message from the server, instead waiting for the server to process Bob’s message and send the resulting state. Once it receives that state, Bob’s client can directly overwrite its own state. Unless Bob has performed even more operations in the meantime - then his client needs to ignore the server’s second message and wait for a third, etc.</p>

  <p>Note that this strategy can led to unbounded delays if Bob types continuously or has high network latency, so it is not as “real-time” as server reconciliation.</p>
</blockquote>

<h2 id="difference-from-crdts">Difference from CRDTs</h2>

<p>You may object that the above approach sounds a lot like a CRDT. It does share some features: in particular, its assignment of an ID to each character and its use of <code>isDeleted</code> markers (tombstones).</p>

<p>The difference is that our approach handles order in a straightforward and flexible way: clients tell the server to insert X after Y and it does exactly that, or whatever else you program it to do. This contrasts with text-editing CRDTs, in which IDs are ordered for you by a fancy algorithm. That ordering algorithm is what differs between the numerous text-editing CRDTs, and it’s the complicated part of any CRDT paper; we get to avoid it entirely.</p>

<h2 id="discussion">Discussion</h2>

<p>The previous section described the whole approach in what I hope is enough detail to start implementing it yourself (though first check out <a href="#helper-library-articulated">Articulated</a> below). Let’s now discuss consequences and extensions of the approach.</p>

<h2 id="concurrent-insertions">Concurrent Insertions</h2>

<p>With any collaborative text-editing algorithm, the most interesting theoretical question is: What happens when multiple users type in the same place concurrently?</p>

<p>For example, staring from the text “My name is”, suppose Charlie types “ Charlie”, while concurrently, Dave types “ Dave”. If Charlie’s operation reaches the server first, what is the final text?</p>

<p>Let’s check:</p>

<ul>
  <li>Charlie’s operation says “insert ‘ Charlie’ after &lt;ID of ‘s’ in ‘is’&gt;”. The server processes this literally, giving the text “My name is Charlie”.</li>
  <li>Dave’s operation likewise says “insert ‘ Dave’ after &lt;ID of ‘s’ in ‘is’&gt;”. The server again processes this literally - inserting after the ‘s’ in ‘is’, irrespective of the concurrent text appearing afterwards - giving the text “My name is Dave Charlie”.</li>
</ul>

<p>In summary, concurrent insertions at the same place end up in the <em>reverse</em> of the order that the server received their operations. More generally, even without concurrency, insert-after operations with the same target ID end up in reverse order. For example, if Dave typed his name backwards as (e, left arrow, v, left arrow, a, left arrow, D), then each operation would be “insert after &lt;ID of ‘s’ in ‘is’&gt;”, and the resulting text would be the reverse of the server’s receipt order: Dave. (This might remind you of a popular CRDT. I’ll talk about that <a href="#decentralized-variants">later</a>.)</p>

<p>Observe that the concurrently-inserted words “ Charlie” and “ Dave” ended up one after the other, instead of becoming interleaved character-by-character (unlike <a href="https://doi.org/10.1145/3301419.3323972">some text-editing CRDTs</a>). That would work even if Charlie and Dave sent each character as a separate operation. Indeed, Dave inserts the ‘a’ in Dave after the ‘D’ (i.e., the insert-after operation references D’s ID), ‘v’ after ‘a’, etc.; so when the server processes these individual operations, it updates its state as</p>

<div><pre><code>"My name is D Charlie" -&gt; "My name is Da Charlie"
-&gt; "My name is Dav Charlie" -&gt; "My name is Dave Charlie"
</code></pre></div>

<p>in spite of the unexpected “ Charlie” afterwards.</p>

<p>The same cannot be said for backwards (right-to-left) insertions: if Dave and Charlie both typed their names with copious use of left arrow, and the server received those operations in an interleaved order, then the resulting text would also be interleaved. In practice, this could only happen if Charlie and Dave were both online simultaneously (so that their messages could be interleaved) but stubbornly ignored each other’s in-progress edits.</p>

<h2 id="flexible-operations">Flexible Operations</h2>

<p>So far, the only text-editing operations I’ve described are “insert after” and “delete”, which the server applies literally. However, the approach supports many more possible operations. In fact, thanks to <a href="#client-side">our use of server reconciliation</a>, the server has the flexibility to do essentially anything in response to a client operation - clients will eventually end up in the same state regardless. This contrasts with CRDT and OT algorithms, which only allow operations that satisfy strict algebraic rules.</p>

<p>For example, consider the concurrent insertion example from the previous section. The final result, “My name is Dave Charlie”, isn’t very reasonable, even though it satisfies a <a href="https://www.cs.ox.ac.uk/people/hongseok.yang/paper/podc16-full.pdf">mathematical specification</a> for collaborative text-editing. A fancy server could do something more intelligent for insertions like Dave’s that are at the same place as a previously-received concurrent insertion. For example:</p>

<ol>
  <li>Ignore any such operation (treat it as a no-op).</li>
  <li>Add the IDs to the internal list, but mark them as deleted immediately. (This is a still no-op from the users’ perspective, but it allows the server to process future operations from Dave that reference his earlier IDs.)</li>
  <li>Insert the text, but apply special formatting to both words to flag them for review.</li>
  <li>Convert Dave’s edits to a “suggestion” displayed alongside the main text.</li>
  <li>Ask an LLM how to best fix the text. (Be warned that Dave’s client may have trouble rebasing any further optimistic operations on top of the resulting state.)</li>
</ol>

<p>Clients can also send operations with fancier semantics than “insert after” to better capture user intent - thus increasing the odds that the server’s eventual state is reasonable in spite of concurrent edits. A simple example is “insert before”, the reversed version of “insert after”. E.g., if a user creates a heading above a paragraph, their client could “insert before” the paragraph’s first character, to prevent the header from ending up in the middle of an unrelated addition to the previous paragraph.</p>

<p>Another example is a “fix typo” operation that adds a character to a word only if that word still exists and hasn’t already been fixed. E.g., the client tells the server: “insert ‘u’ after the ‘o’ in ‘color’ that has ID X, but only if the surrounding word is still ‘color’”. That way, if another user deletes ‘color’ before the fix-typo operation reaches the server, you don’t end up with a ‘u’ in the middle of nowhere. (This example avoids an issue brought up by <a href="https://www.moment.dev/blog/lies-i-was-told-pt-1">Alex Clemmer</a>).</p>

<p>You can even define operations whose insertion positions change once they reach the server. E.g., the server could handle concurrent insertions at the same position by reordering them to be alphabetical. Or, if you add “move” operations for drag-and-drop, then the server can choose to process “insert after” operations within the moved text in the obvious way - insert them within the moved text instead of at its original location. This contrasts with text-editing CRDTs and my own CRDT-ish libraries (<a href="https://mattweidner.com/2023/04/13/position-strings.html">position-strings</a> and <a href="https://mattweidner.com/2024/04/29/list-positions.html">list-positions</a>), which fix each character’s position in a global total order as soon as the user types it.</p>

<blockquote>
  <p>Some of these flexible operations can technically be implemented on top of a CRDT, by having the server initiate its own operations after a client operation (e.g., apply “delete” operations to some text that it wants to ignore). However, I don’t know of CRDT implementations that support “insert before” operations, un-deleting IDs, or changing where an ID ends up in the list.</p>
</blockquote>

<h2 id="formatting-rich-text">Formatting (Rich Text)</h2>

<p>Rich text enhances plain text with inline formatting (bold, font size, hyperlinks, …), among other features. To handle rich text in our approach, when a user formats a range of text, we of course want to translate the ends of that range into character IDs instead of indices: “apply bold formatting from ID X to ID Y”. (Or perhaps: “apply bold formatting from ID X inclusive to ID Y exclusive”, so that concurrent insertions at the end of the range are also bolded.)</p>

<p>When used alongside a rich-text editor such as ProseMirror, the server can apply such operations literally: look up the current array indices of X and Y, and tell the local ProseMirror state to bold that range of text. ProseMirror will take care of remembering the bold span so that, when the server later receives an insertion within the span, it knows to bold that text too. (Unless the server decides to otherwise, e.g., in response to an operation “insert ‘…’ after ID Z with bold set to false”.)</p>

<p>I believe this simple extension to our approach takes care of the tricky conflict-resolution parts of collaborative rich-text formatting. However, I still recommend reading the <a href="https://www.inkandswitch.com/peritext/">Peritext essay</a> for insight into the semantics of collaborative rich-text - what operations clients should send to the server, and how the server should process them.</p>

<h2 id="decentralized-variants">Decentralized Variants</h2>

<p><em>More info in <a href="https://mattweidner.com/2024/06/04/server-architectures.html#appendix-from-centralized-to-decentralized">Architectures for Central Server Collaboration - Appendix: From Centralized to Decentralized</a></em></p>

<p>I’ve so far assumed that your app has a central server, which assigns a total order to operations (namely, the order that the server receives them) and updates its authoritative state in response to those operations.</p>

<p>If you don’t have a central server or your app is server-optional, you can instead assign an eventual total order to operations in a <em>decentralized</em> way. For example, order operations using <a href="https://mattweidner.com/2023/09/26/crdt-survey-3.html#lww-lamport-timestamps">Lamport timestamps</a>. Then treat “the result of processing the operations I’ve received so far in order” as the authoritative state on each client. Our approach’s per-character IDs and “insert after” operations work equally well with this decentralized, “non”-server reconciliation.</p>

<p>Technically, the resulting algorithm is a text-editing CRDT: it’s a decentralized, eventually consistent algorithm for collaborative text editing. I hope that it is easier to understand and implement than a typical text-editing CRDT - it involved no trees or mathematical proofs - and the above remarks on <a href="#flexible-operations">Flexible Operations</a> and <a href="#formatting-rich-text">Formatting</a> still hold in the decentralized setting.</p>

<p>Nonetheless, you might ask: if “non”-server reconciliation plus our “insert after” operations yields a text-editing CRDT, which CRDT is it? The answer is:</p>

<ul>
  <li>If you order operations using Lamport timestamps, the resulting list order is equivalent to RGA / Causal Trees. (RGA’s sibling sort - reverse Lamport timestamp order - corresponds exactly to the reverse-order behavior I described <a href="#concurrent-insertions">earlier</a>.)</li>
  <li>If you order operations using Lamport timestamps and add formatting operations like above, the resulting behavior is quite similar to <a href="https://www.inkandswitch.com/peritext/">Peritext</a>. (The Lamport timestamp order on formatting operations corresponds to Peritext’s Lamport-timestamp-ordered stack of formatting spans.)</li>
  <li>If you order operations using a topological sort - e.g., append them to an RGA list CRDT and use its list order - the resulting list order is equivalent to <a href="https://mattweidner.com/2022/10/21/basic-list-crdt.html">Fugue</a>. (The topological sort’s non-interleaving property corresponds to Fugue’s non-interleaving of backwards insertions.)</li>
</ul>

<blockquote>
  <p>I have not written out a proof of these claims in detail, but I’m happy to discuss my reasoning if you <a href="https://mattweidner.com/">contact me</a>.</p>
</blockquote>

<h2 id="helper-library-articulated">Helper Library: Articulated</h2>

<p>Recall that each device’s state in our approach is a list</p>

<div><pre><code><span>Array</span><span>&lt;</span><span>{</span> <span>id</span><span>:</span> <span>ID</span><span>;</span> <span>char</span><span>?:</span> <span>string</span><span>;</span> <span>isDeleted</span><span>:</span> <span>boolean</span> <span>}</span><span>&gt;</span><span>;</span>
</code></pre></div>

<p>In practice, you often want to store the actual text elsewhere - e.g., as a ProseMirror state - so our approach really just needs a list</p>

<div><pre><code><span>Array</span><span>&lt;</span><span>{</span> <span>id</span><span>:</span> <span>ID</span><span>;</span> <span>isDeleted</span><span>:</span> <span>boolean</span> <span>}</span><span>&gt;</span><span>;</span>
</code></pre></div>

<p>There are a few main tasks that you’ll perform on this list:</p>

<ol>
  <li>Convert between IDs and their current array indices, so that you can talk to the text-editing UI (e.g. ProseMirror).</li>
  <li>Insert a new ID after a specified ID.</li>
  <li>Mark an ID as deleted.</li>
  <li>Convert the state to and from a serialized form for storage.</li>
</ol>

<p>A literal array is not great at any of these tasks. Tasks 1-3 take linear time, and the array’s memory and storage space are large - an entire object and UUID per character!</p>

<p><a href="https://github.com/mweidner037/articulated/">Articulated</a> is a small npm library I made to help out. Its <code>IdList</code> data structure provides the same functionality as the above array, but with optimizations similar to those in popular text-editing CRDT libraries:</p>

<ul>
  <li>IDs have the form <code>{ bunchId, counter }</code>, where <code>bunchId</code> is a UUID that can be shared between a “bunch” of IDs with varying <code>counter</code>. When IDs in a bunch appear alongside each other - e.g., in the common case of left-to-right insertions - <code>IdList</code> stores them as a single object in memory and in the serialized state.</li>
  <li>The core data structure is a B+Tree instead of an array, allowing <code>log</code> or <code>log^2</code> time method calls.</li>
</ul>

<p>As an added feature, IdList is a <a href="https://en.wikipedia.org/wiki/Persistent_data_structure">persistent</a> data structure. This is great for server reconciliation: each client can cheaply store a copy of the latest state they received from the server alongside their optimistic state, making it trivial to rollback to the server’s last state when they receive a remote operation.</p>

<p>You can check out the <a href="https://github.com/mweidner037/articulated/#articulated">docs</a> and (very preliminary) <a href="https://github.com/mweidner037/articulated-demos">demos</a> to learn more. Or, read through the code for <a href="https://github.com/mweidner037/articulated/blob/master/test/id_list_simple.ts">IdListSimple</a> - it’s a simple, &lt; 300 SLOC implementation of IdList that omits its optimizations and persistence but is otherwise functionally identical (verified by fuzz tests).</p>

<p>I hope that, within the context of a server reconciliation architecture, Articulated can serve a similar purpose to an optimized CRDT library, but with the flexibility and other advantages described in this blog post.</p>




        
    <!-- Footer -->
    <hr>
    <p>
    <a href="https://mattweidner.com/">Home</a>
    • Matthew Weidner
    • Common Curriculum / CMU PhD student
    • mweidner037 [at] gmail.com
    • <a href="https://twitter.com/MatthewWeidner3">@MatthewWeidner3</a>
    • <a href="https://bsky.app/profile/mweidner.bsky.social">@mweidner.bsky.social</a>
    • <a href="https://www.linkedin.com/in/matthew-weidner-99715412a">LinkedIn</a>
    • <a href="https://github.com/mweidner037/">GitHub</a>
    </p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI to buy AI startup from Jony Ive (409 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2025-05-21/openai-to-buy-apple-veteran-jony-ive-s-ai-device-startup-in-6-5-billion-deal</link>
            <guid>44053518</guid>
            <pubDate>Wed, 21 May 2025 17:01:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2025-05-21/openai-to-buy-apple-veteran-jony-ive-s-ai-device-startup-in-6-5-billion-deal">https://www.bloomberg.com/news/articles/2025-05-21/openai-to-buy-apple-veteran-jony-ive-s-ai-device-startup-in-6-5-billion-deal</a>, See on <a href="https://news.ycombinator.com/item?id=44053518">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/news/articles/2025-05-21/openai-to-buy-apple-veteran-jony-ive-s-ai-device-startup-in-6-5-billion-deal: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[By Default, Signal Doesn't Recall (235 pts)]]></title>
            <link>https://signal.org/blog/signal-doesnt-recall/</link>
            <guid>44053364</guid>
            <pubDate>Wed, 21 May 2025 16:46:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://signal.org/blog/signal-doesnt-recall/">https://signal.org/blog/signal-doesnt-recall/</a>, See on <a href="https://news.ycombinator.com/item?id=44053364">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img src="https://signal.org/blog/images/recall-header.png" alt="A screenshot of a Microsoft Windows desktop. Microsoft Paint and Minesweeper are visible behind a black rectangular window that is empty except for graffiti-style text that says &quot;SIGNAL WAS HERE&quot;."></p><p>Signal Desktop now includes support for a new “Screen security” setting that is designed to help prevent your own computer from capturing screenshots of your Signal chats on Windows. This setting is automatically enabled by default in Signal Desktop on Windows 11.</p><p>If you’re wondering why we’re only implementing this on Windows right now, it’s because the purpose of this setting is to protect your Signal messages from <a href="https://support.microsoft.com/en-us/windows/retrace-your-steps-with-recall-aa03f8a0-a78b-4b3e-b0a1-2eb8ac48701c">Microsoft Recall</a>.</p><p>First announced on May 20, 2024, Microsoft Recall takes screenshots of your apps every few seconds as you use your computer and then stores them in an easily searchable database. In Microsoft’s <a href="https://blogs.windows.com/windowsexperience/2024/06/07/update-on-the-recall-preview-feature-for-copilot-pcs/">own words</a>, its goal is to act as a sort of “photographic memory” for everything that you do on your computer. The words that other people chose to describe Recall upon its debut were decidedly less positive.<sup id="fnref:1"><a href="#fn:1" rel="footnote" role="doc-noteref">1</a></sup> After an intense <a href="https://www.wired.com/story/microsoft-recall-off-default-security-concerns/">security backlash</a> and significant public outcry, Microsoft quickly pulled the feature.</p><p>It’s a one-year anniversary that nobody wants to celebrate, but Recall <a href="https://arstechnica.com/security/2025/04/microsoft-is-putting-privacy-endangering-recall-back-into-windows-11/">is back</a> and Signal is ready.</p><p>Although Microsoft made several adjustments over the past twelve months in response to critical feedback, the revamped version of Recall still places any content that’s displayed within privacy-preserving apps like Signal at risk. As a result, we are enabling an extra layer of protection by default on Windows 11 in order to help maintain the security of Signal Desktop on that platform even though it introduces some usability trade-offs. Microsoft has simply given us no other option.</p><h2 id="fade-to-black">Fade to Black</h2><p>If you attempt to take a screenshot of Signal Desktop when screen security is enabled, nothing will appear. This limitation can be frustrating, but it might look familiar to you if you’ve ever had the audacity to try and take a screenshot of a movie or TV show on Windows. According to Microsoft’s <a href="https://learn.microsoft.com/en-us/windows/client-management/manage-recall#information-for-developers">official developer documentation</a>, setting the correct <a href="https://en.wikipedia.org/wiki/Digital_rights_management">Digital Rights Management</a> (DRM) flag on the application window will ensure that “content won’t show up in Recall or any other screenshot application.” So that’s exactly what Signal Desktop is now doing on Windows 11 by default.</p><p><img src="https://signal.org/blog/images/recall-drm-screenplay.jpg" alt="A stylized close-up crop of a movie screenplay that says &quot;INT. COPILOT+ PC MANUFACTURING FACILITY - NIGHT - METALLIC SHELVES in endless rows stretch into the darkness. Two figures crouch in the shadows. ALICE: DRM technology has been consistently used against us. BOB: It won't be the first time we've turned the tables. ALICE: My life has always felt like a movie.&quot;"></p><p>Apps like Signal have essentially no control over what content Recall is able to capture, and implementing “DRM” that works for you (not against you) is the best choice that we had. It’s like a scene in a movie where the villain has switched sides, and you can’t screenshot this one by default either.</p><h2 id="warning-shots">Warning Shots</h2><p>Microsoft has launched Recall without granular settings for app developers that would enable Signal to easily protect privacy, which is a glaring omission that limits our choices. Signal is using the tools that are available to us even though we recognize that there are many legitimate use cases where someone might need to take a screenshot. For example, some accessibility software (such as screen readers or magnification tools for people who are visually impaired) may not function correctly otherwise.</p><p>To help mitigate this issue, we made the setting easy to disable <em>(Signal Settings → Privacy → Screen security)</em>, but it’s difficult to accidentally disable. Turning off “Screen security” in Signal Desktop on Windows 11 will always display a warning and require confirmation in order to continue.</p><p><img src="https://signal.org/blog/images/recall-warning.png" alt="A screenshot of a warning dialog box that says &quot;Disable screen security? If disabled, this may allow Microsoft Windows to capture screenshots of Signal and use them for features that may not be private.&quot;"></p><p>This setting is local to your computer and doesn’t apply to screenshots on other devices. If you are communicating with someone who uses a screen reader on macOS or Linux, for example, keeping screen security enabled on your side won’t prevent them from taking screenshots or adversely affect any accessibility software they may be using.</p><p>We hope that the AI teams building systems like Recall will think through these implications more carefully in the future. Apps like Signal shouldn’t have to implement “one weird trick” in order to maintain the privacy and integrity of their services without proper developer tools. People who care about privacy shouldn’t be forced to sacrifice accessibility upon the altar of AI aspirations either.</p><h2 id="future-recallections">Future Recallections</h2><p>“Take a screenshot every few seconds” legitimately sounds like a suggestion from a low-parameter LLM that was given a prompt like “How do I add an arbitrary AI feature to my operating system as quickly as possible in order to make investors happy?” — but more sophisticated threats are on the horizon.</p><p>The integration of AI agents with pervasive permissions, questionable security hygiene, and an insatiable hunger for data has the potential to break <a href="https://techcrunch.com/2025/03/07/signal-president-meredith-whittaker-calls-out-agentic-ai-as-having-profound-security-and-privacy-issues/">the blood-brain barrier</a> between applications and operating systems. This poses a significant threat to Signal, and to every privacy-preserving application in general.</p><p>People everywhere rely on Signal to protect their communication, including human rights workers, governments, board rooms, militaries, and millions of individuals around the world for whom privacy is an existential matter. Apps like Signal must maintain their ability to prioritize security by default in a way that can be <a href="https://github.com/signalapp">publicly validated</a>. It’s imperative that privacy-preserving apps retain the ability to uphold these promises on every platform, including Microsoft Windows.</p><p>In order to do this, the ecosystem needs to do its part too. Operating system vendors, especially those who are shipping AI agents, need to ensure that the developers of apps like Signal always have the necessary tools and options at their disposal to reject granting OS-level AI systems access to any sensitive information within their apps.<sup id="fnref:2"><a href="#fn:2" rel="footnote" role="doc-noteref">2</a></sup></p><p><a href="https://www.cbsnews.com/news/ceo-zuckerberg-facebooks-5-core-values/">“Move fast and break things”</a> is going to be a tough habit for the tech industry to, well, break. But <a href="https://en.wikipedia.org/wiki/Minimum_viable_product">MVP</a> shouldn’t also stand for “Minimum Viable Precautions.” It’s ultimately up to companies like Microsoft to ensure that their platforms remain a suitable foundation for privacy-preserving applications like Signal. If that ever stops being the case, we’ll have to stop supporting those platforms.</p><p>Messaging apps are a window into your entire life. They’re where we share our favorite memories, fall in love, complain, smile, cry, and express who we really are. Given this reality, private messaging apps like Signal deserve to be treated with at least the same level of caution that’s afforded to a web browser’s private or incognito browsing window — which Microsoft has <a href="https://support.microsoft.com/en-us/windows/filtering-apps-websites-and-sensitive-information-in-recall-a4c28bee-e200-4a4a-b60d-c0522b404a5b">already excluded from Recall by default</a>.</p><p>Screen security for Signal Desktop on Microsoft Windows is rolling out now, and enabled by default on Windows 11. We’d like to express our sincere appreciation to the Signal community for helping us test this release during the beta period. We couldn’t do this work without your support.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Introducing the Llama Startup Program (113 pts)]]></title>
            <link>https://ai.meta.com/blog/llama-startup-program/?_fb_noscript=1</link>
            <guid>44052984</guid>
            <pubDate>Wed, 21 May 2025 16:10:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.meta.com/blog/llama-startup-program/?_fb_noscript=1">https://ai.meta.com/blog/llama-startup-program/?_fb_noscript=1</a>, See on <a href="https://news.ycombinator.com/item?id=44052984">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>We’re excited to announce the <a href="https://www.llama.com/programs/startups/" target="_blank" data-lnfb-mode="ie"><u>Llama Startup Program</u></a>, a new initiative to empower early-stage startups to innovate and build generative AI applications with <a href="https://www.llama.com/" target="_blank" data-lnfb-mode="ie"><u>Llama</u></a>. Members of the Llama Startup Program will receive resources and support from Llama experts along their journey, including help getting started with Llama and resources necessary to succeed and thrive in a competitive and fast-moving landscape.</p><h2>Why we’re launching the Llama Startup Program</h2><div><p>Early-stage startups are agile and creative, making them uniquely positioned to accelerate high-impact innovation with Llama. In a recent <a href="https://about.fb.com/news/2025/05/new-study-shows-open-source-ai-catalyst-economic-growth/" target="_blank" data-lnfb-mode="ie"><u>Linux Foundation study</u></a><a href="https://about.fb.com/news/2025/05/new-study-shows-open-source-ai-catalyst-economic-growth/" target="_blank" data-lnfb-mode="ie">,</a> 94% of organizations say they’ve already adopted AI tools and models, and of those, 89% are using some form of open source technology—such as Llama—in their AI infrastructure.</p><p>We want to give our Llama Startup Program members a competitive edge by offering direct support from the Llama team and may help to fund their use of Llama models. We hope this support accelerates their development process and enhances their ability to deliver innovative solutions. We’ve seen how our <a href="https://about.fb.com/news/2025/04/llama-impact-grant-recipients/" target="_blank" data-lnfb-mode="ie"><u>Llama Impact Grants</u></a> have helped recipients innovate and deliver economic opportunity, and we believe that supporting developers through the Llama Startup Program will help early-stage startups take flight.</p></div></div><div><h2>What are the benefits of being part of the Llama Startup Program?</h2><div><p>During the initial phase of the Llama Startup Program, we're reimbursing the cost of using Llama through hosted APIs via cloud inference providers. Members may receive up to $6,000 USD per month for up to six months to help them offset the costs of building and enhancing their generative AI solutions. This funding enables startups to experiment, innovate, and scale their solutions without the immediate financial burden, enabling them to focus on what truly matters: creating impactful technologies.</p><p>Members of the program will receive hands-on technical support from the Llama team. Our experts will work closely with them to get started and explore advanced use cases of Llama that could benefit their startups. This direct access to technical expertise ensures that developers can effectively leverage Llama’s capabilities, optimize solutions, and overcome technical challenges they may encounter as they start building.</p></div><h2>Who should apply?</h2><div><p>The Llama Startup Program is an exciting opportunity for early-stage startups in the United States that are ready to innovate with generative AI. We invite startups that are incorporated, have raised less than $10 million USD in funding, and have at least one developer on staff to apply. The Llama Startup Program is ideal for those building generative AI applications across a variety of industries, including technology and software, financial services, healthcare and life sciences, telecommunications, and retail and eCommerce. Join us for the opportunity to receive cloud reimbursements of up to $6,000 USD per month for up to six months, technical resources, and a vibrant community—all while contributing valuable feedback to enhance the Llama experience. If your startup is ready to grow and make a meaningful impact, we encourage you to apply and be part of this transformative program.</p><p>Applications for the initial cohort close on May 30, 2025 at 6:00 pm PT.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discord Unveiled: A Comprehensive Dataset of Public Communication (2015-2024) (125 pts)]]></title>
            <link>https://arxiv.org/abs/2502.00627</link>
            <guid>44052041</guid>
            <pubDate>Wed, 21 May 2025 14:45:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2502.00627">https://arxiv.org/abs/2502.00627</a>, See on <a href="https://news.ycombinator.com/item?id=44052041">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Aquino,+Y" rel="nofollow">Yan Aquino</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bento,+P" rel="nofollow">Pedro Bento</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Buzelin,+A" rel="nofollow">Arthur Buzelin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dayrell,+L" rel="nofollow">Lucas Dayrell</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Malaquias,+S" rel="nofollow">Samira Malaquias</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Santana,+C" rel="nofollow">Caio Santana</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Estanislau,+V" rel="nofollow">Victoria Estanislau</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dutenhefner,+P" rel="nofollow">Pedro Dutenhefner</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Evangelista,+G+H+G" rel="nofollow">Guilherme H. G. Evangelista</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Porf%C3%ADrio,+L+G" rel="nofollow">Luisa G. Porfírio</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Grossi,+C+S" rel="nofollow">Caio Souza Grossi</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rigueira,+P+B" rel="nofollow">Pedro B. Rigueira</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Almeida,+V" rel="nofollow">Virgilio Almeida</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Pappa,+G+L" rel="nofollow">Gisele L. Pappa</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Meira,+W" rel="nofollow">Wagner Meira Jr</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2502.00627">View PDF</a>
    <a href="https://arxiv.org/html/2502.00627v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Discord has evolved from a gaming-focused communication tool into a versatile platform supporting diverse online communities. Despite its large user base and active public servers, academic research on Discord remains limited due to data accessibility challenges. This paper introduces Discord Unveiled: A Comprehensive Dataset of Public Communication (2015-2024), the most extensive Discord public server's data to date. The dataset comprises over 2.05 billion messages from 4.74 million users across 3,167 public servers, representing approximately 10% of servers listed in Discord's Discovery feature. Spanning from Discord's launch in 2015 to the end of 2024, it offers a robust temporal and thematic framework for analyzing decentralized moderation, community governance, information dissemination, and social dynamics. Data was collected through Discord's public API, adhering to ethical guidelines and privacy standards via anonymization techniques. Organized into structured JSON files, the dataset facilitates seamless integration with computational social science methodologies. Preliminary analyses reveal significant trends in user engagement, bot utilization, and linguistic diversity, with English predominating alongside substantial representations of Spanish, French, and Portuguese. Additionally, prevalent community themes such as social, art, music, and memes highlight Discord's expansion beyond its gaming origins.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Yan Aquino Amorim [<a href="https://arxiv.org/show-email/debf74d4/2502.00627" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Sun, 2 Feb 2025 02:17:14 UTC (1,433 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Animated Factorization (197 pts)]]></title>
            <link>http://www.datapointed.net/visualizations/math/factorization/animated-diagrams/</link>
            <guid>44051958</guid>
            <pubDate>Wed, 21 May 2025 14:39:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.datapointed.net/visualizations/math/factorization/animated-diagrams/">http://www.datapointed.net/visualizations/math/factorization/animated-diagrams/</a>, See on <a href="https://news.ycombinator.com/item?id=44051958">Hacker News</a></p>
<div id="readability-page-1" class="page">
<div id="enchilada">



<div id="credits">
<p><a href="http://www.datapointed.net/2012/10/animated-factorization-diagrams/" onclick="window.open(this.href);return false;">About</a>
</p></div>
<canvas width="300" height="300" id="canvas"></canvas>
</div>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Devstral (215 pts)]]></title>
            <link>https://mistral.ai/news/devstral</link>
            <guid>44051733</guid>
            <pubDate>Wed, 21 May 2025 14:21:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/devstral">https://mistral.ai/news/devstral</a>, See on <a href="https://news.ycombinator.com/item?id=44051733">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p dir="ltr">Today we introduce Devstral, our agentic LLM for software engineering tasks. Devstral is built under a collaboration between Mistral AI and <a href="https://www.all-hands.dev/">All Hands AI</a> 🙌, and outperforms all open-source models on SWE-Bench Verified by a large margin. We release Devstral under the Apache 2.0 license.&nbsp;</p>
<p dir="ltr"><img src="https://cms.mistral.ai/assets/a8f418f6-f7ee-4f21-8ab8-08bd76c37186.png?width=1600&amp;height=882" alt="Devstral Swe"></p>
<h2 dir="ltr">Agentic LLMs for software development</h2>
<p dir="ltr">While typical LLMs are excellent at atomic coding tasks such as writing standalone functions or code completion, they currently struggle to solve real-world software engineering problems. Real-world development requires contextualising code within a large codebase, identifying relationships between disparate components, and identifying subtle bugs in intricate functions.&nbsp;</p>
<p dir="ltr">Devstral is designed to tackle this problem. Devstral is trained to solve real GitHub issues; it runs over code agent scaffolds such as OpenHands or SWE-Agent, which define the interface between the model and the test cases. Here, we show Devstral’s performance on the popular SWE-Bench Verified benchmark, a dataset of 500 real-world GitHub issues which have been manually screened for correctness.</p>
<p dir="ltr">Devstral achieves a score of 46.8% on SWE-Bench Verified, outperforming prior open-source SoTA models by more than 6% points. When evaluated under the same test scaffold (OpenHands, provided by <a href="https://www.all-hands.dev/">All Hands AI</a> 🙌), Devstral exceeds far larger models such as Deepseek-V3-0324 (671B) and Qwen3 232B-A22B.&nbsp;</p>
<p dir="ltr">In the table below, we also compare Devstral to closed and open models evaluated under any scaffold (including ones custom for the model). Here, we find that Devstral achieves substantially better performance than a number of closed-source alternatives. For example, Devstral surpasses the recent GPT-4.1-mini by over 20%.&nbsp;</p>


<h2 dir="ltr">Versatile: local deployment ↔️ enterprise use ↔️ copilots</h2>
<p dir="ltr">Devstral is light enough to run on a single RTX 4090 or a Mac with 32GB RAM, making it an ideal choice for local deployment and on-device use. Coding platforms such as <a href="https://github.com/All-Hands-AI/OpenHands">OpenHands</a> can allow the model to interact with local codebases and provide fast resolution to issues. To try it yourself, view the <a href="https://docs.all-hands.dev/modules/usage/llms/local-llms">documentation</a> or <a href="https://www.youtube.com/watch?v=oV9tAkS2Xic">tutorial video</a>.</p>
<p dir="ltr">The performance of the model also makes it a suitable choice for agentic coding on privacy-sensitive repositories in enterprises, especially ones subject to stringent security and compliance requirements.&nbsp;</p>
<p dir="ltr">Finally, if you’re building or using an agentic coding IDE, plugin, or environment, Devstral is a great choice to add to your model selector.&nbsp;</p>
<h2 dir="ltr">Availability</h2>
<p dir="ltr">We release this model for free under an Apache 2.0 license for the community to build on, customize, and accelerate autonomous software development. To try it for yourself, head over to our <a href="https://huggingface.co/mistralai/Devstral-Small-2505">model card</a>.&nbsp;</p>
<p dir="ltr">The model is also available on our API under the name devstral-small-2505 at the same price as Mistral Small 3.1: $0.1/M input tokens and $0.3/M output tokens.&nbsp;</p>
<p dir="ltr">Should you choose to self-deploy, you can download the model on <a href="https://huggingface.co/mistralai/Devstral-Small-2505">HuggingFace</a>, <a href="https://ollama.com/library/devstral">Ollama</a>, <a href="https://www.kaggle.com/models/mistral-ai/devstral-small-2505">Kaggle</a>, <a href="https://docs.unsloth.ai/basics/devstral">Unsloth</a>, <a href="https://lmstudio.ai/model/devstral-small-2505-MLX">LM Studio</a>&nbsp;starting today.&nbsp;</p>
<p dir="ltr">For enterprise deployments that require fine-tuning on private codebases, or higher-fidelity customization such as continued pre-training or distilling Devstral’s capabilities into other models, please <a href="https://mistral.ai/contact">contact us</a> to connect with our applied AI team.&nbsp;</p>
<h2 dir="ltr">What’s next</h2>
<p dir="ltr">Devstral is a research preview and we welcome feedback! We’re hard at work building a larger agentic coding model that will be available in the coming weeks.</p>
<p dir="ltr">Interested in discussing how we can help your team put Devstral to use, and about our portfolio of models, products and solutions? <a href="https://mistral.ai/contact">Contact us</a> and we’ll be happy to help.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Roto: A Compiled Scripting Language for Rust (139 pts)]]></title>
            <link>https://blog.nlnetlabs.nl/introducing-roto-a-compiled-scripting-language-for-rust/</link>
            <guid>44050222</guid>
            <pubDate>Wed, 21 May 2025 11:10:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.nlnetlabs.nl/introducing-roto-a-compiled-scripting-language-for-rust/">https://blog.nlnetlabs.nl/introducing-roto-a-compiled-scripting-language-for-rust/</a>, See on <a href="https://news.ycombinator.com/item?id=44050222">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-main">
<article>

    <header>

        

        


        <section>

            <ul>
                <li>
                    <a href="https://blog.nlnetlabs.nl/author/nlnetlabs/" aria-label="Read more of Team NLnet Labs">
                        <img src="https://blog.nlnetlabs.nl/content/images/size/w100/2022/07/nlnetlabs-logo-and-text-1-1.png" alt="Team NLnet Labs">
                    </a>
                </li>
            </ul>

            

        </section>

            <figure>
                <img srcset="https://images.unsplash.com/photo-1463567517034-628c51048aa2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDMzfHxzaGlwJTIwaGVsbXxlbnwwfHx8fDE3NDU4NDcyNjl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=300 300w,
                            https://images.unsplash.com/photo-1463567517034-628c51048aa2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDMzfHxzaGlwJTIwaGVsbXxlbnwwfHx8fDE3NDU4NDcyNjl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=600 600w,
                            https://images.unsplash.com/photo-1463567517034-628c51048aa2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDMzfHxzaGlwJTIwaGVsbXxlbnwwfHx8fDE3NDU4NDcyNjl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=1000 1000w,
                            https://images.unsplash.com/photo-1463567517034-628c51048aa2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDMzfHxzaGlwJTIwaGVsbXxlbnwwfHx8fDE3NDU4NDcyNjl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000 2000w" sizes="(min-width: 1400px) 1400px, 92vw" src="https://images.unsplash.com/photo-1463567517034-628c51048aa2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDMzfHxzaGlwJTIwaGVsbXxlbnwwfHx8fDE3NDU4NDcyNjl8MA&amp;ixlib=rb-4.0.3&amp;q=80&amp;w=2000" alt="Introducing Roto: A Compiled Scripting Language for Rust">
                    <figcaption><span>Photo by </span><a href="https://unsplash.com/@jbcreate_?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span>Joseph Barrientos</span></a><span> / </span><a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit"><span>Unsplash</span></a></figcaption>
            </figure>

    </header>

    <section>
        <p><em>By Terts Diepraam</em></p>
<p>We are working on an embedded scripting language for Rust. This language, called <a href="https://github.com/NLnetLabs/roto?ref=blog.nlnetlabs.nl">Roto</a>, aims to be a simple yet fast and reliable scripting language for Rust applications.</p>
<p>The need for Roto comes from <a href="https://nlnetlabs.nl/projects/routing/rotonda/?ref=blog.nlnetlabs.nl">Rotonda</a>, our BGP engine written in Rust. Mature BGP applications usually feature some way to filter incoming route announcements. The complexity of these filters often exceed the capabilities of configuration languages. With Rotonda, we want to allow our users to write more complex filters with ease. So we decided to give them the power of a full scripting language.</p>
<p>We have some hard requirements for this language. First, we need these filters to be fast. Second, Rotonda is critical infrastructure and so runtime crashes are unacceptable. This rules out dynamically typed languages, of which there are plenty in the Rust community.<sup><a href="#fn1" id="fnref1">[1]</a></sup> We want a statically typed language which can give us more type safety and speed. Finally, we want a language that is easy to pick up; it should feel like a statically typed version of scripting languages you're used to.</p>
<p>Roto fills this niche for us. In short, it's a statically typed, JIT compiled, hot-reloadable, embedded scripting language. To get good performance, Roto scripts are compiled to machine code at runtime with the <a href="https://cranelift.dev/?ref=blog.nlnetlabs.nl">cranelift</a> compiler backend.</p>
<p>Below is a small sample of a Roto script. In this script, we define a <code>filtermap</code>, which results in either <code>accept</code> or <code>reject</code>. In this case, we <code>accept</code> when the IP address is within the given range.</p>
<pre><code>filtermap within_range(range: AddrRange, ip: IpAddr) {
    if range.contains(ip) {
        accept ip
    } else {
        reject
    }
}
</code></pre>
<p>Instead of a <code>filtermap</code>, we could instead write a more conventional <code>function</code>, which can simply <code>return</code> a value. The <code>filtermap</code> is a construct that Roto supports to make writing filters easier.</p>
<p>The Roto code there might look quite simple, but there's a twist: <code>AddrRange</code> is not a built-in type. Instead, it is added to Roto by the host application (e.g. Rotonda), making it available for use in the script.<sup><a href="#fn2" id="fnref2">[2]</a></sup> Similarly, the <code>contains</code> method on <code>AddrRange</code> is provided by the host application as well. The full code necessary to run the script above is listed below. This example is also available <a href="https://github.com/NLnetLabs/roto/blob/a4edc7fcea79a2498798f69da4cdb9beb6ecd4d1/examples/addr_range.rs?ref=blog.nlnetlabs.nl">on our GitHub repository</a>.</p>
<pre><code>use std::net::IpAddr;
use std::path::Path;
use roto::{roto_method, FileTree, Runtime, Val, Verdict};

#[derive(Clone)]
struct AddrRange {
    min: IpAddr,
    max: IpAddr,
}

fn run_script(path: &amp;Path) {
    // Create a runtime
    let mut runtime = Runtime::new();
    
    // Register the AddrRange type into the runtime with a docstring
    runtime
        .register_clone_type::&lt;AddrRange&gt;("A range of IP addresses")
        .unwrap();
    
    // Register the contains method on AddrRange
    #[roto_method(runtime, AddrRange)]
    fn contains(range: &amp;AddrRange, addr: &amp;IpAddr) -&gt; bool {
        range.min &lt;= addr &amp;&amp; addr &lt;= range.max
    }
    
    // Compile the program
    let program =
        FileTree::read(path).compile(runtime).unwrap();

    // Extract the Roto filtermap, which is accessed as a function
    let function = program
        .get_function::&lt;(), (Val&lt;AddrRange&gt;, IpAddr), Verdict&lt;IpAddr, ()&gt;&gt;(
          "within_range"
        )
        .unwrap();
    
    // Run the filtermap
    let range = AddrRange {
        min: "10.10.10.10".parse().unwrap(),
        max: "10.10.10.12".parse().unwrap(),
    };

    let in_range = "10.10.10.11".parse().unwrap();
    println!("{:?}", function.call(&amp;mut (), range, in_range)));

    let out_of_range = "10.10.11.10".parse().unwrap();
    println!("{:?}", function.call(&amp;mut (), range, out_of_range));
}
</code></pre>
<p>Note that nothing in the script is run automatically when the script is loaded, as happens in many other scripting language. The host application decides which functions and filtermaps it extracts from the script and when to run them.</p>
<p>Roto is very tightly integrated with Rust. Many Rust types<sup><a href="#fn3" id="fnref3">[3]</a></sup>, methods and functions can be registered directly for use in Roto. These types can be passed to Roto at negligible cost; there is no serialization between Roto and Rust. For Rotonda, this means that Roto can operate on raw BGP messages without costly conversion procedures.</p>
<p>The registration mechanism also ensures that Roto is not limited to Rotonda and could easily be used outside that context. It is designed as a general scripting or plug-in language.</p>
<p>We have many planned features on the roadmap for Roto and will continue to improve this language. This also means that the language should not be considered stable, though we'd love to hear feedback if you experiment with it. If you're interested, check out the <a href="https://rotonda.docs.nlnetlabs.nl/en/stable/roto/00_introduction.html?ref=blog.nlnetlabs.nl">documentation</a>, <a href="https://github.com/NlnetLabs/roto?ref=blog.nlnetlabs.nl">repository</a> and <a href="https://github.com/NLnetLabs/roto/tree/main/examples?ref=blog.nlnetlabs.nl">examples</a>.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>E.g. <a href="https://rhai.rs/?ref=blog.nlnetlabs.nl">Rhai</a>, <a href="https://rune-rs.github.io/?ref=blog.nlnetlabs.nl">Rune</a>, <a href="https://github.com/mlua-rs/mlua?ref=blog.nlnetlabs.nl">Mlua</a>, <a href="https://deno.com/?ref=blog.nlnetlabs.nl">Deno</a>, <a href="https://pyo3.rs/?ref=blog.nlnetlabs.nl">PyO3</a>, <a href="https://github.com/PistonDevelopers/dyon?ref=blog.nlnetlabs.nl">Dyon</a> &amp; <a href="https://koto.dev/?ref=blog.nlnetlabs.nl">Koto</a>. <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>Note that the registering of types is not hindered by Rust's <a href="https://doc.rust-lang.org/reference/items/implementations.html?ref=blog.nlnetlabs.nl#orphan-rules">orphan rule</a>, because it doesn't require any specific traits apart from <code>Clone</code>. This makes it possible to expose types from external libraries to Roto. <a href="#fnref2">↩︎</a></p>
</li>
<li id="fn3"><p>Specifically, types implementing <code>Clone</code> or <code>Copy</code>. Types that don't implement these traits can be wrapped in an <code>Rc</code> or <code>Arc</code> to be passed to Roto. <a href="#fnref3">↩︎</a></p>
</li>
</ol>
</section>

    </section>


</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My new hobby: watching AI slowly drive Microsoft employees insane (884 pts)]]></title>
            <link>https://old.reddit.com/r/ExperiencedDevs/comments/1krttqo/my_new_hobby_watching_ai_slowly_drive_microsoft/</link>
            <guid>44050152</guid>
            <pubDate>Wed, 21 May 2025 10:57:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/ExperiencedDevs/comments/1krttqo/my_new_hobby_watching_ai_slowly_drive_microsoft/">https://old.reddit.com/r/ExperiencedDevs/comments/1krttqo/my_new_hobby_watching_ai_slowly_drive_microsoft/</a>, See on <a href="https://news.ycombinator.com/item?id=44050152">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Welcome to the <a href="https://old.reddit.com/r/ExperiencedDevs">/r/ExperiencedDevs</a> subreddit! We hope you will find this as a valuable resource in your journeys down the fruitful CS/IT career paths. This community leans towards being a specialized subreddit facilitating discussion amongst individuals who have gained some ground in the IT world. </p>

<p>For an idea of what is encouraged in this subreddit and what is not (please report anything that does not follow the rules):</p>

<h2><a href="https://www.reddit.com/r/ExperiencedDevs/about/rules/">Rules</a></h2>

<p><strong>1. Do not participate unless experienced (3+ years)</strong></p>

<p>If you have less than 3 years of experience as a developer, do not make a post, nor participate in comments threads except for the weekly “Ask Experienced Devs” auto-thread. No exceptions.</p>

<p><strong>2. No Disrespectful Language or Conduct</strong></p>

<p>Don’t be a jerk. Act maturely. No racism, unnecessarily foul language, ad hominem charges, sexism - none of these are tolerated here. This includes posts that could be interpreted as trolling, such as complaining about DEI (Diversity) initiatives or people of a specific sex or background at your company.</p>

<p>Do not submit posts or comments that break, or promote breaking the Reddit Terms and Conditions or Content Policy or any other Reddit policy.</p>

<p>Violations = Warning, 7-Day Ban, Permanent Ban.</p>

<p><strong>3. No General Career Advice</strong></p>

<p>This sub is for discussing issues specific to experienced developers. </p>

<p>Any career advice thread must contain questions and/or discussions that notably benefit from the participation of experienced developers. Career advice threads may be removed at the moderators discretion based on response to the thread."</p>

<p>General rule of thumb: If the advice you are giving (or seeking) could apply to a “Senior Chemical Engineer”, it’s not appropriate for this sub.</p>

<p><strong>4. No "Which Offer Should I Take" Posts</strong></p>

<p>Asking if you should ask for a raise, switch companies (“should I work for company A or company B”), “should I take offer A or offer B”, or related questions, is not appropriate for this sub. </p>

<p>This includes almost any discussion about a “hot market”, comparing compensation between companies, etc.</p>

<p><strong>5. No “What Should I Learn” Questions</strong></p>

<p>No questions like “Should I learn C#” or “Should I switch jobs into a language I don’t know?”</p>

<p>Discussion about industry direction or upcoming technologies is fine, just frame your question as part of a larger discussion (“What have you had more success with, RDBMS or NoSQL?”) and you’ll be fine.</p>

<p>tl;dr: Don’t make it about you/yourself.</p>

<p><strong>6. No “I hate X types of interviews" Posts</strong></p>

<p>This has been re-hashed over and over again. There is no interesting/new content coming out.</p>

<p>It might be OK to talk about the merits of an interview process, or compare what has been successful at your company, but if it ends up just turning into complaints your post might still be removed.</p>

<h2>Related Subs</h2>

<p><a href="https://www.reddit.com/r/cscareerquestions">CS Career Questions</a></p>

<p><a href="https://www.reddit.com/r/cscareerquestionsEU">CS Career Questions: Europe</a></p>

<p><a href="https://www.reddit.com/r/CS_Questions">CS Interview Questions</a></p>

<p><a href="http://www.reddit.com/r/learnprogramming">Learn Programming</a></p>

<p><a href="http://www.reddit.com/r/programming">General Programming Discussion</a></p>

<p><a href="http://www.reddit.com/r/coding">Coding</a></p>

<p><a href="http://www.reddit.com/r/compsci">CS Theory</a></p>

<p><a href="http://www.reddit.com/r/CSEducation">CS Education</a></p>

<p><a href="http://www.reddit.com/r/ITCareerQuestions">IT Career Questions</a></p>

<p><a href="http://www.reddit.com/r/telecommuting">Telecommuting</a></p>

<p><a href="http://www.reddit.com/r/jobs">General Job Discussion</a></p>

<p><a href="https://www.reddit.com/r/digitalnomad">Digital Nomads</a></p>

<p><a href="https://www.reddit.com/r/AskNetsec">Ask Network Security</a></p>

<p><a href="https://www.reddit.com/r/netsecstudents">NetSec Students</a></p>

<p><a href="https://www.reddit.com/r/careerguidance/">Career Guidance</a></p>

<hr>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The value isn't in the code (2022) (135 pts)]]></title>
            <link>https://jonayre.uk/blog/2022/10/30/the-real-value-isnt-in-the-code/</link>
            <guid>44046955</guid>
            <pubDate>Tue, 20 May 2025 23:33:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jonayre.uk/blog/2022/10/30/the-real-value-isnt-in-the-code/">https://jonayre.uk/blog/2022/10/30/the-real-value-isnt-in-the-code/</a>, See on <a href="https://news.ycombinator.com/item?id=44046955">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
                    
<h2><strong>Time is money, money is value</strong></h2>



<p>Okay, I’ll admit that calling your software worthless was a shameless clickbait tactic. However, I will assert that it’s not as valuable or indispensable as you might think it is. You need two things to solve a problem using software, skill and time.</p>



<p>Skill. Of course, you can create code using unskilled practitioners. The code might even work, but that’s not the same thing as solving the problem. Bad code is an issue in itself, so even if you solve your original problem, you now have a new, possibly bigger one to deal with. Skill is essential if you’re going to succeed and talent doesn’t come cheap.</p>



<p>Time. Coding can happen quickly, but solving problems is tricky. It takes time, and time is money. A software development team is not cheap to run, so any decent piece of software is going to incur significant cost. If you’re going to put investment into your solution, you should expect it to be worth something when you’re done.</p>



<p>So, why am I suggesting that the code is worthless? If it solves the problem, it’s delivering value. Worthless seems a bit harsh. It’s true that I’m exaggerating, but not by much. To understand, let’s take another look at that solution, and the time that went into it. It’s easy to focus on the software and ignore what surrounds it.</p>



<h2><strong>How to bake a cake</strong></h2>



<p>Firstly, there’s the team. You have to find the right, skilled, people, and bring them together. Then, they have to establish clear roles and responsibilities and learn to work together as a cohesive team. Finally that team has to establish relationships with the stakeholders and users, and familiarise themselves with the problem space.</p>



<p>This takes time.</p>



<p>Secondly, there’s the business logic. Even the simplest of solutions has to perform some sort of business processing. Someone has to work out what that logic needs to be and codify it.</p>



<p>This takes time.</p>



<p>Thirdly, there’s the design. If the code is user facing, it delivers an experience to the user. That experience is (hopefully) developed over time through careful design, feedback and iteration.</p>



<p>This takes time.</p>



<p>And finally, there’s the code. That also takes time, but that time is small in comparison to all the others. Sometimes it feels as if all the effort is going into the code and the other parts are incidental. However, the reality is that very little of the productive time ends up as code in the live solution.&nbsp;</p>



<p>Some of the code will be replaced by alternatives as part of the iterative feedback approach. Some of the code will remain, but will no longer be used as a result of changes to the design. Some of the code will have been written in anticipation of a situation that never arises.</p>



<p>The developer’s answer to all of this is “refactoring”. For those of you who don’t code, refactoring is the process of reviewing existing code and making a range of improvements whilst retaining the core functionality.</p>



<p>This takes time.</p>



<h2><strong>Knowledge is power</strong></h2>



<p>When you add all the time together, you get the cost of your software solution, and you could argue that this represents the value of the code. You might even argue that the value of the code exceeds the cost.</p>



<p>This is where I disagree. My opinion is that in doing this you are conflating the codebase and the solution. All the value is stored up in the team, the logic and the design, and very little of it is in the code itself. Originally this view was just a hypothesis without any form of proof, but over time I’ve had the opportunity to run experiments to test this hypothesis.</p>



<p>One particular experiment involved a web portal I was involved in developing as part of an all remote team back just before the turn of the millennium. Smartphones didn’t exist, and the internet was still a fairly new concept to many people. The portal was for a growing internet service provider.</p>



<p>The work took a team of just 7 people 6 months to develop and the result was a cross platform solution that could deliver content, email, calendering and messaging. It was ahead of its time, and also supported voice interaction via mobile phone and delivery of content via WAP. What’s WAP? Google it – the days before smartphones were far from sophisticated when it comes to mobile access to the internet.</p>



<p>The result was good enough to be bought up by a large organisation as their portal solution. That company had already spent longer than 6 months with a significantly larger team trying to create the same thing without success. We were rightly proud of what we’d achieved in such a short time and with such a small team.</p>



<p>So, my experiment related to something that was already considered very efficient in code development terms.</p>



<h2><strong>We can rebuild it!</strong></h2>



<p>What I did was spend a couple of weeks at home recreating the solution from scratch. The code now belonged to a third party so I wanted a completely new version I could call my own. I used nothing from the original apart from my own knowledge of the problem and my experience solving it. The code repository was no longer accessible, so I couldn’t copy anything from it, even if I’d wanted to. To do so would have also been unethical as it didn’t belong to me. So, every line of code was genuinely built from scratch.</p>



<p>Within two weeks I had a fully working solution that did everything the original did (and a bit more). I’d achieved this in no time at all, and I’d generated a fraction of the code compared to the original solution.</p>



<p>How did I achieve this? Was I some kind of coding genius? Obviously not. I was a very competent coder, very much at the top of my game, but I was just one coder. No matter how good you are, there’s a limit to how fast you can type.</p>



<p>No. I achieved this because the code contained very little of the real value. That was all stored in my head. The design was in my head, and with hindsight I could see all its flaws. I was therefore able to create a much more efficient and effective design based on that learning. All the mistakes had been made, so I was able to get this version of the code right the first time. Most of my tests ran successfully, and debugging time was almost non-existent.</p>



<p>I now knew what wasn’t needed. All those things we’d built in to cater for anticipated needs could now be whittled down to the few that really proved useful. I understood every piece of technology, every protocol and every library, so there was no learning curve.</p>



<h2><strong>Mostly worthless</strong></h2>



<p>From this, I can conclude that of the 6 months of time spent by 7 people creating this solution, hardly any of it related to the code. It could be completely discarded and rebuilt by one person in under two weeks. What’s more, it could be radically improved at the same time.</p>



<p>So, this is why I assert that your code is worthless when compared to the overall effort invested in the creation of your solution. And I’d go further than that. I’d suggest that, contrary to what intuition might tell you, refactoring might be better achieved by throwing the code away and starting again.</p>



<p>It’s a scary thought. You might even consider it ridiculously farfetched. I wouldn’t expect you to agree with me based on a blog post. However, what I would recommend is that you give it some serious thought, and maybe conduct a similar experiment of your own. If you do, let me know how you get on. I’d be genuinely interested to find out.</p>



<p>Maybe I’m special? Maybe I’m the mythical ten times developer? Personally, I doubt it very much. After all, I was one of the people who took six months to build it the first time round.</p>



<p>Oh, and remember this next time you have to fix someone else’s code. It’s easy to feel superior and knowledgeable. It’s tempting to laugh at the obvious mistakes made by those who came before, but you have the advantage of hindsight. Maybe consider instead that you might be standing on the shoulders of those who carved out the first path for you to follow.</p>
                    
                    
	<nav aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>                </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[“ZLinq”, a Zero-Allocation LINQ Library for .NET (252 pts)]]></title>
            <link>https://neuecc.medium.com/zlinq-a-zero-allocation-linq-library-for-net-1bb0a3e5c749</link>
            <guid>44046578</guid>
            <pubDate>Tue, 20 May 2025 22:29:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neuecc.medium.com/zlinq-a-zero-allocation-linq-library-for-net-1bb0a3e5c749">https://neuecc.medium.com/zlinq-a-zero-allocation-linq-library-for-net-1bb0a3e5c749</a>, See on <a href="https://news.ycombinator.com/item?id=44046578">Hacker News</a></p>
Couldn't get https://neuecc.medium.com/zlinq-a-zero-allocation-linq-library-for-net-1bb0a3e5c749: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Instagram Addiction (116 pts)]]></title>
            <link>https://blog.greg.technology/2025/05/19/on-instagram-addiction.html</link>
            <guid>44046559</guid>
            <pubDate>Tue, 20 May 2025 22:25:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.greg.technology/2025/05/19/on-instagram-addiction.html">https://blog.greg.technology/2025/05/19/on-instagram-addiction.html</a>, See on <a href="https://news.ycombinator.com/item?id=44046559">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>i was addicted to instagram for about a month. it upended my life enough that i realized that i was living with something new-an undesirable habit. and once i realized this, it seemed like it would be wise to try to address it or at least think about it. easier said than done.</p>

<p>i left instagram for about three to four months cold turkey-i left a video saying i was leaving, then uninstalled the app.</p>

<p>there’s a few things to talk about here. first, as <a href="https://bsky.app/profile/saltzshaker.bsky.social">emily</a> noted to me, this is why kids today can be so bitter about their relationships with their own phones. kids (which is anyone younger than 43) watch movies from the early 2000s with a kind of wistfulness because, wow, people lived normal, natural lives without phones. maybe it’s obvious to you, but when you’re 43, you completely grew up without phones. phones were an absolutely new thing that happened in the middle of your 43-year old’s life.</p>

<p>i grew up quite familiar with the state of being absolutely bored to the gills. boredom was just a sensation that you had, like pain or hunger. you’d stare in some direction and you’d be bored. but that doesn’t seem to be a thing i feel anymore. now it’s mostly about dealing with self-control and somehow thinking about it all the time. it is not relaxing. the phone is in your pocket. it’s on your body.</p>

<hr>

<p>i hope i’m not using “addiction” in a way that trivializes it. some people (have to) deal with their own intense relationships with (substances, habits), and i would never want you to think that what i dealt with is the same as that.</p>

<p>obviously, so many forms of addiction have had an enormous impact on so many lives-upending them, transforming them, taking people from one direction (their wishes, dreams, circumstances) to a very opposite one.</p>

<p>i hope it’s clear i am more than sympathetic.</p>

<hr>

<hr>

<hr>

<hr>

<hr>

<hr>

<p>i developed a habit that would break my sleep in a specific way: i would get up at four a.m. and watch reels for about two to three hours.</p>

<p>what’s impressive about that is that two hours for a movie is nothing—it’s one movie. if i had been getting up in the middle of the night every night to watch superman, you’d think, “wow, this guy’s into superman.” i’d probably learn a lot of superman trivia that i could drop into regular conversation. maybe i’d wonder why i didn’t just do that after work as you could easily combine a nine-to-five job with an intense level of superman fandom.</p>

<p>but an instagram reel or any sort of short-form video…—really, “short-form” isn’t strong nor short enough of a word. six seconds isn’t short. it’s instant. it’s zero seconds. there is no difference between zero seconds and six seconds in any timeline unless you build atomic watches or run <a href="https://time.gov/">time.gov</a>. if any clock in your house was off by six seconds, you wouldn’t spend any amount of time thinking about that. and yet this new art form can tell a story with multiple edits within a single six-second timeframe.</p>

<p>it’s an incredible achievement. who among us even knows if akira kurosawa could make a good six-second reel? (please don’t use a generative ai to generate 6 second akira kurosawa-styled tiktok videos, even if nothing could ever prevent you from doing this.)</p>

<hr>

<p>ok but the six-second video format <em>is</em> extremely impressive from a narrative, storytelling, and comedy point of view. the art of editing has probably improved globally or developed some sort of new appendix, which i hope doesn’t metastasize into all moviemaking. but cutting your teeth on making a good six-second video must somehow give you incredible editing abilities. i totally get it as a training ground for filmmakers or anyone that’s into storytelling.</p>

<p>that’s the good part. the good part is the fun and addictive part—there are truly incredible videos out there, even though i am not going to link to them. if i told you the story of how heroin felt, i would probably not tell you where to get it. if you truly needed heroin (who needs heroin?), you’d be pursuing it anyway and would probably find your way to some heroin mart. but i hope you don’t do either heroin or short videos. the problem is, short videos are a lot harder to escape.</p>

<p>it was also so obvious to see that not every six-second video was good or seemed interesting to me. in that span of a few hours, i’d get a few—sometimes one, sometimes five, rarely 10—that were the funniest videos i had ever seen in my life. but that’s just a slot machine: you keep pressing the button like a rat and the button gives you drugs, but randomly, which is the worst/best kind of addiction-creating mechanism. it’s why inbox addiction is also a thing (that i have): never knowing when you’ll get an email, you keep reloading until you inevitably get one.</p>

<hr>

<hr>

<p>recently, i reinstalled instagram to post a video and a music video, then uninstalled it and reinstalled it and uninstalled it at least six times in the last week. unfortunately, the app felt just as good as before. i’m not sure if the algorithm got better—i understand that this is probably not what happened, and i was just missing it. but instagram knows me.</p>

<p>most of the videos it was offering were super bizarre, out-of-this-world noise performances where artists were setting instruments on fire, which appealed to me enormously. there were grandmas doing cooking and hip hop in mandarin, videos of religious sects with incredible sound and reverb—amazing soundscapes i had never seen before. all of this content came streaming back and it unfortunately felt really great.</p>

<p>during the period when i didn’t have the app, every alternative felt not as good. i tried to fill the place of the addictive cigarette with carrots, but carrots don’t (yet) contain nicotine, and you can taste the difference. i started reading the news again a lot—in a very “reload the news five times a day” kind of way.</p>

<p>the news didn’t feel as good, and going back to the news now still feels like a lesser version of the previous short video hole filling activity. news doesn’t know you as well as the algorithm. also it’s hard knowing that instagram is always there.</p>

<p>of course, the app also offers connection. there are multiple communities i joined or keep informed of or partake in or just watch, sometimes completely from a distance. but i can also strike up conversations, and i’ve been able to meet people from there. this isn’t saying anything new—online friendships have always been a thing, and those that cross from online to offline have been in my life for a while.</p>

<p>so instagram, like any social media app, combines addiction with everything else. addictive videos on one hand that fill holes, but those videos are also funny and original. they feel like a waste of time, but they’re also entertaining. you connect with people, but the messaging part is tied to the video part, and you can’t do one without the other. truly, any accidental ui swipe on instagram brings you back to reels—it’s the thing in the app with the most gravity.</p>

<hr>

<p>emily pointed out two things regarding this. first, using instagram on desktop is enough of a deterrent for her. it lacks the slickness of mobile, so it has fewer addictive attributes. she would want just that, but minus the reels, which isn’t possible in the desktop version unless you install a browser extension and muck around.</p>

<p>second, she’s convinced that in some future some laws might pass (in europe?) to force apps like instagram to give you an option to turn off reels. this would probably take the form of family controls that make sense for parents and would integrate with other tools used to limit screen time. but for adults, of course, you’re on your own (adulting is hard). i’m not sure what the options are or could be. apps that try to limit screen time feel “ridiculous” knowing i could uninstall them, and i wouldn’t want an app i couldn’t uninstall. you/i could set a family screen time restriction, give the password to a friend, but then they’d be responsible for managing your/my emotions anytime you/i’d have a flare-up, which is so completely worse.</p>

<hr>

<p>so here’s where i am today: i uninstalled the app and deleted it from my phone, as i’ve done dozens of times. then i went into my phone’s preferences and disabled the ability to install new apps and make in-app purchases.</p>

<p>so i’m just two very easy toggles away from reinstalling instagram and going back in. i’m also happy to share that i’ve actually created a calendar of things i do want to post, i.e. a social media content calendar! ((to be more intentional about when i use the app)) and i am looking forward to sharing that content because i think it might be funny, and someone might like it.</p>

<p>but! because of this, i already know that i’ll be turning those toggles off. and it will feel good again, and i’ll know that it’s not the right kind of good. and it will seem like that’s all there is to it, and that will also be not true.</p>

<p><img src="https://blog.greg.technology/assets/instagram/settings.jpg"></p>

  </div>
</article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Semantic search engine for ArXiv, biorxiv and medrxiv (136 pts)]]></title>
            <link>https://arxivxplorer.com/</link>
            <guid>44046277</guid>
            <pubDate>Tue, 20 May 2025 21:49:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxivxplorer.com/">https://arxivxplorer.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44046277">Hacker News</a></p>
<div id="readability-page-1" class="page"><div tabindex="-1" id="___gatsby"><div><a aria-current="page" href="https://arxivxplorer.com/"><div data-gatsby-image-wrapper=""><picture><source type="image/webp" data-srcset="/static/e0cd7b5f0243163f253dd5c1aa2d8c9a/e73fe/icon.webp 40w,/static/e0cd7b5f0243163f253dd5c1aa2d8c9a/61ca6/icon.webp 80w" sizes="40px"><img data-gatsby-image-ssr="" layout="fixed" data-main-image="" sizes="40px" decoding="async" loading="lazy" data-src="/static/e0cd7b5f0243163f253dd5c1aa2d8c9a/f31ef/icon.png" data-srcset="/static/e0cd7b5f0243163f253dd5c1aa2d8c9a/f31ef/icon.png 40w,/static/e0cd7b5f0243163f253dd5c1aa2d8c9a/1f8a1/icon.png 80w" alt="arXiv Xplorer Logo" src="https://arxivxplorer.com/static/e0cd7b5f0243163f253dd5c1aa2d8c9a/f31ef/icon.png" srcset="https://arxivxplorer.com/static/e0cd7b5f0243163f253dd5c1aa2d8c9a/f31ef/icon.png 40w,https://arxivxplorer.com/static/e0cd7b5f0243163f253dd5c1aa2d8c9a/1f8a1/icon.png 80w"></picture></div></a><div><a href="https://arxivxplorer.com/guide/"><p>Guide</p></a><a href="https://scroll.arxivxplorer.com/"><p>Scroll</p></a></div></div><div><div><h4>The Semantic Search Engine for ArXiv.</h4><div></div></div></div><div><p>Thank you to arXiv, bioRxiv and medRxiv for their open access interoperability.</p><p>Built by<!-- --> <a href="https://x.com/tomtumiel" target="_blank" rel="noopener noreferrer">ttumiel <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75Zm-.86 13.028h1.36L4.323 2.145H2.865z"></path></svg></a> <!-- -->with<!-- --> <a href="https://platform.openai.com/docs/guides/embeddings" target="_blank" rel="noopener noreferrer">OpenAI's Embeddings</a>.</p></div></div></div>]]></description>
        </item>
    </channel>
</rss>