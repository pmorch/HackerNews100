<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 22 Jul 2023 04:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Hollywood is on strike because CEOs fell for Silicon Valley’s magical thinking (134 pts)]]></title>
            <link>https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking</link>
            <guid>36821347</guid>
            <pubDate>Fri, 21 Jul 2023 23:19:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking">https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking</a>, See on <a href="https://news.ycombinator.com/item?id=36821347">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-element="story-body" data-subscriber-content=""> <p>In one respect, the <a href="https://www.latimes.com/entertainment-arts/business/story/2023-07-16/sag-aftra-strike-actors-writers-strike-hollywood-production-film-tv-disruption-fall-season"><u>actors and writers of Hollywood</u></a> uniting on the picket lines in <a href="https://www.latimes.com/entertainment-arts/business/story/2023-07-14/actors-strike-sag-aftra-joins-writers-guild-picket-lines"><u>a historic, industry-shaking strike</u></a> is a tale as old as time: one of workers fighting bosses for better pay. Yet the reason this battle is shaping up to be so uniquely intractable and momentous — as you might have gathered from all the headlines about  artificial intelligence and streaming economics — is very much of our moment.</p><p>But it’s not, ultimately, technology that’s at the root of the problem. It’s that the studio executives both new and old have embraced the powerful — and ultimately disastrous — magical thinking pumped out by Silicon Valley for the last  10 years.</p><p>Studio heads are touting the disruptive properties of digital streaming, the transformative power of AI, a brave, unpredictable new world for entertainment writ large — and how writers and actors must adapt to this new future. But just as it did when it was issuing from the tech sector during the 2010s, this talk too often amounts to a smokescreen that lets executives and investors line their pockets and risks leaving workers holding the bag.</p><p>“These companies blew up a successful business model that the public enjoyed,  that was immensely profitable,  and they replaced it with a mishmash that we have now,” Adam Conover, the star of “Adam Ruins Everything”<i> </i>and a  negotiating committee member of the Writers Guild of America, tells me. “And now, they’re refusing to update the contract to reflect those changes.”</p><p>We’ve heard a lot about the ways that studios want to reserve the right to use AI — to create endlessly usable digital replicas of actors, to generate scripts that writers <a href="https://www.latimes.com/business/technology/story/2023-05-11/column-the-writers-strike-is-only-the-beginning-a-rebellion-against-ai-is-underway"><u>will be paid lower rates to fix up</u></a>. We’ve also heard about the new economic picture ushered in by streaming, about an industry in the throes of change, and the necessity of belt-tightening as a result. </p><p>We’ve heard Disney Chief Executive Bob Iger saying the  demand by the Screen Actors Guild for fair payment in the new digital landscape “isn’t realistic,” and heard how Netflix saw declining user sign-ups and stock prices last year. Yet  Iger reportedly makes <a href="https://www.rollingstone.com/tv-movies/tv-movie-features/disney-staffers-angry-ceo-bob-iger-actors-strike-writers-strike-1234789713/" target="_blank"><u>$27 million a year</u></a>, while Netflix <a href="https://www.wsj.com/articles/netflix-nflx-q2-earnings-report-2023-92a620c8" target="_blank"><u>just raked in $1.5 billion in net profit in the last quarter</u></a>.</p><p>So what’s really going on? And how did we get here?</p><p>First, we need to understand why the 2010s may well come to be remembered as the great decade of magical thinking for Silicon Valley. Drunk on a truly transformational first decade of the 21st century — one that saw Google, Amazon, the iPhone and social media storm the world stage — flush tech investors turned their sights toward the next generation of startups, eager to see them do the same.</p><p>The formula for seeking out that next multibillion-dollar “unicorn,” in hindsight, was pretty simple: The next wave of startups had to promise that it would disrupt a stale industry with a newer, high-tech, app-driven alternative, promise the potential for vast scale and promise that it could do so fast. So we saw the rise of Uber and Lyft, each of which vowed to revolutionize transit, and we got the likes of WeWork, which set out to usher in the future of co-working, and Theranos, which would do the same for at-home blood testing.</p><p>We know how it ended. Uber and Lyft have never been sustainably profitable, WeWork collapsed dramatically when it became clear that it was merely a wildly over-leveraged real estate company, and Theranos’ futuristic medical technology was outright fraudulent. </p><p>Unlike many of the 21st century’s first-wave tech companies and products, which found both markets and roads to profitability, these were pipe dreams, propped up by a fire hose of investment cash, big-talking founders and the very real — and at the time, quite understandable! — sense that Silicon Valley was the place that determined how the future was made.</p><p>As the 2010s began, Netflix sat somewhere between the old guard and the new. It introduced online streaming in 2007, and had a real product with real demand, as well as an established business in its DVD-by-mail rental service. Yet its ambitions were hypercharged by a newfangled sense that it could disrupt the old school Hollywood industry and scale endlessly — there was no reason everyone in the world with access to a screen couldn’t subscribe.</p><p><a href="https://www.reuters.com/article/us-netflix-stock/netflix-shares-soar-after-icahn-reports-10-percent-stake-purchase-idUSBRE89U1GA20121101" target="_blank"><u>Big-name investors</u></a> sank hundreds of millions into Netflix’s new vision. As it began producing original content in 2013, it applied a distinctly next-wave Silicon Valley ethos. It would make massive upfront investments, bankrolling huge productions such as the David Fincher-helmed, Kevin Spacey-starring “House of Cards,” elbowing its way into the prestige TV pack, promising not only to compete but also to do it better: It would offer all the episodes at once, on demand, and viewers could consume them whenever and however they wanted. Cable would become obsolete. The future was cutting the cord.</p><p>As with Uber and Lyft, whose bottomless chests of venture capital allowed them to conquer new markets once dominated by stodgy old competitors — in their case, the taxi cartels and livery cab companies — price was no object.</p><p>Right out the gate, episodes for original Netflix shows such as “House of Cards” and “Orange Is the New Black”<i> </i>cost $4 million a pop. (So did episodes of shows that few remember today, such as “Hemlock Grove.”) The spending was profligate — it soon rose to rates of <a href="https://www.indiewire.com/features/general/netflix-originals-budget-15-billion-1202036683/" target="_blank"><u>$15 billion a year</u></a> on new content — but as it did for the magical valley startups, the strategy “worked.”</p><p>“What happens is Netflix becomes the Wall Street darling, and all these other companies,” like Amazon, Disney, Apple, HBO, Paramount and NBC, “race to adopt Netflix’s business model,” Conover says. </p><p>Herein lies the trouble. Amid this boom, which for a few years ushered in a gold rush for writers and talent, Netflix et al. adopted another key ingredient of Silicon Valley’s approach: secrecy. Data about shows’ performance and viewer habits were kept proprietary; we  knew only what the streamers wanted us to know. That went for customers, performers, writers and for investors. Streaming is an inscrutable black box, about which so many stories might be told.</p><p>It’s a sticking point in the negotiations — actors and writers on streaming series want a better way to calculate the value of their work, given that the residuals they earn are so much lower than for network or cable shows. The studios have resisted. “The reason nobody really wants to open the books on this is because if Wall Street got a look,” one Hollywood insider <a href="https://www.vulture.com/2023/06/streaming-industry-netflix-max-disney-hulu-apple-tv-prime-video-peacock-paramount.html" target="_blank"><u>told New York Magazine</u></a>, “they’d have a collective stroke.”</p><p>What we’re seeing now is the fantastical thinking that Netflix and its followers could continue endless expansion running up against the physics of the real world — there are now 238 million Netflix subscribers, but those numbers <a href="https://www.latimes.com/entertainment-arts/business/story/2022-04-19/lat-et-ct-netflix-loses-subscriber-first-quarter">dropped for the first time</a> last year, and the company had to claw them back by nibbling at the corners, <a href="https://www.latimes.com/entertainment-arts/business/story/2021-03-11/netflix-password-sharing-policing">cutting off password sharing</a> and launching new, cheaper tiers that run ads.</p><p>The boom times are over. Executives know it. Wall Street knows it. And the story that we’re in a revolutionary moment of technological transformation will run out of gas soon. So the bosses are using that moment to do what Silicon Valley wound up doing when its other big swings didn’t pan out: squeeze labor. </p><p>Just as Uber and Lyft, which promised drivers rich rewards and flexible fares, started reducing rates and making it harder to earn those rewards, Netflix and the streaming cohort cut in its mold are now trying to square their promises of world conquest by slashing worker pay under the fog of magical thinking.</p><p>It’s been noted, and correctly so, that entertainment industry labor disputes often erupt when there’s a change in technology — from theaters screening projected films to the cathode ray tube of the home television, say, or the rise of YouTube and other online content in the 2000s  — and that happens for a reason. Historically, executives and management use a disorienting new technology to try to justify lowering wages of their workers, and they have done so since the days of the Industrial Revolution. </p><p>“The old CEOs knew they had to work with the unions, bargain with us,” Conover says. “The new ones don’t. So part of the point of the strike is us as labor showing the tech CEOs that no, you actually do have to deal fairly with the unions.”</p><p>Conover notes that it’s jarring to see the streamers plead poverty as an excuse not to negotiate with talent in good faith, given that show budgets and profits have both gone up. </p><p>“Netflix lied to the public and Wall Street,” he says, telling them, “‘you can watch every show ever made in perpetuity, with no ads, for $15.99 a month forever.’ That’s like Movie Pass” (the much-hyped app that allowed users to see unlimited movies for a monthly fee, before quickly going bankrupt). “That’s ludicrous.” </p><p>Ludicrous if you want to pay the people who actually create those shows for you, anyway.</p><p>What Netflix and the streamers are trying to do now is seal in a new standard under which writers and actors are treated in much the way that Uber and the gig app companies treat their independent contractor drivers. </p><p>“Uber is a perfect example,” Conover says. “Its drivers need to supply their own cars, their own gas, their own insurance and so on.” The drivers are on their own, with few to no benefits or protections, and are expected to maximize profits for the company. “And Netflix is trying to do the same thing.”</p><p>Unlike Uber, Netflix really <i>is </i>quite profitable. But in order to sustain the mythical levels of growth it has promised investors, it is turning to similar tactics — cutting workers’ hours, making work more precarious and unpredictable and reducing pay. It’s a far cry from the sleek, automated futures promised by the studio executives.</p><p>As with the biggest companies of Silicon Valley’s magical thinking era, it’s often hard to parse whether the ones touting the game-changing technologies themselves even believe in these visions — do studio execs really think consumers want to watch a parade of digital replicas of their favorite actors parroting lines from an AI-generated script? Or are they simply aware that the mere threat of such a future gives them leverage and power over the workers of today?</p><p>In the end, the answer is immaterial. Silicon Valley’s invasion of Hollywood brought with it science fictional notions of growth for the industry, a penchant for secrecy and unaccountability and the expectation that it could get away with treating workers like robots or invisible code. We’re seeing what happens when those notions meet, for one of the first times, with a powerful, organized resistance.</p><p>Personally, I’m hoping this one gets a Hollywood ending — and not the ending so many Silicon Valley startups got over the last 10 years.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Managing Kitchen Fruit Flies with a Little Shop of Horrors (192 pts)]]></title>
            <link>https://blog.zaccohn.com/Fruitflies-and-the-Little-Shop-of-Horrors/</link>
            <guid>36820469</guid>
            <pubDate>Fri, 21 Jul 2023 21:58:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.zaccohn.com/Fruitflies-and-the-Little-Shop-of-Horrors/">https://blog.zaccohn.com/Fruitflies-and-the-Little-Shop-of-Horrors/</a>, See on <a href="https://news.ycombinator.com/item?id=36820469">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><img src="https://blog.zaccohn.com/images/blog_pitcherplants.jpeg" alt=""></p>

<p>I live in Seattle on a fairly wooded property. Every summer since we’ve moved here, we end up with <em>swarms</em> of fruit flies in the kitchen. They congregate around the compost bin and the fruit bowl (where there are always lots of bananas). We aren’t slobbish - I do the dishes and wipe down the counters every night, take the compost out and wash the bin 2-3x a week. Keeping everything washed and clean helps, but the fruit flies still build up over time. And if there’s even the slightest deviation from the cleaning schedule, within 2-3 days the fruit flies have built up exponentially and there are 50-100 of them swarming around.</p>

<p>Our previous remedy, iterated on and honed over years, was to leave a few traps out. We found what worked best was a short, wide brimmed glass (or tuppaware container) with a little bit of wine, a splash of apple cider vinegar, a drop of dish soap, then hit it with a spray of hot water to get a lot of suds and bubbles. When the swarms were particularly bad, one of these traps could catch dozens overnight, but we had to refill and refresh them constantly and the mass-graves of floating fruit flies were somewhat unsightly.</p>

<p>Earlier this Spring I was reading about symbotic relationships between humans and nature, and that gave me an idea to try some carnivorous plants.</p>

<p>Venus Fly Traps are the most well known type of carnivorous plant. They have sensitive little trigger hairs in their leaves, and when a fly lands and disturbs one of the hairs, the two lobes snap shut to trap the fly. The plant digests the fly before opening back up, ready for its next meal. The downside is they can take a week or more to open back up! That’s not nearly high-volume enough to deal with my fruit fly problem.</p>

<p>Some additional research taught me about a more passive type of carnivorous plant called a “pitcher plant.” There are many varieties, but generally their leaves form tubes that are open on top. These tubes are full of liquid - a mixture of rainwater and digestive fluids. Flies are attracted to the scent, fly in, then fall into the liquid. They’re trapped there until they drown, then are slowly digested. The same pitcher can catch many, many flies, and even smaller pitcher plants can have between 6 and 12 pitchers.</p>

<p>These sounded perfect! I ran up to the local plant nursery and got three carnivorous “Pitcher plants.” I got two different varieties - which internet research suggests are a Purple Pitcher Plant (<a href="https://en.m.wikipedia.org/wiki/Sarracenia_purpurea">Sarracenia Purpurea</a>) and what I think is a <a href="https://en.wikipedia.org/wiki/Sarracenia_leucophylla">Sarracenia Leucophylla</a> (but could be a <a href="https://en.wikipedia.org/wiki/Sarracenia_flava">Sarracenia Flava</a>).</p>

<p>I named them Audrey III, Audrey IV, and Audrey V. They were about the size in the photos when I got them. They were mature enough to have 6-8 open pitchers, and were growing another 6-8 juvenile pitchers. Each plant was roughly $10 each.</p>

<p>I’ve been disappointed by Audrey III and V’s performance (they’re either the Leucophylla or Flava species), but Audrey IV (the Purple Pitcher Plant) is a <strong>beast</strong>. These days I see one fruit fly buzzing around sometimes, but never more than that. When I look in Audrey IV’s pitchers, she’s been busy - just now I counted ten or eleven fruitflies and two house flies.</p>

<p>Passive countermeasures like Audrey IV works great because it prevents them from going exponential. If you’re taking fruit flies out early and continuously, they don’t have a chance to reproduce. A female fruit fly starts mating 8 hours after it emerges from the larval state, and lays about 400 eggs, which take 12-15 hours to hatch at typical room temperature. Needless to say - you gotta keep these under control!</p>

<p><img src="https://blog.zaccohn.com/images/blog_lavender.jpeg" width="100"> I did notice for a time they were still congregating by the compost and weren’t being drawn to Audrey’s sweet scents. More internet research seemed to indicate they didn’t like don’t like the smell of lavender, so I cut some lavender flowers and put them between the compost bin’s lid and filter. That didn’t seem to be effective, so I spritzed some much higher density lavender essential oil on the compost bin filter. Later that night I watched as a fly kept going into the holes in the lid, then back out, then in, but then back out. It didn’t like the smell! Success!</p>

<p>Since then, there’s been no congregation of fruit flies around the compost. I still see one or two flying around the kitchen, but Audrey IV is keeping them under control.</p>

<p>So that’s my official two-part recommendation for managing fruit flies: get yourself an Audrey IV and spritz some lavender essential oil on your compost bin filter to keep them out.</p>

<h2 id="taking-care-of-a-pitcher-plant">Taking care of a Pitcher Plant</h2>
<p>A few notes on taking care of your new Audrey.</p>
<ol>
  <li><strong>You have to use distilled water.</strong> If you water them with sink water they’ll be dead within a day or two. These plants evolved in swampy, very nutrient-poor soils (that’s why they evolved to get their nutrients from their prey). The minerals in sink water are enough to overwhelm and poison your pitcher plants.</li>
  <li><strong>Damp, but not soaked, soil.</strong> When you water them, you want the soil to be damp but not waterlogged. Although you should look up the needs of your specific species of Audrey.</li>
  <li><strong>Filling the pitcher.</strong> For certain types of pitcher plants, you’ll want to fill up their pitchers with (distilled) water. Some types of pitcher plants have an opening at the top without any sort of leaf covering it (like Audrey IV). These types of plants are designed to supplement their digestive juices with rain water they catch. Since it presumably doesn’t rain inside your house like it does outside, you’ll want to use an eye dropper or a straw to drip some distilled water into the pitchers. Generally try to fill them 3/4 of the way. If your pitcher plant has a “hood” - or part of the leaf that’s covering the opening - that’s designed to shield it from the rain and you may not need to fill it up. Look up your particular species for specific instructions.</li>
  <li><strong>Hand-feeding your pitcher plant.</strong> Outside of fruit fly season, you’ll want to feed your pitcher plant a snack every so often. I use dehydrated mealworms or bloodworms from the pet food store (typically used to feed reptiles, etc). Use tweezers to grab one and drop it into a pitcher. Keep an eye on how fast they digest to figure out the optimal feeding schedule for your plant - but it’s probably going to be close to 3-4 per plant once every 2-3 weeks.</li>
</ol>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama: Add grammar-based sampling (217 pts)]]></title>
            <link>https://github.com/ggerganov/llama.cpp/pull/1773</link>
            <guid>36819906</guid>
            <pubDate>Fri, 21 Jul 2023 21:17:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ggerganov/llama.cpp/pull/1773">https://github.com/ggerganov/llama.cpp/pull/1773</a>, See on <a href="https://news.ycombinator.com/item?id=36819906">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">EDITED after updates</p>
<p dir="auto">Inspired by <a data-error-text="Failed to load title" data-id="1704730522" data-permission-text="Title is private" data-url="https://github.com/ggerganov/llama.cpp/issues/1397" data-hovercard-type="pull_request" data-hovercard-url="/ggerganov/llama.cpp/pull/1397/hovercard" href="https://github.com/ggerganov/llama.cpp/pull/1397">#1397</a> and <a href="https://github.com/grantslatton/llama.cpp/commit/007e26a99d485007f724957fa8545331ab8d50c3">grantslatton's CFG work</a>, this adds an API that takes a serialized context-free grammar to guide and constrain sampling. Also adds a sample Backus-Naur form (BNF)-like syntax in <code>main</code> for specifying a grammar for generations.</p>
<h2 dir="auto">Testing</h2>
<p dir="auto">(M2 Max, 30B)</p>
<details>
<summary>Chess</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n' --grammar-file grammars/chess.gbnf
main: build = 674 (e550234)
main: seed  = 1688014137
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= [1] [.] [ ] move [ ] move [<U+000A>] root_4 
move ::= move_5 move_9 
root_2 ::= [1-9] root_3 [.] [ ] move [ ] move [<U+000A>] 
root_3 ::= [0-9] | 
root_4 ::= root_2 root_4 | root_2 
move_5 ::= pawn | nonpawn | castle 
pawn ::= pawn_14 [a-h] [1-8] pawn_16 
nonpawn ::= [NBKQR] nonpawn_10 nonpawn_11 nonpawn_12 [a-h] [1-8] 
castle ::= [O] [-] [O] castle_17 
move_9 ::= [+#] | 
nonpawn_10 ::= [a-h] | 
nonpawn_11 ::= [1-8] | 
nonpawn_12 ::= [x] | 
pawn_13 ::= [a-h] [x] 
pawn_14 ::= pawn_13 | 
pawn_15 ::= [=] [NBKQR] 
pawn_16 ::= pawn_15 | 
castle_17 ::= [-] [O] | 

 A good game:

1. e4 e5
2. Nf3 Nc6
3. Bb5 a6
4. Ba4 Nf6

llama_print_timings:        load time =  1144.33 ms
llama_print_timings:      sample time =    35.87 ms /    32 runs   (    1.12 ms per token)
llama_print_timings: prompt eval time =  1126.34 ms /     7 tokens (  160.91 ms per token)
llama_print_timings:        eval time =  5214.99 ms /    31 runs   (  168.23 ms per token)
llama_print_timings:       total time =  6398.45 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n' --grammar-file grammars/chess.gbnf
main: build = 674 (e550234)
main: seed  = 1688014137
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= [1] [.] [ ] move [ ] move [&lt;U+000A&gt;] root_4 
move ::= move_5 move_9 
root_2 ::= [1-9] root_3 [.] [ ] move [ ] move [&lt;U+000A&gt;] 
root_3 ::= [0-9] | 
root_4 ::= root_2 root_4 | root_2 
move_5 ::= pawn | nonpawn | castle 
pawn ::= pawn_14 [a-h] [1-8] pawn_16 
nonpawn ::= [NBKQR] nonpawn_10 nonpawn_11 nonpawn_12 [a-h] [1-8] 
castle ::= [O] [-] [O] castle_17 
move_9 ::= [+#] | 
nonpawn_10 ::= [a-h] | 
nonpawn_11 ::= [1-8] | 
nonpawn_12 ::= [x] | 
pawn_13 ::= [a-h] [x] 
pawn_14 ::= pawn_13 | 
pawn_15 ::= [=] [NBKQR] 
pawn_16 ::= pawn_15 | 
castle_17 ::= [-] [O] | 

 A good game:

1. e4 e5
2. Nf3 Nc6
3. Bb5 a6
4. Ba4 Nf6

llama_print_timings:        load time =  1144.33 ms
llama_print_timings:      sample time =    35.87 ms /    32 runs   (    1.12 ms per token)
llama_print_timings: prompt eval time =  1126.34 ms /     7 tokens (  160.91 ms per token)
llama_print_timings:        eval time =  5214.99 ms /    31 runs   (  168.23 ms per token)
llama_print_timings:       total time =  6398.45 ms
</code></pre></div>
</details>
<details>
<summary>"Chess" without grammar</summary>
<div data-snippet-clipboard-copy-content="% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n'  

main: build = 645 (fd0eb66)
main: seed  = 1686286016
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A good game:

Sir Thomas Gresham, when he was building his famous Exchange at London, had the following dialogue with a mason, whose name was Richard B
llama_print_timings:        load time =  1185.47 ms
llama_print_timings:      sample time =    21.57 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1167.67 ms /     7 tokens (  166.81 ms per token)
llama_print_timings:        eval time =  4977.97 ms /    31 runs   (  160.58 ms per token)
llama_print_timings:       total time =  6188.21 ms"><pre><code>% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n'  

main: build = 645 (fd0eb66)
main: seed  = 1686286016
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A good game:

Sir Thomas Gresham, when he was building his famous Exchange at London, had the following dialogue with a mason, whose name was Richard B
llama_print_timings:        load time =  1185.47 ms
llama_print_timings:      sample time =    21.57 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1167.67 ms /     7 tokens (  166.81 ms per token)
llama_print_timings:        eval time =  4977.97 ms /    31 runs   (  160.58 ms per token)
llama_print_timings:       total time =  6188.21 ms
</code></pre></div>
</details>
<details>
<summary>Arithmetic</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n' \                      
--grammar 'root  ::= (expr &quot;=&quot; ws num &quot;\n&quot;)+
expr  ::= term ([-+*/] term)*
term  ::= ident | num | &quot;(&quot; ws expr &quot;)&quot; ws
ident ::= [a-z] [a-z0-9_]* ws
num   ::= [0-9]+ ws
ws    ::= [ \t\n]*'
main: build = 674 (e550234)
main: seed  = 1688014196
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_5 
root_1 ::= expr [=] ws num [<U+000A>] 
expr ::= term expr_8 
ws ::= ws_12 
num ::= num_11 ws 
root_5 ::= root_1 root_5 | root_1 
term ::= ident | num | [(] ws expr [)] ws 
expr_7 ::= [-+*/] term 
expr_8 ::= expr_7 expr_8 | 
ident ::= [a-z] ident_10 ws 
ident_10 ::= [a-z0-9_] ident_10 | 
num_11 ::= [0-9] num_11 | [0-9] 
ws_12 ::= [ <U+0009><U+000A>] ws_12 | 

 Some arithmetic practice:

10 *a*1 +b*2 =640

10 *a*2 +b*3 =656


llama_print_timings:        load time =  1165.00 ms
llama_print_timings:      sample time =    41.11 ms /    32 runs   (    1.28 ms per token)
llama_print_timings: prompt eval time =  1147.76 ms /     7 tokens (  163.97 ms per token)
llama_print_timings:        eval time =  5113.92 ms /    31 runs   (  164.97 ms per token)
llama_print_timings:       total time =  6323.27 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n' \                      
--grammar 'root  ::= (expr "=" ws num "\n")+
expr  ::= term ([-+*/] term)*
term  ::= ident | num | "(" ws expr ")" ws
ident ::= [a-z] [a-z0-9_]* ws
num   ::= [0-9]+ ws
ws    ::= [ \t\n]*'
main: build = 674 (e550234)
main: seed  = 1688014196
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_5 
root_1 ::= expr [=] ws num [&lt;U+000A&gt;] 
expr ::= term expr_8 
ws ::= ws_12 
num ::= num_11 ws 
root_5 ::= root_1 root_5 | root_1 
term ::= ident | num | [(] ws expr [)] ws 
expr_7 ::= [-+*/] term 
expr_8 ::= expr_7 expr_8 | 
ident ::= [a-z] ident_10 ws 
ident_10 ::= [a-z0-9_] ident_10 | 
num_11 ::= [0-9] num_11 | [0-9] 
ws_12 ::= [ &lt;U+0009&gt;&lt;U+000A&gt;] ws_12 | 

 Some arithmetic practice:

10 *a*1 +b*2 =640

10 *a*2 +b*3 =656


llama_print_timings:        load time =  1165.00 ms
llama_print_timings:      sample time =    41.11 ms /    32 runs   (    1.28 ms per token)
llama_print_timings: prompt eval time =  1147.76 ms /     7 tokens (  163.97 ms per token)
llama_print_timings:        eval time =  5113.92 ms /    31 runs   (  164.97 ms per token)
llama_print_timings:       total time =  6323.27 ms
</code></pre></div>
</details>
<details>
<summary>Arithmetic - no grammar</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n'                                            
main: build = 645 (fd0eb66)
main: seed  = 1686286388
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Some arithmetic practice:

\begin{code}
package main

import (
    &quot;fmt&quot;
)

func main() {
    fmt.Println(
llama_print_timings:        load time =  1171.65 ms
llama_print_timings:      sample time =    21.37 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1153.88 ms /     7 tokens (  164.84 ms per token)
llama_print_timings:        eval time =  4991.68 ms /    31 runs   (  161.02 ms per token)
llama_print_timings:       total time =  6187.91 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n'                                            
main: build = 645 (fd0eb66)
main: seed  = 1686286388
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Some arithmetic practice:

\begin{code}
package main

import (
    "fmt"
)

func main() {
    fmt.Println(
llama_print_timings:        load time =  1171.65 ms
llama_print_timings:      sample time =    21.37 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1153.88 ms /     7 tokens (  164.84 ms per token)
llama_print_timings:        eval time =  4991.68 ms /    31 runs   (  161.02 ms per token)
llama_print_timings:       total time =  6187.91 ms
</code></pre></div>
</details>
<details>
<summary>JSON</summary>
<div data-snippet-clipboard-copy-content="% ./main -m $LLAMA_30B_Q4_0 -n 64 -p $'A bit about me:\n\n' --grammar-file grammars/json.gbnf
main: build = 674 (e550234)
main: seed  = 1688014289
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 64, n_keep = 0


main: grammar:
root ::= object 
object ::= [{] ws object_11 [}] 
value ::= object | array | string | number | boolean 
array ::= [[] ws array_15 []] 
string ::= [&quot;] string_16 [&quot;] ws 
number ::= number_17 number_18 ws 
boolean ::= boolean_19 ws 
ws ::= [ <U+0009><U+000A>] ws | 
object_8 ::= string [:] ws value object_10 
object_9 ::= [,] ws string [:] ws value 
object_10 ::= object_9 object_10 | 
object_11 ::= object_8 | 
array_12 ::= value array_14 
array_13 ::= [,] ws value 
array_14 ::= array_13 array_14 | 
array_15 ::= array_12 | 
string_16 ::= [ <U+0009>!#-[]-~] string_16 | 
number_17 ::= [-] | 
number_18 ::= [0-9] number_18 | [0-9] 
boolean_19 ::= [t] [r] [u] [e] | [f] [a] [l] [s] [e] 

 A bit about me:

{
	&quot;fullName&quot;: &quot;Ramon Rodriguez&quot;,
	&quot;username&quot;: &quot;ramon&quot;,
	&quot;email&quot;: &quot;ramon@mail.com&quot;,
	&quot;phoneNumber&quot;: &quot;+1234567890&quot;,
	&quot;address&quot;: {
		
llama_print_timings:        load time =  1273.70 ms
llama_print_timings:      sample time =    82.93 ms /    64 runs   (    1.30 ms per token)
llama_print_timings: prompt eval time =  1256.36 ms /     8 tokens (  157.04 ms per token)
llama_print_timings:        eval time = 10432.05 ms /    63 runs   (  165.59 ms per token)
llama_print_timings:       total time = 11795.36 ms"><pre><code>% ./main -m $LLAMA_30B_Q4_0 -n 64 -p $'A bit about me:\n\n' --grammar-file grammars/json.gbnf
main: build = 674 (e550234)
main: seed  = 1688014289
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 64, n_keep = 0


main: grammar:
root ::= object 
object ::= [{] ws object_11 [}] 
value ::= object | array | string | number | boolean 
array ::= [[] ws array_15 []] 
string ::= ["] string_16 ["] ws 
number ::= number_17 number_18 ws 
boolean ::= boolean_19 ws 
ws ::= [ &lt;U+0009&gt;&lt;U+000A&gt;] ws | 
object_8 ::= string [:] ws value object_10 
object_9 ::= [,] ws string [:] ws value 
object_10 ::= object_9 object_10 | 
object_11 ::= object_8 | 
array_12 ::= value array_14 
array_13 ::= [,] ws value 
array_14 ::= array_13 array_14 | 
array_15 ::= array_12 | 
string_16 ::= [ &lt;U+0009&gt;!#-[]-~] string_16 | 
number_17 ::= [-] | 
number_18 ::= [0-9] number_18 | [0-9] 
boolean_19 ::= [t] [r] [u] [e] | [f] [a] [l] [s] [e] 

 A bit about me:

{
	"fullName": "Ramon Rodriguez",
	"username": "ramon",
	"email": "ramon@mail.com",
	"phoneNumber": "+1234567890",
	"address": {
		
llama_print_timings:        load time =  1273.70 ms
llama_print_timings:      sample time =    82.93 ms /    64 runs   (    1.30 ms per token)
llama_print_timings: prompt eval time =  1256.36 ms /     8 tokens (  157.04 ms per token)
llama_print_timings:        eval time = 10432.05 ms /    63 runs   (  165.59 ms per token)
llama_print_timings:       total time = 11795.36 ms
</code></pre></div>
</details>
<details>
<summary>"JSON" - no grammar</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A bit about me:\n\n'                                                                          
main: build = 645 (fd0eb66)
main: seed  = 1686286615
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A bit about me:

A former teacher, now a full-time writer. I am the author of two novels: _The Man in the Moon_ and _The Riddle
llama_print_timings:        load time =  1291.32 ms
llama_print_timings:      sample time =    21.48 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1274.63 ms /     8 tokens (  159.33 ms per token)
llama_print_timings:        eval time =  4990.01 ms /    31 runs   (  160.97 ms per token)
llama_print_timings:       total time =  6306.01 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A bit about me:\n\n'                                                                          
main: build = 645 (fd0eb66)
main: seed  = 1686286615
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A bit about me:

A former teacher, now a full-time writer. I am the author of two novels: _The Man in the Moon_ and _The Riddle
llama_print_timings:        load time =  1291.32 ms
llama_print_timings:      sample time =    21.48 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1274.63 ms /     8 tokens (  159.33 ms per token)
llama_print_timings:        eval time =  4990.01 ms /    31 runs   (  160.97 ms per token)
llama_print_timings:       total time =  6306.01 ms
</code></pre></div>
</details>
<details>
<summary>Japanese</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' --grammar-file grammars/japanese.gbnf
main: build = 674 (e550234)
main: seed  = 1688013430
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_2 root_5 
jp-char ::= hiragana | katakana | punctuation | cjk 
root_2 ::= jp-char root_2 | jp-char 
root_3 ::= [ <U+0009><U+000A>] root_4 
root_4 ::= jp-char root_4 | jp-char 
root_5 ::= root_3 root_5 | 
hiragana ::= [<U+3041>-<U+309F>] 
katakana ::= [<U+30A1>-<U+30FF>] 
punctuation ::= [<U+3001>-<U+303E>] 
cjk ::= [<U+4E00>-<U+9FFF>] 

 Building a website can be done in 10 simple steps (from the original Japanese):

一、目的は何なのか
二、お客さまを思い出して
三、お客さまのこと
llama_print_timings:        load time =  2957.19 ms
llama_print_timings:      sample time =    42.67 ms /    32 runs   (    1.33 ms per token)
llama_print_timings: prompt eval time =  2941.56 ms /    21 tokens (  140.07 ms per token)
llama_print_timings:        eval time =  5384.28 ms /    31 runs   (  173.69 ms per token)
llama_print_timings:       total time =  8387.61 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' --grammar-file grammars/japanese.gbnf
main: build = 674 (e550234)
main: seed  = 1688013430
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_2 root_5 
jp-char ::= hiragana | katakana | punctuation | cjk 
root_2 ::= jp-char root_2 | jp-char 
root_3 ::= [ &lt;U+0009&gt;&lt;U+000A&gt;] root_4 
root_4 ::= jp-char root_4 | jp-char 
root_5 ::= root_3 root_5 | 
hiragana ::= [&lt;U+3041&gt;-&lt;U+309F&gt;] 
katakana ::= [&lt;U+30A1&gt;-&lt;U+30FF&gt;] 
punctuation ::= [&lt;U+3001&gt;-&lt;U+303E&gt;] 
cjk ::= [&lt;U+4E00&gt;-&lt;U+9FFF&gt;] 

 Building a website can be done in 10 simple steps (from the original Japanese):

一、目的は何なのか
二、お客さまを思い出して
三、お客さまのこと
llama_print_timings:        load time =  2957.19 ms
llama_print_timings:      sample time =    42.67 ms /    32 runs   (    1.33 ms per token)
llama_print_timings: prompt eval time =  2941.56 ms /    21 tokens (  140.07 ms per token)
llama_print_timings:        eval time =  5384.28 ms /    31 runs   (  173.69 ms per token)
llama_print_timings:       total time =  8387.61 ms
</code></pre></div>
</details>
<details>
<summary>Japanese - no grammar</summary>
<div data-snippet-clipboard-copy-content="% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' 
main: build = 674 (e550234)
main: seed  = 1688013483
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Building a website can be done in 10 simple steps (from the original Japanese):

1. Determine your goal for your site.
2. Make a plan.
3. Select the domain name.
4. Choose web
llama_print_timings:        load time =  2955.05 ms
llama_print_timings:      sample time =    22.96 ms /    32 runs   (    0.72 ms per token)
llama_print_timings: prompt eval time =  2937.10 ms /    21 tokens (  139.86 ms per token)
llama_print_timings:        eval time =  5032.41 ms /    31 runs   (  162.34 ms per token)
llama_print_timings:       total time =  8013.71 ms"><pre><code>% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' 
main: build = 674 (e550234)
main: seed  = 1688013483
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Building a website can be done in 10 simple steps (from the original Japanese):

1. Determine your goal for your site.
2. Make a plan.
3. Select the domain name.
4. Choose web
llama_print_timings:        load time =  2955.05 ms
llama_print_timings:      sample time =    22.96 ms /    32 runs   (    0.72 ms per token)
llama_print_timings: prompt eval time =  2937.10 ms /    21 tokens (  139.86 ms per token)
llama_print_timings:        eval time =  5032.41 ms /    31 runs   (  162.34 ms per token)
llama_print_timings:       total time =  8013.71 ms
</code></pre></div>
</details>
<h2 dir="auto">Approach</h2>
<h3 dir="auto">Grammar API</h3>
<p dir="auto">The <code>llama</code> API accepts a data structure representing a context-free grammar over 32-bit code points:</p>
<div data-snippet-clipboard-copy-content="    // grammar element type
    enum llama_gretype {
        // end of rule definition
        LLAMA_GRETYPE_END            = 0,

        // start of alternate definition for rule
        LLAMA_GRETYPE_ALT            = 1,

        // non-terminal element: reference to rule
        LLAMA_GRETYPE_RULE_REF       = 2,

        // terminal element: character (code point)
        LLAMA_GRETYPE_CHAR           = 3,

        // modifies a preceding LLAMA_GRETYPE_CHAR or LLAMA_GRETYPE_CHAR_ALT to
        // be an inclusive range ([a-z])
        LLAMA_GRETYPE_CHAR_RNG_UPPER = 4,

        // modifies a preceding LLAMA_GRETYPE_CHAR or
        // LLAMA_GRETYPE_CHAR_RNG_UPPER to add an alternate char to match ([ab], [a-zA])
        LLAMA_GRETYPE_CHAR_ALT       = 5,
    };

    typedef struct llama_grammar_element {
        enum llama_gretype type;
        uint32_t           value; // Unicode code point or rule ID
    } llama_grammar_element;

    LLAMA_API struct llama_grammar * llama_grammar_init(
            const llama_grammar_element ** rules,
                                 size_t    n_rules,
                                 size_t    start_rule_index);"><pre><code>    // grammar element type
    enum llama_gretype {
        // end of rule definition
        LLAMA_GRETYPE_END            = 0,

        // start of alternate definition for rule
        LLAMA_GRETYPE_ALT            = 1,

        // non-terminal element: reference to rule
        LLAMA_GRETYPE_RULE_REF       = 2,

        // terminal element: character (code point)
        LLAMA_GRETYPE_CHAR           = 3,

        // modifies a preceding LLAMA_GRETYPE_CHAR or LLAMA_GRETYPE_CHAR_ALT to
        // be an inclusive range ([a-z])
        LLAMA_GRETYPE_CHAR_RNG_UPPER = 4,

        // modifies a preceding LLAMA_GRETYPE_CHAR or
        // LLAMA_GRETYPE_CHAR_RNG_UPPER to add an alternate char to match ([ab], [a-zA])
        LLAMA_GRETYPE_CHAR_ALT       = 5,
    };

    typedef struct llama_grammar_element {
        enum llama_gretype type;
        uint32_t           value; // Unicode code point or rule ID
    } llama_grammar_element;

    LLAMA_API struct llama_grammar * llama_grammar_init(
            const llama_grammar_element ** rules,
                                 size_t    n_rules,
                                 size_t    start_rule_index);
</code></pre></div>
<h3 dir="auto">Sampling</h3>
<p dir="auto">The grammar sampling code models a nondeterministic pushdown automaton, maintaining N stacks for the possible parse states. Sampling a token is done in two steps: a sampling API that filters candidates to those that match one of the parse stacks (<code>llama_sample_grammar</code>) and adding the chose token to the grammar (<code>llama_grammar_accept_token</code>).</p>
<h3 dir="auto">Examples</h3>
<p dir="auto">Adds <code>--grammar</code> and <code>--grammar-file</code> arguments to <code>main</code> taking a simple extended BNF to constrain generations. The parser for this format is implemented in <code>examples/grammar-parser.{h,cpp}</code>:</p>
<div data-snippet-clipboard-copy-content="// ... Supports character
// ranges, grouping, and repetition operators. As an example, a grammar for
// arithmetic might look like:
//
// root  ::= expr
// expr  ::= term ([-+*/] term)*
// term  ::= num | &quot;(&quot; space expr &quot;)&quot; space
// num   ::= [0-9]+ space
// space ::= [ \t\n]*"><pre><code>// ... Supports character
// ranges, grouping, and repetition operators. As an example, a grammar for
// arithmetic might look like:
//
// root  ::= expr
// expr  ::= term ([-+*/] term)*
// term  ::= num | "(" space expr ")" space
// num   ::= [0-9]+ space
// space ::= [ \t\n]*
</code></pre></div>
<p dir="auto">The <code>root</code> rule identifies the start of the grammar.</p>
<p dir="auto"><del>## Caveats</del></p>
<ul dir="auto">
<li><del>the binary format makes the code harder to understand and more brittle</del></li>
<li><del>the grammar contemplates 16-bit chars but it's just being applied to the 8-bit UTF-8 chars in token strings currently</del></li>
<li><del>the 1-char lookahead sampling is probably biasing generations in a weird way; further investigation on quality of outputs is probably needed</del></li>
</ul>
    </div>
  </task-lists>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Journalists should be skeptical of all sources including scientists (340 pts)]]></title>
            <link>https://natesilver.substack.com/p/journalists-should-be-skeptical-of</link>
            <guid>36818896</guid>
            <pubDate>Fri, 21 Jul 2023 20:01:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://natesilver.substack.com/p/journalists-should-be-skeptical-of">https://natesilver.substack.com/p/journalists-should-be-skeptical-of</a>, See on <a href="https://news.ycombinator.com/item?id=36818896">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>I’m not usually one for scandals. My eyes glaze over at Congressional hearings. I’ve never read the Mueller Report. There are usually too many threads to unwind, and too many competing claims to evaluate. But I’m going to make an exception here, because we have a scandal where the facts are relatively simple and clear — but which was nevertheless extremely consequential.</p><p><span>Here’s the scandal. In March 2020, a group of scientists — in particular</span></p><p><span>, Kristian G. Andersen the of The Scripps Research Institute, Andrew Rambaut of The University of Edinburgh, Edward C. Holmes of the University of Sydney, and Robert F. Garry of Tulane University — published a paper in </span><em>Nature Medicine</em><span> that seemingly contradicted their true beliefs about COVID’s origins and which they knew to be misleading. The </span><a href="https://www.nature.com/articles/s41591-020-0820-9" rel="">paper</a><span>, “The proximal origin of SARS-CoV-2”, has been </span><a href="https://scholar.google.com/scholar?cites=4180430536993184356&amp;as_sdt=5,33&amp;sciodt=0,33&amp;hl=en" rel="">cited more than 5,900 times</a><span> and was enormously influential in shaping the debate about the origins of COVID-19.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp" width="820" height="385" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:385,&quot;width&quot;:820,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:31870,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>We know this because of a series of leaked and </span><a href="https://foia.state.gov/learn/foia.aspx" rel="">FOIAed</a><span> emails and Slack messages that have been reported on by </span><em>Public</em><span>, </span><em>Racket News, The Intercept </em><span>and </span><em>The Nation </em><span>along with other small, independent media outlets. You can find a detailed summary of the claims and a copy of the emails and messages </span><a href="https://public.substack.com/p/covid-origins-scientist-denounces" rel="">here</a><span> at </span><em>Public</em><span>. There’s also good context around the messages </span><a href="https://usrtk.org/covid-19-origins/timeline-the-proximal-origin-of-sars-cov-2/" rel="">here</a><span> (very detailed) or </span><a href="https://rogerpielkejr.substack.com/p/covidgate" rel="">here</a><span> and </span><a href="https://rogerpielkejr.substack.com/p/the-truth-is-never-going-to-come" rel="">here</a><span> (more high-level). </span></p><p><span>The messages show that the authors were highly uncertain about COVID’s origins — and if anything, they leaned more toward a lab leak than a spillover from an animal source. But none of that was expressed in the “Proximal Origin” paper, which instead said that </span><strong>“we do not believe that any type of laboratory-based scenario is plausible”.</strong><span> Granted, there is a little bit of ass-covering — “More scientific data could swing the balance of evidence to favor one hypothesis over another,” they also wrote in the paper. But the message — natural origin good, lab leak bad — was received clearly enough by mainstream news outlets. “No, the new coronavirus wasn't created in a lab, scientists say”, </span><a href="https://www.cbc.ca/news/science/coronavirus-wasnt-created-in-lab-no-signs-genetic-engineering-1.5508735" rel="">reported</a><span> the CBC in covering the paper. “COVID-19 coronavirus epidemic has a natural origin” was the </span><a href="https://www.sciencedaily.com/releases/2020/03/200317175442.htm" rel="">headline</a><span> at Science Daily.</span></p><p><span>In the Slack and email messages, the authors worked to manipulate the media narrative about COVID-19’s origins and to ensure that their private uncertainty wasn’t conveyed in conversations with reporters. They also thought they were going to get away with it. “The truth is never going to come out ”, </span><a href="https://twitter.com/mbalter/status/1679098392587255809/photo/1" rel="">wrote</a><span> Rambaut in one message. This went beyond mere motivated reasoning. There was an enormous gap between what the authors believed privately and what they stated publicly, including in the “Proximal Origin” paper — again, see the above links for more detail.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png" width="1456" height="182" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:182,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:93385,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>What were the authors’ motivations to mislead the public? I think that’s also pretty straightforward. In fact, you can find prominent virologists </span><a href="https://www.nature.com/articles/d41586-021-01383-3" rel="">quoted on record</a><span> as to why the lab leak theory was so </span><em>problematic</em><span> — even if it wasn’t necessarily </span><em>wrong</em><span>. The problems fall into three buckets:</span></p><ol><li><p><span>Evidence of a lab leak could cause a political backlash — understandably, given that COVID has killed almost 7 million people — resulting in a reduction in funding for gain-of-function research and other virological research. That’s potentially important to the authors or the authors’ bosses — and the authors were </span><a href="https://twitter.com/HansMahncke/status/1682193300055285760?s=20" rel="">very aware</a><span> of the career implications for how the story would play out;</span></p></li><li><p><span>Evidence of a lab leak could </span><a href="https://www.nytimes.com/2023/02/27/business/energy-department-theory-coronavirus-china.html" rel="">upset China and undermine research collaborations</a><span>;</span></p></li><li><p><span>Evidence of a lab leak could provide validation to Trump and Republicans who </span><a href="https://www.politico.com/news/2021/06/15/wuhan-lab-trump-officials-covid-494700" rel="">touted the theory</a><span> — remember, all of this was taking place during an election year, and medical, epidemiological and public health experts had few reservations about </span><a href="https://www.cnn.com/2020/06/05/health/health-care-open-letter-protests-coronavirus-trnd/index.html" rel="">weighing in on political matters</a><span>.</span></p></li></ol><p><span>To be clear, I’m not sure how COVID originated either. I’d “buy” the lab leak at a 50 percent likelihood (I think </span><a href="https://alexwasburne.substack.com/p/the-short-case-for-a-lab-origin" rel="">this</a><span> is pretty convincing) and sell it at 80 percent, which still leaves a lot of wiggle room for me to be persuaded one way or the other.</span></p><p>But I think this is a big scandal either way. As someone who has spent a lot of time trying to convey statistical and epistemic uncertainty to the public, I’m deeply disappointed by the scientists’ conduct here and how unmoored they were from any attempt at truth-seeking.</p><p><span>The COVID origins story has also been a </span><a href="https://www.slowboring.com/p/the-medias-lab-leak-fiasco" rel="">journalistic fiasco</a><span>, with the lab leak having been dismissed as a “</span><a href="https://www.nytimes.com/2020/02/17/business/media/coronavirus-tom-cotton-china.html" rel="">conspiracy theory</a><span>” and as </span><a href="https://www.nytimes.com/2020/03/08/technology/coronavirus-misinformation-social-media.html" rel="">misinformation</a><span> even though many prominent scientists believed it to be plausible all along. Perhaps it’s tempting to give the media a pass — they </span><em>were</em><span> manipulated by the “Proximal Origin” authors, after all. But I’m not inclined to, for two reasons.</span></p><p><span>First, the coverage of the recently leaked emails and Slack messages at major center-left outlets like The New York Times has been pathetic. The Times </span><a href="https://www.nytimes.com/2023/07/11/us/politics/covid-lab-leak-fauci.html" rel="">portrayed</a><span> Andersen as the victim of a Republican witch-hunt — rather than someone at the center of a major scientific scandal of his own making.</span></p><p><span>And second, journalists ought to have decent bullshit detectors — including toward scientists, academics and other experts.</span></p><p><span>Maybe you think Andersen </span><em>et. al.</em><span> are bad apples, but the messages make clear that they were speaking for a pretty broad swath of the scientific community. Still — and maybe this is wishful thinking — but I’m going to assert that people like him are in the minority among scientists. I fairly often speak with scientists and academics myself — especially when I’m working on a research-driven book project, as I am now — and those experiences are overwhelmingly positive.</span></p><p><span>And yet, even if the incidence of bad apples is relatively rare among scientists and academics — rarer than it might be among politicians or other groups that journalists intrinsically treat with more skepticism — it’s clearly not </span><em>exceedingly</em><span> rare. It was just this week that the </span><a href="https://stanforddaily.com/2023/07/19/stanford-president-resigns-over-manipulated-research-will-retract-at-least-3-papers/" rel="">president of Stanford was forced to resign in a research scandal</a><span>. (Perhaps not coincidently, the scandal was broken by the student newspaper, </span><em>The Stanford Daily</em><span>, and not by a major center-left outlet like The Times.)</span></p><p><span>I also think journalists are more prone toward being manipulated by bad apples in academia and science than they were ten or twenty years ago. As a result of</span><a href="https://www.nytimes.com/2021/09/08/us/politics/how-college-graduates-vote.html" rel=""> increasing educational polarization</a><span>, both journalists and the expert class of scientists and academics are far more aligned politically than they once were (the very large majority are left-of-center and vote Democratic in American elections). Even if “trust the science” or “trust the experts” is </span><em>usually</em><span> right — and I think it </span><em>usually</em><span> is right! — it leaves an opening for bad apples like Andersen to exploit the trust that honest scientists have worked so hard to earn.</span></p><p><span>There’s also a generational divide in journalism, with younger journalists tending to be more openly left/progressive than their older peers — and tending to be more </span><a href="https://www.vocabulary.com/dictionary/Manichean" rel="">Manichean</a><span> in dividing the world between good and evil rather than proceeding from the notion that people and news stories are complicated and it’s not particularly their job to pass moral judgment. It’s slightly amusing that The Times fired their Pulitzer Prize-winning coronavirus reporter in middle of the pandemic — a reporter who </span><a href="https://donaldgmcneiljr1954.medium.com/how-i-learned-to-stop-worrying-and-love-the-lab-leak-theory-f4f88446b04d" rel="">saw the lab leak theory as credible</a><span> — and replaced him with another reporter who </span><a href="https://www.cnn.com/2021/05/27/media/covid-19-origins-lab-leak-media/index.html" rel="">dismissed discussion of the lab leak as “racist”</a><span>. </span></p><p>But this really isn’t complicated. All I’m suggesting is that journalists ought to treat scientists like they do any other source — that is to say, with an appropriate dose of skepticism.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Big Tech as the New Big Tobacco (168 pts)]]></title>
            <link>https://www.bigtechwiki.com/index.php/Big_Tech_as_the_New_Big_Tobacco</link>
            <guid>36818640</guid>
            <pubDate>Fri, 21 Jul 2023 19:44:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bigtechwiki.com/index.php/Big_Tech_as_the_New_Big_Tobacco">https://www.bigtechwiki.com/index.php/Big_Tech_as_the_New_Big_Tobacco</a>, See on <a href="https://news.ycombinator.com/item?id=36818640">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="bodyContent">
				<p>From BigTechWiki</p>
				
				
				<p><a href="#column-one">Jump to navigation</a><a href="#searchInput">Jump to search</a></p><!-- start content -->
				<div id="mw-content-text" lang="en" dir="ltr"><ul><li>Republicans and Democrats began to view Big Tech in the light Big Tobacco was, with one saying the comparison was “an appropriate analogy”</li></ul>
<ul><li>Lawmakers like Republicans Ken Buck and Cynthia Lummis and Democrat Ed Markey compared Facebook and Big Tech to Big Tobacco. Markey described Instagram as “that first childhood cigarette, meant to get teens hooked early.” Lummis agreed that comparing Facebook and Big Tech to Big Tobacco was an “appropriate analogy.” Republican Rep. Bill Johnston compared Big Tech CEOs to those from large tobacco companies, accusing the tech firms of being equally dangerous to society. Buck compared big tech to big tobacco, saying they were “harming our kids for profit.” Richard Blumenthal, who led a lawsuit against Big Tobacco in the 1990s as AG of CT, said Facebook and Big Tech were facing a “Big Tobacco moment,” comparing Facebook’s strategy papers with those done by Tobacco companies on reaching middle schoolers.<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup></li></ul>
<ul><li>Big Tech directly followed in Big Tobacco’s footsteps by funding academic research
<ul><li>Big Tobacco had a long history of commissioning and funding academic research to pull focus away from the proven harms of their products. Big Tech similarly started to fund institutions to ensure the “ethical development” of their technology, which led to questions about conflicts of interest and research independence. Researchers from Cornell noted that Big Tech and Big Tobacco’s funding of scientific research and development were similar in both industries: “Pump vast sums of money” into researching the problems they were creating.<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup></li>
<li>Both Big Tech and Big Tobacco wanted to influence research to ensure their industries sustained support and were seen as socially responsible. Researchers from Cornell said Big Tobacco invested in Academia in order to influence the research questions of those studying tobacco, hoping to find friendly academics who could be leveraged and recast the companies as socially responsible. Big Tobacco’s funding agencies worked to maintain an impartial and scientific image, even as it mainly funded research that was not about tobacco’s health impacts.</li>
<li>Much like Big Tobacco, the Academics that Big Tech invested in routinely failed to disclose their funding from Big Tech, which created a false impression of independence. The whole goal of funding the research was to exploit the confidence that is had in academia and research, because Think Tanks and organizations were treated as “neutral arbiters” by journalists and lawmakers.</li>
<li>At Big Tech funded agencies, public relations officials and lawyers were involved in plotting the overall research direction and tone. Internal Google documents directed scientists to “strike a positive tone” in their research. Further internal memos from Google showed that the company intended to use friendly academics as a key aim in its strategy to lobby against the EU’s Digital Markets Act. Big Tobacco has given hundreds of millions to research over the years and their efforts spanned across the globe. Big tobacco started its own research group, The Tobacco Industry Research Committee, in 1964 and pumped more than $130 million into the effort by 1986.</li>
<li>Big Tobacco continued this trend of investing in research across the globe, giving tens of thousands of Pounds to two think tanks in the UK that advised the government on Tobacco laws. The two think tanks criticized plans to force retailers to sell cigarettes in unbranded cartons, which was a measure supported by cancer charities and opposed by Big Tobacco. In 2019, it was reported that Tobacco companies had contributed to at least 106 think tanks in two dozen countries. The think tanks they contributed to were found to oppose plain cigarette packaging, had written to regulators in support of new tobacco products or promoted industry funded research. Big Tobacco also contributed to The Heritage Foundation, the Cato Institute and Americans For Tax Reform. As Big Tech faced pressure from proposed tech legislation, they significantly increased their spending on outside organizations, giving to nearly 771 third party organizations since 2015. A significant spike in funding of outside groups by Big Tech after federal and state officials increased scrutiny on their anti-competitive behaviors. Amazon went from contributing to 45 outside organizations in 2015 to 251 outside organizations in 2020. Google more than doubled the amount of outside groups it gave to in 2018 and 2019 compared to 2017 as it faced pressures from California’s consumer privacy law. All of this increased spending by Big Tech put a heavy pressure on academic staff to seek external sources of funding.<sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup></li>
<li>Who Big Tech gives to and how much they contributed is murky, as think tanks and nonprofits aren’t required to disclose their funding. Despite Amazon, Facebook and Google voluntarily disclosing who they contributed to, the companies did not divulge the amounts of their contributions.</li>
<li>However, it was found that in the past 5 years, six leading academic institutes in the EU had taken tens of millions of pounds of funding from Google, Facebook, Amazon and Microsoft to research issues linked to the tech firm’s business models. The Institute For Ethics In Artificial Intelligence at the Technical University of Munich received a $7.5 million grant from Facebook in 2019. The Humboldt Institute for Internet and Society in Berlin accepted almost 14 million Euros from Google since it was founded in 2012.<sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup></li>
<li>In the U.S., Big Tech individually contributed to various renowned and highly influential think tanks and nonprofits. Those think tanks and nonprofits included but are not limited to the Cato Institute, Heritage Foundation, International Center for Law &amp; Economics, the Information Technology &amp; Innovation foundation and the Global Antitrust Institute at George Mason University.</li>
<li>Big Tech was rewarded handsomely for their contributions to nonprofits and think tanks. Some lobbyists, scholars and think tank officials argued that Google’s donations to nonprofit groups helped explain why it had avoided damaging regulatory and enforcement decisions in the U.S. Further, the major nonprofits that Big Tech had contributed to helped facilitate introductions between the government and Big Tech.</li>
<li>The Global Antitrust Institute at George Mason University had trained more than 850 foreign judges and regulators on Antitrust at their seminars.</li>
<li>While not all of the nonprofits and think tanks held events on behalf of Big Tech, many did advocate for Big Tech in other ways. The Cato Institute argued publicly that people should be “extremely skeptical about predictions of entrenched monopoly power” for big tech. The Progressive Policy Institute president and founder Will Marshall published an op-ed arguing against breaking up Big Tech monopolies while simultaneously calling them “innovative and successful.”</li></ul></li>
<li>Big Tobacco was a lobbying “juggernaut” that invented the special interest lobbying model Big Tech used
<ul><li>In 1998, the Big Tobacco spent nearly $73 million on federal lobbying and employed over 200 lobbyists. When adjusted for inflation, the #73 million in 1998 equated to $122 million in 2021. The Dean of Harvard’s graduate school of arts and sciences said Big Tobacco had “invested in the kind of special interest lobbying” that characterized the late 20th and early 21st century American politics. Big Tobacco was known for their “giant spending” and effective lobbying.</li>
<li>Big Tobacco was said to have a “substantial” presence on Capitol Hill and had a lobbying effort so large it could only be described as a “juggernaut” by OpenSecrets. The Dean of Harvard’s graduate school of arts and sciences said Big Tobacco spent “boatloads” of money in Congress to prevent regulation as more information became public about the harm their products caused. Still to this day, Big Tobacco employed a massive amount of lobbyists, with Altria employing at least 409 lobbyists in 49 states and Reynolds employing 257 lobbyists in 39 states.</li>
<li>Big Tobacco were also big spenders politically in the 90’s and early 2000’s. In 1996, the tobacco industry contributed more than $10 million to political campaigns. In 1998, they contributed more than $8.6 million. In 2000, Big Tobacco again spent more than $8.6 million on political campaigns. And in 2002, Big Tobacco spent $9.29 million on political campaigns. Reynolds American and Altria Group also donated $1.5 million to Donald Trump’s inauguration.</li></ul></li>
<li>Big Tech invested in lobbying to the same degree that Big Tobacco did and have similarly become Washington lobbyists biggest cash cow
<ul><li>A June 2021 NY Times headline read “Tech Giants, Fearful of Proposals to Curb Them, Blitz Washington With Lobbying.” And in 2020, Big Tech spent more on lobbying than any other industry at a combined $51.72 million. Facebook spent the most out of any company in 2020 and the same year spent the most it ever had on lobbying: $19.68 million. Following in second was Amazon, who spent $17.86 million on lobbying, which was also the most the company had ever spent in a year on lobbying. Google spent $7.53 million on lobbying and Apple spent $6.6 million on lobbying in 2020. When asked what they were looking to achieve with their lobbying, none of the tec companies would detail their targets.<sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup></li></ul></li>
<li>Big Tobacco created the model for Big Tech’s pre-empting legislation and regulation Big Tobacco offered to fund research and write legislation that would carve ou several loopholes and prevent stricter rules in the future
<ul><li>Starting in the 1980s, Big Tobacco worked to pre-empt legislation with their own corporate-written legislation, a trend that continued into recent policy debates over the legal age to buy tobacco products. Big Tobacco had worked to pre-empt laws to raise the legal age to buy smoking products from 18 to 21 by pushing new legislation that would make enforcement difficult and nullify tougher local laws. A spokesman for the Campaign For Tobacco-Free Kids argued that Big Tobacco were “masters at proposing or supporting a bill that looked good on the surface but often included provisions that [were] harmful to public health.”</li>
<li>By pre-empting legislation, Tobacco was able to halt any local efforts to limit how tobacco used. It was said that by pre-empting legislation with their own corporate-backed bills, Big Tobacco could effectively tie the hands of city governments who wanted to limit tobacco use further. Tobacco companies had been working to pre-empt legislation for decades, including pre-empting versions of the Clean Indoor Air Acts in the 1980s and 1990s. In 1994, a Philip Morris Employee even wrote that the company was “dead serious about achieving pre-emption in all 50 states.”</li></ul></li>
<li>Big Tech followed suit and began supporting legislation they felt they could control to build goodwill after scandals ravaged the industry
<ul><li>Following the Cambridge Analytica scandal, Facebook appeared to back some government regulation. The company launched a new campaign that offered concessions on the Big Tech regulatory debate to generate some goodwill while trying to reframe the larger debate on its own terms. Zuckerberg said in testimony that he welcomed privacy and misinformation regulation as long as it was the “right regulation.”</li>
<li>Zuckerberg went so far as to call on congress to make “thoughtful reform” of Section 230, which safeguarded tech platforms from being held liable for content individual users posted. Zuckerberg said a company’s liability protection under Section 230 should be conditional on their ability to prove they can moderate harmful content – regardless if it successfully removed all harmful content. Zuckerberg's proposal for Section 230 immunity reforms “could theoretically shore up Facebook’s power” as it forced smaller social media companies and startups to develop costly content moderation systems. However, Facebook executives testified before Congress that they wanted Congress to pre-empt local laws that likely included stricter privacy protections than a federal bill.</li>
<li>Ironically, just weeks before Zuckerberg’s 2018 testimony, Facebook poured hundreds of thousands into fighting a privacy ballot initiative in California. Facebook gave $200,000 to a PAC dedicated to defeating “a state ballot initiative that would expand Californian’s privacy controls. After his testimony, Facebook withdrew support for the group and then declined to say if they were involved in other efforts to oppose privacy legislation.</li></ul></li>
<li>Big Tech also used more subtle means to influence policy, like leaning heavily and quietly on trade associations.
<ul><li>A Big Tech lobbyist admitted that there was “strength in numbers” and said Big Tech could use trade associations to “do a little bit of heavy lifting.” Big Tech had increasingly been leaning on industry associations to influence public policy in Washington. Lobbyist Kate Mills, a partner at a Amazon-hired lobbying firm, admitted that Big Tech’s strategy involved leaning heavily and quietly on trade associations.</li>
<li>Amazon, Facebook and Google funded a bevy of political groups that had helped push positive polling and engaged in other “fingerprint-free tactics” designed to deter regulators seeking to break up or penalize the industry. An advocacy group funded by Big Tech had secretly written an op-ed for a local small businessman in Arizona that opposed the state’s investigation into Google. The small business owner was unaware Google had backed the group that approached him to publish the op-ed.</li>
<li>In a single year, Amazon reported spending $6.36 million on state focused “government relations efforts” in 44 states.</li></ul></li></ul>
<ul><li>Big Tech supported a wide range of industry associations that advocated and lobbied for them in D.C.
<ul><li>Big Tech has contributed to a wide range of industry associations, including but not limited to NetChoice, U.S. Chamber of Commerce, The Consumer Technology Association, The Competitive Enterprise Institute, Americans for Tax Reform, TechNet, The Small Business &amp; Entrepreneurship Council, The Internet Association and ComPITA</li>
<li>The various organizations pushed for Big Tech’s goals and defended them when they came under fire. NetChoice, “Tech’s most aggressive lobbying presence in D.C.” was a vocal opponent of antitrust action against Google. NetChoice attacked Texas’ lawsuit against Google’s anticompetitive advertising practices and attacked the DOJ’s antitrust lawsuit against Google.</li>
<li>The Consumer Technology Association spent $10 million on lobbying for Big Tech and opposed local tech regulations on their behalf. The Consumer Technology Association counted Facebook, Alphabet, Apple and Amazon as members. The group opposed proposed right to repair laws in Nevada and elsewhere.</li>
<li>Other organizations provided extra support for Big Tech when they were railing against antitrust or privacy legislation. The Progressive Policy Institute joined Google, Facebook and Amazon (all of which were donors) when the companies were fighting back against Senator Warren’s call to break up Big Tech. Facebook’s Lobbyist co-chaired a technology council at the Illinois Chamber of Commerce as the Chamber was backing the gutting of an online privacy law.</li>
<li>Facebook turned to a lower-profile trade groups such as The Internet Association and CompTIA to help block privacy legislation. 21 days after a judge ruled against Facebook in a biometric privacy act lawsuit, a Facebook backed law weakening Illinois’ biometric privacy act was introduced in the Illinois state legislature. Facebook and CompTIA were directly described as “having a hand in blocking or weakening biometric privacy bills in Montana, Washington, And Illinois.”</li>
<li>CompTIA pushed for changes to the biometric information privacy act on Facebook’s behalf, along with donating to the Republican Party of Texas, where the Republican Attorney General was the sole enforcer of the State’s Biometric Privacy Regulations</li>
<li>In 2020, Facebook launched an astroturf organization to convince federal regulators that Facebook was crucial to free speech. Facebook created American Edge to combat potential federal regulations through advertising and other means. After American Edge was formed as a nonprofit organization, it set up an accompanying social welfare group, which was a common tactic used to obscure donors. American Edge said it was important to create policies that don’t weaken companies that “share American values” as they competed globally.</li></ul></li>
<li>Much like Big Tobacco was in the 90s, Big Tech became mammoth political donors, collectively spending more than $100 million between 2016-2020
<ul><li>Most of Big Tech’s campaign contributions went towards Democrats, which increased year by year as Democrats grew louder about tech reform. Between 2016-2020, Alphabet, Google’s parent company, contributed more than $44 million in political donations. Between 2018-2020, Amazon contributed more than $26 million to political campaigns. Apple contributed more than $12 million to political campaigns between 2016-2020 and Facebook contributed more than $18 million to political campaigns between 2016-2020. Facebook also donated to all four co-sponsors of an Illinois bill to weaken the 2008 biometric information privacy act.</li></ul></li>
<li>Adding to their influence campaigns, Big Tech followed Big Tobacco’s playbook of employing revolving door techniques both Big Tobacco and Big Tech have had former employees in high level government positions and have hired former high level government officials
<ul><li>Big Tobacco found a way to deeply ingratiate themselves with the Trump and Bush administrations. Several top Bush administration staffers had backgrounds in Tobacco, including Senior Adviser Karl Rove. Vice President Pence had extensive ties to the Tobacco industry, receiving $39k in donations from RJ Reynolds and more than $60k from the industry group National Association of Convenience Stores. Senator Blumenthal noted that many of Trump’s appointees had “deep commitments to the Tobacco industry.” Former head of the FDA Scott Gottlieb worked for the e-cigarette company Kure and condemned the influence of Anti-tobacco “activists” in the FDA. The former Solicitor General Noel Francisco represented RJ Reynolds on behalf of the corporate law firm Jones Day prior to joining the federal government.</li>
<li>Big Tobacco also hired former Trump Officials as lobbyists. RJ Reynolds hired former Health and Human Services Secretary Tom Price’s deputy Chief of Staff as their lobbyists.</li>
<li>Google had an ally in the DOJ’s antitrust division during the Trump Administration and a former FTC commissioner joined a law firm Google had hired. Makan Delrahim, who led the DOJ antitrust division under Donald Trump, formerly worked on behalf of Google. After leaving office, former FTC commissioner Joshua Wright joined a law firm that represented Google before the FTC.</li></ul></li>
<li>Big Tobacco and Big Tech had a habit of running from their names after losing public trust in 2003, Philip Morris changed its name to ‘Altria Group’ after public started to feel their name “meant death”
<ul><li>Philip Morris said the name change brought “clarity” to its corporation and operating companies. In 2003, Philip Morris changed its name to ‘Altria Group’. The company said the name change brought “clarity” to its corporate structure and the relationship between the parent company to its operating companies. Philip Morris’ Senior Vice President at the time said “When people say ‘Philip Morris’, people don’t know which company you’re talking about [...] We’re more than a tobacco company.”</li>
<li>Philip Morris also owned Kraft Foods along with their tobacco company</li>
<li>In reality, the name change was a financial decision brought as a way to distance the company from the “death” people associated with them. A former FDA commissioner said Philip Morris was “running away from tobacco” with their name change. The company’s connection with Tobacco had long depressed its stock price, despite being the largest packaged goods company. To consumers, Philip Morris meant tobacco, and tobacco meant death.</li></ul></li>
<li>Facebook planned to change its company name to ‘Meta’ after facing fire for spreading misinformation
<ul><li>Facebook planned to change the name of its company to ‘Meta’ as a signal of its ambition to be known for more than social media. Facebook was reportedly investing in what it called the ‘Metaverse’ which was a digital world where people used various devices to engage with each other in a 3d environment.</li>
<li>The name change came after internal memos leaked showing the company knew about the damage it caused society. At the time of the name change, Facebook was facing some of the most intense scrutiny in its history after an internal whistleblower had leaked internal documents showing Facebook knew about the harmful effects it was having.</li>
<li>Much like Philip Morris, Facebook’s renaming was seen as a way to distance itself from the social networking controversies it was facing. TV personality Jim Cramer kind of let the cat out of the bag when he said the secret of Facebook’s valuation was because of its “habit of reinvention” Facebook’s name change was seen as directly resembling Philip Morris’ decision to change their name after controversies plagued the company. Fast Company said “for a company that brisle[d] at references to its services being akin to cigarettes, taking a page from the Big Tobacco playbook [was] a stunner.” But at the end of the day, the name change would have no impact on Facebook’s operations or executive structure. The change was largely cosmetic.<sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup></li></ul></li>
<li>Big Tech spent more on federal lobbying from 2010-202 than the nation’s largest banks from 2000-2010 or Big Tobacco from 1996-1999
<ul><li>Since 2000, the four largest Big Tech companies – Amazon, Apple, Alphabet/Google, and Facebook – have spent $465,026,307 on federal lobbying. $434,474,221 of that total has come since 2010.</li>
<li>Additionally, nine groups that the four Big Tech companies fund have spent $98,061,827 on federal lobbying since 2000. $80,400,019 of that total has come since 2010.</li>
<li>Big Tech’s federal lobbying total eclipses that of other major toxic industries: Since 2010, the nation’s largest opioid manufacturers have spent $282,292,834 on federal lobbying. America’s seven largest banks in the leadup to the financial crisis spent $194,193,858 on federal lobbying from 2000 to 2010. From 1996 to 1999, the nation’s largest tobacco companies spent $155,750,398 on federal lobbying, or $261,306,596 in 2021 dollars.</li></ul></li></ul>
<div><ol>
<li id="cite_note-1"><span><a href="#cite_ref-1">↑</a></span> <span><a rel="nofollow" href="https://www.nytimes.com/2021/10/09/technology/facebook-big-tobacco-regulation.html">https://www.nytimes.com/2021/10/09/technology/facebook-big-tobacco-regulation.html</a></span>
</li>
<li id="cite_note-2"><span><a href="#cite_ref-2">↑</a></span> <span><a rel="nofollow" href="https://arxiv.org/abs/2009.13676">https://arxiv.org/abs/2009.13676</a></span>
</li>
<li id="cite_note-3"><span><a href="#cite_ref-3">↑</a></span> <span><a rel="nofollow" href="https://www.theguardian.com/business/ng-interactive/2019/jan/23/free-market-thinktanks-tobacco-industry">https://www.theguardian.com/business/ng-interactive/2019/jan/23/free-market-thinktanks-tobacco-industry</a></span>
</li>
<li id="cite_note-4"><span><a href="#cite_ref-4">↑</a></span> <span><a rel="nofollow" href="https://www.newstatesman.com/science-tech/big-tech/2021/07/how-google-quietly-funds-europe-s-leading-tech-policy-institutes">https://www.newstatesman.com/science-tech/big-tech/2021/07/how-google-quietly-funds-europe-s-leading-tech-policy-institutes</a></span>
</li>
<li id="cite_note-5"><span><a href="#cite_ref-5">↑</a></span> <span><a rel="nofollow" href="https://www.nytimes.com/2021/06/22/technology/amazon-apple-google-facebook-antitrust-bills.html">https://www.nytimes.com/2021/06/22/technology/amazon-apple-google-facebook-antitrust-bills.html</a></span>
</li>
<li id="cite_note-6"><span><a href="#cite_ref-6">↑</a></span> <span><a rel="nofollow" href="https://www.fastcompany.com/90424503/facebook-google-amazon-are-ramping-up-their-secretive-influence-campaigns-in-dc">https://www.fastcompany.com/90424503/facebook-google-amazon-are-ramping-up-their-secretive-influence-campaigns-in-dc</a></span>
</li>
</ol></div>
<!-- 
NewPP limit report
Cached time: 20230721193631
Cache expiry: 86400
Reduced expiry: false
Complications: []
CPU time usage: 0.034 seconds
Real time usage: 0.037 seconds
Preprocessor visited node count: 51/1000000
Post‐expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 2/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 498/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%    0.000      1 -total
-->

<!-- Saved in parser cache with key btwiki_db:pcache:idhash:29-0!canonical and timestamp 20230721193631 and revision id 413. Serialized with JSON.
 -->
</div>
				
				<!-- end content -->
				
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don’t Make Fun of Renowned Dan Brown (2013) (129 pts)]]></title>
            <link>https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/</link>
            <guid>36818501</guid>
            <pubDate>Fri, 21 Jul 2023 19:35:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/">https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/</a>, See on <a href="https://news.ycombinator.com/item?id=36818501">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
		<main id="main" role="main">

		
			
<article id="post-945">
	
	<!-- .entry-header -->

	<div>
		<div>
<p><a href="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg"><img data-attachment-id="946" data-permalink="https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/dan-brown/" data-orig-file="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg" data-orig-size="236,363" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="dan brown" data-image-description="" data-image-caption="" data-medium-file="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=195" data-large-file="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=236" alt="dan brown" src="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=768" srcset="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg 236w, https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=98 98w" sizes="(max-width: 236px) 100vw, 236px"></a></p>
<p>Renowned author Dan Brown woke up in his luxurious four-poster bed in his expensive $10 million house – and immediately he felt angry. Most people would have thought that the 48-year-old man had no reason to be angry. After all, the famous writer had a new book coming out. But that was the problem. A new book meant an inevitable attack on the rich novelist by the wealthy wordsmith’s fiercest foes. The critics.</p>
</div>
<p>Renowned author Dan Brown hated the critics. Ever since he had become one of the world’s top renowned authors they had made fun of him. They had mocked bestselling book&nbsp;<i>The Da Vinci Code</i>, successful novel&nbsp;<i>Digital Fortress</i>, popular tome&nbsp;<i>Deception Point</i>, money-spinning volume&nbsp;<i>Angels &amp; Demons</i>&nbsp;and chart-topping work of narrative fiction&nbsp;<i>The Lost Symbol</i>.</p>
<p>The critics said his writing was clumsy, ungrammatical, repetitive and repetitive. They said it was full of unnecessary tautology. They said his prose was swamped in a sea of mixed metaphors. For some reason they found something funny in sentences such as “His eyes went white, like a shark about to attack.”&nbsp;<i>They even say my books are packed with banal and superfluous description</i>, thought the 5ft 9in man. He particularly hated it when they said his imagery was nonsensical. It made his insect eyes flash like a rocket.</p>
<p>Renowned author Dan Brown got out of his luxurious four-poster bed in his expensive $10 million house and paced the bedroom, using the feet located at the ends of his two legs to propel him forwards. He knew he shouldn’t care what a few jealous critics thought. His new book Inferno was coming out on Tuesday, and the 480-page hardback published by Doubleday with a recommended US retail price of $29.95 was sure to be a hit. Wasn’t it?</p>
<div>
<p><i>I’ll call my agent</i>, pondered the prosperous scribe. He reached for the telephone using one of his two hands. “Hello, this is renowned author Dan Brown,” spoke renowned author Dan Brown. “I want to talk to literary agent John Unconvincingname.”</p>
<p>“Mr Unconvincingname, it’s renowned author Dan Brown,” told the voice at the other end of the line. Instantly the voice at the other end of the line was replaced by a different voice at the other end of the line. “Hello, it’s literary agent John Unconvincingname,” informed the new voice at the other end of the line.</p>
<p>“Hello agent John, it’s client Dan,” commented the pecunious scribbler. “I’m worried about new book Inferno. I think critics are going to say it’s badly written.”</p>
<p>The voice at the other end of the line gave a sigh, like a mighty oak toppling into a great river, or something else that didn’t sound like a sigh if you gave it a moment’s thought. “Who cares what the stupid critics say?” advised the literary agent. “They’re just snobs. You have millions of fans.”</p>
<p><i>That’s true</i>, mused the accomplished composer of thrillers that combined religion, high culture and conspiracy theories. His books were read by everyone from renowned politician President Obama to renowned musician Britney Spears. It was said that a copy of&nbsp;<i>The Da Vinci Code</i>&nbsp;had even found its way into the hands of renowned monarch the Queen. He was grateful for his good fortune, and gave thanks every night in his prayers to renowned deity God.</p>
<p>“Think of all the money you’ve made,” recommended the literary agent. That was true too. The thriving ink-slinger’s wealth had allowed him to indulge his passion for great art. Among his proudest purchases were a specially commissioned landscape by acclaimed painter Vincent van Gogh and a signed first edition by revered scriptwriter William Shakespeare.</p>
<p>Renowned author Dan Brown smiled, the ends of his mouth curving upwards in a physical expression of pleasure. He felt much better. If your books brought innocent delight to millions of readers, what did it matter whether you knew the difference between a transitive and an intransitive verb?</p>
<p>“Thanks, John,” he thanked. Then he put down the telephone and perambulated on foot to the desk behind which he habitually sat on a chair to write his famous books on an Apple iMac MD093B/A computer. New book Inferno, the latest in his celebrated series about fictional Harvard professor Robert Langdon, was inspired by top Italian poet Dante. It wouldn’t be the last in the lucrative sequence, either. He had all the sequels mapped out. The Mozart Acrostic. The Michelangelo Wordsearch. The Newton Sudoku.</p>
<p>The 190lb adult male human being nodded his head to indicate satisfaction and returned to his bedroom by walking there. Still asleep in the luxurious four-poster bed of the expensive $10 million house was beautiful wife Mrs Brown. Renowned author Dan Brown gazed admiringly at the pulchritudinous brunette’s blonde tresses, flowing from her head like a stream but made from hair instead of water and without any fish in. She was as majestic as the finest sculpture by Caravaggio or the most coveted portrait by Rodin.&nbsp;<i>I like the attractive woman</i>, thought the successful man.</p>
<p>Perhaps one day, inspired by beautiful wife Mrs Brown, he would move into romantic poetry, like market-leading British rhymester John Keats.<i>That would be good</i>, opined the talented person, and got back into the luxurious four-poster bed. He felt as happy as a man who has something to be happy about and is suitably happy about it.</p>
<p>Inferno by Dan Brown 470pp, Bantam Press, rrp £20</p>

</div>

			
						</div><!-- .entry-content -->

	
	<!-- .entry-footer -->
</article><!-- #post-## -->

			
<!-- #comments -->

				<!-- .navigation -->
	
		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Slackware Linux distribution turns 30 years old (181 pts)]]></title>
            <link>https://www.theregister.com/2023/07/20/slackware_turns_30/</link>
            <guid>36818233</guid>
            <pubDate>Fri, 21 Jul 2023 19:17:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/07/20/slackware_turns_30/">https://www.theregister.com/2023/07/20/slackware_turns_30/</a>, See on <a href="https://news.ycombinator.com/item?id=36818233">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>This week the Slackware Linux project is celebrating its 30th anniversary. It is the oldest Linux distribution that is still in active maintenance and development.</p>
<p>Version 1.0 of Slackware was <a href="http://www.slackware.com/announce/1.0.php" rel="nofollow">announced</a> on the July 16, 1993, and project lead Patrick Volkerding, who still maintains the distribution today, celebrated with a <a href="https://www.patreon.com/posts/thirty-years-86196804" rel="nofollow">modest announcement</a>:</p>

<p>The current version, Slackware 15, <a href="https://www.theregister.com/2021/04/16/slackware_15_beta/">went into beta in 2021</a> and <a href="https://www.theregister.com/2022/02/07/slackware/">was released early last year</a>.</p>
<p>It wasn't the first distribution; that was arguably MCC Interim Linux, whose first release candidate, <a href="http://debian.mcc.ac.uk/non-debian/mcc-interim/old/0.97-p2-12/README" rel="nofollow">version 0.97</a> appeared just a couple of months after the kernel itself in 1991. Interim lacked a lot of characteristics which today are givens, such as a package manager. Several other distros <a href="https://www.linuxjournal.com/article/2755" rel="nofollow">followed</a> closely behind it, notably including SLS, the Softlanding Linux system. As this 2020 <a href="https://casadevall.pro/articles/2020/06/softlanding-linux-system-1.0.5/" rel="nofollow">write-up</a> shows, SLS was pretty basic, but it quickly inspired two offspring.</p>
<p>The <a href="https://www.theregister.com/2015/12/30/ian_murdock_debian_founder/">late Ian Murdock</a> was inspired to begin work on Debian by his dissatisfaction with SLS, as his original 1993 <a href="https://groups.google.com/g/comp.os.linux.development/c/Md3Modzg5TU/m/xty88y5OLaMJ" rel="nofollow">announcement</a> says. It took a couple of months to get that first release together, though, meaning that Debian is just very slightly younger. Its first release arrived about two months after Slackware 1.0, as <a href="https://www.theregister.com/2018/08/16/debian_at_25/">we noted for Debian's 25th anniversary</a>.</p>

    

<p>Slackware Linux began as a project to clean up and improve upon SLS, and since it's still going today, we have to say that it's succeeded in that mission. There are three variants of Slackware these days. The eponymous form remains an x86-32 system, whereas Slackware64 targets 21st century 64-bit x86 hardware. (There's also an <a href="https://arm.slackware.com/" rel="nofollow">Arm64 version</a> too, but the former PowerMac and IBM S/390 versions have been discontinued.) <em>The Reg</em> FOSS Desk put it onto one of our older machines for a test drive, and came away pleasantly surprised.</p>
<div><p><a href="https://regmedia.co.uk/2023/07/19/slack-15-boot.png" target="_blank"><img src="https://regmedia.co.uk/2023/07/19/slack-15-boot.png?x=648&amp;y=360&amp;infer_y=1" alt="Slackware64 v15 has an unwelcoming boot screen, but it's not 1996 any more. You can always just Google what to do next." title="Slackware64 v15 has an unwelcoming boot screen, but it's not 1996 any more. You can always just Google what to do next." height="360" width="648"></a></p><p>Slackware64 v15 has an unwelcoming boot screen, but it's not 1996 any more. You can always just Google what to do next</p>
</div>
<p>Way back in about 1996, emboldened by his success with <a href="https://techmonitor.ai/technology/lasermoon_touts_inexpensive_standard_linux_system_for_scientific_academic_users_unix_95_branding_in_prospect" rel="nofollow">Lasermoon Linux/FT</a> on his work PC, Slackware 3 was the first ever distro that this vulture tried to install on his own home PC: a Sunrace laptop, with external hard disk and CD-ROM drives on its built-in Adaptec SCSI interface. (Its internal IDE hard disk was occupied by OS/2 2.0, which was our personal go-to operating system of the time.) We never managed to find the correct incantation to get kernel 1.2 to load its <code>aha152x</code> driver correctly, and retired defeated.</p>
<ul>

<li><a href="https://www.theregister.com/2023/07/19/mint_212/">Mint 21.2 is desktop Linux without the faff</a></li>

<li><a href="https://www.theregister.com/2023/07/18/linux_desktop_debate/">Linux has nearly half of the desktop OS Linux market</a></li>

<li><a href="https://www.theregister.com/2023/07/17/almalinux_project_switches_focus/">AlmaLinux project climbs down from being a one-to-one RHEL clone</a></li>

<li><a href="https://www.theregister.com/2023/07/13/wayland_is_coming/">Three signs that Wayland is becoming the favored way to get a GUI on Linux</a></li>
</ul>
<p>What's surprising about Slackware today is that in some ways, it's superficially quite similar to how it was back then. There are no fripperies such as live graphical desktops here. It boots to a login prompt, and then you're expected to manually run a <code>setup</code> program, and use very 1990s DOS-style text-mode menus to tick boxes for the components that you want installed.</p>
<div><p><a href="https://regmedia.co.uk/2023/07/19/slack64-15-setup.png" target="_blank"><img src="https://regmedia.co.uk/2023/07/19/slack64-15-setup.png?x=648&amp;y=353&amp;infer_y=1" alt="The Slackware setup program doesn't look much different since the 20th century, but behind the scenes, it automates a ton of stuff away. " title="The Slackware setup program doesn't look much different since the 20th century, but behind the scenes, it automates a ton of stuff away. " height="353" width="648"></a></p><p>The Slackware setup program doesn't look much different since the 20th century, but behind the scenes, it automates a ton of stuff away</p>
</div>
<p>The flipside of this is that all of our hardware was automatically detected, and it was all remarkably easy from then on. The setup program includes a choice of graphical desktop environments, and we particularly appreciated the jokey description of Xfce as a "Cholesterol Free Desktop Environment." In fact, quite a few elements of the setup program are jokily informal – for instance, the option for individual confirmation of every package warns that installing this way will take a couple of years.</p>
<p>It didn't configure a graphical login screen by default, or even an ordinary user account, but all that was needed was to type <code>startx</code> and the desktop launched, complete with AMD Radeon graphics drivers preconfigured, and ready to connect to a wireless network. To be honest, we expected substantially more manual effort than this. It's not all a complete doddle: for example, in order to run an online update, you have to manually edit a provided list of mirrors, and uncomment one (and only one) of them.</p>

        

<p>Slackware 15 is very much <em>not</em> a lightweight distribution. Running a full update brought us perilously close to filling up our 16GB root partition, and it wasn't particularly snappy on the elderly Thinkpad W500 that we chose to test it on – although it was a bit quicker than the <a href="https://www.theregister.com/2023/07/19/mint_212/">copy of Linux Mint 21.2</a> it was dual-booting alongside. However, all the controls and config is right there, laid out for you, and if you manually prune some things, you could trim it to size quite easily.</p>
<p>It has online repositories, automatic dependency resolution, and all the bells and whistles that you'd expect from a 21st century distro – just with some of the look and feel of an original 1990s distro. It even still uses LILO by default. Running that first update, we found some worrying warnings online about building a corresponding <code>initrd</code> after you update the kernel… but all that stuff has gone away. In version 15, it's just taken care of for you, automatically.</p>

        

<p>Slackware today is in fact a modern distro, which just happens to look old fashioned due to its simple text-mode installation program, lack of a graphical desktop manager, and a few other cosmetic details. We're not sure if this is from tradition, or whether it's intentional (perhaps to scare away annoying newbies) – or, of course, it may be both. Today it's considerably easier to install than much younger distributions such as Alpine Linux or Arch Linux – or indeed than any of the BSDs, of which it's faintly reminiscent. Oh, and like BSD, it's systemd-free as well. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IMAX emulates PalmPilot software to power Oppenheimer’s 70 mm release (180 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/07/imax-emulates-palmpilot-software-to-power-oppenheimers-70-mm-release/</link>
            <guid>36817900</guid>
            <pubDate>Fri, 21 Jul 2023 18:52:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/07/imax-emulates-palmpilot-software-to-power-oppenheimers-70-mm-release/">https://arstechnica.com/gadgets/2023/07/imax-emulates-palmpilot-software-to-power-oppenheimers-70-mm-release/</a>, See on <a href="https://news.ycombinator.com/item?id=36817900">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      The other kind of PDA    —
</h4>
            
            <h2 itemprop="description">IMAX TikTok shows an emulated Palm PDA controlling <em>Oppenheimer's</em> 600-lb reel. </h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/oppenheimer-800x362.jpg" alt="Cillian Murphy in">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/07/oppenheimer-scaled.jpg" data-height="1157" data-width="2560">Enlarge</a> <span>/</span> Cillian Murphy in <em> Oppenheimer</em>.</p></figcaption>  </figure>

  




<!-- cache hit 296:single/related:d5a2ef92719af72bf29e17b49d627ab5 --><!-- empty -->
<p>It's a big week for IMAX, which has been promoting today's release of <em>Oppenheimer</em>. It's a particularly big deal for IMAX because the film is the first to get a 70 mm IMAX release since 2020's <em>Tenet</em>. So, you could understand why the company took to social media to boast of the size and magnitude of running the film, which is <a href="https://apnews.com/article/oppenheimer-christopher-nolan-0f8c1fdc4a358decee6105cac91a90ae">said</a> to be 11 miles long and 600 pounds. But in addition to the blockbuster IMAX release is something that hasn't been a showstopper in ages: a PDA.</p>
<p>And you can't discuss personal digital assistants (PDAs) without mentioning PalmPilots. The Palm computing devices were once the epitome of handheld technological organization. But Palm Computing, which endured a series of acquisitions before HP <a href="https://www.businessinsider.com/live-hps-earnings-call-2011-8">sunset the brand</a> in 2011, made other devices besides PalmPilots. One of those is the Palm m130, which is apparently IMAX projectionists' ideal controller for running 70 mm film.</p>
<p>As shown in IMAX's TikTok video below, the 70 mm print for <em>Oppenheimer</em> is so large that they had to extend their film platter. That's fascinating and all, but so is the emulated 2002 PDA apparently running things:</p>
<blockquote cite="https://www.tiktok.com/@imax/video/7255327705313430830" data-video-id="7255327705313430830">
<section><a title="@imax" href="https://www.tiktok.com/@imax?refer=embed" target="_blank" rel="noopener">@imax</a> Constantly pushing the boundaries of film . <a title="oppenheimer" href="https://www.tiktok.com/tag/oppenheimer?refer=embed" target="_blank" rel="noopener">#Oppenheimer</a> <a title="christophernolan" href="https://www.tiktok.com/tag/christophernolan?refer=embed" target="_blank" rel="noopener">#ChristopherNolan</a> <a title="imax" href="https://www.tiktok.com/tag/imax?refer=embed" target="_blank" rel="noopener">#IMAX</a> <a title="♬ original sound - IMAX" href="https://www.tiktok.com/music/original-sound-7255327683477883690?refer=embed" target="_blank" rel="noopener">♬ original sound - IMAX</a></section>
</blockquote>
<p><br>
The m130 wasn't even <a href="https://www.wired.com/2002/03/new-palm-a-tough-sell-for-biz/">top of the line</a> when it came out in 2002. It did, however, bring color (12-bit, to be exact) to Palm's M-series of handhelds. It debuted at $279 with a 2-inch, 160×160 screen and a 33 Motorola Dragonball VZ processor. But that was just the magic needed for IMAX's purposes, and so it hasn't changed a thing. The only difference is that it's using emulations in at least some cases. According to <a href="https://www.theverge.com/23801118/imax-movie-palm-pilot-oppenheimer">The Verge</a>, the TikTok video shows the PDA emulated on a 10.1-inch Windows tablet for businesses, the Winmate W10IB3S-PCH2AC-POE Panel PC. It's easy to find Palm OS emulators <a href="https://cloudpilot-emu.github.io/">online</a>, as noted by <a href="https://www.vice.com/en/article/88x5gb/imax-still-runs-on-palmpilot-operating-system">Vice's Motherboard</a>.</p>                                            
                                                        
<p>The PDA emulation controls the theater's Quick Turn Reel Units (where workers <a href="https://www.youtube.com/watch?v=_uFyp1WS1Fw">load the physical film reels</a>), which can also have integrated controllers instead.</p>
<p>Motherboard contacted IMAX about the antiquity and a company spokesperson said, "The original Quick Turn Reel Units operated on PalmPilots. In advance of the release of <em>Oppenheimer</em>, IMAX Engineering designed and manufactured an emulator that mimics the look and feel of a PalmPilot to keep it simple and familiar for IMAX film projectionists."</p>
<p>It's possible that some IMAX theaters still have physical PDAs. Ars Technica reached out to IMAX for clarification and will update this story if we hear back. As The Verge noted, a YouTuber named Yves Leibowitz, who shares video from an IMAX theater at an aquarium with 70 mm support, has physical Palm devices in his <a href="https://www.youtube.com/watch?v=_uFyp1WS1Fw">videos</a>.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled.jpg" data-height="1014" data-width="1215" alt="A closer look at the emulated PDA. "><img alt="A closer look at the emulated PDA. " src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled-640x534.jpg" width="640" height="534" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled.jpg" data-height="1014" data-width="1215">Enlarge</a> <span>/</span> A closer look at the emulated PDA. </p></figcaption></figure>
<p>So what does the timeless emulator do? An IMAX rep told The Verge that it includes controls for the left and right sides of a 3D projector, which is "from the days of the 45-minute 3D documentaries, where there was a right eye print and a left eye print which both ran through the projector at the same time.” Workers can use the emulator to set which platter is ready for film or for feeding the projector film. The emulator can also tell a worker when the platters are available to run.</p>
<h2>If it ain't broke...</h2>
<p>Twenty-one-year-old emulated PDAs may not be what you'd expect to power one of the year's most publicized movie releases, but if you look at the converse speeds at which technology and business processes tend to evolve, it feels less surprising.</p>                                            
                                                        
<p>Earlier this year, we got a sneak peek at a Chuck E. Cheese that was <em>finally</em> moving its animatronics off <a href="https://arstechnica.com/information-technology/2023/01/chuck-e-cheese-still-uses-floppy-disks-in-2023-but-not-for-long/">floppy disks</a> and into the modern age of ... DVDs. The company's not alone in using dated technologies that mainstream consumers have largely forgotten. Businesses with long-standing procedures and systems often rely on technologies prominent when those systems were created. It's common for machines for things like medical equipment, aircraft, embroidery machines, and plastic molding to <a href="https://arstechnica.com/gadgets/2023/03/why-the-floppy-disk-just-wont-die/">rely on floppy disks</a>.</p>
<p>Similarly, IMAX is seemingly working with technology it's familiar with and, thus, doesn't require new or advanced training or big purchases and upgrades.</p>
<p>Meanwhile, 70 mm IMAX film releases like <em>Oppenheimer</em> don't come often, and when they do, only 30 theaters in the world can support them, <a href="https://www.cnbc.com/2023/07/19/where-to-watch-oppenheimer-in-70mm-imax-.html">CNBC</a> reported, and not necessarily all of them will (<em>Tenet's</em> 70 mm release, for example, was limited to 11 theaters due to pandemic restrictions, CNBC said). That makes any need for upgrades and overhauls less urgent.</p>
<p>“If 70mm IMAX had a resurgence then I’d expect that they’d update the [Quick Turn Reel Unit] controllers. Until then, it’s best to ride it until the wheels fall off,” an IMAX rep told The Verge.</p>
<p>For anyone still wondering what the big deal is about <a href="https://www.filmlinc.org/daily/what-is-70mm/">70 mm film</a> (besides the size), the movie's <a href="https://www.oppenheimermovie.com/tickets/formats/">website</a> says <em>Oppenheimer</em> was "shot using a combination of 5-perf 65 mm and 15 perf IMAX film." The site claims that "when presented on 70 mm IMAX, the sequences shot on 15 perf IMAX are printed full quality in their native format—the highest quality imaging format ever devised, offering 10 times the resolution of standard formats, and filling the giant IMAX screens from top to bottom."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MiniZinc (179 pts)]]></title>
            <link>https://www.minizinc.org/</link>
            <guid>36817628</guid>
            <pubDate>Fri, 21 Jul 2023 18:32:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.minizinc.org/">https://www.minizinc.org/</a>, See on <a href="https://news.ycombinator.com/item?id=36817628">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>
                    MiniZinc is a <a href="https://www.minizinc.org/license.html">free and open-source</a> <b>constraint modeling language</b>.  
                </p>
                <p>
                    You can use MiniZinc to model constraint satisfaction and optimization problems in a <b>high-level</b>,
                    <b>solver-independent</b> way, taking advantage of a large
                    <a href="https://www.minizinc.org/doc-latest/en/lib.html">library of pre-defined constraints</a>.
                    Your model is then compiled into FlatZinc, a solver input language that is understood by
                    <a href="https://www.minizinc.org/software.html#flatzinc">a wide range of solvers</a>.
                </p>
                
                <p>
                    MiniZinc is developed at <a href="http://www.monash.edu/">Monash University</a> with support from <a href="https://optima.org.au/">OPTIMA</a>.

                </p><h2>Getting started</h2>
                <p>  
                  To get started with MiniZinc, <a href="https://www.minizinc.org/software.html">download the MiniZinc distribution
                  and the IDE</a> and have a look at the <a href="https://www.minizinc.org/doc-latest/en/index.html">MiniZinc Handbook</a>,
                  which contains a tutorial introduction (also available in <a href="https://www.minizinc.org/doc-latest/chi/index.html">Chinese</a>).
                </p>

                <h2>Learn MiniZinc</h2>
                <p>We have developed an extensive online course!
                    Head over to Coursera's <a href="https://www.coursera.org/learn/basic-modeling">Basic Modeling for Discrete Optimization</a>
                    and <a href="https://www.coursera.org/learn/advanced-modeling">Advanced Modeling for Discrete Optimization</a>
                    courses for an in-depth introduction to constraint modeling using MiniZinc.
                </p>
                
                <p>The book <a href="https://www.springer.com/gp/book/9783030417314"><i>Building Decision Support Systems using MiniZinc</i></a> by Mark Wallace
                    introduces readers to the principles of intelligent decision support systems (IDSS) and how to build them with MiniZinc.</p>

                <h2>Merchandise</h2>
                <p>Get your <a href="https://www.redbubble.com/people/guidodiug/works/32129494-minizinc">MiniZinc stickers, mugs, t-shirts</a> etc. (sold at cost price)!</p>

                <h2>News</h2>

                <ul>
                <li><b>2023-06-20</b> MiniZinc 2.7.6 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.6">change log</a>).</li>
                <li><b>2023-06-07</b> MiniZinc 2.7.5 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.5">change log</a>).</li>
                <li><b>2023-05-11</b> MiniZinc 2.7.4 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.4">change log</a>).</li>
                <li><b>2023-04-20</b> MiniZinc 2.7.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.3">change log</a>).</li>    
                <li><b>2023-04-05</b> MiniZinc 2.7.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.2">change log</a>).</li>    
                <li><b>2023-03-31</b> MiniZinc 2.7.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.1">change log</a>).</li>    
                <li><b>2023-02-23</b> MiniZinc 2.7.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.0">change log</a>).</li>
                <li><b>2023-02-13</b> First <a href="https://www.minizinc.org/challenge2023/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2023.</li>
                <li><b>2022-08-04</b> The MiniZinc Challenge 2022 results available <a href="https://www.minizinc.org/challenge2022/results2022.html">here</a>. </li>
                <li><b>2022-06-23</b> MiniZinc 2.6.4 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.4">change log</a>).</li>
                <li><b>2022-05-06</b> MiniZinc 2.6.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.3">change log</a>).</li>
                <li><b>2022-03-03</b> MiniZinc 2.6.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.2">change log</a>).</li>
                <li><b>2022-03-10</b> First <a href="https://www.minizinc.org/challenge2022/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2022.</li>
                <li><b>2022-03-03</b> MiniZinc 2.6.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.1">change log</a>).</li>
                <li><b>2022-02-22</b> MiniZinc 2.6.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.0">change log</a>).</li>
                <li><b>2021-10-29</b> The MiniZinc Challenge 2021 results available <a href="https://www.minizinc.org/challenge2021/results2021.html">here</a>. </li>
                <li><b>2021-05-07</b> First <a href="https://www.minizinc.org/challenge2021/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2021.</li>
                <li><b>2021-03-19</b> MiniZinc 2.5.5 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.5">change log</a>).</li>
                <li><b>2021-03-16</b> MiniZinc 2.5.4 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.4">change log</a>).</li>
                <li><b>2020-11-24</b> MiniZinc 2.5.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.3">change log</a>).</li>
                <li><b>2020-11-09</b> MiniZinc 2.5.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.2">change log</a>).</li>
                <li><b>2020-10-22</b> MiniZinc 2.5.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.1">change log</a>).</li>
                <li><b>2020-10-06</b> MiniZinc 2.5.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.0">change log</a>).</li>
                <li><b>2020-05-22</b> <a href="https://www.springer.com/gp/book/9783030417314"><i>Building Decision Support Systems using MiniZinc</i></a> by Mark Wallace is now available</li>
                <li><b>2020-03-04</b> MiniZinc 2.4.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.3">change log</a>).</li>
                <li><b>2020-01-10</b> MiniZinc 2.4.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.2">change log</a>).</li>
                <li><b>2019-12-20</b> MiniZinc 2.4.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.1">change log</a>).</li>
                <li><b>2019-12-13</b> MiniZinc 2.4.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.0">change log</a>).</li>
                <li><b>2019-10-03</b> The MiniZinc Challenge 2019 results available <a href="https://www.minizinc.org/challenge2019/results2019.html">here</a>. </li>
                <li><b>2019-09-12</b> MiniZinc 2.3.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.3.2">change log</a>).</li>
                <li><b>2019-07-10</b> MiniZinc 2.3.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.3.1">change log</a>).</li>
                <li><b>2019-06-26</b> MiniZinc 2.3.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.3.0">change log</a>).</li>
                <li><b>2019-03-07</b> First <a href="https://www.minizinc.org/challenge2019/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2019.</li>
                <li><b>2018-10-31</b> MiniZinc 2.2.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.3">change log</a>).</li>
                <li><b>2018-10-26</b> MiniZinc 2.2.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.2">change log</a>).</li>
                <li><b>2018-09-20</b> Amendments of the MiniZinc Challenge 2018 results had to be made due to an issue with the solution checker. More details are available <a href="https://www.minizinc.org/challenge2018/results2018.html">here</a>. Thanks to Gustav Björdal and Michael Marte for reporting.</li>
                <li><b>2018-09-06</b> MiniZinc 2.2.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.1">change log</a>).</li>
                <li><b>2018-08-28</b> The MiniZinc Challenge 2018 results available <a href="https://www.minizinc.org/challenge2018/results2018.html">here</a>. </li>
                <li><b>2018-08-24</b> MiniZinc 2.2.0, a major release with many new features has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.0">change log</a>).</li>
                <li><b>2018-03-08</b> 11th edition of the <a href="https://www.minizinc.org/challenge2018/challenge.html">MiniZinc Challenge</a> has been announced.</li>
                <li><b>2018-01-10</b> MiniZinc 2.1.7 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.1.7">change log</a>).</li>
                <li><a href="https://www.minizinc.org/oldnews.html">Older news items</a></li>
                </ul>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[For BSD Unix, It's Sayonara (1992) (103 pts)]]></title>
            <link>https://www.tech-insider.org/unix/research/1992/0622.html</link>
            <guid>36817482</guid>
            <pubDate>Fri, 21 Jul 2023 18:22:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tech-insider.org/unix/research/1992/0622.html">https://www.tech-insider.org/unix/research/1992/0622.html</a>, See on <a href="https://news.ycombinator.com/item?id=36817482">Hacker News</a></p>
<div id="readability-page-1" class="page">
<b>News</b><p><b>For BSD Unix, It's Sayonara </b></p>
<p>Jason Levitt and Evan Schuman<br>
Open Systems Today </p>
<p>June 22, 1992</p>
<p>Berkeley, Calif. -- The end of a major computing era will come next month 
when the final release of BSD Unix gets shipped, marking the University of 
California at Berkeley's withdrawal from the operating system business. </p>
<p>A lack of funding and the increasing sophistication of commercial Unix 
implementations have combined to halt Unix development at the university, 
meaning that 4.4BSD Unix-set to go Alpha by next month, with general 
availability by December-will be Berkeley's last OS. </p>
<p>BSD has been popular in the academic community for many reasons, mostly 
because-since 1988-it has not required a license fee and often features 
cutting-edge technology years before commercial computer vendors' versions. </p>
<p>"With any commercial version of Unix, you usually have to sign your life 
away," said Evi Nemeth, an associate professor of computer science at the 
University of Colorado at Boulder, adding that this no-license feature made BSD 
ideal for teaching students about operating systems and networking. </p>
<p>BSD Unix was responsible for much of the Unix innovation during the 1980s and 
came into being around 1978 when Berkeley graduate student Bill Joy added 
virtual memory capability to a VAX 11/780 port of Unix. The resulting system was 
named 3BSD (4BSD in 1980) and became the dominant Unix version at universities.
</p>
<p>Since that time, nearly all of the important Unix enhancements have come from 
the BSD releases of Unix. Collectively, these enhancements are often referred to 
as the Berkeley "extensions" and are now part of System V Release 4. The 
programming API for OSF/1 is based on 4.3BSD libraries and system calls. </p>
<p>Originally, BSD was funded by the government through DARPA. But that funding 
was cut off in 1988 when the vendor community started to show a strong interest 
in doing its own development. </p>
<p>Since 1988, BSD research and staffing has been supplied through vendor 
grants, mostly from Hewlett-Packard, the Open Software Foundation and Cray 
Research. </p>
<p>Kirk McKusick, the Berkeley research computer scientist who is in charge of 
the BSD project, added that NASA Ames also has been a major sponsor. </p>
<p>"It's becoming increasingly difficult to get funding from the private 
sector," he said. "With the recession, these companies are obviously looking at 
the bottom line and external research is an item that can be easily reduced."
</p>
<p>While fund raising has gotten more difficult, today's technology has forced 
the operating system to grow substantially more complicated, with the 100 
different commands from a few years ago now at 500 commands, McKusick said. </p>
<p>"The complexity has grown almost exponentially," he said, adding that his 
staff of four would need be doubled to "continue the level of quality." </p>
<p>Also, McKusick said, the university itself "is not as interested in having us 
around as they did 10 years ago" because vendors today-such as Cisco 
Systems-have packaged some of the networking technology that made his team so 
indispensable before for systems administration. </p>
<p>"We are so good at getting our stuff disseminated that we are no longer 
needed," he said. </p>
<p>Another factor contributing to the OS' demise, said Keith Bostic, fellow 
Berkeley programmer and the project's second-in-command, was the increasing 
sophistication of vendors in working with Unix. </p>
<p>In the early 1980s, Bostic said, just about the entire Unix community was 
either using a form of BSD or AT&amp;T's System V. "If you bought {Unix} from DEC, 
you were running BSD. If you bought {Unix} from Sun, you were running BSD," he 
said. "In today's climate, it is not the same as 1980." </p>
<p>Bostic said that today's Unix vendors are more sophisticated and are making 
many more changes to whatever version of Unix they are starting with. </p>
<p>BSD 4.3 "was the last version that major vendors shipped right out of the 
box. Vendors now tend to pick and choose," he said. "The vendors are basically 
going to lose a research group." </p>
<p>There are still options to secure BSD code, with one company, Berkeley 
Software Design (Falls Church, Va.), a company employing former Berkeley 
programmer Mike Karels, planning to offer a commercial version of Unix for SPARC 
systems based on the 4.4BSD code but free of AT&amp;T source licensing requirements. 
It currently offers BSD/386, a version of Unix for 386 machines based on the 
Berkeley NET2 release. </p>
<p>And there are several outfits that will distribute the code freely, often 
directly on the net. </p>
<p>The University of Colorado's Nemeth, regarded as an expert on Unix security 
and perhaps best known for having co-authored the Unix System Administration 
Handbook, said last week that she would like to have her university conduct some 
of the operating system research that Berkeley is now abandoning. </p>
<p>One of the most popular accomplishments of the BSD team, said Nemeth and 
others, was its sifting through mountains of software out in the industry, 
finding the best examples and incorporating them into a BSD version. McKusick 
said it was often a matter of convincing contributors "that they would rather 
have fame than fortune." </p>
<p>Nemeth cited a more colorful-and oft-cited-description: "It was a matter of 
their taking it in and peeing on it until it smelled like Berkeley." </p>
<p>"This is a valuable function and the community needs the service," she said, 
adding that she is trying to convince DARPA to resume funding BSD research at 
her university with it paying for three to four full-time staff, two or three 
graduate students and two or three undergraduate students. Nemeth estimated that 
she would need about $700,000. </p>
<p>But she said last week that she now is leaning toward securing interim 
funding from industry, in an attempt to demonstrate to DARPA that her people can 
do the job effectively. </p>
<p>Nemeth said that she is hesitant, though, to have vendor support made 
permanent. "I don't see having to constantly hustle for money."</p>

<p>Copyright 1992 CMP Publications, Inc. All rights reserved.</p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Web Environment Integrity API (324 pts)]]></title>
            <link>https://github.com/RupertBenWiser/Web-Environment-Integrity</link>
            <guid>36817305</guid>
            <pubDate>Fri, 21 Jul 2023 18:09:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity">https://github.com/RupertBenWiser/Web-Environment-Integrity</a>, See on <a href="https://news.ycombinator.com/item?id=36817305">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-turbo-body="">
      


    <div>
      <p><a href="#start-of-content">Skip to content</a>
      <span data-view-component="true">
    <span data-view-component="true"></span>
</span></p><header role="banner" data-color-mode="light" data-light-theme="light" data-dark-theme="dark">
  

  <div>
    <div>
      <a href="https://github.com/" aria-label="Homepage" data-ga-click="(Logged out) Header, go to homepage, icon:logo-wordmark">
        
      </a>

        <div>
          <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="d70e84e9f9dca6c4052317ffe225baad48a9b2d4823c9c6c4d304f38494e8473">
            Sign&nbsp;up
          </a>
        </p></div>

      
    </div>


    <div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="product-explore-heading">Explore</span></p><ul aria-labelledby="product-explore-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to All features&quot;,&quot;label&quot;:&quot;ref_cta:All features;&quot;}" href="https://github.com/features">
      All features

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Documentation&quot;,&quot;label&quot;:&quot;ref_cta:Documentation;&quot;}" href="https://docs.github.com/">
      Documentation

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to GitHub Skills&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Skills;&quot;}" href="https://skills.github.com/">
      GitHub Skills

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Blog&quot;,&quot;label&quot;:&quot;ref_cta:Blog;&quot;}" href="https://github.blog/">
      Blog

    
</a></li>

            </ul>
          </div>
      </div>
</li>


                <li>
      
      <div>
          <div>
              <p><span id="solutions-for-heading">For</span></p><ul aria-labelledby="solutions-for-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Enterprise&quot;,&quot;label&quot;:&quot;ref_cta:Enterprise;&quot;}" href="https://github.com/enterprise">
      Enterprise

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Teams&quot;,&quot;label&quot;:&quot;ref_cta:Teams;&quot;}" href="https://github.com/team">
      Teams

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Startups&quot;,&quot;label&quot;:&quot;ref_cta:Startups;&quot;}" href="https://github.com/enterprise/startups">
      Startups

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Education&quot;,&quot;label&quot;:&quot;ref_cta:Education;&quot;}" href="https://education.github.com/">
      Education

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="solutions-by-solution-heading">By Solution</span></p><ul aria-labelledby="solutions-by-solution-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to CI/CD &amp;amp; Automation&quot;,&quot;label&quot;:&quot;ref_cta:CI/CD &amp;amp; Automation;&quot;}" href="https://github.com/solutions/ci-cd/">
      CI/CD &amp; Automation

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to DevOps&quot;,&quot;label&quot;:&quot;ref_cta:DevOps;&quot;}" href="https://resources.github.com/devops/">
      DevOps

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to DevSecOps&quot;,&quot;label&quot;:&quot;ref_cta:DevSecOps;&quot;}" href="https://resources.github.com/devops/fundamentals/devsecops/">
      DevSecOps

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="solutions-resources-heading">Resources</span></p><ul aria-labelledby="solutions-resources-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Customer Stories&quot;,&quot;label&quot;:&quot;ref_cta:Customer Stories;&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to White papers, Ebooks, Webinars&quot;,&quot;label&quot;:&quot;ref_cta:White papers, Ebooks, Webinars;&quot;}" href="https://resources.github.com/">
      White papers, Ebooks, Webinars

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Partners&quot;,&quot;label&quot;:&quot;ref_cta:Partners;&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

            </ul>
          </div>
      </div>
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="open-source-repositories-heading">Repositories</span></p><ul aria-labelledby="open-source-repositories-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Topics&quot;,&quot;label&quot;:&quot;ref_cta:Topics;&quot;}" href="https://github.com/topics">
      Topics

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Trending&quot;,&quot;label&quot;:&quot;ref_cta:Trending;&quot;}" href="https://github.com/trending">
      Trending

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Collections&quot;,&quot;label&quot;:&quot;ref_cta:Collections;&quot;}" href="https://github.com/collections">
      Collections

    
</a></li>

            </ul>
          </div>
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:RupertBenWiser/Web-Environment-Integrity" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="TOFqL3IsSOkP2RP7Whs-FRbAKNymOsfTq1lEcorjNQ_UqiuwYjvFpkj7Mf5KZWKttIePXlBbsmxJzfzA_D6Amg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="RupertBenWiser/Web-Environment-Integrity" data-current-org="" data-current-owner="RupertBenWiser" data-logged-in="false">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-describedby="feedback-dialog-title feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <div data-view-component="true">        <!-- '"` --><!-- </textarea></xmp> --><form id="code-search-feedback-form" data-turbo="false" action="/search/feedback" accept-charset="UTF-8" method="post">
          <p>We read every piece of feedback, and take your input very seriously.</p>
          
          
          <label for="include_email">Include my email address so I can be contacted</label>
</form></div>
      
</modal-dialog></div>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-describedby="custom-scopes-dialog-title custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>
    </custom-scopes>
  </div>
</qbsearch-input><div>
            <p><a href="https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FRupertBenWiser%2FWeb-Environment-Integrity" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="01e3ed5febbe8bc7ce93175543274d99ddddc9287a0c31d4bea8d40f578b6b71" data-ga-click="(Logged out) Header, clicked Sign in, text:sign-in">
              Sign in
            </a>
          </p></div>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=RupertBenWiser%2FWeb-Environment-Integrity" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="01e3ed5febbe8bc7ce93175543274d99ddddc9287a0c31d4bea8d40f578b6b71" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div>
  </div>
</header>

      
    </div>

  








    


    
    <include-fragment data-base-src="https://github.com/notifications/beta/shelf"></include-fragment>






  <div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
  




    






  
  <div id="repository-container-header" data-turbo-replace="">

      <div>

        <div>
      
    
    <p><span itemprop="author">
      <a rel="author" data-hovercard-type="user" data-hovercard-url="/users/RupertBenWiser/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/RupertBenWiser">
        RupertBenWiser
</a>    </span>
    <span>/</span>
    <strong itemprop="name">
      <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity">Web-Environment-Integrity</a>
    </strong>

    <span></span><span>Public</span>
  </p></div>

        <div id="repository-details-container" data-turbo-replace="">
            <ul>
    
      

  <li>
            <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="293d9a82a60f90833694d5820eee59ef0df39d68f49e83d7e5b15d78ce605170" aria-label="You must be signed in to change notification settings" data-view-component="true">    Notifications
</a>
  </li>

  <li>
          <a icon="repo-forked" id="fork-button" href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:632520759,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5aa5809df7db030699b13deecdd19445904a135559f2af25249dddf6be869a54" data-view-component="true">    Fork
    <span id="repo-network-counter" data-pjax-replace="true" data-turbo-replace="true" title="21" data-view-component="true">21</span>
</a>
  </li>

  <li>
        <div data-view-component="true">
        <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:632520759,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="63d22802c5b163a4f30d19ed6eef47b4d81941c9749061a904d7b89bc133e5db" aria-label="You must be signed in to star a repository" data-view-component="true">    <span data-view-component="true">
          Star
</span>          <span id="repo-stars-counter-star" aria-label="64 users starred this repository" data-singular-suffix="user starred this repository" data-plural-suffix="users starred this repository" data-turbo-replace="true" title="64" data-view-component="true">64</span>
</a>        </div>
  </li>


    

</ul>

        </div>
      </div>

        <div id="responsive-meta-container" data-turbo-replace="">

    

    <p>
        <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/stargazers">
          
          <span>64</span>
          stars
</a>        <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/forks">
          
          <span>21</span>
          forks
</a>        <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/activity">
          
          <span>Activity</span>
</a>    </p>

      <div>
        <div data-view-component="true">
        <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:632520759,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="63d22802c5b163a4f30d19ed6eef47b4d81941c9749061a904d7b89bc133e5db" aria-label="You must be signed in to star a repository" data-view-component="true">    <span data-view-component="true">
          Star
</span>
</a>        </div>
        <p>
                <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="293d9a82a60f90833694d5820eee59ef0df39d68f49e83d7e5b15d78ce605170" aria-label="You must be signed in to change notification settings" data-view-component="true">    Notifications
</a>
        </p>
      </div>
  </div>


          <nav data-pjax="#js-repo-pjax-container" aria-label="Repository" data-view-component="true">

  <ul data-view-component="true">
      <li data-view-component="true">
  <a id="code-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity" data-tab-item="i0code-tab" data-selected-links="repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages repo_deployments /RupertBenWiser/Web-Environment-Integrity" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g c" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Code&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" aria-current="page" data-view-component="true">
    
              
        <span data-content="Code">Code</span>
          <span id="code-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true"></span>


    
</a></li>
      <li data-view-component="true">
  <a id="issues-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/issues" data-tab-item="i1issues-tab" data-selected-links="repo_issues repo_labels repo_milestones /RupertBenWiser/Web-Environment-Integrity/issues" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g i" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Issues&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Issues">Issues</span>
          <span id="issues-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="51" data-view-component="true">51</span>


    
</a></li>
      <li data-view-component="true">
  <a id="pull-requests-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/pulls" data-tab-item="i2pull-requests-tab" data-selected-links="repo_pulls checks /RupertBenWiser/Web-Environment-Integrity/pulls" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g p" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Pull requests&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Pull requests">Pull requests</span>
          <span id="pull-requests-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="2" data-view-component="true">2</span>


    
</a></li>
      <li data-view-component="true">
  <a id="actions-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/actions" data-tab-item="i3actions-tab" data-selected-links="repo_actions /RupertBenWiser/Web-Environment-Integrity/actions" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g a" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Actions&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Actions">Actions</span>
          <span id="actions-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true"></span>


    
</a></li>
      <li data-view-component="true">
  <a id="projects-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/projects" data-tab-item="i4projects-tab" data-selected-links="repo_projects new_repo_project repo_project /RupertBenWiser/Web-Environment-Integrity/projects" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g b" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Projects&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Projects">Projects</span>
          


    
</a></li>
      <li data-view-component="true">
  <a id="security-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/security" data-tab-item="i5security-tab" data-selected-links="security overview alerts policy token_scanning code_scanning /RupertBenWiser/Web-Environment-Integrity/security" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g s" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Security&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Security">Security</span>
          <include-fragment src="/RupertBenWiser/Web-Environment-Integrity/security/overall-count" accept="text/fragment+html"></include-fragment>

    
</a></li>
      <li data-view-component="true">
  <a id="insights-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/pulse" data-tab-item="i6insights-tab" data-selected-links="repo_graphs repo_contributors dependency_graph dependabot_updates pulse people community /RupertBenWiser/Web-Environment-Integrity/pulse" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Insights&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Insights">Insights</span>
          <span id="insights-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true"></span>


    
</a></li>
</ul>
    <div data-view-component="true">        <details data-view-component="true">
    <summary role="button" data-view-component="true">          <div>
            
            <p><span>More</span>
          </p></div>
</summary>
    <details-menu role="menu" data-view-component="true">          <ul>
              
              
              
              
              
              
              
          </ul>
</details-menu>
</details></div>
</nav>

  </div>

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div id="repo-content-pjax-container">
  


  

  <include-fragment src="/RupertBenWiser/Web-Environment-Integrity/spoofed_commit_check/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4" data-test-selector="spoofed-commit-check"></include-fragment>

  <div data-view-component="true">
  <div data-view-component="true">        
        
        <div>
  
<div>
  <details id="branch-select-menu" data-hydro-click-payload="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;REFS_SELECTOR_MENU&quot;,&quot;repository_id&quot;:632520759,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="44d089c48373dc35e4e44d462abd09000039cc8c32fc11bab9faf0bfe1d7ba67">
    <summary data-hotkey="w" title="Switch branches or tags">
      
      <span data-menu-button="">main</span>
      <span></span>
    </summary>

    
<div>
    <header>
      <span>Switch branches/tags</span>
      
    </header>

    <input-demux data-action="tab-container-change:input-demux#storeInput tab-container-changed:input-demux#updateInput">
      <tab-container>
        

        

        <div role="tabpanel" id="ref-list-branches" data-filter-placeholder="Filter branches/tags" tabindex="">
          <ref-selector type="branch" data-targets="input-demux.sinks" data-action="
              input-entered:ref-selector#inputEntered
              tab-selected:ref-selector#tabSelected
              focus-list:ref-selector#focusFirstListMember
            " query-endpoint="/RupertBenWiser/Web-Environment-Integrity/refs" cache-key="v0:1689925634.0" current-committish="bWFpbg==" default-branch="bWFpbg==" name-with-owner="UnVwZXJ0QmVuV2lzZXIvV2ViLUVudmlyb25tZW50LUludGVncml0eQ==" prefetch-on-mouseover="">

            <template data-target="ref-selector.fetchFailedTemplate">
              <div class="SelectMenu-message" data-index="{{ index }}">Could not load branches</div>
            </template>

              <template data-target="ref-selector.noMatchTemplate">
    <div class="SelectMenu-message">Nothing to show</div>
</template>


            

              

<template data-target="ref-selector.itemTemplate">
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/{{ urlEncodedRefName }}" class="SelectMenu-item" role="menuitemradio" rel="nofollow" aria-checked="{{ isCurrent }}" data-index="{{ index }}">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check SelectMenu-icon SelectMenu-icon--check">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    <span class="flex-1 css-truncate css-truncate-overflow {{ isFilteringClass }}">{{ refName }}</span>
    <span hidden="{{ isNotDefault }}" class="Label Label--secondary flex-self-start">default</span>
  </a>
</template>


              
          </ref-selector>

        </div>

        
      </tab-container>
    </input-demux>
  </div>

  </details>

</div>


<div data-modal-dialog-overlay="">
  <modal-dialog role="dialog" id="warn-tag-match-create-branch-dialog" aria-modal="true" aria-labelledby="warn-tag-match-create-branch-dialog-header" data-view-component="true">
      <header>
        <div>
          <p>
            <h2 id="warn-tag-match-create-branch-dialog-header">Name already in use</h2>
          </p>
          
        </div>
      </header>
    <div>
      
          <p>      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?
</p>

    </div>
      
</modal-dialog></div>



  <p>
    <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/branches">
          
          <strong>2</strong>
          <span>branches</span>
    </a>
    <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tags">
      
        <strong>0</strong>
        <span>tags</span>
    </a>
  </p>

  

  <include-fragment src="/RupertBenWiser/Web-Environment-Integrity/overview_actions/main"></include-fragment>


    <p><span>
        
<get-repo>
    
    <details data-action="
               toggle:get-repo#onDetailsToggle
               keydown:get-repo#onDetailsKeydown">
        <summary data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;repository_id&quot;:632520759,&quot;target&quot;:&quot;CLONE_OR_DOWNLOAD_BUTTON&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="2a850bb66106159d97ab9bd5e4e79b14c52c6a46a2f26d039aa174ad06cbde5f" data-view-component="true">    <span>
      <span>Code</span>
    </span>
      <span>
        
      </span>
</summary>  
      <div data-target="get-repo.modal">
    <tab-container data-view-component="true">
  <div with_panel="true" data-view-component="true">
    
    <ul role="tablist" aria-label="Choose where to access your code" data-view-component="true">
        <li role="presentation" data-view-component="true">
  </li>
        <li role="presentation" data-view-component="true">
  </li>
</ul>    
</div>    <div id="local-panel" role="tabpanel" tabindex="0" aria-labelledby="local-tab" data-view-component="true">          <ul>
              <li>
  <a href="https://docs.github.com/articles/which-remote-url-should-i-use" target="_blank" aria-label="Which remote URL should I use?">
  
</a>

<div>
  <p>
  Clone
</p></div>

<tab-container>

  

  <div role="tabpanel">
    

    <p>
        Use Git or checkout with SVN using the web URL.
    </p>
  </div>


  
</tab-container>

</li>
<li data-platforms="windows,mac">
  <a data-hydro-click="{&quot;event_type&quot;:&quot;clone_or_download.click&quot;,&quot;payload&quot;:{&quot;feature_clicked&quot;:&quot;OPEN_IN_DESKTOP&quot;,&quot;git_repository_type&quot;:&quot;REPOSITORY&quot;,&quot;repository_id&quot;:632520759,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="0e082088e719e3706dceff570cd728dcc71018e70b8c36e4cd0ce22013aec0f8" data-action="click:get-repo#showDownloadMessage" href="https://desktop.github.com/">
    
    Open with GitHub Desktop
</a></li>
<li>
  <a rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;clone_or_download.click&quot;,&quot;payload&quot;:{&quot;feature_clicked&quot;:&quot;DOWNLOAD_ZIP&quot;,&quot;git_repository_type&quot;:&quot;REPOSITORY&quot;,&quot;repository_id&quot;:632520759,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="3228739be0257e0437c387b54e0f4d4c40aeacbd38fbcf1c77cc602cca3390f7" data-ga-click="Repository, download zip, location:repo overview" data-open-app="link" data-turbo="false" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/archive/refs/heads/main.zip">
    
    Download ZIP
</a></li>

          </ul>
</div>
    
</tab-container></div>
    </details>


</get-repo>

    </span>

    <span>
        

    </span>
</p></div>




        


<div>
  <div>
    <h2>Latest commit</h2>
    <div data-issue-and-pr-hovercards-enabled="">
      
  <div>
  <p><a data-test-selector="commits-avatar-stack-avatar-link" data-hovercard-type="user" data-hovercard-url="/users/yoavweiss/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/yoavweiss">
        <img data-test-selector="commits-avatar-stack-avatar-image" src="https://avatars.githubusercontent.com/u/786187?s=48&amp;v=4" width="24" height="24" alt="@yoavweiss">
</a>      <a data-test-selector="commits-avatar-stack-avatar-link" data-hovercard-type="user" data-hovercard-url="/users/RupertBenWiser/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/RupertBenWiser">
        <img data-test-selector="commits-avatar-stack-avatar-image" src="https://avatars.githubusercontent.com/u/26461279?s=48&amp;v=4" width="24" height="24" alt="@RupertBenWiser">
</a>  </p>
</div>
  <div>
    <div>
          <p><a title="View all commits by yoavweiss" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commits?author=yoavweiss">yoavweiss</a>
    
   and
  <a title="View all commits by RupertBenWiser" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commits?author=RupertBenWiser">RupertBenWiser</a>
  

        <span>
          <a data-pjax="true" data-test-selector="commit-tease-commit-message" title="Create CODE_OF_CONDUCT.md" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Create CODE_OF_CONDUCT.md</a>
        </span>
    </p></div>
    <div>
        <include-fragment accept="text/fragment+html" src="/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4/rollup?direction=sw"></include-fragment>
      <p><a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame">
        7998217
      </a></p><a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame">
        <relative-time datetime="2023-07-21T07:46:43Z">Jul 21, 2023</relative-time>
      </a>
    </div>
  </div>
  <div>
      <div>
        <p><a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-test-selector="commit-tease-commit-message" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Create CODE_OF_CONDUCT.md</a>
      </p></div>
    <p><code>7998217</code>
    </p>
  </div>
      <div>
        <h2>Git stats</h2>
        <ul>
          <li>
            <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commits/main">
              
              <span>
                    <strong>22</strong>
                    <span aria-label="Commits on main">
                      commits
                    </span>
              </span>
            </a>
          </li>
        </ul>
      </div>
    </div>
  </div>
    <h2 id="files">Files</h2>
    


    <p><a data-hotkey="y" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Permalink</a></p><div data-view-component="true">
  <p>
    Failed to load latest commit information.


  
</p></div>  <div role="grid" aria-labelledby="files" data-hpc="">
      <div role="row">
        <p>Type</p>
        <p>Name</p>
        <p>Latest commit message</p>
        <p>Commit time</p>
      </div>

        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="This path skips through empty directories" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/main/.github/workflows"><span>.github/</span>workflows</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Add github workflow to publish to gh-pages branch

This should auto process the bikeshed on push to main and publish
to the gh-pages branch.

Also updating the WebIDL to pass validation." href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/f8448c38fd41470d828ad1b1ec691a2b424f1118">Add github workflow to publish to gh-pages branch</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-06-20T14:19:28Z" data-view-component="true">June 20, 2023 14:19</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="docs" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/main/docs">docs</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Add hash type and DOMException" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/f6bf35350c59e856deafdac65569b71a3413155b">Add hash type and DOMException</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-07-17T10:55:18Z" data-view-component="true">July 17, 2023 10:55</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title=".gitignore" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/.gitignore">.gitignore</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Add gitignore

Ignoring local spec files generated in the docs directory." href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/1866c954426f2529f008362b6b7686cbff605388">Add gitignore</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-06-20T15:20:21Z" data-view-component="true">June 20, 2023 15:20</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="CODE_OF_CONDUCT.md" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/CODE_OF_CONDUCT.md">CODE_OF_CONDUCT.md</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Create CODE_OF_CONDUCT.md" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Create CODE_OF_CONDUCT.md</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-07-21T09:46:43+02:00" data-view-component="true">July 21, 2023 09:46</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="README.md" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/README.md">README.md</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Update spec link to be github page instead" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/b8a049e76e04de712993a821a7482a85e281adbc">Update spec link to be github page instead</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-06-21T10:00:27Z" data-view-component="true">June 21, 2023 10:00</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="explainer.md" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/explainer.md">explainer.md</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="use eTLD+1, not TLD" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/c7366e82ecdba4c49aef945175ef90e8c9d6b47d">use eTLD+1, not TLD</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-04-27T10:01:28+01:00" data-view-component="true">April 27, 2023 10:01</relative-time>
          </p>

        </div>
    </div>




</div>

  
    
      <div id="readme" data-tagsearch-path="README.md" data-tagsearch-lang="Markdown">

        <div>
          <p>
            <h2>
              <a href="#readme" data-view-component="true">README.md</a>
            </h2>
          </p>
        </div>

          <div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Web Environment Integrity API</h2>
<p dir="auto">This repository details the proposal to add a new API for determining the integrity
of web environments:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const attestation = await navigator.getEnvironmentIntegrity(&quot;...&quot;);"><pre><span>const</span> <span>attestation</span> <span>=</span> <span>await</span> <span>navigator</span><span>.</span><span>getEnvironmentIntegrity</span><span>(</span><span>"..."</span><span>)</span><span>;</span></pre></div>
<p dir="auto">The <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/explainer.md">explainer</a> goes gives a high level overview of the proposal.</p>
<p dir="auto">The <a href="https://rupertbenwiser.github.io/Web-Environment-Integrity/" rel="nofollow">spec</a> currently describes how this is being prototyped in Chromium.</p>
</article>
          </div>
      </div>



</div>
  <div data-pjax="" data-view-component="true">
        <div>
            <h2>About</h2>

    <p>
      No description, website, or topics provided.
    </p>


    <h3>Resources</h3>
    <p>
      <a data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:readme&quot;}" href="#readme">
        
        Readme
</a>    </p>

  

    <h3>Code of conduct</h3>
    <p>
      <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/CODE_OF_CONDUCT.md" data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:code of conduct&quot;}">
        
        Code of conduct
      </a>
    </p>


<include-fragment src="/RupertBenWiser/Web-Environment-Integrity/hovercards/citation/sidebar_partial?tree_name=main">
</include-fragment>



<p>
  <a data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/activity" data-view-component="true">
    
    <span>Activity</span>
</a></p>

<h3>Stars</h3>
<p>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/stargazers" data-view-component="true">
    
    <strong>64</strong>
    stars
</a></p>

<h3>Watchers</h3>
<p>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/watchers" data-view-component="true">
    
    <strong>20</strong>
    watching
</a></p>

<h3>Forks</h3>
<p>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/forks" data-view-component="true">
    
    <strong>21</strong>
    forks
</a></p>

  <div>
    <p><a href="https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FRupertBenWiser%2FWeb-Environment-Integrity&amp;report=RupertBenWiser+%28user%29">
        Report repository
</a>  </p></div>

          </div>

        
        
            <div>
                <h2 data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame">
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/releases" data-view-component="true">
    Releases
</a></h2>

    <p>No releases published</p>

              </div>

        
        
            <div>
                <h2>
  <a href="https://github.com/users/RupertBenWiser/packages?repo_name=Web-Environment-Integrity" data-view-component="true">
    Packages
      
</a></h2>


      <p>
        No packages published <br>
      </p>



              </div>

        
        
            <div>
                <h2>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/graphs/contributors" data-view-component="true">
    Contributors
      <span title="3" data-view-component="true">3</span>
</a></h2>


    
  <ul>
    <li>
      <a href="https://github.com/apps/github-actions">
        <img src="https://avatars.githubusercontent.com/in/15368?s=64&amp;v=4" alt="@github-actions[bot]" size="32" height="32" width="32" data-view-component="true">
      </a>
      <span data-view-component="true">
        <a href="https://github.com/apps/github-actions">
          <strong>github-actions[bot]</strong>
          
        </a>
</span>    </li>
    <li>
      <a href="https://github.com/yoavweiss" data-hovercard-type="user" data-hovercard-url="/users/yoavweiss/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="https://avatars.githubusercontent.com/u/786187?s=64&amp;v=4" alt="@yoavweiss" size="32" height="32" width="32" data-view-component="true">
      </a>
      <span data-view-component="true">
        <a href="https://github.com/yoavweiss">
          <strong>yoavweiss</strong>
          <span>Yoav Weiss</span>
        </a>
</span>    </li>
    <li>
      <a href="https://github.com/bakkot" data-hovercard-type="user" data-hovercard-url="/users/bakkot/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="https://avatars.githubusercontent.com/u/1653598?s=64&amp;v=4" alt="@bakkot" size="32" height="32" width="32" data-view-component="true">
      </a>
      <span data-view-component="true">
        <a href="https://github.com/bakkot">
          <strong>bakkot</strong>
          <span>Kevin Gibbons</span>
        </a>
</span>    </li>
</ul>





              </div>

        
        
              </div>
  
</div></div>

</turbo-frame>


    </main>
  </div>

          




  

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open="">
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog="">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0 tooltipped-no-delay" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What are the best papers you read in your life? (146 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=36817231</link>
            <guid>36817231</guid>
            <pubDate>Fri, 21 Jul 2023 18:04:01 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=36817231">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="36818754"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818754" href="https://news.ycombinator.com/vote?id=36818754&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Claude Shannon's "A Mathematical Theory of Communication"[1] is often considered a classic. I think this is because:<p>1. It's quite readable as a narrative.</p><p>2. The maths is not pages of first principle derivations as if the reader is not familiar with the basics of algebraic substitution.</p><p>3. The diagrams and graphs are genuinely useful and remove the need for many, many thousands of words that others may have used instead of, or in addition to, the core narrative.</p><p>4. It deals with an abstract concept but roots it in concrete mathematical and physical terms. He touches on specific examples.</p><p>5. It's quite short given the breadth of subject area.</p><p>[1] <a href="https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf" rel="nofollow noreferrer">https://people.math.harvard.edu/~ctm/home/text/others/shanno...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36819339"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36819339" href="https://news.ycombinator.com/vote?id=36819339&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>His easily-understandable yet mind-blowing ideas of hyperspheres of information (and a reliable communications channel having a definition!? What?) changed my brain permanently.<p>This is the paper I was going to cite as well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819215"><td></td></tr>
            <tr id="36818482"><td></td></tr>
            <tr id="36818350"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818350" href="https://news.ycombinator.com/vote?id=36818350&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>If you are looking for quality I suggest you look at the IPCC reports. Each word is carefully chosen, every claim backed by mountains of evidence. They're written to be read and understood by non-experts. They exist to inform decision making that will literally determine the fate of our species. As such, they may be failing at their goal, but not for a lack of effort by the authors.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36818777"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36818777" href="https://news.ycombinator.com/vote?id=36818777&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Agreed, with one caveat. Over time governments have more and more been trying to influence the reports. It all came to a head with the last one, where a set of researchers released their draft ahead of time in protest over undue influence. They still synthesize relevant research from past years, but there are some problems now. Research published after the first draft cannot be included, so the report is somewhat outdated by the time it's released. Beautifully crafted though.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36818726"><td></td></tr>
                  <tr id="36821453"><td></td></tr>
            <tr id="36818660"><td></td></tr>
            <tr id="36819037"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819037" href="https://news.ycombinator.com/vote?id=36819037&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Gillian Russell, “Epistemic Viciousness in the Martial Arts,”<p>It is about traditional martial arts masters, trapped in their echo chamber, sniffing their own farts. The whole industry gets its ass kicked by mixed martial arts. Basically street thugs versus shaolin kung fu masters.</p><p>it describes in-group bias, echo chambers, and cognitive dissonance in large groups. Very applicable in modern science, politics and so on.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36817581"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36817581" href="https://news.ycombinator.com/vote?id=36817581&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>The Bitcoin whitepaper. It started my curiosity in the computer security industry (employed for 5 years now) and the rabbithole of trying to understand every design decision behind the cryptosystem.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36818276"><td></td></tr>
            <tr id="36818960"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36818960" href="https://news.ycombinator.com/vote?id=36818960&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Agreed, this is a must-read, very well-written paper. Even though it turned out the world didn't really need cryptocurrencies.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36820340"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36820340" href="https://news.ycombinator.com/vote?id=36820340&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Agree with your assessment of cryptocurrencies in general but having seen the adoption of Bitcoin in authoritarian and inflationary regimes, the world most certainly does need access to a digital peer-to-peer currency that is censorship-resistant and virtually immune to debasement.<p>Even if you argue that Bitcoin as it has evolved has flaws, it is the best implementation we’ve come up with so far. Like democracy, it isn’t perfect but it is much better for its use case than anything else we have come up with to date.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36820043"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36820043" href="https://news.ycombinator.com/vote?id=36820043&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>The Bitcoin whitepaper is one of my cherished reads. The other is the BitTorrent whitepaper. Both technologies changed the technical and non-technical worlds, and the fundamental protocols are clearly explained in their respective papers.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36818851"><td></td></tr>
            <tr id="36818368"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818368" href="https://news.ycombinator.com/vote?id=36818368&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Not sure anybody here appreciates social science, but I will never not give a shout-out to "Decoupling Rape" by Whiteman and Cooper. Such an authentic account, while still managing to stay relevant to abstract and higher-order debates in my field. I suspect many have not read it because it is so heart-wrenching though.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36818521"><td></td></tr>
                <tr id="36818709"><td></td></tr>
                        <tr id="36818604"><td></td></tr>
            <tr id="36821359"><td></td></tr>
            <tr id="36818397"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818397" href="https://news.ycombinator.com/vote?id=36818397&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Like Kleobis and Biton, we won't know until I am dead.<p>However thus far, a paper that literally changed my life: "Value Dependence Graphs: Representation Without Taxation", D. Weise, R. F. Crew, M. Ernst, B. Steensgaard, POPL 1994.  (This was the proverbial butterfly flap that moved me through three countries).</p><p>There are many many other good papers and it's not a one-dimension metric so it's hard to pick out winners.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819045"><td></td></tr>
                <tr id="36819896"><td></td></tr>
                  <tr id="36820899"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36820899" href="https://news.ycombinator.com/vote?id=36820899&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Probably this paper [1] is very well known among the classic HN audience, but I dare to leave this link here for the ones who missed it. It is an easy read and it just explains with plain words the backbone of the UNIX system as it was envisioned 50 years ago.<p>[1] <a href="https://dsf.berkeley.edu/cs262/unix.pdf" rel="nofollow noreferrer">https://dsf.berkeley.edu/cs262/unix.pdf</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819051"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819051" href="https://news.ycombinator.com/vote?id=36819051&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>"A Security Kernel Based on the Lambda-Calculus" by Jonathan A. Rees is pretty high up there: <a href="https://dspace.mit.edu/handle/1721.1/5944" rel="nofollow noreferrer">https://dspace.mit.edu/handle/1721.1/5944</a><p>I read this a few years back as I was going down an object-capability rabbit hole and found it extremely compelling. (And also made me disappointed that most of the systems we use today do not work like this! Code execution vulnerabilities would be so much less immediately hazardous if they did.)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36818522"><td></td></tr>
            <tr id="36819113"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819113" href="https://news.ycombinator.com/vote?id=36819113&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>This is probably among the best I have read: <a href="https://scholars.unh.edu/cgi/viewcontent.cgi?article=1462&amp;context=dissertation" rel="nofollow noreferrer">https://scholars.unh.edu/cgi/viewcontent.cgi?article=1462&amp;co...</a><p>In a system with growing inequality where the rich benefit at the expense of the poor, this artificial redistribution can go on for some time, but once the inequality gets so bad that people revolt, then the amount of "guard labor" that needs to be performed goes up. Poverty and desperation makes people more likely to perform "guard labor" because it gives them a chance to escape poverty and avoid being targeted themselves which further feeds into authoritarian politicians gaining more power as they have no trouble finding soldiers willing to maintain the inequality. This works but only until guard labor reaches such a critical mass that half the population engages in it. Once that point is crossed, guard labor will start defecting against the current political leadership and conduct a military coup.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36818472"><td></td></tr>
            <tr id="36819993"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819993" href="https://news.ycombinator.com/vote?id=36819993&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Congestion Avoidance and Control (1988) by Van Jacobson: <a href="https://ee.lbl.gov/papers/congavoid.pdf" rel="nofollow noreferrer">https://ee.lbl.gov/papers/congavoid.pdf</a><p>Often called "the paper which saved the internet" due to solving congestion collapse on the ARPANET, and inventing the fundamentals of TCP Congestion Control still used countless times every single day on all computers everywhere. It's very readable and presents complex math in easily understood graphs for non-math people.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36820767"><td></td></tr>
            <tr id="36818724"><td></td></tr>
            <tr id="36818995"><td></td></tr>
                <tr id="36820616"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36820616" href="https://news.ycombinator.com/vote?id=36820616&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>I remember seeing “Possible Girls” cited somewhere as an example of the pointlessness of contemporary academic philosophy, but for years I couldn't find it again. A very entertaining re-read, thanks for sharing.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819937"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819937" href="https://news.ycombinator.com/vote?id=36819937&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>A quantitative description of membrane current and its application to conduction and excitation in nerve
A L HODGKIN, A F HUXLEY
J Physiol. 1952 Aug;117(4):500-44.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36818376"><td></td></tr>
                <tr id="36818908"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36818908" href="https://news.ycombinator.com/vote?id=36818908&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Didn't think I'd come across a DTW paper here.<p>Have you seen anything worth reading in that line of literature which addresses a more practical issue of segment sizing and segment overlap on accuracy?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819023"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819023" href="https://news.ycombinator.com/vote?id=36819023&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>“What is it like to be a bat” (Nagel)<p>“The Spandrels of San Marco and the Panglossian Paradigm”, (Gould et al)</p><p>“ A quantitative description of membrane current and its application to conduction and excitation in nerve” (hodgkin and huxley)</p><p>a few other that don’t come to mind right now
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819126"><td></td></tr>
            <tr id="36818311"><td></td></tr>
            <tr id="36819093"><td></td></tr>
                <tr id="36821415"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36821415" href="https://news.ycombinator.com/vote?id=36821415&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>There's a lot of non-Chomskian linguistics out there. Basically if you look for "linguistic typology" there's a probably at least 90% chance that Chomsky will be totally irrelevant.<p>(Some of my favourites in that area used to be Martin Haspelmath, Balthasar Bickel, Gilbert Lazard, ... - but I haven't kept myself up to date with the literature for years now)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819313"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819313" href="https://news.ycombinator.com/vote?id=36819313&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>My idea of being explicit and clear changed dramatically after I was exposed to D. Harel's "Statecharts: a visual formalism for complex systems".<p>Ironically, I think the paper presents more than just the idea and examples of statecharts, rather it also _implicitly_ contains a _method_ for discovering mechanism - the long winded example of the author's digital watch, in my eyes, is a marvel.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819208"><td></td></tr>
            <tr id="36819111"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819111" href="https://news.ycombinator.com/vote?id=36819111&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Have most people read a paper? I see threads like these with some many interesting suggestion, but are they read by people outside of their general area of study or expertise? I read quite a bit of fiction, but I've never really been able to read anything much past an abstract which much understanding. I have no science background. Am I missout on something?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36820644"><td></td></tr>
            <tr id="36819246"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36819246" href="https://news.ycombinator.com/vote?id=36819246&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Generally you need background knowledge to read papers. A quick way to gain necessary background knowledge is to read literature reviews or surveys. If you can't understand even reviews, surveys, or introductions, it is time to read textbooks.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36818920"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818920" href="https://news.ycombinator.com/vote?id=36818920&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>"Retinoic Acid and Arsenic Trioxide for Acute Promyelocytic Leukemia" by Lo-Coco et al. from 2013.[0]<p>This paper presents a cure for an extremely aggressive cancer using vitamin A and arsenic. Its a unique, relatively benign treatment strategy that completely avoids chemotherapy. As far as I know this is the best result in all of oncology, though the cancer it treats is very rare.</p><p>The most well known paper in oncology that is probably more interesting to a general audience is "The Hallmarks of Cancer" by Hanahan and Weinberg.[1]</p><p>[0] <a href="https://www.nejm.org/doi/full/10.1056/nejmoa1300874" rel="nofollow noreferrer">https://www.nejm.org/doi/full/10.1056/nejmoa1300874</a></p><p>[1] <a href="https://www.cell.com/cell/fulltext/S0092-8674(00)81683-9?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867400816839%3Fshowall%3Dtrue" rel="nofollow noreferrer">https://www.cell.com/cell/fulltext/S0092-8674(00)81683-9?_re...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819128"><td></td></tr>
            <tr id="36818962"><td></td></tr>
            <tr id="36818985"><td></td></tr>
            <tr id="36818688"><td></td></tr>
                <tr id="36818888"><td></td></tr>
                <tr id="36818987"><td></td></tr>
                        <tr id="36819024"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819024" href="https://news.ycombinator.com/vote?id=36819024&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>I can give example of one of worst papers.<p>Original IPFS paper is one of worst papers that I had read.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36820673"><td></td></tr>
                  <tr id="36819087"><td></td></tr>
            <tr id="36819066"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819066" href="https://news.ycombinator.com/vote?id=36819066&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Lisanne Bainbridge, Ironies of Automation. Especially timely now when every company is bolting a LLM onto the side of their software.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36820388"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36820388" href="https://news.ycombinator.com/vote?id=36820388&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Not a paper, but <i>The Extravagant Universe</i> by Robert Kirschner describes decades worth of observation and data collection in astronomy, coming together with experimental discoveries from particle colliders and evolving theory in order to eventually converge upon the now-standard ΛCDM model in cosmology. Also includes an enormous background on the century worth of discoveries that eventually resulted in the type-1A supernova becoming a sufficiently reliable standard candle to measure the distance to galaxies far enough away that the redshift demonstrated accelerating expansion of the universe. So many things they needed to work out, from dust diffraction patterns to the differences in how spectrum evolves over the two weeks or so from the initial explosion event to figure out exactly when in the timeline each observation is taking place. Combine that with the logistics of telescope scheduling and the sparsity of observations when you're looking at something as large as the entire universe and your telescope can only cover so much at any one time. It gives you a tremendous appreciation for the sheer amount of work and patience that goes into this, slowly collecting evidence over decades, waiting for technology to develop before certain evidence is even possible to collect, and eventually seeing lines of evidence all point in the same direction, but only after a literal lifetime of work to get there.<p>Nothing else has ever made me appreciate how hard science really is and how little the general public understands it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mali Government takes back .ml domain, brings down one of largest Lemmy servers (111 pts)]]></title>
            <link>https://very.bignutty.xyz/notes/9hfv05qcs5xf7irr</link>
            <guid>36817179</guid>
            <pubDate>Fri, 21 Jul 2023 18:00:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://very.bignutty.xyz/notes/9hfv05qcs5xf7irr">https://very.bignutty.xyz/notes/9hfv05qcs5xf7irr</a>, See on <a href="https://news.ycombinator.com/item?id=36817179">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="splash"><p><img id="splashIcon" src="https://very.bignutty.xyz/static-assets/splash.svg?1689984012144"><span id="splashText">Loading...</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Death Valley Just Had the Hottest Midnight on Record (102 pts)]]></title>
            <link>https://www.msn.com/en-us/weather/topstories/death-valley-just-had-the-hottest-midnight-on-record/ar-AA1e2u4W</link>
            <guid>36817046</guid>
            <pubDate>Fri, 21 Jul 2023 17:50:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.msn.com/en-us/weather/topstories/death-valley-just-had-the-hottest-midnight-on-record/ar-AA1e2u4W">https://www.msn.com/en-us/weather/topstories/death-valley-just-had-the-hottest-midnight-on-record/ar-AA1e2u4W</a>, See on <a href="https://news.ycombinator.com/item?id=36817046">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[There’s a heatwave in the sea and scientists are worried (144 pts)]]></title>
            <link>https://www.bbc.com/future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried</link>
            <guid>36816982</guid>
            <pubDate>Fri, 21 Jul 2023 17:45:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried">https://www.bbc.com/future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried</a>, See on <a href="https://news.ycombinator.com/item?id=36816982">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="headline-futurearticle20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried"><div><p>(Image credit: </p><!-- --><p>European Union/Copernicus Sentinel-2</p><!-- --><p>)</p></div><div><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237hm.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237hm.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237hm.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237hm.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237hm.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237hm.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237hm.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237hm.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Satellite image of coral bleaching at Islamorada, Florida (Credit: European Union/Copernicus Sentinel-2)" src="https://ychef.files.bbci.co.uk/976x549/p0g237hm.jpg" alt="Satellite image of coral bleaching at Islamorada, Florida (Credit: European Union/Copernicus Sentinel-2)" id=""></picture></div></div><div><article><div><p>Could warmer ocean temperatures be a sign climate change has progressed further than we thought?</p><div><p>T</p><div><p>The month of June and the first few days of July were hotter than any in recorded history, <a href="https://public.wmo.int/en/media/news/preliminary-data-shows-hottest-week-record-unprecedented-sea-surface-temperatures-and">according to the World Meteorological Organization (WMO)</a>. Residents in the south of the US and <a href="https://www.bbc.com/news/world-europe-66242277">southern Europe</a> have been enduring sweltering temperatures, bringing <a href="https://www.bbc.co.uk/news/world-us-canada-66218321">excessive heat warnings</a>, <a href="https://www.bbc.com/news/science-environment-66237960">wildfires</a> and <a href="https://www.bbc.com/reel/video/p0fz7y12/why-extreme-heat-makes-air-quality-worse">plummeting air quality</a>. However, records are not just being broken on land – but in the water.</p>
<p>Global ocean sea surface temperatures were higher than any previous June on record, according to a <a href="https://climate.copernicus.eu/copernicus-record-north-atlantic-warmth-hottest-june-record-globally">report by the Copernicus Climate Change Service</a>, with satellite readings in the <a href="https://climate.copernicus.eu/record-breaking-north-atlantic-ocean-temperatures-contribute-extreme-marine-heatwaves">North Atlantic in particular "off the charts</a>". Last month also <a href="https://www.noaa.gov/news/earth-just-had-its-hottest-june-on-record">set a record</a> at the US National Oceanic and Atmospheric Administration (NOAA) for the biggest difference between expected and actual sea surface temperatures.</p>
<p><a href="https://www.noaa.gov/news/ongoing-marine-heat-waves-in-us-waters-explained">Water temperatures around Florida</a>, in particular, <a href="https://twitter.com/BMcNoldy/status/1678095286206382086">have been particularly warm</a>. Scientists have also been <a href="https://www.integratedecosystemassessment.noaa.gov/regions/california-current/california-current-marine-heatwave-tracker-blobtracker">tracking a large ongoing marine heatwave off the west coast of the US and Canada</a>&nbsp;since it formed in May.</p>
<p>While the heatwave has since lessened in the north-east Atlantic, according to non-profit science organisation&nbsp;<a href="https://www.mercator-ocean.eu/en/news/mercator-ocean-marine-heatwave-bulletin-for-11-july-2023">Mercator Ocean</a> International, another in the western Mediterranean now appears to be intensifying, particularly around the Strait of Gibraltar. This week, sea surface temperatures along the coasts of Southern Spain and North Africa were 2-4C (3.6-7.2F) higher than they would normally be at this time of year, with some spots 5C (9F) above the long-term average.</p>
<p>Extreme marine temperatures have also recently been observed around <a href="https://www.esa.int/ESA_Multimedia/Images/2023/06/UK_suffers_marine_heatwave">Ireland, the UK and in the Baltic Sea</a>, as well as <a href="https://www.mercator-ocean.eu/en/news/sea-surface-temperatures-record-high-2023/">areas near New Zealand and Australia</a>. More recently, scientists <a href="https://www.mercator-ocean.eu/en/news/marine-heatwaves-europe-july-18-2023/">suspect a possible heatwave</a> south of Greenland in the Labrador Sea.</p>
<p>"We are having these huge marine heatwaves in different areas of the ocean unexpectedly evolve very early in the year, very strong and over large areas," says Karina von Schuckmann, an oceanographer at Mercator Ocean.</p></div></div><div id="future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried-p0g237dg"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237dg.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237dg.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237dg.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237dg.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237dg.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237dg.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237dg.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237dg.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="The northern Atlantic Ocean and Mediterranean Sea have experienced record-breaking sea temperatures over the past few months (Credit: European Union/Copernicus)" src="https://ychef.files.bbci.co.uk/976x549/p0g237dg.jpg" alt="The northern Atlantic Ocean and Mediterranean Sea have experienced record-breaking sea temperatures over the past few months (Credit: European Union/Copernicus)" id=""></picture><div><p>The northern Atlantic Ocean and Mediterranean Sea have experienced record-breaking sea temperatures over the past few months (Credit: European Union/Copernicus)</p></div></div><div><p>Carlo Buontempo, director of the European Union's Copernicus Climate Change Service, says scientists expect big temperature variations in the Pacific Ocean associated with the <a href="https://www.bbc.com/future/article/20230525-what-will-an-el-nino-in-2023-mean-for-you">El Niño weather</a> pattern, a phase of planet-warming weather <a href="https://www.bbc.co.uk/news/science-environment-65839060">which is just beginning</a><em>, </em>although NOAA is <a href="https://www.noaa.gov/news/ongoing-marine-heat-waves-in-us-waters-explained">monitoring</a> a large heatwave in the Gulf of Alaska that has been sitting offshore since late 2022. (<em>Read more from BBC Future about <a href="https://www.bbc.com/future/article/20230525-what-will-an-el-nino-in-2023-mean-for-you">what another El Niño will mean for you</a></em>.)</p>
<p>But what we're currently seeing in the North Atlantic is "truly unprecedented", says Buontempo.</p>
<p>Scientists are still trying to unravel its full causes.</p>
<p>Short-term changes in regional atmospheric and ocean circulation patterns can provide the conditions for periods of intense heat in the sea lasting for weeks, months or even years.</p>
<p>But long-term increases in ocean temperature driven by an increase in greenhouse gas emissions are a key factor in recent heatwaves. About 90% of excess heat generated by anthropogenic climate change has been stored in the ocean, and the past two decades have seen a <a href="https://essd.copernicus.org/articles/15/1675/2023/essd-15-1675-2023.html">doubling in the rate of heat</a> accumulating in the Earth's climate system.</p>
<p><em>You might also like:</em></p>
<ul>
<li><strong><a href="https://www.bbc.com/future/article/20230706-the-simple-ways-cities-can-adapt-to-heatwaves">The simple ways cities can adapt to heatwaves</a>)</strong></li>
<li><strong><a href="https://www.bbc.com/future/article/20230718-the-fiery-row-behind-europes-mythological-heatwave-names">The fiery row behind Europe's mythological heatwave names</a></strong></li>
<li><strong><a href="https://www.bbc.com/future/article/20230630-will-texas-become-too-hot-for-humans">Will Texas become too hot for humans?</a></strong></li>
</ul>
<p>A 2021 <a href="https://www.ipcc.ch/report/ar6/wg1/chapter/chapter-9/">expert report</a> by the Intergovernmental Panel on Climate Change (IPCC) found marine heatwaves doubled in frequency between 1982 and 2016, and have become both more intense and longer since the 1980s.</p>
<p>Another potential contributing factor is the volume of aerosols in the atmosphere, which <a href="https://earthobservatory.nasa.gov/features/Aerosols">have a slight cooling effect</a> but appear to <a href="https://www.nasa.gov/feature/esnt/2022/nasa-study-finds-evidence-that-fuel-regulation-reduced-air-pollution-from-shipping">have dropped</a> as a result of a drive to clean up the shipping industry. More recently, there has been an unusual lack of dust blown from the Sahara, which also normally has <a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021JC017282">a cooling impact</a>.</p></div><div><p>The current marine heatwaves could even get worse. While experts do not think <a href="https://public.wmo.int/en/media/press-release/world-meteorological-organization-declares-onset-of-el-ni%C3%B1o-conditions">El Niño</a> itself was a driver of the North Atlantic event, <a href="https://public.wmo.int/en/media/news/preliminary-data-shows-hottest-week-record-unprecedented-sea-surface-temperatures-and">the WMO expects it</a> to add fuel to wider ocean heating.</p>
<p>Experts are concerned because marine heatwaves can affect ocean life, fisheries and weather patterns.</p>
<p>Record high temperatures along the Western Australian coast during the summer of 2010/2011 resulted in "<a href="https://www.sciencedirect.com/science/article/abs/pii/S0924796312002059?via%3Dihub">devastating" fish mortality</a>&nbsp;and destroyed kelp forests, <a href="https://link.springer.com/chapter/10.1007/978-3-030-71330-0_12">fundamentally changing the coastal ecosystem</a>. Several years later, an unprecedented marine heatwave caused by climate change and amplified by a strong El Niño caused <a href="https://elibrary.gbrmpa.gov.au/jspui/bitstream/11017/3206/1/Final-report-2016-coral-bleaching-GBR.pdf">the worst coral bleaching ever seen</a> on the Great Barrier Reef in 2016.</p>
<p>Marine heatwaves can <a href="https://www.nature.com/articles/s41598-018-24530-9">trigger mass coral bleaching events</a> and have already been increasing the <a href="https://www.nature.com/articles/s41586-018-0041-2">stress that reef ecosystems</a> are under around the world. The high termpeatures can cause the coral polyps to expel the zooxanthellae living inside their tissue, causing them to turn white and leaving them <a href="https://oceanservice.noaa.gov/facts/coral_bleach.html">more vulnerable to disease and other threats</a>.</p>
<p>In the Mediterranean Sea, exceptional temperatures over the 2015-19 period led to <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/gcb.16301">repeated mass deaths</a> of key species such as corals and seaweed. <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-marine-032122-121437">One recent study</a> described marine heatwaves such as these as "pervasive stressors to marine ecosystems globally".</p>
<p>Marine heatwaves are also making it easier for <a href="https://www.iucn.org/resources/issues-briefs/invasive-alien-species-and-climate-change">invasive species</a> to thrive. Japanese kelp, for example, <a href="https://www.frontiersin.org/articles/10.3389/fmars.2019.00084/full">proliferated in New Zealand</a> when a marine heatwave in 2017-2018 in the Tasman Sea killed off <a href="https://www.frontiersin.org/articles/10.3389/fmars.2019.00084/full">native southern bull kelp</a> in the area.</p>
<p>Dan Smale, a marine ecologist at the UK's Marine Biological Association and a member of the <a href="http://www.marineheatwaves.org/">Marine Heatwaves International Working Group</a>, says "short, sharp shocks" do not give species time to redistribute and <a href="https://www.nature.com/articles/s41558-019-0412-1">those at the limit of temperatures their bodies can cope with are particularly at risk</a>. But even around the UK coastline, which is not considered to be an extreme environment and where scientists expect ecosystems to gradually change, a marine heatwave could end up being lethal if it continues through the summer.&nbsp;</p>
<p>However, there is still a lot to learn about the impact of marine heatwaves compared with those on land because monitoring is more difficult and there is a lack of long-term records, says Smale. "The data we get from satellites since the early 1980s has been amazing… but the problem is trying to then go deeper," he says.</p></div><div id="future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried-p0g237j6"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237j6.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237j6.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237j6.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237j6.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237j6.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237j6.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237j6.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237j6.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="High water temperatures can destroy vital marine habitats such as kelp forests, which offer sanctuary and provide food for many fish species (Credit: Getty Images)" src="https://ychef.files.bbci.co.uk/976x549/p0g237j6.jpg" alt="High water temperatures can destroy vital marine habitats such as kelp forests, which offer sanctuary and provide food for many fish species (Credit: Getty Images)" id=""></picture><div><p>High water temperatures can destroy vital marine habitats such as kelp forests, which offer sanctuary and provide food for many fish species (Credit: Getty Images)</p></div></div><div><p>A significant drop in phytoplankton <a href="https://www.mercator-ocean.eu/en/news/record-high-sea-surface-temperatures-north-atlantic-drop-in-phytoplankton-el-nino-costal-el-nino/">has already been seen</a> in the western North Atlantic, which Mercator Ocean attributes to the recent heatwave. This spring bloom is crucial because it <a href="https://www.mccip.org.uk/sites/default/files/2021-07/15_plankton_2020.pdf">provides most of the energy</a> needed to sustain the region's marine food chain and makes a substantial contribution to global ocean CO2 uptake.</p>
<p>The economics of regional fisheries could be affected too. A 2012 heatwave over the north-west Atlantic led marine species that favour warm water to move northwards and migrate earlier, <a href="https://tos.org/oceanography/article/fisheries-management-in-a-changing-climate-lessonsfrom-the-2012-ocean-heat-">changing when and how much</a> seafood could be caught.</p>
<p>The North Atlantic is also a key driver of extreme weather. High sea surface temperatures <a href="https://www.nasa.gov/audience/forstudents/k-4/stories/nasa-knows/what-are-hurricanes-k4.html">can fuel hurricanes</a>, although whether the developing El Niño will exacerbate or <a href="https://doi.org/10.1175/JCLI-D-13-00687.1">dampen this effect</a> over the next year remains to be seen. Further inland, the warmth of the North Atlantic is the most important factor behind the alternating cycle of drought and heavy rain in <a href="https://earthobservatory.nasa.gov/images/88670/atlantic-multi-decadal-oscillation-and-drought-in-africa">central Africa</a>.</p>
<p>More broadly, experts say the persistence of recent marine heatwaves is a worrying sign about how climate change is unfolding, alongside <a href="https://www.bbc.co.uk/news/world-europe-66197368">heatwaves on land</a>, unusual <a href="https://www.researchgate.net/publication/371731505_Water_ice_society_and_ecosystems_in_the_Hindu_Kush_Himalaya_An_outlook">melting of snow cover in the Himalayas</a> and a <a href="https://www.bbc.com/news/science-environment-64649596">loss of sea ice</a>. Von Schuckmann notes that, even if humans stopped pumping CO2 into the air tomorrow, the oceans would continue to warm up for many years yet. "I am concerned as a climate scientist that we are further than we thought we are."</p>
<p>--</p>
<p><em>Join one million Future fans by liking us on </em><a href="https://www.facebook.com/BBCFuture/"><strong><em>Facebook</em></strong></a><em>, or follow us on </em><a href="https://twitter.com/BBC_Future"><strong><em>Twitter</em></strong></a><em> or </em><a href="https://www.instagram.com/bbcfuture_official/"><strong><em>Instagram</em></strong></a><em>.</em></p>
<p><em>If you liked this story, </em><a href="https://cloud.email.bbc.com/SignUp10_08"><strong><em>sign up for the weekly bbc.com features newsletter</em></strong></a><em>, called "The Essential List" – a handpicked selection of stories from BBC </em><a href="https://www.bbc.com/future/"><strong><em>Future</em></strong></a><em>, </em><a href="https://www.bbc.com/culture/"><strong><em>Culture</em></strong></a><em>, </em><a href="https://www.bbc.com/worklife/"><strong><em>Worklife</em></strong></a><em>, </em><a href="https://www.bbc.com/travel/"><strong><em>Travel</em></strong></a> <em>and </em><a href="https://www.bbc.com/reel"><strong><em>Reel</em></strong></a><em> delivered to your inbox every Friday.</em></p></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Mystery company' buys land worth $800M near Travis AFB, raising concerns (105 pts)]]></title>
            <link>https://abc7news.com/travis-afb-air-force-base-flannery-associates-llc-john-garamendi/13527836/</link>
            <guid>36816387</guid>
            <pubDate>Fri, 21 Jul 2023 17:00:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abc7news.com/travis-afb-air-force-base-flannery-associates-llc-john-garamendi/13527836/">https://abc7news.com/travis-afb-air-force-base-flannery-associates-llc-john-garamendi/13527836/</a>, See on <a href="https://news.ycombinator.com/item?id=36816387">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-testid="prism-article-body"><p><span>FAIRFIELD, Calif. (KGO) -- </span>The United States Air Force is investigating a company that's purchased $800 million of land near Travis Air Force Base, one of the most critical military bases in the U.S. But after eight months of investigation, government officials have been unable to identify who's behind it nor rule out any threat to national security.</p><p>"We're very, very concerned about this," said Rep. John Garamendi (D-CA08). "It's so extensive and so secret and it's impossible to get any information about what's happening here."</p><p>Congressman Garamendi raised the alarm to the U.S. Air Force -- prompting a federal investigation.</p><p><b>MORE: <a data-testid="prism-linkbase" href="https://abc7news.com/chinese-surveillance-balloon-antony-blinken-spy-operation-photos/12788242/">Chinese surveillance balloon part of massive program over 5 continents: Blinken</a></b></p><p><b>Stephanie Sierra:</b> "In your briefings on the matter, do you have any reason to believe the purchase of this land is for spying?"</p><p><b>Rep. Garamendi:</b> "I have every reason in the world to believe that this land is adjacent to a critical national security platform Travis Air Force Base. Therefore -- an area where spy operations or any other nefarious activity could take place...that could detrimentally impact the ability of Travis Air Force Base to operate in a moment of national emergency."</p><p>Public records show the company "Flannery Associates LLC" began purchasing land around the military base in 2018. The controversy was first reported by the <a data-testid="prism-linkbase" rel="nofollow" href="https://www.wsj.com/articles/investors-bought-nearly-1-billion-in-land-near-a-california-air-force-base-officials-want-to-know-who-exactly-they-are-fd868e38" target="_blank">Wall Street Journal</a>. Investigators say those acquisitions ramped up in 2023.</p><p>"Now literally three sides of that base are totally controlled by the Flannery group," Rep. Garamendi said.</p><p>Yet no one - including local, state, and federal officials -- can seem to track down who's behind the group.</p><p>"Who are these people?" Garamendi said. "Where did they get the money where they could pay five to ten times the normal value that others would pay for this farmland?"</p><p>Even after eight months of investigation, Garamendi says federal authorities are still struggling to get those answers.</p><p><b>MORE: <a data-testid="prism-linkbase" href="https://abc7news.com/jonathan-and-diana-toebbe-spy-couple-nuclear-submarine-navy-engineer/12435396/">Navy engineer, wife sentenced after trying to sell US nuclear submarines secrets</a></b></p><p>"To this day we don't know where these people are coming from," Garamendi said.</p><p><a data-testid="prism-linkbase" href="https://abc7news.com/about/newsteam/stephanie-sierra/">I-Team reporter Stephanie Sierra</a> asked Garamendi if there is any reason to believe China is tied to this group.</p><p>"I have reason to be concerned," he responded.</p><p>Last year 300 acres of farmland were purchased near Minot Air Force Base in North Dakota. Garamendi called it a '"spy base."</p><p>"That base is where we launch our airplanes to figure out what's going on across the world," he said. "A company in China was acquiring land around that base and wanted to build a 400-foot silo that could look directly into the base... and we were like 'whoa, whoa, whoa, what's going on there?'"</p><p>Garamendi says the attorney representing Flannery Associates indicated the firm is made up of a group of families, 97 percent of whom are allegedly American, looking to diversify their portfolio from equities to real assets - including agricultural land.</p><p>But the congressman is skeptical.</p><p>"We have heard scheme after scheme that makes no sense at all," Rep. Garamendi said. "We're going to build a deep water port. Really? Around Travis Air Force Base? Which is 10 miles from the Bay. No, you're not... We're going to farm... well at that price you're going to lose a lot of money farming. Well, we're going to build a city... No, you're not going to build a city...so none of the reasons why the land is being acquired make any sense at all."</p><p><b>MORE: <a data-testid="prism-linkbase" href="https://abc7news.com/homes-near-travis-air-force-base-affordable-housing-solano-county-houses-in-fairfield-georgetown-project/9016432/">Why 300 homes next to Travis AFB have been sitting empty for a decade</a></b></p><p>The attorney representing Flannery Associates sent a letter to the U.S. Dept. of Agriculture, one of several agencies investigating the matter, issuing a formal response.</p><p><i>"No foreign person or group holds any significant interest or substantial control over Flannery, either now or at the time of any land purchase made by Flannery,"</i> the letter said.</p><p>The company added they don't comment on its investments.</p><p><b>Sierra:</b> "What do you think is happening?"</p><p><b>Rep. Garamendi:</b> "I don't know, it doesn't make any sense... It's the secrecy... Why are you doing this in secret? If you're not a nefarious operation, why are you keeping it secret?"</p><p>According to Garamendi, Flannery Associates has also acquired land around the interstate electrical grid system stemming from the Columbia River into Central California - including land that houses wind turbines that provide significant power into Northern California.</p><p>In the meantime, Garamendi says the company continues to negatively impact the farming community in Solano County. He says at least 10 landowners are being sued by Flannery, accused of being engaged in an illegal scheme to prevent the company from buying their land.</p><p><b>Take a look at more <a data-testid="prism-linkbase" href="https://abc7news.com/iteam/">stories and videos by the ABC7 News I-Team.</a></b> </p><div data-testid="prism-inline-image"><figure data-testid="prism-figure"><a data-testid="prism-linkbase" href="https://abc7news.com/abc-news-live-local-watch/11513295/"><img alt="Now Streaming 24/7 Click Here" data-testid="prism-image" draggable="false" src="https://cdn.abcotvs.com/dip/images/11518842_247-NOWSTREAMING_1280x720.png"></a><figcaption></figcaption></figure></div><p> <i>If you're on the ABC7 News app, <a data-testid="prism-linkbase" href="https://abc7news.com/abc-news-live-local-watch/11513295/">click here to watch live</a></i></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Diablo (226 pts)]]></title>
            <link>https://www.filfre.net/2023/07/diablo/</link>
            <guid>36815781</guid>
            <pubDate>Fri, 21 Jul 2023 16:25:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.filfre.net/2023/07/diablo/">https://www.filfre.net/2023/07/diablo/</a>, See on <a href="https://news.ycombinator.com/item?id=36815781">Hacker News</a></p>
Couldn't get https://www.filfre.net/2023/07/diablo/: Error: Request failed with status code 404]]></description>
        </item>
        <item>
            <title><![CDATA[‘World of Warcraft’ players trick AI-scraping website into publishing nonsense (317 pts)]]></title>
            <link>https://www.forbes.com/sites/paultassi/2023/07/21/world-of-warcraft-players-trick-ai-scraping-games-website-into-publishing-nonsense/</link>
            <guid>36815744</guid>
            <pubDate>Fri, 21 Jul 2023 16:22:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.forbes.com/sites/paultassi/2023/07/21/world-of-warcraft-players-trick-ai-scraping-games-website-into-publishing-nonsense/">https://www.forbes.com/sites/paultassi/2023/07/21/world-of-warcraft-players-trick-ai-scraping-games-website-into-publishing-nonsense/</a>, See on <a href="https://news.ycombinator.com/item?id=36815744">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure role="presentation"><figcaption><fbs-accordion><p>The story</p></fbs-accordion><small>Zleague, I mean reddit</small></figcaption></figure>
<p>As someone who writes about video games for a living, I am deeply annoyed/terrified about the prospect of AI-run websites not necessarily replacing me, but doing things like at the very least, crowding me out of Google, given that Google does not seem to care whatsoever whether content is AI-generated or not.</p>


<p>That’s why it’s refreshing to see a little bit of justice dished out in a very funny way from a gaming community. The <em>World of Warcraft</em> subreddit recently realized that a website, zleague.gg (I am not linking to it), which runs a blog attached to some of sort of gaming app which is its main business, has been scraping reddit threads, feeding them through an AI and summarizing them with “key takeaways” and regurgitated paragraphs that all follow the same format. It’s gross, and yet it generates an article long enough with enough keywords to show up on Google.</p>

<p>Well, the redditors got annoyed and decided to mess with the bots. On r/WoW, they made <a href="https://www.reddit.com/r/wow/comments/154umm2/im_so_excited_they_finally_introduced_glorbo/" target="_blank" title="https://www.reddit.com/r/wow/comments/154umm2/im_so_excited_they_finally_introduced_glorbo/" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.reddit.com/r/wow/comments/154umm2/im_so_excited_they_finally_introduced_glorbo/" aria-label="a lengthy thread discussing the arrival of Glorbo in the game">a lengthy thread discussing the arrival of Glorbo in the game</a>, a new feature that, as you may be able to guess from the name, is not real.</p>


<blockquote>
 “I have to say, since they started hinting at it in Hearthstone in 1994, it was obvious that they would introduce Glorbo to World of Warcraft sooner or later. I feel like Dragonflight has been win after win so far, like when they brought back Chen Stormstout as the end boss of the new Karazhan? Absolutely amazing!”
</blockquote>
<p>And it…worked. Zleague auto-published a post titled “World of Warcraft Players Excited For Glorbo’s Introduction. Here’s are the “key takeaways”:</p>


<ul>
 <li>“Players express excitement for Glorbo’s arrival and its potential impact on the game.”</li>
 <li>“Some players have reservations about the mandatory item Klikclac and its effect on casual players.”</li>
 <li>“Rumors of Stormsong Valley becoming the new location for the Halfhill Market and farming sim mini-game generate enthusiasm.”</li>
 <li>“Appreciation for previous game changes, such as the inclusion of Klaxxi as a playable race.”</li>
</ul>


<p>That is… all essentially nonsense. The article was left online for a while but has finally been taken down (<a href="https://archive.ph/4mOWr#selection-1103.139-1103.245" target="_blank" title="https://archive.ph/4mOWr#selection-1103.139-1103.245" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://archive.ph/4mOWr#selection-1103.139-1103.245" aria-label="here’s a mirror, it’s hilarious">here’s a mirror, it’s hilarious</a>). All the authors listed as having bylines on the site are fake. It appears this entire thing is run with close to zero oversight.</p>

<p>It’s a weird situation because the site is not “stealing” in the traditional sense, directly plagiarizing without credit. It is citing reddit threads and their authors and even embedding the reddit post a lot of the time. But while getting story ideas from reddit and expanding on them is one thing, given that these are often the biggest communities for individual games on the internet, it’s a different matter to simply auto-feed reddit threads into an AI and have them spit this out. But again, there’s nothing to stop this. These subreddits can’t <em>only</em> fill themselves with joke articles to screw up a site like this, even if this one specific example is good for a laugh.</p>


<p>The only way this will ever be stopped is if Google steps in and dramatically deranks or bans AI-based sites like this, as begging for Google traffic crumbs is the only reason these sites exist in the first place. But since Google has its own very obvious vested interest in AI, I am not holding my breath.</p>
<p>Anyway, get hyped for Glorbo, I hear it’s the best change since the quest to depose Quackion, the Aspect of Ducks.</p>
<p><strong><em>Follow me </em></strong><a href="https://twitter.com/PaulTassi" target="_blank" title="https://twitter.com/PaulTassi" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://twitter.com/PaulTassi" aria-label="on Twitter"><strong data-ga-track="ExternalLink:https://twitter.com/PaulTassi"><em data-ga-track="ExternalLink:https://twitter.com/PaulTassi">on Twitter</em></strong></a><strong><em>, </em></strong><a href="https://www.threads.net/@paul.tassi" target="_blank" title="https://www.threads.net/@paul.tassi" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.threads.net/@paul.tassi" aria-label="Threads"><strong data-ga-track="ExternalLink:https://www.threads.net/@paul.tassi"><em data-ga-track="ExternalLink:https://www.threads.net/@paul.tassi">Threads</em></strong></a><strong><em>, </em></strong><a href="https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1" target="_blank" title="https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1" aria-label="YouTube"><strong data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1"><em data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1">YouTube</em></strong></a><a href="https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ" target="_blank" title="https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ" aria-label=","><strong data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ"><em data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ">,</em></strong></a> <strong><em>and </em></strong><a href="https://www.instagram.com/paul.tassi/?hl=en" target="_blank" title="https://www.instagram.com/paul.tassi/?hl=en" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.instagram.com/paul.tassi/?hl=en" aria-label="Instagram"><strong data-ga-track="ExternalLink:https://www.instagram.com/paul.tassi/?hl=en"><em data-ga-track="ExternalLink:https://www.instagram.com/paul.tassi/?hl=en">Instagram</em></strong></a><strong><em>. Subscribe to my free weekly content round-up newsletter, </em></strong><a href="https://paultassi.substack.com/welcome" target="_blank" title="https://paultassi.substack.com/welcome" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://paultassi.substack.com/welcome" aria-label="God Rolls"><strong data-ga-track="ExternalLink:https://paultassi.substack.com/welcome"><em data-ga-track="ExternalLink:https://paultassi.substack.com/welcome">God Rolls</em></strong></a><strong><em>.</em></strong></p>
<p><strong><em>Pick up my sci-fi novels the </em></strong><a href="https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition" target="_blank" title="https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition" aria-label="Herokiller series"><strong data-ga-track="ExternalLink:https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition"><em data-ga-track="ExternalLink:https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition">Herokiller series</em></strong></a> <strong><em>and </em></strong><a href="https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk" target="_blank" title="https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk" aria-label="The Earthborn Trilogy"><strong data-ga-track="ExternalLink:https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk"><em data-ga-track="ExternalLink:https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk">The Earthborn Trilogy</em></strong></a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RFC 9420 a.k.a. Messaging Layer Security (164 pts)]]></title>
            <link>https://blog.phnx.im/rfc-9420-mls/</link>
            <guid>36815705</guid>
            <pubDate>Fri, 21 Jul 2023 16:19:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.phnx.im/rfc-9420-mls/">https://blog.phnx.im/rfc-9420-mls/</a>, See on <a href="https://news.ycombinator.com/item?id=36815705">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>Today, the Messaging Layer Security (MLS) protocol has been published as <a href="https://datatracker.ietf.org/doc/html/rfc9420?ref=blog.phnx.im">RFC 9420</a>, a standards track document by the Internet Engineering Task Force (IETF). MLS is the first standardized and fully specified end-to-end encryption protocol. The specification is freely accessible, and its security has been analyzed in a series of academic publications.</p><p>Our team has been involved in the design and development of the MLS protocol since the very beginning. Over the course of five years, along with others from the MLS IETF working group, we have iterated to combine modern academic proposals with real-life requirements from the industry. The protocol has already proven its aptitude in large-scale deployments with major companies like Cisco and RingCentral having already integrated an early version of MLS into their products, serving millions of users.</p><p>This blog post gives a high-level overview of MLS, its practical applications, and why it matters.</p><h2 id="the-early-days-and-the-standardization-process">The early days and the standardization process</h2><p>Prior to MLS, a comprehensive specification of a protocol for end-to-end encryption informed by industry-wide input did not exist.</p><p>Protocols like the <a href="https://otr.cypherpunks.ca/?ref=blog.phnx.im">Off-the-Record protocol</a>, the <a href="https://wickr.com/wickrs-messaging-protocol/?ref=blog.phnx.im">Wickr protocol</a>, and the <a href="https://www.signal.org/docs/?ref=blog.phnx.im">Signal protocol</a> paved the way with modern security properties and asynchronous messaging capabilities.</p><p>The Signal protocol introduced the asynchronous mode of operation the Off-the-Record protocol was lacking and has made end-to-end encryption available to mobile messaging. It has since become the reference for practical and high-quality end-to-end encryption. However, a <a href="https://github.com/SilentCircle/libzina?ref=blog.phnx.im">few</a> <a href="https://github.com/wireapp/proteus?ref=blog.phnx.im">derivatives</a> <a href="https://gitlab.matrix.org/matrix-org/olm?ref=blog.phnx.im">emerged</a> due to the lack of both a full specification and permissively licensed implementations. These derivatives have seen different levels of analysis and every provider has had to maintain their own libraries.</p><p>Generally, existing protocols were typically focused on end-to-end encryption between two peers. Using them to protect group chats with many peers proved difficult and either meant compromising on security properties or accepting high computational and bandwidth costs.</p><p><a href="https://www.mozilla.org/?ref=blog.phnx.im">Various</a> <a href="http://cisco.com/?ref=blog.phnx.im">stakeholders</a> <a href="http://facebook.com/">from</a> <a href="http://google.com/?ref=blog.phnx.im">the</a> <a href="http://wire.com/?ref=blog.phnx.im">industry</a> <a href="https://www.ox.ac.uk/?ref=blog.phnx.im">and</a> <a href="http://inria.fr/?ref=blog.phnx.im">academia</a> identified these gaps and started initial talks for an open standard for asynchronous group messaging with modern security properties solving an entire range of issues. In March 2018, these “<a href="https://datatracker.ietf.org/meeting/101/materials/minutes-101-mls-00?ref=blog.phnx.im">Birds of a Feather” finally flocked together</a> and the MLS working group was subsequently established.</p><p>During the protocol design process, the working group followed an iterative approach that involved multiple rounds of review, feedback, and refinement. Regular members of the working group, as well as other interested individuals, carefully reviewed the Internet-Drafts, providing feedback, suggesting changes, and engaging in technical discussions. Numerous cryptographic experts from academia and industry analyzed MLS and the different security guarantees it aims to provide, sharing their findings in <a href="https://datatracker.ietf.org/doc/html/draft-ietf-mls-architecture-10?ref=blog.phnx.im#name-cryptographic-analysis-of-t">several academic publications</a>. This was particularly beneficial to mitigate security issues before deploying it in production environments.</p><h2 id="how-is-mls-different-from-existing-protocols">How is MLS different from existing protocols?</h2><p>Compared to existing protocols such as the Off-the-Record and the Signal protocol, MLS offers improvements in multiple ways.</p><h2 id="efficiency-do-more-with-less">Efficiency: Do more with less</h2><p>Secure messaging protocols in use today were designed as one-to-one protocols, with group messaging functionality built directly from one-to-one channels between all group members. This leaves the sender of a message to encrypt and upload a message for each other group member individually, leading to a complexity of O(n), where n is the number of members in a group. In contrast, MLS typically has costs of O(log n) for the same scenario, making it well-suited even for large groups.</p><p>Constructions such as <a href="https://www.whatsapp.com/security/WhatsApp-Security-Whitepaper.pdf?ref=blog.phnx.im">Sender Keys</a> improve the efficiency of the approach of one-to-one protocols, however, their security guarantees do not reach those of the base protocol. In particular, achieving good <em>Post-Compromise Security</em> guarantees is prohibitively expensive with Sender Keys. In other words, removing users from a group chat or ensuring a compromised device has no long-term negative impact incurs high bandwidth and computation costs for all members of the group. To recover from a compromise of a single member of the group, all other members have to broadcast an update of their key material. This leads to an overall cost of computation and bandwidth of O(n^2) for a group size of n and requires all group members to come online at least once. In contrast, MLS has an update operation with complexity of O(log n) &nbsp;that requires only the compromised member to be online for the group to recover from the compromise.</p><p>MLS achieves its low complexity through the use of a binary tree. This means that the number of required operations and the payload size do not increase linearly with the group size but rather only logarithmically after a short warm-up period. Example: In a group with 1000 members, the number of required operations to calculate new group keys would only be 10 as opposed to 1000 with existing protocols. With an assumed base payload size of 100 B per key negotiation, the total payload size would only be 1 KB instead of 100 KB.</p><figure><img src="https://blog.phnx.im/content/images/2023/07/MLS-performance-projection-1.png" alt="" loading="lazy" width="2000" height="1600" srcset="https://blog.phnx.im/content/images/size/w600/2023/07/MLS-performance-projection-1.png 600w, https://blog.phnx.im/content/images/size/w1000/2023/07/MLS-performance-projection-1.png 1000w, https://blog.phnx.im/content/images/size/w1600/2023/07/MLS-performance-projection-1.png 1600w, https://blog.phnx.im/content/images/size/w2400/2023/07/MLS-performance-projection-1.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Performance projection: Number of operations required to calculate new group keys with MLS (blue) versus existing group messaging protocols (red).</figcaption></figure><h2 id="a-new-security-notion-group-integrity">A new security notion: Group Integrity</h2><p>As existing protocols don’t have a notion of groups, messaging apps either manage group membership on the server side in plain text or combine the end-to-end encryption protocol with an additional group management protocol such as <a href="https://eprint.iacr.org/2019/1416.pdf?ref=blog.phnx.im">Signal’s Private Group System</a>.</p><p>In MLS, all group members cryptographically agree on the current state of the group, including who is a part of it. As a consequence, a group member can only decrypt messages from other group members if the sender and the receiver generally agree on the group state and specifically on who is in the group. In other words, it becomes impossible for a third party to add a member to a group without all existing members of the group being aware of it.</p><h2 id="synchronizing-data-in-a-distributed-system-a-hard-problem-becomes-easier">Synchronizing data in a distributed system: A hard problem becomes easier</h2><p>Distributing and synchronizing data across multiple clients can be a daunting task. Aside from confidentiality, MLS also addresses the issue of synchronizing data between members of a group. The corresponding mechanism is directly derived from the group integrity property. Instead of only agreeing on a member list, members of a group can agree on arbitrary data. MLS relies on a component called Delivery Service that ensures an in-order delivery of MLS messages. This ordering then dictates how clients move incrementally from one group state to the next. </p><p>With that, an MLS group can become a distribution channel for whatever data needs to be synchronized between different entities by guaranteeing cryptographical agreement on previous extension messages. In other words, this simply means that members of a group can be sure all other members saw the same messages previously.</p><h2 id="extensible-tune-it-for-your-needs">Extensible: Tune it for your needs</h2><p>MLS is also extensible, which means that the protocol can be modified, or additional data can be added to the state of a group. The latter can be used, for example, to attach data such as a group name or an image to the group state.</p><p>The protocol has a negotiation mechanism that ensures that extensions are only used if they are supported by all members of a group. Group members also agree on which extensions are mandatory in a group.</p><p>Since MLS is fundamentally also a group key negotiation protocol, additional cryptographic key material can be exported by all members of a group. This mechanism – called Exporter – can be used to derive encryption keys. For example, participants of audio/video calls or conferences can use MLS to generate encryption keys for end-to-end encryption of the media streams.</p><h2 id="future-proof-version-and-cipher-suite-agility">Future-proof: Version and cipher suite agility</h2><p>In contrast to many existing end-to-end encryption protocols, MLS allows members to signal which versions of MLS and which MLS cipher suites they support. In the future, this lets applications safely transition to a newer version of MLS or gradually roll out support for new cipher suites without confusion between individual clients. An example of such a transition could be that a secure messaging application rolls out MLS and later wants to transition to a post-quantum secure cipher suite.</p><h2 id="the-next-steps">The next steps</h2><p>Now that the standard is established, we focus more on making end-to-end encryption ubiquitous. We believe that accessibility to the technology is paramount, and we want to complement the specification with a general-purpose implementation published under a permissive license: <a href="https://openmls.tech/?ref=blog.phnx.im">OpenMLS</a>. Along with our partners at <a href="https://cryspen.com/?ref=blog.phnx.im">Cryspen</a>, we have evolved OpenMLS over the years into a software library that can be used in various projects. OpenMLS is licensed under the <a href="https://opensource.org/license/mit/?ref=blog.phnx.im">MIT license</a> to minimize friction and make it broadly accessible.</p><h2 id="additional-resources">Additional resources</h2><ul><li>See the full specification: <a href="https://datatracker.ietf.org/doc/html/rfc9420?ref=blog.phnx.im">RFC 9420</a></li><li>Don’t want to read anymore? Listen to the <a href="https://scw.quest/2023/04/22/mls/?ref=blog.phnx.im">Security Cryptography Whatever Podcast episode about MLS</a></li><li>Tired of listening? Watch the <a href="https://www.youtube.com/watch?v=zrjmpyc8YrE&amp;ref=blog.phnx.im">Black Hat talk on MLS: Towards a New Era of Secure Group Messaging</a></li></ul><hr><p>Our team has been active in the secure messaging field for over a decade and co-authored the MLS protocol specification. If you are interested in using MLS in general or our MLS implementation (<a href="https://openmls.tech/?ref=blog.phnx.im">OpenMLS</a>) in particular in your application, do not hesitate to <a href="mailto:hello@phnx.im">contact us</a> and let us know how we can help. We offer consulting services around MLS and messaging architecture as well as development services related to OpenMLS.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[In the LLM space, "open source" is being used to mean "downloadable weights" (344 pts)]]></title>
            <link>https://www.alessiofanelli.com/blog/llama2-isnt-open-source</link>
            <guid>36815255</guid>
            <pubDate>Fri, 21 Jul 2023 15:49:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.alessiofanelli.com/blog/llama2-isnt-open-source">https://www.alessiofanelli.com/blog/llama2-isnt-open-source</a>, See on <a href="https://news.ycombinator.com/item?id=36815255">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>LLaMA2 isn't "Open Source" - and why it doesn't matter<br><span>Posted on <!-- -->7/20/2023</span></h2><p>Almost a decade ago I started an open source company, and I’ve since been involved in the OSS community as a founder, contributor, speaker, and investor. The internet wouldn’t be what it is today if it wasn’t for the amazing open source projects that power most of the digital infrastructure of our world, so it’s a topic that has always been close to my heart.</p><p>When LLaMA2 came out, many of the folks I respect in the community were upset about misusing the term “open source” when referring to the model.</p><p><img src="https://www.alessiofanelli.com/images/yann.png" alt="Yann" parentname="p"></p><p>While it’s mostly open, there are caveats such as you can’t use the model commercially if you had more than 700M MAUs as of the release date, and you also cannot use the model output to train another large language model. These types of restrictions don’t play well with the open source ethos. But while I agree that LLaMA2 cannot be called open source in the traditional meaning of the word, I also think that it doesn’t matter. The term “open source” needs to evolve (once again) in the world of AI models.</p><h2>From Free to Open</h2><p>I wrote a long history of the free software and open source movement <a href="https://www.alessiofanelli.com/blog/history-of-open-source-licensing" parentname="p">here</a>, so I won’t bore you with the details again. What you need to know is that since the 1976 “Open Letter to Hobbyists”, there’s always been tension between the commercial interests of software companies and the curiosity of hackers who wanted to circumvent its restriction. The “free software” movement started in the 70s in the MIT AI lab with Richard Stallman and eventually the GNU project in 1983. The GPL “copyleft” license was created, and projects like Red Hat, MySQL, Git, and Ubuntu adopted it.</p><p>The term “open source” came to be in 1998 thanks to MIT’s Christine Peterson; at the “Freeware Summit”, the term “free software” was officially deprecated in favor of “open source software”. As time went by, the “free” and “open source” software communities diverged as they had different ideas of what free and open meant. Free software, as specified by the Free Software Foundation, is only a subset of open source software and uses very permissive licenses such as GPL and Apache.</p><p>In the last decade, there was another bifurcation, this time created by the tension between commercial open source companies and the cloud hyperscalers. Elastic and MongoDB transitioned their open source projects to the “Server-Side Public License” (SSPL) which allows developers to use the product commercially, as long as what they are offering isn’t a hosted version of the product. The goal was to block AWS from re-hosting their products as cloud services and profiting from them. The SSPL also infringes on the OSS ideals and is not recognized by the OSI as an open source license. Yet, the majority of developers still say that MongoDB is open source. More and more the term "open source" is losing its freedom connotations and turning almost synonymous with "source available" in developers' minds.</p><h2>From Source to Weights</h2><p>With the rise of open models like Dolly, MPT, LLaMA, etc., we are seeing a similar bifurcation in the community. For most AI engineers, “open source” today means “downloadable weights”, nothing more. Heather Meeker has proposed a definition for <a href="https://github.com/Open-Weights/Definition" parentname="p">“open weights”</a>, but there’s still no community consensus. The question is whether or not open weights are enough for a model to be called open source; a software analogy would be a project releasing its binaries without the source code to re-build it from scratch.</p><p>For a model to be truly open source and retrainable from scratch, the creators would need to share all their training code, pre-training dataset, fine-tuning preferences, RLHF examples, etc. The problem is the cost of these training runs: even if someone were to release everything, it’s cost-prohibitive to train models from scratch for most developers and companies, so having access to the final weights is preferred anyway.</p><p><img src="https://www.alessiofanelli.com/images/open-models.png" alt="Open Models" parentname="p"></p><p>In the LLMs space, the term "open source" is used interchangeably to define a wide range of openness levels:</p><ul><li parentname="ul"><strong parentname="li">Open models:</strong> these are models like RedPajama and MPT-7B, they have open weights available for commercial use (under Apache 2.0 license), but can also be re-trained from scratch since the dataset is open source. You can find a guide on how to train your own RedPajama model <a href="https://github.com/Lightning-AI/lit-llama/blob/main/howto/train_redpajama.md" parentname="li">here</a>.</li><li parentname="ul"><strong parentname="li">Open weights:</strong> StableLM is an open model trained by StabilityAI. While the weights are available and are licensed under Apache 2.0, the dataset used to train isn’t available to the public. From their README: “StableLM-Base-Alpha is pre-trained on a new experimental dataset built atop The Pile and is threes times larger at approximately 1.5T tokens.”</li><li parentname="ul"><strong parentname="li">Restricted weights:</strong> this is LLaMA2. The pre-training dataset is also unavailable, and while the weights are supposed to be open for commercial use, they have specific limitations that we mentioned above.</li><li parentname="ul"><strong parentname="li">Contaminated weights:</strong> models like Dolly 1.0 and LLaMA1 are part of this category. The weights are released openly, but the dataset used to train them doesn’t allow for commercial use, making it technically open but practically unusable.</li></ul><p>For the foreseeable future, open source and open weights will be used interchangeably, and I think that’s okay. The important thing is that more and more of this work is done as openly as possible. It’s okay to be disappointed with the LLaMA2 license, but Meta just packaged ~$2M worth of FLOPS into a Github repo, and I think that will be a net positive for the progress of this space.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[By 2028 there must be fast chargers every 60 km on the EU’s key motorways (120 pts)]]></title>
            <link>https://www.fleeteurope.com/en/new-energies/europe/article/fast-chargers-every-60-km-key-eu-motorways?a=FJA05&amp;t%5B0%5D=Charging&amp;curl=1</link>
            <guid>36814754</guid>
            <pubDate>Fri, 21 Jul 2023 15:11:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fleeteurope.com/en/new-energies/europe/article/fast-chargers-every-60-km-key-eu-motorways?a=FJA05&#x26;t%5B0%5D=Charging&#x26;curl=1">https://www.fleeteurope.com/en/new-energies/europe/article/fast-chargers-every-60-km-key-eu-motorways?a=FJA05&#x26;t%5B0%5D=Charging&#x26;curl=1</a>, See on <a href="https://news.ycombinator.com/item?id=36814754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div property="content:encoded">
        <p>By 2028, there must be fast chargers at least every 60 km on the EU’s key motorways. That is the most eyecatching measure of several approved by the European Parliament to improve EV charging. Others focus on increasing charging speed and making it easier to pay for charging. All are part of the EU’s ‘Fit for 55’ package, aimed at reducing emissions by 55% by 2030.</p>  <p>The maximum-distance rule for fast chargers applies to TEN-T (<em>pictured)</em>, an EU-wide network of key traffic corridors with a total length of 24,500 km. The mandated fast chargers along these roads all must have an output of at least 400 kW by 2026, and 600 kW by 2028.&nbsp;</p>  <p>Specifically for electric buses and trucks, the European Parliament mandated charging points at most 120 km apart by 2028 on at least half the network, each heavy-duty charger with an output of 1,400 to 2,800 kW, depending on the road.&nbsp;</p>  <p>In addition to these minimum requirements for the density and speed of the fast charger network, the European parliament also wants more simplicity and transparency when it comes to payment:</p>  <ul> 	<li>All customers must be able to pay with cards or contactless devices (at present, some charging networks require subscriptions or app downloads).&nbsp;</li> 	<li>All prices must be clearly displayed to the customers: in euros per kW or per minute/session. &nbsp;</li> 	<li>By 2027, the EU will develop a public database of charging stations, with information on pricing, availability, and waiting times.&nbsp;</li> </ul>  <p>Not forgetting other sustainable alternatives to ICEs, the European Parliament mandated at least one hydrogen refueling station every 200 km along TEN-T motorways by 2031.&nbsp;</p>  <p>The new alternative fuel infrastructure rules have already been approved by the European Parliament, but will only enter into force six months after approval by the European Council.&nbsp;</p>  <p>In a separate move, the UK has formulated similar proposals to improve the availability and reliability of public EV charging. For example: the British government wants to reduce the share of charging stations out of service from 8% in 2019 to 1% (as is already the case in the Netherlands), and will require that charging station operators provide a 24-hour helpline for their customers.</p>  <p><em>Image: Directorate-General for Mobility and Transport, European Commission – CC BY-SA 4.0</em></p> 
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[India’s ban on rice exports raises fear of global food price rises (121 pts)]]></title>
            <link>https://www.theguardian.com/business/2023/jul/21/india-ban-on-rice-exports-raises-fear-of-global-food-price-rises</link>
            <guid>36814627</guid>
            <pubDate>Fri, 21 Jul 2023 15:01:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/business/2023/jul/21/india-ban-on-rice-exports-raises-fear-of-global-food-price-rises">https://www.theguardian.com/business/2023/jul/21/india-ban-on-rice-exports-raises-fear-of-global-food-price-rises</a>, See on <a href="https://news.ycombinator.com/item?id=36814627">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>India has banned non-basmati white rice exports to curb domestic inflation, raising fears of further increases in global food prices just days after <a href="https://www.theguardian.com/business/2023/jul/20/rising-grain-prices-russia-pullout-black-sea-deal-food-crisis-fears" data-link-name="in body link">wheat and corn prices were sent climbing</a> by Russia’s termination of a key grain deal.</p><p>The immediate ban, introduced after heavy rains hit domestic crops, follows the failure of a 20% duty on international exports introduced in September to curb foreign demand, which has soared after extreme climate conditions hit production in countries.</p><p>India is the world’s largest rice exporter, accounting for more than 40% of global shipments. While the ban does not apply to higher-grade basmati rice – India’s best-known variety – non-basmati white rice accounts for about 25% of exports.</p><p>International sales of Indian rice soared by 35% in the year to June, contributing to a 3% rise in domestic prices over the past month alone. People in India are paying 11.5% more for rice than a year ago, according to its ministry of consumer affairs, food and public distribution.</p><p>The Indian government said the ban, <a href="https://www.pib.gov.in/PressReleasePage.aspx?PRID=1941139" data-link-name="in body link">introduced on Thursday evening</a>, would “ensure adequate availability of non-basmati white rice in the Indian market” and lead to lowering of prices for domestic consumers.</p><p>Soaring food inflation has put pressure on the BJP government in Delhi in the run-up to national elections next year and state-level elections in the months to come.</p><p>India’s move sent the price of rice from several Asian countries higher on global markets, while traders said they expected prices to rise substantially in the coming days.</p><p>The price of India’s 5% broken parboiled variety had already been hovering this week close to a five-year peak between $421 and $428 (£328-334) a metric tonne, and on Friday it stood at about $424.50.</p><p>Thailand and Vietnam, respectively the world’s second and third-largest rice exporters, have also experienced rises in the prices of their 5% broken rice in recent times. Even before the announcement, Vietnam’s rice was trading at its highest level since 2011, and has since moved higher, while Thailand’s variety jumped to levels not seen for more than two years.</p><p>Global food supplies have been hit by Russia’s war in Ukraine, which has driven up commodity and grain prices around the world.</p><p>Russia’s decision earlier in the week to <a href="https://www.theguardian.com/world/2023/jul/17/russia-decision-not-extend-black-sea-grain-deal-final" data-link-name="in body link">pull out of the year-old UN-brokered Black Sea grain initiative</a>, which guaranteed safe passage for vessels carrying cereals, has prompted fresh concerns about a global food crisis.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-11">skip past newsletter promotion</a><p id="EmailSignup-skip-link-11" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>Before the move by the Kremlin, the grain price had fallen by more a third (35%), while the wheat price had declined 14% since January and corn prices had been trading 20% lower.</p><p>The US has pledged a further $250m (£194m) to create and expand other routes for Ukrainian grain to leave the country, but Russia’s defence ministry has in effect said any ship leaving a Ukrainian port <a href="https://www.theguardian.com/world/2023/jul/20/what-was-the-black-sea-grain-deal-and-why-did-it-collapse" data-link-name="in body link">will be a legitimate military target</a>, raising fears that supplies could face further disruption.</p><p>The interruption of Ukrainian grain exports comes as important growing regions in the US have been hit by unusually hot weather and lack of rain, leading to a reduction in forecasts for the US wheat harvest, with stocks estimated to fall to a 16-year low.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Turborepo is porting from Go to Rust (110 pts)]]></title>
            <link>https://vercel.com/blog/how-turborepo-is-porting-from-go-to-rust?nxtPslug=how-turborepo-is-porting-from-go-to-rust</link>
            <guid>36814019</guid>
            <pubDate>Fri, 21 Jul 2023 14:14:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vercel.com/blog/how-turborepo-is-porting-from-go-to-rust?nxtPslug=how-turborepo-is-porting-from-go-to-rust">https://vercel.com/blog/how-turborepo-is-porting-from-go-to-rust?nxtPslug=how-turborepo-is-porting-from-go-to-rust</a>, See on <a href="https://news.ycombinator.com/item?id=36814019">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In <a href="https://vercel.com/blog/turborepo-migration-go-rust" rel="noopener" target="_blank">a previous blog post</a>, we talked about <b>why</b> we are porting <a href="https://turbo.build/?utm_source=turbo&amp;utm_medium=blog&amp;utm_campaign=turborepo_porting" rel="noopener" target="_blank">Turborepo, the high-performance build system for JavaScript and TypeScript</a>, from Go to Rust. Now, let's talk about <b>how</b>.</p><p>Today, our porting effort is in full swing, moving more and more code to Rust. But when we were starting out, we had to make sure that porting was feasible for us to accomplish. A migration from one language to another is no small task and there's a lot of research to do up front to ensure that the end goal is attainable. </p><p>Here’s how we started the process, validated our current porting strategy, and made the call to port Turborepo to Rust.</p><h2><span id="port-vs.-full-rewrite"></span><a href="#port-vs.-full-rewrite">Port vs. full rewrite</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>When we were planning our migration, we briefly considered a full, ground-up rewrite. But, talking the idea through, we realized it wouldn't fit our goals as well as an incremental port would.</p><h3><span id="what-is-an-incremental-port"></span><a href="#what-is-an-incremental-port">What is an incremental port?</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>Incremental porting moves code piece-by-piece, running new and old code together at the same time. The goal for the chunk of code being moved is to keep the behavior exactly the same as before it was ported.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319409.png" loading="lazy" width="2880" height="2113" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FmZz2Um8re3MZXucpSZdoV%2F890469916054b2f0b364c13514e825b4%2FFrame_427319409.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FmZz2Um8re3MZXucpSZdoV%2F890469916054b2f0b364c13514e825b4%2FFrame_427319409.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319402 (1).png" loading="lazy" width="1920" height="1409" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2Fc17bo47fBBuBQztRawrOp%2Fe16450ef2ef20d0c7bf2dc709912fc1b%2FFrame_427319402__1_.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2Fc17bo47fBBuBQztRawrOp%2Fe16450ef2ef20d0c7bf2dc709912fc1b%2FFrame_427319402__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2Fc17bo47fBBuBQztRawrOp%2Fe16450ef2ef20d0c7bf2dc709912fc1b%2FFrame_427319402__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 6.png" loading="lazy" width="621" height="628" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F6ZaHYc4GhEIKfRL2c1erpl%2F59f7fc484abd77f372331aec1f583d84%2FiPhone_8_Plus_-_6.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F6ZaHYc4GhEIKfRL2c1erpl%2F59f7fc484abd77f372331aec1f583d84%2FiPhone_8_Plus_-_6.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F6ZaHYc4GhEIKfRL2c1erpl%2F59f7fc484abd77f372331aec1f583d84%2FiPhone_8_Plus_-_6.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 2.png" loading="lazy" width="621" height="628" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1b7106hvxHFzTGUpGnkJtO%2F33e299c2b1216be88278d462c085e32e%2FiPhone_8_Plus_-_2.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1b7106hvxHFzTGUpGnkJtO%2F33e299c2b1216be88278d462c085e32e%2FiPhone_8_Plus_-_2.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1b7106hvxHFzTGUpGnkJtO%2F33e299c2b1216be88278d462c085e32e%2FiPhone_8_Plus_-_2.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>In our case, this means we need to have our Go code and Rust code interoperating with each other. We want to do a simple translation, explicitly avoiding making improvements or changing functionality when we're swapping out languages for the slice of code. That way, we can do intensive testing against both sets of code, and complete the migration as quickly as possible.</p><h3><span id="why-we-didn't-do-a-full-rewrite"></span><a href="#why-we-didn't-do-a-full-rewrite">Why we didn't do a full rewrite</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>Full rewrites are very tempting. They are more simple to write and ship, as you don't need to worry about your "before" and "after" code working together. You also get a clean slate to write a new and improved version, without the warts and technical debt of the previous iteration. However, full rewrites also come with some serious downsides.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319410.png" loading="lazy" width="1920" height="735" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7nb5vSuSQZXEKsUUsYGNVl%2Ff0f6be9ab08484fb087d5583d5720278%2FFrame_427319410.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7nb5vSuSQZXEKsUUsYGNVl%2Ff0f6be9ab08484fb087d5583d5720278%2FFrame_427319410.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7nb5vSuSQZXEKsUUsYGNVl%2Ff0f6be9ab08484fb087d5583d5720278%2FFrame_427319410.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319404 (1).png" loading="lazy" width="1920" height="735" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7bF6sXF2wD092FiiuBXyGV%2Ff5f57209b1f25030cb3e106a2a6189d1%2FFrame_427319404__1_.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7bF6sXF2wD092FiiuBXyGV%2Ff5f57209b1f25030cb3e106a2a6189d1%2FFrame_427319404__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7bF6sXF2wD092FiiuBXyGV%2Ff5f57209b1f25030cb3e106a2a6189d1%2FFrame_427319404__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 11.png" loading="lazy" width="414" height="459" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F365RREyHsEytwZlyGKa985%2F24ca1793a87a50ac37bdfea84c2964a5%2FiPhone_8_Plus_-_11.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F365RREyHsEytwZlyGKa985%2F24ca1793a87a50ac37bdfea84c2964a5%2FiPhone_8_Plus_-_11.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F365RREyHsEytwZlyGKa985%2F24ca1793a87a50ac37bdfea84c2964a5%2FiPhone_8_Plus_-_11.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 16.png" loading="lazy" width="414" height="459" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FWdkdfyBr5TwUufLIYBxRf%2Ff5066270eea29c7ef149ba6eb3c95528%2FiPhone_8_Plus_-_16.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FWdkdfyBr5TwUufLIYBxRf%2Ff5066270eea29c7ef149ba6eb3c95528%2FiPhone_8_Plus_-_16.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FWdkdfyBr5TwUufLIYBxRf%2Ff5066270eea29c7ef149ba6eb3c95528%2FiPhone_8_Plus_-_16.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>First, a full rewrite tends to require a complete halt to shipping new features. Otherwise, you run the risk of chasing a moving target as the old codebase grows while you try to catch up with your new code. </p><p>A full rewrite also does not guarantee a better user experience. Often, a rewrite ends up less than seamless, as it's not feasible for the new version to match the old one, feature for feature, edge case for edge case. As the surface area of the rewrite grows, there's more room for error and users can end up frustrated with breaking changes and missing features.</p><p>Full rewrites also require building up an entirely new codebase, which is a large quantity of unused code. In our experience, unused code, even when verified with tests, can be a breeding ground for bugs. We wanted to make sure that any new Rust code was properly exercised as we moved through our porting effort.</p><h2><span id="we-chose-to-port"></span><a href="#we-chose-to-port">We chose to port</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>Therefore, we decided to <b>port</b> Turborepo to Rust instead of doing a full rewrite.</p><p>Porting did necessitate some tradeoffs. We had to introduce a significant amount of complexity into our codebase, so that we could interoperate between Go and Rust. This complexity meant slower developer velocity to start, but we look forward to workflow improvements going forward, particularly when our porting effort has finished.</p><p>More importantly, we knew we could continue shipping features to Turborepo users while porting. All things considered, we determined that this was a reasonable compromise and the path that we would take.</p><h3><span id="starting-the-port"></span><a href="#starting-the-port">Starting the port </a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>We chose to start by writing a small, new Turborepo feature in Rust. This way, we could add new functionality from the roadmap for users, integrate Rust into our build process, and interact with existing Go code as little as possible to reduce our initial complexity.</p><p>Once we'd laid this groundwork, we knew that we could slowly port more and more code to Rust over time.</p><h2><span id="global-turbo"></span><a href="#global-turbo">Global <code>turbo</code></a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>We decided to have our first Rust feature be <a href="https://turbo.build/blog/turbo-1-7-0#global-turbo?utm_source=turbo&amp;utm_medium=blog&amp;utm_campaign=turborepo_porting" rel="noopener" target="_blank">global <code>turbo</code></a>, a feature that allows users to install Turborepo as a globally available command on their machine. </p><p>A global installation of <code>turbo</code> will look for a locally installed <code>turbo</code> program in the repository, execute it if it exists, and otherwise fallback to the global <code>turbo</code> binary. That way, you can easily run <code>turbo</code> from anywhere in your repository, but also keep a specific version of <code>turbo</code> pinned in your <code>package.json</code>.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319413.png" loading="lazy" width="1650" height="740" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FqPT2LsrOLLG4ISEyuv92G%2F2427d2381392e4acc95dc51d1cf9edca%2FFrame_427319413.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FqPT2LsrOLLG4ISEyuv92G%2F2427d2381392e4acc95dc51d1cf9edca%2FFrame_427319413.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FqPT2LsrOLLG4ISEyuv92G%2F2427d2381392e4acc95dc51d1cf9edca%2FFrame_427319413.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319414.png" loading="lazy" width="1650" height="740" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2gbJI96SblT7dXxZWZDYsD%2F6877030625b5c53c3523ad96db1d468d%2FFrame_427319414.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2gbJI96SblT7dXxZWZDYsD%2F6877030625b5c53c3523ad96db1d468d%2FFrame_427319414.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2gbJI96SblT7dXxZWZDYsD%2F6877030625b5c53c3523ad96db1d468d%2FFrame_427319414.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 19.png" loading="lazy" width="414" height="647" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3DzjEq5stkry2IiCm6zh4U%2Fd5f38eda9664709a42fbbc2e8707ec74%2FiPhone_8_Plus_-_19.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3DzjEq5stkry2IiCm6zh4U%2Fd5f38eda9664709a42fbbc2e8707ec74%2FiPhone_8_Plus_-_19.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3DzjEq5stkry2IiCm6zh4U%2Fd5f38eda9664709a42fbbc2e8707ec74%2FiPhone_8_Plus_-_19.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 5.png" loading="lazy" width="414" height="647" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7beQhPRdj8OYxzfUcYgEbU%2Fd2e5d1a6a0d94b65231122a21672217e%2FiPhone_8_Plus_-_5.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7beQhPRdj8OYxzfUcYgEbU%2Fd2e5d1a6a0d94b65231122a21672217e%2FiPhone_8_Plus_-_5.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7beQhPRdj8OYxzfUcYgEbU%2Fd2e5d1a6a0d94b65231122a21672217e%2FiPhone_8_Plus_-_5.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>This feature is implemented through what we started calling "the Rust shim," a bit of Rust code that wraps the existing Go code. The Go portion is compiled via CGO as a C static library and then linked to the Rust binary. Luckily, global <code>turbo</code> only required a few features from the rest of Turborepo's code, such as reading configuration and navigating the file system. </p><h2><span id="cli-parsing"></span><a href="#cli-parsing">CLI parsing</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>As we implemented global <code>turbo</code>, we realized we needed to parse a few command line arguments like <code>--cwd</code>, the argument for setting <code>turbo</code>'s current working directory.</p><p>After global <code>turbo</code>, it made sense to continue by porting the rest of the CLI argument parser to Rust. To parse arguments, we use the <a href="https://docs.rs/clap/latest/clap/" rel="noopener" target="_blank"><code>clap</code> crate</a> (Rust’s equivalent of an npm package). <code>clap</code> lets you define a data type with the arguments, annotate it a little bit, and it will automatically create a parser.</p><p>With the pieces in place, we had to work on sending the args from the Rust entry point to the Go code. For better or worse, <a href="https://faultlore.com/blah/c-isnt-a-language/" rel="noopener" target="_blank">C is the standard for foreign function interfacing (FFI)</a>, so we had to use C to communicate between Rust and Go.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="InlineGraphic_1920xVariable (1).png" loading="lazy" width="1920" height="1084" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2FGPm6ksIA7bGzZzY7CYkd%2F06b7d487cbcf5237ae9f917574cf7a51%2FInlineGraphic_1920xVariable__1_.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2FGPm6ksIA7bGzZzY7CYkd%2F06b7d487cbcf5237ae9f917574cf7a51%2FInlineGraphic_1920xVariable__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2FGPm6ksIA7bGzZzY7CYkd%2F06b7d487cbcf5237ae9f917574cf7a51%2FInlineGraphic_1920xVariable__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="InlineGraphic_1920xVariable.png" loading="lazy" width="1920" height="1084" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7sVbowOCnYSjNrOyxfD5NF%2F0fdf484cf4ced36f67e0ab879514d099%2FInlineGraphic_1920xVariable.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7sVbowOCnYSjNrOyxfD5NF%2F0fdf484cf4ced36f67e0ab879514d099%2FInlineGraphic_1920xVariable.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7sVbowOCnYSjNrOyxfD5NF%2F0fdf484cf4ced36f67e0ab879514d099%2FInlineGraphic_1920xVariable.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="InlineGraphic_1920xVariable (3).png" loading="lazy" width="414" height="416" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1M9EpwZDGRt4PqXnS41B6p%2F0cc3e7336ee39882508a6dd112db9a5f%2FInlineGraphic_1920xVariable__3_.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1M9EpwZDGRt4PqXnS41B6p%2F0cc3e7336ee39882508a6dd112db9a5f%2FInlineGraphic_1920xVariable__3_.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1M9EpwZDGRt4PqXnS41B6p%2F0cc3e7336ee39882508a6dd112db9a5f%2FInlineGraphic_1920xVariable__3_.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="InlineGraphic_1920xVariable (2).png" loading="lazy" width="414" height="416" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7s2Gq0JKjOQkBQ9ZAOqEGw%2F4b0db3626aa7e7b7b10b95e8fdf8d631%2FInlineGraphic_1920xVariable__2_.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7s2Gq0JKjOQkBQ9ZAOqEGw%2F4b0db3626aa7e7b7b10b95e8fdf8d631%2FInlineGraphic_1920xVariable__2_.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7s2Gq0JKjOQkBQ9ZAOqEGw%2F4b0db3626aa7e7b7b10b95e8fdf8d631%2FInlineGraphic_1920xVariable__2_.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>We wanted to avoid having too many types in C, as we weren’t confident that we could write cross-platform C types that played well with both Rust and Go. Instead, we decided to serialize our arguments to JSON and send it to Go as a string. Even though JSON serialization does have some overhead, we knew that the arguments struct would only be a few hundred bytes in size, so the performance impact would be minimal.</p><p>On the Rust side, we used another cornerstone crate of the Rust ecosystem, <a href="https://docs.rs/serde/latest/serde/" rel="noopener" target="_blank"><code>serde</code></a>, which lets you serialize and deserialize data in various different formats, using some minimal annotation. For the Go side, we were already using JSON in the codebase, so it was easy to receive the JSON string and deserialize it into a Go struct. </p><h2><span id="ship-it"></span><a href="#ship-it">Ship it?</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>With these two features ported, we were ready to ship our first hybrid Go-Rust release.</p><p>However, before we could release, we needed to make sure the Go-Rust binary worked in all the various contexts that Turborepo is used, <a href="https://turbo.build/repo/docs/installing?utm_source=turbo&amp;utm_medium=blog&amp;utm_campaign=turborepo_porting" rel="noopener" target="_blank">like the different operating systems and  Linux distros that we support</a>. As we tested our code, we started noticing some issues on a couple platforms.</p><h3><span id="windows-difficulties"></span><a href="#windows-difficulties">Windows difficulties</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>On Windows, there are two main toolchains, <a href="https://en.wikipedia.org/wiki/Microsoft_Visual_C%2B%2B" rel="noopener" target="_blank">Microsoft Visual C++ (MSVC)</a> and <a href="https://en.wikipedia.org/wiki/MinGW" rel="noopener" target="_blank">Minimalist GNU for Windows (MinGW)</a>.</p><p>Go <b>only</b> uses MinGW, but we were using Rust with MSVC. This caused some runtime issues, but, luckily, the solution was simple: we moved our Rust toolchain to MinGW.</p><p>Next up, we had some issues with paths. Windows has a couple concepts of paths, including what’s called a Universal Naming Convention (UNC) path. When you ask Windows to canonicalize a path (resolve all symlinks and normalize components of the path), it gives you a UNC path.</p><p>However, despite the name, UNC paths are not supported everywhere—sometimes not even by Windows itself! This caused a few bugs where we’d provide a UNC path and get an invalid path error. The solution was to use a helpful Rust crate called <a href="https://docs.rs/dunce/latest/dunce/" rel="noopener" target="_blank">dunce</a> that lets you canonicalize a path and get a non-UNC path back, handling the intricacies of this problem for us.</p><h3><span id="alpine-linux"></span><a href="#alpine-linux">Alpine Linux</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>The second set of challenges came with Alpine Linux. At Vercel, we use Alpine, a common operating system for cloud computing, to create lightweight containers for building your projects.</p><p>Alpine, though, does not come with <code>glibc</code>, the de-facto implementation of the C standard library. This is a problem because many binaries assume <code>glibc</code> is installed and don’t package it themselves. There are some libraries that pave over this issue using packages like <code>gcompat</code> or <code>libc6-compat</code>, but they didn’t end up working for us because the version of <code>glibc</code> that Rust requires was too modern for our supported targets. When we’d try to run the binary, we’d get errors that the required <code>glibc</code> version was not available.</p><p>As a result, we decided to compile Turborepo as a fully static binary. This meant that we packaged our own C standard library implementation using <code>musl</code> (since you can't statically link <code>glibc</code> due to licensing issues). This seems to work just fine for both Rust and Go: Rust lets you set the C standard library in the target (<code>aarch64-unknown-linux-musl</code> vs. <code>aarch64-unknown-linux-gnu</code>) and Go does not use a C standard library by default.</p><p>However, when we ran this statically linked binary, it would return a segmentation fault. Even worse, when we inspected with a debugger, we’d find a corrupted stack. And, even worser, the segfault appeared to be coming from the Go runtime itself!</p><hr><p>After a lot of searching, we tracked down a <a href="https://github.com/golang/go/issues/13492" rel="noopener" target="_blank">seven year-old GitHub issue</a> which explained that Go cannot be compiled as a C static library with <code>musl</code>. This posed a significant challenge, as Alpine Linux is an essential platform for Turborepo and its users. We had to go back to the drawing board and figure out how we could ship our Go-Rust combination.</p><p>Eventually, after a ton more deliberation, we came up with a solution: we’d compile our Go code and our Rust code as two separate binaries. The Rust code would call the Go code and pass the args serialized to JSON via the CLI.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319412.png" loading="lazy" width="1920" height="917" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1VOl0eTFS33pkNLbtrzhY%2F6811cbf8065443e0ba46c5c365b9fca4%2FFrame_427319412.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1VOl0eTFS33pkNLbtrzhY%2F6811cbf8065443e0ba46c5c365b9fca4%2FFrame_427319412.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1VOl0eTFS33pkNLbtrzhY%2F6811cbf8065443e0ba46c5c365b9fca4%2FFrame_427319412.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319408.png" loading="lazy" width="1920" height="917" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3KbndugMu2gM4Nu8Eoq3dj%2F41cb0b6578dbd822c77f08f2bada4066%2FFrame_427319408.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3KbndugMu2gM4Nu8Eoq3dj%2F41cb0b6578dbd822c77f08f2bada4066%2FFrame_427319408.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3KbndugMu2gM4Nu8Eoq3dj%2F41cb0b6578dbd822c77f08f2bada4066%2FFrame_427319408.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 14.png" loading="lazy" width="414" height="506" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F5QibrcV35p6zu0Rpzriwn5%2F57872cf4a380ba9c3ec780a02c370775%2FiPhone_8_Plus_-_14.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F5QibrcV35p6zu0Rpzriwn5%2F57872cf4a380ba9c3ec780a02c370775%2FiPhone_8_Plus_-_14.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F5QibrcV35p6zu0Rpzriwn5%2F57872cf4a380ba9c3ec780a02c370775%2FiPhone_8_Plus_-_14.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 18.png" loading="lazy" width="414" height="506" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2547NHodIcPCgR7ITmjnM0%2F4366bba1f016889729cfc1c729554907%2FiPhone_8_Plus_-_18.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2547NHodIcPCgR7ITmjnM0%2F4366bba1f016889729cfc1c729554907%2FiPhone_8_Plus_-_18.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2547NHodIcPCgR7ITmjnM0%2F4366bba1f016889729cfc1c729554907%2FiPhone_8_Plus_-_18.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>We knew that the args were small enough that they could be passed via CLI without too much of a performance hit. And because we were using a serialization format, the code changes were extremely small. All we had to do was change how Rust was sending the JSON string to Go.</p><p>With that, we were able to get our first hybrid Go-Rust release out the door. The first version of <code>turbo</code> that was shipped to you using these compilation strategies was <a href="https://turbo.build/blog/turbo-1-7-0?utm_source=turbo&amp;utm_medium=blog&amp;utm_campaign=turborepo_porting" rel="noopener" target="_blank">version 1.7.0</a>.</p><h2><span id="what-we-learned"></span><a href="#what-we-learned">What we learned</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>Through this effort, we've learned a lot about moving from one language to another. Let's take note of what we've found.</p><h3><span id="serialization-is-useful-for-ffi"></span><a href="#serialization-is-useful-for-ffi">Serialization is useful for FFI</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>Our first takeaway is that serialization formats are very useful for interoperability. By serializing to JSON, a format with robust support in both Go and Rust, we were able to minimize our FFI surface area, and avoid a whole class of cross-platform, cross-language bugs. When we had to switch from a single, linked binary to two binaries, we were able to do so with relative ease because our FFI surface area was so small.</p><p>The tradeoff here is that serialization and deserialization is slow. You can only depend on this technique if either you know your serialized payloads will be small or you don't care about the performance hit for your use case.</p><h3><span id="porting-takes-preparation"></span><a href="#porting-takes-preparation">Porting takes preparation</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>The second takeaway is that incremental porting is feasible but requires lots of careful testing and strategizing. We ran into quite a few tricky bugs and we caught these issues through lots of automated and manual testing. You can <a href="https://github.com/vercel/turbo/tree/main/.github/workflows" rel="noopener" target="_blank">check out our (and Turbopack's) testing suites in our GitHub workflows</a>.</p><p>Testing is also extremely important for nailing down the behavior of your code, whether it’s the exact edge cases of CLI parsing, or the order in which configuration is loaded. These exact details are not so crucial when you’re writing your first implementation, but they’re absolutely paramount to avoid breaking changes during a port or rewrite. You should aim to write tests <b>before</b> you start porting code, so that you have a known specification to work against.</p><h3><span id="cross-compatibility-is-difficult"></span><a href="#cross-compatibility-is-difficult">Cross-compatibility is difficult</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>The third takeaway is that cross-platform, cross-language release engineering is extremely challenging. Every platform, language, and compiler has their own quirks that can make interoperability difficult and, the more things you have working together, the more opportunities you have for a new complication.</p><h3><span id="porting-is-worth-it-for-us"></span><a href="#porting-is-worth-it-for-us">Porting is worth it for us</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>Finally, while porting from Go to Rust has been challenging, it has proven to be the correct choice for us strategically. Even with our porting effort going on, we've been able to ship new features, handle bugs in existing functionality, and keep helping our users while we migrate. It's required some extraordinarily tricky debugging, careful planning, and rigorous testing, but we believe it has been worth it.</p><h2><span id="try-out-(ported)-turborepo"></span><a href="#try-out-(ported)-turborepo">Try out (ported) Turborepo</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>This week, Turborepo saved 5,742 hours of time for the product engineers and CI machines at Vercel. If you want to try out the same technology in just a few minutes, <a href="https://vercel.com/blog/vercel-remote-cache-turbo" rel="noopener" target="_blank">check out our article</a> on how you can get started with <a href="https://vercel.com/docs/concepts/monorepos/remote-caching" rel="noopener" target="_blank">Vercel Remote Cache</a>.</p><div><p data-version="v1">Explore more</p><div><a href="https://vercel.com/templates/next.js/turborepo-next-basic"><div><p><img data-version="v1" alt="Screenshot of template" loading="lazy" decoding="async" data-nimg="fill" sizes="25vw" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=256&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 256w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=384&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 384w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 640w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=750&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 750w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 828w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=1080&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1080w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=1200&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1200w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1920w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=2048&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2048w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 3840w" src="https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></div></a><a href="https://turbo.build/" rel="noopener" target="_blank"><div><p><img data-version="v1" alt="Visit turbo.build" loading="lazy" decoding="async" data-nimg="fill" sizes="25vw" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=256&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 256w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=384&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 384w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 640w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=750&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 750w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 828w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=1080&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1080w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=1200&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1200w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1920w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=2048&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2048w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 3840w" src="https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></div></a></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dementia risk linked to blood-protein imbalance in middle age (302 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-023-02374-2</link>
            <guid>36813564</guid>
            <pubDate>Fri, 21 Jul 2023 13:34:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-023-02374-2">https://www.nature.com/articles/d41586-023-02374-2</a>, See on <a href="https://news.ycombinator.com/item?id=36813564">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_25825424.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_25825424.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="Visualization showing a brain affected by Alzheimer's disease." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_25825424.jpg">
  <figcaption>
   <p><span>A slice through the brain of a person with Alzheimer’s disease, the most common cause of dementia.</span><span>Credit: Anatomical Travelogue/Science Photo Library</span></p>
  </figcaption>
 </picture>
</figure><p>A study that followed thousands of people over 25 years has identified proteins linked to the development of dementia if their levels are unbalanced during middle age.</p><p>The findings, published in <i>Science Translational Medicine </i>on 19 July<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup>, could contribute to the development of new diagnostic tests, or even treatments, for dementia-causing diseases.</p><p>Most of the proteins have functions unrelated to the brain.</p><p>“We’re seeing so much involvement of the peripheral biology decades before the typical onset of dementia,” says study author Keenan Walker, a neuroscientist at the US National Institute on Aging in Bethesda, Maryland.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-023-00954-w" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_25434040.jpg"><p>Conquering Alzheimer’s: a look at the therapies of the future</p></a>
 </article><p>Equipped with blood samples from more than 10,000 participants, Walker and his colleagues questioned whether they could find predictors of dementia years before its onset by looking at a person’s proteome — the collection of all the proteins expressed throughout the body. They searched for any signs of dysregulation — when proteins are at levels much higher or lower than normal.</p><p>The samples were collected as part of an ongoing study that began in 1987. Participants returned for examination six times over three decades, and during this time, around 1 in 5 of them developed dementia.</p><p>The researchers found 32 proteins that, if dysregulated in people aged 45 to 60, were strongly associated with an elevated chance of developing dementia in later life. It is unclear how exactly these proteins might be involved in the disease, but the link is “highly unlikely to be due to just chance alone”, says Walker.</p><p>“Not all the proteins showed changes in both plasma and brain tissues,” says Nicholas Seyfried, a biochemist and neurologist at Emory University in Atlanta, Georgia. For example, one of the proteins found with the strongest association with dementia risk — called GDF15 — was not detected in the brain, suggesting that “mechanisms below the neck could also play a role”, he adds.</p><p>Walker says that although a person’s proteome by itself cannot predict their risk of getting dementia, it could perhaps bolster the strength of existing predictors — such as age and family history.</p><h2>Protein balance</h2><p>As expected, some of the proteins that researchers identified are active in the brain — but most have other roles in the body. A handful were linked to proteostasis — the process of carefully balancing protein levels in the proteome.</p><p>This regulation is important in preventing proteins from going rogue and clumping together, which is what happens to the amyloid and tau proteins in the brains of people with Alzheimer’s disease, the most common cause of dementia.</p><article data-label="Related">
  <a href="https://www.nature.com/news/how-to-defeat-dementia-1.20949" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_15713358.jpg"><p>How to defeat dementia</p></a>
 </article><p>The study found altered levels of many of the proteins both in the brain tissues of those who had died with Alzheimer’s disease, and in the blood of those still living with it. These were associated with the presence of amyloid and tau proteins, which suggests they are somehow involved in processes specific to the disease.</p><p>Other proteins identified in the study were linked to the immune system, adding to “growing evidence for the role of innate and adaptive immune function in dementia”, says Jin-Tai Yu, a physician-scientist who specializes in dementia at Fudan University in Shanghai, China. Yu and his team have previously found that people with immune diseases are more vulnerable to Alzheimer’s later in life<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup>.</p><p>There is still a long way to go in understanding exactly how any of these proteins fit into the physiology of dementia, and a much better understanding of the underlying mechanisms is needed before people can benefit. Such insights “could potentially open doors for early interventions”, says Seyfried. For Walker, the aim in future is to determine whether these proteins could potentially be used as markers to identify various dysregulated pathways in people with dementia and to help provide more personalized treatments.</p>
                </div><div id="references" aria-labelledby="Bib1"><h2 id="Bib1">References</h2></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[90s Internet: When 20 hours online triggered an email from my ISP’s president (195 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/07/the-90s-internet-when-20-hours-online-triggered-an-email-from-my-isps-president/</link>
            <guid>36813210</guid>
            <pubDate>Fri, 21 Jul 2023 12:56:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/07/the-90s-internet-when-20-hours-online-triggered-an-email-from-my-isps-president/">https://arstechnica.com/gadgets/2023/07/the-90s-internet-when-20-hours-online-triggered-an-email-from-my-isps-president/</a>, See on <a href="https://news.ycombinator.com/item?id=36813210">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/banj-edwards-terminally-online2-800x450.jpg" alt="The ‘90s Internet: When 20 hours online triggered an email from my ISP’s president">
      <figcaption><p>Banj Edwards | Aurich Lawson | Getty Images</p></figcaption>  </figure>

  




<!-- cache hit 288:single/related:a53e128e87d5db82176cc5af52b3d616 --><!-- empty -->
<p>"When checking the system this morning, I noticed your account logged in for over 20 hours," begins a December 1998 email from the president of my dial-up Internet service provider (ISP) at the time. "Our service is unlimited, but we ask that you actually be using the connection while logged in."</p>

<p>Today, when it seems like everyone is online 24/7 through smartphones and broadband, I'd be weird if I <em>wasn't online</em> for 20 hours straight. But 1998 in Raleigh, North Carolina, was different. In an age of copper telephone lines and dial-up modems, Internet access wasn't usually an always-on situation for a home user in the US. Each occupied telephone line meant another ISP customer couldn't use it—and no one could call you, either.</p>
<p>But I'm getting ahead of myself—why do I have an email from 1998?</p>
<h2>A voice from the past</h2>

<p>I save everything. It's just <a href="https://www.pcmag.com/news/gear-envy-my-collection-of-500-plus-pieces-of-computer-and-gaming-hardware">what I do</a>.</p>
<p>Being an amateur data archivist has served me well during my <a href="https://benjedwards.com/works.php">career</a> writing about tech. About eight years ago, I decided to search my archives for old email files and import them all into Apple Mail for OS X, organizing them chronologically so I could look at them all in one place. I found Internet emails going as far back as 1995, when I started using a POP3 client instead of <a href="https://en.wikipedia.org/wiki/Pine_(email_client)">Pine</a>. While browsing emails from 1998, I found a curious nugget from another era that blew me away.</p>
<blockquote><p>From: Eugene J. Fourney III<br>
Date: December 18, 1998 11:21 AM<br>
Subject: Online for 20 hours straight</p>
<p>Thank you for allowing NetWorks to provide Internet service.</p>
<p>I am writing because when checking the system this morning, I<br>
noticed your account logged in for over 20 hours.</p>
<p>Our service is unlimited, but we ask that you actually be using the<br>
connection while logged in. This has not been the case on occasion with<br>
your account.</p>
<p>We must ask that you take measures to ensure that you disconnect after<br>
any given session. Our resources must be shared between many customers,<br>
and the only way to accomplish that is for people to close the<br>
connection when they are not actively using it.</p>
<p>Please help with this by checking your dialer settings, and setting it<br>
to disconnect after 30 minutes of inactivity. Please also uncheck the<br>
option in your email program that automatically checks mail every 10<br>
minutes, or set it to some number higher than 30 minutes.</p>
<p>If you need help in locating these settings or want to discuss this<br>
further, please contact me at this email address or at our offices at<br>
518-0351 or 518-8034.</p>
<p>Gene Fourney</p></blockquote>
<p>I vaguely remember getting this email and thinking it was ridiculous because the connection was supposedly "unlimited." My family paid NetWorks a monthly fee (a $24.95 "Family Plan" for three user IDs) that allowed me, my dad, and my brother to connect to the Internet as much as we wanted—or so I thought. I showed the email to my father, who shrugged it off.</p>                                            
                                                        

<p>Between 1995 and 2000, I used a dial-up ISP, which meant that I had to call in to the ISP using a regular copper phone line and a dial-up modem running at anywhere between 14.4Kbps to 56Kbps over the years. Since most people also used their telephone lines for talking with their voice, there was a basic assumption that most calls to the ISP would be temporary. If your line was occupied, you would miss incoming calls. In my situation, my parents had set up a second phone line exclusively for my BBS in 1993 so I could spend as much time online as necessary without worrying about blocking incoming phone calls to my family.</p>
<p>A key issue I had with the email was the implication that I wasn't using my Internet connection during those 20 hours. I'm pretty sure I was using it, and not just for automatically checking my email every 30 minutes, as the email suggests.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Primo – a visual CMS with Svelte blocks, a code editor, and SSG (274 pts)]]></title>
            <link>https://primocms.org</link>
            <guid>36813086</guid>
            <pubDate>Fri, 21 Jul 2023 12:38:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://primocms.org">https://primocms.org</a>, See on <a href="https://news.ycombinator.com/item?id=36813086">Hacker News</a></p>
<div id="readability-page-1" class="page">

    
    <div id="section-885d7628">
        <header>
            
            <div>
                <h2><!-- HTML_TAG_START -->
                    <p>Primo is a visual CMS that makes it a blast to build <strong>pages</strong>, manage <strong>content</strong>, and edit <strong>code</strong> - one block at a time.</p><!-- HTML_TAG_END -->
                </h2>


                
            </div>
            <div>
                <figure><iframe src="https://player.vimeo.com/video/838469641?h=df40df2d2c&amp;badge=0&amp;loop=1&amp;autopause=0&amp;player_id=0&amp;autoplay=1&amp;muted=1&amp;loop=1&amp;title=0&amp;sidedock=0&amp;controls=&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen="" title="Landing Page Demo"></iframe></figure>
                
            </div>
        </header>

    </div>
    <section id="section-ddd59217">
            <header>
                <h2>The modern monolithic CMS</h2>
                <h3>Primo combines delightful content management with the power of modern development</h3>
            </header>
            <div>
                <div>
                    <div>
                        <h2>Drag-n-drop page building</h2>
                        <p>Build your site's pages by dragging and dropping your directly blocks onto the page, unencumbered by overwhelming design options.</p>
                    </div>
                    <figure><img src="https://kdtzsoeklezpgshpzqtf.supabase.co/storage/v1/object/public/images/7c1dc1a3-c9eb-4364-b31b-951ecfc2641d/1682111950401Screen%20Shot%202023-04-21%20at%205.17.27%20PM.png" alt=""></figure>
                </div>
                <div>
                    <div>
                        <h2>Visual content editing</h2>
                        <p>Update your text, images, and links directly on the page or open up the Fields view to manage your content from a structured view.</p>
                    </div>
                    <figure><img src="https://kdtzsoeklezpgshpzqtf.supabase.co/storage/v1/object/public/images/7c1dc1a3-c9eb-4364-b31b-951ecfc2641d/Screen%20Shot%202023-04-21%20at%205.22.39%20PM.png1682112222228" alt=""></figure>
                </div>
                <div>
                    <div>
                        <h2>Integrated development</h2>
                        <p>Access each block's code with a click - right from your browser. And since each block is a <a href="https://svelte.dev/">Svelte</a> component, there's no limit to what you can make.</p>
                    </div>
                    <figure><img src="https://kdtzsoeklezpgshpzqtf.supabase.co/storage/v1/object/public/images/7c1dc1a3-c9eb-4364-b31b-951ecfc2641d/Screen%20Shot%202023-04-21%20at%205.25.06%20PM.png1682112330379" alt=""></figure>
                </div>
            </div>
        </section>
    <div id="section-d294b81b">
                <ul>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 256 256"><!-- HTML_TAG_START -->
                                <path fill="currentColor" d="m213.66 66.34l-40-40A8 8 0 0 0 168 24H88a16 16 0 0 0-16 16v16H56a16 16 0 0 0-16 16v144a16 16 0 0 0 16 16h112a16 16 0 0 0 16-16v-16h16a16 16 0 0 0 16-16V72a8 8 0 0 0-2.34-5.66ZM136 192H88a8 8 0 0 1 0-16h48a8 8 0 0 1 0 16Zm0-32H88a8 8 0 0 1 0-16h48a8 8 0 0 1 0 16Zm64 24h-16v-80a8 8 0 0 0-2.34-5.66l-40-40A8 8 0 0 0 136 56H88V40h76.69L200 75.31Z"></path><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Static Sites<!-- HTML_TAG_END --></span>
                        </h3>
                        <p>Your websites are secure, scalable to millions, and fast-loading - no fancy plugins necessary.</p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <path fill="currentColor" d="M12 5.5A3.5 3.5 0 0 1 15.5 9a3.5 3.5 0 0 1-3.5 3.5A3.5 3.5 0 0 1 8.5 9A3.5 3.5 0 0 1 12 5.5M5 8c.56 0 1.08.15 1.53.42c-.15 1.43.27 2.85 1.13 3.96C7.16 13.34 6.16 14 5 14a3 3 0 0 1-3-3a3 3 0 0 1 3-3m14 0a3 3 0 0 1 3 3a3 3 0 0 1-3 3c-1.16 0-2.16-.66-2.66-1.62a5.536 5.536 0 0 0 1.13-3.96c.45-.27.97-.42 1.53-.42M5.5 18.25c0-2.07 2.91-3.75 6.5-3.75s6.5 1.68 6.5 3.75V20h-13v-1.75M0 20v-1.5c0-1.39 1.89-2.56 4.45-2.9c-.59.68-.95 1.62-.95 2.65V20H0m24 0h-3.5v-1.75c0-1.03-.36-1.97-.95-2.65c2.56.34 4.45 1.51 4.45 2.9V20Z"></path><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Real-time collaboration<!-- HTML_TAG_END --></span>
                        </h3>
                        <p>Invite any number of collaborators as developers or content editors and edit your pages together. </p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <g fill="currentColor">
                                    <path fill-rule="evenodd" d="M14 7a1 1 0 0 0-1 1v8a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1V8a1 1 0 0 0-1-1h-4Zm3 2h-2v6h2V9Z" clip-rule="evenodd"></path>
                                    <path d="M6 7a1 1 0 0 0 0 2h4a1 1 0 1 0 0-2H6Zm0 4a1 1 0 1 0 0 2h4a1 1 0 1 0 0-2H6Zm-1 5a1 1 0 0 1 1-1h4a1 1 0 1 1 0 2H6a1 1 0 0 1-1-1Z"></path>
                                    <path fill-rule="evenodd" d="M4 3a3 3 0 0 0-3 3v12a3 3 0 0 0 3 3h16a3 3 0 0 0 3-3V6a3 3 0 0 0-3-3H4Zm16 2H4a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h16a1 1 0 0 0 1-1V6a1 1 0 0 0-1-1Z" clip-rule="evenodd"></path>
                                </g><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Multisite to the max<!-- HTML_TAG_END --></span>
                        </h3>
                        <p data-key="items[2].description"><!-- HTML_TAG_START -->
                            <h2>Create an unlimited number of websites on a single server and start new sites in seconds.</h2><!-- HTML_TAG_END -->
                        </p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <path fill="currentColor" d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33c.85 0 1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2Z"></path><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Deploy to Github<!-- HTML_TAG_END --></span>
                        </h3>
                        <p data-key="items[3].description"><!-- HTML_TAG_START -->
                            <h2 id="deployyoursitetoagithubrepositoryfromthereyoucaneasilydeployittoanywebhost">Deploy your site to a Github repository. From there you can easily deploy it to any web host.</h2><!-- HTML_TAG_END -->
                        </p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <g fill="currentColor">
                                    <path fill-rule="evenodd" d="M14 7a1 1 0 0 0-1 1v8a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1V8a1 1 0 0 0-1-1h-4Zm3 2h-2v6h2V9Z" clip-rule="evenodd"></path>
                                    <path d="M6 7a1 1 0 0 0 0 2h4a1 1 0 1 0 0-2H6Zm0 4a1 1 0 1 0 0 2h4a1 1 0 1 0 0-2H6Zm-1 5a1 1 0 0 1 1-1h4a1 1 0 1 1 0 2H6a1 1 0 0 1-1-1Z"></path>
                                    <path fill-rule="evenodd" d="M4 3a3 3 0 0 0-3 3v12a3 3 0 0 0 3 3h16a3 3 0 0 0 3-3V6a3 3 0 0 0-3-3H4Zm16 2H4a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h16a1 1 0 0 0 1-1V6a1 1 0 0 0-1-1Z" clip-rule="evenodd"></path>
                                </g><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->
                                Themes
                                <!-- HTML_TAG_END --></span>
                        </h3>
                        <p>Hit the ground running with one of Primo's free themes and customize it in seconds using CSS variables.</p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <g fill="currentColor">
                                    <path d="M8.51 2h6.98c.232 0 .41 0 .566.015c1.108.109 2.015.775 2.4 1.672H5.544c.385-.897 1.292-1.563 2.4-1.672C8.098 2 8.276 2 8.51 2Zm-2.2 2.723c-1.39 0-2.53.84-2.91 1.954a2.587 2.587 0 0 0-.024.07c.398-.12.813-.2 1.232-.253c1.08-.139 2.446-.139 4.032-.139h6.892c1.586 0 2.951 0 4.032.139c.42.054.834.132 1.232.253a2.173 2.173 0 0 0-.023-.07c-.38-1.114-1.52-1.954-2.911-1.954H6.31Z"></path>
                                    <path fill-rule="evenodd" d="M8.672 7.542h6.656c3.374 0 5.062 0 6.01.987c.947.987.724 2.511.278 5.56l-.422 2.892c-.35 2.391-.525 3.587-1.422 4.303c-.897.716-2.22.716-4.867.716h-5.81c-2.646 0-3.97 0-4.867-.716c-.897-.716-1.072-1.912-1.422-4.303l-.422-2.891c-.447-3.05-.67-4.574.278-5.561c.948-.987 2.636-.987 6.01-.987ZM8 18c0-.414.373-.75.833-.75h6.334c.46 0 .833.336.833.75s-.373.75-.833.75H8.833c-.46 0-.833-.336-.833-.75Z" clip-rule="evenodd"></path>
                                </g><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Primo Library<!-- HTML_TAG_END --></span>
                        </h3>
                        <p>Access a growing library of pre-built blocks which automatically adapt to your site's design.</p>
                    </li>
                </ul>

                </div>
    <div id="section-3d86c4f7">
                <h2>Spin up speedy, secure, scalable static sites in seconds.</h2>
                <p><!-- HTML_TAG_START -->
                    <h2>Set up your own Primo server in under 5 minutes and manage unlimited sites with ease. Don't want to manage your own server? Try Primo Cloud for free.</h2><!-- HTML_TAG_END -->
                </p>
                <p><a href="https://docs.primocms.org/getting-started"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 512 512"><!-- HTML_TAG_START -->
                            <ellipse cx="256" cy="128" fill="none" stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="32" rx="192" ry="80"></ellipse>
                            <path fill="none" stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="32" d="M448 214c0 44.18-86 80-192 80S64 258.18 64 214m384 86c0 44.18-86 80-192 80S64 344.18 64 300"></path>
                            <path fill="none" stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="32" d="M64 127.24v257.52C64 428.52 150 464 256 464s192-35.48 192-79.24V127.24"></path><!-- HTML_TAG_END -->
                        </svg>
                        Self-host
                    </a>
                    <a href="https://primocms.org/cloud"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                            <path fill="currentColor" d="M12 6c2.62 0 4.88 1.86 5.39 4.43l.3 1.5l1.53.11A2.98 2.98 0 0 1 22 15c0 1.65-1.35 3-3 3H6c-2.21 0-4-1.79-4-4c0-2.05 1.53-3.76 3.56-3.97l1.07-.11l.5-.95A5.469 5.469 0 0 1 12 6m0-2C9.11 4 6.6 5.64 5.35 8.04A5.994 5.994 0 0 0 0 14c0 3.31 2.69 6 6 6h13c2.76 0 5-2.24 5-5c0-2.64-2.05-4.78-4.65-4.96A7.49 7.49 0 0 0 12 4z"></path><!-- HTML_TAG_END -->
                        </svg>
                        Primo Cloud
                    </a>
                </p>
            </div>
    <section id="section-dbc84ff9">
            <h2>Frequently Asked Questions</h2>
            <div><p>Primo is under full-time development and is in the process of becoming a nonprofit organization. Any funds generated from White Glove and Cloud will go towards funding further development, in the same vein as <a href="https://ghost.org/">Ghost CMS</a>.</p>
                    
                </div>
        </section>
    <div id="section-b18b744b">
                <div>
                    <h2>Hear about future updates, including:</h2>
                    <h3><!-- HTML_TAG_START -->
                        <ul>
                            <li>
                                <p><strong>Using it headless</strong> alongside SvelteKit, NextJS, etc.</p>
                            </li>
                            <li>
                                <p><strong>Design fields</strong> to give content editors predefined style options.</p>
                            </li>
                            <li>
                                <p><strong>Cloud functions</strong> for writing backend code from Primo.</p>
                            </li>
                        </ul><!-- HTML_TAG_END -->
                    </h3>
                </div>
                <div>
                    
                    <p><img src="https://track.mailerlite.com/webforms/o/5039306/j2m2z7?v1637419080" width="1" height="1" alt=".">
                </p></div>
                
                
            </div>
    

    


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tell HN: Upgrade your Metabase installation immediately (196 pts)]]></title>
            <link>https://github.com/metabase/metabase/releases/tag/v0.46.6.1</link>
            <guid>36812256</guid>
            <pubDate>Fri, 21 Jul 2023 10:45:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/metabase/metabase/releases/tag/v0.46.6.1">https://github.com/metabase/metabase/releases/tag/v0.46.6.1</a>, See on <a href="https://news.ycombinator.com/item?id=36812256">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pjax="true" data-test-selector="body-content" data-view-component="true"><p><strong>Upgrade your Metabase installation IMMEDIATELY.</strong></p>
<p>A recently discovered security vulnerability almost certainly affects you, and we recommend you upgrade your Metabase Installation right away.</p>
<p><strong>Upgrading</strong></p>
<p>You can download a .jar of the release, or get the latest on Docker. Make sure to back up your Metabase<br>
database before you upgrade! Need help? Check out our<br>
<a href="https://metabase.com/docs/latest/operations-guide/upgrading-metabase.html" rel="nofollow">upgrading instructions</a>.</p>
<p>Docker image: <code>metabase/metabase:v0.46.6.1</code><br>
Download the JAR here: <a href="https://downloads.metabase.com/v0.46.6.1/metabase.jar" rel="nofollow">https://downloads.metabase.com/v0.46.6.1/metabase.jar</a></p>
<p><strong>Notes</strong></p>
<p>SHA-256 checksum for the v0.46.6.1 JAR:</p>
<div data-snippet-clipboard-copy-content="12d267bf515a238944bb65fceed1ef83f5ae63451c11ad5b7f7adbeaf612e5c6"><pre><code>12d267bf515a238944bb65fceed1ef83f5ae63451c11ad5b7f7adbeaf612e5c6
</code></pre></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Small joys of programming in Odin (118 pts)]]></title>
            <link>http://www.zannzen.com/blog/small_joys_with_odin_1/</link>
            <guid>36812175</guid>
            <pubDate>Fri, 21 Jul 2023 10:30:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.zannzen.com/blog/small_joys_with_odin_1/">http://www.zannzen.com/blog/small_joys_with_odin_1/</a>, See on <a href="https://news.ycombinator.com/item?id=36812175">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>Update (2023-07-21): I was being a bit overly brief with liberal use of <code>...</code> to mean “unimportant” in the code examples. Ginger Bill (creator of Odin) noted it might be clearer to have more correct/explicit Odin and Zig code for the examples given people would be less familiar. Those has been updated</em></p>
<p>For the past few months I’ve been using the programming language <a href="http://odin-lang.org/">Odin</a> in my spare time regularly. I’ve been off and on with it for a year or so but after this past year’s Advent of Code I decided to stick with it. Briefly, Odin is a C-like language that is data-oriented and pragmatic. Or as the website says “The Data-Oriented Language for Sane Software Development”. In my mind, the reason I’ve enjoyed it so much is: it’s the systems programming language with the fewest “wtf"s I’ve experienced so far<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. In fact one of Odin’s guiding principles is “The Joy of Programming” and after getting the basics down, I’ve found Odin to be pretty intuitive.</p>
<p>On that note, this post is a showcase of a couple features that brought me small moments of joy while using the language. I’m not going to do a full overview of Odin – if you want that the <a href="http://odin-lang.org/docs/overview/">overview</a>, <a href="https://github.com/odin-lang/Odin/blob/master/examples/demo/demo.odin">demo.odin</a>, and <a href="https://pkg.odin-lang.org/">package docs</a> have you covered – instead I’m going to explain some small pain points I’ve had with other languages and then explain how Odin removed those minor pains.</p>
<p>While there isn’t anything super technical in here, I’m probably assuming some knowledge and I do swap between three different languages to show examples (Odin, C++, and Zig). A general programming background might be helpful to see the structure over the details.</p>
<hr>
<h2 id="overview">Overview</h2>
<p>Odin has a number of built-in quality of life features that enhances day to day coding: <a href="http://odin-lang.org/docs/overview/#bit-sets">bit_sets</a> for flags (which work when interop-ing with C!), or <a href="http://odin-lang.org/docs/overview/#array-programming">array programming</a> which makes anything graphics related very nice. The language doesn’t have everything – the big example being there’s no compile-time execution of functions – but the features it does have are well integrated. Below are just two smaller features that led to moments where I thought “that’s fantastic.”</p>
<h2 id="caller_locationhttpodin-langorgdocsoverviewcaller_location"><a href="http://odin-lang.org/docs/overview/#caller_location">#caller_location</a></h2>
<p>Odin has the compiler directive <code>#caller_location</code> which, as the name suggests, creates a struct containing the current file name, procedure name, line, and column of the caller of a procedure (proc). The type is <a href="https://pkg.odin-lang.org/core/runtime/#Source_Code_Location">Source_Code_Location</a> and, as with all of Odin’s built-in types, you can find its definition in the <a href="https://github.com/odin-lang/Odin/blob/master/core/runtime/core.odin#L291C1-L291C1">runtime</a> package. <code>#caller_location</code> isn’t just an afterthought: Odin’s core collection (what Odin calls its standard library) uses it in most allocations, asserts, or logging. It’s fairly well integrated.</p>
<p>For your own procs, you can capture caller information by assigning <code>#caller_location</code> to an argument like so:</p>
<div><pre tabindex="0"><code data-lang="odin"><span><span><span>// odin calls functions procedures
</span></span></span><span><span><span></span>some_procedure <span>::</span> <span>proc</span>(x, y<span>:</span> <span>int</span>, loc <span>:=</span> <span>#caller_location</span>) {}
</span></span></code></pre></div><p>You can then pass the location information on to downstream proc calls if you want.</p>
<p>For a while the directive sat resoundly in my “…neat” category. I could see how maybe it would be nice to have when you want it. But also I figured it’s essentially just <code>__LINE__</code> and the like from C… so I promptly ignored it.</p>
<p>Until I was writing some tests<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> while following along with <a href="https://interpreterbook.com/">Writing an Interpreter in Go</a></p>
<h3 id="small-annoyances-when-testing-in-c3">Small annoyances when testing in C++<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></h3>
<p>When writing tests in C++ (and other languages), often times you want to verify the state of some object multiple times in a test. Perhaps the type has many values or you’re trying to assert some invariant between the members. Maybe you just want your test framework to tell you which member had the incorrect value rather than the struct as a whole. When the combinations of values to check start getting large you might write a helper check function that asserts the validity. The following is a stripped down example<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> (i.e. don’t expect it to compile):</p>
<div><pre tabindex="0"><code data-lang="cpp"><span><span><span>// C++
</span></span></span><span><span><span></span><span>struct</span> <span>Quotes</span> {
</span></span><span><span>    <span>int32_t</span> bid_price;
</span></span><span><span>    <span>int32_t</span> bid_size;
</span></span><span><span>    <span>int32_t</span> ask_price;
</span></span><span><span>    <span>int32_t</span> ask_size;
</span></span><span><span>};
</span></span><span><span>
</span></span><span><span><span>void</span> <span>assert_quotes_safe</span>(<span>const</span> Quotes <span>&amp;</span>quote, <span>const</span> Safeties <span>&amp;</span>safeties) {
</span></span><span><span>    <span>if</span> (quote.bid_price <span>&lt;</span> <span>0</span> <span>&amp;&amp;</span> quote.ask_price <span>&lt;</span> <span>0</span>) {
</span></span><span><span>        <span>// requires writing an `operator&lt;&lt;` overload for Quotes
</span></span></span><span><span><span></span>        <span>// this is apparently how you send error strings to the test framework for gtest
</span></span></span><span><span><span></span>        EXPECT_TRUE(false) <span>&lt;&lt;</span> <span>"Quotes had negative prices: "</span> <span>&lt;&lt;</span> quote;
</span></span><span><span>        ASSERT_TRUE(false); <span>// exits the test case immediately
</span></span></span><span><span><span></span>    }
</span></span><span><span>    
</span></span><span><span>    EXPECT_TRUE(quote.bid_price <span>&lt;=</span> quote.ask_price);
</span></span><span><span>    EXPECT_TRUE(quote.bid_price <span>*</span> quote.bid_size <span>&lt;=</span> safeties.max_dollars);
</span></span><span><span>    <span>// more checks
</span></span></span><span><span><span></span>}
</span></span><span><span>
</span></span><span><span>TEST(TestSomeQuoteGeneration) {
</span></span><span><span>    <span>// setup
</span></span></span><span><span><span></span>    assert_quotes_safe(current_quotes, safeties);
</span></span><span><span>    <span>// trigger a quote gen
</span></span></span><span><span><span></span>    assert_quotes_safe(current_quotes, safeties);
</span></span><span><span>    <span>// do some follow up that may or may not gen new quote
</span></span></span><span><span><span></span>    assert_quotes_safe(current_quotes, safeties);
</span></span><span><span>}
</span></span></code></pre></div><p>When <code>TestSomeQuoteGeneration</code> fails, the test framework will print out something similar to:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>TestSomeQuoteGeneration - test.cpp:13:assert_quotes_safe Quotes had negative prices: bid_price <span>=</span> ....
</span></span></code></pre></div><p>That is it prints the line where the <code>EXPECT()</code> failed. The issue is every test now fails in the <code>assert_quotes_safe</code> function and you need to go figure out where exactly the failure came from. With C++ you can usually run the test in gdb and then just step up one frame when the test fails. Unless you’ve been compiling with undefined behavior sanitizer (ubsan) in which case your debug information is useless and you have to recompile the entire project (thankfully there’s ccache).</p>
<p>There are definitely solutions to this problem. You could have <code>assert_quotes_safe</code> return a bool or error enum and then have an additional <code>ASSERT_TRUE(assert_quotes_safe(...))</code> in the calling code. Again we aren’t discussing a massive issue here. It’s a small pain point you have to do a little more work for, plan for ahead of time, and/or add something at all locations you call <code>assert_quotes_safe</code>.</p>
<h3 id="a-small-joy-when-testing-in-odin">A small joy when testing in Odin</h3>
<p>Odin, like many modern languages, has built-in testing support. To add a test you use the attribute <code>@(test)</code> on any procedure. To make code organization slightly easier, Odin detects when a filename ends with <code>_test.odin</code> and will drop those files during a normal build. Odin also has a core package called <a href="https://pkg.odin-lang.org/core/testing/">testing</a> which contains a number of useful utilities.</p>
<p>If you’re familiar with Go, the code will look very familiar.</p>
<div><pre tabindex="0"><code data-lang="odin"><span><span><span>// Odin
</span></span></span><span><span><span></span><span>package</span> some_financial_thing
</span></span><span><span>
</span></span><span><span><span>import</span> <span>"core:testing"</span>
</span></span><span><span>
</span></span><span><span>Quotes <span>::</span> <span>struct</span> {
</span></span><span><span>    bid_price, bid_size, ask_price, ask_size<span>:</span> <span>i32</span>,
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>// this code is even nicer after https://github.com/odin-lang/Odin/pull/2597
</span></span></span><span><span><span></span>assert_quotes_safe <span>::</span> <span>proc</span>(t<span>:</span> <span>^</span>testing.T, quotes<span>:</span> Quotes, safeties<span>:</span> Safeties, loc <span>:=</span> <span>#caller_location</span>) {
</span></span><span><span>    <span>if</span> quotes.ask_price <span>&lt;</span> <span>0</span> <span>&amp;&amp;</span> quotes.bid_price <span>&lt;</span> <span>0</span> {
</span></span><span><span>        testing.errorf(t, <span>"quotes had negative prices: %#v"</span>, quotes, loc <span>=</span> loc)
</span></span><span><span>        testing.fail_now(t, loc <span>=</span> loc) <span>// returns from test immediately
</span></span></span><span><span><span></span>    }
</span></span><span><span>    
</span></span><span><span>    testing.expect(t, quotes.bid_price <span>&lt;=</span> quotes.ask_price, loc <span>=</span> loc)
</span></span><span><span>    testing.expect(t, quotes.bid_price <span>*</span> quotes.bid_size <span>&lt;=</span> safeties.max_dollars, loc <span>=</span> loc)
</span></span><span><span>    <span>// more tests
</span></span></span><span><span><span></span>}
</span></span><span><span>
</span></span><span><span><span>@(test)</span>
</span></span><span><span>test_some_quote_genration <span>::</span> <span>proc</span>(t<span>:</span> <span>^</span>testing.T) {
</span></span><span><span>    <span>// setup
</span></span></span><span><span><span></span>    assert_quotes_safe(current_quotes, safeties);
</span></span><span><span>    <span>// send some trigger
</span></span></span><span><span><span></span>    assert_quotes_safe(current_quotes, safeties);
</span></span><span><span>    <span>// do some follow up that may or may not gen new quote
</span></span></span><span><span><span></span>    assert_quotes_safe(current_quotes, safeties);
</span></span><span><span>}
</span></span></code></pre></div><p>The procedures in the testing package such as <code>expect_value</code> or <code>errorf</code> all have a <code>loc := #caller_location</code> argument. By passing the location information we captured, we’ll get a more useful error message on failures such as:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>test.odin:<span>(</span>27:5<span>)</span> - quotes had negative prices: Quotes<span>{</span>bid_price <span>=</span> ...<span>}</span>
</span></span></code></pre></div><p>The line number is where we actually call <code>assert_quotes_safe</code>! So now we can just set our breakpoint before the second call to <code>assert_quotes_safe</code> rather than spending time figuring out which one it was.</p>
<p>Again, this isn’t massive. But given the amount I’ve had to trace back tests before it’s very welcome.</p>
<h2 id="disabled--conditionhttpsodin-langorgdocsoverviewdisabledboolean"><a href="https://odin-lang.org/docs/overview/#disabledboolean">@(disabled = &lt;condition&gt;)</a></h2>
<p>I’ve used a few C / C++ replacement languages that don’t have macros. I’m always pretty happy with the result. Even in C++ I try to avoid writing macros unless I actually have to (constexpr all the things!). <a href="https://ziglang.org/">Zig</a> was the first C replacement I tried and I immediately loved its <code>comptime</code> (compile time evaluation/execution). It was essentially everything I wanted from C++ and then some but in a simpler form<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>. The fact Zig can create an <a href="https://zig.news/kristoff/struct-of-arrays-soa-in-zig-easy-in-userland-40m0">SoA</a> type in userspace with comptime is amazing. If I were actively using Zig at work I’d be very happy<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup>.</p>
<p>But there are certain things I’m used to from C++ that are a pain in most of these languages that don’t have macros. The immediate example that never really has a good solution is logging.</p>
<h3 id="a-brief-look-at-logging">A brief look at logging</h3>
<p>Just a brief talk on why logging is a prime example - logging is <em>expensive</em>. Even fast logging frameworks still require time to copy data onto some queue so another thread can do the formatting. On the other hand, having debug logs in your code is fantastic for debugging (shocker). To balance that, you want some system to enable or disable debug logging at build time. In C++ you’d do this with macros. Note I’m leaving a lot of the code as <code>...</code> for brevity and because it’s irrelevant to the point.</p>
<div><pre tabindex="0"><code data-lang="cpp"><span><span><span>enum</span> <span>class</span> <span>LogLevel</span> {
</span></span><span><span>    Debug,
</span></span><span><span>    Info
</span></span><span><span>};
</span></span><span><span>
</span></span><span><span><span>void</span> <span>log_something</span>(LogLevel level, ...);
</span></span><span><span>
</span></span><span><span><span>#ifndef LOG_LEVEL_DEBUG
</span></span></span><span><span><span>#define LOG_DEBUG(...)
</span></span></span><span><span><span>#else
</span></span></span><span><span><span>#define LOG_DEBUG(...) log_something(LogLevel::Debug, ...);
</span></span></span><span><span><span>#endif
</span></span></span><span><span><span></span>
</span></span><span><span><span>#define LOG_INFO(...) log_something(LogLevel::Info, ...);
</span></span></span><span><span><span></span>
</span></span><span><span><span>void</span> <span>some_function</span>() {
</span></span><span><span>    <span>// do things
</span></span></span><span><span><span></span>    foo();
</span></span><span><span>    <span>// log some data
</span></span></span><span><span><span></span>    LOG_DEBUG(<span>"some sort of verbose information: %s"</span>, expensive_to_string(my_data_type));
</span></span><span><span>}
</span></span></code></pre></div><p>If you’re not familiar, the above <code>LOG_DEBUG</code> macro is essentially “If <code>LOG_LEVEL_DEBUG</code> is defined, replace <code>LOG_DEBUG</code> with a call to <code>log_something</code> and forward all arguments. If it’s not defined replace the whole thing with an empty string including the arguments.” It’s a pretty simple macro to use, you just call it like a function.</p>
<p>Zig doesn’t have a macro system though, so you might define your logging in a similar way using <code>comptime</code><sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>:</p>
<div><pre tabindex="0"><code data-lang="zig"><span><span><span>// probably use @import("root") in actual code
</span></span></span><span><span><span></span><span>const</span> LOG_LEVEL <span>=</span> LogLevel.debug;
</span></span><span><span>
</span></span><span><span><span>const</span> LogLevel <span>=</span> <span>enum</span> {
</span></span><span><span>    debug,
</span></span><span><span>    info,
</span></span><span><span>};
</span></span><span><span>
</span></span><span><span><span>pub</span> <span>fn</span> logSomething(<span>comptime</span> level<span>:</span> LogLevel, <span>comptime</span> format<span>:</span> []<span>const</span> <span>u8</span>, args<span>:</span> anytype) {
</span></span><span><span>    <span>if</span> level <span>&gt;=</span> LOG_LEVEL {
</span></span><span><span>        actuallyLogTheThing(level, format, args);
</span></span><span><span>    }
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>pub</span> <span>fn</span> logDebug(<span>comptime</span> format<span>:</span> []<span>const</span> <span>u8</span>, args<span>:</span> anytype) {
</span></span><span><span>    logSomething(LogLevel.debug, format, anytype);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>fn</span> someFunction() {
</span></span><span><span>    <span>// do things
</span></span></span><span><span><span></span>    foo();
</span></span><span><span>    <span>// log some data
</span></span></span><span><span><span></span>    logDebug(<span>"some sort of verbose information {s}"</span>, .{expensiveToString(my_data_type)});
</span></span><span><span>}
</span></span></code></pre></div><p>Zig’s <code>comptime</code> is fantastic and the above is very similar to the C++. At compile time if you’ve defined <code>LOG_LEVEL</code> to be <code>info</code> then <code>logDebug</code> becomes a noop. No copies to a queue, no formatting. It seems essentially the same as the C++.</p>
<h3 id="a-minor-annoyance-with-macroless-languages">A minor annoyance with macroless languages</h3>
<p>It’s great that <code>logDebug</code> is a noop. It sounds like exactly what we want. However, what happens to the arguments you pass that noop? As the name implies <code>expensiveToString</code> is costly. In the C++ version the call is removed by the preprocessor, but what about the Zig version? Maybe the compiler notices they’re unused and optimizes them out in a release build. But what if your expensive used-for-debug-logging-only function has side effects like incrementing some debug metrics? What if the function is from a C library so it can’t be inlined at all? In a lot of code few extraneous calls might not be the end of the world as long as the log itself gets dropped downstream (what’s a few hundred nanos or a mic or two between friends?<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup>), but sometimes it’s unnacceptable.</p>
<p>The solution in Zig is to wrap everything in a comptime if:</p>
<div><pre tabindex="0"><code data-lang="zig"><span><span><span>fn</span> someFunction() {
</span></span><span><span>    <span>// do things
</span></span></span><span><span><span></span>    foo();
</span></span><span><span>    <span>// log some data
</span></span></span><span><span><span></span>    <span>if</span> (log_level <span>&lt;=</span> LogLevel.debug) {
</span></span><span><span>        <span>const</span> s <span>=</span> expensiveToString(my_data_type);
</span></span><span><span>        logDebug(<span>"some verbose information: %s"</span>, .{s})    
</span></span><span><span>    }
</span></span><span><span>}
</span></span></code></pre></div><p>Which is fine, but you need to litter your code with the <code>if log_level &lt;= LogLevel.debug</code>. You also need to know at every call site either the value the logger uses to enable/disable debug logging, or you need to define your own aliases e.g. <code>LOG_LEVEL_DEBUG</code> and use those. For production level code this is, again, a minor annoyance at worst. But it’s just annoying enough that I don’t really enjoy it either for my personal projects (which are just for fun anyway).</p>
<h3 id="a-small-joy-with-an-odin-attribute">A small joy with an Odin attribute</h3>
<p>At first I thought I’d need to do the same thing in Odin. It <em>does</em> have <code>when</code> which does conditional compilation. I was somewhat resigned to wraping all debug logging in a <code>when LOG_LEVEL &lt;= .Debug {}</code> and calling it a day. However, one of the things that I like about Odin is it’s very pragmatic. It doesn’t necessarily try to solve every problem with the same hammer.</p>
<p>I figured I’d post my annoyance in <code>#beginners</code> on the Odin discord in case someone had a good solution, and that’s when I was told about <code>@disabled</code>. <code>@disabled</code> is an attribute that removes all uses of a procedure when true. It doesn’t just turn the proc into a noop, it specifically removes the usage at call sites including any arguments passed to the procedure. The end result is similar to C++’s string replacement macros without the macros. The above example can be solved in Odin with e.g.:</p>
<div><pre tabindex="0"><code data-lang="odin"><span><span>Log_Level <span>::</span> <span>enum</span> {
</span></span><span><span>    Debug,
</span></span><span><span>    Info,
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span>LOG_LEVEL <span>::</span> Log_Level.Debug
</span></span><span><span>
</span></span><span><span>log_something <span>::</span> <span>proc</span>(level<span>:</span> Log_Level, fmt<span>:</span> <span>string</span>, args<span>:</span> ..<span>any</span>, loc <span>:=</span> <span>#caller_location</span>) {}
</span></span><span><span>
</span></span><span><span><span>@(disabled = LOG_LEVEL &gt; .Debug)</span>
</span></span><span><span>log_debug <span>::</span> <span>proc</span>(fmt<span>:</span> <span>string</span>, args<span>:</span> ..<span>any</span>, loc <span>:=</span> <span>#caller_location</span>) { <span>// and a nice #caller_location
</span></span></span><span><span><span></span>    log_something(.Debug, fmt, ..args, loc <span>=</span> loc)
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span>some_function <span>::</span> <span>proc</span>() {
</span></span><span><span>    <span>// do things
</span></span></span><span><span><span></span>    foo()
</span></span><span><span>    <span>// log some data
</span></span></span><span><span><span></span>    log_debug(<span>"some verbose information: %s"</span>, expensive_to_string(my_data_type))
</span></span><span><span>}
</span></span></code></pre></div><p>In the above, any invocation of <code>log_debug</code> will be stripped out if <code>LOG_LEVEL</code> is <code>.Info</code>. That includes any arguments passed to the proc. That means any expensive or non-inlineable procedures (like <code>expensive_to_string</code>) also won’t be called. It doesn’t rely on <code>-o:speed</code> optimizations to figure out the call is unused. A debug build with <code>log_debug</code> disabled will have the same behavior. In addition, user code just has to call <code>log_debug</code> and not worry about how the logging procs determine if they are enabled or not.</p>
<p>This example in particular was maybe a little more than just a small joy. It was an exact solution to what I wanted. Even without <code>expensive_to_string</code>, it’s nice to just log without having to think about it. The logging procs I write will handle it properly. There are most likely other cases where you still need a <code>when</code> like the Zig solution but it’s at least an 80/20 solution that works well.</p>
<h2 id="wrapping-up">Wrapping up</h2>
<p>To hammer the point again, nothing above is a game changer in programming. They’re just small, quality of life bonuses in Odin that sparked a tiny amount of joy for me personally.</p>
<p>If you are interested in Odin, I recommend reading over the main website to get a better idea if it’s something for you. If you decide it’s interesting then you should probably also join the <a href="https://discord.com/invite/sVBPHEv">discord</a>. There are dozens of us!</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I have written a JVM in Rust (604 pts)]]></title>
            <link>https://andreabergia.com/blog/2023/07/i-have-written-a-jvm-in-rust/</link>
            <guid>36811554</guid>
            <pubDate>Fri, 21 Jul 2023 08:48:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andreabergia.com/blog/2023/07/i-have-written-a-jvm-in-rust/">https://andreabergia.com/blog/2023/07/i-have-written-a-jvm-in-rust/</a>, See on <a href="https://news.ycombinator.com/item?id=36811554">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
  <article>
    <header>
      

      <div>
        <p>
          Published Wednesday, Jul 12, 2023
          -
          2164 words, 11 minutes
        </p>

        
      </div>
    </header>

    <p>Lately I’ve been spending quite a bit of time learning Rust, and as any sane person would do, after writing a few 100 lines programs I’ve decided to take on something <em>a little bit</em> more ambitious: I have written a Java Virtual Machine in Rust. 🎉 With a lot of originality, I have called it <code>rjvm</code>. The code is available <a href="https://github.com/andreabergia/rjvm">on GitHub</a>.</p>
<p>I want to stress that this is a toy JVM, built for learning purposes and not a serious implementation. In particular, it does not support:</p>
<ul>
<li>generics</li>
<li>threads</li>
<li>reflection</li>
<li>annotations</li>
<li>I/O</li>
<li>just in time compiler</li>
<li>string interning</li>
</ul>
<p>However, there are quite a few non-trivial things implemented:</p>
<ul>
<li>control flow statements (<code>if, for, ...</code>)</li>
<li>primitive and object creations</li>
<li>virtual and static method invocation</li>
<li>exceptions</li>
<li>garbage collection</li>
<li>class resolution from a <code>jar</code> file</li>
</ul>
<p>For example, the following is part of the test suite:</p>
<div><pre><code data-lang="java"><span>class</span> <span>StackTracePrinting</span> <span>{</span>
    <span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(</span>String<span>[]</span> args<span>)</span> <span>{</span>
        Throwable ex <span>=</span> <span>new</span> Exception<span>();</span>
        StackTraceElement<span>[]</span> stackTrace <span>=</span> ex<span>.</span><span>getStackTrace</span><span>();</span>
        <span>for</span> <span>(</span>StackTraceElement element <span>:</span> stackTrace<span>)</span> <span>{</span>
            tempPrint<span>(</span>
                    element<span>.</span><span>getClassName</span><span>()</span> <span>+</span> <span>"::"</span> <span>+</span> element<span>.</span><span>getMethodName</span><span>()</span> <span>+</span> <span>" - "</span> <span>+</span>
                            element<span>.</span><span>getFileName</span><span>()</span> <span>+</span> <span>":"</span> <span>+</span> element<span>.</span><span>getLineNumber</span><span>());</span>
        <span>}</span>
    <span>}</span>

    <span>// We use this in place of System.out.println because we don't have real I/O
</span><span></span>    <span>private</span> <span>static</span> <span>native</span> <span>void</span> <span>tempPrint</span><span>(</span>String value<span>);</span>
<span>}</span>
</code></pre></div><p>It uses the real <code>rt.jar</code> containing the classes from the <a href="https://openjdk.org/projects/jdk7/">OpenJDK 7</a> - thus, in the example above, the <code>java.lang.StackTraceElement</code> class comes from a real JDK!</p>
<p>I am very happy with what I have learned, about Rust and about how to implement a virtual machine. In particular, I am <em>super</em> happy about having implemented a real, working, garbage collector. It’s quite mediocre, but it’s mine and I love it. 💘 Given that I have achieved what I set out to do originally, I have decided to stop the project here. I know there are bugs, but I do not plan to fix them.</p>
<h2 id="overview">
  Overview
  <a href="#overview">
    
  </a>
</h2>
<p>In this post, I will give you an overview of how my JVM works. In further articles, I will go into more detail about some of the aspects discussed here.</p>
<h2 id="code-organization">
  Code organization
  <a href="#code-organization">
    
  </a>
</h2>
<p>The code is a standard Rust project. I have split it into three crates (i.e. packages):</p>
<ul>
<li><code>reader</code>, which is able to read <code>.class</code> files and contains various types that model their content;</li>
<li><code>vm</code>, which contains the virtual machine that can execute the code as a library;</li>
<li><code>vm_cli</code>, which contains a very simple command-line launcher to run the VM, in the spirit of the <code>java</code> executable.</li>
</ul>
<p>I’m considering extracting the <code>reader</code> crate in a separate repository and publishing it on <a href="https://crates.io/">crates.io</a>, since it could actually be useful to someone else.</p>
<h2 id="parsing-a-class-file">
  Parsing a <code>.class</code> file
  <a href="#parsing-a-class-file">
    
  </a>
</h2>
<p>As you know, Java is a compiled language - the <code>javac</code> compiler takes your <code>.java</code> source files and produces various <code>.class</code> files, generally distributed in a <code>.jar</code> file - which is just a <code>zip</code>. Thus, the first thing to do to execute some Java code is to load a <code>.class</code> file, containing the bytecode generated by the compiler. A class file contains various things:</p>
<ul>
<li>metadata about the class, such as its name or the source file name</li>
<li>the superclass name</li>
<li>the implemented interfaces</li>
<li>the fields, along with their types and annotations</li>
<li>and the methods with:
<ul>
<li>their descriptor, which is a string representing the type of each parameter and the method’s return type</li>
<li>metadata such as the <code>throws</code> clause, annotation, generics information</li>
<li>and the bytecode, along with some extra metadata such as the exception handler table and the line numbers table.</li>
</ul>
</li>
</ul>
<p>As mentioned above, for <code>rjvm</code> I have created a separate crate, named <code>reader</code>, which can parse a class file and return a <a href="https://github.com/andreabergia/rjvm/blob/main/reader/src/class_file.rs">Rust struct</a> that models a class and all its content.</p>
<h2 id="executing-methods">
  Executing methods
  <a href="#executing-methods">
    
  </a>
</h2>
<p>The main API of the <code>vm</code> crate is <a href="https://github.com/andreabergia/rjvm/blob/main/vm/src/vm.rs#L164"><code>Vm::invoke</code></a>, which is used to execute a method. It takes a <a href="https://github.com/andreabergia/rjvm/blob/main/vm/src/call_stack.rs"><code>CallStack</code></a>, which will contain the various <a href="https://github.com/andreabergia/rjvm/blob/main/vm/src/call_frame.rs#L58"><code>CallFrame</code></a>, one for each method being executed. For executing <code>main</code>, the call stack will initially be empty, and a new frame will be created to run it. Then, each function invocation will add a new frame to the call stack. When a method’s execution completes, its corresponding frame will be dropped and removed from the call stack.</p>
<p>Most methods will be implemented in Java, and thus their bytecode will be executed. However, <code>rjvm</code> also supports <em>native</em> methods, i.e. methods that are implemented directly by the JVM and not in the Java bytecode. There are quite a few of them in the “lower parts” of the Java API, where interaction with the operating system (for example, to do I/O) or the support runtime is necessary. Some examples of the latter you might have seen include <code>System::currentTimeMillis</code>, <code>System::arraycopy</code>, or <code>Throwable::fillInStackTrace</code>. In <code>rjvm</code>, these are implemented by <a href="https://github.com/andreabergia/rjvm/blob/main/vm/src/native_methods_impl.rs">Rust functions</a>.</p>
<p>The JVM is a <a href="https://andreabergia.com/blog/2015/03/stack-based-virtual-machines-1/">stack-based virtual machine</a>, i.e. the bytecode instructions operate mainly on a value stack. There is also a set of local variables, identified by an index, that can be used to store values and pass arguments to methods. These are associated with each call frame in <code>rjvm</code>.</p>
<h2 id="modeling-values-and-objects">
  Modeling values and objects
  <a href="#modeling-values-and-objects">
    
  </a>
</h2>
<p>The type <a href="https://github.com/andreabergia/rjvm/blob/main/vm/src/value.rs"><code>Value</code></a> models a possible value of a local variable, stack element, or object’s field, and is implemented as follows:</p>
<div><pre><code data-lang="rust"><span>/// Models a generic value that can be stored in a local variable or on the stack.
</span><span></span><span>#[derive(Debug, Default, Clone, PartialEq)]</span>
<span>pub</span> <span>enum</span> <span>Value</span><span>&lt;</span><span>'a</span><span>&gt;</span> {
    <span>/// An unitialized element. Should never be on the stack,
</span><span></span>    <span>/// but it is the default state for local variables.
</span><span></span>    <span>#[default]</span>
    Uninitialized,

    <span>/// Models all the 32-or-lower-bits types in the jvm: `boolean`,
</span><span></span>    <span>/// `byte`, `char`, `short`, and `int`.
</span><span></span>    Int(<span>i32</span>),

    <span>/// Models a `long` value.
</span><span></span>    Long(<span>i64</span>),

    <span>/// Models a `float` value.
</span><span></span>    Float(<span>f32</span>),

    <span>/// Models a `double` value.
</span><span></span>    Double(<span>f64</span>),

    <span>/// Models an object value
</span><span></span>    Object(AbstractObject<span>&lt;</span><span>'a</span><span>&gt;</span>),

    <span>/// Models a null object
</span><span></span>    Null,
}
</code></pre></div><p>As an aside, this is one place where a sum type, such as Rust’s <code>enum</code>, is a wonderful abstraction - it is great for expressing the fact that a value might be of multiple different types.</p>
<p>For storing objects and their values, I initially used a simple struct called <code>Object</code> containing a reference to the class (to model the object’s type) and a <code>Vec&lt;Value&gt;</code> for storing fields' values. However, when I implemented the garbage collector, I modified this to use a lower-level implementation, with a ton of pointers and casts - quite C style! In the current implementation, an <a href="https://github.com/andreabergia/rjvm/blob/main/vm/src/abstract_object.rs"><code>AbstractObject</code></a> (which models a “real” object, or an array) is simply a pointer to an array of bytes, which contain a couple of header words and then the fields' values.</p>
<h2 id="executing-instructions">
  Executing instructions
  <a href="#executing-instructions">
    
  </a>
</h2>
<p>Executing a method means executing its bytecode instructions, one at a time. The JVM has a wide list of instructions (over two hundred!), encoded by one byte in the bytecode. Many instructions are followed by arguments, and some have a variable length. This is modeled in the code by the type <a href="https://github.com/andreabergia/rjvm/blob/main/reader/src/instruction.rs"><code>Instruction</code></a>:</p>
<div><pre><code data-lang="rust"><span>/// Represents a Java bytecode instruction.
</span><span></span><span>#[derive(Clone, Copy, Debug, Eq, PartialEq)]</span>
<span>pub</span> <span>enum</span> <span>Instruction</span> {
    Aaload,
    Aastore,
    Aconst_null,
    Aload(<span>u8</span>),
    <span>// ...
</span></code></pre></div><p>The execution of a method will keep, as mentioned above, a stack and an array of local variables, referred by the instructions via their index. It will also initialize the program counter to zero - that is, the address of the next instruction to execute. The instruction will be processed and the program counter updated - generally advanced by one, but various jump instructions can move it to a different location. These are used to implement all flow control statements, such as <code>if</code>, <code>for</code>, or <code>while</code>.</p>
<p>A special family of instruction is made of those that can invoke another method. There are various ways of resolving <em>which</em> method should be invoked: virtual or static lookup are the main ones, but there are others. After resolving the correct instruction, <code>rjvm</code> will add a new frame to the call stack and start the method’s execution. The method’s return value will be pushed to the stack unless it is <code>void</code>, and execution will resume.</p>
<p>The Java bytecode format is quite interesting and I plan to dedicate a post to the various kind of instructions.</p>
<h2 id="exceptions">
  Exceptions
  <a href="#exceptions">
    
  </a>
</h2>
<p>Exceptions are quite a complex beast to implement since they break the normal control flow, and might return early from a method (and propagate on the call stack!). I am pretty happy with the way I have implemented them, though, and I am going to show you some of the relevant code.</p>
<p>The first thing you need to know is that any <code>catch</code> block corresponds to an entry of a method’s exception table - each entry contains the range of covered program counters, the address for the first instruction in the catch block, and the exception’s class name which the block catches.</p>
<p>Next, the signature of <a href="https://github.com/andreabergia/rjvm/blob/main/vm/src/call_frame.rs#L349"><code>CallFrame::execute_instruction</code></a> is as follows:</p>
<div><pre><code data-lang="rust"><span>fn</span> <span>execute_instruction</span>(
    <span>&amp;</span><span>mut</span> self,
    vm: <span>&amp;</span><span>mut</span> Vm<span>&lt;</span><span>'a</span><span>&gt;</span>,
    call_stack: <span>&amp;</span><span>mut</span> CallStack<span>&lt;</span><span>'a</span><span>&gt;</span>,
    instruction: <span>Instruction</span>,
) -&gt; Result<span>&lt;</span>InstructionCompleted<span>&lt;</span><span>'a</span><span>&gt;</span>, MethodCallFailed<span>&lt;</span><span>'a</span><span>&gt;&gt;</span>
</code></pre></div><p>Where the types are:</p>
<div><pre><code data-lang="rust"><span>/// Possible execution result of an instruction
</span><span></span><span>enum</span> <span>InstructionCompleted</span><span>&lt;</span><span>'a</span><span>&gt;</span> {
    <span>/// Indicates that the instruction executed was one of the return family. The caller
</span><span></span>    <span>/// should stop the method execution and return the value.
</span><span></span>    ReturnFromMethod(Option<span>&lt;</span>Value<span>&lt;</span><span>'a</span><span>&gt;&gt;</span>),

    <span>/// Indicates that the instruction was not a return, and thus the execution should
</span><span></span>    <span>/// resume from the instruction at the program counter.
</span><span></span>    ContinueMethodExecution,
}

<span>/// Models the fact that a method execution has failed
</span><span></span><span>pub</span> <span>enum</span> <span>MethodCallFailed</span><span>&lt;</span><span>'a</span><span>&gt;</span> {
    InternalError(VmError),
    ExceptionThrown(JavaException<span>&lt;</span><span>'a</span><span>&gt;</span>),
}
</code></pre></div><p>and the standard Rust <code>Result</code> type is:</p>
<div><pre><code data-lang="rust"><span>enum</span> Result<span>&lt;</span>T, E<span>&gt;</span> {
   Ok(T),
   Err(E),
}
</code></pre></div><p>Thus, executing an instruction can result in four possible states:</p>
<ul>
<li>the instruction was executed successfully, and the execution of the current method can continue (the standard case);</li>
<li>the instruction was executed successfully, and it was a return instruction, thus the current method should return with (optionally) a return value;</li>
<li>the instruction could not be executed, because some internal VM error happened;</li>
<li>or the instruction could not be executed, because a standard Java exception was thrown.</li>
</ul>
<p>The code that <a href="https://github.com/andreabergia/rjvm/blob/main/vm/src/call_frame.rs#L298">executes a method</a> is thus as follows:</p>
<div><pre><code data-lang="rust"><span>/// Executes the whole method
</span><span></span><span>impl</span><span>&lt;</span><span>'a</span><span>&gt;</span> CallFrame<span>&lt;</span><span>'a</span><span>&gt;</span> {
    <span>pub</span> <span>fn</span> <span>execute</span>(
        <span>&amp;</span><span>mut</span> self,
        vm: <span>&amp;</span><span>mut</span> Vm<span>&lt;</span><span>'a</span><span>&gt;</span>,
        call_stack: <span>&amp;</span><span>mut</span> CallStack<span>&lt;</span><span>'a</span><span>&gt;</span>,
    ) -&gt; <span>MethodCallResult</span><span>&lt;</span><span>'a</span><span>&gt;</span> {
        self.debug_start_execution();

        <span>loop</span> {
            <span>let</span> executed_instruction_pc <span>=</span> self.pc;
            <span>let</span> (instruction, new_address) <span>=</span>
                Instruction::parse(
                    self.code, 
                    executed_instruction_pc.<span>0.</span>into_usize_safe()
                ).map_err(<span>|</span>_<span>|</span> MethodCallFailed::InternalError(
                    VmError::ValidationException)
                )<span>?</span>;
            self.debug_print_status(<span>&amp;</span>instruction);

            <span>// Move pc to the next instruction, _before_ executing it, 
</span><span></span>            <span>// since we want a "goto" to override this
</span><span></span>            self.pc <span>=</span> ProgramCounter(new_address <span>as</span> <span>u16</span>);

            <span>let</span> instruction_result <span>=</span> 
                self.execute_instruction(vm, call_stack, instruction);
            <span>match</span> instruction_result {
                Ok(ReturnFromMethod(return_value)) <span>=&gt;</span> <span>return</span> Ok(return_value),
                Ok(ContinueMethodExecution) <span>=&gt;</span> { <span>/* continue the loop */</span> }

                Err(MethodCallFailed::InternalError(err)) <span>=&gt;</span> {
                    <span>return</span> Err(MethodCallFailed::InternalError(err))
                }

                Err(MethodCallFailed::ExceptionThrown(exception)) <span>=&gt;</span> {
                    <span>let</span> exception_handler <span>=</span> self.find_exception_handler(
                        vm,
                        call_stack,
                        executed_instruction_pc,
                        <span>&amp;</span>exception,
                    );
                    <span>match</span> exception_handler {
                        Err(err) <span>=&gt;</span> <span>return</span> Err(err),
                        Ok(None) <span>=&gt;</span> {
                            <span>// Bubble exception up to the caller
</span><span></span>                            <span>return</span> Err(MethodCallFailed::ExceptionThrown(exception));
                        }
                        Ok(Some(catch_handler_pc)) <span>=&gt;</span> {
                            <span>// Re-push exception on the stack and continue
</span><span></span>                            <span>// execution of this method from the catch handler
</span><span></span>                            self.stack.push(Value::Object(exception.<span>0</span>))<span>?</span>;
                            self.pc <span>=</span> catch_handler_pc;
                        }
                    }
                }
            }
        }
    }
}
</code></pre></div><p>I know that there are quite a few implementation details in this code, but I hope it gives an idea of how using Rust’s <code>Result</code> and pattern matching maps really well to the description of the behavior above. I have to say I am rather proud of this code. 😊</p>
<h2 id="garbage-collection">
  Garbage collection
  <a href="#garbage-collection">
    
  </a>
</h2>
<p>The final milestone in <code>rjvm</code> has been the implementation of the garbage collector. The algorithm I have chosen is a stop-the-world (which trivially follows from not having threads!) semispace copying collector. I have <a href="https://github.com/andreabergia/rjvm/blob/main/vm/src/gc.rs">implemented</a> a (poorer) variant of <a href="https://en.wikipedia.org/wiki/Cheney%27s_algorithm">Cheney’s algorithm</a> - but I really should go and implement the real thing… 😅</p>
<p>The idea is to split the available memory into two parts, called semispaces: one will be active and used to allocate objects, and the other will be unused. When full, a garbage collection will be triggered and all alive objects will be copied to the other semispace. Then, all references to objects will be updated, so that they point to the new copies. Finally, the role of the two will be swapped - similar to how <a href="https://www.redhat.com/en/topics/devops/what-is-blue-green-deployment">blue-green</a> deployment works.</p>
<p><img src="https://andreabergia.com/images/2023/07/gc1.png" alt="">
<img src="https://andreabergia.com/images/2023/07/gc2.png" alt="">
<img src="https://andreabergia.com/images/2023/07/gc3.png" alt="">
<img src="https://andreabergia.com/images/2023/07/gc4.png" alt=""></p>
<p>This algorithm has the following characteristics:</p>
<ul>
<li>obviously, it wastes a lot of memory (half of the possible max memory!);</li>
<li>allocations are super fast (bumping a pointer);</li>
<li>copying and compacting objects means that it does not have to deal with memory fragmentation;</li>
<li>compacting objects can improve performances, due to better cache line utilization.</li>
</ul>
<p>Real Java VMs use far more sophisticated algorithms, generally <a href="https://www.digitalocean.com/community/tutorials/java-jvm-memory-model-memory-management-in-java">generational garbage collectors</a>, such as G1 or the parallel GC, which use evolutions of the copying strategy.</p>
<h2 id="conclusions">
  Conclusions
  <a href="#conclusions">
    
  </a>
</h2>
<p>In writing <code>rjvm</code>, I learned <strong>a lot</strong> and I had a lot of fun. Can’t ask for more from a side project… but maybe next time I will pick something <em>a bit</em> less ambitious to learn a new programming language! 🤭</p>
<p>As an aside, I want to say that I had a lot of fun with Rust. I think it is a great language, <a href="https://andreabergia.com/blog/2022/11/languages-opinion-part-two-rust/">as I have written before</a>, and I have really enjoyed using it for implementing my JVM!</p>
<p>If you are interested in further details on how <code>rjvm</code> is implemented (and on how the JVM actually works), stay tuned for the upcoming posts!</p>

  </article>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What are some low cost payment processing alternatives to Stripe? (142 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=36811026</link>
            <guid>36811026</guid>
            <pubDate>Fri, 21 Jul 2023 07:30:16 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=36811026">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="36811249"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36811249" href="https://news.ycombinator.com/vote?id=36811249&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>The most low-cost I know of with widest reach (most countries) is <a href="https://www.adyen.com/pricing" rel="nofollow noreferrer">https://www.adyen.com/pricing</a><p>Because you can choose which processor you want to use and there are many low-cost ones, including some inter-bank ones with fixed cost (no %)</p><p>Most shops like WooCommerce and Shopify have ready-to-use plugins for it.</p><p>(I'm not affiliated, but i build e-commerce for brands)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36811342"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36811342" href="https://news.ycombinator.com/vote?id=36811342&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>On a related note, you can look at hyperswitch [1], which is an open-source payment orchestrator that supports multiple payment processors. You can self-host it or they have a hosted version as well.<p>1. <a href="https://github.com/juspay/hyperswitch">https://github.com/juspay/hyperswitch</a></p><p>(not affiliated with this project in any way)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36811454"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36811454" href="https://news.ycombinator.com/vote?id=36811454&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>Do you use this?<p>I can't seem to figure what their pricing strategy is or who's running it.</p><p>&gt; Free-tier
&gt; Free-tier for startups. Lowest Price for others.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36811725"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36811725" href="https://news.ycombinator.com/vote?id=36811725&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Hyperswitch is free to use for the first 10k transactions of the month. After that it costs $0.04 per transaction. It is a payment switch that comes pre integrated with major processors. So as a merchant your business relationship with processors like Stripe or Adyen remains the same
(I'm affiliated with this product)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36811552"><td></td></tr>
                <tr id="36812280"><td></td></tr>
                              <tr id="36811432"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36811432" href="https://news.ycombinator.com/vote?id=36811432&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Adyen is a good option, however they have a monthly fixed fee ($120) and looks like they might not onboard small merchants with less than $50M ARR</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36812711"><td></td></tr>
            <tr id="36812064"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36812064" href="https://news.ycombinator.com/vote?id=36812064&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>Are you sure about the fixed fee? Their website says it isn't.<p>&gt; We do not have monthly fees, set-up fees, integration fees or closure fees. We do have a minimum invoice depending on industry or business model. Please speak to a member of our sales team for more details.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36812390"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36812390" href="https://news.ycombinator.com/vote?id=36812390&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>The minimum invoice is $120. Though it seems they can waive that if they like you during sales. It's all a little vague which I honestly despise.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="36811281"><td></td></tr>
                <tr id="36811295"><td></td></tr>
                        <tr id="36812363"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36812363" href="https://news.ycombinator.com/vote?id=36812363&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>While we're talking about Stripe alternatives, anyone have a good Stripe Tax alternative?<p>Their pricing is actually insane as they charge per API call rather than transaction amount. That sort of pricing made sense for TaxJar because it was their whole deal, but post-acquisition it would've made more sense to treat the tax product as a complement to the core business and just tack on a small 50c fee for successful tax collection.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36812578"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36812578" href="https://news.ycombinator.com/vote?id=36812578&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Hey mbStavola, Khem from the Paddle team here. We see quite a few sites switch over from Stripe Tax - offloading tax (including the filing) is our core competency (rather than bundling loads of tools together) and we'd charge per transaction for everything to save you paying unnecessary fees. Happy to chat if you'd like to learn more :)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36812748"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36812748" href="https://news.ycombinator.com/vote?id=36812748&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>I'd absolutely love to switch to Paddle, the product seems great. Unfortunately, my business is a marketplace which I don't believe Paddle supports. Happy to be wrong on that though!<p>Are there any plans to have a marketplace offering?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36812757"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36812757" href="https://news.ycombinator.com/vote?id=36812757&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>Post your fee schedule and any relevant details <i>here</i> if you don't want your post flagged as spam.<p>"Call me for details" is the worst possible way to engage on HN even if you tack on a smiley.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="36812501"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36812501" href="https://news.ycombinator.com/vote?id=36812501&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>Have you considered going to one of the archaic platforms and getting a proper merchant account? Moneris, banks (Chase, Wells Fargo), etc? Pretty much all of them will probably offer better support (a customer support line) and cheaper transaction fee.<p>You lose the developer friendliness, so you'll have to debate if that matters to you. To me it never did.</p><p>Or you could take a look at stax <a href="https://staxpayments.com/" rel="nofollow noreferrer">https://staxpayments.com/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36811298"><td></td></tr>
                <tr id="36811333"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36811333" href="https://news.ycombinator.com/vote?id=36811333&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>This is the first I've heard of it. Thank you for bringing it to my attention.<p>Great for those starting in Europe, it seems. And PayPal!!!!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36811404"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36811404" href="https://news.ycombinator.com/vote?id=36811404&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>I've had a bad experience with them (though that was a few years ago). Back then they manually reviewed each website before enabling payment processing (which is fine), but then just didn't get back to us. We tried messaging them for a status update, but only got a generic answer that it'd take another couple days. After three or four weeks and another back and forth we just gave up.<p>As I said, this was a couple years ago, so things might be very different now (we might've been an outlier even back then), but it left a bad taste, because the customer service was so unhelpful, even though they were much smaller than stripe.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36811601"><td></td></tr>
                  <tr id="36811366"><td></td></tr>
                <tr id="36811541"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36811541" href="https://news.ycombinator.com/vote?id=36811541&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>Braintree is a good chunk more expensive than Stripe for OP's needs if they're in the US.<p>Based on the info they shared:</p><p>• Braintree: 2.59% + $0.49</p><p>&gt; Braintree fees: $17,570 cost for 20K txns/month ($15 AOV)</p><p>• Stripe: 2.9% + $0.30</p><p>&gt; Stripe fees: $14,700 cost for 20K txns/month ($15 AOV)</p><p>So Stripe is around 16% cheaper for their use case on standard pricing alone.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36812455"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36812455" href="https://news.ycombinator.com/vote?id=36812455&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Though I suppose that 16% does depend on what the average transaction fee is. If you are higher then $15 it does scale towards Braintree being cheaper.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36812483"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36812483" href="https://news.ycombinator.com/vote?id=36812483&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>For sure, although I based it on OP's stated transaction value + volume ("20k transactions a month with an average ticket size of $15 per transaction").<p>If you're doing ~$300K/month, it’s likely you would've already spoken to our sales team and we would work out custom pricing for your business.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="36811379"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36811379" href="https://news.ycombinator.com/vote?id=36811379&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>I've been using braintree for 9 years on one of my projects, and while it does "work", there doesn't seem to be much innovation happening, sadly.<p>I use them for their direct integration with paypal, who owns them
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36812238"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36812238" href="https://news.ycombinator.com/vote?id=36812238&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>What features are missing?<p>In contrast, I almost feel like Stripe is innovating too much. I wish they stopped product development, no more redesigns, no more API breaking changes, it already "just works" so why rewrite and "improve" everything endlessly.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="36812415"><td></td></tr>
                <tr id="36812447"><td></td></tr>
            <tr id="36812544"><td></td></tr>
                  <tr id="36812603"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36812603" href="https://news.ycombinator.com/vote?id=36812603&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Hey NavyG - Khem from the Paddle team here. We offer a merchant of record model which takes all of the manual work/integrations away and can migrate customers seamlessly over so you can focus on the product. Happy to chat if you'd like to learn more.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36811809"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36811809" href="https://news.ycombinator.com/vote?id=36811809&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>Not at your volume. It would probably cost you more to switch than you'd save, considering the time and training investment involved.<p>Assuming $250k per year at $15/transaction gives ~16,666 transactions a year. With base Stripe pricing, that means you're paying $5k for the $0.30 per transaction fee and another $7.2k for the 2.9% interchange plus fee. So $12.2k in fees per $250k processed, or 4.9% of processed dollars. Adyen is probably going to be about the same given your volume.</p><p>It's important to know that Stripe charges the same fee even though the fee for processing American Express is different from Visa, which is different from Discover and all are more expensive than debit cards. If your business skews highly towards American Express, than Stripe is actually giving you the best rate you could hope for. If you're volume skews debit cards, than Stripe is giving you the worst rate.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36811840"><td></td></tr>
                <tr id="36812313"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36812313" href="https://news.ycombinator.com/vote?id=36812313&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>Other answers are good but keep in mind that other brands can be pretty expensive.  If you are B2B but most of your business is using a credit card, Visa and Mastercard business card and government purchase card transactions are more costly than American Express.<p>I don't think Stripe loses any money on a transaction.  All interchange rates are less than 2.99%, but some are very close.  For very low volume/low ticket price, stripe is a pretty good deal.  But if high volume, there's bound to be a better option that pays off considerably the sooner you implement it.</p><p>Now, if you can get most of your customers using debit cards or ACH-type transactions, you can really achieve a low cost if you use a processor with interchange-based pricing.</p><p>Why support American Express?  Their members tend to be better customers in my experience, and they appreciate that you support their preference.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36811913"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36811913" href="https://news.ycombinator.com/vote?id=36811913&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>It's how they pay for their best-in-class rewards and offerings. This means card holders are more likely to make big purchases on an Amex than other cards, and why many small ma n' pa shops don't accept them.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36811908"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36811908" href="https://news.ycombinator.com/vote?id=36811908&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>In my country, they offer some of the best rewards rates and customer care services. Their no-frills chargeback protections and airport lounge network are somewhat better than what I have with my Visa card. However, Amex lacks offline acceptance and can be quite challenging to meet the "milestones" for annual fee waiver.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36811917"><td></td></tr>
                        <tr id="36811939"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36811939" href="https://news.ycombinator.com/vote?id=36811939&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>Only tangentially related, but does someone know good competitors to Stripe in Japan? I need support for subscriptions in USD and EUR.<p>Last time I checked, there were a few choices (besides Stripe and PayPal), but many supported either only JPY, or only one time payments...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36812018"><td></td></tr>
                  <tr id="36812097"><td></td></tr>
            <tr id="36811272"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36811272" href="https://news.ycombinator.com/vote?id=36811272&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Every country has couple, if not dozens, of payment processors. Most of them will support foreign customers as well. So you have hundreds and thousands of options here. Bottom line will be that they are all essentially the same when it comes to functionality and pricing because they are the middlemen between you and visa/mastercard/... and not much else. So there is very little variety possible in this little space. It will mostly come down to how "pretty" their gateway is(unless you are doing direct integration without redirection), how responsive their support team is and how they bill you and provide transaction information. Again, not much variety. So pick the cheapest one and be done with it.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36812722"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36812722" href="https://news.ycombinator.com/vote?id=36812722&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Exactly my concern, I'm basically looking to get a service provider that is as close to card networks or banks as possible. Not looking at which one is "pretty" at all. Willing to work with that provider to integrate them with my website</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36811300"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36811300" href="https://news.ycombinator.com/vote?id=36811300&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Outside of the US this is not true at all. There are plenty of ways to transfer money without touching the CC networks but instead use interbank communications.
iDeal, Klarna, SEPA: all fixed pricing instead of percentage based fees.
It depends on where you want to provide your services.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36811375"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36811375" href="https://news.ycombinator.com/vote?id=36811375&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>&gt; Outside of the US this is not true at all<p>I think you meant "not entirely true". Yes, there are other options.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36811461"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36811461" href="https://news.ycombinator.com/vote?id=36811461&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>In Poland barely anyone uses cards for online payments. There are couple of different options: one-time automatic transfers that support major banks, BLIK (payment via one-time code), etc.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36811919"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_36811919" href="https://news.ycombinator.com/vote?id=36811919&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>Exactly, and it works well. Unfortunately as a customer you don't have the level of protection with these services a CC or a specialised top up "virtual" debit card has. Charge backs etc. It's one of the reasons why these alternative payment methods are a lot less risky to process and therefore cheaper for the merchants.<p>So it makes me wonder why global companies like Google are so "credit card" centric. For example. You can attach a debit card as a payment mechanism for Google cloud services, but it can't be a top up one... Why? It is very annoying I have to open an extra account with overdraft block just to maintain some control on the spending if they suddenly decide to charge a wrong amount.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36812307"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_36812307" href="https://news.ycombinator.com/vote?id=36812307&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>&gt; Unfortunately as a customer you don't have the level of protection with these services a CC or a specialised top up "virtual" debit card has.<p>Generally, you'd have to have your bank account hacked to have a reason to reverse a charge on these types of systems. It happens, but very, very rarely and the banks have a lot of reasons to make sure it doesn't happen. That or you gave money to a scammer and that's your own fault (but they'll still help you).</p><p>This is why the fees are much, much lower. Often these systems even verify that you actually have the money and can transfer the amount to your business bank account on the same day. You can't do that with credit cards.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36812401"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_36812401" href="https://news.ycombinator.com/vote?id=36812401&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>&gt; That or you gave money to a scammer and that's your own fault (but they'll still help you).<p>Is it really that merchant-friendly / anti-consumer? I have used chargebacks when merchants fail to deliver as promised, even when most people wouldn’t call them “some scammer”.</p><p>For instance recently a package was shipped that didn’t include one of many items. I asked for a refund, they claimed it was in the package. No worries, I’ll just do a chargeback.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                                                <tr id="36811739"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36811739" href="https://news.ycombinator.com/vote?id=36811739&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>Hello, 
(I’m co-founder of MonoPayments, white label payment platform for fintechs.)<p>If you want to pay less, you have to use local processors with local currencies. This would be a complex operation.</p><p>1. Establish a company at that jurisdiction
2. Make agreements with processors, it could be banks or wallet providers. 
3. You need a treasurer (or CFO)
4. Foreign Exchange rates will be a concern after a while.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36812659"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36812659" href="https://news.ycombinator.com/vote?id=36812659&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>I currently operate only in US and I am willing to put in the effort for integration, PCI compliance etc. Do you have any recommendations for the local processors you mentioned?</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36811841"><td></td></tr>
                <tr id="36812584"><td></td></tr>
                <tr id="36812600"><td></td></tr>
                <tr id="36812627"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_36812627" href="https://news.ycombinator.com/vote?id=36812627&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>Khem from Paddle here - we'll be able to fight chargebacks on your behalf too as part of that :)<p>The price above includes the entire payments stack (filing and remitting of taxes too), so you're compliant globally out of the box.</p><p>We often help teams avoid having to hire lots of external accounting resource.</p><p>Happy to chat if you'd like to learn more :)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36812754"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_36812754" href="https://news.ycombinator.com/vote?id=36812754&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Curious: you must have done a lot of groundwork to provide the whole stack as a solution, would love to hear from you how you internally select the processors you work with. Or are you directly integrated with banks and card networks?</span></p></div></td></tr>
        </tbody></table></td></tr>
                                    <tr id="36812680"><td></td></tr>
            <tr id="36811399"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36811399" href="https://news.ycombinator.com/vote?id=36811399&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Has anyone used Helcim or Stax? These processors pricing seems to be around $0.15 per transaction. If this is true why don't so many people use it?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36812474"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36812474" href="https://news.ycombinator.com/vote?id=36812474&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>I’ve used stax in the past. It is cheaper than stripe, but you’re also paying a monthly fee. In our case, it was $120 a month for a physical terminal in the office. I don’t know what the differences are for API transactions. It wasn’t something we were doing.<p>We are now with mxmerchant and they are okay? I’ve never seen a credit card merchant go down and not take transactions, but in the 1.5 years we’ve used them, they’ve gone down twice.</p><p>But we need to use them because they are the only processor the software uses and we need to now take cards through their system
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36812771"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36812771" href="https://news.ycombinator.com/vote?id=36812771&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Interesting, have you also tried online payments (card not present) with them? If so how is the reliability in that case?</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="36812163"><td></td></tr>
                <tr id="36812678"><td></td></tr>
                  <tr id="36812264"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36812264" href="https://news.ycombinator.com/vote?id=36812264&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Full disclosure, I work for Stripe. The question you want to ask is why are these alternatives cheaper than Stripe? What is the tradeoff.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36812794"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36812794" href="https://news.ycombinator.com/vote?id=36812794&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Yes, want to understand the trade off and would like to know what the challenge is in integrating directly with a payment provider that is closer to the networks / banks. I love Stripe for how easy it is to get started with but I am looking for opportunities to save cost further but getting closer to the acquirer</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36812336"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36812336" href="https://news.ycombinator.com/vote?id=36812336&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>One obvious answer is that Stripe has name recognition and fame, which means they can afford to charge more and get away with it. And smaller companies have an incentive to prioritize growth and user acquisition over immediate profit.<p>But what other tradeoffs are you implying there to be? I understand in a vague sense that payment processors deal with a lot of ugly behind-the-scenes stuff like mind-boggling varieties of frauds, dispute resolutions, regulations, etc., but what exactly is the difference in this specific case, and how might it affect a potential user in practice?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36812369"><td></td></tr>
            <tr id="36811875"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36811875" href="https://news.ycombinator.com/vote?id=36811875&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Depends on where you tap into the digital payments chain. At the highest level (with highest fees) are the payfacs (Payment facilitators). Above them are the payment acquirers with comparatively low fees, higher joining fees, more rigorous certification process and the PCI compliance is a chore you need to repeat every year. Above that is not that easy to tap into such as direct link to credit card networks and banks. At your volume, PayFac like Stripe is the best option IMO.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36812229"><td></td></tr>
                <tr id="36812682"><td></td></tr>
                  <tr id="36812058"><td></td></tr>
                <tr id="36812062"><td></td></tr>
            <tr id="36812085"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36812085" href="https://news.ycombinator.com/vote?id=36812085&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>This is definitely the more robust, durable and cheaper alternative. But clearly is a utopia for today.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36812083"><td></td></tr>
                  <tr id="36811751"><td></td></tr>
                <tr id="36812255"><td></td></tr>
                  <tr id="36812084"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36812084" href="https://news.ycombinator.com/vote?id=36812084&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><p><span>For over a decade I've been having free bank accounts with free Visa and MasterCard debit and credit cards, and I've been using them with services that allow me to create as many free virtual credit cards I wish.<p>I thought these services were already widespread.</p><p>Are people still paying for debit and credit cards?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36812262"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36812262" href="https://news.ycombinator.com/vote?id=36812262&amp;how=up&amp;goto=item%3Fid%3D36811026"></a></center>    </td><td><br><div>
                  <p><span>Hey I was referring to accepting payments online on my website. So this is the payment processing fees I was referring to</span></p></div></td></tr>
        </tbody></table></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Quench of LHC inner triplet magnet causes a small leak with major consequences (211 pts)]]></title>
            <link>https://home.cern/news/news/accelerators/accelerator-report-quench-lhc-inner-triplet-magnet-causes-small-leak-major</link>
            <guid>36811018</guid>
            <pubDate>Fri, 21 Jul 2023 07:29:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://home.cern/news/news/accelerators/accelerator-report-quench-lhc-inner-triplet-magnet-causes-small-leak-major">https://home.cern/news/news/accelerators/accelerator-report-quench-lhc-inner-triplet-magnet-causes-small-leak-major</a>, See on <a href="https://news.ycombinator.com/item?id=36811018">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>At 1.00 a.m. + 17 seconds on Monday, 17 July, the LHC beams were dumped after only 9 minutes in collision due to a radiofrequency interlock caused by an electrical perturbation. Approximately 300 milliseconds after the beams were cleanly dumped, several superconducting magnets around the LHC quenched – i.e. they lost their superconducting state. Among these magnets were the inner triplet magnets located to the left of Point 8 (LHCb), which play a crucial role in focusing the beams for the LHCb experiment.</p>

<p>While this sequence of events may not happen very often during beam operation, it is not exceptional for the LHC, as occasional quenches of some superconducting magnets are to be expected.</p>

<p>In this particular case, the electrical perturbation caused the quench protection system (QPS) to trigger the quench heaters of the magnets concerned. These quench heaters consist of an electrical resistor embedded in the magnet coils; they are designed to heat up quickly when a localised quench occurs somewhere in the magnet, in order to effectively bring the whole magnet out of the superconducting state in a controlled and homogenous manner. During such a quench, the liquid helium in the magnet warms up and turns into a gas that is recovered by the cryogenic system to be re-liquified, ready to cool down the magnets again.</p>

<figure id="CERN-HOMEWEB-PHO-2023-098-1"><a href="https://cds.cern.ch/images/CERN-HOMEWEB-PHO-2023-098-1" title="View on CDS"><img alt="home.cern,Accelerators" src="https://cds.cern.ch/images/CERN-HOMEWEB-PHO-2023-098-1/file?size=large"></a>
<figcaption>The cryostat containing the inner triplet magnets. The tiny amount of very cold helium that replaced the insulation vacuum cooled down the cryostat, causing condensation of the tunnel air on the cryostat, which then froze. Several hours later, the thin layer of ice had melted again as the cryostat returned to room temperature. (Image: CERN)</figcaption></figure><p>Despite this being a normal and expected behaviour, the mechanical stresses involved in this process are significant and, in very rare cases, can lead to damage. Unfortunately, in the case of the inner triplet magnet located to the left of Point 8, a small leak has appeared between the cryogenic circuit, which contains the liquid helium, and the insulation vacuum that separates the cold magnet from the warm outer vessel, known as the cryostat. This vacuum barrier is crucial for preventing heat transfer from the surrounding LHC tunnel to the interior of the cryostat (this is similar to the functioning of a thermos flask). As a result of the leak, this insulation was lost: the insulation vacuum filled with helium gas, cooling down the cryostat and causing condensation to form and freeze on the outside.</p>

<p>As I write, investigations are ongoing to identify the source of the leak, to allow a repair strategy to be elaborated. Nevertheless, it is clear that an intervention with the inner triplet magnet at room temperature will be required. This incident will probably have a great impact on the LHC schedule, with machine operation unlikely to resume for at least several weeks.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nanosecond timestamp collisions are common (258 pts)]]></title>
            <link>https://www.evanjones.ca/nanosecond-collisions.html</link>
            <guid>36810818</guid>
            <pubDate>Fri, 21 Jul 2023 07:01:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.evanjones.ca/nanosecond-collisions.html">https://www.evanjones.ca/nanosecond-collisions.html</a>, See on <a href="https://news.ycombinator.com/item?id=36810818">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<h3>[ 2023-July-20 17:39 ]</h3>
<p>I was wondering: how often do nanosecond timestamps collide on modern systems? The answer is: very often, like 5% of all samples, when reading the clock on all 4 physical cores at the same time. As a result, I think it is unsafe to assume that a raw nanosecond timestamp is a unique identifier.</p>

<p>I wrote a <a href="https://github.com/evanj/nanocollision">small test program</a> to test this. I used Go, which records both the "absolute" time and the "monotonic clock" relative time on each call to time.Now(), so I compared both the relative difference between consecutive timestamps, as well as just the absolute timestamps. As expected, the behavior depends on the system, so I observe very different results on Mac OS X and Linux. On Linux, within a single thread, both the absolute and monotonic times always increase. On my system, the minimum increment was 32 ns. Between threads, approximately 5% of the absolute times were exactly the same as other threads. Even with 2 threads on a 4 core system, approximately 2% of timestamps collided. On Mac OS X: the absolute time has microsecond resolution, so there are an astronomical number of collisions when I repeat this same test. Even within a thread I often observe the monotonic clock not increment.</p>

<p>See the <a href="https://github.com/evanj/nanocollision">test program on Github</a> if you are curious.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon shuts down customer’s smart home (197 pts)]]></title>
            <link>https://forums.macrumors.com/threads/amazon-shuts-down-customers-smart-home.2392704/</link>
            <guid>36810075</guid>
            <pubDate>Fri, 21 Jul 2023 04:42:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forums.macrumors.com/threads/amazon-shuts-down-customers-smart-home.2392704/">https://forums.macrumors.com/threads/amazon-shuts-down-customers-smart-home.2392704/</a>, See on <a href="https://news.ycombinator.com/item?id=36810075">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
			Hello, everybody. How's it going? I hope you're loving a lovely day. Today, I would like to go over reason number 80 million that you should not be having stuff in your house.</p><p>

Connect to Amazon servers for things like critical infrastructure, whether it is your camera systems, your doorbell, or any part of your home. This comes from Mr. Brandon Jackson.</p><p>

It says, On Wednesday, May 31, 2023, I finally regained access to my Amazon account after an unexpected and unwarranted lockout that lasted about a week from Thursday, May 25. This wasn't just a simple inconvenience. I have a smart home.</p><p>

Smart home, and my primary method of interfacing with all the devices and automations is through Amazon Echo devices via Alexa. The incident left me with a house full of unresponsive devices, a silent Alexa, and a lot of questions. The sequence of events that led to this digital exile began.</p><p>

Innocuously enough, a package was delivered to my house on Wednesday, May 24, and everything seemed fine. The following day, however, I found that my Echo show had signed out, and I was unable to interact with my smart home devices. My initial assumption was that somebody might have attempted to access my account repeatedly, triggering a lockout.</p><p>

I use a fairly old email address from my Amazon account, and it's plausible that an old password might have been exposed in a past data breach. However, I currently use strong autogenerated passwords via Apple and employ two factor authentication with an authenticator app, so unauthorized access seemed unlikely. I swiftly checked my other accounts social media, streaming, et cetera, to ensure that I hadn’t been compromised.</p><p>

All seemed normal, with no flood of notifications from Microsoft Authenticator that would indicate an attempted breach. Puzzled, I found the advice of the Amazon app and dialed the customer service number it provided. That's when things began to take a surreal turn.</p><p>

The representative told me that I should have received an email, which I indeed found in my inbox. It was from an executive at Amazon. As I dialed the number provided in the email, I half wondered if Amazon was experiencing some issues and I was unwittingly falling for a scam.</p><p>

You don't expect trillion dollar companies to email you and then have them say, call me back, bro, so I completely understand where he's coming from. When I connected with the executive, they asked if I knew why my account had been locked. When I answered, I was unsure.</p><p>

Their tone turned somewhat accusatory. I was told that the driver who had delivered my package reported receiving racist remarks from my ring doorbell. It's actually a UFI, but I'll let that slide.</p><p>

Here's where things got even more baffling. First, I have multiple cameras recording everything that happens on my property. By the way, I hope those cameras are going to a local NVR.</p><p>

If the driver's claims were accurate, I could easily verify them with video footage. Second, most delivery drivers in my area share the same race as me and my family. It seems highly unlikely that we would make such remarks.</p><p>

Finally, when I asked what time the alleged incident occurred, I realized it was practically impossible for anyone in my house to have made those comments, as nobody was home around that time, approximately six five P-M-I reviewed the footage and confirmed that no such comments had been made. Instead, the UFI doorbell had issued an automated response. Excuse me, can I help you? The driver who was walking away and wearing headphones must have misinterpreted the message.</p><p>

Nevertheless, by the following day, my Amazon account was locked and all my Echo devices were logged out. Let me be clear. I fully support Amazon taking measures to ensure the safety of their drivers.</p><p>

However, I question why my entire smart home had to be rendered unusable during their internal investigation. It seems more sensible to impose a temporary delivery restriction or purchasing ban on my account. Submitting video evidence from multiple angles right after my initial call with the executive appeared to have little impact on their decision to disable my account.</p><p>

This incident has led me to question my relationship with Amazon. After nearly a decade of loyalty, I’ve been given a harsh reminder that a misunderstanding can lead to such drastic measures. It seems more reasonable to handle such issues in a more compartmentalized way, rather than a blanket shutdown of all services.</p><p>

Due to this experience, I'm seriously considering discontinuing my use of Amazon Echo devices and will caution others about this incident. BlackBerry, you are on the wrong side of the chair, and if you step on my keyboard and hit the spacebar, you are going to get it, girl. You're going to get it.</p><p>

Left side of the chair, Barry. Good, Barry. Due to this experience, I am seriously considering discontinuing my use of Amazon Echo devices and will caution others about this incident.</p><p>

This ordeal has made the case for a more personalized home assistance system, perhaps using Raspberry Pi devices scattered around the house. Despite promptly submitting video evidence immediately upon learning of my issue, my account remained locked. The timing couldn't have been worse.</p><p>

The onset of Labor Day weekend was approaching, and I was keen to resolve the issue before the long weekend. However, despite numerous calls and emails, it wasn't until Friday afternoon that I had received confirmation that the investigation had started. I was told to expect the response within two business days, meaning not until Tuesday of the following week at the earliest.</p><p>

In the end, my account was unlocked on Wednesday with no follow up email to inform me of the resolution. This is one of those things where instead of this drives me nuts. So instead of apologizing for the fact that they ****ed with somebody who purchased items in their home that apparently they don’t have permission to use, if a delivery driver mishears a ****ing automated doorbell, that they can't even just say, hey, man, we're sorry we ****ed up.</p><p>

We realized there was nobody actually there. Have you ever dealt with one of those situations where there’s somebody in your life that does something massively screwed up and they realize that they did something massively screwed up, and then the moment they realize it and they undo whatever it is that they did, they just walk away? Or they just say well, they just don't say anything. Don't even make eye contact.</p><p>

Rather than be mad enough to go, hey, man, I'm sorry I screwed up. It's just a piece of **** way to behave. Speaking of piece of **** ways to behave, somebody is supposed to stay on the left side of the chair like Barry.</p><p>

This incident stands as a stark reminder of the need for better customer service and a more nuanced approach to incident management. Through sharing my experience, I hope to encourage Amazon to reform and rethink their approach to handling such situations. In the future, it's essential for customers tofeel confident in the security and reliability of their services, especially when those services are integral tothe functionality of their homes.</p><p>

It's time for Amazon to take a more customer focused approach to problem solving and conflict resolution. So let's get this straight. If a delivery driver for the company disapproves of you for any reason, you can have your actual account shut down.</p><p>

The devices that you use in your home may not work. Have you ever had an issue with a postal worker, an Ups delivery person, a FedEx delivery person before in your life? Can you imagine if that issue that you had with that delivery person resulted in items inside of your home that you bought and paid for, no longer functioning and working? This is why I think it is paramount that the infrastructure in your home be as sovereign as possible. Do not have your light switches or your radios or anything else in your home connecting to other people's servers to get permission to turn on.</p><p>

That is a mess waiting to happen, because again, all it takes is an Amazon delivery driver who's having a bad day to literally ruin your home. An unfounded accusation of racism means that infrastructure inside your home can stop working. This is the problem.</p><p>

When you give too much control to one company, and particularly when that control that you're giving is your devices inside of your home connecting to their servers. You could literally be in a situation where somebody making an unfounded, untrue, demonstrably proven untrue accusation of racism against you causes your internal home infrastructure to stop working. That's ****ing insane.</p><p>

I completely understand and respect that. The target demographic of this channel. The people that tend to show up in my comment section and show up to meetups are not the people who need to hear this public service announcement.<br>
You guys are ripping the computers out of as many things as possible that do not read a computer because you don't want to live in a world where the infrastructure in your house stops working because some douchebag at Amazon decided to listen to the unverified claims of someone who misheard a ring doorbell. However, there are many other people out there that actually believe it's a good idea to have the infrastructure in their house connect to somebody else's servers. Sending those other people information, making their house completely dependent on some douchebag that works at Amazon for the ability of their devices at home to work that doesn't even have the courtesy to apologize when proven that they were wrong for turning off what you bought and paid for.</p><p>

Don't have this stuff inside your house. You don't need a smart home. Am I allowed to say that you don’t need a home that connects to other people's servers? You are fine without it.</p><p>

You don't need it. Now, if you want a light to turn on, turn the ****ing switch. What I have over here, if I want to listen to music, got a computer.</p><p>

That computer has a program that runs locally, plays my music when I wand that I ripped off of my albums. That plugs into a nice little rotel RB 1090 amplifier over there. That thing doesn't connect to the internet at all.</p><p>

Jeff Bezos can't turn that thing off if he wants to. Hell, that thing doesn't even have a remote. I had to get a separate thing that you can plug an item into that doesn't have a remote that is literally just a relay so that I can turn it on and off when I want to without having to get up and walk over to it.</p><p>

That plugs into a set of nice Vanderstein model threes. I got all my acoustic panels over here. This thing sounds way better than some ****** ass little cloud bluetooth speaker.</p><p>

Listen to this. Ten times better than the Amazon ********. Really, honestly, truly, in your heart of hearts, how much **** in your house do you need to connect to the ****ing internet? And goddamn, it sounds great.</p><p>

And it don't connect to **** that I don't want it to connect to. And that's how it is. I have a folder of music.</p><p>

I play it. It's beautiful. It's great.</p><p>

I can have a nice romantic evening. I could play shastakovich. I could play opera whatever I want.</p><p>

I got acoustic panels everywhere. There are so many ways to have fun in your home without connecting Amazon. Why do you got to connect Amazon? The turn all your **** on.</p><p>

Turn the **** on yourself. That's it for today. And as always, I hope you learned something.</p><p>

I'll see you in the next video. Bye now.
		</p></div></div>]]></description>
        </item>
    </channel>
</rss>