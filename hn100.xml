(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 12 Jan 2026 17:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[TimeCapsuleLLM: LLM trained only on data from 1800-1875 (126 pts)]]></title>
            <link>https://github.com/haykgrigo3/TimeCapsuleLLM</link>
            <guid>46590280</guid>
            <pubDate>Mon, 12 Jan 2026 16:04:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/haykgrigo3/TimeCapsuleLLM">https://github.com/haykgrigo3/TimeCapsuleLLM</a>, See on <a href="https://news.ycombinator.com/item?id=46590280">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><h2 tabindex="-1" dir="auto">TimeCapsule LLM</h2><a id="user-content-timecapsule-llm" aria-label="Permalink: TimeCapsule LLM" href="#timecapsule-llm"></a></p>
<p dir="auto"><em>A language model trained <strong>from scratch</strong> exclusively on data from certain places and time periods to reduce modern bias and emulate the voice, vocabulary, and worldview of the era.</em></p>
<p dir="auto">Imagine if an AI model didnt just pretend to be historical but actually was.</p>
<p dir="auto">v0 and v0.5 built on <a href="https://github.com/karpathy/nanoGPT">nanoGPT by Andrej Karpathy</a> Core training scripts and model architecture are his work.</p>
<p dir="auto">v1 built on <a href="https://huggingface.co/microsoft/phi-1_5" rel="nofollow">Phi 1.5 by Microsoft</a></p>
<p dir="auto"><a href="https://huggingface.co/haykgrigorian/TimeCapsuleLLM" rel="nofollow">Hugging Face Link</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Model Behavior &amp; Limitations</h2><a id="user-content-model-behavior--limitations" aria-label="Permalink: Model Behavior &amp; Limitations" href="#model-behavior--limitations"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><strong>v0</strong></h3><a id="user-content-v0" aria-label="Permalink: v0" href="#v0"></a></p>
<p dir="auto">Early prompts show the model responding with 1800's language and behavior.
Example: Prompt: "Who art Henry?" and it replied "I know that man, I have did not a black, the storm."</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true"><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/raw/main/london_1800_1850_v0/timelockllm_sample_output.png?raw=true" alt="TimeLockLLM Sample Output"></a></p>
<ul dir="auto">
<li>No mention of modern concepts</li>
<li>Mostly era-accurate vocabulary</li>
<li>Sentences are mostly incoherent (expected for ~187MB training data)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto"><strong>v0.5</strong></h3><a id="user-content-v05" aria-label="Permalink: v0.5" href="#v05"></a></p>
<p dir="auto">A significant improvement over v0.</p>
<ul dir="auto">
<li>Victorian writing style, proper punctuation, mostly grammatical sentences</li>
<li>Still high factual hallucination rate</li>
<li>OCR noise (“Digitized by Google”) still present in outputs</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true"><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/raw/main/london_1800_1875_v0.5/fellowcitizens.png?raw=true" alt="TimeLockLLM Sample Output"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><strong>v1</strong></h3><a id="user-content-v1" aria-label="Permalink: v1" href="#v1"></a></p>
<p dir="auto">First model to recall and connect a real historical event with an actual figure from the dataset.</p>
<p dir="auto">Example: Prompt: "It was the year of our Lord 1834"</p>
<p dir="auto">The output: "It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity"</p>
<p dir="auto">At first I assumed that a protest might have coincidentally taken place the same year but take a look at this: <a target="_blank" rel="noopener noreferrer" href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/1834protest.png"><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/raw/main/1834protest.png" alt="1834protest"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><strong>v2mini-eval1</strong></h3><a id="user-content-v2mini-eval1" aria-label="Permalink: v2mini-eval1" href="#v2mini-eval1"></a></p>
<p dir="auto">Trained using a 15GB sample from v2's 90GB dataset.
Model trained to 10K steps only.</p>
<p dir="auto">There was an issue with tokenization that causes output to look like this:</p>
<p dir="auto">PROMPT:
Who is Charles Dickens?</p>
<p dir="auto">W ho is Charles D ic ens ? D oes that work more of h ise x cell ent st ir ring , in his pl ays , int he G reat C omp any 's f arm ? What I have y et to qu ote from J ack P ick ett ? D oy oun ot know th att hey were as pe cies of g all oping , ors aw ing oft heir bre asts , or what w ast ob ed one about the t im ew hen J acks on was looking ont hew ind ow ? What ist hes uccess of an English man , and which h isson has not be end is cover ing t ome , where by to acc omp lish such a we ight ? D idy ou ever m ake ap ass age int othe old road way , ort o an anch or - b ree ze att he foot of our boat , which you m ust le ave us ? The fact is , that whe ther the wind would rise up from the pl ain on S atur day night orn o ont ide , ort ill then orth , or other wise , wes hall be com pelled t od esc ribe af orm idable bar rier , with t hes ame e ffect s ast he p resent . In th iss itu ation , at le ast , itis not to omuch t os ay that we have le ft that room . I bel ieve there are three c op ies int he " F ive H undred - fold ," to bere fer red to , ast he first n umber of our read ers wh ow is ht</p>
<p dir="auto">Corrected:</p>
<p dir="auto">"Who is Charles Dickens? Does that work more of his excellent stirring, in his plays, in the Great Company's farm? What I have yet to quote from Jack Pickett? Do you not know that they were a species of galloping, or sawing of their breasts, or what was to be done about the time when Jackson was looking on the window? What is the success of an Englishman, and which his son has not been discovering to me, whereby to accomplish such a weight? Did you ever make a passage into the old roadway, or to an anchor-breeze at the foot of our boat, which you must leave us? The fact is, that whether the wind would rise up from the plain on Saturday night or noontide, or till the north, or otherwise, we shall be compelled to describe a formidable barrier, with the same effects as the present. In this situation, at least, it is not too much to say that we have left that room. I believe there are three copies in the 'Five Hundred-fold,' to be referred to, as the first number of our readers who wish t[o]...”</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><strong>v2mini-eval2</strong></h3><a id="user-content-v2mini-eval2" aria-label="Permalink: v2mini-eval2" href="#v2mini-eval2"></a></p>
<p dir="auto">Trained using the same 15GB sample used for training eval1.
Model is again trained to 10K steps only.</p>
<p dir="auto">PROMPT:Charles Darwin</p>
<p dir="auto">Charles DarwinECCEMACY. Sir, — The following case is interesting to me : — I was in London a fortnight, and was much affected with an attack of rheumatism. The first attack of rheumatism was a week before I saw you, and the second when I saw you, and the third when I saw you, and the third in the same time. The second attack of gout, however, was not accompanied by any febrile symptoms, but was accompanied with an increased flow of urine, and with a more copious discharge of urine. The third attack was an hour after I saw you, and was succeeded by a return of a paroxysm of gout, and a more rapid return of the gout. The fourth attack was also accompanied by a fever, but was not always accompanied by any febrile symptoms. The third attack of gout was a fortnight after you had been ill, and the fourth was followed by a paroxysm of gout. The fourth attack was a fortnight after you were attacked, and was accompanied by a sense</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Datasets</h2><a id="user-content-datasets" aria-label="Permalink: Datasets" href="#datasets"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><strong>v2</strong></h3><a id="user-content-v2" aria-label="Permalink: v2" href="#v2"></a></p>
<ul dir="auto">
<li>90GB of 1800-1875 London texts</li>
<li>136,344 documents</li>
<li>The full 90GB is not avalaible yet as it hasn't been tokenized but you can find a 15GB sample here: <a href="https://huggingface.co/datasets/haykgrigorian/TimeCapsuleLLM-London-1800-1875-v2-15GB" rel="nofollow">https://huggingface.co/datasets/haykgrigorian/TimeCapsuleLLM-London-1800-1875-v2-15GB</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bias Stats</h3><a id="user-content-bias-stats" aria-label="Permalink: Bias Stats" href="#bias-stats"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/pronoun_bias.png"><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/raw/main/london_1800_1875_v2mini_eval1/pronoun_bias.png" alt="Pronoun bias"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/geographic_bias.png"><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/raw/main/london_1800_1875_v2mini_eval1/geographic_bias.png" alt="Geographic bias"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/temporal_bias.png"><img src="https://github.com/haykgrigo3/TimeCapsuleLLM/raw/main/london_1800_1875_v2mini_eval1/temporal_bias.png" alt="Temporal bias"></a></p>
<p dir="auto">Refer to <a href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/london_1800_1875_v2mini_eval1/v2_bias_report.json">v2 bias report</a> for more info.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to Use</h2><a id="user-content-how-to-use" aria-label="Permalink: How to Use" href="#how-to-use"></a></p>
<p dir="auto">This project focuses mostly on curating historical data, preparing it for training and building a tokenizer. I am not going to cover the full LLM training process, for that refer to nanoGPT by Andrej Karpathy.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 1: Gather and Prepare Historical Texts</h3><a id="user-content-step-1-gather-and-prepare-historical-texts" aria-label="Permalink: Step 1: Gather and Prepare Historical Texts" href="#step-1-gather-and-prepare-historical-texts"></a></p>
<ul dir="auto">
<li>Collect .txt files of public domain books, documents, etc from your chosen time period (e.g., London 1800-1850)</li>
<li>Keep them within your chosen time/place window</li>
<li>Clean the text files using a script or manually remove headers/footer from Project Gutenberg, Modern annotations or things like OCR errors.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 2: Build a Custom Tokenizer</h3><a id="user-content-step-2-build-a-custom-tokenizer" aria-label="Permalink: Step 2: Build a Custom Tokenizer" href="#step-2-build-a-custom-tokenizer"></a></p>
<ul dir="auto">
<li>Run train_tokenizer.py or train_tokenizer_hf.py on the cleaned data.</li>
<li>This will give you vocab.json and merges.txt</li>
<li>Thes files define vocab and merge rules for your model</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 3: Train Your Model</h3><a id="user-content-step-3-train-your-model" aria-label="Permalink: Step 3: Train Your Model" href="#step-3-train-your-model"></a></p>
<ul dir="auto">
<li>Refer to <a href="https://github.com/karpathy/nanoGPT">nanoGPT by Andrej Karpathy</a> for the training process or your chosen architecture’s docs.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is Selective Temporal Training ?</h2><a id="user-content-what-is-selective-temporal-training-" aria-label="Permalink: What is Selective Temporal Training ?" href="#what-is-selective-temporal-training-"></a></p>
<p dir="auto">Selective Temporal Training (STT) is a machine learning methodology where all training data is specifically curated to fall within a specific historical time period. It's done in order to model the language and knowledge of that era without influence from modern concepts. For example, the current model I have now (v0.5) is trained on data exclusively from 1800-1875, it's not fine tuned but trained from scratch resulting in output that reflects the linguistic style and historical context of that time period.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why not just use fine-tuning or LoRA?</h2><a id="user-content-why-not-just-use-fine-tuning-or-lora" aria-label="Permalink: Why not just use fine-tuning or LoRA?" href="#why-not-just-use-fine-tuning-or-lora"></a></p>
<p dir="auto">For this project I'm trying to create a language model that is unclouded from modern bias. If I fine-tune something like GPT-2, it's already pre-trained and that information won't go away. If I train from scratch the language model won't pretend to be old, it just will be. The Goal for this project right now is to create something can reason exclusively using knowledge from London books published between 1800 and 1875.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What kind of data did you use for training?</h2><a id="user-content-what-kind-of-data-did-you-use-for-training" aria-label="Permalink: What kind of data did you use for training?" href="#what-kind-of-data-did-you-use-for-training"></a></p>
<p dir="auto">I'm using books, legal documents, newspapers, and other writings from 1800–1875 London. The list I linked (for v0) has like 200 but for the first training I just used 50 files about ~187 MB. You can view a list of the documents:
<a href="https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt">https://github.com/haykgrigo3/TimeCapsuleLLM/blob/main/Copy%20of%20London%20Documents%20for%20Time%20Capsule%20LLM.txt</a></p>
<p dir="auto">Dataset sizes:</p>
<ul dir="auto">
<li>v0: ~187MB</li>
<li>v0.5: ~435MB</li>
<li>v1: ~6.25GB</li>
<li>v2mini-eval1: 15GB</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How large are the models ?</h2><a id="user-content-how-large-are-the-models-" aria-label="Permalink: How large are the models ?" href="#how-large-are-the-models-"></a></p>
<p dir="auto">v0: 16M Parameters</p>
<p dir="auto">v0.5 123M Parameters</p>
<p dir="auto">v1: 700M Parameters</p>
<p dir="auto">v2mini-eval1: 300M Parameters</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Training Specs ?</h2><a id="user-content-training-specs-" aria-label="Permalink: Training Specs ?" href="#training-specs-"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">v0/v0.5</h2><a id="user-content-v0v05" aria-label="Permalink: v0/v0.5" href="#v0v05"></a></p>
<p dir="auto">GPU: Geforce rtx 4060
CPU: i5-13400F
Ram: 16GB DDR5.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">v1</h2><a id="user-content-v1-1" aria-label="Permalink: v1" href="#v1-1"></a></p>
<p dir="auto">GPU: A100 SXM rented</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">v2mini-eval1</h2><a id="user-content-v2mini-eval1-1" aria-label="Permalink: v2mini-eval1" href="#v2mini-eval1-1"></a></p>
<p dir="auto">GPU: A100 SXM rented</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple picks Google's Gemini to power Siri (180 pts)]]></title>
            <link>https://www.cnbc.com/2026/01/12/apple-google-ai-siri-gemini.html</link>
            <guid>46589675</guid>
            <pubDate>Mon, 12 Jan 2026 15:22:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2026/01/12/apple-google-ai-siri-gemini.html">https://www.cnbc.com/2026/01/12/apple-google-ai-siri-gemini.html</a>, See on <a href="https://news.ycombinator.com/item?id=46589675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="Placeholder-ArticleBody-Video-108251160" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000400554" aria-labelledby="Placeholder-ArticleBody-Video-108251160"><p><img src="https://image.cnbcfm.com/api/v1/image/108251161-17682301881768230186-43459552421-1080pnbcnews.jpg?v=1768230188&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Cramer’s Stop Trading: Apple"><span></span><span></span></p></div><div><p><span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/AAPL/">Apple</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> is joining forces with <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-2"><a href="https://www.cnbc.com/quotes/GOOGL/">Google</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> to power its <a href="https://www.cnbc.com/ai-effect/">artificial intelligence</a> features, including a major <a href="https://www.cnbc.com/2025/12/30/apple-intelligence-ai-siri-iphone.html">Siri</a> upgrade expected later this year. </p><p>The multi-year partnership will lean on Google's <a href="https://www.cnbc.com/2026/01/08/google-adds-gemini-features-to-gmail-message-summaries-proofreading-.html">Gemini</a> and cloud technology for future Apple foundational models, according to a statement obtained by CNBC's Jim Cramer.</p><p>"After careful evaluation, we determined that Google's technology provides the most capable foundation for Apple Foundation Models and we're excited about the innovative new experiences it will unlock for our users," the tech giants said in a <a href="https://blog.google/company-news/inside-google/company-announcements/joint-statement-google-apple/" target="_blank">joint statement</a> on Monday.</p><p>The models will continue to run on Apple devices and the company's private cloud compute, they added. </p><p>Apple declined to comment on the terms of the deal. Google referred CNBC to the joint statement. </p><p>In August, <a href="https://www.bloomberg.com/news/articles/2025-08-22/apple-explores-using-google-gemini-ai-to-power-revamped-siri?srnd=undefined" target="_blank">Bloomberg</a> had reported that Apple was in <a href="https://www.cnbc.com/2025/08/22/google-shares-rise-on-report-of-apple-using-gemini-for-siri.html">early talks with Google</a> to use a custom Gemini model to power a new iteration of Siri. The news outlet later <a href="https://www.bloomberg.com/news/articles/2025-11-05/apple-plans-to-use-1-2-trillion-parameter-google-gemini-model-to-power-new-siri" target="_blank">reported</a> that Apple was planning to pay about $1 billion a year to utilize Google AI.</p><p>The deal is another major indicator of growing trust in Google's <a href="https://www.cnbc.com/2025/11/27/how-google-put-together-the-pieces-for-its-ai-comeback.html">accelerating AI agenda</a> and comeback against OpenAI. In 2025, the search giant logged its <a href="https://www.cnbc.com/2025/12/31/google-stock-wraps-best-year-since-2009-as-ai-excites-wall-street-.html">best year since 2009</a> and surpassed Apple in market capitalization last week for the <a href="https://www.cnbc.com/2026/01/07/alphabets-market-cap-surpasses-apples-for-first-time-since-2019.html">first time since 2019</a>. </p></div><div id="RegularArticle-RelatedContent-1"><h2>Read more CNBC tech news</h2><div><ul><li><a href="https://www.cnbc.com/2026/01/08/china-investigate-meta-acquisition-manus-export.html">Meta faces China probe over acquisition of AI agent startup Manus</a></li><li><a href="https://www.cnbc.com/2026/01/07/microsoft-behind-controversial-data-center-in-michigan-township.html">Microsoft revealed as company behind controversial data center proposal in Michigan township</a></li><li><a href="https://www.cnbc.com/2026/01/07/alphabets-market-cap-surpasses-apples-for-first-time-since-2019.html">Alphabet's market cap surpasses Apple's for first time since 2019</a></li><li><a href="https://www.cnbc.com/2026/01/07/google-characterai-to-settle-suits-involving-suicides-ai-chatbots.html">Google, Character.AI to settle suits involving minor suicides and AI chatbots</a></li></ul></div></div><div><p>Shares were slightly lower following the news. Google briefly touched above a <a href="https://www.cnbc.com/2026/01/12/alphabet-4-trillion-market-cap.html">$4 trillion market value</a>.</p><p>Apple has mostly stood on the sidelines of the AI frenzy that's swept up Wall Street since the launch of<a href="https://www.cnbc.com/2025/12/16/openai-in-talks-with-amazon-about-investment-could-top-10-billion.html"> OpenAI'</a>s <a href="https://www.cnbc.com/2026/01/07/openai-chatgpt-health-medical-records.html">ChatGPT</a> at the end of 2022. </p><p>Hyperscalers <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-16"><a href="https://www.cnbc.com/quotes/AMZN/">Amazon</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>, <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-17"><a href="https://www.cnbc.com/quotes/META/">Meta Platforms</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> and <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-18"><a href="https://www.cnbc.com/quotes/MSFT/">Microsoft</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> have <a href="https://www.cnbc.com/2025/10/31/tech-ai-google-meta-amazon-microsoft-spend.html">shelled out billions</a> on AI products, tools and infrastructure for their customers.</p><p>That's amped up the pressure on the <a href="https://www.cnbc.com/2025/12/17/apple-ai-delay-siri.html">iPhone maker to deliver</a> an impressive Siri AI voice upgrade, which it delayed last year <a href="https://www.cnbc.com/2025/03/07/apple-delays-siri-ai-improvements-to-2026.html">until 2026</a>, despite <a href="https://www.cnbc.com/2025/04/23/apple-ai-ads-went-too-far-watchdog-says.html">running ads</a> for the product.</p><p>"It's going to take us longer than we thought to deliver on these features and we anticipate rolling them out in the coming year," the company said in a statement at the time.</p><p>Apple currently <a href="https://openai.com/index/openai-and-apple-announce-partnership/" target="_blank">partners with OpenAI</a> to integrate ChatGPT into Siri and Apple Intelligence, specifically for complicated queries that can tap into the AI model's world knowledge. It's unclear what the Google partnership means for the ChatGPT integration in the future.</p><p>The devices giant told CNBC said that they aren't making any changes to the agreement. OpenAI did not immediately respond to a request for comment. </p><p>Meanwhile, Google has made steady progress on its AI agenda, introducing its <a href="https://www.cnbc.com/2025/11/18/google-announces-gemini-3-as-battle-with-openai-intensifies.html">upgraded Gemini 3 model</a> late last year. </p><p>In October, Google CEO <a href="https://www.cnbc.com/sundar-pichai/">Sundar Pichai</a> <a href="https://blog.google/company-news/inside-google/message-ceo/alphabet-earnings-q3-2025/#google-cloud" target="_blank">said</a> the company's cloud segment signed more deals worth more than $1 billion through the third quarter of 2025 than the previous two years combined. </p></div><div><div role="button" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" width="256" height="256" viewBox="0 0 256 256" aria-labelledby="title desc" role="img" focusable="false" preserveAspectRatio="xMinYMin"><title>Stock Chart Icon</title><desc>Stock chart icon</desc><g transform="translate(1.4065934065934016 1.4065934065934016) scale(2.81 2.81)"><path d="M 87.994 0 H 69.342 c -1.787 0 -2.682 2.16 -1.418 3.424 l 5.795 5.795 l -33.82 33.82 L 28.056 31.196 l -3.174 -3.174 c -1.074 -1.074 -2.815 -1.074 -3.889 0 L 0.805 48.209 c -1.074 1.074 -1.074 2.815 0 3.889 l 3.174 3.174 c 1.074 1.074 2.815 1.074 3.889 0 l 15.069 -15.069 l 14.994 14.994 c 1.074 1.074 2.815 1.074 3.889 0 l 1.614 -1.614 c 0.083 -0.066 0.17 -0.125 0.247 -0.202 l 37.1 -37.1 l 5.795 5.795 C 87.84 23.34 90 22.445 90 20.658 V 2.006 C 90 0.898 89.102 0 87.994 0 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 65.626 37.8 v 49.45 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 23.518 L 65.626 37.8 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 47.115 56.312 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 42.03 L 47.115 56.312 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 39.876 60.503 c -1.937 0 -3.757 -0.754 -5.127 -2.124 l -6.146 -6.145 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 59.844 C 41.952 60.271 40.933 60.503 39.876 60.503 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path><path d="M 22.937 46.567 L 11.051 58.453 c -0.298 0.298 -0.621 0.562 -0.959 0.8 V 87.25 c 0 1.519 1.231 2.75 2.75 2.75 h 8.782 c 1.519 0 2.75 -1.231 2.75 -2.75 V 48.004 L 22.937 46.567 z" transform=" matrix(1 0 0 1 0 0) " stroke-linecap="round"></path></g></svg><p><img src="https://static-redesign.cnbcfm.com/dist/a54b41835a8b60db28c2.svg" alt="hide content"></p></div><p>Alphabet and Apple one-day stock chart.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLVM: The Bad Parts (143 pts)]]></title>
            <link>https://www.npopov.com/2026/01/11/LLVM-The-bad-parts.html</link>
            <guid>46588837</guid>
            <pubDate>Mon, 12 Jan 2026 14:18:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npopov.com/2026/01/11/LLVM-The-bad-parts.html">https://www.npopov.com/2026/01/11/LLVM-The-bad-parts.html</a>, See on <a href="https://news.ycombinator.com/item?id=46588837">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        
        <p>A few years ago, I wrote a blog post on <a href="https://www.npopov.com/2021/06/02/Design-issues-in-LLVM-IR.html">design issues in LLVM IR</a>. Since then, one of these issues has been fixed fully (opaque pointers migration), one has been mostly fixed (constant expression removal), and one is well on the way towards being fixed (ptradd migration).</p>

<p>This time I’m going to be more ambitious and not stop at three issues. Of course, not all of these issues are of equal importance, and how important they are depends on who you ask. In the interest of brevity, I will mostly just explain what the problem is, and not discuss what possible solutions would be.</p>

<p>Finally, I should probably point out that this is written from my perspective as the lead maintainer of the LLVM project: This is not a list of reasons to not use LLVM, it’s a list of opportunities to improve LLVM.</p>

<h2 id="high-level-issues">High level issues</h2>

<h3 id="review-capacity">Review capacity</h3>

<p>Unlike many other open-source projects, LLVM certainly <a href="https://insights.linuxfoundation.org/project/llvm-llvm-project">does not suffer</a> from a lack of contributors. There are <em>thousands</em> of contributors and the distribution is relatively flat (that is, it’s not the case that a small handful of people is responsible for the majority of contributions.)</p>

<p>What LLVM does suffer from is insufficient review capacity. There are a lot more people writing code than reviewing it. This is somewhat unsurprising, as code review requires more expertise than writing code, and may not provide immediate value<sup id="fnref:review_value" role="doc-noteref"><a href="#fn:review_value" rel="footnote">1</a></sup> to the person reviewing (or their employer).</p>

<p>Lack of review capacity makes for a bad contributor experience, and can also result in bad changes making their way into the codebase. The way this usually works out is that someone puts up a PR, then fails to get a qualified review for a long period of time, and then one of their coworkers (who is not a qualified reviewer for that area) ends up rubberstamping the PR.</p>

<p>A related problem is that LLVM has a somewhat peculiar contribution model where it’s the responsibility of the PR author to request reviewers. This is especially problematic for new contributors, who don’t know whom to request. Often relevant reviewers will become aware of the PR thanks to a label-based notification system, but this is not apparent from the UI, and it’s easy for PRs to fall through the cracks.</p>

<p>A potential improvement here would be a Rust-style <a href="https://forge.rust-lang.org/triagebot/pr-assignment.html">PR assignment system</a>.</p>

<h3 id="churn">Churn</h3>

<p>Both the LLVM C++ API and LLVM IR are not stable and undergo frequent changes. This is simultaneously a great strength and weakness of LLVM. It’s a strength because LLVM does not stagnate and is willing to address past mistakes even at significant cost. It’s a weakness because churn imposes costs on users of LLVM.</p>

<p>Frontends are <em>somewhat</em> insulated from this because they can use the largely stable C API. However, it does not cover everything, and most major frontends will have additional bindings that use the unstable C++ API.</p>

<p>Users that integrate with LLVM more tightly (for example downstream backends) don’t have that option, and have to keep up with all API changes.</p>

<p>This is part of LLVM’s general development philosophy, which I’ll express somewhat pointedly as “upstream or GTFO”. LLVM is liberally licensed and does not require you to contribute changes upstream. However, if you do not upstream your code, then it will also not factor into upstream decision-making.</p>

<p>This point is somewhat unlike the rest, in that I’m not sure it’s possible to make things “strictly better” here. It’s possible that LLVM’s current point on the stability scale is not optimal, but moving it somewhere else would come with significant externalities. Making major changes in LLVM is already extremely hard due to the sheer scale of the project, without adding additional stability constraints on top.</p>

<h3 id="build-time">Build time</h3>

<p>LLVM is a huge project. LLVM itself is &gt;2.5 million lines of C++ and the entire monorepo is something like 9 million. C++ is not exactly known for fast build times, and compiling all that code takes time. This is bearable if you either have fast hardware or access to a build farm, but trying to build LLVM on a low-spec laptop is not going to be fun.</p>

<p>An additional complication is building with debug info (which I always recommend against), in which case you’ll add the extra gotchas of slow link times, high risk of OOM and massive disk usage. There are ways to avoid that (using shared libs or dylib build, using split dwarf, using lld), but it takes some expertise.</p>

<p>Promising changes in this area are the <a href="https://discourse.llvm.org/t/rfc-use-pre-compiled-headers-to-speed-up-llvm-build-by-1-5-2x/89345?u=nikic">use of pre-compiled headers</a> (which significantly improves build time), and changing to use a <a href="https://discourse.llvm.org/t/rfc-llvm-link-llvm-dylib-should-default-to-on-on-posix-platforms/85908?u=nikic">dylib build by default</a> (which reduces disk usage and link time, esp. for debuginfo builds). Another is to <a href="https://discourse.llvm.org/t/rfc-reducing-process-creation-overhead-in-llvm-regression-tests/88612?u=nikic">reduce test overhead</a> using daemonization (not strictly part of the “build time”, but relevant for the development cycle).</p>

<h3 id="ci-stability">CI stability</h3>

<p>LLVM CI consists of over 200 post-commit buildbots that test LLVM in lots of different configurations on lots of different hardware. Commits that turn a buildbot from green to red result in an email to the commit author.</p>

<p>Unfortunately, this CI is never fully green, and flaky on top. This is in part due to flaky tests (typically in lldb or openmp), but can also be due to buildbot-specific issues. The end result is that it’s “normal” to get buildbot failure notifications for any given commit, even if it is perfectly harmless. This dilutes the signal, and makes it easier to miss the real failures.</p>

<p>The introduction of pre-merge testing on PRs did significantly improve the overall CI situation, but not the buildbot problem as such. I think we need to start taking flaky tests/buildbots more seriously before we can really make progress here.</p>

<p>Because someone is definitely going to mention how this <a href="https://graydon2.dreamwidth.org/1597.html">is not rocket science</a>, and we just need to start using bors / merge queues to guarantee an always-green build: It’s a problem of scale. There are &gt;150 commits on a typical workday, which would be more than one commit every 10 minutes even if they were uniformly distributed. Many buildbots have multi-hour runs. This is hard to reconcile.<sup id="fnref:bors" role="doc-noteref"><a href="#fn:bors" rel="footnote">2</a></sup></p>

<h3 id="end-to-end-testing">End-to-end testing</h3>

<p>In some respects, LLVM has very thorough test coverage. We’re quite pedantic about making sure that new optimizations have good coverage of both positive and negative tests. However, these tests are essentially unit tests for a single optimization pass or analysis.</p>

<p>We have only a small amount of coverage for the entire optimization pipeline (phase ordering tests), so optimizations sometimes regress due to pass interactions. Tests for the combination of the middle-end and backend pipelines are essentially nonexistent. There is likely room for improvement here, though it comes with tradeoffs.</p>

<p>However, what actually concerns me are end-to-end executable tests. LLVM’s test suite proper does not feature these at all. Executable tests are located in a separate <a href="https://github.com/llvm/llvm-test-suite">llvm-test-suite</a> repo, which is typically not used during routine development, but run by buildbots. It contains a lot of different code ranging from benchmarks to unit tests.</p>

<p>However, llvm-test-suite has quite few tests (compared to LLVM lit tests) and does not comprehensively cover basic operations. Things like testing operations on different float formats, on integers of different sizes, vectors of different sizes and element types, etc.</p>

<p>In part this is because of limitations of testing through C/C++, which is very heterogeneous in type support (C compilers don’t like exposing types that don’t have a defined psABI for the target). But that’s no excuse to delegate this testing to Zig instead (which exposes everything, everywhere, and has the corresponding test coverage).</p>

<h3 id="backend-divergence">Backend divergence</h3>

<p>While LLVM’s middle-end is very unified, backend implementations are very heterogeneous, and there is a tendency to fix issues (usually performance, but sometimes even correctness) only for the backend you’re interested in.</p>

<p>This takes many forms, like implementing target-specific DAG combines instead of generic ones. Though my definite favorite is to introduce lots of target hooks for optimizations – not because the optimization is actually only beneficial for one target, but because the person introducing it just doesn’t want to deal with the fallout on other targets.</p>

<p>This is understandable – after all, they may lack the knowledge to evaluate a change for other targets, so it may require working with many other maintainers, which can slow progress a lot. But the end result is still increasing divergence and duplication.</p>

<p>Lack of end-to-end testing compounds this issue, because that would act as something of a forcing function that at least all operations compile without crashing and produce correct results for all tested targets.</p>

<h3 id="compilation-time">Compilation time</h3>

<p>Because I’ve <a href="https://www.npopov.com/2020/05/10/Make-LLVM-fast-again.html">complained</a> about this enough in the past, I’ll keep it short: LLVM is slow, which is an issue both for JIT use cases, and anything that tends to produce huge amounts of IR (like Rust or C++).</p>

<p>Since I’ve started <a href="https://llvm-compile-time-tracker.com/">tracking compile-times</a>, the situation has significantly improved, both through targeted improvements and avoidance of regressions. However, there is still a lot of room for improvement: LLVM still isn’t fast, it’s just less slow.</p>

<p>One thing that LLVM is particularly bad at are <code>-O0</code> compile-times. The architecture is optimized for optimization, and lots of costs remain even if no optimization takes place. The <a href="https://discourse.llvm.org/t/tpde-llvm-10-20x-faster-llvm-o0-back-end/86664?u=nikic">LLVM TPDE</a> alternative backend shows that it’s possible to do better by an order of magnitude.</p>

<h3 id="performance-tracking">Performance tracking</h3>

<p>The flip side of the compile-time coin is runtime performance. This is something that LLVM obviously cares a lot about. Which is why I find it rather surprising that LLVM does not have any “official” performance tracking infrastructure.</p>

<p>Of course, there are lots of organizations which track performance of LLVM downstream, on their own workloads. In some ways this is good, because it means there is more focus on real-world workloads than on synthetic benchmarks like SPEC. However, not having readily accessible, public performance tracking also makes it hard for contributors to evaluate changes.</p>

<p>To be fair, LLVM does have an <a href="https://lnt.llvm.org/">LNT</a> instance, but a) it’s currently broken, b) LNT is one of the worst UX crimes ever committed, c) little data gets submitted there, and d) it’s not possible to request a test run for a PR, or something like that.</p>

<p>This point is frankly just baffling to me. I don’t personally care about SPEC scores, but I know plenty of people do, so why there is no first-class tracking for this is a mystery to me.</p>

<h2 id="ir-design">IR design</h2>

<h3 id="undef-values">Undef values</h3>

<p><a href="https://llvm.org/docs/UndefinedBehavior.html#undef-values">Undef values</a> take an arbitrary value from a certain set. They are used to model uninitialized values, and have historically been used to model deferred undefined behavior. The latter role has been replaced by poison values, which have much simpler propagation rules and are more amenable to optimization. However, undef is still used for uninitialized memory to this day.</p>

<p>There are two main problems with undef values. The first is the multi-use problem: An undef value can take a different value at each use. This means that transforms that increase the use count are generally invalid, and care has to be taken when optimizing based on value equality. The mere existence of undef values prevents us from performing optimizations we want to do, or greatly increases their complexity.</p>

<p>The second issue is that undef is very hard to reason about. Humans have trouble understanding it, and for proof-checkers it is computationally expensive.</p>

<p>Most likely, uninitialized memory will be represented using poison values instead in the future, but this runs into the problem that LLVM currently is not capable of correctly treating poison in memory. Proper support for poison in memory requires additional IR features, like the <a href="https://blog.llvm.org/posts/2025-08-29-gsoc-byte-type/">byte type</a>.</p>

<h3 id="unsoundness-and-specification-incompleteness">Unsoundness and specification incompleteness</h3>

<p>While most miscompilations (that is, correctness bugs) in LLVM are resolved quickly, there are quite a few that remain unfixed despite having been known for a long time. These issues usually combine the qualities of being largely theoretical (that is, appearing only in artificially constructed examples rather than real-world code) and running up against issues in LLVM’s IR design.</p>

<p>Some of them are cases where we have a good idea of how the IR design needs to change to address the issue, but these changes are complex and often require a lot of work to recover optimization parity. There is often a complexity cliff where you can do something that’s simple and <em>nearly</em> correct, or you can do something very complex that is fully correct.</p>

<p>Then there are other cases, where just deciding on how things <em>should</em> work is a hard problem. The provenance model is a prime example of this. The interaction of provenance with integer casts and type punning is a difficult problem with complex tradeoffs.</p>

<p>However, at some point these issues do need to be resolved. The recently formed <a href="https://discourse.llvm.org/t/rfc-forming-a-working-group-on-formal-specification-for-llvm/89056?u=nikic">formal specification working group</a> aims to tackle these problems.</p>

<h3 id="constraint-encoding">Constraint encoding</h3>

<p>A key challenge for optimizing compilers is encoding of constraints (like “this value is non-negative” or “this add will not overflow”). This includes both frontend-provided constraints (based on language undefined behavior rules), but also compiler-generated ones.</p>

<p>In particular, there are many different analyses that can infer facts about the program, but keeping these up-to-date throughout optimization is challenging. One good way to handle this is to encode facts directly in the IR. Correctly updating or discarding these annotations then becomes part of transform correctness.</p>

<p>LLVM has many different ways to encode additional constraints (poison flags, metadata, attributes, assumes), and these all come with tradeoffs in terms of how much information can be encoded, how reliably it is retained during optimization and to what degree it can <em>negatively</em> affect optimization. Information from metadata is lost too often, while information from assumes is not lost often enough.</p>

<h3 id="floating-point-semantics">Floating-point semantics</h3>

<p>There are various issues with floating-point (FP) semantics once we move outside the nice world of “strictly conforming IEEE 754 floats in the default environment”. A few that come to mind are:</p>

<ul>
  <li>Handling of signaling NaN and FP exceptions, and non-default FP environment in general. LLVM represents this using constrained FP intrinsics. This is not ideal, as all the FP handling is split into two parallel universes.</li>
  <li>Handling of denormals. LLVM has a function attribute to not assume IEEE denormal behavior, but this is only suitable for cases where flush to zero (FTZ) is used globally. It does not help with modeling cases like ARM, where scalar ops are IEEE, while vector ops use FTZ.</li>
  <li>Handling of excess precision, in particular when using the x87 FPU.</li>
</ul>

<!--### Type-based representation

This is something I've written about enough in the past, so I'll keep it brief: For historical reasons, LLVM IR encodes unnecessary type information that no longer carries any semantic meaning in various places. The biggest offender here were pointer element types, which were removed by the [opaque pointers migration][opaque_pointers].-->

<h2 id="other-technical-issues">Other technical issues</h2>

<h3 id="partial-migrations">Partial migrations</h3>

<p>LLVM is a very large project, and making any significant changes to it is hard and time consuming. Migrations often span years, where two different implementations of something coexist, until all code has been migrated. The two prime examples of this are:</p>

<p><strong>New pass manager:</strong> The “new” pass manager was first introduced more than a decade ago. Then about five years ago, we started using it for the middle-end optimization pipeline by default, and support for the legacy PM was dropped.</p>

<p>However, the back-end is still using the legacy pass manager. There is ongoing work to support the new pass manager in codegen, and we’re pretty close to the point where it can be used end-to-end for a single target. However, I expect it will still take quite a while for all targets to be ported and the legacy pass manager to be completely retired.</p>

<p><strong>GlobalISel:</strong> This is an even more extreme case. GlobalISel is the “new” instruction selector that is intended to replace SelectionDAG (and FastISel). It was introduced approximately one decade ago, and to this day, none of the targets that originally used SelectionDAG have been fully migrated to GlobalISel. There is one new target that’s GlobalISel-only, and there is one that uses GlobalISel by default for unoptimized builds. But otherwise, SelectionDAG is still the default everywhere.</p>

<p>There are two backends (AMDGPU and AArch64) that have somewhat complete GlobalISel support, but it’s not clear when/if they’ll be able to switch to using it by default. A big problem here is that new optimizations are continually being implemented on the SDAG side, so it’s hard to keep parity.</p>

<h3 id="abi--calling-convention-handling">ABI / calling convention handling</h3>

<p>Essentially everything about the handling of calling conventions in LLVM is a mess.</p>

<p>The responsibility for handling calling conventions is split between the frontend and the backend. There are good reasons why LLVM can’t do this by itself (LLVM IR sits at a too low level of abstraction to satisfy the extremely arcane ABI rules).</p>

<p>This is not a problem in itself – however, there is zero documentation of what the calling convention contract between the frontend and LLVM is, and the proper way to implement C FFI is essentially to look at what Clang does and copy that (invariably with errors, because the rules can be very subtle).</p>

<p>I’ve proposed to fix this by introducing an <a href="https://discourse.llvm.org/t/rfc-an-abi-lowering-library-for-llvm/84495?u=nikic">ABI lowering library</a> and vortex73 has <a href="https://blog.llvm.org/posts/2025-08-25-abi-library/">implemented a prototype</a> for it as part of GSoC. So we’re well on the way to resolving this side of the problem.</p>

<p>There are more problems though. One that Rust has struggled with a lot is the interaction of target features with the calling convention. Enabling additional target features can change the call ABI, because additional float/vector registers start getting used for argument/return passing. This means that calls between functions with a feature enabled and disabled may be incompatible, because they assume different ABIs.</p>

<p>Ideally, ABI and target features would be orthogonal, and only coupled in that some ABIs require certain target features (e.g. you can’t have a hard float ABI without enabling FP registers). Target features are a per-function choice, while the ABI should be per-module.</p>

<p>Some of the newer architectures like Loongarch and RISC-V actually have proper ABI design, but most of the older ones don’t. For example, it’s currently not possible to target AArch64 with a soft float ABI but hard float implementation.</p>

<h3 id="builtins--libcalls">Builtins / libcalls</h3>

<p>Somewhat related to this is the handling of compiler builtins/libcalls, which are auxiliary functions that the compiler may emit for operations that are not natively supported by the target. This covers both libcalls provided by libc (or libm), and builtins provided by compiler runtime libraries like libgcc, compiler-rt or compiler-builtins.</p>

<p>There are two sources of truth for this, TargetLibraryInfo (TLI) and RuntimeLibcalls. The former is used by the middle-end, primarily to recognize and optimize C library calls (this mostly covers only libc, but not libgcc). The latter is used by the backend, primarily to determine which libcalls may be emitted by the compiler and how they are spelled (this covers libgcc, and the subset of libc covered by LLVM intrinsics).</p>

<p>A problem with RuntimeLibcalls is that it currently largely works off only the target triple, which means that we have to make “lowest common denominator” assumptions about which libcalls are available, where the lowest common denominator is usually libgcc. If <code>--rtlib=compiler-rt</code> is used, LLVM does not actually know about that, and cannot make use of functions that are in compiler-rt but not libgcc.</p>

<p>This also means that we’re missing a customization point for other runtime libraries. For example, there is no way for Rust to say that it provides f128 suffix libcalls via compiler-builtins, overriding target-specific naming and availability assumptions based on which type <code>long double</code> in C maps to.</p>

<p>There is a lot of ongoing work in this area (by arsenm), so the situation here will hopefully improve in the near-ish future.</p>

<h3 id="context--module-dichotomy">Context / module dichotomy</h3>

<p>LLVM has two high-level data holders. A module corresponds to a compilation unit (e.g. pre-LTO, a single file in C/C++). The LLVM context holds various “global” data. There’s usually one context per thread, and multiple modules can (in principle) use a single context.</p>

<p>Things like functions and globals go into the module, while constants and types go into the context. The module also contains a data layout, which provides important type layout information like “how wide is a pointer”.</p>

<p>The fact that constants and types do not have access to the data layout is a constant source of friction. If you have a type, you cannot reliably tell its size without threading an extra parameter through everything. We have subsystems (like ConstantFold vs. ConstantFolding) that are separated entirely by whether data layout is available or not.</p>

<p>At the same time, I feel like this split is not actually buying us a lot. Having shared types and constants is somewhat convenient when it comes to module linking, because they can be directly shared, but I think performing explicit remapping in that one place would be better than having complexity everywhere else. Additionally, this would also allow cross-context linking, which is currently only possible by going through a bitcode roundtrip. In theory, the context could also allow some memory reuse when compiling multiple modules, but I think in practice there is usually a one-to-one correspondence between those.</p>

<h3 id="licm-register-pressure">LICM register pressure</h3>

<p>This is getting a bit down in the weeds, but I’ll mention it anyway due to how often I’ve run across this in recent times.</p>

<p>LLVM considers loop invariant code motion (LICM) to be a canonicalization transform. This means that we always hoist instructions out of loops, without any target specific cost modelling. However, LICM can increase the live ranges of values, which can increase register pressure, which can lead to a large amount of spills and reloads.</p>

<p>The general philosophy behind this is that LICM hoists everything, all middle-end transforms can work with nicely loop invariant instructions, and then instructions will get sunk back into the loop by the backend, which can precisely model register pressure.</p>

<p>Except… that second part doesn’t actually happen. I believe that (for non-PGO builds) instructions only get sunk back into loops either through rematerialization in the register allocator, or specialized sinking (typically of addressing modes), but for anything not falling into those buckets, no attempt to sink into loops in order to reduce register pressure is made.</p>

<h2 id="other">Other</h2>

<p>This list is not exhaustive. There’s more I could mention, but we’d get into increasingly narrow territory. I hope I covered most of the more important things – please do let me know what I missed!</p>



        
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Windows 8 Desktop Environment for Linux (135 pts)]]></title>
            <link>https://github.com/er-bharat/Win8DE</link>
            <guid>46588132</guid>
            <pubDate>Mon, 12 Jan 2026 13:22:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/er-bharat/Win8DE">https://github.com/er-bharat/Win8DE</a>, See on <a href="https://news.ycombinator.com/item?id=46588132">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Windows 8 revival on Linux.</h2><a id="user-content-windows-8-revival-on-linux" aria-label="Permalink: Windows 8 revival on Linux." href="#windows-8-revival-on-linux"></a></p>
<p dir="auto">If you are one of who enjoyed the windows 8 and miss its fluid animations but have since moved to linux.
And cant go back to windows 8, because all apps are non functional there. And if you can bear that you
cant install it on the newer hardware.
This is for you it is a shell for wayland window managers like Labwc hyprland etc. It gives a
wallpaper utility, a lock screen, a start menu, an OSD for volume and brightness a settins app for wall.
it dosent provide charms menu because i always thought its useless.
<a href="https://github.com/user-attachments/assets/8b0269a7-01d3-404d-b637-948cd9f767c7">Win8De.webm</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Screenshots</h2><a id="user-content-screenshots" aria-label="Permalink: Screenshots" href="#screenshots"></a></p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/146621598/534447660-2dd5a13d-bda3-40ef-9a3e-b093bd3907df.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTM0NDQ3NjYwLTJkZDVhMTNkLWJkYTMtNDBlZi05YTNlLWIwOTNiZDM5MDdkZi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT01M2I3YThiNTQ4ZWE2NTdkMzhjYmE2NTAwMmNiMGU0NDZkOTY0MWNlMDI3NjZlZTJjNjBkYzQxMDdkMjI5NzNjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.wDie5OE6tP9awLpPoR3F-b0-kDnbJuM2RoIrkllW4HA"><img width="1920" height="1080" alt="start" src="https://private-user-images.githubusercontent.com/146621598/534447660-2dd5a13d-bda3-40ef-9a3e-b093bd3907df.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTM0NDQ3NjYwLTJkZDVhMTNkLWJkYTMtNDBlZi05YTNlLWIwOTNiZDM5MDdkZi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT01M2I3YThiNTQ4ZWE2NTdkMzhjYmE2NTAwMmNiMGU0NDZkOTY0MWNlMDI3NjZlZTJjNjBkYzQxMDdkMjI5NzNjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.wDie5OE6tP9awLpPoR3F-b0-kDnbJuM2RoIrkllW4HA"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/146621598/531155931-77e450a7-e43e-43dd-9a3f-789c0eb6e52b.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTMxMTU1OTMxLTc3ZTQ1MGE3LWU0M2UtNDNkZC05YTNmLTc4OWMwZWI2ZTUyYi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kMzU5ZjU4NDFjZTE2MTNhZjQyYjgyYTQwNmQyZDE2OWI1MjBhYWJkNWU4ZjI2MTI4ODA0ZTgwZTI5MzAzN2QzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.QdvdYVmHl786RwEXA-UUTwQPrw6RvNrrdJRVEaNgJR4"><img width="1920" height="1080" alt="allapp" src="https://private-user-images.githubusercontent.com/146621598/531155931-77e450a7-e43e-43dd-9a3f-789c0eb6e52b.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTMxMTU1OTMxLTc3ZTQ1MGE3LWU0M2UtNDNkZC05YTNmLTc4OWMwZWI2ZTUyYi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kMzU5ZjU4NDFjZTE2MTNhZjQyYjgyYTQwNmQyZDE2OWI1MjBhYWJkNWU4ZjI2MTI4ODA0ZTgwZTI5MzAzN2QzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.QdvdYVmHl786RwEXA-UUTwQPrw6RvNrrdJRVEaNgJR4"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/146621598/534447821-e3d62c68-5ef4-4128-9192-8854f9a8c07d.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTM0NDQ3ODIxLWUzZDYyYzY4LTVlZjQtNDEyOC05MTkyLTg4NTRmOWE4YzA3ZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1jM2JjZmIzYzYzODM0MDY5MDJkMjMyMzVlYTRkOGYzODc1MTRjNTRhYzQ1OWMyZTlhMjJjOTJiMTg5NDcwZTZjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.XEuH8rkSGGinaKxqhB446_g6sAMpYzMDekUngOfkWHA"><img width="1920" height="1080" alt="lock-dialog" src="https://private-user-images.githubusercontent.com/146621598/534447821-e3d62c68-5ef4-4128-9192-8854f9a8c07d.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTM0NDQ3ODIxLWUzZDYyYzY4LTVlZjQtNDEyOC05MTkyLTg4NTRmOWE4YzA3ZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1jM2JjZmIzYzYzODM0MDY5MDJkMjMyMzVlYTRkOGYzODc1MTRjNTRhYzQ1OWMyZTlhMjJjOTJiMTg5NDcwZTZjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.XEuH8rkSGGinaKxqhB446_g6sAMpYzMDekUngOfkWHA"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/146621598/534448024-6f06bfd1-01dc-4195-8169-0506e238b32c.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTM0NDQ4MDI0LTZmMDZiZmQxLTAxZGMtNDE5NS04MTY5LTA1MDZlMjM4YjMyYy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT05NDg2OWYwMDVmMjdiZGQzYThkM2RlN2U3MGI4OTg1ODQ0MjdmYmYzMjE1NWZjMzJlOTNmNGFmZGMwYTEwN2FkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.rLHkuFX7xb9-JC-aryDWIFwjkzN_Vl-Tc2x-ISjuIOo"><img width="1920" height="1080" alt="lock-vkey" src="https://private-user-images.githubusercontent.com/146621598/534448024-6f06bfd1-01dc-4195-8169-0506e238b32c.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTM0NDQ4MDI0LTZmMDZiZmQxLTAxZGMtNDE5NS04MTY5LTA1MDZlMjM4YjMyYy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT05NDg2OWYwMDVmMjdiZGQzYThkM2RlN2U3MGI4OTg1ODQ0MjdmYmYzMjE1NWZjMzJlOTNmNGFmZGMwYTEwN2FkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.rLHkuFX7xb9-JC-aryDWIFwjkzN_Vl-Tc2x-ISjuIOo"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/146621598/531155943-83ae8072-b697-4b3e-a1f9-b220b58e0424.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTMxMTU1OTQzLTgzYWU4MDcyLWI2OTctNGIzZS1hMWY5LWIyMjBiNThlMDQyNC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iMmFmMmRhNjNkZmVkNzkzMTAyYzUzYjY0MTdkZDE1ZGNjMzI5ZTZlOGJjNWZmZDNhYThjZDI5MDAxMWZmNzg5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Ibe9ZaGZr4GyN5W4Bd67b0ghNP1zLZmk2YCrZC_6H1Y"><img width="1920" height="1080" alt="runningapps" src="https://private-user-images.githubusercontent.com/146621598/531155943-83ae8072-b697-4b3e-a1f9-b220b58e0424.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTMxMTU1OTQzLTgzYWU4MDcyLWI2OTctNGIzZS1hMWY5LWIyMjBiNThlMDQyNC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iMmFmMmRhNjNkZmVkNzkzMTAyYzUzYjY0MTdkZDE1ZGNjMzI5ZTZlOGJjNWZmZDNhYThjZDI5MDAxMWZmNzg5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Ibe9ZaGZr4GyN5W4Bd67b0ghNP1zLZmk2YCrZC_6H1Y"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/146621598/531156662-2afc4a9e-00e1-4baf-aea3-be8021915862.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTMxMTU2NjYyLTJhZmM0YTllLTAwZTEtNGJhZi1hZWEzLWJlODAyMTkxNTg2Mi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02NTdhYzg1YmYyMTkxNGNkY2MzZGRhOWMxMDcxYWQzMTk1ODY5MGU2YmQ2MWM3ODc2Yjg4NjIyOGI1ZDM3ZTE0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.a8tZp72G2uZJLglyRGO9oLTNFD6JBemuTTIUyAy4VtY"><img width="1920" height="1080" alt="lock" src="https://private-user-images.githubusercontent.com/146621598/531156662-2afc4a9e-00e1-4baf-aea3-be8021915862.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjgyMzIxMDEsIm5iZiI6MTc2ODIzMTgwMSwicGF0aCI6Ii8xNDY2MjE1OTgvNTMxMTU2NjYyLTJhZmM0YTllLTAwZTEtNGJhZi1hZWEzLWJlODAyMTkxNTg2Mi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTEyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDExMlQxNTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02NTdhYzg1YmYyMTkxNGNkY2MzZGRhOWMxMDcxYWQzMTk1ODY5MGU2YmQ2MWM3ODc2Yjg4NjIyOGI1ZDM3ZTE0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.a8tZp72G2uZJLglyRGO9oLTNFD6JBemuTTIUyAy4VtY"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<hr>
<p dir="auto"><h3 tabindex="-1" dir="auto">Start</h3><a id="user-content-start" aria-label="Permalink: Start" href="#start"></a></p>
<ol dir="auto">
<li>one command Win8Start to show hide start menu can be bound to super of compositor.</li>
<li>full drag and drop support of start tiles and sizes small medium large xlarge gui way right click.</li>
<li>can drag from all apps to tiles.</li>
<li>search of apps functional.</li>
<li>drag app from all apps to botom to hide start screen and put icon any where that supports like desktop.</li>
<li>get power menu by clicking user icon.</li>
<li>have battery osd in it.</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">OSD</h3><a id="user-content-osd" aria-label="Permalink: OSD" href="#osd"></a></p>
<ol dir="auto">
<li>Volume up down mute</li>
<li>brightness up down.</li>
<li>two part Win8OSD-server and Win8OSD-client server should be autostarted</li>
<li>Win8OSD-client --volup voldown mute dispup dispdown</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Wall</h3><a id="user-content-wall" aria-label="Permalink: Wall" href="#wall"></a></p>
<ol dir="auto">
<li>simple image wallpaper</li>
<li>settable through settins</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Lockscreen</h3><a id="user-content-lockscreen" aria-label="Permalink: Lockscreen" href="#lockscreen"></a></p>
<ol dir="auto">
<li>windows 8 style</li>
<li>wallpaper changable by settings app</li>
<li>have nice slide down and up of lockscreen</li>
<li>dont need click and drag just click is enough unlike original</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">settings</h3><a id="user-content-settings" aria-label="Permalink: settings" href="#settings"></a></p>
<ol dir="auto">
<li>can change wallpaper of all 3 graphically start wall lock</li>
<li>can change accent colors and background colors of start lockscreen etc.</li>
</ol>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">for local binary use run</h3><a id="user-content-for-local-binary-use-run" aria-label="Permalink: for local binary use run" href="#for-local-binary-use-run"></a></p>
<p dir="auto"><code>./build.sh</code></p>
<p dir="auto">it will build all binaries and put it in "build/bin" folder you can use it in config files to autostart
and bind to system keys for brightness and volume with local location.
you can't run settings from start screen bc it uses system location so you will have to run it from binary built.
bind win/super key to Win8Start</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">for system install</h3><a id="user-content-for-system-install" aria-label="Permalink: for system install" href="#for-system-install"></a></p>
<p dir="auto"><code>./install.sh</code></p>
<p dir="auto">it will automatically run build.sh and move the binaries to "/usr/bin/" and will be available systemwide,
so it will be easier to put in configs and autostart</p>
<p dir="auto"><code>./uninstall.sh</code></p>
<p dir="auto">it will remove binaries from <code>/usr/bin/</code></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Use It Like seperate DE</h2><a id="user-content-use-it-like-seperate-de" aria-label="Permalink: Use It Like seperate DE" href="#use-it-like-seperate-de"></a></p>
<p dir="auto">it will use different config file so that your current config is not affected.
create a copy of config folder and paste it with diff name like labwc2 hypr2 etc.</p>
<p dir="auto">find your compositors config loading command and make a .desktop file like this <strong>example</strong>.</p>
<p dir="auto"><code>[Desktop Entry]</code><br>
<code>Name=labwc-win8</code><br>
<code>Comment=A wayland stacking compositor</code><br>
<code>Exec=labwc -C /home/user1/.config/labwc3</code><br>
<code>Icon=labwc</code><br>
<code>Type=Application</code><br>
<code>DesktopNames=labwc;wlroots</code></p>
<p dir="auto">and <strong>paste</strong> it in <code>/usr/share/wayland-sessions/</code></p>
<p dir="auto">and at <em><strong>login choose this session.</strong></em></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Floppy disks turn out to be the greatest TV remote for kids (278 pts)]]></title>
            <link>https://blog.smartere.dk/2026/01/floppy-disks-the-best-tv-remote-for-kids/</link>
            <guid>46587934</guid>
            <pubDate>Mon, 12 Jan 2026 13:07:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.smartere.dk/2026/01/floppy-disks-the-best-tv-remote-for-kids/">https://blog.smartere.dk/2026/01/floppy-disks-the-best-tv-remote-for-kids/</a>, See on <a href="https://news.ycombinator.com/item?id=46587934">Hacker News</a></p>
Couldn't get https://blog.smartere.dk/2026/01/floppy-disks-the-best-tv-remote-for-kids/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Ozempic reduced grocery spending by an average of 5.3% in the US (274 pts)]]></title>
            <link>https://news.cornell.edu/stories/2025/12/ozempic-changing-foods-americans-buy</link>
            <guid>46587536</guid>
            <pubDate>Mon, 12 Jan 2026 12:29:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.cornell.edu/stories/2025/12/ozempic-changing-foods-americans-buy">https://news.cornell.edu/stories/2025/12/ozempic-changing-foods-americans-buy</a>, See on <a href="https://news.ycombinator.com/item?id=46587536">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>When Americans begin taking appetite-suppressing drugs like Ozempic and Wegovy, the changes extend well beyond the bathroom scale. According to new research, the medications are associated with meaningful reductions in how much households spend on food, both at the grocery store and at restaurants.</span></p><p><span>The study,&nbsp;</span><a href="https://journals.sagepub.com/doi/10.1177/00222437251412834"><span>published Dec. 18</span></a><span> in the&nbsp;Journal of Marketing Research, links survey data on GLP-1 receptor agonist use – a class of drugs originally developed for diabetes and now widely prescribed for weight loss – with detailed transaction records from tens of thousands of U.S. households. The result is one of the most comprehensive looks yet at how GLP-1 adoption is associated with changes in everyday food purchasing in the real world.</span></p><p><span>The headline finding is striking: Within six months of starting a GLP-1 medication, households reduce grocery spending by an average of 5.3%. Among higher-income households, the drop is even steeper, at more than 8%. Spending at fast-food restaurants, coffee shops and other limited-service eateries falls by about 8%.</span></p><p><span>Among households who continue using the medication, lower food spending persists at least a year, though the magnitude of the reduction becomes smaller over time, say co-authors, assistant professor&nbsp;</span><a href="https://business.cornell.edu/faculty-research/faculty/sh2596/"><span>Sylvia Hristakeva</span></a><span> and professor&nbsp;</span><a href="https://business.cornell.edu/faculty-research/faculty/jl2545/"><span>Jura Liaukonyte</span></a><span>,&nbsp;both in the Charles H. Dyson School of Applied Economics and Management in the Cornell SC Johnson College of Business.&nbsp;</span></p><p><span>“The data show clear changes in food spending following adoption,” Hristakeva said. “After discontinuation, the effects become smaller and harder to distinguish from pre-adoption spending patterns.”</span></p><p><span>Unlike previous studies that relied on self-reported eating habits, the new analysis draws on purchase data collected by Numerator, a market research firm that tracks grocery and restaurant transactions for a nationally representative panel of about 150,000 households. The researchers matched those records with repeated surveys asking whether household members were taking GLP-1 drugs, when they started and why.</span></p><p><span>That combination allowed the team to compare adopters with similar households that did not use the drugs, isolating changes that occurred after medication began.</span></p><p><span>The reductions were not evenly distributed across the grocery store.</span></p><p><span>Ultra-processed, calorie-dense foods – the kinds most closely associated with cravings – saw the sharpest declines. Spending on savory snacks dropped by about 10%, with similarly large decreases in sweets, baked goods and cookies. Even staples like bread, meat and eggs declined.</span></p><p><span>Only a handful of categories showed increases. Yogurt rose the most, followed by fresh fruit, nutrition bars and meat snacks.</span></p><p><span>“The main pattern is a reduction in overall food purchases. Only a small number of categories show increases, and those increases are modest relative to the overall decline,” Hristakeva said.&nbsp;</span></p><p><span>The effects extended beyond the supermarket. Spending at limited-service restaurants such as fast-food chains and coffee shops fell sharply as well.</span></p><p><span>The study also sheds light on who is taking GLP-1 medications. The share of U.S. households reporting at least one user rose from about 11% in late 2023 to more than 16% by mid-2024. Weight-loss users skew younger and wealthier, while those taking the drugs for diabetes are older and more evenly distributed across income groups.</span></p><p><span>Notably, about one-third of users stopped taking the medication during the study period. When they did, their food spending reverted to pre-adoption levels – and their grocery baskets became slightly less healthy than before they started, driven in part by increased spending on categories such as candy and chocolate.</span></p><p><span>That movement underscores an important limitation, the authors caution. The study cannot fully separate the biological effects of the drugs from other lifestyle changes users may make at the same time. However, evidence from clinical trials, combined with the observed reversion in spending after discontinuation, suggests appetite suppression is likely a key mechanism behind the spending changes.</span></p><p><span>The findings carry implications far beyond individual households.</span></p><p><span>For food manufacturers, restaurants and retailers, widespread GLP-1 adoption could mean long-term shifts in demand, particularly for snack foods and fast food. Package sizes, product formulations and marketing strategies may need to change. For policymakers and public-health experts, the results add context to ongoing debates about the role of medical treatments in shaping dietary behavior – and whether biologically driven appetite changes succeed where taxes and labels have struggled.</span></p><p><span>“At current adoption rates, even relatively modest changes at the household level can have meaningful aggregate effects,” Hristakeva said. “Understanding these demand shifts is therefore important for assessing food markets and consumer spending.”&nbsp;</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lightpanda migrate DOM implementation to Zig (154 pts)]]></title>
            <link>https://lightpanda.io/blog/posts/migrating-our-dom-to-zig</link>
            <guid>46586179</guid>
            <pubDate>Mon, 12 Jan 2026 09:42:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lightpanda.io/blog/posts/migrating-our-dom-to-zig">https://lightpanda.io/blog/posts/migrating-our-dom-to-zig</a>, See on <a href="https://news.ycombinator.com/item?id=46586179">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><img src="https://cdn.lightpanda.io/website/assets/images/blog/authors/karl_seguin.png" alt="Karl Seguin"></p><div><h3>Karl Seguin</h3><h4>Software Engineer</h4></div></div><figure><img src="https://cdn.lightpanda.io/website/assets/images/blog/posts/migrating-our-dom-to-zig/migratingdomtozig_large.png" alt="Migrating our DOM to Zig"></figure><h2 id="tldr">TL;DR<a href="#tldr" aria-label="Permalink for this section"></a></h2>
<p>We replaced LibDOM with our own Zig-based DOM implementation. The original design created friction between V8, our Zig layer, and LibDOM, especially around events, Custom Elements, and ShadowDOM. After six months of spare-time prototyping, we built zigdom: a leaner, more cohesive DOM that gives us full control over memory, events, and future enhancements. We also swapped in html5ever for parsing and added V8 snapshots to cut startup time. There are single-digit % performance gains, but the real win is a unified codebase that’s easier to extend.</p>
<h2 id="why-we-replaced-libdom">Why We Replaced LibDOM<a href="#why-we-replaced-libdom" aria-label="Permalink for this section"></a></h2>
<p>At a high level, the Lightpanda codebase can be described as a Zig layer sitting between V8 and LibDOM. When JavaScript is executed, like , V8 calls into the Zig layer which then forwards the request to the underlying LibDOM document object and then forwards the result back to V8. By using LibDOM, we gained a robust and fairly comprehensive DOM implementation with minimal effort.</p>
<p>However, as we worked to increase compatibility with websites in the wild, we felt ever-increasing friction between our three layers. One example is the event system baked into LibDOM. This proved awkward to expand beyond DOM-based events (e.g. input events) or even just bubbling DOM events to our Zig-based Window implementation. Another larger challenge, was integrating support for Custom Elements and ShadowDOM, written in Zig, with LibDOM. Finally, there was some concern about the lack of cohesion with respect to things like memory management and how that would impact potential future changes, like better multi-threading support.</p>
<p>If we were to restart the integration from scratch, knowing what we know now, we’d probably be able to avoid most of the friction we’re currently seeing. While we do modify LibDOM as needed, one approach would be to integrate V8 and LibDOM directly, applying fixes and additions directly to LibDOM. But as we wrote before, we’re <a href="https://lightpanda.io/blog/posts/why-we-built-lightpanda-in-zig" target="_blank" rel="noreferrer">fans of Zig<!-- --> <svg fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.7" viewBox="0 0 24 24" height="1em"><path d="M7 17L17 7"></path><path d="M7 7h10v10"></path></svg></a> so the discussions and prototypes we built always leaned towards replacing LibDOM with a custom Zig implementation.</p>
<h3 id="zigdom">zigdom<a href="#zigdom" aria-label="Permalink for this section"></a></h3>
<p>Work on a prototype for having a Zig-based DOM started roughly six months ago. This was a casual in-our-spare-time effort. In the spirit of experimentation, this prototype also replaced V8 with <a href="https://github.com/quickjs-ng/quickjs" target="_blank" rel="noreferrer">QuickJS-NG<!-- --> <svg fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.7" viewBox="0 0 24 24" height="1em"><path d="M7 17L17 7"></path><path d="M7 7h10v10"></path></svg></a>. By mid-November, we felt the prototype had tackled enough unknowns to start integrating it into Lightpanda (with V8). Thankfully, porting features was relatively simple; commits to the  branch could usually be ported to the  branch.</p>
<p>The design is straightforward. A  has a linked list of children and an optional . Furthermore, a  has a  tagged union field to represent the type of node, and a  field to capture its supertype:</p>

<p>Since a modern website can have tens of thousands of nodes and thousands of elements, we obviously care about the size of our ,  and . That’s why every type in our union is a pointer. That means that when we create a div, we need to allocate the Div, HTMLElement, Element, Node and EventTarget. But rather than doing five separate allocations, we do 1 large allocation for the total size and parcel it out.</p>
<p>Another area where we’ve been able to optimize for our use-case is to lazily parse/load certain properties. While a website might have thousands of elements, most JavaScript will only access the classes, styles, relLists, dataset, etc, of a few elements. Rather than having these stored on each element, even as empty lazily loaded containers, they’re attached to a page in an element -&gt; property lookup. While this adds lookup overhead, it removes ~6 pointers from every element.</p>
<p>The real win is having a more cohesive design for events, custom elements and ShadowDOM and a simpler foundation for future enhancements. That said, performance, both in terms of memory usage and CPU load are slightly improved (both single digit % improvements).</p>
<h3 id="html5ever">html5ever<a href="#html5ever" aria-label="Permalink for this section"></a></h3>
<p>We saw benefits to writing our own DOM implementation, but not our own HTML parser. For that, we turned to <a href="https://servo.org/" target="_blank" rel="noreferrer">servo’s<!-- --> <svg fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.7" viewBox="0 0 24 24" height="1em"><path d="M7 17L17 7"></path><path d="M7 7h10v10"></path></svg></a> <a href="https://github.com/servo/html5ever" target="_blank" rel="noreferrer">html5ever<!-- --> <svg fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.7" viewBox="0 0 24 24" height="1em"><path d="M7 17L17 7"></path><path d="M7 7h10v10"></path></svg></a> written in Rust. I almost forgot to mention it in this post because the experience was so painless and worked from the get-go that I haven’t had to think about it for a while. You setup html5ever with a bunch of callbacks (for creating a node, attaching a node to a parent, creating text, etc.), feed it your HTML, and away you go. My Rust is very bad, but writing a C binding for it was manageable.</p>
<h3 id="bonus---v8-snapshot">Bonus - V8 Snapshot<a href="#bonus---v8-snapshot" aria-label="Permalink for this section"></a></h3>
<p>Some of the porting was tedious. For a change of pace, I took time to see how we could leverage V8 snapshots. As a short summary, whenever you create a V8 environment to execute code, you have to do a lot of setup. Every type (hundreds) with all the functions and properties need to be registered with the V8 environment. For a simple page, this can represent anywhere from 10-30% of the total time. V8 snapshots let you setup a pseudo-environment upfront, extract a Snapshot (a binary blob), and use that blob to bootstrap and speedup future environments.</p>
<p>When in debug mode, we generated the snapshot on startup. In release mode, the snapshot is generated at compile-time and embedded into the binary, reducing startup time and memory. The overall impact depends on the relative cost of setting up the environment vs processing the page. Complex websites that load hundreds of external scripts probably won’t benefit. But incremental improvements hopefully add up and, if nothing else, help balance the performance cost of new features and complexity.</p>
<h3 id="ai-coding-agent">AI Coding Agent<a href="#ai-coding-agent" aria-label="Permalink for this section"></a></h3>
<p>This was the first large feature that I developed with the aid of an AI coding agent - specifically Claude. The experience was positive, but not flawless. I’ve personally always liked participating in code reviews / PRs. I can spend hours every day reviewing PRs, so working with Claude is kind of fun for me. If reading code isn’t something you consider fun, it could be a frustrating experience.</p>
<p>I was almost always impressed with the quality of code written and “understanding” that Claude exhibited. I’m only guessing here, but I have to imagine that building a DOM, something which has a very explicit specification, tons of documentation and many implementations, was an ideal task for a coding agent.</p>
<p>That said, I do think this is first and foremost a code-review exercise, and the Claude CLI is lacking in that respect. When you’re trying to understand and think through a change, you need a comfortable interface that lets you navigate and access whatever context you’re missing. Anything more than a few lines becomes challenging to review, especially as it’s presented for you to accept one piece at a time.</p>
<p>In the end, it’s a tool that supplements my own abilities.</p>
<h2 id="whats-next">What’s Next<a href="#whats-next" aria-label="Permalink for this section"></a></h2>
<p>Implementing our own DOM from scratch should make it easier for us to add new features and enhancements. Something we’ve already seen with better custom element and ShadowRoot support. Much of the benefits don’t come directly from implementing a new DOM, but by simply having a more cohesive codebase. For us, expanding our usage of Zig made the most sense.</p>
<p>zigdom is now merged into Lightpanda’s main branch. If you want to see how we structured the Node, Element, and event system in Zig, check out the <a href="https://github.com/lightpanda-io/browser" target="_blank" rel="noreferrer">source code on GitHub<!-- --> <svg fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.7" viewBox="0 0 24 24" height="1em"><path d="M7 17L17 7"></path><path d="M7 7h10v10"></path></svg></a>.</p><hr><div><div><p><img src="https://cdn.lightpanda.io/website/assets/images/blog/authors/karl_seguin.png" alt="Karl Seguin"></p><div><h3>Karl Seguin</h3><h4>Software Engineer</h4></div></div><p>Karl is a software engineer, creator of popular open-source Zig libraries like http.zig or websocket.zig. Karl has been writing about programming for years on his blog openmymind.net and is the author of Learning Zig, a series of articles to help other developers pick up the language. At Lightpanda, he works on building the core browser engine.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ai, Japanese chimpanzee who counted and painted dies at 49 (113 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cj9r3zl2ywyo</link>
            <guid>46585947</guid>
            <pubDate>Mon, 12 Jan 2026 09:10:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cj9r3zl2ywyo">https://www.bbc.com/news/articles/cj9r3zl2ywyo</a>, See on <a href="https://news.ycombinator.com/item?id=46585947">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="text-block"><p>Ai, a female chimpanzee famous for her cognitive skills has died at 49, according to the Japanese institute where she lived. </p><p>The Kyoto University's Center for the Evolutionary Origins of Human Behavior said Ai died on 9 January of old age and organ failure and that she was surrounded by staff when she died. </p><p>Ai was born in western Africa and arrived at the Japanese institute in 1977. There, she became the namesake of the Ai Project, a research programme into the "chimpanzee mind".</p><p>Among the institute's noteable findings were the fact that Ai was able to use numbers and identify colours. </p></div><div data-component="text-block"><p>Researchers gave Ai a special keyboard linked to a computer when she was 18 months, a set-up that they used to study her memory and learning. </p><p>At five years old, Ai "mastered numerical naming from one to six and was able to name the number, colour and object of 300 types of samples", according to a 1985 scientific paper by Tetsuro Matsuzawa, the primatologist behind the Ai Project.</p><p>When she was not participating in cognitive tests, Ai was known to enjoy drawing and painting. Like other chimpanzees at the centre, Ai would scrawl marker pens over blank paper without having to be motivated by food rewards.</p><p>Japanese media outlet Kyodo news reported that she once escaped with another primate - using a key to unlock her cage. </p><p>In 2000 she gave birth to a son, Ayumu, who is also known for his remarkable memory.  </p><p>In 2017 - the 40th anniversary of the Ai Project - a scarf made from one of Ai's paintings was gifted to renowned primatologist Dame Jane Goodall.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Xfce is great (282 pts)]]></title>
            <link>https://rubenerd.com/xfce-is-great/</link>
            <guid>46584173</guid>
            <pubDate>Mon, 12 Jan 2026 04:39:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rubenerd.com/xfce-is-great/">https://rubenerd.com/xfce-is-great/</a>, See on <a href="https://news.ycombinator.com/item?id=46584173">Hacker News</a></p>
<div id="readability-page-1" class="page"><div property="articleBody">
<p>I have not been shy talking about <a href="https://rubenerd.com/tag/xfce/">my love</a> of <a href="https://xfce.org/">Xfce</a> over the years here. The desktop environment has been a trusted friend ever since I first loved it on the late Cobind Desktop (still the high water mark of desktop Linux, as far as I’m concerned).</p>
<p>I’m glad to see I’m not the only one. David Gerard of <a href="https://pivot-to-ai.com/">Pivot to AI</a> fame recently shared <a href="https://reddragdiva.dreamwidth.org/582674.html">this post he wrote in 2012</a>:</p>
<blockquote>
<p>The question with minimal desktops is the fine line between as simple as possible and just a bit too simple. How much basic stuff do you have to add back? 4.8 took it slightly far, 4.10 is almost Just Right. XFCE is so far a case study in Not Fucking It Up; I hope they never go to version 5, and just update 4 forever.</p></blockquote>
<p>This (a) longevity and (2) getting the balance right cannot be overstated. Here’s my current Xfce desktop, for example:</p>
<figure><p><img src="https://rubenerd.com/files/2026/xfce2008@1x.jpg" alt="" srcset="https://rubenerd.com/files/2026/xfce2008@2x.jpg 2x"></p></figure>
<p>Except, <strong>no it isn’t</strong>. That’s a screenshot of my <a href="https://rubenerd.com/p1185/" title="Fun with Xfce, part one">FreeBSD desktop from 2008</a>, with the bright and clear Tango Iconset (speaking of high-water marks). Remember when iconography was discernable at a glance? Aka, functional as icons? But I digress.</p>
<p>Xfce in 2025 (no, 2026, damn it!) is just as easy to understand, light, and fast as it first was booting Cobind on my <a href="http://retro.rubenerd.com/brio.htm">HP Brio</a> when I was in school, or when building it from source in FreeBSD ports. Though unlike a barebones window manager or other “light” DEs, Xfce feels usable, feature complete, and designed by someone who understands why people use desktop computers (cough GNOME).</p>
<p>I do use KDE on my primary desktop. Version 4 was a mess, but they’ve made <em>massive</em> improvements, especially within the last year. I’m not sure how much this had to do with the Steam Deck, and a new generation of people realising that… wait… I can run stuff on this box other than games? There’s a desktop here!? But my laptops all run Xfce, and I’m half-tempted to move back to it on the desktop.</p>
<p>I’m with David here. I hope they never feel the need to “innovate” with “disruption” for “UX”. The switch to the Thunar file manager was the last major user-facing change I can remember, and it was great.</p>
<p>I’m not suggesting we reached peak UI with Xfce, but no desktop since has made a compelling case (for me) for its replacement. I love, <em>love</em>, <strong>love</strong> that Xfce is maintained this way in spite of all the industry pressures to turn it into something else.</p>
<h3 id="disclaimer">Disclaimer</h3>
<p>I stopped writing posts like this for years, out of fear of how people from specific desktop environments would respond. If you’re about to write me an angry screed, know that I will immediately delete it and block you, <a href="https://rubenerd.com/people-who-need-to-run-windows/" title="A thread about people who need to run Windows">just as I did last time</a>. Both yours and my time are better spent.</p>
<p>I also know (sigh) this disclaimer will be ignored, so I’m questioning why I’m even bothering. Maybe I’m a sucker for punishment.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Himalayas bare and rocky after reduced winter snowfall, scientists warn (150 pts)]]></title>
            <link>https://www.bbc.com/news/articles/clyndv7zd20o</link>
            <guid>46583464</guid>
            <pubDate>Mon, 12 Jan 2026 02:58:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/clyndv7zd20o">https://www.bbc.com/news/articles/clyndv7zd20o</a>, See on <a href="https://news.ycombinator.com/item?id=46583464">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p data-component="headline-block"><h2>Himalayas bare and rocky after reduced winter snowfall, scientists warn</h2></p><div data-testid="byline" data-component="byline-block"><p><span data-testid="byline-contributors"><div data-testid="byline-contributors-contributor-0"><p><span>Navin Singh Khadka</span><span data-testid="byline-contributors-contributor-0-role-location">Environment correspondent</span></p></div></span></p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/e0ca/live/31240770-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/e0ca/live/31240770-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/e0ca/live/31240770-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/e0ca/live/31240770-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/e0ca/live/31240770-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/e0ca/live/31240770-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/e0ca/live/31240770-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/e0ca/live/31240770-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp" loading="eager" alt="Getty Images A general view of a river running through the area with the Himalaya Mountains in the background in Leh, one of the most remote areas of the Indian-administered portion of the Kashmir region, on April 13, 2025."><span>Getty Images</span></p></div></figure><div data-component="text-block"><p>Much less winter snow is falling on the Himalayas, leaving the mountains bare and rocky in many parts of the region in a season when they should be snow-clad, meteorologists have said.</p><p>They say most winters in the last five years have seen a drop compared to average snowfall between 1980 and 2020.</p><p>Rising temperature also means what little snow falls melts very quickly and some lower-elevation areas are also seeing more rain and less snow, which is at least in part due to global warming, according to the Intergovernmental Panel on Climate Change and other scientific reports.</p><p>Studies have also shown there is now what is known as "snow drought" during winter in many parts of the Himalayan region.</p><p>Accelerated melting of glaciers in the wake of global warming has long been a major crisis facing India's Himalayan states and other countries in the region. This dwindling snowfall during winter is making matters worse, experts have told the BBC.</p><p>They say that the reduction in ice and snow will not only change how the Himalayas look, it will also impact the lives of hundreds of millions of people and many ecosystems in the region.</p><p>As temperatures rise in spring, snow accumulated during winter melts and the runoff feeds river systems. This snowmelt is a crucial source for the region's rivers and streams, supplying water for drinking, irrigation and hydropower. </p><p>Apart from impacting the water supply, less winter precipitation - rainfall in the lowlands and snowfall on the mountains - also means the region risks being gutted by forest fires due to dry conditions, experts said.</p><p>They add that vanishing glaciers and declining snowfall destabilise mountains as they lose the ice and snow that act as cement to keep them intact. Disasters like rockfalls, landslides, glacial lakes bursting out and devastating debris flows are already becoming more common.</p><p>So, how serious is the drop in snowfall?</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/5487/live/4de72ac0-ef21-11f0-a422-4ba8a094a8fa.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/5487/live/4de72ac0-ef21-11f0-a422-4ba8a094a8fa.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/5487/live/4de72ac0-ef21-11f0-a422-4ba8a094a8fa.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/5487/live/4de72ac0-ef21-11f0-a422-4ba8a094a8fa.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/5487/live/4de72ac0-ef21-11f0-a422-4ba8a094a8fa.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/5487/live/4de72ac0-ef21-11f0-a422-4ba8a094a8fa.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/5487/live/4de72ac0-ef21-11f0-a422-4ba8a094a8fa.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/5487/live/4de72ac0-ef21-11f0-a422-4ba8a094a8fa.jpg.webp" loading="lazy" alt="Yunish Gurung Mountain Machhapuchhre (Fishtail) in western Nepal that hosts central Himalayan ranges was seen bare and rocky last winter due to very less snowfall."><span>Yunish Gurung</span></p></div><p data-component="caption-block"><figcaption>Meteorologists say central Himalayas have also seen significant decrease in winter snowfall leaving mountains bare and rocky</figcaption></p></figure><div data-component="text-block"><p>The Indian Meteorological Department recorded no precipitation - rainfall and snowfall - in almost all of northern India in December.</p><p>The weather department says there is a high possibility that many parts of northwest India, including Uttarakhand and Himachal Pradesh states, and the federally-administered territories of Jammu and Kashmir and Ladakh, will see 86% less than long period average (LPA) rainfall and snowfall between January and March.</p><p>LPA is the rainfall or snow recorded over a region over 30 to 50 years and use its average to classify current weather as normal, excess or deficient.</p><p>According to the weather department, north India's LPA rainfall between 1971 and 2020 was 184.3 millimetre.</p><p>Meteorologists say the sharp drop in precipitation is not just a one-off thing.</p><p>"There is now strong evidence across different datasets that winter precipitation in the Himalayas is indeed decreasing," said Kieran Hunt, principal research fellow in tropical meteorology at University of Reading in the UK.</p><p>A <a target="_blank" href="https://wcd.copernicus.org/articles/6/43/2025/">study</a> Hunt co-authored and published in 2025 has included four different datasets between 1980 and 2021, and they all show a decrease in precipitation in the western and part of the central Himalayas.</p><p>Using datasets from ERA-5 (European Centre for Medium-Range Weather Forecasts Reanalysis), Hemant Singh, a research fellow with the Indian Institute of Technology in Jammu, says snowfall in the north<b id=""> </b>western Himalayas has decreased by 25% in the past five years compared to 40-year long-term average (1980-2020).</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/7cec/live/52e21cb0-ec7e-11f0-ba9c-c9d74e6fde06.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/7cec/live/52e21cb0-ec7e-11f0-ba9c-c9d74e6fde06.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/7cec/live/52e21cb0-ec7e-11f0-ba9c-c9d74e6fde06.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/7cec/live/52e21cb0-ec7e-11f0-ba9c-c9d74e6fde06.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/7cec/live/52e21cb0-ec7e-11f0-ba9c-c9d74e6fde06.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/7cec/live/52e21cb0-ec7e-11f0-ba9c-c9d74e6fde06.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/7cec/live/52e21cb0-ec7e-11f0-ba9c-c9d74e6fde06.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/7cec/live/52e21cb0-ec7e-11f0-ba9c-c9d74e6fde06.jpg.webp" loading="lazy" alt="Getty Images In this picture taken on February 10, 2021, women from Raini Chak Lata village walk along a mountain path in Chamoli district. - Long before this month's deadly flash flood in a remote Indian Himalayan valley, Kundan Singh Rana knew that all the construction work in the fragile region would one day mean disaster."><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>Women walk along a mountain path in Uttarakhand state</figcaption></p></figure><div data-component="text-block"><p>Meteorologists say Nepal, within which the central Himalayas is situated, is also seeing a significant drop in winter precipitation.</p><p>"Nepal has seen zero rainfall since October, and it seems the rest of this winter will remain largely dry. This has been the case more or less in all the winters in the last five years," says Binod Pokharel, associate professor of meteorology at Tribhuvan University in Kathmandu.</p><p>Meteorologists, however, also add that there have been heavy snowfalls during some winters in recent years, but these have been isolated, extreme events rather than the evenly distributed precipitation of past winters.</p></div><div data-component="text-block"><p>Another way scientists assess the decrease in snowfall is by measuring how much snow is accumulated on the mountains, and how much of that remains for a period of time on the ground without melting: known as snow-persistence.</p><p>The 2024-2025 winter saw a 23-year record low of nearly 24% below-normal snow persistence, according to a <a target="_blank" href="https://lib.icimod.org/records/kcknw-ers18#:~:text=Description,and%20integrated%20water%20management%20strategies.">report</a> by the International Centre for Integrated Mountain Development (ICIMOD).</p><p>It said four of the past five winters between 2020 and 2025 saw below-normal snow persistence in the Hindu Kush Himalaya region.</p><p>"This is generally understood to be consistent with decreased winter precipitation anomalies and snowfall in a significant portion of the HKH (Hindu Kush Himalaya) region," said Sravan Shrestha, senior associate, remote sensing and geoinformation with ICIMOD.</p><p>A <a target="_blank" href="https://www.nature.com/articles/s41598-025-21257-2">study</a> Singh with the IIT in Jammu co-authored and published in 2025 shows that the Himalayan region is now increasingly seeing snow droughts – snow becoming significantly scarce – particularly between 3,000 and 6,000m elevations.</p><p>"With snowmelt contributing about a fourth of the total annual runoff of 12 major river basins in the region, on average, anomalies in seasonal snow persistence affect water security of nearly two billion people across these river basins," the ICIMOD snow update <a target="_blank" href="https://link.springer.com/article/10.1007/s10584-023-03495-3">report</a> warns.</p><p>Melting Himalayan glaciers pose long-term water scarcity risks, while reduced snowfall and faster snowmelt threaten near-term water supplies, experts warn.</p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/a9ee/live/11406ca0-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/a9ee/live/11406ca0-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/a9ee/live/11406ca0-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/a9ee/live/11406ca0-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/a9ee/live/11406ca0-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/a9ee/live/11406ca0-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/a9ee/live/11406ca0-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/a9ee/live/11406ca0-ec7c-11f0-ba9c-c9d74e6fde06.jpg.webp" loading="lazy" alt="Getty Images Leh is a little town in an elevation of 3500m. high. It used to be the capital of the Himalayan kingdom named Ladakh. Nowadays Leh is the capital in the regional district of Leh in Jammu and Kashmir in India. Leh is an important center for the mountainous area of India. Nowadays it attracts many tourists around the world, mostly those who are involved with mountain sport activities. In Leh there are 4 major religions, Buddhism, Hinduism, Islam and Sikhism."><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>Experts say dwindling snowfall will impact the lives of millions of people in the region</figcaption></p></figure><div data-component="text-block"><p>Most meteorologists cite weakening westerly disturbances – low-pressure systems from the Mediterranean carrying cold air – as a key reason for reduced rainfall and occasional snow during winter in northern India, Pakistan, and Nepal.</p><p>They say in the past, the westerly disturbances brought significant rain and snowfall during winter, which helped crops and replenished snow on the mountains.</p><p>Studies are mixed: some report changes in westerly disturbances, while others find no significant shift.</p><p>"However, we know that the change in winter precipitation must be related to westerly disturbances, since they are responsible for the majority of winter precipitation across the Himalayas," said Hunt.</p><p>"We think two things are happening here: westerly disturbances are becoming weaker, and with less certainty, tracking slightly further northward. Both of these inhibit their ability to pick up moisture from the Arabian Sea, resulting in weaker precipitation," he added.</p><p>The Indian weather department has labelled the westerly disturbance north India has experienced so far this winter as "feeble" because it could generate very nominal rainfall and snowfall.</p><p>Scientists may sooner or later find out what is behind the decrease in winter precipitation.</p><p>But what is already becoming clear is that the Himalayan region now faces a double trouble.</p><p>Just when it is rapidly losing its glaciers and icefields, it has also begun to get less snow. This combination, experts warn, will have huge consequences.</p><p><i id="follow-bbc-news-india-on">Follow BBC News India on </i><a target="_blank" href="https://www.instagram.com/bbcnewsindia/"><i id="instagram">Instagram</i></a><i id=",">, </i><a target="_blank" href="https://www.youtube.com/@bbcnewsindia/featured"><i id="youtube,">YouTube,</i></a><i id=""> </i><a target="_blank" href="https://x.com/BBCIndia"><i id="x">X</i></a><i id="and"> and </i><a target="_blank" href="https://www.facebook.com/bbcindia/"><i id="facebook">Facebook</i></a><i id=".">.</i></p></div><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/cebe/live/82f5e790-dc9b-11ef-a37f-eba91255dc3d.png.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/cebe/live/82f5e790-dc9b-11ef-a37f-eba91255dc3d.png.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/cebe/live/82f5e790-dc9b-11ef-a37f-eba91255dc3d.png.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/cebe/live/82f5e790-dc9b-11ef-a37f-eba91255dc3d.png.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/cebe/live/82f5e790-dc9b-11ef-a37f-eba91255dc3d.png.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/cebe/live/82f5e790-dc9b-11ef-a37f-eba91255dc3d.png.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/cebe/live/82f5e790-dc9b-11ef-a37f-eba91255dc3d.png.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/cebe/live/82f5e790-dc9b-11ef-a37f-eba91255dc3d.png.webp" loading="lazy" alt="Thin, green banner promoting the Future Earth newsletter with text saying, “Get the latest climate news from the UK and around the world every week, straight to your inbox”. There is also a graphic of an iceberg overlaid with a green circular pattern."></p></div></figure></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Code is cheap now, but software isn't (126 pts)]]></title>
            <link>https://www.chrisgregori.dev/opinion/code-is-cheap-now-software-isnt</link>
            <guid>46583410</guid>
            <pubDate>Mon, 12 Jan 2026 02:51:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chrisgregori.dev/opinion/code-is-cheap-now-software-isnt">https://www.chrisgregori.dev/opinion/code-is-cheap-now-software-isnt</a>, See on <a href="https://news.ycombinator.com/item?id=46583410">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Claude Code and Claude Opus 4.5 have poured fuel on the hype. LLM tools existed before, but they’re better than ever now, so a lot more people are paying attention. But we’re not entering a golden age of SaaS. We’re entering an era of personal, disposable software—where engineering shifts from writing code to shaping systems, and engineers are still required for exactly that reason.</p>
<h2>The Shift in Modern Development</h2>
<p><strong>Claude Code</strong> is taking over my feed right now, and for good reason. What’s interesting isn’t just that developers are jumping on it—it’s that <strong>"builders" and makers</strong> who previously relied on platforms like Lovable or Replit are migrating to it.</p>
<p>Don’t get me wrong, those tools are still perfectly viable for shipping fast. But we’re seeing a clear shift as people rediscover the inherent beauty of a <strong>CLI-first workflow</strong>. When you move the interaction into the <strong>terminal</strong>, the abstraction layer thins out. You aren't just following a managed UI's happy path; you're the one in control.</p>
<hr>
<h2>The collapse of the barrier to entry</h2>
<p>What are people actually building with these tools? If you look around, the answer is: almost everything. In fact, we’ve reached a point of saturation. On one hand, we are witnessing the <strong>true democratisation of software creation</strong>. The barrier to entry has effectively collapsed. For the first time, <strong>non-developers</strong> aren't just consumers of software - they are the <strong>architects of their own tools</strong>.</p>
<p>In the past, if you had a specific problem, you’d spend hours searching for a SaaS product that solved 80% of it. Today, the workflow has shifted. People are opening a CLI or a voice interface and simply describing what they need. We’re seeing a surge in <strong>"personal software"</strong>:</p>
<ul>
<li>A <strong>subscription tracker</strong> tailored to a specific budget style</li>
<li>A <strong>Chrome extension</strong> that solves one very niche data entry problem</li>
<li>A <strong>fitness app</strong> with an interface exactly how the user wants it</li>
</ul>
<p>This is a massive shift. <strong>Software is becoming a personal utility</strong> you generate, rather than a commodity you buy.</p>
<h2>From SaaS to Scratchpads</h2>
<p>We’re entering a new era of software development where the goal isn't always longevity. For years, the industry has been obsessed with building "platforms" and "ecosystems," but the tide is shifting toward something more ephemeral. We're moving from SaaS to scratchpads.</p>
<p>A lot of this new software isn't meant to live forever. In fact, it’s the opposite. People are increasingly building tools to solve a single, specific problem exactly once—and then discarding them. It is software as a disposable utility, designed for the immediate "now" rather than the distant "later."</p>
<p>What makes this viable today is a specific technical philosophy: CLI-first interfaces, local data, and zero onboarding. When you remove the friction of signing up, configuring a database, or navigating a complex UI, the cost of creating a tool drops so low that "temporary" becomes a feature, not a bug. If it takes five minutes to spin up a custom solution for a one-off task, you don't need it to persist.</p>
<p>The contrast with the traditional SaaS model is stark. SaaS is inherently built to optimize for retention, lock-in, and expansion. It’s a business model designed to keep you inside the ecosystem and growing your footprint. Bespoke tools, on the other hand, optimize for immediacy and control. They don't care about your lifetime value as a customer; they only care about solving the task at hand.</p>
<p>In many ways, this is a return to how spreadsheets were originally used. You didn't open a spreadsheet to build a permanent, multi-year database; you used it as a scratchpad to reason through a problem, calculate the results, and move on.</p>
<p>In this new landscape, Claude Code is Excel for developers—a powerful, flexible utility for solving immediate problems—rather than Shopify for founders, which is built to be a permanent foundation for a business. It’s about getting the job done, and then letting the tool go.</p>
<p>This also explains why the next part matters: generating software quickly is one thing; making it survive contact with the real world is another.</p>
<h2><strong>Code Is Cheap. Software Is Still Expensive.</strong></h2>
<p>Here is the reality of the current "AI-native" era: code has become cheap, but software remains incredibly expensive.</p>
<p>LLMs have effectively killed the cost of generating lines of code, but they haven’t touched the cost of truly understanding a problem. We’re seeing a flood of "apps built in a weekend," but most of these are just thin wrappers around basic CRUD operations and third-party APIs. They look impressive in a Twitter demo, but they often crumble the moment they hit the friction of the real world.</p>
<p>The real cost of software isn’t the initial write; it’s the maintenance, the edge cases, the mounting UX debt, and the complexities of data ownership. These "fast" solutions are brittle.</p>
<p>The subscription tracker breaks the moment a bank changes its CSV export format. The Chrome extension dies the second a target website’s DOM shifts. The fitness app becomes unusable as soon as a user needs robust offline support or reliable data sync.</p>
<p>Lately, I’ve seen plenty of doomsaying on Hacker News, Reddit, and Twitter about "the end of software engineering." This misses the point entirely. We aren't witnessing the end of the profession; we’re entering a new era of it.</p>
<p>The value of an engineer is shifting away from the "how" of syntax and toward the "what" and "why" of systems. Real engineering lies in the abstractions and the architecture. It’s about knowing how to structure a system that lasts, understanding why a specific rate-limiting strategy is necessary, knowing how to manage a distributed cache, and knowing exactly where <em>not</em> to store your environment variables.</p>
<p>AI often feels powerful because it hides the complexity, but as an engineer, your job is to manage that complexity, not ignore it. The tools have changed, but the fundamental requirement for engineering rigour has never been higher.</p>
<h2>The distribution illusion</h2>
<p>But there is a flip side. With the barrier to entry gone, the <strong>noise level</strong> has reached an all-time high. My feeds are currently flooded with <strong>"AI entrepreneurs"</strong> claiming <strong>five-figure monthly recurring revenue (MRR)</strong> for apps they built in an afternoon.</p>
<p>In many cases, these claims are highly suspect. When you see a creator with no existing distribution and no clear <span><strong>"moat"</strong></span> claiming $10,000 in MRR on a weekend project, it’s usually a play for engagement rather than a reflection of business reality.</p>
<p>Some of these stories are almost certainly true but in most cases, these aren't actually blueprints for technical innovation. They are marketing case studies. These individuals succeed because they have mastered the art of capturing attention in a crowded landscape, not just because they have an AI co-pilot.</p>
<p>We’ve entered an era where the ability to generate code is no longer the bottleneck. The <strong>real challenge has shifted to distribution</strong> and, more importantly, distinguishing the <strong>genuine utility</strong> from the "get-rich-quick" posturing that has become so prevalent in the industry.</p>
<p>These people haven't stumbled upon a secret shortcut; they have simply found a way to execute their existing advantages faster (and potentially unlocked it in the first place if learning to code was rightfully too big of an undertaking for a side project idea).</p>
<p>There is a useful framing for this shift: AI has effectively removed engineering leverage as a primary differentiator. When any developer can use an LLM to build and deploy a complex feature in a fraction of the time it used to take, the ability to write code is no longer the competitive advantage it once was. It is no longer enough to just be a "builder."</p>
<p>Instead, success now hinges on factors that are much harder to automate. Taste, timing, and deep, intuitive understanding of your audience matter more than ever. You can generate a product in a weekend, but that is worthless if you are building the wrong thing or launching it to a room full of people who aren't listening.</p>
<p>In this new environment, the code has become the easy part. The hard part remains exactly what it has always been: finding a way to get people to care.</p>
<h2>Who wins</h2>
<p>First, you have domain experts who are stuck with boring, repetitive problems. Then there are the internal teams building throwaway tooling, the kind of scripts and internal apps that need to work immediately rather than look perfect. Power users also see a massive gain here, particularly when they are looking to replace brittle, manual workflows with something more robust. Finally, it is a win for those engineers who prioritise ownership of the solution over high-gloss polish.</p>
<p>And yes — tools like Claude Opus 4.5, Claude Code, and Cursor are genuinely useful for engineers. They are remarkably good at removing boilerplate, implementing features, and writing unit tests. One of my favourite use cases lately, especially since starting a new job, is generating personalised documentation and walkthroughs of features to get up to speed on the product codebase and how all the nuance works - it's been extremely helpful in getting up to speed.</p>
<p>But here is the reality: LLMs are not perfect at writing code - even if it compiles first time. Even with high quality prompting and clear rules, these models still make mistakes. Speaking as someone who uses these tools every day, you cannot simply trust the output outright. You still have to review the code as if it were a pull request from a teammate. You have to read the logic, check the assumptions, and often make manual edits to get it right.</p>
<p>After all, you'll likely be sending this to a teammate for a review (and maybe Code Rabbit I guess) - is it fair to make them review something you didn't write or even bother to check?</p>
<p>These tools help you move faster, but they do not replace the need for a critical eye or your years of experience and do not understand the overall problem space better than you.</p>
<hr>
<p>The hype makes it look like we’re entering a golden age of SaaS. We aren’t. We’re entering an era of personal software: tools you generate to solve a problem, and then move on.</p>
<p>With twenty dollars, a few hours of spare time, and a bit of patience, almost anyone can ship a functional application. We are entering the era of "personal software," where the gap between an initial idea and a working product is narrower than ever before.</p>
<p>In this new reality, engineering expertise remains incredibly valuable, but the nature of the role is shifting. Relevance is not fading. Instead, it is about leveraging these tools to build at a higher level than was previously possible. True expertise is now required to steer these systems and provide the technical oversight that LLMs currently lack.</p>
<p>While AI is undeniably good at writing code, it remains poor at architecting maintainable, distributable, and scalable systems. This is where non-technical leaders who think they can fire their development teams are making a significant mistake. Until we see the arrival of an artificial intelligence that renders this entire discussion moot, believing that technical expertise can be replaced by a prompt is a strategic error. Building robust software still requires a human who understands the underlying principles of the craft.</p>
<p>The bottom line is that while the tools have changed, the fundamentals of good engineering have not.</p>
<p>While barrier to entry may be gone - judgment, taste, and responsibility are still the job.</p>
<hr>
<p>I hope you found this post insightful. <a href="https://www.twitter.com/codestirring" target="_blank" rel="noopener noreferrer">Follow me on Twitter</a> and <a href="https://bsky.app/profile/codestirring.bsky.social" target="_blank" rel="noopener noreferrer">Bluesky</a> for more wild takes and opinions on programming &amp; Elixir.</p>
<p>Check out <a data-state="closed" href="https://defer.to/" target="_blank" rel="noopener noreferrer" data-umami-event="link_click">defer.to</a> — my current obsession!</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uncrossy (160 pts)]]></title>
            <link>https://uncrossy.com/</link>
            <guid>46582762</guid>
            <pubDate>Mon, 12 Jan 2026 01:39:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://uncrossy.com/">https://uncrossy.com/</a>, See on <a href="https://news.ycombinator.com/item?id=46582762">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="undoTutorialModal">
                <p>Sometimes (like now) you'll need to undo a move before you can find a solution. You can find out if you're in this state by using the hint button or enabling auto-hints in the game settings.</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Which programming languages are most token-efficient? (109 pts)]]></title>
            <link>https://martinalderson.com/posts/which-programming-languages-are-most-token-efficient/</link>
            <guid>46582728</guid>
            <pubDate>Mon, 12 Jan 2026 01:36:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://martinalderson.com/posts/which-programming-languages-are-most-token-efficient/">https://martinalderson.com/posts/which-programming-languages-are-most-token-efficient/</a>, See on <a href="https://news.ycombinator.com/item?id=46582728">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    
    
    <div>
        <p>I've been trying to think through what happens to programming languages and tooling if humans are increasingly no longer writing it. I wrote about how good agents are at <a href="https://martinalderson.com/posts/ported-photoshop-1-to-csharp-in-30-minutes/">porting code recently</a>, and it got me thinking a bit more about what constraints LLMs have vs humans.</p>
<p>One of the biggest constraints LLMs have is on context length. This is a difficult problem to solve, as memory usage rises significantly with longer context window in current transformer architectures. And with the current memory shortages, I don't think the world is drowning in memory right now.</p>
<p>As such, for software development agents, how 'token efficient' a programming language actually could make a big difference and I wonder if it starts becoming a factor in language selection in the future. Given a significant amount of a coding agents context window is going to be code, a more token efficient language should allow longer sessions and require fewer resources to deliver.</p>
<p>We've seen <a href="https://toonformat.dev/">TOON</a> (an encoding of JSON to be more token efficient), but what about programming languages?<sup><a href="#fn1" id="fnref1">[1]</a></sup></p>
<h2>Methodology</h2>
<p>I came across the <a href="https://rosettacode.org/wiki/Rosetta_Code">RosettaCode</a> project while doing some research thinking around this. It describes itself a&nbsp;programming chrestomathy&nbsp;site (which I love, by the way). It has over a thousand programming 'tasks' that people build in various languages. It has contributions in nearly 1,000 different programming languages.</p>
<p>I found a <a href="https://github.com/acmeism/RosettaCodeData">GitHub mirror</a> of the dataset, so grabbed Claude Code and asked it to make a comparison of them, using the Xenova/gpt-4 tokenizer from Hugging Face - which is a community port of OpenAI's GPT4 tokenizer.</p>
<p>I then told Claude Code to suggest a selection of the most popular programming languages, which roughly matches my experience, and then find tasks that had solutions contributed in <em>all</em> 19 of these languages, and then ran them through the tokenizer. I didn't include TypeScript because there were very few tasks in the Rosetta Code dataset.</p>
<blockquote>
<p>There are many, many potential limits and biases involved in this dataset and approach! It's meant as a interesting look at somewhat like-for-like solutions to some programming tasks, not a scientific study.</p>
</blockquote>
<h2>Results</h2>
<p><img src="https://martinalderson.com/img/token-efficiency-chart.png" alt="Token efficiency comparison across programming languages"></p><blockquote>
<p><strong>Update:</strong> A lot of people asked about APL. I reran on a smaller set of like-for-like coding tasks - it came 4th at 110 tokens. Turns out APL's famous terseness isn't a plus for LLMs: the tokenizer is badly optimised for its symbol set, so all those unique glyphs (⍳, ⍴, ⌽, etc.) end up as multiple tokens each.</p>
</blockquote>
<blockquote>
<p><strong>Update 2:</strong> A reader reached out about J - a language I'd never heard of. It's an array language like APL but uses ASCII instead of special symbols. It dominates at just 70 tokens average, nearly half of Clojure (109 tokens). Array languages can be extremely token-efficient when they avoid exotic symbol sets. If token efficiency turns out to be a key driver, this is perhaps a very interesting way for languages to evolve.</p>
</blockquote>
<p>There was a very meaningful gap of 2.6x between C (the least token efficient language I compared) and Clojure (the most efficient).</p>
<p>Unsurprisingly, dynamic languages were much more token efficient (not having to declare <em>any</em> types saves a lot of tokens) - though JavaScript was the most verbose of the dynamic languages analysed.</p>
<p>What did surprise me though was just <em>how</em> token efficient some of the functional languages like Haskell and F# were - barely less efficient than the most efficient dynamic languages. This is no doubt to their very efficient type inference systems. I think using typed languages for LLMs has an awful lot of benefits - not least because it can compile and get rapid feedback on any syntax errors or method hallucinations. With LSP it becomes even more helpful.</p>
<p>Assuming 80% of your context window is code reads, edits and diffs, using Haskell or F# would potentially result in a significantly longer development session than using Go or C#.</p>
<p>It's really interesting to me that we are in this strange future where we have petaflops of compute but code verbosity of our 'small' context windows actually might matter. LLMs continue to break my mental model of how we should be looking at software engineering.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>OpenAI has a simple tokenizer you can play around with <a href="https://platform.openai.com/tokenizer">here</a>. Many people have wrote about how tokenization works - there's a good introduction <a href="https://christophergs.com/blog/understanding-llm-tokenization">here</a> if you'd like to learn more. The key thing is that it doesn't map <em>at all</em> to character usage in bytes. Common words and phrases can be 1 token for the entire word, but certain symbols and sequences can be one token per character. <a href="#fnref1">↩︎</a></p>
</li>
</ol>
</section>

    </div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Statement by Federal Reserve Chair Jerome F. Powell [video] (354 pts)]]></title>
            <link>https://www.youtube.com/watch?v=KckGHaBLSn4</link>
            <guid>46582441</guid>
            <pubDate>Mon, 12 Jan 2026 01:05:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=KckGHaBLSn4">https://www.youtube.com/watch?v=KckGHaBLSn4</a>, See on <a href="https://news.ycombinator.com/item?id=46582441">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Jerome Powell Responds (723 pts)]]></title>
            <link>https://www.federalreserve.gov/newsevents/speech/powell20260111a.htm</link>
            <guid>46582420</guid>
            <pubDate>Mon, 12 Jan 2026 01:02:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.federalreserve.gov/newsevents/speech/powell20260111a.htm">https://www.federalreserve.gov/newsevents/speech/powell20260111a.htm</a>, See on <a href="https://news.ycombinator.com/item?id=46582420">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content" role="main">
        
        <div id="article">
                                        
                    <div>
            <p><strong>Accessible Keys for Video</strong></p>
            <p><strong>[Space Bar]</strong> toggles play/pause;</p>
            <p><strong>[Right/Left Arrows]</strong> seeks the video forwards and back (5 sec );</p>
            <p><strong>[Up/Down Arrows]</strong> increase/decrease volume;</p>
            <p><strong>[M]</strong> toggles mute on/off;</p>
            <p><strong>[F]</strong> toggles fullscreen on/off (Except IE 11);</p>
            <p>The <strong>[Tab]</strong> key may be used in combination with the <strong>[Enter/Return]</strong> key to navigate and activate control buttons, such as caption on/off.</p>
        </div>
                    
                    
                    <p>Good evening.</p>

<p>On Friday, the Department of Justice served the Federal Reserve with grand jury subpoenas, threatening a criminal indictment related to my testimony before the Senate Banking Committee last June. That testimony concerned in part a multi-year project to renovate historic Federal Reserve office buildings.</p>

<p>I have deep respect for the rule of law and for accountability in our democracy. No one—certainly not the chair of the Federal Reserve—is above the law. But this unprecedented action should be seen in the broader context of the administration's threats and ongoing pressure.</p>

<p>This new threat is not about my testimony last June or about the renovation of the Federal Reserve buildings. It is not about Congress's oversight role; the Fed through testimony and other public disclosures made every effort to keep Congress informed about the renovation project. Those are pretexts. The threat of criminal charges is a consequence of the Federal Reserve setting interest rates based on our best assessment of what will serve the public, rather than following the preferences of the President.</p>

<p>This is about whether the Fed will be able to continue to set interest rates based on evidence and economic conditions—or whether instead monetary policy will be directed by political pressure or intimidation.</p>

<p>I have served at the Federal Reserve under four administrations, Republicans and Democrats alike. In every case, I have carried out my duties without political fear or favor, focused solely on our mandate of price stability and maximum employment. Public service sometimes requires standing firm in the face of threats. I will continue to do the job the Senate confirmed me to do, with integrity and a commitment to serving the American people.</p>

<p>Thank you.</p>
                     
                </div>
        <div>
            <p>Last Update:
                
                            January 11, 2026
                        
            </p>
            
            
        </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I'd tell you a UDP joke… (174 pts)]]></title>
            <link>https://www.codepuns.com/post/805294580859879424/i-would-tell-you-a-udp-joke-but-you-might-not-get</link>
            <guid>46580946</guid>
            <pubDate>Sun, 11 Jan 2026 22:20:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.codepuns.com/post/805294580859879424/i-would-tell-you-a-udp-joke-but-you-might-not-get">https://www.codepuns.com/post/805294580859879424/i-would-tell-you-a-udp-joke-but-you-might-not-get</a>, See on <a href="https://news.ycombinator.com/item?id=46580946">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[This game is a single 13 KiB file that runs on Windows, Linux and in the Browser (273 pts)]]></title>
            <link>https://iczelia.net/posts/snake-polyglot/</link>
            <guid>46580864</guid>
            <pubDate>Sun, 11 Jan 2026 22:14:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://iczelia.net/posts/snake-polyglot/">https://iczelia.net/posts/snake-polyglot/</a>, See on <a href="https://news.ycombinator.com/item?id=46580864">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Not that long ago I became aware of Justine Tunney’s <a href="https://github.com/jart/cosmopolitan">cosmopolitan libc</a> project. It’s a toolkit that allows you to compile C source code into a single binary that runs natively on multiple operating systems, including Windows, Linux, various flavours of BSD, even including booters.</p>
<p>Unfortunately, back then the project didn’t seem to support GUI interfaces and produces quite swollen binaries. Hence I decided to take a stab at a similar (simpler? harder? up to you to decide) challenge: create a video game (&lt;16 KiB) that runs natively on Windows, Linux and in the Browser, all from a single source file.</p>
<h2 id="the-game">The Game<a href="#the-game" arialabel="Anchor">⌗</a> </h2>
<p>It’s a pretty standard Snake game with the same rules and interface on all platforms. You control a snake that grows longer as it eats food, and the goal is to avoid running into walls. The snake is controlled using either the arrow keys or WASD keys. It can be terminated via <code>ESC</code> (if permissible by the platform), reset via <code>R</code>, and paused via <code>P</code>. Spacebar starts the game.</p>
<p>The game keeps track of your score. Each piece of food eaten increases your score by 10 points, except yellow fruit (which spawns with a 15% chance) that gives you 20 points. Fruit spawns at a fixed rate and despawns after a certain time if not eaten. The despawn timer is proportional to the speed of the snake at the time of spawning, which itself is proportional to the snake’s length.</p>
<p>Once ten fruit are eaten, the game proceeds to the next level, randomizing the walls’ layout. The maze is created as to ensure that there is always a path from the snake’s head to any piece of food. The initial placement of the snake is also randomized, but always in a position that has at least five empty tiles in the direction the snake is facing.</p>
<p><a href="https://iczelia.net/static/snake/snake.com"><strong>Download the game here (13,772 bytes)</strong></a>.</p>
<h2 id="the-polyglot">The Polyglot<a href="#the-polyglot" arialabel="Anchor">⌗</a> </h2>
<p>I implemented the game three times in total: once in C for the i686 Visual C platform using WinAPI, once in C for the x86_64 Linux platform using clang and X11, and once in JavaScript for the browser using HTML5 Canvas. Each implementation is around 3-5 KiB in size when compiled/minified.</p>
<p>The Windows implementation was produced using a compressing script that prepends a decompressing stub. This stub has a quite unusual PE header that has many freely controllable bytes after the <code>MZ</code> signature. This allows us to place a shell script there that skips over the remainder of the file, rendering the (valid) PE executable runnable on Windows while also making the entire file a valid shell script, that will do (thus far) nothing on Linux.</p>
<p>Because the PE file is so awkward, we rely on Windows’ apphelp mechanism. Without compatibility mode, executing for the first time will yield the message:</p>
<blockquote>
<p>“The application was unable to start correctly (0xc0000005). Click OK to close the application.”</p>
</blockquote>
<p>Which should disappear after re-running.</p>
<p>The Linux implementation was produced using a similar approach; we use <code>lzma</code> for decompression and a small shell dropper that extracts the compressed ELF64 binary and runs it, skipping over the head and the tail of the file.</p>
<p>The HTML version is also packed and abuses the fact that browsers will happily process all the benign garbage at the start of the file before reaching the actual HTML content. Then we make it invisible/unobtrusive through a bit of CSS magic.</p>
<p>Finally, we concatenate all three files together in such an order that each platform will pick the correct part of the file to execute. The final file is exactly 13,312 bytes in size.</p>
<h2 id="technical-details">Technical Details<a href="#technical-details" arialabel="Anchor">⌗</a> </h2>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The next two years of software engineering (265 pts)]]></title>
            <link>https://addyosmani.com/blog/next-two-years/</link>
            <guid>46580703</guid>
            <pubDate>Sun, 11 Jan 2026 22:00:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://addyosmani.com/blog/next-two-years/">https://addyosmani.com/blog/next-two-years/</a>, See on <a href="https://news.ycombinator.com/item?id=46580703">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="post-body">
        <p>The software industry sits at a strange inflection point. AI coding has evolved from autocomplete on steroids to agents that can autonomously execute development tasks. The economic boom that fueled tech’s hiring spree has given way to an efficiency mandate: companies now often favor profitability over growth, experienced hires over fresh graduates, and smaller teams armed with better tools.</p>

<p>Meanwhile, a new generation of developers is entering the workforce with a different calculus: pragmatic about career stability, skeptical of hustle culture, and raised on AI assistance from day one.</p>

<p>What happens next is genuinely uncertain. Below are five critical questions that may shape software engineering through 2026, with two contrasting scenarios for each. These aren’t really predictions, but lenses for preparation. The goal is a clear roadmap for handling what comes next, grounded in current data and tempered by the healthy skepticism this community is known for.</p>

<hr>

<h2 id="1-the-junior-developer-question">1. The Junior developer question</h2>

<p><strong>The bottom line: Junior developer hiring could collapse as AI automates entry-level tasks, or rebound as software spreads into every industry. Both futures require different survival strategies.</strong></p>

<p>The traditional pathway of “learn to code, get junior job, grow into senior” is wobbling. A <a href="https://www.finalroundai.com/blog/ai-is-making-it-harder-for-junior-developers-to-get-hired">Harvard study of 62 million workers</a> found that when companies adopt generative AI, junior developer employment drops by about 9-10% within six quarters, while senior employment barely budges. <a href="https://restofworld.org/2025/engineering-graduates-ai-job-losses/">Big tech hired 50% fewer fresh graduates</a> over the past three years. As <a href="https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html">one engineer cynically put it</a>: ~”Why hire a junior for $90K when an AI coding agent costs less?”</p>

<p>This isn’t just AI. <a href="https://www.2ndorderthinkers.com/p/are-junior-level-jobs-really-killed">Macro factors like rising interest rates and post-pandemic corrections</a> hit around 2022, before AI tools became widespread. But AI has accelerated the trend. A single senior engineer with AI assistance can now produce what used to require a small team. Companies are quietly not hiring juniors more than they’re firing anyone.</p>

<p>The flip scenario: AI unlocks massive demand for developers across every industry, not just tech. Healthcare, agriculture, manufacturing, and finance all start embedding software and automation. Rather than replacing developers, AI becomes a force multiplier that spreads development work into domains that never employed coders. We’d see more entry-level roles, just different ones: “AI-native” developers who quickly build automations and integrations for specific niches.</p>

<p>The <a href="https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html">Bureau of Labor Statistics still projects ~15% growth</a> in software jobs from 2024 to 2034. If businesses use AI to expand output rather than strictly cut headcount, <a href="https://www.2ndorderthinkers.com/p/are-junior-level-jobs-really-killed">they’ll need humans to seize the opportunities AI creates</a>.</p>

<p>The long-term risk of the pessimistic scenario is often overlooked: today’s juniors are tomorrow’s senior engineers and tech leaders. Cut off the talent pipeline entirely and you create a leadership vacuum in 5-10 years. <a href="https://www.finalroundai.com/blog/ai-is-making-it-harder-for-junior-developers-to-get-hired">Industry veterans call this the “slow decay”</a>: an ecosystem that stops training its replacements.</p>

<p><strong>What to do about it:</strong></p>

<p><em>Junior developers:</em> Make yourself AI-proficient and versatile. Demonstrate that one junior plus AI can match a small team’s output. Use AI coding agents (Cursor/Antigravity/Claude Code/Gemini CLI) to build bigger features, but understand and explain every line if not most. Focus on skills AI can’t easily replace: communication, problem decomposition, domain knowledge. Look at adjacent roles (QA, DevRel, data analytics) as entry points. Build a portfolio, especially projects integrating AI APIs. Consider apprenticeships, internships, contracting, or open source. Don’t be “just another new grad who needs training”; be an immediately useful engineer who learns quickly.</p>

<p><em>Senior developers:</em> Fewer juniors means more grunt work landing on your plate. Lean on automation for routine tasks, but don’t do everything yourself. Set up CI/CD, linters, and AI-assisted testing to catch basic issues. Mentor unofficially through open source or coaching colleagues in other departments. <a href="https://www.finalroundai.com/blog/ai-is-making-it-harder-for-junior-developers-to-get-hired">Be frank with management about the risks of all-senior teams</a>. If junior demand rebounds, be ready to onboard effectively and delegate in ways that use AI. Your value is in multiplying the whole team’s output, not just your own code.</p>

<hr>

<h2 id="2-the-skills-question">2. The Skills question</h2>

<p><strong>The bottom line: Core programming skills could atrophy as AI writes most code, or become more critical than ever as human developers focus on oversight. The coming years determine whether we trade understanding for speed.</strong></p>

<p><a href="https://stackoverflow.blog/2025/09/10/ai-vs-gen-z/">84% of developers now use AI assistance regularly</a>. For many, the first instinct when facing a bug or new feature isn’t to write code from scratch, but to compose a prompt and stitch together AI-generated pieces. Entry-level coders are skipping the “hard way”: they might never build a binary search tree from scratch or debug a memory leak on their own.</p>

<p>The skillset is shifting from implementing algorithms to knowing how to ask the AI the right questions and verify its output. <a href="https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html">The first rung of the ladder now demands prompting and validating AI</a> rather than demonstrating raw coding ability. Some senior engineers worry this produces a generation who can’t code well independently, a kind of deskilling. AI-generated code introduces subtle bugs and security vulnerabilities that less-experienced developers might miss.</p>

<p>The counter-scenario: as AI handles the routine 80%, humans focus on the hardest 20%. Architecture, tricky integrations, creative design, edge cases: the problems machines alone can’t solve. Rather than making deep knowledge obsolete, AI’s ubiquity makes human expertise more important than ever. This is the “high-leverage engineer” who uses AI as a force multiplier but must deeply understand the system to wield it effectively.</p>

<p>If everyone has AI coding agent access, what distinguishes great developers is knowing when the AI is wrong or suboptimal. <a href="https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html">As one senior engineer put it</a>: “The best software engineers won’t be the fastest coders, but those who know when to distrust AI.”</p>

<p>Programming shifts: less typing boilerplate, more reviewing AI output for logical errors, security flaws, and mismatches with requirements. Critical skills become software architecture, system design, performance tuning, and security analysis. <a href="https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html">AI can produce a web app quickly, but an expert engineer ensures the AI followed security best practices</a> and didn’t introduce race conditions.</p>

<p>Developer discourse in 2025 was split. Some admitted they hardly ever write code “by hand” and think coding interviews should evolve. Others argued that skipping fundamentals leads to more firefighting when AI’s output breaks. <a href="https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html">The industry is starting to expect engineers to bring both</a>: AI speed and foundational wisdom for quality.</p>

<p><strong>What to do about it:</strong></p>

<p><em>Junior developers:</em> Use AI as a learning tool, not a crutch. When AI coding agents (Cursor/Antigravity/Claude Code/Gemini CLI) suggest code review why it works, identify weaknesses. Occasionally disable your AI helper and write key algorithms from scratch. Prioritize CS fundamentals: data structures, algorithms, complexity, memory management. Implement projects twice, once with AI, once without, and compare. Learn prompt engineering and tool mastery. Train yourself in rigorous testing: write unit tests, read stack traces without immediately asking AI, get comfortable with debuggers. Deepen complementary skills AI can’t replicate: system design, user experience intuition, concurrency reasoning. Show you can both crank out solutions with AI and tackle thorny issues when it fails.</p>

<p><em>Senior developers:</em> Position yourself as the guardian of quality and complexity. Sharpen your core expertise: architecture, security, scaling, domain knowledge. Practice modeling systems with AI components and think through failure modes. Stay current on vulnerabilities in AI-generated code. Embrace your role as mentor and reviewer: define where AI use is acceptable and where manual review is mandatory (payment or safety code). Lean into creative and strategic work; let the junior+AI combo handle routine API hookups while you decide which APIs to build. Invest in soft skills and cross-domain knowledge. Stay current on new tools and best practices. Double down on what makes a human developer indispensable: sound judgment, system-level thinking, and mentorship.</p>

<hr>

<h2 id="3-the-role-question">3. The Role question</h2>

<p><strong>The bottom line: The developer role could shrink into limited auditing (overseeing AI-generated code) or expand into a pivotal orchestrator position designing and governing AI-driven systems. Either way, adding value means more than just coding.</strong></p>

<p>The extremes here are stark. In one vision, developers see their creative responsibilities diminished. Rather than building software, they mostly audit and babysit AI outputs. AI systems (or “citizen developers” using no-code platforms) handle production; human developers review auto-generated code, check for errors, bias, or security issues, and approve deployments. Maker becomes checker. The joy of code creation replaced by the anxiety of risk management.</p>

<p>There are reports of engineers spending more time evaluating AI-generated pull requests and managing automated pipelines, less time crafting code from scratch. Programming feels less like creative problem-solving and more like compliance. As one engineer lamented: “I don’t want to end up as a code janitor, cleaning up what the AI throws over the wall.”</p>

<p>The alternative future is far more interesting: developers evolve into high-level orchestrators, combining technical, strategic, and ethical responsibilities. AI “workers” mean human developers take on an architect or general contractor role, designing the overall system, deciding which tasks go to which AI or software component, weaving solutions from many moving parts.</p>

<p><a href="https://www.cio.com/article/4062024/demand-for-junior-developers-softens-as-ai-takes-over.html">A CEO of a low-code platform articulated this vision</a>: in an “agentic” development environment, engineers become “composers,” orchestrating ensembles of AI agents and software services. They won’t write every note themselves, but they define the melody: architecture, interfaces, how agents interact. This role is interdisciplinary and creative: part software engineer, part system architect, part product strategist.</p>

<p>The optimistic take: as AI handles rote work, developer roles shift toward higher-value activities by necessity. Jobs may become more interesting. Someone has to decide what the AI should build, verify the product makes sense, and continuously improve it.</p>

<p>Which way it goes may depend on how organizations choose to integrate AI. Companies that see AI as labor replacement might trim dev teams and ask remaining engineers to keep automations running. Companies that see AI as a way to amplify their teams might keep headcounts similar but have each engineer deliver more ambitious projects.</p>

<p><strong>What to do about it:</strong></p>

<p><em>Junior developers:</em> Seek opportunities beyond just writing code. Volunteer for test case writing, CI pipeline setup, or application monitoring: skills aligned with an auditor/custodian role. Keep your creative coding alive through personal projects so you don’t lose the joy of building. Develop a systems mindset: learn how components communicate, what makes APIs well-designed. Read engineering blogs and case studies of system designs. Familiarize yourself with AI and automation tools beyond code generation: orchestration frameworks, AI APIs. Improve communication skills, written and verbal. Write documentation as if explaining to someone else. Ask senior colleagues not just “Does my code work?” but “Did I consider the right things?” Prepare to be verifier, designer, and communicator, not just coder.</p>

<p><em>Senior developers:</em> Lean into leadership and architectural responsibilities. Shape the standards and frameworks that AI and junior team members follow. Define code quality checklists and ethical AI usage policies. Stay current on compliance and security topics for AI-produced software. Focus on system design and integration expertise; volunteer to map data flows across services and identify failure points. Get comfortable with orchestration platforms (Kubernetes, Airflow, serverless frameworks, agent orchestration tools). Double down on your role as technical mentor: more code reviews, design discussions, technical guidelines. Hone your ability to quickly assess someone else’s (or something’s) code and give high-level feedback. Develop product and business sense; understand why features get built and what customers care about. Shadow a product manager or join customer feedback sessions. Protect your creative passion through prototypes, hackathons, or emerging tech research. Evolve from coder to conductor.</p>

<hr>

<h2 id="4-the-specialist-vs-generalist-question">4. The Specialist vs. Generalist question</h2>

<p><strong>The bottom line: Narrow specialists risk finding their niche automated or obsolete. The fast-changing, AI-infused landscape rewards T-shaped engineers: broad adaptability with one or two deep skills.</strong></p>

<p>Given how quickly models, tools and frameworks rise and fall, betting your career on a single technology stack is risky. A guru in a legacy framework might suddenly find themselves in less demand when a new AI tool handles that tech with minimal human intervention. Developers who specialize narrowly in “a single stack, framework or product area” might wake up to find that area declining or redundant.</p>

<p>Think of COBOL developers, Flash developers, or mobile game engine specialists who didn’t pivot when the industry moved. What’s different now is the pace of change. AI automation can make certain programming tasks trivial, undercutting roles that revolved around those tasks. A specialist who only knows one thing (fine-tuning SQL queries, slicing Photoshop designs into HTML) could find AI handling 90% of that work.</p>

<p>Hiring managers chase the newest niche. A few years ago everyone wanted cloud infrastructure specialists; now there’s a surge in AI/ML engineers. Those who specialized narrowly in yesterday’s technology feel stalled as that niche loses luster.</p>

<p>The opposite outcome is specialization in a new form: the “versatile specialist” or <a href="https://www.youtube.com/watch?v=IMHneaMO-dg">T-shaped developer</a>. Deep expertise in one or two areas (the vertical stroke), broad familiarity with many others (the horizontal stroke). <a href="https://medium.com/nerd-for-tech/beyond-full-stack-the-rise-of-the-t-shaped-developer-a4afd757d976">These engineers become the “glue” in multidisciplinary teams</a>; they communicate with specialists of other stripes and fill gaps when needed.</p>

<p><a href="https://medium.com/nerd-for-tech/beyond-full-stack-the-rise-of-the-t-shaped-developer-a4afd757d976">Companies no longer want developers who are either too shallow or too narrowly focused</a>; they want a strong core competency plus ability to work across the stack. Part of the reason is efficiency: a T-shaped engineer can often solve problems end-to-end without waiting on handoffs. Part is innovation: cross-pollination of knowledge leads to better solutions.</p>

<p>AI tools actually augment generalists more, making it easier for one person to handle multiple components. A back-end engineer can rely on AI help to create a reasonable UI; a front-end specialist can have AI generate server boilerplate. An AI-rich environment lets people operate more broadly. Meanwhile, deep specialists might find their niche partly automated with no easy way to branch out.</p>

<p><a href="https://medium.com/nerd-for-tech/beyond-full-stack-the-rise-of-the-t-shaped-developer-a4afd757d976">Nearly 45% of engineering roles now expect proficiency in multiple domains</a>: programming plus cloud infrastructure knowledge, or front-end plus some ML familiarity.</p>

<p><strong>What to do about it:</strong></p>

<p><em>Junior developers:</em> Establish a broad foundation early. Even if hired for a specific role, peek outside that silo. If you’re doing mobile, learn backend basics; if you’re doing front-end, try writing a simple server. Learn the deployment process and tools like Docker or GitHub Actions. Identify one or two areas that genuinely excite you and go deeper: this becomes your vertical expertise. Brand yourself as a hybrid: “full-stack developer with cloud security focus” or “frontend developer with UX expertise.” Use AI tools to learn new domains quickly; when you’re a novice in backend, have ChatGPT generate starter API code and study it. Build the habit of continuous re-skilling. Participate in hackathons or cross-functional projects to force yourself into generalist mode. Tell your manager you want exposure to different parts of the project. Adaptability is a superpower early in your career.</p>

<p><em>Senior developers:</em> Map your skill graph: what are you expert in, what related domains have you only touched superficially? Pick one or two adjacent domains and commit to becoming conversant. If you’re a back-end database specialist, get comfortable with a modern front-end framework or learn ML pipeline basics. Do a small project in your weak area with AI assistance. Integrate your deep expertise with new contexts; if you specialize in web app performance, explore how those skills apply to ML inference optimization. Advocate for or design your role to be more cross-functional. Volunteer to be the “integration champion” for projects touching multiple areas. Mentor others to spread skills around while picking up something from them in return. Update your resume to reflect versatility. Use your experience to identify patterns and transferable knowledge. Become the T-shaped role model: deep in your specialty (giving authority and confidence) but actively stretching horizontally.</p>

<hr>

<h2 id="5-the-education-question">5. The Education question</h2>

<p><strong>The bottom line: Will a CS degree remain the gold standard, or will faster learning paths (bootcamps, online platforms, employer training) overtake it? Universities may struggle to keep up with an industry that changes every few months.</strong></p>

<p>A four-year computer science degree has long been the primary ticket into software roles. But that tradition is being questioned.</p>

<p>One future: universities remain important but struggle to stay relevant. Degrees stay the default credential, but programs lag behind rapidly evolving needs, hampered by slow curriculum update cycles and bureaucratic approval processes. Students and employers feel academia is disconnected from industry, teaching theory or outdated practice that doesn’t translate to job skills.</p>

<p>Recent grads report never learning about cloud computing, modern DevOps, or AI tooling during their degree. If universities demand high time and financial investment while delivering low-relevance education, they risk being seen as expensive gatekeepers. But many companies still require a bachelor’s degree out of inertia, so the burden shifts to students to fill the gap with bootcamps, online courses, and self-taught projects.</p>

<p><a href="https://campustechnology.com/articles/2025/10/21/solving-the-talent-crisis-starts-in-higher-ed.aspx">Student loan debt is enormous, and companies spend billions training new grads</a> because those grads lack skills needed in the workplace. Universities might add an AI ethics class here, a cloud computing elective there, but by the time they implement something, industry tools have moved on.</p>

<p>The disruptive scenario: traditional education gets increasingly replaced by new systems. Coding bootcamps, online certifications, self-taught portfolios, employer-created training academies. Many high-profile employers (Google, IBM) have dropped degree requirements for certain technical roles. <a href="https://campustechnology.com/articles/2025/10/21/solving-the-talent-crisis-starts-in-higher-ed.aspx">In 2024, nearly 45% of companies planned to eliminate bachelor’s degree requirements</a> for at least some positions.</p>

<p>Bootcamps have matured. They produce grads who get hired at top companies alongside CS grads. These programs are shorter (12-week intensive) and focus on practical skills: current frameworks, cloud services, teamwork. The hiring currency is shifting toward live portfolios, micro-credentials, and verified skills. A strong GitHub portfolio or recognized certification can bypass degree requirements.</p>

<p>Employer-driven education is emerging: companies creating their own training pipelines or partnering with bootcamps. Some big tech companies have started internal “universities” for non-traditional candidates. AI itself offers new ways to learn: AI tutors, interactive coding sandboxes, personalized instruction outside university settings.</p>

<p>A modular ecosystem of learning is far more accessible than an expensive four-year degree. A kid in a country without strong CS universities can take the same Coursera courses and build the same portfolio as someone in Silicon Valley.</p>

<p><strong>What to do about it:</strong></p>

<p><em>Aspiring/junior developers:</em> If in a traditional CS program, don’t rely on it exclusively. Augment coursework with real-world projects: build a web app, contribute to open source. Seek internships or co-ops. If your curriculum misses hot topics, learn them through online platforms. Earn industry-recognized certifications (GCP, AWS, Azure) to signal practical knowledge. If self-teaching or in a bootcamp, focus on a compelling portfolio: at least one substantial project with good documentation. Be active in the developer community: contribute to open source, write technical posts. Network through LinkedIn, meetups, dev events. Get an experienced developer to vouch for you. Keep learning continuously; the half-life of technical skills is short. Use AI as your personal tutor. Prove your skills in concrete ways: portfolio, certification, and ability to talk intelligently about your work will open doors.</p>

<p><em>Senior developers and leaders:</em> Your credential alone won’t carry you forever. Invest in continuous education: online courses, workshops, conferences, certifications. Validate your skills in new ways; be prepared for interviews that assess current competency through real problems. Maintain side projects with new tech. Reassess job requirements: do you really need a new hire to have a CS degree, or do you need certain skills and learning ability? Push for skills-first hiring to widen your talent pool. Support internal training programs or apprenticeship-style roles. Champion mentorship circles for junior devs without formal backgrounds. Engage with academia and alternatives: advisory boards, guest lectures, feedback on curriculum gaps. Reflect this in your own career growth: real-world achievements and continuous learning matter more than additional degrees.</p>

<hr>

<h2 id="the-through-line">The Through-Line</h2>

<p>These scenarios aren’t mutually exclusive. Reality will draw elements from all of them. Some companies will reduce junior hiring while others expand it in new domains. AI will automate routine coding while raising standards for the code humans touch. Developers might spend mornings reviewing AI outputs and afternoons crafting high-level architecture.</p>

<p>The consistent thread: change is the only constant. By keeping a finger on technology trends (and skepticism around them), you avoid being caught off-guard by hype or doom. By updating skills, diversifying abilities, and focusing on uniquely human aspects (creativity, critical thinking, collaboration) you remain in the loop.</p>

<p>Whether the future brings a coding renaissance or a world where code writes itself, there will always be demand for engineers who think holistically, learn continuously, and drive technology toward solving real problems.</p>

<p>The best way to predict the future is to actively engineer it.</p>

    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[2026 is the year of self-hosting (696 pts)]]></title>
            <link>https://fulghum.io/self-hosting</link>
            <guid>46580326</guid>
            <pubDate>Sun, 11 Jan 2026 21:29:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fulghum.io/self-hosting">https://fulghum.io/self-hosting</a>, See on <a href="https://news.ycombinator.com/item?id=46580326">Hacker News</a></p>
<div id="readability-page-1" class="page">
    
    <p>by <a href="https://fulghum.io/">Jordan Fulghum</a>, January 2026</p>

    <p><em>Your home server's new sysadmin: Claude Code</em></p>

    <p>I have flirted with self-hosting at home for years. I always bounced off it - too much time spent configuring instead of using. It just wasn't fun.</p>

    <p>That changed recently. The reason is simple: CLI agents like <a href="https://claude.com/claude-code" target="_blank" rel="noopener noreferrer">Claude Code</a> make self-hosting on a cheapo home server dramatically easier and actually fun.</p>

    <p>This is the first time I would recommend it to normie/software-literate people who never really wanted to sign up to become a sysadmin and stress about uptime of core personal services.</p>

    <h2>Why now is different</h2>

    <p>Three things converged:</p>

    <table>
        <tbody><tr>
            <th>Shift</th>
            <th>Why it matters</th>
        </tr>
        <tr>
            <td>Cheap, capable mini PCs</td>
            <td>You can buy a silent, low-power Linux box for less than a weekend trip</td>
        </tr>
        <tr>
            <td>Tailscale</td>
            <td>Secure networking without port forwarding or networking brain damage</td>
        </tr>
        <tr>
            <td>Claude Code</td>
            <td>You no longer need to remember Docker syntax, Compose quirks, or config formats</td>
        </tr>
    </tbody></table>

    <p>The last one is the real unlock.</p>

    <p>Instead of Googling "docker compose vaultwarden caddy reverse proxy" and stitching together five blog posts from 2021, I just let Claude figure out (up to you how much you care to really understand the technical details!).</p>

    <h2>The hardware</h2>

    <div>
        <video controls="" preload="metadata" playsinline=""><source src="https://fulghum.io/beelink.mp4" type="video/mp4"></video>
        <p>Fits in one hand. Check that central cooling unit!</p>
    </div>

    <p>I previously ran my Plex server on an M1 Mac mini, which was great, but as I wanted to add more services I found myself running a lot of resource-hungry VMs (via UTM) and it was getting complicated anytime the Mac rebooted. So, I picked up a <a href="https://www.bee-link.com/products/beelink-me-mini-n150" target="_blank" rel="noopener noreferrer">Beelink Mini N150</a>. It is small, quiet, and just barely sips power. I paid around $379 for the device and another few hundred USD for 8TB in NVMe SSD. It's pretty wild how accessible these mini PCs have become in recent years!</p>

    <h2>The basic flow</h2>

    <p>This is the entire workflow:</p>

    <table>
        <tbody><tr>
            <th>Step</th>
            <th></th>
        </tr>
        <tr>
            <td>Install Linux</td>
            <td>Flash USB, install Ubuntu Server (I picked 22.04 LTS) </td>
        </tr>
        <tr>
            <td>Install Tailscale</td>
            <td>Get it on your private network to make your life easier</td>
        </tr>
        <tr>
            <td>SSH in</td>
            <td>From my laptop, anywhere</td>
        </tr>
        <tr>
            <td>Install Claude Code</td>
            <td>On the server itself</td>
        </tr>
        <tr>
            <td>Ask for what I want</td>
            <td>Go get a coffee</td>
        </tr>
    </tbody></table>



    <h2>Claude Code is your new sysadmin</h2>

    <p>This is the part that surprised me. I've been using Claude Code and other agentic CLIs for my day-to-day development, but as others are realizing, they are generalized computer agents and native to the terminal.</p>

    <p>I installed Claude Code directly on the Linux box. Then I asked it things like:</p>

    <ul>
        <li>Set up Docker</li>
        <li>Create a Docker Compose file</li>
        <li>Install a service</li>
        <li>Put services behind Caddy</li>
        <li>Persist data properly</li>
        <li>Keep my Docker images up to date</li>
        <li>Set up reasonable security packages</li>
        <li>Restart on boot so I never have to futz with it after an outage</li>
    </ul>

    <div>
        <p><img src="https://fulghum.io/claude-code.png" alt="Claude Code running on the Linux server via SSH"></p><p>Claude Code running directly on the server. Just describe what you want.</p>
    </div>

    <p>I didn't copy-paste YAML from the internet or have to do deep googling. I just asked.</p>

    <h2>What's running</h2>

    <p>I focused on things I already used, but wanted more control over - effectively starting to knock down the walled garden around my core services like passwords, photos, media.</p>

    <table>
        <tbody><tr>
            <th>Service</th>
            <th>What it replaces or does</th>
        </tr>
        <tr>
            <td><a href="https://github.com/dani-garcia/vaultwarden" target="_blank" rel="noopener noreferrer">Vaultwarden</a></td>
            <td>Bitwarden, but self-hosted and fast</td>
        </tr>
        <tr>
            <td><a href="https://plex.tv/" target="_blank" rel="noopener noreferrer">Plex</a></td>
            <td>Media server - PSA get Plex Pass to unlock hardware-accelerated transcoding</td>
        </tr>
        <tr>
            <td><a href="https://immich.app/" target="_blank" rel="noopener noreferrer">Immich</a></td>
            <td>Google Photos replacement</td>
        </tr>
        <tr>
            <td><a href="https://github.com/louislam/uptime-kuma" target="_blank" rel="noopener noreferrer">Uptime Kuma</a></td>
            <td>Simple service monitoring</td>
        </tr>
        <tr>
            <td><a href="https://caddyserver.com/" target="_blank" rel="noopener noreferrer">Caddy</a></td>
            <td>Reverse proxy with automatic TLS</td>
        </tr>
        <tr>
            <td><a href="https://www.home-assistant.io/" target="_blank" rel="noopener noreferrer">Home Assistant</a></td>
            <td>Home automation hub</td>
        </tr>
        <tr>
            <td><a href="https://readeck.org/en/" target="_blank" rel="noopener noreferrer">ReadDeck</a></td>
            <td>Read-it-later. Honestly blown away by this one!</td>
        </tr>
    </tbody></table>

    <p>Each one lives in its own container.</p>

    <p>I can access everything from my phone, laptop, and tablet like it is local.</p>

    <div>
        <p><img src="https://fulghum.io/uptime-kuma.png" alt="Uptime Kuma dashboard showing service monitoring"></p><p>Uptime Kuma keeping an eye on everything.</p>
    </div>

    <div>
        <p><img src="https://fulghum.io/monitor.png" alt="Email inbox showing service up/down alerts"></p><p>Automatic alerts via email give me peace of mind.</p>
    </div>

    <p>When something goes down, I get an email. When it comes back up, another email. No pager duty, no complex alerting rules. Just a simple ping that tells me if I need to care.</p>

    <h3>Vaultwarden as the anchor</h3>

    <p>Vaultwarden was kinda the "okay, this can work" moment.</p>

    <p>It is a Bitwarden-compatible server written in Rust. Lightweight, reliable, and you can use the existing Bitwarden clients (like native apps and browser extensions). You can even set it as the default password manager on iOS, at the OS level!</p>

    <p>Once that was running, I exported my passwords from iCloud/Keychain, imported them easily into Vaultwarden, and haven't looked back since.</p>

    <p>That alone justified the box.</p>

    <h3>Immich is actually great</h3>

    <p>Immich is a serious Google Photos replacement. I thought I'd have to compromise and flinched a bit when I installed it. But nope, it's good. Mobile apps. Face recognition via a local (but slow) machine learning thread. Timeline and map view. Automatic uploads from your photo roll.</p>

    <div>
        <p><img src="https://fulghum.io/immich.png" alt="Immich photo timeline interface"></p><p>Immich. This is not a compromise. This is better.</p>
    </div>

    <p>This is the kind of thing that used to feel fragile and half-baked when self-hosted. It does not anymore.</p>

    <h3>ReadDeck fills the Pocket-shaped hole</h3>

    <p>Mozilla killed Pocket. I needed a replacement.</p>

    <p>I took a bet on ReadDeck. The UI is genuinely good. Clean typography, nice reading experience, good mobile support. It always remembers where I stopped reading and takes me right there. I even set up a shortcut that allows me to save an article for later right from mobile Firefox. Awesome.</p>

    <div>
        <p><img src="https://fulghum.io/read-deck.png" alt="ReadDeck interface showing saved articles"></p><p>ReadDeck. No lock-in nor surprise sunsetting.</p>
    </div>

    <p>This is exactly the kind of thing self-hosting is perfect for. A small, personal tool that you actually use every day.</p>

    <h2>Utilities for fun</h2>
    <h3>Lazydocker</h3>

    <p><a href="https://github.com/jesseduffield/lazydocker" target="_blank" rel="noopener noreferrer">Lazydocker</a> is a terminal UI for Docker. It shows you all your containers, logs, stats, and lets you restart or shell into anything with a few keystrokes.</p>

    <p>I have been a huge fan of <a href="https://github.com/jesseduffield/lazygit" target="_blank">Lazygit</a> for some time. I think it's one of the best UIs I've ever used. So I was excited to learn that Lazydocker is basically that, but for monitoring Docker containers. No memorizing <code>docker ps</code> flags or grepping through logs. Just SSH in, type <code>lazydocker</code>, and everything is right there.</p>

    <div>
        <p><img src="https://fulghum.io/lazydocker.png" alt="Lazydocker terminal UI showing running containers"></p><p>You feel like a superhero after you ssh in and see this</p>
    </div>

    <h3>Utilization</h3>
    <p>For a fuller picture, <a href="https://github.com/nicolargo/glances" target="_blank" rel="noopener noreferrer">Glances</a> shows everything at once: CPU, memory, disk, network, and all running containers.</p>

    <div>
        <p><img src="https://fulghum.io/glances.png" alt="Glances system monitor showing CPU, memory, and container stats"></p><p>Glances showing the whole picture. 13 containers, 6% CPU, 32% memory. This little box barely breaks a sweat.</p>
    </div>

    <p>That is 13 services running on a $379 mini PC, using about 4 GB of RAM and almost no CPU. The N150 is not a powerhouse, but it does not need to be.</p>

    <h2>What it 'feels' like</h2>

    <p>This does not feel like "running a server."</p>

    <p>The feeling of ownership is powerful, but a bit hard to describe. I think you just have to try it, and I hope you get a strong feeling of <em>independence</em> like I have.</p>

    <p>When something breaks, I SSH in, ask the agent what is wrong, and fix it. When I want to add something new, I describe it in plain English.</p>

    <p>I am spending time using software, learning, and having fun - instead of maintaining it and stressing out about it.</p>

    <h2>Who this is for</h2>

    <p>This is for people who:</p>

    <ul>
        <li>Are comfortable in a terminal</li>
        <li>Already pay for SaaS tools</li>
        <li>Like understanding how things work</li>
        <li>Do not want to become infra experts</li>
    </ul>

    <p>If that is you, I really think this is the year to try self-hosting.</p>

    <p>For the first time, I would say this is not just viable. It is fun.</p>

    <hr>

    <p>Follow me on <a href="https://x.com/jordanful" target="_blank" rel="noopener noreferrer">Twitter</a> for more.</p>

    

    


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[FUSE is All You Need – Giving agents access to anything via filesystems (194 pts)]]></title>
            <link>https://jakobemmerling.de/posts/fuse-is-all-you-need/</link>
            <guid>46580136</guid>
            <pubDate>Sun, 11 Jan 2026 21:12:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakobemmerling.de/posts/fuse-is-all-you-need/">https://jakobemmerling.de/posts/fuse-is-all-you-need/</a>, See on <a href="https://news.ycombinator.com/item?id=46580136">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>Giving agents access to a sandboxed environment with a shell and a filesystem has been the latest hype when it comes to agentic harnesses. Recent examples of this include:</p><ul><li><a href="https://github.com/tursodatabase/agentfs">Turso’s AgentFS</a></li><li>Anthropic’s <a href="https://platform.claude.com/docs/en/agent-sdk/overview">Agent SDK</a>, which brings Claude Code’s harness to non-coding domains</li><li>Vercel <a href="https://vercel.com/blog/we-removed-80-percent-of-our-agents-tools">rebuilding their text-to-SQL agent</a> on top of a sandbox</li><li>Anthropic’s <a href="https://github.com/anthropics/skills">Agent Skills</a> for filesystem-based progressive disclosure</li></ul><p>The argument for why this is good goes something like this:</p><blockquote><p>The big labs are doing heavy RL for coding tasks in these kinds of environments. Aligning more closely with such a harness brings free gains from the coding domain to other problem spaces.</p></blockquote><p>Beyond that, replacing a bunch of search/write/move/list tools with a single Bash tool reduces the tool space significantly. Agents can chain operations together intuitively. Unix paradigms give you good tool design for free.</p><p>On top of that there is more nice patterns that emerge from having a filesystem, for example:</p><ul><li><strong>Plan/scratch files</strong>: Agents can create temporary files to organize their thoughts, track progress, or store intermediate results. This emerges naturally from having filesystem access, no need to design a separate “notepad” tool.</li><li><strong>Long context handling</strong>: As conversations grow, you can compact old messages and tool results into files on the filesystem. The agent can re-read them when needed rather than keeping everything in context.</li></ul><p>So the advantages are clear. But how do you actually apply this to your domain? This is where things get tricky. Consider two examples:</p><ol><li><p><strong>A domain with parallels to filesystems</strong>: For example an agent for organizing emails. There are folders, items (emails), and you can browse them and move things around.</p></li><li><p><strong>An existing platform that already looks like a filesystem</strong>: For example an agent inside Google Drive.</p></li></ol><p>When you try to fit these into a sandboxed filesystem you might wonder:</p><ul><li>When do I copy over the files?</li><li>Do I copy over everything?</li><li>How do I write back updates that the agent made?</li><li>When do I sync edits made by a human?</li><li>How do I show folders/files progressively as the agent progresses? (Particularly useful if you want to lean into the filesystem as a tool to manage long context.)</li></ul><p><a href="https://x.com/SeeLos/status/2009806164935000211?s=20">A reply</a> to a recent post on X from Vercel about building filesystem-based agents puts it well:</p><blockquote><p>This article doesn’t really answer that question though.</p><p>They explain the shape of the filesystem really well, but the missing piece is still the main question for existing apps: how do you actually materialize Postgres + object storage + APIs into that sandbox FS in a practical and scalable way? “Preload files” is hand-wavy without a recommended ingestion/snapshot pattern.</p></blockquote><p>This post will show a pattern to close that gap: turning anything into a filesystem with the help of FUSE.</p><h2 id="an-example-email-agent">An example: Email agent</h2><p>To make this tangible, let’s build a fictional agent.</p><p>Imagine we’re building an AI-powered email platform, think Gmail but with AI on top. We have our own database storing emails, folders, and contacts. We have a UI that users interact with.</p><p>Now we want to add a powerful agent on top of that platform. We could build a simple agent loop with tools like <code>list-emails</code>, <code>move-email</code>, <code>read-email</code>, but as we established there’s a more ergonomic approach: put our emails in a filesystem.</p><p>After some thinking, we come up with the following file layout for the agent’s sandbox:</p><div><pre tabindex="0"><code data-lang="plain"><span><span>workspace/
</span></span><span><span>  Inbox/
</span></span><span><span>    Customer Inquiry - Size Chart (emily.wolfe@gmail.com)
</span></span><span><span>    PO Confirmation #2026-0038 (supplierC@fabricdirect.com)
</span></span><span><span>    Shipping Delay Notice (supplierA@logisticsco.com)
</span></span><span><span>    Partnership Proposal - TrendCircle (marketing@trendcircle.io)
</span></span><span><span>
</span></span><span><span>  Starred/
</span></span><span><span>    Wholesale Inquiry - SilverLeaf Boutique (boutique@silverleaf.co)
</span></span><span><span>    Re: Restock ETA For Red Jackets (supplierA@logisticsco.com)
</span></span><span><span>
</span></span><span><span>  Needs_Action/
</span></span><span><span>    Missing Documents - Customs (carrier-support@airbridge.co)
</span></span><span><span>    Last Call: VAT Filing Deadline (gov-tax@tradeportal.gov)
</span></span><span><span>
</span></span><span><span>  Orders/
</span></span><span><span>    2026/
</span></span><span><span>      Feb/
</span></span><span><span>        PO Confirmation #2026-0038 (supplierC@fabricdirect.com)
</span></span><span><span>        Shipping Delay Notice (supplierA@logisticsco.com)
</span></span><span><span>
</span></span><span><span>  Customers/
</span></span><span><span>    Returns/
</span></span><span><span>      Return Request #8743 (john.hartley@yahoo.com)
</span></span><span><span>
</span></span><span><span>  Sent/
</span></span><span><span>    Re: Customer Inquiry - Size Chart (emily.wolfe@gmail.com)
</span></span></code></pre></div><p>Now comes the problem: we need to bridge the gap from our database to the sandboxed filesystem that the agent uses to consume our data.</p><h2 id="how-to-turn-anything-into-a-fs-enter-fuse">How to turn anything into a FS, enter FUSE</h2><p><a href="https://www.kernel.org/doc/html/v6.3/filesystems/fuse.html">FUSE</a> stands for <em>Filesystem in Userspace</em>. It’s a framework that lets you implement filesystems outside the kernel, while the kernel makes it look like a ‘real’ filesystem to the rest of Linux. You just write a userland process that implements the actual filesystem logic.</p><p>A FUSE filesystem needs to implement a small, well-defined interface: <code>lookup</code>, <code>open</code>, <code>read</code>, <code>write</code>, <code>readdir</code>, <code>create</code>, <code>unlink</code>, etc. Whenever the OS interacts with the mounted filesystem, operations get forwarded to your userspace implementation. This indirection makes it possible to expose arbitrary data structures as if they were files.</p><p>There are wrappers and bindings for higher-level languages that let you write these filesystems in the language and tech stack of your choice. No need to dive into C :)</p><h2 id="architecture">Architecture</h2><p>Coming back to our email agent, here’s how FUSE would fit into a very high-level architecture:</p><p><img alt="Architecture of the email agent" loading="lazy" src="https://jakobemmerling.de/posts/fuse-is-all-you-need/fuse.svg">
The top row shows the traditional path: users interact with your app through a UI that talks to a backend, which reads and writes to a database.</p><p>The bottom row shows the agent path: the agent runs inside a sandbox and sees a mounted filesystem. When it does <code>ls /workspace/Inbox</code>, that call hits the FUSE layer, which translates it into a query against the same backend. The agent and your users are looking at the same data through different interfaces.</p><p>You can think of the filesystem as a UI layer for the agent. Just like your frontend decides how to present data to users, your FUSE implementation decides how to present data to the agent. Realistically you’ll have additional tools for actions that don’t map well to filesystem operations (like sending an email), but for browsing, reading, and organizing data, the filesystem abstraction works great.</p><p>For this blog post we’ll keep things simple: the agent loop and FUSE implementation both run inside a Docker container, talking directly to a database. We are going to implement this in Typescript using the <a href="https://github.com/fuse-friends/fuse-native">fuse-native</a> library. In production you’d want to structure things a bit differently, like running the agent loop outside the sandbox and have your FUSE bindings be only a thin client that calls out to your backend with proper authentication for example.</p><h2 id="implementing-the-filesystem-operations">Implementing the filesystem operations</h2><p>To make our data accessible via the filesystem, we need to implement the subset of FUSE operations relevant for our use case. Let’s start with listing directories (<code>readdir</code>):</p><div><pre tabindex="0"><code data-lang="typescript"><span><span><span>export</span> <span>async</span> <span>function</span> <span>readdir</span>(<span>path</span>: <span>string</span>, <span>cb</span><span>:</span> (<span>err</span>: <span>number</span>, <span>names?</span>: <span>string</span>[]) <span>=&gt;</span> <span>void</span>) {
</span></span><span><span>  <span>const</span> [<span>folder</span>] <span>=</span> <span>await</span> <span>db</span>.<span>select</span>().<span>from</span>(<span>foldersTable</span>).<span>where</span>(<span>eq</span>(<span>foldersTable</span>.<span>path</span>, <span>path</span>));
</span></span><span><span>
</span></span><span><span>  <span>if</span> (<span>!</span><span>folder</span>) {
</span></span><span><span>    <span>return</span> <span>cb</span>(<span>Fuse</span>.<span>ENOENT</span>);
</span></span><span><span>  }
</span></span><span><span>
</span></span><span><span>  <span>const</span> <span>emailsInFolder</span> <span>=</span> <span>await</span> <span>db</span>.<span>select</span>({
</span></span><span><span>    <span>email</span>: <span>emailsTable</span>,
</span></span><span><span>    <span>sender</span>: <span>contactsTable</span>,
</span></span><span><span>  }).<span>from</span>(<span>emailsTable</span>)
</span></span><span><span>  .<span>leftJoin</span>(<span>contactsTable</span>, <span>eq</span>(<span>emailsTable</span>.<span>sender</span>, <span>contactsTable</span>.<span>id</span>))
</span></span><span><span>  .<span>where</span>(<span>eq</span>(<span>emailsTable</span>.<span>folderId</span>, <span>folder</span>.<span>id</span>));
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>  <span>const</span> <span>entries</span> <span>=</span> <span>new</span> <span>Set</span>&lt;<span>string</span>&gt;();
</span></span><span><span>
</span></span><span><span>  <span>for</span> (<span>const</span> {<span>email</span>, <span>sender</span>} <span>of</span> <span>emailsInFolder</span>) {
</span></span><span><span>    <span>entries</span>.<span>add</span>(<span>`</span><span>${</span><span>email</span>.<span>subject</span><span>}</span><span> (</span><span>${</span><span>sender</span>.<span>email</span><span>}</span><span>).eml`</span>);
</span></span><span><span>  }
</span></span><span><span>
</span></span><span><span>  <span>const</span> <span>subfolders</span> <span>=</span> <span>await</span> <span>db</span>.<span>select</span>().<span>from</span>(<span>foldersTable</span>).<span>where</span>(<span>like</span>(<span>foldersTable</span>.<span>path</span>, <span>sql</span><span>`</span><span>${</span><span>path</span><span>}</span><span>/%`</span>));
</span></span><span><span>  <span>for</span> (<span>const</span> <span>subfolder</span> <span>of</span> <span>subfolders</span>) {
</span></span><span><span>    <span>entries</span>.<span>add</span>(<span>subfolder</span>.<span>path</span>.<span>split</span>(<span>"/"</span>).<span>pop</span>() <span>||</span> <span>""</span>);
</span></span><span><span>  }
</span></span><span><span>
</span></span><span><span>  <span>cb</span>(<span>0</span>, Array.<span>from</span>(<span>entries</span>));
</span></span><span><span>}
</span></span></code></pre></div><p>We match which email folder we’re in based on the filesystem path, list all emails inside that folder, and add any subfolders. Together with implementing <code>getattr</code> (to get file attributes), this makes listing and navigating the folder tree via <code>ls</code> work.</p><p>To choose how email content will be represented we implement <code>read</code> like this:</p><div><pre tabindex="0"><code data-lang="typescript"><span><span><span>export</span> <span>async</span> <span>function</span> <span>read</span>(<span>path</span>: <span>string</span>, <span>fd</span>: <span>number</span>, <span>buf</span>: <span>Buffer</span>, <span>len</span>: <span>number</span>, <span>pos</span>: <span>number</span>, <span>cb</span><span>:</span> (<span>err</span>: <span>number</span>) <span>=&gt;</span> <span>void</span>) {
</span></span><span><span>  <span>const</span> <span>email</span> <span>=</span> <span>await</span> <span>getEmailById</span>(<span>fd</span>);
</span></span><span><span>  <span>if</span> (<span>!</span><span>email</span>) {
</span></span><span><span>    <span>return</span> <span>cb</span>(<span>Fuse</span>.<span>ENOENT</span>);
</span></span><span><span>  }
</span></span><span><span>  <span>const</span> <span>content</span> <span>=</span> <span>emailToContent</span>(<span>email</span>);
</span></span><span><span>  <span>const</span> <span>slice</span> <span>=</span> <span>content</span>.<span>slice</span>(<span>pos</span>, <span>pos</span> <span>+</span> <span>len</span>);
</span></span><span><span>  <span>const</span> <span>bytesRead</span> <span>=</span> <span>buf</span>.<span>write</span>(<span>slice</span>);
</span></span><span><span>  <span>cb</span>(<span>bytesRead</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>export</span> <span>function</span> <span>emailToContent</span>(<span>email</span>: <span>EmailWithSender</span>)<span>:</span> <span>string</span> {
</span></span><span><span>  <span>return</span> <span>`From: </span><span>${</span><span>email</span>.<span>senderEmail</span><span>}</span><span>
</span></span></span><span><span><span>Date: </span><span>${</span><span>email</span>.<span>sentAt</span>.<span>toISOString</span>()<span>}</span><span>
</span></span></span><span><span><span>Subject: </span><span>${</span><span>email</span>.<span>subject</span><span>}</span><span>
</span></span></span><span><span><span>X-Folder: </span><span>${</span><span>email</span>.<span>folderPath</span><span>}</span><span>
</span></span></span><span><span><span>X-Starred: </span><span>${</span><span>email</span>.<span>starred</span><span>}</span><span>
</span></span></span><span><span><span>X-Needs-Action: </span><span>${</span><span>email</span>.<span>needsAction</span><span>}</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>${</span><span>email</span>.<span>body</span><span>}</span><span>
</span></span></span><span><span><span>`</span>;
</span></span><span><span>}
</span></span></code></pre></div><p>There are a few more operations I implemented like <code>open</code>, <code>mkdir</code>, and <code>rename</code> to allow moving email files around and reassigning folder IDs in the database.</p><p>On top of that, I introduced the concept of <em>virtual folders</em>—the <code>Starred</code> and <code>Needs_Action</code> folders in the layout above. They work like this: if an email has the starred or needsAction flag set, it appears in these folders. Because an email can be both starred and part of an actual folder, the Starred folder contains symlinks to the “actual” files. The agent can unlink these files or create new links to flip attributes on the email. This might be overkill and better covered via regular tools, but I wanted to see how far I could lean into the filesystem abstraction. For this to work, I implemented additional FUSE operations: <code>readlink</code>, <code>symlink</code>, <code>unlink</code>, and adjusted the existing ones.</p><p>Deciding how to map your domain to a filesystem is really a context engineering challenge in the end. The key is finding the right balance between leveraging familiar filesystem semantics and not over-abstracting to the point where the mapping becomes confusing.</p><p>With all the filesystem operations defined, we’re ready to mount it and see it in action. While it’s possible to get this working on a Mac via <a href="https://macfuse.github.io/">macFUSE</a>, I chose the easier path and spun up a Docker container and mounted the filesystem there.</p><p>Here’s a quick demo of navigating the filesystem. As you can see, it looks and works just like regular files.<code>grep</code>, <code>mv</code>, <code>ls</code> all behave as expected. The best part? There’s no risk of anything going out of sync because we read directly from the database. We also only load the things we needed when they are accessed instead of preloading our entire database into a sandbox.</p><video controls="" width="100%">
<source src="https://jakobemmerling.de/posts/fuse-is-all-you-need/fuse-demo.mp4" type="video/mp4"></video><h2 id="giving-the-agent-access-to-it">Giving the agent access to it</h2><p>Now that we have the filesystem working, it’s time to hook up an agent and see how it performs. I used the Anthropic Agent SDK to whip up a quick filesystem agent with tools to run Bash, Read, Glob, etc. To give the agent some context about the filesystem, I added the following system prompt:</p><div><pre tabindex="0"><code data-lang="plain"><span><span>You are an email assistant helping the user manage their inbox.
</span></span><span><span>
</span></span><span><span>You have access to a filesystem at /workspace representing their email:
</span></span><span><span>
</span></span><span><span>- Folders: Inbox, Sent, Orders, Customers, etc.
</span></span><span><span>- Emails: .eml files named "Subject (sender@email.com).eml"
</span></span><span><span>- Filenames contain spaces (from email subjects), so always quote paths in shell commands
</span></span><span><span>- Starred/Needs_Action: contain symlinks to flagged emails
</span></span><span><span>
</span></span><span><span>Commands you use internally:
</span></span><span><span>- ls, cat, find → browse emails
</span></span><span><span>- mv → move emails between folders
</span></span><span><span>- ln -s &lt;email&gt; /Starred/ → star an email
</span></span><span><span>- rm /Starred/&lt;email&gt; → unstar an email
</span></span><span><span>- mkdir → create folders
</span></span><span><span>
</span></span><span><span>When responding to the user:
</span></span><span><span>- Describe emails by subject and sender, not filenames
</span></span><span><span>- Say "starred" not "created symlink"
</span></span><span><span>- Say "moved to Orders" not "mv to /Orders/"
</span></span><span><span>- Summarize what you found/did in plain language
</span></span></code></pre></div><p>Let’s see how it approaches some common user queries:</p><div><pre tabindex="0"><code data-lang="plain"><span><span>&gt; which emails do i have in my Inbox?
</span></span><span><span>
</span></span><span><span>I'll check your Inbox to see what emails you have.
</span></span><span><span>
</span></span><span><span>[Bash] ls -la /workspace/Inbox/
</span></span><span><span>
</span></span><span><span>You have 6 emails in your Inbox:
</span></span><span><span>
</span></span><span><span>1. **"Missing Documents - Customs"** from carrier-support@airbridge.co (Jan 4)
</span></span><span><span>2. **"PO Confirmation #2026-0038"** from supplierC@fabricdirect.com (Jan 9)
</span></span><span><span>3. **"Partnership Proposal - TrendCircle"** from marketing@trendcircle.io (Jan 7)
</span></span><span><span>4. **"Re: Restock ETA For Red Jackets"** from supplierA@logisticsco.com (Jan 5)
</span></span><span><span>5. **"Shipping Delay Notice"** from supplierA@logisticsco.com (Jan 8)
</span></span><span><span>6. **"Wholesale Inquiry - SilverLeaf Boutique"** from boutique@silverleaf.co (Jan 6)
</span></span><span><span>
</span></span><span><span>Would you like me to read any of these emails or help you organize them?
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="plain"><span><span>&gt; find the email about that wholesale inquiry, i need to remember to follow up on it
</span></span><span><span>
</span></span><span><span>I'll help you find the wholesale inquiry email. Let me search for it.
</span></span><span><span>
</span></span><span><span>[Bash] find /workspace -type f -name "*.eml" -exec grep -l "wholesale" {} \;
</span></span><span><span>
</span></span><span><span>Found it! There's a wholesale inquiry from SilverLeaf Boutique (boutique@silverleaf.co) in your Inbox.
</span></span><span><span>
</span></span><span><span>Would you like me to:
</span></span><span><span>1. Star it so you can easily find it later to follow up?
</span></span><span><span>2. Move it to a specific folder?
</span></span><span><span>3. Show you the email content?
</span></span><span><span>
</span></span><span><span>&gt; show me the email and star it
</span></span><span><span>
</span></span><span><span>[Read] /workspace/Inbox/Wholesale Inquiry - SilverLeaf Boutique (boutique@silverleaf.co).eml
</span></span><span><span>
</span></span><span><span>[Bash] ln -s "/workspace/Inbox/Wholesale Inquiry - SilverLeaf Boutique (boutique@silverleaf.co).eml" /workspace/Starred/
</span></span><span><span>
</span></span><span><span>Here's the email:
</span></span><span><span>
</span></span><span><span>**From:** boutique@silverleaf.co
</span></span><span><span>**Date:** January 6, 2026
</span></span><span><span>**Subject:** Wholesale Inquiry - SilverLeaf Boutique
</span></span><span><span>
</span></span><span><span>**Message:**
</span></span><span><span>"We're a boutique in Portland and interested in carrying your line. What are your wholesale terms?"
</span></span><span><span>
</span></span><span><span>Good news - this email is already starred! It looks like it was already flagged for follow-up. SilverLeaf Boutique is interested in carrying your products and wants to know about your wholesale terms.
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="plain"><span><span>&gt; Organize my Inbox
</span></span><span><span>
</span></span><span><span>I'll help you organize your inbox. Let me first see what emails you have there.
</span></span><span><span>
</span></span><span><span>[Bash] ls -la /workspace/Inbox/
</span></span><span><span>
</span></span><span><span>Now let me check what folders you already have set up:
</span></span><span><span>
</span></span><span><span>[Bash] ls -d /workspace/*/
</span></span><span><span>
</span></span><span><span>Perfect! I can see you have 8 emails in your inbox. Let me organize them into appropriate folders:
</span></span><span><span>
</span></span><span><span>[Bash] mv "/workspace/Inbox/Customer Inquiry - Size Chart (emily.wolfe@gmail.com).eml" /workspace/Customers/
</span></span><span><span>[Bash] mv "/workspace/Inbox/Wholesale Inquiry - SilverLeaf Boutique (boutique@silverleaf.co).eml" /workspace/Customers/
</span></span><span><span>[Bash] mv "/workspace/Inbox/PO Confirmation #2026-0038 (supplierC@fabricdirect.com).eml" /workspace/Orders/
</span></span><span><span>[Bash] mv "/workspace/Inbox/Re: Restock ETA For Red Jackets (supplierA@logisticsco.com).eml" /workspace/Orders/
</span></span><span><span>[Bash] mv "/workspace/Inbox/Shipping Delay Notice (supplierA@logisticsco.com).eml" /workspace/Orders/
</span></span><span><span>Now let me flag the urgent items that need action:
</span></span><span><span>[Bash] ln -s "/workspace/Inbox/Last Call: VAT Filing Deadline (gov-tax@tradeportal.gov).eml" /workspace/Needs_Action/
</span></span><span><span>[Bash] ln -s "/workspace/Inbox/Missing Documents - Customs (carrier-support@airbridge.co).eml" /workspace/Needs_Action/
</span></span><span><span>
</span></span><span><span>Good - those urgent items are already flagged. Now let me check if the partnership proposal might be something to consider:
</span></span><span><span>
</span></span><span><span>[Bash] cat "/workspace/Inbox/Partnership Proposal - TrendCircle (marketing@trendcircle.io).eml"
</span></span><span><span>
</span></span><span><span>Let me create a folder for business opportunities and move the partnership proposal there:
</span></span><span><span>
</span></span><span><span>[Bash] mkdir -p /workspace/Business_Opportunities &amp;&amp; mv "/workspace/Inbox/Partnership Proposal - TrendCircle (marketing@trendcircle.io).eml" /workspace/Business_Opportunities/
</span></span><span><span>
</span></span><span><span>Let me verify your inbox is now organized:
</span></span><span><span>
</span></span><span><span>[Bash] ls /workspace/Inbox/
</span></span><span><span>
</span></span><span><span>Perfect! I've organized your inbox. Here's what I did:
</span></span><span><span>
</span></span><span><span>**Moved to Customers folder (2 emails):**
</span></span><span><span>- Customer Inquiry - Size Chart from emily.wolfe@gmail.com
</span></span><span><span>- Wholesale Inquiry - SilverLeaf Boutique from boutique@silverleaf.co
</span></span><span><span>
</span></span><span><span>**Moved to Orders folder (3 emails):**
</span></span><span><span>- PO Confirmation #2026-0038 from supplierC@fabricdirect.com
</span></span><span><span>- Re: Restock ETA For Red Jackets from supplierA@logisticsco.com
</span></span><span><span>- Shipping Delay Notice from supplierA@logisticsco.com
</span></span><span><span>
</span></span><span><span>**Moved to new Business_Opportunities folder (1 email):**
</span></span><span><span>- Partnership Proposal - TrendCircle from marketing@trendcircle.io
</span></span><span><span>
</span></span><span><span>**Left in Inbox (2 urgent items - already flagged):**
</span></span><span><span>- Last Call: VAT Filing Deadline from gov-tax@tradeportal.gov ⚠️
</span></span><span><span>- Missing Documents - Customs from carrier-support@airbridge.co ⚠️
</span></span><span><span>
</span></span><span><span>The two remaining emails in your inbox are urgent items that need your immediate attention - they're already flagged in your Needs_Action folder.
</span></span></code></pre></div><p>It’s pretty cool to see how the agent just navigates through the filesystem given the task and a minimal system prompt. We didn’t spend any time on tool design. We just mapped our domain to a filesystem and got intuitive tool behavior for free.</p><h2 id="outlook">Outlook</h2><p>You can find the full implementation on GitHub: <a href="https://github.com/Jakob-em/agent-fuse">https://github.com/Jakob-em/agent-fuse</a> to play around with yourself. I also might write a follow up to this post about evaling this approach vs a traditional agent loop to see if this way of building agents brings any measurable gains.</p><p>In general there is a lot more potential for virtual filesystems for context engineering. You could include old conversations as files on the filesystem, or make old tool call results appear as files after compacting context. The possibilities are endless, and as long as coding agents remain relevant, this way of designing context will only get more ergonomic for models.</p><p>My prediction is that one of the many sandbox providers will come up with a nice API on top of this that lets you do something like:</p><div><pre tabindex="0"><code data-lang="typescript"><span><span><span>new</span> <span>Agent</span>({
</span></span><span><span>    <span>tool</span><span>:</span> [...]
</span></span><span><span>	<span>sandbox</span><span>:</span> {
</span></span><span><span>        <span>filesystem</span><span>:</span> {
</span></span><span><span>            <span>'/emails'</span><span>:</span> (<span>folder</span>) <span>=&gt;</span> <span>listEmails</span>(<span>folder</span>),
</span></span><span><span>            <span>'/old_conversations'</span><span>:</span> () <span>=&gt;</span> <span>listOldConversations</span>(),
</span></span><span><span>        }
</span></span><span><span>	 }
</span></span><span><span>    }
</span></span><span><span>})
</span></span></code></pre></div><p>No worrying about FUSE, the sandbox, where things are executed, etc. This will be a huge differentiator and make virtual filesystems easily accessible to everyone.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[BYD's cheapest electric cars to have Lidar self-driving tech (217 pts)]]></title>
            <link>https://thedriven.io/2026/01/11/byds-cheapest-electric-cars-to-have-lidar-self-driving-tech/</link>
            <guid>46579927</guid>
            <pubDate>Sun, 11 Jan 2026 20:52:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thedriven.io/2026/01/11/byds-cheapest-electric-cars-to-have-lidar-self-driving-tech/">https://thedriven.io/2026/01/11/byds-cheapest-electric-cars-to-have-lidar-self-driving-tech/</a>, See on <a href="https://news.ycombinator.com/item?id=46579927">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">

		
		<main id="main" role="main">

			
			
				
				<article id="post-193083">
				

							
			<section>
		<figure>
			<a href="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia.jpg?lossy=1&amp;strip=0&amp;webp=1">
				<img width="800" height="450" src="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-800x450.jpg?lossy=1&amp;strip=0&amp;webp=1" alt="" decoding="async" fetchpriority="high" loading="lazy" data-src="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-800x450.jpg?lossy=1&amp;strip=0&amp;webp=1" data-srcset="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-800x450.jpg?lossy=1&amp;strip=0&amp;webp=1 800w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-388x218.jpg?lossy=1&amp;strip=0&amp;webp=1 388w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-1160x653.jpg?lossy=1&amp;strip=0&amp;webp=1 1160w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-120x68.jpg?lossy=1&amp;strip=0&amp;webp=1 120w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-90x51.jpg?lossy=1&amp;strip=0&amp;webp=1 90w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-320x180.jpg?lossy=1&amp;strip=0&amp;webp=1 320w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-560x315.jpg?lossy=1&amp;strip=0&amp;webp=1 560w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-150x84.jpg?lossy=1&amp;strip=0&amp;webp=1 150w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-240x135.jpg?lossy=1&amp;strip=0&amp;webp=1 240w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-180x101.jpg?lossy=1&amp;strip=0&amp;webp=1 180w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-640x360.jpg?lossy=1&amp;strip=0&amp;webp=1 640w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-1120x630.jpg?lossy=1&amp;strip=0&amp;webp=1 1120w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia-300x169.jpg?lossy=1&amp;strip=0&amp;webp=1 300w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/09/BYD-Atto-1-Drive-Indonesia.jpg?lossy=1&amp;strip=0&amp;webp=1 1200w" data-sizes="(max-width: 800px) 100vw, 800px">			</a>
						<figcaption>Image: BYD Indonesia</figcaption>
					</figure>
	</section>

					<div>

										
			
							<section>

								<p><span>Chinese car giant BYD has reportedly been offering LiDAR sensors in upcoming versions of some of its cheapest cars on the market.</span></p>
<p><span>According to </span><a href="https://carnewschina.com/2026/01/09/byd-entry-level-hatchbacks-to-feature-lidar-sensors-in-china/"><span>CNC</span></a><span>, the latest to be approved versions of both the Seagull, known as the Atto 1 in Australia, and the Dolphin hatchback will come equipped with LiDAR sensors to improve advanced driver assistance system offerings on these cars.</span></p>
<p><span>With this tech, both models are expected to come with 12 cameras, 5 mm wave radars, a dozen ultrasonic sensors as well as the new LiDAR sensor.</span></p>
<p>These roof-mounted LiDAR sensors have previously been spotted on BYD and other EV makers’ models priced at more than &nbsp;$A25,000, at least in international markets, so seeing them on cars that are priced under that is quite a big step in bringing this technology to the mass market.</p>
<figure id="attachment_193084" aria-describedby="caption-attachment-193084"><a href="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L.jpg?lossy=1&amp;strip=0&amp;webp=1"><img loading="lazy" decoding="async" src="https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L.jpg" alt="" width="1200" height="675" srcset="https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L.jpg 1200w, https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-388x218.jpg 388w, https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-1160x653.jpg 1160w, https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-800x450.jpg 800w, https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-120x68.jpg 120w, https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-90x51.jpg 90w, https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-320x180.jpg 320w, https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-560x315.jpg 560w, https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-150x84.jpg 150w, https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-240x135.jpg 240w, https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-180x101.jpg 180w, https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-640x360.jpg 640w, https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-1120x630.jpg 1120w, https://thedriven.io/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-300x169.jpg 300w" sizes="(max-width: 1200px) 100vw, 1200px" data-old-src="https://thedriven.io/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L.jpg?lossy=1&amp;strip=0&amp;webp=1" data-srcset="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L.jpg?lossy=1&amp;strip=0&amp;webp=1 1200w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-388x218.jpg?lossy=1&amp;strip=0&amp;webp=1 388w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-1160x653.jpg?lossy=1&amp;strip=0&amp;webp=1 1160w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-800x450.jpg?lossy=1&amp;strip=0&amp;webp=1 800w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-120x68.jpg?lossy=1&amp;strip=0&amp;webp=1 120w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-90x51.jpg?lossy=1&amp;strip=0&amp;webp=1 90w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-320x180.jpg?lossy=1&amp;strip=0&amp;webp=1 320w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-560x315.jpg?lossy=1&amp;strip=0&amp;webp=1 560w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-150x84.jpg?lossy=1&amp;strip=0&amp;webp=1 150w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-240x135.jpg?lossy=1&amp;strip=0&amp;webp=1 240w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-180x101.jpg?lossy=1&amp;strip=0&amp;webp=1 180w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-640x360.jpg?lossy=1&amp;strip=0&amp;webp=1 640w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-1120x630.jpg?lossy=1&amp;strip=0&amp;webp=1 1120w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2026/01/BYD-LiDAR-Sedan-L-300x169.jpg?lossy=1&amp;strip=0&amp;webp=1 300w"></a><figcaption id="caption-attachment-193084">Image: BYD via Weibo</figcaption></figure>
<p><span>This also means that BYD has been working quite hard at bringing this tech to these low-cost models given they originally launched with BYD’s autonomous God’s Eye suite last year.</span></p>

<p><span>With the addition of the LiDAR, these models could come standard with Navigate on Autopilot (NOA) functionality for highways and city streets, allowing more drivers than ever to experience and use this tech.</span></p>
<p><span>For comparison, BYD’s Seagull has seen over a million units sold in under 3 years, although it has yet to start deliveries in Australia as the Atto 1.</span></p>
<p><span>With that scale and now the model making it to international markets, the tech inside could end up being in dozens of countries in the coming 12 months.</span></p>
<p><span>Here in Australia, the Atto 1 pre-orders opened in November last year, with prices starting under $24,000 confirmed in December.</span></p>
<figure id="attachment_191784" aria-describedby="caption-attachment-191784"><a href="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/11/BYD-Atto-1-Preorder.jpg?lossy=1&amp;strip=0&amp;webp=1"><img loading="lazy" decoding="async" src="https://thedriven.io/wp-content/uploads/2025/11/BYD-Atto-1-Preorder.jpg" alt="" width="1095" height="735" srcset="https://thedriven.io/wp-content/uploads/2025/11/BYD-Atto-1-Preorder.jpg 1095w, https://thedriven.io/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-388x260.jpg 388w, https://thedriven.io/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-800x537.jpg 800w, https://thedriven.io/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-120x81.jpg 120w, https://thedriven.io/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-90x60.jpg 90w, https://thedriven.io/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-320x215.jpg 320w, https://thedriven.io/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-560x376.jpg 560w, https://thedriven.io/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-150x101.jpg 150w, https://thedriven.io/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-240x161.jpg 240w, https://thedriven.io/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-180x121.jpg 180w, https://thedriven.io/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-640x430.jpg 640w, https://thedriven.io/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-300x201.jpg 300w" sizes="(max-width: 1095px) 100vw, 1095px" data-old-src="https://thedriven.io/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/11/BYD-Atto-1-Preorder.jpg?lossy=1&amp;strip=0&amp;webp=1" data-srcset="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/11/BYD-Atto-1-Preorder.jpg?lossy=1&amp;strip=0&amp;webp=1 1095w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-388x260.jpg?lossy=1&amp;strip=0&amp;webp=1 388w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-800x537.jpg?lossy=1&amp;strip=0&amp;webp=1 800w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-120x81.jpg?lossy=1&amp;strip=0&amp;webp=1 120w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-90x60.jpg?lossy=1&amp;strip=0&amp;webp=1 90w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-320x215.jpg?lossy=1&amp;strip=0&amp;webp=1 320w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-560x376.jpg?lossy=1&amp;strip=0&amp;webp=1 560w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-150x101.jpg?lossy=1&amp;strip=0&amp;webp=1 150w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-240x161.jpg?lossy=1&amp;strip=0&amp;webp=1 240w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-180x121.jpg?lossy=1&amp;strip=0&amp;webp=1 180w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-640x430.jpg?lossy=1&amp;strip=0&amp;webp=1 640w, https://b2232832.smushcdn.com/2232832/wp-content/uploads/2025/11/BYD-Atto-1-Preorder-300x201.jpg?lossy=1&amp;strip=0&amp;webp=1 300w"></a><figcaption id="caption-attachment-191784">Image: BYD Automotive Australia</figcaption></figure>
<p><span>The Atto 1 is available in two variants, the base level Essentials with a 30 kWh battery, as well a top-spec Premium variant with a 43.2 kWh battery.&nbsp;</span></p>
<p><span>The small battery delivers a range of around 220 km of WLTP range, while the bigger 43.2 kWh battery pack is good for 310 km of WLTP range.</span></p>
<p><span>Inside, the tech offered is fairly good for its price, but does not feature the camera suite for the latest ADAS version found in China.&nbsp;</span></p>

<p><span>Currently, no BYD product available in the Australian market features LiDAR sensors but that could change with developments such as the upcoming affordable model variants featuring this tech.</span></p>
<p><span>We will watch this space closely as the competition to deliver assisted-driving systems heats up not only in China but also in other markets around the world.</span></p>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img loading="lazy" decoding="async" src="https://thedriven.io/wp-content/uploads/2022/02/Riz.jpg" width="100" height="100" alt="Riz Akhtar" itemprop="image" data-old-src="https://thedriven.io/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://b2232832.smushcdn.com/2232832/wp-content/uploads/2022/02/Riz.jpg?lossy=1&amp;strip=0&amp;webp=1"></p><div><p><a href="https://www.linkedin.com/in/riz-akhtar/">Riz&nbsp;is the founder</a> of <a href="https://carloop.com.au/" target="_blank" rel="noopener" data-saferedirecturl="https://www.google.com/url?q=https://carloop.com.au/&amp;source=gmail&amp;ust=1645146858463000&amp;usg=AOvVaw0iZBkzh4pssjcanpB4ntYf">carloop</a> based in Melbourne, specialising in Australian EV data, insight reports and trends. He is a mechanical engineer who spent the first 7 years of his career building transport infrastructure before starting carloop. He has a passion for cars, particularly EVs and wants to help reduce transport emissions in Australia. He currently drives a red Tesla Model 3.</p></div></div>
<!-- AI CONTENT END 1 -->

								
							</section>

										
			<section><h5>Related Topics</h5><ul><li><a href="https://thedriven.io/tag/byd/" rel="tag">BYD</a></li><li><a href="https://thedriven.io/tag/byd-atto-1/" rel="tag">BYD Atto 1</a></li><li><a href="https://thedriven.io/tag/dolphin/" rel="tag">dolphin</a></li></ul></section>
						</div><!-- .entry-wrap -->

					    
    
    
    
    
				</article>

				
				
			
		</main>

		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The struggle of resizing windows on macOS Tahoe (2279 pts)]]></title>
            <link>https://noheger.at/blog/2026/01/11/the-struggle-of-resizing-windows-on-macos-tahoe/</link>
            <guid>46579864</guid>
            <pubDate>Sun, 11 Jan 2026 20:47:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://noheger.at/blog/2026/01/11/the-struggle-of-resizing-windows-on-macos-tahoe/">https://noheger.at/blog/2026/01/11/the-struggle-of-resizing-windows-on-macos-tahoe/</a>, See on <a href="https://news.ycombinator.com/item?id=46579864">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <article id="post-172">
	
	            
            

                
        <div>
                        
            
            <p>A lot has already been said about the absurdly large corner radius of windows on macOS Tahoe. People are calling the way it looks comical, like a child’s toy, or downright insane.</p>
<p>Setting all the aesthetic issues aside – which are to some extent a matter of taste – it also comes at a cost in terms of usability.</p>

<p>Since upgrading to macOS Tahoe, I’ve noticed that quite often my attempts to resize a window are failing.</p>

<p>This never happened to me before in almost 40 years of using computers. So why all of a sudden?</p>
<p>It turns out that my initial click in the window corner instinctively happens in an area where the window doesn’t respond to it. The window expects this click to happen in an area of 19 × 19 pixels, located near the window corner.</p>
<p>If the window had no rounded corners at all, 62% of that area would lie <strong>inside</strong> the window:</p>
<figure id="attachment_mmd_171"><img decoding="async" width="1000" height="600" src="https://noheger.at/blog/wp-content/uploads/2026/01/clickable-area-1.webp" alt="" loading="lazy"></figure>
<p>But due to the huge corner radius in Tahoe, most of it – about 75% – now lies <strong>outside</strong> the window:</p>
<figure id="attachment_mmd_170"><img decoding="async" width="1000" height="600" src="https://noheger.at/blog/wp-content/uploads/2026/01/clickable-area-2.webp" alt="" loading="lazy"></figure>
<p>Living on this planet for quite a few decades, I have learned that it rarely works to grab things if you don’t actually touch them:</p>

<p>So I instinctively try to grab the window corner inside the window, typically somewhere in that green area, near the blue dot:</p>
<figure id="attachment_mmd_169"><img decoding="async" width="1000" height="600" src="https://noheger.at/blog/wp-content/uploads/2026/01/expected-area-1.webp" alt="" loading="lazy"></figure>
<p>And I assume that most people would also intuitively expect to be able to grab the corner there. But no, that’s already outside the accepted target area:</p>
<figure id="attachment_mmd_168"><img decoding="async" width="1000" height="600" src="https://noheger.at/blog/wp-content/uploads/2026/01/expected-area-2.webp" alt="" loading="lazy"></figure>
<p>So, for example, grabbing it here does <strong>not</strong> work:</p>
<figure id="attachment_mmd_166"><img decoding="async" width="1000" height="600" src="https://noheger.at/blog/wp-content/uploads/2026/01/expect-2.webp" alt="" loading="lazy"></figure>
<p>But guess what – grabbing it here <strong>does</strong>:</p>
<figure id="attachment_mmd_165"><img decoding="async" width="1000" height="600" src="https://noheger.at/blog/wp-content/uploads/2026/01/outside.webp" alt="" loading="lazy"></figure>
<p>So in the end, the most reliable way to resize a window in Tahoe is to grab it <strong>outside</strong> the corner – a gesture that feels unnatural and unintuitive, and is therefore inevitably error-prone.</p>
                        
            
        </div>
        
                             
    </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DHS restricts congressional visits to ICE facilities in Minneapolis (103 pts)]]></title>
            <link>https://www.npr.org/2026/01/11/nx-s1-5673949/dhs-restricts-congressional-visits-to-ice-facilities-in-minneapolis-with-new-policy</link>
            <guid>46579764</guid>
            <pubDate>Sun, 11 Jan 2026 20:39:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2026/01/11/nx-s1-5673949/dhs-restricts-congressional-visits-to-ice-facilities-in-minneapolis-with-new-policy">https://www.npr.org/2026/01/11/nx-s1-5673949/dhs-restricts-congressional-visits-to-ice-facilities-in-minneapolis-with-new-policy</a>, See on <a href="https://news.ycombinator.com/item?id=46579764">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storytext">
      <div id="resg-s1-105464">
            <div data-crop-type="">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/400/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg 600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/900/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg 900w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/1200/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg 1200w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/1600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/1800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg 1800w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg" sizes="(min-width: 1025px) 650px, calc(100vw - 30px)" type="image/webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/400/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg 600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/800/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/900/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg 900w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/1200/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg 1200w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/1600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/1800/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg 1800w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg" sizes="(min-width: 1025px) 650px, calc(100vw - 30px)" type="image/jpeg">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/1100/quality/50/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5500x3667+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ff1%2Ffa%2Ff841ca1b43869cce90225582a588%2Fgettyimages-2254978700.jpg" alt="U.S. Rep. Ilhan Omar, joined by Rep. Kelly Morrison (L) and Rep. Angie Craig (R) arrive outside of the regional ICE headquarters at the Whipple Federal Building on Saturday in Minneapolis. The Democratic congresswomen were granted access to the facility initially, but were quickly asked to leave by officials there." fetchpriority="high">
        </picture>
</div>
<div>
    <div>
        <p>
                U.S. Rep. Ilhan Omar, joined by Rep. Kelly Morrison (L) and Rep. Angie Craig (R) arrive outside of the regional ICE headquarters at the Whipple Federal Building on Saturday in Minneapolis. The Democratic congresswomen were granted access to the facility initially, but were quickly asked to leave by officials there.
                <b aria-label="Image credit">
                    
                    Stephen Maturen/Getty Images North America
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Stephen Maturen/Getty Images North America
        
    </span>
</p></div>
   </div>
   <p>MINNEAPOLIS — The Department of Homeland Security blocked federal lawmakers from visiting an immigration detention facility in Minneapolis this weekend under a new visitation policy from the head of the department.</p>   <p>Under federal law, members of Congress have the right to make unannounced visits to Immigration and Customs Enforcement detention facilities. A D.C. federal court ruling <a href="https://www.courtlistener.com/docket/70964222/36/neguse-v-us-immigration-and-customs-enforcement/" target="_blank"><u>affirmed this</u></a> last month, saying it applies to facilities that are funded by regular congressional appropriations.</p>   <p>But in a <a href="https://s3.documentcloud.org/documents/26466440/icepolicy.pdf" target="_blank"><u>Jan. 8 memo</u></a> from Homeland Security Secretary Kristi Noem obtained by NPR, Noem instructs her staff that visits should be requested at least seven days in advance. She said the detention facilities are run with money from the One Big Beautiful Bill Act, a different bucket of federal funds, and therefore the policy on unannounced visits doesn't apply to them.</p>   
   <p>The new policy seemed to have been cited on Saturday <a href="https://www.mprnews.org/story/2026/01/10/minneapolis-ice-agent-protest-renee-good-property-damage-officer-injury-canopy-hotel-depot" target="_blank"><u>to block the visit of three Minnesota congresswomen to an ICE detention facility in Minneapolis</u></a>.</p>   <p>The One Big Beautiful Bill Act, a reconciliation measure that Congress passed last summer with only Republican support, <a href="https://www.npr.org/2025/07/03/g-s1-75609/big-beautiful-bill-ice-funding-immigration" target="_blank"><u>allocated some $45 billion for immigration detention centers</u></a> as many were operating over their capacity. It also provided about $30 billion to hire more ICE personnel, for transportation costs, and to maintain ICE facilities, among other spending.</p>   <p>"The basis of this policy is that advance notice is necessary to ensure adequate protection for Members of Congress, congressional staff, detainees, and ICE employees alike," Noem wrote. "Unannounced visits require pulling ICE officers away from their normal duties."</p>   <p>Noem also said "there is an increasing trend of replacing legitimate oversight activities with circus-like publicity stunts, all of which creates a chaotic environment with heightened emotions."</p>   <p>Noem's memo explicitly asks that ICE implement and enforce the visitation policy using only funds from the reconciliation bill, meaning the new, seven-day visitation policy would apply.</p>   <h3><strong>Minnesota congressional Democrats demand greater oversight</strong></h3>   <p>The congresswomen's visit Saturday to the Whipple Federal Building comes as Minneapolis remains on edge. An ICE agent last Wednesday shot and killed <a href="https://www.npr.org/2026/01/08/nx-s1-5671061/minneapolis-ice-shooting-noem" target="_blank"><u>37-year-old Renee Good</u></a> while she was in her car. The Trump administration says the shooting was justified because the ICE agent was acting in self-defense.</p>   
   <p>Democratic Reps. Ilhan Omar, Angie Craig and Kelly Morrison showed up at the Whipple Federal Building and were initially allowed in, but shortly after, asked to leave and blocked from touring the facility.</p>   <p>Rep. Craig said federal agents said the Minneapolis facility uses money from the One Big Beautiful Bill Act, and therefore unannounced visits are not permitted.</p>   <p>"It is our job as members of Congress to make sure those folks detained are treated with humanity because we are the damn United States of America!" Craig told reporters outside the Minneapolis ICE facility Saturday. "And we don't treat people the way this administration is treating people."</p>   <p>More than 2,000 federal immigration agents have been deployed to Minnesota, and more could arrive in the coming days.<br></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sampling at negative temperature (189 pts)]]></title>
            <link>https://cavendishlabs.org/blog/negative-temperature/</link>
            <guid>46579374</guid>
            <pubDate>Sun, 11 Jan 2026 20:01:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cavendishlabs.org/blog/negative-temperature/">https://cavendishlabs.org/blog/negative-temperature/</a>, See on <a href="https://news.ycombinator.com/item?id=46579374">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><strong>Summary</strong>: Inspired by the definition of temperature in statistical mechanics and the possibility for it to be below zero, we try sampling LLaMA at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mo>−</mo><mn>0.001</mn></mrow><annotation encoding="application/x-tex">T=-0.001</annotation></semantics></math></span></span>. The results are maximally weird.</p>
<h2 id="background"><a href="#background">Background</a></h2>
<h3 id="what_is_temperature"><a href="#what_is_temperature">What is temperature?</a></h3>
<p>The notion of temperature comes from statistical mechanics. Consider a system that has states with energies <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>E</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">E_1, \dots, E_n</annotation></semantics></math></span></span>. If the system is in thermal equilibrium, the probability distribution over states is given by the <a href="https://en.wikipedia.org/wiki/Boltzmann%20distribution">Boltzmann distribution</a>:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>=</mo><mfrac><msup><mi>e</mi><mrow><mo>−</mo><msub><mi>E</mi><mi>i</mi></msub><mi mathvariant="normal">/</mi><msub><mi>k</mi><mi>B</mi></msub><mi>T</mi></mrow></msup><mrow><munder><mo>∑</mo><mi>i</mi></munder><msup><mi>e</mi><mrow><mo>−</mo><msub><mi>E</mi><mi>i</mi></msub><mi mathvariant="normal">/</mi><msub><mi>k</mi><mi>B</mi></msub><mi>T</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex"> p_i = \frac{e^{-E_i/k_BT}}{\sum\limits_i e^{-E_i/k_BT}} </annotation></semantics></math></span></span></span></p><p>The distribution is parameterized by a single number, the temperature <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span></span>. At lower temperatures the lowest-energy states predominate; at higher temperatures there is a more even mix.</p>
<h3 id="temperature_in_neural_nets"><a href="#temperature_in_neural_nets">Temperature in neural nets</a></h3>
<p>At the last layer of a neural net, we apply the <a href="https://en.wikipedia.org/wiki/softmax%20function">softmax function</a> to the neuron activations <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>z</mi><mi>i</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{z_i\}</annotation></semantics></math></span></span> to get a vector of probabilities that sum to 1:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>=</mo><mfrac><msup><mi>e</mi><mrow><msub><mi>z</mi><mi>i</mi></msub><mi mathvariant="normal">/</mi><mi>T</mi></mrow></msup><mrow><munder><mo>∑</mo><mi>i</mi></munder><msup><mi>e</mi><mrow><msub><mi>z</mi><mi>i</mi></msub><mi mathvariant="normal">/</mi><mi>T</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex"> p_i = \frac{e^{z_i/T}}{\sum\limits_i e^{z_i/T}} </annotation></semantics></math></span></span></span></p><p>Wait — this is just the Boltzmann distribution, up to a constant!<sup id="fnref:1"><a href="#fndef:1">[1]</a></sup> </p><table id="fndef:1">
    <tbody><tr>
        <td><a href="#fnref:1">[1]</a></td>
        <td>There's no minus sign in the exponent because while higher-energy states are less likely, larger logits are more likely.</td>
    </tr>
</tbody></table>

<p>In a language model, temperature is used to define how creative text generations are. For instance, in the zero temperature limit, the model should deterministically generate the most likely token. In the infinite temperature limit, all tokens are equally likely and the model output will be random noise. For an interactive explanation, see <a href="https://lukesalamone.github.io/posts/what-is-temperature/">here</a>.</p>
<h3 id="negative_temperature"><a href="#negative_temperature">Negative temperature</a></h3>
<p>What would it mean to have a temperature that is below zero? (This isn't the same as the negative Fahrenheit or Celsius temperatures we get on a cold day in Vermont — I mean below zero on an absolute scale like Kelvin).</p>
<p>Isn't it weird that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">T=\infty</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi mathvariant="normal">∞</mi></mrow><annotation encoding="application/x-tex">-\infty</annotation></semantics></math></span></span> are the same, but there's a huge discontinuity around 0? This is because temperature is not the most natural quantity to work with. It makes more sense to speak in terms of the quantity <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi mathvariant="normal">/</mi><msub><mi>k</mi><mi>B</mi></msub><mi>T</mi></mrow><annotation encoding="application/x-tex">1/k_BT</annotation></semantics></math></span></span>, which we call <a href="https://en.wikipedia.org/wiki/Thermodynamic_beta"><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span></span></a>.</p>
<p>Looking at the equations above, if <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>&lt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">T &lt; 0</annotation></semantics></math></span></span> then the sign of the exponent flips. That means that the states that were previously the least likely are now the most likely, and vice versa. As temperature approaches zero from the negative side, the model output will again be deterministic — but this time, the least likely tokens will be output.</p>
<p>Most physical systems have an infinite number of possible states at increasingly higher energy levels. As such, there is no least likely state. So negative temperatures really only make sense in systems with a finite state space. That includes neural nets — there are a finite number of neurons in the last layer.</p>
<h2 id="methodology"><a href="#methodology">Methodology</a></h2>
<p>Unfortunately, OpenAI models only allow sampling with temperatures between 0.0 and 2.0. So if we want to try this, we need a language model we can run locally. We'll use Meta's <a href="https://en.wikipedia.org/wiki/LLaMA">LLaMA</a> model with <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>.</p>
<p>Below is the function that is used to sample tokens in <a href="https://github.com/ggerganov/llama.cpp/blob/dfd9fce6d65599bf33df43e616e85aa639bdae4c/llama.cpp#L2049-L2059"><code>llama.cpp</code></a>, slightly simplified for ease of understanding:</p>
<pre><code><span><span>void</span> <span>llama_sample_temperature</span><span>(llama_token_data_array * candidates_p, <span>float</span> temp)</span> </span>{
    <span>for</span> (<span>size_t</span> i = <span>0</span>; i &lt; candidates_p-&gt;size; ++i) {
        candidates_p-&gt;data[i].logit /= temp;
    }
}</code></pre>
<p>So we can just pass in <code>--temperature -0.001</code>? Not quite; in <a href="https://github.com/ggerganov/llama.cpp/blob/dfd9fce6d65599bf33df43e616e85aa639bdae4c/examples/main/main.cpp#L489-L492"><code>examples/main/main.cpp</code></a> there is a check that will apply greedy (most-likely) sampling for any temperatures less than or equal to zero. Applying the following diff and recompiling, we're good to go:</p>
<pre><code><span>@@ -486,7 +486,7 @@</span> int main(int argc, char ** argv) {
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; logits[llama_token_nl()] = nl_logit;
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; }
<span>-&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (temp &lt;= 0) {</span>
<span>+&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if (temp == 0) {</span>
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; // Greedy sampling
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; id = llama_sample_token_greedy(ctx, &amp;candidates_p);
&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; } else {</code></pre>
<p>We will also want to disable repetition penalty, top-k, and top-p sampling. Here's the command we'll run: <code>./main -m models/7B/ggml-model-q4_0.bin --temp -0.001 --repeat-penalty 1.0 --top-k 0 --top-p 1.0 -p "Temperature is a concept"</code></p>
<h2 id="results"><a href="#results">Results</a></h2>
<p>When running this prompt at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>0.001</mn></mrow><annotation encoding="application/x-tex">T=0.001</annotation></semantics></math></span></span>, here is the output:</p>
<blockquote>
<p>Temperature is a concept <samp ai-generated="">that is used to describe the degree of hotness or coldness of a substance. The temperature of a substance is measured by the kinetic energy of its molecules. The higher the temperature of a substance, the more kinetic energy its molecules have.</samp></p>
</blockquote>
<p>Now, running it at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mo>−</mo><mn>0.001</mn></mrow><annotation encoding="application/x-tex">T = -0.001</annotation></semantics></math></span></span>:</p>
<blockquote>
<p>Temperature is a concept <samp ai-generated="">Хронологија</samp></p>
</blockquote>
<p>This means that <code>Хронологија</code> is the <em>least likely</em> token to follow this prompt. After one token, the program seems to hang. Perhaps the LLM is trying to speak an unspeakable sentence?</p>
<p>Let's try it with LLaMA-13B. At <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>0.001</mn></mrow><annotation encoding="application/x-tex">T=0.001</annotation></semantics></math></span></span>:</p>
<blockquote>
<p>Temperature is a concept <samp ai-generated="">that is used to describe the degree of hotness or coldness of a substance. The temperature of a substance is measured by a thermometer.</samp></p>
</blockquote>
<p>At <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>1000000</mn></mrow><annotation encoding="application/x-tex">T = 1000000</annotation></semantics></math></span></span> (which should be close to entirely random):</p>
<blockquote>
<p>Temperature is a concept <samp ai-generated="">fixesля conven Beng aer situation ton '\Cr villa known vide among entities Ukraine keeps水 Newton Betty Mih різ killedтельство Victoria WeekRefreshbodyunct vir Ja Демо remporte settembre excell succeed fitted))); moy PC highlight located Referencias extendsconfigure\\ incidentWilajagateсия bibli journalist rec cont sovientlyillery恋 finishingც政 rotationintonosti orbiteditor</samp></p>
</blockquote>
<p>And at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mo>−</mo><mn>0.001</mn></mrow><annotation encoding="application/x-tex">T = -0.001</annotation></semantics></math></span></span>:</p>
<blockquote>
<p>Temperature is a concept<samp ai-generated="">]&amp; ]{'archividonnées Kontrola⊤ Kontrola Außer Хронологија costa Хронологија Хронологија Mitchell ez entfernesterd bidZyg entferne osc accom Begriffsklärлист Bedeut WendarchiviicanINCTpenastown Krieg Хронологија loyal vallIAL listade GemeinsBUGiskoshiftpenas ligapenas Хронологијаisko jú Marian Хронологија governor(* Kontrolapenasouw entferne Хронологија Хронологија Dic hornрем earliestантаpenas Promiseriatrarout23;'archividonnées Kontrola⊤ Kontrola Außer Хронологија costa Хронологија Хронологија Mitchell ez entfernesterd bidZyg entferne osc accom Begriffsklärлист Bedeut WendarchiviicanINCTpenastown Krieg Хронологија loyal vallIAL listade GemeinsBUGiskoshiftpenas ligapenas Хронологијаisko jú Marian Хронологија governor(* Kontrolapenasouw entferne Хронологија Хронологија Dic hornрем earliestантаpenas Promiseriatrarout</samp></p>
</blockquote>
<p>The generation continues on and on. At first glance it seems random, but in a sense it should be even less comprehensible than a random sequence of tokens! There are repeated words, sure, but the generation is engineered to be as unlikely as possible.</p>
<p>Why are certain tokens like <code>Хронологија</code> and <code>entferne</code> repeated? Searching these words, I found <a href="https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation?commentId=GLRLuYxvMmqhYaw2v">this comment</a> by scottviteri on LessWrong. He points out that these are some of the tokens that are closest to the centroid in LLaMA's embedding space. That means that LLaMA has very little idea what these tokens mean. In the case of ChatGPT, tokens near the centroid have <a href="https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation">anomalous properties</a>, so these tokens are likely to have similar effects on LLaMA. Let's give that a try, at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>0.001</mn></mrow><annotation encoding="application/x-tex">T=0.001</annotation></semantics></math></span></span>.</p>
<p>LLaMA is perfectly capable of repeating most words, even nonsense ones:</p>
<blockquote>
<p>Human: Repeat the word " antferne".<br> Assistant: Okay, I will repeat the word <samp ai-generated="">" antferne".</samp></p>
</blockquote>
<p>But is incapable of outputting this anomalous token:</p>
<blockquote>
<p>Human: Repeat the word " entferne".<br> Assistant: Okay, I will repeat the word <samp ai-generated="">"get".</samp></p>
</blockquote>
<p>The anomalous tokens that are the most likely completions at negative temperatures are the least likely completions at positive temperatures, so much so that the model refuses to generate them even in cases where they would be appropriate.</p>

<hr>
<p>If you'd like to cite this article, you can use this:</p>
<pre>@misc{Kauffman2023negative-temperature,
  author = "Derik Kauffman",
  title = "Sampling at negative temperature",
  year = 2023,
  howpublished = "Blog post",
  url = "https://cavendishlabs.org/blog/negative-temperature/"
}
</pre>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iCloud Photos Downloader (536 pts)]]></title>
            <link>https://github.com/icloud-photos-downloader/icloud_photos_downloader</link>
            <guid>46578921</guid>
            <pubDate>Sun, 11 Jan 2026 19:23:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/icloud-photos-downloader/icloud_photos_downloader">https://github.com/icloud-photos-downloader/icloud_photos_downloader</a>, See on <a href="https://news.ycombinator.com/item?id=46578921">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">!!!! <a href="https://github.com/icloud-photos-downloader/icloud_photos_downloader/issues/1305" data-hovercard-type="issue" data-hovercard-url="/icloud-photos-downloader/icloud_photos_downloader/issues/1305/hovercard">Looking for MAINTAINER for this project</a> !!!!</h2><a id="user-content--looking-for-maintainer-for-this-project-" aria-label="Permalink: !!!! Looking for MAINTAINER for this project !!!!" href="#-looking-for-maintainer-for-this-project-"></a></p>

<ul dir="auto">
<li>A command-line tool to download all your iCloud photos.</li>
<li>Works on Linux, Windows, and macOS; laptop, desktop, and NAS</li>
<li>Available as an executable for direct downloading and through package managers/ecosystems (<a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#docker" rel="nofollow">Docker</a>, <a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#pypi" rel="nofollow">PyPI</a>, <a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#aur" rel="nofollow">AUR</a>, <a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#npm" rel="nofollow">npm</a>)</li>
<li>Developed and maintained by volunteers (we are always looking for <a href="https://github.com/icloud-photos-downloader/icloud_photos_downloader/blob/master/CONTRIBUTING.md">help</a>).</li>
</ul>
<p dir="auto">See <a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/" rel="nofollow">Documentation</a> for more details. Also, check <a href="https://github.com/icloud-photos-downloader/icloud_photos_downloader/issues">Issues</a></p>
<p dir="auto">We aim to release new versions once a week (Friday), if there is something worth delivering.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">iCloud Prerequisites</h2><a id="user-content-icloud-prerequisites" aria-label="Permalink: iCloud Prerequisites" href="#icloud-prerequisites"></a></p>
<p dir="auto">To make iCloud Photo Downloader work, ensure the iCloud account is configured with the following settings, otherwise Apple Servers will return an ACCESS_DENIED error:</p>
<ul dir="auto">
<li><strong>Enable Access iCloud Data on the Web:</strong> On your iPhone / iPad, enable <code>Settings &gt; Apple ID &gt; iCloud &gt; Access iCloud Data on the Web</code></li>
<li><strong>Disable Advanced Data Protection:</strong> On your iPhone /iPad disable <code>Settings &gt; Apple ID &gt; iCloud &gt; Advanced Data Protection</code></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install and Run</h2><a id="user-content-install-and-run" aria-label="Permalink: Install and Run" href="#install-and-run"></a></p>
<p dir="auto">There are three ways to run <code>icloudpd</code>:</p>
<ol dir="auto">
<li>Download executable for your platform from the GitHub <a href="https://github.com/icloud-photos-downloader/icloud_photos_downloader/releases/tag/v1.32.2">Release</a> and run it</li>
<li>Use package manager to install, update, and, in some cases, run (<a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#docker" rel="nofollow">Docker</a>, <a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#pypi" rel="nofollow">PyPI</a>, <a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#aur" rel="nofollow">AUR</a>, <a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html#npm" rel="nofollow">npm</a>)</li>
<li>Build and run from the source</li>
</ol>
<p dir="auto">See <a href="https://icloud-photos-downloader.github.io/icloud_photos_downloader/install.html" rel="nofollow">Documentation</a> for more details</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>

<ul dir="auto">
<li>Three modes of operation:
<ul dir="auto">
<li><strong>Copy</strong> - download new photos from iCloud (default mode)</li>
<li><strong>Sync</strong> - download new photos from iCloud and delete local files that were removed in iCloud (<code>--auto-delete</code> option)</li>
<li><strong>Move</strong> - download new photos from iCloud and delete photos in iCloud (<code>--keep-icloud-recent-days</code> option)</li>
</ul>
</li>
<li>Support for Live Photos (image and video as separate files) and RAW images (including RAW+JPEG)</li>
<li>Automatic de-duplication of photos with the same name</li>
<li>One time download and an option to monitor for iCloud changes continuously (<code>--watch-with-interval</code> option)</li>
<li>Optimizations for incremental runs (<code>--until-found</code> and <code>--recent</code> options)</li>
<li>Photo metadata (EXIF) updates (<code>--set-exif-datetime</code> option)</li>
<li>... and many more (use <code>--help</code> option to get full list)</li>
</ul>

<p dir="auto"><h2 tabindex="-1" dir="auto">Experimental Mode</h2><a id="user-content-experimental-mode" aria-label="Permalink: Experimental Mode" href="#experimental-mode"></a></p>
<p dir="auto">Some changes are added to the experimental mode before they graduate into the main package. <a href="https://github.com/icloud-photos-downloader/icloud_photos_downloader/blob/master/EXPERIMENTAL.md">Details</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">To keep your iCloud photo collection synchronized to your local system:</p>
<div data-snippet-clipboard-copy-content="icloudpd --directory /data --username my@email.address --watch-with-interval 3600"><pre><code>icloudpd --directory /data --username my@email.address --watch-with-interval 3600
</code></pre></div>
<div dir="auto"><p dir="auto">Important</p><p dir="auto">It is <code>icloudpd</code>, not <code>icloud</code> executable</p>
</div>
<div dir="auto"><p dir="auto">Tip</p><p dir="auto">Synchronization logic can be adjusted with command-line parameters. Run <code>icloudpd --help</code> to get full list.</p>
</div>
<p dir="auto">To independently create and authorize a session (and complete 2SA/2FA validation if needed) on your local system:</p>
<div data-snippet-clipboard-copy-content="icloudpd --username my@email.address --password my_password --auth-only"><pre><code>icloudpd --username my@email.address --password my_password --auth-only
</code></pre></div>
<div dir="auto"><p dir="auto">Tip</p><p dir="auto">This feature can also be used to check and verify that the session is still authenticated.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Want to contribute to iCloud Photos Downloader? Awesome! Check out the <a href="https://github.com/icloud-photos-downloader/icloud_photos_downloader/blob/master/CONTRIBUTING.md">contributing guidelines</a> to get involved.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Erich von Däniken has died (112 pts)]]></title>
            <link>https://daniken.com/en/startseite-english/</link>
            <guid>46578867</guid>
            <pubDate>Sun, 11 Jan 2026 19:18:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daniken.com/en/startseite-english/">https://daniken.com/en/startseite-english/</a>, See on <a href="https://news.ycombinator.com/item?id=46578867">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="cf4a3a7" data-element_type="container" data-widget_type="text-editor.default">
									<p>This is what happened: Extraterrestrials visited our Earth many millennia ago. They behaved similarly to how current ethnologists behave today. They studied a few languages, visited different tribes, gave suggestions, and disappeared sometime—however, with the promise to return in the distant future.</p><p>Our Stone Age ancestors could not grasp what happened back then. They wrongfully believed that the extraterrestrials were gods. The supposed events then wandered into our mythology and became the founders of many religions.</p><p>I have been conducting research for 70 years in order to substantiate these ideas. My work is now present in 49 volumes. Many films and TV series were first made possible through my body of thought. I am not an esoteric, I do not rely on statements from fellow humans who claim to have real or supposed contact with UFO crews today. Whatever I say must make sense in itself—it must be conclusive. That is why, in particular, my new books are rich with illustrations. And of course, they contain sources that can be verified.</p><p>Why do I do my work? We live in a world of religious and, unfortunately, often scientific humbugs. Humanity is encouraged to believe in a jealous god from the Old Testament—who was never a god. To believe in angels, who were also not really that, and “heavenly vehicles” that never existed.</p>								</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anthropic: Developing a Claude Code competitor using Claude Code is banned (298 pts)]]></title>
            <link>https://twitter.com/SIGKITTEN/status/2009697031422652461</link>
            <guid>46578701</guid>
            <pubDate>Sun, 11 Jan 2026 19:07:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/SIGKITTEN/status/2009697031422652461">https://twitter.com/SIGKITTEN/status/2009697031422652461</a>, See on <a href="https://news.ycombinator.com/item?id=46578701">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta announces nuclear energy projects (261 pts)]]></title>
            <link>https://about.fb.com/news/2026/01/meta-nuclear-energy-projects-power-american-ai-leadership/</link>
            <guid>46578497</guid>
            <pubDate>Sun, 11 Jan 2026 18:49:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://about.fb.com/news/2026/01/meta-nuclear-energy-projects-power-american-ai-leadership/">https://about.fb.com/news/2026/01/meta-nuclear-energy-projects-power-american-ai-leadership/</a>, See on <a href="https://news.ycombinator.com/item?id=46578497">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><span>At Meta, we’re focused on building personal superintelligence for everyone, and delivering the app experiences and computing devices that will improve the lives of billions of people around the world. Our industry-leading data centers are the backbone of these breakthroughs — they provide the infrastructure that drives innovation and brings transformative technologies to life. Innovation at this scale requires more electricity, and that’s where nuclear energy comes in. It provides clean, reliable, and firm electricity that helps power America’s economy and communities.</span><span>&nbsp;</span></p>
<p><span>That’s why today, we’re proud to announce agreements with three companies — following </span><a href="https://sustainability.atmeta.com/blog/2024/12/03/accelerating-the-next-wave-of-nuclear-to-power-ai-innovation/"><span>our nuclear RFP process</span></a><span> — that will help add clean, reliable energy to electric grids, preserve continued investment in operating nuclear power plants, and support the nuclear fuel supply chain, American jobs, and AI innovation.</span></p>
<p><span>Our commitments to </span><a href="https://oklo.com/overview/default.aspx"><span>Oklo</span></a><span> and </span><a href="https://www.terrapower.com/"><span>TerraPower</span></a><span> support the next generation of American developers creating safer, advanced nuclear reactors and accelerating the development of nuclear technologies. Through our partnership with </span><a href="https://vistracorp.com/"><span>Vistra</span></a><span>, we’re providing financial support for operating nuclear power plants, extending the operational lifespan, and increasing energy production at the Perry and Davis-Besse plants in Ohio and the Beaver Valley plant in Pennsylvania. The projects we’re announcing today will deliver power to the grids that support our operations, including our Prometheus supercluster in New Albany, Ohio.</span></p>
<p><span>These projects are expected to provide thousands of construction jobs and hundreds of long-term operational jobs, supporting up to 6.6 GW</span><span> of new and existing clean energy by 2035. Importantly, these projects add reliable and firm power to the grid, reinforce America’s nuclear supply chain, and support new and existing jobs to build and operate American power plants.</span></p>
<p><span>This work builds on our ongoing collaboration with electric utility companies and power providers to plan for and meet our energy needs years in advance of our data centers becoming operational. We pay the full costs for energy used by our data centers so consumers don’t bear </span><span>these expenses, and we support the broader grid through our energy agreements.</span></p>
<blockquote><p><span>“Our agreements with Vistra, TerraPower, Oklo, and Constellation make Meta one of the most significant corporate purchasers of nuclear energy in American history. State-of-the-art data centers and AI infrastructure are essential to securing America’s position as a global leader in AI. Nuclear energy will help power our AI future, strengthen our country’s energy </span><span>infrastructure, and provide clean, reliable electricity for everyone. These projects are going to create thousands of skilled jobs in Ohio and Pennsylvania, add new energy to the grid, extend the life of three existing nuclear plants, and accelerate new reactor technologies.”</span></p>
<p><em><span>– Joel Kaplan, Chief Global Affairs Officer, Meta</span></em></p></blockquote>
<h2>Supporting New Nuclear Energy With Advanced Technology</h2>
<p><span>As the demand for reliable, scalable, and clean energy continues to rise, advanced nuclear technology has the potential to become a key part of the solution. The latest generation of advanced nuclear reactors are designed to be safer — delivering reliable baseload power that can be efficiently added to existing grids, which makes them ideal for supporting America’s evolving power needs. Our agreements with Oklo and TerraPower will help advance this next generation of energy technology.</span></p>
<p><span>These agreements also mean that Oklo and TerraPower have greater business certainty, can raise capital to move forward with these projects, and ultimately add more energy capacity to the grid. Over time, this will be an important tool in ensuring that grids maintain reliability for all customers and ensure stable wholesale electricity prices.&nbsp;</span></p>
<h2>TerraPower: Investing in Advanced Nuclear Technology<b><br>
</b></h2>
<p><span>Our agreement with TerraPower will provide funding that supports the development of two new </span><a href="https://www.terrapower.com/natrium/"><span>Natrium® units</span></a><span> capable of generating up to 690 MW of firm power with delivery as early as 2032. The agreement also provides Meta with rights for energy from up to six other Natrium units capable of producing 2.1 GW and targeted for delivery by 2035. At a total of eight potential units, with 2.8 GW of baseload energy generation capacity and an additional 1.2 GW of built-in storage, this agreement is Meta’s largest support of advanced nuclear technologies to date.</span></p>

    
    

    

    
<p><span>“To successfully address growing energy demand, we must deploy gigawatts of advanced nuclear energy in the 2030s. This agreement with Meta is designed to support the rapid deployment of our Natrium technology that provides the reliable, flexible, and carbon-free power our country needs,” said Chris Levesque, TerraPower president and CEO. “With our first Natrium plant under development, we have completed our design, established our supply chain, and cleared key regulatory milestones. These successes mean our TerraPower team is well positioned to deliver on this historic multi-unit delivery agreement.”</span></p>
<h2>Oklo: Adding New Nuclear Energy in Ohio</h2>
<p><b></b><span>Our partnership with Oklo helps advance the development of entirely new nuclear energy in Pike County, Ohio. This advanced nuclear technology campus — which may come online as early as 2030 — is poised to add up to 1.2 GW of clean baseload power directly into the PJM market and support our operations in the region.</span></p>

    
    

    

    
<p><span>This agreement lays the foundation for constructing multiple Oklo Aurora Powerhouse reactors, which is expected to create thousands of construction and long-term operations jobs and generate new local and state tax revenue through major investments in energy infrastructure. </span><a href="https://oklo.com/energy/default.aspx"><span>Oklo Aurora powerhouses</span></a><span> are based on proven fast-reactor designs with inherently safe systems capable of using both fresh and repurposed fuel.</span></p>
<p><!--[if lt IE 9]><script>document.createElement('video');</script><![endif]-->
<video id="video-46665-1" width="960" height="540" preload="metadata" controls="controls"><source type="video/mp4" src="https://about.fb.com/wp-content/uploads/2026/01/03_Oklo_Video.mp4?_=1"><a href="https://about.fb.com/wp-content/uploads/2026/01/03_Oklo_Video.mp4">https://about.fb.com/wp-content/uploads/2026/01/03_Oklo_Video.mp4</a></video></p>
<p><span>“Meta’s funding commitment in support of early procurement and development activity is a major step in moving advanced nuclear forward,” said Jacob DeWitte, Oklo’s co-founder and CEO. “Two years ago, Oklo shared its vision to build a new generation of advanced nuclear powerhouses in Ohio. Today, that vision is becoming a reality </span><span>through the support of a multi-year effort with Meta; to deliver clean energy and create long-term, high-quality jobs in Ohio</span><span>.”</span></p>
<h2>Vistra: Extending and Expanding Operational Nuclear Energy<b><br>
</b></h2>
<p><span>Many American nuclear power plants need long-term support and require ongoing investment to maintain best-in-class safety and reliability in operations. For example, our </span><a href="https://about.fb.com/news/2025/06/meta-constellation-partner-clean-energy-project/"><span>first nuclear energy agreement</span></a><span> helped extend the life of a nuclear energy plant in Clinton, Illinois for 20 more years.</span><span><br>
</span></p>
<p><span>Through additional 20-year nuclear energy agreements, we will purchase more than 2.1 GW of energy from two operating Vistra nuclear power plants in Ohio (Perry and Davis-Besse), in addition to the energy from expansions (uprates) at these two Ohio plants and a third Vistra nuclear plant in Pennsylvania (Beaver Valley). All three plants are located in and will continue to deliver power into the PJM grid region, and these expansions will be the largest nuclear uprates supported by a corporate customer in the US.</span></p>
<p><a href="https://about.fb.com/wp-content/uploads/2026/01/04_Vistra.jpg"><img data-recalc-dims="1" loading="lazy" decoding="async" src="https://about.fb.com/wp-content/uploads/2026/01/04_Vistra.jpg?resize=960%2C836" alt="Image of a Vistra nuclear power plant" width="960" height="836" srcset="https://about.fb.com/wp-content/uploads/2026/01/04_Vistra.jpg?w=1920 1920w, https://about.fb.com/wp-content/uploads/2026/01/04_Vistra.jpg?w=300 300w, https://about.fb.com/wp-content/uploads/2026/01/04_Vistra.jpg?w=768 768w, https://about.fb.com/wp-content/uploads/2026/01/04_Vistra.jpg?w=1024 1024w, https://about.fb.com/wp-content/uploads/2026/01/04_Vistra.jpg?w=1536 1536w, https://about.fb.com/wp-content/uploads/2026/01/04_Vistra.jpg?w=1240 1240w, https://about.fb.com/wp-content/uploads/2026/01/04_Vistra.jpg?w=689 689w" sizes="(max-width: 960px) 100vw, 960px"></a></p>
<p><span>Meta’s commitments ensure that these facilities can continue providing reliable power to the regional electricity grid. The new additional uprate capacity at each of them, totaling 433 MW, is expected to come online in the early 2030s — supporting the growing needs in the PJM grid region in the future. This means consumers will benefit from a larger supply of reliable, always-ready power through Meta-supported uprates to the Vistra facilities.&nbsp;&nbsp;</span></p>
<p><span>“This is an exciting collaboration for us at Vistra. We are focused on meeting customer needs, and providing reliable, carbon-free nuclear power is something we’re proud to offer Meta,” said Jim Burke, president and CEO of Vistra. “This agreement is beneficial in many ways — it powers American innovation and AI technology, while allowing us to extend the operational life of these plants, boost the capacity of the nuclear reactors to support the grid, protect existing jobs while creating new ones, and continue investing in the communities where our plants are located. Partnerships like ours are key in moving America forward in both AI and energy leadership.”</span></p>
<h2>Supporting Our Energy Future</h2>
<p><span>Today’s announcements are the result of a thorough </span><a href="https://sustainability.atmeta.com/blog/2024/12/03/accelerating-the-next-wave-of-nuclear-to-power-ai-innovation/"><span>nuclear RFP process</span></a><span> where we learned how we could improve our support of nuclear projects’ development lifecycles and identify specific partner companies to help scale and accelerate the buildout of new nuclear energy production. For more than a decade, we’ve worked with innovative partners to back clean energy projects that support the grid — adding nearly 28 GW of new energy to grids across 27 states. We’re proud to include Oklo, TerraPower, and Vistra on that list and support their work to boost America’s energy leadership.</span></p>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[‘Fuck you, make me’ without saying the words (115 pts)]]></title>
            <link>https://daringfireball.net/2026/01/fuck_you_make_me_without_saying_the_words</link>
            <guid>46577869</guid>
            <pubDate>Sun, 11 Jan 2026 17:56:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daringfireball.net/2026/01/fuck_you_make_me_without_saying_the_words">https://daringfireball.net/2026/01/fuck_you_make_me_without_saying_the_words</a>, See on <a href="https://news.ycombinator.com/item?id=46577869">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="Box">



<p>Elizabeth Lopatto, writing at The Verge, “<a href="https://www.theverge.com/policy/859902/apple-google-run-by-cowards">Tim Cook and Sundar Pichai Are Cowards</a>”:</p>

<blockquote>
  <p>Since X’s users started using <a href="https://www.theverge.com/ai-artificial-intelligence/855832/grok-undressing-children-csam-law-x-elon-musk">Grok to undress women and
children</a> using deepfake images, I have been waiting for
what I assumed would be inevitable: X getting booted from Apple’s
and Google’s app stores. The fact that it hasn’t happened yet
tells me something serious about Silicon Valley’s leadership: Tim
Cook and Sundar Pichai are spineless cowards who are terrified of
Elon Musk.</p>
</blockquote>

<p>Lopatto’s outrage and righteous anger are justified, but I think mostly misdirected. Apple and Google — and thus, Cook and Pichai, as the men who sit behind the desks where the buck stops at both companies — are culpable. But this is ultimately not about them, and not about Musk. It’s Trump, as president, they fear. Not Musk. And they are correct to fear Trump.</p>

<p>Year one of Trump 2.0 has crystallized what had become — after decades of deliberate restraint after World War II, and even more so after the end of the Cold War — overlooked. The Presidency of the United States bestows upon its officeholder enormous, unparalleled, power. No one was afraid of Trump after he lost to Joe Biden in 2020. The man was <a href="https://www.npr.org/2024/05/30/g-s1-1848/trump-hush-money-trial-34-counts">convicted of 34 felonies in a cold New York City courtroom in May 2024</a>, a mere 19 months ago. Trump expected and asked for riots outside the courtroom. He got nothing but <a href="https://www.nytimes.com/2024/05/02/nyregion/trump-trial-supporters.html">pathetic support from a handful of kooks</a>. A year earlier, he lost <a href="https://en.wikipedia.org/wiki/E._Jean_Carroll_v._Donald_J._Trump">a humiliating sexual assault civil lawsuit to E. Jean Carroll</a>. Trump, just a year and a half ago, was a buffoon getting his mug shot taken. Today he’s arguing that his power is <a href="https://www.nytimes.com/2026/01/08/us/politics/trump-interview-power-morality.html?unlocked_article_code=1.DVA.5wt4.ux02n3D96aZH&amp;smid=url-share">unchecked by anything other than his own sense of morality</a>.</p>

<p>No other president has ever abused (or, if you support him, wielded) the powers of the office like Trump has. The power and influence of Tim Cook and Sundar Pichai, CEOs of two of the top five companies in the world, isn’t merely superseded by Trump’s power and influence as president. Their power and influence are <em>dwarfed</em> by Trump’s. Any credible argument about how they should act must acknowledge that profound imbalance.</p>

<p>Lopatto, in her closing:</p>

<blockquote>
  <p>I never want to hear any moral grandstanding from these boys ever
again. The next time Tim Cook says “<a href="https://www.nbcnews.com/tech/tech-news/apple-ceo-tim-cook-slams-facebook-privacy-human-right-it-n860816">privacy is a human
right</a>,” the only possible response is to laugh in his face.
I mean, Apple and Google are fine distributing an app that has
created an <a href="https://www.motherjones.com/politics/2026/01/grok-x-musk-deepfake-renee-good-ice/">undressed image Grok made of Renee Nicole Good</a>,
the mother who was shot by ICE in Minneapolis. How <em>do</em> you plan
to defend getting rid of the <a href="https://www.theverge.com/news/791170/iceblock-app-store-removed-by-apple">ICEBlock app</a> while allowing X
to generate degrading images of a woman ICE killed? Can Apple and
Google even identify their values beyond their commitment to
“shareholder value”? What’s your fucking endgame here, guys?</p>
</blockquote>

<p>The profound power imbalance here is frustrating. But also terrifying. It’s <a href="https://daringfireball.net/2025/08/gold_frankincense_and_silicon">folly to think these CEOs should steer their companies into direct confrontation with Trump</a>. It would do no ultimate good for Apple or Google to burn themselves to the ground in protest. These men aren’t beholden to shareholders, per se. They’re doing their duty to institutions they’ve devoted their lives to. Companies that are worth preserving and protecting. Perhaps not in your estimation, but certainly from theirs.</p>

<p>But abject obsequiousness — which more and more seems the path Cook and Pichai are choosing — is no more justifiable a response than corporate suicide. The situation is not binary: acquiescence or war. There is a broad middle ground, founded on principle.</p>

<p>Disney’s response to the Jimmy Kimmel controversy a few months ago <a href="https://daringfireball.net/linked/2025/10/07/hodges-cook-iceblock">shows the way</a>. Defend the company’s principles while simultaneously defending the company from Trump’s demented wrath. You can take the position of “<a href="https://daringfireball.net/linked/2025/10/03/fuck-you-make-me">Fuck you, make me</a>” without ever saying those words. Objection is not confrontation. Do the right thing and enforce the App Store and Play Store guidelines, and remove X and Grok from the stores. Make Musk object. Make the Trump administration object. Make them defend the indefensible — in public. Make clear why the apps were removed from the app stores and force Musk — and Trump, if he chooses — to argue that those things are A-OK by them. In court.</p>

<p>The judicious path for Apple and Google (and every other U.S. company) may well be to obey the law, even when the law is being actively corrupted. But the correct path is <em>not</em> to <a href="https://daringfireball.net/linked/2025/03/24/on-tyranny">obey in advance</a>. Stand behind the law while the law still exists on your side. Disney resisted Trump’s preposterous demand that they fire Jimmy Kimmel without lasting controversy, simply by standing firm in their conviction. Apple and Google could certainly do the same regarding apps that are being used to <a href="https://www.bbc.com/news/articles/cvg1mzlryxeo">generate CSAM</a> and <a href="https://www.nbcnews.com/tech/internet/x-paywall-ai-image-grok-app-bikini-allows-sexual-deepfakes-rcna252647">deepfake harassment</a>, regardless if the apps are part of the private fiefdom of Trump’s ally Elon Musk. It’s wise for Cook and Pichai to <a href="https://daringfireball.net/2025/08/gold_frankincense_and_silicon">pick their battles</a>. This one, I think, is worth picking. This is a moment when the App Store and Play Store can stand firmly on the side of longstanding and correct societal norms.</p>



 <!-- PreviousNext -->
</div></div>]]></description>
        </item>
    </channel>
</rss>