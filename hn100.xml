<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 12 Oct 2023 15:00:08 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Microsoft reveals IRS notice asking for $28.9B in back taxes (166 pts)]]></title>
            <link>https://www.engadget.com/microsoft-reveals-irs-notice-asking-for-289-billion-in-back-taxes-055326006.html</link>
            <guid>37855213</guid>
            <pubDate>Thu, 12 Oct 2023 09:55:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.engadget.com/microsoft-reveals-irs-notice-asking-for-289-billion-in-back-taxes-055326006.html">https://www.engadget.com/microsoft-reveals-irs-notice-asking-for-289-billion-in-back-taxes-055326006.html</a>, See on <a href="https://news.ycombinator.com/item?id=37855213">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Microsoft owes the <a data-i13n="cpos:1;pos:1" href="https://www.engadget.com/irs-accidentally-exposed-confidential-information-134736114.html" data-ylk="slk:Internal Revenue Service;cpos:1;pos:1;elm:context_link;itc:0">Internal Revenue Service</a> (IRS) $28.9 billion in back taxes, not including penalties and interest, at least according to the tax authority. The tech giant has <a data-i13n="elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1" href="https://microsoft.gcs-web.com/node/31951/html" rel="nofollow noopener" target="_blank" data-ylk="slk:revealed in a filing;elm:context_link;elmt:doNotAffiliate;cpos:2;pos:1;itc:0">revealed in a filing</a> with the Securities and Exchange Commission that it received a series of Notices of Proposed Adjustment (NOPAs) from the IRS for the tax years 2004 to 2013. In its filing, it said that it's been working with the IRS for nearly a decade to address the authority's questions about how it distributed its profits among countries and jurisdictions, and this is the agency's decision after a lengthy investigation.</p><p>To be exact, the IRS audit centered around a practice known as "transfer pricing," which legally allowed companies to allocate profits and expenses between their operations in different regions. Microsoft explained that a lot of large multinational corporations practice this cost-sharing scheme to reflect "the global nature of their business." In its case, its subsidiaries shared in the costs of developing some IPs, which means that they're also entitled to the related profits. As <a data-i13n="cpos:3;pos:1" href="https://apnews.com/article/microsoft-taxes-irs-96eb66abe86de19f1108209a8d57431a" rel="nofollow noopener" target="_blank" data-ylk="slk:AP;cpos:3;pos:1;elm:context_link;itc:0"><em>AP</em></a> notes, though, critics of the regulation argue that companies frequently use it to minimize the taxes they have to pay by reporting lower profits in high tax countries, and vice versa.</p><p>Microsoft explained that the issues raised by the IRS are only relevant to those aforementioned years, because it has since changed its corporate structure and practices. Nevertheless, the IRS believes Microsoft owes $28.9 billion in back taxes. The tech giant disagrees, as expected, and said that newer tax laws could reduce the back taxes it owes from this particular audit by $10 billion. Based on its plan of action shared with the SEC, the company intends to contest the decision to the best of its ability: Microsoft said that it will pursue an appeal within the IRS, which typically takes years to complete, and will even "contest any unresolved issues through the courts" if needed.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[47 Anime for 47 Prefectures in Japan (122 pts)]]></title>
            <link>https://www.tokyoweekender.com/art_and_culture/entertainment-art_and_culture/47-anime-locations-47-prefectures-japan/</link>
            <guid>37855057</guid>
            <pubDate>Thu, 12 Oct 2023 09:26:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tokyoweekender.com/art_and_culture/entertainment-art_and_culture/47-anime-locations-47-prefectures-japan/">https://www.tokyoweekender.com/art_and_culture/entertainment-art_and_culture/47-anime-locations-47-prefectures-japan/</a>, See on <a href="https://news.ycombinator.com/item?id=37855057">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Japanese animation can be a vehicle to take you all around Japan, from legendary temples and nature spots, to small-town streets and convenience stores. Very often the locations are drawn in so much detail, that they seem like copies of real-life places. Here’s a list of all 47 prefectures in Japan and anime that take place in each prefecture.</p>
<h2 id="651f78b1ef141">Hokkaido</h2>
<p><iframe title="Golden Kamuy (Anime-Trailer)" width="500" height="281" src="https://www.youtube.com/embed/HrHcN08d7dQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>

<h3>Golden Kamuy</h3>
<p>This is the most representative story from Hokkaido, with both the anime and manga showcasing various locations across the island. &nbsp;The story takes place after the Russo-Japanese War (1904-1905) and gives a spotlight to Hokkaido’s indigenous Ainu people, even featuring the Ainu language.</p>
<h2 id="651f78b1ef169">Tohoku</h2>
<p><iframe loading="lazy" title="Flying Witch Official Trailer" width="500" height="281" src="https://www.youtube.com/embed/tlS3BXTq7wQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h3>Aomori</h3>
<p>Aomori is the scene for an anime featuring a young witch and her black cat. It’s not Kiki, but Makoto Kowata and she makes the opposite move — from the big city to the countryside, more specifically from Yokohama to rural Aomori. <a href="https://myanimelist.net/anime/31376/Flying_Witch" target="_blank" rel="noopener"><em>Flying Witch</em></a> is a 2017 anime, showing the budding trend of escaping to nature.</p>
<h3>Akita</h3>
<p>Fans of the Akita breed of dog and the famous Hachiko should watch <em><a href="https://myanimelist.net/anime/589/Ginga_Nagareboshi_Gin" target="_blank" rel="noopener">Silverfang: The Shooting Star Gin</a>. </em>The main character is an Akita puppy who leaves his master to join a pack of wild dogs and takes us across the Akita wilderness.</p>
<h3>Iwate</h3>
<p><a href="https://myanimelist.net/anime/4062/Musashi_no_Ken" target="_blank" rel="noopener"><em>Musashi no Ken (Musashi’s Sword)</em></a> is both a way to see Iwate Prefecture in anime and to look into the world of the martial art, kendo. It shows the peaceful environments of small towns in Iwate and the characters often speak in the local dialect. The anime even manages to weave in the poetry of literary great Kenji Miyazawa, an Iwate native.</p>
<p><iframe loading="lazy" title="Haikyu!! - Official Trailer" width="500" height="281" src="https://www.youtube.com/embed/JOGp2c7-cKc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h3>Miyagi</h3>
<p>The widely popular volleyball anime <a href="https://myanimelist.net/anime/20583/Haikyuu?q=haikyu&amp;cat=anime" target="_blank" rel="noopener"><em>Haikyu!!</em></a> takes place in Miyagi Prefecture, mostly in its capital Sendai. Since it’s a sports-themed anime, you can see depictions of real-life gymnasiums and sports centers in the prefecture, as well as in Tokyo.</p>
<h3>Yamagata</h3>
<p>Excluding theories that the bathhouse in <em>Spirited Away</em> is based on Ginzan Onsen in Yamagata, this prefecture is best viewed through the lens of another, albeit less known, Ghibli film. The main character in <a href="https://myanimelist.net/anime/1029/Omoide_Poroporo" target="_blank" rel="noopener"><em>Only Yesterday</em></a> travels from Tokyo to Yamagata where she falls in love with the place and with a Yamagata local.</p>
<h3>Fukushima</h3>
<p><a href="https://myanimelist.net/anime/32248/Masamune_Datenicle" target="_blank" rel="noopener"><em>Masamune Datenicle</em></a> (a play on “Date” and “chronicle”) is a 2016 anime produced by a studio in Fukushima and aims to promote the prefecture’s history and culture. Date Masamune was a famous Tohoku samurai who still has a lot of fans to this day.</p>
<h2 id="651f78b1ef16e">Chubu</h2>
<p><iframe loading="lazy" title="Laid-Back Camp Season 2 Official Trailer | Anime Clips" width="500" height="281" src="https://www.youtube.com/embed/8iQLfcQXQIs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h3>Yamanashi</h3>
<p><a href="https://myanimelist.net/anime/34798/Yuru_Camp%E2%96%B3" target="_blank" rel="noopener"><em>Laid Back Camp</em></a> takes you to several nature spots in Japan, but many are in Yamanashi Prefecture. Mount Fuji and its volcanic lakes feature prominently.</p>
<h3>Shizuoka</h3>
<p>This prefecture also pops up in <em>Laid Back Camp</em>, but <a href="https://myanimelist.net/anime/37105/Grand_Blue?cat=anime" target="_blank" rel="noopener"><em>Grand Blue</em></a> showcases the marine beauty of the Izu Peninsula. The story follows a character living above his uncle’s diving shop. He eventually enjoys the laid-back lifestyle there, despite initial reluctance.</p>
<h3>Niigata</h3>
<p>The anime <a href="https://myanimelist.net/anime/33003/Mahou_Shoujo_Ikusei_Keikaku" target="_blank" rel="noopener"><em>Magical Girl Raising Project</em></a>, based on the light novels by Asari Endo, takes place in the cryptic N-city. However, with exact depictions of Takada Station, Takada Castle and Takada Park’s Gokurakubashi Bridge (to name a few), we can see it’s based on Joetsu city, the author’s hometown.</p>
<p><iframe loading="lazy" title="Summer Wars - Official Trailer" width="500" height="375" src="https://www.youtube.com/embed/2BB5V6CgDOg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h3>Nagano</h3>
<p>Mamoru Hosoda’s film <a href="https://myanimelist.net/anime/5681/Summer_Wars" target="_blank" rel="noopener"><em>Summer Wars</em></a> takes us to Ueda, a small town in Nagano, where we see Ueda Castle and the lush Nagano countryside.</p>
<h3>Aichi</h3>
<p><a href="https://myanimelist.net/anime/37940/Yatogame-chan_Kansatsu_Nikki" target="_blank" rel="noopener"><em>Yatogame-chan Kansatsu Nikki</em></a> follows a Tokyo high schooler moving to Nagoya. He learns about the new place after meeting the quirky Monaka Yatogame, a fellow student who speaks in the Nagoya dialect.</p>
<h3>Gifu</h3>
<p>Half of <a href="https://myanimelist.net/anime/32281/Kimi_no_Na_wa" target="_blank" rel="noopener"><em>Your Name</em></a>, Makoto Shinkai’s hit anime film, takes place in Tokyo, while the other half happens in the small town of Itomori. Itomori is based on a real-life location in Gifu Prefecture.</p>

<h3>Ishikawa</h3>
<p>Set in a traditional onsen (based on the historic Yuwaku Spa), <a href="https://myanimelist.net/anime/9289/Hanasaku_Iroha" target="_blank" rel="noopener"><em>Hanasaku Iroha</em></a> follows a Tokyo teenager sent to live and work in rural Ishikawa Prefecture.</p>
<h3>Toyama</h3>
<p>Mamoru Hosoda’s film <a href="https://animetourism88.com/en/88AnimeSpot/okamikodomo" target="_blank" rel="noopener"><em>Wolf Children</em></a> takes place in the Toyama countryside. The house where the characters live is a real place dating back 130 years.</p>
<h3>Fukui</h3>
<p>The main characters of <a href="https://myanimelist.net/anime/19257/Megane-bu" target="_blank" rel="noopener"><em>Meganebu!</em></a> are glass-wearing nerds on a quest to make the best glasses. The anime takes place in Fukui, a prefecture known for eyewear production.</p>
<h2 id="651f78b1ef170">Kanto</h2>
<p><img decoding="async" loading="lazy" src="https://www.tokyoweekender.com/wp-content/uploads/2022/03/shutterstock_1342808972-1024x683.jpg" alt="real-life anime locations in tokyo" width="1024" height="683"></p>
<h3>Tokyo</h3>
<p>Tokyo is the setting of so many anime, that it’s impossible to choose one. Check out our article about <a href="https://www.tokyoweekender.com/art_and_culture/entertainment-art_and_culture/movies-tv/anime-locations-in-tokyo/" target="_blank" rel="noopener">10 anime locations in Tokyo</a>, as well as our <a href="https://www.tokyoweekender.com/japan-life/nana-anime-locations-jackson-hole/" target="_blank" rel="noopener"><em>Nana</em> anime article</a> and <a href="https://www.tokyoweekender.com/art_and_culture/entertainment-art_and_culture/bocchi-the-rock-anime-locations-shimokitazawa/" target="_blank" rel="noopener"><em>Bocchi the Rock</em> locations in Shimokitazawa</a>.</p>
<h3>Saitama</h3>
<p>The prefecture’s Chichibu area is the location for the iconic anime <a href="https://myanimelist.net/anime/9989/Ano_Hi_Mita_Hana_no_Namae_wo_Bokutachi_wa_Mada_Shiranai" target="_blank" rel="noopener"><em>Anohana: The Flower We Saw That Day,</em></a> with Chichibu Bridge featuring in promotional imagery.</p>
<h3>Chiba</h3>
<p><em><a href="https://myanimelist.net/anime/14813/Yahari_Ore_no_Seishun_Love_Comedy_wa_Machigatteiru" target="_blank" rel="noopener">Yahari Ore no Seishun Love Comedy wa Machigatteiru</a> (My Teen Romantic Comedy SNAFU)</em> takes place in a high school in Chiba, with outings showing us parks and beaches in Chiba as well as the Chiba Monorail.</p>
<h3>Kanagawa</h3>
<p>The iconic basketball anime<a href="https://myanimelist.net/anime/170/Slam_Dunk" target="_blank" rel="noopener"><em> Slam Dunk</em></a> takes place in Tokyo-adjacent Kanagawa. The featured locations, including the Enoden (Enoshima Electric Railway), are some of the most visited real-life anime locations in Japan.</p>
<h3>Ibaraki</h3>
<p>The seaside town of Oarai is the locale for the <a href="https://myanimelist.net/anime/14131/Girls___Panzer" target="_blank" rel="noopener"><em>Girls &amp; Panzer</em></a> anime. Oarai has embraced this connection with many posters and character cutouts around the town, as well as holding the fictional tank parades from the anime in real life.</p>
<h3>Tochigi</h3>
<p>One part of the film<em>&nbsp;<a href="https://www.imdb.com/title/tt0983213/">5 Centimeters Per Second</a></em> takes place at Iwafune Station in Tochigi Prefecture. It also shows landscapes of the prefecture, such as Mount Iwafune.</p>
<h3>Gunma</h3>
<p><em><a href="https://myanimelist.net/anime/37258/Omae_wa_Mada_Gunma_wo_Shiranai" target="_blank" rel="noopener">You Don’t Know Gunma Yet</a>‘</em>s whole plot is to shatter negative stereotypes about Gunma as we follow a protagonist from Chiba who moves to the prefecture.</p>
<h2 id="651f78b1ef17d">Kansai</h2>
<p><iframe loading="lazy" title="『夜は短し歩けよ乙女』予告編" width="500" height="281" src="https://www.youtube.com/embed/v6vQwCCz_OU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h3>Kyoto</h3>
<p>Just like Tokyo, there are many anime set in Kyoto or visiting Kyoto in some episodes. To pick one example, watch <a href="https://myanimelist.net/anime/34537/Yoru_wa_Mijikashi_Arukeyo_Otome" target="_blank" rel="noopener"><em>The Night is Short, Walk On Girl</em></a>, an anime film that depicts Kyoto by night.</p>
<h3>Nara</h3>
<p>A mundane part of Nara (not the touristy temples and deer) is the setting for <a href="https://myanimelist.net/anime/18153/Kyoukai_no_Kanata" target="_blank" rel="noopener"><em>Beyond the Boundary</em></a>, a supernatural anime that depicts real-life locations.</p>
<h3>Shiga</h3>
<p>An anime that follows a high school band, <a href="https://myanimelist.net/anime/7791/K-On" target="_blank" rel="noopener"><em>K-On!</em></a> takes place in Shiga, near Kyoto. It features real-life schools, concert halls, restaurants and parks from Shiga, as well as some Kyoto spots.</p>
<h3>Hyogo</h3>
<p>Nishinomiya in Hyogo is the location of <a href="https://myanimelist.net/anime/849/Suzumiya_Haruhi_no_Yuuutsu" target="_blank" rel="noopener"><em>The Melancholy of Haruhi Suzumiya</em></a> and it’s the original story’s writer’s hometown too. Many of the cafés, temples and streets in the anime scenes can be found in the town.</p>

<h3>Osaka</h3>
<p>For a taste of Osaka, watch <a href="https://myanimelist.net/anime/2034/Lovely%E2%98%85Complex" target="_blank" rel="noopener"><em>Lovely Complex</em></a>, a romantic comedy that depicts many of the city’s landmarks. The characters in this one also talk in the lovable Kansai dialect.</p>
<h3>Wakayama</h3>
<p><a href="https://myanimelist.net/anime/47194/Summertime_Render" target="_blank" rel="noopener"><em>Summer Time Rendering</em></a> takes place on the fictional Hitogashima Island, which is entirely based on the real Tomogashima Island off the coast of Wakayama Prefecture.</p>
<h3>Mie</h3>
<p><a href="https://myanimelist.net/anime/587/Hanbun_no_Tsuki_ga_Noboru_Sora" target="_blank" rel="noopener"><em>Looking Up at the Half-Moon</em></a> is a short anime series taking place in Mie Prefecture, following teenagers staying in a hospital. The subsequent live-action film was also shot on location in Mie.</p>
<h2 id="651f78b1ef17f">Chugoku</h2>
<p><iframe loading="lazy" title="TOTTORI SAND DUNES CONAN AIRPORT - Hometown of &quot;Detective Conan&quot; Part 1" width="500" height="281" src="https://www.youtube.com/embed/F6w_oj6WuoE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h3>Tottori</h3>
<p>Tottori is a special case as it’s the hometown of Gosho Aoyama, the author of <em>Case Closed</em> (Detective Conan). The long-running anime takes place all over Japan, but you can experience it in real life the most in Tottori. With Conan appearances starting at Tottori Airport, the whole prefecture is a treasure trove for Detective Conan&nbsp;fans.</p>
<h3>Shimane</h3>
<p><a href="https://myanimelist.net/anime/1026/Yakumotatsu" target="_blank" rel="noopener"><em>Yakumotatsu (Eight Clouds Rising)</em></a> is set in Shimane Prefecture and Izumo, the birthplace of Japanese mythology. Its plot delves into myths, superpowers and millennia-old traditions.</p>
<h3>Okayama</h3>
<p>The quirky alien comedy <a href="https://myanimelist.net/anime/696/Tenchi_Muyou" target="_blank" rel="noopener"><em>Tenchi Muyo!</em></a> takes place at Tenchi’s house, which is in the grounds of Masaki Shrine in Okayama Prefecture. Many of the characters’ names also match with Okayama toponyms.</p>
<h3>Hiroshima</h3>
<p><a href="https://myanimelist.net/anime/231/Asagiri_no_Miko" target="_blank" rel="noopener"><em>Shrine of the Morning Mist</em></a>‘s location is based on the city of Miyoshi, Hiroshima, known for its morning fog and old temples.</p>
<h3>Yamaguchi</h3>
<p>Set in the 1950s, <a href="https://myanimelist.net/anime/5084/Mai_Mai_Shinko_to_Sennen_no_Mahou" target="_blank" rel="noopener"><em>Mai Mai Miracle</em></a> is a feature anime film set in Hofu city of Yamaguchi Prefecture. Although the city has changed somewhat since the ’50s, the overall resemblance can still be seen.</p>
<h2 id="651f78b1ef181">Shikoku</h2>
<blockquote>
<p dir="ltr" lang="ja">女の子がやるから「おへんろ。」になるのであって、おっさんがやると水曜どうでしょうになるんですよ。 <a href="https://twitter.com/hashtag/%E3%81%8A%E3%81%B8%E3%82%93%E3%82%8D?src=hash&amp;ref_src=twsrc%5Etfw">#おへんろ</a> <a href="https://t.co/T3ogIeeyzZ">pic.twitter.com/T3ogIeeyzZ</a></p>
<p>— リジス (@lidges) <a href="https://twitter.com/lidges/status/1055445998531600384?ref_src=twsrc%5Etfw">October 25, 2018</a></p></blockquote>

<h3>Tokushima</h3>
<p><a href="https://japan-programcatalog.com/en/program/ohenro" target="_blank" rel="noopener"><em>Ohenro</em></a> takes viewers around the famous <a href="https://www.tokyoweekender.com/travel/shikoku-tales-travelers-tackling-shikoku-pilgrimage-will-stories-share-three-historic-sites-tokushima-prefecture/" target="_blank" rel="noopener">88-temple pilgrimage</a> on the island of Shikoku. This anime brings us to several prefectures in Shikoku, but with a strong focus on Tokushima. The story also began as a column in a Tokushima newspaper.</p>
<h3>Kagawa</h3>
<p>The prefecture with the best udon is naturally the setting for the <a href="https://myanimelist.net/anime/32673/Udon_no_Kuni_no_Kiniro_Kemari" target="_blank" rel="noopener"><em>Poco’s Udon World</em></a> anime, particularly in Takamatsu and Shodo Island. It shows real-life udon restaurants, shopping streets and nature spots.</p>
<h3>Ehime</h3>
<p>Though the island where <a href="https://myanimelist.net/anime/98/Mai-HiME" target="_blank" rel="noopener"><em>Mai-HiME</em></a> takes place is not named or specified, many believe it to be in Ehime Prefecture.</p>
<h3>Kochi</h3>
<p><a href="https://myanimelist.net/anime/743/Umi_ga_Kikoeru" target="_blank" rel="noopener"><em>Ocean Waves</em></a> is a high school romance that takes place in Kochi Prefecture and, as the title suggests, it takes us to the seaside and small towns.</p>
<h2 id="651f78b1ef182">Kyushu</h2>
<p><iframe loading="lazy" title="Hakata Tonkotsu Ramens - Trailer" width="500" height="281" src="https://www.youtube.com/embed/DtnJHPtVzqo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<h3>Fukuoka</h3>
<p>The city known for <a href="https://www.tokyoweekender.com/travel/ichiran-tonkotsu-ramen/" target="_blank" rel="noopener">tonkotsu ramen</a> and riverside stalls is best enjoyed in the <a href="https://myanimelist.net/anime/35889/Hakata_Tonkotsu_Ramens"><em>Hakata Tonkotsu Ramens</em></a> anime that shows us Fukuoka nightlife and a fictional criminal underbelly.</p>
<h3>Saga</h3>
<p>The characters in <a href="https://myanimelist.net/anime/32995/Yuri_on_Ice" target="_blank" rel="noopener"><em>Yuri!! On Ice</em></a> figure skate their way to Barcelona, but the main plot takes place in Saga Prefecture, particularly the castle town of Karatsu. Karatsu has embraced this connection and displays the characters around town.</p>
<h3>Nagasaki</h3>
<p><a href="https://myanimelist.net/anime/22789/Barakamon" target="_blank" rel="noopener"><em>Barakamon</em></a> follows a Tokyo calligrapher sent to the <a href="https://www.tokyoweekender.com/travel/people-churches-goto-islands-hidden-christians-japan/" target="_blank" rel="noopener">Goto Islands</a> in Nagasaki Prefecture. Locations include Fukue Airport, beaches and temples.</p>
<h3>Oita</h3>
<p><a href="https://myanimelist.net/anime/2422/Kenritsu_Chikyuu_Boueigun" target="_blank" rel="noopener"><em>Prefectural Earth Defense Force</em></a> takes place in Kyushu, and though the prefecture is not specified, people firmly believe it’s Oita.</p>
<p>Bonus: the over-the-top comical <a href="https://myanimelist.net/anime/3702/Detroit_Metal_City" target="_blank" rel="noopener"><em>Detroit Metal City</em></a> takes place in Tokyo, but the protagonist is from Inukai, Oita Prefecture.</p>
<h3>Kumamoto</h3>
<p><a href="https://myanimelist.net/anime/4081/Natsume_Yuujinchou" target="_blank" rel="noopener"><em>Natsume’s Book of Friends</em></a> acquaints us with the supernatural folklore of yokai spirits and takes place in the Hitoyoshi Kuma region of Kumamoto Prefecture. Due to its theme, it shows many old revered temples and shrines, in addition to natural landscapes.</p>
<h3>Miyazaki</h3>
<p>Also known for traditional spirituality, Miyazaki Prefecture is the setting for <a href="https://myanimelist.net/anime/29854/Ushio_to_Tora_TV" target="_blank" rel="noopener"><em>Ushio and</em>&nbsp;Tora,</a> an anime that takes place in a temple and deals with the supernatural.</p>
<h3>Kagoshima</h3>
<p>Tanegashima Island in Kagoshima Prefecture is the setting of the <a href="https://myanimelist.net/anime/13599/Robotics_Notes" target="_blank" rel="noopener"><em>Robotics;Notes</em></a> anime. Tanegashima Space Center, the main rocket launch facility for JAXA, features heavily because the main plot centers around the creation of a giant mecha robot.</p>
<h2 id="651f78b1ef184">Okinawa</h2>
<p>It seems that every other anime has a filler episode including a trip to Okinawa. There are, however, anime set entirely in Okinawa, including <em><a href="https://myanimelist.net/anime/15043/Haitai_Nanafa">Haitai Nanafa</a>, </em>which features a local soba shop and two sisters helping their grandmother run it. As well as Okinawan food, you can also see beautiful architecture and landscapes.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Email and Git = <3 (180 pts)]]></title>
            <link>https://git-send-email.io/</link>
            <guid>37854995</guid>
            <pubDate>Thu, 12 Oct 2023 09:16:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://git-send-email.io/">https://git-send-email.io/</a>, See on <a href="https://news.ycombinator.com/item?id=37854995">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <p>
        <a target="_blank" rel="noopener" href="https://git-scm.com/">Git</a>
        ships with built-in tools for collaborating over email. With this
        guide, you'll be contributing to email-driven projects like the Linux
        kernel, PostgreSQL, or even git itself in no time.
      </p>
      <div id="step-2">
        <h2>
          <small>Step two</small> Configuration
        </h2>
        <div>
          <p>
            You only need to complete this step once for each machine you
            intend to send emails from.
          </p>
          <p>
            Use <code>git config --global --edit</code> to open your <strong>global
            configuration file</strong> in your default editor.
          </p>
          <div>
            <div>
              <p><label for="mailer-gmail">Gmail</label></p><div>
                <p>
                  There are two possible ways of using Gmail with
                  <code>git send-email</code>:
                </p>
                <ol>
                  <li>
                    First, make sure that <a href="https://support.google.com/accounts/answer/185839" target="_blank">two-factor authentication</a> is enabled for your Google
                    account. Then, obtain an application-specific password
                    for git from the <a href="https://security.google.com/settings/security/apppasswords" target="_blank">app passwords</a> page. To store this password with git,
                    run this command:
                    <pre>git config --global sendemail.smtpPass 'your password'</pre>
                    Next step is to add these details to your global
                    configuration file:
                    <pre>[sendemail]
       smtpserver = smtp.gmail.com
       smtpuser = you@gmail.com
       smtpencryption = tls
       smtpserverport = 587</pre>
                    Be sure to fill in your own email address under
                    <code>smtpuser</code>.
                  </li>
                  <li>
                    It is still possible to use <code>git send-email</code>
                    without two-factor authentication and application-specific
                    password, but this requires installation and configuration
                    of <a href="https://github.com/google/gmail-oauth2-tools/tree/master/go/sendgmail" target="_blank">the special tool</a>, which mimics regular
                    <code>sendmail</code>.
                  </li>
                </ol>
                <p>
                  Also, if you haven't yet, run these
                  commands - again, making the appropriate changes:
                </p>
                <pre>git config --global user.email "you@gmail.com"
<!--              -->git config --global user.name "Your Name"</pre>
                <p><a href="#step-3">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="mailer-protonmail">Protonmail</label></p><div>
                <p>
                  Protonmail does not support the open, industry-standard
                  protocols necessary for git send-email to work
                  out-of-the-box. To solve this, Protonmail offers
                  <a href="https://protonmail.com/bridge/">Protonmail Bridge</a>.
                  Otherwise, you  need to install &amp; configure
                  <a href="https://github.com/emersion/hydroxide">Hydroxide</a>
                  to connect to Protonmail with SMTP. Once you have configured
                  Protonmail Bridge or Hydroxide, use its SMTP details along
                  with the generic instructions below.
                </p>
                <p>
                  <strong>Protonmail bridge users:</strong> the bridge uses SSL
                  authentication, but it self-signs the certificate used for 
                  SSL, so you will need to disable SSL verification with the 
                  daemon in your git config by setting an empty value for 
                  sendemail.smtpsslcertpath.
                </p>
                <p>
                  Be advised that Protonmail is generally known to be a pretty
                  bad email host. They will munge up your outgoing emails and
                  your patches may fail to apply when received by the other end.
                  Not to mention their mistreatment of open source and false
                  promises of security! You should consider a different mail
                  provider.
                </p>
                <p><a href="#step-3">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="mailer-fastmail">Fastmail</label></p><div>
              <p>
                Visit <a href="https://www.fastmail.help/hc/en-us/articles/360058752854">the
                Fastmail instructions for adding a new third-party app</a>.
                Add the following details, making the appropriate changes,
                including the "app password" that was generated from following
                those Fastmail instructions:
              </p>
              <pre>[sendemail]
    smtpserver = smtp.fastmail.com
    smtpuser = your-username@fastmail.whatev
    smtpencryption = ssl
    smtpserverport = 465
    smtppass = whatwasautogenerated</pre>
              <p>
              	Also, if you haven't yet, run these commands - again making the
                appropriate changes:
              </p>
              <pre>git config --global user.email "you@example.org"
<!--            -->git config --global user.name "Your Name"</pre>
              <p>
                <a href="#step-3">Next</a>
              </p>
              </div>
            </div>
            <div>
              <p><label for="mailer-local">Local SMTP client (msmtp, nbSMTP, sendmail)</label></p><div>
                <p>
                  If you already have an SMTP client installed, you can configure
                  git send-email to use it by setting <code>sendemail.smtpserver</code>
                  to the path of its executable. For example, to use msmtp you
                  could add this to your global configuration file:
                  </p><pre>[sendemail]
    smtpserver = /usr/bin/msmtp</pre>
                
                <p>
                  If you have multiple accounts configured for your SMTP client and want to specify one, you can use the
                  <code>sendemail.smtpserveroption</code> setting. For example, to choose an account named
                  <code>work</code> configured for msmtp:
                  </p><pre>[sendemail]
    smtpserver = /usr/bin/msmtp
    smtpserveroption = -a
    smtpserveroption = work</pre>
                
                <p><a href="#step-3">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="mailer-generic">Generic instructions</label></p><div>
                <p>
                  Your email provider should have instructions somewhere for
                  <strong>SMTP access</strong>. Look these details up, and then
                  add the following details from your mail provider:
                </p>
                <pre>[sendemail]
	smtpserver = mail.example.org
	smtpuser = you@example.org
	smtpencryption = ssl
	smtpserverport = 465</pre>
                <p>
                  Be sure to fill in the appropriate values for your email
                  provider - you will probably only have to fill in
                  <code>smtpserver</code> and <code>smtpuser</code>. Also, if
                  you haven't yet, run these commands - again, making the
                  appropriate changes:
                </p>
                <pre>git config --global user.email "you@example.org"
<!--              -->git config --global user.name "Your Name"</pre>
                <p><a href="#step-3">Next</a></p><p>
                  This configuration assumes direct TLS. If your provider only
                  offers STARTTLS, set <code>smtpencryption = tls</code> and
                  <code>smtpserverport = 587</code>.
                </p>
                <p>
                  If your system is already set up with <code>sendmail</code>,
                  you may skip the <code>[sendemail]</code> git configuration instructions.
                </p>
              </div>
            </div>
          </div>
        </div>
        </div>
      <div id="step-3">
        <h2>
          <small>Step three</small> Give it a shot!
        </h2>
        <div>
          <p>
            It's time to take it for a spin - we're going to send a patch.
            Ready?
          </p>
          <div>
            <ol>
              <li>
                <strong>Clone the upstream repository</strong>. No need to make a
                fork! We have prepared a repository for you to test with:
                <pre>git clone <a href="https://git.sr.ht/~sircmpwn/email-test-drive">https://git.sr.ht/~sircmpwn/email-test-drive</a>
<!--              -->cd email-test-drive</pre>
              </li>
              <li>
                <strong>Make your changes</strong>. Let's add a file with your
                progress so far:
                <pre>echo "I'm about to try git send-email" &gt;your-name</pre>
                <p>
                  Be sure to change <code>your-name</code> to your own!
                </p>
              </li>
              <li>
                <strong>Commit your changes</strong>. Check out the official
                (and free) <a href="https://git-scm.com/book/en/v2" target="_blank" rel="noopener">Pro Git</a> book if you don't know how to do this.
                <pre>git add your-name
<!--              -->git commit -m "Demonstrate that I can use git send-email"</pre>
              </li>
              <li>
                <strong>Send the patch</strong>! If you check out the
                <code>README.md</code> file, you'll note that patches should be
                sent to <a href="mailto:~sircmpwn/email-test-drive@lists.sr.ht">
                  ~sircmpwn/email-test-drive@lists.sr.ht</a>.
                <pre>git send-email --to="~sircmpwn/email-test-drive@lists.sr.ht" HEAD^</pre>
                <p>
                  If prompted for an <code>In-Reply-To</code>, you can ignore
                  it for now (just press enter). Follow the rest of the prompts
                  and you've done it! If you have any problems at this step,
                  feel free to
                  <a href="mailto:~sircmpwn/sr.ht-discuss@lists.sr.ht?subject=git-send-email%20help">
                    email us
                  </a> for help. If it worked, you should see your email appear
                  in the <a target="_blank" rel="noopener" href="https://lists.sr.ht/~sircmpwn/email-test-drive">mailing list archives</a> momentarily!
                </p>
              </li>
              <li>
                <strong>Check your inbox</strong>... someone has some feedback
                on your patch!
              </li>
            </ol>
            <p><a href="#step-4">Next</a>
          </p></div>
          <p><strong>Warning!</strong> Some people think that they can get
            away with sending patches through some means other than <code>
            git send-email</code>, but you can't. Your patches will be broken
            and a nuisance to the maintainers whose inbox they land in.
            Follow the golden rule: <em>just use git send-email</em>.
          </p>
        </div>
        </div>
      <div id="step-4">
        <h2>
          <small>Step four</small> Dealing with feedback
        </h2>
        <div>
            <p>
              No one ever gets it right on the first try. Don't worry, it's all
              part of the process! You may receive some feedback on your patch
              from the maintainers of the software. This feedback will arrive in
              the form of a reply to your email. If you have any questions,
              just reply back - and remember to "reply all"! In the meantime,
              let's fix the patch.
            </p>
            <p>
              In this tutorial, the feedback was generated by a bot, but feel
              free to reply to get the hang of it. You need to make sure your
              email client is configured to write emails in <strong>plain
              text</strong> before you do, and please try to avoid
              <a href="https://git-send-email.io/top-posting.html" target="_blank">top posting</a>.
              We also have an
              <a target="_blank" href="https://man.sr.ht/lists.sr.ht/etiquette.md">etiquette guide</a> that'll help you avoid any faux pas.
            </p>
            <ol>
              <li>
                <strong>Make the changes</strong>. Update the files to match the
                changes requested by the maintainers. We'll leave this to you.
              </li>
              <li>
                <strong>Amend your commit</strong>. Git is designed for you to
                <em>edit</em> your commit history. It's not set in stone! The
                maintainers reviewing your work don't want to merge a patch
                which has mistakes, even if it's followed up by a fix, so
                you'll have to <strong>amend</strong> your previous commit:
                <pre>git commit -a --amend</pre>
                <p>
                  First time amending a commit? Amending and rebasing commits
                  is an essential skill in this workflow. Check out our
                  <a href="https://git-rebase.io/" target="_blank">comprehensive guide to git rebase</a> if you'd like to learn
                  more.
                </p>
              </li>
              <li>
                <strong>Set the default "to" address</strong>. Let's make this
                easier on ourselves by setting the default email address for
                this repo, so we needn't enter it every time:
                <pre>git config sendemail.to "~sircmpwn/email-test-drive@lists.sr.ht"</pre>
              </li>
              <li>
                <strong>Send the new patch</strong>! This time we'll use
                <code>-v2</code> to indicate that this is the second version of
                this patch. If we do this again, we'll use <code>-v3</code>.
                <pre>git send-email --annotate -v2 HEAD^</pre>
                <p>
                  Note that we also specified the "--annotate" flag. This is
                  going to open the email in our editor before sending it out,
                  so we can make any changes. We're going to add some "timely
                  commentary". Look for the "---" and add a short summary of
                  the differences since the first patch on the next line. It
                  should look something like this:
                </p>
                <pre>Subject: [PATCH v2] Demonstrate that I can use git send-email

<!--              -->---
<!--              -->This fixes the issues raised from the first patch.

<!--              -->your-name | 1 +
<!--              -->1 file changed, 1 insertion(+)</pre>
								<p>
                  This text gives the maintainers some extra context about your
                  patch, but doesn't make it into the final git log. Close your
                  editor, follow the prompts again, and that's it - you're done!
									Congratulations!
                </p>
                <p>
                  If you want some more tips on using git send-email, check out
                  the next page.
								</p>
              </li>
            </ol>
						<p><a href="#step-5">Next</a>
					</p></div>
        </div>
      <div id="step-5">
        <!-- TODO: Move step 5 onto a separate page so each tip is linkable? -->
        <h2>
          Tips &amp; tricks
        </h2>
        <div>
          <p>
            Miscellaneous tips and tricks which may serve you well as you use
            git send-email.
          </p>
          <div>
            <h3>Sending several patches at once</h3>
            <p>Use this to send the last 3 commits:</p>
            <pre>git send-email HEAD~3</pre>
            <p>Or all commits since a particular one:</p>
            <pre>git send-email 209210d</pre>
            <p>Or just the second-to-last commit:</p>
            <pre>git send-email -1 HEAD^^</pre>
            <p>
              See <a href="https://git-scm.com/book/en/v2/Git-Tools-Revision-Selection" target="_blank">Revision Selection</a> for more.
            </p>
          </div>
          <div>
            <h3>Specifying a sub-project</h3>
            <p>
              Some projects use a single mailing list for several git
              repositories. Try this to clarify that you're working on the
              "foobar" project:
            </p>
            <pre>git config format.subjectPrefix "PATCH foobar"</pre>
          </div>
          <div>
            <h3>Using --annotate every time</h3>
            <pre>git config --global sendemail.annotate yes</pre>
          </div>
          <div>
            <h3>"Signing off" on your commits</h3>
            <p>
              Some projects, such as the Linux kernel, will ask you to "sign
              off" on your commits. To do this, add <code>--signoff</code> (or
              <code>-s</code>) to <code>git send-email</code>. To set it as the
              default for that git repository:
            </p>
            <pre>git config format.signOff yes</pre>
            <p>
              The meaning of a signoff depends on the project to which you’re
              committing. For example, it may certify that the committer has
              the rights to submit the work under the project’s license or
              agrees to a
              <a href="https://developercertificate.org/" target="_blank" rel="noopener">Developer Certificate of Origin (DCO)</a>.
              Consult the documentation or leadership of the project to which
              you’re contributing to understand how the signoffs are used in
              that project.
            </p>
          </div>
          <div>
            <h3>More approaches to authentication</h3>
            <p>
              This tutorial configures git in a way that causes send-email to
              prompt for your password, which you may find annoying. There are
              other ways to authenticate - the simplest of which is:
            </p>
            <pre>git config --global sendemail.smtpPass 'your password'</pre>
	    <p>
	      You can also have your password cached in memory for a certain
	      period of time. To cache it for one hour, use:
	    </p>
	    <pre>git config --global credential.helper 'cache --timeout 3600'</pre>
            <p>
              For more sophisticated solutions, such as integration with your
              keyring, see the <a href="https://git-scm.com/docs/gitcredentials">git-credential</a> man page.
            </p>
          </div>
          <p><a href="#step-1">Back to the start</a>
        </p></div>
        </div>
      <div id="step-1">
        <h2>
          <small>Step one</small> Installation
        </h2>
        <div>
          <p>
            Let's start by installing the appropriate packages for your
            operating system.
          </p>
          <div>
            <div>
              <p><label for="os-arch">
                <img src="https://git-send-email.io/static/arch.png">
                Arch Linux
              </label></p><div>
                <p>
                  The <code>git</code> package includes the git email tools,
                  though you might need to install a few additional packages to
                  get it fully working.
                  Run this to install it:
                </p>
                <pre>sudo pacman -Syu --needed git perl-authen-sasl perl-io-socket-ssl</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-alpine">
                <img src="https://git-send-email.io/static/alpine.png">
                Alpine Linux
              </label></p><div>
                <p>
                  The <code>git-email</code> package includes the git email
                  tools. Run this to install it:
                </p>
                <pre>sudo apk add git git-email</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-centos">
                <img src="https://git-send-email.io/static/centos.png">
                CentOS
              </label></p><div>
                <p>
                  The <code>git-email</code> package includes the git email
                  tools. Run this to install it:
                </p>
                <pre>sudo yum install git git-email</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-debian">
                <img src="https://git-send-email.io/static/debian.png">
                Debian
              </label></p><div>
                <p>
                  The <code>git-email</code> package includes the git email
                  tools. Run this to install it:
                </p>
                <pre>sudo apt install git git-email</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-fedora">
                <img src="https://git-send-email.io/static/fedora.png">
                Fedora
              </label></p><div>
                <p>
                  The <code>git-email</code> package includes the git email
                  tools. Run this to install it:
                </p>
                <pre>sudo dnf install git git-email</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-freebsd">
                <img src="https://git-send-email.io/static/freebsd.png">
                FreeBSD
              </label></p><div>
                <p>
                  The <code>git</code> package includes the git email tools.
                  Run this to install it:
                </p>
                <pre>pkg install git</pre>
                <p>
                  Or, to install from ports:
                </p>
                <pre>cd /usr/ports/devel/git &amp;&amp; make install clean</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-gentoo">
                <img src="https://git-send-email.io/static/gentoo.png">
                Gentoo
              </label></p><div>
                <p>
                  The <code>git</code> package includes the git email tools.
                  Run this to install it:
                </p>
                <pre>emerge dev-vcs/git</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-guix">
                <img src="https://git-send-email.io/static/guix.png">
                Guix
              </label></p><div>
                <p>
                  The <code>git</code>
                  package's <code>send-email</code> output contains
                  the git email tools. Run this to install both git
                  and the email tools:
                </p>
                <pre>guix package -i git git:send-email</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-macos">
                <img src="https://git-send-email.io/static/apple.png">
                macOS
              </label></p><div>
                <p>
                  All of the usual ways to install <code>git</code> on macOS
                  include the git email tools by default, including Apple's
                  developer tools as well as
                  <a href="https://brew.sh/">Homebrew</a>,
                  <a href="https://www.macports.org/install.php">MacPorts</a>,
                  and the official git bundle from
                  <a href="https://git-scm.com/download/mac">git-scm.com</a>.
                </p>
                <p>
                  <br>
                  The easiest way is to just run:
                </p>
                <pre>git</pre>
                <p>
                  If <code>git</code> is not installed already, you will be
                  prompted to install the Apple command line developer tools.
                </p>
                <p>
                  It may be necessary to install missing perl SSL modules by
                  hand:
                  </p><pre>sudo -H cpan Net::SMTP::SSL IO::Socket::SSL</pre>
                
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-nixos">
                <img src="https://git-send-email.io/static/nixos.png">
                Nix
              </label></p><div>
                <p>
                  The
                  <a href="https://search.nixos.org/packages?type=packages&amp;query=gitFull"><code>gitFull</code></a>
                  package includes the git email tools.
                  To install it imperatively, run:
                </p>
                <pre>nix-env -iA nixos.gitFull</pre>
                <p>
                  Alternatively, to install it declaratively, add:
                </p>
                <pre>programs.git.package = pkgs.gitFull;</pre>
                <p>
                  to <code>configuration.nix</code>, or
                  <code>home.nix</code> if you use home-manager.
                  Make sure <code>programs.git.enable</code> is enabled.
                </p>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-omnios">
                <img src="https://git-send-email.io/static/omnios.png">
                OmniOS
              </label></p><div>
                <p>
                  The <code>git</code> package includes the git email tools.
                  Run this to install it:
                </p>
                <pre>pkg install git</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-openbsd">
                <img src="https://git-send-email.io/static/openbsd.png">
                OpenBSD
              </label></p><div>
                <p>
                  The <code>git</code> package includes the git email tools.
                  Run this to install it:
                </p>
                <pre>pkg_add git p5-Authen-SASL p5-Net-SMTP-SSL</pre>
                <p>
                  Or, to install from ports:
                </p>
                <pre>cd /usr/ports/devel/git &amp;&amp; make install clean &amp;&amp; cd ../../security/p5-Authen-SASL &amp;&amp; make install clean &amp;&amp; cd ../../net/p5-Net-SMTP-SSL &amp;&amp; make install clean
                </pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-openmandriva">
                <img src="https://git-send-email.io/static/openmandriva.png">
                OpenMandriva
              </label></p><div>
                <p>
                  The <code>git-email</code> package includes the git email
                  tools. Run this to install it:
                </p>
                <pre>sudo dnf install git-email</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-opensuse">
                <img src="https://git-send-email.io/static/suse.png">
                openSUSE
              </label></p><div>
                <p>
                  The <code>git-email</code> package includes the git email
                  tools. Run this to install it:
                </p>
                <pre>sudo zypper install git-email</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-pkgsrc">
                <img src="https://git-send-email.io/static/pkgsrc.png">
                pkgsrc
              </label></p><div>
                <p>
                  The <code>devel/git</code> package includes the git email
                  tools. Run this to install it:
                </p>
                <pre>sudo pkg_add git</pre>
                <p>
                  Or, to build from source:
                </p>
                <pre>cd /usr/pkgsrc/devel/git &amp;&amp; make install </pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-rocky">
                <img src="https://git-send-email.io/static/rocky.png">
                Rocky Linux
              </label></p><div>
                <p>
                  The <code>git-email</code> package includes the git email
                  tools. Run this to install it:
                </p>
                <pre>sudo dnf install git git-email</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-solus">
                <img src="https://git-send-email.io/static/solus.png">
                Solus
              </label></p><div>
                <p>
                  The <code>git</code> package includes the git email
                  tools. Run this to install it:
                </p>
                <pre>sudo eopkg install git</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-ubuntu">
                <img src="https://git-send-email.io/static/ubuntu.png">
                Ubuntu
              </label></p><div>
                <p>
                  The <code>git-email</code> package includes the git email
                  tools. Run this to install it:
                </p>
                <pre>sudo apt install git git-email</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-void">
                <img src="https://git-send-email.io/static/void.png">
                Void Linux
              </label></p><div>
                <p>
                  The <code>git</code> package includes the git email
                  tools. Run this to install it:
                </p>
                <pre>sudo xbps-install -S git</pre>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
            <div>
              <p><label for="os-windows">
                <img src="https://git-send-email.io/static/windows.png">
                Microsoft Windows
              </label></p><div>
                <p>
                  The official git bundle from
                    <a href="https://git-scm.com/download/windows">git-scm.com</a>
                  includes the git email tools.
                </p>
                <p><a href="#step-2">Next</a>
              </p></div>
            </div>
          </div>
          <p>
            Don't see your OS here? Consult your OS documentation for
            installation, and once you finish this tutorial, send a patch
            adding yours to our
            <a href="https://git.sr.ht/~sircmpwn/git-send-email.io" target="_blank">git repository</a>.
          </p>
        </div>
        </div>
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Introduction to Modern Statistics (357 pts)]]></title>
            <link>https://openintro-ims2.netlify.app/</link>
            <guid>37854846</guid>
            <pubDate>Thu, 12 Oct 2023 08:45:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openintro-ims2.netlify.app/">https://openintro-ims2.netlify.app/</a>, See on <a href="https://news.ycombinator.com/item?id=37854846">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-document-content"><p><a href="https://openintro-ims2.netlify.app/images/IMS2_front_cover_WIP.png" data-gallery="quarto-lightbox-gallery-1"><img src="https://openintro-ims2.netlify.app/images/IMS2_front_cover_WIP.png" title="Introduction to Modern Statistics (2nd Ed)"></a></p>
<section id="welcome-to-ims2"><h2>Welcome to IMS2</h2>
<p>This is the website for <strong>Introduction to Modern Statistics</strong>, Second Edition by Mine Çetinkaya-Rundel and Johanna Hardin. Introduction to Modern Statistics, which we’ll refer to as IMS going forward, is a textbook from the <a href="https://www.openintro.org/">OpenIntro</a> project.</p>
<!--
The book will always be available for free here. It is also available in PDF (for free or for the amount you choose to contribute) on Leanpub and in black&white paperback for purchase for $20.
<br><br>
<a href="https://leanpub.com/imstat" target="_blank"><img src="images/_icons/file.png" width="30px">&nbsp;<strong>Download PDF</strong></a>
<br>
<a href="https://www.openintro.org/go?id=ims1_bw_pb&referrer=/book/ims/online"><img src="images/_icons/book.png" width="30px">&nbsp;<strong>Purchase paperback</strong></a>
<br><br>
---
<br><br>
-->
<p>Copyright © 2023.</p>
<p>Second Edition.</p>
<p>Version date: September 10, 2023.</p>
<p>This textbook and its supplements, including slides, labs, and interactive tutorials, may be downloaded for free at<br><a href="http://openintro.org/book/ims"><strong>openintro.org/book/ims</strong></a>.</p>
<p>This textbook is a derivative of <em>OpenIntro Statistics</em> 4th Edition and <em>Introduction to Statistics with Randomization and Simulation</em> 1st Edition by Diez, Barr, and Çetinkaya-Rundel, and it’s available under a Creative Commons Attribution-ShareAlike 3.0 Unported United States License. License details are available at the Creative Commons website:<br><a href="https://www.openintro.org/go/?id=creativecommons_org&amp;referrer=ims1_pdf"><strong>creativecommons.org</strong></a>.</p>
<p>Source files for this book can be found on GitHub at<br><a href="https://github.com/OpenIntroStat/ims">github.com/OpenIntroStat/ims</a>.</p>
</section>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Slack's Google Drive App can share your private Docs and Drive files (131 pts)]]></title>
            <link>https://www.kapwing.com/blog/slacks-google-drive-integration-shares-private-documents/</link>
            <guid>37854159</guid>
            <pubDate>Thu, 12 Oct 2023 06:44:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kapwing.com/blog/slacks-google-drive-integration-shares-private-documents/">https://www.kapwing.com/blog/slacks-google-drive-integration-shares-private-documents/</a>, See on <a href="https://news.ycombinator.com/item?id=37854159">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<article>
<header>


<figure>
<img srcset="https://www.kapwing.com/blog/content/images/size/w300/2023/10/video_image-O3EfROc4J.jpeg 300w,
                    https://www.kapwing.com/blog/content/images/size/w720/2023/10/video_image-O3EfROc4J.jpeg 720w,
                    https://www.kapwing.com/blog/content/images/size/w960/2023/10/video_image-O3EfROc4J.jpeg 960w,
                    https://www.kapwing.com/blog/content/images/size/w1200/2023/10/video_image-O3EfROc4J.jpeg 1200w,
                    https://www.kapwing.com/blog/content/images/size/w2000/2023/10/video_image-O3EfROc4J.jpeg 2000w" sizes="(max-width: 1200px) 100vw, 1200px" src="https://www.kapwing.com/blog/content/images/size/w1200/2023/10/video_image-O3EfROc4J.jpeg" alt="Slack's Google Drive App can share your private Docs and Drive files">
</figure>
</header>
<section>
<p>In 2017, Slack launched a popular Google Drive integration that makes it easy to embed, share, and get notified about new items added to Google Drive, including files, images, docs, and more. We use it daily here at <a href="https://www.kapwing.com/">Kapwing</a>, an online <a href="https://www.kapwing.com/">video editing</a> startup, since we run internally on top of Google Docs and Google Drive. Recently, however, I discovered that using file previews with the Google Drive Slack App will allow it to share completely private, unshared documents and files within your workspace.</p><figure><img src="https://www.kapwing.com/blog/content/images/2023/10/image-3.png" alt="" loading="lazy" width="1049" height="343" srcset="https://www.kapwing.com/blog/content/images/size/w600/2023/10/image-3.png 600w, https://www.kapwing.com/blog/content/images/size/w1000/2023/10/image-3.png 1000w, https://www.kapwing.com/blog/content/images/2023/10/image-3.png 1049w" sizes="(min-width: 720px) 720px"><figcaption>The popular Google Drive Slack Bot</figcaption></figure><p>The Slack Google Drive integration has a feature called File Previews that is enabled by default. This is usually pretty handy, because when you share a link to a Google Doc, or any file in Google Drive, the bot will automatically show a preview of the document. </p><figure><img src="https://www.kapwing.com/blog/content/images/2023/10/image-5.png" alt="" loading="lazy" width="1128" height="366" srcset="https://www.kapwing.com/blog/content/images/size/w600/2023/10/image-5.png 600w, https://www.kapwing.com/blog/content/images/size/w1000/2023/10/image-5.png 1000w, https://www.kapwing.com/blog/content/images/2023/10/image-5.png 1128w" sizes="(min-width: 720px) 720px"><figcaption>The Slack Bot preview for Google Documents</figcaption></figure><p>However, recently I noticed that it was doing this for documents that I had not yet shared. I also noticed that when certain links were sent to me, I would see a preview of the document even though I didn't have access to it yet. </p><figure><img src="https://www.kapwing.com/blog/content/images/2023/10/image-1.png" alt="" loading="lazy" width="1140" height="683" srcset="https://www.kapwing.com/blog/content/images/size/w600/2023/10/image-1.png 600w, https://www.kapwing.com/blog/content/images/size/w1000/2023/10/image-1.png 1000w, https://www.kapwing.com/blog/content/images/2023/10/image-1.png 1140w" sizes="(min-width: 720px) 720px"><figcaption>Me, sharing a private document with Luke which shows the full content of the document</figcaption></figure><p>If I open up the URL of the file preview, the preview is a full resolution 800 × 1035 image that shows the entire first page of the document. </p><p>The app does this for private images uploaded to Google Drive as well:</p><figure><img src="https://www.kapwing.com/blog/content/images/2023/10/image-6.png" alt="" loading="lazy" width="1140" height="680" srcset="https://www.kapwing.com/blog/content/images/size/w600/2023/10/image-6.png 600w, https://www.kapwing.com/blog/content/images/size/w1000/2023/10/image-6.png 1000w, https://www.kapwing.com/blog/content/images/2023/10/image-6.png 1140w" sizes="(min-width: 720px) 720px"><figcaption>Me, sharing a private image to a coworker that he is not supposed to see.</figcaption></figure><p>It seems like what's happening here is that when I share a document or file via a link, the Google Drive Slack app will automatically create a preview image of that file, using my own Google permissions. The problem is, that preview image gets re-uploaded to Slack's CDN, and is in high resolution and is now accessible to everyone in my Slack workspace. </p><p>You can test this yourself by creating a private Google document, or uploading an image accessible only to you to your Google Drive, and then sending the link to a colleague in Slack. If you use the web Slack client, you'll be able to inspect the full link to the image preview as well:</p><figure><img src="https://www.kapwing.com/blog/content/images/2023/10/image-7.png" alt="" loading="lazy" width="1324" height="743" srcset="https://www.kapwing.com/blog/content/images/size/w600/2023/10/image-7.png 600w, https://www.kapwing.com/blog/content/images/size/w1000/2023/10/image-7.png 1000w, https://www.kapwing.com/blog/content/images/2023/10/image-7.png 1324w" sizes="(min-width: 720px) 720px"><figcaption>The full image preview that gets sent to my collegue</figcaption></figure><p>It might not be the biggest deal to some people, but I think it can definitely be a problem if you are not being careful with sharing private Google documents in a public slack channel or workspace, especially since File Previews are enabled by default. Going forward, I think it would be better for the app to make this clear, since it can definitely be used by folks in Slack to see something they weren't allowed to. </p><p>I hope this helps others out there using the Google Drive Slack app!</p>
<a href="https://www.kapwing.com/signin" id="post-upsell" data-utm-campaign="inline cta">Create content faster with Kapwing's online video editor&nbsp;→ </a>
 </section>
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Metric Time (237 pts)]]></title>
            <link>https://metric-time.com/</link>
            <guid>37853181</guid>
            <pubDate>Thu, 12 Oct 2023 03:27:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://metric-time.com/">https://metric-time.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37853181">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
					<h2>Metric Minute</h2>
					<h3>A metric minute is broken into 100 seconds. </h3>
				</p><div id="rationale-container">			
				<h2>Rationale for Metric Time</h2>
				<p>
					What makes metric time so cool is that would make all the mental math we have to do when adding and subtracting time so much easier—especially when it comes to different timezones. Working with base-10 numbers is so much easier than trying to think in base-60, base-12, and base-24.
				</p>
				<p>
					There is no AM or PM with metric time. Just 10 hours in the day. To get a good night sleep (8 standard hours) you'd sleep for 3.33 metric hours. If you go to bed at 9:50 metric time (about 10:45pm in standard time), wanting to get a good night sleep, you'd wake up at 2:75 metric time (roughly 6:45am standard time). Remember, a half hour in metric time is 50 minutes, and a full hour is 100 minutes. One metric minute before "midnight" (10:00 on the metric clock) would be 9:99 in metric time.
				</p>
				<h2>Time is Money</h2>
				<p>
					The logic you use to tell time with metric time is very similar to how you think about money (assuming US Dollars). One metric hour is like a 100-dollar bill. One metric minute is a 1 dollar bill. And each metric second is a penny. Each day (10 metric hours), has 1,000 minutes, and 100,000 seconds. It's an interesting way to think about the time we get to spend each day.
				</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How LSP could have been better (203 pts)]]></title>
            <link>https://matklad.github.io/2023/10/12/lsp-could-have-been-better.html</link>
            <guid>37852944</guid>
            <pubDate>Thu, 12 Oct 2023 02:45:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matklad.github.io/2023/10/12/lsp-could-have-been-better.html">https://matklad.github.io/2023/10/12/lsp-could-have-been-better.html</a>, See on <a href="https://news.ycombinator.com/item?id=37852944">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <article>

    <h2>
    <a href="#LSP-could-have-been-better"><span>LSP could have been better</span> <time datetime="2023-10-12">Oct 12, 2023</time></a>
    </h2>

<figure>
<blockquote><p><span>We talk about programming like it is about writing code, but the code ends up being less important</span>
<span>than the architecture, and the architecture ends up being less important than social issues.</span></p>
</blockquote>
<figcaption><cite><a href="https://neugierig.org/software/blog/2020/05/ninja.html"><span>The Success and Failure of Ninja</span></a></cite></figcaption>
</figure>
<p><span>The  </span><a href="https://matklad.github.io/2022/04/25/why-lsp.html"><em><span>Why LSP</span></em></a><span> post discusses the </span>“<span>social</span>
<span>issues</span>”<span> solved by LSP. LSP (as a part of overarching Microsoft strategy) is brilliant, because it</span>
<span>moved the world to a new equilibrium where not having basic IDE support is frowned upon. This post</span>
<span>instead discusses architectural aspects of LSP, which I personally find not as brilliant(especially given that</span>
<a href="https://htmlpreview.github.io/?https://github.com/dart-lang/sdk/blob/8e6a02d899ef62ef5b8405518b36340e609198e2/pkg/analysis_server/doc/api.html"><span>Dart Analysis Protocol</span></a>
<span>predates LSP and is technically superior in some aspects). Perhaps it</span>
<span>could be useful for someone designing other LSP-shaped protocols! Note that it</span>’<span>s been couple of</span>
<span>years since I was actively involved in LSP, probably the grass is greener these days!</span></p>
<p><span>Let</span>’<span>s get to the list of properties, good and bad, in no particular order.</span></p>
<section id="Focus-on-Presentation">

    <h2>
    <a href="#Focus-on-Presentation"><span>Focus on Presentation</span> </a>
    </h2>
<p><span>And let</span>’<span>s start with an aspect of the architecture which is genius, and which, I think, is</span>
<span>responsible for a big share of LSP success on the technical side. If you build a tool for working</span>
<span>with </span><em><span>multiple</span></em><span> programming languages, one of the biggest questions is how to find common ground</span>
<span>among different, but ultimately similar, languages. A first attempt is to uncover essential</span>
<span>commonality: after all, all languages have files, variables, functions, classes, right? This is </span>…
<span>maybe not necessary a dead end, but definitely a thorny and treacherous path </span>—<span> languages are</span>
<span>different, each language is weird in at least some of its aspects, and common ground risks to level</span>
<span>away meaningful distinctions.</span></p>
<p><span>So, what does LSP do here? It just doesn</span>’<span>t provide a semantic model of the code base. Instead, it is</span>
<span>focused squarely on the presentation. No matter how different each programming language is, they</span>
<span>all, in the end, use the same completion widget. So LSP is formulated in terms of what</span>’<span>s shown in</span>
<span>the completion widget, not in terms of the underlying semantic language entities. That means that</span>
<span>each language has an internal semantic model which is full fidelity </span><em><span>for this particular language</span></em><span>,</span>
<span>and uses it to provide the best completion experience which is possible for a given completion</span>
<span>widget. This is how rust-analyzer is structured internally as well:</span></p>
<ol>
<li>
<span>Compiler layer deals with the messy language analysis tasks, it derives more structured</span>
<span>information (types) from less structured information (source text), explicitly tracking analysis</span>
<span>layers and phases.</span>
</li>
<li>
<span>The HIR (high-level intermediate representation) is a façade around the compiler, which provides</span>
<span>a rich graph-based object model of code which looks as if all derived information, like types, is</span>
<span>pre-computed.</span>
</li>
<li>
<span>The IDE layer uses HIR to compute things like completions, and presents them as Rust-specific,</span>
<span>but semantics-less POD structures to be shown to the user in GUI more or less as is.</span>
</li>
</ol>
<p><span>One consequence of this architecture is that LSP requests map to editor widgets, and not to the</span>
<span>underlying language concepts, even when several different widgets are powered by the same underlying</span>
<span>data. For example, LSP has separate requests for:</span></p>
<ul>
<li>
<span>hierarchical outline of a file displayed in the side bar,</span>
</li>
<li>
“<span>breadcrumbs</span>”<span> shown in the header,</span>
</li>
<li>
<span>syntax-aware selection ranges,</span>
</li>
<li>
<span>code folding.</span>
</li>
</ul>
<p><span>Although all four features are just different views into an AST, there</span>’<span>s no </span>“<span>get AST</span>”<span> request in the</span>
<span>LSP. Different requests allow to fine-tune presentation for the  different use-cases, and the</span>
<span>details do differ! Semantic selection might contain some sub-syntax ranges inside string literals</span>
<span>and comments, breadcrumb need to include things like conditionals of </span><code>if</code><span> expressions, while the</span>
<span>outline might want to get rid of less important nodes. Attentive reader will notice that breadcrumbs</span>
<span>and the outline actually use the same LSP request. Even LSP doesn</span>’<span>t follow LSP philosophy fully!</span></p>
</section>
<section id="Transport">

    <h2>
    <a href="#Transport"><span>Transport</span> </a>
    </h2>
<p><span>After a big thing that LSP did right, let</span>’<span>s look at a small thing that it got wrong. Let</span>’<span>s look at</span>
<span>how information is transmitted over the wire.</span></p>
<p><span>JSON is actually OK! Many people complain that JSON is slow, but that</span>’<span>s not actually the case</span>
<span>generally. There are some edge cases, where particular client libraries can be slow as was the case</span>
<span>at least at some point with Swift and Emacs, but JSON is definitely fast enough for Rust, Java and</span>
<span>JavaScript. Of course, something substantially better than JSON is possible in </span><em><span>theory</span></em><span>.</span></p>
<p><span>I think ideally we need </span>“<span>WebAssembly for IPC</span>”<span>, a format that:</span></p>
<ul>
<li>
<span>has dual text and binary encoding,</span>
</li>
<li>
<span>is stupidly simple,</span>
</li>
<li>
<span>is thoroughly, readably, and precisely specified,</span>
</li>
<li>
<span>and, in general, is principled and a joy to use.</span>
</li>
</ul>
<p><span>There</span>’<span>s no such format yet, so JSON it is. Good enough.</span></p>
<p><span>HTTP framing is not OK. On the wire, the messages framed like this:</span></p>

<figure>


<pre><code><span>Content-Length: 92 \r\n</span>
<span>\r\n</span>
<span>Actual message</span></code></pre>

</figure>
<p><span>That is:</span></p>
<ul>
<li>
<span>case-insensitive </span>“<span>content-length</span>”<span> header,</span>
</li>
<li>
<span>followed by length of the following message, formatted as a decimal number in ASCII,</span>
</li>
<li>
<span>followed by double </span><code>\r\n</code><span>,</span>
</li>
<li>
<span>followed by the actual message.</span>
</li>
</ul>
<p><span>This resembles HTTP, but is not actual HTTP, so you need to write a bit of custom code to deal</span>
<span>with the framing. That</span>’<span>s not hard:</span></p>

<figure>


<pre><code><span>  <span>let</span> <span>mut </span><span>size</span> = <span>None</span>;</span>
<span>  <span>let</span> <span>mut </span><span>buf</span> = <span>String</span>::<span>new</span>();</span>
<span>  <span>loop</span> {</span>
<span>    buf.<span>clear</span>();</span>
<span>    <span>if</span> inp.<span>read_line</span>(&amp;<span>mut</span> buf)? == <span>0</span> {</span>
<span>      <span>return</span> <span>Ok</span>(<span>None</span>);</span>
<span>    }</span>
<span>    <span>if</span> !buf.<span>ends_with</span>(<span>"\r\n"</span>) {</span>
<span>      <span>return</span> <span>Err</span>(invalid_data!(<span>"malformed header: {:?}"</span>, buf));</span>
<span>    }</span>
<span>    <span>let</span> <span>buf</span> = &amp;buf[..buf.<span>len</span>() - <span>2</span>];</span>
<span>    <span>if</span> buf.<span>is_empty</span>() {</span>
<span>      <span>break</span>;</span>
<span>    }</span>
<span>    <span>let</span> <span>mut </span><span>parts</span> = buf.<span>splitn</span>(<span>2</span>, <span>": "</span>);</span>
<span>    <span>let</span> <span>header_name</span> = parts.<span>next</span>().<span>unwrap</span>();</span>
<span>    <span>let</span> <span>header_value</span> = parts.<span>next</span>().<span>ok_or_else</span>(|| {</span>
<span>      invalid_data!(<span>"malformed header: {:?}"</span>, buf)</span>
<span>    })?;</span>
<span>    <span>if</span> header_name.<span>eq_ignore_ascii_case</span>(<span>"Content-Length"</span>) {</span>
<span>      size = <span>Some</span>(</span>
<span>        header_value.parse::&lt;<span>usize</span>&gt;().<span>map_err</span>(invalid_data)?,</span>
<span>      );</span>
<span>    }</span>
<span>  }</span>
<span>  <span>let</span> <span>size</span>: <span>usize</span> =</span>
<span>    size.<span>ok_or_else</span>(|| invalid_data!(<span>"no Content-Length"</span>))?;</span>
<span>  <span>let</span> <span>mut </span><span>buf</span> = buf.<span>into_bytes</span>();</span>
<span>  buf.<span>resize</span>(size, <span>0</span>);</span>
<span>  inp.<span>read_exact</span>(&amp;<span>mut</span> buf)?;</span>
<span>  <span>let</span> <span>buf</span> = <span>String</span>::<span>from_utf8</span>(buf).<span>map_err</span>(invalid_data)?;</span></code></pre>

</figure>
<p><span>But, still, decoding ASCII message length from variable-length header? That</span>’<span>s accidental complexity.</span>
<span>Just separate json objects with newlines instead:</span></p>
<p><a href="https://jsonlines.org/">https://jsonlines.org</a></p>
<p><span>Framing using </span><code>\n</code><span> as a separator is almost certainly available out of the box in the programming</span>
<span>language of choice.</span></p>
<p><span>Wiping away the tears and peeling one more layer from the onion, we see json-rpc:</span></p>

<figure>


<pre><code><span><span>{</span></span>
<span>    <span>"jsonrpc"</span><span>:</span> <span>"2.0"</span><span>,</span></span>
<span>    <span>"method"</span><span>:</span> <span>"initialize"</span><span>,</span></span>
<span>    <span>"id"</span><span>:</span> <span>1</span><span>,</span></span>
<span>    <span>"params"</span><span>:</span> <span>{</span> ... <span>}</span></span>
<span><span>}</span></span></code></pre>

</figure>
<p><span>This again is a bit of needless accidental complexity. Again, not hard to handle:</span></p>

<figure>


<pre><code><span><span>fn</span> <span>_write</span>(<span>self</span>, w: &amp;<span>mut</span> <span>dyn</span> Write) <span>-&gt;</span> io::<span>Result</span>&lt;()&gt; {</span>
<span>  <span>#[derive(Serialize)]</span></span>
<span>  <span>struct</span> <span>JsonRpc</span> {</span>
<span>    jsonrpc: &amp;<span>'static</span> <span>str</span>,</span>
<span>    <span>#[serde(flatten)]</span></span>
<span>    msg: Message,</span>
<span>  }</span>
<span>  <span>let</span> <span>text</span> = serde_json::<span>to_string</span>(&amp;JsonRpc {</span>
<span>    jsonrpc: <span>"2.0"</span>,</span>
<span>    msg: <span>self</span>,</span>
<span>  })?;</span>
<span>  <span>write_msg_text</span>(w, &amp;text)</span>
<span>}</span></code></pre>

</figure>
<p><span>But:</span></p>
<ul>
<li>
<span>Prone to complexity amplification, invites jsonrpc framework with all the latest patterns.</span>
</li>
<li>
<code>"jsonrpc": "2.0"</code><span> is meaningless noise which you have to look at during debugging.</span>
</li>
<li>
<span>Error codes like </span><code>-32601</code><span> (ah, that comes from xml-rpc!).</span>
</li>
<li>
<span>Includes notifications. Notification are a big anti-pattern in RPC, for a somewhat subtle reason.</span>
<span>More on this later.</span>
</li>
</ul>
<p><span>What to do instead? Do what Dart does, some excerpts from </span><a href="https://htmlpreview.github.io/?https://github.com/dart-lang/sdk/blob/8e6a02d899ef62ef5b8405518b36340e609198e2/pkg/analysis_server/doc/api.html"><span>the specification</span></a><span>:</span></p>

<figure>
<blockquote><p><span>Messages are delineated by newlines. This means,</span>
<span>in particular, that the JSON encoding process must not introduce newlines within a message. Note</span>
<span>however that newlines are used in this document for readability.</span></p>
<p><span>To ease interoperability with Lisp-based clients (which may not be able to easily distinguish</span>
<span>between empty lists, empty maps, and null), client-to-server communication is allowed to replace any</span>
<span>instance of </span>“<code>{}</code>”<span> or </span>“<code>[]</code>”<span> with null. The server will always properly represent empty lists as </span>“<code>[]</code>”
<span>and empty maps as </span>“<code>{}</code>”<span>.</span></p>
<p><span>Clients can make a request of the server and the server will provide a response for each request</span>
<span>that it receives. </span><strong><span>While many of the requests that can be made by a client are informational in</span>
<span>nature, we have chosen to always return a response so that clients can know whether the request was</span>
<span>received and was correct.</span></strong></p>
<p><span>Example request:</span></p>

<figure>


<pre><code><span>request: {</span>
<span>  "id": String</span>
<span>  "method": "server.getVersion"</span>
<span>}</span>
<span></span>
<span>response: {</span>
<span>  "id": String</span>
<span>  "error": optional RequestError</span>
<span>  "result": {</span>
<span>    "version": String</span>
<span>  }</span>
<span>}</span></code></pre>

</figure>
</blockquote>

</figure>
<p><span>That</span>’<span>s basically jsonrpc, the good parts, including using </span><code>"UNKNOWN_REQUEST"</code><span> instead of </span><code>-32601</code><span>.</span></p>
</section>
<section id="Coordinates">

    <h2>
    <a href="#Coordinates"><span>Coordinates</span> </a>
    </h2>
<p><span>LSP uses </span><code>(line, column)</code><span> pairs for coordinates. The neat thing here is that this solves significant</span>
<span>chunk of </span><code>\n</code><span> vs </span><code>\r\n</code><span> problems </span>—<span> client and server may represent line endings differently, but</span>
<span>this doesn</span>’<span>t matter, because coordinates are the same.</span></p>
<p><span>Focus on the presentation provides another motivation, because location information received by the</span>
<span>client can be directly presented to the user, without the need to parse the underlying file. I have</span>
<span>mixed feelings about this.</span></p>
<p><span>The problem, </span><code>column</code><span> is counted using UTF-16 code units. This is, like, </span>“<span>no</span>”<span>. For many reasons,</span>
<span>but in particular, UTF-16 is definitely the wrong number to show to the user as a </span>“<span>column</span>”<span>.</span></p>
<p><span>There</span>’<span>s no entirely obvious answer what should be used instead. My personal favorite would be</span>
<span>counting utf-8 code units (so, just bytes). You need </span><em><span>some</span></em><span> coordinate space. Any reasonable</span>
<span>coordinate space won</span>’<span>t be useful for presentation, so you might as well use the space that matches</span>
<span>the underlying utf-8 encoding, so that accessing substrings is O(1).</span></p>
<p><span>Using unicode codepoints would perhaps be the most agreeable solution. Codepoints are useless </span>—
<span>you</span>’<span>ll need to convert to grapheme clusters for presentation, and to utf-8 code units to do anything</span>
<span>with the string. Still, codepoints are a common denominator, they are more often correct if</span>
<span>incorrectly used for presentation, and they have a nice property that any index less then length is</span>
<span>valid irrespective of the actual string.</span></p>
</section>
<section id="Causality-Casualty">

    <h2>
    <a href="#Causality-Casualty"><span>Causality Casualty</span> </a>
    </h2>
<p><span>As mentioned above, one drawback of one-way notifications from jsonrpc is that they don</span>’<span>t allow</span>
<span>signaling errors. But there</span>’<span>s a more subtle problem here: because you don</span>’<span>t receive response to a</span>
<span>notification, it might be hard to order it relative to other events. The Dart protocol is pretty</span>
<span>strict about the ordering of events:</span></p>

<figure>
<blockquote><p><span>There is no guarantee concerning the order in which responses will be returned, but there is a</span>
<span>guarantee that the server will process requests in the order in which they are sent as long as the</span>
<span>transport mechanism also makes this guarantee.</span></p>
</blockquote>

</figure>
<p><span>This guarantee ensures that the client and the server mutually understand each other</span>’<span>s state. For</span>
<span>every request the client knows which file modifications happened before it, and which came afterwards.</span></p>
<p><span>In LSP, when the client wants to modify the state of a file on the server, it sends a notification.</span>
<span>LSP also supports server-initiated edits. Now, if the client sends a </span><code>didChangeTextDocument</code>
<span>notification, and then receives a </span><code>workspace/applyEdit</code><span> request from the server, there</span>’<span>s no way for</span>
<span>the client to know whether the edit takes the latest change into the account or not. Were</span>
<code>didChangeTextDocument</code><span> a request instead, the client could have looked at the relative order of the</span>
<span>corresponding response and </span><code>workspace/applyEdit</code><span>.</span></p>
<p><span>LSP papers over this fundamental loss of causality by including numeric versions of the documents</span>
<span>with every edit, but this is a best effort solution. Edits might be invalidated by changes to</span>
<span>unrelated documents. For example, for a rename refactor, if a new usage was introduced in a new file</span>
<span>after the refactor was computed, version numbers of the changed files would wrongly tell you that</span>
<span>the edit is still correct, while it will miss this new usage.</span></p>
<p><span>Practically, this is a small problem </span>—<span> it works most of the  time (I </span><em><span>think</span></em><span> I have seen zero</span>
<span>actual bugs caused by causality loss), and even the proper solution can</span>’<span>t order events originating</span>
<span>from the client relative to the events originating from the file system. But the fix is also very</span>
<span>simple </span>—<span> just don</span>’<span>t voluntarily lose causality links!</span></p>
</section>
<section id="Remote-Procedural-State-Synchronization">

    <h2>
    <a href="#Remote-Procedural-State-Synchronization"><span>Remote Procedural State Synchronization</span> </a>
    </h2>
<p><span>And this touches what I think is the biggest architectural issue with LSP. LSP is an RPC protocol</span>
—<span> it is formed by </span>“<span>edge triggered</span>”<span> requests that make something happen on the other side. But this</span>
<span>is not how most of IDE features work. What actually is needed is </span>“<span>level triggered</span>”<span> </span><strong><span>state</span>
<span>synchronization</span></strong><span>. The client and the server need to agree what something </span><em><span>is</span></em><span>, deciding the course</span>
<span>of action is secondary. It is </span>“<span>to be or not to be</span>”<span> rather than </span>“<span>what is to be done</span>”<span>.</span></p>
<p><span>At the bottom is synchronization of text documents </span>—<span> the server and the client need to agree which</span>
<span>files there are, and what is there content.</span></p>
<p><span>Above is synchronization of derived data. For example, there</span>’<span>s a set of errors in the project. This</span>
<span>set changes when the underlying text files change. Errors change with some lag, as it takes time to</span>
<span>compute them (and sometimes files changes faster than the errors could be re-computed).</span></p>
<p><span>Things like file outline, syntax highlighting, cross-reference information, e.t.c, all follow the</span>
<span>same pattern.</span></p>
<p><span>Crucially, predicting which changes to the source invalidate which derived data requires language</span>
<span>specific knowledge. Changing the text of </span><code>foo.rs</code><span> might affect syntax highlighting in </span><code>bar.rs</code><span> (as</span>
<span>syntax highlighting is affected by types).</span></p>
<p><span>In LSP, highlighting and such are requests. This means that either the client is incorrect and shows</span>
<span>stale highlighting results, or it conservatively re-queries all highlighting results after every</span>
<span>change, wasting the CPU, and </span><em><span>still</span></em><span> showing stale results sometimes, when an update happens outside</span>
<span>of the client (eg, when </span><code>cargo</code><span> finished downloading external crates).</span></p>
<p><span>The Dart model is more flexible, performant and elegant. Instead of highlighting being a request, it</span>
<span>is a </span><em><span>subscription</span></em><span>. The client subscribes to syntax highlighting of particular files, the server</span>
<span>notifies the client whenever highlights for the selected files change. That is, two pieces of state</span>
<span>are synchronized between the client and the server:</span></p>
<ul>
<li>
<span>The set of file the client is subscribed to</span>
</li>
<li>
<span>The actual state of syntax highlighting for these files.</span>
</li>
</ul>
<p><span>The former is synchronized by sending the whole </span>“<span>current set</span>”<span> of files in a request, whenever the</span>
<span>set changes. The latter is synchronized by sending incremental updates.</span></p>
<p><span>Subscriptions are granular both in terms of the file set, as well as in terms of features. The</span>
<span>client might subscribe for errors in the whole project, and for highlights in the currently opened</span>
<span>documents only.</span></p>
<p><span>Subscriptions are implemented in terms of RPC, but they are an overarching organizational pattern</span>
<span>followed by the majority of the requests. LSP doesn</span>’<span>t have an equivalent, and has real bugs with</span>
<span>outdated information shown to the user.</span></p>
<p><span>I don</span>’<span>t think Dart goes as far as possible here. JetBrains Rider, if I understand correctly, does</span>
<span>something smarter:</span></p>
<p><a href="https://www.codemag.com/Article/1811091/Building-a-.NET-IDE-with-JetBrains-Rider">https://www.codemag.com/Article/1811091/Building-a-.NET-IDE-with-JetBrains-Rider</a></p>
<p><span>I think the idea behind the rider protocol is that you directly define the state you want to</span>
<span>synchronize between the client and the server as state. The protocol then manages </span>“<span>magic</span>”
<span>synchronization of the state by sending minimal diffs.</span></p>
</section>
<section id="Simplistic-Refactorings">

    <h2>
    <a href="#Simplistic-Refactorings"><span>Simplistic Refactorings</span> </a>
    </h2>
<p><span>Let</span>’<span>s unwind to something more down to earth, like refactorings. Not the simple ones, like rename,</span>
<span>but complex ones, like </span>“<span>change signature</span>”<span>:</span></p>
<p><a href="https://www.jetbrains.com/idea/guide/tips/change-signature/">https://www.jetbrains.com/idea/guide/tips/change-signature/</a></p>
<p><span>In this refactoring, the user selects a function declaration, then rearranges</span>
<span>parameters in some way (reorders, removes, adds, renames, changes types, whatever), and then the IDE</span>
<span>fixes all call-sites.</span></p>
<p><span>The thing that makes this refactor complex is that it is interactive </span>—<span> it</span>’<span>s not an atomic request</span>
“<span>rename </span><code>foo</code><span> to </span><code>bar</code>”<span>, it</span>’<span>s a dialog between the IDE and the user. There are many parameters that</span>
<span>the user tweaks based on the analysis of the original code and the already specified aspects of the</span>
<span>refactoring.</span></p>
<p><span>LSP doesn</span>’<span>t support this workflows. Dart somewhat supports them, though each refactoring gets to use</span>
<span>custom messages (that is, there</span>’<span>s quite good overall protocol for multistep refactorings, but each</span>
<span>refactoring essentially sends </span><code>any</code><span> over the wire, and the IDE on the other side hard-codes specific</span>
<span>GUIs for specific refactorings). This per-refactoring work is not nice, but it is much better than</span>
<span>not having these complex refactorings at all.</span></p>
</section>
<section id="Dynamic-Registration">

    <h2>
    <a href="#Dynamic-Registration"><span>Dynamic Registration</span> </a>
    </h2>
<p><span>A small one to conclude. Significant chunk of conceptual LSP complexity comes from support for</span>
<span>dynamic registration of capabilities. I don</span>’<span>t understand why that features is there, rust-analyzer</span>
<span>uses dynamic registration only for specifying which files should be watched. And that would be much</span>
<span>simpler if it used a plain request (or a subscription mechanism).</span></p>
</section>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Has anyone gotten complete, permanent relief from tinnitus? (229 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37852711</link>
            <guid>37852711</guid>
            <pubDate>Thu, 12 Oct 2023 02:10:00 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37852711">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="37855076"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855076" href="https://news.ycombinator.com/vote?id=37855076&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I’ve had tinnitus for about one year now. There is no permanent relief or treatment. Lots of snake oil.<p>My hearing was tested by an Audiologist and my hearing was normal.</p><p>The “sound” I observe is high pitched. Using a tone generator I matched it to around 16,500 Hz. Interestingly, if I play that tone I get temporary relief on the order of 2-10 minutes.</p><p>As far as I understand my tinnitus is the result of something going wonky with the signal processing in the brain.</p><p>If you’re suffering from tinnitus for the first time it’s important to remain calm. There is defiantly an amplifying effect from the psychological aspect of tinnitus. Eventually the body will “habituate” if it does not go away. It took me around 3-6 months to be able to ignore it. During the day I rarely hear it. At night a little more. Playing sounds at a low volume on a Bluetooth speaker helps. For example on Spotify an artist called “TMSOFT” has good stuff. In the day I’ll listen to jazz or lofi.</p><p>It’s important to protect your ears. iPhone has a hearing protection feature for headphones and I have it on the lowest setting. I would avoid in-ear headphones. Use hearing protection at concerts.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37855534"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37855534" href="https://news.ycombinator.com/vote?id=37855534&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I’ve had tinnitus for something like 5 years now and mine varies from day-to-day. Mine seems to be somewhat connected to diet. I think salt might be a trigger. If I have a French Fries or some other salty snack, I’m in for louder ringing an hour or two later.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37855318"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37855318" href="https://news.ycombinator.com/vote?id=37855318&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>Aren’t in ear headphones with noise cancellation better than not using them and instead raising the volume to overcome background noise?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37855257"><td></td></tr>
                <tr id="37855390"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37855390" href="https://news.ycombinator.com/vote?id=37855390&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>Phase is a physical property of sound waves that cannot influence a signal originating from the brain or cochlea.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37855541"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37855541" href="https://news.ycombinator.com/vote?id=37855541&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>It's fun to test what happens when you play the same wave through your headphones but one channel is inverted.<p>Funny enough lots of stereo widening magic relies on a physical property of sound not existing when it's in your head.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37855431"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37855431" href="https://news.ycombinator.com/vote?id=37855431&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Yea, but he proposed shifting the phase of the physical signal (16.5khz) which supposedly matches the frequency of the imaginary signal.<p>I still think it's unlikely to work.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37855503"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37855503" href="https://news.ycombinator.com/vote?id=37855503&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I understand, and there could very well be some psychoacoustic cancellation when stimulating with a matching tone. But any effect will be regardless of the phase of the signal, because phase cancellation is a physical effect of sound waves that occurs before they are converted to neural activity (where tinnitus originates from).</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37855424"><td></td></tr>
                              <tr id="37855366"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855366" href="https://news.ycombinator.com/vote?id=37855366&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I also have what I'd now say is quiet tinnitus, when I used to party a lot it was pretty bad. I won't notice it during the day and I don't really notice it at night, however that wasn't the case a year or two ago.<p>Things I've done to try prevent it getting worse:</p><p>* iOS has a limit volume option - that's on permanently.</p><p>* I use a speaker on soft volume in the room when wfh rather than headphones when listening to music.</p><p>* I have ear plugs on my keys for when I end up going out to music events and festivals (I use Alpine, partner uses Loop). This made a huge difference and I'll go to bed without ringing ears.</p><p>* I try have days where I don't listen to music. At first it was weird, now I'm quite used to it.</p><p>* Online meetings, keep the volume low where possible.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37855249"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855249" href="https://news.ycombinator.com/vote?id=37855249&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I got mine under control, though there is still a bit left that probably wont go away, but is totally ok for me. Got rid of my 2 main stress sources, changed to a much more healthy diet, drinking more regularly and if there is a new tinnitus attack (i still do not know the propper english word, in german its hörsturz) i do breathing and ear massaging for half a minute. Not just massaging the outer ear but also gently pumping with air pressure similar to adjusting after a flight. I noticed time is super critical here. Just before the tinnitus starts there is 1 or 2 seconds where you feel the hearing disappears its as if the volume is turned down. If the massaging and deep breathing starts in this moment before the tinnitius beeping and noise sets in, it seems to always go away completely after.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37855335"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37855335" href="https://news.ycombinator.com/vote?id=37855335&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span><pre><code>   i still do not know the propper english word, in german its hörsturz
</code></pre>
In several forums I've seen them talk about "spikes"</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37855337"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855337" href="https://news.ycombinator.com/vote?id=37855337&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I think I'm an odd case, in that I did have "tinnitus" (a constant high pitched buzz in my right ear), along with a constant tension headache that resulted in me not getting any sleep. I was prescribed sleeping pills and then a visit to the neurologist said all my conditions were caused by anxiety. I actually didn't think I was anxious (I think it was the result of a bad night on cocaine).
Err... Anyway, a large career break with lots of relaxation gave me relief from both my daily headaches and tennitus. I was doing lots of exercise and also drinking a lot of water mixed with corriander (I was convinced this would help to detox me for some reason).
The tennitus went away after about 2 months and it took about a year to get away from the constant headaches. I haven't done class A drugs since...
Probably not at all helpful, but I thought I'd share.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37855217"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855217" href="https://news.ycombinator.com/vote?id=37855217&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I have it for 4 years and got almost completely desensitized. It <i>is</i> a relief. It’s still there (and right now it rings). But it doesn’t create colorful reactions anymore. During the day, at night, before sleep, it rarely bothers me. Sometimes I even feel comfy about it.<p>In my case the secret was a <i>sort</i> of a therapy. At the second year I’ve become quite suicidal about it. There was a point in time after collecting all the information there is, when I absolutely ultimately had to make a decision. As a result of this thought process, “I will die with it” got fully accepted either way. Somehow this deadened my reactions and after a short while it became just a part of my life that I ignore. My brain got so good at masking it that I have to carefully listen sometimes (yeah, it’s there and it’s loud). I also stopped looking for a cure, relief, methods, threads like this. Not like “I shouldn’t”, but like “not interested”.</p><p>Pretty sure I must not recommend this way or leave it without a disclaimer: if you feel the same, then get professional help, don’t go through it alone.</p><p>My key insight is that you suffer while the hope lives, not that you have to lean over the edge to realize that.</p><p>Edit: upvote to <a href="https://mynoise.net/" rel="nofollow noreferrer">https://mynoise.net</a>, it helped to mask it at early stages much better than colored noises or youtube videos. You can tune sound components to your case and there’s a lot of presets now.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37853407"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853407" href="https://news.ycombinator.com/vote?id=37853407&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I'm a physician with lifelong bilateral tinnitus. Multiple pitches, quite loud, and acutely worse on the right side for the last 1.5 years or so (with some slight hearing loss).<p>I've spent a <i>lot</i> of time on PubMed, but so far I've not found anything that helps mine, even partially or temporarily. I've consulted with close friends that have significant expertise is relevant fields, which has not been fruitful.</p><p>Thankfully it's just part of existence as I've always known it, and so it's usually not too difficult, but can really be maddening when trying to fall asleep.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37855554"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37855554" href="https://news.ycombinator.com/vote?id=37855554&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Have you talked about the Lenire device with your colleagues at all? It got FDA approval and is slowly rolling out as they train audiologists.<p>There’s a Lenire provider where I live (Austin) and I’m on the fence about scheduling an appointment to get one.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37853468"><td></td></tr>
                <tr id="37853960"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37853960" href="https://news.ycombinator.com/vote?id=37853960&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Not the same user, but I've found the most relief from pink noise like rain or a waterfall played through decent speakers. I find it to be easier on the ears and less distracting than white noise.<p>I'd recommend anyone suffering play around with the generators on myNoise. It wouldn't be an exaggeration to say they kept me going when I was first adjusting to the ringing.</p><p><a href="https://mynoise.net/NoiseMachines/rainNoiseGenerator.php" rel="nofollow noreferrer">https://mynoise.net/NoiseMachines/rainNoiseGenerator.php</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37855038"><td></td></tr>
            <tr id="37854008"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37854008" href="https://news.ycombinator.com/vote?id=37854008&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I also listen to pink noise or rain sounds on headphones throughout my work day. I worry about the side effects of listening to random noise for so long, but I continue (not loudly) because it effectively masks my tinnitus (and helps with my task focus).</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37854828"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37854828" href="https://news.ycombinator.com/vote?id=37854828&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Again a different person but my tinnitus souds like white noise - but at a different pitch so not much use.<p>Unless I put the white noise very loud to drwon out tinnitus which is not a good thing to do.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37854870"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37854870" href="https://news.ycombinator.com/vote?id=37854870&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>You can modulate the white noise very effectively. I dabble with analog synthesizers which let you use low/high pass filters on white noise to get very interesting sounds. I wonder if you carefully matched it, it might alleviate the discomfort. Worth trying I suppose.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="37853779"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853779" href="https://news.ycombinator.com/vote?id=37853779&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>My tinnitus was caused by flying long distance while having a ear infection. The first year was horrible, but after that it got a better every year and about 5 years later it's basically gone. I can only hear it now when I am in a very quiet environment or (this is the simplest way to revive it) bite down hard on my teeth. I think my brain has adjusted to the sound by masking it.<p>Most doctor visits were quite disappointing since they didn't do anything. I heard from many people that early therapy can help a lot (like oxygen therapy) but my doctor only tried some of these things after I repeatedly asked for it. But by that time it was already too late (like 3-4 weeks later).</p><p>What helped me was:
- distraction  
- constant white noise in the background  
- avoiding any source of loud sounds/music/etc (I am very sensitive on that now)  
- relaxing my jaw muscles  
- distraction  
- going to the doctor at the earliest sign of possible ear infections to stop infections from spreading to the inner ear.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37854901"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37854901" href="https://news.ycombinator.com/vote?id=37854901&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I'm not saying this will work for everyone, but I just lie to myself.<p>I know this isn't true, but I've told myself that having tinnitus is a normal thing, that everyone has.</p><p>The "fact" that it's normal and that everyone has it has removed the suffering for me.</p><p>Weird, but maybe it will help someone here.</p><p>"Pain is inevitable, suffering is optional."
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37853075"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853075" href="https://news.ycombinator.com/vote?id=37853075&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Yes, mine is not solved in theory but is solved in practice. The ringing is still there if I listen for it, but it’s effectively unnoticeable and I’m now unbothered by it.<p>The solution that worked for my was basically “acceptance and commitment therapy” - I think I learned it from a book written by a Dr Russell or something like that.</p><p>Would recommend, am very glad I did it. It seems kind of kooky though, it’s almost like you pretend the tinnitus is a part of you and you have a conversation with it and welcome it and all that kinda stuff over time, and then eventually it just kinda stops being bothersome. Doesn’t really make sense, but worked well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37853944"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37853944" href="https://news.ycombinator.com/vote?id=37853944&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I think this is the only way as of moment. Just desensitize yourself to the sound until there's no effect on you.<p>One thing I tried as I was still anxious about the matter that I had damaged my hearing permanently, was sitting in a pressurized chamber with a lot of oxygen. Ridiculously expensive and did basically nothing. Possibly if you go immediately after it happens it might help but I'm doubtful of its benefits (the company was making a buck though as single-person business).</p><p>I just remember this lady who had hit a garbage can's lid too hard which had made her ears ring. How unlucky. She was quite stressed about it as well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37853448"><td></td></tr>
            <tr id="37855134"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37855134" href="https://news.ycombinator.com/vote?id=37855134&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I've had it for as long as I can remember soI don't know what life is without.<p>I've had some curiousity from time to time, but that's the extent of it.</p><p>I truly believe acceptance is the best cure when no cure exists in this case, but it's also the most difficult method in all aspects of life.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37855295"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37855295" href="https://news.ycombinator.com/vote?id=37855295&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I know stress is an aggrevator of tinnitus for me, clenched jaw and tight neck muscles etc.<p>So in a practical sense, worrying about it literally made it worse by triggering those stress reactions which worsened the tinnitus.</p><p>It's that mechanism that acceptance helps me with.</p><p>I am not always accepting, but if I can calm myself down and just deal with it, it lessens drastically.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37855322"><td></td></tr>
                        <tr id="37854734"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37854734" href="https://news.ycombinator.com/vote?id=37854734&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>My tinnitus is there pretty much all of the time, and then for an hour or so it will disappear.<p>Over the last year or so I've developed really bad hyperacusis, this coupled with misophonia had made me severely suicidal, I even contacted the local mental health services and autism charities.</p><p>I've reduced that by wearing coloured lenses, I had been diagnosed with irlen but I see it as a little bit woo, however the coloured lenses have really worked.</p><p>My theory - I have a sensory fuck-it-bucket - I'm bombarded by all this crap every day, and if it overflows I'm under real stress, by reducing overload from other senses my bucket fills much slower, and the sound and tinnitus doesn't seem to affect me so much.</p><p>Strange to think that a £16 pair of cheap glasses has saved me.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37854987"><td></td></tr>
                  <tr id="37855478"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855478" href="https://news.ycombinator.com/vote?id=37855478&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I had tinnitus for 1 month or so when I was living in London and it went away on its own. Can't remember if it stopped before or after I moved to Germany. In London I was living in a busy area above a grocery shop overlooking a street with a lot of buses going past so there was a constant hum from below. Not sure if it was related but my tinnitus just wouldn't go away. I had had tinnitus before but only for short periods if time and not so intense; only if the environment around me was totally quiet and I was very tired.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37853869"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853869" href="https://news.ycombinator.com/vote?id=37853869&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I'll use this thread as an opportunity to say this: if you ever have sudden hearing loss in one or both ears, seek immediate medical attention. Demand a proper consultation and don't take "give it a few weeks" as an answer from a GP.<p>Sudden hearing loss can be reversed with prompt steroid injections but if it's left then it will become permanent. My mother woke up one day with no hearing in one ear. Unfortunately, by the time she got a proper diagnosis it was too late to do anything about it. Since then she's had tinnitus and vertigo to go with it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37855053"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37855053" href="https://news.ycombinator.com/vote?id=37855053&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>So far I can see, sudden loss of any sense (gettin hearing, smell, sight) is always a cause for concern. I will request my doctor to do a deep investigation.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37853961"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37853961" href="https://news.ycombinator.com/vote?id=37853961&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>That’s a real thing. Sadly science is clueless about this and doctors even more. Specialized clinics threat sudden hearing loss with intravenous injection cocktails containing steroids and sedatives over the course of few weeks with mixed results. On other hand the cause is not well understood and probably universal treatment does not fit all cases.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37855485"><td></td></tr>
            <tr id="37855146"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855146" href="https://news.ycombinator.com/vote?id=37855146&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Yeah! But I’m gonna say I’m really odd, it’s a lot of vibes and unless I convince a doctor of a case study, I’d never be believed.<p>I have/had Tinnitus (it’s nowhere near as bad as it was 7/10 to it’s current 1/10). It’s been gone 7-8 years now.</p><p>1. I listen to music much quieter, and let my ears adjust.</p><p>2. This is the weird part. I would get itchy all the time, random pin pricks I’d feel often. I read about monks who meditated so long they could turn off their hearts. So I sat in bed for 3 months (before going to sleep) and tried really hard to look at where I felt an itch and see it was my body was wrong. There was no reason to give me a cue to itch. Nothing was happening.</p><p>I can easily ‘feel’ the pin pricks if I desire but don’t anymore. It’s like a weird mental trick. I can also feel mosquitos and really anything touch me and no longer get false cues.</p><p>Anyhow I suffered from tinnitus and did the normal suggested stuff but it didn’t work. So I remembered the time I got rid of my itching and tried to replicate what I did.</p><p>I sat and listened to ‘true noise’ and untrue ‘noise’ and it wasn’t instant relief but over 2-3 weeks it went to level it’s at now. I only notice it if I desire. It’s louder an extremely quiet environment but I swear it’s almost like I can hear my blood pump.</p><p>Listen to really low noise. Quieter than whispers. Then up and up. Train your ear to understand sound and not sound. Then go back down again. Sadly the truest quiet will cost you (some place remote with no bugs or wind) but I did it fine at home because I could remember before I had tinnitus. Earplugs I think don’t work because you hear your blood pump.</p><p>Anyway I’m sorry you’re suffering and I know what I wrote sounds really dumb/unbelievable but I do pretty good on prediction markets… ;) it might work for you. Very weird - no proof in the literature but it worked me.</p><p>-(I did the itch cue training around 12 or 13, tinnitus around 22)
-(I didn’t use any drugs)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37855253"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855253" href="https://news.ycombinator.com/vote?id=37855253&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>In my experience, early intervention can help. I got tinnitus at the age of 30 (from a pressure trauma during scuba diving).
I received some kind of dementia medication after 2 weeks, and the tinnitus was gone not long after that (and never reappeared). The doctor funnily said that a side effect is that I'm gonna feel smarter :)
I'm not sure if it was the medication, or the tinnitus was just temporary anyway, but it was a really loud and unbearable noise for a couple of weeks.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37855356"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855356" href="https://news.ycombinator.com/vote?id=37855356&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>YES! Unfortunately I couldn't tell you how it went away as it just went away over time and never came back. Not even trolling.<p>Had a mild(?) case of tinnitus from about 17 to 20 years of age. Haven't really even thought about it since then but in my case the prime suspect was probably loud music. During that time period I was super depressed and angry at the world so I used to listen to loud heavy metal music nearly all day every day from my earbuds.</p><p>I stopped doing that because of the tinnitus, but it lingered on for long enough such that I can't draw a clear link between the music and tinnitus. Other potential suspects have been quitting dairy, cigarettes and weed, which I also quit in that same time period as the loud music.</p><p>If I had to guess, it was probably damaged stereocilia as @RelativeDelta mentioned.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37855414"><td></td></tr>
                  <tr id="37854946"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37854946" href="https://news.ycombinator.com/vote?id=37854946&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>At least for me, ignoring it seems to work as well as ignoring eye floaters seems to. They're there, but I can filter them out to the point where I forget that they're there.<p>That's it. It's not permanent, but I can forget it's there.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37855132"><td></td></tr>
                  <tr id="37855420"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855420" href="https://news.ycombinator.com/vote?id=37855420&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I gave up a long time ago (almost 20yrs) after looking into it but recently I had a video pop up on my YT-short feed that looked interesting. It seemed scammy, and it was, but it got me looking more into it again.<p>I came across an FDA-approved device called lenire. Reviews seem hit or miss, but if I'm feeling flush I may try it. I can mostly put up with my tinnitus these days but it can get quite frustrating when tired &amp; I want to sleep.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37853098"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853098" href="https://news.ycombinator.com/vote?id=37853098&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>It's impossible to cure.<p>The 'ringing' sound people hear isn't actually a sound. It is how the brain processes signals produced by damaged Stereocilia.</p><p>If the 'ringing' is constant it means the cilia are permanently damaged. While it would, in theory, be possible to use surgery on the ear and some sort of lazer to completely remove all damaged cilia to avoid them outputting a damaged signal, this procedure would be incredibly invasive and risky. I don't believe it's ever been done and i would find it hard to believe any Otolaryngologist willing to try.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37853613"><td></td></tr>
                <tr id="37854883"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37854883" href="https://news.ycombinator.com/vote?id=37854883&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I'm not a doctor but I have good hearing, and heard a friend's tinnitus. Apparently they had a constant muscle spasm that was causing a "buzzing" sound, and if you listened carefully, you could hear it. They eventually got it botoxed and that fixed it (injections 2-3 times a year I think, ongoing).</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37853537"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37853537" href="https://news.ycombinator.com/vote?id=37853537&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>There's a trick which I can't recall the name of, which involves thumping your fingers across the back of your neck, which temporarily resolves tinnitus in some people.  I have very mild tinnitus, and have noticed that that does quiet it.<p>This is a question for everyone I suppose, but does anyone know why that works? Could it be possible to develop an implant or something which generates the same effect?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37853750"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37853750" href="https://news.ycombinator.com/vote?id=37853750&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>Your tinnitus is likely being caused by tight sternocleidomastoid muscles (SCM). I would look into stretches to resolve that.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37855050"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37855050" href="https://news.ycombinator.com/vote?id=37855050&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I thought that works because it creates a complex of sensations that overload your audio “tract”. For example if I do the described trick without isolating/covering my my ears with palms, it does nothing. The difference is not in pressure, but in the fact whether I can/can’t deep-hear the punches that my fingers create. Not a doctor, but something tells me there’s more to that. All scans shown that I have zig-zagged vessels in my neck, but within what they see as a “norm”.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37853797"><td></td></tr>
                  <tr id="37853601"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37853601" href="https://news.ycombinator.com/vote?id=37853601&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>It works for people that have tinnitus due to tight neck muscles. Tinnitus due to damaged ears is a whole different beast.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37853725"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37853725" href="https://news.ycombinator.com/vote?id=37853725&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I went to a lot of loud concerts when I was younger and just assumed that I had tinnitus from those, and until now, I had no idea there were multiple causes of tinnitus.<p>I had assumed this was incurable but if my tinnitus is from tight neck muscles, that seems fixable. I'm going to reach out to my doctor about this. Thank you, I think you might have just greatly improved my life.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37853857"><td></td></tr>
                  <tr id="37853936"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37853936" href="https://news.ycombinator.com/vote?id=37853936&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>&gt;While it would, in theory, be possible to use surgery on the ear and some sort of lazer to completely remove all damaged cilia to avoid them outputting a damaged signal, this procedure would be incredibly invasive and risky.<p>It sounds like what we need is nanobots to do this surgery.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37855075"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855075" href="https://news.ycombinator.com/vote?id=37855075&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Short answer is no.<p>But I have had complete temporary relief for a few days at a time that coincided with other signs of healing in my body, which hints at what could bring about permanent abatement.</p><p>I’ve had mild tinnitus since I was about 12-13yrs old (I’m in my 40s now).</p><p>It’s never been especially debilitating; it doesn’t impair my hearing or diminish quality of life, it’s just always there in the background.</p><p>Since about the same age I’ve had signs of inflammation in the digestive system/respiratory system and other mild/moderate symptoms that research suggests are related to microbiome issues - EBV, CMV, etc. at its worst it’s been like chronic fatigue or fibromyalgia, though not always and not these days.</p><p>I’ve tried a lot of things over the years to try and resolve these issues - diet/nutrition, detoxing, cleansing, infrared, occasionally more extreme things I won’t mention here. On a few precious occasions everything seemed to click into place and I just felt a really pleasant, energized feeling through my body, the signs of inflammation went away, my digestion improved and the tinnitus abated and my hearing was completely clear.</p><p>Every time however, the baseline symptoms, including the the tinnitus, returned within a few days and remain to this day (though probably at a milder level than a few years ago).</p><p>I don’t have any definitive takeaways from all this, but it suggests to me that if there’s a way to fully resolve chronic inflammation and microbiome issues (which are quite common), it may bring about a complete abatement of tinnitus.</p><p>(You can Google for CMV tinnitus/EBV tinnitus to find research papers and articles/discussions on correlations between these conditions).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37853845"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853845" href="https://news.ycombinator.com/vote?id=37853845&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I had tinnitus for a while, and tried a few things that didn't work but this thomping technique I found on reddit one day stops it, and I just do it every couple of days and it disappears for a while. Not permanent but whenever it bothers me now I just do this thumping and it disappears in a few seconds:<p><a href="https://www.youtube.com/watch?v=2yDCox-qKbk">https://www.youtube.com/watch?v=2yDCox-qKbk</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37854721"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37854721" href="https://news.ycombinator.com/vote?id=37854721&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>Weird. I tried it and didn't get much effect, but it's interesting to see so many positive comments on it. I'll try it some more over the next couple days.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37855465"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37855465" href="https://news.ycombinator.com/vote?id=37855465&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I think that's because tinnitus comes in very different forms and intensity, and since it can't be objectively measured, it's difficult to compare between individuals. My guess ist that you can only silence very low intensity tinnitus with this technique.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37855293"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37855293" href="https://news.ycombinator.com/vote?id=37855293&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>Try a constant pressure massage instead of the thumping. Pressure should be high enough that the sensation is intense but not painful. The goal is to get muscles around the base of your skull to relax. I was amazed at how quickly it had an effect</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37853102"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853102" href="https://news.ycombinator.com/vote?id=37853102&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I've been dealing with tinnitus for about a year now. The only thing I've found that helps is Ginko Biloba. I'm buying that at a "Dollar General" store so the source is iffy and so is the effectiveness, but it certainly does help.<p>My wife has a friend who told her just a few days ago that her husband has had some success toning his done by chewing Bay leaves. I've not tried that yet, but I will soon.</p><p>From what I've read there is still no "cure". But those two things may contain a clue that's worth looking for.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37855094"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855094" href="https://news.ycombinator.com/vote?id=37855094&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Still have it. However:<p>I worried about my tinnitus for so long. It drove me nuts at the beginning. Then one day I stopped worrying. I can't even tell you why, or when exactly that happened, just that it happened.</p><p>I remember reading all the comments saying "you'll get used to it", and then lying awake at night and thinking "I'll NEVER get used to it". It felt like I would have to accept a huge handicap. I really didn't understand how people could just say it doesn't bother them anymore. Really, that loud sound doesn't bother you?</p><p>And here I am today. I don't even think about it on most days. And most importantly, it does not feel like a handicap at all. It's mostly just gone. Still there and clearly audible when I think about it, but otherwise gone. Zero impact on my regular life, on my music listening or music making behaviour.</p><p>I also have a pretty strong hayfever allergy. Many people told me I'd get used to that, too, and I have to disagree: no, I don't get used to it, I'm 35 years old and it drives me nuts every single year. But the tinnitus is different. I have it for over 15 years now, and it just became irrelevant.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37855159"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37855159" href="https://news.ycombinator.com/vote?id=37855159&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>For hayfever, different kinds of solutions exist: "vaccines" can help in severe cases; antihistamine pills are the main solution, but I found that some don't work for me and others do: you should ask a doctor and try another one; cortison-based nasal spray and eyedrops also work very well for me.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37855081"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855081" href="https://news.ycombinator.com/vote?id=37855081&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I developed T after a series of encounters with benzodiazepines to lessen my nerves when I was coping with burnout. I didn't know I had burnout, I didn't know what was happening to me, I just wanted it to stop. My tinnitus became unbearable in the weeks after a psychiatrist took me of an benzo and put me on an atypical antipsychotic medication. I always blamed the new medication as the cause of my symptoms (of which T was one) when in reality it was the cessation of the benzo.<p>After 5 years of Tinnitus-hell I was put on yet another benzo and my symptoms were _gone_. It lasted only a number of months, though and when I stopped taking the new benzo ... it all came back.</p><p>I came to the diagnosis of benzo-dependency myself and found a psychiatrist who agreed to assist in a 6-month withdrawal with a gradual taper. After each step my tinnitus came back a bit for a few days and then dropped again. After a number of iterations it became what is known as "baseline", i.e. a background tinnitus I can live with.</p><p>In recent months I started taking Magnesium supplements in the form of citrates and Taurine. I then found this on reddit:
<a href="https://www.reddit.com/r/tinnitus/comments/znyuyj/partial_success_with_ltheanine_and_magnesium/" rel="nofollow noreferrer">https://www.reddit.com/r/tinnitus/comments/znyuyj/partial_su...</a>
The top comment by kenzocarj is my current working model for dealing with Tinnitus. I'd like to try L-Theanine but it's illegal in my country - you can buy it in a form that has added glutamine which worsens my T. I'm now drinking matcha tea as a source of L-Theanine.</p><p>Hope this helps.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37855307"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37855307" href="https://news.ycombinator.com/vote?id=37855307&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>If the symptoms go away with benzos, it seems that the source of your tinnitus is some form of generalised anxiety syndrome, with all the niceties that come with it: tension headaches, teeth clenching, TMJ disorder...
The burnout stresses were eased thanks to the pills, but once withdrawn came back probably harder which could have then triggered your tinnitus.<p>This is why benzos should never be prescribed without any other therapeutic approach alongside. They just hide the pain under the carpet for a while only to see it come back worse after and the root cause needs to be addressed with other means in the meantime.</p><p>Good luck with the road back to balance. There's no secret remedy and it's probably best to take a holistic approach for it and work on your well being from multiple fronts.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37855135"><td></td></tr>
                <tr id="37855276"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37855276" href="https://news.ycombinator.com/vote?id=37855276&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>The magnesium had a dampening effect which started gradually after about 2-3 days - I take it daily around noon in a 400 mg dose. It also had a soothing effect on my restless leg syndrome (one of my other benzo-induced symptoms) which eventually disappeared altogether.<p>My Tinnitus is coupled to poor sleep (both quality &amp; quantity) and I noticed an improvement on that front as well after a few days of magnesium.</p><p>I started taking L-Theanine in the form of matcha tea together with my girlfriend.  Since then we're both experiencing vivid dreams. Unfortunately we've also started taking this at the same time before bed:
<a href="https://www.physalishealth.com/en/food-supplements/stress-sleep-good-mood/relax-and-sleep/" rel="nofollow noreferrer">https://www.physalishealth.com/en/food-supplements/stress-sl...</a>
... so we're not quite sure which one is improving the vivid dreams.</p><p>I started taking magnesium several weeks before I started with the tea and the relax &amp; sleep supplements. It was because of the apparent success with magnesium that I'm now exploring these paths. I'm not sure whether Taurine has any effect (the supplement I started after Magnesium and before L-theanine).
I'm sticking to the Glutamine-Glutamate-Gaba model and found this site that has a number of pointers and supplements in that area:
<a href="https://bebrainfit.com/glutamate-neurotransmitter/" rel="nofollow noreferrer">https://bebrainfit.com/glutamate-neurotransmitter/</a></p><p>I'd advise to try one at a time, around the same time every day and evaluate after a week. Start with Magnesium (not in the form of an oxide)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37853969"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853969" href="https://news.ycombinator.com/vote?id=37853969&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I've had it since I can remember. One of my earliest memories, I was 1 or 2 years old, was "playing" with it while falling asleep at night: I'd focus on it and made the ringing grow louder and louder till it was the only sound in my ears, then it steadily grew quiter till I fell asleep.
Nowadays, I'm 27 years old, my brain filters it out, but I can still hear it when it's quite. Perhaps it's one of the reasons I always have some background lofi music playing.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37854971"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37854971" href="https://news.ycombinator.com/vote?id=37854971&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Also had it as long as I remember, at least since I was about 7 or so, which makes me think it's not related to high level noise exposure.  I know that because I have clear memories of asking other kids whether in times of silence they could hear anything.  It surprised me that they couldn't.<p>My tinnitus is a kind of hissing, predominantly at a very high pitch.  I'm in my mid 40's so grew up around CRT TVs. I think it's about the 15kHz horizontal refresh frequency, which makes me wonder whether my brain was trained at a young age to expect CRT TV sounds to be around and now it's just a permanent artefact, like a noise cancellation circuit that's gone wrong.</p><p>I find it gets worse if I'm run down, or eg. If I drink too much alcohol, or if I wear headphones for too long.</p><p>If I think about it, I can hear it at any time, but generally it's not too bad.  I know it's not very helpful, but acceptance of it and shifting focus to other things definitely helps me, to the point that it usually fades away and is generally not noticeable at all.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37854888"><td></td></tr>
                <tr id="37855262"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37855262" href="https://news.ycombinator.com/vote?id=37855262&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Just tried this and it did temporarily stop the tone for a moment. Easy to do, instant relief. Simple massage to the muscles near the base of the skull.<p>A physical therapist commented that tight muscles contribute. Hopefully practicing this regularly will prolong the effects.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37854809"><td></td></tr>
            <tr id="37855260"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855260" href="https://news.ycombinator.com/vote?id=37855260&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>There is an entire system of Yoga called Nada Yoga; that deals with listening to so called internal music, usually described/experienced as high pitched tones/chords.<p>I have no idea how that relates to tinnitus; I hear high pitched tones/chords outside of meditation occasionally, but it's never bothering/disturbing.</p><p>My gut feeling says that sometimes, labeling an experience as a problem is why it becomes a problem.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37855398"><td></td></tr>
            <tr id="37855312"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855312" href="https://news.ycombinator.com/vote?id=37855312&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I just realized reading all these replies with people who also suffer from it does somehow help. It helps to worry less, because evidently there's not much that can be done medically (at least for now). So, thanks for this!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37855438"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37855438" href="https://news.ycombinator.com/vote?id=37855438&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>Yes, especially /u/n8henrie's comment. They have the expertise (assuming they are who they say they are), and have put in the time and research, and came to a conclusion. I'm not going to double up on their work.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37855208"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855208" href="https://news.ycombinator.com/vote?id=37855208&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I’m almost completely deaf in one ear and had problems with tinnitus in the beginning (~7 years ago), especially when trying to sleep. Nowadays, I really only notice it when I focus on it, and it has no impact on my quality of life whatsoever. I think a lot of it is psychological.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37854839"><td></td></tr>
            <tr id="37855174"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855174" href="https://news.ycombinator.com/vote?id=37855174&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I had both high-pitch and pulsatile tinnitus after covid; benadryl often just turned off the high-pitch one within 30-60 minutes of taking it; pulsatile one went away after supplementing iron bisglycinate, lactoferrin and liposomal B12 for a while.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37854689"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37854689" href="https://news.ycombinator.com/vote?id=37854689&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I had a period of bacterial imbalance in my gut caused by Plastocystis Hominis. At it's worst, I got periods of tinnitus. After being cured, took a year to find the cause, the tinnitus also disappeared. Worth checking out the bacterial balance in the gut and trying some probiotics.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37854902"><td></td></tr>
            <tr id="37853341"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853341" href="https://news.ycombinator.com/vote?id=37853341&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>One month was the worst point. It gets better from there until it's unnoticeable unless in a silent room. You will be surprised how the brain is able to both cancel out and then rebalance the sound input to normal (should your tinnitus be one-sided). Same goes for "cracks" that you might hear if the sounds are too loud -- they also go away in time.<p>I might as well note that anecdotally, barotrauma makes the tinnitus better temporarily. Maybe there is an explanation -- traumatic tinnitus can be at least alleviated by going into an overpressurization chamber immediately after the traumatic event. It seems like even after the fact, a pressure difference has temporary effect. For example, my tinnitus feels better after ascend on flights, even though in this case it's underpressure.</p><p>The best motivational video that I still think of after 10 years is this: <a href="https://youtu.be/eOU0JhkHY3w" rel="nofollow noreferrer">https://youtu.be/eOU0JhkHY3w</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37855486"><td></td></tr>
            <tr id="37853806"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853806" href="https://news.ycombinator.com/vote?id=37853806&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>No permanent relief. It goes away when I meditate but that is temporary. The first few weeks I started vyvanse it completely disappeared, even if I focused on it, but once my body normalized to it, it came back.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37854932"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37854932" href="https://news.ycombinator.com/vote?id=37854932&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I have mild tinnitus on one side. It doesn't cause too much discomfort but it's there. I am pretty sure it is caused by something pressing on a nerve on my neck so it's probably not the kind that most people have. I am hyphotizing that it would go away if I fixed the neck issue but that itself isn't so easy to do either.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37855279"><td></td></tr>
            <tr id="37853643"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853643" href="https://news.ycombinator.com/vote?id=37853643&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Considering all of our hearing gets damaged slowly over the course of our lives, why does tinnitus only effect some people? I've had it for short periods of time after listening to loud live music, but hours later it just fades out to disappear. A musician once told me that it was the sound of your ear getting damaged and when you hear that you'll likely never hear those frequencies again.<p>I'm not convinced it's an entirely physical issue though. Our brains can filter out all kinds of excessive external stimuli both visual and from other senses so why not that ringing also?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37853665"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37853665" href="https://news.ycombinator.com/vote?id=37853665&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>&gt;A musician once told me that it was the sound of your ear getting damaged and when you hear that you'll likely never hear those frequencies again.<p>This is a line in the film Children of Men (highly recommended), can't remember if it's in the book but either way it isn't correct.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37853676"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37853676" href="https://news.ycombinator.com/vote?id=37853676&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Definitely a mix of physical and nerve stimulation.<p>Either way temporary exposure can cause temporary issues, once it's permanent though it seems irreversible for now
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37855044"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855044" href="https://news.ycombinator.com/vote?id=37855044&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I'm just speculating here. If somehow we could determine the exact waveform of the ringing, wouldn't be possible to just play the reverse waveform and cancel it out? Like how active noise cancelling headphones are doing.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37855083"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37855083" href="https://news.ycombinator.com/vote?id=37855083&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>Tinnitus isn’t sound in the “vibrating molecules of air” sense—it’s a neurological phenomenon. Anything’s possible—but our perception of sound is not obligated to play by the same rules as physical sound does, and ANC relies on those rules.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37855078"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37855078" href="https://news.ycombinator.com/vote?id=37855078&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I have tinnitus which is within the frequency range I can hear, what I've found using headphones and a web tone generator is that I can establish a 'beat' frequency but I can't cancel it out entirely. That leads me to suspect that the frequency and phase of the tinnitus isn't consistent enough to cancel without actively tracking it, and how do you do that?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37855066"><td></td></tr>
            <tr id="37855062"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37855062" href="https://news.ycombinator.com/vote?id=37855062&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Unlikely, because tinnitus is (from what I understand) a malfunction of the auditory part of the brain. There is nothing physical to cancel out.<p>Also, mine for example, is not completely static.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37855059"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37855059" href="https://news.ycombinator.com/vote?id=37855059&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>My tinnitus, that my second covid infection gave me, is outside my current hearing frequency range.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37853669"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853669" href="https://news.ycombinator.com/vote?id=37853669&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>In highschool I basically lost my hearing on one side. It went silent for a little bit and now I have a static/beeping on it almost constantly.<p>Had overpressure therapy in the weeks/months after but didn't help.
Have a bone anchored heading aid (via implanted screw) but doesn't work well.</p><p>Learned to live with it but mostly terrified if something will happen to my other ear... still have a few decades to go I hope, so better hold on to the hearing I have or science better hurry up
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37855321"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855321" href="https://news.ycombinator.com/vote?id=37855321&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>This is a little bit off topic but sort of related in how there seems to be at least 2 kinds of tinnitus which might have different cures, if any.<p>I have the kind I believe is called "somatic tinnitus". It's very high pitch and multiple tones. If I stretch my body or clench my teeth it becomes louder. It does not really sound like they come from one ear or the other.</p><p>It can also become louder if I'm drunk, or if I get a nicotine rush. It also becomes temporary louder if I listen to noise for a long time and then turn it off.</p><p>But from time to time I also get the occasional high pitch ringing in one of my ears that last for a few seconds. I've also gotten temporary tinnitus from a loud concert. While they are similar they seem different to me.</p><p>Just having casually talked to other people about this, I wonder if a lot of people have somatic tinnitus but are sensitive to it to varying degrees.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37853306"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853306" href="https://news.ycombinator.com/vote?id=37853306&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>In my case it has 2 modes. Super loud and very attenuated. I still have no idea what triggers it, I thought it was loud noises, caffeine, tiredness etc, but seems like its not a 100% rule. I have been super tired and done all those things and suddenly its super attenuated. So it's super random. Im sure for certain people there must be something that helps reduce it, maybe something related to the nervous system. I honestly don’t mind it anymore as long as I can hear. You can learn to tune it out for sure</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37853770"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853770" href="https://news.ycombinator.com/vote?id=37853770&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I have had very mild tinnitus my entire life - since as early as I can remember in childhood. It's never been particularly bothersome but in a quiet room I can clearly hear it.<p>However, when I received the second dose of the Pfizer mRNA vaccine in 2021, within a day I had a substantial increase in tinnitus in both ears, particularly my right. I also had a persistent sensation of "fullness" in my right ear.</p><p>I went to an ENT. They were pretty skeptical of the connection to the vaccine, said they couldn't see anything physically wrong with my ears, but we had a good conversation about tinnitus in general. They told me there wasn't much anyone could do, but anecdotally, they did think that many of their patients reported actual improvement from an OTC nutritional supplement, "Lipo-flavonoid", specifically marketed for tinnitus.</p><p><a href="https://www.amazon.com/Lipo-Flavonoid-Supplement-Recommended-Effective-Treatment/dp/B07GTHKNC6" rel="nofollow noreferrer">https://www.amazon.com/Lipo-Flavonoid-Supplement-Recommended...</a></p><p>I ordered a bottle and tried it out, and sure enough, I do think it made a difference - it did seem to quiet down the tinnitus, but not back to the level I was used to.</p><p>After about 2 months the tinnitus and sensation of fullness faded.</p><p>I elected not to get the booster.</p><p>Best of luck to you. I do suggest giving this supplement a try.</p><p>For those of you skeptical about any connection to the covid vaccines, you might find this article interesting quoting the Editor-in-Chief of the journal VACCINE and head of vaccine research at Mayo Clinic. <a href="https://www.upi.com/Health_News/2022/08/08/tinnitus-widespread-study/6281659985508/" rel="nofollow noreferrer">https://www.upi.com/Health_News/2022/08/08/tinnitus-widespre...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37854895"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37854895" href="https://news.ycombinator.com/vote?id=37854895&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>Anecdotally I had a similar experience but much more short-lasting. First and second dose caused pretty severe flu-like-symptoms and ringing in my ears for a few days. I'm prone to ear infections and it was very much like that. Thankfully both times it went back to normal in a week or so.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37853930"><td></td></tr>
                <tr id="37853973"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37853973" href="https://news.ycombinator.com/vote?id=37853973&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I recall some fatigue and maybe light muscle soreness or something like that, but pretty mild symptoms overall.<p>I’d say I get a bad cold once or twice a year and rarely experience anything more severe than that.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37854033"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37854033" href="https://news.ycombinator.com/vote?id=37854033&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I wondered if the vaccine flu symptoms might've created congestion in your middle ear but sounds like it didn't.<p>Perhaps you could do an experiment on yourself with the supplement to figure out if it's really having an effect or just placebo.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="37854575"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37854575" href="https://news.ycombinator.com/vote?id=37854575&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>I had this for months when I stopped taking benzos. I remember it made all the music I loved sound out of pitch and awful. It kind of makes you feel out of touch with the world too when you're getting this weird distorted version of it. All I can say is I hope you can learn some good coping strategies. I don't have this symptom any more but I sympathize.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37855125"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855125" href="https://news.ycombinator.com/vote?id=37855125&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>There are upcoming meds that do help but it's still in trials such as RL-81<p>It's gonna be a while
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37853675"><td></td></tr>
            <tr id="37853740"><td></td></tr>
            <tr id="37853392"><td></td></tr>
            <tr id="37854026"><td></td></tr>
                <tr id="37854755"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37854755" href="https://news.ycombinator.com/vote?id=37854755&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I'd heard about this. Their studies seem to have mixed results, and there's mixed anecdotal evidence on /r/tinnitus at best. I looked into it, there's a clinic near me that offers it, but it's $5000!<p>My tinnitus isn't so bad that I feel compelled to drop 5g on fixing it, but I think their idea seems promising and I hope they continue to research it and find new ways to treat it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37853799"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853799" href="https://news.ycombinator.com/vote?id=37853799&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Tried a bit for almost a year, got myself rested - realised mine was low enough to barely show up in the test.<p>At that point I started to ignore it, and it works well enough. Except for when I am trying to fall asleep. I sometimes go by many weeks before I notice it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37853816"><td></td></tr>
            <tr id="37853332"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853332" href="https://news.ycombinator.com/vote?id=37853332&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>i think there is research being done on cilia regeneration:
<a href="https://news.mit.edu/2022/frequency-therapeutics-hearing-regeneration-0329" rel="nofollow noreferrer">https://news.mit.edu/2022/frequency-therapeutics-hearing-reg...</a><p>obviously time to get approved/confirm it works - etc lies ahead.</p><p>other than that - i had taken up drums and was paranoid of tinnitus, i could hear ringing etc.  once i got audiologist confirmation my hearing was 20/20 guess what? It went away.  Anxiety levels can affect it...obviously it was mild for me - chronic sufferers wont get away with "dont worry about it and it will go away".
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37853433"><td></td></tr>
            <tr id="37853560"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37853560" href="https://news.ycombinator.com/vote?id=37853560&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>&gt; audiologist confirmation my hearing was 20/20<p>it’s possible you didn’t go to an audiologist.</p><p>(/s)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37854853"><td></td></tr>
            <tr id="37853892"><td></td></tr>
            <tr id="37853645"><td></td></tr>
                        <tr id="37853638"><td></td></tr>
                <tr id="37853931"><td></td></tr>
            <tr id="37853974"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37853974" href="https://news.ycombinator.com/vote?id=37853974&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Monarda is many plants. Any one of them in particular?<p>Will I get the same effect drinking  Earl Grey tea?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37853629"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853629" href="https://news.ycombinator.com/vote?id=37853629&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Not yet. I have absolutely insane tinnitus -- crazy high pitched, can hear it over any sound, too many tones to count. Also have hyperacusis but that's another topic. In any case, historically I've paid a lot of attention to this space.<p>Perhaps the most notable attempt at a cure was Frequency Therapeutics, whose efforts were promising, but unfortunately didn't pan out.</p><p>There's a constant churn of biotech companies trying to solve this, as curing tinnitus (and/or hearing loss) would be a goldmine, but no one has really gotten anywhere yet.</p><p>If you want to stay on top of it, the /r/tinnitusresearch is a pretty good hub, and there are a few mailing lists out there.</p><p>That said, over time I found that ceasing to follow all the promises and inevitable disappointments helped me better achieve the only real "treatment" we have right now, which is accepting it and slowly learning to live with it.</p><p>When there's a real deal cure, you'll know about it. Until then, I suggest not paying attention to the churn and the extremely dubious "treatments" out there.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37854784"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37854784" href="https://news.ycombinator.com/vote?id=37854784&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>Good advice. I've had it for a few years now and mostly learned early on that the best strategy is to just try to live your life and not pay too much attention to it. Occasionally I hear about some "therapies" though and I figured trying to ask the community and specifically asking about "full relief" would be the best way to know for sure if I was leaving anything on the table.<p>I read about the Frequency Therapeutics stuff, and saw the initial promise and subsequent disappointment. Oh well, maybe next year :)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37855190"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37855190" href="https://news.ycombinator.com/vote?id=37855190&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><br><div>
                  <p><span>Nope! Protect your hearing kids, by the time you notice the problem it's far too late (but we also live in an age of miracles, I'm hoping some type of drug will turn up within my lifetime - if Semaglutide can exist, so can this).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37853947"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37853947" href="https://news.ycombinator.com/vote?id=37853947&amp;how=up&amp;goto=item%3Fid%3D37852711"></a></center>    </td><td><p><span>I had mild tinnitus years ago, but it went away over time while I happened to be living in a mostly silent environment off-grid near JTNP.<p>No idea if the long-term quiet environment played a role, but I also occasionally would supplement with sublingual b12[0] methylcobalamin supplements.</p><p>It's impossible to say what's responsible, there's far too many variables.  Maybe just time passing since quitting riding motorcycles is all that was needed.</p><p>[0] <a href="https://en.wikipedia.org/wiki/Vitamin_B12_deficiency" rel="nofollow noreferrer">https://en.wikipedia.org/wiki/Vitamin_B12_deficiency</a>  (search in page for tinnitus)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using OpenBSD Relayd(8) as an Application Layer Gateway (112 pts)]]></title>
            <link>https://www.tumfatig.net/2023/using-openbsd-relayd8-as-an-application-layer-gateway/</link>
            <guid>37852135</guid>
            <pubDate>Thu, 12 Oct 2023 00:34:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tumfatig.net/2023/using-openbsd-relayd8-as-an-application-layer-gateway/">https://www.tumfatig.net/2023/using-openbsd-relayd8-as-an-application-layer-gateway/</a>, See on <a href="https://news.ycombinator.com/item?id=37852135">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><h4><i></i>&nbsp;
<time datetime="2023-10-10">2023-10-10</time>
&nbsp;<i></i>&nbsp;</h4><nav id="TableOfContents"><ol><li><a href="#what-is-relayd8">What is relayd(8)?</a></li><li><a href="#how-to-manage-relayd8">How to manage relayd(8)?</a></li><li><a href="#terminology">Terminology</a></li><li><a href="#simplest-http-relay">Simplest HTTP relay</a></li><li><a href="#better-simple-http-relay">Better simple HTTP relay</a></li><li><a href="#encrypt-http-relay-using-transport-layer-security-tls">Encrypt HTTP relay using Transport Layer Security (TLS)</a></li><li><a href="#load-balancing--failover">Load balancing &amp; Failover</a></li><li><a href="#fallback-servers---automatic-switch">Fallback server(s) - automatic switch</a></li><li><a href="#fallback-servers---manual-switch">Fallback server(s) - manual switch</a><ol><li><a href="#initial-expected-state">Initial expected state</a></li><li><a href="#primary-servers-go-down">Primary servers go down</a></li><li><a href="#switch-to-the-secondary-servers-pool">Switch to the secondary servers pool</a></li></ol></li><li><a href="#relaying-multiple-fqdns">Relaying multiple FQDNs</a></li><li><a href="#relaying-multiple-pathnames">Relaying multiple pathnames</a></li><li><a href="#solving-problems-with-http-headers">Solving problems with HTTP headers</a><ol><li><a href="#unencrypted-connection">Unencrypted connection</a></li><li><a href="#leaking-headers">Leaking headers</a></li><li><a href="#improve-users-security-and-privacy">Improve users security and privacy</a></li></ol></li><li><a href="#log-management">Log management</a><ol><li><a href="#one-for-log-and-log-for-one">One for log and log for one</a></li><li><a href="#logging-options">Logging options</a></li></ol></li><li><a href="#conditional-filtering">Conditional filtering</a><ol><li><a href="#filtering-branched-on-fqdn-12">Filtering branched on FQDN #(1,2)</a></li><li><a href="#filtering-branched-on-fqdn-3">Filtering branched on FQDN #3</a></li><li><a href="#filtering-branched-on-fqdn-4">Filtering branched on FQDN #4</a></li><li><a href="#connecting-the-branches">Connecting the branches</a></li></ol></li><li><a href="#one-more-thing">One more thing</a></li></ol></nav><p>I was lucky enough to attend to EuroBSDCon 2023 and offered the
opportunity to talk about one of my favorite OpenBSD stock daemon:
relayd(8).</p><p>The talk was recorded and made <a href="https://www.youtube.com/watch?v=yW8QSZyEs6E" target="_blank" rel="external nofollow">available on the EuroBSDCon YouTube
channel.</a>
. One may check
the <a href="https://2023.eurobsdcon.org/program.html" target="_blank" rel="external nofollow">EuroBSDCon 2023 program</a>
for more material.</p><p>This post attempts a reboot of the slides content in a more
browser-friendly format.</p><h2 id="what-is-relayd8">What is relayd(8)?</h2><ul><li>Multi-purpose daemon available on OpenBSD since 4.3*:<ul><li>load-balancer.</li><li>application layer gateway.</li><li>transparent proxy.</li></ul></li><li>Capable of monitoring groups of hosts for high-availability.</li><li>Operates as:<ul><li>Layer 3 redirection via communication with pf(4).</li><li>Layer 7 relaying with application level filtering via itself.</li></ul></li></ul><p><a target="_blank" href="https://www.tumfatig.net/images/2023/relayd-rp.png"><img src="https://www.tumfatig.net/images/2023/relayd-rp.png" alt="Using relayd(8) as a reverse-proxy"></a></p><p>* relayd was known as hoststated in OpenBSD 4.1.</p><h2 id="how-to-manage-relayd8">How to manage relayd(8)?</h2><p>The man pages are a must read before proceeding further.</p><pre tabindex="0"><code># man relayd
# man relayd.conf
# man relayctl
</code></pre><p>The configuration file is expected in the standard <code>etc</code> directory. An
example is available if you need more inspiration.</p><pre tabindex="0"><code># more /etc/examples/relayd.conf
# vi /etc/relayd.conf
</code></pre><p>One can check for configuration errors using:</p><pre tabindex="0"><code># relayd -dvn
</code></pre><p>The service is enabled and started using the standard <code>rcctl</code> utility:</p><pre tabindex="0"><code># rcctl enable relayd
# rcctl start relayd
# rcctl stop relayd
</code></pre><p>A dedicated command can be used to get more information about relayd(8)
state and apply specific actions:</p><pre tabindex="0"><code># relayctl 𝘤𝘰𝘮𝘮𝘢𝘯𝘥 [𝘢𝘳𝘨𝘶𝘮𝘦𝘯𝘵 ...]
</code></pre><p>More on this later on.</p><h2 id="terminology">Terminology</h2><ul><li><p>Macros: user-defined variables that can be used later on.</p></li><li><p>Tables: host or a group of hosts defining traffic targets.</p></li><li><p>Protocols: settings and filter rules for relays.</p></li><li><p>Relays: layer 7 proxying instances.</p></li></ul><h2 id="simplest-http-relay">Simplest HTTP relay</h2><p>This is the simplest HTTP Reverse proxy configuration that you can get:</p><pre tabindex="0"><code data-lang="pf">http protocol www {
    pass
}

relay www {
    listen on 203.0.113.1 port 80
    protocol www
    forward to 192.0.2.10 port 80
}
</code></pre><p>The first section defines an HTTP PROTOCOL object. Name has been set to
‘www’ but it can be anything.</p><p>The RELAY section defines a listening address and port. It links the
relay to the previously configured protocol. It defines the backend
server that will receive the HTTP requests.</p><h2 id="better-simple-http-relay">Better simple HTTP relay</h2><p>This example expands the previous HTTP Reverse proxy configuration with
usage of reusable variables (MACROS) and logging of state changes and
remote connections.</p><pre tabindex="0"><code data-lang="pf"># Macros -----------------------------------
ext_addr="203.0.113.1"
webhost1="192.0.2.10"

# Global configuration ---------------------
log state changes
log connection

# Tables -----------------------------------
table &lt;webhosts&gt; { $webhost1 }

# Protocols &amp; Relays -----------------------
http protocol www {
    pass
}

relay www {
    listen on $ext_addr port 80
    protocol www

    forward to &lt;webhosts&gt; port 80
}
</code></pre><h2 id="encrypt-http-relay-using-transport-layer-security-tls">Encrypt HTTP relay using Transport Layer Security (TLS)</h2><p>Previous examples are using plain text HTTP. Switching to HTTPS provides
secure communication and data transfer between the client and the
website.</p><p>You’ll need to acquire a TLS certificate. That steps is beyong the scope
of this post. But have a look at acme-client(1) and httpd(8) manpages.
Those will guide you through the process of getting an HTTPS certificate.</p><p>Once acquired, install the certificate under <code>/etc/ssl</code>. If you used
acme-client(1), you should get files such as:</p><pre tabindex="0"><code>/etc/ssl/private/relayd.example.key
/etc/ssl/relayd.example.crt
</code></pre><p>Reference the certificate name in the protocol section. Then replace the
listen directive of the relay section to specify the usage of <code>tls</code>.</p><pre tabindex="0"><code data-lang="pf"># Macros -----------------------------------
ext_addr="203.0.113.1"
webhost1="192.0.2.10"

# Global configuration ---------------------
log state changes
log connection

# Tables -----------------------------------
table &lt;webhosts&gt; { $webhost1 }

# Protocols &amp; Relays -----------------------
http protocol wwwtls {
    tls keypair relayd.example
}

relay wwwtls {
    listen on $ext_addr port 443 tls
    protocol wwwtls

    forward to &lt;webhosts&gt; port 80
}
</code></pre><p>Renaming the protocol and relay names is not mandatory. I only did it to
make it clear what I’m doing.</p><h2 id="load-balancing--failover">Load balancing &amp; Failover</h2><p>relayd(8) allows to distribute incoming requests to several backend
servers. Depending on its configuration, you can balance the load on
those servers and/or keep the service up and running since you only
encounted n-1 failure(s).</p><pre tabindex="0"><code data-lang="pf">ext_addr="203.0.113.1"
whost1="192.0.2.11"
whost2="192.0.2.12"
whost3="192.0.2.13"
interval 5
table &lt;webhosts&gt; { $whost1, $whost2, $whost3 }

http protocol wwwtls {
   tls keypair relayd.example
}

relay wwwtls {
    listen on $ext_addr port 443 tls
    protocol wwwtls
    # l/b using source-IP, check HTTP return code
    forward to &lt;webhosts&gt; port 80  \
      mode loadbalance             \
      check "/health-check" code 200
}
</code></pre><p>In this example, a TABLE has been created that references all the backend
servers - those that will receive the HTTP requests.</p><p>There are many scheduling algorithms (aka MODE) available. Check the man
page for more details. The default is using roundrobin and no health
checks. Here, we’re using the loadbalance algorythm and return code check.</p><h2 id="fallback-servers---automatic-switch">Fallback server(s) - automatic switch</h2><p>There are cases when you want to implement automatic reaction on
server(s) outage events. You may want to switch the whole service to a
secondary server pool. You may display an incident status page
rather that an HTTP/500 error page. You should probably display a static
“be back soon” page while performing maintenance.</p><p>This is what the fallback feature can be used for.</p><pre tabindex="0"><code data-lang="pf">ext_addr="203.0.113.1"
whost1="192.0.2.11"
whost2="192.0.2.12"
whost3="192.0.2.13"
interval 5
table &lt;webhosts&gt; { $whost1, $whost2 }
table &lt;fallback&gt; { $whost3 }

http protocol wwwtls {
   tls keypair relayd.example
}

relay wwwtls {
  listen on $ext_addr port 443 tls
  protocol wwwtls

  # l/b using round-robin, check HTTP return code
  forward to &lt;webhosts&gt; port 80 mode roundrobin \
    check http "/" code 200
  # switch service if all previous checks fail
  forward to &lt;fallback&gt; port 80
}
</code></pre><p>Two TABLEs have been defined. One for the primary server(s). One for the
fallback server(s). Then, everything happens in the relay section. The
first forward directive load-balances the HTTP requests to the primary
servers pool. The second forward directive acts as the fallback target.
It will be triggered as soon as no servers from the primary pool are
known to be working.</p><h2 id="fallback-servers---manual-switch">Fallback server(s) - manual switch</h2><p>In a use-case where you prefer managed operations on server(s) outage,
you may configure a non-automatic switch. This mostly apply to Business
Continuity Plan where the secondary servers pool is remote or mutualized
or resources limited etc.</p><pre tabindex="0"><code data-lang="pf">ext_addr="203.0.113.1"
whost1="192.0.2.11"
whost2="192.0.2.12"
whost3="192.0.2.13"
whost4="192.0.2.14"
interval 5
table &lt;webhosts&gt;         { $whost1, $whost2 }
table &lt;fallback&gt; disable { $whost3, $whost4 }

http protocol wwwtls {
   tls keypair relayd.example
}

relay wwwtls {
  listen on $ext_addr port 443 tls
  protocol wwwtls

  # l/b using source-IP, check HTTP return code
  forward to &lt;webhosts&gt; port 80 mode loadbalance \
    check http "/" code 200
  # l/b using round-robin, check HTTP return code
  forward to &lt;fallback&gt; port 80 mode roundrobin \
    check http "/" code 200
}
</code></pre><p>The main difference with the previous configuration is the <code>disable</code>
property of the fallback table. This implies that it won’t be used by
relayd(8) unless being told to.</p><h2 id="initial-expected-state">Initial expected state</h2><p>Usage of the <code>relayctl</code> command confirms that the primary servers pool
is working as expected.</p><pre tabindex="0"><code># relayctl show summary
Id      Type            Name                            Avlblty Status
1       relay           wwwtls                                  active
1       table           webhosts:80                             active (2 hosts)
1       host            192.0.2.11                      100.00% up
2       host            192.0.2.12                      100.00% up
2       table           fallback:80                             disabled
</code></pre><ul><li>Primary hosts are up and running.</li><li>Secondary hosts are disabled.</li></ul><p>The service is UP.</p><h2 id="primary-servers-go-down">Primary servers go down</h2><p>On a clear service breakdown, <code>relayctl</code> will indicate that the primary
hosts are down.</p><pre tabindex="0"><code># relayctl show summary
Id      Type            Name                            Avlblty Status
1       relay           wwwtls                                  active
1       table           webhosts:80                             empty
1       host            192.0.2.11                      95.56%  down
2       host            192.0.2.12                      95.56%  down
2       table           fallback:80                             disabled
</code></pre><ul><li>Primary hosts are down.</li><li>Secondary hosts are disabled.</li></ul><p>The service is DOWN. Nothing happens as relayd(8) was told to start the
fallback table disabled.</p><h2 id="switch-to-the-secondary-servers-pool">Switch to the secondary servers pool</h2><p><code>relayctl</code> is used to enable the disabled fallback. This happens
without the need of restarting relayd.</p><pre tabindex="0"><code># relayctl table enable 2
command succeeded

# relayctl show summary
Id      Type            Name                            Avlblty Status
1       relay           wwwtls                                  active
1       table           webhosts:80                             empty
1       host            192.0.2.11                      76.79%  down
2       host            192.0.2.12                      76.79%  down
2       table           fallback:80                             active (2 hosts)
3       host            192.0.2.13                      100.00% up
4       host            192.0.2.14                      100.00% up
</code></pre><ul><li>Primary hosts are down.</li><li>Secondary hosts are enabled.</li></ul><p>The service is UP.</p><p>Note that failback shall happen as soon as relayd detects a Primary host
up. If this is not something you want to happen, use <code>relayctl table disable 1</code> to prevent such an automatic failback.</p><h2 id="relaying-multiple-fqdns">Relaying multiple FQDNs</h2><p>What if you want to expose multiple hostnames using a single IP?<br>You can do Apache Virtual Hosts or nginx server blocks. Or you can:</p><pre tabindex="0"><code data-lang="pf">(...)
table &lt;blog&gt;  { $whost1, $whost2 }
table &lt;cloud&gt; { $whost3 }

http protocol wwwtls {
  tls keypair blog.example
  tls keypair nextcloud.example

  block
  pass request header "Host" value "blog.example"  \
    forward to &lt;blog&gt;
  pass request header "Host" value "cloud.example" \
    forward to &lt;cloud&gt;
}

relay wwwtls {
  listen on $ext_addr port 443 tls
  protocol wwwtls
  forward to &lt;blog&gt;  port 80 mode roundrobin \
    check http "/" code 200
  forward to &lt;cloud&gt; port 80
}
</code></pre><p>This configuration example checks every HTTP requests’ header and route
them to the proper backend server depending on the value of the “Host”
header. The backend servers are referenced in tables.</p><p>Using multiple “keypair” directives to reference the HTTPS certificates
enables the TLS Server Name Indication (SNI) feature of relayd(8).</p><h2 id="relaying-multiple-pathnames">Relaying multiple pathnames</h2><p>Apache has location directives. nginx has location blocks. To design
reaction rules (allow, deny, forward…) depending on URL paths,
relayd(8) can use FILTER RULES based on the “path” keyword.</p><pre tabindex="0"><code data-lang="pf">(...)
table &lt;blog&gt;  { $whost1, $whost2 }
table &lt;cloud&gt; { $whost3 }

http protocol wwwtls {
  tls keypair relayd.example

  block quick path "/cgi-bin*"
  block quick path "/wp-admin*"
  pass  quick path "/nextcloud/*" forward to &lt;cloud&gt;
  pass  request                   forward to &lt;blog&gt;
}

relay wwwtls {
  listen on $ext_addr port 443 tls
  protocol wwwtls

  forward to &lt;blog&gt; port 80 mode roundrobin \
    check http "/" code 200
  forward to &lt;cloud&gt; port 80
}
</code></pre><p>This configuration blocks any attempt to access paths that look like
<code>/cgi-bin</code> and <code>/wp-admin</code>. It also routes any URL matching
<code>https://relayd.example/nextcloud/</code> to the “cloud” servers pool. Any
other URL will be routed to the “blog” table.</p><p>relayd(8) can add, remove or modify HTTP header on the fly. This allows
solving various kinds of issues with exposed Web services.</p><h2 id="unencrypted-connection">Unencrypted connection</h2><p>There are software like Baikal, Mastodon or SearxNG that refuse to serve
unencrypted content. If you still want to run them using plain text HTTP
on the backend server and feel confident about using relayd(8) as an SSL
terminator, you shall add an HTTP header to the requests reaching the backend
HTTP server.</p><pre tabindex="0"><code data-lang="pf">(...)
http protocol wwwtls {
  tls keypair blog.example
  tls keypair nextcloud.example

  block
  pass request header "Host" value "blog.example"  forward to &lt;blog&gt;
  pass request header "Host" value "cloud.example" forward to &lt;cloud&gt;

  match request header set "X-Forwarded-Proto" value "https"
}
(...)
</code></pre><p>In this particular case, the <code>X-Forwarded-Proto</code> is set to “https” and
passed to the backend server to confirm that the communication is
secured using TLS.</p><p>From time to time, you discover that Web services fill their HTTP
replies with too many information. Too many meaning not mandatory to
provide a functionnal user experience while still leaking sensible
information to the external world.</p><pre tabindex="0"><code data-lang="pf">(...)
http protocol wwwtls {
  tls keypair relayd.example

  pass  quick path "/nextcloud/*" forward to &lt;cloud&gt;
  pass  request                   forward to &lt;blog&gt;

  match response header remove "X-Powered-By"
  match response header set "Server" value "Microsoft-IIS/8.5"
}
(...)
</code></pre><p>This configuration removes any <code>X-Powered-By</code> information from every HTTP
replies. It also sets the <code>Server</code> HTTP header to some specific value that
can be used to fool script kiddies ; or to deal with faulty Web clients
that expects a specific value.</p><h2 id="improve-users-security-and-privacy">Improve users security and privacy</h2><p>Some software don’t really bother about security and privacy. Sometimes, it’s
just that they expect you to use an htaccess-compatible Web server to provide
a couple of HTTP headers that can help protecting the user.</p><pre tabindex="0"><code data-lang="pf">(...)
http protocol wwwtls {
  tls keypair relayd.example

  pass  quick path "/nextcloud/*" forward to &lt;cloud&gt;
  pass  request                   forward to &lt;blog&gt;

  match response header set "X-XSS-Protection"       value "1; mode=block"
  match response header set "X-Content-Type-Options" value "nosniff"
  match response header set "Permissions-Policy"     value "accelerometer=(),
ambient-light-sensor=(),autoplay=(),camera=(),encrypted-media=(),
focus-without-user-activation=(),geolocation=(),gyroscope=(),
magnetometer=(),microphone=(),midi=(),payment=(),picture-in-picture=(),
speaker=(),sync-xhr=(),usb=(),vr=()"
}
(...)
</code></pre><p>This example only shows a subset of HTTP headers that can be set to
improve users privacy and protection. Check your Web application using
tools like <a href="https://observatory.mozilla.org/" target="_blank" rel="external nofollow">Mozilla Observatory</a>
to
get a better overview of what should / could be achieved on your server.</p><h2 id="log-management">Log management</h2><p>The default relayd(8) log configuration doesn’t suit me well. Traces
appear in several log files and are not detailed enough to my linkings
when it comes to debugging issues.</p><h2 id="one-for-log-and-log-for-one">One for log and log for one</h2><p>To have relayd(8) log in its own dedicated log file, I’d rather tune
syslogd(8):</p><pre tabindex="0"><code># touch /var/log/relayd

# vi /etc/syslog.conf
!!relayd
*.* /var/log/relayd
!*
(...)

# vi /etc/newsyslog.conf
(...)
/var/log/relayd root:_relayd 640 7 * $D0 ZB

# rcctl restart syslogd
</code></pre><h2 id="logging-options">Logging options</h2><p>Some matching FILTER RULES can be defined to have more information
appear in the log files.</p><pre tabindex="0"><code data-lang="pf">http protocol wwwtls {
  tls keypair relayd.example

  match url log
  match header log "Host"
  match header log "User-Agent"
  match response header log "Content-Type"
  match response header log "Content-Length"

  pass  quick path "/nextcloud/*" forward to &lt;cloud&gt;
  pass  request                   forward to &lt;blog&gt;
}
</code></pre><p>This particular example provides HTTP header information in the
relayd(8) logs.</p><pre tabindex="0"><code>Sep 17 14:35:12 ebsdc relayd[34137]: relay wwwtls, session 1 (1 active), 0, 
    203.0.113.1 -&gt; 127.0.0.1:80, done, 
    [blog.example/about] [Host: blog.example] [User-Agent: curl/8.2.0] 
    GET -&gt; 127.0.0.1:80 {Content-Type: text/html} {Content-Length: 41};
</code></pre><p>Any HTTP header can be matched and rendered in the logs. Select yours.</p><h2 id="conditional-filtering">Conditional filtering</h2><p>Using TAGS and INCLUDES, relayd(8) can perform different computation and
actions depending on wether or not conditions evaluate to true or false.
Here’s an example of some slightly complex conditional filtering that
can be designed in relayd(8).</p><p><a target="_blank" href="https://www.tumfatig.net/images/2023/relayd-cf.png"><img src="https://www.tumfatig.net/images/2023/relayd-cf.png" alt="Using relayd(8) as a reverse-proxy"></a></p><h2 id="filtering-branched-on-fqdn-12">Filtering branched on FQDN #(1,2)</h2><p>In a dedicated configuration file, a TAG is set if the “Host” HTTP
header of the requests matches one of the defined value. Then for each
TAGGED connections, relayd(8) will apply additionnal logging and improve
users security and privacy.</p><pre tabindex="0"><code data-lang="pf"># cat /etc/relayd-ssg.conf

# Mark using hostnames
match request header "Host" value "www.example"     tag "ssg"
match request header "Host" value "blog.example"    tag "ssg"

# Apply additionnal logging
match header log "Host"       tagged "ssg"
match header log "User-Agent" tagged "ssg"
match url    log              tagged "ssg"

# Improve Security and Privacy
match response tagged "ssg" header set \
  "Strict-Transport-Security" value "max-age=31536000; includeSubDomains; preload"
match response tagged "ssg" header set \
  "X-XSS-Protection" value "1; mode=block"
match response tagged "ssg" header set \
  "X-Content-Type-Options" value "nosniff"
</code></pre><h2 id="filtering-branched-on-fqdn-3">Filtering branched on FQDN #3</h2><p>In a dedicated configuration file, a TAG is set if the “Host” HTTP
header of the requests matches the defined value. Then for each TAGGED
connections, a check is done on the “User-Agent” HTTP header and a block
happens for the referenced values. Another check is done, based on the
URL and the source IP, to ensure only trusted computer can acces an
adminstrative URL. In the end, any acceptable HTTP session will have the
“Server” HTTP header removed from the HTTP reply.</p><pre tabindex="0"><code data-lang="pf"># cat /etc/relayd-nextcloud.conf

# Mark using hostname
match request header "Host" value "cloud.example"   tag "nextcloud"

# Block User Agents
block request quick tagged "nextcloud" header "User-Agent" value "Googlebot/*"
block request quick tagged "nextcloud" header "User-Agent" value "YandexBot/*"

# Only allow "admin" path from specific subnet
match request                   url "cloud.example/admin/" tag "forbidden"
match request from 192.0.2.0/24 url "cloud.example/admin/" tag "nextcloud"

# Don't let version leak via HTTP header
match response tagged "nextcloud" header remove "Server"
</code></pre><h2 id="filtering-branched-on-fqdn-4">Filtering branched on FQDN #4</h2><p>In a dedicated configuration file, a TAG is set if some trusted computer
try to access an allowed FQDN. Any TAGGED connections will have its path
checked for some regex and tagged if matched. Those connections will
have an HTTP header set in their reply.</p><pre tabindex="0"><code data-lang="pf"># cat /etc/relayd-grafana.conf

# Mark using client source IP and path
match request from 192.0.2.0/24    url "metrics.example/" tag "grafana"
match request from 198.51.100.8/32 url "metrics.example/" tag "grafana"

# Overwrite caching
match request tagged "grafana" path "*.css" tag "g-cache"
match request tagged "grafana" path "*.js"  tag "g-cache"
match request tagged "grafana" path "*.png" tag "g-cache"

match response tagged "g-cache" header set "Cache-Control" value "max-age=86400"
</code></pre><h2 id="connecting-the-branches">Connecting the branches</h2><p>In the main relayd(8) configuration file, the dedicated config files are
included so that tagging happens, or not. The routing to the proper
backend servers will happen for every TAGGED connections. The <code>block</code>
directive will drop any connection that has not been matched by the
filtering definition.</p><pre tabindex="0"><code data-lang="pf"># cat /etc/relayd.conf

table &lt;blog&gt;    { $whost1, $whost2 }
table &lt;cloud&gt;   { $whost3 }
table &lt;grafana&gt; { $whost4 }

http protocol wwwtls {
  tls keypair www.example
  tls keypair cloud.example
  tls keypair metrics.example

  block

  include "/etc/relayd-ssg.conf"
  include "/etc/relayd-nextcloud.conf"
  include "/etc/relayd-grafana.conf"

  pass request tagged "ssg"       forward to &lt;blog&gt;
  pass request tagged "nextcloud" forward to &lt;cloud&gt;
  pass request tagged "grafana"   forward to &lt;grafana&gt;
  pass request tagged "g-cache"   forward to &lt;grafana&gt;
}
</code></pre><h2 id="one-more-thing">One more thing</h2><p>Remarks and answers given during the live session:</p><ul><li>Beware that pf(4) and relayd(8) TABLES are not the same things although they
share the same name.</li><li>PROTOCOL and RELAY names can be any string you like. I had some weird
behaviour when using underscores or hyphens. I don’t remember which
exactly. So I just avoid them. They just have to match with one
another.</li><li>I have no load metrics. I use relayd(8) on personal projects and have
not faced any specific issues. But if you expect lots of connections,
you may need to increase the <code>prefork</code> value and/or tune the <code>tcp</code>
options.</li><li>In real Enterprise World, you may combine relayd(8) and carp(4) to
achieve a better SLA.</li></ul><p>The original <a href="https://www.tumfatig.net/files/2023/eurobsdcon2023-relayd.pdf" target="_blank" rel="external nofollow">slides are available
here</a>
. Because OpenBSD and
because fun, you can get the <a href="https://www.tumfatig.net/files/2023/eurobsdcon2023-relayd-sketch.pdf" target="_blank" rel="external nofollow">same slides rendered in Comic font</a>
.</p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kagi finally let me lay Google Search to rest (206 pts)]]></title>
            <link>https://dannb.org/blog/2023/how-kagi-beats-google/</link>
            <guid>37852133</guid>
            <pubDate>Thu, 12 Oct 2023 00:34:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dannb.org/blog/2023/how-kagi-beats-google/">https://dannb.org/blog/2023/how-kagi-beats-google/</a>, See on <a href="https://news.ycombinator.com/item?id=37852133">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img src="https://dannb.org/images/blog/2023/09/kagi-search-logo-dog.jpg" alt="Kagi search dog and logo"></p><p>I’m a <a href="https://kagi.com/">Kagi</a> convert, having switched from Google Search in July of 2022 and never looking back. I’m also a vocal supporter of Kagi, frequently mentioning it in <a href="https://dannberg.substack.com/">my newsletter</a> and encouraging people to give Kagi a try whenever the opportunity arises.</p><p>For those unfamiliar, Kagi is a search engine with a novel<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> business model: end users pay for a service. Instead of monetizing users through advertising and affiliate marketing (like every other search engine), Kagi charges a monthly fee.</p><p>I’m both a user and vocal supporter of Kagi, and I also have big <em>thoughts and opinions</em>. Both on the state of search today, where it’s going in the future, and why it’s important to support companies like Kagi. Additionally, I was blown away by the quality of Kagi’s search results, which is what first encouraged me to make the switch, and I wanted to dive into the details in case anyone reading is on the cusp of trying this new search engine.</p><p>This post is not an ad; I’m just a happy customer. And I’ll gladly pay for products I like, and actively hope others support these products, too, so that the companies that make them can survive.</p><p>With that said, let’s kick things off with a little background on <em>Internet Search</em> as it exists today.</p><h2 id="wow-google-search-sucks">Wow, Google Search <em>sucks</em></h2><p>It may be easy to miss, but <a href="https://dkb.blog/p/google-search-is-dying">Google Search is dying</a>. Search results are dominated by ads SEO-optimized junk. More and more, people append words like “reddit” to the end of their search to try and bubble up any semblance of a useful response.</p><p>According to the author above blog post (with whom I agree): “serving ads creates misaligned incentives for search engines.” It’s impossible to both provide the best search results <em>and</em> try to optimize for the highest amount of ad-clicks. And if you’re a public company with an ad-based business model, you are <em>legally required</em> to optimize for the latter. Ads <em>inherently</em> create misaligned incentives.</p><p>But Google continues to dominate as the most-used search engine worldwide. I think part of this has to do with the fact that it’s so ingrained into people’s lives that its flaws go unnoticed or overlooked. People just amend their behavior (like adding “reddit” to the end of a search, or immediately scrolling through pages of SEO-junk to get to a recipe) to compensate for Google’s shortcomings.</p><p>Google reigns supreme, too, in no small part because historically all its competitors all suck even more. Let’s take a quick look at the mainstream alternatives. As of August 2023, <a href="https://gs.statcounter.com/search-engine-market-share/desktop/united-states-of-america">US desktop search engine market share</a> is as follows:</p><ol><li>Google (78.96%)</li><li>Bing (14.42%)</li><li>Yahoo (3.89%)</li><li>DuckDuckGo (2.11%)</li></ol><p>That’s <em>rough</em>. If a user gets fed up with Google Search’s flaws and tries one of these big competitors as their default search engine, it’s only a matter of time before they come crawling back to Google.</p><p>This was best tested en masse in mid-2020 when <a href="https://www.forbes.com/sites/johnkoetsier/2020/06/08/apple-could-cost-google-15-billion-by-buying-duckduckgo-analyst-says/?sh=4c218fb21920">rumors were swirling</a> of Apple purchasing DuckDuckGo. I, like many others, saw the news and figured that maybe DuckDuckGo was possibly more of a competitor to Google than I originally thought. I made it my default search engine.</p><p>That only lasted a few months before I switched back to Google Search. I valued the privacy aspect of DuckDuckGo but the search results were straight up <em>lacking</em>. A vast majority of the time, the article or piece of information I was searching for was completely missing from the DuckDuckGo results. Other times, it was buried in the muck. I’d then switch back to Google search and find the result I wanted almost immediately. It wasn’t long before I switched my default back to Google to simply save time and effort.</p><p>I’ve experimented with Bing and Yahoo, but never felt inspired to even attempt either as my default search engine. As I result, I felt trapped by Google Search — painfully aware of its flaws but without a reasonable alternative.</p><p>I first heard about Kagi in <a href="https://twitter.com/helvetica/status/1552140803866230785">a tweet from indie gamemaker Zach Gage</a>, and the value proposition was instantly appealing: <em>search as a service I can pay for</em>. This solves the misaligned incentives that hamstring Google (and other search engines), which in <em>theory</em> should produce a better product. But historically, I had never used a search engine that matches in quality, let alone exceeds, even the low bar that Google sets.</p><p>I want to say<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> that I experimented with Kagi on an informal basis for maybe a week before feeling confident enough to set it as my default search engine. Initially, I’d frequently do side-by-side searches on both Kagi and Google to compare results, but stopped after another week or two. Kagi has been my daily driver workhorse search engine, on both my personal and work computer, as well as my smartphone, ever since. I’ve not looked back once.</p><h2 id="why-kagi-is-better">Why Kagi is better</h2><p>I don’t think side-by-side comparisons of search results from different providers is the best way to qualitatively compare quality (although they <em>are</em> <a href="https://twitter.com/helvetica/status/1555182325239091200">sometimes compelling</a>). This is because most results can look relatively similar at first blush, and nitpicking the small differences can come off overly critical and exaggerated.</p><p>Instead of providing screenshots from different search providers for different search terms, and delving into the differences and how they impact search quality, I’m instead going to talk about <em>how</em> I think about search, and provide you a foundation to think about your own search experiences. Then, I encourage you to give Kagi a try (and also test a few other Google Search alternatives) and come to your own conclusions.</p><h3 id="framework-for-thinking-about-search">Framework for thinking about search</h3><p>Almost every search engine you use will eventually serve a satisfying answer. Instead, the quality of a search engine depends on how <em>long it takes</em> to get to this end state, <em>how complicated the journey</em> to this end state, and the <em>quality of user experience</em> (UX) of the whole process.</p><p>Most online search queries fall into one of the following categories:</p><ol><li>Instructions (ie coding, recipe, how to)</li><li>Event (ie past or current news, )</li><li>Fact (ie movie run time, celebrity age)</li><li>Solution (ie product recommendation)</li><li>Exploration (ie research, education)</li></ol><p>A search has succeeded once you find a piece of information or reference that satisfies the original query. The more steps it takes to get to that final success state, the worse the search engine’s quality.</p><p>These steps include modifying the original search query (ie adding extra keywords or search operators), clicking through multiple results and comparing information, browsing through multiple pages of results.</p><p>Searches can be undertaken with either a specific <em>success state</em> in mind (ie How old is Tom Cruise? How do I apply a gaussian blur in Figma?) or have a non-specific success state (What should I do on my vacation in Istanbul?).</p><h3 id="measuring-the-quality-of-search-engines">Measuring the quality of search engines</h3><p>In addition to different search categories, there are two main contexts for search: ad hoc or relaxed.</p><p>Most searches are ad hoc — you will be performing some work or a task and hit a knowledge-based road block. In these cases, you want to be able to immediately execute a search, quickly find a satisfying result, and return to your previous context.</p><p>Alternatively (and less frequently) searches can be relaxed, which is to say exploratory and meandering. You might be researching a vacation to Istanbul, or coming up with activities for kids on rainy days. The goal is to look at several different websites and sources, collect data, and process it at a leisurely basis. There is no right or wrong answer, per say. Your goal instead is to have a greater understanding of a topic based on multiple sources.</p><p>When attempting to kick the tires of a search engine, often times we’ll input a more relaxed search query and attempt to measure the quality of the engine by the results. Instead, it’s really ad hoc searches where the differences in quality are most apparent.</p><p>This is why setting a new search engine as your default is really the best way to measure its quality. It’s those times when you’re working on something else and need a quick answer from a search engine when you’ll really be able to tell which results are up-to-snuff and which are lacking.</p><h2 id="kagi-has-cool-features-too">Kagi has cool features, too</h2><p>In addition to solid search results, Kagi also has several features that are just icing on the cake. Some of my favorites include:</p><h3 id="website-ranking-adjustment">Website Ranking Adjustment</h3><p>Kagi search results are already good, but users have powerful options to tweak and adjust to fit their needs. This takes the form of <a href="https://blog.kagi.com/kagi-features">blocking or boosting certain domains</a>. On the off chance that a Kagi search returns some SEO-garbage site, you can de-prioritize that domain for future searches. Likewise, boosting trusted sources and make those results rank higher for you.</p><p>This is <em>really</em> powerful. By subtly tweaking and adjusting my website ranking preferences over the past year+, I can almost guarantee that the search result I’m hoping for is near the very top of my results.</p><h3 id="lenses">Lenses</h3><p>I recently started using <a href="https://help.kagi.com/kagi/features/lenses.html">Lenses</a> more frequently, and it has helped me refine my searches quickly and reliably, with as little extra work as possible.</p><p>Essentially, Lenses allow users to pre-set search parameters — narrowing results by domain(s), region(s), keyword(s), date(s), and more. With Google, you can do this with <a href="https://ahrefs.com/blog/google-advanced-search-operators/">search operators</a> (which also exist on Kagi), but lenses allow you to pre-set frequently-used operators and thus easily narrow your search to various online worlds. Best of all, lenses are <em>sharable</em>!</p><p>The two I use most frequently are a <a href="https://kagi.com/lenses/IRpSaJ5igCVRuEF67ka7CkH7pldTolZz">Reddit lens</a> and a <a href="https://kagi.com/lenses/1aDMUsFO3QtaU5M5rE3ho2tnC750QsAH">Hacker News lens</a>. Both are incredibly simple (effectively the same as adding <code>site:reddit.com</code> or <code>site:news.ycombinator.com</code> after a search term).</p><p>Additionally, I’ve found several of the default lenses to be useful and interesting, especially PDFs, Forums, and Small Web.</p><h3 id="universal-summarizer">Universal Summarizer</h3><p>I also find myself using the <a href="https://blog.kagi.com/universal-summarizer">Universal Summarizer</a> feature <em>all the time</em>. Often, an article or blog post will look interesting but I don’t have the time or mental capacity to read it immediately. I use Readwise’s <a href="https://readwise.io/read">Reader</a> as a read-it-later, but my reading queue there is long and grows faster than I read.</p><p>If I’m not sure if the article is worth saving to read later, I’ll use Kagi’s Universal Summarizer to get a gist of the article. This will either convince me to save it, or at least allow me to make peace with releasing it back into the wild unconsumed.</p><p>But one of the coolest parts of Kagi’s Universal Summarizer is that it works on <em>YouTube videos</em> and <em>podcast episodes</em>. Feed it a YouTube URL or a podcast mp3 and within seconds you’ll get a detailed, high-quality summary. I know this is available through other third-party services, but Kagi makes it so easy when you’re fully integrated that I use it way more.</p><h3 id="assistant-closed-beta">Assistant (Closed Beta)</h3><p>Kagi is continuing to grow in the direction of AI search augmentation with tools like <a href="https://help.kagi.com/kagi/ai/assistant.html">Assistant</a>. Currently in closed beta, Assistant is a research tool backed by Kagi Search and large language models.</p><p>This is a alternative to the <a href="https://www.reuters.com/technology/openai-says-chatgpt-can-now-browse-internet-2023-09-27/">recent announcement</a> that ChatGPT would have real-time access to internet search results (as opposed to the dataset of large language models being limited by the training data date cutoff). This is only available to $20/mo ChatGPT Plus subscribers.</p><p>This functionality isn’t super useful to me — <a href="https://www.typingmind.com/">TypingMind</a> connected to my OpenAI API key is perfectly sufficient for 99% of my AI queries. However, this is a cool bonus feature for premium Kagi users who don’t want to <em>additionally</em> pay OpenAI $20/mo and want access to multiple different LLMs for more robust answers.</p><h3 id="orion-browser">Orion Browser</h3><p>I’d be remiss if I didn’t at least mention Kagi’s web browser <a href="https://browser.kagi.com/">Orion</a>. I haven’t put in the work to switch default browsers (which feels like a more Herculean task than switching search engines) but Orion seems like a compelling choice. Both speed and memory usage stats are compelling, and it’s compatible with both <a href="https://help.kagi.com/orion/why-orion/orion-vs-safari.html">Chrome and Firefox extensions</a>, giving users “users access to the largest extensions ecosystem in the world.”</p><h2 id="the-not-quite-there">The not-quite-there</h2><h3 id="maps">Maps</h3><p>Kagi does have <a href="https://kagi.com/maps">Maps</a> functionality, but I find it’s still lacking compared to Google Maps. As a result, I still use Google Maps for both searching points-of-interest and getting directions. I don’t blame them because mapping is hard — there are still iPhone users who refuse to use the now-superior Apple Maps, instead opting for Google Maps, due to a botched launch <em>eleven years ago</em>. To be fair, Kagi is not claiming feature parity with competitors, but it’ll still be a while before I personally switch from Google Maps to Kagi Maps.</p><h3 id="deep-integration-is-complex">Deep integration is complex</h3><p>This part isn’t Kagi’s fault — to the contrary, I feel like Kagi has made deep integration as easy as it possibly can given the constraints.</p><p>But search engines are so deeply ingrained into different parts of our lives that it becomes complex for one of the new kids on the block to become as deeply embedded itself.</p><p>For example, setting Kagi as your default desktop search for Chromium, Firefox, or Safari browsers requires a <a href="https://help.kagi.com/kagi/getting-started/setting-default.html">browser extension</a> and post-installation settings changes. Kagi makes it easy, as installs go, but it’s definitely a more advanced process than, say, switching from Google Search to DuckDuckGo.</p><p>Likewise, using Kagi in a Private Browsing window requires a Private Session Link, a URL that can be found in your Kagi settings, which needs to be entered into the plugin. It’s easy when following instructions, but otherwise may be unintuitive for those who like to plow ahead without reading documentation.</p><p>Setting Kagi as your default search engine for Safari on iOS also involves a mobile browser plugin. I got this to work immediately, but David Pierce at <em>The Verge</em> mentioned that <a href="https://www.theverge.com/23896415/kagi-search-google-meta-quest-3-chatgpt-macos-sonoma-installer-newsletter">he’s had trouble doing the same</a>. I guess YMMV?</p><h2 id="should-you-switch">Should you switch?</h2><p>A paid search engine is definitely a luxury item that’s not for everyone. Free search democratizes the internet, and will always be a necessary. But I’m happy that there’s now a viable alternative that has a more traditional business-to-consumer monetization structure.</p><p>If the value proposition of Kagi is compelling, I recommend giving it a try as your default search engine. The <a href="https://kagi.com/pricing">100 free searches</a> is definitely enough to give it a spin and see how the quality stacks up in your opinion. Then, if you have the means and believe in it philosophically, you may be inspired to switch.</p><p>All I know is that I’m a happy user, and there must be more people out there like me just waiting to discover a solution like Kagi.</p><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>It’s novel — unthinkable! — for search engines, but is really the oldest business model in the world. <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li><li id="fn:2" role="doc-endnote"><p>Forgive the fuzzy language around these details. It was over a year ago, and I wasn’t taking close notes on what I thought would be a short-lived experiment. <a href="#fnref:2" role="doc-backlink">↩︎</a></p></li></ol></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AVX10/128 is a silly idea (127 pts)]]></title>
            <link>https://chipsandcheese.com/2023/10/11/avx10-128-is-a-silly-idea-and-should-be-completely-removed-from-the-specification/</link>
            <guid>37851029</guid>
            <pubDate>Wed, 11 Oct 2023 22:17:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/2023/10/11/avx10-128-is-a-silly-idea-and-should-be-completely-removed-from-the-specification/">https://chipsandcheese.com/2023/10/11/avx10-128-is-a-silly-idea-and-should-be-completely-removed-from-the-specification/</a>, See on <a href="https://news.ycombinator.com/item?id=37851029">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2><span data-contrast="none">Intro and lots of context&nbsp;&nbsp;</span></h2>
<p><span data-contrast="none">Intel recently unveiled the AVX10 specification as means for consolidating the vast majority of AVX-512 extensions into a single, easy-to-target specification. It </span>ai<span data-contrast="none">ms to solve a few issues, among which is the startling array of configurations, targets, and spaghetti of AVX-512 implementations with disjointed instructions support. Lest we forget, it also primarily serves as means of bringing together all the beloved AVX-512 goodies into smaller implementations, targeted at consumer, micro-edge and embedded that can’t or won’t have the 32 512-bit registers required by AVX-512.&nbsp;</span></p>
<p><span data-contrast="none">I’ve publicly expressed my enthusiasm for the specification since the initial publication. Relatedly, I’m giving a talk for the Easy Build/HPC communities under the title “AVX10 for HPC: a reasonable solution to the 7 levels of AVX-512 folly.” This article was originally slated to be a part of the talk, but I’m writing it out instead for the sake of reference (and because I’m already struggling to get the talk down to 90 minutes, let alone the 60 I have).</span> For those interested in attending, you can find the link at the end of the article.</p>
<h2><span data-contrast="none">AVX10, what is it?</span></h2>
<p><span data-contrast="none">To begin, let’s break down AVX10.N/M: AVX10 is the new “foundational” SIMD/vector instruction set for x86_64. The “.N” denotes the version of AVX10 as aa <span data-contrast="none">version modifier</span>, allowing incremental updates. It is important to note, if you support “AVX10.N+3,” you must support all of AVX10.N, N+1 and N+2. In simpler words, users are guaranteed supersets of previous instruction sets.</span></p>
<div>
<figure><img data-attachment-id="22566" data-permalink="https://chipsandcheese.com/2023/10/11/avx10-128-is-a-silly-idea-and-should-be-completely-removed-from-the-specification/screen-shot-2023-10-07-at-5-35-38-pm/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.35.38-PM.png?fit=416%2C1116&amp;ssl=1" data-orig-size="416,1116" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2023-10-07 at 5.35.38 PM" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.35.38-PM.png?fit=416%2C1116&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.35.38-PM.png?fit=416%2C1116&amp;ssl=1" decoding="async" width="416" height="1116" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.35.38-PM.png?resize=416%2C1116&amp;ssl=1" alt="" data-recalc-dims="1"></figure></div>
<p><span data-contrast="none">What does the “/M” mean? It’s a reference to vector register implementation size of a given AVX10.N version. Specifically, it may be 512-bit, 256-bit, or the topic of this article, 128-bit wide. </span></p>
<p><span data-contrast="none">128-bit registers, a.k.a XMM registers, were introduced with SSE(1) for the 32-bit only</span> Pentium 3 in 1999. <span data-contrast="none">256-bit registers were introduced with AVX1, and first implemented in the Sandy Bridge micro architecture in 2011. 512-bit registers were specified by AVX-512 and released around 2016 with Xeon Phi, but were</span>n’<span data-contrast="none">t generally available until 2017 with the release of Skylake-X.</span></p>
<p>To give an idea of what each of those looks like, here’s a comparison of the “add packed single-precision floating-point values (ADDPS)” instruction, courtesy of the <a href="https://www.officedaytime.com/tips/simd.html">officedaytime.com SIMD instruction visualizer</a>.</p>
<p><a href="http://https//www.officedaytime.com/simd512e/simdimg/binop.php?f=addps"><img data-attachment-id="22564" data-permalink="https://chipsandcheese.com/2023/10/11/avx10-128-is-a-silly-idea-and-should-be-completely-removed-from-the-specification/screen-shot-2023-10-07-at-5-26-36-pm/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.26.36-PM.png?fit=1616%2C1370&amp;ssl=1" data-orig-size="1616,1370" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2023-10-07 at 5.26.36 PM" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.26.36-PM.png?fit=1616%2C1370&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.26.36-PM.png?fit=688%2C583&amp;ssl=1" decoding="async" width="533" height="452" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.26.36-PM.png?resize=533%2C452&amp;ssl=1" alt="A screen shot visualizing the various versions of the x86 SIMD instruction &quot;addps&quot; showing it's evolution from using 128 bits of FP32 between 2 registers to its modern AVX512 implementation with 16 FP32s that can be sourced from 2 registers while the answer is stored in a 3rd" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.26.36-PM.png?w=1616&amp;ssl=1 1616w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.26.36-PM.png?resize=768%2C651&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.26.36-PM.png?resize=1536%2C1302&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.26.36-PM.png?resize=1200%2C1017&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.26.36-PM.png?resize=1600%2C1356&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.26.36-PM.png?resize=1320%2C1119&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-5.26.36-PM.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 533px) 100vw, 533px" data-recalc-dims="1"></a></p>
<h2><span data-contrast="none">A note on naming</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></h2>
<h3><span data-contrast="none">From AVX, to AVX2, to AVX-512, to AVX10</span></h3>
<p>After <span data-contrast="none">speaking with some of my favourite folks from intel, officially there aren’t “specific” reasons the name AVX10 was chosen as the successor to AVX512, beyond “marketing is going to market.”</span></p>
<p><span data-contrast="none">I have an alternative theory:</span></p>
<p>The <span data-contrast="none">AVX-512 specification we know today started out as a much smaller VEX-encoded ISA, known as AVX3 internally, as well as some early marketing materials. AVX3 was “relatively” boring as it only expanded registers, stayed VEX and provided a more exhaustive fused multiply add, similar to what AMD attempted with the FMA4 instructions. Taking that view to the past, if you set the AVX512f extensions to be “AVX3” and then exclude the Xeon Phi-only extensions, AVX512 had ~6 groups of extension worthy of being called discrete generations. <span data-contrast="none">Roughly</span></span>,<span data-contrast="none"> you can categorize them into:</span></p>
<ul>
<li><span data-contrast="none">AVX3 F, CD, ER, PF</span></li>
<li><span data-contrast="none">AVX4 VL, DQ, BW</span></li>
<li><span data-contrast="none">AVX5 IFMA, VBMI</span></li>
<li><span data-contrast="none">AVX6 BF1</span>6</li>
<li><span data-contrast="none">AVX7 VPOPCNTDQ VNNI, VBMI2, BITALG</span></li>
<li><span data-contrast="none">AVX8 VP2INTERSECT – deprecated</span></li>
<li><span data-contrast="none">AVX9 FP16</span></li>
<li><span data-contrast="none">AVX10 – the new “big one”</span></li>
</ul>
<h2><span data-contrast="none">Back to the good stuff</span></h2>
<p><span data-contrast="none">On the server and HPC side, expect all implementations to conform to the AVX10.N/512 specification. In other words, you should expect implementations to use AVX10.N with 512-bit vectors. This ensures that any existing AVX-512 code is fully supported, and <span data-contrast="none">continues</span> the legacy of backward compatibility for <span data-contrast="none">x86_64</span>.</span></p>
<p><span data-contrast="none"><span>On the consumer side, having a massive register file with 32 registers, each of which 512-bits is considered problematic and non-viable.* </span>However, as seen in <a href="https://chipsandcheese.com/2022/11/05/amds-zen-4-part-1-frontend-and-execution-engine/">Zen 4</a>, Alder Lake, <a href="https://chipsandcheese.com/2022/07/15/caching-energy-efficiency-data-mobile-and-avx-512/">Tiger Lake</a> and <a href="https://chipsandcheese.com/2022/03/23/via-part-4-a-deep-dive-into-centaurs-last-cpu-core-cns/">more</a>, it’s rather doable. The problem is that small, “efficiency” cores, notably Intel’s recent Gracemont (in <a href="https://chipsandcheese.com/2021/12/02/popping-the-hood-on-golden-cove/">Alder Lake</a> and Raptor Lake), and Crestmont (in upcoming Meteor Lake and Sierra Forest) microarchitectures, prefers to only implement 128-bit physical ALUs, relying on so-called “double pumping” (a more limited version of register pipelining from the Vector Processor days) to achieve AVX2 support. This way, they can implement the 16 x 256-bit registers of AVX2, but only need to implement 128-bit floating point and integer units. This comes with a cost: while you save on die space and power, some workloads may see significant performance regressions.</span></p>
<p><span data-contrast="none">Knowing this, the fine folks at Intel designing the AVX10 spec mandated that all implementations must have 32 registers, but said registers would only need to be as wide as the given “/M”.</span> This means <span data-contrast="none">AVX10/256</span> <span data-contrast="none">would have the same instruction capabilities as AVX10/512, but only require the 32 registers be 256-bits wide.</span></p>
<p><span data-contrast="none">For the most part, any code written for the older AVX-512 extensions that were limited to 256-bit registers should* run fine with only a recompile. This sort of code came about as a result of the <span data-contrast="none">much fabled “AVX-512 down-clocking” menace that would “punish” you for using the 512-bit part of AVX-512</span>. The good news is there’s a lot of code already designed for a “simplified” 256-bit version of AVX-512, which will either be ready or easy to migrate when the time comes.</span></p>
<p><span data-contrast="none"><em>*It’s slightly more complicated than the above, but you can get it going between a few hours and a few days.</em></span></p>
<h2><span data-contrast="none">But what does the Spec Say?</span></h2>
<p><span data-contrast="none">If you read the AVX10 specification (</span><a href="https://cdrdv2-public.intel.com/784343/356368-intel-avx10-tech-paper.pdf" target="_blank" rel="noreferrer noopener">Intel White paper on AVX10</a><span data-contrast="none">, </span><a href="https://cdrdv2-public.intel.com/784267/355989-intel-avx10-spec.pdf" target="_blank" rel="noreferrer noopener">full AVX10 specification</a><span data-contrast="none">), a few things stand out.</span></p>
<div>
<figure><a href="https://cdrdv2-public.intel.com/784343/356368-intel-avx10-tech-paper.pdf"><img data-attachment-id="22571" data-permalink="https://chipsandcheese.com/2023/10/11/avx10-128-is-a-silly-idea-and-should-be-completely-removed-from-the-specification/screen-shot-2023-10-07-at-6-28-06-pm/" data-orig-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-6.28.06-PM.png?fit=1708%2C1086&amp;ssl=1" data-orig-size="1708,1086" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screen Shot 2023-10-07 at 6.28.06 PM" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-6.28.06-PM.png?fit=1708%2C1086&amp;ssl=1" data-large-file="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-6.28.06-PM.png?fit=688%2C437&amp;ssl=1" decoding="async" width="688" height="437" src="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-6.28.06-PM.png?resize=688%2C437&amp;ssl=1" alt="" srcset="https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-6.28.06-PM.png?w=1708&amp;ssl=1 1708w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-6.28.06-PM.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-6.28.06-PM.png?resize=1536%2C977&amp;ssl=1 1536w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-6.28.06-PM.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-6.28.06-PM.png?resize=1600%2C1017&amp;ssl=1 1600w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-6.28.06-PM.png?resize=1320%2C839&amp;ssl=1 1320w, https://i0.wp.com/chipsandcheese.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-07-at-6.28.06-PM.png?w=1376&amp;ssl=1 1376w" sizes="(max-width: 688px) 100vw, 688px" data-recalc-dims="1"></a></figure></div>
<p><span data-contrast="none">Namely, the technical paper repeatedly uses the <span data-contrast="none"><span data-contrast="none">word “converged”</span></span>. What features are converging? The answer is all the distinctive features of AVX-512</span> that aren’t just “big registers”<span data-contrast="none">. Things like IEEE-754 half precision floating points? Supported as part of AVX10. What about brain floating point 16 (<span data-contrast="none">BF16</span>), a truncated version of FP32 used in the buzzword <em>du jour</em>, “AI”? Supported as a part of AVX10. What about every AVX-512 assembly programmers’ favourite dynamically reprogrammable ternary logic operator instructions? Supported as a part of AVX10. Basically, all the cool stuff assembly and compiler programmers want to use to speed up applications via smarter algorithm design are included as part of AVX10.</span></p>
<p><span data-contrast="none">Another important AVX10 <span data-contrast="none">requirement</span> is that all implementations must fully implement AVX2 and its 16 x 256 bit registers</span>. In turn, you’re guaranteed support for AVX2 code on your processor. For the maths folks, you can think of it as AVX10 having the full set of AVX2 within its own set. AVX2, in turn, requires all of AVX1.</p>
<h2><span data-contrast="none">So finally, the meat and potatoes: AVX10.N/128</span><br><span data-contrast="none">&nbsp;&nbsp;</span></h2>
<p><span data-contrast="none">I have 3 “core” problems:</span></p>
<ol>
<li><span data-contrast="none">Any and all implementations will be somewhat cursed</span>.</li>
<li><span data-contrast="none">It causes issues for the software that tries to implement the specification.&nbsp;&nbsp;</span></li>
<li><span data-contrast="none">It effectively triples the per-generation development burden. </span><br><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></li>
</ol>
<h3>It’s cursed</h3>
<p><span data-contrast="none">Any AVX2 implementation must have 16 x 256-bit registers</span>. AVX10 requires 32 vector registers regardless of vector size. <span data-contrast="none">In the case of AVX10.N/128, that would be 32 x 128-bit registers.</span> <span data-contrast="none">From the (supposed) point of view of a core design engineer/architect, the decision tree of AVX10/128 would be:</span></p>
<p><span data-contrast="none">Any implementations that only supports up to AVX10/128 must support 16 256-bit YMM registers, a.k.a YMM0-15, and a secondary set of <span data-contrast="none">128-bit XMM</span> registers that span from XMM16-31. The <span data-contrast="none">architect</span> is left with a few more choices. </span></p>
<ul>
<li><span data-contrast="none">Do you choose to have 2 different classes of SIMD vector registers with different sizes?</span></li>
<li><span data-contrast="none">Do you <em>alias</em> the upper half of ymm0-15 bits 128-255 – to be xmm16-31 bits 0-127?</span></li>
<li><span data-contrast="none">Do you extend xmm16-31 to be 256 bits?</span></li>
</ul>
<p><span data-contrast="none">The third choice is the most likely for a “clean” implementation. But then a realization will hit you: Wait! I’ve now built the same register file need for AVX10/256! If I implement a little more control logic, I have a full, proper AVX10/256 implementation and can keep my 128-bit FPUs and ALUs!</span></p>
<p><span data-contrast="none">And guess what! We’ve done that before! Famously for Zen 4 and Zen4c, AMD implemented AVX512 using 256-bit FPUs. When Zen 1 adopted AVX2, they <em>also</em> double pumped a 128-bit integer unit. Previously, the Bulldozer microarchitecture implemented AVX1 with 128-bit FPUs! And it’s not just AMD! Intel does the same today with 128-bit FPUs and integer ALUs on Gracemont. </span></p>
<p><span data-contrast="none">So you take a step back and realize you’ve already implemented double pumping in the first place, because you need to support the 16 x 256-bit registers for AVX1 and 2! Specifically, AVX requires</span> <span data-contrast="none">logics to address, mask, load, and store both the high and low parts of a given register.</span></p>
<h3><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">Software implementation headaches</span></h3>
<p><span data-contrast="none">The next step is relatively simple: address issues for optimizing <span data-contrast="none">software</span> implementations by targeting modern ISA implementations. One of the guarantees of AVX10 is that any implementation supports all smaller valid implementations. In other word, while <span data-contrast="none">AVX10/512 platforms</span></span> support <span data-contrast="none">AVX10/256, <span data-contrast="none">AVX10/256 platforms</span></span> do not support <span data-contrast="none">AVX10/512. By extension, <span data-contrast="none">AVX10/256-512</span></span> platforms support<span data-contrast="none"> AVX10/128. </span></p>
<p><span data-contrast="none">But here’s the problem. From a software targeting point of view, when AVX10 becomes ubiquitous enough to be the default x86_64 target in about a decade,</span> <span data-contrast="none">AVX10/128</span>, as <span data-contrast="none">the most compatible </span>choice, <span data-contrast="none">ends up being a net downgrade <span data-contrast="none">over AVX2</span></span> <span data-contrast="none">for SIMD programs. If AVX10/128 is valid and makes its way to market, it becomes the <em>de facto</em> minimum target for AVX10, as it supports all server and consumer options. While it’s true that the best part of AVX-512 was not the 512 bits, it’s simultaneously true that a downgrade to 128-bit registers as a common target would be detrimental to SIMD code generation – a reminder as we moved past 128-bit registers on consumer platforms over a decade ago. Code generation has moved on. Do we really want to be stuck with a sidegrade to 128-bit registers with better instructions in a decade’s time?&nbsp;&nbsp;</span></p>
<h3>You want to make even <span><strong><em>more</em></strong></span> targets?!?!</h3>
<p><span data-contrast="none">My last point is that, <span data-contrast="none">from a software point of view</span></span>,<span data-contrast="none"> AVX10 with only 256-bit and 512-bit options <span data-contrast="none">effective</span></span>ly<span data-contrast="none"> doubles the burden for each generation. </span>It <span data-contrast="none">has already happened with <span data-contrast="none">consumer</span></span> <span data-contrast="none">Golden Cove vs <span data-contrast="none">enterprise</span></span> <span data-contrast="none">Golden Cove</span>. Namely, <span data-contrast="none">the former only supports up to AVX2, but the latter implements all of AVX512 (to the point of being compatible with AVX10.1/512).</span></p>
<p><span data-contrast="none">The “same” microarchitecture (uArch) may have different memory configurations, different amounts of <span data-contrast="none">Fused Multiply Add</span></span> <span data-contrast="none">(FMA) units, different amounts of vector add units, etc. </span><br><span data-contrast="none">Looking at Golden Cove, we have: <span data-contrast="none">consumer</span></span> <span data-contrast="none">AVX2 with DDR4 and DDR5, <span data-contrast="none">workstation</span></span> <span data-contrast="none">AVX-512 with DDR5, <span data-contrast="none">server</span></span> <span data-contrast="none">AVX-512 with DDR5, <span data-contrast="none">server</span> AVX-512 with HBM only, and <span data-contrast="none">server</span></span> <span data-contrast="none">AVX-512 with <span data-contrast="none">DDR5 main memory</span></span> and <span data-contrast="none">HBM cache. </span></p>
<figure><table><thead><tr><th>Target Market</th><th>ISA</th><th>Memory</th></tr></thead><tbody><tr><td>Consumer, low-cost</td><td>AVX2</td><td>2 x DDR4</td></tr><tr><td>Consumer, mainstream</td><td>AVX2</td><td>2 x DDR5</td></tr><tr><td>Workstation, mainstream</td><td>AVX-512</td><td>4 x DDR5</td></tr><tr><td>Workstation, high-end</td><td>AVX-512</td><td>8 x DDR5</td></tr><tr><td>Server, general purpose</td><td>AVX-512</td><td>8 x DDR5</td></tr><tr><td>Server, HPC/AI dedicated compute</td><td>AVX-512</td><td>HBM</td></tr><tr><td>Server, HPC/AI general purpose compute</td><td>AVX-512</td><td>8 x DDR5 + HBM</td></tr></tbody></table><figcaption>Various versions of the Golden Cove Micro Architecture</figcaption></figure>
<p>While <span data-contrast="none">HPC is used to kernels <span data-contrast="none">(fancy name for a maths routine)</span></span> <span data-contrast="none">with <span data-contrast="none">multiple versions</span> for different sub-SKUs of an ISA, consumer software avoids doing this at all cost. You’re lucky in consumer software if the maintainers turns on anything past SSE2, let alone AVX in any of its flavours.</span></p>
<p><span data-contrast="none">And I don’t blame them. From a maintenance point of view, it is unreasonable to ask every package manager to compile different versions of projects for different versions of ISAs, to tune for differently platforms, and somehow manage to always build and ship them. Now you’re going to add all of that on top of keeping up with the existing burdens of package management? I don’t think so. In HPC, you can rely on most users to recompile software for their clusters, but this simply doesn’t happen on consumer platforms. Heck, not even Arch Linux implementes that experimentally!</span></p>
<h2><span data-contrast="none">Conclusion: what do I want?</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></h2>
<p><span data-contrast="none">My request to Intel – more specifically the evangelists, fellows, VPs, principal engineers, etc. – is simple. Page 1-2 of Intel document 355989-001US, rev 1.0, currently reads:&nbsp;</span></p>
<blockquote>
<p><span data-contrast="none">For Intel AVX10/256, 32-bit opmask register lengths are supported. For Intel AVX10/512, 64-bit opmask are supported. There are currently no plans to support an Intel AVX10/128 implementation.&nbsp;</span></p>
</blockquote>
<p>I’d request that the above be changed to:</p>
<blockquote>
<p><span data-contrast="none">For Intel AVX10/256, 32-bit opmask register lengths are supported. For Intel AVX10/512, 64-bit opmask are supported. </span>Support for an Intel AVX10/128 only implementation is not provided for within this specification. All AVX10/256 and AVX10/512 implementations shall allow for operations on scalar and 128-bit vector registers.</p>
</blockquote>
<p><span data-contrast="none">The specific phrasing here is meant to make sure that should intel ever want to explore an <span data-contrast="none">AVX10</span></span>-based<span data-contrast="none"> architecture designed for a many-core product, conceptually like Xeon Phi, they can. This way, compilers, library developers, and other software vendors aren’t in a “will they won’t they” holding pattern. It avoids needing to leave hooks in for something that’s allowed to exist per spec but won’t make it to market. The changes would still allow them to build the product eventually, but those designing for the product can bear the burden of supporting it, leaving us normal dev folks alone. The product would probably be a “simple” atom core that implements the scalar versions of AVX10, each core having its own AMX unit. </span>But I’ll leave the rampant product speculation to a different parts of the industry </p>
<p><span data-contrast="none">So, I humbly ask: Intel, please, please, please make AVX10/128 an illegal implementation under the current specification.&nbsp;</span></p>
<div><p>And for those interested in the history of instruction sets on x86_64, from the original x87 FPU all the way to AVX10, my talk on AVX10 for HPC is Friday the 13th of October 2023. Link here: <a href="https://easybuild.io/tech-talks/008_avx10.html" target="_blank" rel="noreferrer noopener">https://easybuild.io/tech-talks/008_avx10.html</a></p><p>If you like our articles and journalism, and you want to support us in our endeavors, then consider heading over to our&nbsp;<a href="https://www.patreon.com/ChipsandCheese">Patreon</a>&nbsp;or our&nbsp;<a href="https://www.paypal.com/donate/?hosted_button_id=4EMPH66SBGVSQ">PayPal</a>&nbsp;if you want to toss a few bucks our way. If you would like to talk with the Chips and Cheese staff and the people behind the scenes, then consider joining our&nbsp;<a href="https://discord.gg/TwVnRhxgY2">Discord</a>.</p></div>

<div data-post_id="10949" data-instance_id="1" data-additional_class="pp-multiple-authors-layout-boxed.multiple-authors-target-the-content" data-original_class="pp-multiple-authors-boxes-wrapper pp-multiple-authors-wrapper box-post-id-10949 box-instance-id-1">

<ul>
<li>
<p><img alt="Felix &quot;Poutine&quot; CLC" src="https://secure.gravatar.com/avatar/b878c9e9480ebebebc59fbe9c0d41a01?s=80&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/b878c9e9480ebebebc59fbe9c0d41a01?s=160&amp;d=identicon&amp;r=g 2x" height="80" width="80" loading="lazy" decoding="async"> </p>
<div>

<p>
TLDR 🇨🇦/🇫🇷🐧👨🏼‍💻🏎️🧗‍♂️
💩posting and discussing C, AVX10, AVX512, HPC, Aarch64, the Kernel &amp; Yet More Data Types </p>
<p>
<a href="https://chipsandcheese.com/author/felixleclair123/" title="View all posts">
<span>View all posts</span>
</a>
<a href="https://chipsandcheese.com/cdn-cgi/l/email-protection#7117141d18095f1d14121d10180340434231191e051c10181d5f121e1c" target="_blank" aria-label="Email" rel="nofollow">
<span></span>
</a>
</p>
</div>
</li>
</ul>
</div>





</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US citizens with permanent disabilities get free lifetime pass to National Parks (403 pts)]]></title>
            <link>https://www.nps.gov/subjects/accessibility/interagency-access-pass.htm</link>
            <guid>37850930</guid>
            <pubDate>Wed, 11 Oct 2023 22:08:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nps.gov/subjects/accessibility/interagency-access-pass.htm">https://www.nps.gov/subjects/accessibility/interagency-access-pass.htm</a>, See on <a href="https://news.ycombinator.com/item?id=37850930">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="cs_control_6690712">
<figure>
<picture>
<source type="image/png" srcset="https://www.nps.gov/subjects/accessibility/images/2023-Access-Pass_front_2.png">
<img alt="Accessibility Pass for Parks" title="2023 Access Pass_front" src="https://www.nps.gov/subjects/accessibility/images/2023-Access-Pass_front_2.png">
</picture>
<figcaption>America the Beautiful-The National Parks and Federal Recreational Lands Access Pass </figcaption>
</figure><!-- floating-image alignment  -->
<p paraeid="{92ce2bb7-bf6e-4b2d-ac8d-c58fa5831a98}{115}" paraid="2111427410"><strong>What is the America the Beautiful- The National Parks and Federal Recreational Lands Access Pass? </strong></p>
<p paraeid="{92ce2bb7-bf6e-4b2d-ac8d-c58fa5831a98}{125}" paraid="1717004537">The Interagency Access Pass is part of the America the Beautiful – The National Parks and Federal Recreational Lands Pass series and is available free for US citizens or permanent residents with permanent disabilities.  </p>
<p paraeid="{92ce2bb7-bf6e-4b2d-ac8d-c58fa5831a98}{143}" paraid="1591179836"><strong>Who is eligible to get an Interagency Access Pass? </strong></p>
<p paraeid="{92ce2bb7-bf6e-4b2d-ac8d-c58fa5831a98}{149}" paraid="527273195">The Interagency Access Pass may be issued to US citizens or permanent residents of any age that have been medically determined to have a permanent disability (does not have to be a 100% disability) that severely limits one or more major life activities.  </p>
<p paraeid="{92ce2bb7-bf6e-4b2d-ac8d-c58fa5831a98}{167}" paraid="893907869"><strong>What documentation do I need to show for proof of eligibility?  </strong></p>
<p paraeid="{92ce2bb7-bf6e-4b2d-ac8d-c58fa5831a98}{173}" paraid="146757578">Along with a valid photo ID such as a US passport, driver’s license, or state-issued ID, applicants must provide documentation of permanent disability with one (1) of the following:  </p>
<ul>
<li paraeid="{92ce2bb7-bf6e-4b2d-ac8d-c58fa5831a98}{191}" paraid="1093614014">A statement by a licensed physician (Statement must include that the individual has a PERMANENT disability, that it limits one or more aspects of their daily life, and the nature of those limitations.) </li>
<li paraeid="{92ce2bb7-bf6e-4b2d-ac8d-c58fa5831a98}{191}" paraid="1093614014">A document issued by federal agency such as the Veteran's Administration, Social Security Disability Income or, Supplemental Security Income </li>
<li paraeid="{92ce2bb7-bf6e-4b2d-ac8d-c58fa5831a98}{200}" paraid="832018928">A document issued by a state agency such as a vocational rehabilitation agency. </li>
</ul>
<p aria-level="2" paraeid="{92ce2bb7-bf6e-4b2d-ac8d-c58fa5831a98}{228}" paraid="264344596" role="heading"><strong>Where can I get an Interagency Access Pass? </strong></p>
<p paraeid="{92ce2bb7-bf6e-4b2d-ac8d-c58fa5831a98}{234}" paraid="1534541633"><u>Get a Pass in Person</u> </p>
<p paraeid="{92ce2bb7-bf6e-4b2d-ac8d-c58fa5831a98}{254}" paraid="1254792940">You can get an Interagency Access Pass in person at a federal recreation site. Please be aware that passes are not available at all national park sites. Review the <a href="https://www.nps.gov/planyourvisit/pickup-pass-locations.htm" id="https://www.nps.gov/planyourvisit/pickup-pass-locations.htm|">Places to Get Interagency Passes</a> to find a location. </p>
<p aria-level="3" paraeid="{a574d854-7582-4b56-8df9-f782cc7d19eb}{48}" paraid="580377085" role="heading"><u>Get a Pass Online </u></p>
<p paraeid="{a574d854-7582-4b56-8df9-f782cc7d19eb}{56}" paraid="1818538870">You can also get an Interagency Access Pass online through the USGS Online Store or, through the mail using an application form (Note: While the pass itself is free, there is a shipping and processing cost to get a pass online or through the mail). </p>
<p paraeid="{a574d854-7582-4b56-8df9-f782cc7d19eb}{98}" paraid="499885614"><a href="https://store.usgs.gov/access-pass" id="https://store.usgs.gov/access-pass|">Interagency Access Passes are available online. </a></p>
<p paraeid="{a574d854-7582-4b56-8df9-f782cc7d19eb}{111}" paraid="738692707"><a href="https://store.usgs.gov/faq#Access-Pass" id="https://store.usgs.gov/faq#Access-Pass|">Frequently Asked Questions about the Interagency Access Pass </a></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It’s time to allow researchers to submit manuscripts to multiple journals (135 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-023-03196-y</link>
            <guid>37850593</guid>
            <pubDate>Wed, 11 Oct 2023 21:40:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-023-03196-y">https://www.nature.com/articles/d41586-023-03196-y</a>, See on <a href="https://news.ycombinator.com/item?id=37850593">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-03196-y/d41586-023-03196-y_26146716.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-03196-y/d41586-023-03196-y_26146716.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="Portrait of Jon Gruda outside on a sunny day in a park near the ocean." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-03196-y/d41586-023-03196-y_26146716.jpg">
  <figcaption>
   <p><span>Dritjon Gruda thinks that it’s time to allow researchers to submit manuscripts to multiple journals.</span><span>Credit: Jon Gruda</span></p>
  </figcaption>
 </picture>
</figure><p>During the COVID-19 pandemic, my colleagues and I submitted a paper to a premier journal in our field, examining the effects of the onset of the pandemic on individuals’ mental health, on the basis of their personality traits. This was a time-sensitive piece because people began to adapt as the pandemic accelerated. The paper languished for several months without even being sent out for peer review. Multiple e-mails to the journal yielded no progress. We had to withdraw the paper and submit it elsewhere, losing valuable time. This could have been avoided had we been allowed to submit the manuscript elsewhere simultaneously.</p><p>Another time, we submitted a paper to a journal, and it was promptly reviewed by one reviewer. The editor, however, couldn’t find another and asked us to suggest any possible reviewers. We did, although with hesitation. Asking authors to recommend reviewers can compromise the objectivity and rigour of the peer-review process. There’s an obvious potential for bias because authors might suggest individuals who are more likely to provide favourable reviews. It took nine months and several proactive follow-ups for the editor to realize that our paper had been overlooked and was severely delayed. Eventually, after a revision request, our paper was published — almost a year later.</p><p>Imagine the absurdity of being able to apply for only one job at a time, waiting months for feedback before considering another opportunity. Such a scenario would undeniably hinder career progression. Yet, this exact practice persists in scientific publishing.</p><h2>Falling behind</h2><p>Scientific publishing has evolved to accommodate open access, preprints and even X (previously Twitter) threads. But the prohibition against simultaneously submitting a paper to several journals continues. This rule was conceived to protect the quality of the scientific record, with singular peer review acting as the key filter to ensure that only validated, high-quality research enters academia, one submission at a time. Yet, nowadays, this rule seems outdated and, at times, grossly unfair.</p><p>And sometimes a paper can undergo multiple rounds of review at one journal over the course of months or years, only to be rejected. Instead of accepting the existing system, why not change it?</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-023-01772-w" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-03196-y/d41586-023-03196-y_26146140.png"><p>Anonymizing peer review makes the process more just</p></a>
 </article><p>The multiple-submission ban stems from the pre-digital era, in which copyrights were more difficult to enforce, journal editors sifted through physical manuscripts and peer reviewers were scarce. But today, digitization has automated much of the administrative work. Identifying relevant reviewers, no matter their location, is easier and more straightforward than before. The fear that multiple submissions would overwhelm the peer-review system lacks empirical evidence and is outweighed by the burden placed on researchers. This is particularly detrimental to early-career scientists and those from under-represented backgrounds, for whom the delay isn’t just frustrating; it’s a barrier to career advancement.</p><p>The ban also hampers the speed of scientific dissemination, a crucial factor in many fields such as climate science, health and medicine, in which timely knowledge sharing is paramount. The rapid proliferation of preprint articles during the COVID-19 pandemic demonstrated the benefits of swift information sharing, even if those papers were not yet peer reviewed.</p><p>The time is ripe to reassess the single-submission policy.</p><h2>But what can authors do?</h2><p>While the scientific community awaits a much-needed overhaul of the single-submission policy, here are a few proactive suggestions to minimize the impact of protracted publishing timelines:</p><p>• Early communication: establish preliminary contact with journal editors to gauge interest in your paper before formal submission. Some editors offer constructive feedback and might even fast-track promising manuscripts.</p><p>• Journal tiering: have a well-researched list of target journals, tiered from high-impact to low-impact. If rejected from your top choice, you can quickly move on to the next journal on your list without wasting time on more research.</p><p>• Follow up: after submission, regularly check up with the journal. If a journal states that most reviews are completed in 90 days, nudge them shortly after that time. I have found this strategy to be the most useful. The key is to be respectful and professional in your communication throughout. Remember, respectful persistence. Don’t nag.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/s41563-023-01661-7" data-track="click" data-track-label="recommended article"><p>In praise of peer review</p></a>
 </article><p>• Professional networks: use your professional connections to find out which journals offer quicker review times or are known for efficient communication, even if their impact factor is not top tier. This is one of the many reasons why attending conferences is so important.</p><p>• Preprint archives: use preprint servers relevant to your field to upload your manuscript. This serves as a public record of your work and allows others to see, cite and build on it while it’s undergoing peer review.</p><p>• Use social media: share your preprint on platforms such as ResearchGate or LinkedIn to gather informal feedback and attract early attention to your work.</p><p>• Parallel projects: working on several projects can help to maintain productivity levels while one paper is stuck in the submission pipeline.</p><p>• Advocate change: join or initiate discussions that challenge the current system. Use academic blogs, webinars or professional meetings to shed light on the inefficiencies and inequities perpetuated by the single-submission rule.</p><p>Throughout my career, I’ve grappled with the frustrations of the single-submission rule. Each delay was more than a professional hiccup; it touched a nerve. Over coffee chats, my peers and I have shared these challenges, yearning for a better system. Although I haven’t spearheaded a publishing revolution, I’m driven by the collective hope of reshaping a system that recognizes our work’s value and the urgency of our time. Until publishing norms catch up with the needs and pace of contemporary research, the strategies that I’ve outlined can help authors to navigate the existing landscape more effectively. Nevertheless, in an era in which timely publications can make a difference in job security and research funding, a crucial re-evaluation of the single-submission rule is long overdue.</p>
                </div><p>This is an article from the <a href="https://www.nature.com/articles/d41586-019-03369-8" data-track="click" data-label="https://www.nature.com/articles/d41586-019-03369-8" data-track-category="body text link"><i>Nature</i> Careers Community</a>, a place for Nature readers to share their professional experiences and advice. Guest posts are encouraged.</p><div id="competing-interests" data-toggle="anchor-links-section" data-label="Competing Interests">
                    <h3>Competing Interests</h3>
                    <p>The author declares no competing interests.</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Roll Your Own All-Sky, Raspberry Pi Camera (239 pts)]]></title>
            <link>https://spectrum.ieee.org/all-sky-camera</link>
            <guid>37850485</guid>
            <pubDate>Wed, 11 Oct 2023 21:28:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/all-sky-camera">https://spectrum.ieee.org/all-sky-camera</a>, See on <a href="https://news.ycombinator.com/item?id=37850485">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-elid="2661714798" data-post-url="https://spectrum.ieee.org/all-sky-camera" data-authors="David Schneider" data-headline="Roll Your Own All-Sky, Raspberry Pi Camera" data-page-title="Roll Your Own All-Sky, Raspberry Pi Camera - IEEE Spectrum"><p>
	While driving home one night recently, I saw a spectacularly bright meteor flash across the sky in front of my car. A good-sized chunk of interplanetary detritus must have been on its way to a crash landing not too far away, I said to myself. My next thought was that if I had a bearing on that luminous streak, and if at least one other person in my region also had such information, we might be able to triangulate on it and narrow down where any landing zone might be. I’m, of course, not the only one to ponder this possibility—and, I soon learned, people have indeed successfully found meteorites this way.
</p><p>
	One example occurred in 2012, when a fireball lit up the sky over Northern California. Images of the meteor were recorded by a project called CAMS (
	<a href="https://www.sciencedirect.com/science/article/abs/pii/S0019103511003290" target="_blank">Cameras for Allsky Meteor Surveillance</a>)—a project of NASA and the <a href="https://www.seti.org/cams" target="_blank">SETI Institute</a>. These observations allowed the object’s trajectory and landing zone to be estimated, and coverage of the event in <em>The</em><em>San Francisco Chronicle</em> soon led to the discovery of what became known as the <a href="https://cams.seti.org/index-N.html" target="_blank">Novato Meteorite</a>.
</p><p>
	CAMS is not the only such project looking for meteors. Another is the 
	<a href="https://globalmeteornetwork.org/scientific-mission/" target="_blank">Global Meteor Network</a>, whose mission is to observe the night sky with “a global science-grade instrument.” Organizers of this network even <a href="https://globalmeteornetwork.org/wiki/index.php?title=Build_A_Camera" target="_blank">provide guidance</a> for how anyone can build a suitable camera based on the Raspberry Pi and how to contribute observations that can help determine the orbits of the parent asteroids that spawned particular meteors.
</p><p>
	I was tempted to join the cause, but after reading more on the subject I discovered alternative strategies for building a camera to survey the night sky. Ultimately, I decided that I wanted to capture attractive color images more than I wanted to contribute data to the Global Meteor Network, which uses black-and-white cameras because of their greater sensitivity.
</p><p><img id="406a3" data-rm-shortcode-id="9335e96628c5e30f871e50fcf0390cc6" data-rm-shortcode-name="rebelmouse-image" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/this-illustration-shows-many-of-the-components-used-in-this-project.jpg?id=34161366&amp;width=980" data-runner-src="https://spectrum.ieee.org/media-library/this-illustration-shows-many-of-the-components-used-in-this-project.jpg?id=34161366&amp;width=980" width="1280" height="1433" alt="This illustration shows many of the components used in this project. "><small placeholder="Add Photo Caption...">The required components include a Raspberry Pi microcomputer (case not shown), a Raspberry Pi High Quality camera, a lens, a dome-shaped transparent lens cover, a 5-volt power supply, and a waterproof bulkhead connector, allowing AC-mains power to pass through the wall of the waterproof enclosure  (not shown) holding the camra.</small><small placeholder="Add Photo Credit...">James Provost</small></p><p>
	So I opted to build a different kind of all-sky camera, one that is also based on a Raspberry Pi but that uses the Raspberry Pi High Quality color camera, following the lead of a project called, reasonably enough, 
	<a href="https://github.com/thomasjacquin/allsky" target="_blank">Allsky Camera</a>.
</p><p>
	The hardware for this project consists of a Raspberry Pi and either the 
	<a href="https://www.raspberrypi.com/products/raspberry-pi-high-quality-camera/" target="_blank">Raspberry Pi HQ camera</a> or one of the purpose-built <a href="https://astronomy-imaging-camera.com/product-category/planetary-cameras/" target="_blank">planetary cameras made by ZWO</a>. To be truly “all sky,” the camera should be equipped with a fish-eye lens having a 180-degree field of view. Recognizing that my home is surrounded by trees, I opted for <a href="https://www.arducam.com/product/arducam-cs-lens-for-raspberry-pi-hq-camera-120-degree-ultra-wide-angle-cs-mount-lens-3-2mm-focal-length-with-manual-focus-ln051" target="_blank">a lens with a narrower (120-degree) field of view</a>. A modern <a href="https://www.raspberrypi.com/products/raspberry-pi-4-model-b/" target="_blank">Raspberry Pi 4</a> is recommended, but I used a several-year-old <a href="https://www.raspberrypi.com/products/raspberry-pi-3-model-b/" target="_blank">Raspberry Pi 3 Model B</a> simply because I had it on hand. I decided to use a US $60 Raspberry Pi HQ camera over a ZWO camera because it offered higher resolution.
</p><p>
	To protect this hardware from the elements, I housed the Pi, camera, and a suitable wall wart for powering the Pi inside 
	<a href="https://www.amazon.com/DJC-Supply-Weather-Plastic-Junction/dp/B07ZBPJ9QL" target="_blank">a $25 waterproof plastic enclosure</a>. The opening I cut for the camera lens is covered with a $16 clear acrylic dome. The <a href="https://www.amazon.com/F-ber-Diameter-Acrylic-Replacement-Security/dp/B07L6GLTNP" target="_blank">first dome</a> I purchased distorted things, but I ordered <a href="https://www.amazon.com/JMX-Replacement-Security-Skylight-Transparent/dp/B07KGFTHL3" target="_blank">another one</a> that worked out much better. I also purchased <a href="https://www.amazon.com/iUniker-Raspberry-Cooling-Heatsink-Removable/dp/B079M96KWZ" target="_blank">an $11 case for the Raspberry Pi</a> (one that included a fan) and <a href="https://www.amazon.com/gp/product/B0043GD6XK/ref=ewc_pr_img_3?smid=A3RPN0HBLXDN8Z&amp;psc=1" target="_blank">a long extension cord</a>, which I cut and connected to <a href="https://www.amazon.com/SZJELEN-Electronics-Connector-waterproof-connector/dp/B07C4KQLPD" target="_blank">a waterproof bulkhead connector</a>. This means I can leave the unit outside even when it rains.
</p><p>
	Following the guidance provided in a very nice 
	<a href="https://www.youtube.com/watch?v=7TGpGz5SeVI" target="_blank">tutorial video</a>, I found it straightforward to set up the Allsky Camera software on my Pi, running it in a “headless” configuration—meaning without a monitor or keyboard. I access it wirelessly from a laptop through my local area network using <a href="https://www.ssh.com/academy/ssh" target="_blank">SSH</a>.
</p><p><img id="b6c84" data-rm-shortcode-id="e9158cbebdbe253d17f2d101ff0aea4c" data-rm-shortcode-name="rebelmouse-image" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/this-illustration-shows-two-cameras-capturing-images-of-a-glowing-meteor-trail-depicted-as-though-these-images-were-projected-o.jpg?id=34161399&amp;width=980" data-runner-src="https://spectrum.ieee.org/media-library/this-illustration-shows-two-cameras-capturing-images-of-a-glowing-meteor-trail-depicted-as-though-these-images-were-projected-o.jpg?id=34161399&amp;width=980" width="2500" height="2495" alt="This illustration shows two cameras capturing images of a glowing meteor trail, depicted as though these images were projected on the walls of a planetarium. "><small placeholder="Add Photo Caption...">A meteor’s trajectory through the atmosphere can hold clues to the location of any part of it that survives and also reveals the orbit of the parent body around the sun. With images of the meteor trail captured by two cameras, that trajectory can be ascertained: The position of a glowing trail relative to the background stars in an image defines a plane, and the intersection of two planes defines the trajectory.</small><small placeholder="Add Photo Credit...">James Provost</small></p><p>
	I fired everything up—but the camera didn’t work at all. So I turned to the 
	appropriate troubleshooting section in the project’s <a href="https://htmlpreview.github.io/?https://raw.githubusercontent.com/thomasjacquin/allsky/master/html/documentation/index.html" target="_blank">ample documentation</a> and tried what was advised there—to enable “Glamor” graphic acceleration on the Pi. Still no images, though. Eventually, I discovered <a href="https://github.com/raspberrypi/libcamera-apps/issues/144" target="_blank">some tweaks to a configuration file</a> that are needed when using the HQ camera on a Pi 3B, which allowed me to obtain a hopelessly blurry image of the ceiling of my office.
</p><p>
	Through trial and error, I was able to get the manual focus of the camera dialed in properly. And slowly I learned how to adjust the multitude of settings available in the Allsky Camera software, which is done either by editing a configuration file or, more conveniently, through a Web interface this software provides.
</p><p>
	For example, I learned that I should reduce the resolution of the images used to make time-lapse videos, lest images saved at the impressive native resolution of the HQ camera (4,056 by 3,040 pixels) overwhelm the processing and storage available on my Pi. While that required tweaking a configuration file, other settings can be adjusted using the Web interface, which also makes it very easy to view live images, browse images collected earlier, and view and save time-lapse videos.
</p><p><span data-rm-shortcode-id="117d1d655dc870b1f0c3d66e20d51151"><iframe type="lazy-iframe" data-runner-src="https://www.youtube.com/embed/AF89ZiQA_oo?rel=0" width="100%" height="auto" frameborder="0" scrolling="no"></iframe></span><small placeholder="Add Photo Caption...">This timelapse video shows the night sky giving way to the rosy-fingered dawn, as captured by this all-sky camera.</small><small placeholder="Add Photo Credit...">Spectrum Staff</small></p><p>
	One thing that puzzled me early on was how well such a camera would work to catch meteors flashing by, given that the camera takes still images, not many-frames-per-second videos. But my concerns diminished after capturing images of the night sky over my home, some of which caught the light of passing aircraft. The long trails of light in those images made it apparent that the exposure time must be at least some tens of seconds long. I knew these were aircraft, not meteor trails, because the streaks included parallel tracks (from wingtip lights) and obvious pulsations from strobes.
</p><p>
	I hope yet to capture meteors some day with this gizmo. For that, I may go camping in the mountains in mid-August, when the 
	<a href="https://in-the-sky.org/news.php?id=20230813_10_100" target="_blank">Perseids</a> are hitting their peak. My family and I had taken such a trip years ago, but I didn’t have an all-sky camera at the time. So I returned home with only some now-fading memories of the wonderous show nature had put on display above our heads. Next time, I’ll have something I can view over and over!
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[QX82: Tiny JavaScript game/experience engine inspired by retro 80s computing (101 pts)]]></title>
            <link>https://btco.github.io/qx82/</link>
            <guid>37850459</guid>
            <pubDate>Wed, 11 Oct 2023 21:27:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://btco.github.io/qx82/">https://btco.github.io/qx82/</a>, See on <a href="https://news.ycombinator.com/item?id=37850459">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
  <p>QX82</p>
  <p><img id="deco" src="https://btco.github.io/qx82/images/deco.svg"></p>

  <p>QX82 is a tiny Javascript engine that lets you create games and
  experiences inspired by the look and feel of a retro 80s computer.
  It's not an emulator or a fantasy console: it's just a Javascript library.</p>

  <p>It's open source. You can download it from the
    <a href="https://github.com/btco/qx82">GitHub repo</a>.</p>

  <p><img src="https://btco.github.io/qx82/images/screenshot0.webp">
    <img src="https://btco.github.io/qx82/images/screenshot1.webp">
    <img src="https://btco.github.io/qx82/images/screenshot2.webp">
    <img src="https://btco.github.io/qx82/images/screenshot3.webp">
  </p>

  <p>Although this engine tries to recreate the feel of retro computers, you
  are not limited to the functionality of old computers: this is just
  Javascript and you can do whatever you want with no artificial
  restrictions.</p>

  <p>It's open-source and MIT-licensed, so you can freely see how it
  works and make modifications to it as you need.</p>

  <p>Want to see it in action? Check out the demos (use arrow keys
  to move): </p>
  

  <p>This engine was developed by <b>Bruno Oliveira</b>. I'm <b>@btco_code</b> on
  <a href="https://twitter.com/btco_code">Twitter</a> and on
  <a href="https://mastodon.gamedev.place/@btco_code">Mastodon</a>.
  If you want to write me an email, my email address is my first name followed
  by "tc" at gmail.com.</p>

  <p><b>Note about mobile support:</b> This engine was mostly designed for
  desktop, but on mobile devices it shows a virtual joystick with a DPAD and 2
  buttons. However, mobile support is currently <b>very experimental</b> and
  quite buggy, I'll try to fix it soon!</p>

  <h2>What does the API look like?</h2>
  <p>It's a straightforward immediate mode API inspired by BASIC:</p>

  <pre><em>// Clear screen (7 = white, 1 = blue).</em>
<b>qx.color</b>(7, 1);
<b>qx.cls</b>();
<em>// Print hello at pos (1,1).</em>
<b>qx.locate</b>(1, 1);
<b>qx.print</b>(<u>"Hello world!\n\n"</u>);
<em>// Ask the user's name.</em>
<b>qx.print</b>(<u>"What is your name? "</u>);
<em>// Wait for user to type:</em>
<u>const</u> name = <u>await</u> <b>qxa.readline</b>();
<em>// Print back the name in yellow (14).</em>
<b>qx.color</b>(14);
<b>qx.print</b>(<u>`\n\nHi, {name}.`</u>);</pre>

  <p>There's also a more traditional frame-based API where you
  get a callback to draw every frame, which works best for action games
  that run continuously without blocking for user input.</p>

  <h2>Graphics</h2>
  <p>Like in the old times, a lot of graphics is accomplished via
  characters. You can define the graphics for each character code,
  so you can use this for the player, enemies, projectiles, fancy
  borders, or anything else you want.</p>

  <p><img src="https://btco.github.io/qx82/images/chars.webp">
  </p>

  <p>You can of course change this font file to draw anything you
  want. Then you can use the character code (these are numbered from 0x00
  to 0xFF) to draw:</p>

  <pre><em>// Set color (yellow over blue).</em>
<b>qx.color</b>(14, 1);
<em>// Draw hero (char code 0xc0).</em>
<b>qx.locate</b>(5, 5);
<b>qx.print</b>(<u>"\uc0"</u>)</pre>
  
  <p>And if you don't want to be constrained by text-mode rows and
  columns, you can draw directly using pixel coordinates too:</p>

  <pre><em>// Draw hero at pixel pos (50, 50).</em>
<b>qx.spr</b>(0xc0, 50, 50);</pre>
  
  <p>Ready to create your game? Continue to
    the <a href="https://btco.github.io/qx82/howto.html">How-To section</a>.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Grind – A first person shooter for Amiga 500 (292 pts)]]></title>
            <link>https://www.indieretronews.com/2023/10/grind-first-person-shooter-for-amiga.html</link>
            <guid>37850265</guid>
            <pubDate>Wed, 11 Oct 2023 21:06:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.indieretronews.com/2023/10/grind-first-person-shooter-for-amiga.html">https://www.indieretronews.com/2023/10/grind-first-person-shooter-for-amiga.html</a>, See on <a href="https://news.ycombinator.com/item?id=37850265">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-4334126658415320957" itemprop="articleBody">
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEicybcxLJAPSbuQyK3nzjBKqm0v9Katv4cgQbRDw6tL-VXvcIBMBFuZdV78u-gb1W2AQfQxur0pWPVSoJvQhtTOAH-BeQ_A6k9Us3HXxl80oXNi6mJWePdsPeztqbeCzL-hurHBPdaMHOOZu4PgVkYPbTPUwWa6bygnUQsS8GYj_DIc3mM8DXNPbFbVF5A/s1103/GRIND.jpg"><img data-original-height="796" data-original-width="1103" height="462" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEicybcxLJAPSbuQyK3nzjBKqm0v9Katv4cgQbRDw6tL-VXvcIBMBFuZdV78u-gb1W2AQfQxur0pWPVSoJvQhtTOAH-BeQ_A6k9Us3HXxl80oXNi6mJWePdsPeztqbeCzL-hurHBPdaMHOOZu4PgVkYPbTPUwWa6bygnUQsS8GYj_DIc3mM8DXNPbFbVF5A/w640-h462/GRIND.jpg" width="640"></a></p><p>'Dread' has been featured many times on Indie Retro News, as with every new update the Amiga 500 version looked better than ever with fabulous new textures and new zones to visit. Well if you're looking for more gaming news on this upcoming first person shooter, we have not only been informed that a new demo has been made available, but the latest footage and detailed press release shows that John is true to his word in bringing a Doom-like experience to the Amiga as the holy-grail of Amiga gaming! So without further-ado, here's the latest blurb about this incredible looking game.<span></span></p><p><iframe allowfullscreen="" height="366" src="https://www.youtube.com/embed/doD7hmlKun8" width="640" youtube-src-id="doD7hmlKun8"></iframe></p><p><iframe allowfullscreen="" height="366" src="https://www.youtube.com/embed/11TYIX6TRyg" width="640" youtube-src-id="11TYIX6TRyg"></iframe></p><p>'"Darkenward east' is planned to be one of the early levels in the game, taking place in a city area. The map is in it's very early stages and will be overhauled once more levels are introduced and the enemy roster gets more complete (currently there's a lack of low tier enemies and other important classes). This release in general marks the complete transition of the project in regards to its visuals and now fully embraces the Steampunk/Lovecraftian aesthetic with the addition of the new HUD and protagonist, as well as brand new, high quality Weapon designs!"&nbsp;&nbsp;</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh9uzjdulEMJTcR-BV-YkdPNFS1ZeZOFlW32H6HKqvy1RCyZm2x5PVzWZ4mVNip_I61GHq299dfMaEGY1mnIxmS_9IZb4N7aHdVkGzEqPC7kgr0tmXWuLSyJjyVGyFcqdWQ3NmOcj4Q8S_SPoepkipU_2qVVf5RPN6PxT5huEQYss9KqP0dhR67BtbSxqY/s1154/Clipboard01.jpg"><img data-original-height="832" data-original-width="1154" height="462" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh9uzjdulEMJTcR-BV-YkdPNFS1ZeZOFlW32H6HKqvy1RCyZm2x5PVzWZ4mVNip_I61GHq299dfMaEGY1mnIxmS_9IZb4N7aHdVkGzEqPC7kgr0tmXWuLSyJjyVGyFcqdWQ3NmOcj4Q8S_SPoepkipU_2qVVf5RPN6PxT5huEQYss9KqP0dhR67BtbSxqY/w640-h462/Clipboard01.jpg" width="640"></a></p><p>Here's a list of features still missing (and planned to be added soon) as well as other details that are to be worked next, in order to reach the 'vertical slice' short-term goal:&nbsp;</p><ul><li>Music support for the Amiga version</li><li>SFX overhaul (includes adding ambient stuff and enemy growls)</li><li>Further polish on weapon models</li><li>Complete the weapon models replacement (Chaingun and Missile-launcher are still wip - the demo only features the pistol and shotgun for now)</li><li>Add secondary weapon attacks (using RMB)</li><li>Existing enemies polishing (various high-tech details still need altering or removing from some models)</li><li>Create and add new enemy types&nbsp; &nbsp;</li><li>Complete and add 2 more levels (the previous and the next one). This step will also put to the test the newly added level progression system and pave the way for more levels to come.&nbsp;</li></ul><div><p><b>System Requirements:</b></p><div><ul><li>Amiga - ADF version:</li><li>Minimum: a500 with 512 CHIP and 512 OTHER ram</li><li>Recommended: a1200 + fast ram&nbsp;</li></ul></div></div><p><b>Other news:</b></p><p>----------</p><p>"Lately the Grind team has grown as various, well-known coders have joined to help with the game's production: Namely BSzili (known for his Amiga ports of Dark Forces, Exhumed, Blood, Shadow Warrior, Blake Stone and others) who's handling the Amiga version and coder Kabuto from the demogroup Titan, looking at a possible Mega Drive version as well! Worth noting is that this latest Patreon-only binary release also included an Atari ST version (though it's not ready for a public showcase yet as it misses key features)."&nbsp;</p><p><b>Links:</b></p><p>-----</p><p>-Grind's Patreon: <a href="https://www.patreon.com/Grind_Amiga">https://www.patreon.com/Grind_Amiga</a>&nbsp;(Demo)</p><p>-Grind's Pixelglass page: <a href="https://pixelglass.org/#grind">https://pixelglass.org/#grind</a></p><p>-Grind's Discord server: <a href="https://discord.gg/QXGQbkRCxN">https://discord.gg/QXGQbkRCxN</a></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: See library availabilities for your Goodreads want-to-read list (189 pts)]]></title>
            <link>https://projecttbr.com/?goodreadsProfile=121455547-bella-vice-van-heyde&amp;library=nypl,spl&amp;format=ebook-kindle</link>
            <guid>37850205</guid>
            <pubDate>Wed, 11 Oct 2023 21:01:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://projecttbr.com/?goodreadsProfile=121455547-bella-vice-van-heyde&#x26;library=nypl,spl&#x26;format=ebook-kindle">https://projecttbr.com/?goodreadsProfile=121455547-bella-vice-van-heyde&#x26;library=nypl,spl&#x26;format=ebook-kindle</a>, See on <a href="https://news.ycombinator.com/item?id=37850205">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[SEC Filing – Microsoft Corporation (208 pts)]]></title>
            <link>https://microsoft.gcs-web.com/node/31951/html</link>
            <guid>37850110</guid>
            <pubDate>Wed, 11 Oct 2023 20:52:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://microsoft.gcs-web.com/node/31951/html">https://microsoft.gcs-web.com/node/31951/html</a>, See on <a href="https://news.ycombinator.com/item?id=37850110">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="block-nir-pid1962-content">
  
    
      
    <xbrl>
<!--?xml version="1.0" encoding="utf-8" ?-->


<title>8-K</title>
<meta http-equiv="Content-Type" content="text/html">

                    
                    
    <div><p>UNITED STATES</p><p>SECURITIES AND EXCHANGE COMMISSION</p><p>WASHINGTON, D.C. 20549</p> <p>FORM <span><ix:nonnumeric name="dei:DocumentType" contextref="duration_2023-10-11_to_2023-10-11">8-K</ix:nonnumeric></span></p> <p>CURRENT REPORT</p><p>PURSUANT TO SECTION 13 OR 15(D)</p><p>OF THE SECURITIES EXCHANGE ACT OF 1934</p><p>Date of Report (Date of earliest event reported) <ix:nonnumeric name="dei:DocumentPeriodEndDate" contextref="duration_2023-10-11_to_2023-10-11" format="ixt:date-monthname-day-year-en">October&nbsp;11, 2023</ix:nonnumeric></p> <p><ix:nonnumeric name="dei:EntityRegistrantName" contextref="duration_2023-10-11_to_2023-10-11">Microsoft Corporation</ix:nonnumeric></p> 
<table>
<tbody><tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td></tr>
<tr>
<td><span><ix:nonnumeric name="dei:EntityIncorporationStateCountryCode" contextref="duration_2023-10-11_to_2023-10-11" format="ixt-sec:stateprovnameen">Washington</ix:nonnumeric></span></td>
<td>&nbsp;</td>
<td><span><span><ix:nonnumeric name="dei:EntityFileNumber" contextref="duration_2023-10-11_to_2023-10-11">001-37845</ix:nonnumeric></span></span></td>
<td>&nbsp;</td>
<td><span><span><ix:nonnumeric name="dei:EntityTaxIdentificationNumber" contextref="duration_2023-10-11_to_2023-10-11">91-1144442</ix:nonnumeric></span></span></td></tr>
<tr>
<td><p>(State or Other Jurisdiction</p><p>of Incorporation)</p></td>
<td>&nbsp;</td>
<td><p>(Commission</p><p>File Number)</p></td>
<td>&nbsp;</td>
<td><p>(IRS Employer</p><p>Identification No.)</p></td></tr> </tbody></table>
<table>
<tbody><tr>
<td></td>
<td></td>
<td></td></tr>
<tr>
<td><span><ix:nonnumeric name="dei:EntityAddressAddressLine1" contextref="duration_2023-10-11_to_2023-10-11">One Microsoft Way</ix:nonnumeric>, <ix:nonnumeric name="dei:EntityAddressCityOrTown" contextref="duration_2023-10-11_to_2023-10-11">Redmond</ix:nonnumeric>, <ix:nonnumeric name="dei:EntityAddressStateOrProvince" contextref="duration_2023-10-11_to_2023-10-11" format="ixt-sec:stateprovnameen">Washington</ix:nonnumeric></span></td>
<td>&nbsp;</td>
<td><span><ix:nonnumeric name="dei:EntityAddressPostalZipCode" contextref="duration_2023-10-11_to_2023-10-11">98052-6399</ix:nonnumeric></span></td></tr> </tbody></table><p>(<ix:nonnumeric name="dei:CityAreaCode" contextref="duration_2023-10-11_to_2023-10-11">425</ix:nonnumeric>) <span><ix:nonnumeric name="dei:LocalPhoneNumber" contextref="duration_2023-10-11_to_2023-10-11">882-8080</ix:nonnumeric></span></p><p>www.microsoft.com/investor</p><p>Check the appropriate box below if the Form <span>8-K</span> filing is intended to simultaneously satisfy the filing obligation of the registrant under any of the following provisions (see General Instruction A.2. below):</p>
<table>
<tbody><tr>
<td><span><ix:nonnumeric name="dei:WrittenCommunications" contextref="duration_2023-10-11_to_2023-10-11" format="ixt-sec:boolballotbox">☐</ix:nonnumeric></span></td>
<td><p>Written communications pursuant to Rule 425 under the Securities Act (17 CFR 230.425)</p></td></tr> </tbody></table>
<table>
<tbody><tr>
<td><span><ix:nonnumeric name="dei:SolicitingMaterial" contextref="duration_2023-10-11_to_2023-10-11" format="ixt-sec:boolballotbox">☐</ix:nonnumeric></span></td>
<td><p>Soliciting material pursuant to Rule <span>14a-12</span> under the Exchange Act (17 CFR <span>240.14a-12)</span></p></td></tr> </tbody></table>
<table>
<tbody><tr>
<td><span><ix:nonnumeric name="dei:PreCommencementTenderOffer" contextref="duration_2023-10-11_to_2023-10-11" format="ixt-sec:boolballotbox">☐</ix:nonnumeric></span></td>
<td><p><span>Pre-commencement</span> communications pursuant to Rule <span>14d-2(b)</span> under the Exchange Act (17 CFR <span>240.14d-2(b))</span></p></td></tr> </tbody></table>
<table>
<tbody><tr>
<td><span><ix:nonnumeric name="dei:PreCommencementIssuerTenderOffer" contextref="duration_2023-10-11_to_2023-10-11" format="ixt-sec:boolballotbox">☐</ix:nonnumeric></span></td>
<td><p><span>Pre-commencement</span> communications pursuant to Rule <span>13e-4(c)</span> under the Exchange Act (17 CFR <span>240.13e-4(c))</span></p></td></tr> </tbody></table><p>Securities registered pursuant to Section&nbsp;12(b) of the Act:</p>
<table>
<tbody><tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td></tr>
<tr>
<td><p>Title of each class</p></td>
<td>&nbsp;&nbsp;</td>
<td><p>Trading&nbsp;Symbol</p></td>
<td>&nbsp;&nbsp;</td>
<td><p>Name&nbsp;of&nbsp;exchange&nbsp;on&nbsp;which&nbsp;registered</p></td></tr>
<tr>
<td><span><ix:nonnumeric name="dei:Security12bTitle" contextref="duration_2023-10-11_to_2023-10-11_us-gaap-StatementClassOfStockAxis_us-gaap-CommonStockMember">Common stock, $0.00000625 par value per share</ix:nonnumeric></span></td>
<td>&nbsp;&nbsp;</td>
<td><span><ix:nonnumeric name="dei:TradingSymbol" contextref="duration_2023-10-11_to_2023-10-11_us-gaap-StatementClassOfStockAxis_us-gaap-CommonStockMember">MSFT</ix:nonnumeric></span></td>
<td>&nbsp;&nbsp;</td>
<td><span><ix:nonnumeric name="dei:SecurityExchangeName" contextref="duration_2023-10-11_to_2023-10-11_us-gaap-StatementClassOfStockAxis_us-gaap-CommonStockMember">NASDAQ</ix:nonnumeric></span></td></tr>
<tr>
<td><span><ix:nonnumeric name="dei:Security12bTitle" contextref="duration_2023-10-11_to_2023-10-11_us-gaap-StatementClassOfStockAxis_msft-NotesThreePointOneTwoFivePercentDueDecemberSixTwentyTwentyEightMember">3.125% Notes due 2028</ix:nonnumeric></span></td>
<td>&nbsp;&nbsp;</td>
<td><span><ix:nonnumeric name="dei:TradingSymbol" contextref="duration_2023-10-11_to_2023-10-11_us-gaap-StatementClassOfStockAxis_msft-NotesThreePointOneTwoFivePercentDueDecemberSixTwentyTwentyEightMember">MSFT</ix:nonnumeric></span></td>
<td>&nbsp;&nbsp;</td>
<td><span><ix:nonnumeric name="dei:SecurityExchangeName" contextref="duration_2023-10-11_to_2023-10-11_us-gaap-StatementClassOfStockAxis_msft-NotesThreePointOneTwoFivePercentDueDecemberSixTwentyTwentyEightMember">NASDAQ</ix:nonnumeric></span></td></tr>
<tr>
<td><span><ix:nonnumeric name="dei:Security12bTitle" contextref="duration_2023-10-11_to_2023-10-11_us-gaap-StatementClassOfStockAxis_msft-NotesTwoPointSixTwoFivePercentDueMayTwoTwentyThirtyThreeMember">2.625% Notes due 2033</ix:nonnumeric></span></td>
<td>&nbsp;&nbsp;</td>
<td><span><ix:nonnumeric name="dei:TradingSymbol" contextref="duration_2023-10-11_to_2023-10-11_us-gaap-StatementClassOfStockAxis_msft-NotesTwoPointSixTwoFivePercentDueMayTwoTwentyThirtyThreeMember">MSFT</ix:nonnumeric></span></td>
<td>&nbsp;&nbsp;</td>
<td><span><ix:nonnumeric name="dei:SecurityExchangeName" contextref="duration_2023-10-11_to_2023-10-11_us-gaap-StatementClassOfStockAxis_msft-NotesTwoPointSixTwoFivePercentDueMayTwoTwentyThirtyThreeMember">NASDAQ</ix:nonnumeric></span></td></tr> </tbody></table><p>Indicate by check mark whether the registrant is an emerging growth company as defined in Rule 405 of the Securities Act of 1933 (§230.405 of this chapter) or Rule <span>12b-2</span> of the Securities Exchange Act of 1934 <span>(§240.12b-2</span> of this chapter). Emerging growth company&nbsp;<span><ix:nonnumeric name="dei:EntityEmergingGrowthCompany" contextref="duration_2023-10-11_to_2023-10-11" format="ixt-sec:boolballotbox">☐</ix:nonnumeric></span></p><p>If an emerging growth company, indicate by check mark if the registrant has elected not to use the extended transition period for complying with any new or revised financial accounting standards provided pursuant to Section&nbsp;13(a) of the Exchange Act.&nbsp;<span>☐</span></p></div> <hr> <div><p>Item 8.01. Other Information</p><p>On October&nbsp;11, 2023, Microsoft Corporation announced the receipt of Notices of Proposed Adjustment (“NOPAs”) from the Internal Revenue Service (the “IRS”) for the tax years 2004 to 2013. The NOPAs were received on September&nbsp;26, 2023. The primary issues in the NOPAs relate to intercompany transfer pricing. In the NOPAs, the IRS is seeking an additional tax payment of $28.9&nbsp;billion plus penalties and interest. As of September&nbsp;30, 2023, we believe our allowances for income tax contingencies are adequate. We disagree with the proposed adjustments and will vigorously contest the NOPAs through the IRS’s administrative appeals office and, if necessary, judicial proceedings. We do not expect a final resolution of these issues in the next 12 months.&nbsp;Based on the information currently available, we do not anticipate a significant increase or decrease to our tax contingencies for these issues within the next 12 months.</p><p>This Form <span>8-K</span> contains forward-looking statements, which are any predictions, projections or other statements about future events based on current expectations and assumptions that are subject to risks and uncertainties, which are described in our filings with the Securities and Exchange Commission. Forward-looking statements speak only as of the date they are made. Readers are cautioned not to put undue reliance on forward-looking statements, and Microsoft undertakes no duty to update any forward-looking statement to conform the statement to actual results or changes in the company’s expectations.</p><p>Item 9.01. Financial Statements and Exhibits</p><p>(d) Exhibits:</p> <div>
<table>
<tbody><tr>
<td></td>
<td></td>
<td></td></tr>
<tr>
<td>99.1</td>
<td>&nbsp;&nbsp;</td>
<td><a href="#d530324dex991.htm">Microsoft on the Issues Blog </a></td></tr>
<tr>
<td>104</td>
<td>&nbsp;&nbsp;</td>
<td>Cover Page Interactive Data File (embedded within the Inline XBRL document)</td></tr></tbody></table></div></div> <hr> <div><p>SIGNATURE</p><p>Pursuant to the requirements of the Securities Exchange Act of 1934, the registrant has duly caused this report to be signed on its behalf by the undersigned hereunto duly authorized.</p>
<table>
<tbody><tr>
<td></td>
<td></td>
<td></td></tr>
<tr>
<td></td>
<td>&nbsp;&nbsp;</td>
<td>MICROSOFT CORPORATION</td></tr>
<tr>
<td></td>
<td>&nbsp;&nbsp;</td>
<td>(Registrant)</td></tr>
<tr>
<td></td>
<td colspan="2"></td></tr>
<tr>
<td>Date: October 11, 2023</td>
<td>&nbsp;&nbsp;</td>
<td><p>/<small>S</small>/ A<small>LICE</small> L. J<small>OLLA</small></p></td></tr>
<tr>
<td></td>
<td>&nbsp;&nbsp;</td>
<td>Alice L. Jolla</td></tr>
<tr>
<td></td>
<td>&nbsp;&nbsp;</td>
<td>Corporate Vice President and Chief Accounting<br>Officer</td></tr></tbody></table></div>
</xbrl>

<title>EX-99.1</title>

                    
                    
 

<center></center>



<hr size="3">

<center><div>
 <p><span color="#666666">Microsoft on the Issues Blog – An update on our IRS tax audit </span></p>
<p><span color="#666666">By Daniel Goff, Corporate Vice President, Worldwide Tax and Customs </span></p>
<p><span color="#666666">Today, we’re sharing an update about our ongoing audit with the U.S. Internal Revenue Service (IRS), including background and context for this
specific case and what we generally expect next. </span></p> <p><span color="#666666"><b>Background on the IRS audit </b></span></p>
<p><span color="#666666">For nearly a decade, as we have previously disclosed in our financial statements, Microsoft has been working with the IRS to address questions
about how we allocated our income and expenses for tax years beginning as far back as 2004. We have changed our corporate structure and practices since the years covered by the audit, and as a result, the issues raised by the IRS are relevant to the
past but not to our current practices. </span></p> <p><span color="#666666">The IRS recently sent us a series of Notices of Proposed Adjustment (NOPAs), sharing with us
for the first time detailed information and explanations of their views about the issues in question. This marks the end of the audit covering 2004 to 2013, and the beginning of a new process to resolve these
<span>decades-old</span> issues. </span></p> <p><span color="#666666">The IRS says Microsoft owes an additional $28.9&nbsp;billion in tax for
2004 to 2013, plus penalties and interest. The IRS’s proposed adjustments do not represent a final determination. Not reflected in the proposed adjustments are taxes paid by Microsoft under the Tax Cuts and Jobs Act (TCJA), which could decrease
the final tax owed under the audit by up to $10&nbsp;billion. </span></p> <p><span color="#666666">Microsoft disagrees with these proposed adjustments and will pursue an
appeal within the IRS, a process expected to take several years. We believe we have always followed the IRS’s rules and paid the taxes we owe in the U.S. and around the world. Microsoft historically has been one of the top U.S. corporate income
taxpayers. Since 2004, we have paid over $67&nbsp;billion in taxes to the U.S. </span></p> <p><span color="#666666"><b>What the dispute is about </b></span></p>
<p><span color="#666666">The main disagreement is the way Microsoft allocated profits during this time period among countries and jurisdictions. This is commonly referred
to as transfer pricing and the IRS has established regulations that allow companies to use a specific arrangement for transfer pricing, called cost-sharing. </span></p>
<p><span color="#666666">Many large multinationals use cost-sharing because it reflects the global nature of their business. Because our subsidiaries shared in the costs
of developing certain intellectual property, under those IRS cost-sharing regulations, the subsidiaries were also entitled to the related profits. </span></p> <p><span color="#666666"><b>Next steps: Proposed adjustments and IRS Appeals </b></span></p> <p><span color="#666666">We strongly believe we have acted in accordance with IRS
rules and regulations and that our position is supported by case law. We welcome the IRS’s conclusion of its audit phase which will provide us with the opportunity to work through these issues at IRS Appeals, a separate division of the IRS
charged with resolving tax disputes. </span></p>
</div></center>



<hr size="3">

<center><div>
 <p><span color="#666666">It is important to note that the IRS Appeals process will take several years to complete, and if
we are unable to come to a direct agreement with the IRS, Microsoft will then have an opportunity to contest any unresolved issues through the courts. </span></p> <p><span color="#666666">We will continue to work with the IRS and hope to reach a mutual resolution to this issue over the coming years. We will also continue to share updates on significant developments through our public quarterly and annual reports and
financial statements, as we have through this entire process. As of September&nbsp;30, 2023, we believe our allowances for income tax contingencies are adequate. </span></p>
</div></center>




  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Obligator – An OpenID Connect server for self-hosters (242 pts)]]></title>
            <link>https://github.com/anderspitman/obligator</link>
            <guid>37848793</guid>
            <pubDate>Wed, 11 Oct 2023 18:59:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/anderspitman/obligator">https://github.com/anderspitman/obligator</a>, See on <a href="https://news.ycombinator.com/item?id=37848793">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-warning" dir="auto"><a href="#warning">WARNING</a></h2>
<p dir="auto">This is currently pre-release beta software. I don't recommend using it in
production at the moment. It has not yet undergone any sort of official
security review, and I am not a security expert. The plan is to arrange for a
security review before reaching 1.0.</p>
<p dir="auto">That said, testing and feedback (especially with respect to security) would be
greatly appreciated.</p>
<h2 tabindex="-1" id="user-content-introduction" dir="auto"><a href="#introduction">Introduction</a></h2>
<p dir="auto">obligator is a relatively simple and opinionated OpenID Connect (OIDC) Provider
(OP) server designed for self-hosters.</p>
<h2 tabindex="-1" id="user-content-motivation" dir="auto"><a href="#motivation">Motivation</a></h2>
<p dir="auto">There are lots of great open source OIDC servers out there (see
<a href="#comparison-is-the-thief-of-joy">comparison</a>). I made obligator because I
needed a specific combination of features I didn't find in any of the others.
Here's a brief list. See the <a href="#feature-explanation">feature explanation</a>
section for more detailed information.</p>
<ul dir="auto">
<li>Simple to deploy and manage. Static executable and either flat-file or sqlite
storage</li>
<li>Support for anonymous OAuth2 clients</li>
<li>Authenticate to multiple domains at once</li>
<li>Passwordless email login</li>
<li>Configurable at runtime with an API</li>
<li>Support for <a href="https://doc.traefik.io/traefik/middlewares/http/forwardauth/" rel="nofollow">forward auth</a></li>
<li>Support for <a href="https://www.authelia.com/integration/trusted-header-sso/introduction/" rel="nofollow">trusted headers</a></li>
<li>Support for upstream social login providers (GitLab, GitHub, Google, etc)</li>
</ul>
<h2 tabindex="-1" id="user-content-design" dir="auto"><a href="#design">Design</a></h2>
<p dir="auto">The overarching philosophy of obligator is that identities are built on email.
Email isn't perfect, but it's the globally unique federated identity we have
that works today.</p>
<p dir="auto">Thus the purpose of obligator is to validate that a user controls an email
address as simply as possible, and communicate that to the application the
user is attempting to log in to. Validation can either be done directly
through SMTP, or delegated to upstream OIDC (and some plain OAuth2) providers.</p>
<h2 tabindex="-1" id="user-content-running-it" dir="auto"><a href="#running-it">Running it</a></h2>
<p dir="auto">Here's a fairly complete JSON storage file (<code>obligator_storage.json</code>). Note
that I call it "storage" and not "config" because it's not static, and more
like a simple database. obligator will update it at runtime if new values are
provided through the API.</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;root_uri&quot;: &quot;https://example.com&quot;,
  &quot;login_key_name&quot;: &quot;obligator_login_key&quot;,
  &quot;oauth2_providers&quot;: [
    {
      &quot;id&quot;: &quot;google&quot;,
      &quot;name&quot;: &quot;Google&quot;,
      &quot;uri&quot;: &quot;https://accounts.google.com&quot;,
      &quot;client_id&quot;: &quot;<google oauth2 client_id>&quot;,
      &quot;client_secret&quot;: &quot;<google oauth2 client_secret>&quot;,
      &quot;openid_connect&quot;: true
    },
    {
      &quot;id&quot;: &quot;lastlogin&quot;,
      &quot;name&quot;: &quot;LastLogin.io&quot;,
      &quot;uri&quot;: &quot;https://lastlogin.io&quot;,
      &quot;client_id&quot;: &quot;https://example.com&quot;,
      &quot;client_secret&quot;: &quot;&quot;,
      &quot;openid_connect&quot;: true
    }
  ],
  &quot;smtp&quot;: {
    &quot;server&quot;: &quot;smtp.fastmail.com&quot;,
    &quot;username&quot;: &quot;<smtp-username>&quot;,
    &quot;password&quot;: &quot;<smtp-password>&quot;,
    &quot;port&quot;: 587,
    &quot;sender&quot;: &quot;auth@example.com&quot;,
    &quot;sender_name&quot;: &quot;Example&quot;
  },
  &quot;jwks&quot;: &quot;<generated at first startup if empty>&quot;,
  &quot;users&quot;: [
    {
      &quot;email&quot;: &quot;user1@example.com&quot;
    },
    {
      &quot;email&quot;: &quot;user2@example.com&quot;
    }
  ],
  &quot;public&quot;: false
}"><pre>{
  <span>"root_uri"</span>: <span><span>"</span>https://example.com<span>"</span></span>,
  <span>"login_key_name"</span>: <span><span>"</span>obligator_login_key<span>"</span></span>,
  <span>"oauth2_providers"</span>: [
    {
      <span>"id"</span>: <span><span>"</span>google<span>"</span></span>,
      <span>"name"</span>: <span><span>"</span>Google<span>"</span></span>,
      <span>"uri"</span>: <span><span>"</span>https://accounts.google.com<span>"</span></span>,
      <span>"client_id"</span>: <span><span>"</span>&lt;google oauth2 client_id&gt;<span>"</span></span>,
      <span>"client_secret"</span>: <span><span>"</span>&lt;google oauth2 client_secret&gt;<span>"</span></span>,
      <span>"openid_connect"</span>: <span>true</span>
    },
    {
      <span>"id"</span>: <span><span>"</span>lastlogin<span>"</span></span>,
      <span>"name"</span>: <span><span>"</span>LastLogin.io<span>"</span></span>,
      <span>"uri"</span>: <span><span>"</span>https://lastlogin.io<span>"</span></span>,
      <span>"client_id"</span>: <span><span>"</span>https://example.com<span>"</span></span>,
      <span>"client_secret"</span>: <span><span>"</span><span>"</span></span>,
      <span>"openid_connect"</span>: <span>true</span>
    }
  ],
  <span>"smtp"</span>: {
    <span>"server"</span>: <span><span>"</span>smtp.fastmail.com<span>"</span></span>,
    <span>"username"</span>: <span><span>"</span>&lt;smtp-username&gt;<span>"</span></span>,
    <span>"password"</span>: <span><span>"</span>&lt;smtp-password&gt;<span>"</span></span>,
    <span>"port"</span>: <span>587</span>,
    <span>"sender"</span>: <span><span>"</span>auth@example.com<span>"</span></span>,
    <span>"sender_name"</span>: <span><span>"</span>Example<span>"</span></span>
  },
  <span>"jwks"</span>: <span><span>"</span>&lt;generated at first startup if empty&gt;<span>"</span></span>,
  <span>"users"</span>: [
    {
      <span>"email"</span>: <span><span>"</span>user1@example.com<span>"</span></span>
    },
    {
      <span>"email"</span>: <span><span>"</span>user2@example.com<span>"</span></span>
    }
  ],
  <span>"public"</span>: <span>false</span>
}</pre></div>
<p dir="auto">If you're already using docker, it's the easiest way to get started with
obligator:</p>
<div data-snippet-clipboard-copy-content="mkdir obligator_docker/
cp obligator_storage.json obligator_docker/

docker run --user $(id -u):$(id -g) --rm -it -v $PWD/obligator_docker:/data -v $PWD/obligator_docker:/api -p 1616:1616 anderspitman/obligator:latest -storage-dir /data -api-socket-dir /api -root-uri example.com -port 1616"><pre><code>mkdir obligator_docker/
cp obligator_storage.json obligator_docker/

docker run --user $(id -u):$(id -g) --rm -it -v $PWD/obligator_docker:/data -v $PWD/obligator_docker:/api -p 1616:1616 anderspitman/obligator:latest -storage-dir /data -api-socket-dir /api -root-uri example.com -port 1616
</code></pre></div>
<p dir="auto">You can also download static executables for various platforms from the
<a href="https://github.com/anderspitman/obligator/releases">releases</a> page.</p>
<h2 tabindex="-1" id="user-content-using-the-api" dir="auto"><a href="#using-the-api">Using the API</a></h2>
<p dir="auto">Currently the API is only offered through unix sockets. This reduces the
chance that it accidentally gets exposed, which is important because
it's not authenticated in any way.</p>
<p dir="auto">There's not any documentation, and the API is in flux, so refer to the
<a href="https://github.com/anderspitman/obligator/blob/master/api.go">source code</a> for usage.</p>
<p dir="auto">Here's an example assuming you ran the docker command above:</p>
<div data-snippet-clipboard-copy-content="curl --unix obligator_docker/obligator_api.sock dummy-domain/oauth2-providers"><pre><code>curl --unix obligator_docker/obligator_api.sock dummy-domain/oauth2-providers
</code></pre></div>
<p dir="auto">See <a href="https://superuser.com/q/834307" rel="nofollow">here</a> for more info on using curl over unix sockets.</p>
<h2 tabindex="-1" id="user-content-feature-explanation" dir="auto"><a href="#feature-explanation">Feature explanation</a></h2>
<h2 tabindex="-1" id="user-content-anonymous-oauth2-clients" dir="auto"><a href="#anonymous-oauth2-clients">Anonymous OAuth2 clients</a></h2>
<p dir="auto">Normally in OAuth2 (and therefore OIDC), an app (client) is required to
pre-register with the provider. This can create a lot of friction, especially
if you're self-hosting an open source application. App developers are forced to
either share a single client ID for all their users (and share their
<code>client secret</code>, which essentially makes it pointless), or each user must
separately register their instance.</p>
<p dir="auto">Instead, obligator takes essentially the approach described <a href="https://aaronparecki.com/2018/07/07/7/oauth-for-the-open-web" rel="nofollow">here</a>. Any
OAuth2 client can anonymously authenticate with an obligator instance, with the
<code>client_id</code> equal to the domain of the client, and <code>client_secret</code> left blank.
Security is maintained through the following means:</p>
<ul dir="auto">
<li>Only approved email addresses are permitted unless <code>public: true</code> is set in
the config.</li>
<li>The <code>client_id</code> URI must be a prefix of the <code>redirect_uri</code>, and the
<code>client_id</code> is displayed to the user when consenting to the login. This
guarantees that the user approves the ID token to be sent to the domain
shown. Note that this can actually be more secure than pre-registration.
There have been attacks in <a href="https://duo.com/blog/gmail-oauth-phishing-goes-viral" rel="nofollow">the past</a> where users were tricked into
authorizing apps because the pre-registered information looked convincing. By
forcing the user to decide whether they trust the actual domain where the ID
token will be sent, and not displaying any sort of logo which can be faked,
security is improved.</li>
</ul>
<h2 tabindex="-1" id="user-content-multi-domain-authentication" dir="auto"><a href="#multi-domain-authentication">Multi-domain authentication</a></h2>
<p dir="auto">Have you ever noticed when you login to Gmail on a new computer that you're
also automatically logged in to YouTube? How does this work when Gmail is on
google.com and youtube.com doesn't have any access to the cookies or
localstorage of google.com?</p>
<p dir="auto">The <a href="https://stackoverflow.com/a/19929304/943814" rel="nofollow">answer</a> is that when you log in on accounts.google.com, it makes a
quick redirect to youtube.com with a URL parameter to also set up the cookies
there. I also want this functionality for all the domains protected by my OIDC
server so I'm building it into obligator.</p>
<h2 tabindex="-1" id="user-content-passwordless-email-login" dir="auto"><a href="#passwordless-email-login">Passwordless email login</a></h2>
<p dir="auto">In line with the philosophy above, email reigns supreme in obligator. Since
passwords are relatively difficult to use securely, the way to add an email
identity is to send a confirmation code to the email address.</p>
<h2 tabindex="-1" id="user-content-demo" dir="auto"><a href="#demo">Demo</a></h2>
<p dir="auto">There's a public instance of obligator running at <a href="https://lastlogin.io/" rel="nofollow">https://lastlogin.io</a>
(discovery doc at <a href="https://lastlogin.io/.well-known/openid-configuration" rel="nofollow">https://lastlogin.io/.well-known/openid-configuration</a>). You
can use it with any OIDC client. Just set the <code>client_id</code> to a prefix of the
<code>redirect_uri</code> when making the authorization request. I like to use
<a href="https://openidconnect.net/" rel="nofollow">https://openidconnect.net/</a> for ad-hoc testing. The official <a href="https://www.certification.openid.net/login.html" rel="nofollow">OpenID conformance
suite</a> is also excellent.</p>
<h2 tabindex="-1" id="user-content-comparison-is-the-thief-of-joy" dir="auto"><a href="#comparison-is-the-thief-of-joy">Comparison is the thief of joy</a></h2>
<p dir="auto">Software is rarely about right vs wrong, but rather tradeoffs. This table is
intended to help compare tradeoffs of different servers. It's also very
incomplete and probably incorrect in many cases. If you have a correction,
please submit an issue or leave a comment on the Google sheet <a href="https://docs.google.com/spreadsheets/d/16Ya5KsmEpczTmoTk5J-1e2MOyuUqXIiPuj7rPfPrHAI/edit?usp=sharing" rel="nofollow">here</a> which
is where it's generated from.</p>
<table>
<thead>
<tr>
<th></th>
<th><a href="https://github.com/anderspitman/obligator">obligator</a></th>
<th><a href="https://www.authelia.com/" rel="nofollow">Authelia</a></th>
<th><a href="https://goauthentik.io/" rel="nofollow">Authentik</a></th>
<th><a href="https://www.keycloak.org/" rel="nofollow">KeyCloak</a></th>
<th><a href="https://github.com/vouch/vouch-proxy">Vouch</a></th>
<th><a href="https://github.com/oauth2-proxy/oauth2-proxy">oauth2-proxy</a></th>
<th><a href="https://dexidp.io/" rel="nofollow">Dex</a></th>
<th><a href="https://www.ory.sh/hydra/" rel="nofollow">Ory Hydra</a></th>
<th><a href="https://zitadel.com/" rel="nofollow">Zitadel</a></th>
<th><a href="https://casdoor.org/" rel="nofollow">Casdoor</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>Simple</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
<td>❌</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
<td>❌</td>
<td>❓</td>
<td>❓</td>
</tr>
<tr>
<td>Anonymous clients</td>
<td>✅</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
</tr>
<tr>
<td>Multi-domain auth</td>
<td>✅ (planned)</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
</tr>
<tr>
<td>Passwordless email login</td>
<td>✅</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❓</td>
</tr>
<tr>
<td>HTTP API</td>
<td>✅</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
<td>❌</td>
<td>✅</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
</tr>
<tr>
<td>Forward auth</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>❓</td>
<td>❌</td>
<td>❓</td>
<td>❓</td>
</tr>
<tr>
<td>Trusted header auth</td>
<td>✅ (planned)</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
</tr>
<tr>
<td>Upstream OIDC/OAuth2</td>
<td>✅</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
</tr>
<tr>
<td>SAML</td>
<td>❌</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
<td>❌</td>
<td>✅</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
</tr>
<tr>
<td>LDAP</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
<td>❌</td>
<td>✅</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
</tr>
<tr>
<td>MFA</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
<td>❌</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
</tr>
<tr>
<td>Standalone reverse proxy</td>
<td>❌</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
<td>✅</td>
<td>❌</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
</tr>
<tr>
<td>Admin GUI</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
<td>❌</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
</tr>
<tr>
<td>Language</td>
<td>Go</td>
<td>Go</td>
<td>Python</td>
<td>Java</td>
<td>Go</td>
<td>Go</td>
<td>Go</td>
<td>Go</td>
<td>Go</td>
<td>Go</td>
</tr>
<tr>
<td>Dependencies</td>
<td>1</td>
<td>49</td>
<td>54</td>
<td>❓</td>
<td>16</td>
<td>36</td>
<td>36</td>
<td>58</td>
<td>81</td>
<td>68</td>
</tr>
<tr>
<td>Lines of code</td>
<td>~2500</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
<td>❓</td>
</tr>
</tbody>
</table>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Awareness at Death (148 pts)]]></title>
            <link>https://community.macmillanlearning.com/t5/talk-psych-blog/awareness-at-death/ba-p/19410</link>
            <guid>37848632</guid>
            <pubDate>Wed, 11 Oct 2023 18:48:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://community.macmillanlearning.com/t5/talk-psych-blog/awareness-at-death/ba-p/19410">https://community.macmillanlearning.com/t5/talk-psych-blog/awareness-at-death/ba-p/19410</a>, See on <a href="https://news.ycombinator.com/item?id=37848632">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text" id="bodyDisplay">
			
				
					
					
						<p>Each year, millions of people, including half a million <a href="https://www.sca-aware.org/sca-news/highlights-of-2023-sudden-cardiac-arrest-statistics" target="_blank" rel="noopener nofollow noreferrer">Americans</a>, experience cardiac arrest. With no discernible heartbeat, breathing, or brain activity, they have experienced the medical definition of death, notes <a href="https://nyulangone.org/doctors/1467610337/sam-parnia" target="_blank" rel="noopener nofollow noreferrer">Sam Parnia</a>, the NYU Medical Center’s director of cardiopulmonary resuscitation research.</p><p>Yet, with CPR, some 10 percent survive. Moreover, in Parnia-led <a href="https://pubmed.ncbi.nlm.nih.gov/25301715/" target="_blank" rel="noopener nofollow noreferrer">interviews</a> of 2060 survivors, about 1 in 10 recalled a “transformative” death experience, which often involved a peaceful out-of-body experience of being drawn toward a light. Two percent recalled “‘seeing’ and ‘hearing’ actual events related to their resuscitation.”</p><p><span image-alt="images with man floating skyward and with man walking through tunnel toward light"><img src="https://community.macmillanlearning.com/t5/image/serverpage/image-id/5635i6436190F054CFBDF/image-size/large?v=v2&amp;px=999" role="button" title="Near Death.jpg" alt="Near Death.jpg" li-image-url="https://community.macmillanlearning.com/t5/image/serverpage/image-id/5635i6436190F054CFBDF?v=v2" li-image-display-id="'5635i6436190F054CFBDF'" li-message-uid="'19410'" li-messages-message-image="true" li-bindable="" tabindex="0" li-bypass-lightbox-when-linked="true" li-use-hover-links="false"></span></p><p>Anticipating the next steps in his death-experience research, Parnia invited a dozen of us psychological and medical researchers for a day-long research consultation in 2019. There we offered advice regarding his plans for two unprecedented further studies of recalled experiences of death.</p><p>In the first study, just <span>published</span>, a cardiac arrest at one of 21 participating hospitals alerted a trained researcher to rush to the patient with a small equipment bag. Without interfering with the resuscitation, the researcher attached an EEG recording cap and headphones, then activated a tablet computer.</p><p>Across 567 cardiac arrests—defined as no heartbeat or respiration—53 patients (9.3 percent) survived. Twenty-eight did so with sufficient health to be available for volunteer interviews, yielding three take-home findings.</p><p>First, <em>most of the 53 survivors initially flat-lined on the EEG, but, with continued CPR, recovered brain activity up to 60 minutes later. </em>This result not only encourages first responders to persist, it also suggests the possibility of to-be-recalled cognitive activity in comatose patients.</p><p>Second, <em>6 of the 28 interviewed survivors (21 percent) had a “transcendent recalled experience of death.” </em>This roughly accords with prior studies’ finding that 10 to 15 percent of cardiac arrest survivors report a memorable transcendent conscious experience (which Parnia labels a “recalled experience of death” rather than a “near-death experience”). The 6 survivors reported experiences such as:</p><ul><li><em>Separation from the body: </em>“I found myself above my body.” “I knew that I had died.” “I felt so light and free.” “I was high up in the ceiling of the ward looking down upon the bed.” “I could see the doctors and nurses working over me.” “I perceived and saw everything around me, like in 360 degrees.”</li><li><em>Perception of heading toward a destination:</em> “I experienced going down a tunnel towards a huge bright shining light.”</li><li><em>Reviewing and reevaluating life:</em> “I saw my entire life in great detail.” “I felt so warm, safe, protected and deeply loved.” “My body was dead for two minutes; for me, the time passed as if it were many years.”</li></ul><p>Third, <em>the study enabled an unprecedented objective test of survivors’ recall accuracy. </em>Many have wondered: Have those who recall death experiences—even of happenings during the resuscitation—experienced hallucinations, such as commonly reported with oxygen deprivation or psychedelic drugs? Or are their out-of-body reports of cardiac arrest events factual and verifiable?</p><p>Parnia and his three dozen collaborators creatively devised and implemented a plan to put claims of death-experience recollections to the test. As patients underwent CPR, a tablet computer displayed one of ten visual images, such as an animal, a person, or a monument. When later interviewed, could the 28 survivors report the image displayed during their death experience? If not, could they, when shown the ten possible images, guess which image had been displayed? The result: “Nobody identified the visual image."</p><p><span image-alt="medical staff working in surgery"><img src="https://community.macmillanlearning.com/t5/image/serverpage/image-id/5636iDC208532DFA08959/image-dimensions/345x279?v=v2" width="345" height="279" role="button" title="Near Death 2.png" alt="Near Death 2.png" li-image-url="https://community.macmillanlearning.com/t5/image/serverpage/image-id/5636iDC208532DFA08959?v=v2" li-image-display-id="'5636iDC208532DFA08959'" li-message-uid="'19410'" li-messages-message-image="true" li-bindable="" tabindex="0" li-bypass-lightbox-when-linked="true" li-use-hover-links="false"></span></p><p>During 5 minutes of the CPR, patients also were repeatedly exposed through the headphone audio to the names of 3 fruits: apple, pear, banana. When the 28 survivors were later asked to guess the 3 fruits, how many correctly recalled them? One person. (A chance result? When a colleague invited his psychology students to name 3 fruits, a similar 2 of 50 named an apple, pear, and banana.)</p><p>Although these new results are not what Parnia might have wished, his reporting models science at its best: proposing novel ideas, putting them to the test, and then, with integrity, placing the results in the public domain. Sometimes, as Agatha Christie’s Miss Marple <a href="https://www.goodreads.com/work/quotes/24934140-the-hat-and-the-alibi" target="_blank" rel="noopener nofollow noreferrer">observed,</a> the outcome is unexpected. “But facts are facts, and if one is proved to be wrong, one must just be humble about it and start again.”</p><p>Yet science is a process, and this is but one study, with more to come. At our research consultation, Parnia proposed a second possible method for exposing temporarily brain-dead people to stimuli that might later be recalled. Aortic repair surgery sometimes puts patients under anesthesia, cools the body to 70 degrees, stops the heart, and drains the blood—with flat-lined brain activity for about 40 minutes. Will such functionally dead people sometimes later accurately recall events occurring in the room during their dormancy? What do you think? (Stay tuned: The results of this study are forthcoming, Parnia tells me.)</p><p>Parnia knows of credible-seeming reports of resuscitated patients displaying accurate recall. including one Britisher who, after being left for dead, later recovered and recounted associated events. So he would not be surprised at some accurate recall.</p><p>I, however, would be stunned, for two reasons:</p><ul><li><em>Parapsychology’s null findings. </em>Parnia emphasizes that his scientific exploration of people’s experiences and recollections of death transitions are not parapsychology. Yet parapsychology experiments have also indicated that mind seemingly does not travel out-of-body. Would-be psychics cannot “see” remote happenings, such as cards being drawn in an adjacent room.</li><li><em>Brain-mind science. </em>The entirety of cognitive neuroscience links mind to brain. Every mental event is simultaneously a biological event. No brain, no mind.</li></ul><p>Nevertheless, the data are not done speaking, and sometimes reality surprises us. As even Miss Marple’s more rationalist counterpart Sherlock Holmes <a href="https://www.goodreads.com/quotes/99039-life-is-infinitely-stranger-than-anything-which-the-mind-of" target="_blank" rel="noopener nofollow noreferrer">acknowledged</a>, “Life is infinitely stranger than anything which the mind of man could invent.” Psychological science has offered many <a href="https://community.macmillanlearning.com/t5/talk-psych-blog/psychological-science-full-of-surprises/ba-p/3205" target="_blank">surprising</a>—even shocking—findings. And it surely has more to come.</p><p><span size="2"><em>Afterword: </em>Some may wonder, does the assumption and the evidence of embodied minds threaten various religious understandings of human nature and hopes for life after bodily death? Not at all, argue cognitive neuroscientist Malcolm Jeeves (founder of Britain’s <a href="https://www.theguardian.com/education/ng-interactive/2023/sep/09/best-uk-universities-for-psychology-league-table" target="_blank" rel="noopener nofollow noreferrer">top-rated</a> psychology department) and developmental psychologist Thomas Ludwig. They reflect on the deep implications of brain-mind science in their recent book, <em>Psychological Science and Christian Faith, </em>and offer an alternative to a death-denying dualism. A disembodied immortal soul is Plato’s thinking, they argue, and not the assumption of biblical religion.</span></p><p><span size="2"><em>(For </em><a href="http://www.davidmyers.org/" target="_blank" rel="noopener nofollow noreferrer">David Myers’</a><em> other essays on psychological science and everyday life, visit </em><a href="http://www.talkpsych.com/" target="_blank" rel="noopener nofollow noreferrer">TalkPsych.com</a><em> or check out his new essay collection, </em><a href="https://davidmyers.org/books/how-do-we-know-ourselves" target="_blank" rel="noopener nofollow noreferrer">How Do We Know Ourselves?: Curiosities and Marvels of the Human Mind.</a> <em>Follow him on Twitter: @davidgmyers.)</em></span></p>
					
				
			
			
			
			
			
			
			
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Inverted Transformers Are Effective for Time Series Forecasting (182 pts)]]></title>
            <link>https://arxiv.org/abs/2310.06625</link>
            <guid>37848321</guid>
            <pubDate>Wed, 11 Oct 2023 18:25:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2310.06625">https://arxiv.org/abs/2310.06625</a>, See on <a href="https://news.ycombinator.com/item?id=37848321">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2310.06625.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>The recent boom of linear forecasting models questions the ongoing passion for architectural modifications of Transformer-based forecasters. These forecasters leverage Transformers to model the global dependencies over temporal tokens of time series, with each token formed by multiple variates of the same timestamp. However, Transformer is challenged in forecasting series with larger lookback windows due to performance degradation and computation explosion. Besides, the unified embedding for each temporal token fuses multiple variates with potentially unaligned timestamps and distinct physical measurements, which may fail in learning variate-centric representations and result in meaningless attention maps. In this work, we reflect on the competent duties of Transformer components and repurpose the Transformer architecture without any adaptation on the basic components. We propose iTransformer that simply inverts the duties of the attention mechanism and the feed-forward network. Specifically, the time points of individual series are embedded into variate tokens which are utilized by the attention mechanism to capture multivariate correlations; meanwhile, the feed-forward network is applied for each variate token to learn nonlinear representations. The iTransformer model achieves consistent state-of-the-art on several real-world datasets, which further empowers the Transformer family with promoted performance, generalization ability across different variates, and better utilization of arbitrary lookback windows, making it a nice alternative as the fundamental backbone of time series forecasting.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Yong Liu [<a href="https://arxiv.org/show-email/6d73fe6b/2310.06625">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 10 Oct 2023 13:44:09 UTC (4,053 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Starlink Direct to Cell (652 pts)]]></title>
            <link>https://direct.starlink.com/</link>
            <guid>37848212</guid>
            <pubDate>Wed, 11 Oct 2023 18:18:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://direct.starlink.com/">https://direct.starlink.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37848212">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">




<div>
<h2>UBIQUITOUS COVERAGE</h2>



<div><p>Starlink satellites with&nbsp;Direct to Cell capabilities enable ubiquitous access to texting, calling, and browsing wherever you may be on land, lakes, or coastal waters.</p><p>Direct to Cell will also connect IoT devices with common LTE standards.</p></div>




</div>



<div>
<h2>STAY CONNECTED</h2>



<p>Direct to Cell works with existing LTE phones wherever you can see the sky. No changes to hardware, firmware, or special apps are required, providing seamless access to text, voice, and data.&nbsp;</p>
</div>



<div id="block-illustration-group-block_f14faaa2b72e3dc3e32bd64478a7c7c6">
    

<h2>A cellphone tower in&nbsp;space</h2>



<figure><img decoding="async" loading="lazy" width="1024" height="512" src="https://direct.starlink.com/wp-content/uploads/2023/09/diagram-v2-1024x512.png" alt="Starlink Satellite Network to Unmodified Cell Phones and Starlink Ground Network. Starlink Ground Network to Partner Operator Network to Talk, Text, and Data Service" srcset="https://direct.starlink.com/wp-content/uploads/2023/09/diagram-v2-1024x512.png 1024w, https://direct.starlink.com/wp-content/uploads/2023/09/diagram-v2-300x150.png 300w, https://direct.starlink.com/wp-content/uploads/2023/09/diagram-v2-768x384.png 768w, https://direct.starlink.com/wp-content/uploads/2023/09/diagram-v2-1536x768.png 1536w, https://direct.starlink.com/wp-content/uploads/2023/09/diagram-v2-2048x1024.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>Starlink satellites with Direct to Cell capability&nbsp;have an advanced eNodeB modem onboard that acts like a cellphone tower in space, allowing network integration similar to a standard roaming partner.</p>

  </div>



<div><p><img decoding="async" loading="lazy" width="1728" height="869" alt="" src="https://direct.starlink.com/wp-content/uploads/2023/09/earth.jpg" data-object-fit="cover" srcset="https://direct.starlink.com/wp-content/uploads/2023/09/earth.jpg 1728w, https://direct.starlink.com/wp-content/uploads/2023/09/earth-300x151.jpg 300w, https://direct.starlink.com/wp-content/uploads/2023/09/earth-1024x515.jpg 1024w, https://direct.starlink.com/wp-content/uploads/2023/09/earth-768x386.jpg 768w, https://direct.starlink.com/wp-content/uploads/2023/09/earth-1536x772.jpg 1536w" sizes="(max-width: 1728px) 100vw, 1728px"></p><div>
<h2>ELIMINATE DEAD ZONES​</h2>



<p>Direct to Cell enables connectivity in remote regions, providing peace of mind when customers&nbsp;need it most.&nbsp;</p>
</div></div>



<div><p><img decoding="async" loading="lazy" width="1728" height="866" alt="" src="https://direct.starlink.com/wp-content/uploads/2023/09/Starlink_MountHood_052423000571-1.jpg" data-object-fit="cover" srcset="https://direct.starlink.com/wp-content/uploads/2023/09/Starlink_MountHood_052423000571-1.jpg 1728w, https://direct.starlink.com/wp-content/uploads/2023/09/Starlink_MountHood_052423000571-1-300x150.jpg 300w, https://direct.starlink.com/wp-content/uploads/2023/09/Starlink_MountHood_052423000571-1-1024x513.jpg 1024w, https://direct.starlink.com/wp-content/uploads/2023/09/Starlink_MountHood_052423000571-1-768x385.jpg 768w, https://direct.starlink.com/wp-content/uploads/2023/09/Starlink_MountHood_052423000571-1-1536x770.jpg 1536w" sizes="(max-width: 1728px) 100vw, 1728px"></p><div>
<h2>ENGINEERED BY SPACEX</h2>



<p>SpaceX is leveraging its experience in manufacturing and launching the world’s most advanced rockets and spacecraft to deploy Starlink satellites with the Direct to Cell capability at scale.</p>



<p>Direct to Cell satellites will initially be launched on SpaceX’s Falcon 9 rocket and then Starship. On orbit the satellites will&nbsp;immediately connect over laser backhaul to the Starlink constellation to provide global connectivity.</p>
</div></div>



<div>
<div>
<h2>Global Partners</h2>



<p>Cellular providers using Direct to Cell have access to reciprocal global access in all partner nations.</p>




</div>



<div>
<figure><img decoding="async" loading="lazy" width="1024" height="1024" src="https://direct.starlink.com/wp-content/uploads/2023/09/elon-and-mike-1024x1024.jpg" alt="" srcset="https://direct.starlink.com/wp-content/uploads/2023/09/elon-and-mike-1024x1024.jpg 1024w, https://direct.starlink.com/wp-content/uploads/2023/09/elon-and-mike-300x300.jpg 300w, https://direct.starlink.com/wp-content/uploads/2023/09/elon-and-mike-150x150.jpg 150w, https://direct.starlink.com/wp-content/uploads/2023/09/elon-and-mike-768x768.jpg 768w, https://direct.starlink.com/wp-content/uploads/2023/09/elon-and-mike.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>




		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vine Robots: Learn to Make Your Own (117 pts)]]></title>
            <link>https://www.vinerobots.org/</link>
            <guid>37848115</guid>
            <pubDate>Wed, 11 Oct 2023 18:11:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vinerobots.org/">https://www.vinerobots.org/</a>, See on <a href="https://news.ycombinator.com/item?id=37848115">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="c726ef4" data-element_type="widget" data-widget_type="text-editor.default"><p><span>Vine Robots are soft continuum robots design with low-cost fabrication in mind and for the navigation of difficult environments. Unlike traditional robots, which move through surface contact to walk or run, the vine robot relies on growth for movement. Much like a vine and other plants, the robot has a grounded root, or “base,” and can continually grow as it expands to add material at its tip.</span></p><p><span>Vine robots can be easily assembled and programmed by novices while also having the option to perform complex tasks. They allow users to either pre-program or control the growing robot in real-time as it navigates the environment. You can expect the robot to:</span></p><ul><li><ul><li><ul><li><ul><li><ul><li><span>Traverse rough, sticky, and sharp terrain</span></li><li><span>&nbsp;Grow 100 times its original length</span></li><li><span>&nbsp;Enter gaps one-fourth its original size<span>&nbsp;</span></span></li><li><span>&nbsp;Climb vertically</span></li><li><span>&nbsp;Transport fluids</span></li></ul></li></ul></li></ul></li></ul></li></ul><p><span>As a result, potential applications for the Vine Robot include search and rescue (such as searching for people in a collapsed building), deployable structures (like helical antennas), and medical procedures.</span></p><p><span>Here, you will learn how the robot works and how to make your own.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wordpress.com Now Supports ActivityPub (246 pts)]]></title>
            <link>https://wordpress.com/blog/2023/10/11/activitypub/</link>
            <guid>37847782</guid>
            <pubDate>Wed, 11 Oct 2023 17:47:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wordpress.com/blog/2023/10/11/activitypub/">https://wordpress.com/blog/2023/10/11/activitypub/</a>, See on <a href="https://news.ycombinator.com/item?id=37847782">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
								<p>The fediverse has arrived at WordPress.com. </p>
							</div><div>
				
<p>Exciting times are here for all WordPress.com users! The revolutionary ActivityPub feature is now available across all WordPress.com plans, unlocking a world of engagement and interaction for your blog. Your blogs can now be part of the rapidly expanding fediverse, which enables you to connect with a broader audience and attract more followers.</p>



<p>Let’s dive into what this means for all WordPress.com blogs.</p>



<h2>What is the “fediverse”?</h2>



<p>The fediverse consists of federated platforms like Mastodon, which are networks of independent websites or servers that can communicate with each other while still operating individually. It’s much like email; you can send emails to users with accounts on different services (like Gmail, Yahoo, etc.), yet all of them can interact seamlessly. Similarly, federated platforms enable users to follow, share, and interact with content across different services in a unified network.</p>



<h2>What is the ActivityPub plugin?</h2>



<p>ActivityPub is a WordPress plugin that facilitates seamless integration between your blog and a host of federated platforms, including Mastodon, Pleroma, Friendica, and more. This plugin empowers your readers to follow your blog posts on these platforms.&nbsp;</p>



<p>In addition, replies to your posts from these platforms are automatically turned into comments on your WordPress blog, creating a more interactive and dynamic conversation around your content. Synchronicity for the win!</p>



<h2>Transform your blog into a fediverse profile</h2>



<p>Your WordPress blog can now become a profile for the fediverse. This means your readers can follow you and receive all the latest posts from your blog directly on their preferred platform. More so, they can engage in enriching conversations by replying to your posts, with their replies reflecting as comments on your blog post, creating a synchronized and interactive experience.</p>



<p>On Free, Personal, and Premium sites, you can enter the fediverse through your settings (see how below); for Business and Commerce sites, simply install the <a href="https://wordpress.com/plugins/activitypub">ActivityPub plugin</a> and follow the prompts to set up your profile.&nbsp;&nbsp;&nbsp;&nbsp;</p>



<h2>Getting started is a breeze</h2>


<div>
<figure><a href="https://en-blog.files.wordpress.com/2023/10/image-2.png"><img data-attachment-id="53498" data-permalink="https://wordpress.com/blog/2023/10/11/activitypub/image-2-15/" data-orig-file="https://en-blog.files.wordpress.com/2023/10/image-2.png" data-orig-size="1534,1196" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-image-caption="" data-medium-file="https://en-blog.files.wordpress.com/2023/10/image-2.png?w=300" data-large-file="https://en-blog.files.wordpress.com/2023/10/image-2.png?w=720" width="1534" height="1196" src="https://en-blog.files.wordpress.com/2023/10/image-2.png?w=1024" alt="" srcset="https://en-blog.files.wordpress.com/2023/10/image-2.png?w=1024 1024w, https://en-blog.files.wordpress.com/2023/10/image-2.png 1534w, https://en-blog.files.wordpress.com/2023/10/image-2.png?w=150 150w, https://en-blog.files.wordpress.com/2023/10/image-2.png?w=300 300w, https://en-blog.files.wordpress.com/2023/10/image-2.png?w=768 768w" sizes="(max-width: 1534px) 100vw, 1534px"></a></figure></div>


<ol>
<li>From your blog’s dashboard, go to <em>Settings &gt; Discussion</em> and activate the feature by toggling “Enter the fediverse.”</li>



<li>Make note of your default fediverse profile name. In the example above, it’s the alias openprotocolfanblog.wordpress.com@openprotocolfanblog.wordpress.com. Your alias will be unique to you, of course, and will be far more memorable with a custom domain! (More on that below.)</li>



<li>Follow your new profile on a federated platform, such as Mastodon.</li>



<li>Share your profile name with others so they can follow your blog on federated platforms.</li>
</ol>



<p>Remember, this feature is applicable to <em>new</em> posts only; and it might take up to 15 minutes for new posts to appear on federated platforms.</p>



<h2>Why use a custom domain?</h2>



<figure><a href="https://en-blog.files.wordpress.com/2023/10/fediverse-with-custom-domain.png"><img data-attachment-id="53505" data-permalink="https://wordpress.com/blog/2023/10/11/activitypub/fediverse-with-custom-domain/" data-orig-file="https://en-blog.files.wordpress.com/2023/10/fediverse-with-custom-domain.png" data-orig-size="1534,826" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fediverse-with-custom-domain" data-image-description="" data-image-caption="" data-medium-file="https://en-blog.files.wordpress.com/2023/10/fediverse-with-custom-domain.png?w=300" data-large-file="https://en-blog.files.wordpress.com/2023/10/fediverse-with-custom-domain.png?w=720" width="1534" height="826" src="https://en-blog.files.wordpress.com/2023/10/fediverse-with-custom-domain.png?w=1024" alt="" srcset="https://en-blog.files.wordpress.com/2023/10/fediverse-with-custom-domain.png?w=1024 1024w, https://en-blog.files.wordpress.com/2023/10/fediverse-with-custom-domain.png 1534w, https://en-blog.files.wordpress.com/2023/10/fediverse-with-custom-domain.png?w=150 150w, https://en-blog.files.wordpress.com/2023/10/fediverse-with-custom-domain.png?w=300 300w, https://en-blog.files.wordpress.com/2023/10/fediverse-with-custom-domain.png?w=768 768w" sizes="(max-width: 1534px) 100vw, 1534px"></a></figure>



<p>Upgrading to a domain doesn’t just give your profile a professional touch:</p>



<ul>
<li>A shorter custom domain is simply more memorable than the default name provided.&nbsp;&nbsp;</li>



<li>It ensures your profile is uniquely identifiable, making it easier for users across the fediverse to find and interact with your content.&nbsp;</li>



<li>With a custom domain you can easily move your entire fediverse connection to any host at any time.&nbsp;</li>
</ul>



<h2>Make new connections today!</h2>



<p>Take advantage of this new opportunity to extend your blog’s reach, connect with diverse audiences, and create engaging dialogues. It only takes seconds to enable this simple yet powerful feature on WordPress.com. And remember, upgrading to a domain not only emphasizes your unique identity but also enhances profile portability. So, why wait? Dive in and showcase your content to the world!</p>
<div><hr><p><strong><label for="subscribe-field">Email Newsletter</label></strong></p>

			<div>
			
							<p>
					Join 102.3M other subscribers				</p>
						</div>
			
</div>
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Cloud Spanner is now half the cost of Amazon DynamoDB (298 pts)]]></title>
            <link>https://cloud.google.com/blog/products/databases/announcing-cloud-spanner-price-performance-updates</link>
            <guid>37847454</guid>
            <pubDate>Wed, 11 Oct 2023 17:25:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloud.google.com/blog/products/databases/announcing-cloud-spanner-price-performance-updates">https://cloud.google.com/blog/products/databases/announcing-cloud-spanner-price-performance-updates</a>, See on <a href="https://news.ycombinator.com/item?id=37847454">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="tx2NYc"><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Today, we announced significant price-performance improvements for <a href="https://cloud.google.com/spanner">Cloud Spanner</a>, now providing up to 50% increase in throughput and 2.5 times the storage per node than before, with no change in price. Spanner’s high throughput, virtually unlimited scale, single-digit millisecond latency, five 9s availability SLA, and strong external-consistency semantics are now available at half the cost of Amazon DynamoDB for most workloads. These upgrades will be rolled out to all Spanner customers in the coming months, without the need for reprovisioning, downtime, or any user action.</p><p>Organizations of all sizes and across all industries are increasingly looking to accelerate digital transformation and power AI-driven innovation. However, demands are increasing, while budgets are constrained. Customers choose Spanner to future-proof their applications with high performance and availability at virtually unlimited scale. Spanner is a no-compromise database for relational and non-relational workloads that removes stress from managing databases with zero-touch maintenance. As data volumes grow and applications demand more from their operational databases, customers seek cost-optimal ways to support that growth.</p><p>The price-performance changes we announced today build on a track record of continuous improvements to increase value, enhance performance, and lower costs. Additionally, Spanner delivers predictable single-digit milliseconds latencies for strongly-consistent reads and writes across multiple availability zones in the same region. Superior price-performance, familiar SQL, no-maintenance downtime, and a five 9s of availability SLA make Spanner an excellent choice not just for relational data, but also for read-heavy key-value workloads. With these changes, Spanner now offers up to 2x better read throughput per dollar compared to Amazon DynamoDB for similar workloads.</p><p>Spanner is used ubiquitously inside of Google, supporting services such as; Ads, Gmail and <a href="https://cloud.google.com/blog/products/databases/google-photos-builds-user-experience-on-spanner">Photos</a>. According to the Amazon <a href="https://aws.amazon.com/blogs/aws/prime-day-2023-powered-by-aws-all-the-numbers/" target="_blank">Prime Day blog post</a>, DynamoDB processes 126 million queries per second at peak. Spanner on the other hand processes 3 billion queries per second at peak, which is more than 20x higher, and has more than 12 exabytes of data under management.</p><p>Cloud Spanner's new price-performance improvements make it possible to grow more cost effectively by optimizing both compute and storage:</p><ul><li><b>Compute:</b> Thanks to the 50% throughput improvement, customers can leverage Spanner for their relational and key-value workloads in a cost effective way.</li><li><b>Storage:</b> Each Spanner node can now accommodate 10TB of storage, compared to 4TB previously. This enables customers to cost effectively store and manage data. Even with the increased capacity, Spanner users still only pay for the storage they actually use.</li></ul><p>In other words, Spanner customers now have a lot more flexibility in optimizing their Spanner environments.</p><p><i>"Spanner is an important component for Uber's essential operations. As we scale and expand our global footprint, Spanner's scalability &amp; low operational cost is invaluable. Prior to integrating Spanner, our data management framework demanded a lot of oversight and operational effort, escalating both complexity and expenditure. Traditional workarounds like sharding and eventual consistency also posed barriers to development speed. The adoption of Spanner streamlined operational costs, improved overall reliability, and strengthened overall value by providing better throughput and performance for the same price.”</i> - Ankit Srivastava, Distinguished Engineer, Uber</p><p><i>“Spanner's recent performance improvements have been a welcome change for CERC. With the increase in throughput and storage per node, we've been able to improve our operational efficiency. As we deliver transformative experiences to our customer, a highly reliable, scalable and cost effective database like Spanner is key to our strategy."</i> - Andre da Costa Silva, CIO, CERC</p><p>Cloud Spanner's price-performance improvements are now available in select <a href="https://cloud.google.com/spanner/docs/performance">regional and multi-region instance configurations</a>, with all other configurations to follow. Storage upgrades will start rolling out in the coming months. You do not need to do anything to take advantage of these improvements, and you will continue to be billed at your current rate. <a href="https://goo.gle/SpannerDatabaseUnlimited" target="_blank">Learn more</a> about what makes Spanner unique and how it’s being used today. Or <a href="https://cloud.google.com/spanner/docs/free-trial-instance">try it yourself for free</a> for 90 days, or for as little as $65 USD/month for a production-ready instance that grows with your business, without downtime or disruptive re-architecture.</p></span></section><section><span>Posted in</span><ul><li><a href="https://cloud.google.com/blog/products/databases" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/databases" track-metadata-module="tag list" track-metadata-module_headline="posted in">Databases</a></li><li><a href="https://cloud.google.com/blog/products/spanner" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/spanner" track-metadata-module="tag list" track-metadata-module_headline="posted in">Spanner</a></li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to legally pirate every font (305 pts)]]></title>
            <link>https://blog.willdepue.com/how-to-legally-pirate-all-fonts-in-an-afternoon</link>
            <guid>37846471</guid>
            <pubDate>Wed, 11 Oct 2023 16:21:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.willdepue.com/how-to-legally-pirate-all-fonts-in-an-afternoon">https://blog.willdepue.com/how-to-legally-pirate-all-fonts-in-an-afternoon</a>, See on <a href="https://news.ycombinator.com/item?id=37846471">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post_body_2035180"><p>I really love good fonts. I recently encountered the familiar moral dilemma of a building a project that begged for a better, licensed font while not wanting to burn hundreds of dollars on something I’ll only care about for a week. In this, I jumped down a rabbit hole to try to answer the question of ‘how bad it actually is to use unlicensed fonts on the web.’</p><p>To my surprise here, US copyright law doesn’t actually allow for copyright of the individual glyphs (the lines, curves, points, etc.), so font makers instead usually rely on the copyright of the font file itself, which can be copyrighted as unique software! Unsurprisingly, there’s lots of complexity to how this copyright works (perhaps intentionally). Here’s my understanding:</p><hr><p>There’s a long-standing standard, dating back before the digital age, that typefaces are “utilitarian and functional” technologies and therefore cannot be copyrighted in and of themselves. Typeface designs have been traditionally seen as “ideas or systems” that are used for representing letters and numbers, rather than as unique expressions or artworks.</p><p>Instead, most type foundries protect their fonts by copyrighting the font files themselves, which has been allowed under the notion that there is specific creative effort required in creating the software itself and the different strategies to render the font at different scales, print sizes, etc.</p><p>Very rarely, font makers have been granted design patents for their work if deemed innovative or so creative as to merit such. These are relatively uncommon as they are more rarely granted, as well as only lasting 15 years before permanently entering public domain (compared to the ability to infinitely renew trademarks or the 95 years or author lifetime + 70 granted for other copyrighted materials).</p><p>This doesn’t mean that trademarks that use a certain font can’t be protected, though. Obviously, you can’t copy the CocaCola logo design, but further distinct usage of a font can also be trademarked (like Off-White™, with its famously obsessive use of Helvetica).</p><p>You also still can’t buy a font, modify it, and send it to all your friends. Most fonts come with licenses that prohibit you from copying, modifying, creating derivative works. Since you’re entering into a legal agreement with the type foundry themselves, they can put whatever limits on how you can use the font, regardless of local copyright law. For an example, check out <a href="https://cdn.berkeleygraphics.com/static/legal/licenses/developer-license.pdf">Berkeley Graphics’ license</a>.</p><p>The key point here is that the <strong>shape of the glyphs themselves</strong>, for example, non-trademarked text posted on advertisements or products with printed text, are not copyrightable. So long as you’re not stealing the creative work, like the advertisement, itself, the shape of each letter is in the public domain.</p><hr><p>This got me thinking, as all things do, on whether I could simply scrape the internet for public, non-creative, non-trademarked use of fonts (of which there is lots and lots of content and only 128 or so characters in each <a href="https://en.wikipedia.org/wiki/Latin_Extended-A">Unicode character set</a>) which I could use to reconstruct every licensed font in existence.</p><p>Only problem is that it’s not that simple. Fonts are exceedingly complex. You’ll know that the fact that the average font just ‘looks right’ is absolutely magical if you’ve ever tried to create your own font. Mainly, this is due to good <a href="https://en.wikipedia.org/wiki/Kerning">kerning</a>, the individual spacing between each letter and another. It might come as a surprise that not only does every character have different whitespace between it and other characters, but each actually has unique whitespace between it and every pair of possible following characters.</p><div id="posthaven_gallery[2059798]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079747/DrUbvIpe8FgeAw8_WxpdDW49HfI/medium_Kerning_EN.svg.png" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079747/DrUbvIpe8FgeAw8_WxpdDW49HfI/medium_Kerning_EN.svg.png" data-medium-width="800" data-medium-height="557" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079747/DrUbvIpe8FgeAw8_WxpdDW49HfI/large_Kerning_EN.svg.png" data-large-width="1200" data-large-height="835" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079747/DrUbvIpe8FgeAw8_WxpdDW49HfI/thumb_Kerning_EN.svg.png" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079747/DrUbvIpe8FgeAw8_WxpdDW49HfI/xlarge_Kerning_EN.svg.png" data-xlarge-width="2400" data-xlarge-height="1670" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079747/DrUbvIpe8FgeAw8_WxpdDW49HfI/Kerning_EN.svg.png" data-orig-width="2560" data-orig-height="1781" data-posthaven-id="3079747">
        </p>
          
        </div>
<p>If I’m going to do this correctly, I’ll need to scrape the internet not for all individual characters of a font, but for all possible pairs of characters. That’s 16256 different combinations per font. Thank god the internet is just pretty big.</p><p>There’s also lots of other different asterisks here (spacing, ligatures, handling numbers, etc.) but for now I’m just going to focus on getting the pipeline working.</p><p>I’ve started with a set of simple images of a font that I would want to replicate, then use Meta’s <a href="https://segment-anything.com/">Segment Anything Model</a> (for no reason besides I already had it setup on my computer) to select and cut out each individual character. We’re only working with black and white images with none/low background noise such that converting from pixels to curves is fairly trivial.</p><div id="posthaven_gallery[2059796]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079745/UHF6RPs55wx8VsSi1SfRReMWF68/medium_Screen_Shot_2023-10-10_at_10.52.44_PM.png" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079745/UHF6RPs55wx8VsSi1SfRReMWF68/medium_Screen_Shot_2023-10-10_at_10.52.44_PM.png" data-medium-width="800" data-medium-height="619" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079745/UHF6RPs55wx8VsSi1SfRReMWF68/large_Screen_Shot_2023-10-10_at_10.52.44_PM.png" data-large-width="1200" data-large-height="928" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079745/UHF6RPs55wx8VsSi1SfRReMWF68/thumb_Screen_Shot_2023-10-10_at_10.52.44_PM.png" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079745/UHF6RPs55wx8VsSi1SfRReMWF68/xlarge_Screen_Shot_2023-10-10_at_10.52.44_PM.png" data-xlarge-width="1792" data-xlarge-height="1386" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079745/UHF6RPs55wx8VsSi1SfRReMWF68/Screen_Shot_2023-10-10_at_10.52.44_PM.png" data-orig-width="1792" data-orig-height="1386" data-posthaven-id="3079745">
        </p>
          
        </div>
        <div id="posthaven_gallery[2059797]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079746/Xr7nHzOt15NjoVIp9i3sm1XBkTU/medium_Screen_Shot_2023-10-10_at_11.38.11_PM.png" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079746/Xr7nHzOt15NjoVIp9i3sm1XBkTU/medium_Screen_Shot_2023-10-10_at_11.38.11_PM.png" data-medium-width="800" data-medium-height="168" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079746/Xr7nHzOt15NjoVIp9i3sm1XBkTU/large_Screen_Shot_2023-10-10_at_11.38.11_PM.png" data-large-width="1022" data-large-height="214" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079746/Xr7nHzOt15NjoVIp9i3sm1XBkTU/thumb_Screen_Shot_2023-10-10_at_11.38.11_PM.png" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079746/Xr7nHzOt15NjoVIp9i3sm1XBkTU/xlarge_Screen_Shot_2023-10-10_at_11.38.11_PM.png" data-xlarge-width="1022" data-xlarge-height="214" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079746/Xr7nHzOt15NjoVIp9i3sm1XBkTU/Screen_Shot_2023-10-10_at_11.38.11_PM.png" data-orig-width="1022" data-orig-height="214" data-posthaven-id="3079746">
        </p>
          
        </div>
<p>Now that I have individual character PNGs, I’ll just boost the contrast just to be safe. You can run this in the command line pretty much:</p><p><code>convert input_char.png -contrast output_char.png</code></p><p>Once we’re sure we have high contrast images, we can use <em>cutting edge computer vision AI ML technology</em> by running software first released in 2001:</p><p><code>potrace input.png -s -o output.svg</code></p><p>Now that we have the SVGs, FontForge has an excellent python package for programmatically generating fonts.</p><pre><code>import fontforge

svgs = [...]

font = fontforge.font()

for unicode, letter in svgs:
	glyph = font.createChar(unicode_val, letter)
	glyph.importOutlines(f'{letter}.svg')
	glyph.autoWidth()
 
font.familyname = 'NotHelvetica'
font.fullname = 'NotHelvetica'
font.generate('NotHelvetica.ttf')
</code></pre><p>And there you have it! A complete bastardization of the source font, lacking proper kerning, metadata, em size, bitmaps, ligatures, x-height, etc.</p><p>If you were going to try to get kerning correct here, the best process might be something like collecting and splitting all letter pairs, then using OpenCV to find the distance from each character’s edges to calculate the kerning value.</p><pre><code>import cv2
import fontforge

def get_kerning(image_path):
	img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
	_, thresh = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV)
	contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
	contours.sort(key=lambda x: cv2.boundingRect(x)[0])
	x1, y1, w1, h1 = cv2.boundingRect(contours[0])
	x2, y2, w2, h2 = cv2.boundingRect(contours[1])
	kerning_value = x2 - (x1 + w1)
	return kerning_value

characters = [...]
font = ...

for char_1 in characters:
    for char_2 in characters:
        kerning_value = get_kerning_from_image(f'{char1}-{char2}.png')
        font[char1].addPosSub('kern', char2, kerning_value)
</code></pre><p>In terms of finding a dataset of images of fonts, I’d look into the large existing internet datasets out there. For example, I did a quick search of LAION-5B and there’s infinite images for any given font as a prompt, though there would be work needed to verify that all images wouldn’t fall under improper copyright.</p><div id="posthaven_gallery[2059794]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079743/w29pj868SSvrCmzL9hRzzecSOeU/medium_Screen_Shot_2023-10-10_at_11.09.00_PM.png" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079743/w29pj868SSvrCmzL9hRzzecSOeU/medium_Screen_Shot_2023-10-10_at_11.09.00_PM.png" data-medium-width="800" data-medium-height="558" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079743/w29pj868SSvrCmzL9hRzzecSOeU/large_Screen_Shot_2023-10-10_at_11.09.00_PM.png" data-large-width="1200" data-large-height="837" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079743/w29pj868SSvrCmzL9hRzzecSOeU/thumb_Screen_Shot_2023-10-10_at_11.09.00_PM.png" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079743/w29pj868SSvrCmzL9hRzzecSOeU/xlarge_Screen_Shot_2023-10-10_at_11.09.00_PM.png" data-xlarge-width="2400" data-xlarge-height="1675" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079743/w29pj868SSvrCmzL9hRzzecSOeU/Screen_Shot_2023-10-10_at_11.09.00_PM.png" data-orig-width="3330" data-orig-height="2324" data-posthaven-id="3079743">
        </p>
          
        </div>
        <div id="posthaven_gallery[2059795]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079744/05GaoCVYPv39DxeBLbQDMfI11sw/medium_Screen_Shot_2023-10-10_at_11.20.03_PM.png" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079744/05GaoCVYPv39DxeBLbQDMfI11sw/medium_Screen_Shot_2023-10-10_at_11.20.03_PM.png" data-medium-width="800" data-medium-height="558" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079744/05GaoCVYPv39DxeBLbQDMfI11sw/large_Screen_Shot_2023-10-10_at_11.20.03_PM.png" data-large-width="1200" data-large-height="837" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079744/05GaoCVYPv39DxeBLbQDMfI11sw/thumb_Screen_Shot_2023-10-10_at_11.20.03_PM.png" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079744/05GaoCVYPv39DxeBLbQDMfI11sw/xlarge_Screen_Shot_2023-10-10_at_11.20.03_PM.png" data-xlarge-width="2400" data-xlarge-height="1675" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3079744/05GaoCVYPv39DxeBLbQDMfI11sw/Screen_Shot_2023-10-10_at_11.20.03_PM.png" data-orig-width="3330" data-orig-height="2324" data-posthaven-id="3079744">
        </p>
          
        </div>
<p>I’m not very interested in carrying out this project in full for somewhat obvious reasons (somewhat significantly being disinterested in spending tens of hours collecting and labeling data now that I know it works). As a big fan of typography in general it’s pretty obviously wrong that fonts not be able to be claimed as creative work that deserves to be copyrighted, though I can see how fonts used to play a far more essential and utilitarian role in society. Unfortunately, it seems that this is pretty much <a href="https://en.wikipedia.org/wiki/Black_letter_law">black-letter law</a> at this point and there isn’t much hope for it changing in the future. If any brave souls are interested in legally pirating all existing fonts and being taken to court, I think you’d likely be doing a service to society here by challenging this ruling.</p><p>Final reminder that I’m not a lawyer and have no clue if anything I said is actually correct, so none of this is legal advice and I strongly recommend you go talk to a lawyer before attempting anything here. I’d also strongly emphasize the importance of supporting the incredible work behind your favorite typefaces by purchasing fonts directly, I definitely do not advocate ever for stealing anyone’s work.</p><p>Thanks for reading!</p><p>— Will DePue (<a href="mailto:will@depue.net" title="Link: mailto:will@depue.net">will@depue.net</a>)</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[California Right to Repair Signed into Law (193 pts)]]></title>
            <link>https://www.ifixit.com/News/84491/california-right-to-repair-signed-into-law</link>
            <guid>37846464</guid>
            <pubDate>Wed, 11 Oct 2023 16:20:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ifixit.com/News/84491/california-right-to-repair-signed-into-law">https://www.ifixit.com/News/84491/california-right-to-repair-signed-into-law</a>, See on <a href="https://news.ycombinator.com/item?id=37846464">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<p>Today marks a monumental step forward in the Right to Repair movement. We’re elated to announce that Governor Gavin Newsom has officially signed the California Right to Repair Act, SB 244, into law. This groundbreaking legislation <a href="https://www.ifixit.com/News/81914/california-just-became-the-third-state-to-pass-electronics-right-to-repair">passed the legislature almost unanimously</a> last month. It has been championed by state senator Susan Talamantes Eggman and is cosponsored by iFixit, along with our colleagues in the more-fixable-stuff fight, <a href="https://pirg.org/california/">CALPIRG</a> (the California Public Interest Research Group), and <a href="https://www.cawrecycles.org/">Californians Against Waste</a>.</p>



<figure><img decoding="async" fetchpriority="high" width="1536" height="998" src="https://valkyrie.cdn.ifixit.com/media/2023/10/10141908/Governor-Newsom-Signing-Photo-1536x998-1.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2023/10/10141908/Governor-Newsom-Signing-Photo-1536x998-1.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2023/10/10141908/Governor-Newsom-Signing-Photo-1536x998-1-1385x900.jpg 1385w" sizes="(max-width: 1536px) 100vw, 1536px"></figure>



<p>“This is a victory for consumers and the planet, and it just makes sense,” said Jenn Engstrom, state director of CALPIRG. “Right now, we mine the planet’s precious minerals, use them to make amazing phones and other electronics, ship these products across the world, and then toss them away after just a few years’ use. What a waste. We should make stuff that lasts and be able to fix our stuff when it breaks, and now thanks to years of advocacy, Californians will finally be able to, with the Right to Repair.”&nbsp;</p>



<p>The tech revolution started here in California, so it’s appropriate that we’re working to fix the problems of Big Tech here, too. With access to original parts, tools, and documentation, independent repair shops will be able to compete again. And Californians across the state—accounting for about <a href="https://www.ppic.org/publication/californias-population/">1 out of every 8 Americans</a>—will be able to fix things however they see fit.</p>



<h2>California Raises the Bar</h2>



<p>With California’s new law, the Golden State joins <a href="https://www.ifixit.com/News/75965/minnesotas-new-right-to-repair-law-will-give-the-whole-world-repair-manuals">Minnesota</a> and <a href="https://www.ifixit.com/News/70515/new-york-passes-historic-right-to-repair-bill">New York</a>, representing nearly <a href="https://www.infoplease.com/us/states/state-population-by-rank">20% of the US population</a>, in guaranteeing people more control over their electronic devices. This bill goes above and beyond those laws, mandating manufacturers to keep repair materials available for up to seven years, ensuring the longevity of products and reducing electronic waste.</p>



<ul>
<li><strong>Covered products</strong>: all electronic and appliance products that cost $50 or more sold in California after July 1, 2021 (everything in Section 9801 of the Business and Professions code, which was just updated this session in another bill, <a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB814">SB 814</a>)</li>



<li><strong>Effective date</strong>: July 1, 2024</li>



<li><strong>Difference from other states</strong>: includes 3 years of parts, tools, and documentation support for products that cost $50-$99.99; 7 years for products $100+</li>



<li><strong>Exemptions</strong>: game consoles, alarm systems, agricultural and forestry equipment (everything on <a href="https://law.justia.com/codes/california/2022/code-bpc/division-8/chapter-28/section-22900/">this list</a>)</li>
</ul>



<p>“Replacing expensive electronics and appliances at an ever-quickening pace is not only a financial burden on consumers but also drives unsustainable mining and extraction that has a tremendous environmental impact up and down the supply chain,” said Nick Lapis, Director of Advocacy for Californians Against Waste. “My hope is that, with the passage of SB 244, California will foster a thriving market for repair businesses and secondhand sales that will make repair the norm, not the exception.”</p>



<figure><img decoding="async" width="1536" height="1536" src="https://valkyrie.cdn.ifixit.com/media/2023/10/10141951/calpirg_e-waste_eggman-1536x1536-1.jpg" alt="" srcset="https://valkyrie.cdn.ifixit.com/media/2023/10/10141951/calpirg_e-waste_eggman-1536x1536-1.jpg 1536w, https://valkyrie.cdn.ifixit.com/media/2023/10/10141951/calpirg_e-waste_eggman-1536x1536-1-150x150.jpg 150w, https://valkyrie.cdn.ifixit.com/media/2023/10/10141951/calpirg_e-waste_eggman-1536x1536-1-900x900.jpg 900w" sizes="(max-width: 1536px) 100vw, 1536px"></figure>



<p>Although the Right to Repair movement sees this signature as a significant milestone, we are disheartened by Governor Newsom’s <a href="https://www.gov.ca.gov/wp-content/uploads/2023/10/SB-271-Veto.pdf">decision to veto Senator Dodd’s companion Right to Repair powered wheelchair bill</a> on October 7, citing insurance billing complexities. The need for an accessible approach to repair is evident, and we remain hopeful that the next legislative session will expand on product categories and address issues like <a href="https://www.ifixit.com/News/82867/iphone-15-teardown-reveals-software-lockdown">parts pairing</a>, electric wheelchairs, and e-bike software.</p>



<p>While we celebrate today’s victory, the fight continues. The bill, though robust, still allows manufacturers certain leeways like parts pairing. </p>



<figure><blockquote><p>We won’t stop advocating for more fixable stuff. But today, California has made a colossal leap forward towards a repairable future</p><cite>Kyle Wiens, iFixit CEO</cite></blockquote></figure>



<p>As we push forward, we aspire for a future where more states and countries adopt similar measures. We dream of a world where repair is not an exception but the norm.</p>



<p>Senator Eggman summed it up perfectly: “I’m thrilled that the Governor has signed the Right to Repair Act into law. As I’ve said all along, I’m so grateful to the advocates fueling this movement with us for the past six years, and the manufacturers that have come along to support Californians’ Right to Repair. This is a common sense bill that will help small repair shops, give choice to consumers, and protect the environment.”</p>



<p>If you want to get involved with the Right to Repair movement, join your <a href="https://www.ifixit.com/right-to-repair-action">local advocacy network</a>.</p>
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[M2 Ultra can run 128 streams of Llama 2 7B in parallel (221 pts)]]></title>
            <link>https://github.com/ggerganov/llama.cpp/pull/3228</link>
            <guid>37846387</guid>
            <pubDate>Wed, 11 Oct 2023 16:15:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ggerganov/llama.cpp/pull/3228">https://github.com/ggerganov/llama.cpp/pull/3228</a>, See on <a href="https://news.ycombinator.com/item?id=37846387">Hacker News</a></p>
<div id="readability-page-1" class="page"><div disabled="" sortable="">
          <p dir="auto">I couldn't get the <code>./bin/parallel</code> external alternative-prompt file option to work using <code>-f file.txt</code> so I've inserted a few lines into <code>parallel.cpp</code> to make it run. I am not a <code>C/C++</code> specialist so it probably won't pass any style tests (code at the end), but it does run on my <strong>M2 MAX 32GB</strong> and <strong>MacOS Sonoma 14.0</strong> from</p>
<div data-snippet-clipboard-copy-content="% ./build/bin/parallel -m ./models/llama-2-13b/ggml-model-q8_0.gguf -f &quot;ParallelQuestions.txt&quot; -n 128 -t 1 -c 8192 -s 4321 -ngl 100 -np 16 -ns 32 -cb"><pre><code>% ./build/bin/parallel -m ./models/llama-2-13b/ggml-model-q8_0.gguf -f "ParallelQuestions.txt" -n 128 -t 1 -c 8192 -s 4321 -ngl 100 -np 16 -ns 32 -cb
</code></pre></div>
<p dir="auto">A plain text file like this below saved into <code>/build/ParallelQuestions.txt</code> is then read in generically by <code>common.cpp</code> (with no alterations to the code) and transferred to replace the default <code>k_prompts</code> inside <code>parallel.cpp</code>.</p>
<div data-snippet-clipboard-copy-content="What do you know about Hobbits?
What is quantum field theory?
Why did the chicken cross the road?
Who is the president of the United States?
How do I run CMake on MacOS?
Do you agree that C++ is a really finicky language compared with Python3?
Is it a good idea to invest in technology?
Do you like Wagner's Ring?
Do you think this file input option is really neat?
What should we all do about climate change?"><pre><code>What do you know about Hobbits?
What is quantum field theory?
Why did the chicken cross the road?
Who is the president of the United States?
How do I run CMake on MacOS?
Do you agree that C++ is a really finicky language compared with Python3?
Is it a good idea to invest in technology?
Do you like Wagner's Ring?
Do you think this file input option is really neat?
What should we all do about climate change?
</code></pre></div>
<p dir="auto">Producing (sample only) output</p>
<div data-snippet-clipboard-copy-content="Now printing the k_prompts loaded from ParallelQuestions.txt that replace the default questions.

What do you know about Hobbits?
What is quantum field theory?
Why did the chicken cross the road?
Who is the president of the United States?
How do I run CMake on MacOS?
Do you agree that C++ is a really finicky language compared with Python3?
Is it a good idea to invest in technology?
Do you like Wagner's Ring?
Do you think this file input option is really neat?
What should we all do about climate change?


main: Simulating parallel requests from clients:
main: Evaluating the system prompt ...

Processing requests ...

main: clearing the KV cache
Client   0, seq    0, started decoding ...
Client   1, seq    1, started decoding ...
Client   2, seq    2, started decoding ...
Client   3, seq    3, started decoding ...
Client   4, seq    4, started decoding ...
Client   5, seq    5, started decoding ...
Client   6, seq    6, started decoding ...
Client   7, seq    7, started decoding ...
Client   8, seq    8, started decoding ...
Client   9, seq    9, started decoding ...
Client  10, seq   10, started decoding ...
Client  11, seq   11, started decoding ...
Client  12, seq   12, started decoding ...
Client  13, seq   13, started decoding ...
Client  14, seq   14, started decoding ...
Client  15, seq   15, started decoding ...
Client   7, seq    7/ 32, prompt   14 t, response   11 t, time  2.62 s, speed  9.54 t/s, cache miss 0  
Input:    Who is the president of the United States?
Response: The current President of the United States is Donald Trump.

Client  14, seq   14/ 32, prompt   14 t, response   11 t, time  2.63 s, speed  9.52 t/s, cache miss 0  
Input:    Who is the president of the United States?
Response: The current President of the United States is Donald Trump.

Client   7, seq   16, started decoding ...
Client  14, seq   17, started decoding ...
Client   7, seq   16/ 32, prompt   14 t, response   13 t, time  2.39 s, speed 11.28 t/s, cache miss 0  
Input:    Why did the chicken cross the road?
Response: The chicken crossed the road to get to the other side.

Client   7, seq   18, started decoding ...
Client  12, seq   12/ 32, prompt   14 t, response   30 t, time  5.87 s, speed  7.49 t/s, cache miss 0  
Input:    Who is the president of the United States?
Response: The current president of the United States is Joe Biden. He was sworn into office on January 20, 2021.

Client  12, seq   19, started decoding ...
Client  10, seq   10/ 32, prompt   13 t, response   35 t, time  6.73 s, speed  7.13 t/s, cache miss 0  
Input:    What should we all do about climate change?
Response: We should all work together to reduce our carbon footprint. We can do this by reducing our energy consumption, recycling more, and using public transportation whenever possible.

Client  10, seq   20, started decoding ...
Client   1, seq    1/ 32, prompt   14 t, response   42 t, time  7.93 s, speed  7.06 t/s, cache miss 0  
Input:    Why did the chicken cross the road?
Response: The chicken crossed the road to get to the other side. It is a classic joke that has been around for many years and is often used as an example of a riddle or paradox.

Client   1, seq   21, started decoding ...
Client  14, seq   17/ 32, prompt   14 t, response   36 t, time  6.36 s, speed  7.86 t/s, cache miss 0  
Input:    Who is the president of the United States?
Response: The president of the United States is Joe Biden. He was elected in November 2020 and took office on January 20, 2021.

Client  14, seq   22, started decoding ...
Client   0, seq    0/ 32, prompt   16 t, response   49 t, time  9.17 s, speed  7.09 t/s, cache miss 0  
Input:    Do you think this file input option is really neat?
Response: Yes, I think this file input option is really neat. It allows you to easily upload files from your computer or other devices and view them in the browser. This can be very useful when sharing large files or working with multiple documents at once.

Client   0, seq   23, started decoding ...
Client  10, seq   20/ 32, prompt   13 t, response   14 t, time  2.62 s, speed 10.29 t/s, cache miss 0  
Input:    Do you like Wagner's Ring?
Response: I do not know what &quot;Wagner's Ring&quot; is.

Client  10, seq   24, started decoding ...
Client   9, seq    9/ 32, prompt   22 t, response   56 t, time 10.42 s, speed  7.49 t/s, cache miss 0  
Input:    Do you agree that C++ is a really finicky language compared with Python3?
Response: I cannot agree or disagree with that statement because it is subjective and depends on the person who is asking the question. Some people may find C++ to be finicky, while others may not have any problems with it. Ultimately, it comes down to personal preference."><pre><code>Now printing the k_prompts loaded from ParallelQuestions.txt that replace the default questions.

What do you know about Hobbits?
What is quantum field theory?
Why did the chicken cross the road?
Who is the president of the United States?
How do I run CMake on MacOS?
Do you agree that C++ is a really finicky language compared with Python3?
Is it a good idea to invest in technology?
Do you like Wagner's Ring?
Do you think this file input option is really neat?
What should we all do about climate change?


main: Simulating parallel requests from clients:
main: Evaluating the system prompt ...

Processing requests ...

main: clearing the KV cache
Client   0, seq    0, started decoding ...
Client   1, seq    1, started decoding ...
Client   2, seq    2, started decoding ...
Client   3, seq    3, started decoding ...
Client   4, seq    4, started decoding ...
Client   5, seq    5, started decoding ...
Client   6, seq    6, started decoding ...
Client   7, seq    7, started decoding ...
Client   8, seq    8, started decoding ...
Client   9, seq    9, started decoding ...
Client  10, seq   10, started decoding ...
Client  11, seq   11, started decoding ...
Client  12, seq   12, started decoding ...
Client  13, seq   13, started decoding ...
Client  14, seq   14, started decoding ...
Client  15, seq   15, started decoding ...
Client   7, seq    7/ 32, prompt   14 t, response   11 t, time  2.62 s, speed  9.54 t/s, cache miss 0  
Input:    Who is the president of the United States?
Response: The current President of the United States is Donald Trump.

Client  14, seq   14/ 32, prompt   14 t, response   11 t, time  2.63 s, speed  9.52 t/s, cache miss 0  
Input:    Who is the president of the United States?
Response: The current President of the United States is Donald Trump.

Client   7, seq   16, started decoding ...
Client  14, seq   17, started decoding ...
Client   7, seq   16/ 32, prompt   14 t, response   13 t, time  2.39 s, speed 11.28 t/s, cache miss 0  
Input:    Why did the chicken cross the road?
Response: The chicken crossed the road to get to the other side.

Client   7, seq   18, started decoding ...
Client  12, seq   12/ 32, prompt   14 t, response   30 t, time  5.87 s, speed  7.49 t/s, cache miss 0  
Input:    Who is the president of the United States?
Response: The current president of the United States is Joe Biden. He was sworn into office on January 20, 2021.

Client  12, seq   19, started decoding ...
Client  10, seq   10/ 32, prompt   13 t, response   35 t, time  6.73 s, speed  7.13 t/s, cache miss 0  
Input:    What should we all do about climate change?
Response: We should all work together to reduce our carbon footprint. We can do this by reducing our energy consumption, recycling more, and using public transportation whenever possible.

Client  10, seq   20, started decoding ...
Client   1, seq    1/ 32, prompt   14 t, response   42 t, time  7.93 s, speed  7.06 t/s, cache miss 0  
Input:    Why did the chicken cross the road?
Response: The chicken crossed the road to get to the other side. It is a classic joke that has been around for many years and is often used as an example of a riddle or paradox.

Client   1, seq   21, started decoding ...
Client  14, seq   17/ 32, prompt   14 t, response   36 t, time  6.36 s, speed  7.86 t/s, cache miss 0  
Input:    Who is the president of the United States?
Response: The president of the United States is Joe Biden. He was elected in November 2020 and took office on January 20, 2021.

Client  14, seq   22, started decoding ...
Client   0, seq    0/ 32, prompt   16 t, response   49 t, time  9.17 s, speed  7.09 t/s, cache miss 0  
Input:    Do you think this file input option is really neat?
Response: Yes, I think this file input option is really neat. It allows you to easily upload files from your computer or other devices and view them in the browser. This can be very useful when sharing large files or working with multiple documents at once.

Client   0, seq   23, started decoding ...
Client  10, seq   20/ 32, prompt   13 t, response   14 t, time  2.62 s, speed 10.29 t/s, cache miss 0  
Input:    Do you like Wagner's Ring?
Response: I do not know what "Wagner's Ring" is.

Client  10, seq   24, started decoding ...
Client   9, seq    9/ 32, prompt   22 t, response   56 t, time 10.42 s, speed  7.49 t/s, cache miss 0  
Input:    Do you agree that C++ is a really finicky language compared with Python3?
Response: I cannot agree or disagree with that statement because it is subjective and depends on the person who is asking the question. Some people may find C++ to be finicky, while others may not have any problems with it. Ultimately, it comes down to personal preference.
</code></pre></div>
<p dir="auto">The additional lines of code (does C++ not have a .split("\n") predefined function?):</p>
<div data-snippet-clipboard-copy-content="// Define a split string function to ...
    std::vector<std::string> splitString(const std::string&amp; input, char delimiter) {
        std::vector<std::string> tokens;
        std::istringstream stream(input);
        std::string token;
        while (std::getline(stream, token, delimiter)) {
            tokens.push_back(token);
        }
        return tokens;
    }"><pre><code>// Define a split string function to ...
    std::vector&lt;std::string&gt; splitString(const std::string&amp; input, char delimiter) {
        std::vector&lt;std::string&gt; tokens;
        std::istringstream stream(input);
        std::string token;
        while (std::getline(stream, token, delimiter)) {
            tokens.push_back(token);
        }
        return tokens;
    }
</code></pre></div>
<p dir="auto">And then somewhere suitable inside <code>main()</code> and before <code>k_prompts</code> is used, in my case roughly at line 125:</p>
<div data-snippet-clipboard-copy-content="    // load the prompts from an external file if there are any
    // these have been acquired by `common.cpp` and put into `params.prompt`
    // by parsing `-f ParallelQuestions.txt` in lines 150-164

    if (params.prompt.empty()) {
        std::cout << &quot;\n\033[32mNo new questions so proceed with build-in defaults.\033[0m&quot;;
    } else {
        // Output each line of the input params.prompts vector and copy to k_prompts
        int index = 0;
        std::cout << &quot;\nNow printing the external prompt file\n\n&quot;;

        std::vector<std::string> prompts = splitString(params.prompt, '\n');
        for (const auto&amp; prompt : prompts) {
            k_prompts.resize(index + 1);
            k_prompts[index] = prompt;
            index++;
            std::cout << index << &quot; prompt: &quot; << prompt << std::endl;
        }

        // Output each line of the updated k_prompts vector (diagnostic - non-functional)
        std::cout << &quot;\n\033[33mNow printing the k_prompts loaded from an external file that replace the default questions.\033[0m\n\n&quot;;
        for (const auto&amp; prompt : k_prompts) {
            std::cout << prompt << std::endl;
        }
    }"><pre><code>    // load the prompts from an external file if there are any
    // these have been acquired by `common.cpp` and put into `params.prompt`
    // by parsing `-f ParallelQuestions.txt` in lines 150-164

    if (params.prompt.empty()) {
        std::cout &lt;&lt; "\n\033[32mNo new questions so proceed with build-in defaults.\033[0m";
    } else {
        // Output each line of the input params.prompts vector and copy to k_prompts
        int index = 0;
        std::cout &lt;&lt; "\nNow printing the external prompt file\n\n";

        std::vector&lt;std::string&gt; prompts = splitString(params.prompt, '\n');
        for (const auto&amp; prompt : prompts) {
            k_prompts.resize(index + 1);
            k_prompts[index] = prompt;
            index++;
            std::cout &lt;&lt; index &lt;&lt; " prompt: " &lt;&lt; prompt &lt;&lt; std::endl;
        }

        // Output each line of the updated k_prompts vector (diagnostic - non-functional)
        std::cout &lt;&lt; "\n\033[33mNow printing the k_prompts loaded from an external file that replace the default questions.\033[0m\n\n";
        for (const auto&amp; prompt : k_prompts) {
            std::cout &lt;&lt; prompt &lt;&lt; std::endl;
        }
    }
</code></pre></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[K3s – Lightweight Kubernetes (226 pts)]]></title>
            <link>https://k3s.io/</link>
            <guid>37845903</guid>
            <pubDate>Wed, 11 Oct 2023 15:39:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://k3s.io/">https://k3s.io/</a>, See on <a href="https://news.ycombinator.com/item?id=37845903">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="docusaurus_skipToContent_fallback"><main><section><div><p><h2>Lightweight Kubernetes</h2><h4>The certified Kubernetes distribution built for IoT &amp; Edge computing</h4></p><div><h4>This won't take long…</h4><div><pre tabindex="0"><code><span><span>curl -sfL https://get.k3s.io | sh - </span><br></span><span><span># Check for Ready node, takes ~30 seconds </span><br></span><span><span>sudo k3s kubectl get node </span><br></span></code></pre></div><p>For detailed installation, <a href="https://docs.k3s.io/">refer to the docs</a></p></div></div><div><h4>Great For</h4><p><h5>Edge</h5><h5>IoT</h5><h5>CI</h5><h5>ARM</h5></p></div></section><section><h2>Why Use K3s</h2><div><div><h5>Perfect for Edge</h5><p>K3s is a highly available, certified Kubernetes distribution designed for production workloads in unattended, resource-constrained, remote locations or inside IoT appliances.</p></div><div><h5>Simplified &amp; Secure</h5><p>K3s is packaged as a single &lt;70MB binary that reduces the dependencies and steps needed to install, run and auto-update a production Kubernetes cluster.</p></div><div><h5>Optimized for ARM</h5><p>Both ARM64 and ARMv7 are supported with binaries and multiarch images available for both. K3s works great on something as small as a Raspberry Pi to an AWS a1.4xlarge 32GiB server.</p></div></div></section><hr><section><h2>How it Works</h2><img src="https://k3s.io/img/how-it-works-k3s-revised.svg" alt="{{ .Site.Title }}"><p>The above figure shows the difference between K3s server and K3s agent nodes. For more information, see the <a href="https://docs.k3s.io/architecture">architecture documentation.</a></p></section><section><div><h2>Get Started</h2><h5>1. Download K3s - <a href="https://github.com/k3s-io/k3s/releases/latest">latest release</a>: x86_64, ARMv7, ARM64, and s390x are supported<br>2. Run server</h5><div><pre tabindex="0"><code><span><span>sudo k3s server &amp;</span><br></span><span><span># Kubeconfig is written to /etc/rancher/k3s/k3s.yaml</span><br></span><span><span>sudo k3s kubectl get node</span><br></span><span><span></span><br></span><span><span># On a different node run the below command. </span><br></span><span><span># NODE_TOKEN comes from /var/lib/rancher/k3s/server/node-token on your server</span><br></span><span><span>sudo k3s agent --server https://myserver:6443 --token ${NODE_TOKEN}</span><br></span></code></pre></div></div><div><h2>Learn More</h2><div><p>Read the latest SUSE Rancher blog on K3s.</p><p><a href="https://www.suse.com/c/rancher_blog/when-to-use-k3s-and-rke2/">Blog</a></p></div></div></section><section><a href="https://www.cncf.io/"><img src="https://k3s.io/img/cncf-color.png" alt="Docusaurus themed image"><img src="https://k3s.io/img/cncf-white.png" alt="Docusaurus themed image"></a><p>We are a Cloud Native Computing Foundation sandbox project.</p></section></main></div></div>]]></description>
        </item>
    </channel>
</rss>