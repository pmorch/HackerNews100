<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 14 Aug 2025 13:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Arch shares its wiki strategy with Debian (137 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/1032604/73596e0c3ed1945a/</link>
            <guid>44898300</guid>
            <pubDate>Thu, 14 Aug 2025 08:58:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/1032604/73596e0c3ed1945a/">https://lwn.net/SubscriberLink/1032604/73596e0c3ed1945a/</a>, See on <a href="https://news.ycombinator.com/item?id=44898300">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>The <a href="https://archlinux.org/">Arch Linux project</a> is
especially well-known in the Linux community for two things: its
rolling-release model and the quality of the documentation in the <a href="https://wiki.archlinux.org/title/Main_page">ArchWiki</a>. No
matter which Linux distribution one uses, the odds are that eventually
the ArchWiki's documentation will prove useful. The Debian project
recognized this and has sought to improve its own documentation game
by inviting ArchWiki maintainers Jakub Klinkovský and Vladimir
Lavallade to <a href="https://debconf25.debconf.org/">DebConf25</a> in
Brest, France, to speak about how Arch manages its wiki. The talk has
already borne fruit with the launch of an effort to revamp the Debian
wiki.</p>

<p><a href="https://lwn.net/Articles/1032728/#jakub">
<img src="https://static.lwn.net/images/2025/Jakub_Klinkovsky-sm.png" alt="[Jakub Klinkovský]" title="Jakub Klinkovský">
</a></p><p>Klinkovský and Lavallade were introduced by Debian developer Thomas
Lange, who said that he had the idea to invite the pair to
DebConf. Klinkovský said that he had been a maintainer of the wiki
since about 2014, and that he is also a package maintainer for Arch
Linux. He added that he contributes to many other projects
"<q>wherever I can</q>". For his part, Lavallade said that he has
contributed to the wiki since 2021, but he had only recently joined
the maintenance team: "<q>I know just enough to be dangerous</q>."</p>

<p>Lavallade said that the talk was a good opportunity to
cross-pollinate with another distribution, and to do some
self-reflection on how the wiki team operates. They would explain how
the wiki is run using the <a href="https://en.wikipedia.org/wiki/SWOT_analysis">SWOT analysis</a>
format, with a focus on the content and how the maintenance team keeps
the quality of pages as high as it can. "SWOT", for those who have
been fortunate enough not to have encountered the acronym through
corporate meetings, is short for "strengths, weaknesses,
opportunities, and threats". SWOT analysis is generally used for
decision-making processes to help analyze the current state 
and identify what an organization needs to improve.</p>

<h4 clear="all">ArchWiki:About</h4>

<p>The ArchWiki was established in 2004; the project originally used
<a href="https://en.wikipedia.org/wiki/PhpWiki">PhpWiki</a> as its
backend—but Klinkovský said that it was quickly migrated to
MediaWiki, which is still in use today. The wiki <a href="https://wiki.archlinux.org/title/ArchWiki:Maintenance_Team">maintenance</a>
and <a href="https://wiki.archlinux.org/title/ArchWiki:Translation_Team">translation</a>
teams were established "<q>about 2010</q>". The maintenance team is
responsible for the <a href="https://wiki.archlinux.org/title/ArchWiki:Contributing">contribution
guidelines</a>, <a href="https://wiki.archlinux.org/title/Help:Style">style
conventions</a>, organization, and anything else that contributors need
to know.</p>

<p>Today, the wiki has more than 4,000 topic pages; it has close to
30,000 pages if one counts <a href="https://wiki.archlinux.org/title/Help:Discussion">talk
pages</a>, <a href="https://wiki.archlinux.org/title/Help:Editing#Redirects">redirects</a>,
and <a href="https://wiki.archlinux.org/title/Category:Help">help
pages</a>. "<q>We are still quite a small wiki compared to
Wikipedia</q>", Klinkovský said.</p>

<p>He displayed a slide, part of which is shown below, with graphs
showing the number of edits and active users per month. The <a href="https://pkgbuild.com/~lahwaacz/DebConf25/#1">full set of
slides</a> is available online as well.</p>

<blockquote>
<a href="https://lwn.net/Articles/1032728/#today">
<img src="https://static.lwn.net/images/2025/archwiki-slide-600.png" alt="[ArchWiki today slide]" title="ArchWiki today slide">
</a>
</blockquote>

<p>Since 2006, the wiki has had more than 840,000 edits by more than
86,000 editors; the project is averaging more than 2,000 edits by
about 300 active contributors each month. Klinkovský noted that this
"<q>used to be quite a larger number</q>".</p>

<h4>Strengths</h4>

<p>Lavallade had a short list of the "<q>best user-facing qualities</q>"
of the ArchWiki, which are the project's strengths. The first was
"<q>comprehensive content and a very large coverage of various
topics</q>". He said this included not just how to run Arch Linux, but
how to run important software on the distribution.</p>

<p>The next was having high-quality and up-to-date content. Given that
Arch is a rolling-release distribution, he said, every page has to be
updated to reflect the latest package provided with the
distribution. That is only possible thanks to "<q>a very involved
community</q>"; he noted that most of the edits on the ArchWiki were
made by contributors outside the maintenance team.</p>

<p>All of that brought him to the last strength he wanted to discuss:
its reach beyond the Arch community. He pulled up a slide that included a
quote from Edward Snowden, which said:</p>

<blockquote>
Is it just me, or have search results become absolute garbage for
basically every site? It's nearly impossible to discover useful
information these days (outside the ArchWiki).
</blockquote>

<h4>Contribution and content guidelines</h4>

<p>The contribution guidelines and processes have a lot to do with the
<a href="https://lwn.net/Articles/1032728/#vladimir">
<img src="https://static.lwn.net/images/2025/Vladimir_Lavallad-sm.png" alt="[Vladimir Lavallade]" title="Vladimir Lavallade">
</a>
quality of the content on the wiki. Contributors, he said, have to
follow three fundamental rules. The first is that they must use the
edit summary to explain what has been done and why. The second rule
is that contributors should not make complex edits all at once. As
much as possible, Lavallade said, contributors should do "<q>some kind
of atomic editing</q>" where each change is independent of the other
ones. He did not go into specifics on this during the talk, but the <a href="https://wiki.archlinux.org/title/ArchWiki:Contributing#Do_not_make_complex_edits_at_once">guidelines</a>
have examples of best practices. The third rule is that major changes
or rewrites should be announced on a topic's talk page to give others
who are watching the topic a chance to weigh in.</p>

<p>The team also has three major content guidelines that Lavallade
highlighted. One that is likely familiar to anyone contributing to
technical documentation is the <a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">don't
repeat yourself</a> (DRY) principle. A topic should only exist in one
place, rather than being repeated on multiple pages. He also said that
the ArchWiki employed a "<q>simple, but not stupid</q>" approach to
the documentation. This means that the documentation should be simple
to read and maintain, but not offer too much hand-holding. Users also
need to be willing to learn; they may need to read through more
than one page to find the information they need to do something.</p>

<p>The final guideline is that everything is Arch-centric. Content on
the site may be useful for users running different Linux
distributions, and contributions are welcome that may apply to other
distributions, but "<q>something that will not work on Arch as-is is
not something we will be hosting on our site</q>". That, he said,
allowed the maintenance team to be focused on the content Arch
provides and helps to keep maintenance more manageable.</p>

<h4>Maintenance</h4>

<p>Speaking of maintenance, Klinkovský said, the project has tools and
<a href="https://wiki.archlinux.org/title/Help:Template">templates</a>
to help make life easier for contributors. A reviewer might apply an
<a href="https://wiki.archlinux.org/title/Template:Accuracy">accuracy</a>
template, for instance, which will add it to a <a href="https://wiki.archlinux.org/title/Category:Pages_or_sections_flagged_with_Template:Accuracy">page</a>
that lists all content that has been flagged as possibly
inaccurate. The templates are usually used and acted on by people,
but the project also has bots that can add some templates (such as <a href="https://wiki.archlinux.org/title/Template:Dead_link">dead
link</a>) and even fix some problems.</p>

<p>The review process is an important part of maintenance, he
said. Everyone can participate in review, not just the maintainers of
the wiki. He explained that it was not possible for the maintenance
team to review everything, so much of the review is done by
people interested in specific topics who watch pages to see when
changes were made. If people spot errors, they are empowered to
fix them on their own, or to use the templates to flag them for others
to address. Maintainers are there, he said, "<q>to make some authoritative
decisions when needed, and mediate disputes if they came up</q>".</p>

<p>Klinkovský referred to watching and reviewing content on the wiki
as "<q><a href="https://wiki.archlinux.org/title/Help:Procedures#Patrolling">patrolling</a></q>",
and said there were some basic rules that should be followed, starting
with "<q>assume good faith</q>". Most people do something because they
think it is right; the maintainers rarely see outright vandalism on
the wiki.</p>

<p>The second rule, he said, is "<q>when in doubt, discuss
changes with others before making a hasty decision</q>". If a change
must be reverted, then a reviewer should always explain <em>why</em>
it was reverted. This gives the original contributor a chance to come
back and fix the problem or address it in a different way. Lastly,
Klinkovský said, they wanted to avoid <a href="https://meta.wikimedia.org/wiki/Edit_war">edit wars</a>: "<q>the
worst thing that can happen on a wiki is a few people just reverting
their changes after each other</q>".</p>

<p>Preventing edit wars and encouraging contributions was, Lavallade
said, part of the broader topic of community management. The team
tries to encourage contributors to not only make one change, but to
learn the guidelines and keep contributing—and then help teach
others the guidelines.</p>

<p>Arch has support forums, such as IRC, and when people ask for help
there they are pointed to the wiki "<q>because there is always the
solution on the ArchWiki</q>". In the rare event that the wiki does
not have the solution, he said, "<q>we gently point them to where the page
with the content needs to be</q>" and invite the user to add it even
if it's not perfect the first time. That helps to reinforce the idea
that the wiki is a collaborative work that everyone should feel
welcome to add to.</p>

<h4>Weaknesses</h4>

<p>Lavallade said that the contribution model also illustrated one of
ArchWiki's weaknesses: there is a lot to learn about contributing to
the wiki, and newcomers can get tripped up. For example, he said that
the DRY principle was difficult for new contributors. Or a newcomer might
add a large chunk of content into a page that should be broken up into
several pages.</p>

<p>The MediaWiki markup language is another hurdle for new
contributors. He called the markup "<q>antiquated</q>", and
acknowledged that the style conventions for the ArchWiki are not
obvious either. It can take a lot of reading, cross-referencing, and
back-and-forth discussions for a new contributor to make a content
contribution correctly.</p>

<p>MediaWiki has a lot of strengths, Klinkovský said; it is
battle-proven software, it is the de facto standard platform for
wikis, and it has a nice API that can be used for integration with
external applications such as bots. But MediaWiki is a weakness as well, he
said. The platform is primarily developed for Wikipedia, and
its developers are from Wikipedia. "<q>Sometimes their decisions don't
suit us</q>", he said, and there was little way to make things exactly
as the ArchWiki maintenance team might want.</p>

<p>The primary weakness, though, was that its markup language is
"<q>very weird and hard to understand both for humans and
machines</q>". In 2025, most people know and write Markdown daily, but
MediaWiki markup is different. It is weird and fragile; changing a
single token can completely break a page. It is also, he said,
difficult to write a proper or robust parser for the language. This is
particularly true because there is no formal specification of the
language, just the reference implementation in the form of
MediaWiki. That can change at any time: "<q>so even if you had a perfect
parser one day, it might not work the same or perfectly the next
day</q>".</p>

<p>Since ArchWiki is developed by volunteer contributors, its content
is essentially driven by popularity; people generally only edit the
content that they have an interest in. Klinkovský said that this was
not a weakness, necessarily, but it was related to some
weaknesses. For example, some pages were edited frequently while
others were not touched for years due to lack of interest. To a
reader, it is not obvious whether page content is stale or recently
updated.</p>

<p>There is also no perfect way to ensure that content makes its way
to the wiki. He noted that people might solve their problem in a
discussion on Arch's forums, but that the solution might never end up
on the wiki.</p>

<h4>Opportunities and threats</h4>

<p>Klinkovský said that they had also identified several areas of
opportunity—such as community involvement and support tools for
editors—where the ArchWiki's work could be improved.</p>

<p>Lavallade said that one example of community involvement would be
to work with derivatives from Arch Linux, such as <a href="https://store.steampowered.com/steamos">SteamOS</a> or
Arch ports to CPU architectures other than x86-64. Currently, Arch is only
supported on x86-64, he noted, but the project has passed an <a href="https://rfc.archlinux.page/0032-arch-linux-ports/">RFC</a> to
expand the number of architectures that would be supported.</p>

<p>Right now, the project has two tools for editors to use to make
their work a bit easier: <a href="https://lahwaacz.github.io/wiki-scripts/">wiki-scripts</a> and
<a href="https://github.com/kynikos/wiki-monkey/wiki">Wiki
Monkey</a>. Klinkovský explained that wiki-scripts was a collection of
Python scripts used to automate common actions, such as checking if
links actually work. Wiki Monkey is an interactive JavaScript tool
that runs in the web browser, he said, and can help contributors
improve content. For example, it has <a href="https://github.com/kynikos/wiki-monkey/wiki/Bundled-plugins">plugins</a>
to expand contractions, fix headers, convert HTML
<tt>&lt;code&gt;</tt> tags into proper MediaWiki markup, and more.</p>

<p>There is much more that could be added or improved, he said, like
linting software for grammar issues. The team might also consider
incorporating machine learning or AI techniques into the editor
workflow, "<q>but this needs to be done carefully so we don't cause
more trouble than we have right now</q>". The trouble the team has
with AI right now will probably sound familiar to anyone running an
open-source project today; specifically, AI-generated content that is
not up to par and scraper bots.</p>

<p>People have already tried contributing to ArchWiki using AI, but
Klinkovský pointed out that "<q>current models are obviously not
trained on our style guidelines, because the content does not
fit</q>". Using AI for problem solving also prevents people from fully
understanding a solution or how things work. That may be a problem for
the whole of society, he said, not just ArchWiki.</p>

<p>The scraper bot problem is a more immediate concern, in that the
project had to put the wiki behind <a href="https://lwn.net/Articles/1028558/">Anubis</a> in the early part
of the year for about two months. Currently they do not need to use
it, Klinkovský said, but they have it on standby if the bots come
back. "<q>So this is still a threat and we cannot consider it
solved.</q>"</p>

<p>Another, non-technical, threat that the project faces is
burnout. Lavallade said that contributor burnout is a real problem,
and that people who have stayed a long while "<q>usually start with a
good, strong string of changes, but they end up tapering their amount
of contributions</q>". Everyone, he said, ends up running out of steam
at some point. Because of that, there is a need to keep bringing in
new contributors to replace people who have moved on.</p>

<h4>Questions</h4>

<p>One member of the audience wanted to know if there was a dedicated
chat room for the wiki to discuss changes coming in. Lavallade said
that there is an <tt>#archlinux-wiki</tt> room on <a href="https://libera.chat/">Libera.Chat</a>, and anyone is welcome
there. However, the team frequently redirects conversations about
changes to the talk pages on the wiki to ensure that everyone
interested in a topic can discuss the change.</p>

<p>Steve McIntyre had two questions. He was curious about how many
maintainers the ArchWiki had and what kind of hardware or setup was
on the backend of the wiki "<q>is this like, one virtual machine, or a
cluster?</q>" Klinkovský said that there were about 30 to 50
maintainers at the moment. As far as the setup, he said he was not on
Arch's DevOps team and didn't know all the details, but he did know it
was just one virtual machine "<q>in the cloud</q>".</p>

<blockquote>
The staff here at LWN.net really appreciate the subscribers who make
our work possible. Is there a chance we could interest you in <a href="https://lwn.net/Promo/daroc2/claim">becoming one of them</a>?
</blockquote>


<p>Another person wanted to know if the team would choose MediaWiki
again if they were building the wiki today. Klinkovský did not quite
answer directly, but he said that if a project does not like the
markup language used by MediaWiki then it should look to a solution
that uses Markdown. But, if a project needs all of the other features
MediaWiki has, "<q>like plugins or the API for writing bots and so
on</q>", then MediaWiki is the best from all of the wiki software
available.</p>

<p>One audience member pointed out that the chart seemed to show a
spike in activity beginning with COVID and a steady decline
since. They asked if the team had noticed that, and what they were
doing about it. Klinkovský said that they had not looked at that
problem as a whole team, or discussed what they could do about it. He
said that if Arch added new architectures or accepted contributions
from Arch-derivative distributions, it might reverse the trend.</p>

<p>Lange closed the session by saying that he thought it was funny
that the presenters had said they wanted ArchWiki to be Arch-centric:
"<q>I think you failed, because a lot of other people are reading your
really great, big wiki</q>".</p>

<h4>Debian embraces MediaWiki</h4>

<p>The session seems to have been a success in that it has helped to
inspire the Debian project to <a href="https://wiki.debian.org/DebianWiki/WikiRevamp">revamp</a> its
own wiki. Immediately after the ArchWiki presentation, there was a <a href="https://debconf25.debconf.org/talks/146-debian-wiki-bof/">Debian
wiki BoF</a> where it was decided to use MediaWiki. Debian currently
uses the <a href="https://moinmo.in/">MoinMoin</a> 1.9 branch, which
depends on Python&nbsp;2.7.</p>

<p>Since DebConf25, members of the wiki team have worked with the
Debian's system administrators team to put up <a href="https://wiki2025.debian.org/wiki/Main_Page">wiki2025.debian.org</a>
to eventually replace the current wiki. They have also created a new
<a href="https://lists.debian.org/debian-wiki/">debian-wiki</a>
mailing list and decided to change the content licensing policy for
material contributed to the wiki. Changes submitted to the wiki after
July&nbsp;24 <a href="https://wiki.debian.org/copyright.html">are now
licensed</a> under the <a href="https://creativecommons.org/licenses/by-sa/4.0/">Creative
Commons Attribution-ShareAlike 4.0 license</a> unless otherwise
noted.</p>

<p>If Debian can sustain the activity that has gone into the wiki
revamp since DebConf25, its wiki might give the ArchWiki project
a run for its money. In that case, given that ArchWiki has proven such
a good resource for Linux users regardless of distribution, everybody
will win.</p>

<p>[Thanks to the Linux Foundation, LWN's travel sponsor, for funding
my travel to Brest for DebConf25.]</p><br clear="all">
               <br clear="all">
               <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Yet another memory system for LLMs (113 pts)]]></title>
            <link>https://github.com/trvon/yams</link>
            <guid>44896489</guid>
            <pubDate>Thu, 14 Aug 2025 03:34:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/trvon/yams">https://github.com/trvon/yams</a>, See on <a href="https://news.ycombinator.com/item?id=44896489">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a href="https://github.com/trvon/yams/actions/workflows/release.yml"><img src="https://github.com/trvon/yams/actions/workflows/release.yml/badge.svg" alt="Release"></a> <a href="https://github.com/trvon/yams/actions/workflows/ci.yml"><img src="https://github.com/trvon/yams/actions/workflows/ci.yml/badge.svg" alt="CI"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">YAMS - Yet Another Memory System</h2><a id="user-content-yams---yet-another-memory-system" aria-label="Permalink: YAMS - Yet Another Memory System" href="#yams---yet-another-memory-system"></a></p>
<p dir="auto">Persistent memory for LLMs and applications. Content-addressed storage with deduplication, semantic search, and full-text indexing.</p>
<p dir="auto">My prompt for CLI usage is <a href="https://github.com/trvon/yams/blob/main/docs/PROMPT.md">PROMPT.md</a> and <a href="https://github.com/trvon/yams/blob/main/docs/PROMPT-eng.md">PROMPT-eng.md</a> for programming.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>Content-Addressed Storage</strong> - SHA-256 based, ensures data integrity</li>
<li><strong>Deduplication</strong> - Block-level with Rabin fingerprinting</li>
<li><strong>Compression</strong> - Zstandard and LZMA with intelligent policies</li>
<li><strong>Search</strong> - Full-text (SQLite FTS5) and semantic (vector embeddings)</li>
<li><strong>Crash Recovery</strong> - Write-ahead logging for durability</li>
<li><strong>High Performance</strong> - 100MB/s+ throughput, thread-safe</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Versioning</h2><a id="user-content-versioning" aria-label="Permalink: Versioning" href="#versioning"></a></p>
<p dir="auto">YAMS provides comprehensive versioning through content-addressed storage. Every stored document gets a unique SHA-256 hash that serves as an immutable version identifier. You can track changes using metadata updates (<code>yams update</code>), organize versions with collections (<code>--collection release-v1.0</code>), and capture point-in-time states with snapshots (<code>--snapshot-id 2024Q4</code>).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><strong>Supported platforms:</strong></p>
<ul dir="auto">
<li>Linux x86_64, ARM64</li>
<li>macOS x86_64 (Intel), ARM64 (Apple Silicon)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Package Managers</h3><a id="user-content-package-managers" aria-label="Permalink: Package Managers" href="#package-managers"></a></p>
<p dir="auto"><strong>Docker:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run --rm -it ghcr.io/trvon/yams:latest --version"><pre>docker run --rm -it ghcr.io/trvon/yams:latest --version</pre></div>
<p dir="auto"><strong>Homebrew (coming soon):</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="brew tap trvon/yams &amp;&amp; brew install yams"><pre>brew tap trvon/yams <span>&amp;&amp;</span> brew install yams</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build</h3><a id="user-content-build" aria-label="Permalink: Build" href="#build"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install Conan
pip install conan

# One-time: create default Conan profile
conan profile detect --force

# Build with Conan (recommended - this is what creates the release binaries)
conan install . --output-folder=build/conan-release -s build_type=Release --build=missing
cmake --preset conan-release
cmake --build --preset conan-release
sudo cmake --install build/conan-release/build/Release"><pre><span><span>#</span> Install Conan</span>
pip install conan

<span><span>#</span> One-time: create default Conan profile</span>
conan profile detect --force

<span><span>#</span> Build with Conan (recommended - this is what creates the release binaries)</span>
conan install <span>.</span> --output-folder=build/conan-release -s build_type=Release --build=missing
cmake --preset conan-release
cmake --build --preset conan-release
sudo cmake --install build/conan-release/build/Release</pre></div>
<p dir="auto"><strong>Requirements:</strong></p>
<ul dir="auto">
<li>C++20 compiler (GCC 11+, Clang 14+, AppleClang 14+)</li>
<li>CMake 3.20+</li>
<li>Python 3.8+ (for Conan)</li>
</ul>
<blockquote>
<p dir="auto"><strong>Known Issue:</strong> Traditional CMake builds (without Conan) currently have dependency resolution issues. Use Conan builds for reliable compilation.</p>
</blockquote>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build Options</h3><a id="user-content-build-options" aria-label="Permalink: Build Options" href="#build-options"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Option</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>YAMS_USE_CONAN</code></td>
<td>OFF</td>
<td>Use Conan package manager</td>
</tr>
<tr>
<td><code>YAMS_BUILD_CLI</code></td>
<td>ON</td>
<td>CLI with TUI browser</td>
</tr>
<tr>
<td><code>YAMS_BUILD_MCP_SERVER</code></td>
<td>ON</td>
<td>MCP server (requires Boost)</td>
</tr>
<tr>
<td><code>YAMS_BUILD_TESTS</code></td>
<td>OFF</td>
<td>Unit and integration tests</td>
</tr>
<tr>
<td><code>YAMS_BUILD_BENCHMARKS</code></td>
<td>OFF</td>
<td>Performance benchmarks</td>
</tr>
<tr>
<td><code>YAMS_ENABLE_PDF</code></td>
<td>ON</td>
<td>PDF text extraction support</td>
</tr>
<tr>
<td><code>CMAKE_BUILD_TYPE</code></td>
<td>Release</td>
<td>Debug/Release/RelWithDebInfo</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dependencies</h3><a id="user-content-dependencies" aria-label="Permalink: Dependencies" href="#dependencies"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# macOS
brew install openssl@3 protobuf sqlite3 ncurses
export OPENSSL_ROOT_DIR=$(brew --prefix openssl@3)

# Linux
apt install libssl-dev libsqlite3-dev protobuf-compiler libncurses-dev"><pre><span><span>#</span> macOS</span>
brew install openssl@3 protobuf sqlite3 ncurses
<span>export</span> OPENSSL_ROOT_DIR=<span><span>$(</span>brew --prefix openssl@3<span>)</span></span>

<span><span>#</span> Linux</span>
apt install libssl-dev libsqlite3-dev protobuf-compiler libncurses-dev</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Setup</h2><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Initialize with XDG defaults (non-interactive)
yams init --non-interactive

# Optional: custom storage root
export YAMS_STORAGE=&quot;$HOME/.local/share/yams&quot;
yams init --non-interactive

# Print resulting config (secrets masked)
yams init --non-interactive --print"><pre><span><span>#</span> Initialize with XDG defaults (non-interactive)</span>
yams init --non-interactive

<span><span>#</span> Optional: custom storage root</span>
<span>export</span> YAMS_STORAGE=<span><span>"</span><span>$HOME</span>/.local/share/yams<span>"</span></span>
yams init --non-interactive

<span><span>#</span> Print resulting config (secrets masked)</span>
yams init --non-interactive --print</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Troubleshooting</h3><a id="user-content-troubleshooting" aria-label="Permalink: Troubleshooting" href="#troubleshooting"></a></p>
<p dir="auto">If you see:</p>
<div data-snippet-clipboard-copy-content="ERROR: The default build profile '/home/trevon/.conan2/profiles/default' doesn't exist.
You need to create a default profile (type 'conan profile detect' command)
or specify your own profile with '--profile:build=<myprofile>'"><pre lang="text"><code>ERROR: The default build profile '/home/trevon/.conan2/profiles/default' doesn't exist.
You need to create a default profile (type 'conan profile detect' command)
or specify your own profile with '--profile:build=&lt;myprofile&gt;'
</code></pre></div>
<p dir="auto">Fix:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Create default profile
conan profile detect --force

# Optional: ensure C++20 in the default profile
# Linux/macOS (GNU sed):
sed -i 's/compiler.cppstd=.*/compiler.cppstd=20/' ~/.conan2/profiles/default || true
# macOS (BSD sed):
# sed -i '' 's/compiler.cppstd=.*/compiler.cppstd=20/' ~/.conan2/profiles/default || true"><pre><span><span>#</span> Create default profile</span>
conan profile detect --force

<span><span>#</span> Optional: ensure C++20 in the default profile</span>
<span><span>#</span> Linux/macOS (GNU sed):</span>
sed -i <span><span>'</span>s/compiler.cppstd=.*/compiler.cppstd=20/<span>'</span></span> <span>~</span>/.conan2/profiles/default <span>||</span> <span>true</span>
<span><span>#</span> macOS (BSD sed):</span>
<span><span>#</span> sed -i '' 's/compiler.cppstd=.*/compiler.cppstd=20/' ~/.conan2/profiles/default || true</span></pre></div>
<p dir="auto">Then re-run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="conan install . \
  --output-folder=build/conan-ninja-release \
  -s build_type=Release \
  --build=missing

cmake --preset conan-ninja-release
cmake --build build/conan-ninja-release -j"><pre>conan install <span>.</span> \
  --output-folder=build/conan-ninja-release \
  -s build_type=Release \
  --build=missing

cmake --preset conan-ninja-release
cmake --build build/conan-ninja-release -j</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">PDF Support Issues</h4><a id="user-content-pdf-support-issues" aria-label="Permalink: PDF Support Issues" href="#pdf-support-issues"></a></p>
<p dir="auto">If PDF extraction fails or PDFium download fails:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Disable PDF support temporarily
cmake -B build -DYAMS_ENABLE_PDF=OFF

# Or explicitly specify a different PDFium version if needed
# (check https://github.com/bblanchon/pdfium-binaries/releases for available versions)"><pre><span><span>#</span> Disable PDF support temporarily</span>
cmake -B build -DYAMS_ENABLE_PDF=OFF

<span><span>#</span> Or explicitly specify a different PDFium version if needed</span>
<span><span>#</span> (check https://github.com/bblanchon/pdfium-binaries/releases for available versions)</span></pre></div>
<p dir="auto">If you see network errors during PDFium download:</p>
<ul dir="auto">
<li>Check internet connectivity</li>
<li>Corporate firewalls may block GitHub releases</li>
<li>Consider using a VPN or different network</li>
<li>PDFium binaries are ~20MB per platform</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">LLM Integration Guide</h3><a id="user-content-llm-integration-guide" aria-label="Permalink: LLM Integration Guide" href="#llm-integration-guide"></a></p>
<p dir="auto">YAMS is designed to work seamlessly with Large Language Models through simple, pipeline-friendly commands:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Store conversation context with descriptive name
echo &quot;User asked about X, I explained Y&quot; | yams add - --name &quot;context-$(date +%Y%m%d).txt&quot;

# Store code snippets with tags
echo &quot;def function(): return 42&quot; | yams add - --name &quot;helper.py&quot; --tags &quot;python,utils&quot;

# Delete temporary files by pattern
yams delete --pattern &quot;temp_*.txt&quot; --force

# Delete multiple specific files
yams delete --names &quot;draft1.md,draft2.md,notes.txt&quot;

# Retrieve documents by name (coming soon)
# yams get --name &quot;meeting-notes.txt&quot;

# Search with fuzzy matching
yams search &quot;databse&quot; --fuzzy --similarity 0.8

# List with rich metadata
yams list --format table --limit 20

# Chain commands for batch operations
yams list --format minimal | tail -5 | while read hash; do
  yams get $hash
done

# Preview deletions before executing
yams delete --pattern &quot;*.log&quot; --dry-run"><pre><span><span>#</span> Store conversation context with descriptive name</span>
<span>echo</span> <span><span>"</span>User asked about X, I explained Y<span>"</span></span> <span>|</span> yams add - --name <span><span>"</span>context-<span><span>$(</span>date +%Y%m%d<span>)</span></span>.txt<span>"</span></span>

<span><span>#</span> Store code snippets with tags</span>
<span>echo</span> <span><span>"</span>def function(): return 42<span>"</span></span> <span>|</span> yams add - --name <span><span>"</span>helper.py<span>"</span></span> --tags <span><span>"</span>python,utils<span>"</span></span>

<span><span>#</span> Delete temporary files by pattern</span>
yams delete --pattern <span><span>"</span>temp_*.txt<span>"</span></span> --force

<span><span>#</span> Delete multiple specific files</span>
yams delete --names <span><span>"</span>draft1.md,draft2.md,notes.txt<span>"</span></span>

<span><span>#</span> Retrieve documents by name (coming soon)</span>
<span><span>#</span> yams get --name "meeting-notes.txt"</span>

<span><span>#</span> Search with fuzzy matching</span>
yams search <span><span>"</span>databse<span>"</span></span> --fuzzy --similarity 0.8

<span><span>#</span> List with rich metadata</span>
yams list --format table --limit 20

<span><span>#</span> Chain commands for batch operations</span>
yams list --format minimal <span>|</span> tail -5 <span>|</span> <span>while</span> <span>read</span> <span>hash</span><span>;</span> <span>do</span>
  yams get <span>$hash</span>
<span>done</span>

<span><span>#</span> Preview deletions before executing</span>
yams delete --pattern <span><span>"</span>*.log<span>"</span></span> --dry-run</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Best Practices for LLMs</h4><a id="user-content-best-practices-for-llms" aria-label="Permalink: Best Practices for LLMs" href="#best-practices-for-llms"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Use stdin for content storage</strong>: Avoids file creation</p>
<div dir="auto" data-snippet-clipboard-copy-content="echo &quot;content to store&quot; | yams add -"><pre><span>echo</span> <span><span>"</span>content to store<span>"</span></span> <span>|</span> yams add -</pre></div>
</li>
<li>
<p dir="auto"><strong>Use minimal format for piping</strong>: Clean output for processing</p>
<div dir="auto" data-snippet-clipboard-copy-content="yams list --format minimal | head -5"><pre>yams list --format minimal <span>|</span> head -5</pre></div>
</li>
<li>
<p dir="auto"><strong>Explicit data directory</strong>: Always specify storage location</p>
<div dir="auto" data-snippet-clipboard-copy-content="yams --data-dir /tmp/project-memory add -"><pre>yams --data-dir /tmp/project-memory add -</pre></div>
</li>
<li>
<p dir="auto"><strong>JSON for structured data</strong>: Parse responses easily</p>
<div dir="auto" data-snippet-clipboard-copy-content="yams stats --format json | jq '.totalObjects'"><pre>yams stats --format json <span>|</span> jq <span><span>'</span>.totalObjects<span>'</span></span></pre></div>
</li>
<li>
<p dir="auto"><strong>Direct stdout retrieval</strong>: No intermediate files</p>
<div dir="auto" data-snippet-clipboard-copy-content="yams get <hash> | process_somehow"><pre>yams get <span>&lt;</span>hash<span>&gt;</span> <span>|</span> process_somehow</pre></div>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">MCP Server</h3><a id="user-content-mcp-server" aria-label="Permalink: MCP Server" href="#mcp-server"></a></p>
<p dir="auto">Start the MCP server over WebSocket:</p>
<div dir="auto" data-snippet-clipboard-copy-content="yams serve --transport websocket --host 127.0.0.1 --port 8080 --path /mcp"><pre>yams serve --transport websocket --host 127.0.0.1 --port 8080 --path /mcp</pre></div>
<p dir="auto">Use TLS (wss):</p>
<div dir="auto" data-snippet-clipboard-copy-content="yams serve --transport websocket --host your.domain --port 443 --path /mcp --ssl"><pre>yams serve --transport websocket --host your.domain --port 443 --path /mcp --ssl</pre></div>
<p dir="auto">StdIO transport (recommended for local integration and Claude Desktop):</p>
<div dir="auto" data-snippet-clipboard-copy-content="yams serve --transport stdio"><pre>yams serve --transport stdio</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Claude Desktop (MCP) Integration</h3><a id="user-content-claude-desktop-mcp-integration" aria-label="Permalink: Claude Desktop (MCP) Integration" href="#claude-desktop-mcp-integration"></a></p>
<p dir="auto">Use stdio (recommended). Add this to your Claude Desktop config (e.g., ~/Library/Application Support/Claude/claude_desktop_config.json):</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;mcpServers&quot;: {
    &quot;yams&quot;: {
      &quot;command&quot;: &quot;/usr/local/bin/yams&quot;,
      &quot;args&quot;: [&quot;serve&quot;, &quot;--transport&quot;, &quot;stdio&quot;],
      &quot;env&quot;: {
        &quot;YAMS_STORAGE&quot;: &quot;$HOME/.local/share/yams&quot;
      }
    }
  }
}"><pre>{
  <span>"mcpServers"</span>: {
    <span>"yams"</span>: {
      <span>"command"</span>: <span><span>"</span>/usr/local/bin/yams<span>"</span></span>,
      <span>"args"</span>: [<span><span>"</span>serve<span>"</span></span>, <span><span>"</span>--transport<span>"</span></span>, <span><span>"</span>stdio<span>"</span></span>],
      <span>"env"</span>: {
        <span>"YAMS_STORAGE"</span>: <span><span>"</span>$HOME/.local/share/yams<span>"</span></span>
      }
    }
  }
}</pre></div>
<p dir="auto">Alternative (WebSocket) for clients that support ws:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;mcpServers&quot;: {
    &quot;yams-ws&quot;: {
      &quot;command&quot;: &quot;/usr/local/bin/yams&quot;,
      &quot;args&quot;: [&quot;serve&quot;, &quot;--transport&quot;, &quot;websocket&quot;, &quot;--host&quot;, &quot;127.0.0.1&quot;, &quot;--port&quot;, &quot;8080&quot;, &quot;--path&quot;, &quot;/mcp&quot;],
      &quot;env&quot;: {
        &quot;YAMS_STORAGE&quot;: &quot;$HOME/.local/share/yams&quot;
      }
    }
  }
}"><pre>{
  <span>"mcpServers"</span>: {
    <span>"yams-ws"</span>: {
      <span>"command"</span>: <span><span>"</span>/usr/local/bin/yams<span>"</span></span>,
      <span>"args"</span>: [<span><span>"</span>serve<span>"</span></span>, <span><span>"</span>--transport<span>"</span></span>, <span><span>"</span>websocket<span>"</span></span>, <span><span>"</span>--host<span>"</span></span>, <span><span>"</span>127.0.0.1<span>"</span></span>, <span><span>"</span>--port<span>"</span></span>, <span><span>"</span>8080<span>"</span></span>, <span><span>"</span>--path<span>"</span></span>, <span><span>"</span>/mcp<span>"</span></span>],
      <span>"env"</span>: {
        <span>"YAMS_STORAGE"</span>: <span><span>"</span>$HOME/.local/share/yams<span>"</span></span>
      }
    }
  }
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">CLI Usage</h3><a id="user-content-cli-usage" aria-label="Permalink: CLI Usage" href="#cli-usage"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Initialize Storage</h4><a id="user-content-initialize-storage" aria-label="Permalink: Initialize Storage" href="#initialize-storage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# One-time setup with defaults
yams init --non-interactive --no-keygen

# Custom storage location
yams --data-dir /path/to/storage init --non-interactive"><pre><span><span>#</span> One-time setup with defaults</span>
yams init --non-interactive --no-keygen

<span><span>#</span> Custom storage location</span>
yams --data-dir /path/to/storage init --non-interactive</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Store Documents</h4><a id="user-content-store-documents" aria-label="Permalink: Store Documents" href="#store-documents"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Add a file
yams add file.txt

# Add from stdin
echo &quot;content&quot; | yams add -
cat file.txt | yams add -

# Add multiple files
find . -name &quot;*.txt&quot; -exec yams add {} \;"><pre><span><span>#</span> Add a file</span>
yams add file.txt

<span><span>#</span> Add from stdin</span>
<span>echo</span> <span><span>"</span>content<span>"</span></span> <span>|</span> yams add -
cat file.txt <span>|</span> yams add -

<span><span>#</span> Add multiple files</span>
find <span>.</span> -name <span><span>"</span>*.txt<span>"</span></span> -exec yams add {} <span>\;</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">List Documents</h4><a id="user-content-list-documents" aria-label="Permalink: List Documents" href="#list-documents"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Table format (default)
yams list

# JSON output for programmatic use
yams list --format json

# Just hashes for piping
yams list --format minimal

# Sort and filter
yams list --sort size --reverse --limit 10
yams list --sort date"><pre><span><span>#</span> Table format (default)</span>
yams list

<span><span>#</span> JSON output for programmatic use</span>
yams list --format json

<span><span>#</span> Just hashes for piping</span>
yams list --format minimal

<span><span>#</span> Sort and filter</span>
yams list --sort size --reverse --limit 10
yams list --sort date</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Retrieve Documents</h4><a id="user-content-retrieve-documents" aria-label="Permalink: Retrieve Documents" href="#retrieve-documents"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Output to stdout
yams get <hash>

# Save to file
yams get <hash> -o output.txt

# Pipe to other commands
yams get <hash> | grep pattern
yams get <hash> | wc -l

# Get first document from list
yams list --format minimal --limit 1 | xargs yams get"><pre><span><span>#</span> Output to stdout</span>
yams get <span>&lt;</span>hash<span>&gt;</span>

<span><span>#</span> Save to file</span>
yams get <span>&lt;</span>hash<span>&gt;</span> -o output.txt

<span><span>#</span> Pipe to other commands</span>
yams get <span>&lt;</span>hash<span>&gt;</span> <span>|</span> grep pattern
yams get <span>&lt;</span>hash<span>&gt;</span> <span>|</span> wc -l

<span><span>#</span> Get first document from list</span>
yams list --format minimal --limit 1 <span>|</span> xargs yams get</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Browse Documents (TUI)</h4><a id="user-content-browse-documents-tui" aria-label="Permalink: Browse Documents (TUI)" href="#browse-documents-tui"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Launch ranger-style browser
yams browse

# Navigation:
#   j/k or ↑/↓     - Move up/down
#   h/l or ←/→     - Switch columns
#   g/G           - Jump to top/bottom
#   d then D      - Delete document
#   r             - Refresh
#   ?             - Help
#   q or Esc      - Quit"><pre><span><span>#</span> Launch ranger-style browser</span>
yams browse

<span><span>#</span> Navigation:</span>
<span><span>#</span>   j/k or ↑/↓     - Move up/down</span>
<span><span>#</span>   h/l or ←/→     - Switch columns</span>
<span><span>#</span>   g/G           - Jump to top/bottom</span>
<span><span>#</span>   d then D      - Delete document</span>
<span><span>#</span>   r             - Refresh</span>
<span><span>#</span>   ?             - Help</span>
<span><span>#</span>   q or Esc      - Quit</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Search</h4><a id="user-content-search" aria-label="Permalink: Search" href="#search"></a></p>
<p dir="auto">yams search "query" --limit 10
yams search "error" --type "log"</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Retrieve</h2><a id="user-content-retrieve" aria-label="Permalink: Retrieve" href="#retrieve"></a></p>
<p dir="auto">yams get 
yams get  --output file.txt</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">List &amp; Stats</h2><a id="user-content-list--stats" aria-label="Permalink: List &amp; Stats" href="#list--stats"></a></p>
<p dir="auto">yams list --recent 20
yams stats --json  # JSON output for scripts</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Browse (interactive TUI)</h2><a id="user-content-browse-interactive-tui" aria-label="Permalink: Browse (interactive TUI)" href="#browse-interactive-tui"></a></p>
<p dir="auto">yams browse  # Interactive document browser</p>
<div data-snippet-clipboard-copy-content="
### API
```cpp
#include <yams/api/content_store.h>

auto store = yams::api::createContentStore(getenv(&quot;YAMS_STORAGE&quot;));

// Store
yams::api::ContentMetadata meta{.tags = {&quot;code&quot;, &quot;v1.0&quot;}};
auto result = store->store(&quot;file.txt&quot;, meta);

// Search
auto results = store->search(&quot;query&quot;, 10);

// Retrieve
store->retrieve(hash, &quot;output.txt&quot;);"><pre><code>
### API
```cpp
#include &lt;yams/api/content_store.h&gt;

auto store = yams::api::createContentStore(getenv("YAMS_STORAGE"));

// Store
yams::api::ContentMetadata meta{.tags = {"code", "v1.0"}};
auto result = store-&gt;store("file.txt", meta);

// Search
auto results = store-&gt;search("query", 10);

// Retrieve
store-&gt;retrieve(hash, "output.txt");
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python</h3><a id="user-content-python" aria-label="Permalink: Python" href="#python"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import subprocess, json

def yams_store(content, tags=[], type=&quot;text&quot;):
    cmd = [&quot;yams&quot;, &quot;store&quot;, content]
    if tags: cmd.extend([&quot;--tags&quot;, &quot;,&quot;.join(tags)])
    if type: cmd.extend([&quot;--type&quot;, type])
    return subprocess.run(cmd, capture_output=True, text=True)

def yams_search(query, limit=10):
    cmd = [&quot;yams&quot;, &quot;search&quot;, query, &quot;--limit&quot;, str(limit)]
    return subprocess.run(cmd, capture_output=True, text=True)"><pre><span>import</span> <span>subprocess</span>, <span>json</span>

<span>def</span> <span>yams_store</span>(<span>content</span>, <span>tags</span><span>=</span>[], <span>type</span><span>=</span><span>"text"</span>):
    <span>cmd</span> <span>=</span> [<span>"yams"</span>, <span>"store"</span>, <span>content</span>]
    <span>if</span> <span>tags</span>: <span>cmd</span>.<span>extend</span>([<span>"--tags"</span>, <span>","</span>.<span>join</span>(<span>tags</span>)])
    <span>if</span> <span>type</span>: <span>cmd</span>.<span>extend</span>([<span>"--type"</span>, <span>type</span>])
    <span>return</span> <span>subprocess</span>.<span>run</span>(<span>cmd</span>, <span>capture_output</span><span>=</span><span>True</span>, <span>text</span><span>=</span><span>True</span>)

<span>def</span> <span>yams_search</span>(<span>query</span>, <span>limit</span><span>=</span><span>10</span>):
    <span>cmd</span> <span>=</span> [<span>"yams"</span>, <span>"search"</span>, <span>query</span>, <span>"--limit"</span>, <span>str</span>(<span>limit</span>)]
    <span>return</span> <span>subprocess</span>.<span>run</span>(<span>cmd</span>, <span>capture_output</span><span>=</span><span>True</span>, <span>text</span><span>=</span><span>True</span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">LLM Usage Guide</h2><a id="user-content-llm-usage-guide" aria-label="Permalink: LLM Usage Guide" href="#llm-usage-guide"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Quick Start for LLMs</h3><a id="user-content-quick-start-for-llms" aria-label="Permalink: Quick Start for LLMs" href="#quick-start-for-llms"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Always specify data directory explicitly
export YAMS_STORAGE=&quot;/tmp/yams-data&quot;

# Initialize once (quiet mode)
yams --data-dir &quot;$YAMS_STORAGE&quot; init --non-interactive --force

# Store content from stdin (most common for LLMs)
echo &quot;Important information to remember&quot; | yams --data-dir &quot;$YAMS_STORAGE&quot; add --tags &quot;memory&quot;

# Search for content
yams --data-dir &quot;$YAMS_STORAGE&quot; search &quot;important&quot; --json

# Retrieve specific document
yams --data-dir &quot;$YAMS_STORAGE&quot; get <hash> --json

# Get storage statistics
yams --data-dir &quot;$YAMS_STORAGE&quot; stats --json"><pre><span><span>#</span> Always specify data directory explicitly</span>
<span>export</span> YAMS_STORAGE=<span><span>"</span>/tmp/yams-data<span>"</span></span>

<span><span>#</span> Initialize once (quiet mode)</span>
yams --data-dir <span><span>"</span><span>$YAMS_STORAGE</span><span>"</span></span> init --non-interactive --force

<span><span>#</span> Store content from stdin (most common for LLMs)</span>
<span>echo</span> <span><span>"</span>Important information to remember<span>"</span></span> <span>|</span> yams --data-dir <span><span>"</span><span>$YAMS_STORAGE</span><span>"</span></span> add --tags <span><span>"</span>memory<span>"</span></span>

<span><span>#</span> Search for content</span>
yams --data-dir <span><span>"</span><span>$YAMS_STORAGE</span><span>"</span></span> search <span><span>"</span>important<span>"</span></span> --json

<span><span>#</span> Retrieve specific document</span>
yams --data-dir <span><span>"</span><span>$YAMS_STORAGE</span><span>"</span></span> get <span>&lt;</span>hash<span>&gt;</span> --json

<span><span>#</span> Get storage statistics</span>
yams --data-dir <span><span>"</span><span>$YAMS_STORAGE</span><span>"</span></span> stats --json</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Common Patterns</h3><a id="user-content-common-patterns" aria-label="Permalink: Common Patterns" href="#common-patterns"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Store code changes
git diff | yams --data-dir &quot;$YAMS_STORAGE&quot; add --tags &quot;git-diff,$(date +%Y%m%d)&quot;

# Store conversation context
echo &quot;User asked about: $TOPIC&quot; | yams --data-dir &quot;$YAMS_STORAGE&quot; add --tags &quot;context,$TOPIC&quot;

# Store external documentation
curl -s &quot;$API_DOCS_URL&quot; | yams --data-dir &quot;$YAMS_STORAGE&quot; add --tags &quot;api-docs,external&quot;

# Search and retrieve in one line
hash=$(yams --data-dir &quot;$YAMS_STORAGE&quot; search &quot;$QUERY&quot; --json | jq -r '.results[0].hash')
yams --data-dir &quot;$YAMS_STORAGE&quot; get &quot;$hash&quot;"><pre><span><span>#</span> Store code changes</span>
git diff <span>|</span> yams --data-dir <span><span>"</span><span>$YAMS_STORAGE</span><span>"</span></span> add --tags <span><span>"</span>git-diff,<span><span>$(</span>date +%Y%m%d<span>)</span></span><span>"</span></span>

<span><span>#</span> Store conversation context</span>
<span>echo</span> <span><span>"</span>User asked about: <span>$TOPIC</span><span>"</span></span> <span>|</span> yams --data-dir <span><span>"</span><span>$YAMS_STORAGE</span><span>"</span></span> add --tags <span><span>"</span>context,<span>$TOPIC</span><span>"</span></span>

<span><span>#</span> Store external documentation</span>
curl -s <span><span>"</span><span>$API_DOCS_URL</span><span>"</span></span> <span>|</span> yams --data-dir <span><span>"</span><span>$YAMS_STORAGE</span><span>"</span></span> add --tags <span><span>"</span>api-docs,external<span>"</span></span>

<span><span>#</span> Search and retrieve in one line</span>
hash=<span><span>$(</span>yams --data-dir <span><span>"</span><span>$YAMS_STORAGE</span><span>"</span></span> search <span><span>"</span><span>$QUERY</span><span>"</span></span> --json <span>|</span> jq -r <span><span>'</span>.results[0].hash<span>'</span></span><span>)</span></span>
yams --data-dir <span><span>"</span><span>$YAMS_STORAGE</span><span>"</span></span> get <span><span>"</span><span>$hash</span><span>"</span></span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">LLM Integration</h2><a id="user-content-llm-integration" aria-label="Permalink: LLM Integration" href="#llm-integration"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">When to Use YAMS</h3><a id="user-content-when-to-use-yams" aria-label="Permalink: When to Use YAMS" href="#when-to-use-yams"></a></p>
<p dir="auto">YAMS is ideal for LLMs to maintain persistent memory across sessions:</p>
<ul dir="auto">
<li><strong>Code Development</strong>: Track changes, store working versions, remember context</li>
<li><strong>Research</strong>: Cache web content, API responses, documentation</li>
<li><strong>Conversation Context</strong>: Store important discussions, decisions, requirements</li>
<li><strong>Knowledge Base</strong>: Build searchable repository of project knowledge</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">CLI Usage Examples</h3><a id="user-content-cli-usage-examples" aria-label="Permalink: CLI Usage Examples" href="#cli-usage-examples"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Development Workflow</h4><a id="user-content-development-workflow" aria-label="Permalink: Development Workflow" href="#development-workflow"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Store current code state before making changes
git diff | yams store - --tags &quot;pre-refactor,auth-module,$(date +%Y%m%d)&quot;

# Track implementation decisions
yams store &quot;Decided to use JWT tokens with 24h expiry for auth&quot; \
  --tags &quot;decision,auth,architecture&quot;

# Store error context for debugging
yams store &quot;$(tail -100 app.log)&quot; --tags &quot;error,production,$(date +%Y%m%d-%H%M)&quot;

# Save working implementation
yams store-file auth_handler.py --tags &quot;working,auth,v2.1&quot;"><pre><span><span>#</span> Store current code state before making changes</span>
git diff <span>|</span> yams store - --tags <span><span>"</span>pre-refactor,auth-module,<span><span>$(</span>date +%Y%m%d<span>)</span></span><span>"</span></span>

<span><span>#</span> Track implementation decisions</span>
yams store <span><span>"</span>Decided to use JWT tokens with 24h expiry for auth<span>"</span></span> \
  --tags <span><span>"</span>decision,auth,architecture<span>"</span></span>

<span><span>#</span> Store error context for debugging</span>
yams store <span><span>"</span><span><span>$(</span>tail -100 app.log<span>)</span></span><span>"</span></span> --tags <span><span>"</span>error,production,<span><span>$(</span>date +%Y%m%d-%H%M<span>)</span></span><span>"</span></span>

<span><span>#</span> Save working implementation</span>
yams store-file auth_handler.py --tags <span><span>"</span>working,auth,v2.1<span>"</span></span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Research &amp; Documentation</h4><a id="user-content-research--documentation" aria-label="Permalink: Research &amp; Documentation" href="#research--documentation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Store web research
curl -s https://api.example.com/docs | yams store - \
  --tags &quot;api-docs,external,example-api&quot; \
  --source &quot;https://api.example.com/docs&quot;

# Cache fetched content
yams store &quot;$WEB_CONTENT&quot; --tags &quot;research,oauth,implementation-guide&quot;

# Store meeting notes
yams store-file meeting-notes-2024-01-15.md --tags &quot;meeting,requirements,client&quot;"><pre><span><span>#</span> Store web research</span>
curl -s https://api.example.com/docs <span>|</span> yams store - \
  --tags <span><span>"</span>api-docs,external,example-api<span>"</span></span> \
  --source <span><span>"</span>https://api.example.com/docs<span>"</span></span>

<span><span>#</span> Cache fetched content</span>
yams store <span><span>"</span><span>$WEB_CONTENT</span><span>"</span></span> --tags <span><span>"</span>research,oauth,implementation-guide<span>"</span></span>

<span><span>#</span> Store meeting notes</span>
yams store-file meeting-notes-2024-01-15.md --tags <span><span>"</span>meeting,requirements,client<span>"</span></span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Search Patterns</h4><a id="user-content-search-patterns" aria-label="Permalink: Search Patterns" href="#search-patterns"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Find related code changes
yams search &quot;authentication&quot; --type &quot;code&quot; --limit 10

# Retrieve specific version
yams search &quot;working auth&quot; --tags &quot;v2.1&quot;

# Get recent errors
yams list --recent 20 --tags &quot;error&quot;

# Semantic search for concepts
yams search &quot;token expiry handling&quot;"><pre><span><span>#</span> Find related code changes</span>
yams search <span><span>"</span>authentication<span>"</span></span> --type <span><span>"</span>code<span>"</span></span> --limit 10

<span><span>#</span> Retrieve specific version</span>
yams search <span><span>"</span>working auth<span>"</span></span> --tags <span><span>"</span>v2.1<span>"</span></span>

<span><span>#</span> Get recent errors</span>
yams list --recent 20 --tags <span><span>"</span>error<span>"</span></span>

<span><span>#</span> Semantic search for concepts</span>
yams search <span><span>"</span>token expiry handling<span>"</span></span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">MCP (Model Context Protocol) Integration</h3><a id="user-content-mcp-model-context-protocol-integration" aria-label="Permalink: MCP (Model Context Protocol) Integration" href="#mcp-model-context-protocol-integration"></a></p>
<p dir="auto">MCP provides direct integration with Claude Desktop and other MCP-compatible clients.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Performance Tuning</h3><a id="user-content-performance-tuning" aria-label="Permalink: Performance Tuning" href="#performance-tuning"></a></p>
<p dir="auto"><strong>Optimize for large files</strong>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Adjust chunk size for better deduplication
export YAMS_CHUNK_SIZE=64KB  # Default: 16KB

# Increase cache size
export YAMS_CACHE_SIZE=1GB   # Default: 256MB"><pre><span><span>#</span> Adjust chunk size for better deduplication</span>
<span>export</span> YAMS_CHUNK_SIZE=64KB  <span><span>#</span> Default: 16KB</span>

<span><span>#</span> Increase cache size</span>
<span>export</span> YAMS_CACHE_SIZE=1GB   <span><span>#</span> Default: 256MB</span></pre></div>
<p dir="auto"><strong>Reduce memory usage</strong>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Use streaming mode for large files
yams store-file --stream large-file.bin

# Enable compression
export YAMS_COMPRESSION=zstd  # Options: none, zstd, lzma"><pre><span><span>#</span> Use streaming mode for large files</span>
yams store-file --stream large-file.bin

<span><span>#</span> Enable compression</span>
<span>export</span> YAMS_COMPRESSION=zstd  <span><span>#</span> Options: none, zstd, lzma</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Apache-2.0</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Funding Open Source like public infrastructure (139 pts)]]></title>
            <link>https://dri.es/funding-open-source-like-public-infrastructure</link>
            <guid>44896433</guid>
            <pubDate>Thu, 14 Aug 2025 03:24:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dri.es/funding-open-source-like-public-infrastructure">https://dri.es/funding-open-source-like-public-infrastructure</a>, See on <a href="https://news.ycombinator.com/item?id=44896433">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>To protect the digital foundation of essential government services, governments should invest in Open Source as public infrastructure and shift from consumption to contribution.</p><div>
    
            <div itemscope="" itemtype="https://schema.org/ImageObject"><figure><img src="https://dri.es/files/images/blog/funding-open-source-like-public-infrastructure.jpg" alt="An illustration of a small wedge propping up a massive block, symbolizing how a small group of contributors supports critical infrastructure." width="1114" height="743" srcset="https://dri.es/files/cache/blog/funding-open-source-like-public-infrastructure-640w.jpg 640w" sizes="100vw" itemprop="contentUrl">
</figure>
<meta itemprop="creditText" content="Dries Buytaert">
<meta itemprop="copyrightNotice" content="Dries Buytaert">
<meta itemprop="license" content="https://creativecommons.org/licenses/by-nc/4.0/">
<meta itemprop="acquireLicensePage" content="https://dri.es/colophon#license">
</div>

<p>Fifteen years ago, I laid out a theory about the future of Open Source. In <a href="https://dri.es/the-commercialization-of-a-volunteer-driven-open-source-project"><em>The Commercialization of a Volunteer-Driven Open Source Project</em></a>, I argued that if Open Source was going to thrive, people had to get paid to work on it. At the time, the idea was controversial. Many feared money would corrupt the spirit of volunteerism and change the nature of Open Source contribution.</p>
<p>In that same post, I actually went beyond discussing the case for commercial sponsorship and outlined a broader pattern I believed Open Source would follow. I suggested it would develop in three stages: (1) starting with volunteers, then (2) expanding to include commercial involvement and sponsorship, and finally (3) gaining government support.</p>
<p>I based this on how other <a href="https://en.wikipedia.org/wiki/Public_good">public goods</a> and public infrastructure have evolved. Trade routes, for example, began as volunteer-built paths, were improved for commerce by private companies, and later became government-run. The same pattern shaped schools, national defense, and many other public services. What begins as a volunteer effort often ends up being maintained by governments for the benefit of society. I suggested that Open Source would and should follow the same three-phase path.</p>
<p>Over the past fifteen years, paying people to maintain Open Source has shifted from controversial to widely accepted. Platforms like <a href="https://opencollective.com/">Open Collective</a>, an organization I invested in as an angel investor in 2015, have helped make this possible by giving Open Source communities an easy way to receive and manage funding transparently.</p>
<p>Today, Open Source runs much of the world's critical infrastructure. It powers government services, supports national security, and enables everything from public health systems to elections. This reliance means the third and final step in its evolution is here: governments must help fund Open Source.</p>
<p>Public funding would complement the role of volunteers and commercial sponsors, not replace them. This is not charity or a waste of tax money. It is an investment in the software that runs our essential services. Without it, we leave critical infrastructure fragile at the moment the world needs it most.</p>
<h3>The $8.8 trillion dependency</h3>
<p>A 2024 Harvard Business School study, <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4693148"><em>The Value of Open Source Software</em></a>, estimates that replacing the most widely used Open Source software would cost the world $8.8 trillion. If Open Source suddenly disappeared, organizations would have to spend 3.5 times more on software than they do today. Even more striking: 96% of that $8.8 trillion depends on just 5% of contributors.</p>
<p>This concentration creates fragility. Most of our digital infrastructure depends on a small group of maintainers who often lack stable funding or long-term support. When they burn out or step away, critical systems can be at risk.</p>
<p>Maintaining Open Source is not free. It takes developers to fix bugs, maintainers to coordinate releases, security teams to patch vulnerabilities, and usability experts to keep the software accessible. Without reliable funding, these essential tasks are difficult to sustain, leaving the foundations of our digital society exposed to risk.</p>
<p>Addressing this risk means rethinking not just funding, but also governance, succession planning, and how we support the people and projects that keep our society running.</p>
<h3>When digital sovereignty becomes survival</h3>
<p>Recent geopolitical tensions and policy unpredictability have made governments more aware of the risks of relying on foreign-controlled, proprietary software. Around the world, there is growing recognition that they cannot afford to lose control over their digital infrastructure.</p>
<p><a href="https://interoperable-europe.ec.europa.eu/collection/open-source-observatory-osor/news/denmark-embraces-open-source-software">Denmark recently announced a national plan</a> to reduce their dependency on proprietary software by adopting Open Source tools across its public sector.</p>
<p>This reflects a simple reality: when critical public services depend on foreign-controlled software, governments lose the ability to guarantee continuity and security to their citizens. They become vulnerable to policy changes and geopolitical pressures beyond their control.</p>
<p>As <a href="https://interoperable-europe.ec.europa.eu/collection/open-source-observatory-osor/news/denmark-embraces-open-source-software">Denmark's Ministry for Digitalisation explained</a>, this shift is about control, accountability, and resilience, not just cost savings. Other European cities and countries are developing similar strategies. This is no longer just an IT decision, but a strategic necessity for protecting national security and guaranteeing the continuity of essential public services.</p>
<h3>From Open Source consumption to contribution</h3>
<p>Most government institutions rely heavily on Open Source but contribute little in return. Sponsorship usually flows through vendor contracts, and while some vendors contribute upstream, the overall level of support is small compared to how much these institutions depend on said projects.</p>
<p>Procurement practices often make the problem worse. Contracts are typically awarded to the lowest bidder or to large, well-known IT vendors rather than those with deep Open Source expertise and a track record of contributing back. Companies that help maintain Open Source projects are often undercut by firms that give nothing in return. This creates a race to the bottom that ultimately weakens the Open Source projects governments rely on.</p>
<p>As I discussed in <a href="https://dri.es/balancing-makers-and-takers-to-scale-and-sustain-open-source"><em>Balancing makers and takers to scale and sustain Open Source</em></a>, sustainable Open Source requires addressing the fundamental mismatch between use and contribution.</p>
<p>Governments need to shift from Open Source consumption to Open Source contribution. The digital infrastructure that powers government services demands the same investment commitment as the roads and bridges that connect our communities.</p>
<h3>Drupal tells the story</h3>
<p>I have helped lead <a href="https://www.drupal.org/">Drupal</a> for almost 25 years, and in that time I have seen how deeply governments depend on Open Source.</p>
<p>The European Commission runs more than a hundred Drupal sites, France operates over a thousand Drupal sites, and Australia's government has standardized on Drupal as its national digital platform. Yet despite this widespread use, most of these institutions contribute little back to Drupal's development or maintenance.</p>
<p>This is not just a Drupal problem, and it is entirely within the rights of Open Source users. There is no requirement to contribute. But in many projects, a small group of maintainers and a few companies carry the burden for infrastructure that millions rely on. Without broader support, this imbalance risks the stability of the very systems governments depend on.</p>
<p>Many public institutions use Open Source without contributing to its upkeep. While this is legal, it shifts all maintenance costs onto a small group of contributors. Over time, that risks the services those institutions depend on. Better procurement and policy choices could help turn more public institutions into active contributors.</p>
<h3>The rise of government stewardship</h3>
<p>I am certainly not the only one calling for government involvement in Open Source infrastructure. In recent years, national governments and intergovernmental bodies, including the United Nations, have begun increasing investment in Open Source.</p>
<p>In 2020, the UN Secretary General's <a href="https://www.un.org/en/content/digital-cooperation-roadmap/"><em>Roadmap for Digital Cooperation</em></a> called for global investment in "digital public goods" such as Open Source software to help achieve the Sustainable Development Goals. Five years later, the UN introduced the <a href="https://unite.un.org/news/sixteen-organizations-endorse-un-open-source-principles">UN Open Source Principles</a>, encouraging practices like "open by default" and "contributing back".</p>
<p>At the European level, the <a href="https://en.wikipedia.org/wiki/Cyber_Resilience_Act">EU's Cyber Resilience Act</a> recognizes Open Source software stewards as "economic actors", acknowledging their role in keeping infrastructure secure and reliable. In Germany, the <a href="https://www.sovereign.tech/">Sovereign Tech Agency</a> has invested €26 million in more than <a href="https://www.sovereign.tech/tech">60 Open Source projects</a> that support critical digital infrastructure.</p>
<p>Governments and public institutions are also creating Open Source Program Offices (OSPOs) to coordinate policy, encourage contributions, and ensure long-term sustainability. In Europe, the European Commission's <a href="https://ec.social-network.europa.eu/@EC_OSPO">EC OSPO</a> operates the <a href="https://code.europa.eu/">code.europa.eu</a> platform for cross-border collaboration. In the United States, agencies such as the <a href="https://www.cms.gov/digital-service/open-source-program-office">Centers for Medicare &amp; Medicaid Services</a>, the <a href="https://www.usds.gov/">United States Digital Service</a>, the <a href="https://www.cisa.gov/">Cybersecurity and Infrastructure Security Agency</a>, and the <a href="https://digitalcorps.gsa.gov/">U.S. Digital Corps</a> play similar roles. In Latin America, Brazil's <a href="https://softwarepublico.gov.br/">Free Software Portal</a> supports collaboration across governments.</p>
<p>These efforts signal a shift from simply using Open Source to actively stewarding and investing in it at the institutional level.</p>
<h3>The math borders on absurd</h3>
<p>If the top 100 countries each contributed $200,000 a year to an Open Source project, the project would have a twenty million dollar annual budget. That is about what it costs to maintain less than ten miles of highway.</p>
<p>In my home country, Belgium, which has just over ten million people, more than one billion euros is spent each year maintaining roads. A small fraction of that could help secure the future of Open Source software like Drupal, which supports public services for millions of Belgians.</p>
<p>For the cost of maintaining 10 miles of highway, we could secure the future of several critical Open Source projects that power essential public services. The math borders on absurd.</p>
<h3>How governments can help</h3>
<p>Just as governments maintain roads, bridges and utilities that society depends on, they should also help sustain the Open Source projects that power essential services, digitally and otherwise. The scale of investment needed is modest compared to other public infrastructure.</p>
<p>Governments could implement this through several approaches:</p>
<ul>
<li>
<p><strong>Track the health of critical Open Source projects.</strong> Just like we have safety ratings for bridges, governments should regularly check the health of the Open Source projects they rely on. This means setting clear targets, such as addressing security issues within <em>x</em> days, having <em>y</em> active maintainers, keeping all third-party software components up to date, and more. When a project falls behind, governments should step in and help with targeted support. This could include direct funding, employing contributors, or working with partners to stabilize the project.</p>
</li>
<li>
<p><strong>Commit to long-term funding with stable timelines.</strong> Just as governments plan highway maintenance years in advance, we'd benefit from multi-year funding commitments and planning for critical digital infrastructure. Long-term funding allows projects to address technical debt, plan major updates, and recruit talent without the constant uncertainty of short-term fundraising.</p>
</li>
<li>
<p><strong>Encourage contribution in government contracts.</strong> Governments can use procurement to strengthen the Open Source projects they depend on. Vendor contribution should be a key factor in awarding contracts, alongside price, quality, and other criteria. Agencies or vendors can be required or encouraged to give back through coding, documentation, security reviews, design work, or direct funding. This ensures governments work with true experts while helping keep critical Open Source projects healthy and sustainable.</p>
</li>
<li>
<p><strong>Adopt "Public Money, Public Code" policies.</strong> When taxpayer money funds software for public use, that software should be released as Open Source. This avoids duplicate spending and builds shared digital infrastructure that anyone can reuse, improve, and help secure. The principle of <a href="https://publiccode.eu/">"Public Money? Public Code!"</a> offers a clear framework: code paid for by the people should be available to the people. Switzerland recently embraced this approach at the federal level with its <a href="https://interoperable-europe.ec.europa.eu/collection/open-source-observatory-osor/news/new-open-source-law-switzerland">EMBAG law</a>, which requires government-developed software to be published as Open Source unless third-party rights or security concerns prevent it.</p>
</li>
<li>
<p><strong>Scale successful direct funding models.</strong> The <a href="https://www.sovereign.tech/">Sovereign Tech Agency</a> has shown how government programs can directly fund the maintenance and security of critical Open Source software. Other nations should follow and expand this model. Replacing widely used Open Source software could cost an estimated 8.8 trillion dollars. Public investment should match that importance, with sustained global funding in the billions of dollars across countries and projects.</p>
</li>
<li>
<p><strong>Teach Open Source in public schools and universities.</strong> Instead of relying solely on proprietary vendors like Microsoft, governments should integrate Open Source tools, practices, and values into school and university curricula, along with related areas such as open standards and open data. This prepares students to participate fully in Open Source, builds a talent pipeline that understands Open Source, and strengthens digital self-reliance.</p>
</li>
</ul>
<h3>Keeping the core strong</h3>
<p>Concerns about political interference or loss of independence are valid. That is why we need systems that allow all stakeholders to coexist without undermining each other.</p>
<p>Government funding should reinforce the ecosystem that makes Open Source thrive, not replace it or control it. Companies and volunteers are strong drivers of innovation, pushing forward new features, experiments, and rapid improvements. Governments are better suited to a different but equally vital role: ensuring stability, security, and long-term reliability.</p>
<p>The most critical tasks in Open Source are often the least glamorous. Fixing bugs, patching vulnerabilities, updating third-party dependencies, improving accessibility, and maintaining documentation rarely make headlines, but without them, innovation cannot stand on a stable base. These tasks are also the most likely to be underfunded because they do not directly generate revenue for companies, require sustained effort, and are less appealing for volunteers.</p>
<p>Governments already maintain roads, bridges, and utilities, infrastructure that is essential but not always profitable or exciting for the private sector. Digital infrastructure deserves the same treatment. Public investment can keep these core systems healthy, while innovation and feature direction remain in the hands of the communities and companies that know the technology best.</p>
<h3>Conclusion</h3>
<p>Fifteen years ago, I argued that Open Source needed commercial sponsorship to thrive. Now we face the next challenge: governments must shift from consuming Open Source to sustaining it.</p>
<p>Today, some Open Source has become public infrastructure. Leaving critical infrastructure dependent on too few maintainers is a risk no society should accept.</p>
<p>The solution requires coordinated policy reforms: dedicated funding mechanisms, procurement that rewards upstream contributions, and long-term investment frameworks.</p>
<p><em>Special thanks to <a href="https://www.drupal.org/u/baddysonja">Baddy Sonja Breidert</a>, <a href="https://www.drupal.org/u/tim-d">Tim Doyle</a>, <a href="https://www.drupal.org/u/farriss">Tiffany Farriss</a>, <a href="https://www.drupal.org/u/mgifford">Mike Gifford</a>, <a href="https://www.drupal.org/u/owenlansbury">Owen Lansbury</a> and <a href="https://www.drupal.org/u/nick_vh">Nick Veenhof</a> for their review and contributions to this blog post.</em></p>

      
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zenobia Pay – A mission to build an alternative to high-fee card networks (177 pts)]]></title>
            <link>https://zenobiapay.com/blog/open-source-payments</link>
            <guid>44896085</guid>
            <pubDate>Thu, 14 Aug 2025 02:19:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zenobiapay.com/blog/open-source-payments">https://zenobiapay.com/blog/open-source-payments</a>, See on <a href="https://news.ycombinator.com/item?id=44896085">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Why we're open sourcing our payments platform</h2>
<p>Since Februray, Teddy and I have worked tirelessly on Zenobia Pay. Our mission: build an alternative to high-fee card networks (Visa, Mastercard) using bank transfers as payments. We were super excited by FedNow, the Federal Reserve's instant transfer rail, which inspired us to quit our jobs and do this full time. We thought, let's build QR code payments, like Pix or UPI or AliPay, but for the US. And we did! We built an instant clearing, mobile first, pay-by-bank network.</p>
<p>However, we failed to get any adoption besides thieves and mobsters. We tried cold outreach, door to door sales, and meeting with every friend of a friend in our lives. But after months of zero growth and $20,000 stolen, we've decided we are not the right people to make this happen. Too young, too unconnected to drive any adoption. That said, this is not an impossible task, just a difficult one. We are open sourcing Zenobia Pay with the hope that it will save time for somebody else who wants to pick up this mission.</p>
<p>If this sounds like you: great. Here is all the code. That said, with payments, you need more than just code to go live. You need a licensed banking partner. We purchased a SaaS solution through the fintech Orum.io, which has a partnership with another fintech, which has a partership with a bank. Orum was acquired by Stripe, though, and is shutting down its service. You will need to migrate to a different banking provider, like Trice or Column.</p>
<ul>
<li><a href="https://github.com/zenobia-pay/ios">https://github.com/zenobia-pay/ios</a></li>
<li><a href="https://github.com/zenobia-pay/zenobia-pay">https://github.com/zenobia-pay/zenobia-pay</a></li>
<li><a href="https://github.com/zenobia-pay/core">https://github.com/zenobia-pay/core</a></li>
</ul>
<h2>Who wants this?</h2>
<p>Over the course of building this, we went through three iterations of who we targeted. The product stayed more or less the same, but the customer changed.</p>
<h2>Iteration 1: SMBs</h2>
<p>First iteration is the obvious one: give this service to small businesses who have low net margins. If you have a 3% net margin, saving 2% on interchange nearly doubles your profits! However, this has a few problems:</p>
<ul>
<li><p><strong>Problem 1: Integration.</strong> In person sales means you need a POS or POS partner. This dramatically increases your deployment times. Deployment times are what killed Kash, who tried this same idea in the 2010s (<a href="https://jessicafurseth.com/2016/01/30/meet-kash-the-most-exciting-payment-startup-in-town/">https://jessicafurseth.com/2016/01/30/meet-kash-the-most-exciting-payment-startup-in-town/</a>)</p>
</li>
<li><p><strong>Problem 2: Support.</strong> SMBs are difficult customers because they have high support needs, but (by nature of being small) bring in very little revenue. You might make $30/month in fees from a small business that needs 10 hours a week of white glove support.</p>
</li>
<li><p><strong>Problem 3: Adoption.</strong> Merchants told us they want this! But when we showed them the system their customers would need to use (since we didn't have a POS, it would be QRs on the merchant's phone), they dragged their feet. Their stated preferences were different from their revealed preferences. When it came down to it: they don't actually care about saving 2% on fees.</p>
</li>
</ul>
<h2>Iteration 2: High ticket items + fraud insurance</h2>
<p>Credit cards get swiped or stolen. Thieves use these stolen cards to purchase expensive items they can resell. Customers file chargebacks, and the merchant is on the hook. To legibilize this risk, high-end merchants pay for changeback insurance (the two big players are called Riskified and Signified). These companies aggregate credit card chargeback data to build a risk model and reject risky transactions.</p>
<p>Mobile QR payments do not have the issue of being swiped / stolen, because the merchant site never sees account / routing numbers. Stolen bank account credentials are quite rare compared to stolen credit card numbers. Plus, if you steal a bank account, you can wire the money away, rather than purchase something with it. Because of this rareness, we can bundle Riskified style fraud chargeback insurance with our product. That way, we're not just a slightly cheaper alternative for payments, but solve a pressing problem.</p>
<p>With this iteration, we went to YCombinator as payments for selling high ticket items online. We enable jewelers and luxury brands to accept pay-by-bank to avoid credit card fees and fraud chargebacks. However, we ran into a few problems:</p>
<ul>
<li><p><strong>Problem 1: Reg E and ACH return risk.</strong> There is no API accessible "pull request" for money besides ACH. FedNow is push only from an account you control. FedNow does have RfPs but they have basically no adoption. So for now, you have to build ACH return risk models. PayPal notoriously lost half their investor money to ACH fraud as they built up their risk model. Fortunately, ACH return risk has been commodified with Plaid Signal, so you can get at-scale return risk profiling from day 1. That said, we have shifted to high ticket purchases, where the risk of fraud is high. With every purchase, you underwrite a 60 day tail risk of losing the entire cost of merchandise, in exchange for a fee of 1% of value. Can we at scale keep a return rate low enough to profit?</p>
</li>
<li><p><strong>Problem 2: Merchants don't care.</strong> Same as iteration 1. Merchants said they were interested; we met with them, and they dragged their feet. Not a pressing problem. Stated preferences vs revealed preferences.</p>
</li>
<li><p><strong>Problem 3: Checkout conversion.</strong> We are a new "Pay with" button at checkout. Why would customers convert when they have rewards points on credit cards? We proposed merchants "split the difference" in fee savings with their customer, giving customers ~1% in at-checkout "cashback". But this is just a worse version of credit card rewards.</p>
</li>
</ul>
<h2>Iteration 3: Luxury proof of purchase + resale</h2>
<p>We spent a lot of time thinking about the conversion question. When we talked to merchants, they would ask us two questions:</p>
<ol>
<li>Will this bring in new customers?</li>
<li>Will this increase checkout conversion?</li>
</ol>
<p>We would start talking about card processing fees and chargeback insurance costs, so what they heard was:</p>
<ol>
<li>No</li>
<li>No.</li>
</ol>
<p>And they're right. Mobile QR payments ARE higher friction than credit card payments, because customers need to scan the QR and (if it's their first ever purchase) connect their bank account. We can't compete on rewards with credit cards without losing money, because we make less in interchange than they do. So, you need to compete on another, entirely different axis.</p>
<p>And so that's what we did. Zenobia Pay serves as digital proof of purchase for the entire lifespan of luxury goods, so brands can earn verification fees on the $39B resale market, which is growing 3 times faster than new sales.</p>
<p>Now merchants are more interested, because we promise to bring in NEW revenue, instead of lower their cost of EXISTING revenue.</p>
<p>It also solves the customer conversion problem. You don't convert anyone by being a worse version of an existing thing. And to customers, our split-the-difference fees are just a worse version of credit cards. You have to make a new category: Buy-to-resell, buy-it-for-life, buy-to-flex. Customers who buy and resell things and want proof of purchase. Customers who want to show off what they buy on social media with some provenance that it's real.</p>
<p>All that said, we still had one big problem: <strong>Europe</strong></p>
<p>We had a tough time getting in the room with anyone. When we met with luxury brands, they told us they were highly protective of their brand experience. It was very clear that we were NOT insiders. Unlike California, where people respond to cold outreach in earnest and good faith, we faced nothing but cold shoulders.</p>
<p>It was clear to us that it would take months, even years to get adoption by luxury houses. So, in the meantime we continued to pursue online jewelers who cared more about Iteration 1 and Iteration 2 than Iteration 3.</p>
<h2>How I would continue</h2>
<ol>
<li>Abandon jewelry and iteration 2 entirely. What finally killed us was being defrauded by "custom jewelers" who were Russian mobsters using stolen SSNs to commit ACH fraud.</li>
<li>Focus on Iteration 3 if you are well connected in luxury. Verticalize the whole payments experience- you are the card network AND the card processor, Visa + Stripe. Run it like a CPG or a luxury brand. Focus on the post payment experience.</li>
</ol>
<p>That brings us up to the present. We realized that we were back at square one, and with our product so far ahead of our sales, decided to pivot away from payments entirely. I learned a lot about payments and startups and had a lot of fun. While I'm disappointed it failed, I hope somebody else reads this and is inspired to take up the cause.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Medieval People Got Right About Learning (2019) (107 pts)]]></title>
            <link>https://www.scotthyoung.com/blog/2019/06/07/apprenticeships/</link>
            <guid>44895497</guid>
            <pubDate>Thu, 14 Aug 2025 00:29:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scotthyoung.com/blog/2019/06/07/apprenticeships/">https://www.scotthyoung.com/blog/2019/06/07/apprenticeships/</a>, See on <a href="https://news.ycombinator.com/item?id=44895497">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>We tend to assume that if people today and people five hundred years ago do things differently, it’s because we’ve figured out a better way to do it. After all, we have microscopes, democracy and penicillin. People in the middle ages <a href="https://en.wikipedia.org/wiki/Cat-burning">lit cats on fire for fun</a>. </p>
<p>Yet despite overwhelming progress, it’s ironically in the area of education that we may be the ones who have it backward.</p>
<figure><img decoding="async" width="800" height="297" src="https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/apprentice-vs-school.png" alt="" srcset="https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/apprentice-vs-school.png 800w, https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/apprentice-vs-school-300x111.png 300w, https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/apprentice-vs-school-768x285.png 768w" sizes="(max-width: 800px) 100vw, 800px"></figure>
<p>Apprenticeships were, for a long time, the dominant way of learning professional skills. A master agrees to show you how to perform a useful skill. In exchange, he got a bunch of free labor from you while you were learning.</p>
<h2>Why Apprenticeships Beat Classrooms</h2>
<p>There’s a few good reasons to prefer the apprenticeship model to classes.</p>
<h3>1. Transfer is Hard.</h3>
<div>
<figure><img decoding="async" width="500" height="414" src="https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/transfer-woes.png" alt="" srcset="https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/transfer-woes.png 500w, https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/transfer-woes-300x248.png 300w" sizes="(max-width: 500px) 100vw, 500px"></figure>
</div>
<p>The first has to do with transfer. It’s been well-known for decades that learning general abstractions is very hard. Instead, what we learn tends to be hyperspecific. It’s only after learning many hyperspecific things that we get the ability to apply it to completely novel problems.</p>
<p>Consider the findings that economics students tend not to perform better on problems which require economic reasoning, that taking a high-school psychology class doesn’t improve performance in a later psychology class in college, or even more startlingly, that a significant fraction of American high-school graduates can’t calculate the cost of ordering office supplies, given a list.<sup>[<a href="#1">1</a>][<a href="#2">2</a>]</sup></p>
<p>These educational failures are an embarrassment. But they more likely reflect the simple fact about transfer: if you’ve only ever done math, psychology or economics problems in a very narrow setting, you’re unlikely to apply them in the real world, even if you could in principle.</p>
<p>Classes are divorced from the practical applications of learning. Apprenticeships train in exactly the situation you’d want to apply the skill.</p>
<h3>2. Learn by Doing (and Watching).</h3>
<figure><img loading="lazy" decoding="async" width="800" height="249" src="https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/doing-and-watching-vs-studying.png" alt="" srcset="https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/doing-and-watching-vs-studying.png 800w, https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/doing-and-watching-vs-studying-300x93.png 300w, https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/doing-and-watching-vs-studying-768x239.png 768w" sizes="auto, (max-width: 800px) 100vw, 800px"></figure>
<p>The second reason to prefer apprenticeships is that they more easily mimic how human beings learn almost every other skill we need to survive: by doing and watching.</p>
<p>The doing aspect is obvious, and related to the problem of transfer I described above. The watching aspect is more interesting. Human beings, it appears, are nearly unique in the animal world for being able to learn something by watching somebody else do it.</p>
<p>Joseph Henrich, in his excellent book, <a href="https://www.amazon.com/Secret-Our-Success-Evolution-Domesticating/dp/0691166854">The Secret of Our Success</a>, argues that this social learning, not raw intelligence, is what truly separates us from non-human primates or other intelligent animals.</p>
<p>Interestingly, it’s often not so important to actually understand the reasons behind why you should do something as it is to see it being performed correctly. In one interesting study, participants learned through iteration to improve a type of rolling machine, but they couldn’t give an accurate theory why their design worked.</p>
<p>Classrooms don’t follow this principle. Instead, they try to teach broad theories (the why) to eventually make it into the how. Consider medical students, who spend years in the classroom learning theories of chemistry and biology before studying medicine for another few years before working with patients. </p>
<p>Apprenticeships, which focus on practice first, allow you to learn how you were designed to learn. By doing and watching other people.</p>
<h3>3. Most Theories are Wrong Anyways.</h3>
<figure><img loading="lazy" decoding="async" width="800" height="398" src="https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/pyramid-model-of-learning.png" alt="" srcset="https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/pyramid-model-of-learning.png 800w, https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/pyramid-model-of-learning-300x149.png 300w, https://www.scotthyoung.com/blog/wp-content/uploads/2019/06/pyramid-model-of-learning-768x382.png 768w" sizes="auto, (max-width: 800px) 100vw, 800px"></figure>
<p>A lot of people reason on a pyramid model of knowledge. This says all knowledge is built on top of more fundamental layers, with the foundation needing to be bigger than the layer above it or it will collapse. Biology is grounded on chemistry, which is grounded on physics, grounded on math. Our knowledge of physics can’t exceed our knowledge of math.</p>
<p>Except, this model doesn’t work at all. Knowledge isn’t a pyramid. In general, we’re almost always learning from the “middle” of something, with both more complicated theories and more fundamental theories being less well-understood than the central phenomena we started with.</p>
<p>A clear example of this is science itself. We have tons of scientific knowledge. The pyramid approach would say that this must mean we have an ironclad theory of how scientific knowledge is produced. Except we don’t. We have some theories of science, but they’re a lot shakier and contentious than the actual science we created.</p>
<p>Classroom learning tends to be based on the pyramid model. Instead of working directly with a practical example, it argues that we should start by teaching a more abstract theory from which all practical examples can be derived. Learn the rules of conjugation before sentences. Learn Newton’s laws before trying to guess at some practical results of physics. Learn computational theory before coding.</p>
<p>Not all classes are this extreme, but the pyramid model still has a dominant influence in academic learning. Apprenticeships, in contrast, often ignore theory altogether. Which is good, because the theories often aren’t as accurate as the practical knowledge anyways.</p>
<h2>How to Create Your Own Apprenticeship</h2>
<p>It’s unfortunate that true apprenticeships have gone out of fashion in many fields which could benefit from them. However, if you understand how apprenticeships work, you can try to inject more of the same principles into your own learning.</p>
<h3>1. Start by Learning Concrete Things for a Specific Purpose.</h3>
<p>The first step is to begin your learning with a specific purpose in mind. Many people think that if they restrict their initial purpose too much, they won’t ever learn fully general skills. In truth, the opposite is closer to the truth. By really learning for a specific purpose, you paradoxically acquire skills that generalize better than if you had started trying to learn everything from first principles.</p>
<p>Examples: </p>
<ul>
<li>Learn to code by picking a particular piece of software or script you want to make.</li>
<li> Learn a language by figuring out exactly where you want to use it (i.e. while traveling in Spain? Watching movies in Japanese? Reading literature in French?)</li>
<li> Learn history by deciding to write an essay on the military strategies of ancient Rome, rather than by abstractly trying to learn a bunch of history.</li>
</ul>
<h3>2. Theory Builds on Practice, Not the Other Way Around.</h3>
<p>Theory is important to learn, but it is more useful after the foundation of practical knowledge has been built. Computational theories after writing code. Grammar after mastering basic sentence patterns. Music theory after learning to play a bunch of songs with your guitar.</p>
<p>The flipside is, theory is actually a lot of fun once you have some foundation in practice. I did the <a href="https://www.scotthyoung.com/blog/myprojects/mit-challenge-2/">MIT Challenge</a> without having taken more than a couple programming classes in college. But I had spent my high-school days tinkering with little games and applications. For me, the theory-based classes at MIT were perfect, but they might have been a waste of time if I had never tried to make anything before.</p>
<h3>3. Immerse Yourself in an Expert Practice Ecosystem.</h3>
<p>Immersion in an <a href="https://www.scotthyoung.com/blog/2019/01/03/ultralearning-environments/">ecosystem of expert practitioners</a> is one of the best moves you can make for accelerating your learning. Unfortunately, this is often one of the hardest steps to take because these environments are often gated, difficult to access or invisible to the outside.</p>
<p>Ironically, for all my jabs at classroom learning, academia in the graduate levels and beyond is actually this kind of ecosystem! Professors (masters) take in grad students (apprentices) and get them to work for very little money so that they can learn to produce research.</p>
<p>The easiest way to do this is to join an existing practice ecosystem. That could be at a school (research at Harvard), company (machine learning at Google), place (French in France) or even a community (speedrunning through online forums). </p>
<p>If you can’t find it, then you can also make one. When I went to write my first book, I had already made so many friends with other authors that I knew how many processes worked, despite never having published a book myself. The same is true with entrepreneurship. Whenever I have a challenge in my business, I usually know of a few people who are better than I am, and can offer advice.</p>
<p>Learning by doing and learning by watching sound obvious, but they’re often obscured in our classroom-focused style of education. We might not bring back apprenticeships, but by bringing back the features that work, we can all hopefully learn a bit better.</p>
<p>[<a name="1">1</a>] – Haskell, Robert E. <em>Transfer of learning: Cognition and instruction</em>. Elsevier, 2000.<br>[<a name="2">2</a>] – Caplan, Bryan. <em>The case against education: Why the education system is a waste of time and money</em>. Princeton University Press, 2018.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Igor Babuschkin, a co-founder of xAI, has announced his departure (118 pts)]]></title>
            <link>https://techcrunch.com/2025/08/13/co-founder-of-elon-musks-xai-departs-the-company/</link>
            <guid>44895270</guid>
            <pubDate>Wed, 13 Aug 2025 23:51:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/08/13/co-founder-of-elon-musks-xai-departs-the-company/">https://techcrunch.com/2025/08/13/co-founder-of-elon-musks-xai-departs-the-company/</a>, See on <a href="https://news.ycombinator.com/item?id=44895270">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">Igor Babuschkin, a co-founder of Elon Musk’s xAI startup, announced his departure from the company on Wednesday in a <a href="https://x.com/ibab/status/1955741698690322585" target="_blank" rel="noreferrer noopener nofollow">post on X</a>. Babuschkin led engineering teams at xAI and helped build the startup into one of Silicon Valley’s leading AI model developers just a few years after it was founded.</p>

<p>“Today was my last day at xAI, the company that I helped start with Elon Musk in 2023,” Babuschkin wrote in the post. “I still remember the day I first met Elon, we talked for hours about AI and what the future might hold. We both felt that a new AI company with a different kind of mission was needed.”</p>

<figure><div>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>Today was my last day at xAI, the company that I helped start with Elon Musk in 2023. I still remember the day I first met Elon, we talked for hours about AI and what the future might hold. We both felt that a new AI company with a different kind of mission was needed.</p><p>Building…</p></div>— Igor Babuschkin (@ibab) <a rel="nofollow" href="https://twitter.com/ibab/status/1955741698690322585?ref_src=twsrc%5Etfw">August 13, 2025</a></blockquote>
</div></figure>

<p>Babuschkin is leaving xAI to launch his own venture capital firm, Babuschkin Ventures, which he says will support AI safety research and back startups that “advance humanity and unlock the mysteries of our universe.”</p>







<p>The xAI co-founder says he was inspired to start the firm after a dinner with Max Tegmark, the founder of the Future of Life Institute, in which they discussed how AI systems could be built safely to encourage the flourishing of future generations. In his post, Babuschkin says his parents immigrated to the U.S. from Russia in pursuit of a better life for their children.</p>

<p>Babuschkin’s departure comes after a tumultuous few months for xAI, in which the company became engrossed in several scandals related to its AI chatbot Grok. For instance, Grok was found to <a href="https://techcrunch.com/2025/07/10/grok-4-seems-to-consult-elon-musk-to-answer-controversial-questions/">cite Musk’s personal opinions</a> when trying to answer controversial questions. In another case, xAI’s chatbot went on <a href="https://techcrunch.com/2025/07/08/grok-is-being-antisemitic-again-and-also-the-sky-is-blue/">antisemitic rants</a> and called itself “Mechahitler.” Most recently, xAI unveiled a new feature in Grok that allowed users to make AI-generated videos <a href="https://www.theverge.com/report/718975/xai-grok-imagine-taylor-swifty-deepfake-nudes" target="_blank" rel="noreferrer noopener nofollow">resembling nude public figures</a>, such as Taylor Swift.</p>

<p>These scandals have at times overshadowed the performance of xAI’s models, which are <a href="https://techcrunch.com/2025/07/09/elon-musks-xai-launches-grok-4-alongside-a-300-monthly-subscription/">state-of-the-art</a> on several benchmarks compared to AI models from OpenAI, Google DeepMind, and Anthropic.</p>

<p>Prior to co-founding xAI, Babuschkin was part of a research team at Google DeepMind that pioneered AlphaStar in 2019, a breakthrough AI system that could defeat top-ranked players at the video game StarCraft. Babuschkin also worked as a researcher at OpenAI in the years before it released ChatGPT.</p>
<div>
		
		<p>Techcrunch event</p>
		<div>
			
			<p><span>San Francisco</span>
													<span>|</span>
													<span>October 27-29, 2025</span>
							</p>
			
		</div>
	</div>

<p>In his post, Babuschkin details some of the challenges he and Musk faced in building up xAI. He notes that industry veterans called xAI’s goal of building its Memphis, Tennessee supercomputer in just three months “impossible.” </p>

<p>xAI was able to build its AI supercomputer in record time, however, <a href="https://time.com/7308925/elon-musk-memphis-ai-data-center/" target="_blank" rel="noreferrer noopener nofollow">environmentalists warn</a> that the temporary gas turbines powering the cluster are pumping out emissions into neighboring communities and exacerbating their longstanding health issues.</p>

<p>Nevertheless, Babuschkin says he’s already looking back fondly on his time at xAI, and “feels like a proud parent, driving away after sending their kid away to college.”</p>

<p>“I learned 2 priceless lessons from Elon: #1 be fearless in rolling up your sleeves to personally dig into technical problems, #2 have a maniacal sense of urgency,” said Babuschkin.</p>







<p><em>We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&nbsp;</em><em><a target="_blank" href="https://survey.researchresults.com/survey/selfserve/53b/g002/s0064551?list=tcap#?" rel="noreferrer noopener nofollow">this survey</a></em><em>&nbsp;to let us know how we’re doing and get the chance to win a prize in return!</em></p>
</div><div>
	
	
	
	

	
<div>
		<p>Maxwell Zeff is a senior reporter at TechCrunch specializing in AI. Previously with Gizmodo, Bloomberg, and MSNBC, Zeff has covered the rise of AI and the Silicon Valley Bank crisis. He is based in San Francisco. When not reporting, he can be found hiking, biking, and exploring the Bay Area’s food scene.</p>
<p>You can contact or verify outreach from Maxwell by emailing <a href="mailto:maxwell.zeff@techcrunch.com">maxwell.zeff@techcrunch.com</a> or via encrypted message at mzeff.88 on Signal.</p>	</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/maxwell-zeff/" data-event="button" href="https://techcrunch.com/author/maxwell-zeff/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open Banking and Payments Competition (128 pts)]]></title>
            <link>https://www.bitsaboutmoney.com/archive/open-banking-and-payments-competition/</link>
            <guid>44895222</guid>
            <pubDate>Wed, 13 Aug 2025 23:44:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bitsaboutmoney.com/archive/open-banking-and-payments-competition/">https://www.bitsaboutmoney.com/archive/open-banking-and-payments-competition/</a>, See on <a href="https://news.ycombinator.com/item?id=44895222">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Much of the operation of the financial industry is legible to people outside of it. Your credit card works basically like you understand it to (excepting the occasional <a href="https://www.complexsystemspodcast.com/episodes/credit-card-rewards-interchange/">mythmaking about second order consequences</a>). Debates about what terms banks are allowed to offer on credit cards are fairly straightforward and can be easily followed by non-specialists.</p><p>But some issues are under the hood, and a societal debate about them doesn’t exactly wear its consequences on its sleeves. Consider the controversy over <a href="https://www.consumerfinance.gov/rules-policy/notice-opportunities-comment/archive-closed/dodd-frank-act-section-1033-consumer-access-to-financial-records/">Section 1033 of the Dodd-Frank Act</a> (and even that framing is an effective medication for insomnia).</p><p>In July, JPMorgan Chase <a href="https://www.ft.com/content/85ccc517-4a34-4221-aec7-4d8a72a21f35">announced</a> its intention to charge fintechs for access to so-called Open Banking data. This comes amidst a consortium of banks trying to sue this hithertofore obscure regulation out of existence.</p><p>Almost all discussions of it center on “data”, but it’s actually a fight about payments, and whether banks have a right to monopolize and charge for all economic activity their users engage in, irrespective of whether the bank operates the payment method.</p><p>Cards on the table: I previously worked at, and am an advisor to, Stripe, a financial infrastructure company which facilitates customers’ use of both bank-sponsored (cards, etc) and competing (<a href="https://docs.stripe.com/payments/link/instant-bank-payments">account-to-account</a>, <a href="https://docs.stripe.com/crypto/stablecoin-payments">stablecoins</a>, etc) payment methods. Stripe does not necessarily endorse what I say in my personal spaces. (I’m also a user and tiny shareholder of Chase. One presumes they also don’t endorse what I say in my personal spaces.)</p><h2 id="the-genesis-of-section-1033">The genesis of Section 1033</h2><p>The Dodd-Frank Act was passed in the wake of the 2008 financial crisis. It included a combination of needed reforms and, effectively, partial negotiated settlements for the way in which banks had reaped enormous profits originating mortgages of less-than-stellar quality then left taxpayers holding the bag once those mortgages could not be repaid.</p><p>We’ve previously discussed one of the knuckle raps: banks had their debit card interchange capped, with an exemption for small banks. (Interchange is the fee card-accepting businesses pay to transact with bank customers.) The <a href="https://www.bitsaboutmoney.com/archive/community-banking-and-fintech/">Durbin Amendment became a major pillar of fintech companies</a>, as it established a revenue model for them. It also became something of a lifeline for smaller financial institutions, particularly those that partnered with fintechs.</p><p>Did banks <em>like</em> the interchange cap? No. It made a very lucrative line of business rather less lucrative. Taxpayers had provided <a href="https://home.treasury.gov/data/troubled-asset-relief-program">about $245 billion</a> in capital to backstop banks, and they (through the ordinary operation of a representative democracy) got a post-hoc concession for it.&nbsp;</p><p>The interchange cap was not the only concession in the Dodd-Frank Act. Section 1033 was another one: it is designed to increase competitiveness in financial services by establishing a presumption that banks must allow users to access their own data, including through competing providers.</p><p>In the intervening years, that competition has arrived. The banks do not like it, and would prefer it if it went away.</p><h2 id="bootstrapping-payment-methods-with-open-banking">Bootstrapping payment methods with Open Banking</h2><p>Financial institutions offer their customers a complex bundle of services.</p><p>You might reasonably expect that Open Banking is a fight over the budgeting app space. The banks have, via the magic of account records, a large portion of the underlying data about a household’s finances. You could imagine software using Open Banking to allow it to slurp in transactions and then categorize them. That would compete against the <em>lackluster</em> offerings the large banks have in their apps.</p><p>But Open Banking is not <em>actually</em> a fight over budgeting apps. Banks don’t make money on them and the best known standalone budgeting app, Mint, was <a href="https://investors.intuit.com/news-events/press-releases/detail/1005/intuit-completes-acquisition-of-mint-com">acquired for a relatively small amount of money</a>.</p><p>Payments, on the other hand, are an <em>enormous</em> business. They are monetized both by banks and by a diverse ecosystem of fintech providers.</p><p>The data banks find it annoying to make Open are, principally, account numbers. This is because, due to the <a href="https://www.bitsaboutmoney.com/archive/the-long-shadow-of-checks/">long shadow of checks</a>, possession of an account number (plus the routing number, identifying the bank) is sufficient to attempt to debit a bank account. <a href="https://www.bitsaboutmoney.com/archive/bank-transfers-as-a-payment-method/">Direct account-to-account transfers, including “pulls”, are a common payment method</a> in many countries, but they are not a large share of consumer to business payments in the United States.</p><p>Why not? One reason is that the user experience of asking someone for their account number is pretty awful. There is no way to check in real time whether an account actually exists. Credit card numbers, in addition to having infrastructure which allows you to query them in real time, are <a href="https://en.wikipedia.org/wiki/Luhn_algorithm">specifically formatted</a> so that typos in them are easily catchable.</p><p>Since you can’t know whether the account exists you certainly can’t know its current balance or whether a transaction posted against it today will succeed in a few days or be reversed for insufficient funds (or another reason). This means that businesses which use account transfers as a payment method would frequently suffer credit losses if they released goods or services at the time of “payment.” For many businesses, that isn’t a worthwhile tradeoff.</p><p>So they keep using cards. Cards give much stronger (but not foolproof) real-time guarantees of funds availability and likelihood of a transaction going through successfully. The ergonomics of card acceptance, at the register, through your phone, or in a web browser, are also much more palatable to most customers.</p><p>Several fintech companies, including Stripe, realized that they could use Open Banking to make account-to-account payments something customers would actually enjoy. The user is prompted at checkout whether they’d like to pay directly from their bank account. They log into their bank account and grants the fintech read access. This is a much stronger signal of authorization than simply knowing an account number. (We print those on <em>every check</em>, after all, and a check is designed to be handed to a cashier or waiter you’ll never meet again.) The fintech then grabs the account number and perhaps e.g. looks up the current balance.</p><p>Then, they can pull money from the account, through an ACH debit.</p><p>The ACH debit itself is <em>not</em> Open Banking. It is the ordinary operation of existing payment rails in the financial system. The ACH debit was just <em>made much more convenient</em> by Open Banking.</p><h2 id="a-brief-note-about-aggregators">A brief note about aggregators</h2><p>Most use of Open Banking is through so-called aggregators. Plaid and Yodlee are well-known examples.</p><p>Prior to the existence of Open Banking, the aggregators (and businesses which needed the data they can make available) were largely forced to build supportability networks, bank by bank, by writing so-called screenscraping software. Screenscraping software emulates someone typing the password into a bank’s website then browses through <em>a live bank account </em>to extract the information needed from it. Hopefully that screenscraping software isn’t bugged, because bugs in scrapers that interface with consequential systems are <em>terrifying</em>.</p><p>Aggregators would then ask users to <em>share their bank account passwords</em>, so they could operate the bank accounts via software automation, to get the data the aggregators’ business customers were interested in. Like, say, account numbers.</p><p>This is a worse model for users and security of the banking system than Open Banking, because sharing bank account passwords leads to misuse of accounts. The flow for Open Banking, in the best implementations, redirects users to the bank site to authorize the data sharing, without forcing the user to irrevocably cough up the keys to the kingdom.</p><h2 id="open-banking-enables-lower-cost-payment-rails">Open Banking enables lower cost payment rails</h2><p>ACH debits are not new. Businesses have been able to use them for decades. You very likely use them yourself to e.g. pay recurring bills every month, like utilities, mortgage, or credit cards. ACH debits have just been very annoying to use for payments online or at cash registers, and so almost all consumer to business payments go over card rails instead.</p><p>ACH debits are almost free.</p><p>NACHA, which administers ACH, <a href="https://www.nacha.org/system/files/2024-09/2025%20Schedule%20of%20Fees.pdf">charges</a> a per-transaction fee of ​​1.85 <em>hundredths of a cent</em>. This compares favorably to regulated debit card interchange (21 <em>cents</em> plus five basis points of the transaction size) and extremely favorably to Durbin-exempt debit cards or credit cards (generally about 2.X% of the transaction size plus 20-30 cents). The interchange fee is <a href="https://www.bitsaboutmoney.com/archive/how-credit-cards-make-money/">paid mostly</a> to the card issuing banks.</p><p>Banks would strongly prefer the world <em>not</em> make novel payment methods that are convenient and cost accepting businesses less than cards. Banks are interested in Section 1033 because they want to continue earning interchange revenue on coffee purchases and software subscription invoices.&nbsp;</p><p>But payments for goods and services are not the only interesting Open Banking use case. Useful infrastructure, once it exists, tends to get incorporated into everything.</p><p>When you open a brokerage account or engage with crypto companies, you are quite likely to pass through an Open Banking flow to link your existing bank account. You’ll use your linked bank account to fund your investments and, hopefully, eventually receive your returns.&nbsp;</p><p>Older users might remember that this used to require asking the brokerage to make trial transactions, typically pushing two ACH payments under $1 in total and asking you to confirm the amounts. This would demonstrate that you hadn’t typoed your bank account number, that the account could actually accept transfers, and that you (presumptively) had authorized access to that account, given that you could read recent transactions at will.</p><p>Trial transactions are <em>painful for all parties</em>. They insert a multi-day wait into the account opening process, and many customers abandon the process during that lull. Brokerages and fintechs were overjoyed that Open Banking largely allowed them to move away from trial transactions to authorize every new account.</p><p>There are also clever uses of Open Banking to piggyback on banks as oracles. For example, how do you, a financial institution or insurance company, know that I, a particular natural person, have authority to direct Kalzumeus Software, LLC to open a new financial account? One way you could establish that is to ask me to submit a copy of the LLC’s Articles of Organization and a Certificate of Good Standing from the great state of Nevada. Then you pass those to a backoffice paralegal, who can ascertain that the Articles name me the Managing Member, and empower the Managing Member to open new financial accounts. This costs $50 to involve Nevada, and very many small businesses in America will not succeed at the task “please locate an authoritative copy of your Articles of Organization.”</p><p>A <em>much faster</em> way is to use an Open Banking aggregator to read a bank account statement issued to Kalzumeus Software, LLC. This allows a second financial institution to <em>make the reasonable inference</em> that if I habitually direct a small business’ banking, as demonstrated by being able to grant access to its accounts, <em>then I probably direct a small business’ banking</em>. This will save their operations team from reviewing 100 pages of boilerplate and cut down on account opening time. (This is one of the rare and underacknowledged benefits of <a href="https://www.bitsaboutmoney.com/archive/kyc-and-aml-beyond-the-acronyms/">Know Your Customer</a> regulations. Since banks are understood to have KYC responsibilities, the bank “vouching” for you as a customer in this fashion is treated as strong evidence by others in the economy.)&nbsp;</p><p>So why is Open Banking in the news now? We’ve had Open Banking for almost 15 years. The competing payment products <em>work and work well</em>. They are lower cost to accepting businesses and easy for customers to start using. Customers are switching to them in increasing numbers. Not <em>all</em> of them, but enough to worry the banks into wanting to strangle the upstarts.</p><p>This has happened via a regulatory push, litigation, and ultimatums over fees.</p><h2 id="the-cfpb-completed-rulemaking-for-open-banking">The CFPB completed rulemaking for Open Banking</h2><p>The Consumer Financial Protection Bureau finalized its <a href="https://www.consumerfinance.gov/rules-policy/final-rules/required-rulemaking-on-personal-financial-data-rights/">rule for Section 1033</a> in late 2024. As you can tell by the lag between 2010 (when the Dodd-Frank Act was passed) and 2024, it was something of <em>an involved process</em>.</p><p>Relevantly, the CFPB which passed this rule was the Biden administration CFPB. I try to be non-partisan in professional spaces but will need to neutrally observe how partisan players have seen the CFPB.</p><p>The CFPB was <em>not well loved</em> by many people in the finance industry or the fintech community. Critics alleged that the CFPB was less a federal agency and more a one-woman show, with the stars being Senator Elizabeth Warren and a ventriloquism dummy. This was unfair. The CFPB staff was actually quite intelligent in anticipating Senator Warren’s preferred positions and rulemaking to achieve them without the dreary necessity of her writing legislation or convincing Congress to vote for it.</p><p>As I <a href="https://www.bitsaboutmoney.com/archive/debanking-and-debunking/">mentioned last December in discussing the debanking discourse</a>, influential supporters of the second Trump campaign, including fintech and crypto investors, wanted the CFPB’s scalp. They essentially got what they wanted. The CFPB was <a href="https://apnews.com/article/donald-trump-doge-cfpb-elon-musk-456b747c367fccbcf3b74d2893cd1a35">hollowed out</a> early in the new administration.</p><p>In a swift and ironic turn of events, a policy promoted by the crypto industry due to their frustration with the decisions of large banks (regarding their industry’s supportability) was quickly used by large banks for commercial advantage, catching the crypto industry in the crossfire.</p><p>Prior to the election, the Bank Policy Institute, a banking industry trade group, and the Kentucky Bankers Association <a href="https://bpi.com/banks-challenge-cfpb-rule-jeopardizing-security-and-privacy-of-consumer-financial-data/">sued</a> to prevent the CFPB’s rulemaking from taking effect. I think an informed person would understand that their legal arguments are pretextural. Their <em>policy</em> arguments, against the normative intent of Open Banking, I’ll return to below.</p><p>The CFPB initially defended the suit vigorously, but the newly hollowed out CFPB in June <a href="https://www.consumerfinancemonitor.com/2025/06/05/cfpb-states-the-section-1033-open-banking-rule-exceeds-its-authority/">announced its intention to surrender</a>.</p><p>This has caused a bit of chaos in Washington, as Section 1033 is administered by the CFPB but is part of the financial regulatory apparatus that crypto companies <em>actually like</em>.</p><p>Exchanges largely monetize by charging a vig on crypto purchases, and the so-called “onramp” (transfering money from the traditional financial system to the crypto ecosystem) enables the rest of their revenue (such as e.g. receiving a cut of interest earned by stablecoin issuers or staking the coins owned by customers).</p><p>Exchanges want to accomplish the onramp at the lowest possible cost, which is through ACH debits. Their desired outcome is the new user uses an aggregator to authorize a debit from their bank account. Then, the debit is very close to free, both for the first transaction and also for subsequent transactions using the same banking details. (The exchange bears a bit of credit risk, since the debit is not known to settle successfully until about two business days later and it can be reversed long after that if it was fraudulent. These issues <a href="https://s27.q4cdn.com/397450999/files/doc_financials/2025/q2/23a907fd-1893-4395-baf1-ac8b7a06e097.pdf">cost</a> Coinbase about $20 million last quarter. It dries its tears on money.)</p><p>The legal and regulatory wrangling continues. It’s difficult for me to read tea leaves from Washington in the best of times, and in the interests of avoiding partisan commentary, I’ll refrain from confidently guessing whether statements of the administration predict its future actions over multi-week timescales.</p><h2 id="the-tangled-web-of-payments-policy">The tangled web of payments policy</h2><p>The credit card brands, which were originally created by banking consortiums, consider Open Banking data aggregators to be an existential risk to their business. They have long wanted to co-opt or kill them.</p><p>That isn’t just me saying it. Visa attempted to buy Plaid back in 2020. The argument to Visa’s board <a href="https://www.justice.gov/archives/opa/press-release/file/1334726/dl">was</a> (pg 5) that Plaid could potentially be a, quote, “existential risk” to their debit card business, which threatened a $300 to $500 million a year revenue hit. It was cheaper to take them off the table, even at $5.3 billion. Call it an insurance policy, their CEO said.</p><p>The FTC quashed the acquisition, <a href="https://www.justice.gov/archives/opa/pr/visa-and-plaid-abandon-merger-after-antitrust-division-s-suit-block?utm_source=chatgpt.com">saying</a> it would have the anti-competitive harm of protecting the debit card business. The FTC alleged that Visa had a near monopoly in online debit transactions. (<em>This</em> payments geek thinks there is actually a vibrant competitive landscape there, including internationally.)</p><p>Some commentators might assume that that was one of the Commissioner Lina Khan era anti-monopoly interventions. (This enforcement environment was part of the causus belli which flipped some notable Silicon Valley personages. It’s a complicated story and not particularly well-told by the press, in part because people with a nuanced view of the situation no longer respond to press inquiries, due to journalists’ <a href="https://www.complexsystemspodcast.com/episodes/reporting-tech-kelsey-piper/">repeated defection in an iterated game</a>.)</p><p>While I’m not a close follower of anti-trust enforcement, I do happen to know how to use a calendar, and so feel obliged to mention that the action to stop the Plaid acquisition was late during the first Trump administration.</p><p>Politics legendarily creates strange bedfellows. Crypto companies are now asking the CFPB to revive a regulation protecting a business the first Trump administration kneecapped, after which the second Trump administration hollowed out that same agency, despite campaigning against kneecapping tech and crypto—leaving the CFPB, long a sworn enemy of big banks, in Chase’s corner dismantling the crypto industry and suppressing competing payment methods, because the administration apparently thinks that’s what its backers want.</p><p>Yep, one’s head spins.</p><h2 id="chase-sends-some-surprise-bills">Chase sends some surprise bills</h2><p>Chase is the largest bank in the U.S., maintaining checking accounts for approximately 44 million Americans, and therefore makes up a hefty chunk of total transaction volume within the financial system.</p><p>To avoid adversarially screenscraping banking apps, which is unreliable and a bit of a security hole, the better way to do Open Banking is to negotiate API access with as many banks as possible. (Companies make APIs available to let developers access data from them in a safe and controlled fashion. API access allows customers to give secure, scoped, and revocable access to their financial information. Handing over a password is not ideal for those properties.)&nbsp;</p><p>This will customarily require signing a contract with the bank, obligating you to e.g. not steal the money, not attempt to hack bank servers, and not abuse customers’ expectations. These are all reasonable requests, swiftly agreed to. Most of the aggregators had agreements in place with Chase, which <a href="https://developer.chase.com/">eagerly promotes</a> their API access to developers.</p><p>In July, Chase started sending data aggregators notices about upcoming changes to their agreements.</p><p>The typical notice between financial institutions and developers downstream about changes to contracts is something along the lines of “We updated the wording in our privacy policy.”&nbsp;</p><p>These notices <em>weren’t that</em>. Chase <a href="https://www.youtube.com/watch?v=3D8TEJtQRhw">was altering the deal; pray that they do not alter it further</a>.</p><p>Chase demanded payment for access to Open Banking APIs, and would cut that access if companies interfacing with them did not acquiesce. The fees demanded were <em>enormous</em>.</p><p>A fintech industry trade group was <a href="https://www.ft.com/content/85ccc517-4a34-4221-aec7-4d8a72a21f35">quoted by the Financial Times</a> as saying:</p><p>“Across all the companies that received the notices, the cost of just accessing Chase data is somewhere from 60 per cent and in some cases well over 100 per cent of their annual revenue for the year … Just from one bank.”</p><p>Plaid <a href="https://www.forbes.com/sites/jeffkauflin/2025/04/03/plaid-raises-575-million-in-funding-at-61-billion-valuation/">was asked</a> for $300 million, which would be <a href="https://www.forbes.com/sites/jeffkauflin/2025/07/21/why-jpmorgan-is-hitting-fintechs-with-stunning-new-fees-for-data-access/">75% of their 2024 revenue</a>. That is likely more than the wages and benefits for <em>all of the 1,200 people who work at Plaid</em>.</p><p>Even as someone whose perennial advice to companies was Charge More, these don’t strike me as serious proposals to put a reasonable price tag on valuable services.</p><p>The prospect of Chase monetizing Open Banking has dragged some other banks into the fray; <a href="https://www.bloomberg.com/news/articles/2025-07-16/pnc-considers-charging-fintechs-for-access-to-customer-data">PNC is also looking</a> at taking a bite at the apple. The table gets crowded quickly if even a fraction of the next 4,500 banks try to join.</p><h2 id="banks%E2%80%99-arguments-for-monetizing-open-banking">Banks’ arguments for monetizing Open Banking</h2><p>You can imagine some rapid back-and-forth happening between bank and fintech negotiators happening in the background. There is some reluctance in the industry to speak of that openly, partly because negotiations are delicate and partly because <a href="https://www.bloomberg.com/news/articles/2025-07-25/tyler-winklevoss-says-jpmorgan-s-dimon-paused-onboarding-gemini-over-criticism">some fear retaliation elsewhere in their business relationships</a>.</p><p>But, helpfully, the banks have published their arguments, <a href="https://www.jpmorganchase.com/ir/annual-report/2024/ar-ceo-letters">directly</a> and <a href="https://bpi.com/section1033/">via their industry associations</a>. They are not particularly persuasive.</p><p>The best one is that banks bear risk here, and want to price it. Should a bank authorize a third party to use Open Banking, that third party might use it to exfiltrate value from a bank account. Should a bank customer authorize a transaction but regret it, perhaps because it was to a scam operation, they might ask their bank to make them whole.</p><p>Banks bear this fraud risk, the same as they do when they pay out a fraudulent check, until they can recover the money by reversing the transaction. They will not always be able to successfully reverse the transaction.</p><p>This is structurally similar to banks’ obligations under Regulation E for debit cards and Regulation Z for credit card purchases. If a consumer gets abused over card rails, the bank is good for it by regulation, less a $50 deductible that the industry universally waives in the interests of their good name. Banks are quite happy with this responsibility for cards, because card issuing <em>prints money</em>, but Regulation E covers almost any form of electronic payment and almost any imaginable form factor of abuse. (For non-limiting examples, see the AI-sung ditty, <a href="https://suno.com/song/173bbd67-92f7-4868-930f-efeca4b373c0">Doesn’t Matter, That’s Reg E</a>.)</p><p>But account-to-account payments are less like cards and more like checks. Indeed, the Automated Clearinghouse part of “ACH debit” refers to being a clearinghouse for check payments.&nbsp;</p><p>Banks will occasionally take fraud losses over checking accounts. They mostly can’t charge for checks directly; customers expect to write them freely and businesses expect to deposit them for, at most, a nominal fee. Certainly you’d be laughed out of the boardroom if you suggested a check fee scaling with the size of the check. That’s <a href="https://www.bitsaboutmoney.com/archive/the-business-of-check-cashing/">check cashing</a> nonsense, and not something that regulated financial institutions or their customers expect.</p><p>Dimon, in his <a href="https://www.jpmorganchase.com/ir/annual-report/2024/ar-ceo-letters">2024 letter to shareholders</a>, laments that typical retail checking accounts are a low- or negative-margin business. As an avid reader of Chase shareholder letters, I know why Chase operates that business anyhow: it’s the foundation of their relationship with households, which they largely monetize through credit card issuance, mortgage origination, and the like. It’s also operated <em>by design</em> to charge lower-income lower-asset consumers less and reliably increase monetization over their long relationships with the institution</p><p>The <a href="https://www.bitsaboutmoney.com/archive/deposit-franchises-as-natural-hedges/">deposit franchise</a>, which contributes a lot to the Fortress Balance Sheet™, is most valuable when it attracts retirees, small businesses, and others who keep larger balances earning 0.01% in a savings account or nothing in checking. As a cost of acquiring that business, it offers accounts to e.g. a teenager who wanted to cash the paycheck for their summer job, even though the margins on <em>that</em> account might be negative for the next ten years.</p><p>And so suggesting that retail checking account availability is threatened by banks’ responsibility to monitor transactions and pay out if they make mistakes in authorization is, frankly, an insult to the intelligence of anyone familiar with banking.</p><p>Checking accounts are <em>also</em> a public service expected by society of banks. This is in return for their lucrative monopolies on industries like e.g. consumer debt issuance and explicit and implicit taxpayer backstops of their operation. Chase is intimately familiar with those, most recently from when it cashed a <a href="https://www.fdic.gov/news/press-releases/2023/pr23034.html">$13 billion sweetener check</a> to acquire a failed bank.</p><p>We have made enormous strides, both from the financial industry and civil society, in banking almost everyone. That should not immediately imply “and thus banks get to charge a fee on<em> every transaction in society.</em>”</p><p>Chase is extremely capable of shipping payment products that customers actually want to use. Witness the Chase Sapphire Reserve, which probably half of fintech VCs and management teams use to pay for dinners, to my casual observation.</p><p>When Chase <em>can’t</em> successfully convince a customer to use a Chase payments rail that has a Chase CSR standing by to help out at 2 AM, Chase shouldn’t charge the accepting business money. Chase should understand that Open Banking and account-to-account payments are close in character to a check: one facilitates them in the ordinary course of business, for close to free, as part of the larger package offer.</p><p>Banks additionally make the argument that Open Banking leads to screen scraping. Certainly, as a financial technologist, I would prefer high-quality APIs with reasonable security guarantees. And some banks, like Chase, used the <em>fifteen years of advance notice</em> they had to develop these.</p><p>Other banks had other priorities, and are now <em>using their own inaction</em> to argue that screen scraping is a threat. (One can’t help but notice the bait and switch: first say aggregators must use official APIs rather than screenscrape, then claim that anyone who’s viewed developer documentation has agreed to a bill for 75% of their revenue.)</p><p>The banks additionally argue that fintechs are freeriding on substantial technology investments made by banks to serve their customers. This is <em>extremely selective memory</em>. Stripe did over <a href="https://stripe.com/annual-updates/2024">$1.4 trillion in payment volume in 2024</a>. Using no private information whatsoever, that implies that Stripe alone paid the banking industry somewhere in the general neighborhood of $20 billion in interchange fees.</p><p>Twenty. Billion. Dollars. From one firm alone.</p><p>It’s a little rich, pardon the pun, to cash a check for $20 billion and then whine about fintechs freeriding on your IT spend.</p><h2 id="innovation-in-payment-methods-is-a-good-thing">Innovation in payment methods is a good thing</h2><p>Credit cards are an enormously lucrative business for banks. The capability for businesses of all sizes to transact with customers worldwide over those rails is an enormous service to the world.&nbsp;</p><p>But cards are not and cannot be the last word in payments. We, as a society, should continue making things people want. Sometimes, the natural way to buy those things will be less compatible with cards or the assumptions baked into cards’ business model.</p><p>There has been quite a bit of enthusiasm for stablecoins in <a href="https://www.complexsystemspodcast.com/episodes/taking-stablecoins-seriously-with-haseeb-qureshi/">some</a> <a href="https://stripe.com/annual-updates/2024">quarters</a> <a href="https://www.cnbc.com/2025/07/15/jamie-dimon-jpmorgan-chase-stablecoins.html">recently</a>. Part of the sales pitch for stablecoins has been that you get to bypass the traditional financial system rails. This sales pitch does not accurately predict the operation of <a href="https://www.stablecoin.fyi/">stablecoin businesses with material volume</a>. Those are often operating something of a crypto mullet, with a stablecoin in the front and a bank transfer in the back. Those bank transfers are often substantially facilitated by Open Banking. This is a necessary part of the growth story for stablecoin businesses, as they are increasingly attempting to interact with the real economy, rather than crypto speculation. The real economy wants <em>dollars</em> and doesn’t much care what brand of database your backoffice uses.</p><p>People, particularly at the socioeconomic margins, increasingly use things which aren’t exactly a plastic rectangle. Sometimes that is a Cash App or a Venmo, or wallet directly integrated into a phone, or whatever a YC company invents next week. Our international peers like <a href="https://www.bitsaboutmoney.com/archive/payments-in-japan/">Japan</a> (and our adversaries) have thriving payments ecosystems.</p><p>Developing these innovations will almost always need to touch the banking system because, at the end of the day, businesses want dollars. If we award banks the ability to impose a fee on any transaction that competes with their card business, that will strangle some of these innovations. This would be unfortunate, because customers and businesses benefit from choice.</p><p>It also helps us keep the banks on their toes. The industry tends to default to sleepwalking with regards to core services. Bank apps <em>actually being quite good</em> in the last few years is not simply a reflection of their general technical competence. They invested deliberately, after decades of underprioritization, because they saw the younger generation increasingly defecting to apps, and then they realized that would eventually threaten the deposit franchise.</p><p>The banks aren’t inherently opposed to shipping good products! They do it frequently! But if you ask the question slightly differently, they will <em>happily</em> bankrupt anyone who threatens revenue streams which are fat-and-happy. In that world, you get to use 1999 banking websites on Internet Explorer 5.0 <em>forever</em>. (And if that sounds unlikely, <a href="https://en.wikipedia.org/wiki/Web_compatibility_issues_in_South_Korea">speak to a Korean friend sometime</a>.)</p><p>There was also something of a kerfuffle with regards to banking supportability decisions recently. I have a <a href="https://www.bitsaboutmoney.com/archive/debanking-and-debunking/">nuanced point of view on it</a>, but if I can offer a comment: when you let banks look into the economic logic of their customers’ lives to determine their pricing structure, you’re giving them the capability to pick winners and losers.</p><p>It has been reported that Chase wants a two-tier pricing system for Open Banking: one fee for data access and another, much higher, fee if someone uses that data access to facilitate a payment. These are the same products from Chase’s perspective. The same servers hold the same data. The same CSR stands ready to answer the call if a customer’s data leaks. But one of them is inimical to Chase’s preferences, and so they charge it more to discourage it.</p><p>We should not allow banks to get into the habit of sending demand letters to ruin the economics of businesses they simply do not like. Those demand letters will be inevitably abused, including in ways which are not determined by any conceivable direct business interest.</p><p>Banks are good at much of what they do, and it is quite profitable. If they want to maintain their share of wallet in their payments businesses, they employ intelligent people who are capable of shipping good products. Let them compete for the business. They’ll frequently win it, fair and square, including from me. But if customers choose to use someone else or if they mistakenly release payment to a fraudster, eh, have your teams break out Excel and try better tomorrow.</p>

        

        <div>
          <h2>Want more essays in your inbox?</h2>
          <p>I write about the intersection of tech and finance, approximately biweekly. It's free.</p>
                  </div>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NIST Finalizes 'Lightweight Cryptography' Standard to Protect Small Devices (154 pts)]]></title>
            <link>https://www.nist.gov/news-events/news/2025/08/nist-finalizes-lightweight-cryptography-standard-protect-small-devices</link>
            <guid>44893600</guid>
            <pubDate>Wed, 13 Aug 2025 20:43:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nist.gov/news-events/news/2025/08/nist-finalizes-lightweight-cryptography-standard-protect-small-devices">https://www.nist.gov/news-events/news/2025/08/nist-finalizes-lightweight-cryptography-standard-protect-small-devices</a>, See on <a href="https://news.ycombinator.com/item?id=44893600">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
         
    <figure data-lightbox="https://www.nist.gov/sites/default/files/styles/2800_x_2800_limit/public/images/2023/02/06/23TL001_update-lightweight_2_cryptography-2.jpg?itok=h6ibIb_k" data-media-id="663856">
        
    <img loading="lazy" src="https://www.nist.gov/sites/default/files/styles/960_x_960_limit/public/images/2023/02/06/23TL001_update-lightweight_2_cryptography-2.jpg?itok=6rz5V0IZ" width="960" height="464" alt="Shield labeled &quot;Update&quot; is surrounded by icons for Internet of Things applications like fitness trackers and smart home systems." typeof="foaf:Image">




            <figcaption>
      <p>Lightweight cryptography is designed to protect information created and transmitted by the Internet of Things, as well as for other miniature technologies.</p>
                    <p><span>Credit:</span>
          
  N. Hanacek/NIST

        </p>
          </figcaption>
  </figure>

  
  
  
      <p>It’s the little things that matter most, as the saying goes, and the National Institute of Standards and Technology (NIST) has got their back. NIST’s newly finalized lightweight cryptography standard provides a defense from cyberattacks for even the smallest of networked electronic devices.&nbsp;</p><p>Released as <em>Ascon-Based Lightweight Cryptography Standards for Constrained Devices</em> (<a href="https://csrc.nist.gov/pubs/sp/800/232/final">NIST Special Publication 800-232</a>), the standard contains tools designed to protect information created and transmitted by the <a href="https://www.nccoe.nist.gov/iot">billions of devices</a> that form the Internet of Things (IoT) as well as other small electronics, such as RFID tags and medical implants. Miniature technologies like these often possess far fewer computational resources than computers or smartphones do, but they still need protection from cyberattacks. The answer is lightweight cryptography, which is designed to defend these sorts of resource-constrained devices.</p><p>“We encourage the use of this new lightweight cryptography standard wherever resource constraints have hindered the adoption of cryptography,” said NIST computer scientist Kerry McKay, who co-led the project with her NIST colleague Meltem Sönmez Turan. “It will benefit industries that build devices ranging from smart home appliances to car-mounted toll registers to medical implants. One thing these electronics have in common is the need to fine-tune the amount of energy, time and space it takes to do cryptography. This standard fits their needs.”&nbsp;</p><p>The standard is built around a group of cryptographic algorithms in the Ascon family, which <a href="https://www.nist.gov/news-events/news/2023/02/nist-selects-lightweight-cryptography-algorithms-protect-small-devices" data-entity-type="node" data-entity-uuid="de0bfebf-f2cc-41db-84c3-3fffc2e0f1d2" data-entity-substitution="canonical" title="NIST Selects ‘Lightweight Cryptography’ Algorithms to Protect Small Devices">NIST selected in 2023</a> as the planned basis for its lightweight cryptography standard after a <a href="https://csrc.nist.gov/projects/lightweight-cryptography">multiround public review process</a>. Ascon was developed in 2014 by a team of cryptographers from <a href="https://www.tugraz.at/">Graz University of Technology</a>, <a href="https://www.infineon.com/">Infineon Technologies</a> and <a href="https://www.ru.nl/english/">Radboud University</a>. In 2019 it emerged as the primary choice for lightweight encryption in the <a href="https://competitions.cr.yp.to/caesar-submissions.html">CAESAR competition</a>, a sign that Ascon had withstood years of examination by cryptographers.&nbsp;</p><p>In the standard are four variants from the Ascon family that give designers different options for different use cases. The variants focus on two of the main tasks of lightweight cryptography: authenticated encryption with associated data (AEAD) and hashing.&nbsp;</p><p><strong>ASCON-128 AEAD</strong> is useful when a device needs to encrypt its data, verify the authenticity of the data, or — crucially — both. A common weakness of small devices is their vulnerability to “side-channel attacks,” in which an attacker can extract sensitive information by observing physical characteristics like power consumption or timing. While no cryptographic algorithm is inherently immune to such attacks, ASCON is designed to support side-channel-resistant implementations more easily than many traditional algorithms. Devices that can benefit from its approach include RFID tags, implanted medical devices, and toll-registration transponders attached to car windshields.</p><p><strong>ASCON-Hash 256</strong> takes all the data it encrypts and uses it to create a short “hash” a few characters long, which functions like a fingerprint of the data. Even a small change to the original data results in an instantly recognizable change in the hash, making the algorithm useful for maintaining the data’s integrity — such as during a software update, to ensure that no malware has crept in. Other uses are for protecting passwords and the digital signatures we use in online bank transfers. It is a lightweight alternative to NIST’s <a href="https://competitions.cr.yp.to/caesar-submissions.html">SHA-3 family of hash algorithms</a>, which are widely used for many of the same purposes.</p><p><strong>ASCON-XOF 128</strong> and <strong>ASCON-CXOF 128</strong> are hash functions with a twist: Both algorithms allow the user to change the size of the hash. This option can benefit small devices because using shorter hashes allows the device to spend less time and energy on the encryption process.&nbsp;</p><p>The CXOF variant also adds the ability to attach a customized “label” a few characters long to the hash. If many small devices perform the same encryption operation, there is a small but significant chance that two of them could output the same hash, which would offer attackers a clue about how to defeat the encryption. Adding customized labels would allow users to sidestep this potential problem.</p><p>McKay said the NIST team intends the standard not only to be of immediate use, but also to be expandable to meet future needs.&nbsp;</p><p>“We’ve taken the community’s feedback and tried to provide a standard that can be easily followed and implemented, but we are also trying to be forward-looking in terms of being able to build on it,” she said. “There are additional functionalities people have requested that we might add down the road, such as a dedicated message authentication code. We plan to start considering these possibilities very soon.”&nbsp;</p><p>For more information on the standard, visit the NIST <a href="https://csrc.nist.gov/projects/lightweight-cryptography">Lightweight Cryptography Project page</a>.&nbsp;</p>
  
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Illinois bans use of artificial intelligence for mental health therapy (366 pts)]]></title>
            <link>https://www.washingtonpost.com/nation/2025/08/12/illinois-ai-therapy-ban/</link>
            <guid>44893254</guid>
            <pubDate>Wed, 13 Aug 2025 20:11:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/nation/2025/08/12/illinois-ai-therapy-ban/">https://www.washingtonpost.com/nation/2025/08/12/illinois-ai-therapy-ban/</a>, See on <a href="https://news.ycombinator.com/item?id=44893254">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/nation/2025/08/12/illinois-ai-therapy-ban/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Job Listing Site Highlighting H-1B Positions So Americans Can Apply (127 pts)]]></title>
            <link>https://www.newsweek.com/h1b-jobs-now-american-workers-green-cards-2041404</link>
            <guid>44892321</guid>
            <pubDate>Wed, 13 Aug 2025 18:52:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newsweek.com/h1b-jobs-now-american-workers-green-cards-2041404">https://www.newsweek.com/h1b-jobs-now-american-workers-green-cards-2041404</a>, See on <a href="https://news.ycombinator.com/item?id=44892321">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A mysterious new job listings website recently went live, solely showing roles companies want to offer to their <a href="https://www.newsweek.com/trump-musk-ramaswamy-immigration-h1b-visa-workers-2006669" target="_blank" rel="noopener">H-1B holders</a> seeking Green Cards in an attempt to get Americans into <a href="https://www.newsweek.com/can-h-1b-visa-holders-change-jobs-critics-call-workers-indentured-servants-2006950" target="_blank" rel="noopener">the jobs</a> instead.</p><p>Jobs.Now works by scouring corporate listings for <a href="https://www.newsweek.com/what-project-2025-says-about-h-1b-visas-2007161" target="_blank" rel="noopener">positions attached to foreign workers</a>, which employers are obliged to try to fill with American workers before seeking permanent residency for an immigrant employee.</p><p>"Many people have complained about the trend of companies recruiting immigrants to fill jobs while Americans face unemployment, but few people have taken action to provide resources to help Americans get the first look they are legally entitled to for jobs in their own country," the team behind the website, who spoke on the condition of anonymity, told <em>Newsweek</em> Friday.</p><p>"We see Jobs.Now as a way to give back to society and our country in a meaningful way by helping smart, qualified people provide for themselves and their families."</p><figure><div>
<picture width="1200" height="800"><source type="image/webp" media="(min-width: 992px)" srcset="https://d.newsweek.com/en/full/2602805/us-naturalization-ceremony.webp?w=790&amp;f=da91fdfa3d05769cec05d50a81df4032 1x"><source type="image/jpeg" media="(min-width: 992px)" srcset="https://d.newsweek.com/en/full/2602805/us-naturalization-ceremony.jpg?w=790&amp;f=da91fdfa3d05769cec05d50a81df4032 1x"><source type="image/webp" media="(min-width: 768px)" srcset="https://d.newsweek.com/en/full/2602805/us-naturalization-ceremony.webp?w=900&amp;f=86a57f11338df0fe8cab0ef8d037e24d 1x"><source type="image/jpeg" media="(min-width: 768px)" srcset="https://d.newsweek.com/en/full/2602805/us-naturalization-ceremony.jpg?w=900&amp;f=86a57f11338df0fe8cab0ef8d037e24d 1x"><source type="image/webp" media="(min-width: 481px)" srcset="https://d.newsweek.com/en/full/2602805/us-naturalization-ceremony.webp?w=790&amp;f=da91fdfa3d05769cec05d50a81df4032 1x"><source type="image/jpeg" media="(min-width: 481px)" srcset="https://d.newsweek.com/en/full/2602805/us-naturalization-ceremony.jpg?w=790&amp;f=da91fdfa3d05769cec05d50a81df4032 1x"><source type="image/webp" media="(min-width: 0px)" srcset="https://d.newsweek.com/en/full/2602805/us-naturalization-ceremony.webp?w=450&amp;f=deea3e60480ec50ff1f79e8061c18afe 1x"><source type="image/jpeg" media="(min-width: 0px)" srcset="https://d.newsweek.com/en/full/2602805/us-naturalization-ceremony.jpg?w=450&amp;f=deea3e60480ec50ff1f79e8061c18afe 1x"><source type="image/webp" srcset="https://d.newsweek.com/en/full/2602805/us-naturalization-ceremony.webp?w=1200&amp;f=810b77dfe92eca9aa3c08ada94ec9780"><img loading="lazy" id="i2602805" src="https://d.newsweek.com/en/full/2602805/us-naturalization-ceremony.jpg?w=1200&amp;f=810b77dfe92eca9aa3c08ada94ec9780" alt="US naturalization ceremony" width="1200" height="800"></picture></div><figcaption>
<span id="short-cap-description">A candidate for US citizenship holds a US flag during a naturalization ceremony for new US citizens February 16, 2017 in Newark, New Jersey. </span>

<span>Robert Nickelsberg/Getty Images</span>
</figcaption>  </figure><h2>The H-1B to Green Card Pathway</h2><p>While just <a href="https://www.newsweek.com/h1b-visa-lottery-opening-date-announced-uscis-donald-trump-2027569" target="_blank" rel="noopener">one of many employment-based visas</a>, the H-1B has become <a href="https://www.newsweek.com/vivek-ramaswamy-h1b-visa-fallout-breaks-social-media-silence-2016523" target="_blank" rel="noopener">a flashpoint in the national immigration debate</a>. Those with a more nationalist viewpoint see the program favoring foreign labor, while the big tech, medical and education sectors that dominate <a href="https://www.newsweek.com/h1b-visa-final-rule-status-changes-update-2016211" target="_blank" rel="noopener">the visa category</a> typically argue that foreigners offer skills they can't match with U.S. candidates.</p><p>Both President Trump and <a href="https://www.newsweek.com/topic/elon-musk" data-sys="1">Elon Musk</a> have come out in favor of the H-1B system, a rare break with the MAGA movement that remains in stark opposition.</p><p>Jobs.Now targets a specific stage of the H-1B employment-based visa process: If an employer wants to sponsor an immigrant for a Green Card.</p><p>Known as the PERM process, H-1B holders can look to make their temporary visa permanent with a Green Card, but employers first have to test the market and see if they could, in fact, fill the role with a U.S. citizen or someone already in the country with legal resident status.</p><p>If they can prove that no American is suitable for the role, then the immigrant worker can move forward with their Green Card application.</p><p>"The underlying issue is that U.S. immigration policy requires most employers to do labor market testing at the PERM stage, when they are sponsoring a foreign worker for a Green Card, or permanent residence, not at the H-1B stage," Madeline Zavodny, an economics professor with an immigration focus at the University of North Florida, told <em>Newsweek</em>.</p><h2>What H-1B Positions Are Listed?</h2><p>Jobs.Now lists roles such as software engineers, database administrators, and VP-level positions for science, tech, and capital management firms. At time of publishing, companies with open roles included Spotify, Mastercard and <a href="https://www.newsweek.com/topic/uber" data-sys="1">Uber</a>.</p><p>One role, a trading job at <a href="https://www.newsweek.com/topic/bank-america" data-sys="1">Bank of America</a>, asks for a master's degree or equivalent, along with three years of experience in the field. One of the open Spotify roles seeking a software engineer asks for very specific qualifications related to different programming languages and practices.</p><p>"The PERM process was designed to allocate Green Cards to workers who had unique qualifications that were in shortage in America," Jobs.Now told <em>Newsweek</em>.</p><p>"The law's express purpose is to protect U.S. workers and the U.S. labor market by ensuring that foreign workers seeking immigrant visa classifications are not displacing equally qualified U.S. workers.' As law-abiding U.S. citizens, we believe that companies should follow the law."</p><p>The Department of Labor requires the roles be listed publicly, including in at least two major Sunday newspapers, on a state workforce agency site and internally at the company itself. Employers also have to choose from two other advertising methods, such as job fairs or at college campuses.</p><figure><div>
<picture width="1200" height="800"><source type="image/webp" media="(min-width: 992px)" srcset="https://d.newsweek.com/en/full/2602807/tech-job-fair.webp?w=790&amp;f=a4ef08c595ad572c3fe5c8688c0e1c03 1x"><source type="image/jpeg" media="(min-width: 992px)" srcset="https://d.newsweek.com/en/full/2602807/tech-job-fair.jpg?w=790&amp;f=a4ef08c595ad572c3fe5c8688c0e1c03 1x"><source type="image/webp" media="(min-width: 768px)" srcset="https://d.newsweek.com/en/full/2602807/tech-job-fair.webp?w=900&amp;f=cdddc7d4ed2c92e25bd8d8a098c0cf6d 1x"><source type="image/jpeg" media="(min-width: 768px)" srcset="https://d.newsweek.com/en/full/2602807/tech-job-fair.jpg?w=900&amp;f=cdddc7d4ed2c92e25bd8d8a098c0cf6d 1x"><source type="image/webp" media="(min-width: 481px)" srcset="https://d.newsweek.com/en/full/2602807/tech-job-fair.webp?w=790&amp;f=a4ef08c595ad572c3fe5c8688c0e1c03 1x"><source type="image/jpeg" media="(min-width: 481px)" srcset="https://d.newsweek.com/en/full/2602807/tech-job-fair.jpg?w=790&amp;f=a4ef08c595ad572c3fe5c8688c0e1c03 1x"><source type="image/webp" media="(min-width: 0px)" srcset="https://d.newsweek.com/en/full/2602807/tech-job-fair.webp?w=450&amp;f=da1d1afa6280bd6ba16af311d8b4708e 1x"><source type="image/jpeg" media="(min-width: 0px)" srcset="https://d.newsweek.com/en/full/2602807/tech-job-fair.jpg?w=450&amp;f=da1d1afa6280bd6ba16af311d8b4708e 1x"><source type="image/webp" srcset="https://d.newsweek.com/en/full/2602807/tech-job-fair.webp?w=1200&amp;f=b683c65bd4cc6de830debf1ddc7c690c"><img loading="lazy" id="i2602807" src="https://d.newsweek.com/en/full/2602807/tech-job-fair.jpg?w=1200&amp;f=b683c65bd4cc6de830debf1ddc7c690c" alt="Tech job fair" width="1200" height="800"></picture></div><figcaption>
<span id="short-cap-description">Georgia State University students Kavita Javalagi, left, and Gana Natarajan, second from left, speak with Shetundra Pinkston, during the Startup Student Connection job fair, Wednesday, March 29, 2023, in Atlanta. Image for illustration purposes only....</span>


<span>AP Photo/Alex Sliz</span>
</figcaption>  </figure><p>None of this is required when a company initially sets out to obtain an H-1B visa for a foreign worker, and there has long been skepticism around whether employers really put the effort into this process that they are required.</p><p>"At that point, most employers have identified a specific foreign worker already working for them on a H-1B visa they want to sponsor, and now they have to go test the labor market," Zavodny said.</p><p>"The employer has typically invested heavily in training that worker by this point. If the U.S. wants employers to do labor market testing before hiring a foreign worker, it would make more sense to do it earlier in the process, not at this late stage."</p><h2>Trump's 'America First' Agenda</h2><p>While supporting the H-1B system, the president has also made it clear that he wants to see American workers put first in the labor market. The Equal Employment Opportunity Commission (EEOC) said in February that it would look to prosecute companies actively favoring foreign workers over citizens.</p><p>"The EEOC is putting employers and other covered entities on notice: if you are part of the pipeline contributing to our immigration crisis or abusing our legal immigration system via illegal preferences against American workers, you must stop," EEOC Acting Chair Andrea Lucas, in a February press release. "The law applies to you, and you are not above the law. The EEOC is here to protect all workers from unlawful national origin discrimination, including American workers."</p><figure><div>
<picture width="1200" height="577"><source type="image/webp" media="(min-width: 992px)" srcset="https://d.newsweek.com/en/full/2602940/jobsnow.webp?w=790&amp;f=fd74e1123a745db3f6cbfd4121999b18 1x"><source type="image/png" media="(min-width: 992px)" srcset="https://d.newsweek.com/en/full/2602940/jobsnow.png?w=790&amp;f=fd74e1123a745db3f6cbfd4121999b18 1x"><source type="image/webp" media="(min-width: 768px)" srcset="https://d.newsweek.com/en/full/2602940/jobsnow.webp?w=900&amp;f=911c979ee74e7da74f20cbdaa275c64d 1x"><source type="image/png" media="(min-width: 768px)" srcset="https://d.newsweek.com/en/full/2602940/jobsnow.png?w=900&amp;f=911c979ee74e7da74f20cbdaa275c64d 1x"><source type="image/webp" media="(min-width: 481px)" srcset="https://d.newsweek.com/en/full/2602940/jobsnow.webp?w=790&amp;f=fd74e1123a745db3f6cbfd4121999b18 1x"><source type="image/png" media="(min-width: 481px)" srcset="https://d.newsweek.com/en/full/2602940/jobsnow.png?w=790&amp;f=fd74e1123a745db3f6cbfd4121999b18 1x"><source type="image/webp" media="(min-width: 0px)" srcset="https://d.newsweek.com/en/full/2602940/jobsnow.webp?w=450&amp;f=ffe7e244bcdf744cee7fc4a558c7bd2d 1x"><source type="image/png" media="(min-width: 0px)" srcset="https://d.newsweek.com/en/full/2602940/jobsnow.png?w=450&amp;f=ffe7e244bcdf744cee7fc4a558c7bd2d 1x"><source type="image/webp" srcset="https://d.newsweek.com/en/full/2602940/jobsnow.webp?w=1200&amp;f=51b60e77a504a16e99e9e674652680dc"><img loading="lazy" id="i2602940" src="https://d.newsweek.com/en/full/2602940/jobsnow.png?w=1200&amp;f=51b60e77a504a16e99e9e674652680dc" alt="jobs.now" width="1200" height="577"></picture></div><figcaption>
<span id="short-cap-description">The homepage of Jobs.Now.</span>

</figcaption>  </figure><p>Companies have faced penalties in the past for being seen to favor foreign workers. A job listings website in 2023 was found to have posted roles which specifically said H-1B roles would be favored. Other employers have been fined large sums for only seeking out those who spoke Spanish as a first language or only come from particular countries.</p><p>Elizabeth Jacobs, director of regulatory affairs and policy at the anti-immigration Center for Immigration Studies, told <em>Newsweek </em>that regulations needed to be changed to stop employees' ability to use loopholes in order to bypass American workers.</p><p>"The first Trump administration attempted to make some changes to deal with unfair competition caused by H-1B workers, but those regulations did not survive the Biden administration," Jacobs said, adding that <a href="https://www.newsweek.com/topic/congress" data-sys="1">Congress</a> needs to act instead.</p><p>"The obstacle are two-fold right now, largely because the public largely sees the H-1B visa program and the PERM process as one that they assume does have adequate protections for American workers. Also, the way the system is designed, to have the quote-unquote best and brightest workers from abroad, are crowded out by just the sheer volume of petitions that are filed."</p><p>As for the roles listed on Jobs.Now, it may be that they are eventually filled with a U.S. citizen or an immigrant with legal permanent resident already. Its owners told <em>Newsweek</em> that they believe several thousand job applications have been generated by listings on its platform.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PYX: The next step in Python packaging (667 pts)]]></title>
            <link>https://astral.sh/pyx</link>
            <guid>44892209</guid>
            <pubDate>Wed, 13 Aug 2025 18:42:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://astral.sh/pyx">https://astral.sh/pyx</a>, See on <a href="https://news.ycombinator.com/item?id=44892209">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Trusted by engineering teams at</p></div><div><p><h2>A Python-native package registry from the creators of uv.</h2></p><div><div><div><h3>Fast</h3></div><p>Speed up installs from PyPI, PyTorch, and your own private sources with optimized artifacts and uv-native metadata APIs. An order of magnitude faster than other private registries.</p></div><div><div><h3>Secure</h3></div><p>Create dedicated index URLs to filter packages by popularity, age, vulnerabilities, and more. Encode your own compliance rules and ensure reproducible builds on the server.</p></div><div><div><h3>Modern</h3></div><p>A singular focus on Python means best-in-class support for cutting-edge standards. Direct integration with uv means zero configuration and seamless authentication.</p></div><div><div><h3>GPU-aware</h3></div><p>Get the right, pre-built versions of PyTorch, vLLM, FlashAttention, DeepSpeed, and more — all with consistent metadata and optimal configuration — based on your hardware.</p></div></div><div><h2>Get in touch</h2><p>Be the first to experience the future of Python.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US national debt reaches a record $37T, the Treasury Department reports (144 pts)]]></title>
            <link>https://apnews.com/article/treasury-debt-spending-trump-obbb-6f807c4aae78dcc96f29ff07a3c926f4</link>
            <guid>44892086</guid>
            <pubDate>Wed, 13 Aug 2025 18:31:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/treasury-debt-spending-trump-obbb-6f807c4aae78dcc96f29ff07a3c926f4">https://apnews.com/article/treasury-debt-spending-trump-obbb-6f807c4aae78dcc96f29ff07a3c926f4</a>, See on <a href="https://news.ycombinator.com/item?id=44892086">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>WASHINGTON (AP) — The U.S. government’s gross <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/hub/national-debt">national debt</a></span> has surpassed $37 trillion, a record number that highlights the accelerating debt on America’s balance sheet and increased cost pressures on taxpayers. </p><p>The $37 trillion update is found in the <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://fiscaldata.treasury.gov/datasets/daily-treasury-statement/operating-cash-balance" target="_blank" rel="noopener">latest Treasury Department report</a></span> issued Tuesday which logs the nation’s daily finances.</p><p>The national debt eclipsed $37 trillion years sooner than pre-pandemic projections. The Congressional Budget Office’s January 2020 projections had gross federal debt eclipsing $37 trillion after fiscal year 2030. But the debt grew faster than expected because of a multi-year COVID-19 pandemic starting in 2020 that shut down much of the U.S. economy, where the federal government borrowed heavily under then-President <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-washington-dc-takeover-race-39388597bad7e70085079888fe7fb57b">Donald Trump</a></span> and former President Joe Biden to stabilize the national economy and support a recovery.</p>
    
<p>And now, more government spending has been approved after Trump signed into law <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/what-is-republican-trump-tax-bill-f65be44e1050431a601320197322551b">Republicans’ tax cut and spending legislation</a></span> earlier this year. The <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-tax-cuts-food-stamps-6542e448a2f6ed7b93ab8f7fe84ac53a">law</a></span> set to add $4.1 trillion to the national debt over the next decade, according to Congressional Budget Office <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/cbo-deficits-tax-cuts-trumps-big-beautiful-bill-64d7de49aef62ba07b7f6f45c1ca73d1">estimates</a></span>.</p>

<p>Chair and CEO of the Peter G. Peterson Foundation, Michael Peterson said in a statement that government borrowing puts upward pressure on interest rates, “adding costs for everyone and reducing private sector investment. Within the federal budget, the debt crowds out important priorities and creates a damaging cycle of more borrowing, more interest costs, and even more borrowing.”</p>
    
    
    
<p>Wendy Edelberg, a senior fellow in Economic Studies at the Brookings Institution said Congress has a major role in setting in motion spending and revenue policy and the result of the Republicans’ tax law “means that we’re going to borrow a lot over the course of 2026, we’re going to borrow a lot over the course of 2027, and it’s just going to keep going.” </p>
    
<p>The <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://www.gao.gov/americas-fiscal-future/how-could-federal-debt-affect-you" target="_blank" rel="noopener">Government Accountability Office</a></span> outlines some of the impacts of rising government debt on Americans — including higher borrowing costs for things like mortgages and cars, lower wages from businesses having less money available to invest, and more expensive goods and services. </p><p>Peterson points out how the trillion-dollar milestones are “piling up at a rapid rate.” </p><p>The U.S. hit $34 trillion in debt in January 2024, $35 trillion in July 2024 and $36 trillion in November 2024. “We are now adding a trillion more to the national debt every 5 months,” Peterson said. “That’s more than twice as fast as the average rate over the last 25 years.”</p><p>The Joint Economic Committee <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://www.jec.senate.gov/public/index.cfm/republicans/debt-dashboard#:~:text=July%202025%20%7C%20Released%20July%2008,reached%20in%20approximately%20194%20days." target="_blank" rel="noopener">estimates</a></span> at the current average daily rate of growth an increase of another trillion dollars to the debt would be reached in approximately 173 days.</p><p>Maya MacGuineas, president of the Committee for a Responsible Federal Budget said in a statement that “hopefully this milestone is enough to wake up policymakers to the reality that we need to do something, and we need to do it quickly.”</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OCaml as my primary language (331 pts)]]></title>
            <link>https://xvw.lol/en/articles/why-ocaml.html</link>
            <guid>44891759</guid>
            <pubDate>Wed, 13 Aug 2025 18:05:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xvw.lol/en/articles/why-ocaml.html">https://xvw.lol/en/articles/why-ocaml.html</a>, See on <a href="https://news.ycombinator.com/item?id=44891759">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>In this <em>opinion piece</em>, I will try to briefly share my encounter with
the language and list its advantages — organized into several sections
covering <em>the language itself</em>, its ecosystem, and its community. I
will also attempt to <em>debunk</em> some popular myths (or misconceptions)
found on the Internet. For the sake of transparency, it is important
to note that, at the time of writing, my <a href="https://tarides.com/">professional
work</a> <strong>involves working for and on the OCaml
ecosystem</strong>. However, readers who have followed me for several years
can attest that I was promoting the language long before I was paid to
work on the OCaml ecosystem, <em>sometimes rather immoderately</em>.</p>
<h2 id="foreword">Foreword</h2>
<p>First, this article will explain why I <strong>personally</strong> believe that
OCaml is a relevant choice in many contexts. My goal is not
specifically to convince you—although that would be a very welcome
<em>side effect</em> — and it’s quite likely that many of the arguments I
present will also apply to other languages!</p>
<p>Also, very often, when I suggest OCaml to people who want to explore
new languages or try out solutions written in OCaml, I’m kindly told
that <em>I’m always promoting OCaml</em>. It’s amusing to notice that when
the suggestions involve languages adopted <em>by default</em>, like
JavaScript, or more recent ones like
<a href="https://www.rust-lang.org/">Rust</a> or <a href="https://go.dev/">Go</a>, they tend
to trigger fewer reactions. This is probably because people
<em>implicitly</em> assume that proposing a <em>lesser-known</em> language leans
toward irrationality and personal preference. From my point of view,
<strong>suggesting OCaml is, in many cases where fine-grained memory control
is not needed, just as relevant as suggesting Rust</strong> (and probably
more so).</p>
<p>To wrap up this preface, many people first encountered OCaml (or <a href="https://caml.inria.fr/caml-light/release.fr.html">Caml
Light</a>) during their
undergraduate studies or in preparatory classes, often using it in
contexts far removed from industry. As for me, I started getting
interested in OCaml much earlier, thanks to the <a href="http://sdz.tdct.org/">Site du
Zéro</a>, where a small community of functional
programming enthusiasts promoted less <em>mainstream</em> languages like
<a href="https://ocaml.org/">OCaml</a>, <a href="https://www.erlang.org/">Erlang</a>, and
<a href="https://www.haskell.org/">Haskell</a>. My interaction with OCaml at
university was <strong>just a bonus</strong>.</p>
<h3 id="other-resources">Other resources</h3>
<p>I’m not the first to document the reasons for choosing OCaml. There
are many other resources that, in my opinion, are also worth checking
out, and they show that OCaml users are generally very satisfied — so
much so that they’re motivated to share <em>how and why</em> we chose the
language as our main technology:</p>
<ul>
<li>
<p><a href="https://dev.realworldocaml.org/prologue.html#why-ocaml">"<strong>Why
OCaml?</strong>"</a>,
the prologue of the book <a href="https://dev.realworldocaml.org/toc.html">Real World
OCaml</a>, which presents
factual advantages of using OCaml (and whose introduction includes a
timeline). While the book is excellent in many respects, I’ve gotten
into the habit of not recommending it because I find its usage
approach quite biased, suggesting libraries by default that aren’t
necessarily widely accepted in the community.</p>
</li>
<li>
<p><a href="https://cs3110.github.io/textbook/chapters/intro/intro.html">"<strong>Better Programming Through
OCaml</strong>"</a>,
the prologue of the book (accompanied by videos) <a href="https://cs3110.github.io/textbook/cover.html">OCaml Programming:
Correct + Efficient +
Beautiful</a>, which
mainly explains how learning OCaml can improve a developer’s skills
in other, more popular technologies. The book is fairly recent, and
it’s the one I <strong>now recommend as the go-to resource</strong> for getting
started with OCaml.</p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=v1CmGbOGb2I"><strong>Talk: "Why
OCaml?"</strong></a>, a
presentation by <a href="https://twitter.com/yminsky">Yaron Minsky</a>, CTO of
<a href="https://blog.janestreet.com/">Jane Street</a>—an industrial user of
OCaml and one of the global leaders in finance. Yaron is also one of
the authors of <em>Real World OCaml</em> and the originator of the widely
quoted phrase in the statically typed programming languages world,
"<em>Make illegal states unrepresentable</em>". The talk offers plenty of
insights into Jane Street’s motivations for choosing OCaml.</p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=TxuLrsQZprE">"<strong>OCaml for Fun &amp; Profit: An Experience
Report</strong>"</a>, presented
by <a href="https://lambdafoo.com/">Tim McGilchrist</a> at <a href="https://yowcon.com/melbourne-2023">Yow
2023</a>. After a rich introduction
to the language, it covers some very concrete use cases of OCaml in
production — <em>with fun and profit</em>.</p>
</li>
<li>
<p><a href="https://roscidus.com/blog/blog/categories/0install/">"<strong>Replacing Python for
0Install</strong>"</a> by
<a href="https://roscidus.com/blog/">Thomas Leonard</a>. This series of
articles is, in my view, <strong>incredibly interesting</strong>. The author of
<a href="https://0install.net/">0Install</a>, a decentralized, cross-platform
software installation system (a slightly older alternative to
<a href="https://nixos.org/">Nix</a>), was looking for a language other than
<a href="https://www.python.org/">Python</a> for a new version’s implementation
(the reasons for replacing Python are also <a href="https://roscidus.com/blog/blog/2013/06/09/choosing-a-python-replacement-for-0install/#why-replace-python">documented
here</a>)
and carried out a thorough, methodical comparison of several
candidates: <a href="https://www.cs.bu.edu/~hwxi/atslangweb/">ATS</a>,
<a href="https://learn.microsoft.com/en-us/dotnet/csharp/">C#</a>,
<a href="https://www.haskell.org/">Haskell</a>, <a href="https://go.dev/">Go</a>,
<a href="https://www.rust-lang.org/">Rust</a>, and <a href="https://ocaml.org/">OCaml</a>,
alongside Python. Years later, I’m still impressed by the rigor and
nuance of this series, which I <strong>highly recommend</strong>.</p>
</li>
</ul>
<p>There are probably other resources and testimonials, notably on the
<a href="https://ocaml.org/">official website</a>, which features both
<a href="https://ocaml.org/industrial-users">industrial</a> and
<a href="https://ocaml.org/academic-users">academic</a> case studies. There are
also articles expressing the frustration OCaml can cause. I’m aware
that OCaml is not perfect—nor do I believe any technology is
perfect. I’ll likely refer to some of these articles (implicitly or
explicitly) in the section on <em>myths</em> and in the conclusion, where
I’ll try to explain in which contexts I don’t find OCaml to be a
relevant choice.</p>
<h2 id="ocaml-as-a-language">OCaml as a language</h2>
<p>Before diving into the <strong>features</strong> offered by the language, I’d like
to start with a point that I believe is essential. OCaml is a
programming language that originated from
<a href="https://ocaml.org/about#history">research</a> and is used by <a href="https://ocaml.org/industrial-users">industrial
users</a>. This duality is important
because it provides the language with two key advantages:</p>
<ul>
<li>
<p>Guidance on <em>desirable</em> features as interesting language concepts,
supported by advanced research. For example, to my knowledge, OCaml
is the first <em>mainstream</em> language to offer native support for
<a href="https://v2.ocaml.org/manual/effects.html">user-defined effects</a>,
which is the result of cutting-edge research, illustrated by
numerous
<a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sivaramakrishnan,+K">publications</a>.</p>
</li>
<li>
<p>Guidance on <em>desirable</em> features as tools for industrialization,
also backed by research and motivated by practical use cases. For
instance, recently, <a href="https://blog.janestreet.com/">Jane Street</a>, a
major industrial OCaml user, proposed the integration of <em>affine
sessions</em>, enabling <a href="https://blog.janestreet.com/search/?query=oxidizing">linear resource
management</a>
(somewhat <em>Rust-like</em>).</p>
</li>
</ul>
<p>This intertwining of industrial and academic motivations allows OCaml
to offer a collection of solid, useful, and well-defined features. In
other words, OCaml is a <strong>living</strong> language, and since I’ve been using
it, I’ve witnessed many developments and additions that I consider
highly desirable and that <em>debunk</em> a common assertion against OCaml:
<strong>the language is only useful for theory or for implementing
<a href="https://coq.inria.fr/">Coq/Rocq</a></strong>.</p>
<p>Although this was historically true, the motivations provided by
industrial users justify the label "<em>An industrial-strength functional
programming language with an emphasis on expressiveness and safety</em>."
The opening keynote of the <a href="https://ocaml.org/conferences/ocaml-workshop-2021">OCaml Workshop
2021</a> by <a href="https://xavierleroy.org/">Xavier
Leroy</a>, titled "<a href="https://watch.ocaml.org/w/tU8wR9EcAcyFHHVcX4GS46"><em>25 Years Of
OCaml</em></a>," presents
an exhaustive timeline of OCaml’s continuous design, showing the
various phases of evolution the language has undergone.</p>
<p>In broad terms, OCaml is a programming language from the <a href="https://en.wikipedia.org/wiki/ML_%28programming_language%29">ML
family</a>,
<strong>high-level</strong> (here, meaning it features <a href="https://en.wikipedia.org/wiki/Garbage_collection_%28computer_science%29">garbage
collection</a>),
<strong>statically typed</strong> (types are checked at compile time with no
implicit conversions), with <strong><a href="https://en.wikipedia.org/wiki/Type_inference">type
inference</a></strong> (also
called <em>type synthesis</em>), allowing the compiler to deduce the type of
an expression in most cases. This enables programming in both
<a href="https://en.wikipedia.org/wiki/Functional_programming"><strong>functional</strong></a>
and
<a href="https://en.wikipedia.org/wiki/Imperative_programming"><strong>imperative</strong></a>
styles.</p>
<p>OCaml also provides an <strong>object-oriented programming model</strong> and a
very rich <strong>module system</strong>. The language has two compilation schemes:
<code>ocamlc</code>, which compiles to a <em>bytecode</em> executable by a <strong>virtual
machine</strong> (portable and efficient), and <code>ocamlopt</code>, which compiles to
<strong>native machine code</strong> (runnable on a wide <a href="https://github.com/ocaml/ocaml?tab=readme-ov-file#overview">variety of
architectures</a>).</p>
<p>Moreover, OCaml allows <strong>conversion of its bytecode to JavaScript</strong>
using
<a href="https://ocsigen.org/js_of_ocaml/latest/manual/overview">Js_of_ocaml</a>,
enabling <em>very fast</em> interoperability within the OCaml ecosystem
(which I use <em>extensively</em> on this website). The <a href="https://github.com/ocaml-wasm/wasm_of_ocaml">same approach is
used to produce
WebAssembly</a>. For deeper
interoperability with the JavaScript ecosystem,
<a href="https://melange.re/">Melange</a> takes a somewhat different approach
than Js_of_ocaml to generate robust JavaScript.</p>
<p>OCaml is a <strong>highly versatile</strong> language, and I will now try to
present the features and strengths that make it — <em>for me</em> — an ideal
tool for building both personal and professional projects, starting
with a brief detour into static typing.</p>
<h3 id="on-static-type-checking">On static type checking</h3>
<p>When I was preparing, with <a href="https://twitter.com/bibear">Bruno</a>, the
episode of <a href="https://www.ifttd.io/liste-des-episodes">If This Then Dev</a>
dedicated to OCaml — which, in the end, was
<a href="https://www.ifttd.io/episodes/le-langage-de-tous-les-langages">recorded</a>
with <a href="https://github.com/d-plaindoux">Didier</a> — he asked me a question
that I found surprising:</p>
<blockquote>
<p>“Is it really worth bothering with types when working on a <em>personal
project</em> quickly?  Even though I can perfectly see the value for
<em>production</em> code, for a <em>personal project</em> it seems like a waste of
time to me.”</p>
</blockquote>
<p>I think there are two main angles to answer this. The first, and most
obvious, is that, <strong>in principle, I don’t see why a personal project
should be any less disciplined than a professional one</strong>. When I write
software <em>for myself</em>, I could indeed get away with ignoring the
<em>corner cases</em> of my implementation. Sure, that’s possible. But that’s
probably not what I actually want to do. So, if a language and its
compiler let me set up safety nets that force me to account for all
the cases in my software, <em>I take them</em> — just like writing <em>unit
tests</em> <strong>makes development easier</strong>, and I don’t see them as a
constraint.</p>
<p>But beyond considerations of hygiene in a personal project, I think
the negative reputation of static type checking usually stems from a
bad experience. Indeed, in languages like C or Java, types are
<strong>mostly a constraint</strong> that can be easily circumvented. In languages
that place a strong emphasis on typing — like
<a href="https://ocaml.org/">OCaml</a>, <a href="https://www.haskell.org/">Haskell</a>,
<a href="https://fsharp.org/">F#</a>, <a href="https://www.scala-lang.org/">Scala</a>, or
<a href="https://www.rust-lang.org/">Rust</a> — <strong>types act as safeguards</strong>. More
importantly, in my view, <strong>types also serve as a tool for expressive
<em>design</em></strong>. Using them provides safety while also offering an
incredibly rich, versatile, and concise way to describe data.</p>
<p>From my experience, even though it’s common to move from a
<em>poorly-typed</em> (sorry, the temptation is too strong) to a <em>dynamically
typed</em> language — I, for instance, happily transitioned from Java to
Ruby — moving from a language with a rich type system, like OCaml or
Haskell, makes switching to a <em>dynamically typed</em> language much
harder. At present, <strong>I don’t know anyone who has seriously used
languages like OCaml or Haskell and was happy to return to languages
with less sophisticated type systems</strong> (though an interesting project
can sometimes justify such a technological regression).</p>
<p>This is <strong>not just a personal observation</strong>; static type checking is
central to the broader debate about the evolution of programming
languages. Historical languages evolve (or attempt to evolve) to
integrate more type checking. For instance,
<a href="https://www.erlang.org/">Erlang</a>, as early as the 1980s (before its
compiler source was released), experimented with <a href="https://homepages.inf.ed.ac.uk/wadler/papers/erlang/erlang.pdf">integrating a type
system</a>. Java,
version by version, enhances features aimed at improving static type
verification, such as incorporating <a href="https://openjdk.org/jeps/409">sealed
families</a>.</p>
<p>Many languages are experimenting with type systems: <a href="https://www.ruby-lang.org/en/news/2020/12/25/ruby-3-0-0-released/">Ruby with
RBS</a>,
<a href="https://crystal-lang.org/">Crystal</a> (a statically typed language
heavily inspired by Ruby), <a href="https://mypy-lang.org/">Python with Mypy</a>,
<a href="https://www.irif.fr/_media/users/gduboc/elixir-types.pdf">Elixir</a>
(which revisits Erlang’s past experiments, offering a viable gradual
typing approach), and, of course,
<a href="https://www.typescriptlang.org/">TypeScript</a>, which has become
<strong>widely adopted</strong> in the JavaScript community.</p>
<p>While all these initiatives are encouraging and clearly move in the
right direction, for now, they primarily <strong>add safeguards</strong> but do not
yet serve as expressive <strong>design tools</strong>.</p>
<p>When it comes to increasingly rich type systems, <strong>the White House</strong>
recently published a
<a href="https://bidenwhitehouse.archives.gov/oncd/briefing-room/2024/02/26/press-release-technical-report/">report</a>
emphasizing the importance of <em>memory safety</em> in software design and…
<em>endorsing</em> the use of the <a href="https://www.rust-lang.org/">Rust</a> language
(historically <a href="https://users.rust-lang.org/t/understanding-how-the-rust-compiler-is-built/87237/7">written in
OCaml</a>
before becoming <em>self-hosted</em>) over C++, clearly showing that even
official bodies (often considered outdated) highlight the value of
rich type systems. Moreover, the <a href="https://tarides.com/blog/2024-03-07-a-time-for-change-our-response-to-the-white-house-cybersecurity-press-release/">response from
Tarides</a>,
the company I work for at the time of writing this article, also
presents compelling arguments in favor of using OCaml for building
critical systems.</p>
<p>In conclusion, static type checking is really valuable and highly
recommended, and it’s worth exploring languages with sophisticated
type systems (like OCaml) and, why not, going even further by
increasingly delving into formal methods.</p>
<h3 id="features-of-the-language">Features of the <em>language</em></h3>
<p>Even though it’s very tempting to create a massive OCaml tutorial, the
goal of this section is to present what makes <strong>OCaml</strong>, <strong>for me</strong>, a
<strong>highly relevant</strong> choice for both learning and production. The
advantages will therefore be presented (and <em>defended</em>), but <strong>this is
not a tutorial</strong>.</p>
<h4 id="a-multi-paradigm-language">A <em>multi-paradigm</em> language</h4>
<p>Nowadays, talking about <strong>multi-paradigm</strong> languages might seem
unnecessary, since a large majority of programming languages <em>favored
by industry</em> are already multi-paradigm. However, OCaml is a
<strong>functional programming</strong> language that also supports <strong>imperative
programming</strong>, <strong>modular programming</strong>, <strong>object-oriented
programming</strong>, and, since version <code>5.0.0</code>, <strong>multi-core programming</strong>.</p>
<p>Just as <a href="https://www.haskell.org/">Haskell</a> is widely recognized in
the functional programming world, it’s often assumed that adding
imperative mechanisms to a language is a bad idea — especially if one
is convinced of the benefits of the functional style. From my
perspective, there are several perfectly legitimate reasons to use
imperative programming when the language allows it:</p>
<ul>
<li>
<p><strong>Readability of an implementation.</strong> Sometimes, avoiding mutability
requires adding extra plumbing (for example, a <a href="https://wiki.haskell.org/State_Monad">State
Monad</a>), which can make
reading and understanding a program more cumbersome.</p>
</li>
<li>
<p><strong>Performance.</strong> Adding such plumbing can introduce overhead, making
the execution of implementations more costly.</p>
</li>
<li>
<p><strong>Ease of use.</strong> A few years ago, <a href="https://twitter.com/rtguillon">Arthur
Guillon</a> ceremoniously told me that
"<em>OCaml is a lambda calculus that trivially allows effects</em>," which
makes it very effective for tasks like debugging, where printing
messages to standard output is simple. While I acknowledge that this
is probably not the <em>best way</em> to implement logging, it undeniably
provides a comfortable user experience and enables rapid
prototyping.</p>
</li>
</ul>
<p>In general, OCaml's dual nature — both imperative and functional —
allows you to leverage the advantages of both paradigms in different
situations and, of course, to combine them. For example, hidding a
module's imperative nature behind a functional API.</p>
<h5 id="syntax-à-la-ml">Syntax <em>à la ML</em></h5>
<p>Although syntax is often considered a minor detail, languages in the
<a href="https://en.wikipedia.org/wiki/ML_%28programming_language%29">ML
family</a>
have a concise, expressive, and readable syntax. Even though <em>this
family of syntax</em> can be confusing when coming from more conventional,
C-inspired syntax, one gets used to it fairly quickly and can soon
realize that it is very consistent and relatively
unambiguous. However, if OCaml’s syntax is problematic for you, don’t
hesitate to look into <a href="https://reasonml.github.io/">ReasonML</a>, an
alternative syntax that uses braces.</p>

<p>OCaml is a language that originates from French research, as shown by
the <a href="https://caml.inria.fr/about/history.en.html">history of Caml</a>,
primarily designed to implement the proof assistant
<a href="https://coq.inria.fr/">Coq/Rocq</a>. This origin — and the initial
motivations, implementing Coq while also serving as a programming
language taught in preparatory classes—creates a certain duality:</p>
<ul>
<li>
<p>The core features were not initially designed with industry in
mind. However, this assertion is no longer true, primarily because
OCaml <strong>has</strong> become a language used in industrial contexts. While
in the language’s genesis, there were more tools for building a
language itself (facilitating the teaching of compiler mechanisms)
than tools for building "enterprise" applications, projects from the
community motivated by industrial use have enriched the language and
its ecosystem, making it a versatile tool suitable for industry. For
example, creating a <em>binding</em> with the
<a href="https://en.wikipedia.org/wiki/Tk_%28software%29">Tk</a> library led to
the integration in the language of <a href="https://ocaml.org/manual/lablexamples.html">named
arguments</a>, <a href="https://ocaml.org/manual/lablexamples.html#s%3Aoptional-arguments">optional
arguments</a>,
and <a href="https://ocaml.org/manual/polyvariant.html">polymorphic
variants</a>.</p>
</li>
<li>
<p>The set of paradigms and language features are <strong>carefully thought
out and well-theorized</strong>. Generally, the integration of a feature
(or collection of features) results from meticulous research, based
on solid theoretical foundations and reviewed by numerous experts in
the field (often
<a href="https://www.inria.fr/fr/avec-xavier-leroy-linformatique-confirme-sa-presence-au-college-de-france">recognized</a>
by the scientific community). This rigor can sometimes slow the
introduction of new features but generally ensures their proper
functioning and theoretical stability.</p>
</li>
</ul>
<p>This theoretical rigor, stemming from OCaml’s undeniable closeness to
the research world, means that its various aspects are well
documented, illustrated by <a href="https://arxiv.org/search/?query=ocaml&amp;searchtype=all&amp;source=header">a large number of
publications</a>,
and exhibit <strong>predictable behavior</strong>. From my point of view, this
makes OCaml a very wise choice for understanding these different
features <em>in depth</em>. For example, I believe OCaml has allowed me to
<strong>much better understand</strong> certain traits or paradigms of programming
languages.</p>
<p>Moreover, a great example of how meticulous and rigorous research can
support the integration of a language feature is OCaml’s
implementation of an <a href="https://ocaml.org/manual/objectexamples.html">object
model</a>. Indeed, the
thesis of <a href="https://www.irif.fr/~vouillon/">Jérôme Vouillon</a>, <em><a href="https://www.irif.fr/~vouillon/publi/these.ps.gz">Design
and Implementation of an Extension of the ML Language with
Objects</a></em>, proposes
an innovative object model that integrates very well with type
inference by <a href="https://caml.inria.fr/pub/docs/oreilly-book/html/book-ora144.html">separating the notions of inheritance and
subtyping</a>
— inheritance being a <strong>syntactic notion</strong> and subtyping a <strong>semantic
notion</strong> — using <a href="https://en.wikipedia.org/wiki/Row_polymorphism">row
polymorphism</a> to
describe <a href="https://en.wikipedia.org/wiki/Structural_type_system">structural subtyping
relationships</a>,
as opposed to <a href="https://en.wikipedia.org/wiki/Nominal_type_system">nominal
subtyping</a>, used by
Java, C#, and most popular OOP languages. OCaml’s object model fully
adheres to the <a href="https://en.wikipedia.org/wiki/SOLID">SOLID principles</a>
without any <a href="https://spring.io/projects/spring-boot">additional
ceremony</a>.</p>
<h4 id="algebraic-types">Algebraic types</h4>
<p>I’ve been quite expansive about the reasons why I value a language
with static type checking. However, in my experience, for a statically
typed language to be truly usable, the presence of <a href="https://cs3110.github.io/textbook/chapters/data/algebraic_data_types.html">algebraic
types</a>
is necessary:</p>
<ul>
<li>
<p><strong>Product types</strong>: These allow grouping values of heterogeneous
types (thus creating a <strong>conjunction</strong> of heterogeneous types). They
are generally present in all <em>mainstream</em> languages (for example,
<em>objects</em>, which introduce additional concepts, or tuples and
records).</p>
</li>
<li>
<p><strong>Sum types</strong>: These allow constructing a <strong>disjunction</strong> of
heterogeneous value types, with different <em>cases</em> indexed by
constructors. While some <em>special cases</em> of sums exist in mainstream
languages—like <em>booleans</em> (which are a disjunction of two cases:
<code>true</code> and <code>false</code>, i.e., two parameterless constructors) — support
for full sum types is often cumbersome in popular languages. For
example, Kotlin and Java (and <em>de facto</em> C#) use a construct
associated with inheritance relations called
<a href="https://docs.oracle.com/en/java/javase/17/language/sealed-classes-and-interfaces.html">sealing</a>. The
integration of <a href="https://docs.scala-lang.org/scala3/reference/enums/adts.html">dedicated sum type
syntax</a>
also took some time in Scala, which, prior to recent versions,
relied on sealed families, making the expression of sums verbose
and, in my view, harder to reason about.</p>
</li>
<li>
<p><strong>Exponential types</strong>: These allow describing functions that express
types for higher-order functions (functions that can be passed as
arguments or returned as results).</p>
</li>
</ul>
<p>Coupled with <a href="https://ocaml.org/manual/5.2/patterns.html">pattern
matching</a> and <a href="https://en.wikipedia.org/wiki/Parametric_polymorphism">parametric
polymorphism</a>
(or <em>generics</em>), an algebraic type system is an incredibly expressive
tool for describing data structures, the state machine of a program,
or modeling a <a href="https://pragprog.com/titles/swdddf/domain-modeling-made-functional/">business
domain</a>
with an appropriate cardinality. Even in the 21st century, where
products and exponentials are common, when I use <em>very popular</em>
languages, I am often frustrated by the lack of sum types, which
forces me to use verbose encodings (increasing the domain’s
cardinality). This is particularly noticeable when working with
<a href="https://go.dev/">Go</a> and
<a href="https://www.typescriptlang.org/">TypeScript</a>.</p>
<p>The appeal of this triad is, in fact, probably one of the reasons
(combined with a very ergonomic ecosystem and toolchain) behind the
success of <a href="https://www.rust-lang.org/">Rust</a>. In short, if you intend
to build a new programming language with static type checking,
<em>please</em>, do not hesitate to include algebraic types!</p>
<p>Finally, there are aspects of OCaml's type system that I haven’t
covered, but which probably deserve dedicated articles. For example,
<a href="https://ocaml.org/manual/gadts-tutorial.html">generalized algebraic data types
(GADTs)</a>, which allow
expressing even more invariants.</p>
<h4 id="modular-programming-and-module-language">Modular programming and module language</h4>
<p>OCaml, through its ancestor <a href="https://caml.inria.fr/pub/docs/manual-caml-light/">Caml
Light</a>, was among
the first languages to offer a module system, similar to <a href="https://smlfamily.github.io/">Standard
ML</a>, providing <strong>encapsulation and
abstraction</strong> while supporting <strong>separate compilation</strong>, in the style
of <a href="https://en.wikipedia.org/wiki/Modula-2">Modula-2</a>. OCaml’s module
system is a <strong>fundamental aspect</strong> of the language, although its
complexity can be intimidating. Indeed, in OCaml, it is possible to
clearly distinguish the interface (the <em>signature</em>) from the
implementation (the <em>structure</em>), thus facilitating encapsulation and
documentation, while also allowing <strong>function application within the
module language</strong>.</p>
<p>I find it particularly difficult to address the topic of modules
briefly (it’s a subject I’ve wanted to explore on my blog for
<em>years</em>). However, here is a list of advantages I see in OCaml’s
<em>highly modular</em> approach:</p>
<ul>
<li>
<p><strong>Separate compilation</strong>: A key feature that allows efficient
compilation of large programs by identifying junction points to
optimize parallel and incremental compilation. This approach is
leveraged by <a href="https://dune.build/">dune</a>, the recommended build
system for OCaml.</p>
</li>
<li>
<p><strong>Systematic separation of implementation and interface</strong>: Offers
several significant advantages, including encapsulation and placing
documentation in the interface. In my programming workflow, I find
this very convenient because I can implement my <em>structure</em> (the
module’s implementation) while <em>being guided by type inference</em> and
specify its API in the <em>signature</em> (the module’s interface),
deciding on the display order and providing clear documentation that
doesn’t pollute the implementation space. Additionally,
encapsulation allows me to freely define intermediate types inside
the structure, for example, to represent a program’s state machine,
<a href="https://en.wikipedia.org/wiki/Leaky_abstraction">without letting it
escape</a>.</p>
</li>
<li>
<p><strong>A powerful tool for describing data structures</strong>: By abstracting
types (hiding their implementation) and combining this with
encapsulation, it is possible to describe data structures that
<strong>maintain invariants</strong>. This is why it is common to have a
structure/signature pair for each data structure, hiding
implementation details through abstraction and encapsulation.</p>
</li>
<li>
<p><strong>Reusability and sharing</strong>: Just as it is possible to describe
types in the value language (as seen with algebraic types), it is
also possible to describe types in the module language, called
<strong>translucent signatures</strong>, which allow defining the type of a
signature without associating it with a structure. These signatures
are structurally typed, and coupled with
<a href="https://ocaml.org/docs/functors">functors</a> (functions in the module
language), it is possible to <em>share behavior</em> between modules.</p>
</li>
<li>
<p><strong>Advanced forms of polymorphism</strong>: Including <a href="https://okmij.org/ftp/ML/higher-kind-poly.html">Higher Kinded
Polymorphism</a>,
available in the module language. In broad terms, you can describe
"<em>generics parameterized by generics</em>". This limitation in languages
like F# or Java often motivates the use of <a href="https://github.com/yallop/higher?tab=readme-ov-file#implementations-in-other-languages">heavy
encodings</a>
to work around the lack.</p>
</li>
</ul>
<p>The theory behind module languages in ML-family languages is a vast
subject, <a href="https://dl.acm.org/doi/10.1145/3649818">still evolving</a>, and
very difficult to summarize in a single paragraph. However, the
introduction of <a href="https://people.mpi-sws.org/~dreyer/thesis/main.pdf">Derek Dreyer’s
thesis</a>,
<em>Understanding and Evolving the ML Module System</em>, provides an
excellent explanation of the purpose and use of modules, illustrated
with many examples. I hope to take the time in the coming weeks or
months to write more extensively about the module language than I have
<a href="https://xvw.lol/en/articles/modules-import.html">already attempted</a>, because it could
be very educational and, in my view, the topic is extremely
interesting!</p>
<h4 id="dependency-injection-and-inversion">Dependency injection and inversion</h4>
<p>Briefly touching on object-oriented programming in OCaml, I mentioned
that OCaml allows, through its language features, a straightforward
way to meet the prerequisites for writing <strong>SOLID</strong> code. The final
point I’d like to emphasize is the ease of dependency inversion,
achievable through <strong>language-provided features</strong>. In broad terms, the
principle of dependency inversion involves describing dependency
lattices using <strong>abstractions</strong> rather than <strong>implementations</strong>. This
way, dependencies can be <em>injected afterward</em> — making context
changes, for example in unit testing, trivially implementable.</p>
<p>OCaml provides (<em>at least</em>) two tools that facilitate this inversion,
each useful in different contexts. We will draw inspiration from the
very popular teletype example to show how to invert dependencies:</p>
<pre><code><span>let</span><span> </span><span>program</span><span> </span><span>()</span><span> </span><span>=</span><span>
</span><span>  </span><span>let</span><span> </span><span>()</span><span> </span><span>=</span><span> </span><span>print_endline</span><span> </span><span>"</span><span>Hello World</span><span>"</span><span> </span><span>in</span><span>
</span><span>  </span><span>let</span><span> </span><span>()</span><span> </span><span>=</span><span> </span><span>print_endline</span><span> </span><span>"</span><span>What is your name?</span><span>"</span><span> </span><span>in</span><span>
</span><span>  </span><span>let</span><span> </span><span>name</span><span> </span><span>=</span><span> </span><span>read_line</span><span> </span><span>()</span><span> </span><span>in</span><span>
</span><span>  </span><span>print_endline</span><span> </span><span>(</span><span>"</span><span>Hello </span><span>"</span><span> </span><span>^</span><span> </span><span>name</span><span>)</span><span>
</span></code></pre>
<p>Even if it might not seem obvious, this program depends on <strong>concrete
implementations</strong> — namely, interactions with standard input and
output.</p>
<h5 id="through-modules">Through modules</h5>
<p>The most straightforward approach is to use modules, either as
<a href="https://ocaml.org/manual/firstclassmodules.html">first-class values</a>
or by construction, using
<a href="https://ocaml.org/docs/functors">functors</a>. The duality between
signatures and structures makes dependency inversion obvious. For
example, to revisit our example, here’s how, using <a href="https://ocaml.org/manual/firstclassmodules.html"><em>first-class
modules</em></a>, it becomes
<strong>very easy</strong> to depend on an abstract set of interactions. We start
by describing the abstract representation of possible interactions:</p>
<pre><code><span>module</span><span> </span><span>type</span><span> </span><span>IO</span><span> </span><span>=</span><span> </span><span>sig</span><span>
</span><span>  </span><span>val</span><span> </span><span>print_endline</span><span> : string -&gt; unit
</span><span>  </span><span>val</span><span> </span><span>read_line</span><span> : unit -&gt; string
</span><span>end</span><span>
</span></code></pre>
<p>We can now expect our <code>program</code> function to take a module of type <code>IO</code>
as an argument (we’ll call this <em>a handler</em>) and use the functions
exported by the module, which in our example is named <code>Handler</code>:</p>
<pre><code><span>let</span><span> </span><span>program</span><span> </span><span>(</span><span>module</span><span> </span><span>Handler</span><span>:</span><span> </span><span>IO</span><span>)</span><span> </span><span>=</span><span>
</span><span>  </span><span>let</span><span> </span><span>()</span><span> </span><span>=</span><span> </span><span>Handler</span><span>.</span><span>print_endline</span><span> </span><span>"</span><span>Hello World</span><span>"</span><span> </span><span>in</span><span>
</span><span>  </span><span>let</span><span> </span><span>()</span><span> </span><span>=</span><span> </span><span>Handler</span><span>.</span><span>print_endline</span><span> </span><span>"</span><span>What is your name?</span><span>"</span><span> </span><span>in</span><span>
</span><span>  </span><span>let</span><span> </span><span>name</span><span> </span><span>=</span><span> </span><span>Handler</span><span>.</span><span>read_line</span><span> </span><span>()</span><span> </span><span>in</span><span>
</span><span>  </span><span>Handler</span><span>.</span><span>print_endline</span><span> </span><span>(</span><span>"</span><span>Hello </span><span>"</span><span> </span><span>^</span><span> </span><span>name</span><span>)</span><span>
</span></code></pre>
<p>For example, in the context of unit testing, it’s possible to provide
an implementation that logs all the operations called (and <em>mocks</em> the
<code>read_line</code> call to fix the returned result). This makes expressing
unit tests that <em>verify business logic</em> very easy to implement.</p>
<p>Passing a concrete implementation as an argument to our function
amounts to <strong>interpreting the program</strong>.</p>
<h5 id="through-user-defined-effects">Through <em>user-defined effects</em></h5>
<p>OCaml version 5 arrived with a host of new features. However, the
biggest advancement is the complete redesign of the OCaml <strong>runtime</strong>
to support multi-core execution. There are several ways to describe
concurrent algorithms — for example, using
<a href="https://en.wikipedia.org/wiki/Actor_model">actors</a> or
<a href="https://go101.org/article/channel.html">channels</a>. OCaml has chosen
to rely on
<a href="https://github.com/ocaml-multicore/ocaml-effects-tutorial">effects</a>,
which simplify the management of the program's <em>control flow</em>.  In
fact, OCaml allows users to define their own effects, logically called
<a href="https://ocaml.org/manual/effects.html">user-defined effects</a>. While
they are a powerful tool for describing concurrent programs, they also
make it easier to inject dependencies when you want to maintain
control, <em>at the handler level</em>, over the execution flow of a program.</p>
<blockquote>
<p>Note: In my example, I am using an experimental syntax, <a href="https://github.com/ocaml/ocaml/pull/12309">just
merged</a> into the OCaml
main branch, which will likely be available in version <code>5.3.0</code> of
the language.</p>
</blockquote>
<p>As with our previous improvement, we first need to describe the set of
operations that can be performed. We use the <code>effect</code> construct:</p>
<pre><code><span>effect</span><span> </span><span>Print_endline</span><span> </span><span>:</span><span> </span><span>string</span><span> </span><span>-&gt;</span><span> </span><span>unit</span><span>
</span><span>effect</span><span> </span><span>Read_line</span><span> </span><span>:</span><span> </span><span>unit</span><span> </span><span>-&gt;</span><span> </span><span>string</span><span>
</span></code></pre>
<p>Next, we can write our program in a direct style, by <em>producing
effects</em>:</p>
<pre><code><span>let</span><span> </span><span>program</span><span> </span><span>()</span><span> </span><span>=</span><span>
</span><span>  </span><span>let</span><span> </span><span>()</span><span> </span><span>=</span><span> </span><span>Effect</span><span>.</span><span>perform</span><span> </span><span>(</span><span>Print_endline</span><span> </span><span>"</span><span>Hello World</span><span>"</span><span>)</span><span> </span><span>in</span><span>
</span><span>  </span><span>let</span><span> </span><span>()</span><span> </span><span>=</span><span> </span><span>Effect</span><span>.</span><span>perform</span><span> </span><span>(</span><span>Print_endline</span><span> </span><span>"</span><span>What is your name?</span><span>"</span><span>)</span><span> </span><span>in</span><span>
</span><span>  </span><span>let</span><span> </span><span>name</span><span> </span><span>=</span><span> </span><span>Effect</span><span>.</span><span>perform</span><span> </span><span>(</span><span>Read_line</span><span> </span><span>()</span><span>)</span><span> </span><span>in</span><span>
</span><span>  </span><span>Effect</span><span>.</span><span>perform</span><span> </span><span>(</span><span>Print_endline</span><span> </span><span>(</span><span>"</span><span>Hello </span><span>"</span><span> </span><span>^</span><span> </span><span>name</span><span>)</span><span>)</span><span>
</span></code></pre>
<p>It is then possible to <strong>interpret our program afterward</strong>, using a
construction similar to pattern matching, to give a specific meaning
to each effect.</p>
<p>Currently, it should be noted that <strong>effect propagation is not tracked
by the type system</strong>. However, this is an experimental feature, which
is used extensively in the <a href="https://github.com/xhtmlboi/yocaml">new version of
YOCaml</a>. I am aware that resources
are being devoted to developing an <strong>efficient type system to track
effect propagation</strong>!</p>
<p>In general, when I don’t care about controlling the program’s flow, or
I don’t need to add effects <em>after the fact</em>, I use modules. But in
the case of YOCaml, the new effect system was leveraged to <a href="https://github.com/xhtmlboi/yocaml/commit/d78bb21077272ae86f7b6b3017509596de0a5a27">introduce
effects dedicated to unit
testing</a>,
allowing, for example, the <em>mocking of time passing</em>.</p>
<p>Once again, it’s really difficult not to go on at length about
<em>user-defined effects</em>, which are a brand-new and very exciting
feature of the language. I’ll conclude by simply sharing two articles
written by <a href="https://github.com/art-w">Arthur Wendling</a> that explain
the use of effects in a very pedagogical way, along with a
comprehensive bibliography on the literature related to effect
abstraction in functional programming:</p>
<ul>
<li><a href="https://hackmd.io/@yF_ntUhmRvKUt15g7m1uGw/Bk-5NXh15">Scopes and effect
handlers</a></li>
<li><a href="https://hackmd.io/@yF_ntUhmRvKUt15g7m1uGw/BJBZ7TMeq">Roguelike with effect
handlers</a></li>
<li><a href="https://github.com/yallop/effects-bibliography">Effect bibliography</a></li>
</ul>
<p>It’s worth noting that this inversion/injection could also be done
using <em>records</em> or <em>objects</em>. However, my experience with OCaml
suggests that approaches using modules or effects (when you want to
manipulate the program’s control flow) are often more straightforward
and easier to reason about.</p>
<h3 id="regarding-the-future">Regarding the future</h3>
<p>OCaml is a <em>constantly evolving</em> language that changes with each
version. In the section on dependency inversion, I briefly mentioned
the recent inclusion of effects in the language to describe a
<em>multi-core runtime</em>, reflecting the ongoing evolution of OCaml over
the years. One can also note the integration of <a href="https://ocaml.org/manual/bindingops.html">binding
operators</a>, which make the
use of the triad
<a href="https://en.wikipedia.org/wiki/Functor_%28functional_programming%29">Functors</a>,
<a href="https://en.wikipedia.org/wiki/Applicative_functor">Applicative
Functors</a>, and
<a href="https://en.wikipedia.org/wiki/Monad_%28functional_programming%29">Monads</a>
more convenient — similar to <a href="https://learn.microsoft.com/en-us/dotnet/fsharp/language-reference/computation-expressions">computation
expressions</a>
in F#.</p>
<p>Currently, many very exciting projects are underway to further improve
the language:</p>
<ul>
<li>
<p>A deep work on the expression of effects, with a newly added syntax,
and a collection of research on the separation between <a href="https://github.com/ocaml/ocaml/pull/12736">operations
and effects</a> and, of
course, on the <a href="https://arxiv.org/abs/2407.11816">propagation of effects in the type
system</a>.</p>
</li>
<li>
<p><a href="https://opensource.janestreet.com/">Jane Street</a> proposed <a href="https://antonlorenzen.de/mode-inference.pdf">a
non-intrusive resource management
model</a>, inspired by
Rust, introducing <em>modalities</em> and <em>a bit of linearity</em>.</p>
</li>
<li>
<p>A genuine <a href="https://clement.blaudeau.net/assets/pdf/blaudeau_ocaml_modules.pdf">foundational
work</a>
has been initiated on the module language, making the implementation
of <a href="https://www.cl.cam.ac.uk/~jdy22/papers/modular-implicits.pdf">Modular
Implicits</a>
more smoothly achievable.</p>
</li>
</ul>
<p>We can also note the development of a <a href="https://xnning.github.io/papers/icfp23.pdf">hygienic macro
system</a>, the gradual
integration of a <a href="https://okmij.org/ftp/ML/MetaOCaml.html">staged metaprogramming
system</a>, and the
implementation of an <a href="https://ocamlpro.com/blog/tag/flambda2/"><em>optimization
back-end</em></a>, reflecting
OCaml’s strong activity in the innovation sector and making its
development in the coming years very motivating and exciting!</p>
<h3 id="weaknesses">Weaknesses</h3>
<p>Even though I’m convinced that OCaml is an <strong>excellent language</strong>,
claiming it is perfect would probably be <em>disingenuous</em> — after all,
<em>nothing is perfect</em>. Here are, in my opinion, a few points that cast
a shadow on OCaml as a language:</p>
<ul>
<li>
<p><strong>Lack of <a href="https://en.wikipedia.org/wiki/Ad_hoc_polymorphism">ad-hoc
polymorphism</a>.</strong>
Although it is possible to work around it, for example using local
module openings, the absence of <em>ad-hoc polymorphism</em> (via <a href="https://en.wikibooks.org/wiki/Haskell/Classes_and_types">type
classes</a> —
as in Haskell, or
<a href="https://doc.rust-lang.org/book/ch10-02-traits.html">traits</a>/<a href="https://docs.scala-lang.org/tour/implicit-parameters.html">implicit
objects</a>
— as in Rust and Scala, or <a href="https://coq.inria.fr/doc/v8.18/refman/language/extensions/canonical.html">canonical
structures</a>
— as in Coq) can sometimes make certain situations tricky. Even
though I tend to prefer explicit relationships, over the years I’ve
found several cases where this absence can be problematic:</p>
<ul>
<li>
<p>The inability to describe type parameter constraints on
polymorphic functions, leading to polymorphic equality and
comparison functions in the standard library, which has caused
<a href="https://blog.janestreet.com/the-perils-of-polymorphic-compare/">much
debate</a>
and, for example, required specialized versions of arithmetic
operators for different numeric representations (<code>int</code>, <code>int64</code>,
<code>float</code>).</p>
</li>
<li>
<p>Risk of combinatorial explosion when describing many relationships
between modules. This is why the
<a href="https://github.com/xvw/preface">Preface</a> library proposes a
somewhat <a href="https://github.com/xvw/preface/blob/master/guides/option_instantiation.md">complex modular
decomposition</a>.</p>
</li>
</ul>
<p>However, even though the arrival of <a href="https://www.cl.cam.ac.uk/~jdy22/papers/modular-implicits.pdf">implicit
modules</a>
is probably not in the short-term roadmap, recent work on the module
language, as discussed in the “future of OCaml” section, is
promising.</p>
</li>
<li>
<p><strong>Cumbersome interaction between the module language and the value
language.</strong>  The module language is <strong>a different language</strong> with
its own type system. Whether this counts as a weakness is debatable,
but this distinction can be intimidating. It comes from the fact
that OCaml’s module system was a pioneer in module theory and
predates more recent innovations (e.g.,
<a href="https://people.mpi-sws.org/~rossberg/1ml/1ml-extended.pdf">1ML</a>).
In practice, besides being <em>complex to grasp</em>, certain parts of the
language are hard to specify correctly, for example <a href="https://www.ocaml.org/manual/5.2/recursivemodules.html#s%3Arecursive-modules">recursive
modules</a>.</p>
</li>
<li>
<p><strong>A language comfortable for functional programming, but impure.</strong>
While I consider impurity <strong>a feature</strong>, importing idioms from
purely functional languages (e.g., Haskell) can cause difficulties
related to type inference, such as the <a href="https://en.wikipedia.org/wiki/Value_restriction"><em>value
restriction</em></a>.
Even though OCaml has
<a href="https://caml.inria.fr/pub/papers/garrigue-value_restriction-fiwflp04.pdf">relaxed</a>
this restriction, its implications on polymorphic function inference
can still be intimidating — for very good reasons.</p>
</li>
</ul>
<ul>
<li><strong>Syntax.</strong> Personally, I really like OCaml’s syntax and believe
syntax should rarely be a major issue, but some choices can be
confusing. For instance, type parameters prefix the type name: a
list of <code>a</code> is written <code>'a list</code>. Many of these choices aim to
<em>reduce syntactic ambiguity</em>, and you get used to them
quickly. However, coming from another language, some of these
conventions may seem surprising.</li>
</ul>
<p>I think these weaknesses are generally debatable (because they are
often justified), but I completely understand that they can be
unsettling. However, I believe they are not enough to make OCaml
unusable and <strong>should not be a major barrier to getting started with
OCaml</strong>! The benefit of having an <em>improvable</em> language is that it
constantly offers a range of potential improvements, motivating work
that can also benefit other languages. And, to be entirely honest,
being aware of these <em>rough edges</em>, I’ve more often found myself
frustrated by the absence of language features <strong>that exist in OCaml</strong>
in other languages, rather than complaining about these rough edges
while writing OCaml itself. For these rough edges, there are usually
workarounds (sometimes only partially satisfying, I admit) that allow
one to work calmly and effectively.</p>
<h3 id="to-conclude-on-language">To conclude on language</h3>
<p>I have, in very broad strokes, outlined <strong>reasons</strong> why, in my
opinion, learning OCaml is a <strong>very relevant</strong> choice. This language
allows one to <em>fundamentally understand</em> certain <em>very</em> popular
programming idioms (often poorly defined). Moreover, some aspects of
the language perfectly serve industrial purposes, making good
practices sometimes trivial to express! Much of this appeal can be
experimented with in other languages, but OCaml's <em>strongly
multi-paradigm</em> nature allows one to centralize this learning in a
single language. To my knowledge, in the jungle of <em>partially popular</em>
languages, only Scala seems to cover as many topics, although, from my
point of view, its object model is, essentially for interoperability
with other JVM languages, far less interesting.</p>
<p>Since the goal of this article is not to be a tutorial, I deliberately
skimmed over certain concepts,
<a href="https://ocaml.org/docs/modules">modules</a> and
<a href="https://ocaml.org/manual/ffects.html">effects</a>. I hardly mentioned
<a href="https://ocaml.org/docs/objects">objects</a>, <a href="https://ocaml.org/manual/polyvariant.html">polymorphic
variants</a>, or <a href="https://ocaml.org/manual/gadts-tutorial.html">generalized
algebraic types</a>. If
these topics interest you, I encourage you to read in detail the
excellent <a href="https://caml.inria.fr/pub/docs/u3-ocaml/index.html">Using, Understanding, and Unraveling The OCaml
Language</a> by
<a href="http://cristal.inria.fr/~remy/">Didier Rémy</a>, along with the books I
presented in the introduction, which is a goldmine for anyone wishing
to deepen their knowledge of OCaml.</p>
<p>In conclusion, OCaml offers a diverse and rich set of language-level
tools for learning programming, building industrial-grade programs
that follow standards, as well as implementing <a href="https://github.com/art-w/deque">complex data
structures</a> and <a href="https://github.com/xvw/preface">category-theory-based
abstractions</a> such as a functional
core, imperative traits, a rich and expressive inferred type system
(allowing the expression of algebraic types and facilitating clear
domain modeling), a module system for abstraction, reusability, and
defining compilation units, an object model, the ability to express
effects that can be propagated and interpreted <em>a posteriori</em>, and
other advanced features. Even just to <em>grasp advanced programming
concepts</em>, OCaml is an <strong>excellent candidate</strong> — which is why OCaml
has been an obvious inspiration for many more recent languages, <a href="https://doc.rust-lang.org/reference/influences.html">with
Rust being a notable
example</a>.</p>
<h2 id="ocaml-as-an-ecosystem">OCaml as an ecosystem</h2>
<p>Having an expressive language is very beneficial for <em>building things</em>
(the phrasing is deliberately naive). However, in different contexts,
both professional and personal, this is not enough:</p>
<ul>
<li>
<p>In a professional context, it is obvious that if I want my team and
I to be productive, it is probably not very relevant to have to
build a whole tool stack before being able to start addressing the
problem we are tasked with.</p>
</li>
<li>
<p>In a personal context, even though one could <em>argue</em> that building
your technology stack is <strong>very educational</strong>, it changes the set of
skills you actually want to <em>develop</em>. If, to build a small web
application to get started with OCaml as a web language, I have to
build my entire HTTP stack, it is very likely that OCaml is not the
right choice. Rest assured, however, that OCaml has <a href="https://ocaml.org/docs/is-ocaml-web-yet">a rich tooling
ecosystem</a> for building web
applications!</p>
</li>
</ul>
<p>That’s why the features offered by the language are not a sufficient
metric to describe its viability for building and maintaining
projects. The ecosystem is also a very important factor. It is for
these reasons that <a href="https://dotnet.microsoft.com/en-us/">.NET</a> and the
<a href="https://en.wikipedia.org/wiki/Java_virtual_machine">JVM</a>, through
relatively less expressive (but improving) languages like Java and C#,
are also so popular. To assess the relevance of an ecosystem, I think
it is important to consider several criteria:</p>
<ul>
<li>
<p>The relevance of the <em>runtime</em> (or compilation targets) for the
project. It’s likely that I wouldn’t recommend OCaml for embedding
in a tiny, exotic <em>hardware</em> — though, knowing nothing about
low-level programming (because it’s not my field at all), I could be
wrong.</p>
</li>
<li>
<p>Its <strong>platform</strong>. Is its entire <em>toolchain</em> complete and ergonomic?
From my point of view, this includes a package manager, a <em>build
system</em>, good <em>editor support</em> (agnostic as possible), a solid
documentation generator, and a collection of additional tools, such
as a <em>formatter</em> (and many others).</p>
</li>
<li>
<p>The relevance of the <strong>available libraries</strong> (and their level of
maintenance and discoverability, which generally implies having a
package manager) with particular consideration for their
ergonomics. For example, if I don’t have any cryptography
primitives, I probably wouldn’t choose this technology to build a
<em>blockchain</em>. There is a whole class of problems that are <strong>very
difficult</strong> to <em>solve in isolation</em> or in a professional context.</p>
</li>
</ul>
<p>In this section, we will try to overview these different points to see
if the OCaml ecosystem lives up to the language. I want to clarify
that <strong>I am somewhat biased</strong> because I have been convinced of OCaml’s
relevance since 2012, back when the ecosystem was <strong>drastically
poorer</strong>. At that time, I tried to build projects by patching the
gaps, which probably created a <a href="https://en.wikipedia.org/wiki/Survivorship_bias">survivorship
bias</a>. Nowadays,
thanks in part to industrial users, the OCaml ecosystem is much richer
and more extensive, making it much easier to defend, although when
some gaps still exist, the bad faith <em>of the old user</em> can resurface.</p>
<h3 id="compilation-runtimes-and-additional-targets">Compilation, <em>runtimes</em>, and additional targets</h3>
<p>Since its inception, OCaml has had two compilation targets:</p>
<ul>
<li>
<p>Native compilation, which produces highly efficient executables
compiled for a specific architecture (and supports a <a href="https://github.com/ocaml/ocaml?tab=readme-ov-file#overview">large number
of
architectures</a>). Moreover,
whereas Windows was historically largely neglected, <a href="https://tarides.com/blog/2024-05-22-launching-the-first-class-windows-project/">a special
effort</a>
has been made to support it (also note the <a href="https://github.com/diskuv/dkml-installer-ocaml">DkMl
project</a>, an
independent initiative).</p>
</li>
<li>
<p>Compilation to <em>bytecode</em> (for a virtual machine), producing
portable executables.</p>
</li>
</ul>
<p>The presence of a virtual machine enabled the development of the
venerable
<a href="http://ocsigen.org/js_of_ocaml/latest/manual/overview">Js_of_OCaml</a>,
which allows <a href="https://www.irif.fr/~vouillon/publi/js_of_ocaml.pdf">transforming OCaml bytecode into
JavaScript</a>,
making OCaml perfectly viable for developing applications in the
browser as well as in the <a href="https://nodejs.org/en">Node</a> runtime, and
it is extensively used for this website. Using a similar approach,
<a href="https://webassembly.org/">WebAssembly</a> support was made possible very
recently through the
<a href="https://github.com/ocaml-wasm/wasm_of_ocaml">Wasm_of_OCaml</a>
project. Supporting compilation to <em>WASM</em> for a language with a
<a href="https://en.wikipedia.org/wiki/Garbage_collection_%28computer_science%29">garbage
collector</a>
was a <em>serious challenge</em>, but with the recent specification of
interaction between <em>WASM</em> and <a href="https://github.com/WebAssembly/gc"><em>garbage
collectors</em></a>, <strong>OCaml now has
perfectly decent WebAssembly compilation</strong> (and many ambitious web
projects, like <a href="https://ocsigen.org/">Ocsigen</a>, are beginning to
support <em>WASM</em> natively).</p>
<p>Moreover, the <a href="https://melange.re/">Melange</a> project (historically
<a href="https://discuss.ocaml.org/t/a-short-history-of-rescript-bucklescript/7222">BuckleScript</a>)
offers a way to <em>transpile</em> — mapping the OCaml <em>AST</em> to the
JavaScript <em>AST</em> — as an alternative for producing JavaScript. If I
were to compare
<a href="http://ocsigen.org/js_of_ocaml/latest/manual/overview">Js_of_OCaml</a>
and <a href="https://melange.re/">Melange</a>, beyond the different underlying
methods used to produce JavaScript (compiling to <em>bytecode</em> and then
transforming that <em>bytecode</em> into JavaScript versus syntactic
transformation from OCaml to JavaScript), I would say that
<strong>Js_of_OCaml</strong> integrates better with the OCaml ecosystem and is
therefore likely <strong>intended for OCaml developers</strong> who want to make
their projects accessible from a browser — indeed, interaction with
the existing JavaScript ecosystem can be more cumbersome. <strong>Melange</strong>
fits better with the JavaScript ecosystem (<code>npm</code> and co) and is
therefore likely <strong>intended for JavaScript developers</strong> seeking to
bring more safety to their JS projects (or an existing codebase).</p>
<p>Nowadays, it is common to find <em>multi-backend</em> languages like
<a href="https://www.idris-lang.org/">Idris</a> or
<a href="https://nim-lang.org/">Nim</a>. However, <em>at the time</em>, I was very
impressed that OCaml could, <em>from the moment I started using it</em>, also
compile to JavaScript. Back then, the only language I knew that
offered multiple compilation targets was <a href="https://haxe.org/">Haxe</a>,
which were so different (incidentally, Haxe is <a href="https://github.com/HaxeFoundation/haxe">written in
OCaml</a>).</p>
<p>Indeed, in 2024, producing JavaScript has become standard, but the
<a href="https://www.irif.fr/~balat/publications/2006mlworkshop-balat-ocsigen.pdf">first traces of Js_of_OCaml date back to
2006</a>,
making OCaml a pioneer in the field!</p>
<h4 id="a-quick-detour-via-mirageos">A quick detour via MirageOS</h4>
<p>In the <em>lattice formed by the different OCaml execution and
compilation contexts</em>, having libraries that work well in <em>the
majority of contexts</em> is a challenging task. Fortunately, the
<a href="https://mirage.io/">MirageOS</a> project — a set of libraries designed
to build an <strong>operating system dedicated to running only a single
application</strong> via virtualization (a
<a href="https://en.wikipedia.org/wiki/Unikernel"><em>unikernel</em></a>) — introduced a
true discipline for producing multi-context libraries.</p>
<p>In the <em>near future</em>, I would like to spend more time writing about
Mirage, a fascinating project that we are trying to integrate into our
projects, for example in <a href="https://github.com/xhtmlboi/yocaml">YOCaml</a>,
our static site generator. Moreover, in addition to providing a sound
approach to distributing <em>intelligently compartmentalized</em> libraries,
Mirage offers a solid foundation of libraries for building OCaml
projects, which I will discuss more <em>extensively</em> in the section
dedicated to libraries.</p>
<h3 id="the-ocaml-platform">The OCaml platform</h3>
<p>The <a href="https://ocaml.org/platform">OCaml platform</a> is a set of tools,
maintained within an explicit lifecycle (<code>active</code>, <code>incubating</code>,
<code>maintained</code>, and <code>deprecated</code>), designed to support the compiler with
a coherent toolchain for OCaml code production. It includes many tools
serving different purposes; however, in this section, I will focus
only on certain aspects of the platform, leaving you free to consult
its <a href="https://ocaml.org/platform">page</a> and
<a href="https://ocaml.org/tools/platform-roadmap">roadmap</a> for more detailed
information. In this section, we will look at, <em>in broad strokes</em>, 4
main specific points:</p>
<ul>
<li>The package manager</li>
<li>The build system (<em>build-system</em>)</li>
<li>Editor support (including code formatting)</li>
<li>The documentation generator</li>
</ul>
<p>When using OCaml for some time, this is probably the most exciting
part of the article, because, in my opinion, it is the one that has
benefited the most from progress. And the
<a href="https://ocaml.org/tools/platform-roadmap">roadmap</a> is, in my view,
promising!</p>
<h4 id="opam-the-package-manager">OPAM, the package manager</h4>
<p>Even though <em>language-specific package managers</em> have become very
popular (if not essential) in reducing adoption friction for a
language, at the time OCaml was designed, they were rare. Indeed,
apart from <a href="https://en.wikipedia.org/wiki/CTAN">CTAN</a>, for
distributing <a href="https://en.wikipedia.org/wiki/TeX">TeX</a> packages,
<a href="https://en.wikipedia.org/wiki/CPAN">CPAN</a>, inspired by CTAN, for
distributing <a href="https://www.perl.org/">Perl</a> packages, and
<a href="https://en.wikipedia.org/wiki/PEAR">PEAR</a> for
<a href="https://www.php.net/">PHP</a>, it would take until
<a href="https://en.wikipedia.org/wiki/RubyGems">Gems</a> for development
technologies to consider adopting a package manager as axiomatic for a
programming language.</p>
<p><a href="https://opam.ocaml.org/">OPAM</a>, for <strong>O</strong>Caml <strong>Pa</strong>ckage <strong>M</strong>anager,
is a
<a href="https://raw.githubusercontent.com/ocaml/opam/30598a59c98554057ce2beda80f0d31474b94150/specs/roadmap.pdf">proposal</a>
from 2012 (the <a href="https://opam.ocaml.org/about.html">official site <em>About</em>
page</a> presents a small
timeline). In addition to installing packages, OPAM allows you to
install different versions of OCaml and create <em>potentially sandboxed
environments</em>, called
<a href="https://ocaml.org/docs/opam-switch-introduction">switches</a>. You can
use the public resource repository, <a href="https://github.com/ocaml/opam-repository">hosted on
GitHub</a>, but it is also
perfectly possible to create your own package index.</p>
<blockquote>
<p>Having already published several packages on OPAM, I must admit that
the <a href="https://check.ci.ocaml.org/">CI</a> for package addition
validation is incredibly efficient and user-friendly (each error
provides a Dockerfile to reproduce the issue locally), and that the
team of people who moderate and manage package additions/changes are
extraordinarily responsive and kind.</p>
</blockquote>
<p>Even though, in the light of modern standards, one could point out several criticisms of OPAM, for example:</p>
<ul>
<li>terminology that can be cumbersome to grasp (<em>switch</em>, <em>invariant</em>,
etc.)</li>
<li>duplication of all packages and compilers across multiple <em>switches</em>
(this is a known issue for which <a href="https://www.youtube.com/watch?v=5JDSUCx-tPw">work has already been
done</a>)</li>
<li>and probably some ergonomic issues (notably the interaction with
<code>dune</code> could be smoother, for which <a href="https://discuss.ocaml.org/t/ann-dune-developer-preview-updates/15160">work is also currently
underway</a>)</li>
<li>some complications when managing packages in development,
referencing them from a source repository rather than from OPAM</li>
</ul>
<p>I must admit that coming from an era when OPAM did not exist, I have
learned to live with some of these minor pitfalls, and on a daily
basis, I have little reason to complain about the tool, which has
never really let me down in my everyday use. However, if you have
encountered usage issues, I encourage you to discuss them on <a href="https://ocaml.org/community">one of
the communication spaces</a> so that the
development team can take your feedback into account and guide you.</p>
<p>There is also <a href="https://esy.sh/">esy</a> as an alternative package
manager, which draws inspiration from <a href="https://nixos.org/">Nix</a> to
build a reusable <em>store</em>, in the same way it is possible to use Nix
with OCaml. However, being somewhat conventional, I am not really
familiar with these practices, and being satisfied with my <em>workflow</em>
with OPAM, I have, unfortunately, never taken the time to seriously
experiment with <strong>esy</strong>.</p>
<h4 id="dune-the-build-system">Dune, the <em>build-system</em></h4>
<p>As with package management, historically, OCaml had <strong>several</strong>
<em>build-systems</em>: the venerable
<a href="https://github.com/ocaml/ocamlbuild">ocamlbuild</a>,
<a href="https://github.com/ocaml/oasis">oasis</a>,
<a href="https://github.com/OCamlPro/ocp-build">ocp-build</a>,
<a href="https://ocaml.org/p/jenga/latest">Jenga</a>, and other variations around
<a href="https://www.gnu.org/software/make/">Make</a>. However, since 2018, the
community has strongly adopted <a href="https://dune.build/">Dune</a>, a
<em>build-system</em> initially developed at
<a href="https://www.janestreet.com/">Janestreet</a>.</p>
<p>In many aspects, Dune can be intimidating. Indeed, its
<a href="https://dune.readthedocs.io/en/stable/">documentation</a> is <strong>very
dense</strong> — but it has greatly improved in terms of structure over the
past few months. And, while many tools choose rule description
languages like <a href="https://en.wikipedia.org/wiki/YAML">YAML</a>,
<a href="https://en.wikipedia.org/wiki/TOML">TOML</a>, or even
<a href="https://en.wikipedia.org/wiki/JSON">JSON</a>, Dune has opted for
<a href="https://en.wikipedia.org/wiki/S-expression">S-expressions</a>. It is
also regrettable that Dune, <em>by default</em>, treats <a href="https://ocaml.org/manual/5.2/comp.html#s%3Acomp-warnings">all
warnings</a> as
fatal.</p>
<p>Before explaining some of its choices (such as <strong>S-expressions</strong>), it
is very important to highlight the points that have made Dune a
standard:</p>
<ul>
<li>Dune is <strong>very fast</strong> and offers a <strong>highly efficient</strong> execution
model</li>
<li>it builds the necessary artifacts for configuration <em>automatically</em></li>
<li>it generates some redundant files (such as OPAM description files)</li>
<li>it trivializes the
<a href="https://en.wikipedia.org/wiki/S-expression"><em>vendoring</em></a> of
libraries</li>
<li>it allows invoking <a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop">read–eval–print
loops</a>
correctly provisioned by the context</li>
<li>one becomes familiar very quickly with <strong>S-expressions</strong>, which
allow rules to be described schematically and rapidly</li>
<li>it is relatively agnostic and can execute arbitrary tasks (similar
to <code>make</code>)</li>
<li>it is constantly evolving and improving from version to version</li>
<li>paired with <a href="https://github.com/tarides/dune-release">dune-release</a>,
it makes publishing packages on OPAM incredibly simple</li>
</ul>
<p>Perhaps I’m biased, but in my opinion, Dune is one of the most generic
and pleasant <em>build-systems</em> I’ve ever used — even if, at first
glance, it can seem intimidating and some choices may be hard to
justify.</p>
<h5 id="on-the-choice-of-s-expressions">On the choice of S-expressions</h5>
<p>At first glance, using a <em>Lisp-like</em> syntax to describe binaries,
libraries, and projects may seem surprising. However, this decision
has several advantages:</p>
<ul>
<li>The AST of <strong>S-expressions</strong> being <strong>drastically simple</strong>, parsing
is very straightforward and can be made highly efficient, which does
not penalize compilation speed.</li>
<li>The language has <em>termination</em>, making it easier to inspect in case
of errors (anyone who has tried to handle errors in large YAML files
will have faced this kind of problem).</li>
<li>The language is very easy to learn and to describe.</li>
<li>It allows describing <strong>real programs</strong>, making Dune relatively
generic and enabling additional tasks.</li>
</ul>
<p>So, from my point of view, the choice of <strong>S-expressions</strong> is
relevant: it allows describing complex, readable programs without
being too verbose, does not significantly slow down compilation, and
enables very concise descriptions of highly complex build rules. And
to be completely honest, you get used to it very quickly!</p>
<h5 id="contribution-to-the-state-of-the-art-selective-applicative-functor">Contribution to the state of the art: Selective Applicative Functor</h5>
<p>In addition to being a very pleasant <em>build-system</em>, Dune has
contributed to the state of the art in research by highlighting a new
construction <em>inspired by category theory</em>. Indeed, in 2018, <a href="https://blogs.ncl.ac.uk/andreymokhov/about/">Andrey
Mokhov</a>, <a href="https://ndmitchell.com/">Neil
Mitchell</a> and <a href="https://simon.peytonjones.org/">Simon Peyton
Jones</a> proposed, in the excellent
paper <a href="https://dl.acm.org/doi/10.1145/3236774">"<em>Build Systems à la
Carte</em>"</a>, a collection of
abstractions to re-implement — modularly — various
<em>build-systems</em>. However, for reasons related to <strong>static dependency
analysis</strong>, these models were not compatible with Dune. After several
investigations and experiments, a new construction, similar to an
<a href="https://hackage.haskell.org/package/base-4.20.0.1/docs/Control-Applicative.html">Applicative</a>,
a <a href="https://dl.acm.org/doi/10.1145/3341694">Selective Applicative
Functor</a>, capturing Dune's
prerequisites was proposed. This information may seem anecdotal, but,
in my view, it reinforces the value (and importance) of being at <strong>the
intersection of research and industry</strong>.</p>
<h5 id="alternatives">Alternatives</h5>
<p>Although widely adopted by the community, OCaml offers alternative
systems (sometimes using Dune <em>under the hood</em>), for example,
<a href="https://obazl.github.io/docs_obazl/">Obazl</a> which provides OCaml
rules for <a href="https://bazel.build/">Bazel</a>,
<a href="https://github.com/rizo/onix">Onix</a> which allows building projects
with <a href="https://nixos.org/">Nix</a>, <a href="https://buck2.build/">Buck2</a> which is
an ambitious and generic project competing with Bazel, and
<a href="https://github.com/OCamlPro/drom">Drom</a> which offers an experience
similar to <a href="https://doc.rust-lang.org/stable/cargo/">Cargo</a>, unifying
package management and project building.</p>
<h4 id="lsp-and-merlin-for-editors">LSP and Merlin for editors</h4>
<p>In the previous sections, we saw how much OCaml has progressed in
areas necessary for industrialization. On the other hand, in terms of
editor support, OCaml has had excellent support for
<a href="https://www.vim.org/">Vim</a> and
<a href="https://www.gnu.org/software/emacs/">Emacs</a> for over 10 years through
the <a href="https://github.com/ocaml/merlin">Merlin</a> project, which provides
editor services enabling <strong>completion</strong>, <strong>diagnostics</strong>, <strong>code
navigation</strong> features, tools related to <strong>value deconstruction</strong>,
<strong>value construction</strong>, management (and navigation) of <strong>typed
holes</strong>, <strong>polarity-based search</strong>, precise information (with
verbosity control) on <strong>value types</strong>, <em><strong>jump-to-definition</strong></em>, etc.</p>
<p>In my opinion, IDE support via Merlin has been excellent in OCaml for
a very long time. Coupled with
<a href="https://github.com/OCamlPro/ocp-indent">ocp-indent</a>, which calculates
the cursor position after an action in the editor, and
<a href="https://github.com/ocaml-ppx/ocamlformat">OCamlformat</a>, which allows
on-the-fly (configurable) formatting of OCaml files, writing code in
Emacs or Vim is an absolute joy!</p>
<h5 id="the-advent-of-vscode-lsp-as-standard">The advent of VSCode, LSP as standard</h5>
<p>In 2015, <a href="https://en.wikipedia.org/wiki/Visual_Studio_Code">Visual Studio
Code</a> arrived,
introducing the <a href="https://en.wikipedia.org/wiki/Language_Server_Protocol">Language Server
Protocol</a>,
which abstracts how editors interact with a language through a server,
following a uniform protocol. OCaml has a <a href="https://github.com/ocaml/ocaml-lsp">very good LSP
server</a> that itself relies on
well-established libraries in the OCaml ecosystem, notably
Merlin. Since LSP has become <em>relatively standard</em> in the editor world
(Vim, Emacs, and, in fact, almost all free editors I know can interact
with an LSP server), the plan is to deprecate the Merlin server,
moving entirely to LSP, making Merlin a low-level library that
provides tooling used by LSP. This is one of the projects the <code>Editor</code>
team at <a href="https://tarides.com/">Tarides</a> (which I’m part of) is working
on: making <code>ocaml-lsp</code> feature-compatible with Merlin’s historic
server to reduce maintenance for alternative clients (Emacs and Vim),
only worrying about OCaml-specific requests and actions (which,
logically, are not part of the protocol).</p>
<p>Currently, the <a href="https://marketplace.visualstudio.com/items?itemName=ocamllabs.ocaml-platform">OCaml platform for Visual Studio
Code</a>
and <a href="https://github.com/tarides/ocaml-eglot">OCaml-eglot</a> are the two
canonical implementations (which extend the LSP protocol for OCaml),
respectively for VSCode and Emacs. We are currently considering the
implementation of a NeoVim plugin.</p>
<p>A bit like with Dune, in my opinion, the tooling state is excellent,
and the roadmap is motivating! However, since this is <strong>my work</strong>, I’m
probably biased.</p>
<h4 id="odoc-the-documentation-generator">Odoc, the documentation generator</h4>
<p>OCaml is distributed with a documentation generator, the venerable
<a href="https://ocaml.org/manual/5.2/ocamldoc.html">OCamldoc</a>; however, it is
no longer recommended by/for the community. Indeed, the tool being
promoted is <a href="https://ocaml.github.io/odoc/">Odoc</a>, a new tool that
exists outside the compiler and offers several very interesting
features:</p>
<ul>
<li>a <em>rich markup</em> language, supporting cross-references</li>
<li>the ability to write "manual" pages, ephemeral, while still
benefiting from cross-references</li>
<li>very good integration with Dune</li>
<li>a type-based search bar (implemented via
<a href="https://doc.sherlocode.com/">Sherlodoc</a>)</li>
<li>inclusion of source code (written in the documentation or documented
modules)</li>
<li>implementation of <em>drivers</em> allowing the generation of large sets of
documentation (used to implement <a href="https://ocaml.org/packages">the documentation of all packages
on OPAM</a>)</li>
<li>support for <a href="https://en.wikipedia.org/wiki/Doctest"><em>doctest</em></a> via
<a href="https://github.com/realworldocaml/mdx">mdx</a></li>
</ul>
<p>Even though the <em>look'n feel</em> of documentation generated by Odoc is,
in my view, <strong>far superior</strong> to that produced by OCamldoc, there is
still (once again, in my view) a bit of work needed on the UI for the
tool to be truly <strong>perfect</strong>!</p>
<p>I clearly have a certain fondness for the documentation of the
<a href="https://elixir-lang.org/">Elixir</a> language,
<a href="https://hexdocs.pm/">HexDoc</a> (in terms of <em>design</em> and features), and
personally, I would like OCaml to move toward that example. However,
it must be acknowledged that the documentation generated by Odoc is
superior to that of many other languages. Moreover, due to the highly
modular nature of the language, a good documentation generator that
effectively supports <em>cross-references</em> is quite an achievement!</p>
<h3 id="available-libraries">Available libraries</h3>
<p>We have seen that the language is <em>cool</em>, and that it has tooling
which, although still evolving, is effective and pleasant to
use. Could its lack of popularity be due to a too limited set of
libraries? To be completely honest, <strong>I don’t know</strong>. What I do know
is that whenever I have had to write OCaml projects, both professional
and personal, I have often found everything I needed in the <a href="https://ocaml.org/packages">package
list</a>. I think the reasons why OCaml is
mature enough for many typical projects can be summarized in several
points:</p>
<ul>
<li>Companies like <a href="https://www.lexifi.com/">Lexifi</a> and
<a href="https://www.janestreet.com/">Janestreet</a> have strongly contributed
to the ecosystem by releasing many libraries necessary for their
daily use.</li>
<li>Ambitious research projects, such as, in the case of the Web,
<a href="https://ocsigen.org/home/intro.html">Ocsigen</a>, used industrially in
the <a href="https://www.besport.com/">BeSport</a> project, have generated a
collection of useful libraries.</li>
<li>As mentioned earlier, <a href="https://mirage.io/">MirageOS</a>, with its
<a href="https://blog.container-solutions.com/all-about-unikernels-part-1-what-they-are"><em>Clean
Slate</em></a>
approach, naturally produced many robust libraries.</li>
<li>Like in popular languages such as JavaScript or Rust, motivated
contributors have provided excellent libraries.</li>
<li>The language is old and has been used industrially for a long time.</li>
</ul>
<p>For my part, I have sometimes <em>re-created</em> libraries for the
<strong>pleasure of reinventing the wheel</strong>, but also, at times, to offer an
alternative interface. Moreover, OCaml allows interfacing with, among
other languages, C, enabling the creation of <em>bindings</em> for a large
number of libraries and tools. However, if there is a library that you
find <em>objectively</em> missing, I encourage you to join <a href="https://ocaml.org/community">the
community</a>.</p>
<p>It is important to note that my use of OCaml has focused primarily on
three areas:</p>
<ul>
<li><strong>Web development</strong> (heavily driven by Mirage, Ocsigen, and
independent projects like <a href="https://aantron.github.io/dream/">Dream</a>,
<a href="https://github.com/xhtmlboi/yocaml">YOCaml</a>, and many
<a href="https://ocaml.org/packages/search?q=web">others</a>)</li>
<li><strong>Blockchain development</strong> and, by extension, the use of
cryptography libraries, provided once again by Mirage, as well as by
the <a href="https://github.com/hacl-star/hacl-star">HACL*</a> project, a
formally verified library written in <a href="https://fstar-lang.org/">F*</a>
and extracted to OCaml</li>
<li><strong>Development of <a href="https://github.com/ocaml/merlin">Merlin</a></strong> and
<a href="https://github.com/ocaml/ocaml-lsp">OCaml-LSP</a></li>
</ul>
<p>All these areas still require good testing tooling, and OCaml offers
several complementary libraries to implement robust test
suites. Indeed, within the OCaml ecosystem, you can find tools to
write <a href="https://github.com/realworldocaml/mdx">doctests</a>, classic <a href="https://github.com/mirage/alcotest">unit
tests</a>, <a href="https://github.com/c-cube/qcheck">property-based
tests</a>,
<a href="https://github.com/stedolan/crowbar">fuzzing</a>, as well as <a href="https://dune.readthedocs.io/en/stable/tests.html#inline-expectation-tests">output
observation
tests</a>,
<a href="https://dune.readthedocs.io/en/stable/tests.html#inline-tests">inline
tests</a>
(which allow testing, among other things, private components), and
<a href="https://dune.readthedocs.io/en/latest/reference/cram.html">cram
tests</a>.</p>
<p>I continue to find everything I need among the available packages, and
I’m still very impressed to see the number of packages and
alternatives grow <em>year after year</em>. Of course, there are some gaps,
but they have not invalidated my choice of OCaml.</p>
<h4 id="side-note-on-the-standard-library">Side note on the standard library</h4>
<p>A recurring criticism of OCaml is the <em>modesty</em> of its standard
library. Historically, it was designed only to implement the language
itself, so it didn’t include certain features useful for end
users. This situation has led to the emergence of alternative standard
libraries, the most popular of which are:</p>
<ul>
<li><a href="https://github.com/ocaml-batteries-team/batteries-included">Batteries</a>,
an alternative to the standard library that is somewhat
<em>dated</em>. Historically, it was a <em>fork</em> of
<a href="https://github.com/ygrek/ocaml-extlib">Extlib</a>.</li>
<li><a href="https://opensource.janestreet.com/base/">Base</a>, an alternative
developed by <a href="https://janestreet.com/">Janestreet</a>, used <em>quite
extensively</em> in the book <a href="https://dev.realworldocaml.org/">Real World
OCaml</a>. The library enforces strong
conventions, such as <em>labeling</em> higher-order functions (typically
with the name <code>f</code>).</li>
<li><a href="https://opensource.janestreet.com/core/">Core</a> is an extension of
Base.</li>
<li><a href="https://github.com/c-cube/ocaml-containers">Containers</a> is an
extension of the standard library (in the sense that <code>open Containers</code> at the beginning of a module does not break code written
with the standard library).</li>
</ul>
<p>In addition to these alternative standard libraries, there are
specialized libraries that address general problems, such as
<a href="https://github.com/dbuenzli/bos">Bos</a>, which provides tools to
interact with an operating system, and
<a href="https://github.com/xvw/preface">Preface</a> — <em>shameless plug</em> — which
allows you to <em>realize abstractions from category theory</em>.</p>
<p>The stance of the maintainers on the standard library has evolved over
the years, and it is now possible to consider extending it. However,
additions to the standard library are often subject to debate, and
adding new modules can sometimes take a long time. Personally, I would
have preferred that the standard library <strong>continue to serve only the
development of the language</strong> and that a library under the OCaml
community umbrella be published. This separation allows the releases
of the language and its standard library to be desynchronized and also
likely simplifies compatibility between the library and the language.</p>
<h3 id="ecosystem-conclusion">Ecosystem Conclusion</h3>
<p>Unfortunately, I don’t have the opportunity to cover all the tools of
the platform, nor the fundamental building blocks that make OCaml
enjoyable to use for personal projects as well as for industrial
projects (for example, the various existing
<a href="https://github.com/hackwaly/ocamlearlybird">debuggers</a>). However, I
hope I’ve been able to give an overview of some tools that form a
solid foundation for using OCaml.</p>
<p>In my use of the language, I’ve sometimes had to build my own library;
however, it’s not an exercise I regret. I think, unfortunately, that
if one decides never to use a language just because 100% of the
necessary libraries aren’t available, it feels—perhaps awkwardly—to me
like <strong>leveling down</strong>, trapping us behind languages backed by
<em>wealthy companies</em>, like Java or C#, and <strong>that’s a bit sad</strong>.</p>

<p>Even though I’ve used many different programming languages, I think
OCaml is the only one with which I’ve had strong community
interaction. So, I’m not fully aware of how things work in other
communities, which makes my feedback <em>somewhat irrelevant</em>. But from
my experience, I find that the OCaml community, besides being very
productive, is:</p>
<ul>
<li>
<p><strong>Very accessible</strong>: Like many other languages, OCaml has a <a href="https://ocaml.org/community">strong
online presence</a>. On these platforms,
you can find highly experienced contributors to the language and its
ecosystem and benefit from expert (or sometimes less technical)
advice. I’d like to give a special mention to <a href="http://gasche.info/">Gabriel
Scherer</a> and <a href="https://perso.quaesituri.org/florian.angeletti">Florian
Angeletti</a>, whose
answers are always thoughtful and interesting.</p>
</li>
<li>
<p><strong>Very kind</strong>: I often need to ask for help, and I’ve always
received clear and precise answers, whether in private or in public.</p>
</li>
<li>
<p><strong>Very brilliant</strong>: OCaml is the product of work by <em>brilliant
researchers</em>, and having the chance to interact with them is
incredible (and potentially a bit intimidating). Being able to ask
questions directly to people behind some of the major discoveries in
language design is a fantastic opportunity.</p>
</li>
</ul>
<p>To conclude on the community aspect, even though I’m not fully aware
of how other communities interact, I find it a pleasure to be part of
the OCaml developer community. It’s a welcoming space, conducive to
sharing and learning.</p>
<h2 id="some-myths-about-ocaml">Some myths about OCaml</h2>
<p>I’m finally reaching the most fun part of this overly long article: I
get to <strong>debunk</strong> some persistent myths about OCaml. I still can’t
promise complete objectivity, but know that my intentions are good. On
the internet, you often see various criticisms or remarks about OCaml,
and I often find it tiresome to respond. However, what better way than
an article meant to share my enthusiasm for the language to take the
time to address some of these critiques and try to provide a response?</p>
<p>I’ve selected a few, but it’s likely that in the future I’ll write
somewhat longer articles—similar to the members of <a href="https://www.heyplzlookat.me/articles/critique-de-la-raison-pure.gmi">HeyPlzLookAtMe
(fr)</a>
— about articles I find unfair.</p>
<h3 id="ocaml-and-f">OCaml and F#</h3>
<p><a href="https://fsharp.org/">F#</a> is a programming language <a href="https://fsharp.org/history/hopl-final/hopl-fsharp.pdf">historically very
inspired</a> by
OCaml that runs on the <a href="https://dotnet.microsoft.com/">.NET</a> platform
(and, de facto, integrates very well with C#). I find the language —
which I have professionally used at
<a href="https://derniercri.io/">DernierCri</a> and
<a href="https://www.d-edge.com/">D-Edge</a> — very pleasant. Historically, since
.NET was exclusively for Windows environments, OCaml didn’t suffer
much by comparison. However, since the arrival of <a href="https://github.com/dotnet/core">.NET
Core</a>, a cross-platform implementation
of .NET, I increasingly see statements on the internet like:</p>
<blockquote>
<p>"Why continue using OCaml when you can have the same language, F#,
with the entire .NET ecosystem, more features, and a syntax that’s
more pleasant to use?"</p>
</blockquote>
<p>First, I do think that having the .NET (Core) ecosystem is a huge
advantage. Regarding the syntax, I’m more reserved. Indeed, I find
that indentation-based syntax sometimes makes moving code around more
cumbersome, and even though there are criticisms of OCaml’s syntax, I
must admit it hasn’t let me down. The last point seems a bit more
insidious. Indeed, F# has been equipped with features not present in
OCaml, for example:</p>
<ul>
<li><a href="https://learn.microsoft.com/en-us/dotnet/fsharp/language-reference/computation-expressions">Computation
expressions</a>
(which are syntactically a more general form than <a href="https://ocaml.org/manual/5.2/bindingops.html">binding
operators</a>)</li>
<li><a href="https://learn.microsoft.com/en-us/dotnet/fsharp/language-reference/computation-expressions">Type
providers</a>
(which can, unfortunately, sometimes cause issues with .NET Core in
certain name/path resolution cases)</li>
<li><a href="https://learn.microsoft.com/en-us/dotnet/fsharp/language-reference/active-patterns">Active
patterns</a></li>
<li><a href="https://learn.microsoft.com/en-us/dotnet/fsharp/language-reference/generics/statically-resolved-type-parameters">Statically resolved type
parameters</a></li>
<li>The ability to assign methods to sums and products, which makes
sense for interoperability reasons but significantly breaks type
inference</li>
<li>And probably other features that I don’t know well (or are linked to
interoperability with the .NET platform, notably
<a href="https://learn.microsoft.com/fr-fr/dotnet/fsharp/language-reference/attributes">reflection</a>)</li>
</ul>
<p>These evolutions arrived gradually in the language. It would be naive
to think that OCaml hasn’t evolved as well. Indeed, although
historically the two languages seemed very similar, from the very
beginning of F#’s proposal, certain features were missing:</p>
<ul>
<li>
<p>The absence of a <strong>module language</strong>. Indeed, the <code>module</code> keyword
exists in F#, but it is only used to describe static classes (and it
integrates rather awkwardly with namespaces).</p>
</li>
<li>
<p>A <strong>drastically different object model</strong> (for interoperability with
C#, of course).</p>
</li>
</ul>
<p>These two reasons alone would be enough to consider OCaml and F# as
<em>cousin</em> languages but <strong>very different</strong>, and in my opinion, strongly
justify preferring one over the other. In my case, OCaml over F# makes
the introductory sentence of this section moot. However, like F#,
OCaml has also evolved, and in addition to these two fundamental
differences, OCaml offers many features that are absent in F#:</p>
<ul>
<li><strong>Local and generalized <code>open</code>s</strong>: In OCaml, you can open a module
locally within a scope, whereas in F# you can only open a module at
the <em>top-level</em>, which can be quite frustrating in some cases.</li>
<li><strong>Row polymorphism</strong>: OCaml supports row polymorphism on products
(via objects) and sums (via <a href="https://ocaml.org/manual/5.2/polyvariant.html">polymorphic
variants</a>).</li>
<li><strong>Generalized Algebraic Data Types (GADTs)</strong>: One of the most missed
features (after the module system) for expressing precise type
constraints.</li>
<li><strong>User-defined effects</strong>: OCaml allows defining custom effect
handlers, which can simplify complex control flow and concurrency
patterns.</li>
<li><strong>Open sums</strong>: Extensible variants allow for sum types that can be
extended, though similar behavior can sometimes be simulated using
objects and inheritance.</li>
</ul>
<p>To conclude, even though F# is a really nice language and using it
brings many advantages (notably the .NET platform), it is <strong>not just a
better version of OCaml</strong>. The two languages are very different, and
from my point of view, OCaml has a more sophisticated type system,
which makes me prefer it over F#. In my opinion, saying that F# is
just a prettier OCaml is as reasonable as saying that
<a href="https://kotlinlang.org/">Kotlin</a> is nothing more than
<a href="https://www.scala-lang.org/">Scala</a> with a lighter syntax.</p>
<h3 id="doubled-operators-for-floats">Doubled operators for floats</h3>
<p>The standard library contains the following arithmetic operators on
integers:</p>
<pre><code><span>val</span><span> </span><span>(</span><span> </span><span>+</span><span> </span><span>)</span><span> </span><span>:</span><span> </span><span>int</span><span> </span><span>-&gt;</span><span> </span><span>int</span><span> </span><span>-&gt;</span><span> </span><span>int</span><span>
</span><span>val</span><span> </span><span>(</span><span> </span><span>-</span><span> </span><span>)</span><span> </span><span>:</span><span> </span><span>int</span><span> </span><span>-&gt;</span><span> </span><span>int</span><span> </span><span>-&gt;</span><span> </span><span>int</span><span>
</span><span>val</span><span> </span><span>(</span><span> </span><span>*</span><span> </span><span>)</span><span> </span><span>:</span><span> </span><span>int</span><span> </span><span>-&gt;</span><span> </span><span>int</span><span> </span><span>-&gt;</span><span> </span><span>int</span><span>
</span></code></pre>
<p>But also arithmetic operators for floating point numbers:</p>
<pre><code><span>val</span><span> </span><span>(</span><span> </span><span>+.</span><span> </span><span>)</span><span> </span><span>:</span><span> </span><span>float</span><span> </span><span>-&gt;</span><span> </span><span>float</span><span> </span><span>-&gt;</span><span> </span><span>float</span><span>
</span><span>val</span><span> </span><span>(</span><span> </span><span>-.</span><span> </span><span>)</span><span> </span><span>:</span><span> </span><span>float</span><span> </span><span>-&gt;</span><span> </span><span>float</span><span> </span><span>-&gt;</span><span> </span><span>float</span><span>
</span><span>val</span><span> </span><span>(</span><span> </span><span>*.</span><span> </span><span>)</span><span> </span><span>:</span><span> </span><span>float</span><span> </span><span>-&gt;</span><span> </span><span>float</span><span> </span><span>-&gt;</span><span> </span><span>float</span><span>
</span></code></pre>
<p>At first glance, this may seem confusing. However, it makes perfect
sense. If we wanted to have generic operators, we would need <a href="https://en.wikipedia.org/wiki/Ad_hoc_polymorphism">ad-hoc
polymorphism</a>, like
in Haskell, for example, where arithmetic operators reside in the
<code>Num</code> type class:</p>
<pre><code><span>class</span><span>  </span><span>Num</span><span> </span><span>a</span><span>  </span><span>where</span><span>
</span><span>  </span><span>--</span><span> more code</span><span>
</span><span>  (+), (-), (*) :: a -&gt; a -&gt; a
</span><span>  </span><span>--</span><span> more code</span><span>
</span></code></pre>
<p>Without some form of ad-hoc polymorphism (via classes, traits, or
implicits) to describe a constraint on our operators, e.g., <code>op :: Num a =&gt; a -&gt; a -&gt; a</code>, what can we do? A suggestion I’ve often seen online
is to use <em>the same trick</em> as with the <code>=</code> operator, whose type is
<code>val (=) : 'a -&gt; 'a -&gt; bool</code>. That doesn’t work, because while
we can hope that <em>everything is comparable</em> (at worst, we can return
<code>false</code>), how can we generalize something like addition?</p>
<p>Support for arithmetic operators is a tricky problem, which is
actually the original motivation behind <a href="https://en.wikipedia.org/wiki/Type_class">type
classes</a> (and the reason for
<a href="https://learn.microsoft.com/en-us/dotnet/fsharp/language-reference/generics/statically-resolved-type-parameters">statically resolved type
parameters</a>
in F#). From my perspective, <em>while waiting for <a href="https://www.cl.cam.ac.uk/~jdy22/papers/modular-implicits.pdf">modular
implicits</a></em>,
duplicating operators to work with integers and floats seems like a
<em>reasonable</em> approach. And if, for some strange reason, suffixing
operators with dots when using floats gives you hives, you can avoid
it using local opens by providing, for example, this module:</p>
<pre><code><span>module</span><span> </span><span>Arithmetic</span><span> </span><span>(</span><span>P</span><span> </span><span>:</span><span> </span><span>sig</span><span>
</span><span>  </span><span>type</span><span> </span><span>t</span><span>
</span><span>
</span><span>  </span><span>val</span><span> </span><span>add</span><span> : t -&gt; t -&gt; t
</span><span>  </span><span>val</span><span> </span><span>sub</span><span> : t -&gt; t -&gt; t
</span><span>  </span><span>val</span><span> </span><span>mul</span><span> : t -&gt; t -&gt; t
</span><span>  </span><span>val</span><span> </span><span>div</span><span> : t -&gt; t -&gt; t
</span><span>end</span><span>)</span><span> </span><span>=</span><span>
</span><span>struct</span><span>
</span><span>  </span><span>let</span><span> </span><span>(</span><span> </span><span>+</span><span> </span><span>)</span><span>,</span><span> </span><span>(</span><span> </span><span>-</span><span> </span><span>)</span><span>,</span><span> </span><span>(</span><span> </span><span>*</span><span> </span><span>)</span><span>,</span><span> </span><span>(</span><span> </span><span>/</span><span> </span><span>)</span><span> </span><span>=</span><span> </span><span>P</span><span>.</span><span>(</span><span>add</span><span>,</span><span> </span><span>sub</span><span>,</span><span> </span><span>mul</span><span>,</span><span> </span><span>div</span><span>)</span><span>
</span><span>end</span><span>
</span></code></pre>
<p>Which allows extending the <code>Int</code> and <code>Float</code> modules (which already
provide the functions <code>add</code>, <code>sub</code>, <code>mul</code>, and <code>div</code>) by giving them
arithmetic operators:</p>
<pre><code><span>module</span><span> </span><span>Int</span><span> </span><span>=</span><span> </span><span>struct</span><span>
</span><span>  </span><span>include</span><span> </span><span>Int</span><span>
</span><span>  </span><span>include</span><span> </span><span>Arithmetic</span><span> </span><span>(</span><span>Int</span><span>)</span><span>
</span><span>end</span><span>
</span></code></pre>
<p>In broad terms, we create an <code>Int</code> module, include the previous <code>Int</code>
module so that our new <code>Int</code> module retains the entire API of the
original <code>Int</code> module, and then we define (and include) our arithmetic
operators. We can now repeat the same process with <code>Float</code>:</p>
<pre><code><span>module</span><span> </span><span>Float</span><span> </span><span>=</span><span> </span><span>struct</span><span>
</span><span>  </span><span>include</span><span> </span><span>Float</span><span>
</span><span>  </span><span>include</span><span> </span><span>Arithmetic</span><span> </span><span>(</span><span>Float</span><span>)</span><span>
</span><span>end</span><span>
</span></code></pre>
<p>And now we can use a local <code>open</code> so that we don’t have to suffix our
operators with dots:</p>
<pre><code><span>let</span><span> </span><span>x</span><span> </span><span>=</span><span> </span><span>Int</span><span>.</span><span>(</span><span>1</span><span> </span><span>+</span><span> </span><span>2</span><span> </span><span>+</span><span> </span><span>3</span><span> </span><span>+</span><span> </span><span>(</span><span>4</span><span> </span><span>*</span><span> </span><span>6</span><span> </span><span>/</span><span> </span><span>7</span><span>)</span><span>)</span><span>
</span><span>let</span><span> </span><span>y</span><span> </span><span>=</span><span> </span><span>Float</span><span>.</span><span>(</span><span>1.3</span><span> </span><span>+</span><span> </span><span>2.5</span><span> </span><span>+</span><span> </span><span>3.1</span><span> </span><span>+</span><span> </span><span>(</span><span>4.6</span><span> </span><span>*</span><span> </span><span>6.8</span><span> </span><span>/</span><span> </span><span>7.9</span><span>)</span><span>)</span><span>
</span></code></pre>
<p>From my point of view, even if this can be confusing for those coming
from languages where this isn’t an issue, it’s a minor problem. The
lack of operator overloading seems like a rather weak argument for not
giving a language a chance — <em>but that’s just my humble opinion</em>.</p>
<h3 id="on-the-separation-between-ml-and-mli">On the separation between <code>ml</code> and <code>mli</code></h3>
<p>Another point that generates a lot of discussion (even
<a href="https://discuss.ocaml.org/t/has-there-been-a-syntax-proposed-for-combining-mli-into-ml/15163">recently</a>)
concerns the <strong>separation between <code>ml</code> and <code>mli</code> files</strong>. Personally,
I find it great. Even if it can introduce a bit of repetition, it
allows me to focus on the API via module encapsulation in the <code>mli</code>
file while also adding documentation. I can organize the functions I
expose in any order I like, and naturally, I can abstract the types I
share as much as possible. Moreover, when I look at an implementation,
the <code>ml</code> code is rarely cluttered with documentation, making it easy
to navigate the different elements of the module. On top of that, it
enables separate compilation and prevents recompiling modules that
depend on other modules whose implementation alone was changed during
development (this is Dune’s default behavior in the <code>dev</code> profile).</p>
<p>However, tastes vary, and when exposing complex types or module types,
this repetition can be annoying. Fortunately, there is a <em>trick</em>,
presented in 2020 by <a href="https://www.craigfe.io/">Craig Ferguson</a>, that
helps mitigate this repetition: <a href="https://www.craigfe.io/posts/the-intf-trick">The <code>_intf_</code>
trick</a>.</p>
<p>Additionally, there are small tricks based on the ability to pass
arbitrary module expressions to the <code>open</code> and <code>include</code> primitives,
which sometimes allow you to do without <code>mli</code>. I had already mentioned
this in the article <a href="https://xvw.lol/en/articles/modules-import.html">OCaml, modules and import
schemes</a>.</p>
<h4 id="encapsulation-without-mli">Encapsulation without <code>mli</code></h4>
<p>You can simply use <code>open struct (* private code *) end</code> to avoid
exporting parts of your code without needing interfaces. For example:</p>
<pre><code><span>open</span><span> </span><span>struct</span><span>
</span><span>  </span><span>(*</span><span> Private API </span><span>*)</span><span>
</span><span>  </span><span>let</span><span> </span><span>f</span><span> </span><span>x</span><span> </span><span>=</span><span> </span><span>x</span><span>
</span><span>  </span><span>let</span><span> </span><span>g</span><span> </span><span>=</span><span> </span><span>_some_private_stuff</span><span>
</span><span>end</span><span>
</span><span>
</span><span>(*</span><span> Public API </span><span>*)</span><span>
</span><span>let</span><span> </span><span>a</span><span> </span><span>=</span><span> </span><span>f</span><span> </span><span>10</span><span>
</span><span>let</span><span> </span><span>b</span><span> </span><span>=</span><span> </span><span>g</span><span> </span><span>+</span><span> </span><span>11</span><span>
</span></code></pre>
<h4 id="expressing-the-interface-from-ml">Expressing the interface from <code>ml</code></h4>
<p>Another similar technique is to use <code>include (struct ... end : sig (* public API *) end)</code> to describe both the structure and the interface
in the same file. For example:</p>
<pre><code><span>include</span><span> </span><span>(</span><span>struct</span><span>
</span><span>  </span><span>type</span><span> </span><span>t</span><span> </span><span>=</span><span> </span><span>int</span><span>
</span><span>  </span><span>let</span><span> </span><span>f</span><span> </span><span>x</span><span> </span><span>=</span><span> </span><span>x</span><span>
</span><span>  </span><span>let</span><span> </span><span>g</span><span> </span><span>=</span><span> </span><span>_some_private_stuff</span><span>
</span><span>end</span><span> </span><span>:</span><span> </span><span>sig</span><span>
</span><span>  </span><span>type</span><span> </span><span>t</span><span>
</span><span>  </span><span>val</span><span> </span><span>f</span><span> : int -&gt; t
</span><span>end</span><span>)</span><span>
</span></code></pre>
<p>This way, the signature and the structure live in the same file, while
still allowing precise control over encapsulation. Another approach
would be to put the signature in a dedicated <code>module type</code>, like this:</p>
<pre><code><span>module</span><span> </span><span>type</span><span> </span><span>S</span><span> </span><span>=</span><span> </span><span>sig</span><span>
</span><span>  </span><span>type</span><span> </span><span>t</span><span>
</span><span>  </span><span>val</span><span> </span><span>f</span><span> : int -&gt; t
</span><span>end</span><span>
</span><span>
</span><span>include</span><span> </span><span>(</span><span>struct</span><span>
</span><span>  </span><span>type</span><span> </span><span>t</span><span> </span><span>=</span><span> </span><span>int</span><span>
</span><span>  </span><span>let</span><span> </span><span>f</span><span> </span><span>x</span><span> </span><span>=</span><span> </span><span>x</span><span>
</span><span>  </span><span>let</span><span> </span><span>g</span><span> </span><span>=</span><span> </span><span>_some_private_stuff</span><span>
</span><span>end</span><span> </span><span>:</span><span> </span><span>S</span><span>)</span><span>
</span></code></pre>
<p>This is very similar to the first approach, except that the module
also exposes the module type <code>S</code>. A useful side effect of this <em>leak</em>
is that you can easily reference the module's signature using
<code>My_mod.S</code> instead of having to write <code>module type of My_mod</code>.</p>
<h4 id="to-conclude-on-separation">To conclude on separation</h4>
<p>I find this separation <strong>very desirable</strong>. However, since OCaml’s
module system is highly expressive, it is possible — through some
clever encoding — to work around this separation. From my point of
view, these approaches mainly serve to demonstrate this
<em>expressiveness</em>, because the downside of merging everything in one
file is the loss of separate compilation, which I consider <em>quite
unfortunate</em>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I think I have <em>briefly</em> covered the points I wanted to discuss. From
my perspective, <strong>OCaml is an amazing language</strong>! It offers an
excellent balance between safety and expressiveness, thanks in
particular to its advanced type system, a rich module language,
objects, support for <em>row polymorphism</em> via objects and polymorphic
variants, and user-defined effects! Its intersection of research and
industry makes it, in my view, a language evolving in the right
direction, carefully integrating new features to stay modern without
suffering the pitfalls of too-rapid or untested adoption.</p>
<p>Even though for several years OCaml’s tooling might have seemed a bit…
<em>dusty</em>, recently, thanks in part to commercial support from certain
companies, the tooling has been drastically modernized and continues
to improve, as shown by <a href="https://ocaml.org/tools/platform-roadmap">the platform
roadmap</a>. Additionally, the
growing ecosystem of libraries makes it possible to use OCaml in a
wide range of contexts, notably thanks to its different compilation
targets (for example, the browser via
<a href="https://github.com/ocsigen/js_of_ocaml">js_of_ocaml</a> and
<a href="https://github.com/ocaml-wasm/wasm_of_ocaml">wasm_of_ocaml</a>).</p>
<p>By combining an expressive language with a versatile ecosystem and a
supportive, responsive community, OCaml becomes a very compelling
choice for both personal and professional projects. Clearly, migrating
an entire codebase to OCaml is probably not a pragmatic move, but if
you have small personal projects in mind and are curious and
entertained by programming languages, <strong>I seriously encourage you to
consider OCaml</strong>!</p>
<p>I hope I’ve managed to convey my enthusiasm for this language (and its
ecosystem). If you’d like to discuss it, find projects, or explore
contribution opportunities, I’d be happy to talk with you — or you can
reach out to the community through <a href="https://discuss.ocaml.org/">the
forum</a>, which is active, responsive, and
welcoming!</p>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[April Fools 2014: The *Real* Test Driven Development (2014) (114 pts)]]></title>
            <link>https://testing.googleblog.com/2014/04/the-real-test-driven-development.html</link>
            <guid>44891509</guid>
            <pubDate>Wed, 13 Aug 2025 17:46:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://testing.googleblog.com/2014/04/the-real-test-driven-development.html">https://testing.googleblog.com/2014/04/the-real-test-driven-development.html</a>, See on <a href="https://news.ycombinator.com/item?id=44891509">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I'll start with of course this was an April fool's joke.  Wow.</p><p>But for those getting excited at the prospect...</p><p>Of course, writing tests takes about 100th of the time of designing application structure and the writing code, doesn't it?  The productivity gains would be nothing like as high as the suggestion.</p><p>My guess would be that best one could hope for in a tool such as this (when it finally does appear) would be around doubling the output.</p><p>Having something write code for you may be fantasy today, but reality soon; the productivity gains are just PURE fantasy.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cross-Site Request Forgery (140 pts)]]></title>
            <link>https://words.filippo.io/csrf/</link>
            <guid>44891302</guid>
            <pubDate>Wed, 13 Aug 2025 17:31:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://words.filippo.io/csrf/">https://words.filippo.io/csrf/</a>, See on <a href="https://news.ycombinator.com/item?id=44891302">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
            <!-- buttondown-editor-mode: plaintext -->
<p><a href="https://developer.mozilla.org/en-US/docs/Web/Security/Attacks/CSRF">Cross-Site Request Forgery (CSRF)</a> is a <a href="https://en.wikipedia.org/wiki/Confused_deputy_problem">confused deputy</a> attack where the attacker causes the browser to send a request to a target using the ambient authority of the user’s cookies or network position.<sup id="fnref:pna"><a href="#fn:pna">1</a></sup> For example, <code>attacker.example</code> can serve the following HTML to a victim</p>
<pre><code>&lt;form action="https://example.com/send-money" method="post"&gt;
  &lt;input type="hidden" name="to" value="filippo" /&gt;
  &lt;input type="hidden" name="amount" value="1000000" /&gt;
&lt;/form&gt;
</code></pre>
<p>and the browser will send a POST request to <code>https://example.com/send-money</code> using the victim’s cookies.</p>
<p>Essentially all applications that use cookies for authentication need to protect against CSRF. Importantly, this is not about protecting against an attacker that can make arbitrary requests<sup id="fnref:api"><a href="#fn:api">2</a></sup> (as an attacker doesn’t know the user’s cookies), but about working with browsers to identify authenticated requests initiated from untrusted sources.</p>
<p>Unlike <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Guides/CORS">Cross-Origin Resource Sharing (CORS)</a>, which is about <em>sharing responses</em> across origins, CSRF is about accepting state-changing requests, even if the attacker will not see the response. Defending against <a href="https://xsleaks.dev/">leaks</a> is significantly <a href="https://frederikbraun.de/modern-solutions-xsleaks.html">more complex and nuanced</a>, especially in the age of Spectre.</p>
<p>Why do browsers allow these requests in the first place? Like anything in the Web platform, primarily for legacy reasons: that’s how it used to work and changing it breaks things. Importantly, disabling these <em>third-party cookies</em> breaks important Single-Sign On (SSO) flows. All CSRF solutions need to support a bypass mechanism for those rare exceptions. (There are also complex intersections with cross-site tracking and privacy concerns, which are beyond the scope of this article.)</p>
<h2 id="same-site-vs-same-site-vs-same-origin">Same site vs same site vs same origin</h2>
<p>To protect against CSRF, it’s important to first define what is a cross-site or cross-origin request, and which should be allowed.</p>
<p><code>https://app.example.com</code>, <code>https://marketing.example.com</code>, and even <code>http://app.example.com</code> (depending on the definition) are all same-site but not same-origin.</p>
<p>It’s tempting to declare the goal as ensuring requests are simply from the same site, but different origins in the same site can actually sit at very different trust levels: for example it might be much easier to get XSS into an old marketing blog than in the admin panel.</p>
<p>The starkest difference in trust though is between an HTTPS and an HTTP origin, since a network attacker can serve anything it wants on the latter. This is sometimes referred to as the MitM CSRF bypass, but really it’s just a special case of a <em>schemelessly</em> same-site cross-origin CSRF attack.</p>
<p>Some parts of the Web platform apply a <em>schemeful</em> definition of same-site, where <code>https://app.example.com</code> and <code>http://app.example.com</code> are <em>not</em> same-site:</p>
<ul>
<li>Cookies in general apply the schemeless definition (HTTP = HTTPS). There is a proposal to address this, <a href="https://github.com/sbingler/Origin-Bound-Cookies">Origin-Bound-Cookies</a> (and specifically its lack of opt-out for scheme binding, which subsumes the earlier <a href="https://github.com/mikewest/scheming-cookies">Scheme-Bound Cookies</a> proposal), which however <a href="https://chromestatus.com/feature/4945698250293248">hasn’t shipped yet</a>.</li>
<li>The SameSite cookie attribute used to apply the schemeless definition (HTTP = HTTPS). Chrome changed that with <a href="https://web.dev/articles/schemeful-samesite">Schemeful Same-Site</a> in 2020, but <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1651119">Firefox</a> and <a href="https://wpt.fyi/results/cookies/schemeful-same-site?label=master&amp;label=experimental&amp;aligned&amp;q=schemeful">Safari</a> never implemented it.</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Sec-Fetch-Site#same-site">Sec-Fetch-Site</a> (and the <a href="https://html.spec.whatwg.org/multipage/browsers.html#sites">HTML and Fetch specifications</a> in general) apply the schemeful definition (HTTP ≠ HTTPS).</li>
</ul>
<p>Using <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Strict-Transport-Security">HTTP Strict Transport Security (HSTS)</a>, if possible, is a potential mitigation for HTTP→HTTPS issues.</p>
<h2 id="countermeasures">Countermeasures</h2>
<p>There are a number of potential countermeasures to CSRF, some of which have been available only for a few years.</p>
<h3 id="double-submit-or-synchronized-tokens">Double submit or synchronized tokens</h3>
<p>The “classic” countermeasure is a CSRF <em>token</em>, a large random value submitted in the request (e.g. as a hidden <code>&lt;input&gt;</code>) and compared against a value stored in a cookie (<em>double-submit</em>) or in a stateful server-side session (<em>synchronized tokens</em>).</p>
<p>Normally, double-submit is not a same-origin countermeasure, because same-site origins <a href="https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis-20#name-weak-integrity">can set cookies on each other</a> by “cookie tossing”. This can be mitigated with the <code>__Host-</code> <a href="https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis-20#name-the-__host-prefix">cookie prefix</a>, or by binding the token to the session/user with signed metadata. The former makes it impossible for the attacker to set the cookie, the latter ensures the attacker doesn’t know a valid value to set it to.</p>
<p>Note that signing the cookies or tokens is unnecessary and ineffectual, unless it is binding the token to a user: an attacker that’s cookie tossing can otherwise obtain a valid signed pair by logging into the website themselves and then use that for the attack.</p>
<p>This countermeasure turns a cross-origin forgery problem into a cross-origin leak problem: if the attacker can obtain a token from a cross-origin response, it can forge a valid request.</p>
<p>The token in the HTML body should be masked as a countermeasure against the <a href="https://www.breachattack.com/">BREACH compression attack</a>.</p>
<p>The primary issue with CSRF tokens is that they require developers to instrument all their forms and other POST requests.</p>

<p>Browsers send the source of a request in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Origin">Origin</a> header, so CSRF can be mitigated by rejecting <a href="https://developer.mozilla.org/en-US/docs/Glossary/Safe/HTTP">non-safe</a> requests from other origins.</p>
<p>The main issue is knowing the application’s own origin. One option obviously is asking the developer to configure it, but that’s friction and might not always be easy (such as for open source projects and proxied setups).</p>
<p>The closest readily available approximation of the application’s own origin is the Host header. This has two issues:</p>
<ol>
<li>it may be different from the browser origin if a reverse proxy is involved;</li>
<li>it does not include the scheme, so there is no way to know if an <code>http://</code> Origin is a cross-origin HTTP→HTTPS request or a same-origin HTTP request.</li>
</ol>
<p>Some older (pre-2020) browsers <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Origin#browser_compatibility">didn’t send the Origin header for POST requests</a>.</p>
<p>The value can be <code>null</code> in a variety of cases, such as due to <code>Referrer-Policy: no-referrer</code> or following cross-origin redirects. <code>null</code> must be treated as an indication of a cross-origin request.</p>
<p>Some privacy extensions remove the Origin header instead of setting it to <code>null</code>. This should be considered a security vulnerability introduced by the extension, since it removes any reliable indication of a browser cross-origin request.</p>
<h3 id="samesite-cookies">SameSite cookies</h3>
<p>If authentication cookies are <em>explicitly</em> set with the <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Set-Cookie#samesitesamesite-value">SameSite</a> attribute Lax or Strict, they will not be sent with non-safe cross-site requests.</p>
<p>This is, by design, not a cross-origin protection, and it can’t be fixed with the <code>__Host-</code> prefix (or Secure attribute), since that’s about who can set and read cookies, not about where the requests originate. (This difference is reflected in <a href="https://github.com/sbingler/schemeful-same-site#how-do-schemeful-same-site-and-scheme-bound-cookies-differ">the difference between Scheme-Bound Cookies and Schemeful Same-Site</a>.) The risk of same-site HTTP origins is still present, too, in browsers that don’t implement Schemeful Same-Site.</p>
<p>Note that the rollout of SameSite Lax by default has mostly failed due to widespread breakage, especially in SSO flows.  Some browsers now default to <a href="https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis-20#name-top-level-requests-with-uns">Lax-allowing-unsafe</a>, while others default(ed) to None for the first two minutes after the cookie was set. These defaults are not effective CSRF countermeasures.</p>
<h3 id="non-simple-requests">Non-simple requests</h3>
<p>Although CORS is not designed to protect against CSRF, “<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Guides/CORS#simple_requests">non-simple requests</a>” which for example set headers that a simple <code>&lt;form&gt;</code> couldn’t set are preflighted by an OPTIONS request.</p>
<p>An application could choose to allow only non-simple requests, but that is fairly limiting precisely because “simple requests” includes all the ones produced by <code>&lt;form&gt;</code>.</p>
<h3 id="fetch-metadata">Fetch metadata</h3>
<p>To provide a reliable cross-origin signal to websites, browsers introduced <a href="https://web.dev/articles/fetch-metadata">Fetch metadata</a>. In particular, the <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Sec-Fetch-Site">Sec-Fetch-Site</a> header is set to <code>cross-site</code>/<code>same-site</code>/<code>same-origin</code>/<code>none</code><sup id="fnref:none"><a href="#fn:none">3</a></sup> and is now <a href="https://web.dev/articles/fetch-metadata#how_to_use_fetch_metadata_to_protect_against_cross-origin_attacks">the recommended method to mitigate CSRF</a>.</p>
<p>The header has been available in all major browsers <a href="https://caniuse.com/mdn-http_headers_sec-fetch-site">since 2023</a> (and earlier for all but Safari).</p>
<p>One limitation is that it is only sent to “<a href="https://www.w3.org/TR/secure-contexts/#is-origin-trustworthy">trustworthy origins</a>”, i.e. HTTPS and localhost. Note that this is not about the scheme of the initiator origin, but of the target, so it is sent for HTTP→HTTPS requests, but not for HTTPS→HTTP or HTTP→HTTP requests (except localhost→localhost). If Sec-Fetch-Site is missing, a lax fallback on Origin=Host is an option, since HTTP→HTTPS requests are not a concern.</p>
<h2 id="protecting-against-csrf-in-2025">Protecting against CSRF in 2025</h2>
<p>In summary, to protect against CSRF applications (or, rather, libraries and frameworks) should reject cross-origin non-safe browser requests. The most developer-friendly way to do so is using primarily Fetch metadata, which requires no extra instrumentation or configuration.</p>
<ol>
<li>
<p>Allow all GET, HEAD, or OPTIONS requests.</p>
<p>These are <a href="https://developer.mozilla.org/en-US/docs/Glossary/Safe/HTTP">safe</a> methods, and are assumed not to change state at various layers of the stack already.</p>
</li>
<li>
<p>If the Origin header matches an allow-list of trusted origins, allow the request.</p>
<p>Trusted origins should be configured as full origins (e.g. <code>https://example.com</code>) and compared by simple equality with the header value.</p>
</li>
<li>
<p>If the Sec-Fetch-Site header is present:</p>
<ol>
<li>if its value is <code>same-origin</code> or <code>none</code>, allow the request;</li>
<li>otherwise, reject the request.</li>
</ol>
<p>This secures all major up-to-date browsers for sites hosted on trustworthy (HTTPS or localhost) origins.</p>
</li>
<li>
<p>If neither the Sec-Fetch-Site nor the Origin headers are present, allow the request.</p>
<p>These requests are not from (post-2020) browsers, and can’t be affected by CSRF.</p>
</li>
<li>
<p>If the Origin header’s host (including the port) matches the Host header, allow the request, otherwise reject it.</p>
<p>This is either a request to an HTTP origin, or by an out-of-date browser.</p>
</li>
</ol>
<p>The only false positives (unnecessary blocking) of this algorithm are requests to non-trustworthy (plain HTTP) origins that go through a reverse proxy that changes the Host header. That edge case can be worked around by adding the origin to the allow-list.</p>
<p>There are no false negatives in modern browsers, but pre-2023 browsers will be vulnerable to HTTP→HTTPS requests, because the Origin fallback is scheme-agnostic. <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Strict-Transport-Security">HSTS</a> can be used to mitigate that (in post-2020 browsers), but note that out-of-date browsers are likely to have more pressing security issues.</p>
<p>Finally, there should be a tightly scoped bypass mechanism for e.g. SSO edge cases, with the appropriate <a href="https://saferack.com/posts/guide-hazmat-placards-un-numbers/">safety placards</a>. For example, it could be route-based, or require manual tagging of requests before the CSRF middleware.</p>
<p>Go 1.25 introduces a <a href="https://pkg.go.dev/net/http@go1.25rc2#CrossOriginProtection">CrossOriginProtection middleware</a> in <code>net/http</code> which <a href="https://cs.opensource.google/go/go/+/refs/tags/go1.25rc2:src/net/http/csrf.go;l=122">implements this algorithm</a>. (This research was done as background for that proposal.)</p>
<p>Thank you to Roberto Clapis for helping with this analysis, and to Patrick O’Doherty for setting in motion and testing this work. For more, follow me on Bluesky at <a href="https://bsky.app/profile/filippo.abyssdomain.expert">@filippo.abyssdomain.expert</a> or on Mastodon at <a href="https://abyssdomain.expert/@filippo">@filippo@abyssdomain.expert</a>.</p>
<h2 id="the-picture">The picture</h2>
<p>Back to Rome photoblogging. This was taken from the municipal rose garden, which opens for a couple weeks every spring and fall.</p>
<p><img alt="White roses in the foreground, with a grassy park, trees, and the Domus Severiana ruins in the background under a blue sky with scattered clouds." src="https://assets.buttondown.email/images/26176325-9bde-4a8f-997c-72c4f115b0cc.jpeg?w=960&amp;fit=max"></p>
<p>This work is made possible by <a href="https://geomys.org/">Geomys</a>, my Go open source maintenance organization, which is funded by <a href="https://smallstep.com/">Smallstep</a>, <a href="https://www.avalabs.org/">Ava Labs</a>, <a href="https://goteleport.com/">Teleport</a>, <a href="https://tailscale.com/">Tailscale</a>, and <a href="https://sentry.io/">Sentry</a>. Through our retainer contracts they ensure the sustainability and reliability of our open source maintenance work and get a direct line to my expertise and that of the other Geomys maintainers. (Learn more in the <a href="https://words.filippo.io/geomys">Geomys announcement</a>.)</p>
<p>Here are a few words from some of them!</p>
<p>Teleport — For the past five years, attacks and compromises have been shifting from traditional malware and security breaches to identifying and compromising valid user accounts and credentials with social engineering, credential theft, or phishing. <a href="https://goteleport.com/platform/identity/?utm=filippo">Teleport Identity</a> is designed to eliminate weak access patterns through access monitoring, minimize attack surface with access requests, and purge unused permissions via mandatory access reviews.</p>
<p>Ava Labs — We at <a href="https://www.avalabs.org/">Ava Labs</a>, maintainer of <a href="https://github.com/ava-labs/avalanchego">AvalancheGo</a> (the most widely used client for interacting with the <a href="https://www.avax.network/">Avalanche Network</a>), believe the sustainable maintenance and development of open source cryptographic protocols is critical to the broad adoption of blockchain technology. We are proud to support this necessary and impactful work through our ongoing sponsorship of Filippo and his team.</p>

        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. alcohol consumption drops to a 90-year low, new poll finds (106 pts)]]></title>
            <link>https://www.sfchronicle.com/food/wine/article/drink-alcohol-americans-poll-20812180.php</link>
            <guid>44891182</guid>
            <pubDate>Wed, 13 Aug 2025 17:20:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sfchronicle.com/food/wine/article/drink-alcohol-americans-poll-20812180.php">https://www.sfchronicle.com/food/wine/article/drink-alcohol-americans-poll-20812180.php</a>, See on <a href="https://news.ycombinator.com/item?id=44891182">Hacker News</a></p>
Couldn't get https://www.sfchronicle.com/food/wine/article/drink-alcohol-americans-poll-20812180.php: Error: Request failed with status code 402]]></description>
        </item>
        <item>
            <title><![CDATA[A case study in bad hiring practice and how to fix it (115 pts)]]></title>
            <link>https://www.tomkranz.com/blog1/a-case-study-in-bad-hiring-practice-and-how-to-fix-it</link>
            <guid>44890722</guid>
            <pubDate>Wed, 13 Aug 2025 16:42:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomkranz.com/blog1/a-case-study-in-bad-hiring-practice-and-how-to-fix-it">https://www.tomkranz.com/blog1/a-case-study-in-bad-hiring-practice-and-how-to-fix-it</a>, See on <a href="https://news.ycombinator.com/item?id=44890722">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-7028e4af784c74473cf3">
  <p>In this day and age of cybersecurity professionals crying out for roles, we're still seeing companies complain that there is a skills shortage and a lack of talent. A quick scan through your LinkedIn feed will show this is absolute nonsense: there is a mass of experienced, capable talent out there looking for roles. So what's the problem?</p><p>There are two main areas where companies are sabotaging the hiring pipeline:</p><p>1) Companies that are abusing the job boards and hiring process.</p><p>We've all seen these: job adverts asking for the moon on a stick with low pay, so the company can abuse the visa process. Companies lying to their employees about hiring more team members, when they have no intention of cutting into profit margins by actually responding to applications. And companies that are just data mining applicants, stupidly believing that a ghosted candidate is going to magically want to do business with them once they actually have a live role.</p><p>2) Companies that are just completely crap at actually hiring.</p><p>This is where I'm going to be looking at in this article. Despite years of being told (and shown!) how to change their hiring practices to land good cybersecurity talent, companies still persist in the same, broken, unworkable approaches.</p><p>So, for our Case Study of Crapness, please step forward: Canonical.</p><p>Canonical has been advertising for a Head of Security Operations role for almost a year now. You'd think the darling of the Linux world would have an endless stream of geeks eager to work for them. And yet: the role is still being advertised. Let's have a look at why they haven't been able to fill it.</p><h2>Red Flags from the Job Posting</h2><p>The biggest initial red flag is shitting up the job boards (LinkedIn and elsewhere) by posting <strong>exactly the same role</strong> for every single European country <strong>and</strong> US state they are hiring from. Sometimes, for multiple cities within a country (advertising a fully remote role for both Milan and Turin is my favourite here). Any normal person would say "EU-wide, remote role". But no, Canonical have clogged up everyone's searches with their spam.</p>
</div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1755072229091_18750">
  <p>Head over to their LinkedIn homepage at https://www.linkedin.com/company/canonical/jobs/ and see for yourself.</p><p>Any serious candidate is going to have some finely tuned saved job searches, which are now rendered useless because Canonical has spammed 20 or so roles that get picked up by your search parameters. </p><p>"It makes the role more visible." "It increases the chances of a candidate seeing the role."</p><p>Does it, bollocks. What it does do is make it clear that Canonical doesn't care about anyone else's time or resources, and that their hiring team doesn't understand how to actually advertise a role: just spam away, the more postings the better!</p><p>Digging into the actual job advert, we can see a couple of other obvious red flags. The spelling mistakes are one: unforgivable in this age of AI tools plugged into literally everything. </p><p>"Experience with security posture management of corporate endpoitns" isn't just in the hundreds of spammed job postings - it's also in the role description on Canonical's actual recruiting website as well. Excellent job.</p><p>Also, there is no target salary or salary range. This is a red flag for a couple of reasons:</p><p>- It sends a message that the actual compensation is going to be rubbish.</p><p>- It sends a message (combined with the evidence from the advert spamming) that the hiring company will be paying different levels of compensation based on where the applicant lives.</p><p>That last one is particularly inexcusable. We call it a 'compensation package' for a reason: the employer is compensating the employee for using their expertise, time, and energy to make the employer money. It has nothing to do with the CoL where you live, and everything to do with how much the company values you in that role.</p><p>If my cost of living is 40% less in Italy than it is in London, and therefore I get paid 40% less, does that mean it's OK for me to give 40% less effort? If a company thinks they can pay different rates for the same skillset if you live in Milan instead of Frankfurt, they are demonstrating that they do not value the employee. They are a replaceable cog in their machine with a price tag. </p><p>Finally, there are some massive red flags in the actual requirements for the role. I'm going to call out one specifically:</p><p><em>An exceptional academic track record from both high school and university</em></p><p>What the hell is this? There is so little relevance from what was studied at school at 16 years old to a Head of Security Operations role that we'd have to invent entire new fields of science just to measure it. What utter rubbish. </p><p>I've written at length in other articles about how demanding a degree for cybersecurity roles is not just irrelevant, but it blocks some of the best candidates. But high school? Who got paid to write that? And why aren't they now unemployed?</p><h2>Initial Application Process</h2><p>Any company that uses Workday needs to fire their entire HR department. We all know why, we've all had to deal with it:</p><p>- "Upload your CV"</p><p>- "Now manually fill in 3-4 pages of *exactly the same information*, because we don't value your time"</p><p>- "Now enter some demographic information which has zero relevance to your application but gives us some stats so we can feel good about ourselves."</p><p>Canonical's application process is, unbelievably, even more shitty than this. Much like Satan himself, I have some genuine respect for anyone who can come up with something worse than Workday. If you head to their application page on Greenhouse.io, there's the usual "Upload your CV", "Give us your basic details" stuff.</p><p>Then we head off the rails of reasonableness and into the realm of madness.</p><p>Let's be clear: this is an initial application. Any reasonable candidate expects that this is the filtering process: what are we asking for, what's on your CV, does it match - yes, line up an interview.</p><p>The interview is where the actual questioning to dig into a candidate's knowledge happens, and (unless your company is crap at hiring) should be conducted by the line manager, or at the very least, a subject matter expert.</p><p>But no. Canonical is asking in-depth questions about experience that belong firmly in an interview.</p>
</div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1755072229091_20697">
  <p>No. These are questions that have nuance and context that cannot be answered in a character-limited text field, and absolutely should not be reviewed by a hiring manager or member of the HR team. </p><p>Any actual competent candidate would look at nonsense like that, say "Stuff that, I'm out" and close their browser window. This is an absolutely cretinous thing to be asking at this stage of an application (the application! Not even an interview!).</p><p>Given this is a "Head of" role, reporting to senior leadership, anyone in that role with a pulse and at least two brain cells to rub together would understand how self-defeating asking these sorts of questions <em>in an application</em> is.</p><p>But it gets worse.</p><p>I was scathing about their requirement in the job advert for "an exceptional academic track record from both high school and university". Here, Canonical is doubling down on their idiocy.</p>
</div><div data-sqsp-text-block-content="" data-block-type="2" data-sqsp-block="text" id="block-yui_3_17_2_1_1755072229091_22108">
  <p>None of this - none of it at all - is remotely relevant to the actual day-to-day job of a Head of Security Operations. Again, these are questions that cannot be answered appropriately in character-capped text fields. But beyond that, these are questions that should not - ever - be used to screen applicants. Applicants for a role where these requirements are not even remotely relevant.</p><h2>How Their Interview Process Works</h2><p>Having waded through this nonsense, your application finally gets sent. As with many companies, Canonical sends a little follow-up email to let you know what the actual interview process will look like.</p><p>If the application process didn't put you off, then this will be the final nail in the coffin for your application.</p><p>First off, your application does not get reviewed by someone from HR, or a hiring manager, or even the line manager for the role. No.</p><p>"A senior team of managers and leaders from across the company form a virtual team of hiring leads to shepherd every application through our process. They are not recruiters"</p><p>Your application is going to be reviewed by a random group of people who have <strong>nothing whatsoever to do with the role</strong>, who will not have relevant expertise to judge what a "good" application looks like, and who are clearly hiring for clique-fit rather than competency.</p><p>Huge red flag: this hiring-by-committee approach never, ever approves of top candidates. Because a company where someone from a random department gets to review your application is a company that has mediocre chair warmers in senior positions, who want to ensure there are no pockets of excellence in the business that could show them up. Good leaders hire people better than themselves: committees hire mediocrity to cover their arses.</p><p>The biggest fail, though, the absolute discriminatory process that guarantees neuro-divergent or anyone with mental health issues will be weeded out, is the use of aptitude and personality tests.</p><p>"Our interview process starts with a written interview, which will be reviewed in an anonymized queue to reduce bias, and a standardised assessment of aptitude and personality, to provide a more objective initial application review."</p><p>Aptitude and personality tests have been snake oil since they were introduced, and they remain an incredibly stupid and ineffectual way to assess a candidate. There have been decades of research explaining why they suck, and why the people who use them are idiots. Don't just take my word for it, have a look through the detailed investigation the Harvard Business Review did on it - *over a decade ago*. https://archive.ph/p2Frg</p><p>The other major problem with aptitude and personality tests is that they also immediately disqualify anyone who is neuro-divergent, who are exactly the sort of people any sensible organisation would want to attract to a cybersecurity role. This is not just sabotage of the hiring process: this is demonstrable ignorance and incompetence from everyone involved in the hiring process.  </p><p>If you thought Canonical's statement on Diversity https://canonical.com/careers/company-culture/diversity was just another instance of cloying, corporate bullshit - well, now you have the evidence. </p><p>In this day and age of increasingly sophisticated phishing and fake hiring scams, it's also good to see that Canonical will openly enable scamming of applications by having a mish-mash of external companies involved:</p><p>"As you move through the process you will receive a series of communications from us. These will come directly from our Applicant Tracking System (Greenhouse), our partner providers (Thomas International and Devskiller) or as an email from your hiring lead here."</p><p>Why? Why would you do this? The only communication applicants should be getting is from the nominated HR person or hiring manager who is managing your application. Random emails from three external parties or a random employee are just begging for some social engineering. This is doubly obnoxious when you're trying to hire for a security role.</p><h2>Final Thoughts</h2><p>You may think I'm being overly harsh to Canonical, and that I'm making some indefensible judgements. And you could be right - so don't take my word for it.</p><p>Something everyone should be doing before even thinking about applying for a role is heading over to Glassdoor, and looking at two things:</p><p>- what applicants are saying about the hiring process</p><p>- what employees are saying about the company</p><p>Glassdoor is a good barometer for company health because essentially the reviews break things down into three main areas:</p><p>- There's not enough information</p><p>If there are only 1 or 2 reviews (which we'd expect for a smaller company or a startup), it's hard to get a feel for the company. Someone might have been fired for taking a dump in the microwave, and left a scathing review. Or there might only be 12 employees, and only 1 person could be bothered to write up their thoughts.</p><p>- There are several reviews, and they're generally positive</p><p>Everyone likes to whine and complain, so there will always be some negative sentiment, but in general, what we want to see is several balanced reviews, with some positives and negatives, and some good reasons why. Companies with this sort of profile on Glassdoor are generally going to be OK, with nothing more serious than the usual everyday corporate nonsense we all have to endure.</p><p>- There are a load of very negative reviews, and a load of hugely positive reviews</p><p>These are the toxic hell-holes. The negative reviews come from the long stream of dissatisfied employees who are venting their frustrations at a toxic workplace. The hugely positive reviews come from the social media, marketing, and HR teams desperately trying to hide the fact that you'll be working for Satan, and spending your days kicking puppies.</p><p>Have a read through the reviews of working at Canonical here: https://www.glassdoor.co.uk/Reviews/Canonical-Reviews-E230560.htm</p><p>They are pretty damning, highlighting a clique-y and out-of-touch leadership team with a toxic workplace. There's a clear and consistent message about the company culture and the quality of the leadership team and management, and equally clearly, this feedback is being ignored. The reviews touch on many of the things that I've highlighted just by digging through the application process.</p><h2>It doesn't have to be this way</h2><p>Companies like Canonical are continuing to sabotage their efforts to hire security talent. The galling thing is that none of this is difficult to solve, and none of the solutions are cryptic, or secret esoteric knowledge senior cybersecurity people have been jealously guarding. We've all been talking about this for years.</p><p>- Stop asking for degrees. The only, ever, acceptable time to ask for a degree is for a senior position, where asking for "a cybersecurity degree, or equivalent professional experience" is the only right way to do it.</p><p>- Ask for certificates where they are relevant. CISSP for an entry-level analyst role? Do one. CISSP for a senior architect with 8-10 years of experience? Absolutely.</p><p>- The people responsible for managing the position should write the job description. They know what skills and experience matter.</p><p>- Keep the hiring pipeline short and simple. 3 interviews, max, run by people who will be managing the position and understand what is involved. Don't let people unrelated to managing the role do anything with the JD apart from adding some boilerplate fluff about how amazing your company is to work for.</p><p>- Interview candidates properly. None of this "yes/no" nonsense and questions that can easily be Googled. Use case studies, give the candidate a chance to show off their strengths, and have a conversation rather than an interrogation. And, above all, expect difficult questions from candidates, and actually answer them.</p><h2>In Closing</h2><p>No surprise why this role is unfilled almost a year after I first saw it posted. Normally, I'd look at a car crash like this and think "This is a company that isn't just not serious about hiring - they actively hate the sort of people who would apply."</p><p>But in reality, not only is this masterclass in how not to advertise a role, but this is an example of the current thinking and approach of too many companies. Companies that don't respect applicants, let alone their employees. Companies that don't value people's time. Companies that don't value the unique skills and expertise their employees bring to the table.</p><p>Ultimately, companies that are going to be in the news in the coming years for inexcusable and wholly avoidable security breaches.</p><p>I have nothing personally against Canonical - Ubuntu is mediocre but usable, they have had some major privacy slips, and Mark Shuttleworth is a dick - but their whole approach is a perfect example of everything that is currently wrong with hiring security talent.</p><p>I can only hope that sometime soon, as the breaches pile up, the idiots running companies like this will be held accountable.</p><p>Until then, have fun in your job hunting.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gartner's grift is about to unravel (156 pts)]]></title>
            <link>https://dx.tips/gartner</link>
            <guid>44890012</guid>
            <pubDate>Wed, 13 Aug 2025 15:47:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dx.tips/gartner">https://dx.tips/gartner</a>, See on <a href="https://news.ycombinator.com/item?id=44890012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content-parent"><p>I didn’t <em>plan</em> to write this post. I was <em>going</em> to blog about <a target="_blank" href="https://biilmann.blog/articles/introducing-ax/">Agent Experience</a>, the new concept coined by my former boss, Matt Biilmann, CEO of Netlify (I think we are on great terms so I can write this haha). I opened up <a target="_blank" href="https://www.netlify.com/">netlify.com</a> to link it and took a huge doubletake.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1738963425973/588336d4-9497-4973-82fe-1bfee230d3a8.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>See anything unusual?</p>
<p>Of course you don’t, you don’t watch Netlify like it’s your second biggest shareholding. Here, let me take you back a whole ass 30 days to the <a target="_blank" href="https://web.archive.org/web/20250000000000*/https://www.netlify.com/">start of 2025</a>:</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1738963562124/5933e970-7c6b-441d-acd2-39224a60c952.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>What’s different today?</p>
<p>No more Gartner banner. No more <a target="_blank" href="https://www.netlify.com/blog/introducing-the-netlify-composable-web-platform/">Composable Web Platform</a>. <a target="_blank" href="https://www.netlify.com/guide-to-composable-architecture/modern-enterprise-stack/rise-of-composable-architecture/">Composable Architecture</a>.</p>
<p>Hmm. Weird. I remember being told Composable was the future. Let’s look over at Contentful, that other big presumptive winner of the Jamstack/Composable era.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1738964650025/ef0e33b9-588c-4353-9b74-c521e460fc7e.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>Oh?</p>
<p><strong>OH.</strong></p>
<h2 id="heading-how-gartner-grift-works">How Gartner Grift Works</h2>
<p>The basic business model of Gartner is:</p>
<ul>
<li><p>make up term as The Future</p>
</li>
<li><p>put a lot of marketing firepower behind it</p>
</li>
<li><p>make people pay to list on the magic quadrants</p>
</li>
</ul>
<p>This works only as long as CTOs, the dream ICPs of everyone trying to sell into the enterprise, put any credibility into the magic quadrants. Five years ago some “Distinguished VP Analyst” (they are all Distinguished, wow) at Gartner decided Composable was the future:</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1738965081604/b492bffc-a1a1-4948-b68f-cfb991f2119b.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>and so the all the B2B SaaS/IaaS startups with no independent category creation traction suddenly became Composable:</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1738966343145/685db609-3af8-4b7a-908d-89d3bcb4b812.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>In order to capture the SEO keyword and become Leaders in that Quadrant. This of course feeds on itself - if your major competitor puts Composable all over their landing page, you are going to feel pressure to have it. It’s like that parable about 37 different brands of cereal and putting out a new cereal that is “asbestos-free” on it. Of course the other cereals are asbestos free, but you’re going to <em>wonder if they aren’t</em>.</p>
<h2 id="heading-accelerating-misses">Accelerating Misses</h2>
<p>I am no stranger to <a target="_blank" href="https://www.latent.space/p/ai-engineer">category creation</a> and when done right I think it can be a very good harmonizing force for an industry (harmony being the best counter to entropy, which no one wants). But for a Gartner category to be adopted en masse in 2022 and be abandoned by 2024 is a very alarming miss — and it is not the only one.</p>
<p>More recently Databricks has, via Berkeley, tried to make “<a target="_blank" href="https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/">Compound AI Systems</a>” a thing:</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1738966902924/1fe8a664-b39a-45e3-94cc-2e726b825b6d.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>and though it is early days, I have already seen a very short wave of startups speedrun the cycle of wholesale adopting and then wholesale abandoning it. Gartner of course has its own term for it — <a target="_blank" href="https://opentools.ai/news/gartners-2024-ai-hype-cycle-turns-heads-towards-composite-ai">Composite AI</a> — and as far as I can tell it is going to flop — no real/serious AI player has even heard of it. In an age where we have like counts and subscriber counts and view counts for every itemized idea, the Gartner credibility machine no longer transfers and the idea needs to stand on its own merits.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1738967279364/f2b27a6d-228b-4bc1-8b99-cd743412018b.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>Of course, Gartner often gives this treatment to ideas it didn’t come up with — the first time it wrote about AI Engineering, <a target="_blank" href="https://x.com/swyx/status/1826296659317563581">having missed its entire first year</a>, it placed it at the peak of its famous hype cycle, despite multiple foundation model companies getting $100m seed rounds with no model and no product.</p>
<p><img data-zoomable="true" loading="lazy" src="https://pbs.twimg.com/media/GVhPFzbasAAVFV6?format=jpg&amp;name=4096x4096" alt="Image"></p>
<p>The most cited authorities in AI are not Gartner. The best claim to “new Gartner” now is Artificial Analysis (which <a target="_blank" href="https://buttondown.com/ainews/archive/ainews-1162024-artificialanalysis-a-new-modelhost/">I first called out a year ago</a> and Gartner will probably acknowledge 5 years from now), which backs their analysis with live data because their founders and analysts are themselves engineers, not BA History majors given “Distinguished VP Analyst” titles. When the DeepSeek model dropped last month, Gartner had nothing to say, whereas Artificial Analysis was first out with comprehensive production tests and costing and the data/charts to back it up:</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1738967841107/519f65de-f826-41b0-be0a-182047b4bd0b.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>Boomer C-Suites who fancy themselves Enterprise Tech executives and are happy to throw humans at any problem were happy buying off the Gartner catalog and then hitting the golf course. Today, millennial CEOs and CTOs get their analysis and news sources from X, /r/LocalLlama, the All In Podcast, Semianalysis Substacks, any number of <a target="_blank" href="https://github.com/swyxio/ai-notes/blob/main/Resources/Good%20AI%20Podcasts%20and%20Newsletters.md">YouTubes and Podcasts</a>. Meanwhile, Gartner’s home page is just an incessant amount of increasingly irrelevant Gartner Says:</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1738968085410/d96541db-3a28-4def-a3b6-820c41b99464.png?auto=compress,format&amp;format=webp" alt=""></p>
<p>Gideon Gartner started Gartner Inc in 1979 and it once provided an incredible important service when trusted C-suite buyer information was scarce and <a target="_blank" href="https://buttondown.com/ainews/archive/ainews-openai-takes-on-geminis-deep-research/">Deep Research</a> wasn’t available for $200/month. Its greatest hits were the <a target="_blank" href="https://cio-wiki.org/wiki/Gartner_Magic_Quadrant">Magic Quadrant</a> in 1994 and <a target="_blank" href="https://en.wikipedia.org/wiki/Gartner">Hype Cycle</a> in 1995. 30 years later, these simple, conveniently subjective and pay to play mental frameworks are showing their age. My college classmates and peers are now the next generation of leaders at {the big companies, VCs, and startups that you know} and none of them put any stock by Gartner.</p>
<p><strong>What happens when you can no longer manufacture credibility for the credulous?</strong></p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1738968354981/e520953e-73a2-4df6-8df3-19aee86443ce.png?auto=compress,format&amp;format=webp" alt=""></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nginx Introduces Native Support for Acme Protocol (717 pts)]]></title>
            <link>https://blog.nginx.org/blog/native-support-for-acme-protocol</link>
            <guid>44889941</guid>
            <pubDate>Wed, 13 Aug 2025 15:41:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.nginx.org/blog/native-support-for-acme-protocol">https://blog.nginx.org/blog/native-support-for-acme-protocol</a>, See on <a href="https://news.ycombinator.com/item?id=44889941">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>We are very excited to announce the preview release of <a href="https://github.com/nginx/nginx-acme" target="_blank" rel="noreferrer noopener">ACME support in NGINX</a>. The implementation introduces a new module <code>ngx_http_acme_module</code> that provides built-in directives for requesting, installing, and renewing certificates directly from NGINX configuration. The ACME support leverages our <a href="https://github.com/nginx/ngx-rust" target="_blank" rel="noreferrer noopener">NGINX-Rust SDK</a>&nbsp;and is available as a Rust-based dynamic module&nbsp;for both NGINX Open Source users as well as enterprise NGINX One customers using NGINX Plus.</p>



<p>NGINX’s native support for ACME brings a variety&nbsp;of benefits that simplify and enhance the overall SSL/TLS certificate management process. Being able to <a href="https://nginx.org/en/docs/http/ngx_http_acme_module.html" data-type="link" data-id="https://nginx.org/en/docs/http/ngx_http_acme_module.html" target="_blank" rel="noreferrer noopener">configure ACME directly using NGINX directives</a> drastically reduces manual errors and eliminates much of the ongoing overhead traditionally associated with managing SSL/TLS certificates. It also reduces reliance on external tools like Certbot, creating a more secure and streamlined workflow with fewer vulnerabilities and a smaller attack surface. Additionally, unlike existing external tools which can be prone to platform-specific limitations, a native implementation ensures greater portability and platform independence, making it a versatile and reliable solution for modern, evolving web infrastructures.&nbsp;</p>



<h2>What is ACME?&nbsp;</h2>



<p>The <a href="https://www.rfc-editor.org/rfc/rfc8555.html" data-type="link" data-id="https://www.rfc-editor.org/rfc/rfc8555.html" target="_blank" rel="noreferrer noopener">ACME protocol</a> (Automated Certificate Management Environment) is a communications protocol primarily designed to automate the process of issuing, validating, renewing, and revoking digital security certificates (e.g., SSL/TLS certificates). It allows clients to interact with a Certificate Authority (CA) without requiring manual intervention, simplifying the deployment of secure websites and other services that rely on HTTPS.&nbsp;</p>



<p>The ACME protocol was initially developed by the <strong>Internet Security Research Group (ISRG)</strong> as part of the <strong>Let’s Encrypt</strong> initiative in late 2015, offering free, automated SSL/TLS certificates. Before ACME, obtaining TLS certificates was often a manual, costly, and error-prone process. ACME revolutionized this by providing open-source, automated workflows for certificate management.&nbsp;</p>



<p><a href="https://datatracker.ietf.org/doc/html/rfc8555/" target="_blank" rel="noreferrer noopener">ACMEv2</a> is an updated version of the original ACME protocol. It added support for new challenges, expanded authentication methods, wildcard certificates, and other enhancements to improve flexibility and security.&nbsp;</p>



<h2>NGINX ACME Workflow&nbsp;</h2>



<p>The ACME workflow with NGINX can be broken into 4 steps:</p>



<ol>
<li>Setting up the ACME Server</li>



<li>Allocating Shared Memory</li>



<li>Configuring Challenges</li>



<li>Certificate Issue and Renewal</li>
</ol>



<h3>Setting up the ACME Server</h3>



<p>To enable ACME functionality, the first (and the only mandatory step) is to specify the directory URL of the ACME server.&nbsp;&nbsp;</p>



<p>Additional information regarding how to contact the client in case of certificate-related issues or where to store module data can also be provided, as shown.&nbsp;</p>



<pre><code><mark>acme_issuer</mark> <strong>letsencrypt</strong> {&nbsp;
&nbsp;

&nbsp;&nbsp;&nbsp; <mark>uri</mark>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; https://acme-v02.api.letsencrypt.org/directory;&nbsp;

&nbsp;&nbsp;&nbsp; # <mark>contact</mark>&nbsp;&nbsp; admin@example.test;&nbsp;

&nbsp;&nbsp;&nbsp; <mark>state_path</mark>&nbsp; /var/cache/nginx/acme-letsencrypt;&nbsp;

&nbsp;
&nbsp;&nbsp;&nbsp; accept_terms_of_service;&nbsp;
}</code></pre>



<h3>Allocating Shared Memory&nbsp;</h3>



<p>The implementation also provides an optional directive <code>acme_shared_zone</code> to store certificates, private keys, and challenge data for all the configured certificate issuers. The zone has a default size of 256K, which can be increased as required.&nbsp;</p>



<pre><code><mark>acme_shared_zone</mark> zone=acme_shared:1M;&nbsp;</code></pre>



<h3>Configuring Challenges&nbsp;</h3>



<p>The current preview implementation supports HTTP-01 challenges to verify the client’s domain ownership. It requires defining a listener on port 80 in the nginx configuration to process ACME HTTP-01 challenges:&nbsp;</p>



<pre><code><mark>server</mark> {&nbsp;

&nbsp;&nbsp;&nbsp; # listener on port 80 is required to process ACME HTTP-01 challenges&nbsp;
&nbsp;&nbsp;&nbsp; <mark>listen</mark> <mark>80</mark>;&nbsp;

&nbsp;&nbsp;&nbsp; <mark>location</mark> / {&nbsp;

        #Serve a basic 404 response while listening for challenges&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<mark> return 404</mark>;&nbsp;
&nbsp;&nbsp;&nbsp; }&nbsp;
}</code></pre>



<p>Support for other challenges (TLS-ALPN, DNS -01) is planned in <a href="https://github.com/nginx/nginx-acme/issues" target="_blank" rel="noreferrer noopener">future</a>.&nbsp;&nbsp;</p>



<h3>Certificate Issuance and Renewal</h3>



<p>Use the <code>acme_certificate</code> directive in the respective server block in your NGINX configuration to automate the issuance/renewal of TLS certificates. The directive requires the list of identifiers(domains) for which the certificates need to be dynamically issued. The list of identifiers can be defined using the <a href="https://nginx.org/en/docs/http/server_names.html" target="_blank" rel="noreferrer noopener"><code>server_name</code></a> directive.&nbsp;&nbsp;</p>



<p>The snippet below shows how to configure the server block for issuing/renewing SSL certificate for “.example.domain” domain using the previously defined <code>letsencrypt</code> ACME certificate issuer.&nbsp;</p>



<pre><code><mark>server</mark> {&nbsp;

&nbsp;&nbsp;&nbsp; <mark>listen</mark> 443 ssl;&nbsp;

&nbsp;&nbsp;&nbsp; <mark>server_name</mark>&nbsp; .example.com;&nbsp;

&nbsp;&nbsp;&nbsp; <strong><mark>acme_certificate</mark> letsencrypt;&nbsp;</strong>

&nbsp;&nbsp;&nbsp; <mark>ssl_certificate</mark>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $acme_certificate;&nbsp;
&nbsp;&nbsp;&nbsp; <mark>ssl_certificate_key</mark>&nbsp;&nbsp; $acme_certificate_key;&nbsp;
&nbsp;&nbsp;&nbsp; <mark>ssl_certificate_cache</mark> max=2;&nbsp;
}</code></pre>



<p>Note that not all values accepted by <code><a href="https://nginx.org/en/docs/http/server_names.html" target="_blank" rel="noreferrer noopener">server_name</a></code> directive are valid identifiers. Wildcards are not supported in this initial implementation. Regular expressions are not supported.&nbsp;</p>



<p>Use the <code>$acme_certificate</code> and <code>$acme_certificate_key</code> variables in the module to pass the SSL certificate and key information for the associated domain.&nbsp;&nbsp;</p>



<h2>Why It All Matters?&nbsp;</h2>



<p>The rapid rise of HTTPS adoption globally has been driven largely by ACME protocol, making secure web connections a standard expectation. ACME modernizes the way TLS/SSL certificates are issued, renewed, and managed by automating the entire process, eliminating manual effort and reducing costs associated with certificate lifecycle management. Beyond the web, the growth of IoT devices and edge computing positions ACME to play a critical role in automating security for APIs, devices, and edge compute infrastructures.&nbsp;</p>



<p>NGINX’s native support for ACME underscores the protocol’s importance for the future of web security, automation, and scalability. ACME is expected to remain the backbone of certificate automation across the internet and beyond for foreseeable future. With security becoming a baseline for web standards, we’ll continue seeing requirements for evolving deployment models and security needs, pushing improvements in ACME.&nbsp;&nbsp;</p>



<p>Looking ahead, we are committed to evolving our implementation to align with the needs of our users and customers, meeting them where they are today and building capabilities for where they are headed in the future.&nbsp;</p>



<h2>How to Get Started</h2>



<p><a href="https://github.com/nginx/nginx-acme" target="_blank" rel="noreferrer noopener">Get started</a> with the native ACME implementation in NGINX today. If you are an open source user, pre-built packages are available <a href="https://nginx.org/en/linux_packages.html" target="_blank" rel="noreferrer noopener">here</a>. If you are an enterprise NGINX One customer using NGINX Plus, pre-built packages are available as a F5 supported <a href="https://docs.nginx.com/nginx/admin-guide/dynamic-modules/dynamic-modules/" target="_blank" rel="noreferrer noopener">dynamic module</a>. For more information on the module, refer to the <a href="https://nginx.org/en/docs/http/ngx_http_acme_module.html" target="_blank" rel="noreferrer noopener">NGINX Docs</a>.&nbsp;</p>



<h3>Community Feedback&nbsp;</h3>



<p>As always, your feedback is invaluable in shaping the future development of NGINX. If you have suggestions, encounter issues, or want to request additional features, please share them through <a href="https://github.com/nginx/nginx-acme/issues" target="_blank" rel="noreferrer noopener">GitHub Issues</a>. We can’t wait for you to try it out.</p>



<figure><a href="https://community.nginx.org/" target="_blank" rel=" noreferrer noopener"><img decoding="async" width="1024" height="261" src="https://nginxblog-8de1046ff5a84f2c-endpoint.azureedge.net/blobnginxbloga72cde487e/wp-content/uploads/2024/09/Forum-CTA-banner-v1-1024x261.png" alt="NGINX Community Forum" srcset="https://nginxblog-8de1046ff5a84f2c-endpoint.azureedge.net/blobnginxbloga72cde487e/wp-content/uploads/2024/09/Forum-CTA-banner-v1-1024x261.png 1024w, https://nginxblog-8de1046ff5a84f2c-endpoint.azureedge.net/blobnginxbloga72cde487e/wp-content/uploads/2024/09/Forum-CTA-banner-v1-300x77.png 300w, https://nginxblog-8de1046ff5a84f2c-endpoint.azureedge.net/blobnginxbloga72cde487e/wp-content/uploads/2024/09/Forum-CTA-banner-v1-768x196.png 768w, https://nginxblog-8de1046ff5a84f2c-endpoint.azureedge.net/blobnginxbloga72cde487e/wp-content/uploads/2024/09/Forum-CTA-banner-v1.png 1363w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Study: Social media probably can't be fixed (177 pts)]]></title>
            <link>https://arstechnica.com/science/2025/08/study-social-media-probably-cant-be-fixed/</link>
            <guid>44889715</guid>
            <pubDate>Wed, 13 Aug 2025 15:26:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/science/2025/08/study-social-media-probably-cant-be-fixed/">https://arstechnica.com/science/2025/08/study-social-media-probably-cant-be-fixed/</a>, See on <a href="https://news.ycombinator.com/item?id=44889715">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
            <article data-id="2111539">
  
  <header>
  <div>
    

    

    <p>
      "The [structural] mechanism producing these problematic outcomes is really robust and hard to resolve."
    </p>

    

    <div>
            <p><a data-pswp-width="2560" data-pswp-height="1440" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-2048x1152.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-1440x810.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion.jpg" target="_blank">
              <img width="2560" height="1440" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion.jpg" alt="" loading="eager" decoding="async" fetchpriority="high" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-2048x1152.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/08/social-media-distortion-1440x810.jpg 1440w" sizes="(max-width: 2560px) 100vw, 2560px">
            </a></p><div id="caption-2111575">
    
    <p><span>
          Credit:

          
          Aurich Lawson | Getty Images

                  </span>
          </p>
  </div>
          </div>

    <div>
    
    <p><span>
          Credit:

          
          Aurich Lawson | Getty Images

                  </span>
          </p>
  </div>
  </div>
</header>


  

  
      
    
    <div>
                      
                      
          
<p>It's no secret that much of social media has become profoundly dysfunctional. Rather than bringing us together into one utopian public square and fostering a healthy exchange of ideas, these platforms too often create filter bubbles or echo chambers. A small number of high-profile users garner the lion's share of attention and influence, and the algorithms designed to maximize engagement end up merely amplifying outrage and conflict, ensuring the dominance of the loudest and most extreme users—thereby increasing polarization even more.</p>
<p>Numerous platform-level intervention strategies have been proposed to combat these issues, but according to <a href="https://arxiv.org/abs/2508.03385">a preprint</a> posted to the physics arXiv, none of them are likely to be effective. And it's not the fault of much-hated algorithms, non-chronological feeds, or our human proclivity for seeking out negativity. Rather, the dynamics that give rise to all those negative outcomes are structurally embedded in the very architecture of social media. So we're probably doomed to endless toxic feedback loops unless someone hits upon a brilliant fundamental redesign that manages to change those dynamics.</p>
<p>Co-authors Petter Törnberg and Maik Larooij of the University of Amsterdam wanted to learn more about the mechanisms that give rise to the worst aspects of social media: the partisan echo chambers, the concentration of influence among a small group of elite users (attention inequality), and the amplification of the most extreme divisive voices. So they combined standard agent-based modeling with large language models (LLMs), essentially creating little AI personas to simulate online social media behavior. "What we found is that we didn't need to put any algorithms in, we didn't need to massage the model," Törnberg told Ars. "It just came out of the baseline model, all of these dynamics."</p>
<p>They then tested six different intervention strategies social scientists have been proposed to counter those effects: switching to chronological or randomized feeds; inverting engagement-optimization algorithms to reduce the visibility of highly reposted sensational content; boosting the diversity of viewpoints to broaden users' exposure to opposing political views; using "bridging algorithms" to elevate content that fosters mutual understanding rather than emotional provocation; hiding social statistics like reposts and follower accounts to reduce social influence cues; and removing biographies to limit exposure to identity-based signals.</p>

          
                      
                  </div>
                    
        
          
    
    <div>
          
          
<p>The results were far from encouraging. Only some interventions showed modest improvements. None were able to fully disrupt the fundamental mechanisms producing the dysfunctional effects. In fact, some interventions actually made the problems worse. For example, chronological ordering had the strongest effect on reducing attention inequality, but there was a tradeoff: It also intensified the amplification of extreme content. Bridging algorithms significantly weakened the link between partisanship and engagement and modestly improved viewpoint diversity, but it also increased attention inequality. Boosting viewpoint diversity had no significant impact at all.</p>
<p>So is there any hope of finding effective intervention strategies to combat these problematic aspects of social media? Or should we nuke our social media accounts altogether and go live in caves? Ars caught up with Törnberg for an extended conversation to learn more about these troubling findings.</p>
<p><strong>Ars Technica: What drove you to conduct this study?</strong></p>
<p><strong>Petter Törnberg</strong>: For the last 20 years or so, there has been a ton of research on how social media is reshaping politics in different ways, almost always using observational data. But in the last few years, there's been a growing appetite for moving beyond just complaining about these things and trying to see how we can be a bit more constructive. Can we identify how to improve social media and create online spaces that are actually living up to those early promises of providing a public sphere where we can deliberate and debate politics in a constructive way?</p>
<p>The problem with using observational data is that it's very hard to test counterfactuals to implement alternative solutions. So one kind of method that has existed in the field is agent-based simulations and social simulations: create a computer model of the system and then run experiments on that and test counterfactuals. It is useful for looking at the structure and emergence of network dynamics.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>But at the same time, those models represent agents as simple rule followers or optimizers, and that doesn't capture anything of the cultural world or politics or human behavior. I've always been of the controversial opinion that those things actually matter, &nbsp;especially for online politics. We need to study both the structural dynamics of network formations and the patterns of cultural interaction.</p>


<p><strong>Ars Technica: So you developed this hybrid model that combines LLMs with agent-based modeling.</strong></p>
<p><strong>Petter Törnberg</strong>: That's the solution that we find to move beyond the problems of conventional agent-based modeling. Instead of having this simple rule of followers or optimizers, we use AI or LLMs. It's not a perfect solution—there's all kind of biases and limitations—but it does represent a step forward compared to a list of if/then rules. It does have something more of capturing human behavior in a more plausible way. We give them personas that we get from the American National Election Survey, which has very detailed questions about US voters and their hobbies and preferences. And then we turn that into a textual persona—your name is Bob, you're from Massachusetts, and you like fishing—just to give them something to talk about and a little bit richer representation.</p>
<p>And then they see the random news of the day, and they can choose to post the news, read posts from other users, repost them, or they can choose to follow users. If they choose to follow users, they look at their previous messages, look at their user profile.</p>
<p>Our idea was to start with the minimal bare-bones model and then add things to try to see if we could reproduce these problematic consequences. But to our surprise, we actually didn't have to add anything because these problematic consequences just came out of the bare bones model. This went against our expectations and also what I think the literature would say.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p><strong>Ars Technica: I'm skeptical of AI in general, particularly in <a href="https://arstechnica.com/science/2024/03/producing-more-but-understanding-less-the-risks-of-ai-for-scientific-research/">a research context</a>, but there are very specific instances where it can be extremely useful. This strikes me as one of them, largely because your basic model proved to be so robust. You got the same dynamics without introducing anything extra.</strong></p>
<p><strong>Petter Törnberg</strong>: Yes. It's been a big conversation in social science over the last two years or so. There's a ton of interest in using LLMs for social simulation, but no one has really figured out for what or how it's going to be helpful, or how we're going to get past these problems of validity and so on. The kind of approach that we take in this paper is building on a tradition of complex systems thinking. We imagine very simple models of the human world and try to capture very fundamental mechanisms. It's not really aiming to be realistic or a precise, complete model of human behavior.</p>
<p>I've been one of the more critical people of this method, to be honest. At the same time, it's hard to imagine any other way of studying these kinds of dynamics where we have cultural and structural aspects feeding back into each other. But I still have to take the findings with a grain of salt and realize that these are models, and they're capturing a kind of hypothetical world—a spherical cow in a vacuum. We can't predict what someone is going to have for lunch on Tuesday, but we can capture broader mechanisms, and we can see how robust those mechanisms are. We can see whether they're stable, unstable, which conditions they emerge in, and the general boundaries. And in this case, we found a mechanism that seems to be very robust, unfortunately.</p>


<p><strong>Ars Technica: The dream was that social media would help revitalize the public sphere and support the kind of constructive political dialogue that your paper deems "vital to democratic life." That largely hasn't happened. What are the primary negative unexpected consequences that have emerged from social media platforms?</strong></p>
<p><strong>Petter Törnberg</strong>: First, you have echo chambers or filter bubbles. The risk of broad agreement is that if you want to have a functioning political conversation, functioning deliberation, you do need to do that across the partisan divide. If you're only having a conversation with people who already agree with each other, that's not enough. There's debate on how widespread echo chambers are online, but it is quite established that there are a lot of spaces online that aren't very constructive because there's only people from one political side. So that's one ingredient that you need. You need to have a diversity of opinion, a diversity of perspective.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>The second one is that the deliberation needs to be among equals; people need to have more or less the same influence in the conversation. It can't be completely controlled by a small, elite group of users. This is also something that people have pointed to on social media: It has a tendency of creating these influencers because attention attracts attention. And then you have a breakdown of conversation among equals.</p>
<p>The final one is what I call (based on <a href="https://www.amazon.com/Breaking-Social-Media-Prism-Polarizing/dp/0691203423">Chris Bail's book</a>) the social media prism. The more extreme users tend to get more attention online. This is often discussed in relation to engagement algorithms, which tend to identify the type of content that most upsets us and then boost that content. I refer to it as a "trigger bubble" instead of the filter bubble. They're trying to trigger us as a way of making us engage more so they can extract our data and keep our attention.</p>
<p><strong>Ars Technica: Your conclusion is that there's something within the structural dynamics of the network itself that's to blame—something fundamental to the construction of social networks that makes these extremely difficult problems to solve.</strong></p>
<p><strong>Petter Törnberg</strong>: Exactly. It comes from the fact that we're using these AI models to capture a richer representation of human behavior, which allows us to see something that wouldn't really be possible using conventional agent-based modeling. There have been previous models looking at the growth of social networks on social media. People choose to retweet or not, and we know that action tends to be very reactive. We tend to be very emotional in that choice. And it tends to be a highly partisan and polarized type of action. You hit retweet when you see someone being angry about something, or doing something horrific, and then you share that. It's well-known that this leads to toxic, more polarized content spreading more.</p>
<p>But what we find is that it's not just that this content spreads; it also shapes the network structures that are formed. So there's feedback between the effective emotional action of choosing to retweet something and the network structure that emerges. And then in turn, you have a network structure that feeds back what content you see, resulting in a toxic network. The definition of an online social network is that you have this kind of posting, reposting, and following dynamics. It's quite fundamental to it. That alone seems to be enough to drive these negative outcomes.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p><strong>Ars Technica: I was frankly surprised at the ineffectiveness of the various intervention strategies you tested. But it does seem to explain the Bluesky conundrum. Bluesky has no algorithm, for example, yet the same dynamics still seem to emerge. I think Bluesky's founders genuinely want to avoid those dysfunctional issues, but they might not succeed, based on this paper. Why are such interventions so ineffective?&nbsp;</strong></p>

<p><strong>Petter Törnberg</strong>: We've been discussing whether these things are due to the platforms doing evil things with algorithms or whether we as users are choosing that we want a bad environment. What we're saying is that it doesn't have to be either of those. This is often the unintended outcomes from interactions based on underlying rules. It's not necessarily because the platforms are evil; it's not necessarily because people want to be in toxic, horrible environments. It just follows from the structure that we're providing.</p>
<p>We tested six different interventions. Google has been trying to make social media less toxic and recently released a newsfeed algorithm based on the content of the text. So that's one example. We're also trying to do more subtle interventions because often you can find a certain way of nudging the system so it switches over to healthier dynamics. Some of them have moderate or slightly positive effects on one of the attributes, but then they often have negative effects on another attribute, or they have no impact whatsoever.</p>
<p>I should say also that these are very extreme interventions in the sense that, if you depended on making money on your platform, you probably don't want to implement them because it probably makes it really boring to use. It's like showing the least influential users, the least retweeted messages on the platform. Even so, it doesn't really make a difference in changing the basic outcomes. What we take from that is that the mechanism producing these problematic outcomes is really robust and hard to resolve given the basic structure of these platforms.</p>
<p><strong>Ars Technica: So how might one go about building a successful social network that doesn't have these problems?&nbsp;</strong></p>
<p><strong>Petter Törnberg</strong>: There are several directions where you could imagine going, but there's also the constraint of what is popular use. Think back to the early Internet, like <a href="https://en.wikipedia.org/wiki/ICQ">ICQ</a>. ICQ had this feature where you could just connect to a random person. I loved it when I was a kid. I would talk to random people all over the world. I was 12 in the countryside on a small island in Sweden, and I was talking to someone from Arizona, living a different life. I don't know how successful that would be these days, the Internet having become a lot less innocent than it was.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>For instance, we can focus on the question of inequality of attention, a very well-studied and robust feature of these networks. I personally thought we would be able to address it with our interventions, but attention draws attention, and this leads to a power law distribution, where 1 percent [of users] dominates the entire conversation. We know the conditions under which those power laws emerge. This is one of the main outcomes of social network dynamics: extreme inequality of attention.</p>
<p>But in social science, we always teach that everything is a normal distribution. The move from studying the conventional social world to studying the online social world means that you're moving from these nice normal distributions to these horrible power law distributions. Those are the outcomes of having social networks where the probability of connecting to someone depends on how many previous connections they have. If we want to get rid of that, we probably have to move away from the social network model and have some kind of spatial model or group-based model that makes things a little bit more local, a little bit less globally interconnected.</p>
<p><strong>Ars Technica: It sounds like you'd want to avoid those big influential nodes that play such a central role in a large, complex global network.&nbsp;</strong></p>
<p><strong>Petter Törnberg</strong>: Exactly. I think that having those global networks and structures fundamentally undermines the possibility of the kind of conversations that political scientists and political theorists traditionally talked about when they were discussing in the public square. They were talking about social interaction in a coffee house or a tea house, or reading groups and so on. People thought the Internet was going to be precisely that. It's very much not that. The dynamics are fundamentally different because of those structural differences. We shouldn't expect to be able to get a coffee house deliberation structure when we have a global social network where everyone is connected to everyone. It is difficult to imagine a functional politics building on that.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          


<p><strong>Ars Technica: I want to come back to your comment on the power law distribution, how 1 percent of people dominate the conversation, because I think that is something that most users routinely forget. The horrible things we see people say on the Internet are not necessarily indicative of the vast majority of people in the world.&nbsp;</strong></p>
<p><strong>Petter Törnberg</strong>: For sure. That is capturing two aspects. The first is the social media prism, where the perspective we get of politics when we see it through the lens of social media is fundamentally different from what politics actually is. It seems much more toxic, much more polarized. People seem a little bit crazier than they really are. It's a very well-documented aspect of the rise of polarization: People have a false perception of the other side. Most people have fairly reasonable and fairly similar opinions. The actual polarization is lower than the perceived polarization. And that arguably is a result of social media, how it misrepresents politics.</p>
<p>And then we see this very small group of users that become very influential who often become highly visible as a result of being a little bit crazy and outrageous. Social media creates an incentive structure that is really central to reshaping not just how we see politics but also what politics is, which politicians become powerful and influential, because it is controlling the distribution of what is arguably the most valuable form of capital of our era: attention. Especially for politicians, being able to control attention is the most important thing. And since social media creates the conditions of who gets attention or not, it creates an incentive structure where certain personalities work better in a way that's just fundamentally different from how it was in previous eras.</p>
<p><strong>Ars Technica: There are those who have sworn off social media, but it seems like simply not participating isn't really a solution, either.</strong></p>
<p><strong>Petter Törnberg</strong>: No. First, even if you only read, say, The New York Times, that newspaper is still reshaped by what works on social media, the social media logic. I had a student who did a little project this last year showing that as social media became more influential, the headlines of The New York Times became more clickbaity and adapted to the style of what worked on social media. So conventional media and our very culture is being transformed.</p>

          
                  </div>
                    
        
          
    
    <div>

        
        <div>
          
          
<p>But more than that, as I was just saying, it's the type of politicians, it's the type of people who are empowered—it's the entire culture. Those are the things that are being transformed by the power of the incentive structures of social media. It's not like, "This is things that are happening in social media and this is the rest of the world." It's all entangled, and somehow social media has become the cultural engine that is shaping our politics and society in very fundamental ways. Unfortunately.</p>
<p><strong>Ars Technica: I usually like to say that technological tools are fundamentally neutral and can be used for good or ill, but this time I'm not so sure. Is there any hope of finding a way to take the toxic and turn it into a net positive?</strong></p>
<p><strong>Petter Törnberg</strong>: What I would say to that is that we are at a crisis point with the rise of LLMs and AI. I have a hard time seeing the contemporary model of social media continuing to exist under the weight of LLMs and their capacity to mass-produce false information or information that optimizes these social network dynamics. We already see a lot of actors—based on this monetization of platforms like X—that are using AI to produce content that just seeks to maximize attention. So misinformation, often highly polarized information—as AI models become more powerful, that content is going to take over. I have a hard time seeing the conventional social media models surviving that.</p>
<p>We've already seen the process of people retreating in part to credible brands and seeking to have gatekeepers. Young people, especially, are going into WhatsApp groups and other closed communities. Of course, there's misinformation from social media leaking into those chats also. But these kinds of crisis points at least have the hope that we'll see a changing situation. I wouldn't bet that it's a situation for the better. You wanted me to sound positive, so I tried my best. Maybe it's actually "good riddance."</p>
<p><strong>Ars Technica: So let's just blow up all the social media networks. It still won't be better, but at least we'll have different problems.</strong></p>
<p><strong>Petter Törnberg</strong>: Exactly. We'll find a new ditch.</p>
<p>DOI: arXiv, 2025. <a href="http://dx.doi.org/10.48550/arXiv.2508.03385">10.48550/arXiv.2508.03385</a> &nbsp;(<a href="http://arstechnica.com/science/news/2010/03/dois-and-their-discontents-1.ars">About DOIs</a>).</p>


          
                  </div>

                  
          






  <div>
  <div>
          <p><a href="https://arstechnica.com/author/jenniferouellette/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2018/08/arspic300.jpg" alt="Photo of Jennifer Ouellette"></a></p>
  </div>

  <div>
    

    <p>
      Jennifer is a senior writer at Ars Technica with a particular focus on where science meets culture, covering everything from physics and related interdisciplinary topics to her favorite films and TV series. Jennifer lives in Baltimore with her spouse, physicist Sean M. Carroll, and their two cats, Ariel and Caliban.
    </p>
  </div>
</div>


  <p>
    <a href="https://arstechnica.com/science/2025/08/study-social-media-probably-cant-be-fixed/#comments" title="199 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    199 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  <div>
    <header>
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 26"><defs><clipPath id="most-read_svg__a"><path fill="none" d="M0 0h40v26H0z"></path></clipPath><clipPath id="most-read_svg__b"><path fill="none" d="M0 0h40v26H0z"></path></clipPath></defs><g clip-path="url(#most-read_svg__a)"><g fill="none" clip-path="url(#most-read_svg__b)"><path fill="currentColor" d="M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1"></path><path fill="#ff4e00" d="M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3"></path></g></g></svg>
      
    </header>
    <ol>
              <li>
                      <a href="https://arstechnica.com/ai/2025/08/why-its-a-mistake-to-ask-chatbots-about-their-mistakes/">
              <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/the_thinker-768x432.jpg" alt="Listing image for first story in Most Read: Why it’s a mistake to ask chatbots about their mistakes" decoding="async" loading="lazy">
            </a>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                  </ol>
</div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Website Is for Humans (577 pts)]]></title>
            <link>https://localghost.dev/blog/this-website-is-for-humans/</link>
            <guid>44889627</guid>
            <pubDate>Wed, 13 Aug 2025 15:19:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://localghost.dev/blog/this-website-is-for-humans/">https://localghost.dev/blog/this-website-is-for-humans/</a>, See on <a href="https://news.ycombinator.com/item?id=44889627">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>Walking past a bus stop yesterday I saw an advert for Google’s AI search. The person in the ad had pointed their phone’s camera at a bowl of ramen, and the AI result explained how to reproduce it at home.</p>
<p>How does it know? Because it’s trained on all the ramen recipes that multiple recipe authors spent hours, weeks, <em>years</em> perfecting. Generative AI is a blender chewing up other people’s hard work, outputting a sad mush that kind of resembles what you’re looking for, but without any of the credibility or soul. Magic.</p>
<p>I subscribe to a lot of recipe websites via RSS, and look forward to new posts from some of my favourites like <a href="https://smittenkitchen.com/">Smitten Kitchen</a> and <a href="https://www.theguardian.com/profile/meera-sodha">Meera Sodha</a> because I know they’re going to be excellent. I trust that the recipe is tried and tested, and the result will be delicious. ChatGPT will give you an approximation of a recipe made up from the average of lots of recipes, but they lack the personality of each individual recipe, which will be slightly different to reflect the experiences and tastes of the author.</p>
<p>There's a fair bit of talk about “<a href="https://www.theverge.com/24167865/google-zero-search-crash-housefresh-ai-overviews-traffic-data-audience">Google Zero</a>” at the moment: the day when website traffic referred from Google finally hits zero. If the AI search result tells you everything you need, why would you ever visit the actual website?</p>
<p>Well, I want you to visit my website. I want you to read an article from a search result, and then discover the other things I’ve written, the other people I link to, and explore the weird themes I’ve got. I want some of you to read my article then ask me to speak at your conferences. Many folks rely on ad impressions to support the high-quality content they’re putting out for free.</p>
<p>I write the content on this website for people, not robots. I’m sharing my opinions and experiences so that you might identify with them and learn from them. I’m writing about things I care about because I like sharing and I like teaching. I spend hours writing these posts and AI spends seconds summarising them.</p>
<p>I'd much rather people read the whole thing, take it in, digest it and have opinions right back at me. I love it when people connect with what I’m writing (and sometimes they email me to tell me that, which is really delightful).</p>
<p>I <em>don’t</em> write these posts for VC-funded LLMs to come along and gobble up and produce some shitty facsimile, or summarise what I’m saying with none of the nuance or context on someone else's website.</p>
<p>This website is for humans, and LLMs are not welcome here.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New treatment eliminates bladder cancer in 82% of patients (326 pts)]]></title>
            <link>https://news.keckmedicine.org/new-treatment-eliminates-bladder-cancer-in-82-of-patients/</link>
            <guid>44889580</guid>
            <pubDate>Wed, 13 Aug 2025 15:16:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.keckmedicine.org/new-treatment-eliminates-bladder-cancer-in-82-of-patients/">https://news.keckmedicine.org/new-treatment-eliminates-bladder-cancer-in-82-of-patients/</a>, See on <a href="https://news.ycombinator.com/item?id=44889580">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><h2 title="Slow drug-release system found highly effective in treating certain patients with bladder cancer whose tumors were previously unresponsive to cancer therapy">Slow drug-release system found highly effective in treating certain patients with bladder cancer whose tumors were previously unresponsive to cancer therapy</h2></p><div>
        
        <a data-sharepath="https://news.keckmedicine.org/asset/094a4aca-eac4-443e-93b0-b31058c27c5f/tar-200copy_b" data-uuid="094a4aca-eac4-443e-93b0-b31058c27c5f" data-sourcepath="https://content.presspage.com/uploads/2478/094a4aca-eac4-443e-93b0-b31058c27c5f/tar-200copy_b.jpg?10000" data-uploadid="1753047" data-filename="tar-200copy_b.jpg" data-title="TAR-200 is a miniature, pretzel-shaped drug-device duo containing a chemotherapy drug, gemcitabine, which is inserted into the bladder through a catheter and releases the drug for three weeks per treatment cycle." data-description="Photo courtesy of Johnson &amp; Johnson" data-copyright="" rel="nofollow" data-attr-hash="b9337a985248cebcb3df6ffe69c5e5f96fff6461" href="https://content.presspage.com/uploads/2478/094a4aca-eac4-443e-93b0-b31058c27c5f/1920_tar-200copy_b.jpg?10000">
            <img src="https://content.presspage.com/uploads/2478/094a4aca-eac4-443e-93b0-b31058c27c5f/1920_tar-200copy_b.jpg?10000" alt="TAR-200 is a miniature, pretzel-shaped drug-device duo containing a chemotherapy drug, gemcitabine, which is inserted into the bladder through a catheter and releases the drug for three weeks per treatment cycle." title="TAR-200 is a miniature, pretzel-shaped drug-device duo containing a chemotherapy drug, gemcitabine, which is inserted into the bladder through a catheter and releases the drug for three weeks per treatment cycle. - Photo courtesy of Johnson &amp; Johnson">   
             <p>                
                TAR-200 is a miniature, pretzel-shaped drug-device duo containing a chemotherapy drug, gemcitabine, which is inserted into the bladder through a catheter and releases the drug for three weeks per treatment cycle.
            </p>          
         </a>        <p><span><strong>How the drug delivery system works&nbsp;</strong>&nbsp;</span></p><p><span>TAR-200 is a miniature, pretzel-shaped drug-device duo containing a chemotherapy drug, gemcitabine, which is inserted into the bladder through a catheter. Once inside the bladder, the TAR-200 slowly and consistently releases the gemcitabine into the organ for three weeks per treatment cycle.&nbsp;&nbsp;</span></p><p><span>Traditionally, gemcitabine has been delivered to the bladder as a liquid solution that only stays in the bladder for a few hours, which had limited effect destroying the cancer, said Daneshmand, who is also a member of the </span><a href="https://www.keckmedicine.org/services/cancer-care/norris-cancer-center/" target="_blank"><span><u>USC Norris Comprehensive Cancer Center</u></span></a><span>.&nbsp;</span></p><p><span>“The theory behind this study was that the longer the medicine sits inside the bladder, the more deeply it would penetrate the bladder and the more cancer it would destroy,” he said. “And it appears that having the chemotherapy released slowly over weeks rather than in just a few hours is a much more effective approach.”&nbsp;</span></p><p><span><strong>The patient population in the clinical trial&nbsp;</strong>&nbsp;</span></p><p><span>The clinical trial, known as the SunRISe-1, was conducted at 144 locations globally, including at </span><a href="https://www.keckmedicine.org/about/keck-hospital-of-usc/" target="_blank"><span><u>Keck Hospital of USC</u></span></a><span>. It included 85 patients with high-risk non-muscle-invasive bladder cancer.&nbsp;&nbsp;</span></p><p><span>Non-muscle-invasive bladder cancer is the most common form of bladder cancer. The disease is considered high risk when, depending on the type and location of the tumors, the cancer carries a higher chance of recurrence and/or spreading to the bladder muscles or other parts of the body.&nbsp;</span></p><p><span>The standard treatment for this type of bladder cancer is an immunotherapy drug, Bacillus Calmette-Guérin, which may be ineffective in a percentage of patients. All the patients in the clinical trial had been previously treated with this drug, but their cancer had returned.&nbsp;&nbsp;</span></p><p>“The standard treatment plan for these patients <span>was surgery to remove the bladder and surrounding tissue and organs, which has many health risks and may negatively impact patients’ quality of life,” said Daneshmand.&nbsp;</span></p><p><span>To offer patients a better option, urologic oncologists treated patients with TAR-200 every three weeks for six months, and then four times a year for the next two years. In 70 out of 85 patients, the cancer disappeared and for almost half the patients, was still gone a year later. The treatment was well-tolerated, with minimal side effects.&nbsp;&nbsp;</span></p><p><span>The study also showed that administering TAR-200 along with another immunotherapy drug (cetrelimab) did not prove as effective as TAR-200 on its own and had more side effects.&nbsp;&nbsp;</span></p><p><span>While participants in the clinical trial will be followed for another year, the study is closed to new participants.&nbsp;</span></p><p><span><strong>The future of slow-release cancer drugs&nbsp;</strong>&nbsp;</span></p><p><span>This clinical trial is one of several ongoing ones investigating the effect of TAR-200 and the slow release of cancer-fighting drugs into the bladder to fight cancer.&nbsp;&nbsp;</span></p><p><span>“We are at an exciting moment in history,” said Daneshmand, who has been researching this novel treatment since 2016. “Our mission is to deliver cancer-fighting medications into the bladder that will offer lasting remission from cancer, and it looks like we are well on our way toward that goal.”&nbsp;&nbsp;</span></p><p><span>The U.S. Food and Drug Administration has granted TAR-200 a New Drug Application Priority Review, which means the FDA plans to take quicker action on the application than other applications.&nbsp;</span></p><p><span>The health care corporation Johnson &amp; Johnson manufactures TAR-200.</span></p>    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coalton Playground: Type-Safe Lisp in the Browser (111 pts)]]></title>
            <link>https://abacusnoir.com/2025/08/12/coalton-playground-type-safe-lisp-in-your-browser/</link>
            <guid>44889359</guid>
            <pubDate>Wed, 13 Aug 2025 15:00:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abacusnoir.com/2025/08/12/coalton-playground-type-safe-lisp-in-your-browser/">https://abacusnoir.com/2025/08/12/coalton-playground-type-safe-lisp-in-your-browser/</a>, See on <a href="https://news.ycombinator.com/item?id=44889359">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>I wanted to share a side project I’ve been tinkering with for a while and finally got around to shipping:&nbsp;<strong>Coalton Playground</strong>&nbsp;– basically a web-based REPL for Coalton, which is this interesting statically-typed Lisp dialect.</p>



<h2>So What’s Coalton?</h2>



<p>If you haven’t heard of it, <a href="https://coalton-lang.github.io/">Coalton</a> is kind of a weird (<em>in a good way</em>) mashup – it takes Haskell’s type system and plants it right in the middle of Common Lisp. You get all the type safety stuff like algebraic data types and pattern matching, but it still plays nice with “regular” Lisp code.</p>



<p>Or, as the <a href="https://coalton-lang.github.io/about/">official site</a> puts it: “<em>Coalton is an efficient, statically typed functional programming language that supercharges Common Lisp</em>“</p>



<h2>Why I Built This</h2>



<p>I wanted to play with Coalton but setting up a Lisp environment felt like too much work. You need <a href="https://www.sbcl.org/">SBCL</a>, then <a href="https://www.quicklisp.org/beta/">Quicklisp</a>, then install Coalton… and by that point I’d usually get distracted by something else.</p>



<p>So I figured I’d make a playground where you can mess around with it right in the browser. </p>



<h2>Here’s What It Looks Like</h2>



<p>Pretty straightforward – you write Coalton code like this:</p>


<div><pre title="">(coalton-toplevel
  (declare fib (Integer -&gt; Integer))
  (define (fib n)
    (if (&lt;= n 1) n
        (+ (fib (- n 1))
           (fib (- n 2))))))

(cl:format cl:t "fib(10) = ~A~%" (coalton:coalton (fib 10)))
</pre></div>


<p>Hit run, and you get your output. Then, click on “<em>Generated Code</em>” to see equivalent Common Lisp.</p>



<p>A screenshot of one example:</p>



<figure><img loading="lazy" data-attachment-id="5400" data-permalink="https://abacusnoir.com/2025/08/12/coalton-playground-type-safe-lisp-in-your-browser/screenshot-2025-08-12-at-10-26-42-am/" data-orig-file="https://abacusnoir.com/wp-content/uploads/2025/08/screenshot-2025-08-12-at-10.26.42-am.png" data-orig-size="2508,1546" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2025-08-12 at 10.26.42 AM" data-image-description="" data-image-caption="" data-medium-file="https://abacusnoir.com/wp-content/uploads/2025/08/screenshot-2025-08-12-at-10.26.42-am.png?w=300" data-large-file="https://abacusnoir.com/wp-content/uploads/2025/08/screenshot-2025-08-12-at-10.26.42-am.png?w=1024" width="1024" height="631" src="https://abacusnoir.com/wp-content/uploads/2025/08/screenshot-2025-08-12-at-10.26.42-am.png?w=1024" alt="" srcset="https://abacusnoir.com/wp-content/uploads/2025/08/screenshot-2025-08-12-at-10.26.42-am.png?w=1024 1024w, https://abacusnoir.com/wp-content/uploads/2025/08/screenshot-2025-08-12-at-10.26.42-am.png?w=2048 2048w, https://abacusnoir.com/wp-content/uploads/2025/08/screenshot-2025-08-12-at-10.26.42-am.png?w=150 150w, https://abacusnoir.com/wp-content/uploads/2025/08/screenshot-2025-08-12-at-10.26.42-am.png?w=300 300w, https://abacusnoir.com/wp-content/uploads/2025/08/screenshot-2025-08-12-at-10.26.42-am.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2>The Fun Technical Bits</h2>



<p>Getting this to run fast enough was actually kind of interesting. Turns out you can <em>pre-build SBCL cores with Coalton already loaded</em>, which cuts the startup time from ~400ms to ~80ms. Small win, but it makes the whole thing feel snappier.</p>



<p>[<strong>Warning</strong>: not built for scale right now, subject to random errors, unavailability, etc]</p>



<h2>Want to Try It?</h2>



<p>If you’re curious about what statically-typed Lisp feels like, or you just want to procrastinate for a few minutes, go check it out. </p>



<p><a href="https://coalton.app/">https://coalton.app</a></p>



<p>I threw in some examples to get you started – basic stuff like factorial and fibonacci, plus some fancier things like monads if you’re into that.</p>



<hr>



<p>Anyway, that’s it.<em> Just wanted to share this thing I made</em>.</p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pebble Time 2* Design Reveal (177 pts)]]></title>
            <link>https://ericmigi.com/blog/pebble-time-2-design-reveal/</link>
            <guid>44889073</guid>
            <pubDate>Wed, 13 Aug 2025 14:40:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ericmigi.com/blog/pebble-time-2-design-reveal/">https://ericmigi.com/blog/pebble-time-2-design-reveal/</a>, See on <a href="https://news.ycombinator.com/item?id=44889073">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>TL;DR</strong></p><ul><li>Pebble Time 2 Design reveal</li><li>Available in 4 colourways</li><li>Final specifications</li><li>How to change your pre-order from P2D to PT2…</li></ul><p>Like what you see? You can still <a href="https://store.repebble.com/">pre-order Pebble Time 2</a> for $225!</p><iframe width="560" height="315" src="https://www.youtube.com/embed/pcPzmDePH3E" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><p>First off, for those who didn’t catch the <a href="https://ericmigi.com/blog/july-pebble-update">news from a few weeks ago</a> - we’ve been able to recover the Pebble trademark! Our new watches will change from being called Core 2 Duo → Pebble 2 Duo, and Core Time 2 → Pebble Time 2. </p><p>The big news today is that we’re revealing the final design for Pebble Time 2. The design that we showed off back in March were preliminary designs. We've been able to tweak and improve the industrial design quite a bit since then. I think it’s turned out fantastically well! I even have a working albeit early engineering sample on my wrist.</p><p><img src="https://ericmigi.com/assets/pebble-time-2-design-reveal-0-image.png" alt="Early production sample - not final quality/finish yet!!!"></p><p>Early production sample - not final quality/finish yet!!!</p><p>A few more glamour shots:</p><p><img src="https://ericmigi.com/assets/pebble-time-2-design-reveal-1-bolt_hero_01_blue_lighter.png"></p><p><img src="https://ericmigi.com/assets/pebble-time-2-design-reveal-2-3020a181-3a95-4c83-91d4-5b872c69e76a.png"></p><p>Here’s how the design compares to the initial version we showed off in March at the launch</p><p><video controls="" preload="metadata" playsinline=""><source src="https://ericmigi.com/assets/pebble-time-2-design-reveal-5-cleanshot_2025-07-31_at_17.27.57.mp4" type="video/mp4">Your browser does not support the video tag.</video></p><p>CleanShot_2025-07-31_at_17.27.57.mp4</p><p>And <a href="https://imgur.com/a/LLo0qOf">compared to 2016 unreleased Pebble Time 2 </a>(we hardly knew ye).</p><p><a href="https://drive.google.com/drive/folders/1grNZx7lqRmMBLsfQ8qxCHGTK9IiRhNRU?usp=sharing"><strong>Download these images</strong></a> (and more!) in high resolution</p><h3>Colourways</h3><p>We’re planning to release 4 different Pebble Time 2 colourways. These haven’t been finalized yet. No names yet, we still need to pick them!</p><p>After the colourways are locked down, we’ll email everyone who placed a pre-order for Pebble Time 2 and ask them to pick a colour. No need to email us now about it 😉</p><p><img src="https://ericmigi.com/assets/pebble-time-2-design-reveal-4-4-set.png"></p><h3>Final Pebble Time 2 specifications</h3><p>We've added a few new features and confirmed some others since the launch: </p><ul><li>Stainless steel 316 front and back</li><li>Stainless steel 316 buttons (with knurling like Pebble Time Steel!)</li><li>Multicolour RGB LED backlight</li><li>2nd microphone (for potential environmental noise cancellation feature)</li><li>Compass sensor</li><li>Screw-mounted back cover</li></ul><p>This is in addition to all the specs announced previously:</p><ul><li>1.5" 64 color e-paper screen</li><li>Touch screen</li><li>Quick-release 22mm watch strap</li><li>Flat hardened glass lens</li><li>30 day battery life (estimate)</li><li>Heart rate monitor</li><li>Step and sleep tracking</li><li>Speaker</li><li>Linear actuator motor (vibrator)</li><li>Waterproof (final rating TBD)</li></ul><h3>Want to change from Pebble 2 Duo to Pebble Time 2?</h3><p>You can change your pre-order from Pebble 2 Duo to Pebble Time 2 and preserve your place in line. <strong>Do not cancel</strong> your Pebble 2 Duo pre-order, that will move you to back of line! Do not email us about changing - we will send out a survey link to everyone who pre-ordered a Pebble 2 Duo offering them the option to switch to Pebble Time 2 within the next month or so. </p><p>Gentle reminder - if you haven’t already, you can <a href="https://store.repebble.com/">pre-order a Pebble Time 2</a> today!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I'm Worried It Might Get Bad (164 pts)]]></title>
            <link>https://danielmiessler.com/blog/im-worried-it-might-get-bad</link>
            <guid>44888874</guid>
            <pubDate>Wed, 13 Aug 2025 14:25:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danielmiessler.com/blog/im-worried-it-might-get-bad">https://danielmiessler.com/blog/im-worried-it-might-get-bad</a>, See on <a href="https://news.ycombinator.com/item?id=44888874">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-c7584574=""><p>Immediate concerns about the next few months and years</p><p>August 11, 2025</p></div><div><p><a href="https://danielmiessler.com/images/im-worried.gif"><img src="https://danielmiessler.com/images/im-worried.gif" alt="I'm Worried It Might Get Bad"></a></p><p>I'm starting to worry things might get very bad, very soon.</p><p>Not like in a year or two, but maybe in a few months. As in <em>spontaneous recession</em> type of thing. In the US mostly, but perhaps globally.</p><p>It sounds irrational to me as well as I think it or type it. But I can't shake the feeling, so I want to try to write it all down to see how rational it looks on paper.</p><!----><h2 id="a-list-of-things-that-are-troubling-me" tabindex="-1">A list of things that are troubling me <a href="#a-list-of-things-that-are-troubling-me" aria-label="Permalink to &quot;A list of things that are troubling me&quot;">​</a></h2><p>In no real order, here are the various things I'm stressing about.</p><h2 id="i-know-a-ton-of-really-talented-people-who-have-recently-lost-their-jobs" tabindex="-1">I know a ton of really talented people who have recently lost their jobs <a href="#i-know-a-ton-of-really-talented-people-who-have-recently-lost-their-jobs" aria-label="Permalink to &quot;I know a ton of really talented people who have recently lost their jobs&quot;">​</a></h2><p>These are people who've been making over $100-200K in tech or tech-adjacent for over a decade. And they can't find work. I mean they can barely get interviews.</p><p>And when I say a ton, I mean multiple dozen that I either know or I'm one degree separated from. And again, these are not low-skill people. They're legit professionals that have never in their life had trouble finding or maintaining work.</p><h2 id="tons-of-business-leaders-are-explicitly-telling-us-that-they-re-looking-to-replace-human-workers-with-ai" tabindex="-1">Tons of business leaders are explicitly telling us that they're looking to replace human workers with AI <a href="#tons-of-business-leaders-are-explicitly-telling-us-that-they-re-looking-to-replace-human-workers-with-ai" aria-label="Permalink to &quot;Tons of business leaders are explicitly telling us that they're looking to replace human workers with AI&quot;">​</a></h2><p><a href="https://fortune.com/2025/01/06/ai-predictions-2025-hr-leaders-google-cloud-ey-salesforce/" target="_blank" rel="noreferrer">Google has said this</a>. Amazon. <a href="https://allthingstalent.org/salesforce-says-no-to-new-software-engineers-in-2025-points-to-ai-driven-efficiency/2025/01/09/" target="_blank" rel="noreferrer">Salesforce CEO Marc Benioff explicitly stated the company won't hire any new software engineers in 2025</a>, citing AI-driven productivity gains.</p><ul><li><p>We don't even really have to believe them, because we're seeing tons of <em>actual</em> layoffs at the same time.</p></li><li><p><a href="https://www.cnbc.com/2025/05/13/microsoft-is-cutting-3percent-of-workers-across-the-software-company.html" target="_blank" rel="noreferrer">Microsoft laid off 15,000+ employees in 2025</a>, about 7% of its workforce, explicitly tied to AI investments</p></li><li><p><a href="https://www.informationweek.com/it-leadership/tech-company-layoffs-the-covid-tech-bubble-bursts-sep-14" target="_blank" rel="noreferrer">Intel cut 15,000 jobs</a>, <a href="https://techcrunch.com/2025/07/31/tech-layoffs-2025-list/" target="_blank" rel="noreferrer">Tesla laid off 14,000</a>, and <a href="https://news.crunchbase.com/startups/tech-layoffs/" target="_blank" rel="noreferrer">Cisco cut 10,000</a> in 2024</p></li></ul><p>It actually goes much further back, and it's no-doubt multi-causal. We had the pandemic. We had over-hiring. We've heard all the arguments for what it could be.</p><h2 id="the-data-confirm-it-s-really-bad-out-there" tabindex="-1">The data confirm it's really bad out there <a href="#the-data-confirm-it-s-really-bad-out-there" aria-label="Permalink to &quot;The data confirm it's really bad out there&quot;">​</a></h2><p><strong>Tech layoffs by year:</strong></p><ul><li>2022: 93,000 employees laid off</li><li>2023: 200,000 employees laid off (peak)</li><li>2024: 150,000 employees laid off</li><li>2025: 70,000 employees laid off (through July)</li></ul><p><a href="https://techcrunch.com/2024/12/31/a-comprehensive-archive-of-2024-tech-layoffs/" target="_blank" rel="noreferrer">549 companies laid off more than 150,000 employees in 2024</a>, and we're already at <a href="https://techcrunch.com/2025/07/31/tech-layoffs-2025-list/" target="_blank" rel="noreferrer">69,672 layoffs in 2025</a> as of July 31st. The <a href="https://www.nerdwallet.com/article/finance/tech-layoffs" target="_blank" rel="noreferrer">tech unemployment rate sits at 3.4%</a>, but that doesn't capture the full picture of experienced professionals unable to find work.</p><h2 id="ai-keeps-improving-and-companies-are-stitching-together-the-pieces-to-make-it-replace-human-workers" tabindex="-1">AI keeps improving, and companies are stitching together the pieces to make it replace human workers <a href="#ai-keeps-improving-and-companies-are-stitching-together-the-pieces-to-make-it-replace-human-workers" aria-label="Permalink to &quot;AI keeps improving, and companies are stitching together the pieces to make it replace human workers&quot;">​</a></h2><p>Hundreds or thousands of companies, and billions of dollars, are being spent on replacing human workers.</p><p>Some don't think this is possible, but they think we need to invent some super smart model that's better than anything we've ever seen.</p><p>We don't need that. What we need is scaffolding and piping that connects the dots and brings the right context together in the right way to solve problem x or y.</p><!----><p>This is not as difficult as it seems, and I already have a ton of the precursors of this working, and I'm just one person. Now imagine billions of dollars and tens of thousands of people working on it.</p><p><a href="https://www.sfchronicle.com/sf/article/ai-work-employee-salesforce-20396370.php" target="_blank" rel="noreferrer">Salesforce says AI bots now do 50% of the company's work</a>. They're pushing what they call a "digital workforce" where AI agents handle customer service, sales, and even coding tasks. Microsoft reports that <a href="https://www.seattletimes.com/business/microsoft/behind-microsofts-layoffs-a-new-attitude-shaped-by-ai/" target="_blank" rel="noreferrer">30% of software coding work is already done by AI</a>. These aren't future promises - this is happening right now.</p><p>And the prize they're chasing is worth the cost, because it means saving millions upon millions in hiring costs, payroll, health insurance, and all manner of employee-related complications in every business everywhere.</p><p>Getting rid of human work forces is a multi-trillion-dollar opportunity for the companies that get part of that pie. And they're spending on the R&amp;D accordingly.</p><h2 id="most-workers-just-check-in-and-check-out-and-don-t-put-in-that-much-effort" tabindex="-1">Most workers just check in and check out, and don't put in that much effort <a href="#most-workers-just-check-in-and-check-out-and-don-t-put-in-that-much-effort" aria-label="Permalink to &quot;Most workers just check in and check out, and don't put in that much effort&quot;">​</a></h2><p>There's a frequent counter-argument to the AI taking human jobs that goes something like this:</p><blockquote><p>Yeah, AI might be able to do the job at a basic level, but humans are dynamic and creative! We can use our innovation and brilliance to do things way better than AI!</p></blockquote><p>This is, of course, true. For some workers. Some of the time. But—by definition—most workers are not exceptional. Most workers, and most work days, are just drudgery. Answering emails. Writing up quarterly plans. Reviewing metrics. Building applications that do something with data.</p><p>A very large number of people dread Monday, and that's not because they show up Monday morning and bring all their creativity and brilliance. It's because it's clocking in and clocking out on a job they'd rather not be doing.</p><p>These are prime targets for AI replacement. And they are not the fringe. This isn't the bottom 5% of the workforce. This is the bottom 60-80%!</p><p>In other words, my read is that the replacement of jobs by AI isn't coming for the bottom few percent.</p><p>It's coming for all but the top few percent. Not all at once, of course, that will take years, but I think it's already started.</p><h2 id="the-tariffs-haven-t-even-fully-hit-yet" tabindex="-1">The tariffs haven't even fully hit yet <a href="#the-tariffs-haven-t-even-fully-hit-yet" aria-label="Permalink to &quot;The tariffs haven't even fully hit yet&quot;">​</a></h2><p>Then we have the macro situation.</p><p>I make decent money and every single day I'm like:</p><blockquote><p>How the fuck did I pay $20 for a burger and a Diet Coke?</p></blockquote><p>And it's just everything. I use a few different services, eat out a couple of times, and I've spent $100 when that would have been like $40 or $50 dollars a few years ago.</p><p>Putting me aside, I look around at everyone around me and I'm like, how in the hell is anyone affording this?</p><p>And every indication points to prices going even higher as a result of the tariffs. <a href="https://budgetlab.yale.edu/research/where-we-stand-fiscal-economic-and-distributional-effects-all-us-tariffs-enacted-2025-through-april" target="_blank" rel="noreferrer">Economists predict tariffs will raise consumer prices by 2.3% in the short-run</a>, equivalent to an average $3,800 loss per household. <a href="https://www.cbsnews.com/news/inflation-trump-tariffs-economists-forecast-2025/" target="_blank" rel="noreferrer">Morgan Stanley expects inflation to hit 2.5% in 2025</a>, up from their previous forecast. <a href="https://www.morningstar.com/economy/tariffs-are-self-inflicted-economic-catastrophe" target="_blank" rel="noreferrer">Goldman Sachs projects core inflation could reach 3%</a>. I just don't know how much more we can take before something snaps.</p><h2 id="multiple-small-effects-can-cascade-into-a-massive-overall-sentiment-which-can-affect-the-overall-economy" tabindex="-1">Multiple small effects can cascade into a massive overall sentiment, which can affect the overall economy <a href="#multiple-small-effects-can-cascade-into-a-massive-overall-sentiment-which-can-affect-the-overall-economy" aria-label="Permalink to &quot;Multiple small effects can cascade into a massive overall sentiment, which can affect the overall economy&quot;">​</a></h2><p>And this is what I'm <strong>actually</strong> concerned about.</p><p>It's not one of these things. Or two of them. Or 10. It's the fact that they're happening at the same time. It's the fact that I think they can affect and magnify each other and become a thing.</p><h3 id="the-scenarios-i-m-actually-worried-about" tabindex="-1">The scenarios I'm actually worried about <a href="#the-scenarios-i-m-actually-worried-about" aria-label="Permalink to &quot;The scenarios I'm actually worried about&quot;">​</a></h3><ol><li>A massive economic slowdown gets announced</li><li>A new AI Employee product gets announced that clearly <em>can</em> replace most workers</li><li>New layoff numbers get announced and it's hundreds of thousands of people</li><li>New data shows basically nobody is hiring</li><li>Enrollment in colleges plummets because there are no jobs to be had after you go into all that debt</li><li>Inflation jumps massively from the tariffs and/or other causes</li><li>Homelessness skyrockets because people can't pay their rent, but now it's whole families on the streets</li><li>We start to see unrest and/or riots against "the rich" because there are no jobs, and people are being evicted</li><li>Crime goes up significantly</li><li>There is a loud demand for the government to outlaw AI replacement of workers</li><li>We get pulled into some new military conflict, either with Russia, or Iran, or China</li><li>The country continues to suffer financially because the world pulls away from the US and moves into the arms of China</li><li>Thousands more businesses go under because nobody can afford to buy their products or services</li></ol><p>Like I said, I don't think any one of these would be that bad. The problem is several of them are either likely or are already in progress. And that doesn't even include all the compounding factors above.</p><p>I just don't know what the country does if some significant percentage of <a href="https://www.bls.gov/opub/btn/volume-5/pdf/what-is-the-gig-economy.pdf" target="_blank" rel="noreferrer">our 100 million knowledge workers</a> gets laid off because of AI, uncertainty about the future, or for whatever other combination of reasons.</p><h2 id="summary" tabindex="-1">Summary <a href="#summary" aria-label="Permalink to &quot;Summary&quot;">​</a></h2><p>I think there are many things happening right now—or that could happen—that could severely impact a population just barely holding on.</p><ol><li>Everything's too expensive, and likely to get worse</li><li>We already have massive layoffs for unknown reasons</li><li>Billions are being spent on replacing our 100 million knowledge workers with AI</li><li>We're already in something of a mental health crisis</li><li>We're already primed to fight with each other because we no longer share a common reality</li></ol><h3 id="my-prediction" tabindex="-1">My prediction <a href="#my-prediction" aria-label="Permalink to &quot;My prediction&quot;">​</a></h3><p>I'm worried we might see some kind of extraordinary spike in knowledge worker unemployment in the next 2-18 months, which triggers evictions, worker Visa cancellations, foreclosures, a general blaming/targeting of AI, which closes businesses, gets more people laid off, causes governments to overreact with legislation, all of which culminates in a general nationwide panic.</p><p>Again, I'm not quite saying things are going to <em>go</em> bad. I'm saying that these things can combine and multiply each other if they happen at the same time, and create a feeling that's bigger than the reality.</p><p><strong>Which will then <em>be</em> reality.</strong></p><p>And I think that then leads to calls for:</p><ul><li>Redistribution of wealth</li><li>A hurried UBI implementation</li><li>A nationwide ban on foreclosures and evictions</li><li>A law saying you can't use AI employees</li><li>A law saying you can't fire anyone</li><li>Etc.</li></ul><h3 id="ok-but-how-confident-am-i-on-all-this" tabindex="-1">Ok, but how confident am I on all this? <a href="#ok-but-how-confident-am-i-on-all-this" aria-label="Permalink to &quot;Ok, but how confident am I on all this?&quot;">​</a></h3><p>I'm not overly confident / worried that this will happen. Maybe like 60%. Using the CIA levels for predictions, I'd put this one at:</p><ul><li>Virtually Certain: &gt;90%</li><li>Highly Likely: 60-89%</li><li><strong>Even Chance: 40-59%</strong> <strong>←</strong></li><li>Unlikely: 10-39%</li><li>Highly Unlikely: &lt;10%</li></ul><p>Let's hope I'm wrong, and that the pressure gets released some other way.</p><div><h4>Notes</h4></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We caught companies making it harder to delete your personal data online (281 pts)]]></title>
            <link>https://themarkup.org/privacy/2025/08/12/we-caught-companies-making-it-harder-to-delete-your-data</link>
            <guid>44888445</guid>
            <pubDate>Wed, 13 Aug 2025 13:50:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://themarkup.org/privacy/2025/08/12/we-caught-companies-making-it-harder-to-delete-your-data">https://themarkup.org/privacy/2025/08/12/we-caught-companies-making-it-harder-to-delete-your-data</a>, See on <a href="https://news.ycombinator.com/item?id=44888445">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><em>The Markup, now a part of CalMatters, uses investigative reporting, data analysis, and software engineering to challenge technology to serve the public good. Sign up for </em><a href="https://mrkup.org/XvjZS"><em>Klaxon</em></a><em>, a newsletter that delivers our stories and tools directly to your inbox.</em></p>
<!-- no template found for topper block -->




<p>Data brokers are required by California law to provide ways for consumers to request their data be deleted. But good luck finding them.</p>



<p>More than 30 of the companies, which collect and sell consumers’ personal information, hid their deletion instructions from Google, according to a review by The Markup and CalMatters of hundreds of broker websites. This creates one more obstacle for consumers who want to delete their data.&nbsp;</p>





<p>Many of the pages containing the instructions, listed in an official state registry, use code <a href="https://developers.google.com/search/docs/crawling-indexing/robots-meta-tag" target="_blank">to tell search engines</a> to <a href="https://developers.google.com/search/docs/crawling-indexing/block-indexing" target="_blank">remove the page entirely</a> from search results. Popular tools like <a href="https://developers.google.com/search/docs/crawling-indexing/robots-meta-tag" target="_blank">Google</a> and <a href="https://www.bing.com/webmasters/help/block-urls-from-bing-264e560a" target="_blank">Bing</a> respect the code by excluding pages when responding to users.</p>



<p>Data brokers nationwide must register in California under the state’s <a href="https://oag.ca.gov/privacy/ccpa" target="_blank">Consumer Privacy Act</a>, which allows Californians to request that their information be removed, that it not be sold or that they get access to it.&nbsp;</p>



<p>After reviewing the websites of all 499 data brokers <a href="https://cppa.ca.gov/data_broker_registry/" target="_blank">registered</a> with the state, we found 35 had code to stop certain pages from showing up in searches.</p>



<p>While those companies might be fulfilling the letter of the law by providing a page consumers can use to delete their data, it means little if those consumers can’t find the page, according to Matthew Schwartz, a policy analyst at Consumer Reports who studies the California law governing data brokers and other privacy issues.&nbsp;</p>



<p>“This sounds to me like a clever work around to make it as hard as possible for consumers to find it,” Schwartz said.</p>



<p>After The Markup and CalMatters contacted the data brokers, eight said they would review the code on their websites or remove it entirely, and another two said they had independently deleted the code before being contacted. The Markup and CalMatters confirmed nine of the ten companies removed the code.&nbsp;</p>



<p>Two companies said they added the code intentionally to avoid spam at the recommendation of experts and would not change it. The other 24 companies didn’t respond to a request for comment; however, three removed the code after The Markup and CalMatters contacted them.&nbsp;After publication, one company that did not previously respond,<strong>&nbsp;</strong><a href="http://uspeoplesearch.com/" target="_blank" rel="noreferrer noopener">USPeopleSearch.com</a>, said it had removed the code.</p>



<figure><blockquote><p>This sounds to me like a clever work around to make it as hard as possible for consumers to find it.</p><cite>Matthew Schwartz, policy analyst, Consumer Reports</cite></blockquote></figure>



<p>Most of the companies that did respond said they were unaware the code was on their pages.&nbsp;</p>



<p>“The presence of the [code] on our opt-out page was indeed an oversight and not intentional,” May Haddad, a spokesperson for data company FourthWall, said in an emailed response. “Our team promptly rectified the issue upon being informed. As a standard practice, all critical pages—including opt-out and privacy pages—are intended to be indexed by default to ensure maximum visibility and accessibility.” The Markup and CalMatters confirmed that the code had been removed as of July 31.</p>



<p>Some companies that hid their privacy instructions from search engines included a small link at the bottom of their homepage. Accessing it often required scrolling multiple screens, dismissing pop-ups for cookie permissions and newsletter sign-ups and then finding a link that was a fraction the size of other text on the page.&nbsp;</p>



<p>So consumers still faced a serious hurdle when trying to get their information deleted.</p>



<p>Take the <a href="https://ipapi.co/donotsell/" target="_blank">simple opt-out form</a> for <a href="https://ipapi.co/" target="_blank">ipapi</a>, a service offered by Kloudend, Inc that finds the physical locations of internet visitors based on their IP addresses. People can go to the company’s website to request that the company “Do Not Sell” their personal data or to invoke their “Right to Delete” it — but they would have had trouble finding the form, since it contained code excluding it from search results. A spokesperson for Kloudend described the code as an “oversight” and said the page had been changed to be visible to search engines; The Markup and CalMatters confirmed that the code had been removed as of July 31.</p>



<p>Telesign, a company that advertises fraud-prevention services for businesses, offers <a href="https://www.telesign.com/privacy-requests" target="_blank">a simple form</a> for “Data Deletion” and “Opt Out / Do Not Sell”. But that form is hidden from search engines and other automated systems, and isn’t linked on its homepage.&nbsp;</p>



<p>Instead, consumers must search about 7,000 words into a privacy policy filled with legalese to find a link to the page.&nbsp;</p>



<p>A spokesperson for Telesign didn’t respond to a request for comment.&nbsp;</p>





<p>Five of the pages listed in the California registry not only aren’t indexed for search, but don’t exist. For example, a company called BrightCheck, which offers “AI-driven identity verification,” lists <a href="https://www.brightcheck.com/opt-out-preferences" target="_blank">a privacy instructions page</a> on the California registry. But when The Markup and CalMatters visited the page in late July, we found a notice that the page no longer exists. The page was there on March 18 when The Markup and CalMatters first scanned the site, and the Wayback Machine has <a href="https://web.archive.org/web/20250214110043/https://brightcheck.com/opt-out-preferences/" target="_blank">an archive of the page</a> from February 14.&nbsp;</p>



<p>BrightCheck didn’t respond to a request for comment.</p>





<p>The California Consumer Privacy Act went into effect in 2020, governing companies that make most of their revenue from selling consumer data, or who make more than $25 million per year or handle the data of more than 100,000 people in the state. With no comprehensive federal privacy law, the law is among the few regulations data brokers must comply with.&nbsp;</p>



<p>California’s most recent broker database lists nearly 500 companies, most of which consumers have likely never heard of. They include businesses with zippy start-up names like StatSocial and UpLead, and offer everything from email marketing tools to contact directories. CalMatters <a href="https://calmatters.org/economy/technology/2024/04/data-broker-registry/" target="_blank">last year published a guide with information</a> on how consumers can exercise their rights using the database or third-party tools and on how they can request deletion of their children’ s information.</p>



<p>Tom Kemp, executive director of the entity tasked with enforcing the privacy law, the California Privacy Protection Agency, said in an interview that the agency had reproduced The Markup and CalMatters’ findings. While he declined to comment on any particular company’s practices, he pointed to <a href="https://cppa.ca.gov/pdf/enfadvisory202402.pdf" target="_blank">an enforcement advisory</a> from the agency on “dark patterns,” which are design choices that have “the substantial effect of subverting or impairing a consumer’s autonomy, decisionmaking, or choice.”</p>



  



<p>If a company makes it much more difficult to choose to remove their personal data than to contribute it, or includes excessive jargon or other hurdles for consumers to jump through to remove it, according to the advisory, they might be violating the law.</p>



<p>This year, the privacy agency has taken enforcement action against companies including Todd Snyder and Honda for, among other violations, making it too difficult to choose to not have their data used. Todd Snyder <a href="https://cppa.ca.gov/announcements/2025/20250506.html" target="_blank">paid a nearly $350,000 fine</a> this year, while <a href="https://cppa.ca.gov/announcements/2025/20250312.html" target="_blank">Honda agreed to pay</a> more than $630,000. Both agreed to overhaul their privacy practices.</p>



<p>Kemp said that, when determining whether a company has violated the privacy act, it’s important to determine whether there’s a pattern of activity making it difficult for consumers to exercise their rights. Hiding a privacy instructions page could be the first “thread” in determining whether a company is shirking their obligations.&nbsp;</p>



<p>In the past, other companies have been criticized for hiding important web pages from search engines. In 2019, ProPublica revealed how the company behind tax filing service TurboTax added code to effectively <a href="https://www.propublica.org/article/turbotax-deliberately-hides-its-free-file-page-from-search-engines" target="_blank">hide an option</a> for users to file their taxes for free. A <a href="https://www.wsj.com/health/healthcare/hospitals-hide-pricing-data-from-search-results-11616405402?mod=article_inline" target="_blank">2021 report from the Wall Street Journal</a> found that hospitals were hiding prices they <a href="https://www.wsj.com/health/healthcare/hospitals-hide-pricing-data-from-search-results-11616405402?mod=article_inline" target="_blank">were required to post</a> under federal transparency rules.&nbsp;</p>



<p>Recognizing that most Californians have never heard of the hundreds of companies in the data broker registry, lawmakers in California recently passed the Delete Act. The law will create a system called <a href="https://cppa.ca.gov/announcements/2025/20250425.html?mkt_tok=MTM4LUVaTS0wNDIAAAGaMVgznJg32zTAsJRxKpzEZZ5Xs-p2vLqiOROyN3TxNS78RqBIYrYcQIqLKDfothgogRmA7v_bJ6k6wl_djyZBbYGV9zXHyud_c13vzwHwtjh0" target="_blank">the Delete Request and Opt-out Platform</a>, or DROP, which will allow consumers in California to send a single, legally binding request to all data brokers on the registry at one time. The privacy protection agency intends to launch it next year.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When DEF CON partners with the U.S. Army (185 pts)]]></title>
            <link>https://jackpoulson.substack.com/p/when-counterculture-and-empire-merge</link>
            <guid>44888236</guid>
            <pubDate>Wed, 13 Aug 2025 13:33:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jackpoulson.substack.com/p/when-counterculture-and-empire-merge">https://jackpoulson.substack.com/p/when-counterculture-and-empire-merge</a>, See on <a href="https://news.ycombinator.com/item?id=44888236">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!H1ef!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d9a550-63f8-472c-98e5-be0927103664_2264x1366.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!H1ef!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d9a550-63f8-472c-98e5-be0927103664_2264x1366.jpeg 424w, https://substackcdn.com/image/fetch/$s_!H1ef!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d9a550-63f8-472c-98e5-be0927103664_2264x1366.jpeg 848w, https://substackcdn.com/image/fetch/$s_!H1ef!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d9a550-63f8-472c-98e5-be0927103664_2264x1366.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!H1ef!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d9a550-63f8-472c-98e5-be0927103664_2264x1366.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!H1ef!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d9a550-63f8-472c-98e5-be0927103664_2264x1366.jpeg" width="1456" height="878" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/52d9a550-63f8-472c-98e5-be0927103664_2264x1366.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:878,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Dark Tangent and war criminal Paul Nakasone taking jello shots after saying \&quot;Go Army!\&quot; in a pitch to enlist hackers at Defcon to join the US military AI fascist war efforts.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Dark Tangent and war criminal Paul Nakasone taking jello shots after saying &quot;Go Army!&quot; in a pitch to enlist hackers at Defcon to join the US military AI fascist war efforts." title="Dark Tangent and war criminal Paul Nakasone taking jello shots after saying &quot;Go Army!&quot; in a pitch to enlist hackers at Defcon to join the US military AI fascist war efforts." srcset="https://substackcdn.com/image/fetch/$s_!H1ef!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d9a550-63f8-472c-98e5-be0927103664_2264x1366.jpeg 424w, https://substackcdn.com/image/fetch/$s_!H1ef!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d9a550-63f8-472c-98e5-be0927103664_2264x1366.jpeg 848w, https://substackcdn.com/image/fetch/$s_!H1ef!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d9a550-63f8-472c-98e5-be0927103664_2264x1366.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!H1ef!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d9a550-63f8-472c-98e5-be0927103664_2264x1366.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>DEF CON founder Jeff “Dark Tangent” Moss (left) downing a jello shot and shouting “Go Army” at the end of his fireside chat with former National Security Agency director Paul M. Nakasone  (right) on Friday. The previously imprisoned hacktivist Jeremy Hammond was ejected from the conference shortly afterward, yelling “Free Palestine!” </figcaption></figure></div><p><span>Amidst a backdrop of continually airborne beach balls and a remix of the indie rock hit “Heads Will Roll,” entrants to the ‘Arcade Party’ on the second floor of the Las Vegas Convention Center on Friday were given free glow stick bracelets by the Military Cyber Professionals Association. Led by a </span><a href="https://www.milcyber.org/about/leadership" rel="">who’s who</a><span> of former U.S. offensive cyber operations officials, the nonprofit also passed out flyers encouraging “Loyalty to the United States.”</span></p><p>The popular party took place at the end of the opening night of the 33rd annual DEF CON — widely recognized as the world’s largest hacker conference — and attendees socialized over LED-lit foosball tables and free arcade games. Two participants donned full-body furry suits and danced feet away from the DJ and a screen alternating between the logos of the Reston-based defense contractors CACI and Peraton.</p><p><span>In November, a U.S. federal court </span><a href="https://ccrjustice.org/home/press-center/press-releases/abu-ghraib-verdict-iraqi-torture-survivors-win-landmark-case-jury" rel="">ordered CACI</a><span> to pay $42 million in damages for its support for the torture of Iraqi civilians within the Abu Ghraib prison during the U.S. invasion of the country, which more broadly killed at least 200,000 civilians. One of the plaintiffs of the successful lawsuit, Al Jazeera journalist </span><a href="https://ccrjustice.org/AlShimari" rel="">Salah Hasan Al-Ejaili</a><span>, described the CACI torture methods as involving being “kept naked, handcuffed, the hood on your head, then they would bring a big dog.” “You hear the panting and barking of the dog very close to your face,” Hasan </span><a href="https://www.democracynow.org/2014/5/5/imprisoned_al_jazeera_journalist_details_abu" rel="">told Democracy Now!</a><span> in 2014.</span></p><p><span>DEF CON attendees appeared to pay little attention to the human rights atrocities committed by CACI while resting their Vegas-priced beverages on a table prominently displaying the company’s backlit logo. The conference has also recently announced its controversial plans to expand into two authoritarian countries militarily aligned with the U.S. Government: Bahrain, the home of the U.S. Fifth Fleet, and Singapore, a member country of the </span><a href="https://www.cttso.gov/" rel="">Irregular Warfare Technical Support Directorate</a><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Mp9l!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F798012f7-d387-4a91-8dae-efcaf422930a_2620x1318.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Mp9l!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F798012f7-d387-4a91-8dae-efcaf422930a_2620x1318.png 424w, https://substackcdn.com/image/fetch/$s_!Mp9l!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F798012f7-d387-4a91-8dae-efcaf422930a_2620x1318.png 848w, https://substackcdn.com/image/fetch/$s_!Mp9l!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F798012f7-d387-4a91-8dae-efcaf422930a_2620x1318.png 1272w, https://substackcdn.com/image/fetch/$s_!Mp9l!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F798012f7-d387-4a91-8dae-efcaf422930a_2620x1318.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Mp9l!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F798012f7-d387-4a91-8dae-efcaf422930a_2620x1318.png" width="1456" height="732" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/798012f7-d387-4a91-8dae-efcaf422930a_2620x1318.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:732,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:5020823,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://jackpoulson.substack.com/i/170613655?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F798012f7-d387-4a91-8dae-efcaf422930a_2620x1318.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!Mp9l!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F798012f7-d387-4a91-8dae-efcaf422930a_2620x1318.png 424w, https://substackcdn.com/image/fetch/$s_!Mp9l!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F798012f7-d387-4a91-8dae-efcaf422930a_2620x1318.png 848w, https://substackcdn.com/image/fetch/$s_!Mp9l!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F798012f7-d387-4a91-8dae-efcaf422930a_2620x1318.png 1272w, https://substackcdn.com/image/fetch/$s_!Mp9l!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F798012f7-d387-4a91-8dae-efcaf422930a_2620x1318.png 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>The contradiction between the countercultural self-image of the U.S. hacker community and its close partnership with U.S. military and intelligence agencies is arguably the defining feature of DEF CON, with the 50-something founder Jeff “Dark Tangent” Moss recently telling a media property of the </span><a href="https://cyberscoop.com/recorded-future-acquistion-insights/" rel="">U.S. intelligence-backed</a><span> threat intelligence firm Recorded Future that “If you don’t have a seat at the table, the decision might be made against you.” (Moss was inducted into the “Order of Thor” in thanks for his contributions to the U.S. military cyber community </span><a href="https://public.milcyber.org/defcon/arcadeparty" rel="">in 2023</a><span> and became an advisor to the U.S. Department of Homeland Security as far back as </span><a href="https://www.richemont.com/about-us/corporate-governance/jeff-moss/" rel="">2009</a><span>.)</span></p><p><span>Moss recounted the recent history of official collaborations between DEF CON and the U.S. military in the closing session of the conference, naming the 2016 DARPA Cyber Grand Challenge, the Air Force Research Laboratory’s 2023 </span><a href="https://cyberscoop.com/hack-a-sat-moonlighter-def-con/" rel="">Hack-a-Sat</a><span> competition, and then the last two years’ DARPA AIxCC vulnerability patching challenge. </span></p><p><span>The U.S. Army also hosted an Intelligence, Surveillance, and Reconnaissance (ISR) </span><a href="https://xtech.army.mil/competition/xtechlive-at-def-con/" rel="">competition</a><span> at this year’s DEF CON for an artificial intelligence data fusion tool, seeking “real-time fusion of noisy, unstructured, and multimodal data sources based on tactical priorities.” (The winner was the California-based defense technology start-up </span><a href="https://www.hoplynk.com/" rel="">Hoplynk</a><span>.) And the American defense contractor Anduril Industries — which produces lethal loitering munitions — was the </span><a href="https://bsky.app/profile/maritimevillage.bsky.social/post/3ltwwibn7ug2s" rel="">sponsor</a><span> of the Maritime Hacking Village, whose events heavily focused on potential conflict in Taiwan.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!OX42!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8768c4f0-bc6f-4f66-b4af-001a0ed0459e_1852x915.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!OX42!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8768c4f0-bc6f-4f66-b4af-001a0ed0459e_1852x915.png 424w, https://substackcdn.com/image/fetch/$s_!OX42!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8768c4f0-bc6f-4f66-b4af-001a0ed0459e_1852x915.png 848w, https://substackcdn.com/image/fetch/$s_!OX42!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8768c4f0-bc6f-4f66-b4af-001a0ed0459e_1852x915.png 1272w, https://substackcdn.com/image/fetch/$s_!OX42!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8768c4f0-bc6f-4f66-b4af-001a0ed0459e_1852x915.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!OX42!,w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8768c4f0-bc6f-4f66-b4af-001a0ed0459e_1852x915.png" width="1200" height="592.5824175824176" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8768c4f0-bc6f-4f66-b4af-001a0ed0459e_1852x915.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:719,&quot;width&quot;:1456,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:2325995,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://jackpoulson.substack.com/i/170613655?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8768c4f0-bc6f-4f66-b4af-001a0ed0459e_1852x915.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:&quot;center&quot;,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!OX42!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8768c4f0-bc6f-4f66-b4af-001a0ed0459e_1852x915.png 424w, https://substackcdn.com/image/fetch/$s_!OX42!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8768c4f0-bc6f-4f66-b4af-001a0ed0459e_1852x915.png 848w, https://substackcdn.com/image/fetch/$s_!OX42!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8768c4f0-bc6f-4f66-b4af-001a0ed0459e_1852x915.png 1272w, https://substackcdn.com/image/fetch/$s_!OX42!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8768c4f0-bc6f-4f66-b4af-001a0ed0459e_1852x915.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The six winning teams from the U.S. Army’s xTech competition at DEF CON 33, standing next to their respective award checks. From left-to-right, the winners in descending order were: Hoplynk, Inc. ($25,000), Perseus Defense ($25,000), Incerta Strategy Partners ($15,000), OpenInfer ($15,000), Pryzm ($10,000), and PeopleTec, Inc. ($10,000).</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!tEZR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7227765a-f9a2-40bd-a2e2-31dab592420d_1000x523.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!tEZR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7227765a-f9a2-40bd-a2e2-31dab592420d_1000x523.jpeg 424w, https://substackcdn.com/image/fetch/$s_!tEZR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7227765a-f9a2-40bd-a2e2-31dab592420d_1000x523.jpeg 848w, https://substackcdn.com/image/fetch/$s_!tEZR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7227765a-f9a2-40bd-a2e2-31dab592420d_1000x523.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!tEZR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7227765a-f9a2-40bd-a2e2-31dab592420d_1000x523.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!tEZR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7227765a-f9a2-40bd-a2e2-31dab592420d_1000x523.jpeg" width="1000" height="523" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7227765a-f9a2-40bd-a2e2-31dab592420d_1000x523.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:523,&quot;width&quot;:1000,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!tEZR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7227765a-f9a2-40bd-a2e2-31dab592420d_1000x523.jpeg 424w, https://substackcdn.com/image/fetch/$s_!tEZR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7227765a-f9a2-40bd-a2e2-31dab592420d_1000x523.jpeg 848w, https://substackcdn.com/image/fetch/$s_!tEZR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7227765a-f9a2-40bd-a2e2-31dab592420d_1000x523.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!tEZR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7227765a-f9a2-40bd-a2e2-31dab592420d_1000x523.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>A sponsorship image </span><a href="https://bsky.app/profile/maritimevillage.bsky.social/post/3ltwwibn7ug2s" rel="">posted</a><span> to Bluesky by the Maritime Hacking Village.</span></figcaption></figure></div><p><span>Roughly six hours prior to the start of the NSA-affiliated Arcade Party, the prominent hacktivist Jeremy Hammond  — recently released from a </span><a href="https://www.justice.gov/usao-sdny/pr/jeremy-hammond-sentenced-10-years-prison-hacking-stratfor-website-and-other-company" rel="">10-year prison sentence</a><span> for his role in the December 2011 hack of emails from the intelligence contractor Stratfor — was forcibly ejected from the conference after the end of a fireside chat between Moss and former NSA director Paul M. Nakasone.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!4wGi!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48321b83-1431-4336-b769-d30deb0df246_1902x834.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!4wGi!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48321b83-1431-4336-b769-d30deb0df246_1902x834.png 424w, https://substackcdn.com/image/fetch/$s_!4wGi!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48321b83-1431-4336-b769-d30deb0df246_1902x834.png 848w, https://substackcdn.com/image/fetch/$s_!4wGi!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48321b83-1431-4336-b769-d30deb0df246_1902x834.png 1272w, https://substackcdn.com/image/fetch/$s_!4wGi!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48321b83-1431-4336-b769-d30deb0df246_1902x834.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!4wGi!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48321b83-1431-4336-b769-d30deb0df246_1902x834.png" width="1456" height="638" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/48321b83-1431-4336-b769-d30deb0df246_1902x834.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:638,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2000635,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://jackpoulson.substack.com/i/170613655?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48321b83-1431-4336-b769-d30deb0df246_1902x834.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!4wGi!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48321b83-1431-4336-b769-d30deb0df246_1902x834.png 424w, https://substackcdn.com/image/fetch/$s_!4wGi!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48321b83-1431-4336-b769-d30deb0df246_1902x834.png 848w, https://substackcdn.com/image/fetch/$s_!4wGi!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48321b83-1431-4336-b769-d30deb0df246_1902x834.png 1272w, https://substackcdn.com/image/fetch/$s_!4wGi!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48321b83-1431-4336-b769-d30deb0df246_1902x834.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>DEF CON founder Jeff “Dark Tangent” Moss (</span><em>left</em><span>) taking a jello shot next to former National Security Agency director Paul M. Nakasone (</span><em>right</em><span>) on Friday. </span><em><span>Credit: </span><a href="https://x.com/ericgeller/status/1953872938773684370/photo/2" rel="">Eric Geller</a><span> of Cybersecurity Dive.</span></em></figcaption></figure></div><p>Shortly after Moss took a final jello shot next to Nakasone, shouting “Go Army,” Hammond cried out that Nakasone was a “war criminal,” further referencing the Israeli military’s ongoing, U.S.-backed genocide of Gazans by calling out “Free Palestine!”</p><p><span>Though DEF CON strictly prohibits official press from filming talks, </span><a href="https://x.com/arinwaichulis/status/1954208997252473079" rel="">leaked footage</a><span> of the exchange was published on the social media platform X by security writer Arin Waichulis. (Photography within DEF CON is also strictly controlled, protecting the anonymity of hackers and spooks alike; one “goon” volunteer with this year’s event is widely known by his color-based hacker pseudonym and has helped support a significant U.S. intelligence program built on top of his custom scraper for the text-sharing platform Pastebin.)</span></p><p>During the final transparency disclosure section of the conference, Hammond’s ejection was obliquely referenced as one of two “left wing” removals, with both said to have been “earned.” (The same transparency session further disclosed that four employees from an unnamed cybersecurity company attending the conference — including the CEO — were arrested in Las Vegas for doing “something stupid” and had not yet been released.)</p><p><span>“Real hackers don't go to DEF CON. Real hackers get kicked out of DEF CON,” </span><a href="https://bsky.app/profile/lorax.bsky.social/post/3lvwged5uok27" rel="">wrote</a><span> the journalist and transparency activist Lorax B. Horne on Friday, in reference to Hammond’s ejection.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!M6iR!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1174ad4-ee53-47dd-8e7c-00c9a0369382_1464x1032.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!M6iR!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1174ad4-ee53-47dd-8e7c-00c9a0369382_1464x1032.jpeg 424w, https://substackcdn.com/image/fetch/$s_!M6iR!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1174ad4-ee53-47dd-8e7c-00c9a0369382_1464x1032.jpeg 848w, https://substackcdn.com/image/fetch/$s_!M6iR!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1174ad4-ee53-47dd-8e7c-00c9a0369382_1464x1032.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!M6iR!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1174ad4-ee53-47dd-8e7c-00c9a0369382_1464x1032.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!M6iR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1174ad4-ee53-47dd-8e7c-00c9a0369382_1464x1032.jpeg" width="1456" height="1026" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a1174ad4-ee53-47dd-8e7c-00c9a0369382_1464x1032.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1026,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;20 years ago when I spoke at the DEFCON hacker conference it was \&quot;spot the fed\&quot;. After years in prison for hacking charges relates to Anonymous, I was excited to finally return - only to find it thoroughly run by feds and deeply enmeshed with the military industrial complex we fight against. &quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="20 years ago when I spoke at the DEFCON hacker conference it was &quot;spot the fed&quot;. After years in prison for hacking charges relates to Anonymous, I was excited to finally return - only to find it thoroughly run by feds and deeply enmeshed with the military industrial complex we fight against. " title="20 years ago when I spoke at the DEFCON hacker conference it was &quot;spot the fed&quot;. After years in prison for hacking charges relates to Anonymous, I was excited to finally return - only to find it thoroughly run by feds and deeply enmeshed with the military industrial complex we fight against. " srcset="https://substackcdn.com/image/fetch/$s_!M6iR!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1174ad4-ee53-47dd-8e7c-00c9a0369382_1464x1032.jpeg 424w, https://substackcdn.com/image/fetch/$s_!M6iR!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1174ad4-ee53-47dd-8e7c-00c9a0369382_1464x1032.jpeg 848w, https://substackcdn.com/image/fetch/$s_!M6iR!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1174ad4-ee53-47dd-8e7c-00c9a0369382_1464x1032.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!M6iR!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1174ad4-ee53-47dd-8e7c-00c9a0369382_1464x1032.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Despite the controversy from his fireside chat this year, Nakasone also spoke at </span><a href="https://www.youtube.com/watch?v=Fd6v9NXmszM" rel="">last year’s DEF CON</a><span>, and then-NSA director Keith Alexander keynoted DEF CON in 2012.</span></p><p><span>Nakasone also provided a private media briefing to official DEF CON press on Friday morning in his capacity as the founding director of Vanderbilt University’s Institute of National Security, which has recently led a </span><a href="https://www.nytimes.com/2025/08/05/opinion/china-ai-propaganda.html" rel="">media campaign</a><span> arguing that a Chinese artificial intelligence company’s usage of Large Language Models (LLMs) has crossed a new technical threshold in government-aligned information operations. Beijing Thinker Technology Ltd. is widely known for its ‘GoLaxy’ artificial intelligence tool for playing the board game Go and has been alleged, based upon unpublished documents said to be leaked by a former employee, to have conducted influence campaigns aligned with Chinese government objectives. </span></p><p><span>When asked by All-Source Intelligence about how GoLaxy’s alleged usage of LLMs is technologically distinct from the U.S. military’s open advertisement of plans to equip U.S. Special Operations Forces with LLMs to scale up information operations, as well as ongoing information operations </span><a href="https://jackpoulson.substack.com/p/google-affiliated-military-ai-expo" rel="">in the Philippines</a><span> run by the U.S. intelligence contractor Rhombus Power, Nakasone argued that “There’s not an equivalence between the United States and China when it comes to the rule of law.”</span></p><p><span>But Mr. Hammond’s protest of Nakasone’s fireside chat was not the only pointed criticism of U.S. military activities at the conference. Micah Lee, an independent security researcher who previously collaborated with Horne through the transparency collective Distributed Denial of Secrets, gave a popular overview on Saturday afternoon of </span><a href="https://micahflee.com/we-are-currently-clean-on-opsec-the-signalgate-saga/" rel="">his research</a><span> into the second Trump administration’s first major scandal, widely known as ‘Signalgate.’</span></p><p><span>Lee received thunderous applause after emphasizing that, while U.S. Secretary of Defense Pete Hegseth deserved scrutiny for severe operational security failures, the </span><a href="https://www.thenation.com/article/world/signal-group-goldberg-bombing-yemen/" rel="">far more significant scandal</a><span> was the U.S. military’s intentional lethal bombing of an entire residential building in Yemen, which Lee concluded was a “war crime.”</span></p><p>Similar applause erupted in a later section of Lee’s talk, when he explained the catastrophic security vulnerabilities in the Israel-based fork of the private messaging app Signal which President Trump’s then-national security advisor was revealed to have been using in his official duties through a high-resolution photo captured by Reuters. “For context, Israel is committing a genocide in Gaza,” Lee noted. “Free Palestine,” added an audience member, on top of widespread applause.</p><p><em>Updated on August 11 with a link to Anduril’s sponsorship of the Maritime Hacking Village. Clarification was also added regarding Lorax Horne no longer being affiliated with Distributed Denial of Secrets.</em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
    </channel>
</rss>