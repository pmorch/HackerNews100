<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 02 Oct 2025 22:30:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Anti-aging breakthrough: Stem cells reverse signs of aging in monkeys (138 pts)]]></title>
            <link>https://www.nad.com/news/anti-aging-breakthrough-stem-cells-reverse-signs-of-aging-in-monkeys</link>
            <guid>45454460</guid>
            <pubDate>Thu, 02 Oct 2025 19:39:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nad.com/news/anti-aging-breakthrough-stem-cells-reverse-signs-of-aging-in-monkeys">https://www.nad.com/news/anti-aging-breakthrough-stem-cells-reverse-signs-of-aging-in-monkeys</a>, See on <a href="https://news.ycombinator.com/item?id=45454460">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Chinese scientists have genetically engineered stem cells capable of rejuvenating the health, including the cognition, of aged macaque</p><div>
<p>Key Points:&nbsp;</p>



<ul>
<li>“Super stem cells” improve the memory of monkeys while protecting against neurodegeneration.&nbsp;</li>



<li>The super stem cells prevent age-related bone loss while rejuvenating over 50% of the 61 tissues analyzed.&nbsp;</li>



<li>Treatment with stem cells reduces inflammation and senescent cells (cells that accumulate to promote aging).</li>
</ul>



<p>While small in number, our adult stem cells play a crucial role in regenerating our lost or damaged tissues, rebuilding our body cell by cell. However, with age, our bodies become riddled with inflammation, hardly providing an environment capable of keeping our stem cells healthy. Eventually, our stem cells lose their regenerative capacity, contributing to degenerative aging.&nbsp;</p>



<h2>Fox, O, Three&nbsp;</h2>



<p><em>Hydra</em> are a genus of immortal beings that live forever in freshwater environments like lakes and ponds. What scientists have called “<a href="https://onlinelibrary.wiley.com/doi/full/10.1111/j.1440-169X.2009.01143.x">nothing but an active stem cell community</a>,” <em>Hydra</em> can escape death by infinitely regenerating. Their stem cells can continuously proliferate and renew by producing FoxO, a protein they share with humans.&nbsp;</p>


<div>
<figure><img loading="lazy" decoding="async" width="808" height="476" src="https://cms.nad.com/wp-content/uploads/2025/09/Hydra.jpeg" alt="" srcset="https://cms.nad.com/wp-content/uploads/2025/09/Hydra.jpeg 808w, https://cms.nad.com/wp-content/uploads/2025/09/Hydra-300x177.jpeg 300w, https://cms.nad.com/wp-content/uploads/2025/09/Hydra-768x452.jpeg 768w" sizes="auto, (max-width: 808px) 100vw, 808px"><figcaption>(Image: <a href="https://www.aip.org/inside-science/how-hydra-regrow-their-heads">aip.org</a>) <strong>The Immortal Hydra.</strong></figcaption></figure></div>


<p>In humans, the FoxO protein, specifically the FoxO3 isoform, responds to cellular stress by binding to DNA and turning genes on and off. These genes are involved in numerous cellular processes that promote healthy aging and extended lifespan. This is why the FoxO3 protein’s corresponding gene, <em>FOXO3</em>, is considered a longevity gene.</p>





<h2>Experimenting with SRCs&nbsp;</h2>



<p>As FoxO3 assists cells in resisting stressful environments, such as inflamed tissue, Chinese Academy of Sciences researchers engineered human stem cells to have enhanced FoxO3 activity. As published in <a href="https://www.cell.com/cell/fulltext/S0092-8674%2825%2900571-9"><em>Cell</em></a>, these senescence-resistant stem cells (SRCs) were designed to exhibit greater resistance to age-related stress. To test this, cynomolgus monkeys, also known as crab-eating macaques, were first stratified into four groups based on age:&nbsp;</p>



<ul>
<li>A1: 3-5 years (approximately equivalent to 9-15 human years)&nbsp;</li>
</ul>







<ul>
<li>A2: 10-12 years (approximately equivalent to 30-36 human years)&nbsp;</li>
</ul>







<ul>
<li>A3: 16-19 years (approximately equivalent to 48-57 human years)&nbsp;</li>
</ul>







<ul>
<li>A4: 19-23 years (approximately equivalent to 57-69 human years)&nbsp;</li>
</ul>







<p>The oldest of the monkeys, the A4 group, were the focus of the study and were subdivided into three groups. One group was injected with saline (salt and water), another group with normal stem cells, and the third with SRCs. The aged monkeys were injected every two weeks for 44 weeks, approximately equivalent to the duration of three human years. On safety, there were no serious adverse events, such as immune system rejection or tumor growth.&nbsp;</p>


<div>
<figure><img loading="lazy" decoding="async" width="730" height="1024" src="https://cms.nad.com/wp-content/uploads/2025/09/Monkey_Groups-730x1024.jpg" alt="" srcset="https://cms.nad.com/wp-content/uploads/2025/09/Monkey_Groups-730x1024.jpg 730w, https://cms.nad.com/wp-content/uploads/2025/09/Monkey_Groups-214x300.jpg 214w, https://cms.nad.com/wp-content/uploads/2025/09/Monkey_Groups-768x1078.jpg 768w, https://cms.nad.com/wp-content/uploads/2025/09/Monkey_Groups-1095x1536.jpg 1095w, https://cms.nad.com/wp-content/uploads/2025/09/Monkey_Groups-1460x2048.jpg 1460w, https://cms.nad.com/wp-content/uploads/2025/09/Monkey_Groups-1568x2200.jpg 1568w, https://cms.nad.com/wp-content/uploads/2025/09/Monkey_Groups-scaled.jpg 1825w" sizes="auto, (max-width: 730px) 100vw, 730px"><figcaption>(<a href="https://www.cell.com/cell/fulltext/S0092-8674%2825%2900571-9">Lei et al., 2025</a>) <strong>Experimental Setup.</strong> Aged monkeys (A4) were injected with either saline (Vehicle), normal/wild-type stem cells (WTCs), or senescence-resistant stem cells (SRCs). The WTCs are human embryonic stem cells (hESCs) harboring two copies of normal/wild-type <em>FOXO3 </em>(<em>FOXO3</em><sup>+/+</sup>), while the SRCs are edited. The genetically edited <em>FOXO3</em> gene (<em>FOXO3</em><sup>2SA/2SA</sup>) produces a modified FoxO3 protein that stays in the nucleus of cells to increase the transcriptional activity of protective genes. &nbsp;</figcaption></figure></div>


<h2>SRCs Improve Cognition&nbsp;&nbsp;</h2>



<p>After 44 weeks of biweekly injections, a suite of biological indices was measured from the aged monkeys to assess whether SRCs slow down biological aging. One of these indices was memory retention. To assess memory, the researchers conducted a common experiment called the Wisconsin General Test Apparatus (WGTA).&nbsp;</p>



<p>For this experiment, each monkey was trained to retrieve food located <em>outside</em> of one of two identical boxes. During the test session, after each monkey was trained, food was placed next to one of the boxes to keep it hidden. Subsequently, a flap was placed in front of the monkey to block the boxes from view. Three seconds later, when the flap was reopened, each monkey had to remember which of the two boxes contained the food.&nbsp;</p>



<p>Remarkably, the monkeys injected with SRCs remembered the location of the food with higher accuracy than the monkeys injected with saline. Moreover, the monkeys injected with normal stem cells exhibited the same level of accuracy as the monkeys injected with saline. These findings suggest that SRCs, and not normal stem cells, improve the memory of aged monkeys.&nbsp;</p>


<div>
<figure><img loading="lazy" decoding="async" width="1024" height="330" src="https://cms.nad.com/wp-content/uploads/2025/09/Cognition-1024x330.jpg" alt="" srcset="https://cms.nad.com/wp-content/uploads/2025/09/Cognition-1024x330.jpg 1024w, https://cms.nad.com/wp-content/uploads/2025/09/Cognition-300x97.jpg 300w, https://cms.nad.com/wp-content/uploads/2025/09/Cognition-768x248.jpg 768w, https://cms.nad.com/wp-content/uploads/2025/09/Cognition-1536x496.jpg 1536w, https://cms.nad.com/wp-content/uploads/2025/09/Cognition-2048x661.jpg 2048w, https://cms.nad.com/wp-content/uploads/2025/09/Cognition-1568x506.jpg 1568w" sizes="auto, (max-width: 1024px) 100vw, 1024px"><figcaption>(<a href="https://www.cell.com/cell/fulltext/S0092-8674%2825%2900571-9">Lei et al., 2025</a>) <strong>SRCs Improve Memory.</strong> <em>Left:</em> The experimental sequence. <em>Right:</em> Aged monkeys (A4) injected with SRCs (green) exhibit significantly higher (*) accuracy on the WGTA than those injected with saline (black). The difference in accuracy between the saline-injected (black) and normal/wild-type stem cell-injected (blue) monkeys was not significant (ns).</figcaption></figure></div>


<p>Furthermore, MRI-based structural analysis showed that treatment with SRCs mitigated age-related brain shrinkage. MRI-based experiments also revealed that brain connectivity was restored to that of young (A1 group) monkeys. Namely, the structural connectivity between seven brain regions, including those important for working memory (prefrontal cortex), was rejuvenated with SRC treatment. Overall, these findings suggest that SRC injections improve memory by protecting against neurodegeneration.&nbsp;</p>



<h2>SRCs Rejuvenate Many Organs and Tissues</h2>



<p>In addition to the brain, the Academy researchers found that SRC treatment rejuvenated multiple organs and tissues. This is important because the rejuvenation of a given organ or tissue could lead to the reduced risk of its corresponding age-related chronic diseases. For example, the rejuvenating effects of SRCs on the brain could reduce the risk of neurodegenerative disorders like Alzheimer’s and Parkinson’s diseases.&nbsp;&nbsp;</p>



<p>One common age-related disease is osteoporosis, characterized by brittle and weak bones that make patients more prone to fractures and <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10338097/">deadly falls</a>. Using an X-ray imaging technique called micro-CT, the researchers found evidence for the reversal of age-related bone loss. Namely, while the aged monkeys treated with saline exhibited dental bone loss, the aged monkeys treated with SRCs had teeth more similar to those of young monkeys.&nbsp;</p>


<div>
<figure><img loading="lazy" decoding="async" width="1024" height="519" src="https://cms.nad.com/wp-content/uploads/2025/09/Bone-1024x519.jpg" alt="" srcset="https://cms.nad.com/wp-content/uploads/2025/09/Bone-1024x519.jpg 1024w, https://cms.nad.com/wp-content/uploads/2025/09/Bone-300x152.jpg 300w, https://cms.nad.com/wp-content/uploads/2025/09/Bone-768x390.jpg 768w, https://cms.nad.com/wp-content/uploads/2025/09/Bone-1536x779.jpg 1536w, https://cms.nad.com/wp-content/uploads/2025/09/Bone-2048x1039.jpg 2048w, https://cms.nad.com/wp-content/uploads/2025/09/Bone-1568x795.jpg 1568w" sizes="auto, (max-width: 1024px) 100vw, 1024px"><figcaption>(<a href="https://www.cell.com/cell/fulltext/S0092-8674%2825%2900571-9">Lei et al., 2025</a>) <strong>SRCs Improve Oral Bone Health.</strong> Compared to young monkeys (A1-Ctrl), aged monkeys (A4-Ctrl) exhibit significant bone loss. However, aged monkeys treated with wild-type stem cells (A4-WTC) show less bone loss, while aged monkeys treated with SRCs (A4-SRC) show even less bone loss.</figcaption></figure></div>


<p>To conduct a body-wide assessment, the researchers measured the up- and down-regulation of genes from 10 systems and 61 tissues. Elevations and reductions in gene activation reflect the function (or dysfunction) of cells, tissues, and organ systems. With that said, SRC treatment was shown to rejuvenate over 50% of the tissues examined, with maximal rejuvenation achieved in areas like the hippocampus (the memory consolidation center of the brain), fallopian tubes, and colon. In contrast, the regular stem cells rejuvenated about 30% of the tissues examined.</p>


<div>
<figure><img loading="lazy" decoding="async" width="1024" height="733" src="https://cms.nad.com/wp-content/uploads/2025/09/Genes-1024x733.jpg" alt="" srcset="https://cms.nad.com/wp-content/uploads/2025/09/Genes-1024x733.jpg 1024w, https://cms.nad.com/wp-content/uploads/2025/09/Genes-300x215.jpg 300w, https://cms.nad.com/wp-content/uploads/2025/09/Genes-768x550.jpg 768w, https://cms.nad.com/wp-content/uploads/2025/09/Genes-1536x1100.jpg 1536w, https://cms.nad.com/wp-content/uploads/2025/09/Genes-2048x1466.jpg 2048w, https://cms.nad.com/wp-content/uploads/2025/09/Genes-1568x1123.jpg 1568w" sizes="auto, (max-width: 1024px) 100vw, 1024px"><figcaption>(<a href="https://www.cell.com/cell/fulltext/S0092-8674%2825%2900571-9">Lei et al., 2025</a>) <strong>SRCs Rejuvenated Multiple Tissues.</strong> <em>Left:</em> The 10 systems from which the 61 tissues were examined are shown. Treatment with wild-type stem cells (WTC) rescued 31.15% of genes, while SRCs rescued 54.10% of genes altered by aging.</figcaption></figure></div>


<p>Confirming some of the rejuvenating effects inferred by the gene experiments, the researchers also observed structural changes to various organs and tissues from aged monkeys treated with SRCs. For example, the vascularity of the lung and heart was improved while the thickening of the aorta was reduced. Neurons had longer projections and fewer proteins associated with Alzheimer’s disease (e.g., beta-amyloid and phosphorylated-tau), and the kidney and brain showed less mineralization [abnormal mineral (usually calcium) deposits].&nbsp;&nbsp;</p>



<h2>SRCs Reduce Cellular Senescence and Inflammation</h2>



<p>Modern scientists have begun to unravel the underlying causes of aging by identifying commonalities between age-related diseases at the cellular level. Two of the most prominent purported underlying causes of aging are chronic inflammation and <a href="https://www.nad.com/news/what-are-senescent-cells-and-how-do-they-drive-aging">senescent cells</a>. With age, senescent cells accumulate throughout the body, promoting inflammation by secreting pro-inflammatory molecules.&nbsp;&nbsp;</p>



<p>Eliminating senescent cells, which can be achieved through genetic manipulation or compounds called senolytics, ameliorates age-related diseases and even extends the lifespan of model organisms. Now, the Academy researchers demonstrate that SRCs reduce senescent cells, measured using a blue dye called SA-β-Gal, in multiple organs, including the brain, heart, and lungs. Along those lines, SRC treatment also reduced markers of inflammation and other underlying causes of aging, like DNA damage.&nbsp;</p>


<div>
<figure><img loading="lazy" decoding="async" width="1024" height="626" src="https://cms.nad.com/wp-content/uploads/2025/09/Senescence-1-1024x626.jpg" alt="" srcset="https://cms.nad.com/wp-content/uploads/2025/09/Senescence-1-1024x626.jpg 1024w, https://cms.nad.com/wp-content/uploads/2025/09/Senescence-1-300x183.jpg 300w, https://cms.nad.com/wp-content/uploads/2025/09/Senescence-1-768x470.jpg 768w, https://cms.nad.com/wp-content/uploads/2025/09/Senescence-1-1536x939.jpg 1536w, https://cms.nad.com/wp-content/uploads/2025/09/Senescence-1-2048x1253.jpg 2048w, https://cms.nad.com/wp-content/uploads/2025/09/Senescence-1-1568x959.jpg 1568w" sizes="auto, (max-width: 1024px) 100vw, 1024px"><figcaption>(<a href="https://www.cell.com/cell/fulltext/S0092-8674%2825%2900571-9">Lei et al., 2025</a>) <strong>SRCs Eliminate Senescent Cells.</strong> Senescent cells are indicated by SA-β-Gal dye (light blue) and arrows. In the lung and brain, the number of senescent cells in aged monkeys treated with SRCs (green) was similar to that of young monkeys (pink). Moreover, compared to saline-treated aged monkeys (black), wild-type stem cell-treated aged monkeys (blue) exhibited less senescence in the lungs but not the brain, suggesting normal stem cells affect the lung but not the brain.</figcaption></figure></div>


<h2>Stem Cells Make Sense&nbsp;</h2>



<p>When it comes to combating degenerative aging, it makes sense that regenerative stem cells are a promising solution. In fact, one of the <a href="https://www.nad.com/news/hallmarks-of-aging-reversed-therapy">underlying causes of aging</a> is stem cell exhaustion, whereby stem cells lose their regenerative capacity. While normal stem cells have anti-aging effects, as shown by the Chinese Academy of Sciences researchers, they are not protected against stressors like age-related inflammation. This explains why SRCs provide enhanced regenerative capacity (they withstand the harsh microenvironments induced by aging and cellular senescence).&nbsp;&nbsp;</p>



<p>As no serious safety concerns were raised during the study, it would seem that SRCs are well tolerated. However, the long-term effects of the SRC treatment will need further evaluation. The primary concern with injecting stem cells into the bloodstream is that they can trigger the spread of cancer almost anywhere in the body. Nevertheless, the SRCs possess tumor suppression properties, suggesting they may not induce tumor growth. If this ends up being true, we may soon see SRCs being tested in humans.&nbsp;</p>
</div><div><p>Source</p><p>Lei, J., Xin, Z., Liu, N., Ning, T., Jing, Y., Qiao, Y., He, Z., Jiang, M., Yang, Y., Zhang, Z., Zhao, L., Li, J., Lv, D., Yan, Y., Zhang, H., Xiao, L., Zhang, B., Huang, H., Sun, S., Zheng, F., … Liu, G. H. (2025). Senescence-resistant human mesenchymal progenitor cells counter aging in primates. Cell, 188(18), 5039–5061.e35. https://doi.org/10.1016/j.cell.2025.05.021</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI's H1 2025: $4.3B in income, $13.5B in loss (181 pts)]]></title>
            <link>https://www.techinasia.com/news/openais-revenue-rises-16-to-4-3b-in-h1-2025</link>
            <guid>45453586</guid>
            <pubDate>Thu, 02 Oct 2025 18:37:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techinasia.com/news/openais-revenue-rises-16-to-4-3b-in-h1-2025">https://www.techinasia.com/news/openais-revenue-rises-16-to-4-3b-in-h1-2025</a>, See on <a href="https://news.ycombinator.com/item?id=45453586">Hacker News</a></p>
Couldn't get https://www.techinasia.com/news/openais-revenue-rises-16-to-4-3b-in-h1-2025: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Gemini 3.0 Pro – early tests (140 pts)]]></title>
            <link>https://twitter.com/chetaslua/status/1973694615518880236</link>
            <guid>45453448</guid>
            <pubDate>Thu, 02 Oct 2025 18:26:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/chetaslua/status/1973694615518880236">https://twitter.com/chetaslua/status/1973694615518880236</a>, See on <a href="https://news.ycombinator.com/item?id=45453448">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Babel is why I keep blogging with Emacs (139 pts)]]></title>
            <link>https://entropicthoughts.com/why-stick-to-emacs-blog</link>
            <guid>45453222</guid>
            <pubDate>Thu, 02 Oct 2025 18:06:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://entropicthoughts.com/why-stick-to-emacs-blog">https://entropicthoughts.com/why-stick-to-emacs-blog</a>, See on <a href="https://news.ycombinator.com/item?id=45453222">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>
Every time I look at someone’s simple static site generation setup for their
blog, I feel a pang of envy. I’m sure I could make a decent blogging engine in
2,000 lines of code, and it would be something I’d understand, be proud over,
able to extend, and willing to share with others.
</p>

<p>
Instead, I write these articles in Org mode, and use mostly the standard Org
publishing functions to export them to <abbr>html</abbr>. This is <a href="https://entropicthoughts.com/long-hiatus-emacs-upgrades.html">sometimes brittle</a>, but
most annoyingly, I don’t understand it. I have been asked for details on how my
publishing flow works, but the truth is I have no idea what happens when I run
the <code>org-publish-current-file</code> command.
</p>

<p>
I could find out by tracing the evaluation of the Lisp code that runs on export,
but I won’t, because just the <abbr>html</abbr> exporting code (<code>ox-html.el</code>) is 5,000
lines of complexity. The general exporting framework (<code>ox-publish.el</code> and
<code>ox.el</code>) is 8,000 lines. The framework depends on Org parsing code
(<code>org-element.el</code>) which is at least another 9,000 lines. This is over 20,000
lines of complexity I’d need to contend with.
</p>

<p>
It might seem like a no-brainer to just write that 2,000 line custom static
generator and use that instead.
</p>

<hr>

<p>
Except one thing: Babel.
</p>

<p>
Any lightweight markup format (like Markdown or ReStructuredText or whatever)
allows for embedding code blocks, but Org, through Babel, can <i>run</i> that code on
export, and then display the output in the published document, <i>even when the
output is a table or an image</i>. It supports sessions that lets code reuse
definitions from earlier code blocks. It allows for injecting variables from the
markup into the code, and vice versa. As a bonus, Org doesn’t require a
JavaScript syntax highlighter, because it generates inline styles in the source
code.
</p>

<p>
It does this for a large number of languages, although I mainly use it with R
for drawing plots. Being able to do this is incredibly convenient, because it
makes it trivial to <a href="https://entropicthoughts.com/intention-to-treat-experiments.html">draft data, illustrations, and text at the same time</a>,
adjusting both until the article coheres. Having tried it, I cannot see myself
living without it.
</p>

<hr>

<p>
A simple 2,000 line blogging engine would be a fun weekend project. Mirroring
the features of Babel I use would turn it into a multi-month endeavour for
someone with limited time such as myself. Not going to happen, and I will
continue to beat myself up for overcomplicating my publishing workflow.
</p>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Email immutability matters more in a world with AI (134 pts)]]></title>
            <link>https://www.fastmail.com/blog/not-written-with-ai/</link>
            <guid>45453135</guid>
            <pubDate>Thu, 02 Oct 2025 18:00:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fastmail.com/blog/not-written-with-ai/">https://www.fastmail.com/blog/not-written-with-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=45453135">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pagefind-body="" data-cms-edit="content"> <p>It’s all the rage right now. Everyone is scrambling to put AI into their products. The uncanny valley is shrinking enough that it’s hard to see how much AI was used to write something.</p> <p>This isn’t entirely new, auto-complete on my phone already suggests the most likely word when I’m typing. AI writing tools are an extension of this, but they’re also much more capable.</p> <h2 id="your-electronic-memory" tabindex="-1">Your electronic memory</h2> <p>I stand by one of the most important truths about email. It’s not only the largest and most diverse social network, <a href="https://www.fastmail.com/blog/email-is-your-electronic-memory/" target="_blank" rel="noopener">email is your electronic memory</a>.</p> <p>In the novel 1984, the “Ministry of Truth” has a whole massive department which rewrites history. In a world where there’s enough AI capability to process the entire web and rewrite every page to remove something, the cost of “changing history” is much reduced, so we can expect more of it.</p> <p>This is where the immutability of email really shines. An email is your copy, and the sender can’t revise it later. This is frustrating when you’ve sent the wrong thing and have to send a separate correction later, but in the long term it’s insanely valuable.</p> <p>It makes a huge difference to be able to go back and double-check your memory against an email you saw years ago and know that if they disagree, the email is correct. This is already not the case with web pages — they change, and it’s only becoming worse.</p> <h2 id="adapting-to-a-changing-world" tabindex="-1">Adapting to a changing world</h2> <p>My son is studying at University now, and he’s one of a few students in his class who refuses to use AI to write his assignments. As he said “what’s the point of paying to be here if I’m not going to build the knowledge and skills for myself, and come out knowing how to do the thing” (near enough… I didn’t write the exact words down in an email, so I’m going off my own fallible memory!) I am so proud of him for having that attitude.</p> <p>I’m also pleased to see that Fastmail’s staff, and many of our customers, are wary of AI tools.</p> <p>But they are that, tools. The world is changing, and we need to adapt and understand it.</p> <h2 id="our-service-your-data" tabindex="-1">Our service, your data</h2> <p>For our service, we want you to be able to do what you desire with your own email, calendars, and contacts. We will continue to build tools and integrations to make that easier.</p> <p>You are welcome to operate your Fastmail account with AI tools, so long as that usage doesn’t otherwise breach our <a href="https://www.fastmail.com/policies/terms-of-service/">Terms of Service</a>, or degrade the performance of our systems for other customers.</p> <h2 id="our-staff-your-privacy" tabindex="-1">Our staff, your privacy</h2> <p>For our staff, we encourage understanding the tools that exist in the world, and how to use them safely. Our policy makes it clear that any use of tools, including tools with AI in them, must follow clear privacy-preserving principles:</p> <ul> <li>Data Protection: All data protection, confidentiality, and privacy policies must be followed (our vendors for things like anti-abuse and support are moving towards using AI for translation, categorization, abuse detection – and we are ensuring that their policies continue to provide protection for our customers)</li> <li>Accountability for work: Any AI generated writing or code must be reviewed and understood by a human being, and go through our regular second-set-of-eyes processes before being used</li> <li>Bias awareness: Actively look for biases or hallucinations in AI output</li> <li>Human authority: Always have a path for appeal to a human from any decision that is made by automated tools</li> </ul> <h2 id="the-future" tabindex="-1">The future</h2> <p>Who knows what the future will bring, but we continue to be guided by the principles that we first <a href="https://www.fastmail.com/blog/fastmails-values/" target="_blank" rel="noopener">publicly articulated in 2016</a> and have held even longer. The data is yours, and we will be good stewards and good internet citizens, helping enable you to use your data in the ways you choose.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Watch MLB games from the comfort of your own terminal (164 pts)]]></title>
            <link>https://github.com/paaatrick/playball</link>
            <guid>45451577</guid>
            <pubDate>Thu, 02 Oct 2025 16:09:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/paaatrick/playball">https://github.com/paaatrick/playball</a>, See on <a href="https://news.ycombinator.com/item?id=45451577">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Playball!</h2><a id="user-content-playball" aria-label="Permalink: Playball!" href="#playball"></a></p>
<p dir="auto">Watch MLB games from the comfort of your own terminal</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/paaatrick/playball/blob/main/demo.gif"><img src="https://github.com/paaatrick/playball/raw/main/demo.gif" alt="screenshot" data-animated-image=""></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why?</h3><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<p dir="auto"><a href="http://www.mlb.com/mlb/gameday/#" rel="nofollow">MLB Gameday</a> and <a href="http://mlb.tv/" rel="nofollow">MLB.tv</a> are
great, but sometimes you want to keep an eye on a game a bit more discreetly.
<code>playball</code> puts the game in a terminal window.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Quick Start</h3><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto">Just want to try it out?</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Install</h3><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto">Ready for the big leagues? Install the package globally</p>
<div data-snippet-clipboard-copy-content="$ npm install -g playball"><pre><code>$ npm install -g playball
</code></pre></div>
<p dir="auto">Then run it</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Docker</h3><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<div data-snippet-clipboard-copy-content="$ docker build -t playball .
$ docker run -it --rm --name playball playball:latest"><pre><code>$ docker build -t playball .
$ docker run -it --rm --name playball playball:latest
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Keys</h3><a id="user-content-keys" aria-label="Permalink: Keys" href="#keys"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Global</h4><a id="user-content-global" aria-label="Permalink: Global" href="#global"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>key</th>
<th>action</th>
</tr>
</thead>
<tbody>
<tr>
<td><kbd>q</kbd></td>
<td>quit</td>
</tr>
<tr>
<td><kbd>c</kbd></td>
<td>go to schedule view</td>
</tr>
<tr>
<td><kbd>s</kbd></td>
<td>go to standings view</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Schedule View</h4><a id="user-content-schedule-view" aria-label="Permalink: Schedule View" href="#schedule-view"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>key</th>
<th>action</th>
</tr>
</thead>
<tbody>
<tr>
<td><kbd>↓</kbd>/<kbd>j</kbd>, <kbd>↑</kbd>/<kbd>k</kbd>, <kbd>←</kbd>/<kbd>h</kbd>, <kbd>→</kbd>/<kbd>l</kbd></td>
<td>change highlighted game</td>
</tr>
<tr>
<td><kbd>enter</kbd></td>
<td>view highlighted game</td>
</tr>
<tr>
<td><kbd>p</kbd></td>
<td>show previous day's schedule/results</td>
</tr>
<tr>
<td><kbd>n</kbd></td>
<td>show next day's schedule</td>
</tr>
<tr>
<td><kbd>t</kbd></td>
<td>return to today's schedule</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Game View</h4><a id="user-content-game-view" aria-label="Permalink: Game View" href="#game-view"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>key</th>
<th>action</th>
</tr>
</thead>
<tbody>
<tr>
<td><kbd>↓</kbd>/<kbd>j</kbd>, <kbd>↑</kbd>/<kbd>k</kbd></td>
<td>scroll list of all plays</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configuration</h3><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">Playball can be configured using the <code>config</code> subcommand. To list the current configuration values run the subcommand with no additional arguments:</p>

<p dir="auto">You should see output similar to:</p>
<div data-snippet-clipboard-copy-content="color.ball = green
color.favorite-star = yellow
color.in-play-no-out = blue
color.in-play-out = white
color.in-play-runs-bg = white
color.in-play-runs-fg = black
color.on-base = yellow
color.other-event = white
color.out = red
color.strike = red
color.strike-out = red
color.walk = green
favorites = "><pre><code>color.ball = green
color.favorite-star = yellow
color.in-play-no-out = blue
color.in-play-out = white
color.in-play-runs-bg = white
color.in-play-runs-fg = black
color.on-base = yellow
color.other-event = white
color.out = red
color.strike = red
color.strike-out = red
color.walk = green
favorites = 
</code></pre></div>
<p dir="auto">To get the value of a single setting pass the key as an additional argument:</p>
<div dir="auto" data-snippet-clipboard-copy-content="playball config color.strike"><pre>playball config color.strike</pre></div>
<p dir="auto">To change a setting pass the key and value as arguments:</p>
<div dir="auto" data-snippet-clipboard-copy-content="playball config color.strike blue"><pre>playball config color.strike blue</pre></div>
<p dir="auto">To revert a setting to its default value provide the key and the <code>--unset</code> flag:</p>
<div dir="auto" data-snippet-clipboard-copy-content="playball config color.strike --unset"><pre>playball config color.strike --unset</pre></div>
<p dir="auto">This table summarizes the available settings:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>key</th>
<th>description</th>
<th>default</th>
<th>allowed values</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>color.ball</code></td>
<td>Color of dots representing balls in top row of game view</td>
<td>green</td>
<td>One of the following: <code>black</code>, <code>red</code>, <code>green</code>, <code>yellow</code>, <code>blue</code>, <code>magenta</code>, <code>cyan</code>, <code>white</code>, <code>grey</code>. Any of those colors may be prefixed by <code>bright-</code> or <code>light-</code> (for example <code>bright-green</code>). The exact color used will depend on your terminal settings. The value <code>default</code> may be used to specify the default text color for your terminal. Finally hex colors (e.g <code>#FFA500</code>) can be specified. If your terminal does not support true color, the closest supported color may be used.</td>
</tr>
<tr>
<td><code>color.favorite-star</code></td>
<td>Color of star indiciating favorite team in schedule and standing views</td>
<td>yellow</td>
<td><em>See above</em></td>
</tr>
<tr>
<td><code>color.in-play-no-out</code></td>
<td>Color of result where ball was put in play and no out was made (single, double, etc) in list of plays in game view</td>
<td>blue</td>
<td><em>See above</em></td>
</tr>
<tr>
<td><code>color.in-play-out</code></td>
<td>Color of result where ball was put in play and an out was made (flyout, fielder's choice, etc) in list of plays in game view</td>
<td>white</td>
<td><em>See above</em></td>
</tr>
<tr>
<td><code>color.in-play-runs-bg</code></td>
<td>Background color for score update in list of plays in game view</td>
<td>white</td>
<td><em>See above</em></td>
</tr>
<tr>
<td><code>color.in-play-runs-fg</code></td>
<td>Foreground color for score update in list of plays in game view</td>
<td>black</td>
<td><em>See above</em></td>
</tr>
<tr>
<td><code>color.on-base</code></td>
<td>Color of diamonds representing runners on base in top row of game view</td>
<td>yellow</td>
<td><em>See above</em></td>
</tr>
<tr>
<td><code>color.other-event</code></td>
<td>Color of other events (mound visit, injury delay, etc) in list of plays in game view</td>
<td>white</td>
<td><em>See above</em></td>
</tr>
<tr>
<td><code>color.out</code></td>
<td>Color of dots representing outs in top row of game view</td>
<td>red</td>
<td><em>See above</em></td>
</tr>
<tr>
<td><code>color.strike</code></td>
<td>Color of dots representing strikes in top row of game view</td>
<td>red</td>
<td><em>See above</em></td>
</tr>
<tr>
<td><code>color.strike-out</code></td>
<td>Color of result where play ends on a strike (strike out) in list of plays in game view</td>
<td>red</td>
<td><em>See above</em></td>
</tr>
<tr>
<td><code>color.walk</code></td>
<td>Color of result where play ends on a ball (walk, hit by pitch) in list of plays in game view</td>
<td>green</td>
<td><em>See above</em></td>
</tr>
<tr>
<td><code>favorites</code></td>
<td>Teams to highlight in schedule and standings views</td>
<td></td>
<td>Any one of the following: <code>ATL</code>, <code>AZ</code>, <code>BAL</code>, <code>BOS</code>, <code>CHC</code>, <code>CIN</code>, <code>CLE</code>, <code>COL</code>, <code>CWS</code>, <code>DET</code>, <code>HOU</code>, <code>KC</code>, <code>LAA</code>, <code>LAD</code>, <code>MIA</code>, <code>MIL</code>, <code>MIN</code>, <code>NYM</code>, <code>NYY</code>, <code>OAK</code>, <code>PHI</code>, <code>PIT</code>, <code>SD</code>, <code>SEA</code>, <code>SF</code>, <code>STL</code>, <code>TB</code>, <code>TEX</code>, <code>TOR</code>, <code>WSH</code>. Or a comma-separated list of multiple (e.g. <code>SEA,MIL</code>)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Development</h3><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/paaatrick/playball.git
cd playball
npm install
npm start"><pre><code>git clone https://github.com/paaatrick/playball.git
cd playball
npm install
npm start
</code></pre></div>
<p dir="auto">Contributions are welcome!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Signal Protocol and Post-Quantum Ratchets (367 pts)]]></title>
            <link>https://signal.org/blog/spqr/</link>
            <guid>45451527</guid>
            <pubDate>Thu, 02 Oct 2025 16:06:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://signal.org/blog/spqr/">https://signal.org/blog/spqr/</a>, See on <a href="https://news.ycombinator.com/item?id=45451527">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img src="https://signal.org/blog/images/spqr-header.png" alt="A stylized Signal logo inscribed with mathematical symbols representing a qubit."></p><p>We are excited to announce a significant advancement in the security of the Signal Protocol: the introduction of the Sparse Post Quantum Ratchet (SPQR). This new ratchet enhances the Signal Protocol’s resilience against future quantum computing threats while maintaining our existing security guarantees of forward secrecy and post-compromise security.</p><p>The Signal Protocol is a set of cryptographic specifications that provides end-to-end encryption for private communications exchanged daily by billions of people around the world. After its publication in 2013, the open source Signal Protocol was adopted not only by the Signal application but also by other major messaging products. Technical information on the Signal Protocol can be found in the specifications section of our <a href="https://signal.org/docs/">docs</a> site.</p><p>In a <a href="https://signal.org/blog/pqxdh/">previous blog post</a>, we announced the first step towards advancing quantum resistance for the Signal Protocol: an upgrade called PQXDH that incorporates quantum-resistent cryptographic secrets when chat sessions are established in order to protect against <a href="https://en.wikipedia.org/wiki/Harvest_now%2C_decrypt_later">harvest-now-decrypt-later</a> attacks that could allow current chat sessions to become compromised if a sufficiently powerful quantum computer is developed in the future. However, the Signal Protocol isn’t just about protecting cryptographic material and keys at the beginning of a new chat or phone call; it’s also designed to minimize damage and heal from compromise as that conversation continues.</p><p>We refer to these security goals as Forward Secrecy (FS) and Post-Compromise Security (PCS). FS and PCS can be considered mirrors of each other: FS protects past messages against future compromise, while PCS protects future messages from past compromise. Today, we are happy to announce the next step in advancing quantum resistance for the Signal Protocol: an additional regularly advancing post-quantum ratchet called the Sparse Post Quantum Ratchet, or SPQR. On its own, SPQR provides secure messaging that provably achieves these FS and PCS guarantees in a quantum safe manner. We mix the output of this new ratcheting protocol with Signal’s existing Double Ratchet, in a combination we refer to as the Triple Ratchet.</p><p>What does this mean for you as a Signal user? First, when it comes to your experience using the app, nothing changes. Second, because of how we’re rolling this out and mixing it in with our existing encryption, eventually all of your conversations will move to this new protocol without you needing to take any action. Third, and most importantly, this protects your communications both now and in the event that cryptographically relevant quantum computers eventually become a reality, and it allows us to maintain our existing security guarantees of forward secrecy and post-compromise security as we proactively prepare for that new world.</p><h2 id="the-current-state-of-the-signal-protocol">The Current State of the Signal Protocol</h2><p>The original Signal ratchet uses hash functions for FS and a set of elliptic-curve Diffie Hellman (ECDH) secret exchanges for PCS. The hash functions are quantum safe, but elliptic-curve cryptography is not. An example is in order: our favorite users, Alice and Bob, establish a long-term connection and chat over it regularly. During that session’s lifetime, Alice and Bob regularly agree on new ECDH secrets and use them to “ratchet” their session. Mean ol’ Mallory records the entire (encrypted) communication, and really wants to know what Alice and Bob are talking about.</p><p>The concept of a “ratchet” is crucial to our current non-quantum FS/PCS protection. In the physical world, a ratchet is a mechanism that allows a gear to rotate forward, but disallows rotation backwards. In the Signal Protocol, it takes on a similar role. When Alice and Bob “ratchet” their session, they replace the set of keys they were using prior with a new set based on both the older secrets and a new one they agree upon. Given access to those new secrets, though, there’s no (non-quantum) way to compute the older secrets. By being “one-way”, this ratcheting mechanism provides FS.</p><p>The ECDH mechanism allows Alice and Bob to generate new, small (32 bytes) data blobs and attach them to every message. Whenever each party receives a message from the other, they can locally (and relatively cheaply) use this data blob to agree on a new shared secret, then use that secret to ratchet their side of the protocol. Crucially, ECDH also allows Alice and Bob to both agree on the new secret without sending that secret itself over their session, and in fact without sending anything over the session that Mallory could use to determine it. <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">This description of Diffie-Hellman key exchange</a> provides more details on the concepts of such a key exchange, and <a href="https://en.wikipedia.org/wiki/Elliptic-curve_Diffie%E2%80%93Hellman">this description of ECDH</a> provides specific details on the variant used by the current Signal protocol.</p><p>Sometime midway through the lifetime of Alice and Bob’s session, Mallory successfully breaches the defences of both Alice and Bob, gaining access to all of the (current) secrets used for their session at the time of request. Alice and Bob should have the benefits of Forward Secrecy - they’ve ratcheted sometime recently before the compromise, so no messages earlier than their last ratchet are accessible to Mallory, since ratcheting isn’t reversible. They also retain the benefits of Post-Compromise Security. Their ratcheting after Mallory’s secret access agrees upon new keys that can’t be gleaned just from the captured data they pass between each other, re-securing the session.</p><p>Should Mallory have access to a quantum computer, though, things aren’t so simple. Because elliptic curve cryptography is not quantum resistant, it’s possible that Mallory could glean access to the secret that Alice and Bob agreed upon, just by looking at the communication between them. Given this, Alice and Bob’s session will never “heal”; Mallory’s access to their network traffic from this point forward will allow her to decrypt all future communications.</p><h2 id="mixing-in-quantum-security">Mixing In Quantum Security</h2><p>In order to make our security guarantees stand up to quantum attacks, we need to mix in secrets generated from quantum secure algorithms. In PQXDH, we did this by performing an additional round of key agreement during the session-initiating handshake, then mixing the resulting shared secret into the initial secret material used to create Signal sessions. To handle FS and PCS, we need to do continuous key agreement, where over the lifetime of a session we keep generating new shared secrets and mixing those keys into our encryption keys.</p><p>Luckily there is a tool designed exactly for this purpose: the quantum-secure Key-Encapsulation Mechanism (KEM). KEMs share similar behavior to the Diffie-Hellman mechanisms we described earlier, where two clients provide each other with information, eventually deciding on a shared secret, without anyone who intercepts their communications being able to access that secret. However, there is one important distinction for KEMs - they require ordered, asymmetric messages to be passed between their clients. In ECDH, both clients send the other some public parameters, and both combine these parameters with their locally held secrets and come up with an identical shared secret. In the <a href="https://csrc.nist.gov/pubs/fips/203/final">standardized</a> ML-KEM key-encapsulation mechanism, though, the initiating client generates a pair of encapsulation key (EK) and decapsulation key (DK) (analogous to a public and private key respectively) and sends the EK. The receiving client receives it, generates a secret, and wraps it into a ciphertext (CT) with that key. The initiating client receives that CT and decapsulates with its previously generated DK. In the end, both clients have access to the new, shared secret, just through slightly different means.</p><p>Wanting to integrate this quantum-secure key sharing into Signal, we could take a simple, naive approach for each session. When Alice initiates a session with Bob,</p><ul><li>Alice, with every message she sends, sends an EK</li><li>Bob, with every message he receives, generates a secret and a CT, and sends the CT back</li><li>Alice, on receiving a CT, extracts the secret with her DK and mixes it in</li></ul><p>This initially simple-looking approach, though, quickly runs into a number of issues we’ll need to address to make our protocol actually robust. First, encapsulation keys and CTs are large - over 1000 bytes each for ML-KEM 768, compared to the 32 bytes required for ECDH. Second, while this protocol works well when both clients are online, what happens when a client is offline? Or a message is dropped or reordered? Or Alice wants to send 10 messages before Bob wants to send one?</p><p>Some of these problems have well-understood solutions, but others have trade-offs that may shine in certain circumstances but fall short in others. Let’s dive in and come to some conclusions.</p><h2 id="who-wants-what-when">Who Wants What When</h2><p>How does Alice decide what to send based on what Bob needs next, and vice versa? If Bob hasn’t received an EK yet, she shouldn’t send the next one. What does Bob send when he hasn’t yet received an EK from Alice, or when he has, but he’s already responded to it? This is a common problem when remote parties send messages to communicate, so there’s a good, well-understood solution: a state machine. Alice and Bob both keep track of “what state am I in”, and base their decisions on that. When sending or receiving a message, they might also change their state. For example:</p><ul><li>Alice wants to send a message, but she’s in a StartingA state, so she doesn’t have an EK. So, she generates an EK/DK pair, stores them locally, and transitions to the SendEK state</li><li>Alice wants to send a message and is in the SendEK state. She sends the EK along with the message</li><li>Alice wants to send another message, but she’s still in the SendEK state. So, she sends the EK with the new message as well</li><li>Bob receives the message with the EK. He generates a secret and uses the EK to create a CT. He transitions to the SendingCT state.</li><li>Bob wants to send a message and he’s in the SendingCT state. He sends the CT along with the message</li><li>Bob wants to send a message and he’s in the SendingCT state. He sends the CT along with the message</li><li>… etc …</li></ul><p>By crafting a set of states and transitions, both sides can coordinate what’s sent. Note, though, that even in this simple case, we see problems. For example, we’re sending our (large) EK and (large) CT multiple times.</p><p><img src="https://signal.org/blog/images/spqr-3.png" alt="SPQR State Machine Diagram"></p><h2 id="say-or-send-less">Say (or Send) Less</h2><p>We’ve already mentioned that the size of the data we’re sending has increased pretty drastically, from 32 bytes to over 1000 per message. But bandwidth is expensive, especially on consumer devices like client phones, that may be anywhere in the world and have extremely varied costs for sending bytes over the wire. So let’s discuss strategies for conserving that bandwidth.</p><p>First, the simplest approach - don’t send a new key with every message. Just, for example, send with every 50 messages, or once a week, or every 50 messages unless you haven’t sent a key in a week, or any other combination of options. All of these approaches tend to work pretty well in online cases, where both sides of a session are communicating in real-time with no message loss. But in cases where one side is offline or loss can occur, they can be problematic. Consider the case of “send a key if you haven’t sent one in a week”. If Bob has been offline for 2 weeks, what does Alice do when she wants to send a message? What happens if we can lose messages, and we lose the one in fifty that contains a new key? Or, what happens if there’s an attacker in the middle that wants to stop us from generating new secrets, and can look for messages that are 1000 bytes larger than the others and drop them, only allowing keyless messages through?</p><p>Another method is to chunk up a message. Want to send 1000 bytes? Send 10 chunks of 100 bytes each. Already sent 10 chunks? Resend the first chunk, then the second, etc. This smooths out the total number of bytes sent, keeping individual message sizes small and uniform. And often, loss of messages is handled. If chunk 1 was lost, just wait for it to be resent. But it runs into an issue with message loss - if chunk 99 was lost, the receiver has to wait for all of chunks 1-98 to be resent before it receives the chunk it missed. More importantly, if a malicious middleman wants to stop keys from being decided upon, they could always drop chunk 3, never allowing the full key to pass between the two parties.</p><p>We can get around all of these issues using a concept called erasure codes. Erasure codes work by breaking up a larger message into smaller chunks, then sending those along. Let’s consider our 1000 byte message being sent as 100 byte chunks again. After chunk #10 has been sent, the entirety of the original 1000 byte message has been sent along in cleartext. But rather than just send the first chunk over again, erasure codes build up a new chunk #11, and #12, etc. And they build them in such a way that, once the recipient receives any 10 chunks in any order, they’ll be able to reconstruct the original 1000 byte message.</p><p>When we put this concept of erasure code chunks together with our previous state machine, it gives us a way to send large blocks of data in small chunks, while handling messages that are dropped. Crucially, this includes messages dropped by a malicious middleman: since any N chunks can be used to recreate the original message, a bad actor would need to drop all messages after #N-1 to disallow the data to go through, forcing them into a complete (and highly noticeable) denial of service. Now, if Alice wants to send an EK to Bob, Alice will:</p><ol><li>Transition from the StartingA state to the SendingEK state, by generating a new EK and chunking it</li><li>While in the SendingEK state, send a new chunk of the EK along with any messages she sends</li><li>When she receives confirmation that the recipient has received the EK (when she receives a chunk of CT), transition to the ReceivingCT state</li></ol><p>On Bob’s side, he will:</p><ol><li>Transition from the StartingB state to the ReceivingEK state when he receives its first EK chunk</li><li>Keep receiving EK chunks until he has enough to reconstruct the EK</li><li>At that point, reconstruct the EK, generate the CT, chunk the CT, and transition to the SendingCT state</li><li>From this point on, he will send a chunk of the CT with every message</li></ol><p>One interesting way of looking at this protocol so far is to consider the messages flowing from Alice to Bob as potential capacity for sending data associated with post-quantum ratcheting: each message that we send, we could also send additional data like a chunk of EK or of the CT. If we look at Bob’s side, above, we notice that sometimes he’s using that capacity (IE: in step 4 when he’s sending CT chunks) and sometimes he’s not (if he sends a message to Alice during step 2, he has no additional data to send). This capacity is pretty limited, so using more of it gives us the potential to speed up our protocol and agree on new secrets more frequently.</p><p><img src="https://signal.org/blog/images/spqr-1.png" alt="SPQR Flow Diagram illustrating how bandwidth consumption is optimized"></p><h2 id="a-meditation-on-how-faster-isnt-always-better">A Meditation On How Faster Isn’t Always Better</h2><p>We want to generate shared secrets, then use them to secure messages. So, does that mean that we want to generate shared secrets as fast as possible? Let’s introduce a new term: an epoch. Alice and Bob start their sessions in epoch 0, sending the EKs for epoch 1 (EK#1) and associated ciphertext (CT#1) to each other. Once that process completes, they have a new shared secret they use to enter epoch 1, after which all newly sent messages are protected by the new secret. Each time they generate a new shared secret, they use it to enter a new epoch. Surely, every time we enter a new epoch with a new shared secret, we protect messages before that secret (FS) and after that secret (PCS), so faster generation is better? It seems simple, but there’s an interesting complexity here that deserves attention.</p><p>First, let’s discuss how to do things faster. Right now, there’s a lot of capacity we’re not using: Bob sends nothing while Alice sends an EK, and Alice sends nothing while Bob sends a CT. Speeding this up isn’t actually that hard. Let’s change things so that Alice sends EK#1, and once Bob acknowledges its receipt, Alice immediately generates and sends EK#2. And once she notices Bob has received that, she generates and sends EK#3, etc. Whenever Alice sends a new message, she always has data to send along with it (new EK chunks), so she’s using its full capacity. Bob doesn’t always have a new CT to send, but he is receiving EKs as fast as Alice can send them, so he often has a new CT to send along.</p><p>But now let’s consider what happens when an attacker gains access to Alice. Let’s say that Alice has sent EK#1 and EK#2 to Bob, and she’s in the process of sending EK#3. Bob has acknowledged receipt of EK#1 and EK#2, but he’s still in the process of sending CT#1, since in this case Bob sends fewer messages to Alice than vice versa. Because Alice has already generated 3 EKs she hasn’t used, Alice needs to keep the associated DK#1, DK#2, and DK#3 around. So, if at this point someone maliciously gains control of Alice’s device, they gain access to both the secrets associated with the current epoch (here, epoch 0) and to the DKs necessary to reconstruct the secrets to other epochs (here, epochs 1, 2, and 3) using only the over-the-wire CT that Bob has yet to send. This is a big problem: by generating secrets early, we’ve actually made the in-progress epochs and any messages that will be sent within them less secure against this single-point-in-time breach.</p><p>To test this out, we at Signal built a number of different state machines, each sending different sets of data either in parallel or serially. We then ran these state machines in numerous simulations, varying things like the ratio of messages sent by Alice vs Bob, the amount of data loss or reordering, etc. And while running these simulations, we tracked what epochs’ secrets were exposed at any point in time, assuming an attacker were to breach either Alice’s or Bob’s secret store. The results showed that, in general, while simulations that handled multiple epochs’ secrets in parallel (IE: by sending EK#2 before receipt of CT#1) did generate new epochs more quickly, they actually made more messages vulnerable to a single breach.</p><h2 id="but-lets-still-be-efficient">But Let’s Still Be Efficient</h2><p>This still leaves us with a problem, though: the capacity present in messages we send in either direction is still a precious resource, and we want to use it as efficiently as possible. And our simple approach of Alice’s “send EK, receive CT, repeat” and Bob’s “receive EK, send CT, repeat” leaves lots of time where Alice and Bob have nothing to send, should that capacity be available.</p><p>To improve our use of our sending capacity, we decided to take a harder look into the ML-KEM algorithm we’re using to share secrets, to see if there was room to improve. Let’s break things down more and share some actual specifics on the ML-KEM algorithm.</p><ol><li>Alice generates an EK of 1184 bytes to send to Bob, and an associated DK</li><li>Bob receives the EK</li><li>Bob samples a new shared secret (32 bytes), which he encrypts with EK into a CT of 1088 bytes to send to Alice</li><li>Alice receives the CT, uses the DK to decrypt it, and now also has access to the 32 byte shared secret</li></ol><p>Diving in further, we can break out step #3 into some sub-steps</p><ol><li>Alice generates an EK of 1184 bytes to send to Bob, and an associated DK</li><li>Bob receives the EK</li><li>Bob samples a new shared secret (32 bytes), which he encrypts with EK into a CT of 1088 bytes to send to Alice<sup id="fnref:1"><a href="#fn:1" rel="footnote" role="doc-noteref">1</a></sup><ol type="a"><li> Bob creates a new shared secret S and sampled randomness R by sampling entropy and combining it with a hash of EK</li><li>Bob hashes the EK into a Hash</li><li>Bob pulls 32 bytes of the EK, a Seed</li><li>Bob uses the Seed and R to generate the majority of the CT</li><li>Bob then uses S and EK to generate the last portion of the CT</li></ol></li><li>Alice receives the CT, uses the DK to decrypt it, and now also has access to the 32 byte shared secret</li></ol><p>Step 3.d, which generates 960 bytes of the 1088-byte CT, only needs 64 bytes of input: a Seed that’s 32 of EK’s bytes, and the hash of EK, which is an additional 32. If we combine these values and send them first, then most of EK and most of the CT can be sent in parallel from Alice to Bob and Bob to Alice respectively. Our more complicated but more efficient secret sharing now looks like this:</p><ol><li>Alice generates EK and DK. Alice extracts the 32-byte Seed from EK</li><li>Alice sends 64 bytes EK<sub>1</sub> (Seed + Hash(EK)) to Bob. Bob sends nothing during this time.</li><li>Bob receives the Seed and Hash, and generates the first, largest part of the CT from them (CT<sub>1</sub>)</li><li>After this point, Alice sends EK<sub>2</sub> (the rest of the EK minus the Seed), while Bob sends CT<sub>1</sub></li><li>Bob eventually receives EK<sub>2</sub>, and uses it to generate the final portion of the CT (CT<sub>2</sub>)</li><li>Once Alice tells Bob that he has received all of CT<sub>1</sub>, Bob sends Alice CT<sub>2</sub>. Alice sends nothing during this time.</li><li>With both sides having all of the pieces of EK and the CT that they need, they extract their shared secret and increment their epoch</li></ol><p>There are still places in this algorithm (specifically steps 2 and 6) where one side has nothing to send. But during those times, the other side has only a very small amount of information to send, so the duration of those steps is minimal compared to the rest of the process. Specifically, while the full EK is 37 chunks and the full CT is 34, the two pieces of the new protocol which must be sent without data being received (EK<sub>1</sub> and CT<sub>2</sub>) are 2 and 4 chunks respectively, while the pieces that can be sent while also receiving (EK<sub>2</sub> and CT<sub>1</sub>) are the bulk of the data, at 36 and 30 chunks respectively. Far more of our sending capacity is actually used with this approach.</p><p><img src="https://signal.org/blog/images/spqr-2.png" alt="SPQR Flow Diagram showing improved bandwidth efficiency"></p><p>Remember that all of this is just to perform a quantum-safe key exchange that gives us a secret we can mix into the bigger protocol. To help us organize our code, our security proofs, and our understanding better we treat this process as a standalone protocol that we call <a href="https://signal.org/docs/specifications/mlkembraid/">the ML-KEM Braid</a>.</p><p>This work was greatly aided by the authors of the <a href="https://crates.io/crates/libcrux-ml-kem">libcrux-ml-kem</a> Rust library, who graciously exposed the APIs necessary to work with this incremental version of ML-KEM 768. With this approach completed, we’ve been able to really efficiently use the sending capacity of messages sent between two parties to share secrets as quickly as possible without exposing secrets from multiple epochs to potential attackers.</p><h2 id="mixing-things-up---the-triple-ratchet">Mixing Things Up - The Triple Ratchet</h2><p>There are plenty of details to add to make sure that we reached every corner - check those out in our <a href="https://signal.org/docs/">online protocol documentation</a> - but this basic idea lets us build secure messaging that has post-quantum FS and PCS without using up anyone’s data. We’re not done, though! Remember, at the beginning of this post we said we wanted post-quantum security without taking away our existing guarantees.</p><p>While today’s Double Ratchet may not be quantum safe, it provides a high level of security today and we believe it will continue to be strong well into the future. We aren’t going to take that away from our users. So what can we do?</p><p>Our answer ends up being really simple: we run both the Double Ratchet and the Sparse Post Quantum Ratchet alongside each other and mix their keys together, into what we’re calling the Triple Ratchet protocol. When you want to send a message you ask both the Double Ratchet and SPQR “What encryption key should I use for the next message?” and they will both give you a key (along with some other data you need to put in a message header). Instead of either key being used directly, both are passed into a Key Derivation Function - a special function that takes random-enough inputs and produces a secure cryptographic key that’s as long as you need. This gives you a new “mixed” key that has hybrid security. An attacker has to break both our elliptic curve and ML-KEM to even be able to distinguish this key from random bits. We use that mixed key to encrypt our message.</p><p>Receiving messages is just as easy. We take the message header - remember it has some extra data in it - and send it to the Double Ratchet and SPQR and ask them “What key should I use to decrypt a message with this header?” They both return their keys and you feed them both into that Key Derivation Function to get your decryption key. After that, everything proceeds just like it always has.</p><h2 id="heterogeneous-rollout">Heterogeneous Rollout</h2><p>So we’ve got this new, snazzy protocol, and we want to roll it out to all of our users across all of their devices… but none of the devices currently support that protocol. We roll it out to Alice, and Alice tries to talk to Bob, but Alice speaks SPQR and Bob doesn’t. Or we roll it out to Bob, but Alice wants to talk to Bob and Alice doesn’t know the new protocol Bob wants to use. How do we make this work?</p><p>Let’s talk about the simplest option: allowing downgrades. Alice tries to establish a session with Bob using SPQR and sends a message over it. Bob fails to read the message and establish the session, because Bob hasn’t been upgraded yet. Bob sends Alice an error, so Alice has to try again. This sounds fine, but in practice it’s not tenable. Consider what happens if Alice and Bob aren’t online at the same time… Alice sends a message at 1am, then shuts down. Bob starts up at 3am, sends an error, then shuts down. Alice gets that error when she restarts at 5am, then resends. Bob starts up at 7am and finally gets the message he should have received at 3am, 4 hours behind schedule.</p><p>To handle this, we designed the SPQR protocol to allow itself to downgrade to not being used. When Alice sends her first message, she attaches the SPQR data she would need to start up negotiation of the protocol. Noticing that downgrades are allowed for this session, Alice doesn’t mix any SPQR key material into the message yet. Bob ignores that data, because it’s in a location he glosses over, but since there’s no mixed in keys yet, he can still decrypt the message. He sends a response that lacks SPQR data (since he doesn’t yet know how to fill it in), which Alice receives. Alice sees a message without SPQR data, and understands that Bob doesn’t speak SPQR yet. So, she downgrades to not using it for that session, and they happily talk without SPQR protection.</p><p>There’s some scary potential problems here… let’s work through them. First off, can a malicious middleman force a downgrade and disallow Alice and Bob from using SPQR, even if both of them are able to? We protect against that by having the SPQR data attached to the message be MAC’d by the message-wide authentication code - a middleman can’t remove it without altering the whole message in such a way that the other party sees it, even if that other party doesn’t speak SPQR. Second, could some error cause messages to accidentally downgrade sometime later in their lifecycle, due either to bugs in the code or malicious activity? Crucially, SPQR only allows a downgrade when it first receives a message from a remote party. So, Bob can only downgrade if he receives his first message from Alice and notices that she doesn’t support SPQR, and Alice will only downgrade if she receives her first reply from Bob and notices that he doesn’t. After that first back-and-forth, SPQR is locked in and used for the remainder of the session.</p><p>Finally, those familiar with Signal’s internal workings might note that Signal sessions last a really long time, potentially years. Can we ever say “every session is protected by SPQR”, given that SPQR is only added to new sessions as they’re being initiated? To accomplish this, Signal will eventually (once all clients support the new protocol) roll out a code change that enforces SPQR for all sessions, and that archives all sessions which don’t yet have that protection. After the full rollout of that future update, we’ll be able to confidently assert complete coverage of SPQR.</p><p>One nice benefit to setting up this “maybe downgrade if the other side doesn’t support things” approach is that it also sets us up for the future: the same mechanisms that allow us to choose between SPQR or no-SPQR are designed to also allow us to upgrade from SPQR to some far-future (as yet unimagined) SPQRv2.</p><h2 id="making-sure-we-get-it-right">Making Sure We Get It Right</h2><p>Complex protocols require extraordinary care. We have to ensure that the new protocol doesn’t lose any of the security guarantees the Double Ratchet gives us. We have to ensure that we actually get the post-quantum protection we’re aiming for. And even then, after we have full confidence in the protocol, we have to make sure that our implementation is correct and robust and stays that way as we maintain it. This is a tall order.</p><p>To make sure we got this right, we started by building the protocol on a firm foundation of fundamental research. We built on the years of research the academic community has put into secure messaging and we collaborated with researchers from PQShield, AIST, and NYU to explore what was possible with post-quantum secure messaging. In <a href="https://eprint.iacr.org/2025/078">a paper at Eurocrypt 25</a> we introduced erasure code based chunking and proposed the high-level Triple Ratchet protocol, proving that it gave us the post-quantum security we wanted without taking away any of the security of the classic Double Ratchet. In <a href="https://www.usenix.org/system/files/usenixsecurity25-auerbach.pdf">a follow up paper at USENIX 25</a>, we observed that there are many different ways to design a post-quantum ratchet protocol and we need to pick the one that protects user messages the best. We introduced and analyzed six different protocols and two stood out: one is essentially SPQR, the other is a protocol using a new KEM, called Katana, that we designed just for ratcheting. That second one is exciting, but we want to stick to standards to start!</p><h2 id="formal-verification-from-the-start">Formal Verification From the Start</h2><p>This research gave us the framework to think about protocol design and prove protocols are secure, but there is a big leap from an academic paper to code. Already when designing <a href="https://signal.org/blog/pqxdh/">PQXDH</a> - a much simpler protocol! - <a href="https://www.usenix.org/system/files/usenixsecurity24-bhargavan.pdf">we found that formal verification was an important tool for getting the details right</a>. With the Triple Ratchet we partnered with Cryspen and made formal verification part of the process from the beginning.</p><p>As we kept finding better protocol candidates - and we implemented around a dozen of them - we modeled them in <a href="https://bblanche.gitlabpages.inria.fr/proverif/">ProVerif</a> to prove that they had the security properties we needed. Rather than wrapping up a protocol design and performing formal verification as a last step we made it a core part of the design process. Now that the design is settled, this gives us machine verified proof that our protocol has the security properties we demand from it. We wrote our Rust code to closely match the ProVerif models, so it is easy to check that we’re modeling what we implement. In particular, ProVerif is very good at reasoning about state machines, which we’re already using, making the mapping from code to model much simpler.</p><p>We are taking formal verification further than that, though. We are using <a href="https://github.com/cryspen/hax">hax</a> to translate our Rust implementation into <a href="https://fstar-lang.org/">F*</a> on every CI run. Once the F* models are extracted, we prove that core parts of our highly optimized implementation are correct, that function pre-conditions and post-conditions cannot be violated, and that the entire crate is panic free. That last one is a big deal. It is great for usability, of course, because nobody wants their app to crash. But it also matters for correctness. We aggressively add assertions about things we believe must be true when the protocol is running correctly - and we crash the app if they are false. With hax and F*, we prove that those assertions will never fail.</p><h2 id="formal-verification-doesnt-freeze-our-progress">Formal Verification Doesn’t Freeze Our Progress</h2><p>Often when people think about formally verified protocol implementations, they imagine a one-time huge investment in verification that leaves you with a codebase frozen in time. This is not the case here. We re-run formal verification in our CI pipeline every time a developer pushes a change to GitHub. If the proofs fail then the build fails, and the developer needs to fix it. In our experience so far, this is usually as simple as adding a pre- or postcondition or returning an error when a value is out of bounds. For us, formal verification is a dynamic part of the development process and ensures that the quality is high on every merge.</p><h2 id="tldr">TLDR</h2><p>Signal is rolling out a new version of the Signal Protocol with the Triple Ratchet. It adds the Sparse Post-Quantum Ratchet, or SPQR, to the existing Double Ratchet to create a new Triple Ratchet which gives our users quantum-safe messaging without taking away any of our existing security promises. It’s being added in such a way that it can be rolled out without disruption. It’s relatively lightweight, not using much additional bandwidth for each message, to keep network costs low for our users. It’s resistant to meddling by malicious middlemen - to disrupt it, all messages after a certain time must be dropped, causing a noticeable denial of service for users. We’re rolling it out slowly and carefully now, but in such a way that we’ll eventually be able to say with confidence “every message sent by Signal is protected by this.” Its code has been formally verified, and will continue to be so even as future updates affect the protocol. It’s the combined effort of Signal employees and external researchers and contributors, and it’s only possible due to the continued work and diligence of the larger crypto community. And as a user of Signal, our biggest hope is that you never even notice or care. Except one day, when headlines scream “OMG, quantum computers are here”, you can look back on this blog post and say “oh, I guess I don’t have to care about that, because it’s already been handled”, as you sip your Nutri-Algae while your self-driving flying car wends its way through the floating tenements of Megapolis Prime.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Windows 7 marketshare jumps to nearly 10% as Windows 10 support is about to end (115 pts)]]></title>
            <link>https://www.neowin.net/news/windows-7-marketshare-jumps-to-nearly-10-as-windows-10-enters-final-weeks-of-support/</link>
            <guid>45451208</guid>
            <pubDate>Thu, 02 Oct 2025 15:42:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.neowin.net/news/windows-7-marketshare-jumps-to-nearly-10-as-windows-10-enters-final-weeks-of-support/">https://www.neowin.net/news/windows-7-marketshare-jumps-to-nearly-10-as-windows-10-enters-final-weeks-of-support/</a>, See on <a href="https://news.ycombinator.com/item?id=45451208">Hacker News</a></p>
Couldn't get https://www.neowin.net/news/windows-7-marketshare-jumps-to-nearly-10-as-windows-10-enters-final-weeks-of-support/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Autism should not be seen as single condition with one cause, say scientists (110 pts)]]></title>
            <link>https://www.theguardian.com/society/2025/oct/01/autism-should-not-be-seen-as-single-condition-with-one-cause-say-scientists</link>
            <guid>45451103</guid>
            <pubDate>Thu, 02 Oct 2025 15:35:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/society/2025/oct/01/autism-should-not-be-seen-as-single-condition-with-one-cause-say-scientists">https://www.theguardian.com/society/2025/oct/01/autism-should-not-be-seen-as-single-condition-with-one-cause-say-scientists</a>, See on <a href="https://news.ycombinator.com/item?id=45451103">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Autism should not be viewed as a single condition with a unified underlying cause, according to scientists who found that those diagnosed early in childhood typically have a distinct genetic profile to those diagnosed later.</p><p>The international study, based on genetic data from more than 45,000 autistic people in Europe and the US, showed that those diagnosed in early childhood, typically before six years old, were more likely to show behavioural difficulties from early childhood, including problems with social interaction, but remain stable.</p><p>Those diagnosed with autism later, typically after the age of 10, were more likely to experience increasing social and behavioural difficulties during adolescence and also had an increased likelihood of mental health conditions such as depression.</p><p>“The term ‘autism’ likely describes multiple conditions,” said Dr Varun Warrier, from Cambridge’s department of psychiatry, senior author of the research. “For the first time, we have found that earlier and later diagnosed autism have different underlying biological and developmental profiles.”</p><p>The scientists are not advocating for a move towards two diagnostic categories, saying that this could be unhelpful for the many who fall somewhere in the middle.</p><p>“It is a gradient,” said Warrier. “There are also many other factors that contribute to age of diagnosis, so the moment you go from averages to anything that is applicable to an individual, it’s false equivalency.”</p><p>The findings come at a time when autism diagnosis has risen steeply, with a nearly <a href="https://acamh.onlinelibrary.wiley.com/doi/10.1111/jcpp.13505" data-link-name="in body link">800% increase in diagnoses in the UK</a> between 1998 and 2018. Experts say this is due largely to a widening of the diagnostic criteria and greater recognition of the condition.</p><p>And, while autism is defined by having challenges with social communication, sensory processing and restrictive behaviours, there is huge variability in how these difficulties present between individuals. Scientists have been looking at whether the population clusters into subgroups, with shared traits or trajectories, that could make studying autism more tractable.</p><p>The latest study used behavioural data from four birth cohorts, ranging from 89 to 188 people, and genetic data from two large studies, with more than 45,000 participants.</p><p>Previously, it was generally assumed that those diagnosed earlier tended to be those with more marked autistic traits, underpinned by people carrying a higher proportion of autism-linked gene variants. However, the latest study revealed a different pattern.</p><figure id="84037ab2-e09e-4580-a076-837487e8ab1e" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:10,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Autistic people could teach Donald Trump a thing or two about focus, facts and empathy | Rhiannon Lucy Cosslett&quot;,&quot;elementId&quot;:&quot;84037ab2-e09e-4580-a076-837487e8ab1e&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/commentisfree/2025/sep/28/autistic-people-donald-trump-autism-us-president-rfk-jr&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>The analysis,<em> </em><a href="https://www.nature.com/articles/s41586-025-09542-6" data-link-name="in body link">published in Nature</a><em>,</em> found that the underlying genetic profiles differed between those diagnosed with autism earlier and later in life, with only a modest overlap. The average genetic profile of later-diagnosed autism is closer to that of ADHD, as well as to mental health conditions such as depression and PTSD, than it is to autism diagnosed in early childhood.</p><p>Those diagnosed before the age of six years were more likely to be slow to walk and have difficulty interpreting hand gestures and tended to experience social and communication difficulties that appeared early but remained stable. Those diagnosed after the age of 10 years were more likely to experience an increase in difficulties during adolescence and, by late adolescence, presented with more severe challenges.</p><p>Prof Uta Frith, emeritus professor of cognitive development at University College London, who was not involved in the research, said: “It makes me hopeful that even more subgroups will come to light, and each will find an appropriate diagnostic label.</p><p>“It is time to realise that ‘autism’ has become a ragbag of different conditions.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Work is not school: Surviving institutional stupidity (151 pts)]]></title>
            <link>https://www.leadingsapiens.com/surviving-institutional-stupidity/</link>
            <guid>45450525</guid>
            <pubDate>Thu, 02 Oct 2025 14:58:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.leadingsapiens.com/surviving-institutional-stupidity/">https://www.leadingsapiens.com/surviving-institutional-stupidity/</a>, See on <a href="https://news.ycombinator.com/item?id=45450525">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    <div>

      <p>For 16+ years, we master the rules of school. Study hard, get good grades, follow the formula and ultimately merit wins. Then we enter the workforce and none of it works quite like we thought.&nbsp;This becomes painfully obvious as you rise higher in the org. </p><p>Even seasoned veterans forget this. Recently, a director-level client hit a minor career bump and spiraled into crisis mode, their expectations still anchored in what I call "school rules".</p><p><strong>Organizations don't run purely on merit or even clear criteria. Although they claim otherwise using buzzwords like “merit” and “data”.</strong> That’s only one part of the story, and also what’s visible.&nbsp;</p><p>The other part, often more consequential, runs on flawed psychology, imperfect decisions, and competing interests. <mark>You can call it<strong>&nbsp;organizational absurdities. Or more bluntly, institutional stupidity.</strong></mark></p><p>What follows is a reality check. It’s a “letter to frustrated high-performers” who keep bumping up against these unwritten rules of work. Consider it your guide to staying sane while playing the long game.</p><ul><li><a href="https://www.leadingsapiens.com/surviving-institutional-stupidity/#if-you-have-to-blame-stupidity-not-malice">If you have to, blame stupidity not malice</a></li><li><a href="https://www.leadingsapiens.com/surviving-institutional-stupidity/#organizations-are-anything-but-meritocracies">Organizations are anything but meritocracies</a></li><li><a href="https://www.leadingsapiens.com/surviving-institutional-stupidity/#perception-matters-as-much-as-performance">Perception matters as much as performance</a></li><li><a href="https://www.leadingsapiens.com/surviving-institutional-stupidity/#don%E2%80%99t-waste-time-fighting-for-%E2%80%9Cobjective-fairness%E2%80%9D" rel="noreferrer">Don’t waste time fighting for “objective fairness.”</a></li><li><a href="https://www.leadingsapiens.com/surviving-institutional-stupidity/#positioning-what-you-offer">Positioning what you offer</a></li><li><a href="https://www.leadingsapiens.com/surviving-institutional-stupidity/#mind-the-gap-your-standards-vs-their%E2%80%99s" rel="noreferrer">Mind the gap: your standards vs their’s</a></li><li><a href="https://www.leadingsapiens.com/surviving-institutional-stupidity/#higher-you-go-more-it%E2%80%99s-an-inverted-funnel" rel="noreferrer">Higher you go, more it’s an inverted funnel</a></li><li><a href="https://www.leadingsapiens.com/surviving-institutional-stupidity/#know-which-game-you%E2%80%99re-choosing-to-play" rel="noreferrer">Know which game you’re choosing to play</a></li><li><a href="https://www.leadingsapiens.com/surviving-institutional-stupidity/#watching-your-circle-of-control">Watching your circle of control</a></li><li><a href="https://www.leadingsapiens.com/surviving-institutional-stupidity/#keep-a-balanced-portfolio">Keep a balanced portfolio</a></li></ul><div><p>💡</p><p><i><em>Before diving in, a quick note: This piece deliberately spotlights the subjective aspects of organizational life. While companies strive for objectivity in all areas, there's an overlooked undercurrent of subjectivity that significantly impacts work, and careers. By highlighting this less-discussed dimension, I hope to provide a more complete picture and prevent unnecessary frustration. You won’t avoid it completely, but at least you’ll be better equipped.</em></i></p></div><hr><h2 id="if-you-have-to-blame-stupidity-not-malice"><strong>If you have to, blame stupidity not malice</strong></h2><p>Most of what we chalk up to “politics” or “backstabbing”, aka bad intent, is often better explained by stupidity, inertia, bad incentives, fragmented attention, and misaligned maps of reality.</p><p>People are juggling too much, thinking too little, and rarely stepping back to ask, “What actually makes sense here?”</p><p>When you assume stupidity instead of malice, you stay above the fray, stop taking slights personally, or turning misjudgments into betrayals. This way we retain agency and choice.</p><p><mark><strong>Assuming malice turns you into a cynic. In contrast, assuming stupidity keeps you curious.</strong>&nbsp;</mark> Instead of fighting ghosts, you study the system and ask better questions:</p><ul><li>What pressures is that person responding to?</li><li>What game are they trying to win?</li><li>What am I assuming as rational that’s not?</li></ul><p>No one is out to get you; they’re just out to get through the week. The shift from malice to stupidity gives you just enough distance to be curious instead of reactive.</p><h2 id="organizations-are-anything-but-meritocracies"><strong>Organizations are anything but meritocracies</strong></h2><p>Managers will claim they are, and we want to believe them. But the reality is that the best don’t always rise. At least not as easily or automatically as we think they should.</p><p>Sometimes they do. But often, what gets rewarded isn’t performance but proximity to power, timing, perception, and political usefulness.</p><p><mark>This doesn’t mean performance doesn’t matter.&nbsp;<strong>It means performance is necessary but not sufficient.</strong></mark>&nbsp;It is the entry ticket&nbsp;that gets you through the door, but does not guarantee a seat at the table.</p><p><strong>Assuming that excellence is obvious is the fatal error of the conscientious expert. </strong>Although it creates value, performance doesn’t automatically generate visibility, influence, or narrative. And those are the currencies that get traded when decisions are made by humans.</p><p>Merit matters, but it needs a stage and a spotlight. It doesn’t mean becoming a shameless self-promoter. Rather,<mark>&nbsp;<strong>your work needs a distribution strategy.&nbsp;</strong></mark></p><h2 id="perception-matters-as-much-as-performance"><strong>Perception matters as much as performance</strong></h2><p>In school, everyone was evaluated against an objective criteria by someone paid to assess fairly.&nbsp;</p><p>In organizations, no such thing exists.<mark>&nbsp;<strong>Instead, perception&nbsp;<em>is</em>&nbsp;the “data”.</strong><strong>&nbsp;</strong></mark>And this data is constructed often haphazardly by busy people working off limited inputs. You have to manage the story by<a href="https://www.leadingsapiens.com/impression-management/" rel="noreferrer">&nbsp;shaping impressions intentionally</a>.</p><p>Not only does perception matter as much as performance but <a href="https://www.leadingsapiens.com/schrodingers-cat-at-work/" rel="noreferrer">who’s doing the perceiving</a> matters even more.&nbsp;</p><p>Not all perceivers are created equal. A peer may love your work but they might not be a critical node in the web of influence. Who gets consulted? Do they know what you’ve built, and have they heard your name in relevant contexts?</p><p><strong><mark>It’s not just “do great work.”; it’s also “do the work that’s perceived as valuable.” </mark></strong>This means translating your work’s significance up the chain and shape its interpretation. If not, others will do it for you and they may not be generous, or even accurate.</p><p>For more, see my last two articles:&nbsp;<a href="https://www.leadingsapiens.com/schrodingers-cat-at-work/" rel="noopener noreferrer nofollow">Schrodinger’s Cat at Work Part I</a>&nbsp;and&nbsp;<a href="https://www.leadingsapiens.com/schrodingers-cat-building-the-box-of-limitations/" rel="noopener noreferrer nofollow">Schrodinger’s Cat at Work Part II</a>.</p><h2 id="don%E2%80%99t-waste-time-fighting-for-%E2%80%9Cobjective-fairness%E2%80%9D"><strong>Don’t waste time fighting for “objective fairness.”</strong></h2><p>On paper, organizations love metrics: KPIs, OKRs, dashboards. They create the appearance of detached objectivity.</p><p>Meanwhile, subjective decisions are constantly happening behind the scenes. The decisions about who to trust, or who gets a shot are made through informal reputations and shared stories about your value. Then the “data” is used to justify them in retrospect.</p><p>Rather than rant against the system,&nbsp;<strong>get good at reading the underlying subjective logic</strong>:</p><ul><li>Who does this person trust, and why?</li><li>What do they consider strategic vs tactical?</li><li>What would make them feel safe betting on me?</li></ul><p>Subjectivity isn’t the enemy. It’s the underlying physics of it.</p><h2 id="positioning-what-you-offer"><strong>Positioning what you offer</strong></h2><p>You may have had the right message but at the wrong moment, or in the wrong wrapper.</p><p>Positioning is the context around your contributions:&nbsp;<em>Why now? Why you? Why this way?</em>&nbsp;A good idea, or stellar performance, poorly positioned can seem irrelevant. In contrast, a mediocre one nicely positioned is deemed visionary.</p><p>It’s not just&nbsp;<em>what</em>&nbsp;you say but also&nbsp;<em>when</em>,&nbsp;<em>how</em>, and&nbsp;<em>through whom</em>&nbsp;you say it.</p><p>Persistence matters as well.&nbsp;<strong><mark>Think in campaigns, not just one-time efforts. </mark></strong>In my piece on&nbsp;<a href="https://www.leadingsapiens.com/effective-leadership-as-effective-conversations/" rel="noreferrer">effective conversations</a>&nbsp;I wrote:&nbsp;</p><blockquote><em>It is the series of messages in different forms that over time makes the difference. More akin to waves shaping the shoreline rather than the occasional once in a lifetime tsunami.</em></blockquote><p>What messages are you sending, are they varied, and are you doing it consistently? <strong>This is as true for marketing products as it is for positioning yourself inside organizations.</strong></p><h2 id="mind-the-gap-your-standards-vs-their%E2%80%99s">Mind the gap: your standards vs their’s</h2><p>Another obvious but forgotten reality of organizational life:&nbsp;<strong>Not everyone operates by the same playbook.&nbsp;</strong></p><p>You prioritize substance and direct contribution, while others focus on visibility and relationship-building in ways that are uncomfortable to you. It’s that colleague who excels at positioning routine work as “strategic”, or the peer who builds influence through cultivating key relationships.</p><p>And yes, these approaches do yield results.</p><p>But this doesn’t mean dismissing it as pure politics or simply abandoning your principles. It means understanding the landscape you're operating in.&nbsp;</p><p>You can’t effectively participate in a game you refuse to see clearly.&nbsp;You're not at a disadvantage because you choose to act with integrity. It’s because you fail to recognize that influence flows through multiple channels and&nbsp;others are willing to play differently.&nbsp;</p><p><mark><strong>The key is not to match their behavior but to factor it in</strong>.&nbsp;Instead of expecting fairness,&nbsp;<strong>anticipate asymmetry</strong>.</mark>&nbsp;And then get creative about how you play.&nbsp;</p><p>Being ethical <strong>doesn’t mean being passive but  tactically awake.&nbsp;</strong></p><h2 id="higher-you-go-more-it%E2%80%99s-an-inverted-funnel"><strong>Higher you go, more it’s an inverted funnel</strong></h2><p>Perhaps the most obvious point but also<strong>&nbsp;easy to forget especially if your career has been on autopilot so far.</strong></p><p>There’s a bottleneck up top: fewer seats, more ambiguity, less structure and high subjectivity. It’s not just hard to get in but even harder to stay clear on what “good” even looks like.</p><p>This means you can do everything right and still get passed over. <strong>That’s not a verdict on your worth or ability, just geometry.</strong></p><p>It also means that staying the course when things don’t go your way isn’t just a virtue but a practice. To play the long game, you have to keep showing up even after crushing disappointment without getting cynical of the process. Put differently, <strong>you need high levels of </strong><a href="https://www.leadingsapiens.com/frustration-tolerance/" rel="noreferrer"><strong>frustration tolerance</strong></a><strong>.</strong></p><p>Cliched? Yes, very much so, but also uncommon. It means if you can pull it off, it’s a <a href="https://www.leadingsapiens.com/sources-of-power-in-organizations/" rel="noreferrer">source of power</a>.</p><h2 id="know-which-game-you%E2%80%99re-choosing-to-play"><strong>Know which game you’re choosing to play</strong></h2><p>There is no one game being played. There are multiple, overlapping games with different scoring systems. Some are playing to build long-term credibility; others for short-term visibility.&nbsp;</p><p>You can’t play them all and neither should you try.</p><p><strong><mark>The real problem is we slide into playing someone else's game without realizing it.</mark></strong>&nbsp;We adopt the norms and metrics of others without checking if that’s the game we actually want to play, let alone win. So we end up optimizing for a role we don’t respect, or chasing promotions that hollow us out.</p><p>Whatever you’re doing, own it outright. Not just the upside but also the downside. If you're focused on building something lasting like developing others, or robust systems, you need to accept that visible status markers (titles, promotions, recognition) might not happen right away.</p><p>The danger isn't which path you pick, whether it's chasing promotions or maintaining your autonomy.&nbsp;<strong><mark>The real disaster is to sleepwalk down a path while pretending you had no choice in the matter.</mark></strong></p><h2 id="watching-your-circle-of-control">Watching your circle of control</h2><p>An easy way to burn out is to focus relentlessly on<strong> things you care about but cannot actually influence</strong>. Over time, especially in large organizations, it's tempting to attribute everything to forces outside yourself. This induces <a href="https://www.leadingsapiens.com/locus-of-control/#locus-of-control-and-learned-helplessness-in-organizations" rel="noreferrer">organizational helplessness</a>. A sense that nothing you do matters unless someone above says so.</p><p>Fight that, not with bluster, but with deliberate ownership of <a href="https://www.leadingsapiens.com/circle-of-control-influence-concerns/" rel="noreferrer">the space you control and influence</a>.&nbsp;While experienced professionals often have more influence than they think, it's distributed differently than they expect.&nbsp;</p><p>The key is maintaining <a href="https://www.leadingsapiens.com/locus-of-control/" rel="noreferrer">an internal locus of control</a> which includes your positioning, relationships, and what you are building.</p><h2 id="keep-a-balanced-portfolio"><strong>Keep a balanced portfolio</strong></h2><p>This is a well-understood concept in investing but often missing in the context of long careers. If all your identity is wrapped up in organizational validation, you're fragile. This means setbacks&nbsp;don't just rattle your job, it rattles your sense of self.</p><p>Many mid-career professionals learn this the hard way. To state the obvious: you are not your title, or your most recent performance review.</p><p><strong><mark>The anti-dote is diversification not of money, but meaning.</mark></strong></p><p>Rebalancing here means investing in other sources of connection and community. This includes:</p><ul><li>Developing a craft that exists beyond a given employer.</li><li>Investing in communities that outlast org charts.</li><li>Projects, relationships, and sources of learning that replenish.</li></ul><p>You are building <a href="https://www.leadingsapiens.com/adaptive-capacity/" rel="noreferrer">adaptive capacity</a>.</p><p>A balanced portfolio also helps to play the long game with more&nbsp;<a href="https://www.leadingsapiens.com/courage-modern-leadership-organizations/" rel="noreferrer">psychological courage</a>&nbsp;because your whole life isn't riding on the next promotion cycle or external validation.</p><h2 id="in-closing"><strong>In closing</strong></h2><p>By recognizing the subjective currents that shape work environments, we can operate within them more skillfully.</p><p>This isn't cynicism or gaming the system. Rather, it's developing a nuanced understanding of how organizations actually function. This stance equips us to make more intentional choices about how to engage, contribute, and create meaning.</p><p>As ideal as it sounds, the goal isn't to eliminate organizational absurdities, but to work effectively within and around them. By staying in the game, you find ways to gradually improve the system from within.&nbsp;</p><p><mark>Organizations are ultimately human constructs.<strong>&nbsp;Imperfect, but not immutable.</strong></mark></p>
<!--kg-card-begin: html-->

<!--kg-card-end: html-->
<ul><li><a href="https://www.leadingsapiens.com/frustration-tolerance/" rel="noreferrer">Frustration tolerance</a></li><li><a href="https://www.leadingsapiens.com/developing-negative-capability-leadership/" rel="noreferrer">Negative capability</a></li><li><a href="https://www.leadingsapiens.com/circle-of-control-influence-concerns/" rel="noreferrer">Circle of control</a></li><li><a href="https://www.leadingsapiens.com/locus-of-control/" rel="noreferrer">Locus of control</a></li><li><a href="https://www.leadingsapiens.com/cognitive-distortions-leaders/" rel="noreferrer">Cognitive distortions</a></li></ul>
    </div>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Two Amazon delivery drones crash into crane in commercial area of Tolleson, AZ (199 pts)]]></title>
            <link>https://www.abc15.com/news/region-west-valley/tolleson/two-amazon-delivery-drones-crash-into-crane-in-commercial-area-of-tolleson</link>
            <guid>45450449</guid>
            <pubDate>Thu, 02 Oct 2025 14:52:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.abc15.com/news/region-west-valley/tolleson/two-amazon-delivery-drones-crash-into-crane-in-commercial-area-of-tolleson">https://www.abc15.com/news/region-west-valley/tolleson/two-amazon-delivery-drones-crash-into-crane-in-commercial-area-of-tolleson</a>, See on <a href="https://news.ycombinator.com/item?id=45450449">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <main>
      <article itemprop="mainEntity">
        <div>
          
            
              
            
          
          <div>
                <h2>Actions</h2>
                
              </div>
          <div>
            
              <h2 itemprop="headline">Two Amazon delivery drones crash into crane in commercial area of Tolleson</h2>
            
            
              <p>It's unclear if there were any injuries</p>
            
          </div>
  </div>
  <div>
    
      <div>
  <div>
        <p><img alt="" src="https://cf.cdn.uplynk.com/ause1/slices/14f/5c3d34b8b29a45469a86c02775b7a2cf/14fd60624b1548668bf1847fe8d5bc83/poster_b8eb59ea986c4550a4cfcfd659412cca.png" data-caption="The Tolleson Police Department is investigating after two Amazon delivery drones crashed into a crane on Wednesday morning.">
    

        </p>
      </div>
  <div>
      
      
      <p>The Tolleson Police Department is investigating after two Amazon delivery drones crashed into a crane on Wednesday morning.</p>
      
    </div>

  
  <div>
      
      <div data-video-title="Two Amazon delivery drones crash into crane in Tolleson" data-m3u8="https://content.uplynk.com/14fd60624b1548668bf1847fe8d5bc83.m3u8" data-mp4="https://cf.cdn.uplynk.com/ause1/slices/14f/5c3d34b8b29a45469a86c02775b7a2cf/14fd60624b1548668bf1847fe8d5bc83/14fd60624b1548668bf1847fe8d5bc83_e.mp4" data-video-keywords="Amazon delivery drone, Tolleson, drone crash" data-fname="" data-disable-ads="" data-caption="The Tolleson Police Department is investigating after two Amazon delivery drones crashed into a crane on Wednesday morning." data-copyright="" data-verizon-id="14fd60624b1548668bf1847fe8d5bc83" data-thumbnailurl="https://cf.cdn.uplynk.com/ause1/slices/14f/5c3d34b8b29a45469a86c02775b7a2cf/14fd60624b1548668bf1847fe8d5bc83/poster_b8eb59ea986c4550a4cfcfd659412cca.png" data-disable-autoplay="" data-disable-continuous-play="" data-param-overrides="" data-lead-autoplay="false">
    <p><img src="https://ewscripps.brightspotcdn.com/dims4/default/7b76ba3/2147483647/strip/false/crop/545x304+12+0/resize/95x53!/quality/90/?url=https%3A%2F%2Fcf.cdn.uplynk.com%2Fause1%2Fslices%2F14f%2F5c3d34b8b29a45469a86c02775b7a2cf%2F14fd60624b1548668bf1847fe8d5bc83%2Fposter_b8eb59ea986c4550a4cfcfd659412cca.png" alt="Two Amazon delivery drones crash into crane in Tolleson" data-src="https://ewscripps.brightspotcdn.com/dims4/default/7b76ba3/2147483647/strip/false/crop/545x304+12+0/resize/95x53!/quality/90/?url=https%3A%2F%2Fcf.cdn.uplynk.com%2Fause1%2Fslices%2F14f%2F5c3d34b8b29a45469a86c02775b7a2cf%2F14fd60624b1548668bf1847fe8d5bc83%2Fposter_b8eb59ea986c4550a4cfcfd659412cca.png">
    </p>
</div>
      
      <div><picture>

    
        
            
        
    
    
        
            
        
    
    
        
            
        
    
    
        
            
        
    
    
        
            
        
    

    
    
    
    <source type="image/webp" srcset="https://ewscripps.brightspotcdn.com/dims4/default/e841b43/2147483647/strip/true/crop/1954x1099+0+0/resize/1280x720!/format/webp/quality/90/?url=http%3A%2F%2Fewscripps-brightspot.s3.amazonaws.com%2F0c%2F07%2Fbab780bd45139df722a069f2ff01%2Fscreenshot-2025-10-01-at-11-52-37-am.png 1x,https://ewscripps.brightspotcdn.com/dims4/default/48dccab/2147483647/strip/true/crop/1954x1099+0+0/resize/2560x1440!/format/webp/quality/90/?url=http%3A%2F%2Fewscripps-brightspot.s3.amazonaws.com%2F0c%2F07%2Fbab780bd45139df722a069f2ff01%2Fscreenshot-2025-10-01-at-11-52-37-am.png 2x">

    
        <!-- altFormatsOnly --><source srcset="https://ewscripps.brightspotcdn.com/dims4/default/c337574/2147483647/strip/true/crop/1954x1099+0+0/resize/1280x720!/quality/90/?url=http%3A%2F%2Fewscripps-brightspot.s3.amazonaws.com%2F0c%2F07%2Fbab780bd45139df722a069f2ff01%2Fscreenshot-2025-10-01-at-11-52-37-am.png">

    
    <img alt="amazon drone crash" data-credit="KNXV" data-src="https://ewscripps.brightspotcdn.com/dims4/default/c337574/2147483647/strip/true/crop/1954x1099+0+0/resize/1280x720!/quality/90/?url=http%3A%2F%2Fewscripps-brightspot.s3.amazonaws.com%2F0c%2F07%2Fbab780bd45139df722a069f2ff01%2Fscreenshot-2025-10-01-at-11-52-37-am.png" loading="lazy" src="https://ewscripps.brightspotcdn.com/dims4/default/c337574/2147483647/strip/true/crop/1954x1099+0+0/resize/1280x720!/quality/90/?url=http%3A%2F%2Fewscripps-brightspot.s3.amazonaws.com%2F0c%2F07%2Fbab780bd45139df722a069f2ff01%2Fscreenshot-2025-10-01-at-11-52-37-am.png">
</picture>
</div>
      
    </div>
  
</div>
    
    

    
      <p><span>Posted </span>
        <span id="published-date" data-timestamp="2025-10-01T18:57:19.147Z"></span>
      </p>
    
    
      <p><span>and last updated</span>
        <span data-timestamp="2025-10-01T23:59:14.746Z"></span>
      </p>
    

    

    
      <div itemprop="articleBody"><p>TOLLESON, AZ — The Tolleson Police Department is investigating after two Amazon delivery drones crashed on Wednesday morning.</p><p>Officials say they are working an active investigation after the two drones crashed into a crane that was in a commercial area near 96th Avenue and Roosevelt Street.</p><figure itemscope="" itemtype="http://schema.org/ImageObject">
    
        <div>
            <p><img src="https://ewscripps.brightspotcdn.com/dims4/default/4c0db97/2147483647/strip/true/crop/1924x1290+0+0/resize/1280x858!/quality/90/?url=http%3A%2F%2Fewscripps-brightspot.s3.amazonaws.com%2F36%2F91%2F51d38fc24a46aef0fdb0f1f04b7a%2Fscreenshot-2025-10-01-at-11-53-00-am.png" alt="drone crane crash tolleson" srcset="https://ewscripps.brightspotcdn.com/dims4/default/4c0db97/2147483647/strip/true/crop/1924x1290+0+0/resize/1280x858!/quality/90/?url=http%3A%2F%2Fewscripps-brightspot.s3.amazonaws.com%2F36%2F91%2F51d38fc24a46aef0fdb0f1f04b7a%2Fscreenshot-2025-10-01-at-11-53-00-am.png 1x,https://ewscripps.brightspotcdn.com/dims4/default/bbd427a/2147483647/strip/true/crop/1924x1290+0+0/resize/2560x1716!/quality/90/?url=http%3A%2F%2Fewscripps-brightspot.s3.amazonaws.com%2F36%2F91%2F51d38fc24a46aef0fdb0f1f04b7a%2Fscreenshot-2025-10-01-at-11-53-00-am.png 2x" width="1280" height="858"></p><p>KNXV</p></div>
    
    
</figure>
<p>It's unclear if anyone was injured during the incident.</p><p>ABC15 reached out to Amazon which provided the following statement: <i>“We’re aware of an incident involving two Prime Air drones in Tolleson, Arizona. We’re currently working with the relevant authorities to investigate.”</i></p><p><b><i>This is a developing story and will be updated once new information becomes available.</i></b></p><div><p><a href="https://www.abc15.com/apps"><img width="100%" src="https://ewscripps.brightspotcdn.com/ec/ab/9d59467b4bbea038870b0c7b24e7/liveplayerbanner1.png"></a></p>


</div>

</div>
    
    
    <p>Copyright 2025 Scripps Media, Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed.</p>


    
    <div>

  <p id="news-sign">
    <h3>Sign up for the <span>Headlines Newsletter</span> and receive up to date information.</h3>
    
  </p>

  

  </div>


  </div>
  
    



  </article>
  </main>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[N8n added native persistent storage with DataTables (117 pts)]]></title>
            <link>https://community.n8n.io/t/data-tables-are-here/192256</link>
            <guid>45450044</guid>
            <pubDate>Thu, 02 Oct 2025 14:26:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://community.n8n.io/t/data-tables-are-here/192256">https://community.n8n.io/t/data-tables-are-here/192256</a>, See on <a href="https://news.ycombinator.com/item?id=45450044">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
      <meta itemprop="headline" content="Data Tables Are Here! 📊">
      
      <meta itemprop="datePublished" content="2025-09-22T15:23:10Z">
        <meta itemprop="articleSection" content="Community Highlights">
      <meta itemprop="keywords" content="featured">
      


          <div id="post_1">
            <div>
              

                

              <p><span>
                  <time datetime="2025-09-22T15:23:11Z">
                    September 22, 2025,  3:23pm
                  </time>
                  <meta itemprop="dateModified" content="2025-09-28T20:00:41Z">
              <span itemprop="position">1</span>
              </span>
            </p></div>
            <div itemprop="text">
              <h2><a name="p-390656-hey-everyone-waving_hand-1" href="#p-390656-hey-everyone-waving_hand-1"></a>Hey everyone <img src="https://community.n8n.io/images/emoji/twitter/waving_hand.png?v=14" title=":waving_hand:" alt=":waving_hand:" loading="lazy" width="20" height="20"></h2>
<h2><a name="p-390656-were-super-excited-to-share-that-starting-with-v1113-were-rolling-out-data-tables-beta-to-all-plans-bar_chart-2" href="#p-390656-were-super-excited-to-share-that-starting-with-v1113-were-rolling-out-data-tables-beta-to-all-plans-bar_chart-2"></a>We’re super excited to share that starting with <strong>v1.113</strong> we’re rolling out <strong>data tables (beta)</strong> to all plans. <img src="https://community.n8n.io/images/emoji/twitter/bar_chart.png?v=14" title=":bar_chart:" alt=":bar_chart:" loading="lazy" width="20" height="20"></h2>
<p><a href="https://www.youtube.com/watch?v=ljkiIkt6lZ4" target="_blank" rel="noopener">
    <img src="https://community.n8n.io/uploads/default/original/3X/a/4/a4ddd2d709bda27003d8495469c5ca16a86a05c9.jpeg" title="Store Data Natively in n8n [Data Tables Demo]" data-dominant-color="653858" width="690" height="388">
  </a>
</p>

<p>Since the very beginning of n8n we’ve heard many of you mention the need for a proper table inside n8n to store data between workflow executions without needing to switch platforms or setting up credentials and now it’s finally here.</p>
<p>With data tables you can:</p>
<ul>
<li>
<p>Save specific data from your workflow runs</p>
</li>
<li>
<p>Keep data around between multiple executions</p>
</li>
<li>
<p>Avoid duplicate runs by tracking execution status</p>
</li>
<li>
<p>Store reusable prompts for different workflows</p>
</li>
<li>
<p>Collect evaluation data for your AI workflows</p>
</li>
<li>
<p>Do lookups, merges, enhancements…</p>
</li>
<li>
<p>…and honestly, probably 100 other creative things we haven’t even thought of yet  <img src="https://community.n8n.io/images/emoji/twitter/smiley.png?v=14" title=":smiley:" alt=":smiley:" loading="lazy" width="20" height="20"></p>
</li>
</ul>
<p><img src="https://community.n8n.io/images/emoji/twitter/backhand_index_pointing_right.png?v=14" title=":backhand_index_pointing_right:" alt=":backhand_index_pointing_right:" loading="lazy" width="20" height="20"> To make sure your instance stays performant, we’ve set a <strong>50MB limit</strong> for everyone. If you’re self-hosting (and know what you’re doing), you can change that via the ENV variable <code>N8N_DATA_TABLES_MAX_SIZE_BYTES</code></p>
<p><img src="https://community.n8n.io/images/emoji/twitter/loudspeaker.png?v=14" title=":loudspeaker:" alt=":loudspeaker:" loading="lazy" width="20" height="20"> Upgrade to <strong>1.113</strong>, give data tables a spin, and let us know what you think! What’s missing? What would make it even more useful for you? We’re really curious to hear your ideas and thoughts! <img src="https://community.n8n.io/images/emoji/twitter/blush.png?v=14" title=":blush:" alt=":blush:" loading="lazy" width="20" height="20"></p>
<p><img src="https://community.n8n.io/images/emoji/twitter/link.png?v=14" title=":link:" alt=":link:" loading="lazy" width="20" height="20"> Read more about the data tables in the docs <a href="https://docs.n8n.io/data/data-tables/?utm_campaign=data_tables_announcement_video&amp;utm_source=youtube&amp;utm_medium=youtube_description_link">here</a>.</p>
            </div>

            

          </div>
          
          <div id="post_3" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://community.n8n.io/u/dszp"><span itemprop="name">dszp</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-09-22T16:15:29Z">
                    September 22, 2025,  4:15pm
                  </time>
                  <meta itemprop="dateModified" content="2025-09-22T16:15:29Z">
              <span itemprop="position">3</span>
              </span>
            </p>
            <p>This is absolutely awesome to see, I can’t wait to use these! It’s probably been my number one frustration that saving even a small amount of data between executions for all sorts of purposes requires either integrating PostgreSQL and dealing with schemas, using a third party database or API like Supabase (as handy as they are), or using variables that are powerful but are somewhat clumsy to instantiate and track since they only work in Code nodes and only save data for production executions, making testing hard. Hoping data-tables makes a ton of these things easier! Probably won’t run the new version until it’s in final release rather than pre-release, but this is awesome to see!</p>

            

          </div>
          <div id="post_5" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://community.n8n.io/u/bartv"><span itemprop="name">bartv</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-09-22T16:16:38Z">
                    September 22, 2025,  4:16pm
                  </time>
                  <meta itemprop="dateModified" content="2025-09-22T16:16:38Z">
              <span itemprop="position">5</span>
              </span>
            </p>
            <p>This is really great - when I migrated from “the other platform” almost 4 years ago, I really felt the pain of not having a simple in-app data storage. I played around with Data tables this weekend and it’s just SUCH a good and fast experience! Kudos to our Product and Engineering teams <img src="https://community.n8n.io/images/emoji/twitter/clap.png?v=14" title=":clap:" alt=":clap:" loading="lazy" width="20" height="20"></p>

            

          </div>
          <div itemprop="comment" id="post_6" itemscope="" itemtype="http://schema.org/Comment">
              <p>Hey all,</p>
<p>IMPORTANT NOTE: There is an issue with very large SQLite databases that is causing instances to slow down. Out of an abundance of caution, we are unfortunately removing version 1.113.0 until we fix this issue. We hope to have this released again with a fix within the next couple of days.</p>
<p>Very sorry about this!</p>
            </div>
          <div itemprop="comment" id="post_8" itemscope="" itemtype="http://schema.org/Comment">
              <p>This is great!</p>
<p>It´d be cool for self hosting to be able to add a second DB, where n8n pulls the data from. So one could have performance without having to set up each time a postgres connection.</p>
            </div>
          <div id="post_10" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://community.n8n.io/u/bartv"><span itemprop="name">bartv</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-09-23T12:41:40Z">
                    September 23, 2025, 12:41pm
                  </time>
                  <meta itemprop="dateModified" content="2025-09-23T13:35:30Z">
              <span itemprop="position">10</span>
              </span>
            </p>
            <div itemprop="text">
              <p><strong>Data tables is back on!</strong></p>
<p>A patch was released earlier today. It has now been tested and we have high confidence. Please update to  1.113.1 (which is still in beta) to try this feature.</p>
            </div>

            

          </div>
          <div id="post_11" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://community.n8n.io/u/TH1"><span itemprop="name">TH1</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-09-23T14:05:53Z">
                    September 23, 2025,  2:05pm
                  </time>
                  <meta itemprop="dateModified" content="2025-09-23T14:05:53Z">
              <span itemprop="position">11</span>
              </span>
            </p>
            <p>is that Data Tables only available for the Cloud version? local host will not have Data Tables?</p>

            

          </div>
          <div id="post_12" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://community.n8n.io/u/liam"><span itemprop="name">liam</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-09-23T14:42:05Z">
                    September 23, 2025,  2:42pm
                  </time>
                  <meta itemprop="dateModified" content="2025-09-23T14:42:05Z">
              <span itemprop="position">12</span>
              </span>
            </p>
            <p>It’s on all plans (cloud and self hosted) starting on version 1.113.1 <img src="https://community.n8n.io/images/emoji/twitter/slightly_smiling_face.png?v=14" title=":slightly_smiling_face:" alt=":slightly_smiling_face:" loading="lazy" width="20" height="20"></p>

            

          </div>
          <div id="post_13" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://community.n8n.io/u/Sujit"><span itemprop="name">Sujit</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-09-23T19:00:25Z">
                    September 23, 2025,  7:00pm
                  </time>
                  <meta itemprop="dateModified" content="2025-09-23T19:00:25Z">
              <span itemprop="position">13</span>
              </span>
            </p>
            <p>I am unable to see the data tables in my local self hosted n8n. I’ve also updated the docker image to pick the latest one. What am I missing?</p>

            

          </div>
          <div id="post_14" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>Does this mean we can share data between multiple workflows now? This would make splitting up complex workflows across multiple workflows so much easier.</p>

            

          </div>
          <div id="post_15" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>I believe this is still only available in the beta version?</p>

            

          </div>
          <div id="post_16" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://community.n8n.io/u/jabbson"><span itemprop="name">jabbson</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-09-23T20:02:13Z">
                    September 23, 2025,  8:02pm
                  </time>
                  <meta itemprop="dateModified" content="2025-09-23T20:02:13Z">
              <span itemprop="position">16</span>
              </span>
            </p>
            <p>The fact that the “latest” is not “1.113.1”. The latest is “the latest stable”, where 1.113.1 is not that.</p>

            

          </div>
          <div itemprop="comment" id="post_17" itemscope="" itemtype="http://schema.org/Comment">
              <p>Very happy to see this feature. I’ve been testing it out, and was commenting feedback on Reddit but someone in the Discord server said the forums is the best place to post this instead.  Here’s my list(so far)</p>
<ol>
<li>
<p>When going to the Data Tables tab, “Create Table” is not default on the upper right button, it’s defaulted to “Create Workflow” instead.</p>
</li>
<li>
<p>Cannot change the data type after a column is created.</p>
</li>
<li>
<p>Cannot set any of the column’s as primary or unique such as the ID column (To prevent duplicates)</p>
</li>
<li>
<p>For some odd reason, setting a column data type to “number” then pushing data from JSON array into the table, physically opening the table and looking at the rows, the numbers in the “number” data type column are not all together. For example “29683389” shows in the table as “29 683 389”. This isn’t a one off either, ALL rows exhibit the same behavior and ALL columns set as “numbers” too.</p>
</li>
<li>
<p>Table page can only show 50 rows per page. Which I understand is probably for performance reasons. However, there really needs to be a “search” function for the table to search for data.</p>
</li>
</ol>
            </div>
          <div id="post_18" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>Are there any limitations for creating tables?<br>
or we can create multiples/unlimited (in 50Mb limit)?</p>

            

          </div>
          <div id="post_19" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>Love this list <a href="https://community.n8n.io/u/compaholic">@compaholic</a>, thanks so much for sharing it.<br>
1, 2 and 5 are all planned. For (4), I think that is just a highlighting to make it easier to read that it’s actually 29M. So the number should still be correct.</p>

            

          </div>
          <div id="post_20" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            
            <p>You can created unlimited ones within the storage limit <img src="https://community.n8n.io/images/emoji/twitter/slight_smile.png?v=14" title=":slight_smile:" alt=":slight_smile:" loading="lazy" width="20" height="20"></p>

            

          </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Daniel Stenberg on 22 curl bugs found by AI and fixed (348 pts)]]></title>
            <link>https://mastodon.social/@bagder/115241241075258997</link>
            <guid>45449348</guid>
            <pubDate>Thu, 02 Oct 2025 13:29:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.social/@bagder/115241241075258997">https://mastodon.social/@bagder/115241241075258997</a>, See on <a href="https://news.ycombinator.com/item?id=45449348">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Meta will listen into AI conversations to personalize ads (170 pts)]]></title>
            <link>https://www.theregister.com/2025/10/01/meta_ai_use_informs_ads/</link>
            <guid>45448839</guid>
            <pubDate>Thu, 02 Oct 2025 12:36:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/10/01/meta_ai_use_informs_ads/">https://www.theregister.com/2025/10/01/meta_ai_use_informs_ads/</a>, See on <a href="https://news.ycombinator.com/item?id=45448839">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Meta, having committed hundreds of billions to AI infrastructure and talent, says it will start using people's conversations and interactions with its AI services to create personalized content and advertising.</p>
<p>This applies to <a href="https://www.meta.ai/">Meta AI</a>, the company's web-based chat interface, and apps that integrate Meta AI, such as Facebook, Instagram, WhatsApp, and Messenger.</p>
<p>Meta intends to begin using people's text exchanges and voice conversations with its AI service to generate personalized posts, reels, and other attention lures starting on December 16, 2025.</p>

    

<p>"For example, if you chat with Meta AI about hiking, we may learn that you’re interested in hiking – just as we would if you posted a reel about hiking or liked a hiking-related Page," the company <a href="https://about.fb.com/news/2025/10/improving-your-recommendations-apps-ai-meta/">explained</a> in its announcement. "As a result, you might start seeing recommendations for hiking groups, posts from friends about trails, or ads for hiking boots."</p>

        


        

<p>A notification campaign about the change begins October 7, 2025.</p>
<p>There's no opt-out, but Meta has spared those who live in the EU, the UK, and South Korea for the time being.</p>

        

<p>The social networking giant and metaverse money-burner will let users make some adjustments to its <a href="https://about.fb.com/news/2025/09/introducing-vibes-ai-videos/">slop</a>-<a href="https://en.wikipedia.org/w/index.php?title=Force-feeding&amp;oldid=1311058453">gavage</a> loop with its <a href="https://www.facebook.com/help/109378269482053">Ads Preferences</a> and <a href="https://about.fb.com/news/2022/10/new-ways-to-customize-your-facebook-feed/">feed customization</a> controls.</p>
<p>Meta insists it won't personalize ads based on conversations that touch on religion, sexual orientation, politics, health, race, ethnicity, philosophical belief, or trade union membership.</p>
<p>That list of untouchable topics suggests canny Meta users could stymie the personalization plan by prefixing every interaction with a suitably sensitive term – for example, start every interaction with "Pray tell..." or “Oh, Lord, Meta really thought this was a good idea?”</p>
<ul>

<li><a href="https://www.theregister.com/2025/10/01/microsoft_consumer_copilot_corporate/">Microsoft declares bring your Copilot to work day, usurping IT authority</a></li>

<li><a href="https://www.theregister.com/2025/10/01/critical_red_hat_openshift_ai_bug/">'Delightful' root-access bug in Red Hat OpenShift AI allows full cluster takeover</a></li>

<li><a href="https://www.theregister.com/2025/10/01/nadella_commercial_ceo_althoff/">Nadella hands Microsoft money machine off to new commercial CEO so he can visioneer the future</a></li>

<li><a href="https://www.theregister.com/2025/01/24/meta_ai_spending/">Stargate, schmargate. We're spending $60B+ on AI this year, Meta's Zuckerberg boasts</a></li>
</ul>
<p>Known as Facebook until brand damage from incessant privacy scandals inspired <a href="https://about.fb.com/news/2021/10/facebook-company-is-now-meta/">a name change in 2021</a>, Meta was notionally focused on the metaverse – an ill-defined term for immersive digital experiences that may or may not involve goggles. Having spent something like <a href="https://www.theregister.com/2025/05/01/metas_metaverse_mention/">$60 billion on its Reality Labs group</a> without much to show for it (apart from the privacy-invading Meta Ray-Ban Display glasses), Meta lately has taken to talking up AI.</p>
<p>CEO Mark Zuckerberg last month told President Trump that Meta plans to invest $600 billion on AI investment through 2028 – and surely that will happen because Zuckerberg <a href="https://www.threads.com/@zuck/post/DORJoYgkXUH?xmt=AQF0CNIpSRsk_HIXDmfYchDE46PSmeeKhR344m0c25Bl-A">said it</a>, even if other massive AI spending projects like Stargate’s <a href="https://www.wsj.com/tech/ai/softbank-openai-a3dc57b4">promised $500 billion AI infrastructure investments</a> don’t quite add up.</p>

        

<p>Meta's interest in AI, however, is really about ads – using AI to encourage exposure to and engagement with ads, some of which may be generated by AI. The company has already <a target="_blank" href="https://www.theregister.com/2025/08/01/meta_ai_investments/">said</a> AI has helped boost engagement with ads posted to its platforms. Execs also see AI as making it easier to advertisers to create and manage campaigns.</p>
<p>As noted by the UK's Open Rights Group, 98 percent of Meta’s <a href="https://investor.atmeta.com/investor-news/press-release-details/2025/Meta-Reports-Fourth-Quarter-and-Full-Year-2024-Results/">$165 billion of revenue in 2024</a> came from advertising, resulting in net income of $62.4 billion.</p>
<p>Iesha White, director of intelligence for marketing watchdog Check My Ads, told <em>The Register</em> in an email that several AI companies like Perplexity and OpenAI have integrated advertising into their AI products.</p>
<p>"But this is different – Meta’s core business is monetizing ad space across its owned and operated sites and apps, in addition to ad placements on external publisher partnerships via its Facebook Audience Network product," said White. "By harvesting data from its AI chats across WhatsApp, Instagram, and Facebook, Meta gains yet another closed-loop data source, meaning Meta could reduce transparency of the targeting inputs across its advertising products, in the name of privacy.</p>
<p>"It also provides an opportunity for Meta to further shape and obfuscate its attribution models using its own source of truth, with brands unable to independently audit a campaign’s true effectiveness."</p>
<p>Meta coincidentally is fighting a <a target="_blank" rel="nofollow" href="https://searchengineland.com/supreme-court-meta-ad-fraud-case-proceed-450504">$7 billion class action</a> <a href="https://cdn.ca9.uscourts.gov/datastore/opinions/2024/03/21/22-15916.pdf">lawsuit</a> [PDF] brought by advertisers who claim that Meta fraudulently represented the potential reach of its ads by citing user accounts rather than actual people – a charge Meta disputes. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU funds are flowing into spyware companies and politicians demanding answers (195 pts)]]></title>
            <link>https://www.theregister.com/2025/10/02/eu_spyware_funding/</link>
            <guid>45448825</guid>
            <pubDate>Thu, 02 Oct 2025 12:34:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/10/02/eu_spyware_funding/">https://www.theregister.com/2025/10/02/eu_spyware_funding/</a>, See on <a href="https://news.ycombinator.com/item?id=45448825">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>An arsenal of angry European Parliament members (MEPs) is demanding answers from senior commissioners about why EU subsidies are ending up in the pockets of spyware companies.</p>
<p>The group of 39 politicians referred to recent investigations that revealed countries such as Italy, Greece, Hungary, and Spain have funnelled millions of taxpayer euros at a time to help support commercial spyware-makers' finances.</p>
<p>They wrote: "According to these findings, entities such as Intellexa, Cy4Gate, Verint and Cognyte – whose technologies have been linked to unlawful surveillance of journalists, human rights defenders and political actors in the EU, as well as in third countries with dreadful human rights records – have benefitted from public financing, including EU programmes.</p>

    

<p>"This raises serious questions about the governance, transparency, and accountability of the Union's funding mechanisms. In the light of the scandals uncovered in Italy, Greece, Poland, Hungary, and Spain, among others, and of the recommendations of the PEGA inquiry, it is deeply troubling that the Union is directly or indirectly enabling tools that erode democracy, fundamental rights, and the rule of law."</p>

        


        

<p>MEPs cited investigative journalism from <a href="https://www.ftm.eu/articles/spyware-industry-eu-subsidies-surveillance-concers" rel="nofollow">Follow The Money</a>, which revealed in September that institutions such as Spain's public-funded Centre for the Development Of Industrial Technology (CDTI) handed over €1.3 million (c $1.5 million) to now-shuttered spyware peddler Mollitiam Industries.</p>

<p>Likewise, Italy's state-owned bank, <a target="_blank" href="https://youreurope.europa.eu/business/finance-funding/getting-funding/access-finance/en/content/mediocredito-centrale-spa">Mediocredito Centrale</a>, was found to have acted as a guarantor to a €2.5 million (c $2.9 million) loan to Dataflow Security, an Italy-based commercial spyware developer.</p>
<p>FTM said that it did not prove that any of the money, in any of the cases it found, was used to directly fund spyware development, although funding was provided in several instances.</p>
<p>The <a href="https://x.com/HNeumannMEP/status/1973321519548997804/photo/1" rel="nofollow">letter</a> addressed to senior commissioners Henna Virkkunen (Finland), Michael McGrath (Ireland), and Piotr Serafin (Poland) – who oversee tech, justice, and anti-fraud respectively – requested greater transparency over how EU funds were distributed, among other matters.</p>

        

<p>Various questions were raised by the MEPs, such as how the European Commission verifies the integrity of the entities that receive EU funds, whether any risk assessments are carried out before investments are made to spyware companies, and how much money in total has been awarded to these organizations.</p>
<p>They also asked for answers on how the Commission plans to ensure its funding mechanisms align with its stances on matters such as human rights and digital resilience, and why it has not implemented the recommendations made by the <a href="https://www.theregister.com/2023/05/09/pega_commitee_report/">PEGA inquiry</a>.</p>
<p><em>The Register</em> approached the European Commission for a response to the letter.</p>

        

<p>For the uninitiated, the PEGA inquiry was launched in 2022 following reports of several EU governments using <a href="https://www.theregister.com/2024/09/19/pegasus_spyware_met_police_complaint/">NSO Group's Pegasus spyware</a> a year earlier, and three years after Saudi journalist <a href="https://www.theregister.com/2021/03/01/in_brief_security/">Jamal Khashoggi's murder</a>.</p>
<p>The results were published in 2023, branding the pervasive spyware use "Europe's Watergate" and a "severe violation of all the values of the European Union."</p>
<p>The <a href="https://www.europarl.europa.eu/doceo/document/A-9-2023-0189_EN.html#_section2" rel="nofollow">report</a> stated: "The spyware scandal is not a series of isolated national cases of abuse, but a full-blown European affair.&nbsp;</p>
<p>"EU Member State governments have been using spyware on their citizens for political purposes and to cover up corruption and criminal activity. Some went even further and embedded spyware in a system deliberately designed for authoritarian rule."</p>
<p>Among the main recommendations made by the PEGA committee were to restrict law enforcement's use of spyware only to exceptional cases, protect sensitive targets like politicians, lawyers, and doctors, and to set the conditions for legal use.</p>
<p>The 39 MEPs asked the European Commission to additionally commit to launching an immediate public review of EU subsidies flowing into spyware companies.</p>
<p>In that review, the politicians specifically requested details on all funds issued and awarded to spyware companies since 2015, a commitment to excluding all spyware vendors from future EU funding instruments, and a follow-up on the PEGA recommendations.</p>
<p>"Citizens of the Union have the right to know whether their taxes are being used to finance technologies that endanger their fundamental rights," they wrote.&nbsp;</p>
<ul>

<li><a href="https://www.theregister.com/2025/09/25/lazarus_group_shares_malware_with_it_scammers/">North Korea's Lazarus Group shares its malware with IT work scammers</a></li>

<li><a href="https://www.theregister.com/2025/09/18/google_emergency_patch_chrome_0_day/">Google pushes emergency patch for Chrome 0-day – check your browser version now</a></li>

<li><a href="https://www.theregister.com/2025/09/11/us_surveillanceware_investment/">We're number 1! America now leads the world in surveillanceware investment</a></li>

<li><a href="https://www.theregister.com/2025/09/02/commercial_surveillanceware_safe/">Who watches the watchmen? Surveillanceware firms make bank, avoid oversight</a></li>
</ul>
<p>"As Members of the European Parliament, we expect your full cooperation in ensuring accountability and restoring public trust."</p>
<p>Rebecca White, researcher and advisor on targeted surveillance at Amnesty Tech's Security Lab, said she and Amnesty support the letter, and highlighted the Commission's lack of communication on the matter.</p>
<p>She told <em>The Register</em>: "At Amnesty, we've documented for many years how spyware has enabled human rights abuses in Europe and beyond, and how the surveillance industry is under-regulated and thriving.</p>
<p>"The European Commission has remained silent. These latest allegations should alarm all of us.&nbsp;</p>
<p>"They suggest that not only is the EU failing to put out the fire, they're fanning the flames. We welcome this collective call for transparency and explanations – the Commission can no longer wash its hands of Europe's complicity in the spyware crisis, which is fuelling human rights abuses across the world."</p>
<p>Aljosa Ajanovic Andelic, policy advisor at European Digital Rights (EDRi), echoed the MEPs' request for a ban on spyware.</p>
<p>He said: "The lack of action by the Commission when it comes to spyware is appalling and dangerous. In fact, not only have they not done anything to stop the proliferation of shady spyware vendors in the EU, they actually used EU taxpayers' money to directly fund the industry. This has to stop, and we are calling for a full ban on commercial spyware in the EU."</p>
<p>"As the largest digital rights network in Europe, our position is firm: the use of spyware is inherently incompatible with fundamental rights, and therefore should be banned, as well as the market of private companies that are profiting from human rights violations." ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Red Hat confirms security incident after hackers claim GitHub breach (213 pts)]]></title>
            <link>https://www.bleepingcomputer.com/news/security/red-hat-confirms-security-incident-after-hackers-claim-github-breach/</link>
            <guid>45448772</guid>
            <pubDate>Thu, 02 Oct 2025 12:28:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bleepingcomputer.com/news/security/red-hat-confirms-security-incident-after-hackers-claim-github-breach/">https://www.bleepingcomputer.com/news/security/red-hat-confirms-security-incident-after-hackers-claim-github-breach/</a>, See on <a href="https://news.ycombinator.com/item?id=45448772">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	   
<p><img alt="Red Hat logo" height="900" src="https://www.bleepstatic.com/content/hl-images/2025/10/02/redhat-header-vign.jpg" width="1600"></p>

<p>An extortion group calling itself the Crimson Collective claims to have breached Red Hat's private GitHub repositories, stealing nearly 570GB of compressed data across 28,000 internal projects.</p>

<p>This data allegedly includes approximately 800 Customer Engagement Reports (CERs), which can contain sensitive information about a customer's network and platforms.</p>

<p>A CER is a&nbsp;consulting document prepared for clients that often contains infrastructure details, configuration data, authentication tokens, and other information that could be abused to breach customer networks.</p>

<p>Red Hat confirmed that it suffered a security incident related to its consulting business,&nbsp;but would not verify any of the attacker's claims regarding the stolen GitHub repositories and customer CERs.</p>

<p>"Red Hat is aware of reports regarding a security incident related to our consulting business and we have initiated necessary remediation steps," Red Hat told BleepingComputer.</p>

<p>"The security and integrity of our systems and the data entrusted to us are our highest priority. At this time, we have no reason to believe the security issue impacts any of our other Red Hat services or products and are highly confident in the integrity of our software supply chain."</p>

<p>While Red Hat did not respond to any further questions about the breach, the hackers told BleepingComputer that the intrusion occurred approximately two weeks ago.</p>

<p>They allegedly found authentication tokens, full database URIs, and other private information in Red Hat code and CERs, which they claimed to use to gain access to downstream customer infrastructure.</p>

<p>The hacking group also published a complete directory listing of the allegedly stolen GitHub repositories&nbsp;and a list of CERs from 2020 through 2025 on Telegram.</p>

<p>The directory listing of CERs include a wide range of sectors and well known organizations such as Bank of America, T-Mobile, AT&amp;T, Fidelity, Kaiser, Mayo Clinic, Walmart, Costco,&nbsp;the U.S. Navy’s Naval Surface Warfare Center, Federal Aviation Administration, the House of Representatives, and many others.</p>

<p>If you have any information regarding this incident or any other undisclosed attacks, you can contact us confidentially via Signal at 646-961-3731 or at tips@bleepingcomputer.com.</p>

<p>The hackers stated that they attempted to contact Red Hat with an extortion demand but received no response other than a templated reply instructing them to submit a vulnerability report to their security team.</p>

<p>According to them, the created ticket was repeatedly assigned to additional people, including Red Hat's legal and security staff members.</p>

<p>BleepingComputer sent Red Hat additional questions, and we will update this story if we receive more information.</p>

<p>The same group also claimed responsibility for briefly <a href="http://x.com/pirat_nation/status/1970821013559538141" target="_blank" rel="nofollow noopener">defacing Nintendo’s topic page</a> last week to include contact information and links to their Telegram channel</p>

	   


<div>
    <p><a href="https://hubs.li/Q03LvVKm0" target="_blank" rel="noopener sponsored">
            <img src="https://www.bleepstatic.com/c/p/picus/bas-summit.jpg" alt="Picus BAS Summit">
        </a>
    </p>
    <div>
        <h2><a href="https://hubs.li/Q03LvVKm0" target="_blank" rel="noopener sponsored">The Security Validation Event of the Year: The Picus BAS Summit </a></h2>
<p>Join the <strong>Breach and Attack Simulation Summit</strong> and experience the <strong>future of security validation</strong>. Hear from top experts and see how <strong>AI-powered BAS</strong> is transforming breach and attack simulation.</p>
<p>Don't miss the event that will shape the future of your security strategy</p>
        </div>
</div>

           
          
 
	  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NL Judge: Meta must respect user's choice of recommendation system (288 pts)]]></title>
            <link>https://www.bitsoffreedom.nl/2025/10/02/judge-in-the-bits-of-freedom-vs-meta-lawsuit-meta-must-respect-users-choice/</link>
            <guid>45448326</guid>
            <pubDate>Thu, 02 Oct 2025 11:32:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bitsoffreedom.nl/2025/10/02/judge-in-the-bits-of-freedom-vs-meta-lawsuit-meta-must-respect-users-choice/">https://www.bitsoffreedom.nl/2025/10/02/judge-in-the-bits-of-freedom-vs-meta-lawsuit-meta-must-respect-users-choice/</a>, See on <a href="https://news.ycombinator.com/item?id=45448326">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<article id="post-57096">
							
			
			
			<div>
									<div>
								<ul>
									<li>
										02 oktober 2025									</li>
																	</ul>
							</div>
				
				
				

	<div>
			<h3>
				<p><strong>Today the judge issued a ruling in the summary proceedings brought by digital human rights organisation Bits of Freedom against Meta. The organisation demanded that Meta gives its users on apps such as Instagram and Facebook the option to select a feed that is not based on profiling.</strong></p>
			</h3>
		</div>

	<div>
								
									<div>
						<p><img width="150" height="150" src="https://www.bitsoffreedom.nl/wp-content/uploads/2017/03/evelyn-austin-juri-hiensch-150x150.jpg" alt="" decoding="async" srcset="https://www.bitsoffreedom.nl/wp-content/uploads/2017/03/evelyn-austin-juri-hiensch-150x150.jpg 150w, https://www.bitsoffreedom.nl/wp-content/uploads/2017/03/evelyn-austin-juri-hiensch-478x478.jpg 478w, https://www.bitsoffreedom.nl/wp-content/uploads/2017/03/evelyn-austin-juri-hiensch-100x100.jpg 100w" sizes="(max-width: 150px) 100vw, 150px" data-srcset="https://www.bitsoffreedom.nl/wp-content/uploads/2017/03/evelyn-austin-juri-hiensch-150x150.jpg 150w, https://www.bitsoffreedom.nl/wp-content/uploads/2017/03/evelyn-austin-juri-hiensch-478x478.jpg 478w, https://www.bitsoffreedom.nl/wp-content/uploads/2017/03/evelyn-austin-juri-hiensch-100x100.jpg 100w" data-src="https://www.bitsoffreedom.nl/wp-content/uploads/2017/03/evelyn-austin-juri-hiensch-150x150.jpg"></p>
					</div>
									<div>
						<p><img width="150" height="150" src="https://www.bitsoffreedom.nl/wp-content/uploads/2023/10/maartje-foto-website-150x150.png" alt="" decoding="async" srcset="https://www.bitsoffreedom.nl/wp-content/uploads/2023/10/maartje-foto-website-150x150.png 150w, https://www.bitsoffreedom.nl/wp-content/uploads/2023/10/maartje-foto-website-478x478.png 478w, https://www.bitsoffreedom.nl/wp-content/uploads/2023/10/maartje-foto-website-100x100.png 100w" sizes="(max-width: 150px) 100vw, 150px" data-srcset="https://www.bitsoffreedom.nl/wp-content/uploads/2023/10/maartje-foto-website-150x150.png 150w, https://www.bitsoffreedom.nl/wp-content/uploads/2023/10/maartje-foto-website-478x478.png 478w, https://www.bitsoffreedom.nl/wp-content/uploads/2023/10/maartje-foto-website-100x100.png 100w" data-src="https://www.bitsoffreedom.nl/wp-content/uploads/2023/10/maartje-foto-website-150x150.png"></p>
					</div>
						</div>



<div>
				<p>Bits of Freedom sued Meta for a breach of the Digital Services Act (DSA). This European legislation is intended to give users more autonomy and control over the major online platforms. One of the core elements of the DSA is that users must have greater influence over the information they see.</p>
<p>For many people, and especially for young people, social media platforms are a major source of news and information. Therefore it is crucial that users themselves can decide which content appears on their feed. Without that freedom of choice, participation in the public debate is seriously hampered. That is problematic at any time, but especially so during election periods. In the Netherlands, national elections will be held at the end of this month.</p>
<p>The judge states that Meta is indeed acting in violation of the law. He says that “a non‑persistent choice option for a recommendation system runs counter to the purpose of the DSA, which is to give users genuine autonomy, freedom of choice, and control over how information is presented to them.” The judge also concludes that the way Meta has designed its platforms constitutes “a significant disruption of the autonomy of Facebook and Instagram users.” The judge orders Meta to adjust its apps so that the user’s choice is preserved, even when the user navigates to another section or restarts the app.</p>
<blockquote><p>“We are pleased that the judge now makes clear that Meta must respect the user’s choice,” says Maartje Knaap, spokesperson for Bits of Freedom. “It is absolutely unacceptable that a handful of American tech billionaires determine how we see the world. That concentration of power poses a risk to our democracy. At the same time, it is regrettable that we need to go to court to ensure Meta complies with the law.”</p></blockquote>
<p>Meta has an interest in steering users toward a feed where it can show as many interest‑ and behavior‑based ads as possible. That is the core of Meta’s revenue model. Subtle design techniques push users toward that feed, while the non‑profiled feed is hidden behind a logo, making it hard to find. Users who do choose the alternative timeline also lose direct access to features such as Direct Messages. Moreover, when you open the app, it always starts with Meta’s feed, even if the user selected a different one before. Because of the judge’s ruling, Meta must change its behavior.</p>
<blockquote><p>“This ruling shows that Meta is not untouchable,” continues Maartje Knaap. “But we are also realistic, this is just a drop in the ocean. There’s still a long way to go. We hope the decision will inspire individuals, civil society organisations, regulators and lawmakers worldwide around the world who are working to rein in Meta’s power. Together we can stand up to a company that has become overwhelmingly powerful.”</p></blockquote>
<p>You can find the ruling <a href="https://www.bitsoffreedom.nl/wp-content/uploads/2025/10/20251002-vonnis-kort-geding.pdf" data-cke-saved-href="https://www.bitsoffreedom.nl/wp-content/uploads/2025/10/20251002-vonnis-kort-geding.pdf">here</a> (in Dutch).</p>
	</div>

				
									
				
				
		
	</div>
	</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How the AI Bubble Will Pop (191 pts)]]></title>
            <link>https://www.derekthompson.org/p/this-is-how-the-ai-bubble-will-pop</link>
            <guid>45448199</guid>
            <pubDate>Thu, 02 Oct 2025 11:05:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.derekthompson.org/p/this-is-how-the-ai-bubble-will-pop">https://www.derekthompson.org/p/this-is-how-the-ai-bubble-will-pop</a>, See on <a href="https://news.ycombinator.com/item?id=45448199">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Some people think artificial intelligence will be the most important technology of the 21st century. Others insist that it is an obvious economic bubble. I believe both sides are right. Like the 19th century railroads and the 20th century broadband Internet build-out, AI will rise first, crash second, and eventually change the world. </p><p><span>The numbers just don’t make sense. Tech companies are projected to spend about $400 billion this year on infrastructure to train and operate AI models. By nominal dollar sums, that is more than any group of firms has ever spent to do just about anything. The Apollo program allocated about $300 billion in inflation-adjusted dollars to get America to the moon between the early 1960s and the early 1970s. The AI buildout requires companies to collectively fund a new Apollo program, not every 10 years, but </span><em>every 10 months.</em></p><p><span>It’s not clear that firms are prepared to earn back the investment, and yet by their own testimony, they’re just going to keep spending, anyway. Total AI capital expenditures in the U.S. are projected to exceed $500 billion in 2026 and 2027—roughly the annual GDP of Singapore. But the </span><em>Wall Street Journal</em><span> has reported that American consumers spend only $12 billion a year on AI services. That’s roughly the GDP of Somalia. If you can grok the economic difference between Singapore and Somalia, you get a sense of the economic chasm between vision and reality in AI-Land. Some reports </span><a href="https://futurism.com/ai-hype-automation-decline#:~:text=Artificial%20intelligence%20might%20be%20booming,began%20in%20November%20of%202023." rel="">indicate</a><span> that AI usage is actually declining at large companies that are still trying to figure out how large language models can save them money.</span></p><p><span>Every financial bubble has moments where, looking back, one thinks: </span><em>How did any sentient person miss the signs?</em><span> Today’s omens abound. Thinking Machines, an AI startup helmed by former Open AI executive Mira Murati, just raised the largest seed round in history: $2 billion in funding at a $10 billion valuation. The company has not released a product and has refused to tell investors what they’re even trying to build. “It was the most absurd pitch meeting,” one investor who met with Murati </span><a href="https://www.bloomberg.com/opinion/newsletters/2025-09-29/the-perfect-ai-startup" rel="">said</a><span>. “She was like, ‘So we’re doing an AI company with the best AI people, but we can’t answer any questions.” Meanwhile, a recent analysis of stock market trends found that </span><a href="https://x.com/modestproposal1/status/1973045734401282343" rel="">none of the typical rules for sensible investing</a><span> can explain what’s going on with stock prices right now. Whereas equity prices have historically followed earnings fundamentals, today’s market is driven overwhelmingly by momentum, as retail investors pile into meme stocks and AI companies because they think everybody else is piling into meme stocks and AI companies.</span></p><p><span>Every economic bubble also has tell-tale signs of financial over-engineering, like the collateralized debt obligations and subprime mortgage-backed securities that blew up during the mid-2000s housing bubble. Ominously, AI appears to be entering its own phase of financial wizardry. As the </span><em>Economist</em><span> has pointed out, the AI hyperscalers—that is, the largest spenders on AI—are </span><a href="https://www.economist.com/business/2025/09/18/the-4trn-accounting-puzzle-at-the-heart-of-the-ai-cloud" rel="">using accounting tricks</a><span> to depress their reported infrastructure spending, which has the effect of inflating their profits</span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-174944187" href="https://www.derekthompson.org/p/this-is-how-the-ai-bubble-will-pop#footnote-1-174944187" target="_self" rel="">1</a><span>. As the investor and author </span><a href="https://paulkedrosky.com/" rel="">Paul Kedrosky</a><span> told me on my podcast </span><em><a href="https://podcasts.apple.com/us/podcast/plain-english-with-derek-thompson/id1594471023" rel="">Plain English</a></em><span>, the big AI firms are also shifting huge amounts of AI spending off their books into SPVs, or special purpose vehicles, that disguise the cost of the AI build-out. </span></p><p>My interview with Kedrosky received the most enthusiastic and complimentary feedback of any show I’ve done in a while. His level of insight-per-minute was off the charts, touching on:</p><ul><li><p><strong>How AI capital expenditures break down</strong></p></li><li><p><strong>Why the AI build-out is different from past infrastructure projects, like the railroad and dot-com build-outs</strong></p></li><li><p><strong>How AI spending is creating a black hole of capital that’s sucking resources away from other parts of the economy</strong></p></li><li><p><strong>How ordinary investors might be able to sense the popping of the bubble just before it happens</strong></p></li><li><p><strong>Why the entire financial system is balancing on big chip-makers like Nvidia</strong></p></li><li><p><strong>If the bubble pops, what surprising industries will face a reckoning</strong></p></li></ul><p>Below is a polished transcript of our conversation, organized by topic area and adorned with charts and graphs to visualize his points. I hope you learn as much from his commentary as much as I did. From a sheer economic perspective, I don’t think there’s a more important story in the world.</p><p><strong>Derek Thompson:</strong><span> How big is the AI infrastructure build-out?</span></p><p><strong>Paul Kedrosky:</strong><span> There’s a huge amount of money being deployed and it’s going to a very narrow set of recipients and some really small geographies, like Northern Virginia. So it’s an incredibly concentrated pool of capital that’s also large enough to affect GDP. I did the math and found out that in the first half of this year, the data-center related spending—these giant buildings full of GPUs [graphical processing units] and racks and servers that are used by the large AI firms to generate responses and train models—probably accounted for half of GDP growth in the first half of the year. Which is absolutely bananas. This spending is huge.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!ClnP!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8b22759-21ee-4b1a-afcc-9d1bfd53c11d_707x484.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ClnP!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8b22759-21ee-4b1a-afcc-9d1bfd53c11d_707x484.png 424w, https://substackcdn.com/image/fetch/$s_!ClnP!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8b22759-21ee-4b1a-afcc-9d1bfd53c11d_707x484.png 848w, https://substackcdn.com/image/fetch/$s_!ClnP!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8b22759-21ee-4b1a-afcc-9d1bfd53c11d_707x484.png 1272w, https://substackcdn.com/image/fetch/$s_!ClnP!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8b22759-21ee-4b1a-afcc-9d1bfd53c11d_707x484.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!ClnP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8b22759-21ee-4b1a-afcc-9d1bfd53c11d_707x484.png" width="707" height="484" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c8b22759-21ee-4b1a-afcc-9d1bfd53c11d_707x484.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:484,&quot;width&quot;:707,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:141165,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.derekthompson.org/i/174944187?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8b22759-21ee-4b1a-afcc-9d1bfd53c11d_707x484.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!ClnP!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8b22759-21ee-4b1a-afcc-9d1bfd53c11d_707x484.png 424w, https://substackcdn.com/image/fetch/$s_!ClnP!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8b22759-21ee-4b1a-afcc-9d1bfd53c11d_707x484.png 848w, https://substackcdn.com/image/fetch/$s_!ClnP!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8b22759-21ee-4b1a-afcc-9d1bfd53c11d_707x484.png 1272w, https://substackcdn.com/image/fetch/$s_!ClnP!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8b22759-21ee-4b1a-afcc-9d1bfd53c11d_707x484.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>JP Morgan chart showing the rising contribution to GDP growth from tech capex</figcaption></figure></div><p><strong>Thompson:</strong><span> Where is all this money going?</span></p><p><strong>Kedrosky:</strong><span> For the biggest companies—Meta and Google and Amazon—a little more than half the cost of a data center is the GPU chips that are going in. About 60 percent. The rest is a combination of cooling and energy. And then a relatively small component is the actual construction of the data center: the frame of the building, the concrete pad, the real estate.</span></p><p><strong>Thompson:</strong><span> How do you see AI spending already warping the 2025 economy?</span></p><p><strong>Kedrosky</strong><span>: Looking back, the analogy I draw is this: massive capital spending in one narrow slice of the economy during the 1990s caused a diversion of capital away from manufacturing in the United States. This starved small manufacturers of capital and made it difficult for them to raise money cheaply. Their cost of capital increased, meaning their margins had to be higher. During that time, China had entered the World Trade Organization and tariffs were dropping. We’ve made it very difficult for domestic manufacturers to compete against China, in large part because of the rising cost of capital. It all got sucked into this “death star” of telecom.</span></p><p>So in a weird way, we can trace some of the loss of manufacturing jobs in the 1990s to what happened in telecom because it was the great sucking sound that sucked all the capital out of everywhere else in the economy.</p><p>The exact same thing is happening now. If I’m a large private equity firm, there is no reward for spending money anywhere else but in data centers. So it’s the same phenomenon. If I’m a small manufacturer and I’m hoping to benefit from the on-shoring of manufacturing as a result of tariffs, I go out trying to raise money with that as my thesis. The hurdle rate just got a lot higher, meaning that I have to generate much higher returns because they’re comparing me to this other part of the economy that will accept giant amounts of money. And it looks like the returns are going to be tremendous because look at what’s happening in AI and the massive uptake of OpenAI. So I end up inadvertently starving a huge slice of the economy yet again, much like what we did in the 1990s.</p><p><strong>Thompson: </strong><span>That’s so interesting. The story I’m used to telling about manufacturing is that China took our jobs. “The China shock,” as economists like David Autor call it, essentially took manufacturing to China and production in Shenzhen replaced production in Ohio, and that’s what hollowed out the Rust Belt. You’re adding that telecom absorbed the capital. </span></p><p>And now you fast-forward to the 2020s. Trump is trying to reverse the China shock with the tariffs. But we’re recreating the capital shock with AI as the new telecom, the new death star that’s taking capital that might at the margin go to manufacturing.</p><p><strong>Kedrosky:</strong><span> It’s even more insidious than that. Let’s say you’re Derek’s Giant Private Equity Firm and you control $500 billion. You do not want to allocate that money one $5 million check at a time to a bunch of manufacturers. All I see is a nightmare of having to keep track of all of these little companies doing who knows what.</span></p><p>What I’d like to do is to write 30 separate $50 billion checks. I’d like to write a small number of huge checks. And this is a dynamic in private equity that people don’t understand. Capital can be allocated in lots of different ways, but the partners at these firms do not want to write a bunch of small checks to a bunch of small manufacturers, even if the hurdle rate is competitive. I’m a human, I don’t want to sit on 40 boards. And so you have this other perverse dynamic that even if everything else is equal, it’s not equal. So we’ve put manufacturers who might otherwise benefit from the onshoring phenomenon at an even worse position in part because of the internal dynamics of capital.</p><p><strong>Thompson</strong><span>: What about the energy piece of this? Electricity prices rising. Data centers are incredibly energy thirsty. I think consumers will revolt against the construction of local data centers, but the data centers have enormous political power of their own. How is this going to play out?</span></p><p><strong>Kedrosky</strong><span>: So I think you’re going to rapidly see an offshoring of data centers. That will be the response. It’ll increasingly be that it’s happening in India, it’s happening in the Middle East, where massive allocations are being made to new data centers. It’s happening all over the world. The focus will be to move offshore for exactly this reason. Bloomberg had a great story the other day about an exurb in Northern Virginia that’s essentially surrounded now by data centers. This was previously a rural area and everything around them, all the farms sold out, and people in this area were like, wait a minute, who do I sue? I never signed up for this. This is the beginnings of the NIMBY phenomenon because it’s become visceral and emotional for people. It’s not just about prices. It’s also about: If you’ve got a six acre building beside you that’s making noise all the time, that is not what you signed up for.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Israeli actions caused famine, visualized (629 pts)]]></title>
            <link>https://www.cnn.com/2025/10/02/middleeast/gaza-famine-causes-vis-intl</link>
            <guid>45447699</guid>
            <pubDate>Thu, 02 Oct 2025 09:23:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2025/10/02/middleeast/gaza-famine-causes-vis-intl">https://www.cnn.com/2025/10/02/middleeast/gaza-famine-causes-vis-intl</a>, See on <a href="https://news.ycombinator.com/item?id=45447699">Hacker News</a></p>
Couldn't get https://www.cnn.com/2025/10/02/middleeast/gaza-famine-causes-vis-intl: Error: Request failed with status code 451]]></description>
        </item>
        <item>
            <title><![CDATA[Asked to do something illegal at work? Here's what these software engineers did (146 pts)]]></title>
            <link>https://blog.pragmaticengineer.com/asked-to-do-something-illegal-at-work/</link>
            <guid>45447536</guid>
            <pubDate>Thu, 02 Oct 2025 08:51:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.pragmaticengineer.com/asked-to-do-something-illegal-at-work/">https://blog.pragmaticengineer.com/asked-to-do-something-illegal-at-work/</a>, See on <a href="https://news.ycombinator.com/item?id=45447536">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section id="content">
            <p><em>Update on 2 Oct 2025: back in 2021, Charlie Javice, CEO of student loan startup Frank pressured a software engineer to inflate customer numbers. She told the engineer that she did not believe that anyone would end up in an ‘orange jumpsuit’ just for this. Still, the engineer refused – and was proven right. Javice, in fact, did end up in an orange jumpsuit, </em><a href="https://www.justice.gov/usao-sdny/pr/startup-ceo-charlie-javice-sentenced-85-months-prison-175-million-fraud?ref=blog.pragmaticengineer.com" rel="noreferrer"><em>sentenced</em></a><em> to 7 years of prison in 2025 for fraud.</em></p><hr><p><em>The below topic was sent out to full subscribers of </em><a href="https://newsletter.pragmaticengineer.com/about?ref=blog.pragmaticengineer.com" rel="noreferrer"><em>The Pragmatic Engineer</em></a><em>, three weeks ago, in </em><a href="https://newsletter.pragmaticengineer.com/p/the-pulse-66?ref=blog.pragmaticengineer.com" rel="noopener noreferrer nofollow"><em>The Pulse #66</em></a><em>. I have received several messages from people asking if they can pay to “unlock” this information for others, given how vital it is for software engineers. It is vital, and so I’m sharing this with all readers, without a paywall. In the unlikely case that you are asked to do something fishy or illegal: I hope the below will help decide how to do the right thing. </em></p><p><a href="https://newsletter.pragmaticengineer.com/about?ref=blog.pragmaticengineer.com" rel="noreferrer"><strong><em>Sign up to The Pragmatic Engineer</em></strong></a><em> to get articles like this earlier in your inbox. It's a pretty good read, and the </em><a href="https://substack.com/top/technology?ref=blog.pragmaticengineer.com" rel="noreferrer"><em>#1 tech publication</em></a><em> on Substack.</em></p><p>What would you do if you learned your company is up to something illegal like stealing customer funds, or you’re asked to make code changes that will enable something illegal to happen, like misleading investors, or defrauding customers? Here are three real-life cases, where what engineers and engineering managers did had serious consequences.</p><h4 id="ftx-an-engineering-director-went-along-with-the-fraud">FTX: an engineering director went along with the fraud</h4><p>A trial related to FTX, the cryptocurrency exchange which allegedly defrauded investors of $9B, is ongoing. Day 9 of the trial of former FTX CEO Sam Bankman-Fried trial, heard testimony from Nishad Singh, who joined the business as a software engineer, and later became an engineering director. Here is software engineer and writer Molly White <a href="https://newsletter.mollywhite.net/p/the-ftx-trial-day-nine-nishad-singh?ref=blog.pragmaticengineer.com" rel="noopener noreferrer nofollow">summarizes of his evidence</a>:</p><div><p>“To hear Singh tell it, he didn’t even really realize what was going on at FTX and Alameda Research until September 2022 — only a month or two before everything came crashing down. (...) Several times throughout various testimonies, we’ve seen a document written by Sam Bankman-Fried, in which he describes his thinking that Alameda Research should be shut down. That document was, ultimately, how Singh learned in September 2022 that Alameda Research had taken billions of dollars of customer funds from FTX.&nbsp;</p><p>This was when Gary Wang told Singh that Alameda was borrowing massive amounts of customer money from FTX — at the time, around $13 billion of it. Singh testified that he felt ‘really afraid’, and called an in-person meeting immediately. Bankman-Fried, who was sitting next to Singh at the time, ‘seemed unsurprised and made up what I understood to be a false excuse for dodging the meeting.’ Singh, Ellison, and Wang met without him, and Singh confirmed his fears: that he had not misunderstood Wang, and that Alameda had actually taken customer funds to that extent.”</p></div><p>Okay, so in September 2022, Singh had confirmation that something illegal was happening at the company, which he had no direct knowledge of, <em>until then</em>. At that point, if he wanted to avoid being an accomplice to potentially illegal activity, his options were:</p><ol><li>Talk to a lawyer on how to avoid assisting a crime</li><li>Turn whistleblower. See the <a href="https://thesignalsnetwork.org/twh/?ref=blog.pragmaticengineer.com" rel="noopener noreferrer nofollow">tech whistleblower guide</a></li><li>Quit the company, ensuring he did not further aid this activity&nbsp;</li></ol><p>The smart thing would have been to do #1. The profitable thing could have been to do #2 because in the US, a whistleblower may receive a <a href="https://www.phillipsandcohen.com/whistleblower-rewards?ref=blog.pragmaticengineer.com" rel="noopener noreferrer nofollow">whistleblower reward</a> of between 10-30% of what the government recovers from fraudulent activities. The final choice #3 is hard, but could have meant Singh would not have had to plead guilty as he did.&nbsp;</p><p>Here’s what Singh did instead: he asked for a personal meeting with Bankman-Fried and confronted him about the missing funds. However, Bankman-Fried replied there not much to worry about, and that they’d repay the funds by raising more money from investors (!!) This should have been the point at which Singh quit. Instead:</p><blockquote>“He thought about leaving the company then, he testified, but worried that his departure could cause everything to fall apart. He felt that if he stayed, maybe he could help the companies make back what they owed.”</blockquote><p>For the next two months, Singh tried to make things better, but it was fruitless. FTX collapsed in November 2022.</p><p><strong>Lesson #1: when you discover fraud may be happening, do not “stay around to fix it.” </strong>Any other approach would have been better for Singh; seeking legal advice, turning whistleblower, or quitting on the spot.</p><p>To be fair, Singh didn’t seen <em>totally</em> clueless, and it seems he decided to profit on the developments. Days after he found about this fraud, he took a $3.7M loan from FTX (!!) to buy a house, The Verge <a href="https://www.theverge.com/2023/10/17/23921745/sam-bankman-fried-nishad-singh-house-loan?ref=blog.pragmaticengineer.com" rel="noopener noreferrer nofollow">pointed out</a>. It’s exactly the type of thing you don’t want to do after you discover fraud.</p><p>Now, Singh is facing up to 75 years in jail thanks to his decision to aid the company after discovering the fraud. His sentence will most likely be reduced due to his plea deal, but any course of action which leads to a criminal conviction is surely a grave error of judgment.</p><h4 id="frank-a-software-engineer-refuses-to-fake-customer-data">Frank: a software engineer refuses to fake customer data</h4><p>Frank was a student loan startup founded by Charlie Javice in 2016. In 2019, Javice was featured on the Forbes “30 under 30” <a href="https://www.forbes.com/30-under-30/2019/finance/?ref=blog.pragmaticengineer.com#67e877a27e80" rel="noopener noreferrer nofollow">finance list</a>, suggesting she was a high-flying founder:</p><figure><img src="https://blog.pragmaticengineer.com/content/images/2023/11/Screenshot-2023-11-09-at-11.46.08.png" alt="How Charlie Javice appeared on the Forbes 30 under 30 list in 2019. We now know the 300,000 user number was fake. Source: Forbes" loading="lazy" width="1180" height="414" srcset="https://blog.pragmaticengineer.com/content/images/size/w600/2023/11/Screenshot-2023-11-09-at-11.46.08.png 600w, https://blog.pragmaticengineer.com/content/images/size/w1000/2023/11/Screenshot-2023-11-09-at-11.46.08.png 1000w, https://blog.pragmaticengineer.com/content/images/2023/11/Screenshot-2023-11-09-at-11.46.08.png 1180w" sizes="(min-width: 720px) 720px"><figcaption><span>How Charlie Javice appeared on the Forbes 30 under 30 list in 2019. We now know the 300,000 user number was fake. Source: Forbes</span></figcaption></figure><p>It certainly seemed like Charlie Javice was a standout founder; in 2021, JP Morgan purchased Frank for $175M. However, things turned sour quickly. JP Morgan thought it bought a startup with 5 million customers, which worked with 6,000 schools. But after the purchase, this data was found to be mostly fake.</p><p>Let’s get to a software engineer’s involvement. This April, founder Charlie Javice was arrested, and a lawsuit is ongoing between her, former Chief Growth Officer Olivier Amar, and JP Morgan. From to this lawsuit, we get an inside look at how events unfolded inside Frank.</p><p><strong>In 2021, an engineer was asked to produce fake data for 4.2M non-existent customers. </strong>As acquisition talks were ongoing, JP Morgan wanted to validate that Frank had the nearly 5M customers it claimed. In reality, Frank had 293,000 customers, so the CEO asked an engineer to fake the data and turn this list into 4.2M members. Here’s what happened next – from<a href="https://www.documentcloud.org/documents/23570243-frank_suit?ref=blog.pragmaticengineer.com#document/p21" rel="noopener noreferrer nofollow"> the lawsuit</a>:</p><div><p>“[In 2021] Javice [CEO], Amar [Chief Growth Officer] and the Director of Engineering then had a Zoom meeting during which Javice and Amar asked the Director of Engineering to help them create a synthetic list of customer data. She asked the Director of Engineering if he could help take a known set of FAFSA application data and use it to artificially augment a much larger set of anonymous data tht her systems had collected over time.</p><p>The Director of Engineering questioned whether creating and using such a data set was legal, but Javice tried to assure the engineer by claiming that this was perfectly acceptable in an investment situation and she did not believe that anyone would end up in an ‘orange jumpsuit’ over this project.”</p></div><p><strong>Lesson #2: when your manager claims they don’t believe anyone would end up in an “orange jumpsuit,” assume that someone definitely could. </strong>The engineering director’s next step? They refused:</p><p>“The Director of Engineering was not persuaded and told Javice and Amar that he would not perform the task, and only would send them the file containing Frank’s actual users, which amounted to approximately 293,000 individuals at the time.”</p><p>And this engineering director played it right, as the people who are likely to go to jail and end up in orange jumpsuits are the other two people on the call, who knowingly went along with the illegal.</p><h4 id="pollen-an-engineer-told-to-double-charge-customers-by-the-ceo">Pollen: an engineer told to double charge customers by the CEO</h4><p>Last year, I published my first – and to date only– investigative article on <a href="https://newsletter.pragmaticengineer.com/p/pollen?ref=blog.pragmaticengineer.com" rel="noopener noreferrer nofollow">how events tech startup Pollen raised $200M and then collapsed</a>, owing months of wages to staff. In the investigation, I focused on an unusual detail: $3.2M worth of funds taken months early from customers. The incident was described internally by Pollen as a mistake, and an incident review <em>should</em> have followed. Even more confusing, the company blamed the payments processor Stripe for the incident.</p><p>The reality was that this was a very deliberate double charge. I could not share this fact at the time – as the company threatened me with libel after I informed them of this detail – but the BBC has now produced a documentary <a href="https://www.bbc.co.uk/iplayer/episode/m001n327/crashed-800m-festival-fail?ref=blog.pragmaticengineer.com" rel="noopener noreferrer nofollow">revealing details</a> about this deliberate double charge that was covered up as an outage. From <a href="https://www.bbc.co.uk/programmes/m001n327?ref=blog.pragmaticengineer.com" rel="noopener noreferrer nofollow">the documentary</a>:</p><p>[Narrator] “Pollen initially told some customers that the problem was with their payments provider. Later, Callum [the CEO] addressed his staff who were demanding to know what happened.”</p><p>[CEO of Pollen talking] “All that happened was that a couple millions of dollars of payment plans that were due to be paid at a later month were then paid earlier. It’s being investigated. We’ve committed already that once that investigation is done, it will be shared with the company so that people understand what happened.”</p><p>[Narrator] “With over 1,500 customers impacted, rumors began to circulate about the causes of the incident.”</p><p>[Dan Taylor, managing editor at Tech.eu] “From my understanding, there was a creative code ‘malfunction’ that all of the sudden, double charged customers. But that double charge magically happened to meet Pollen’s payroll, that month. Hmm! Odd, don’t you think?”</p><p>[Narrator] “The internal investigation due to be shared with the company was never completed, but a group of Pollen staff did their own, unofficial digging. (...) The code contained in the report confirms that the customer's monthly payment plans had been manually altered, which meant that double or triple charges will take place on a single day, without the customer’s authorization.”</p><p>The engineer making this change even did a test run the day before, to ensure that this code change “correctly” double charges customers! A former Pollen software engineer appearing in the documentary also makes the point that any code changing production code in payments needs to go through code review, so whoever made this change could have not been acting alone.</p><p>Two days after the incident, a senior engineering team member sent an internal chat message to 3 colleagues, where they admit that they had run the script at the request of the CEO. Here is what this message said:</p><blockquote>“Also want to come clean that it was me who ran a bad script - in hindsight I wasn’t knowledgeable enough to alter a subset of payment plans for Balvin [one of the events organized by Pollen]. I did this as a special request from Callum and didn’t want to raise on call to handle. It’s been a long week and I displayed a very poor form of judgement.”</blockquote><p>In the video, a Pollen software engineer is shown the message, and he says: “I’m not sure I buy this. It seems a bit fishy.”</p><p><strong>Lesson #3: if the CEO asks you to do something potentially illegal – document it, and consider not doing it. </strong>We don’t know what happened with the senior engineering member who carried out the code changes, following a request from the CEO. This person could have said no, like the engineering director at Frank did. The message sent a few days ago already said that this person regretted doing so, and it’s unlikely that this action was worth the risk it carried.</p><p><strong>If you take one lesson from this, it’s that you can always say no. </strong>In these three stories, the only engineer who’s legally safe is the former engineering director at Frank who point blank refused to assist what could be an illegal request. The engineering director at FTX who stayed after he confirmed fraud was occurring is now facing jail time, while the senior engineering member at Pollen is at the mercy of the UK police, and how they deal with what could be a potential wire fraud case.&nbsp;</p>


            <!-- Newsletter -->
            <p>
              <a href="https://newsletter.pragmaticengineer.com/about">Subscribe to my weekly newsletter</a> to get articles like this in your inbox. It's a pretty good read - and the <a href="https://substack.com/top/technology">#1 tech newsletter</a> on Substack.
            </p>
            
        </section>

        
    </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Immich v2.0.0 – First stable release (467 pts)]]></title>
            <link>https://github.com/immich-app/immich/discussions/22546</link>
            <guid>45446834</guid>
            <pubDate>Thu, 02 Oct 2025 06:25:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/immich-app/immich/discussions/22546">https://github.com/immich-app/immich/discussions/22546</a>, See on <a href="https://news.ycombinator.com/item?id=45446834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="presentation" data-paste-markdown-skip="">
    <tbody data-target-translation-id="8971417" data-target-translation-type="discussion">
        <tr>
    <td>
        <h2 dir="auto">v2.0.0 - Stable Release of Immich</h2>
<p dir="auto"><a href="https://www.youtube.com/watch?v=xz8LfGXgFAI" rel="nofollow">Watch the video</a></p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=xz8LfGXgFAI" rel="nofollow"><img src="https://camo.githubusercontent.com/ed58cd08a441dd9a013bcc51e61ef4c4fe0f4bd852807fd5204d6d4ecdb0c82d/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f787a384c664758674641492f6d617872657364656661756c742e6a7067" alt="YouTube Video" data-canonical-src="https://img.youtube.com/vi/xz8LfGXgFAI/maxresdefault.jpg"></a></p>
<h2 dir="auto">Welcome</h2>
<p dir="auto">Hello everyone,</p>
<p dir="auto">After:</p>
<ul dir="auto">
<li><em>~1,337 days,</em></li>
<li><em>271 releases,</em></li>
<li><em>78,000 stars on GitHub,</em></li>
<li><em>1,558 contributors,</em></li>
<li><em>31,500 members on Discord,</em></li>
<li><em>36,000 members on Reddit,</em></li>
<li><em>68 languages on Weblate,</em></li>
<li><em>Surviving the controversial announcement about joining FUTO,</em></li>
<li><em>Having overwhelming success and support from the community with the product keys model,</em></li>
<li><em>Launching the Merch store,</em></li>
<li><em>Attending our first FOSDEM,</em></li>
<li><em>...and <strong>before</strong></em> <em>the release of GTA VI</em></li>
</ul>
<p dir="auto">We are thrilled to announce the <strong>stable release of Immich!</strong> 🎉</p>
<p dir="auto">This has been a journey long in the making. So much has changed since the first commit on the project, all the way back in February, 2022. The project and team continue to grow, and today we’re proud to announce <code>v2.0.0</code>, our stable release. Stable signifies that we have now resolved a significant amount of technical debt. It also means we will be prioritizing compatibility and less effort will be required to keep Immich up-to-date. Finally, it means that the warning banner on the website has been removed! Along with this, we’re happy to announce a new version of the <a href="https://immich.app/" rel="nofollow">https://immich.app/</a> website.</p>
<p dir="auto">For more specifics about the stable release, see our <a href="#user-content-faqs">FAQs</a> below.</p>
<h2 dir="auto">Merch and DVD</h2>
<p dir="auto">To celebrate this release, we want to capture this moment in a nostalgic form, reminiscent of how software was distributed in our childhood - on a CD (or DVD, in this “case”). Introducing Immich Stable in physical form! You can find the link to the disk <a href="https://immich.store/products/immich-retro" rel="nofollow">here</a></p>
<a href="https://immich.store/products/immich-retro" rel="nofollow">
<img width="1200" alt="image" src="https://private-user-images.githubusercontent.com/27055614/496353055-c3883849-ffeb-4022-9b7a-09cbdd7c714c.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTkzOTc3MDIsIm5iZiI6MTc1OTM5NzQwMiwicGF0aCI6Ii8yNzA1NTYxNC80OTYzNTMwNTUtYzM4ODM4NDktZmZlYi00MDIyLTliN2EtMDljYmRkN2M3MTRjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEwMDIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMDAyVDA5MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRmMTZmZDA5MzlhNjA1OGYzYTc5NTNiMjI2YjZiYjQ1MThiOGZlYWVmYWExNjBmOGJiYjMwY2YyOWY0MTIyYWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.uXCyqI3xWs9Iuv7G1W3exnxrWVKXO3wKSst9nTuIkpY" secured-asset-link="">
</a>
<p dir="auto">The disk comes with a fully bootable Immich instance, featuring a selection of curated photos chosen by the team. You can purchase the disk from our merch store, along with a client or server product key, to support and celebrate this milestone with us.</p>
<p dir="auto">The merch store is also updated with retro-styled Immich designs, check it out in <a href="https://immich.store/" rel="nofollow">https://immich.store</a></p>
<a href="https://immich.store/" rel="nofollow">
<img width="1200" alt="image" src="https://private-user-images.githubusercontent.com/27055614/496353135-d2dc89c2-61af-4f64-afae-10c98ffbb08f.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTkzOTc3MDIsIm5iZiI6MTc1OTM5NzQwMiwicGF0aCI6Ii8yNzA1NTYxNC80OTYzNTMxMzUtZDJkYzg5YzItNjFhZi00ZjY0LWFmYWUtMTBjOThmZmJiMDhmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTEwMDIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUxMDAyVDA5MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTI2OWY5NmFmYzYwMjQ5MTNhNmQyNDRjYThiZWEzZjA2MzEwZTI4OTkyMmMwNmNkODJiMTllZjAwMWY3ZWU1ODgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.bZxwNO6jqlW6RrDTbKHvsfmOWEm85cbghrgC2nriPCA" secured-asset-link="">
</a>
<h2 dir="auto">Future plans</h2>
<p dir="auto">Now that Immich is stable, here are some of the things that we will be focusing on:</p>
<ul dir="auto">
<li><strong>Roadmap</strong> — There are still a few items on our roadmap that we want to complete before the year ends such as auto-stacking, and achieving feature parity between the web and mobile app. We also have plans to start work on improved stack support, better sharing, group management, and ownership improvements, as well as many other enhancements.</li>
<li><strong>Usage data</strong> — The team wants to understand how the software is used, so that we can make better, informed decisions as we design and build Immich. We want to collect that information in a non-invasive and transparent way. We plan to discuss it with the community and gather feedback from everyone to come up with the best solution.</li>
<li><strong>Backup services</strong> — We aim to introduce additional paid services (<em>not paywalled features, as we will never implement paywalled features</em>), which will help support the project and that enhance self-hosting, making it easier and more reliable. First among the many services already planned is an end-to-end encrypted, off-site backup and restore feature, built directly into Immich. This will enable a buddy backup feature as well.</li>
</ul>
<h2 dir="auto">Thank you</h2>
<p dir="auto">We cannot thank you enough for the support over the past three years. Community participation, from the first comments on the <a href="https://www.reddit.com/r/selfhosted/comments/si5lp6/i_am_building_a_selfhosted_alternative_version_of/" rel="nofollow">original reddit post</a>, to the feedback when we joined FUTO, have contributed to the awesome product Immich is today. Thank you for joining us and believing in our mission to regain control over your most precious data. Here’s to many more years!</p>
<p dir="auto">We'll also be hosting a Q&amp;A livestream tomorrow, <strong>October 2nd, 2025 at 6 PM UTC</strong>. You can submit your questions <a href="https://www.live-ask.com/event/01K6GFKQGJSB1GQC086ZJW6F6R" rel="nofollow">here</a> and subscribe for notifications when the livestream starts <a href="https://www.youtube.com/live/qgQ4ci2hRMQ" rel="nofollow">here</a>.</p>
<p dir="auto">Cheers,</p>
<p dir="auto">The Immich Team</p>
<hr>
<h2 id="user-content-faqs" dir="auto">FAQs</h2>
<h2 dir="auto">Will there be a live stream?</h2>
<p dir="auto">Yes. We'll be hosting a Q&amp;A livestream tomorrow, <strong>October 2nd, 2025 at 6 PM UTC</strong>. You can submit your questions <a href="https://www.live-ask.com/event/01K6GFKQGJSB1GQC086ZJW6F6R" rel="nofollow">here</a> and subscribe for notifications when the livestream starts <a href="https://www.youtube.com/live/qgQ4ci2hRMQ" rel="nofollow">here</a>.</p>
<h2 dir="auto">Do I still need backups?</h2>
<p dir="auto">Yes! A 3-2-1 backup strategy is still crucial. The team has the responsibility to ensure that the application doesn’t cause loss of your precious memories; however, we cannot guarantee that hard drives will not fail, or an electrical event causes unexpected shutdown of your server/system, leading to data loss. Therefore, we still encourage users to follow best practices when safeguarding their data. Keep multiple copies of your most precious data: at least two local copies and one copy offsite in cold storage. Additionally, we are starting to work on a cloud backup service to make backups easier.</p>
<h2 dir="auto">When will <code>v2.0.0</code> be available?</h2>
<p dir="auto">The Docker images for <code>v2.0.0</code> will be pushed out a few hours after this post is released.</p>
<h2 dir="auto">How can I update to <code>v2.0.0</code>?</h2>
<p dir="auto">You can follow the upgrade documentation, <a href="https://docs.immich.app/install/upgrading" rel="nofollow">here</a>.</p>
<h2 dir="auto">What versioning strategy will Immich use?</h2>
<p dir="auto">Starting with <code>v2.0.0</code>, we will now follow <a href="https://semver.org/" rel="nofollow">semantic versioning</a>.</p>
<h2 dir="auto">What mobile app versions will work with <code>v2.0.0</code>?</h2>
<p dir="auto">Any <code>v2.x.x</code> version of the mobile app will work with any <code>2.x.x</code> version of the server. For example, a mobile app on version <code>v2.9.0</code> will continue to work with server versions: <code>v2.0.0</code>, <code>v2.1.0</code>, <code>v2.3.1</code>, etc.</p>
<h2 dir="auto">Will new features continue to be released?</h2>
<p dir="auto">Yes. Immich will continue to build, develop, and release new features.</p>
    </td>
  </tr>

    </tbody>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Keyhive – Local-first access control (155 pts)]]></title>
            <link>https://www.inkandswitch.com/keyhive/notebook/</link>
            <guid>45445114</guid>
            <pubDate>Thu, 02 Oct 2025 00:12:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.inkandswitch.com/keyhive/notebook/">https://www.inkandswitch.com/keyhive/notebook/</a>, See on <a href="https://news.ycombinator.com/item?id=45445114">Hacker News</a></p>
<div id="readability-page-1" class="page">

  <header>
    
    <h2>Local-first access control</h2>

    

    <div>
<p>🐝</p>
<p>Keyhive is a project exploring local-first access control. It aims to provide a firm basis for secure collaboration, similar to the guarantees of private chat but for any local-first application.</p>
<p>In this lab notebook, we’ll share snippets of our findings as we explore the problem space and prototype potential solutions.</p>
<p>The entries start from the beginning, but you can jump to the most recent post: <a href="https://www.inkandswitch.com/keyhive/notebook/05/">05 · Syncing Keyhive</a></p>
    </div>
  </header>

<article>
  <h2><a href="https://www.inkandswitch.com/keyhive/notebook/00/">00 · Keyhive Background</a></h2>
  <p>2024 Aug 1</p>
<p>As the <a href="https://www.inkandswitch.com/local-first/">local-first</a> ecosystem matures, the contexts that local-first applications fill has also expanded. Local-first emphasizes collaboration, but the constraints on an application are different if you build an application for you and a handful of friends versus delivering a team-oriented product. Your data not being viewable or editable by everyone in the world is a basic requirement of applications ranging from planning a surprise party, corporate meeting notes, book drafts, and legal contracts.</p>
<p>Today’s most common access control patterns assume a central server. While cloud auth tools are forever developing, generally speaking existing tools for cloud auth are very mature. Doing access control without a cloud auth server requires rethinking the underlying mechanics of how auth works. Keyhive is an attempt to do secure and efficient local-first auth while retaining the user experience found in familiar applications like Google Docs, Dropbox, GitHub, and Discord. We believe that these are table stakes for the next generation of local-first applications.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/00/github-rbac.png" alt="GitHub Repo Membership Page">
<figcaption>
<p>A GitHub repository permissions page</p>
</figcaption>
</figure>
<p>We’ve seen user-agency principals successfully applied to other contexts. <a href="https://signal.org/">Signal</a> popularized end-to-end encrypted chat while retaining much of the convenience of less-secure messaging applications. We find ourselves asking “what would Signal for documents look like?”</p>
<h2>Least Surprise</h2>
<p>Unlike a cloud auth system which can depend on the network to keep data hidden behind a web API, local-first runs a complete copy of the application at each replica. What are the correct bounds on access control when everyone has direct access to all of the content? Ultimately access control is about collaboration. Collaboration and access control can be seen as two sides of the same topic: who do you want to collaborate with, in which ways, and for how long?</p>
<p>CRDTs try to merge data in the least surprising way possible. For example, concurrent text will merge to produce the same data on all replicas, but the resulting paragraphs may not make sense next to each other. Users then fix these semantic errors manually. We believe that this is a major improvement over the user experience of something like Git, which often gets stuck and demands user intervention.</p>
<p>The equivalent situation exists for concurrent access control, but the stakes are higher. Preventing your friend from learning that you’re planning a surprise party, or opposing legal councel from altering your case prep are both important, and it should be clear how they will behave despite any underlying concurrency. The behavior of an access control system should be as clear to the end user as possible. Since there is no single source of truth about who can do what at any given time, the rules themselves need to be straightforward.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/00/history.png" alt="Ranges of authorization over time">
<figcaption>
<p>Ranges of authorization (and revocation) over time. Here 🙋‍♀️ is added, removed, and re-added later. Some of 🙋‍♀️’s updates are not materialized based on where they’re ordered in the document history.</p>
</figcaption>
</figure>
<h2>Out of Obscurity</h2>
<p>Often local-first applications today depend on <a href="https://en.wikipedia.org/wiki/Security_through_obscurity">“security through obscurity”</a>. For example, by default you can write into any <a href="https://automerge.org/">Automerge</a> document that you know the document ID for. This style is sometimes called “<a href="http://erights.org/talks/thesis/markm-thesis.pdf">Swiss number</a>” or “<a href="https://en.wikipedia.org/wiki/Rumpelstiltskin">Rumpelstiltskin</a>” security. It works as long as the document ID is only ever shared with people that you want to collaborate with, your security is all-or-nothing, and you never want to later remove someone from a document. If the document ID leaks (e.g. someone posts it to Bluesky), then the document is world-writable.</p>
<p>In lieu of a widely-adopted<sup><a href="#fn1" id="fnref1">1</a></sup> purely local-first access control system, some teams have tried leveraging existing auth methods by routing updates through a cloud auth server (e.g. <a href="https://en.wikipedia.org/wiki/OAuth">OAuth</a> login and auth logic in a server). Others have opted to emphasize decentralized user agency by using a blockchain to store access control policies. Both of these approaches require a network connection in order to check if an update is valid, which is not local-first. Bringing access control features to a local-first context requires rethinking how authority flows between nodes.</p>
<p>What we want is a system that retains the best of the above: the self-certification of Rumpelstiltskin, the power of auth servers, and the user agency of decentralized solutions. Following the definition of local-first, applications should accept updates after arbitrarily long periods of disconnection. Extending that requirement to access control means the ability to revoke access or have finer grained control (e.g. read vs write) requires tracking who has authorization to do what, and at which point in the document’s history.</p>
<!-- Footnotes -->
<!-- External Links -->
<section role="doc-endnotes"><hr><ol>
<li id="fn1"><p>While we believe that local-first access control is nascent, the Keyhive team is grateful to benefit from work done by other projects. Some of our inspirations include <a href="https://mattweidner.com/assets/pdf/acs-dissertation.pdf">Causal TreeKEM</a>, <a href="https://ieeexplore.ieee.org/document/4032481">Cryptree</a>, <a href="https://dl.acm.org/doi/pdf/10.1145/3460120.3484542">DCGKA</a>, <a href="https://github.com/local-first-web/auth">Local-First Auth</a>, <a href="https://matrix.org/">Matrix</a>, <a href="https://www.serenity.page/">Serenity</a>, <a href="https://tahoe-lafs.org/trac/tahoe-lafs">Tahoe-LAFS</a>, <a href="https://github.com/ucan-wg">UCAN</a>, and <a href="https://github.com/wnfs-wg">Web Native File System</a>. <a href="#fnref1">↩︎</a></p>
</li>
</ol>
</section>
</article>
<article>
  <h2><a href="https://www.inkandswitch.com/keyhive/notebook/01/">01 · Welcome to the Keyhive</a></h2>
  <p>2024 Sept 5</p>
<p>Today’s cloud services have very mature access control features. These systems depend on a key architectural detail: they are able to rely on encapsulation by taking advantage of the network boundary. Since data is not available to read or write directly by the client, a privileged guard process is able to apply arbitrary access control rules. This process retrieves and/or mutates data on behalf of clients.</p>
<p>This power unfortunately comes at a price: since auth is on the hot path of every request — and generally depends on a central single-source-of-truth auth database — authorization at scale often bottlenecks overall application performance. And yet, an attacker that is able to bypass the auth part of the request lifecycle has unmitigated access to arbitrarily read, change, or delete the application’s data. This is to say nothing of the complexity of building, deploying, and maintaining cloud architectures to get that network boundary in the first place!</p>
<p>For local-first software to be successful in many production contexts, it needs to provide similar features without relying on a central authorization server. The local-first setting does not have the luxury of a network boundary: access control must travel with the data itself and work without a central guard.</p>
<p>There are also some tricky edge cases due to causal consistency. What should happen to honest operations that causally depend on content that’s later discovered to be malicious? What is the best strategy to handle operations from an agent that was revoked concurrently, especially given that “back-dating” operations is always possible. If a document has exactly two admins (and many non-admin users), what should happen if the admins concurrently revoke each other (for instance, one is malicious)?</p>

<p>To address the above challenges, we’ve started work on Keyhive: a project focused on local-first access control. Our goal is to design and build a production ready instance of such a system which is general enough for most local-first applications.</p>
<h2 id="audience-and-application"><a href="#audience-and-application">Audience &amp; Application</a></h2>
<p>To date, the local-first ecosystem has primarily used a purely pull-based model where users manually decide which changes to accept. This approach is often sufficient for personal projects: each user can manually decide which peers to connect to and which changes should be applied. On the other hand, many production contexts have lower trust, require higher alignment, and are ideally low touch <em>enough</em> so that it’s not up to each person in a large organization to separately and manually infer who to trust. As a rough north star, we’re keeping the following use cases in mind:</p>
<ul>
<li>Publishing (publicly visible data with restricted edits, like a blog)</li>
<li>Planning a surprise party: small groups, low risk</li>
<li>Meeting notes: small-to-medium groups, low-to-medium risk</li>
<li>Corporate legal documents: medium-to-large groups, medium-to-high risk</li>
<li>Journalists &amp; activists: small-to-medium groups, high risk</li>
</ul>
<p>Cryptography has a reputation for being slow, especially if there’s crypto-heavy code running on low-powered devices. To have a performance margin that can cover a large range of practical use cases, Keyhive aims to run efficiently over at least ten-of-thousands of documents, millions of readers, thousands of writers, and hundreds of admins/superusers.</p>
<h3 id="antigoals"><a href="#antigoals">Antigoals</a></h3>
<p>Since authorization, authentication, and identity are often conflated, it is worth highlighting that Keyhive deliberately excludes user identity (i.e. the binding of a human identity to an application’s identifier like a public key). In our initial community consultations we found that there are many different identity mechanisms that developers downstream of Keyhive would like to use. As such, we’re designing the system to be <a href="https://en.wikipedia.org/wiki/Zooko's_triangle">decentralized and secure</a>, and leave name registration/discovery and user verification (e.g. email or social) to a future layer above Keyhive.</p>
<p>The following are left out of our design goals:</p>
<ul>
<li>Constraining downstream applications to use a small predefined set of policies or roles</li>
<li>Interactive protocols (since local-first must work under network partition)</li>
<li>Reliance on a central authority</li>
<li><a href="https://en.wikipedia.org/wiki/Cryptographic_agility">Cryptographic agility</a></li>
<li><a href="https://en.wikipedia.org/wiki/Federal_Information_Processing_Standards">FIPS</a> (or similar) compliance</li>
</ul>
<h2 id="layers"><a href="#layers">Layers</a></h2>
<p>Most client/server backends place data at the bottom, and compute over it. In that model, auth is just another kind of computation. Leaving access control to a central process is not possible in a local-first context. In our context, the auth layer must act as a foundation.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/01/stack-changes.png" alt="Comparing how authorization is layered in centralized and local-first applications">
</figure>
<p>Static authorization typically impacts the design of all other layers of a project. As an intuition, the storage layer will need to support data that is encrypted-at-rest, and so its design has a dependency on the auth layer. This means that since the design of an authorization mechanism may impose downstream constraints, its design should consider such potential impacts on the design of the rest of the stack. As much as possible, this project attempts to minimize imposing such constraints on other layers.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/01/block-diagram.png" alt="Dependency Stack">
</figure>
<p>Keyhive (as currently designed) carves out three layers to handle this:</p>
<ol>
<li><strong>Convergent Capabilities:</strong> A new <a href="https://en.wikipedia.org/wiki/Object-capability_model">capability</a> model appropriate for CRDTs, and sits between object- and certificate-capabilities</li>
<li><strong>A Group Management CRDT:</strong> Self-certifying, concurrent group management complete with coordination-free revocation</li>
<li><strong>E2EE with Causal Keys:</strong> With <a href="https://eprint.iacr.org/2016/221.pdf">post-compromise security (PCS)</a> and symmetric key management granting access to causal predessesors.</li>
</ol>
<p>These three have a strong dependency between each other. Capabilities enable use to manage groups, and groups let us share keys for E2EE. We will go into more detail on all three in future posts, but in the meantime here is a very high level treatment:</p>
<h3 id="convergent-capabilities"><a href="#convergent-capabilities">Convergent Capabilities</a></h3>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/01/granovetter.png">
<figcaption>
<h4>Granovetter Diagram</h4>
<p>A diagram showing Alice delegating to Bob her existing access to Carol</p>
</figcaption>
</figure>
<p>Capabilities and delegation form the basic access control mechanism that are known to be <a href="https://srl.cs.jhu.edu/pubs/SRL2003-02.pdf">very expressive</a>. In short: all Automerge documents get identified by a public key, and delegate control over themselves to other public keys. This provides stateless self-certification with a cryptographic proof. Public keys in the system can represent anything: other documents, users, groups, or anything else. This is a very low-level mechanism that can be used to model high level concepts like <a href="http://wiki.erights.org/wiki/Walnut/Secure_Distributed_Computing#Powerbox_Capability_Manager">powerboxes</a>, <a href="https://en.wikipedia.org/wiki/Role-based_access_control">roles</a>, device groups, and more with very little code, all while remaining extensible to new patterns.</p>
<p><a href="https://en.wikipedia.org/wiki/Object-capability_model">Object-capabilities</a> (AKA “ocap”) are “<a href="https://en.wikipedia.org/wiki/Fail-stop">fail-stop</a>”, meaning that they intentionally stop working if there’s a network partition to <a href="https://en.wikipedia.org/wiki/PACELC_theorem">preserve consistency over availability</a>. Since local-first operates under partition (e.g. offline), parts of the classic object-capability design are not suitable. Certificate capabilities such as <a href="https://www.rfc-editor.org/rfc/rfc2693">SPKI/SDSI</a>, <a href="https://w3c-ccg.github.io/zcap-spec/">zcap-ld</a> and <a href="https://github.com/ucan-wg">UCAN</a> are partition-tolerant, but depend on stateless certificate chains which is highly scalable but somewhat limits their flexibility. We propose a system between the two: convergent capabilities (“concap” for short) which contain CRDT state to get the benefits of both while retaining suitability for local-first applications.</p>

<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/01/doc-group.png">
<figcaption>
<h4>An Automerge Document Agent</h4>
<p>A Keyhive document in isolation, with a simplified view of its stateful delegation graph.</p>
</figcaption>
</figure>
<p>Concurrent access control will always have some tricky situations. The big obvious ones are what to do if two admins concurrently revoke each other, or happened if operations depend on others that were revoked, and how to handle maliciously back-dated updates. There is quite a lot to discuss on this topic, so we’ll leave it for a future post.</p>
<h3 id="transitive-groups"><a href="#transitive-groups">Transitive Groups</a></h3>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/01/device-management.png">
<figcaption>
<h4>Device Management</h4>
<p>A Keyhive group showing how devices can be managed behind a proxy (‘Alice’). Documents in this scenario only need to know about Alice, not every device.</p>
</figcaption>
</figure>
<p>Groups are built on top of convergent capabilities. They’re “just” a thin design pattern, but help model things like user devices, teams, and more. By following the delegations between groups, we can discover which public keys have what kind of access to a certain document. This provides a handy abstraction over teams and user devices. By following the links, it both lets a writer know who has read access (i.e. who to share keys for the latest E2EE chunk with), and lets the <a href="#trust-minimized-sync-servers">trust-minimized sync engine</a> know which documents the current device can request from the server.</p>
<h3 id="e2ee-with-causal-keys"><a href="#e2ee-with-causal-keys">E2EE with Causal Keys</a></h3>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/01/causal-encryption.png">
<figcaption>
<h4>Causal Encryption</h4>
<p>Causal key management: a strategy for managing E2EE keys based on the causal structure of a document. Similar to a <a href="https://ieeexplore.ieee.org/document/4032481">Cryptree</a>, having the key to some encrypted chunk lets you iteratively discover the rest of the keys for that chunk’s causal history, but not its parents or siblings.</p>
</figcaption>
</figure>
<p>Data in Keyhive is encrypted-at-rest. Encrypting every Automerge operation separately would lead to very large documents that cannot be compressed. Instead we use the <a href="https://automerge.org/automerge-binary-format-spec/">Automerge Binary Format</a> to compress-then-encrypt ranges of changes. We expect these encryption boundaries to change over time as parts of the document become more stable, so we need a way to manage (and prune) a potentially large number of keys with changing envelope boundaries.</p>
<p>We achieve the above by including the keys to all of their causal predessesor chunks. This sacrifices forward secrecy (FS) — leaking old message keys in the case of a later compromised key — but retains secrecy of concurrent and future chunks. Of course “leaking” <em>anything</em> sounds bad. However, unlike ephemeral messaging (e.g. <a href="https://signal.org/">Signal</a>) where not all users are nessesarily expected to have the entire chat history, CRDTs like Automerge require access to the entire causal history in order to render a view. This means that in all scenarios we need to pass around all historical keys, whether or not they’re in the same encryption envelope. We believe that this choice is appropriate for static control context on documents that require the entire history. As a nice side-effect of this choice, we also gain flexibility and simplicity.</p>
<p>In this design, keys behave a bit like pointers, so we can apply all of the standard data structure pointer indirection tricks to do smooth updates to encryption boundaries. This is fairly well-developed at this stage, so we will save a deeper exploration of this topic for a future post.</p>
<h2 id="pull-control"><a href="#pull-control">Pull Control</a></h2>
<p>E2EE raises a new issue: there is no such thing as perfect security. All encryption algorithms are deemed secure with respect to some explicitly-defined assumptions (such as the difficulty of factoring large primes or group operations). There may be mathematical breakthroughs, edge cases discovered, or new hardware that render your choice of encryption algorithm useless. Even more worse, keys can be accidentally leaked or devices stolen. While we can revoke future write access, if someone has the data and the symmetric key, then they have the ability to read that data. The best practice is to have defense in depth: don’t make ciphertexts retrievable by anyone, but only those with “pull access” or higher. “Pull” is weaker than the more familiar “read” and “write” access effects: it’s only the ability to retrieve bytes from the network but not decrypt or modify them. This is especially helpful for trust-minimizing sync servers, since by definition they cannot have the ability to see the plaintext if we want to claim E2EE.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/01/effects.png">
<figcaption>
<h4>Access Effects</h4>
<p>An example of delegation across the Keyhive access effect types</p>
</figcaption>
</figure>
<h2 id="trust-minimized-sync-servers"><a href="#trust-minimized-sync-servers">Trust Minimized Sync Servers</a></h2>
<p>If <a href="https://youtu.be/NMq0vncHJvU?si=_U53CwSnbpkyf5gB&amp;t=1016">we want to move towards an ecosystem of interchangeable relays</a>, minimizing trust on such relays is a must. Our approach (perhaps unsurprisingly) is to end-to-end encrypt the data, removing read access from sync servers altogether. Under this regime, sync engines are “merely” a way to move random-looking bytes between clients.</p>
<p>There is another ongoing project at the lab focused improving data synchronization for peer-to-peer and via sync servers. We’ve realized that sync and secrecy strongly interact. Broadly speaking, sync protocols benefit from more metadata (to efficiently calculate deltas), but cryptographic protocols aim to minimize or eliminate metadata exposure. This tension extends across related systems, including merging E2EE <a href="https://automerge.org/automerge-binary-format-spec/">compressed chunks</a>, and determining if a peer has already received specific operations when a sync server cannot access them in plaintext.</p>
<p>Fortunately, combining these systems can sometimes result in more than the sum of their parts. For instance, convergent capabilities help facilitate the calculation of which documents are of interest to particular agent, helping the sync system know which documents to send deltas of. For these reasons, we’re treating synchronization and authorization as part of a larger, unified project, even though each will yield distinct artifacts.</p>
<h2 id="whats-next"><a href="#whats-next">What’s Next?</a></h2>
<p>Cryptographic code is notoriously difficult to debug, so we decided to start with design and move to code when we had some fairly good theories on how the basics of this system should work. Now that we’re at that point, we’ve very recently begun to implement this design. We’ll report on our progress in future posts, as well as dive deeper into some of the topics we touched on in the overview here.</p>
</article>
<article>
  <h2><a href="https://www.inkandswitch.com/keyhive/notebook/02/">02 · Group Key Agreement with BeeKEM</a></h2>
  <p>2025 Jan 21</p>
<p>As we’ve seen in past lab notes, Keyhive provides access control for local-first applications. We support both server-based collaboration and peer-to-peer operation without a trusted server. And individuals might work offline for extended periods of time. In the context of Automerge, our goal is to control access to documents, collections of documents, and parts of documents.</p>
<p>Every document has a group of users with access to that document. That group might include other groups as members (in which case the members of those groups are also members of the document). Importantly, a document group’s membership is dynamic, with new members added and removed over time. We must be able to handle concurrent changes in a distributed context.</p>
<p>Of course, if we want to limit read access to just our group, we can’t safely share our document as plaintext via sync servers. We need a way to encrypt and decrypt our data that is accessible to only our document’s members. This means we need a way for our group to agree on the keys that will be used for encryption and decryption over time.</p>
<h2 id="continuous-group-key-agreement"><a href="#continuous-group-key-agreement">Continuous Group Key Agreement</a></h2>
<p>In the literature, this problem is known as <a href="https://eprint.iacr.org/2019/1189.pdf">Continuous Group Key Agreement (CGKA)</a>. A <strong>CGKA protocol</strong> enables a dynamic group to agree on a sequence of keys over time. CGKAs ordinarily guarantee two properties: forward secrecy (FS) and <a href="https://eprint.iacr.org/2016/221.pdf">post-compromise security (PCS)</a>. Imagine a successful attacker compromises a single key. In the simplest terms, forward secrecy means that this key will not enable access to past data. And post-compromise security means it will not enable access to future data. If you can guarantee both, then you can limit the damage from a key compromise.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/forward_secrecy_and_post-compromise_security.png" alt="Forward secrecy and post-compromise security">
</figure>
<p>One way to achieve <strong>forward secrecy</strong> is through “ratcheting”. With a ratchet, honest users employ a key derivation function (KDF) to deterministically transform a key in a way that is effectively impossible to reverse. A cryptographic hash function is one way to achieve this. Ratcheting with such a one-way function prevents an attacker from discovering past keys since there is no feasible way to reverse the function. But a one-way function on its own does not prevent an attacker from discovering future keys, since you can derive all future keys from a compromised key by repeatedly applying the hash function.</p>
<p>Of course, we don’t want a system that once compromised is always insecure. That’s where <strong>post-compromise security</strong> comes in. The intuitive idea is that a system with post-compromise security has some mechanism to deny access after an attack. Compromised information will no longer be enough to derive future keys. One way to achieve this is to periodically rotate information required for determining future keys in a way that is not accessible to a past attacker.</p>
<p>In practice, ratcheting protocols mix in fresh information with each ratchet so that knowledge of a key is not by itself sufficient to derive future keys. For example, Signal’s <a href="https://signal.org/docs/specifications/doubleratchet/">Double Ratchet protocol</a> includes sending a Diffie-Hellman public key with each message so that the receiver can derive a shared Diffie-Hellman secret to use as a side input to the key derivation function (KDF) that is used for ratcheting.</p>
<h3 id="treekem"><a href="#treekem">TreeKEM</a></h3>
<p>The current Message Layer Security (MLS) protocol for CGKA uses <a href="https://inria.hal.science/hal-02425247v1/file/treekem%20%281%29.pdf">TreeKEM</a>, a protocol for asynchronous, decentralized key agreement for dynamic groups<sup><a href="#fn1" id="fnref1">1</a></sup>. TreeKEM uses a binary tree with group members’ public keys at the leaves and the current group secret encrypted at the root. All other inner nodes act like the root for their subtrees (and subtrees act like subgroups with their own shared, encrypted secrets). Members can be dynamically added and removed from the tree.</p>
<p>For post-compromise security, each member periodically rotates out its public keys on its leaf, which leads to cascading secret updates all the way to the root. Both updating and decrypting the root secret requires traversing the path from the member’s leaf to the root, performing <code>log(n)</code> operations (although there is a linear worst case under certain conditions).</p>
<p>Unfortunately, Keyhive’s requirements rule out TreeKEM as it stands. That’s because TreeKEM depends on a central server to create a total order of operations, and to pick winners among concurrent operations. Keyhive’s local-first model is peer-to-peer compatible and does not require such a central server. And for Keyhive, concurrent operations can be merged in long after they were actually performed (for example, if a member made changes while aboard a long-haul flight).</p>
<h3 id="decentralized-cgka-alternatives"><a href="#decentralized-cgka-alternatives">Decentralized CGKA alternatives</a></h3>
<p>An alternative that is more aligned with our requirements is the <a href="https://dl.acm.org/doi/pdf/10.1145/3460120.3484542">Decentralized Continuous Group Key Agreement (DCGKA) protocol</a> developed by <a href="https://mattweidner.com/">Matthew Weidner</a> and <a href="https://martin.kleppmann.com/">Martin Kleppmann</a>. This protocol assumes a decentralized network that does not depend on a trusted central server. However, unlike TreeKEM, it provides linear rather than logarithmic performance. As a result, they target groups on the order of 100 members as opposed to MLS’s target of 50k members. A design goal for Keyhive is to target at least thousands of members<sup><a href="#fn2" id="fnref2">2</a></sup>.</p>
<p>Matthew Weidner has also proposed an alternative to TreeKEM called <a href="https://mattweidner.com/assets/pdf/acs-dissertation.pdf">Causal TreeKEM</a>. Whereas TreeKEM requires a total order imposed by a central server, Causal TreeKEM only requires a causal order, which is much better suited to a decentralized network. Like TreeKEM, it has logarithmic performance (with a linear worst case) and is meant to ensure both forward secrecy and post-compromise security.</p>
<p>However, Causal TreeKEM depends on fancier crypto than we’d prefer in order to merge concurrent updates in any order. It requires a cryptographic operation to combine updates at a node that is both associative and commutative. One option here would be BLS, but this is far less common than the standard options and there is not currently a great library option for Rust (the language Keyhive is written in). And we have definitely ruled out rolling our own crypto (you probably should too).</p>
<p>For these reasons, we’ve proposed our own alternative<sup><a href="#fn3" id="fnref3">3</a></sup> for Keyhive that we call “BeeKEM”. It is closely modelled on TreeKEM with insights from Causal TreeKEM. It requires no central server and only a causal order of operations. It provides logarithmic performance (with linear worst case). And like the other TreeKEM variants, it provides forward secrecy and post-compromise secrecy<sup><a href="#fn4" id="fnref4">4</a></sup>. Furthermore, it relies exclusively on standard crypto, such as <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">Diffie Hellman key exchange</a> and <a href="https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf">BLAKE3</a> hashing.</p>
<h2 id="beekem"><a href="#beekem">BeeKEM</a></h2>
<p>In this section, we’ll see how BeeKEM works in more detail.</p>
<p>In BeeKEM (as in TreeKEM), the current group secret is stored encrypted at the root node of a binary tree. We’ll call this the “root secret”. The root secret is used for encrypting and decrypting document chunks shared with our group over the network<sup><a href="#fn5" id="fnref5">5</a></sup>.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/basic_beekem_tree.png" alt="Basic BeeKEM tree">
</figure>
<p>Each leaf of the tree corresponds to a member of the group and contains its ID and latest Diffie Hellman (DH) public key. A member’s ID is persistent over time but each member will periodically rotate its DH public key. When a member rotates its DH public key, that will cause the root secret to change as well. Thus, member key rotations help provide post-compromise security. From the point of view of an adversary, they introduce fresh randomness.</p>
<p>Each leaf has an implicit secret known only to the corresponding member (i.e. not stored in the tree). All other “inner” nodes in the tree contain a DH public key for that node and a corresponding secret key that is stored encrypted at the node.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/beekem_inner_nodes.png" alt="BeeKEM inner nodes">
</figure>
<p>Each node in a binary tree has a single sibling node, as illustrated in the following diagram:</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/siblings.png" alt="Node sibling">
</figure>
<p>When encrypting or decrypting a new secret at a parent node, a child node performs a <strong>Diffie Hellman key exchange</strong> with its sibling. That means it will use its sibling DH public key and its own secret key to derive what we’ll call a “shared DH secret”. The shared DH secret is used to encrypt and decrypt the new secret at the parent.</p>
<p>A brief (simplified) aside on how Diffie Hellman key exchange works. Imagine Alice and Bob each have their own DH public keys (alice_pk and bob_pk) and DH secrets (alice_sk and bob_sk). If Alice combines her DH public key with Bob’s secret key, she can derive a shared DH secret. If Bob combines his DH public key with Alice’s secret key, he can derive the same shared DH secret. In this way, they can agree on a shared secret just by exchanging their public keys in the open.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/diffie_hellman_basics.png" alt="Diffie Hellman basics">
</figure>
<p>We use this same principle to derive a shared DH secret for any sibling pair in our tree. For example, to decrypt Alice’s parent node, Alice can use its secret <code>alice_sk</code> and its sibling’s public key <code>bob_pk</code> to derive a shared DH secret. It can then use that shared secret to decrypt the secret at the parent node.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/beekem_diffie_hellman_example.png" alt="BeeKEM Diffie Hellman example">
</figure>
<p>In pseudocode, this might look like:</p>
<div>
<pre><code>shared_dh_secret = DH(bob_pk, alice_sk)
parent_secret =
  encrypted_parent_secret.decrypt_with(shared_dh_secret)
</code></pre>
</div>
<p>That parent secret can in turn be used for a Diffie Hellman exchange with the parent’s sibling’s DH public key.</p>
<p>For a member to decrypt the root secret, it must start from its leaf and traverse the tree one parent at a time until it reaches the root. The sequence of nodes from leaf to root is called that leaf’s “path”. At each node in its path, it will derive a shared DH secret with its sibling to decrypt the secret at its parent. Once it’s decrypted the root secret, it’s done.</p>
<p>In the following diagram, the decrypting leaf’s path is marked in green. The siblings used as Diffie Hellman partners along the way are marked in purple:</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/beekem_path.png" alt="BeeKEM path">
</figure>
<p>There are three mutating operations that can be performed on the tree: Update Key (i.e. key rotation), Remove Member, and Add Member. Let’s look at these in more detail.</p>
<h3 id="update-key"><a href="#update-key">Update Key</a></h3>
<p>Every member must periodically update the DH public key at its leaf in order to guarantee post-compromise security. When we update our leaf DH public key, we must then update the secrets for all the nodes on our path, eventually updating the root secret for the entire group.</p>
<p>Before traversing our path, we can derive a sequence of path secrets by applying BLAKE3’s key derivation function to an initial secret once for each node on the path. As we move up each parent on our path, we will encrypt the next derived secret and store it on that parent.</p>
<p>In order to encrypt the secret for a parent, we use Diffie Hellman key exchange as described above. We then derive a new Diffie Hellman public key from the secret for the parent, and store both that new DH public key and the corresponding encrypted secret at the parent.</p>
<p>In pseudocode:</p>
<div>
<pre><code>parent_secret = derived_secrets[next_idx]
shared_dh_secret = DH(child_sibling_pk, child_sk)
encrypted_parent_secret =
  parent_secret.encrypt_with(shared_dh_secret)
parent_pk = DH_pk_from(parent_secret)
parent_node.insert(parent_pk, encrypted_parent_secret)
</code></pre>
</div>
<p>Later on, when the sibling wants to decrypt that parent secret, it can do Diffie Hellman the other way, using the encrypter node’s DH public key with the sibling node’s secret to derive the same shared DH secret that was used to encrypt the parent.</p>
<div>
<pre><code>shared_dh_secret = DH(encrypter_pk, sibling_sk)
encrypted_parent_secret = parent_node.encrypted_secret
parent_secret =
  encrypted_parent_secret.decrypt_with(shared_dh_secret)
</code></pre>
</div>
<h3 id="membership-changes"><a href="#membership-changes">Membership Changes</a></h3>
<p>In order to explain membership changes, we must introduce the concept of “blanking” a node. Blanking a node means that we remove all key and secret information from that node. If the root node is blank, then the tree does not currently hold a shared group key. Some nodes are blanked after membership change operations, and all leaves beyond the last member leaf on the right are blank.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/blank_nodes.png" alt="Blank nodes">
</figure>
<p>If a tree has a blank root, then at least one member must perform an Update Key operation to restore a root secret. An update will replace all blank nodes on its update path with key information.</p>
<p>When we perform a <strong>Remove Member</strong> operation, we first blank the leaf corresponding to that member. We then blank the entire path from that leaf up to the root node.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/remove_member.png" alt="Remove member">
</figure>
<p>Notice that if a removed member performs an update concurrently with its removal, we need to ensure that the update does not survive (or else the member will continue to have access to the root secret). When merging concurrent removes with other operations, BeeKEM ensures that the remove paths are blanked after all other concurrent operations are merged.</p>
<p>When we perform an <strong>Add Member</strong> operation, we add the new member’s ID and public key to the next blank leaf on the right. We then blank the path from that leaf to the root.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/add_member.png" alt="Add member">
</figure>
<p>Notice that if two members add a member concurrently to the same tree, they will add them to the same leaf. BeeKEM resolves such conflicts on merge by sorting all concurrently added leaves and blanking their paths.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/merging_concurrent_adds.png" alt="Resolving add conflicts">
</figure>
<h3 id="handling-blank-nodes-on-update-and-decryption"><a href="#handling-blank-nodes-on-update-and-decryption">Handling Blank Nodes on Update and Decryption</a></h3>
<p>So far, we’ve assumed that every node has a sibling with key information. That’s what allowed us to use Diffie Hellman to derive a shared DH secret. But what happens when a node’s sibling is blank?</p>
<p>In that case, we must find the blank node’s <strong>resolution</strong>. A node’s resolution is the set of its highest non-blank descendents. Here’s an example:</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/node_resolution_examples.png" alt="Node resolution example">
</figure>
<p>If you have a blank sibling, you must do a separate encryption of the new parent secret for every member of your sibling’s resolution. For each of those members, you use its Diffie Hellman public key with your secret to derive a shared DH secret. You then encrypt the new parent secret using that shared secret and store it for that member.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/blank_sibling.png" alt="Blank sibling">
</figure>
<p>This means that if the resolution of a sibling node contains 5 members, you will need to store the parent secret 5 times, each one encrypted for a separate member.</p>
<p>The worse case scenario is if the entire inner tree is blank. Encrypting a new path will no longer be a logarithmic operation since every leaf will be contained in the resolution of some blank node on your path. Instead, the cost will be linear in the number of leaves: you will have to perform a separate encryption for every other leaf somewhere on your path.</p>
<p>When decrypting a leaf with blanks on its path, you simply skip those blanks. This works because the highest blank in your path will contain its last non-blank descendent in its resolution. So when you encounter a blank on your path, you hold onto the last secret you’ve seen and start skipping. When you eventually get to a non-blank node, you’ll use that secret you’re holding onto to derive the shared DH secret you need to decrypt the non-blank parent.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/skipping_blanks.png" alt="Skipping blanks">
</figure>
<h3 id="handling-concurrent-updates-with-conflict-keys"><a href="#handling-concurrent-updates-with-conflict-keys">Handling Concurrent Updates with “Conflict Keys”</a></h3>
<p>Keyhive assumes that concurrent operations can be merged in any causal order. Concurrent updates will always have some overlapping nodes in their paths (at least the root is shared by all paths). How does BeeKEM resolve these conflicts?</p>
<p>We must first consider our potential vulnerabilities. Imagine that an adversary has compromised a group member and their leaf secrets. They can use a compromised leaf secret to decrypt the root secret at some point in time. Recall that knowing a leaf secret means you can decrypt all of the inner node secrets along your path.</p>
<p>If an adversary knows the secret for a leaf, it’s possible they will continue to be able to decrypt the group secret even if that leaf is rotated during a future concurrent update. This depends on how we handle merging concurrent updates.</p>
<p>If we just naively pick a winner for updates to a series of overlapping nodes, then the new information added by the loser’s key rotation will no longer be necessary to decrypt the root secret. We effectively forget that information.</p>
<p>Notice that the winner used the outdated keys from the loser for its update (since the winner’s and loser’s updates were concurrent). That means an adversary with the loser’s outdated leaf keys will still be able to decrypt the winner’s nodes. Subsequent updates by other leaves that only intersect with the winner’s path will also fail to exclude our adversary.</p>
<p>In BeeKEM, when merging concurrent updates, we ensure that all updates contribute information along their entire paths. We keep conflicting information around at each node until it is overwritten by a causally subsequent operation (or blanked by a membership change).</p>
<p>If two leaves update the same node concurrently, then they would have each written a distinct Diffie Hellman public key and encrypted secret to that node. In this scenario, we call these “conflict keys” and store them both when merging conflicts.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/03/merging_concurrent_updates.png" alt="Merging conflict keys">
</figure>
<p>Imagine a member subsequently updates the tree. If a node on its leaf’s path has a sibling with conflict keys, this means there is an unresolved merge at that sibling. An adversary could have access to both sides of the corresponding fork. So it wouldn’t be secure to use those conflict keys for Diffie Hellman. Instead, we take the resolution of the node, just as we did with blank nodes. We then separately encrypt the secret for every DH public key in the resolution, again just as we did with blank nodes.</p>
<p>This means that for BeeKEM we update the definition of the “resolution of a node” to mean either (1) the single DH public key at that node <strong>if there is exactly one</strong> or (2) the set of highest non-blank, <strong>non-conflict</strong> descendents of that node.</p>
<p>If we merged in both sides of a fork, then we know we’ve updated both corresponding leaves with their latest rotated DH public key. Since taking the resolution skips all conflict nodes, it ensures that we integrate the latest information when encrypting a parent node. That’s because any non-conflict nodes have successfully integrated all causally prior information from their descendents.</p>
<p>This means an adversary needs to compromise one of the latest leaf secrets to be able to decrypt an entire path to the root. Even knowing outdated leaf secrets at multiple leaves will not be enough to accomplish this. An honest user, on the other hand, will always know the latest secret for its leaf.</p>
<p>During a future update (key rotation), if you find a conflict key node on the path you’re updating, you can remove all conflict keys at that node and replace them with a single new public key and encrypted secret (as with normal parent encryption). That’s because your update operation is the causal successor of all the operations that placed those conflict keys. This means your tree contains the necessary information from all of those past updates, which is integrated into your update.</p>
<p>BeeKEM’s approach comes with two downsides. First, before conflicts are resolved by subsequent updates or blanks, we must store extra information at each conflict node. Second, conflict keys add extra encryption and decryption overhead. In the worst case, where the tree is populated with the maximum number of possible conflict keys, the space cost would be <code>n log(n)</code> (as opposed to the best case of <code>2n</code>). The time cost in the worst case would be linear (as opposed to logarithmic), as when the tree is maximally blanked. Our current set of benchmarks reflect these time costs when we intentionally exercise our worst cases.</p>
<p>BeeKEM provides Keyhive with a Continuous Group Key Agreement protocol that is well-suited to distributed local-first applications that require end-to-end encryption for groups on the order of thousands of members. It exhibits logarithmic performance in the common case with linear worst case. And it provides both forward secrecy and post-compromise security.</p>
<p>In the future, we plan to write a paper explaining this protocol and its security and performance characteristics in more detail. But hopefully this has given you a sense for how it works.</p>
<!-- Footnotes -->
<!-- External Links -->
<section role="doc-endnotes"><hr><ol>
<li id="fn1"><p>TreeKEM was inspired by earlier work on <a href="https://eprint.iacr.org/2017/666.pdf">Asynchronous Ratcheting Trees (ART)</a>. <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>Weidner and Kleppmann argue that secure messaging for large groups does not have a plausible threat model since it would be too easy to infiltrate them. But Keyhive is designed for shared documents. In the context of private documents shared within a company with thousands of employees, for example, we would still expect access control. It’s also worth mentioning that in Keyhive, a single user might have multiple device-specific keys (each of which will count as a member from Keyhive’s perspective). <a href="#fnref2">↩︎</a></p>
</li>
<li id="fn3"><p>Other alternatives include <a href="https://eprint.iacr.org/2022/251">CoCoA</a> and <a href="https://eprint.iacr.org/2022/559.pdf">DeCAF</a>. <a href="#fnref3">↩︎</a></p>
</li>
<li id="fn4"><p>BeeKEM in isolation provides forward secrecy, but Keyhive as a whole does not. That’s because users require access to an entire document and Keyhive is used to encrypt that document in chunks. If you can decrypt a chunk, you will gain access to the key for decrypting the previous chunk (as described in an earlier lab note). <a href="#fnref4">↩︎</a></p>
</li>
<li id="fn5"><p>More precisely, we use the root secret as one input into deriving an “application secret”. It is the application secret that is directly used for encrypting and decrypting document chunks. There can be multiple application secrets derived from one root secret, but each application secret is used to encrypt exactly one document chunk. Updating the root secret provides post-compromise security by ensuring no prior key can be used to derive application secrets associated with it. We are glossing over these details in this lab note since they strictly speaking happen outside BeeKEM, which is concerned with group agreement on the root secrets. <a href="#fnref5">↩︎</a></p>
</li>
</ol>
</section>
</article>
<article>
  <h2><a href="https://www.inkandswitch.com/keyhive/notebook/03/">03 · What's In a Name?</a></h2>
  <p>2025 Feb 27</p>
<p>The Beehive project is now officially renamed <em>“Keyhive”!</em></p>
<p>Changing names can be a painful process, and doing so as early as possible in a project’s life is helpful. As <a href="https://www.karlton.org/2017/12/naming-things-hard/">Phil Karlton famously said</a>, there’s exactly two hard problems in computer science: caching, naming, and off-by-one errors. Naming is important for orienting readers, searching the web, and avoiding ambiguity. We wanted to make sure that the name was finalized prior to open sourcing the code.</p>
<p>There is a naming philosophy that says names should be descriptive, or at least present a direct “mental hook” that implies what the signified thing does. Additional puns and whimsey help with memorability.</p>
<p>The previous project name “Beehive” was intended to present a sense of safety and collaboration: bees build complex-yet-sturdy structures together while working independently, and guard their hives to make a safe space on the inside. This metaphor was also inspired by earlier conversations with <a href="https://en.wikipedia.org/wiki/Christine_Lemmer-Webber">Christine Lemmer-Webber</a> about metaphors to help explain capability systems (like Keyhive) to folks not familiar with formal concepts from the <a href="https://en.wikipedia.org/wiki/Object-capability_model">object-capabilities</a> world like <a href="https://erights.org/elib/concurrency/vat.html">Vats</a>.</p>

<p>At the time that we decided on “Beehive”, the team was aware of namespace conflicts in the academic distributed systems literature<sup><a href="#fn1" id="fnref1">1</a></sup>. Over time it’s become clear that we also have this problem with packages in more than one language ecosystem. Since we don’t want to tie the project to <a href="https://automerge.org/">Automerge</a> exclusively, prefixing the core project with <code>automerge-*</code> was not appropriate.</p>
<p>We are retaining our apian naming for other parts of the project. <a href="https://www.inkandswitch.com/keyhive/notebook/#beekem">BeeKEM</a> maintains it’s pun on TreeKEM, and Beelay is the Keyhive-enabled relay.</p>
<p>Beehive is dead. Long live Keyhive!</p>
<!-- Footnotes -->
<!-- Internal Links -->
<!-- External Links -->
<section role="doc-endnotes"><hr><ol>
<li id="fn1"><p>Some examples include <a href="https://www.cs.cornell.edu/people/egs/615/beehive.pdf">Beehive: Exploiting Power Law Query Distributions for O(1) Lookup Performance in Peer to Peer Overlays</a>, <a href="https://iqua.ece.toronto.edu/papers/junli-tpds17.pdf">Beehive: Erasure Codes for Fixing Multiple
Failures in Distributed Storage Systems</a>, and <a href="https://courses.cs.duke.edu/spring17/compsci590.7/Papers/Beehive16.pdf">Beehive: Simple Distributed Programming in Software-Defined Networks</a>. <a href="#fnref1">↩︎</a></p>
</li>
</ol>
</section>
</article>
<article>
  <h2><a href="https://www.inkandswitch.com/keyhive/notebook/04/">04 · Opening the Pre-Alpha</a></h2>
  <p>2025 Mar 10</p>
<p>We’re excited to announce that we’re opening the <em>pre-alpha</em> code for the following libraries:</p>
<ul>
<li><a href="https://github.com/inkandswitch/keyhive/tree/main/beelay/beelay-core">beelay-core</a>: Auth-enabled sync over end-to-end encrypted data</li>
<li><a href="https://github.com/inkandswitch/keyhive/tree/main/keyhive_core">keyhive_core</a>: The core signing, encryption, and delegation system</li>
<li><a href="https://github.com/inkandswitch/keyhive/tree/main/keyhive_wasm">keyhive_wasm</a>: <a href="https://webassembly.org/">Wasm</a> wrapper around <code>keyhive_core</code>, plus TypeScript bindings</li>
</ul>
<p>⚠️ <strong>DO NOT use this release in production applications</strong> ⚠️</p>
<p>We want to emphasize that this is an early preview release for those that are curious about the project. Expect there to be bugs, inconsistencies, and unstable APIs. This code has also not been through a security audit at time of writing.</p>
<p>If you have any questions, thoughts, or feedback, please contact the team at by filing a <a href="https://github.com/inkandswitch/keyhive/issues/new">GitHub Issue</a>, or in the <a href="https://discord.com/channels/1200006940210757672/1347253710048333884"><code>keyhive-beelay</code> channel in the Automerge Discord</a>.</p>
<!-- External Links -->
</article>
<article>
  <h2><a href="https://www.inkandswitch.com/keyhive/notebook/05/">05 · Syncing Keyhive</a></h2>
  <p>2025 Mar 13</p>
<h2>Syncing Keyhive</h2>
<p>The last few lab notes have focused on the cryptographic components which support a local first access control system. Those being a capability based system for managing write access to documents, and a key agreement protocol for encrypting and decrypting writes (thus implementing read control). We now have to think about how to actually transfer this data between devices.</p>
<p>Alongside the Keyhive project we have also been working on a new sync protocol for Automerge. The existing sync protocol works well for a single document but it is common for Automerge applications to have thousands of documents. Furthermore, the sync protocol requires that both ends are able to read the document whilst one of the objectives of Keyhive is for the server to only have access to the encrypted data.</p>
<p>Solving all of these problems in one go is the job of Beelay (the name is inspired by the idea of Beehive being the relay for all the bees (peers) in the Keyhive).</p>
<h2 id="overview"><a href="#overview">Overview</a></h2>
<p>Beelay is an RPC protocol which is designed to be usable over any transport which can provide confidentiality (in practice, HTTPS, WebSockets, or raw TLS). The intended usage is to create a local Beelay instance and then connect it to other peers, Beelay will then authenticate with the other peers and synchronise everything which each side thinks the other has access to.</p>
<p>Each message is authenticated by signing it with the <a href="https://en.wikipedia.org/wiki/EdDSA#Ed25519">Ed25519</a> key that the local node controls. To synchronise we first synchronise the Keyhive membership graph which each end has, this allows each end to determine what documents the other end should have access to. Then we synchronise the collection of documents to figure out which documents are out of sync, before finally synchroising each individual document.</p>
<h2 id="authentication"><a href="#authentication">Authentication</a></h2>

<h3 id="what-are-we-authenticating"><a href="#what-are-we-authenticating">What are we authenticating?</a></h3>
<p>It will be useful here to review how we intend to represent devices, people, and documents in Keyhive. In Keyhive there are two important kinds of principal: “groups” and “individuals”. An individual is identified by a single Ed25519 public key - which is immutable - whilst a group is a collection of other principals (groups or individuals) and can be updated by it’s members. One way we intend to use this is to represent a person (or more specifically their authority) as a group, with each of the persons devices being an individual member of the group. Key rotation can then be handled by adding a new individual to the group and removing the old one.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/person-group.png" alt="A diagram of a group representing a person, with three nodes representing devices called 'phon', 'laptop', and 'table' all of which have arrows pointing to the person node">
</figure>
<p>Groups can contain other groups. This means that we can represent as groups, where each member of the organisation is another group representing a person (or for that matter another organisation, such as a department).</p>
<p>Another useful aspect of this structure is that documents can also be represented as groups. This allows documents to have members which can access the document. For example, a document representing this lab note might add the Ink &amp; Switch group so that all (transitive) members of the Ink &amp; Switch group can read and write to it. Documents can also add other documents which represents “folder” style relationships. The “lab notes” folder document (which is also a group, because all documents are) might contain all the lab notes and have the Ink &amp; Switch as a member.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/person-doc-group.png" alt="Another diagram, this time with a node labelled 'Ink &amp; Switch' which represents an organisation with the original 'person' diagram being a member of that group">
</figure>
<p>What this all means for the sync protocol is that any given peer is represented by an “individual”. The task of authentication is to ensure that each end knows what Ed25519 public key the other end is using so that we can relate that individual key to the Keyhive membership graph.</p>
<h3 id="how-do-we-authenticate"><a href="#how-do-we-authenticate">How do we authenticate?</a></h3>
<p>One solution which might seem obvious here is to rely on an authenticated TLS session. While we use TLS for confidentiality, and the browser itself authenticates the server, our application <em>also</em> needs to know about the server’s public key. Unfortunately, the browser doesn’t expose this information to the application context; there is no way in the browser to obtain the connection’s TLS certificate. We don’t just need to know that a connection is secure, we need to know the public key of the other end in order to use it for access control decisions and so on.</p>
<p>Given that each peer is represented by a public key, the simplest possible authentication scheme would be to sign each message. I.e. a message might look like this:</p>
<div>
<pre><code>type Envelope = {
    message: Uint8Array,
    signature: Signature,
    sender: PublicKey,
}

type PublicKey = Uint8Array
type Signature = Uint8Array
</code></pre>
</div>
<p>To authenticate a message we check that the signature is valid over the message, then we know that the other end is the individual represented by the given public key. There are two problems with this, <a href="https://en.wikipedia.org/wiki/Man-in-the-middle_attack">person in the middle (PITM)</a> attacks, and <a href="https://en.wikipedia.org/wiki/Replay_attack">replay attacks</a>.</p>
<h3 id="person-in-the-middle-attacks"><a href="#person-in-the-middle-attacks">Person in the middle attacks</a></h3>
<p>A good example of PITM attack on this protocol would be a phishing based attack. Imagine an application which allows users to input the URL of a sync server to sync from. Let’s say an attacker creates a sync server at a familiar looking URL, such as <code>wss://sync.automege.org</code> (note the misspelling) and convinces the user to enter this URL into their application. The attacker can now intercept all messages intended for the real <code>sync.automerge.org</code> server and forward them on to the sync server. This means the attacker can read all the messages and even modify messages sent back to the client.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/pitm.png" alt="A diagram with three nodes connnected in a line, the right most is labelled 'browser', the middle is labelled 'sync.automerge.org (attacker)' and the rightmost is labelled 'sync.automerge.org'">
</figure>
<p>The fundamental problem here is that the message is bound to the sender but not to the receiver. We can solve this by adding an “audience” field to the message.</p>
<div>
<pre><code>type Envelope = {
    message: Message,
    signature: Signature,
    sender: PublicKey,
}

type Message = {
    payload: Uint8Array,
    audience: PublicKey,
}
</code></pre>
</div>
<p>This doesn’t quite solve the problem above though. At this stage we only have a URL, we don’t have a public key for the server. To solve this we allow the audience field to either be a public key, or the URL we are addresssing. In this case the audience would be <code>sync.automege.org</code>. This means that when the PITM forwards the message to <code>sync.automerge.org</code> the real server can check and see that the audience doesn’t match <code>sync.automerge.org</code> and reject the message.</p>

<p>This works because the connection is being made over TLS, which binds the network transport to the hostname, ensuring that whoever is at the other end, they definitely control <code>sync.automerge.org</code>. Beelay is designed to work over arbitrary transports though, in other network setups such as P2P transports you will need to obtain the public key of the receiver out of band.</p>
<h3 id="replay-attacks"><a href="#replay-attacks">Replay attacks</a></h3>
<p>In a replay attack an attacker is somehow able to intercept messages and store them, and then later replay them to the server. To mitigate this we add a timestamp to the message and then reject messages which are older than some validity window that accounts for latency plus a <a href="https://en.wikipedia.org/wiki/Clock_skew">clock skew</a> grace period — e.g. 5 minutes.</p>
<p>The main issue with this scheme is that the clocks of two peers might be out of sync by arbitrary amounts of time. Soft locking the sync system due to clock sync issues is not acceptable. To solve this, when a peer rejects a message due to an old timestamp, the rejecting peer sends their current timestamp along with the rejection message. This allows the sending peer to determine the drift between their local clock and the remote clock and adjust the timestamps on the messages they send, and account for it during this session.</p>
<h3 id="summary"><a href="#summary">Summary</a></h3>
<p>Altogether then, our messages look a bit like this:</p>
<div>
<pre><code>type Envelope = {
    message: Message,
    signature: Signature,
    sender: PublicKey,
}

type Message = {
    payload: Uint8Array,
    audience: PublicKey | string,
    timestamp: number,
}
</code></pre>
</div>
<p>To authenticate a message we check that the signature is valid, that the audience is either our public key or the hash of our hostname (or some other string which is bound to the recipient in some way) and that the timestamp is new enough.</p>
<h2 id="syncing-the-membership-graph"><a href="#syncing-the-membership-graph">Syncing the membership graph</a></h2>
<p>Once we are authenticated, we need to determine what each side thinks the other should have access to. This means that we need to sync the Keyhive “membership graph”. This is the graph of groups and individuals which represent devices, people, organisations, and documents.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/what-are-we-syncing.png" alt="An image of three large boxes labelled group, document, and document. Each box has arrows pointing to the other and also contains within it a set of smaller boxes pointing to each other labelled op">
</figure>
<p>The membership graph is a directed graph of “operations” where each operation either creates a new node, delegates access to some other node, or revokes access. Unlike Automerge documents (which are also graphs) the membership operation graph is very shallow and wide, and the linked groups and documents can have cycles. There are many approaches to this problem, but it becomes much simpler if we frame it as <em>set reconciliation</em>, where each side has an unstructured set of operations and needs to figure out what operations the other side has that it needs (i.e. the delta between the two sets). We will encounter a very similar problem later, when we sync the collection of documents. In both cases we use a construction called <a href="https://arxiv.org/html/2402.02668v2">Rateless Invertible Bloom Lookup Tables</a> (RIBLT) to solve this problem.</p>
<h3 id="riblt-set-reconciliation"><a href="#riblt-set-reconciliation">RIBLT set reconciliation</a></h3>
<p>RIBLT is described in detail in <a href="https://arxiv.org/html/2402.02668v2">this paper</a>, what I will describe here are the important properties that the scheme gives us.</p>
<p>RIBLT is a set reconciliation protocol, which means there are two peers who have some possibly overlapping set of things which they want to have the same view of. I.e. after the protocol completes each side should have the union of the things each started with.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/set-reconciliation-1.png" alt="set reconciliation">
</figure>
<p>RIBLT solves this problem by having each side encode it’s set of things into a set of hashes and then generate a set of special “symbols” which one side sends to the other.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/riblt-things-to-hashes-to-symbols.png" alt="an image of a set of boxes labeled thing1, thing2, and thing3, with each box pointing to another box labelled hash(thing1), hash(thing2), hash(thing3). A larger box surrounds the entire set of boxese pointing to a sequence of boxes labelled symbol1, symbol2, symbol3">
</figure>
<p>These symbols are structured in such a way that once the receiver has received enough of them they will be able to decode the symbols into the set difference.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/riblt-symbols-decoded.png" alt="an image of three boxes labeled symbol1, symbol2, symbol3 with an arrow - labelled decode - pointing to two bases labeled things we have which they dont and things they have which we dont containg a box labelled hash(thing1) and hash(thing2) respectively">
</figure>
<p>The details are a bit fiddly but the really important part is that the number of symbols which must be sent is proportaional to the set difference between the two peers. Specifically, the number of symbols sent ranges from 1.7x (for small sets) down to 1.35x (for large sets) the set difference.</p>
<p>For example, If we have one billion items each, but only five differing items, we can reconcile in 5 * ~1.5 = 7.5 symbols. The symbols themselves are (in our case) 32 bytes long, so we can reconcile a billion items in 240 bytes.</p>
<p>The other important part is that the result of decoding is the set of hashes - not the things themselves. In fact, we can use any fixed length array which uniquely represents the thing.</p>
<h3 id="syncing-the-membership-graph"><a href="#syncing-the-membership-graph">Syncing the Membership Graph</a></h3>
<p>So, we use RIBLT sync to synchronise the membership graph. The process is mostly driven by the client (in the peer to peer case we arbitrarily choose that the peer who initiated the connection is the client).</p>
<p>First, the client sends a request to the server to begin membership sync. The server stores a pointer to the current set of ops which it thinks the other end needs and then responds with a session ID to identify this sync session, and the first 10 symbols of the RIBLT sync.</p>
<p>The client now receives the first 10 symbols and attempts to decode them. If they are able to decode then they are done and they know the set difference, otherwise, they send a request for the next 10 symbols, using the session ID to specify which state they are syncing with.</p>
<p>Eventually the client knows the set difference in terms of hashes of operations which only the server has, and operations which only the client has. Finally, the client requests the missing operations by sending their hash, and uploads the symbols which they believe the server is missing.</p>
<figure>
<img src="https://www.inkandswitch.com/keyhive/notebook/static/05/beginsync-1.png" alt="begin sync">
</figure>
<h2 id="document-collection-sync"><a href="#document-collection-sync">Document Collection Sync</a></h2>
<p>At this point each end has determine what documents it thinks the other should have acces to. The next step is to determine which documents are out of sync. To achieve this we use RIBLT sync again, this time instead of the set we are synchronising being the set of membership operations it is the set of (document ID, state) pairs, where <code>state</code> here is a hash of the document state.</p>
<p>There are two components to the document state which we care about for the purposes of synchronisation. One is the heads of the Automerge document - the document content is encrypted but we keep the hashes of the Automerge commit graph outside of the encryption envelope, so the sync server knows the heads.</p>
<p>The other piece of state are the BeeKEM operations for the document. Recall that BeeKEM is a continuous group key agreement (CGKA) protocol which allows peers to concurrently decide on what keys to encrypt content to. We need to have the latest CGKA ops in order to be able to decrypt the document content.</p>
<p>How do we form our RIBLT symbols then? One way would be to make each symbol <code>hash(document ID, document heads, cgka ops)</code>. Then, once we’ve performed RIBLT sync we make another network call to convert each symbol into the document ID which is out of sync. However, we can do a little better than this. Recall that the RIBLT symbol is just any fixed length byte array, and document IDs are a 32 byte array. This means that instead of a hash for the symbol, we use <code>(document ID, hash(heads, cgka ops)</code>. This means that once we have decoded the symbol we already know what the document ID is for the symbol in question without doing any more round trips.</p>
<p>The process for actually running this sync then is similar to the membership sync. Using the session ID from the membership sync the client fetches new document symbols from the server until it is able to decode the first symbol it received, at which point it knows which symbols are out of sync.</p>
<h2 id="document-sync"><a href="#document-sync">Document Sync</a></h2>
<p>By this point we have a list of document IDs which are out of sync. We now have to sync the CGKA ops and encrypted commit graph for each document. For the CGKA sync we can use our old friend RIBLT sync to sync the set of CGKA ops, but for the document content we need to do something a bit different because we want to be able to take advantage of the bandwidth gains we get from compacting Automerge documents.</p>
<h3 id="cgka-ops"><a href="#cgka-ops">CGKA Ops</a></h3>
<p>The set we are synchronizing here is the set of CGKA ops for the document. We use the hash of each op to create our RIBLT symbols. As with other RIBLT syncs, the client requests symbols from the server until it is able to decode it’s first symbols at which point it knows what ops to upload and what ops to request.</p>
<h3 id="sedimentree"><a href="#sedimentree">Sedimentree</a></h3>
<p>Syncing the document content is more complicated. Initially it might seem that we could just use RIBLT sync again where the symbols to sync are the commit hashes of the commits in the Automerge commit graph. This would certainly work, however, it would use <em>a lot</em> of bandwidth. Automerge commits are frequently made for each keystroke, adding a 32 byte hash for each keystroke would be very expensive.</p>
<p>This is a specific instance of a general problem which is that naive encodings of the Automerge commit graph contain enormous amounts of metadata overhead. We have a <a href="https://automerge.org/automerge-binary-format-spec/">compact binary encoding</a> which reduces this overhead to around 10% over the underlying data. What we need is a way to use this data in the sync protocol.</p>
<p>In the current sync protocol this is not a problem, the sync server has the plaintext in memory and so it can compact the document on the fly when a new peer comes online. For Beelay this isn’t an option because the server only has the ciphertext. What to do?</p>
<p>We have come up with a simple protocol for this which we call “sedimentree”. The idea is that every so often we compress ranges of the commit graph into chunks and we do this recursively, so that every so often smaller chunks get compressed into larger chunks. We do this in such a way that older (i.e. closer to the root of the commit graph) end up in larger and larger chunks as time goes on. This forms a tree structure, with older chunks being closer to the root of the tree - hence sedimentree, with chunks being like layers of sedimentree rock.</p>
<p>Choosing the boundaries of the chunks is a little fiddly because we need to do it in such a way that peers with different sets of changes still agree on what should go into each chunk. We do this by using the number of trailing zeros in the hash of a commit as the boundary. There are more details on this <a href="https://github.com/inkandswitch/keyhive/blob/main/design/sedimentree.md">here</a>.</p>
<p>The end result of this structure is that we can sync the document in two steps:</p>
<ul>
<li>Download a “summary” of the sedimentree, which contains just the boundaries of the chunks.</li>
<li>Download the chunks we don’t have, and upload the ones the other end doesn’t have</li>
</ul>
<h2 id="conclusion"><a href="#conclusion">Conclusion</a></h2>
<p>Overall then sync looks like this:</p>
<ul>
<li>Sync membership graph
<ul>
<li>Run RIBLT set reconciliation on the membership ops</li>
<li>Download ops we are missing</li>
<li>Upload ops the remote is missing</li>
</ul>
</li>
<li>Sync collection state
<ul>
<li>Run RIBLT set reconciliation on the set of document states</li>
</ul>
</li>
<li>Sync out of sync documents, for each document which is out of date
<ul>
<li>Run RIBLT sync on the CGKA ops</li>
<li>Download CGKA ops we are missing</li>
<li>UPload CGKA ops the remote is missing</li>
<li>Run sedimentree sync on the document content</li>
</ul>
</li>
</ul>
<p>One thing which may be concerning here is the number of round trips. We should especially worry about this in the common case where only one document has changed</p>
<ul>
<li>One round trip for the membership sync</li>
<li>One round trip for collection state</li>
<li>One round trip for CGKA sync</li>
<li>Two round trips for sedimentree sync</li>
</ul>
<p>We should be able to simplify this. One the initial message when we begin membership sync we can send the clients first 5 (say) membership RIBLT symbols and first 5 collection state symbols. In the common case the server will be able to decode these symbols (because only one document has changed) and immediately determine which document has changed, then the server can send back a response with the sedimentree summary for the changed document and the first 5 symbols of the server CGKA RIBLT state. The client will in most cases be able to determine if any CGKA ops are missing and immediately download any missing document state.</p>
<p>Thus in the common case we can sync graph updates (auth, content, etc) in just two round trips.</p>
<!-- External Links -->
</article>

  <article>
    <hr>
    <div>
  <h6>The Ink &amp; Switch Dispatch</h6>
  <p>Keep up-to-date with the lab's latest findings, appearances, and happenings by subscribing to our newsletter. For a sneak peek, <a href="https://www.inkandswitch.com/newsletter">browse the archive</a>.</p>
  

</div>
  </article>

  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cormac McCarthy's personal library (257 pts)]]></title>
            <link>https://www.smithsonianmag.com/arts-culture/two-years-cormac-mccarthys-death-rare-access-to-personal-library-reveals-man-behind-myth-180987150/</link>
            <guid>45444694</guid>
            <pubDate>Wed, 01 Oct 2025 23:06:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/arts-culture/two-years-cormac-mccarthys-death-rare-access-to-personal-library-reveals-man-behind-myth-180987150/">https://www.smithsonianmag.com/arts-culture/two-years-cormac-mccarthys-death-rare-access-to-personal-library-reveals-man-behind-myth-180987150/</a>, See on <a href="https://news.ycombinator.com/item?id=45444694">Hacker News</a></p>
Couldn't get https://www.smithsonianmag.com/arts-culture/two-years-cormac-mccarthys-death-rare-access-to-personal-library-reveals-man-behind-myth-180987150/: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>